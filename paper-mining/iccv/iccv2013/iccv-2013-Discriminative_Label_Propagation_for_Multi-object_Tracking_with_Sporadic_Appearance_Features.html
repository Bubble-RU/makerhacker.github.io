<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-120" href="#">iccv2013-120</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</h1>
<br/><p>Source: <a title="iccv-2013-120-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Kumar_Discriminative_Label_Propagation_2013_ICCV_paper.pdf">pdf</a></p><p>Author: K.C. Amit Kumar, Christophe De_Vleeschouwer</p><p>Abstract: Given a set of plausible detections, detected at each time instant independently, we investigate how to associate them across time. This is done by propagating labels on a set of graphs that capture how the spatio-temporal and the appearance cues promote the assignment of identical or distinct labels to a pair of nodes. The graph construction is driven by the locally linear embedding (LLE) of either the spatio-temporal or the appearance features associated to the detections. Interestingly, the neighborhood of a node in each appearance graph is defined to include all nodes for which the appearance feature is available (except the ones that coexist at the same time). This allows to connect the nodes that share the same appearance even if they are temporally distant, which gives our framework the uncommon ability to exploit the appearance features that are available only sporadically along the sequence of detections. Once the graphs have been defined, the multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured by each of the graphs. This results into a difference of convex program that can be efficiently solved. Experiments are performed on a basketball and several well-known pedestrian datasets in order to validate the effectiveness of the proposed solution.</p><p>Reference: <a title="iccv-2013-120-reference" href="../iccv2013_reference/iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This is done by propagating labels on a set of graphs that capture how the spatio-temporal and the appearance cues promote the assignment of identical or distinct labels to a pair of nodes. [sent-7, score-0.524]
</p><p>2 The graph construction is driven by the locally linear embedding (LLE) of either the spatio-temporal or the appearance features associated to the detections. [sent-8, score-0.482]
</p><p>3 Interestingly, the neighborhood of a node in each appearance graph is defined to include all nodes for which the appearance feature is available (except the ones that coexist at the same time). [sent-9, score-1.021]
</p><p>4 This allows to connect the nodes that share the same appearance even if they are temporally distant, which gives our framework the uncommon ability to exploit the appearance features that are available only sporadically along the sequence of detections. [sent-10, score-0.779]
</p><p>5 Once the graphs have been defined, the multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured by  each of the graphs. [sent-11, score-0.397]
</p><p>6 We assume that the targets have been detected at each time instant and their appearance features (if available) have been extracted. [sent-16, score-0.411]
</p><p>7 Then, our objective is to link these detections into consistent trajectories using a graphbased formalism. [sent-17, score-0.21]
</p><p>8 With such a stationary measurement process, the likelihood that the detections along a path correspond to the same physical object can be reasonably es-  timated based on the accumulation of dissimilarities (similarities) between consecutive nodes in the path. [sent-25, score-0.361]
</p><p>9 In contrast, these approaches are not appropriate in cases for which appearance features cannot be measured with same accuracy and reliability in every space and time co-ordinates. [sent-26, score-0.239]
</p><p>10 In the i-th layer, running through a node is penalized when the appearance of the node is available and differs from the i-th presumed appearance. [sent-35, score-0.423]
</p><p>11 This method demonstrates that exploiting sporadic features can significantly improve the tracking performance. [sent-37, score-0.362]
</p><p>12 How2000  (a) Two trajectories withT 2im ×e 2 appearance measurements  (b) Spatio-temporal graph  (c) Appearance graph  (d) Exclusion graph  Figure 1. [sent-38, score-0.729]
</p><p>13 (a) An example with two targets (red and blue) with associated detections at each time. [sent-40, score-0.319]
</p><p>14 Gray detections mean that no appearance feature is available. [sent-41, score-0.384]
</p><p>15 (b) Spatio-temporal graph that depicts the spatio-temporal association between the nodes, (c) Appearance graph that connects nodes even if they are far in time. [sent-42, score-0.564]
</p><p>16 (d) Exclusion graph in which edges connect nodes that coexist at the same time. [sent-43, score-0.519]
</p><p>17 ever, it is restricted to cases for which the number and the appearance of the targets are known a priori. [sent-45, score-0.32]
</p><p>18 In contrast, [5] proposes an iterative hypothesis testing strategy to exploit appearances features that are corrupted by non-stationary noise or are only sporadically available. [sent-46, score-0.274]
</p><p>19 In short, the authors iteratively consider each node in the graph as a key-node, and investigate how to link this keynode with other nodes in its neighborhood, under the assumption that the target appearance is defined by the keynode appearance. [sent-47, score-0.819]
</p><p>20 This is done through a shortest-path computation in the temporal neighbourhood, while promoting the nodes that have an appearance similar to that of the keynode. [sent-48, score-0.391]
</p><p>21 This not only allows to handle the cases for which the discrete set of possible appearance is not known, but also alleviates the construction of the L-layered graph. [sent-49, score-0.279]
</p><p>22 For this, we construct a number of distinct graphs, one for each appearance feature, apart from the usual spatiotemporal graph. [sent-54, score-0.338]
</p><p>23 Additionally, we also construct an exclusion graph in order to reflect the fact that two detections that occur at the same time should be assigned to distinct labels. [sent-55, score-0.772]
</p><p>24 L is ttehem npuormabl,e Kr o afp appearance nfeeat exurcelsu. [sent-57, score-0.207]
</p><p>25 In case of a sport game, for example, the jersey color and the digit, printed on it, can be considered as two appearance features, and result in two distinct appearance graphs. [sent-61, score-0.673]
</p><p>26 The framework is scalable in that it allows incorporating as many appearance features as needed. [sent-62, score-0.207]
</p><p>27 An edge connects two nodes and has a weight that increases with the similarity between the nodes in terms of space, time and appearance. [sent-66, score-0.4]
</p><p>28 Exceptionally, in case of the exclusion graph, the weights among the nodes, which occur at the same time, are equal. [sent-68, score-0.357]
</p><p>29 Given these graphs, the tracking problem is then formulated as finding a label assignment that jointly and consistently labels the nodes. [sent-69, score-0.3]
</p><p>30 The quality  of labelling is measured by the labelling error, that accumulates the difference in the labels between a node and other nodes that are connected to it. [sent-71, score-0.792]
</p><p>31 Ifthe nodes are more likely to have similar labels, then the labelling error is small and vice versa. [sent-72, score-0.445]
</p><p>32 Due to the definition of weights in our graph, a good labelling should minimize the labelling error in the spatiotemporal and the appearance graphs while maximizing the error due to the exclusion graph. [sent-73, score-1.24]
</p><p>33 The rest of the paper is organized as follows: the construction of graphs and the formulation of the problem are presented in Section 2. [sent-74, score-0.207]
</p><p>34 Afterwards, the multi-object tracking is formulated as a consistent labelling problem in the graphs. [sent-80, score-0.367]
</p><p>35 Nevertheless, the constructions of spatio-temporal and appearance graphs are similar. [sent-86, score-0.342]
</p><p>36 Afterwards, the graph construction can be formulated as the problem of finding the vector of reconstruction weights wi? [sent-96, score-0.277]
</p><p>37 Once the weights for each data point are computed, we gather them into a graph G = (V, E, W), where  –  –  –  ×  V is the set of nodes, with i-th node corresponding to the i-th sample. [sent-129, score-0.313]
</p><p>38 In the case of the appearance graph,  X(i)  a data point xi corresponds to an appearance feature (e. [sent-147, score-0.414]
</p><p>39 The exclusion graph captures the constraint associated to the fact that the detections that occur at the same time instant should have different labels. [sent-153, score-0.826]
</p><p>40 Hence, the neighborhood of the i-th sample for the exclusion graph is defined to comprise all other samples that occur at the same time instant, and their weights are taken uniformly, i. [sent-154, score-0.579]
</p><p>41 Tracking problem formulation In this section, we formulate the multi-object tracking as a consistent labelling problem in a set of associated graphs. [sent-158, score-0.396]
</p><p>42 Given a graph G = (V, E, W), we consider a label assignment Y = (y1, . [sent-159, score-0.3]
</p><p>43 that assigns a label distribution yi ∈ [0, 1]|V | to each node i. [sent-163, score-0.226]
</p><p>44 etween the labels with respect to the graph G, we adopt the harmonic function approach, introduced in [28], and define the labelling error as  EG(Y ) =21? [sent-168, score-0.473]
</p><p>45 aph theory, IL i sis | positivesemi definite and therefore the labelling error Tr(Y? [sent-181, score-0.261]
</p><p>46 We represent the exclusion graph by L(−) , and other graphs by ,p = 0, . [sent-185, score-0.589]
</p><p>47 , K, where p = 0 corresponds to the spatio-temporal graph and 1 ≤ p ≤ K corresponds to the psp-athteio appearance graph. [sent-188, score-0.381]
</p><p>48 Wd e1 explicitly Kin ctroorrdeuscpeo tnhdes m toin thues (respectively, plus) superscript in order to emphasize that we would like to maximize (respectively, minimize) the labelling error on the corresponding graph. [sent-189, score-0.261]
</p><p>49 Given the measure of labelling error on each graph, we want to define a label assignment Y? [sent-190, score-0.387]
</p><p>50 that minimizes the labelling errors due to and maximizes the labelling error due to L(−) . [sent-191, score-0.492]
</p><p>51 Propagation of labels in a graph has been extensively studied in machine learning as a semi-supervised learning approach, and a concise sur-  vey of recent developments can be found in [18]. [sent-267, score-0.212]
</p><p>52 In short, most of these approaches assume that the label of a node is approximated as the linear combination of the labels of its neighbours [26]. [sent-268, score-0.232]
</p><p>53 Afterwards, they minimize the ratio between labelling errors due to the positive and negative graphs. [sent-272, score-0.231]
</p><p>54 Our method differs from [25] both in the definition of the graph similarities, and the label propagation method. [sent-274, score-0.348]
</p><p>55 Specifically, since we use multi-class labels instead of binary labels, and impose that the label distribution at each node should lie on a probability simplex, our problem is difficult to cast into their formalism. [sent-275, score-0.232]
</p><p>56 Message passing approaches have been used to label the nodes in a graph [19, 6]. [sent-278, score-0.444]
</p><p>57 In [19], a subset of the nodes are initially labelled and then a conditional random field is used to infer the label of the remaining nodes. [sent-279, score-0.319]
</p><p>58 For this, the authors compute various appearance features and assume that the features are always available with similar accuracies. [sent-280, score-0.239]
</p><p>59 Hence, their approach cannot exploit appearance features that are sporadic or affected by non-stationary noise. [sent-281, score-0.433]
</p><p>60 In [6], the authors utilized such non-stationary and sporadic features in order to priori-  tize the propagation of belief, related to the label probability distribution. [sent-282, score-0.432]
</p><p>61 Even though this approach allows to exploit sporadically available appearance features, it relies on the assumption that the target appearances are known beforehand, which is not the case of our approach. [sent-283, score-0.373]
</p><p>62 , the exclusivity constraint associated to the detections that coexist in time) has been considered in [16, 17] in order to learn discriminative appearance features. [sent-287, score-0.556]
</p><p>63 In these papers, first of all, a low-level but reliable tracker is used to connect unambiguous detections into tracklets. [sent-288, score-0.444]
</p><p>64 Afterwards, positive samples are defined by pairs of detections that belong to the same tracklet, while negative samples correspond to pairs that belong to tracklets that likely correspond to distinct objects (because they overlap in time). [sent-289, score-0.373]
</p><p>65 In [7, 8], the authors define a mutual exclusion term based on the physical distance between two detections that occur at the same time. [sent-292, score-0.535]
</p><p>66 Our 2003  formulation is different in that our mutual exclusion term  is defined in terms of the similarity in the label distribution rather than the position. [sent-295, score-0.366]
</p><p>67 The candidate detections are computed independently at each time instant based on a ground occupancy map, as described in [14]. [sent-306, score-0.268]
</p><p>68 For each detection, the jersey color and its digit are computed to define the appearance features. [sent-307, score-0.56]
</p><p>69 The digit feature is inherently sporadic as it is available only when the digit on the jersey faces the camera. [sent-310, score-0.736]
</p><p>70 However, the pedestrians wear similar dark clothes, which makes appearance comparison very challenging. [sent-315, score-0.257]
</p><p>71 Afterwards, 8-bin CIE-LAB color histograms are computed for each channel of each bounding box, resulting in a 24-bin appearance vector. [sent-318, score-0.281]
</p><p>72 The size of the temporal neighborhood in spatio-temporal graph is chosen to be 10 frames. [sent-333, score-0.222]
</p><p>73 In the current implementation, the graph construction step takes around 3 minutes for the PETS dataset and 2 minutes for the TUD Stadtmitte and the label propagation step is still the bottleneck. [sent-335, score-0.42]
</p><p>74 We first pre-process the data by aggregating some of the detections into tracklets based on a spatio-temporally local but reliable tracker. [sent-339, score-0.304]
</p><p>75 On the other hand, it helps to aggregate the appearance feature(s) along the tracklet in order to infer the appearance more accurately. [sent-342, score-0.486]
</p><p>76 The local but reliable tracker associates unambiguous detections between successive frames. [sent-343, score-0.408]
</p><p>77 Two detections are supposed to be unambiguous if the distance between them is less than 15 cm, and if there are no other detections within that distance. [sent-344, score-0.42]
</p><p>78 The re-  sulting tracklets define the nodes in our graphs. [sent-345, score-0.277]
</p><p>79 The neighborhood of the spatio-temporal graph is defined to extend the tracklet size by 100 frames on each side, which allows us to connect tracklets that are up to 4 seconds apart. [sent-346, score-0.484]
</p><p>80 In the exclusion graph, the neighborhood of a node consists of all the nodes that overlap in time. [sent-347, score-0.657]
</p><p>81 Finally, the appearance features of a tracklet is inferred by averaging the appearance features of the detections along the tracklet. [sent-348, score-0.663]
</p><p>82 The low-level tracker takes 15 seconds, graph construction takes 1minute and label optimization step takes 5 minutes. [sent-349, score-0.431]
</p><p>83 It uses only the spatiotemporal information in order to label the nodes in the graph. [sent-355, score-0.335]
</p><p>84 Thus, we construct only the spatio-temporal and the exclusion graphs. [sent-356, score-0.28]
</p><p>85 In this case, we use α0 > α1 (α0 for the spatio-temporal graph and α1 for the appearance graph) for the TUD and PETS datasets. [sent-360, score-0.381]
</p><p>86 This constrains the spatiotemporal consistency more strictly than the appearance con-  sistency. [sent-361, score-0.272]
</p><p>87 The reason is that the targets wear similar clothes and therefore have similar appearances in the datasets. [sent-362, score-0.252]
</p><p>88 This is because our approach is able to connect the detections even if they are far in time, resulting in longer and consistent tracks. [sent-380, score-0.245]
</p><p>89 00 28  GMCP tracker [27] Global appearance [23] Iterative hypothesis [5]  90. [sent-390, score-0.369]
</p><p>90 Similarly, the global appearance approach [23], the iterative hypothesis testing [5] and the GMCP tracker [27] use appearance features. [sent-405, score-0.621]
</p><p>91 This is done by setting α0 = 1, α1 = 0, α2 = 0, where the indices 0, 1 and 2 correspond to the spatiotemporal,the color and the digit graphs respectively. [sent-418, score-0.372]
</p><p>92 Afterwards, we use both the digit and the color features. [sent-419, score-0.237]
</p><p>93 As the color feature is less discriminant (because the players from the same team wear jersey of the same color) than the digit feature, we set α1 < α2. [sent-420, score-0.438]
</p><p>94 The reason might be because of the fact that iterative hypothesis testing framework associates two nodes only when the connection is sufficiently reliable than alternative connections. [sent-448, score-0.387]
</p><p>95 This might be because of the fact that we do not consider the appearance feature if the overlap between their We performed  a  grid search  on  for various values of α1 and 2005  α2  . [sent-456, score-0.273]
</p><p>96 Therefore, neither the position nor the appearance disambiguates the identities of the targets. [sent-461, score-0.261]
</p><p>97 Conclusion In this paper, we focus on the problem of multi-object tracking under sporadic appearance features. [sent-475, score-0.569]
</p><p>98 For this, a number ofdistinct graphs are constructed in order to capture the spatio-temporal (including the exclusivity constraint), and the appearance information. [sent-476, score-0.392]
</p><p>99 Afterwards, we formulate the multi-object tracking as a consistent labelling problem in the associated graphs, and provide an efficient solution based on DC (Difference of Convex) functions programming. [sent-477, score-0.396]
</p><p>100 Iterative hypothesis testing for multi-object tracking with noisy/missing appearance features. [sent-509, score-0.406]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('apidis', 0.283), ('exclusion', 0.28), ('labelling', 0.231), ('sporadic', 0.226), ('appearance', 0.207), ('digit', 0.197), ('nodes', 0.184), ('detections', 0.177), ('graph', 0.174), ('tud', 0.16), ('afterwards', 0.147), ('tracking', 0.136), ('graphs', 0.135), ('stadtmitte', 0.125), ('jersey', 0.116), ('motp', 0.116), ('targets', 0.113), ('sporadically', 0.113), ('node', 0.108), ('mota', 0.104), ('tracker', 0.099), ('tracklets', 0.093), ('coexist', 0.093), ('instant', 0.091), ('pets', 0.088), ('propagation', 0.088), ('amit', 0.087), ('label', 0.086), ('aryg', 0.085), ('gmcp', 0.075), ('tracklet', 0.072), ('construction', 0.072), ('convex', 0.069), ('connect', 0.068), ('ff', 0.067), ('unambiguous', 0.066), ('distinct', 0.066), ('spatiotemporal', 0.065), ('hypothesis', 0.063), ('wi', 0.062), ('lp', 0.061), ('formalism', 0.058), ('keynode', 0.057), ('cm', 0.055), ('tr', 0.055), ('inequality', 0.054), ('identities', 0.054), ('appearances', 0.053), ('basketball', 0.053), ('wear', 0.05), ('exclusivity', 0.05), ('delannay', 0.05), ('momentarily', 0.05), ('labelled', 0.049), ('paths', 0.049), ('neighborhood', 0.048), ('occur', 0.046), ('equation', 0.046), ('iterative', 0.045), ('exceeds', 0.044), ('wij', 0.044), ('andriyenko', 0.044), ('mot', 0.044), ('sw', 0.043), ('assignment', 0.04), ('berclaz', 0.04), ('kuo', 0.04), ('color', 0.04), ('labels', 0.038), ('identity', 0.038), ('fleuret', 0.037), ('printed', 0.037), ('overlap', 0.037), ('clothes', 0.036), ('lle', 0.036), ('players', 0.035), ('player', 0.035), ('reliable', 0.034), ('bounding', 0.034), ('beforehand', 0.033), ('graphbased', 0.033), ('pedestrian', 0.032), ('assigns', 0.032), ('neighbourhood', 0.032), ('reliability', 0.032), ('authors', 0.032), ('connects', 0.032), ('switching', 0.032), ('associates', 0.032), ('le', 0.031), ('weights', 0.031), ('appendix', 0.031), ('equality', 0.03), ('aaai', 0.03), ('missed', 0.03), ('error', 0.03), ('spurious', 0.029), ('associated', 0.029), ('fact', 0.029), ('frames', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000019 <a title="120-tfidf-1" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>Author: K.C. Amit Kumar, Christophe De_Vleeschouwer</p><p>Abstract: Given a set of plausible detections, detected at each time instant independently, we investigate how to associate them across time. This is done by propagating labels on a set of graphs that capture how the spatio-temporal and the appearance cues promote the assignment of identical or distinct labels to a pair of nodes. The graph construction is driven by the locally linear embedding (LLE) of either the spatio-temporal or the appearance features associated to the detections. Interestingly, the neighborhood of a node in each appearance graph is defined to include all nodes for which the appearance feature is available (except the ones that coexist at the same time). This allows to connect the nodes that share the same appearance even if they are temporally distant, which gives our framework the uncommon ability to exploit the appearance features that are available only sporadically along the sequence of detections. Once the graphs have been defined, the multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured by each of the graphs. This results into a difference of convex program that can be efficiently solved. Experiments are performed on a basketball and several well-known pedestrian datasets in order to validate the effectiveness of the proposed solution.</p><p>2 0.18523893 <a title="120-tfidf-2" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>Author: Minsu Cho, Karteek Alahari, Jean Ponce</p><p>Abstract: Many tasks in computer vision are formulated as graph matching problems. Despite the NP-hard nature of the problem, fast and accurate approximations have led to significant progress in a wide range of applications. Learning graph models from observed data, however, still remains a challenging issue. This paper presents an effective scheme to parameterize a graph model, and learn its structural attributes for visual object matching. For this, we propose a graph representation with histogram-based attributes, and optimize them to increase the matching accuracy. Experimental evaluations on synthetic and real image datasets demonstrate the effectiveness of our approach, and show significant improvement in matching accuracy over graphs with pre-defined structures.</p><p>3 0.17762239 <a title="120-tfidf-3" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>Author: Aleksandr V. Segal, Ian Reid</p><p>Abstract: We propose a novel parametrization of the data association problem for multi-target tracking. In our formulation, the number of targets is implicitly inferred together with the data association, effectively solving data association and model selection as a single inference problem. The novel formulation allows us to interpret data association and tracking as a single Switching Linear Dynamical System (SLDS). We compute an approximate posterior solution to this problem using a dynamic programming/message passing technique. This inference-based approach allows us to incorporate richer probabilistic models into the tracking system. In particular, we incorporate inference over inliers/outliers and track termination times into the system. We evaluate our approach on publicly available datasets and demonstrate results competitive with, and in some cases exceeding the state of the art.</p><p>4 0.17091504 <a title="120-tfidf-4" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>Author: Ernesto Brau, Jinyan Guan, Kyle Simek, Luca Del Pero, Colin Reimer Dawson, Kobus Barnard</p><p>Abstract: Jinyan Guan† j guan1 @ emai l ari z ona . edu . Kyle Simek† ks imek@ emai l ari z ona . edu . Colin Reimer Dawson‡ cdaws on@ emai l ari z ona . edu . ‡School of Information University of Arizona Kobus Barnard‡ kobus @ s i sta . ari z ona . edu ∗School of Informatics University of Edinburgh for tracking an unknown and changing number of people in a scene using video taken from a single, fixed viewpoint. We develop a Bayesian modeling approach for tracking people in 3D from monocular video with unknown cameras. Modeling in 3D provides natural explanations for occlusions and smoothness discontinuities that result from projection, and allows priors on velocity and smoothness to be grounded in physical quantities: meters and seconds vs. pixels and frames. We pose the problem in the context of data association, in which observations are assigned to tracks. A correct application of Bayesian inference to multitarget tracking must address the fact that the model’s dimension changes as tracks are added or removed, and thus, posterior densities of different hypotheses are not comparable. We address this by marginalizing out the trajectory parameters so the resulting posterior over data associations has constant dimension. This is made tractable by using (a) Gaussian process priors for smooth trajectories and (b) approximately Gaussian likelihood functions. Our approach provides a principled method for incorporating multiple sources of evidence; we present results using both optical flow and object detector outputs. Results are comparable to recent work on 3D tracking and, unlike others, our method requires no pre-calibrated cameras.</p><p>5 0.15430556 <a title="120-tfidf-5" href="./iccv-2013-Learning_People_Detectors_for_Tracking_in_Crowded_Scenes.html">242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</a></p>
<p>Author: Siyu Tang, Mykhaylo Andriluka, Anton Milan, Konrad Schindler, Stefan Roth, Bernt Schiele</p><p>Abstract: People tracking in crowded real-world scenes is challenging due to frequent and long-term occlusions. Recent tracking methods obtain the image evidence from object (people) detectors, but typically use off-the-shelf detectors and treat them as black box components. In this paper we argue that for best performance one should explicitly train people detectors on failure cases of the overall tracker instead. To that end, we first propose a novel joint people detector that combines a state-of-the-art single person detector with a detector for pairs of people, which explicitly exploits common patterns of person-person occlusions across multiple viewpoints that are a frequent failure case for tracking in crowded scenes. To explicitly address remaining failure modes of the tracker we explore two methods. First, we analyze typical failures of trackers and train a detector explicitly on these cases. And second, we train the detector with the people tracker in the loop, focusing on the most common tracker failures. We show that our joint multi-person detector significantly improves both de- tection accuracy as well as tracker performance, improving the state-of-the-art on standard benchmarks.</p><p>6 0.15174289 <a title="120-tfidf-6" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>7 0.14173511 <a title="120-tfidf-7" href="./iccv-2013-Learning_Graph_Matching%3A_Oriented_to_Category_Modeling_from_Cluttered_Scenes.html">237 iccv-2013-Learning Graph Matching: Oriented to Category Modeling from Cluttered Scenes</a></p>
<p>8 0.13953863 <a title="120-tfidf-8" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>9 0.13747266 <a title="120-tfidf-9" href="./iccv-2013-Directed_Acyclic_Graph_Kernels_for_Action_Recognition.html">116 iccv-2013-Directed Acyclic Graph Kernels for Action Recognition</a></p>
<p>10 0.12538023 <a title="120-tfidf-10" href="./iccv-2013-Simultaneous_Clustering_and_Tracklet_Linking_for_Multi-face_Tracking_in_Videos.html">393 iccv-2013-Simultaneous Clustering and Tracklet Linking for Multi-face Tracking in Videos</a></p>
<p>11 0.1231102 <a title="120-tfidf-11" href="./iccv-2013-Improving_Graph_Matching_via_Density_Maximization.html">214 iccv-2013-Improving Graph Matching via Density Maximization</a></p>
<p>12 0.11720198 <a title="120-tfidf-12" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>13 0.11446776 <a title="120-tfidf-13" href="./iccv-2013-Tracking_Revisited_Using_RGBD_Camera%3A_Unified_Benchmark_and_Baselines.html">424 iccv-2013-Tracking Revisited Using RGBD Camera: Unified Benchmark and Baselines</a></p>
<p>14 0.11352478 <a title="120-tfidf-14" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>15 0.11215331 <a title="120-tfidf-15" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>16 0.10897769 <a title="120-tfidf-16" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>17 0.1065876 <a title="120-tfidf-17" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>18 0.1043578 <a title="120-tfidf-18" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>19 0.10061353 <a title="120-tfidf-19" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>20 0.09817902 <a title="120-tfidf-20" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.238), (1, -0.015), (2, 0.011), (3, 0.014), (4, 0.054), (5, 0.002), (6, -0.094), (7, 0.143), (8, 0.026), (9, 0.02), (10, -0.109), (11, -0.078), (12, 0.025), (13, 0.128), (14, 0.12), (15, 0.115), (16, 0.077), (17, -0.026), (18, -0.057), (19, 0.019), (20, -0.089), (21, 0.011), (22, -0.016), (23, -0.03), (24, 0.11), (25, 0.041), (26, -0.07), (27, -0.108), (28, 0.043), (29, 0.032), (30, 0.058), (31, 0.039), (32, 0.057), (33, -0.021), (34, 0.023), (35, 0.097), (36, 0.081), (37, -0.021), (38, -0.037), (39, 0.024), (40, 0.089), (41, -0.067), (42, -0.06), (43, 0.015), (44, -0.105), (45, 0.027), (46, 0.089), (47, 0.012), (48, -0.024), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95473439 <a title="120-lsi-1" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>Author: K.C. Amit Kumar, Christophe De_Vleeschouwer</p><p>Abstract: Given a set of plausible detections, detected at each time instant independently, we investigate how to associate them across time. This is done by propagating labels on a set of graphs that capture how the spatio-temporal and the appearance cues promote the assignment of identical or distinct labels to a pair of nodes. The graph construction is driven by the locally linear embedding (LLE) of either the spatio-temporal or the appearance features associated to the detections. Interestingly, the neighborhood of a node in each appearance graph is defined to include all nodes for which the appearance feature is available (except the ones that coexist at the same time). This allows to connect the nodes that share the same appearance even if they are temporally distant, which gives our framework the uncommon ability to exploit the appearance features that are available only sporadically along the sequence of detections. Once the graphs have been defined, the multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured by each of the graphs. This results into a difference of convex program that can be efficiently solved. Experiments are performed on a basketball and several well-known pedestrian datasets in order to validate the effectiveness of the proposed solution.</p><p>2 0.74732322 <a title="120-lsi-2" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>Author: Aleksandr V. Segal, Ian Reid</p><p>Abstract: We propose a novel parametrization of the data association problem for multi-target tracking. In our formulation, the number of targets is implicitly inferred together with the data association, effectively solving data association and model selection as a single inference problem. The novel formulation allows us to interpret data association and tracking as a single Switching Linear Dynamical System (SLDS). We compute an approximate posterior solution to this problem using a dynamic programming/message passing technique. This inference-based approach allows us to incorporate richer probabilistic models into the tracking system. In particular, we incorporate inference over inliers/outliers and track termination times into the system. We evaluate our approach on publicly available datasets and demonstrate results competitive with, and in some cases exceeding the state of the art.</p><p>3 0.7412101 <a title="120-lsi-3" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>Author: Martin Schiegg, Philipp Hanslovsky, Bernhard X. Kausler, Lars Hufnagel, Fred A. Hamprecht</p><p>Abstract: The quality of any tracking-by-assignment hinges on the accuracy of the foregoing target detection / segmentation step. In many kinds of images, errors in this first stage are unavoidable. These errors then propagate to, and corrupt, the tracking result. Our main contribution is the first probabilistic graphical model that can explicitly account for over- and undersegmentation errors even when the number of tracking targets is unknown and when they may divide, as in cell cultures. The tracking model we present implements global consistency constraints for the number of targets comprised by each detection and is solved to global optimality on reasonably large 2D+t and 3D+t datasets. In addition, we empirically demonstrate the effectiveness of a postprocessing that allows to establish target identity even across occlusion / undersegmentation. The usefulness and efficiency of this new tracking method is demonstrated on three different and challenging 2D+t and 3D+t datasets from developmental biology.</p><p>4 0.69435436 <a title="120-lsi-4" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>Author: Chetan Arora, Amir Globerson</p><p>Abstract: This paper addresses the data assignment problem in multi frame multi object tracking in video sequences. Traditional methods employing maximum weight bipartite matching offer limited temporal modeling. It has recently been shown [6, 8, 24] that incorporating higher order temporal constraints improves the assignment solution. Finding maximum weight matching with higher order constraints is however NP-hard and the solutions proposed until now have either been greedy [8] or rely on greedy rounding of the solution obtained from spectral techniques [15]. We propose a novel algorithm to find the approximate solution to data assignment problem with higher order temporal constraints using the method of dual decomposition and the MPLP message passing algorithm [21]. We compare the proposed algorithm with an implementation of [8] and [15] and show that proposed technique provides better solution with a bound on approximation factor for each inferred solution.</p><p>5 0.67815065 <a title="120-lsi-5" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>Author: Minsu Cho, Karteek Alahari, Jean Ponce</p><p>Abstract: Many tasks in computer vision are formulated as graph matching problems. Despite the NP-hard nature of the problem, fast and accurate approximations have led to significant progress in a wide range of applications. Learning graph models from observed data, however, still remains a challenging issue. This paper presents an effective scheme to parameterize a graph model, and learn its structural attributes for visual object matching. For this, we propose a graph representation with histogram-based attributes, and optimize them to increase the matching accuracy. Experimental evaluations on synthetic and real image datasets demonstrate the effectiveness of our approach, and show significant improvement in matching accuracy over graphs with pre-defined structures.</p><p>6 0.66840386 <a title="120-lsi-6" href="./iccv-2013-Joint_Optimization_for_Consistent_Multiple_Graph_Matching.html">224 iccv-2013-Joint Optimization for Consistent Multiple Graph Matching</a></p>
<p>7 0.65973759 <a title="120-lsi-7" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>8 0.63685012 <a title="120-lsi-8" href="./iccv-2013-Improving_Graph_Matching_via_Density_Maximization.html">214 iccv-2013-Improving Graph Matching via Density Maximization</a></p>
<p>9 0.62718505 <a title="120-lsi-9" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>10 0.62237859 <a title="120-lsi-10" href="./iccv-2013-Simultaneous_Clustering_and_Tracklet_Linking_for_Multi-face_Tracking_in_Videos.html">393 iccv-2013-Simultaneous Clustering and Tracklet Linking for Multi-face Tracking in Videos</a></p>
<p>11 0.61248052 <a title="120-lsi-11" href="./iccv-2013-Learning_Graph_Matching%3A_Oriented_to_Category_Modeling_from_Cluttered_Scenes.html">237 iccv-2013-Learning Graph Matching: Oriented to Category Modeling from Cluttered Scenes</a></p>
<p>12 0.59618568 <a title="120-lsi-12" href="./iccv-2013-Network_Principles_for_SfM%3A_Disambiguating_Repeated_Structures_with_Local_Context.html">289 iccv-2013-Network Principles for SfM: Disambiguating Repeated Structures with Local Context</a></p>
<p>13 0.58633995 <a title="120-lsi-13" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>14 0.58612829 <a title="120-lsi-14" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>15 0.58241749 <a title="120-lsi-15" href="./iccv-2013-Finding_Causal_Interactions_in_Video_Sequences.html">167 iccv-2013-Finding Causal Interactions in Video Sequences</a></p>
<p>16 0.56547755 <a title="120-lsi-16" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>17 0.55977529 <a title="120-lsi-17" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>18 0.55783206 <a title="120-lsi-18" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>19 0.54046816 <a title="120-lsi-19" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>20 0.53584707 <a title="120-lsi-20" href="./iccv-2013-Directed_Acyclic_Graph_Kernels_for_Action_Recognition.html">116 iccv-2013-Directed Acyclic Graph Kernels for Action Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.058), (7, 0.019), (26, 0.086), (30, 0.19), (31, 0.031), (34, 0.017), (42, 0.111), (64, 0.091), (73, 0.04), (78, 0.017), (88, 0.01), (89, 0.2), (95, 0.018), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88007468 <a title="120-lda-1" href="./iccv-2013-Active_Visual_Recognition_with_Expertise_Estimation_in_Crowdsourcing.html">43 iccv-2013-Active Visual Recognition with Expertise Estimation in Crowdsourcing</a></p>
<p>Author: Chengjiang Long, Gang Hua, Ashish Kapoor</p><p>Abstract: We present a noise resilient probabilistic model for active learning of a Gaussian process classifier from crowds, i.e., a set of noisy labelers. It explicitly models both the overall label noises and the expertise level of each individual labeler in two levels of flip models. Expectation propagation is adopted for efficient approximate Bayesian inference of our probabilistic model for classification, based on which, a generalized EM algorithm is derived to estimate both the global label noise and the expertise of each individual labeler. The probabilistic nature of our model immediately allows the adoption of the prediction entropy and estimated expertise for active selection of data sample to be labeled, and active selection of high quality labelers to label the data, respectively. We apply the proposed model for three visual recognition tasks, i.e, object category recognition, gender recognition, and multi-modal activity recognition, on three datasets with real crowd-sourced labels from Amazon Mechanical Turk. The experiments clearly demonstrated the efficacy of the proposed model.</p><p>same-paper 2 0.85839301 <a title="120-lda-2" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>Author: K.C. Amit Kumar, Christophe De_Vleeschouwer</p><p>Abstract: Given a set of plausible detections, detected at each time instant independently, we investigate how to associate them across time. This is done by propagating labels on a set of graphs that capture how the spatio-temporal and the appearance cues promote the assignment of identical or distinct labels to a pair of nodes. The graph construction is driven by the locally linear embedding (LLE) of either the spatio-temporal or the appearance features associated to the detections. Interestingly, the neighborhood of a node in each appearance graph is defined to include all nodes for which the appearance feature is available (except the ones that coexist at the same time). This allows to connect the nodes that share the same appearance even if they are temporally distant, which gives our framework the uncommon ability to exploit the appearance features that are available only sporadically along the sequence of detections. Once the graphs have been defined, the multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured by each of the graphs. This results into a difference of convex program that can be efficiently solved. Experiments are performed on a basketball and several well-known pedestrian datasets in order to validate the effectiveness of the proposed solution.</p><p>3 0.85250586 <a title="120-lda-3" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>Author: Cai-Zhi Zhu, Hervé Jégou, Shin'Ichi Satoh</p><p>Abstract: Visual object retrieval aims at retrieving, from a collection of images, all those in which a given query object appears. It is inherently asymmetric: the query object is mostly included in the database image, while the converse is not necessarily true. However, existing approaches mostly compare the images with symmetrical measures, without considering the different roles of query and database. This paper first measure the extent of asymmetry on large-scale public datasets reflecting this task. Considering the standard bag-of-words representation, we then propose new asymmetrical dissimilarities accounting for the different inlier ratios associated with query and database images. These asymmetrical measures depend on the query, yet they are compatible with an inverted file structure, without noticeably impacting search efficiency. Our experiments show the benefit of our approach, and show that the visual object retrieval task is better treated asymmetrically, in the spirit of state-of-the-art text retrieval.</p><p>4 0.839338 <a title="120-lda-4" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>Author: Gang Hua, Chengjiang Long, Ming Yang, Yan Gao</p><p>Abstract: Active learning is an effective way of engaging users to interactively train models for visual recognition. The vast majority of previous works, if not all of them, focused on active learning with a single human oracle. The problem of active learning with multiple oracles in a collaborative setting has not been well explored. Moreover, most of the previous works assume that the labels provided by the human oracles are noise free, which may often be violated in reality. We present a collaborative computational model for active learning with multiple human oracles. It leads to not only an ensemble kernel machine that is robust to label noises, but also a principled label quality measure to online detect irresponsible labelers. Instead of running independent active learning processes for each individual human oracle, our model captures the inherent correlations among the labelers through shared data among them. Our simulation experiments and experiments with real crowd-sourced noisy labels demonstrated the efficacy of our model.</p><p>5 0.82709688 <a title="120-lda-5" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>Author: Basura Fernando, Tinne Tuytelaars</p><p>Abstract: In this paper we present a new method for object retrieval starting from multiple query images. The use of multiple queries allows for a more expressive formulation of the query object including, e.g., different viewpoints and/or viewing conditions. This, in turn, leads to more diverse and more accurate retrieval results. When no query images are available to the user, they can easily be retrieved from the internet using a standard image search engine. In particular, we propose a new method based on pattern mining. Using the minimal description length principle, we derive the most suitable set of patterns to describe the query object, with patterns corresponding to local feature configurations. This results in apowerful object-specific mid-level image representation. The archive can then be searched efficiently for similar images based on this representation, using a combination of two inverted file systems. Since the patterns already encode local spatial information, good results on several standard image retrieval datasets are obtained even without costly re-ranking based on geometric verification.</p><p>6 0.80953324 <a title="120-lda-6" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>7 0.80688339 <a title="120-lda-7" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>8 0.8051244 <a title="120-lda-8" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>9 0.80458021 <a title="120-lda-9" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>10 0.8031112 <a title="120-lda-10" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>11 0.80174631 <a title="120-lda-11" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>12 0.80101013 <a title="120-lda-12" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>13 0.80065501 <a title="120-lda-13" href="./iccv-2013-Event_Detection_in_Complex_Scenes_Using_Interval_Temporal_Constraints.html">146 iccv-2013-Event Detection in Complex Scenes Using Interval Temporal Constraints</a></p>
<p>14 0.80021203 <a title="120-lda-14" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>15 0.79994434 <a title="120-lda-15" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>16 0.79968953 <a title="120-lda-16" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>17 0.79866946 <a title="120-lda-17" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>18 0.79814243 <a title="120-lda-18" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>19 0.79795372 <a title="120-lda-19" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>20 0.79760587 <a title="120-lda-20" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
