<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>395 iccv-2013-Slice Sampling Particle Belief Propagation</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-395" href="#">iccv2013-395</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>395 iccv-2013-Slice Sampling Particle Belief Propagation</h1>
<br/><p>Source: <a title="iccv-2013-395-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Muller_Slice_Sampling_Particle_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Oliver Müller, Michael Ying Yang, Bodo Rosenhahn</p><p>Abstract: Inference in continuous label Markov random fields is a challenging task. We use particle belief propagation (PBP) for solving the inference problem in continuous label space. Sampling particles from the belief distribution is typically done by using Metropolis-Hastings (MH) Markov chain Monte Carlo (MCMC) methods which involves sampling from a proposal distribution. This proposal distribution has to be carefully designed depending on the particular model and input data to achieve fast convergence. We propose to avoid dependence on a proposal distribution by introducing a slice sampling based PBP algorithm. The proposed approach shows superior convergence performance on an image denoising toy example. Our findings are validated on a challenging relational 2D feature tracking application.</p><p>Reference: <a title="iccv-2013-395-reference" href="../iccv2013_reference/iccv-2013-Slice_Sampling_Particle_Belief_Propagation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We use particle belief propagation (PBP) for solving the inference problem in continuous label space. [sent-4, score-0.609]
</p><p>2 Sampling particles from the belief distribution is typically done by using Metropolis-Hastings (MH) Markov chain Monte Carlo (MCMC) methods which involves sampling from a proposal distribution. [sent-5, score-0.88]
</p><p>3 This proposal distribution has to be carefully designed depending on the particular model and input data to achieve fast convergence. [sent-6, score-0.298]
</p><p>4 We propose to avoid dependence on a proposal distribution by introducing a slice sampling based PBP algorithm. [sent-7, score-0.593]
</p><p>5 Our findings are validated on a challenging relational 2D feature tracking application. [sent-9, score-0.348]
</p><p>6 Introduction Markov Random Fields (MRFs) are a powerful tool for modeling relational dependencies among observations. [sent-11, score-0.157]
</p><p>7 Numerous optimization approaches for discrete labels have been proposed, from binary labeled Graph Cuts [4], to multi-label tree reweighted message passing [17, 7]. [sent-14, score-0.186]
</p><p>8 In this paper, we deal with continuous labeled MRFs where we use a particle belief propagation (PBP) approach [6]. [sent-15, score-0.573]
</p><p>9 The efficiency of such particle based approaches highly depends on the sampling scheme used to explore the label space. [sent-16, score-0.42]
</p><p>10 Previous approaches use Metropolis-Hastings (MH) Markov chain Monte Carlo (MCMC) methods for particle sampling. [sent-17, score-0.316]
</p><p>11 The performance of these methods depends on a carefully designed proposal distribution. [sent-18, score-0.26]
</p><p>12 We propose a novel sampling technique for PBP based on slice sampling [12]. [sent-20, score-0.487]
</p><p>13 This method exploits the structure of the PBP message passing equations for direct sampling from the target distribution and does not de-  #1·· #377·· #467··  Figure 1. [sent-21, score-0.341]
</p><p>14 pend on a proposal distribution which is difficult to tune. [sent-23, score-0.254]
</p><p>15 Our findings are then verified on a complex 2D relational feature tracking application as shown in Fig. [sent-25, score-0.348]
</p><p>16 We furthermore provide a publicly available database of image sequences for feature tracking applications including manually labeled groundtruth data [11]. [sent-27, score-0.274]
</p><p>17 Section 3 introduces notations and definitions used throughout the paper and gives a short introduction to slice sampling. [sent-30, score-0.212]
</p><p>18 5 we present a thorough evaluation of our method compared to the state-of-the-art and propose a 2D relational feature tracking application. [sent-34, score-0.316]
</p><p>19 Often such approaches are hard to apply on tasks where a continuous label space would be a more natural choice, such as feature tracking with relational constraints [14, 9]. [sent-39, score-0.393]
</p><p>20 Loopy belief propagation is a prominent method using a local message passing mechanism for coordinating the optimal labeling of neighboring nodes. [sent-40, score-0.451]
</p><p>21 Recently, message passing approaches working in continuous rather than discrete label space were proposed 11 112299  Gbr(axtph)icalM Mtos→u dtse(lx (set)xempbl(saxrsy)b(xs)mc samplingxs  Figure 2. [sent-43, score-0.263]
</p><p>22 Right: MCMC particle sampling of the belief b(xs) with an exemplary MCMC sampling chain of one particle (blue) and its corresponding histogram (red). [sent-46, score-1.056]
</p><p>23 To the best of our knowledge, all previously proposed MCMC based belief propagation methods use Metropolis-Hastings (MH) sampling. [sent-49, score-0.296]
</p><p>24 This sampling strategy consists of two steps: (a) sampling a candidate particle from an easy to sample proposal distribution, and (b) accept or reject the candidate depending on a transition probability [18]. [sent-50, score-0.748]
</p><p>25 Applying this sampling technique involves a careful design of the proposal distri-  bution, which is a compromise between exploring the label space (using a broad proposal distribution) and maximizing the transition acceptance ratio (minimize sample moves) at the same time. [sent-51, score-0.662]
</p><p>26 Throughout the paper we show that considering alternative sampling techniques can be advantageous. [sent-52, score-0.148]
</p><p>27 We propose to use slice sampling [12] instead of MH, rendering proposal distribution selection obsolete in the context of PBP. [sent-53, score-0.593]
</p><p>28 To demonstrate superior performance of our method on a real world problem we propose a relational feature tracking application inspired by [9, 14] in the experiment section. [sent-54, score-0.316]
</p><p>29 Some related works such as [15, 5] propose to formulate feature tracking as a discrete labeling problem and use global optimization algorithms (i. [sent-55, score-0.19]
</p><p>30 Closely related methods use belief propagation combined with particle filtering [19, 9, 14], but still use proposal distributions for particle perturbation which introduces sensible optimization parameter tuning. [sent-59, score-1.009]
</p><p>31 o Fdeors every nod⊂e s th theree s eist a flab neelig xs fbroormin gth neo ldaebsel t space VL. [sent-64, score-0.313]
</p><p>32 Max-Product Particle Belief Propagation In the following we summarize the max-product particle belief propagation algorithm [8, 3]. [sent-84, score-0.532]
</p><p>33 The energy term E(x) is approximated by particles such that the label space Ls of iesa caph pnrooxdeim s tine dth bey M paRrtFi cilse represented by a bseelt sopfa particles Ps = ,. [sent-85, score-0.416]
</p><p>34 Then the estimated belief bsn ) or log disbelief Bsn ) = log(bsn )) of node s at iteration n is calculated as )fo =llo −wlso [g3(]b:  {x(s1)  (x(si)  xs(p)  −  (x(si)  (x(si)  Bsn(x(si)) = ψs(x(si)) + ? [sent-89, score-0.595]
</p><p>35 for xs node s are:  ∈  (2)  Ps from node t to  Mtn→s(xs) =x mt∈inPt[ψs,t(xs,xt)+Btn−1(xt)−Msn→−t1(xt)]. [sent-91, score-0.405]
</p><p>36 (3) Note that the log disbelief Bsn (xs) and the messages  Mtn→s (xs) can be calculated for all continuous values xs ∈ Ls →rasther than only on the particle set Ps. [sent-92, score-0.761]
</p><p>37 On the othe∈r hLand, the messages from node s to node t are approximated only using the particles xt from the particle set Pt = of node t. [sent-93, score-0.696]
</p><p>38 (4)  The main issue in PBP lies in how to sample new particles xsn ∼ Bsn (xs). [sent-102, score-0.19]
</p><p>39 This method requires a proposal distribution q where new particles can be easily sampled from. [sent-104, score-0.444]
</p><p>40 Algorithm 1 summarizes the Metropolis-Hastings based max-product particle belief propagation algorithm (MH-PBP). [sent-107, score-0.532]
</p><p>41 Typically, q needs to be carefully adjusted to the true belief distribution. [sent-108, score-0.252]
</p><p>42 In the following we propose to replace the MH sampling step by a slice sampling approach which does not depend on proposal distribution selection. [sent-110, score-0.741]
</p><p>43 ,p, proposal distribu1: 2: 3: 4: 5: 6: 7: 8:  utito:n I pσ Initialize the messages Mt0→s (xs) and log disbelief Bs0 with zero ∀s, t fworit hB zPe riote r∀asti,otn n = 1to N do for each node s and each particle i= 1, . [sent-115, score-0.669]
</p><p>44 ,p do Initialize sampling chain ← for MCMC iteration m = 1, . [sent-118, score-0.228]
</p><p>45 , ←M x do Sample ∼ pσ(x | from proposal d pist(rixb |u txion pσ Calc. [sent-121, score-0.216]
</p><p>46 )  1, we propose itoo randomly sample one Ldim∈en sRion in each MCMC step and slice sample on this dimension while the other dimensions are held fixed. [sent-133, score-0.191]
</p><p>47 Assume the unary and/ or binary potential functions ψs and ψst are given as an analytic function. [sent-135, score-0.155]
</p><p>48 Image Denoising For analyzing the random walk behaviour of our method we have chosen the application of image denoising due to its relatively simple model structure. [sent-142, score-0.163]
</p><p>49 (18)  For minimizing particle noise in the final estimation re-  sult an annealing scheme is used where the target belief distribution is modified to where Tn = T0 · (TN/T0)n/N is the temperature at PBP iteration n, T0 is the· start temperature, and TN the end temperature. [sent-144, score-0.619]
</p><p>50 We further compared the efficiency of the slice sampling method to the Metropolis-Hastings sampling applied on the image denoising problem. [sent-161, score-0.544]
</p><p>51 An MCMC chain of M = 500 samples is generated for each particle and  xθ(i)  11 113322  Figure 4. [sent-163, score-0.316]
</p><p>52 Comparison of the empirical risk for with different proposal distributions. [sent-175, score-0.288]
</p><p>53 For the MH-PBP proposal distribution the family of Gaussian distributions pσ(x | x? [sent-178, score-0.254]
</p><p>54 In order to provide a fpai[r− comparison the proposal distribution is adapted to the current temperature by  using pσ(x | x? [sent-185, score-0.342]
</p><p>55 Figure x5 s xhows a comparison of the empirical risk for different MH-PBP proposal distributions. [sent-188, score-0.288]
</p><p>56 This effect can be significantly reduced by averaging over particles instead of only selecting the best one as stated in Eq. [sent-194, score-0.212]
</p><p>57 For comparing the random walk behavior of the MCMC sampling chains from S-PBP and MH-PBP, the normalized autocorrelation function  ρk=? [sent-196, score-0.261]
</p><p>58 It can be observed that the MH-PBP method produces a much higher autocorrelation than the S-PBP method, thus the MCMC chain mixing behaviour of S-PBP outperforms MH-PBP. [sent-213, score-0.185]
</p><p>59 Relational Feature Tracking We propose to apply our S-PBP algorithm on a 2D relational feature tracking system inspired by [9, 14] as a more complex application. [sent-220, score-0.316]
</p><p>60 The model is separated into two parts: (a) the unary potentials are derived from a feature patch matching model, and (b) the binary potentials encode the relative positioning of the features to each other. [sent-224, score-0.177]
</p><p>61 Teh iem oagrieentation vector os encodes two aspects: the feature patch rotation (rotation of os, i. [sent-233, score-0.216]
</p><p>62 The modifications include an additional particle resampling step, where for each frame the initial set of particles are sampled with replacement from the set of particles }i=1,. [sent-258, score-0.639]
</p><p>63 For the slice sampling approach we need to define the boundary functions Aψs (u) and Axψts,t (u). [sent-269, score-0.339]
</p><p>64 An analytic description of the unary potential is not available thus we have to define the boundary manually. [sent-272, score-0.155]
</p><p>65 ps ∈ [1, W] [1, H], where W and H are the image wid∈th [a1n,dW height respectively, Wan adn tdo H res atrreic tt os mtoos ∈ [−10, 10] [−10, 10] . [sent-275, score-0.228]
</p><p>66 This way it is ensured that the sampling space i×s large enough. [sent-276, score-0.148]
</p><p>67 iOsn w tahye oitt hiser e n hsaunrde,d particles sampled outside the true (sub-)bounds are automatically rejected by the algorithm. [sent-277, score-0.19]
</p><p>68 In order to provide a fair comparison of our slice sampling approach to the stateof-the-art MH-PBP approach, the design of the proposal distribution has to be done very carefully. [sent-279, score-0.593]
</p><p>69 The label space can be divided into two parts, the feature position ps ∈ R2 and orthogonal feature transformation os ∈ R2. [sent-281, score-0.368]
</p><p>70 The∈ proposal distributionforps | = I2×2· σxy), where N(μ, Σ) is a Ga|uspsian pdf with mean μ and covaria),n wceh Σere. [sent-282, score-0.216]
</p><p>71 The sequences have a spatial resolution of 960 px 540 px and csoeqnusiesnt oefs 5h6av3e a an dsp 7a2ti6a lfr raemsoelust respectively. [sent-298, score-0.345]
</p><p>72 The similar appearing features were chosen to stress the relational structure of our tracker model. [sent-300, score-0.256]
</p><p>73 The PAPER1 sequence consists of five feature patches with a carefully chosen position pattern which allows unique identification of the features by only having knowledge about the relative distances of the features to each other. [sent-302, score-0.162]
</p><p>74 The PAPER2 sequence is more challenging since the number of features is increased to 70 and the features are arranged in a grid structure allowing local relational ambiguities. [sent-303, score-0.182]
</p><p>75 The sequences have a spatial resolution of 352 px s2i8o8n px T(FheAC seEqOuCeCnc1e) sa hndav v3e2 0a px t×i 2l4 r0es px (tiFoAnC oEfOC 35C22p) xan ×d both consist of 8188) afnrdam 3e2s0 pexac×h. [sent-305, score-0.568]
</p><p>76 The sequences and tracking results are shown in Fig. [sent-307, score-0.175]
</p><p>77 For the HOG features we set the smallest scale pyramid resolution to 50 px 50 px. [sent-313, score-0.177]
</p><p>78 We use N = 20 PBP iterations and p = 10 particles for each node. [sent-317, score-0.243]
</p><p>79 Since we compare the overall sampling behaviour of the proposed method rather than the belief propagation convergence behaviour selecting these parameters should be uncritical. [sent-319, score-0.57]
</p><p>80 We consider the distance εtrack between the estimated feature position and the groundtruth (manually labeled) position as a quality measure. [sent-321, score-0.167]
</p><p>81 For MH-PBP, the MH sampling parameters {σxy, σr, σφ} are chosen (from thes asmetp {lin0g. [sent-330, score-0.172]
</p><p>82 We have evaluated the tracking performance for different MCMC iterations M = 2 to 5. [sent-364, score-0.177]
</p><p>83 This is mainly due to a much higher overall sampling noise of the MH-PBP method compared to S-PBP. [sent-367, score-0.148]
</p><p>84 We observed that the sampling noise of S-PBP is much less than with MH-PBP at feature positions with high confidence (i. [sent-368, score-0.183]
</p><p>85 On the other hand the sampling noise of S-PBP increases for uncertain feature positions. [sent-371, score-0.209]
</p><p>86 The RMSD in sequence PAPER2 and FACEOCC 1is higher for S-PBP than for MH-PBP due to temporal tracking failures. [sent-372, score-0.149]
</p><p>87 These tracking failures are caused by strong local deformations or by occlusions of many feature points. [sent-373, score-0.194]
</p><p>88 Typical tracking failures  are depicted in the bottom row of Fig. [sent-374, score-0.159]
</p><p>89 It can be observed in such cases that S-PBP leads to much higher tracking error than MH-PBP due to broader particle sampling in uncertain feature positions. [sent-376, score-0.569]
</p><p>90 Figure 9 shows an evaluation of MH-PBP under differing (non-optimal) sampling parameters. [sent-377, score-0.188]
</p><p>91 In order to visualize both the performance differences for nearoptimal parameters and tracking failures, the error values below and above the 15 px mark are shown with a differing vertical axis scaling. [sent-380, score-0.331]
</p><p>92 It can be observed that the tracking performance of MH-PBP strongly depends on careful parameter selection. [sent-384, score-0.172]
</p><p>93 The parameter σxy has the highest impact on the tracking performance and the optimal parameter value varies strongly between sequences (σxy = 5 for PAPER1 and σxy = 0. [sent-385, score-0.225]
</p><p>94 The computational complexity for MH-PBP is O(NSpM (1+ V p)) and for S-PBP is O(NSpM(3 + 2Vi ps) O) given tMhe number of PBP iterationsi sN O, nNoSdpesM MS(,3 particles p, vMenCM thCe iterations M and the average number of neighbors per node V . [sent-391, score-0.289]
</p><p>95 Relational feature tracker evaluation results showing the overal RMSD (for MCMC iterations from 2 to 5) and box plots over the error distance to groundtruth for selected MCMC iterations. [sent-401, score-0.227]
</p><p>96 Note that the vertical axis is stretched for error values lower than 15 px in order to better visualize performance differences. [sent-405, score-0.167]
</p><p>97 Conclusion We presented a novel particle belief propagation algorithm using slice sampling (S-PBP) instead of MetropolisHastings. [sent-408, score-0.871]
</p><p>98 We exploit the message passing equations to compute the slice sampling bounds, provided the unary and binary potentials are defined by analytic functions or can be bounded by one. [sent-409, score-0.642]
</p><p>99 Furthermore we showed that our approach performs equally well or better than MH-PBP on challenging relational feature tracking sequences. [sent-411, score-0.316]
</p><p>100 Pmbp: Patchmatch  [4] [5]  [6] [7] [8] [9] [10]  [11]  [12] [13]  [14]  [15]  [16]  belief propagation for correspondence field estimation. [sent-434, score-0.296]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pbp', 0.36), ('xs', 0.313), ('mcmc', 0.307), ('bsn', 0.24), ('particle', 0.236), ('proposal', 0.216), ('belief', 0.208), ('faceocc', 0.192), ('slice', 0.191), ('particles', 0.19), ('relational', 0.157), ('sampling', 0.148), ('tracking', 0.124), ('px', 0.122), ('os', 0.117), ('ps', 0.111), ('xy', 0.098), ('message', 0.094), ('temperature', 0.088), ('propagation', 0.088), ('mh', 0.087), ('chain', 0.08), ('tracker', 0.075), ('disbelief', 0.072), ('mtn', 0.072), ('rmsd', 0.072), ('messages', 0.07), ('si', 0.068), ('analytic', 0.064), ('groundtruth', 0.064), ('xt', 0.062), ('passing', 0.061), ('denoising', 0.057), ('unary', 0.056), ('iterations', 0.053), ('autocorrelation', 0.053), ('behaviour', 0.052), ('mrfs', 0.052), ('sequences', 0.051), ('annealing', 0.049), ('ihler', 0.048), ('mhpbp', 0.048), ('msdr', 0.048), ('nspm', 0.048), ('prse', 0.048), ('mrf', 0.046), ('node', 0.046), ('carefully', 0.044), ('risk', 0.043), ('markov', 0.043), ('tn', 0.042), ('continuous', 0.041), ('differing', 0.04), ('bounds', 0.04), ('distribution', 0.038), ('monte', 0.037), ('tnt', 0.037), ('label', 0.036), ('carlo', 0.036), ('ller', 0.035), ('toy', 0.035), ('feature', 0.035), ('potential', 0.035), ('failures', 0.035), ('position', 0.034), ('rotation', 0.034), ('findings', 0.032), ('ns', 0.031), ('discrete', 0.031), ('chains', 0.03), ('patch', 0.03), ('walk', 0.03), ('resolution', 0.029), ('polar', 0.029), ('empirical', 0.029), ('log', 0.029), ('potentials', 0.028), ('pt', 0.027), ('pyramid', 0.026), ('uncertain', 0.026), ('sequence', 0.025), ('parameter', 0.025), ('axis', 0.024), ('chosen', 0.024), ('overhead', 0.024), ('ch', 0.024), ('modifications', 0.023), ('compromise', 0.023), ('careful', 0.023), ('movements', 0.022), ('pages', 0.022), ('selecting', 0.022), ('vertical', 0.021), ('definitions', 0.021), ('tential', 0.021), ('specialize', 0.021), ('nvo', 0.021), ('eev', 0.021), ('dsp', 0.021), ('zpe', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999994 <a title="395-tfidf-1" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>Author: Oliver Müller, Michael Ying Yang, Bodo Rosenhahn</p><p>Abstract: Inference in continuous label Markov random fields is a challenging task. We use particle belief propagation (PBP) for solving the inference problem in continuous label space. Sampling particles from the belief distribution is typically done by using Metropolis-Hastings (MH) Markov chain Monte Carlo (MCMC) methods which involves sampling from a proposal distribution. This proposal distribution has to be carefully designed depending on the particular model and input data to achieve fast convergence. We propose to avoid dependence on a proposal distribution by introducing a slice sampling based PBP algorithm. The proposed approach shows superior convergence performance on an image denoising toy example. Our findings are validated on a challenging relational 2D feature tracking application.</p><p>2 0.22983341 <a title="395-tfidf-2" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>Author: Naiyan Wang, Jingdong Wang, Dit-Yan Yeung</p><p>Abstract: This paper studies the visual tracking problem in video sequences and presents a novel robust sparse tracker under the particle filter framework. In particular, we propose an online robust non-negative dictionary learning algorithm for updating the object templates so that each learned template can capture a distinctive aspect of the tracked object. Another appealing property of this approach is that it can automatically detect and reject the occlusion and cluttered background in a principled way. In addition, we propose a new particle representation formulation using the Huber loss function. The advantage is that it can yield robust estimation without using trivial templates adopted by previous sparse trackers, leading to faster computation. We also reveal the equivalence between this new formulation and the previous one which uses trivial templates. The proposed tracker is empirically compared with state-of-the-art trackers on some challenging video sequences. Both quantitative and qualitative comparisons show that our proposed tracker is superior and more stable.</p><p>3 0.19185145 <a title="395-tfidf-3" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>Author: Zhibin Hong, Xue Mei, Danil Prokhorov, Dacheng Tao</p><p>Abstract: Combining multiple observation views has proven beneficial for tracking. In this paper, we cast tracking as a novel multi-task multi-view sparse learning problem and exploit the cues from multiple views including various types of visual features, such as intensity, color, and edge, where each feature observation can be sparsely represented by a linear combination of atoms from an adaptive feature dictionary. The proposed method is integrated in a particle filter framework where every view in each particle is regarded as an individual task. We jointly consider the underlying relationship between tasks across different views and different particles, and tackle it in a unified robust multi-task formulation. In addition, to capture the frequently emerging outlier tasks, we decompose the representation matrix to two collaborative components which enable a more robust and accurate approximation. We show that theproposedformulation can be efficiently solved using the Accelerated Proximal Gradient method with a small number of closed-form updates. The presented tracker is implemented using four types of features and is tested on numerous benchmark video sequences. Both the qualitative and quantitative results demonstrate the superior performance of the proposed approach compared to several stateof-the-art trackers.</p><p>4 0.14867362 <a title="395-tfidf-4" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>Author: Aleksandr V. Segal, Ian Reid</p><p>Abstract: We propose a novel parametrization of the data association problem for multi-target tracking. In our formulation, the number of targets is implicitly inferred together with the data association, effectively solving data association and model selection as a single inference problem. The novel formulation allows us to interpret data association and tracking as a single Switching Linear Dynamical System (SLDS). We compute an approximate posterior solution to this problem using a dynamic programming/message passing technique. This inference-based approach allows us to incorporate richer probabilistic models into the tracking system. In particular, we incorporate inference over inliers/outliers and track termination times into the system. We evaluate our approach on publicly available datasets and demonstrate results competitive with, and in some cases exceeding the state of the art.</p><p>5 0.11320006 <a title="395-tfidf-5" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>Author: Stefan Duffner, Christophe Garcia</p><p>Abstract: In this paper, we present a novel algorithm for fast tracking of generic objects in videos. The algorithm uses two components: a detector that makes use of the generalised Hough transform with pixel-based descriptors, and a probabilistic segmentation method based on global models for foreground and background. These components are used for tracking in a combined way, and they adapt each other in a co-training manner. Through effective model adaptation and segmentation, the algorithm is able to track objects that undergo rigid and non-rigid deformations and considerable shape and appearance variations. The proposed tracking method has been thoroughly evaluated on challenging standard videos, and outperforms state-of-theart tracking methods designed for the same task. Finally, the proposed models allow for an extremely efficient implementation, and thus tracking is very fast.</p><p>6 0.1058419 <a title="395-tfidf-6" href="./iccv-2013-Inferring_%22Dark_Matter%22_and_%22Dark_Energy%22_from_Videos.html">216 iccv-2013-Inferring "Dark Matter" and "Dark Energy" from Videos</a></p>
<p>7 0.1045834 <a title="395-tfidf-7" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>8 0.10304172 <a title="395-tfidf-8" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>9 0.099979907 <a title="395-tfidf-9" href="./iccv-2013-Estimating_Human_Pose_with_Flowing_Puppets.html">143 iccv-2013-Estimating Human Pose with Flowing Puppets</a></p>
<p>10 0.095897883 <a title="395-tfidf-10" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>11 0.087663718 <a title="395-tfidf-11" href="./iccv-2013-Flattening_Supervoxel_Hierarchies_by_the_Uniform_Entropy_Slice.html">172 iccv-2013-Flattening Supervoxel Hierarchies by the Uniform Entropy Slice</a></p>
<p>12 0.087134741 <a title="395-tfidf-12" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>13 0.087026216 <a title="395-tfidf-13" href="./iccv-2013-Human_Re-identification_by_Matching_Compositional_Template_with_Cluster_Sampling.html">205 iccv-2013-Human Re-identification by Matching Compositional Template with Cluster Sampling</a></p>
<p>14 0.085846864 <a title="395-tfidf-14" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>15 0.081035659 <a title="395-tfidf-15" href="./iccv-2013-Tracking_Revisited_Using_RGBD_Camera%3A_Unified_Benchmark_and_Baselines.html">424 iccv-2013-Tracking Revisited Using RGBD Camera: Unified Benchmark and Baselines</a></p>
<p>16 0.07998728 <a title="395-tfidf-16" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>17 0.078742497 <a title="395-tfidf-17" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<p>18 0.077010237 <a title="395-tfidf-18" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>19 0.076577663 <a title="395-tfidf-19" href="./iccv-2013-Measuring_Flow_Complexity_in_Videos.html">263 iccv-2013-Measuring Flow Complexity in Videos</a></p>
<p>20 0.073801748 <a title="395-tfidf-20" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.167), (1, -0.052), (2, -0.006), (3, 0.027), (4, 0.009), (5, -0.039), (6, -0.099), (7, 0.113), (8, -0.032), (9, 0.075), (10, -0.087), (11, -0.121), (12, 0.036), (13, 0.092), (14, 0.048), (15, 0.041), (16, 0.023), (17, 0.006), (18, -0.035), (19, -0.027), (20, -0.014), (21, -0.014), (22, -0.001), (23, -0.049), (24, -0.023), (25, 0.004), (26, 0.075), (27, -0.025), (28, 0.004), (29, 0.064), (30, 0.022), (31, -0.01), (32, 0.038), (33, -0.009), (34, 0.058), (35, -0.077), (36, -0.041), (37, -0.095), (38, 0.034), (39, -0.002), (40, 0.026), (41, -0.031), (42, 0.038), (43, -0.084), (44, 0.066), (45, -0.029), (46, -0.081), (47, -0.006), (48, -0.003), (49, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94220185 <a title="395-lsi-1" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>Author: Oliver Müller, Michael Ying Yang, Bodo Rosenhahn</p><p>Abstract: Inference in continuous label Markov random fields is a challenging task. We use particle belief propagation (PBP) for solving the inference problem in continuous label space. Sampling particles from the belief distribution is typically done by using Metropolis-Hastings (MH) Markov chain Monte Carlo (MCMC) methods which involves sampling from a proposal distribution. This proposal distribution has to be carefully designed depending on the particular model and input data to achieve fast convergence. We propose to avoid dependence on a proposal distribution by introducing a slice sampling based PBP algorithm. The proposed approach shows superior convergence performance on an image denoising toy example. Our findings are validated on a challenging relational 2D feature tracking application.</p><p>2 0.77508593 <a title="395-lsi-2" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>Author: Yu Pang, Haibin Ling</p><p>Abstract: Evaluating visual tracking algorithms, or “trackers ” for short, is of great importance in computer vision. However, it is hard to “fairly” compare trackers due to many parameters need to be tuned in the experimental configurations. On the other hand, when introducing a new tracker, a recent trend is to validate it by comparing it with several existing ones. Such an evaluation may have subjective biases towards the new tracker which typically performs the best. This is mainly due to the difficulty to optimally tune all its competitors and sometimes the selected testing sequences. By contrast, little subjective bias exists towards the “second best” ones1 in the contest. This observation inspires us with a novel perspective towards inhibiting subjective bias in evaluating trackers by analyzing the results between the second bests. In particular, we first collect all tracking papers published in major computer vision venues in recent years. From these papers, after filtering out potential biases in various aspects, we create a dataset containing many records of comparison results between various visual trackers. Using these records, we derive performance rank- ings of the involved trackers by four different methods. The first two methods model the dataset as a graph and then derive the rankings over the graph, one by a rank aggregation algorithm and the other by a PageRank-like solution. The other two methods take the records as generated from sports contests and adopt widely used Elo’s and Glicko ’s rating systems to derive the rankings. The experimental results are presented and may serve as a reference for related research.</p><p>3 0.74488908 <a title="395-lsi-3" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>Author: Zhibin Hong, Xue Mei, Danil Prokhorov, Dacheng Tao</p><p>Abstract: Combining multiple observation views has proven beneficial for tracking. In this paper, we cast tracking as a novel multi-task multi-view sparse learning problem and exploit the cues from multiple views including various types of visual features, such as intensity, color, and edge, where each feature observation can be sparsely represented by a linear combination of atoms from an adaptive feature dictionary. The proposed method is integrated in a particle filter framework where every view in each particle is regarded as an individual task. We jointly consider the underlying relationship between tasks across different views and different particles, and tackle it in a unified robust multi-task formulation. In addition, to capture the frequently emerging outlier tasks, we decompose the representation matrix to two collaborative components which enable a more robust and accurate approximation. We show that theproposedformulation can be efficiently solved using the Accelerated Proximal Gradient method with a small number of closed-form updates. The presented tracker is implemented using four types of features and is tested on numerous benchmark video sequences. Both the qualitative and quantitative results demonstrate the superior performance of the proposed approach compared to several stateof-the-art trackers.</p><p>4 0.74447328 <a title="395-lsi-4" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>Author: Naiyan Wang, Jingdong Wang, Dit-Yan Yeung</p><p>Abstract: This paper studies the visual tracking problem in video sequences and presents a novel robust sparse tracker under the particle filter framework. In particular, we propose an online robust non-negative dictionary learning algorithm for updating the object templates so that each learned template can capture a distinctive aspect of the tracked object. Another appealing property of this approach is that it can automatically detect and reject the occlusion and cluttered background in a principled way. In addition, we propose a new particle representation formulation using the Huber loss function. The advantage is that it can yield robust estimation without using trivial templates adopted by previous sparse trackers, leading to faster computation. We also reveal the equivalence between this new formulation and the previous one which uses trivial templates. The proposed tracker is empirically compared with state-of-the-art trackers on some challenging video sequences. Both quantitative and qualitative comparisons show that our proposed tracker is superior and more stable.</p><p>5 0.67605025 <a title="395-lsi-5" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>Author: Seunghoon Hong, Suha Kwak, Bohyung Han</p><p>Abstract: We propose a novel offline tracking algorithm based on model-averaged posterior estimation through patch matching across frames. Contrary to existing online and offline tracking methods, our algorithm is not based on temporallyordered estimates of target state but attempts to select easyto-track frames first out of the remaining ones without exploiting temporal coherency of target. The posterior of the selected frame is estimated by propagating densities from the already tracked frames in a recursive manner. The density propagation across frames is implemented by an efficient patch matching technique, which is useful for our algorithm since it does not require motion smoothness assumption. Also, we present a hierarchical approach, where a small set of key frames are tracked first and non-key frames are handled by local key frames. Our tracking algorithm is conceptually well-suited for the sequences with abrupt motion, shot changes, and occlusion. We compare our tracking algorithm with existing techniques in real videos with such challenges and illustrate its superior performance qualitatively and quantitatively.</p><p>6 0.67199826 <a title="395-lsi-6" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>7 0.64941019 <a title="395-lsi-7" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>8 0.62552643 <a title="395-lsi-8" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>9 0.60914588 <a title="395-lsi-9" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>10 0.57118547 <a title="395-lsi-10" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>11 0.554501 <a title="395-lsi-11" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>12 0.54503518 <a title="395-lsi-12" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>13 0.54434097 <a title="395-lsi-13" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<p>14 0.53792346 <a title="395-lsi-14" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<p>15 0.5349822 <a title="395-lsi-15" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>16 0.52520347 <a title="395-lsi-16" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>17 0.51384157 <a title="395-lsi-17" href="./iccv-2013-Initialization-Insensitive_Visual_Tracking_through_Voting_with_Salient_Local_Features.html">217 iccv-2013-Initialization-Insensitive Visual Tracking through Voting with Salient Local Features</a></p>
<p>18 0.50635177 <a title="395-lsi-18" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>19 0.45754182 <a title="395-lsi-19" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>20 0.45184043 <a title="395-lsi-20" href="./iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees.html">76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.041), (26, 0.509), (31, 0.033), (34, 0.014), (42, 0.074), (64, 0.06), (73, 0.038), (89, 0.117)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93469894 <a title="395-lda-1" href="./iccv-2013-Structured_Light_in_Sunlight.html">405 iccv-2013-Structured Light in Sunlight</a></p>
<p>Author: Mohit Gupta, Qi Yin, Shree K. Nayar</p><p>Abstract: Strong ambient illumination severely degrades the performance of structured light based techniques. This is especially true in outdoor scenarios, where the structured light sources have to compete with sunlight, whose power is often 2-5 orders of magnitude larger than the projected light. In this paper, we propose the concept of light-concentration to overcome strong ambient illumination. Our key observation is that given a fixed light (power) budget, it is always better to allocate it sequentially in several portions of the scene, as compared to spreading it over the entire scene at once. For a desired level of accuracy, we show that by distributing light appropriately, the proposed approach requires 1-2 orders lower acquisition time than existing approaches. Our approach is illumination-adaptive as the optimal light distribution is determined based on a measurement of the ambient illumination level. Since current light sources have a fixed light distribution, we have built a prototype light source that supports flexible light distribution by controlling the scanning speed of a laser scanner. We show several high quality 3D scanning results in a wide range of outdoor scenarios. The proposed approach will benefit 3D vision systems that need to operate outdoors under extreme ambient illumination levels on a limited time and power budget.</p><p>same-paper 2 0.89789504 <a title="395-lda-2" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>Author: Oliver Müller, Michael Ying Yang, Bodo Rosenhahn</p><p>Abstract: Inference in continuous label Markov random fields is a challenging task. We use particle belief propagation (PBP) for solving the inference problem in continuous label space. Sampling particles from the belief distribution is typically done by using Metropolis-Hastings (MH) Markov chain Monte Carlo (MCMC) methods which involves sampling from a proposal distribution. This proposal distribution has to be carefully designed depending on the particular model and input data to achieve fast convergence. We propose to avoid dependence on a proposal distribution by introducing a slice sampling based PBP algorithm. The proposed approach shows superior convergence performance on an image denoising toy example. Our findings are validated on a challenging relational 2D feature tracking application.</p><p>3 0.8920874 <a title="395-lda-3" href="./iccv-2013-Anchored_Neighborhood_Regression_for_Fast_Example-Based_Super-Resolution.html">51 iccv-2013-Anchored Neighborhood Regression for Fast Example-Based Super-Resolution</a></p>
<p>Author: Radu Timofte, Vincent De_Smet, Luc Van_Gool</p><p>Abstract: Recently there have been significant advances in image upscaling or image super-resolution based on a dictionary of low and high resolution exemplars. The running time of the methods is often ignored despite the fact that it is a critical factor for real applications. This paper proposes fast super-resolution methods while making no compromise on quality. First, we support the use of sparse learned dictionaries in combination with neighbor embedding methods. In this case, the nearest neighbors are computed using the correlation with the dictionary atoms rather than the Euclidean distance. Moreover, we show that most of the current approaches reach top performance for the right parameters. Second, we show that using global collaborative coding has considerable speed advantages, reducing the super-resolution mapping to a precomputed projective matrix. Third, we propose the anchored neighborhood regression. That is to anchor the neighborhood embedding of a low resolution patch to the nearest atom in the dictionary and to precompute the corresponding embedding matrix. These proposals are contrasted with current state-of- the-art methods on standard images. We obtain similar or improved quality and one or two orders of magnitude speed improvements.</p><p>4 0.87748784 <a title="395-lda-4" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>Author: Tomáš Kazmar, Evgeny Z. Kvon, Alexander Stark, Christoph H. Lampert</p><p>Abstract: In this work we propose a system for automatic classification of Drosophila embryos into developmental stages. While the system is designed to solve an actual problem in biological research, we believe that the principle underlying it is interesting not only for biologists, but also for researchers in computer vision. The main idea is to combine two orthogonal sources of information: one is a classifier trained on strongly invariant features, which makes it applicable to images of very different conditions, but also leads to rather noisy predictions. The other is a label propagation step based on a more powerful similarity measure that however is only consistent within specific subsets of the data at a time. In our biological setup, the information sources are the shape and the staining patterns of embryo images. We show experimentally that while neither of the methods can be used by itself to achieve satisfactory results, their combination achieves prediction quality comparable to human per- formance.</p><p>5 0.86096728 <a title="395-lda-5" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>Author: Abdelaziz Djelouah, Jean-Sébastien Franco, Edmond Boyer, François Le_Clerc, Patrick Pérez</p><p>Abstract: In this paper, we address the problem of object segmentation in multiple views or videos when two or more viewpoints of the same scene are available. We propose a new approach that propagates segmentation coherence information in both space and time, hence allowing evidences in one image to be shared over the complete set. To this aim the segmentation is cast as a single efficient labeling problem over space and time with graph cuts. In contrast to most existing multi-view segmentation methods that rely on some form of dense reconstruction, ours only requires a sparse 3D sampling to propagate information between viewpoints. The approach is thoroughly evaluated on standard multiview datasets, as well as on videos. With static views, results compete with state of the art methods but they are achieved with significantly fewer viewpoints. With multiple videos, we report results that demonstrate the benefit of segmentation propagation through temporal cues.</p><p>6 0.85935897 <a title="395-lda-6" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>7 0.85295105 <a title="395-lda-7" href="./iccv-2013-Refractive_Structure-from-Motion_on_Underwater_Images.html">348 iccv-2013-Refractive Structure-from-Motion on Underwater Images</a></p>
<p>8 0.79155827 <a title="395-lda-8" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>9 0.76553798 <a title="395-lda-9" href="./iccv-2013-A_Deformable_Mixture_Parsing_Model_with_Parselets.html">8 iccv-2013-A Deformable Mixture Parsing Model with Parselets</a></p>
<p>10 0.76472306 <a title="395-lda-10" href="./iccv-2013-Data-Driven_3D_Primitives_for_Single_Image_Understanding.html">102 iccv-2013-Data-Driven 3D Primitives for Single Image Understanding</a></p>
<p>11 0.6791929 <a title="395-lda-11" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>12 0.67559487 <a title="395-lda-12" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>13 0.65480411 <a title="395-lda-13" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>14 0.637896 <a title="395-lda-14" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>15 0.63694906 <a title="395-lda-15" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>16 0.62362623 <a title="395-lda-16" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>17 0.61822659 <a title="395-lda-17" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>18 0.61749905 <a title="395-lda-18" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>19 0.61718065 <a title="395-lda-19" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>20 0.61185563 <a title="395-lda-20" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
