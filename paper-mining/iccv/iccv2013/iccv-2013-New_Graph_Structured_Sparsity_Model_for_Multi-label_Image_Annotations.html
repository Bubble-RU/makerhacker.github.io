<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-290" href="#">iccv2013-290</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</h1>
<br/><p>Source: <a title="iccv-2013-290-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Cai_New_Graph_Structured_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: In multi-label image annotations, because each image is associated to multiple categories, the semantic terms (label classes) are not mutually exclusive. Previous research showed that such label correlations can largely boost the annotation accuracy. However, all existing methods only directly apply the label correlation matrix to enhance the label inference and assignment without further learning the structural information among classes. In this paper, we model the label correlations using the relational graph, and propose a novel graph structured sparse learning model to incorporate the topological constraints of relation graph in multi-label classifications. As a result, our new method will capture and utilize the hidden class structures in relational graph to improve the annotation results. In proposed objective, a large number of structured sparsity-inducing norms are utilized, thus the optimization becomes difficult. To solve this problem, we derive an efficient optimization algorithm with proved convergence. We perform extensive experiments on six multi-label image annotation benchmark data sets. In all empirical results, our new method shows better annotation results than the state-of-the-art approaches.</p><p>Reference: <a title="iccv-2013-290-reference" href="../iccv2013_reference/iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Previous research showed that such label correlations can largely boost the annotation accuracy. [sent-6, score-0.494]
</p><p>2 However, all existing methods only directly apply the label correlation matrix to enhance the label inference and assignment without further learning the structural information among classes. [sent-7, score-0.383]
</p><p>3 In this paper, we model the label correlations using the relational graph, and propose a novel graph structured sparse learning model to incorporate the topological constraints of relation graph in multi-label classifications. [sent-8, score-1.246]
</p><p>4 As a result, our new method will capture and utilize the hidden class structures in relational graph to improve the annotation results. [sent-9, score-0.829]
</p><p>5 In proposed objective, a large number of structured sparsity-inducing norms are utilized, thus the optimization becomes difficult. [sent-10, score-0.246]
</p><p>6 We perform extensive experiments on six multi-label image annotation benchmark data sets. [sent-12, score-0.194]
</p><p>7 In all empirical results, our new method shows  better annotation results than the state-of-the-art approaches. [sent-13, score-0.194]
</p><p>8 An example of label correlations for class membership inference. [sent-30, score-0.306]
</p><p>9 Different to traditional single-label multi-class image classifications, in image annotation, each image or video clip is often associated with more than one semantic label, which poses so-called multi-label multi-class classification problem. [sent-34, score-0.216]
</p><p>10 The multi-label multi-class classifications have many applications, such as document classification, protein function prediction, and music annotation. [sent-38, score-0.118]
</p><p>11 An important difference between single-label classification and multi-label classification is that, the annotation classes in single-label classification are mutually exclusive, but the annotation terms in multi-label classification are correlated to each other. [sent-39, score-1.035]
</p><p>12 Thus, in multi-label classification, researchers can utilize such annotation label correlations to infer the class memberships from one to another. [sent-40, score-0.552]
</p><p>13 However, from the training visual data, we can learn the high correlations between “sky” and “plane”, and between “ocean” and “ship”. [sent-43, score-0.16]
</p><p>14 Many previous multi-label image annotation methods explore such label correlations to improve the classification accuracy [3, 17, 11, 12, 13]. [sent-48, score-0.562]
</p><p>15 However, all previous methods enhance the multi-label classifications by directly multiplying a label correlation matrix C ∈ ? [sent-49, score-0.405]
</p><p>16 c×c (which can be calculated by the normalmizeatdr icxo Csine ∈ similarity between classes and c is the number of classes) on the label matrix or coefficient matrix to improve the label propagation or label assignment. [sent-50, score-0.579]
</p><p>17 None of them explores the structures of classes under the label correlations. [sent-51, score-0.256]
</p><p>18 Beyond straightforwardly applying the label correlation matrix, in this work, we propose to utilize the class relational graph to model the underlying structures existing in multi-label classes. [sent-52, score-0.803]
</p><p>19 The label correlations indeed can be modeled as a class relational graph. [sent-53, score-0.6]
</p><p>20 For example, using PASCAL 2006 data set, we can model the correlations among annotation term as a relational graph G = {V, E} in Fig. [sent-54, score-0.846]
</p><p>21 2, where nodes ains Va are tiohen aaln gnroatpathio Gn c =las {seVs, Ean}d weights ,o fw edges oind eEs are the correlation values between classes (nodes). [sent-55, score-0.247]
</p><p>22 Some classes, such as “Cat”, “Cow”, “Sheep”, have very small correlations with the rest classes shown in the left panel of Fig. [sent-56, score-0.347]
</p><p>23 Such a relational graph model can capture the underlying structural interrelations between classes. [sent-61, score-0.492]
</p><p>24 How to utilize this relational graph with discovering the hidden classes structures to enhance multi-label classification is computationally challenging. [sent-62, score-0.88]
</p><p>25 In this paper, we will propose the novel structured sparsity-inducing norm regularization to incorporate the relational graph information into multi-label classification model. [sent-63, score-0.893]
</p><p>26 Different to previous methods, which directly use the label correlation values to enhance the classification results, our new method will impose the correlated classes to share the common space, such that the input data relevant to both classes will learn jointly. [sent-64, score-0.662]
</p><p>27 Our new class relational graph regularization will include a large number of non-smooth structured sparsity-inducing norms, such that the objective function optimization becomes difficult. [sent-65, score-0.892]
</p><p>28 We will introduce new optimization algorithms to solve the proposed non-smooth convex objective with convergence proof. [sent-66, score-0.21]
</p><p>29 We perform our new method on six multi-label classification benchmark data sets and compare the results with eight state-of-the-art multi-label classification methods. [sent-67, score-0.224]
</p><p>30 Multi-Label  Classification  Using  Graph  Structured Sparse Learning Model The existing multi-label learning models cannot incorporate the semantic terms relational graph to enhance the annotation results. [sent-69, score-0.905]
</p><p>31 To study the feature or class structural re-  lations, many structured sparse learning methods have been proposed in recent research and shown promising results [18, 6, 4, 8, 1, 14, 15, 7]. [sent-70, score-0.247]
</p><p>32 However, these approaches also cannot incorporate the label relational graph into the classification models. [sent-71, score-0.751]
</p><p>33 To address this challenging problem, we propose new graph structured sparsity-inducing norms, which learn the correlated classes in a common space under the relational graph structure. [sent-72, score-1.05]
</p><p>34 n×c for c classes, the structured sparsityinducing norm ∈ba ? [sent-76, score-0.222]
</p><p>35 a nTdh eL regularization term Ω(W) is the structured sparsity-inducing norm, which usually uses the mixed norms to capture the features and classes structural relations for enhancing the classification tasks. [sent-81, score-0.554]
</p><p>36 In multi-label annotations, we have the label (semantic terms) relational graph G = {V, E} (e. [sent-82, score-0.588]
</p><p>37 the class relationtael graph claotniosntarulc gteradp ihn G Fig. [sent-84, score-0.248]
</p><p>38 If we correctly incorporate such label relational graph into multi-label classifi-  cation model, the performance can definitely be boosted. [sent-88, score-0.639]
</p><p>39 Thus, the structured sparsity-inducing norm Ω(W) is expected to model the label relational graph. [sent-89, score-0.551]
</p><p>40 However, it is challenging to model such graph structured sparsity by the convex norm. [sent-91, score-0.447]
</p><p>41 We propose a new graph structured sparsity model to capture the graph structures using the structured sparsityinducing norms. [sent-92, score-0.859]
</p><p>42 Our new graph structured sparse multilabel classification model is to solve:  mW,inbL(X,W,b;Y ) + γE? [sent-93, score-0.601]
</p><p>43 Our regularization terms go through all edges in E to include all topological constraints by the structured sparsity-inducing norms. [sent-104, score-0.29]
</p><p>44 id=1  880022  graph, where nodes are labels and weights of edges are correlation values between classes. [sent-106, score-0.128]
</p><p>45 Meanwhile, our regularization terms are also convex norms which guarantee the globally optimal results. [sent-108, score-0.211]
</p><p>46 Because the weight aij of the edge connecting nodes Vi and Vj represents the correlation level of these two classes, we also use the weights values to scale the regularization terms. [sent-109, score-0.26]
</p><p>47 As a result, the highly correlated classes will get large weight in the joint sparsity regularization. [sent-110, score-0.238]
</p><p>48 2,1-norm minimization problem, based on which we will further derive the algorithm to solve the main objective in (4). [sent-140, score-0.161]
</p><p>49 ion Tr(GiT(X)DiGi (X)), where Di is a diagonal matrix  with the k-th diagonal element as 2? [sent-154, score-0.239]
</p><p>50 In the following, we will prove that this algorithm will converge and converge to a local or global solution to the problem in (5), when the problem in (5) is non-convex or convex. [sent-159, score-0.191]
</p><p>51 Algorithm Convergence Analysis To prove the convergence of our Algorithm 1, first we introduce the following lemma: Lemma 1 Suppose D is a diagonal matrix, where the k-th diagonal element is 2? [sent-163, score-0.221]
</p><p>52 i  Thus the Algorithm 1monotonically decreases the value of objective function in (5) or remains the objective function value unchanged in each iteration t. [sent-295, score-0.224]
</p><p>53 The following theorem guarantees that the Algorithm 1 will converge to a local or global solution to the problem (5). [sent-299, score-0.154]
</p><p>54 Theorem 2 The Algorithm 1will converge to a local optimal solution of the objective in (5), and will converge to a global solution if the objective in (5) is a convex function. [sent-300, score-0.463]
</p><p>55 i2γiDiGi(X) −∂h∂(XX,Λ)  =  0,  (11)  where D is a diagonal matrix, and the k-th diagonal element is Suppose the Algorithm 1 converges to a solution X∗, from Step 2 in Algorithm 1, we have:  2? [sent-311, score-0.22]
</p><p>56 iγiTr(GiT(X)(D∗)iGi(X)),  (12) where D is a diagonal matrix with the k-th diagonal element as 2? [sent-315, score-0.239]
</p><p>57 Therefore, the converged solution X∗ is a local solution of the objective in (5). [sent-324, score-0.234]
</p><p>58 Moreover, if the objective in (5) is a convex function, then the converged solution X∗ is a global solution of the objective in (5) ? [sent-325, score-0.395]
</p><p>59 In the next section, we will derive the algorithm to solve the objective in (4) based on Algorithm 1. [sent-326, score-0.161]
</p><p>60 Algorithm to Solve Objective in (4) According to Algorithm 1, the key step to solve the objective in (4) is to solve the following problem:  γmWi? [sent-328, score-0.21]
</p><p>61 matrix with the k-th diagonal ele-  ment We simplify the second term in Eq. [sent-335, score-0.147]
</p><p>62 (17) Therefore, we get the optimal solution of the problem (16) as: wi = (XHXT + γMi)−1XHyi . [sent-420, score-0.144]
</p><p>63 (18) Based on the above derivation, the detailed algorithm to solve the objective in (4) is summarized in Algorithm 2. [sent-421, score-0.161]
</p><p>64 Because the objective in (4) is a convex problem, according to Theorem 2, we can obtain the global solution with Algorithm 2. [sent-422, score-0.197]
</p><p>65 Experiment Data In this section, we will briefly introduce the multi-label image data sets that we used to evaluation the proposed graph structured sparse multi-label learning model. [sent-426, score-0.395]
</p><p>66 Note that multiple objects from multiple classes may be present in the same image. [sent-440, score-0.119]
</p><p>67 It has 25000 images with 38 classes downloaded from the social photography site Flickr through its public API. [sent-463, score-0.119]
</p><p>68 colors, seasons and place names, the average number of annotation per image is 8. [sent-466, score-0.194]
</p><p>69 Experiment Settings In our experment, we used the following way to build the graph structure for the annotations. [sent-472, score-0.198]
</p><p>70 mDi affnedre 0nt o fhreormw sceo,n ∀vie n=tio 1n,2a,l single-label classification learning in which classes are mutual exclusive, the annotations are interrelated with one another in multi-label problem. [sent-477, score-0.343]
</p><p>71 We utilize the following cosine similarity to calculate the annotation affinity matrix  A(i,j) = cos(yi,yj) =(|  j| )  (19)  where yi and yj are the i-th and j-th column of the indicator matrix of the labeled data Y ∈ Rl respectively. [sent-478, score-0.356]
</p><p>72 Thus, a graph G = (V, E) is induced∈, w Rhere V = A and E ⊆ V V . [sent-479, score-0.198]
</p><p>73 d Wucheadt by mthoer eo,u itnlie orr ddearta to or imneovvitea tbhlee ”innaocicsyu”rate annotation information of the training data, we set up a filter to set those entries of A in Eq. [sent-481, score-0.194]
</p><p>74 We will use the above calculated annotation graph structure as input for both our method and the comparison approaches. [sent-483, score-0.392]
</p><p>75 Moreover, we compare our proposed method with the following state-of-art multi-label classification methods: K Nearest Neighbor (KNN), where we set K as 1(1NN) for its simple and intuitive interpretation, that is, we predict the annotations of the testing data as the ones of its nearest neighbor. [sent-499, score-0.262]
</p><p>76 the rest strategy to predict the annotations one by one, where we chose the linear kernel and set C as 1. [sent-503, score-0.15]
</p><p>77 Multi-Label Informed Latent Semantic Indexing (MLSI) [17] is an approach to extend unsupervised latent semantic indexing (LSI) to utilize the provided supervision information. [sent-506, score-0.156]
</p><p>78 However, the way that MLLS takes advantage of the annotation information is different with our proposed method. [sent-509, score-0.194]
</p><p>79 o Itnati [o3n], i infd wicea tdoern moteatr tihxe as tYa m∈a Rtrinx× acs, tXhen ∈ M RLLaSn explores tthioen l iinnedairc atonrno mtaattiroinx ainsf Yorm ∈at iRon by calculating XY YTX only without the graph information. [sent-511, score-0.198]
</p><p>80 What is more, with the development of feature selection methods, more and more filter methods or their variations can be used to reduce the dimension of feature and further boost the multi-label classification performance. [sent-512, score-0.156]
</p><p>81 In addition, they used 1NN as the classifier to evaluate the multi-label classification performance on 10% to 70% selected features and reported the best multilabel classification result based on a certain number of selected features. [sent-515, score-0.318]
</p><p>82 Multi-Label Classification Results Two standard multi-label classification performance metrics precision and F1 score are used to evaluate image annotation performances. [sent-518, score-0.306]
</p><p>83 In our experiment, we report both macro and micro results in Table. [sent-519, score-0.147]
</p><p>84 As can be observed from the table, first of all, correlations between annotations can indeed boost the classification performance compared with the methods that consider annotation classification independently, like SVM. [sent-521, score-0.734]
</p><p>85 Moreover, given the same graph structure, our proposed graph structured sparse multi-label  learning method can consistently beat those dimension reduction methods as well as feature selection methods invented for multi-label classification on most data sets. [sent-522, score-0.705]
</p><p>86 Therefore, although the precision of our method is higher, we get a less macro and micro F1 score. [sent-524, score-0.147]
</p><p>87 Given an image having “Chairs”, “Dinning table”, “Person” inside, the annotation affinity matrix shows the correlation values between these semantic terms. [sent-529, score-0.425]
</p><p>88 Because semantic terms “Chairs” and “Dinning table” often appear together and have large correlations, the weight of edge connecting them in the label relational graph G is large. [sent-530, score-0.692]
</p><p>89 Thus, their regularization term has large contribution in training process (in right-bottom panel), such that the learned coefficient matrix W∗ showing these correlations. [sent-531, score-0.194]
</p><p>90 2,1-norm with the help of pairwise annotation correlation information, which is shown in the top panel. [sent-534, score-0.266]
</p><p>91 Obviously two semantic terms show similar weight coefficient structures, i. [sent-536, score-0.166]
</p><p>92 The existing methods didn’t consider the shared structure between correlated semantic terms, hence they predict “Dinning table”, but miss “Chairs” in the prediction. [sent-540, score-0.222]
</p><p>93 Our graph structured sparse multi-label learning model can correctly predict both labels due to the shared similar weight structures in W∗ . [sent-541, score-0.474]
</p><p>94 Conclusion In this paper, we model the label correlations using the relational graph, and propose a novel graph structured s880077  ? [sent-543, score-0.909]
</p><p>95 2,1-norm will shrink the coefficient matrix based on different weight values. [sent-544, score-0.117]
</p><p>96 And the higher weight will boost the multi-label classification  via graph structured sparse learning. [sent-545, score-0.551]
</p><p>97 parse learning model to incorporate the topological constraints of relation graph to tackle multi-label classifications problem. [sent-546, score-0.419]
</p><p>98 Moreover, it is a general method to incorporate graph structure information to the supervised learning. [sent-547, score-0.249]
</p><p>99 Compared with multiple state-of-art multi-label classification methods, our method consistently achieves superior classification result with respect to both precision and F1 score in macro as well as micro cases. [sent-550, score-0.371]
</p><p>100 Image annotation using birelational graph ofimages and semantic labels. [sent-635, score-0.496]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('relational', 0.294), ('ocean', 0.203), ('graph', 0.198), ('annotation', 0.194), ('git', 0.183), ('digi', 0.172), ('structured', 0.161), ('correlations', 0.16), ('ak', 0.141), ('aijdij', 0.138), ('dinning', 0.138), ('gi', 0.128), ('itr', 0.127), ('sky', 0.125), ('classes', 0.119), ('classifications', 0.118), ('objective', 0.112), ('classification', 0.112), ('annotations', 0.112), ('wi', 0.108), ('ship', 0.107), ('semantic', 0.104), ('relieff', 0.103), ('label', 0.096), ('multilabel', 0.094), ('nie', 0.094), ('diagonal', 0.092), ('chairs', 0.091), ('cai', 0.089), ('norms', 0.085), ('correlated', 0.08), ('regularization', 0.077), ('wit', 0.077), ('macro', 0.076), ('barcelona', 0.073), ('annotate', 0.073), ('correlation', 0.072), ('gist', 0.072), ('micro', 0.071), ('aakk', 0.069), ('atda', 0.069), ('hxtwi', 0.069), ('incf', 0.069), ('mlls', 0.069), ('tkdd', 0.069), ('xhxt', 0.069), ('panel', 0.068), ('cow', 0.064), ('download', 0.064), ('enhance', 0.064), ('lemma', 0.064), ('coefficient', 0.062), ('sparsityinducing', 0.061), ('igi', 0.061), ('tda', 0.061), ('dij', 0.06), ('sheep', 0.06), ('theorem', 0.059), ('converge', 0.059), ('hyi', 0.057), ('nodes', 0.056), ('aij', 0.055), ('matrix', 0.055), ('reweighted', 0.055), ('utilize', 0.052), ('topological', 0.052), ('incorporate', 0.051), ('cmt', 0.051), ('arlington', 0.051), ('vj', 0.05), ('converged', 0.05), ('meanwhile', 0.05), ('class', 0.05), ('convex', 0.049), ('solve', 0.049), ('proof', 0.049), ('heng', 0.049), ('kkt', 0.049), ('boost', 0.044), ('cat', 0.044), ('informed', 0.043), ('huang', 0.043), ('pascal', 0.042), ('mwin', 0.042), ('sydney', 0.042), ('xx', 0.041), ('bus', 0.041), ('structures', 0.041), ('plane', 0.04), ('motorbike', 0.04), ('demonstration', 0.04), ('sparsity', 0.039), ('texas', 0.038), ('wj', 0.038), ('predict', 0.038), ('bicycle', 0.037), ('prove', 0.037), ('sparse', 0.036), ('solution', 0.036), ('exclusive', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="290-tfidf-1" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: In multi-label image annotations, because each image is associated to multiple categories, the semantic terms (label classes) are not mutually exclusive. Previous research showed that such label correlations can largely boost the annotation accuracy. However, all existing methods only directly apply the label correlation matrix to enhance the label inference and assignment without further learning the structural information among classes. In this paper, we model the label correlations using the relational graph, and propose a novel graph structured sparse learning model to incorporate the topological constraints of relation graph in multi-label classifications. As a result, our new method will capture and utilize the hidden class structures in relational graph to improve the annotation results. In proposed objective, a large number of structured sparsity-inducing norms are utilized, thus the optimization becomes difficult. To solve this problem, we derive an efficient optimization algorithm with proved convergence. We perform extensive experiments on six multi-label image annotation benchmark data sets. In all empirical results, our new method shows better annotation results than the state-of-the-art approaches.</p><p>2 0.1816199 <a title="290-tfidf-2" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>Author: Minsu Cho, Karteek Alahari, Jean Ponce</p><p>Abstract: Many tasks in computer vision are formulated as graph matching problems. Despite the NP-hard nature of the problem, fast and accurate approximations have led to significant progress in a wide range of applications. Learning graph models from observed data, however, still remains a challenging issue. This paper presents an effective scheme to parameterize a graph model, and learn its structural attributes for visual object matching. For this, we propose a graph representation with histogram-based attributes, and optimize them to increase the matching accuracy. Experimental evaluations on synthetic and real image datasets demonstrate the effectiveness of our approach, and show significant improvement in matching accuracy over graphs with pre-defined structures.</p><p>3 0.17290446 <a title="290-tfidf-3" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: Automatic image categorization has become increasingly important with the development of Internet and the growth in the size of image databases. Although the image categorization can be formulated as a typical multiclass classification problem, two major challenges have been raised by the real-world images. On one hand, though using more labeled training data may improve the prediction performance, obtaining the image labels is a time consuming as well as biased process. On the other hand, more and more visual descriptors have been proposed to describe objects and scenes appearing in images and different features describe different aspects of the visual characteristics. Therefore, how to integrate heterogeneous visual features to do the semi-supervised learning is crucial for categorizing large-scale image data. In this paper, we propose a novel approach to integrate heterogeneous features by performing multi-modal semi-supervised classification on unlabeled as well as unsegmented images. Considering each type of feature as one modality, taking advantage of the large amoun- t of unlabeled data information, our new adaptive multimodal semi-supervised classification (AMMSS) algorithm learns a commonly shared class indicator matrix and the weights for different modalities (image features) simultaneously.</p><p>4 0.1339846 <a title="290-tfidf-4" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>Author: Bo Wang, Zhuowen Tu, John K. Tsotsos</p><p>Abstract: In graph-based semi-supervised learning approaches, the classification rate is highly dependent on the size of the availabel labeled data, as well as the accuracy of the similarity measures. Here, we propose a semi-supervised multi-class/multi-label classification scheme, dynamic label propagation (DLP), which performs transductive learning through propagation in a dynamic process. Existing semi-supervised classification methods often have difficulty in dealing with multi-class/multi-label problems due to the lack in consideration of label correlation; our algorithm instead emphasizes dynamic metric fusion with label information. Significant improvement over the state-of-the-art methods is observed on benchmark datasets for both multiclass and multi-label tasks.</p><p>5 0.12212438 <a title="290-tfidf-5" href="./iccv-2013-Incorporating_Cloud_Distribution_in_Sky_Representation.html">215 iccv-2013-Incorporating Cloud Distribution in Sky Representation</a></p>
<p>Author: Kuan-Chuan Peng, Tsuhan Chen</p><p>Abstract: Most sky models only describe the cloudiness ofthe overall sky by a single category or parameter such as sky index, which does not account for the distribution of the clouds across the sky. To capture variable cloudiness, we extend the concept of sky index to a random field indicating the level of cloudiness of each sky pixel in our proposed sky representation based on the Igawa sky model. We formulate the problem of solving the sky index of every sky pixel as a labeling problem, where an approximate solution can be efficiently found. Experimental results show that our proposed sky model has better expressiveness, stability with respect to variation in camera parameters, and geo-location estimation in outdoor images compared to the uniform sky index model. Potential applications of our proposed sky model include sky image rendering, where sky images can be generated with an arbitrary cloud distribution at any time and any location, previously impossible with traditional sky models.</p><p>6 0.11826062 <a title="290-tfidf-6" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>7 0.11634201 <a title="290-tfidf-7" href="./iccv-2013-Allocentric_Pose_Estimation.html">46 iccv-2013-Allocentric Pose Estimation</a></p>
<p>8 0.11537925 <a title="290-tfidf-8" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>9 0.1088432 <a title="290-tfidf-9" href="./iccv-2013-Learning_Graph_Matching%3A_Oriented_to_Category_Modeling_from_Cluttered_Scenes.html">237 iccv-2013-Learning Graph Matching: Oriented to Category Modeling from Cluttered Scenes</a></p>
<p>10 0.10604518 <a title="290-tfidf-10" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>11 0.10376889 <a title="290-tfidf-11" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>12 0.10272715 <a title="290-tfidf-12" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>13 0.097844228 <a title="290-tfidf-13" href="./iccv-2013-Improving_Graph_Matching_via_Density_Maximization.html">214 iccv-2013-Improving Graph Matching via Density Maximization</a></p>
<p>14 0.096885987 <a title="290-tfidf-14" href="./iccv-2013-Semantic_Transform%3A_Weakly_Supervised_Semantic_Inference_for_Relating_Visual_Attributes.html">380 iccv-2013-Semantic Transform: Weakly Supervised Semantic Inference for Relating Visual Attributes</a></p>
<p>15 0.094789654 <a title="290-tfidf-15" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>16 0.09411297 <a title="290-tfidf-16" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>17 0.089011535 <a title="290-tfidf-17" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>18 0.088947728 <a title="290-tfidf-18" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>19 0.088564895 <a title="290-tfidf-19" href="./iccv-2013-Directed_Acyclic_Graph_Kernels_for_Action_Recognition.html">116 iccv-2013-Directed Acyclic Graph Kernels for Action Recognition</a></p>
<p>20 0.08829774 <a title="290-tfidf-20" href="./iccv-2013-Characterizing_Layouts_of_Outdoor_Scenes_Using_Spatial_Topic_Processes.html">72 iccv-2013-Characterizing Layouts of Outdoor Scenes Using Spatial Topic Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.217), (1, 0.078), (2, -0.043), (3, -0.066), (4, -0.002), (5, 0.043), (6, -0.053), (7, 0.022), (8, 0.05), (9, -0.123), (10, -0.05), (11, -0.034), (12, -0.066), (13, 0.016), (14, 0.045), (15, 0.048), (16, -0.009), (17, -0.007), (18, -0.005), (19, 0.01), (20, -0.039), (21, 0.025), (22, -0.066), (23, -0.024), (24, 0.118), (25, -0.004), (26, 0.037), (27, -0.006), (28, 0.117), (29, 0.096), (30, 0.122), (31, 0.015), (32, 0.019), (33, -0.023), (34, -0.07), (35, 0.077), (36, 0.0), (37, 0.03), (38, -0.041), (39, 0.057), (40, 0.069), (41, -0.14), (42, -0.039), (43, -0.045), (44, 0.093), (45, -0.062), (46, 0.046), (47, -0.01), (48, -0.006), (49, 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96696198 <a title="290-lsi-1" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: In multi-label image annotations, because each image is associated to multiple categories, the semantic terms (label classes) are not mutually exclusive. Previous research showed that such label correlations can largely boost the annotation accuracy. However, all existing methods only directly apply the label correlation matrix to enhance the label inference and assignment without further learning the structural information among classes. In this paper, we model the label correlations using the relational graph, and propose a novel graph structured sparse learning model to incorporate the topological constraints of relation graph in multi-label classifications. As a result, our new method will capture and utilize the hidden class structures in relational graph to improve the annotation results. In proposed objective, a large number of structured sparsity-inducing norms are utilized, thus the optimization becomes difficult. To solve this problem, we derive an efficient optimization algorithm with proved convergence. We perform extensive experiments on six multi-label image annotation benchmark data sets. In all empirical results, our new method shows better annotation results than the state-of-the-art approaches.</p><p>2 0.82808125 <a title="290-lsi-2" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: Automatic image categorization has become increasingly important with the development of Internet and the growth in the size of image databases. Although the image categorization can be formulated as a typical multiclass classification problem, two major challenges have been raised by the real-world images. On one hand, though using more labeled training data may improve the prediction performance, obtaining the image labels is a time consuming as well as biased process. On the other hand, more and more visual descriptors have been proposed to describe objects and scenes appearing in images and different features describe different aspects of the visual characteristics. Therefore, how to integrate heterogeneous visual features to do the semi-supervised learning is crucial for categorizing large-scale image data. In this paper, we propose a novel approach to integrate heterogeneous features by performing multi-modal semi-supervised classification on unlabeled as well as unsegmented images. Considering each type of feature as one modality, taking advantage of the large amoun- t of unlabeled data information, our new adaptive multimodal semi-supervised classification (AMMSS) algorithm learns a commonly shared class indicator matrix and the weights for different modalities (image features) simultaneously.</p><p>3 0.7569502 <a title="290-lsi-3" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>Author: Bo Wang, Zhuowen Tu, John K. Tsotsos</p><p>Abstract: In graph-based semi-supervised learning approaches, the classification rate is highly dependent on the size of the availabel labeled data, as well as the accuracy of the similarity measures. Here, we propose a semi-supervised multi-class/multi-label classification scheme, dynamic label propagation (DLP), which performs transductive learning through propagation in a dynamic process. Existing semi-supervised classification methods often have difficulty in dealing with multi-class/multi-label problems due to the lack in consideration of label correlation; our algorithm instead emphasizes dynamic metric fusion with label information. Significant improvement over the state-of-the-art methods is observed on benchmark datasets for both multiclass and multi-label tasks.</p><p>4 0.67682904 <a title="290-lsi-4" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>Author: Minsu Cho, Karteek Alahari, Jean Ponce</p><p>Abstract: Many tasks in computer vision are formulated as graph matching problems. Despite the NP-hard nature of the problem, fast and accurate approximations have led to significant progress in a wide range of applications. Learning graph models from observed data, however, still remains a challenging issue. This paper presents an effective scheme to parameterize a graph model, and learn its structural attributes for visual object matching. For this, we propose a graph representation with histogram-based attributes, and optimize them to increase the matching accuracy. Experimental evaluations on synthetic and real image datasets demonstrate the effectiveness of our approach, and show significant improvement in matching accuracy over graphs with pre-defined structures.</p><p>5 0.66444433 <a title="290-lsi-5" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>Author: Honghui Zhang, Jingdong Wang, Ping Tan, Jinglu Wang, Long Quan</p><p>Abstract: We propose an adaptive subgradient descent method to efficiently learn the parameters of CRF models for image parsing. To balance the learning efficiency and performance of the learned CRF models, the parameter learning is iteratively carried out by solving a convex optimization problem in each iteration, which integrates a proximal term to preserve the previously learned information and the large margin preference to distinguish bad labeling and the ground truth labeling. A solution of subgradient descent updating form is derived for the convex optimization problem, with an adaptively determined updating step-size. Besides, to deal with partially labeled training data, we propose a new objective constraint modeling both the labeled and unlabeled parts in the partially labeled training data for the parameter learning of CRF models. The superior learning efficiency of the proposed method is verified by the experiment results on two public datasets. We also demonstrate the powerfulness of our method for handling partially labeled training data.</p><p>6 0.65773433 <a title="290-lsi-6" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<p>7 0.65423834 <a title="290-lsi-7" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>8 0.64595222 <a title="290-lsi-8" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>9 0.6362651 <a title="290-lsi-9" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>10 0.63175374 <a title="290-lsi-10" href="./iccv-2013-Learning_Coupled_Feature_Spaces_for_Cross-Modal_Matching.html">235 iccv-2013-Learning Coupled Feature Spaces for Cross-Modal Matching</a></p>
<p>11 0.61942083 <a title="290-lsi-11" href="./iccv-2013-Visual_Reranking_through_Weakly_Supervised_Multi-graph_Learning.html">445 iccv-2013-Visual Reranking through Weakly Supervised Multi-graph Learning</a></p>
<p>12 0.60913956 <a title="290-lsi-12" href="./iccv-2013-Handling_Uncertain_Tags_in_Visual_Recognition.html">191 iccv-2013-Handling Uncertain Tags in Visual Recognition</a></p>
<p>13 0.60809809 <a title="290-lsi-13" href="./iccv-2013-Joint_Optimization_for_Consistent_Multiple_Graph_Matching.html">224 iccv-2013-Joint Optimization for Consistent Multiple Graph Matching</a></p>
<p>14 0.60596424 <a title="290-lsi-14" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>15 0.60439742 <a title="290-lsi-15" href="./iccv-2013-Unbiased_Metric_Learning%3A_On_the_Utilization_of_Multiple_Datasets_and_Web_Images_for_Softening_Bias.html">431 iccv-2013-Unbiased Metric Learning: On the Utilization of Multiple Datasets and Web Images for Softening Bias</a></p>
<p>16 0.60349762 <a title="290-lsi-16" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>17 0.59946936 <a title="290-lsi-17" href="./iccv-2013-Ensemble_Projection_for_Semi-supervised_Image_Classification.html">142 iccv-2013-Ensemble Projection for Semi-supervised Image Classification</a></p>
<p>18 0.59731364 <a title="290-lsi-18" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>19 0.5880965 <a title="290-lsi-19" href="./iccv-2013-Learning_to_Rank_Using_Privileged_Information.html">248 iccv-2013-Learning to Rank Using Privileged Information</a></p>
<p>20 0.57780159 <a title="290-lsi-20" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.085), (7, 0.013), (26, 0.073), (31, 0.047), (34, 0.011), (35, 0.013), (42, 0.121), (64, 0.051), (73, 0.019), (78, 0.332), (89, 0.141), (98, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.80075759 <a title="290-lda-1" href="./iccv-2013-Capturing_Global_Semantic_Relationships_for_Facial_Action_Unit_Recognition.html">69 iccv-2013-Capturing Global Semantic Relationships for Facial Action Unit Recognition</a></p>
<p>Author: Ziheng Wang, Yongqiang Li, Shangfei Wang, Qiang Ji</p><p>Abstract: In this paper we tackle the problem of facial action unit (AU) recognition by exploiting the complex semantic relationships among AUs, which carry crucial top-down information yet have not been thoroughly exploited. Towards this goal, we build a hierarchical model that combines the bottom-level image features and the top-level AU relationships to jointly recognize AUs in a principled manner. The proposed model has two major advantages over existing methods. 1) Unlike methods that can only capture local pair-wise AU dependencies, our model is developed upon the restricted Boltzmann machine and therefore can exploit the global relationships among AUs. 2) Although AU relationships are influenced by many related factors such as facial expressions, these factors are generally ignored by the current methods. Our model, however, can successfully capture them to more accurately characterize the AU relationships. Efficient learning and inference algorithms of the proposed model are also developed. Experimental results on benchmark databases demonstrate the effectiveness of the proposed approach in modelling complex AU relationships as well as its superior AU recognition performance over existing approaches.</p><p>2 0.78023219 <a title="290-lda-2" href="./iccv-2013-Recognising_Human-Object_Interaction_via_Exemplar_Based_Modelling.html">344 iccv-2013-Recognising Human-Object Interaction via Exemplar Based Modelling</a></p>
<p>Author: Jian-Fang Hu, Wei-Shi Zheng, Jianhuang Lai, Shaogang Gong, Tao Xiang</p><p>Abstract: Human action can be recognised from a single still image by modelling Human-object interaction (HOI), which infers the mutual spatial structure information between human and object as well as their appearance. Existing approaches rely heavily on accurate detection of human and object, and estimation of human pose. They are thus sensitive to large variations of human poses, occlusion and unsatisfactory detection of small size objects. To overcome this limitation, a novel exemplar based approach is proposed in this work. Our approach learns a set of spatial pose-object interaction exemplars, which are density functions describing how a person is interacting with a manipulated object for different activities spatially in a probabilistic way. A representation based on our HOI exemplar thus has great potential for being robust to the errors in human/object detection and pose estimation. A new framework consists of a proposed exemplar based HOI descriptor and an activity specific matching model that learns the parameters is formulated for robust human activity recog- nition. Experiments on two benchmark activity datasets demonstrate that the proposed approach obtains state-ofthe-art performance.</p><p>same-paper 3 0.77353168 <a title="290-lda-3" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: In multi-label image annotations, because each image is associated to multiple categories, the semantic terms (label classes) are not mutually exclusive. Previous research showed that such label correlations can largely boost the annotation accuracy. However, all existing methods only directly apply the label correlation matrix to enhance the label inference and assignment without further learning the structural information among classes. In this paper, we model the label correlations using the relational graph, and propose a novel graph structured sparse learning model to incorporate the topological constraints of relation graph in multi-label classifications. As a result, our new method will capture and utilize the hidden class structures in relational graph to improve the annotation results. In proposed objective, a large number of structured sparsity-inducing norms are utilized, thus the optimization becomes difficult. To solve this problem, we derive an efficient optimization algorithm with proved convergence. We perform extensive experiments on six multi-label image annotation benchmark data sets. In all empirical results, our new method shows better annotation results than the state-of-the-art approaches.</p><p>4 0.75588542 <a title="290-lda-4" href="./iccv-2013-Line_Assisted_Light_Field_Triangulation_and_Stereo_Matching.html">252 iccv-2013-Line Assisted Light Field Triangulation and Stereo Matching</a></p>
<p>Author: Zhan Yu, Xinqing Guo, Haibing Lin, Andrew Lumsdaine, Jingyi Yu</p><p>Abstract: Light fields are image-based representations that use densely sampled rays as a scene description. In this paper, we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching. The triangulation problem aims to fill in the ray space with continuous and non-overlapping simplices anchored at sampled points (rays). Such a triangulation provides a piecewise-linear interpolant useful for light field superresolution. We show that the light field space is largely bilinear due to 3D line segments in the scene, and direct triangulation of these bilinear subspaces leads to large errors. We instead present a simple but effective algorithm to first map bilinear subspaces to line constraints and then apply Constrained Delaunay Triangulation (CDT). Based on our analysis, we further develop a novel line-assisted graphcut (LAGC) algorithm that effectively encodes 3D line constraints into light field stereo matching. Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality.</p><p>5 0.71811688 <a title="290-lda-5" href="./iccv-2013-Multi-attributed_Dictionary_Learning_for_Sparse_Coding.html">276 iccv-2013-Multi-attributed Dictionary Learning for Sparse Coding</a></p>
<p>Author: Chen-Kuo Chiang, Te-Feng Su, Chih Yen, Shang-Hong Lai</p><p>Abstract: We present a multi-attributed dictionary learning algorithm for sparse coding. Considering training samples with multiple attributes, a new distance matrix is proposed by jointly incorporating data and attribute similarities. Then, an objective function is presented to learn categorydependent dictionaries that are compact (closeness of dictionary atoms based on data distance and attribute similarity), reconstructive (low reconstruction error with correct dictionary) and label-consistent (encouraging the labels of dictionary atoms to be similar). We have demonstrated our algorithm on action classification and face recognition tasks on several publicly available datasets. Experimental results with improved performance over previous dictionary learning methods are shown to validate the effectiveness of the proposed algorithm.</p><p>6 0.69766521 <a title="290-lda-6" href="./iccv-2013-From_Actemes_to_Action%3A_A_Strongly-Supervised_Representation_for_Detailed_Action_Understanding.html">175 iccv-2013-From Actemes to Action: A Strongly-Supervised Representation for Detailed Action Understanding</a></p>
<p>7 0.64524221 <a title="290-lda-7" href="./iccv-2013-Facial_Action_Unit_Event_Detection_by_Cascade_of_Tasks.html">155 iccv-2013-Facial Action Unit Event Detection by Cascade of Tasks</a></p>
<p>8 0.6113745 <a title="290-lda-8" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>9 0.59985024 <a title="290-lda-9" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>10 0.59180701 <a title="290-lda-10" href="./iccv-2013-From_Subcategories_to_Visual_Composites%3A_A_Multi-level_Framework_for_Object_Detection.html">179 iccv-2013-From Subcategories to Visual Composites: A Multi-level Framework for Object Detection</a></p>
<p>11 0.58456767 <a title="290-lda-11" href="./iccv-2013-Modeling_4D_Human-Object_Interactions_for_Event_and_Object_Recognition.html">268 iccv-2013-Modeling 4D Human-Object Interactions for Event and Object Recognition</a></p>
<p>12 0.58415902 <a title="290-lda-12" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>13 0.5835458 <a title="290-lda-13" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>14 0.58297288 <a title="290-lda-14" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>15 0.57865494 <a title="290-lda-15" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>16 0.57698238 <a title="290-lda-16" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>17 0.57590979 <a title="290-lda-17" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>18 0.57573861 <a title="290-lda-18" href="./iccv-2013-Correntropy_Induced_L2_Graph_for_Robust_Subspace_Clustering.html">94 iccv-2013-Correntropy Induced L2 Graph for Robust Subspace Clustering</a></p>
<p>19 0.57444847 <a title="290-lda-19" href="./iccv-2013-A_Unified_Probabilistic_Approach_Modeling_Relationships_between_Attributes_and_Objects.html">31 iccv-2013-A Unified Probabilistic Approach Modeling Relationships between Attributes and Objects</a></p>
<p>20 0.57401311 <a title="290-lda-20" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
