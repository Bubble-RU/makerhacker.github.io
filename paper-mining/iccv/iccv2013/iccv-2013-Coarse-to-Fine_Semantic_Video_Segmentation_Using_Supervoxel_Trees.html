<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-76" href="#">iccv2013-76</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</h1>
<br/><p>Source: <a title="iccv-2013-76-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Jain_Coarse-to-Fine_Semantic_Video_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Aastha Jain, Shuanak Chatterjee, René Vidal</p><p>Abstract: We propose an exact, general and efficient coarse-to-fine energy minimization strategy for semantic video segmentation. Our strategy is based on a hierarchical abstraction of the supervoxel graph that allows us to minimize an energy defined at the finest level of the hierarchy by minimizing a series of simpler energies defined over coarser graphs. The strategy is exact, i.e., it produces the same solution as minimizing over the finest graph. It is general, i.e., it can be used to minimize any energy function (e.g., unary, pairwise, and higher-order terms) with any existing energy minimization algorithm (e.g., graph cuts and belief propagation). It also gives significant speedups in inference for several datasets with varying degrees of spatio-temporal continuity. We also discuss the strengths and weaknesses of our strategy relative to existing hierarchical approaches, and the kinds of image and video data that provide the best speedups.</p><p>Reference: <a title="iccv-2013-76-reference" href="../iccv2013_reference/iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Our strategy is based on a hierarchical abstraction of the supervoxel graph that allows us to minimize an energy defined at the finest level of the hierarchy by minimizing a series of simpler energies defined over coarser graphs. [sent-7, score-1.395]
</p><p>2 In this paper, we propose an exact, general and efficient coarse-to-fine energy minimization strategy for image and video segmentation, which can be used to speedup any approximate energy minimization approach (e. [sent-37, score-0.409]
</p><p>3 Therefore, contiguous supervoxels (both in space and in time) are very likely to have the same label. [sent-41, score-0.516]
</p><p>4 For instance, if we consider supervoxels of size k k superpixels spanning k frames, then the nvuoxmeblser o fo sfi possible segmentations fnoirn gth ke example eabno thvee reduces to which is significant even for k = 2. [sent-43, score-0.558]
</p><p>5 To capture the spatial and temporal continuity of a video, we define a hierarchical abstraction of the supervoxel graph such that most supervoxels at a coarse level correspond to a single label. [sent-44, score-1.503]
</p><p>6 We use a hierarchical graph-based supervoxel segmentation method (see [3 1] for an overview) to identify the supervoxels (at various scales) that are likely to have the same label. [sent-46, score-1.277]
</p><p>7 Such methods create a supervoxel tree with the biggest (coarsest) supervoxels at the highest level. [sent-47, score-1.201]
</p><p>8 The top row shows the various abstraction levels in the supervoxel tree. [sent-53, score-0.777]
</p><p>9 The second row  shows the portion of the supervoxel tree explored by our coarse-to-fine scheme to find the optimal labeling of segments. [sent-54, score-0.801]
</p><p>10 Given this hierarchy, we construct a series of energy functions for different levels of abstraction and propose a coarse-to-fine inference scheme that minimizes these energies to find an optimal segmentation at the finest level of the hierarchy. [sent-57, score-0.662]
</p><p>11 To define the different energy functions, we first augment the set of labels with an auxiliary label called mixed, which accounts for the fact that coarse supervoxels may contain finer supervoxels with more than one pure label. [sent-58, score-1.291]
</p><p>12 We then define the unary, pairwise and higherorder costs of the energy at any level of the hierarchy as lower bounds for the costs at the finest level. [sent-59, score-0.678]
</p><p>13 Our coarseto-fine inference scheme starts by performing inference at the coarsest level of the supervoxel hierarchy using any inference method (e. [sent-61, score-1.213]
</p><p>14 If the solution at the current level of refinement is such that no supervoxel is assigned the mixed label, then an optimal solution at the finest level has been found by performing inference over a very coarse graph. [sent-64, score-1.283]
</p><p>15 Otherwise, the mixed supervoxels are refined into its constituent (finer) supervoxels, and a new inference problem is solved over both coarse and fine supervoxels. [sent-65, score-0.814]
</p><p>16 In general, it is very hard to know if the proposed scheme is more efficient that direct inference over the finest layer. [sent-67, score-0.337]
</p><p>17 Clearly if the hierarchy of supervoxels is poorly constructed so that many refinement cycles are needed, our method could be less efficient because it solves too many small inference problems. [sent-68, score-0.734]
</p><p>18 One line  of work in hierarchical video segmentation is a bottomup approach based on merging supervoxels using similarity metrics based on variation of intensity inside a supervoxel [13, 18]. [sent-74, score-1.364]
</p><p>19 Nonetheless, the supervoxel tree obtained by these approaches can be used as the abstraction hierarchy in our framework. [sent-76, score-0.911]
</p><p>20 Another line of work defines a hierarchical cost function over supervoxels at all levels. [sent-77, score-0.604]
</p><p>21 Specifically, the works of [22, 25] solve a multilayer optimization problem, while we optimize a cost function defined at the finest layer only. [sent-83, score-0.259]
</p><p>22 To do this more efficiently, we use the supervoxel tree to iteratively refine the parts of the video that could have more than one label. [sent-84, score-0.773]
</p><p>23 However, unlike our method, the abstraction used is image-agnostic and the messages at 11886666  a coarse level are only used to initialize messages at the finer level and not to prevent expanding all nodes. [sent-89, score-0.309]
</p><p>24 Also, we can use any of these algorithms [21, 14, 10, 4] to solve the energy minimization problem in each iteration (at the current level of refinement of the graph) and hence they can complement our hierarchical inference algorithm. [sent-93, score-0.366]
</p><p>25 We would like to emphasize that further advances in supervoxel tree creation and energy minimization (both being integral components of our approach) will further increase the speedup of our hierarchical algorithm. [sent-95, score-0.99]
</p><p>26 For the sake of concreteness, we will describe our formulation using a RF whose nodes are the supervoxels in a video. [sent-98, score-0.537]
</p><p>27 , Lod}e, which represents the category label at supervoxel vi ∈, V}. [sent-105, score-0.74]
</p><p>28 , eij ∈ E if supervoxels iand j share a common boundary. [sent-110, score-0.492]
</p><p>29 The labeling of all the nodes in clique c is denoted by a vector xc ∈ L|c| , while the labeling of all the supervoxels in a video is∈ d Lenoted by x ∈ L|V| . [sent-113, score-0.742]
</p><p>30 j  (1) The unary potential, ψiU (xi, V ), captures the cost of assigning the label xi ∈ L to the supervoxel vi in video V . [sent-123, score-0.955]
</p><p>31 Unary potentials are usually o tbhtea siunepder by training a classifier for  ×  every class on appropriate supervoxel descriptors extracted from the videos in the training data. [sent-124, score-0.773]
</p><p>32 The higher-order potential ψcH (xc, V ) for video V captures the cost of assigning a label xc to all the supervoxels inside clique c, and can be used to measure the consistency of the labels of all supervoxels inside c. [sent-127, score-1.274]
</p><p>33 Therefore, energy minimization is usually done using approximate inference methods such as graph cuts, belief propagation, and their extensions to higher-order potentials. [sent-133, score-0.315]
</p><p>34 For instance, in the case of a video with around 100 frames, each one having a resolution of 960 720 pixe10ls0, t fhrea mneusm,eb aerc ho fo supervoxels rceosoullud easily 9b6e on t 7he2 0o prdixe-r 100, 000. [sent-135, score-0.556]
</p><p>35 Our approach exploits the fact that labels are coherent both in space and in time, hence we expect many large, contiguous patches of supervoxels to have the same category label. [sent-139, score-0.546]
</p><p>36 Supervoxel hierarchy The first step in our approach is the construction of a hierarchical supervoxel tree [13, 18]. [sent-142, score-0.884]
</p><p>37 , level m) contains the biggest supervoxels and the finest level (i. [sent-145, score-0.825]
</p><p>38 A supervoxel at site iand level j is denoted by vij and its label by xij . [sent-148, score-0.889]
</p><p>39 The set of all supervoxels at level j is denoted by Vj and its labeling by xj . [sent-149, score-0.605]
</p><p>40 The refinement of a supervoxel bviyj (j ≥ 2) is the set of supervoxels at the next finer level (j −(1j) t≥hat 2 occupy tsheet same pseertv oofx veolsxe atls hine et nhee xvtid feinoe as evvije . [sent-150, score-1.286]
</p><p>41 For k < j, we also let R(i, j,ka)s ⊂ (Vi,kj ,dje n−ot 1e) t h⊂e Vset of supervoxels wobeta ailnsoed l by refining )vij ⊂ f oVr j k times. [sent-152, score-0.492]
</p><p>42 The reverse function Parent : Vj → Vjf+o1r maps a supervoxel rtoe vietsr parent supervoxel att :th Ve n→ext coarser level. [sent-153, score-1.357]
</p><p>43 In this paper, we will only consider hierarchical supervoxel trees, and hence each supervoxel has a unique parent. [sent-154, score-1.382]
</p><p>44 The supervoxel hierarchy can be obtained by running any of the existing hierarchical video segmentation algorithms, such as those in [18, 3 1]. [sent-155, score-0.96]
</p><p>45 By varying this parameter, we can get the desired supervoxel hierarchy. [sent-157, score-0.659]
</p><p>46 Coarse-to-fine inference scheme Given a hierarchical supervoxel tree, we propose a coarse-to-fine algorithm for efficient inference. [sent-160, score-0.849]
</p><p>47 The likely scenario is when all the (contiguous) supervoxels at level j − 1 that constitute a supervoxel at level j get the same jla −bel 1 1fr thomat t choen ssetitt Lute. [sent-162, score-1.301]
</p><p>48 T ah esu unlikely lsc aetn laervieol i js gwehten th a supervoxel afrto lmeve thl j sheats L c. [sent-163, score-0.659]
</p><p>49 To represent the latter scenario, we introduce a new label L + 1, to denote the case where a supervoxel vij (j ≥ 2) has constituents with more than one label. [sent-165, score-0.819]
</p><p>50 Of course, only supervoxels that can be further refined can have the mixed label, i. [sent-167, score-0.605]
</p><p>51 We start by finding a labeling for the coarsest supervoxels in Vm from the augmented label sthete L coAa. [sent-177, score-0.687]
</p><p>52 r Tehstis s labeling liss fi nou Vnd by minimizing EVm (x, V ) using some inference algorithm A, which can be graph cuts,  =  ubesilinegf propagation or some hlimne Aar, program, depending on the form ofthe energy function being optimized. [sent-178, score-0.342]
</p><p>53 All current supervoxels (in Vm) that receive a label L + 1are replaced sinu ptherev ocuxerrlesn (ti optimization problem (at level m) by their constituent supervoxels from the next finer level (m − 1). [sent-179, score-1.272]
</p><p>54 cTohniss iretufiennetm seunpte risv always possible, sxitn cfine a supervoxel can only receive the mixed label if it can be further refined. [sent-180, score-0.833]
</p><p>55 For example, we can have a pair of neighboring supervoxels vi1j1 and vi2j2 with j1 j2. [sent-184, score-0.492]
</p><p>56 As before, we can obtain a labeling for the supervoxels in Vcurr by minimizing tEaiVncu arr l (abx,e V ) using algorithm xAel. [sent-188, score-0.563]
</p><p>57 W ine V can then refine a supervoxel v,jiV th )a uts riengcei avlgeso rthiteh mmi Axe. [sent-189, score-0.659]
</p><p>58 d W Wlaebe cla Ln t+h e1n by replacing it by its constituent supervoxels in R(i, j,j −1). [sent-190, score-0.548]
</p><p>59 We repeat itht ibsy process iteratively, eurnvtoilx aell s supervoxels receive pure elaa-t bels. [sent-191, score-0.552]
</p><p>60 Since every supervoxel eventually refines to its finest constituents, which in turn can only take pure labels, this process is guaranteed to terminate. [sent-192, score-0.908]
</p><p>61 Also, at any point in the algorithm, there exists exactly one ancestor of every finest level supervoxel vi1 in the current set of supervoxels. [sent-193, score-0.931]
</p><p>62 Exactness of the coarse-to-fine solution To make our coarse-to-fine inference scheme converge to the same labeling as that obtained by running A on the finest tlehevesla omftehlea supervoxel hierarchy (e. [sent-197, score-1.159]
</p><p>63 , a fnlaint graph ctuhtes algorithm), the potentials of the energy at a coarse level, EVcurr , need to be chosen in a specific manner. [sent-199, score-0.264]
</p><p>64 Since our goal is to minimize the energy function E, the admissible heuristics for the unary, pairwise and higher-order potentials of EVcurr need to be chosen as lower bounds for the values of the corresponding potentials of E. [sent-201, score-0.426]
</p><p>65 Specifically, let x denote any label assignment for the finest level supervoxels and let x∗  denote the optimal labeling. [sent-202, score-0.823]
</p><p>66 These inequalities ensure that when we terminate upon finding a pure labeling for the current set of supervoxels (at various levels), all other possible assignments have a higher or equal cost (since their lower bound cost is worse than the current optimal cost of the pure labeling). [sent-205, score-0.804]
</p><p>67 3, in order for Algorithm 1 to converge to the same solution as that obtained by running A on the finest level, the potentials associated with 11886688  the nodes at the coarse levels should be lower-bounds on the cost associated with the patches of fine nodes constituting these coarse nodes. [sent-215, score-0.585]
</p><p>68 For the sake of simplicity, we discuss the construction of the lower bounds for an energy function consisting of unary and pairwise terms only. [sent-217, score-0.262]
</p><p>69 We define the unary cost ψ(Ui,j) (xij) of assigning a pure label l ∈ L to a coarse supervoxel vij at level j as the sum ofthe unary costs of assigning label lto all the nodes at level 1that constitute vij, i. [sent-220, score-1.416]
</p><p>70 We define the unary cost of assigning a mixed label to a coarse supervoxel as the minimum cost associated with the RF defined by the constituent supervoxels at level 1subject to the constraint that all the constituent supervoxels cannot get the same label. [sent-228, score-2.234]
</p><p>71 We define the pairwise potential of coarse supervoxels vji11 and vji22, ψ(Pi1,j1)(i2,j2)(xij11,xij22), as  ? [sent-234, score-0.609]
</p><p>72 Therefore, the cost Eo f: tihe ∈ edge betw,e1)en,j jtw ∈o coarse supervoxels vji11 aen,d th vji22 oiss tth oef sum of the costs of the edges connecting the constituent supervoxels of and at level 1. [sent-237, score-1.258]
</p><p>73 In the case where one of the supervoxels gets the mixed label, the potential associated to the edge is set to zero. [sent-238, score-0.604]
</p><p>74 Practical considerations As discussed earlier, in general it is very hard to know if the proposed scheme is more efficient that direct inference over the finest layer. [sent-242, score-0.337]
</p><p>75 Consider two scenarios: all the lower bounds on potentials  in scenario 1 are tighter than the corresponding bounds in scenario 2, for the same supervoxel hierarchy. [sent-245, score-0.951]
</p><p>76 In most cases, only a small number of nodes in the supervoxel tree are used in the entire inference procedure. [sent-252, score-0.84]
</p><p>77 Thus, we can save computation time by not computing the entire supervoxel tree upfront, and only refining the supervoxels with the mixed label when needed. [sent-253, score-1.353]
</p><p>78 This on-demand refinement scheme, however, can be more expensive if we end up expanding most of the nodes in the supervoxel tree. [sent-254, score-0.749]
</p><p>79 Such a hierarchical scheme would have a mixed label at every label level. [sent-260, score-0.315]
</p><p>80 For more details on how to manage a label hierarchy simulta-  neously with a supervoxel hierarchy, we refer the reader to [8], where such a scenario is considered. [sent-261, score-0.857]
</p><p>81 Moreover, since our goal is to find an optimal labeling for the finest layer of the hierarchy only, the experiments are not designed to find the optimal labeling at every layer of the hierarchy. [sent-265, score-0.426]
</p><p>82 We simply use the more abstract layers and the associated lower bound costs to find the optimal labeling at the finest layer. [sent-266, score-0.326]
</p><p>83 While the proposed coarse-to-fine scheme can be exponentially faster than flat optimization in the best case, it can also be much slower when all the supervoxels need to be refined down to their finest level. [sent-267, score-0.843]
</p><p>84 The unary potential ψiU(x, V ) is defined as the cost of assigning a class label x to supervoxel vi. [sent-291, score-0.888]
</p><p>85 This cost is obtained as the score of an SVM classifier applied to the descriptor di of supervoxel vi. [sent-292, score-0.707]
</p><p>86 This classifier is trained on the supervoxel descriptors for each class. [sent-293, score-0.659]
</p><p>87 The supervoxel descriptor needs to be chosen such that it captures the discriminative characteristics of the supervoxels (both appearance and motion attributes) across various classes. [sent-295, score-1.151]
</p><p>88 For our experiments, we used 5 levels (including the coarsest and finest levels). [sent-301, score-0.322]
</p><p>89 The number of supervoxels at the two extreme levels and time taken in minutes (using the on-demand generation scheme) is detailed in Table 2. [sent-302, score-0.519]
</p><p>90 = xj),  (4)  where lij is the area of the common boundary between the supervoxels vi and vj and Ii denotes the average intensity of supervoxel vi. [sent-305, score-1.209]
</p><p>91 We used the LIBSVX [2] library’s implementation of a graph-based hierarchical method [18] to generate the supervoxel trees. [sent-310, score-0.723]
</p><p>92 Notice that these speedups do not account for the supervoxel tree creation time, which is only required by our algorithm. [sent-317, score-0.737]
</p><p>93 Thus, our approach provides significant speed up, even including the time to construct the supervoxel tree. [sent-320, score-0.659]
</p><p>94 Besides computation time, it is also informative to look at the explored portions of the supervoxel tree to get a better understanding of where the computational savings come from. [sent-325, score-0.737]
</p><p>95 The blacked out superpixels at each level are the ones which never received the mixed label and hence were never refined. [sent-329, score-0.288]
</p><p>96 We do not show any segmentation results in the paper since the quality of the segmentation is the same as what would be obtained by using α-expansion or belief propagation with the chosen energy function. [sent-332, score-0.352]
</p><p>97 3e79as  do not include supervoxel tree computation time. [sent-348, score-0.709]
</p><p>98 A flat problem formulation works with the latter large set, while we use an abstraction scheme (namely supervoxel trees) to identify the former smaller set and work on the smaller problem. [sent-361, score-0.841]
</p><p>99 Percentage of correctly classified supervoxels after every iteration of the coarse-to-fine belief propagation algorithm. [sent-363, score-0.636]
</p><p>100 It is also exact since it uses admissible heuristic costs for the coarser supervoxel potentials. [sent-365, score-0.827]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('supervoxel', 0.659), ('supervoxels', 0.492), ('finest', 0.211), ('suny', 0.127), ('hierarchy', 0.111), ('speedup', 0.107), ('mixed', 0.093), ('camvid', 0.093), ('abstraction', 0.091), ('inference', 0.086), ('coarsest', 0.084), ('energy', 0.084), ('belief', 0.081), ('potentials', 0.075), ('evcurr', 0.075), ('vcurr', 0.075), ('vij', 0.071), ('unary', 0.07), ('coarse', 0.067), ('video', 0.064), ('hierarchical', 0.064), ('propagation', 0.063), ('admissible', 0.063), ('segmentation', 0.062), ('level', 0.061), ('label', 0.059), ('constituent', 0.056), ('bounds', 0.056), ('labeling', 0.052), ('flat', 0.051), ('tree', 0.05), ('cost', 0.048), ('rf', 0.047), ('refinement', 0.045), ('nodes', 0.045), ('superpixels', 0.045), ('xvcurr', 0.045), ('costs', 0.042), ('cuts', 0.042), ('labelings', 0.041), ('scheme', 0.04), ('spikes', 0.04), ('xij', 0.039), ('coarser', 0.039), ('videos', 0.039), ('pure', 0.038), ('graph', 0.038), ('xc', 0.037), ('vj', 0.036), ('assigning', 0.033), ('continuity', 0.031), ('pairwise', 0.031), ('labels', 0.03), ('blacked', 0.03), ('constituents', 0.03), ('evm', 0.03), ('ipj', 0.03), ('conference', 0.029), ('finer', 0.029), ('exponentially', 0.029), ('tighter', 0.028), ('speedups', 0.028), ('portions', 0.028), ('scenario', 0.028), ('levels', 0.027), ('exactness', 0.026), ('xcf', 0.026), ('minimization', 0.026), ('cliques', 0.025), ('chatterjee', 0.024), ('pylon', 0.024), ('python', 0.024), ('exact', 0.024), ('temporally', 0.024), ('contiguous', 0.024), ('bottomup', 0.023), ('integer', 0.023), ('semantic', 0.023), ('receive', 0.022), ('vi', 0.022), ('iu', 0.022), ('heuristics', 0.021), ('lower', 0.021), ('segmentations', 0.021), ('refinements', 0.021), ('ieee', 0.021), ('ice', 0.02), ('eed', 0.02), ('refined', 0.02), ('higherorder', 0.019), ('viterbi', 0.019), ('minimizing', 0.019), ('potential', 0.019), ('assignments', 0.019), ('vm', 0.019), ('strategy', 0.018), ('termination', 0.018), ('superpixel', 0.018), ('frames', 0.018), ('ladicky', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999899 <a title="76-tfidf-1" href="./iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees.html">76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</a></p>
<p>Author: Aastha Jain, Shuanak Chatterjee, René Vidal</p><p>Abstract: We propose an exact, general and efficient coarse-to-fine energy minimization strategy for semantic video segmentation. Our strategy is based on a hierarchical abstraction of the supervoxel graph that allows us to minimize an energy defined at the finest level of the hierarchy by minimizing a series of simpler energies defined over coarser graphs. The strategy is exact, i.e., it produces the same solution as minimizing over the finest graph. It is general, i.e., it can be used to minimize any energy function (e.g., unary, pairwise, and higher-order terms) with any existing energy minimization algorithm (e.g., graph cuts and belief propagation). It also gives significant speedups in inference for several datasets with varying degrees of spatio-temporal continuity. We also discuss the strengths and weaknesses of our strategy relative to existing hierarchical approaches, and the kinds of image and video data that provide the best speedups.</p><p>2 0.56362724 <a title="76-tfidf-2" href="./iccv-2013-Flattening_Supervoxel_Hierarchies_by_the_Uniform_Entropy_Slice.html">172 iccv-2013-Flattening Supervoxel Hierarchies by the Uniform Entropy Slice</a></p>
<p>Author: Chenliang Xu, Spencer Whitt, Jason J. Corso</p><p>Abstract: Supervoxel hierarchies provide a rich multiscale decomposition of a given video suitable for subsequent processing in video analysis. The hierarchies are typically computed by an unsupervised process that is susceptible to undersegmentation at coarse levels and over-segmentation at fine levels, which make it a challenge to adopt the hierarchies for later use. In this paper, we propose the first method to overcome this limitation and flatten the hierarchy into a single segmentation. Our method, called the uniform entropy slice, seeks a selection of supervoxels that balances the relative level of information in the selected supervoxels based on some post hoc feature criterion such as objectness. For example, with this criterion, in regions nearby objects, our method prefers finer supervoxels to capture the local details, but in regions away from any objects we prefer coarser supervoxels. We formulate the uniform entropy slice as a binary quadratic program and implement four different feature criteria, both unsupervised and supervised, to drive the flattening. Although we apply it only to supervoxel hierarchies in this paper, our method is generally applicable to segmentation tree hierarchies. Our experiments demonstrate both strong qualitative performance and superior quantitative performance to state of the art baselines on benchmark internet videos.</p><p>3 0.32415453 <a title="76-tfidf-3" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>Author: Matthias Reso, Jörn Jachalsky, Bodo Rosenhahn, Jörn Ostermann</p><p>Abstract: Superpixel algorithms represent a very useful and increasingly popular preprocessing step for a wide range of computer vision applications, as they offer the potential to boost efficiency and effectiveness. In this regards, this paper presents a highly competitive approach for temporally consistent superpixelsfor video content. The approach is based on energy-minimizing clustering utilizing a novel hybrid clustering strategy for a multi-dimensional feature space working in a global color subspace and local spatial subspaces. Moreover, a new contour evolution based strategy is introduced to ensure spatial coherency of the generated superpixels. For a thorough evaluation the proposed approach is compared to state of the art supervoxel algorithms using established benchmarks and shows a superior performance.</p><p>4 0.14323251 <a title="76-tfidf-4" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<p>Author: Fabio Galasso, Naveen Shankar Nagaraja, Tatiana Jiménez Cárdenas, Thomas Brox, Bernt Schiele</p><p>Abstract: Video segmentation research is currently limited by the lack of a benchmark dataset that covers the large variety of subproblems appearing in video segmentation and that is large enough to avoid overfitting. Consequently, there is little analysis of video segmentation which generalizes across subtasks, and it is not yet clear which and how video segmentation should leverage the information from the still-frames, as previously studied in image segmentation, alongside video specific information, such as temporal volume, motion and occlusion. In this work we provide such an analysis based on annotations of a large video dataset, where each video is manually segmented by multiple persons. Moreover, we introduce a new volume-based metric that includes the important aspect of temporal consistency, that can deal with segmentation hierarchies, and that reflects the tradeoff between over-segmentation and segmentation accuracy.</p><p>5 0.11276389 <a title="76-tfidf-5" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>Author: Gemma Roig, Xavier Boix, Roderick De_Nijs, Sebastian Ramos, Koljia Kuhnlenz, Luc Van_Gool</p><p>Abstract: Most MAP inference algorithms for CRFs optimize an energy function knowing all the potentials. In this paper, we focus on CRFs where the computational cost of instantiating the potentials is orders of magnitude higher than MAP inference. This is often the case in semantic image segmentation, where most potentials are instantiated by slow classifiers fed with costly features. We introduce Active MAP inference 1) to on-the-fly select a subset of potentials to be instantiated in the energy function, leaving the rest of the parameters of the potentials unknown, and 2) to estimate the MAP labeling from such incomplete energy function. Results for semantic segmentation benchmarks, namely PASCAL VOC 2010 [5] and MSRC-21 [19], show that Active MAP inference achieves similar levels of accuracy but with major efficiency gains.</p><p>6 0.082487449 <a title="76-tfidf-6" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>7 0.082113408 <a title="76-tfidf-7" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>8 0.079371221 <a title="76-tfidf-8" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>9 0.077713311 <a title="76-tfidf-9" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>10 0.077436052 <a title="76-tfidf-10" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>11 0.073541693 <a title="76-tfidf-11" href="./iccv-2013-Online_Video_SEEDS_for_Temporal_Window_Objectness.html">299 iccv-2013-Online Video SEEDS for Temporal Window Objectness</a></p>
<p>12 0.073142901 <a title="76-tfidf-12" href="./iccv-2013-Estimating_the_3D_Layout_of_Indoor_Scenes_and_Its_Clutter_from_Depth_Sensors.html">144 iccv-2013-Estimating the 3D Layout of Indoor Scenes and Its Clutter from Depth Sensors</a></p>
<p>13 0.069415972 <a title="76-tfidf-13" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>14 0.068008624 <a title="76-tfidf-14" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>15 0.067125887 <a title="76-tfidf-15" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>16 0.065315217 <a title="76-tfidf-16" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>17 0.063742042 <a title="76-tfidf-17" href="./iccv-2013-Volumetric_Semantic_Segmentation_Using_Pyramid_Context_Features.html">447 iccv-2013-Volumetric Semantic Segmentation Using Pyramid Context Features</a></p>
<p>18 0.061164733 <a title="76-tfidf-18" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>19 0.058222748 <a title="76-tfidf-19" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>20 0.058152612 <a title="76-tfidf-20" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.144), (1, -0.016), (2, 0.03), (3, 0.027), (4, 0.055), (5, 0.068), (6, -0.099), (7, 0.079), (8, 0.04), (9, -0.134), (10, -0.047), (11, 0.105), (12, 0.04), (13, 0.077), (14, -0.026), (15, 0.074), (16, -0.097), (17, -0.11), (18, -0.126), (19, -0.012), (20, 0.022), (21, -0.13), (22, -0.049), (23, 0.006), (24, -0.181), (25, -0.139), (26, -0.013), (27, -0.025), (28, -0.082), (29, -0.003), (30, 0.145), (31, -0.12), (32, -0.101), (33, -0.065), (34, 0.208), (35, -0.263), (36, 0.155), (37, -0.135), (38, -0.016), (39, 0.117), (40, -0.006), (41, -0.152), (42, -0.012), (43, -0.171), (44, 0.077), (45, 0.107), (46, -0.134), (47, 0.011), (48, -0.155), (49, 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92057037 <a title="76-lsi-1" href="./iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees.html">76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</a></p>
<p>Author: Aastha Jain, Shuanak Chatterjee, René Vidal</p><p>Abstract: We propose an exact, general and efficient coarse-to-fine energy minimization strategy for semantic video segmentation. Our strategy is based on a hierarchical abstraction of the supervoxel graph that allows us to minimize an energy defined at the finest level of the hierarchy by minimizing a series of simpler energies defined over coarser graphs. The strategy is exact, i.e., it produces the same solution as minimizing over the finest graph. It is general, i.e., it can be used to minimize any energy function (e.g., unary, pairwise, and higher-order terms) with any existing energy minimization algorithm (e.g., graph cuts and belief propagation). It also gives significant speedups in inference for several datasets with varying degrees of spatio-temporal continuity. We also discuss the strengths and weaknesses of our strategy relative to existing hierarchical approaches, and the kinds of image and video data that provide the best speedups.</p><p>2 0.8742435 <a title="76-lsi-2" href="./iccv-2013-Flattening_Supervoxel_Hierarchies_by_the_Uniform_Entropy_Slice.html">172 iccv-2013-Flattening Supervoxel Hierarchies by the Uniform Entropy Slice</a></p>
<p>Author: Chenliang Xu, Spencer Whitt, Jason J. Corso</p><p>Abstract: Supervoxel hierarchies provide a rich multiscale decomposition of a given video suitable for subsequent processing in video analysis. The hierarchies are typically computed by an unsupervised process that is susceptible to undersegmentation at coarse levels and over-segmentation at fine levels, which make it a challenge to adopt the hierarchies for later use. In this paper, we propose the first method to overcome this limitation and flatten the hierarchy into a single segmentation. Our method, called the uniform entropy slice, seeks a selection of supervoxels that balances the relative level of information in the selected supervoxels based on some post hoc feature criterion such as objectness. For example, with this criterion, in regions nearby objects, our method prefers finer supervoxels to capture the local details, but in regions away from any objects we prefer coarser supervoxels. We formulate the uniform entropy slice as a binary quadratic program and implement four different feature criteria, both unsupervised and supervised, to drive the flattening. Although we apply it only to supervoxel hierarchies in this paper, our method is generally applicable to segmentation tree hierarchies. Our experiments demonstrate both strong qualitative performance and superior quantitative performance to state of the art baselines on benchmark internet videos.</p><p>3 0.64673012 <a title="76-lsi-3" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>Author: Matthias Reso, Jörn Jachalsky, Bodo Rosenhahn, Jörn Ostermann</p><p>Abstract: Superpixel algorithms represent a very useful and increasingly popular preprocessing step for a wide range of computer vision applications, as they offer the potential to boost efficiency and effectiveness. In this regards, this paper presents a highly competitive approach for temporally consistent superpixelsfor video content. The approach is based on energy-minimizing clustering utilizing a novel hybrid clustering strategy for a multi-dimensional feature space working in a global color subspace and local spatial subspaces. Moreover, a new contour evolution based strategy is introduced to ensure spatial coherency of the generated superpixels. For a thorough evaluation the proposed approach is compared to state of the art supervoxel algorithms using established benchmarks and shows a superior performance.</p><p>4 0.51067102 <a title="76-lsi-4" href="./iccv-2013-Online_Video_SEEDS_for_Temporal_Window_Objectness.html">299 iccv-2013-Online Video SEEDS for Temporal Window Objectness</a></p>
<p>Author: Michael Van_Den_Bergh, Gemma Roig, Xavier Boix, Santiago Manen, Luc Van_Gool</p><p>Abstract: Superpixel and objectness algorithms are broadly used as a pre-processing step to generate support regions and to speed-up further computations. Recently, many algorithms have been extended to video in order to exploit the temporal consistency between frames. However, most methods are computationally too expensive for real-time applications. We introduce an online, real-time video superpixel algorithm based on the recently proposed SEEDS superpixels. A new capability is incorporated which delivers multiple diverse samples (hypotheses) of superpixels in the same image or video sequence. The multiple samples are shown to provide a strong cue to efficiently measure the objectness of image windows, and we introduce the novel concept of objectness in temporal windows. Experiments show that the video superpixels achieve comparable performance to state-of-the-art offline methods while running at 30 fps on a single 2.8 GHz i7 CPU. State-of-the-art performance on objectness is also demonstrated, yet orders of magnitude faster and extended to temporal windows in video.</p><p>5 0.44745857 <a title="76-lsi-5" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<p>Author: Fabio Galasso, Naveen Shankar Nagaraja, Tatiana Jiménez Cárdenas, Thomas Brox, Bernt Schiele</p><p>Abstract: Video segmentation research is currently limited by the lack of a benchmark dataset that covers the large variety of subproblems appearing in video segmentation and that is large enough to avoid overfitting. Consequently, there is little analysis of video segmentation which generalizes across subtasks, and it is not yet clear which and how video segmentation should leverage the information from the still-frames, as previously studied in image segmentation, alongside video specific information, such as temporal volume, motion and occlusion. In this work we provide such an analysis based on annotations of a large video dataset, where each video is manually segmented by multiple persons. Moreover, we introduce a new volume-based metric that includes the important aspect of temporal consistency, that can deal with segmentation hierarchies, and that reflects the tradeoff between over-segmentation and segmentation accuracy.</p><p>6 0.37707877 <a title="76-lsi-6" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>7 0.3603237 <a title="76-lsi-7" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>8 0.34016344 <a title="76-lsi-8" href="./iccv-2013-Volumetric_Semantic_Segmentation_Using_Pyramid_Context_Features.html">447 iccv-2013-Volumetric Semantic Segmentation Using Pyramid Context Features</a></p>
<p>9 0.32044625 <a title="76-lsi-9" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>10 0.31247503 <a title="76-lsi-10" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>11 0.29769695 <a title="76-lsi-11" href="./iccv-2013-Estimating_the_Material_Properties_of_Fabric_from_Video.html">145 iccv-2013-Estimating the Material Properties of Fabric from Video</a></p>
<p>12 0.29752117 <a title="76-lsi-12" href="./iccv-2013-YouTube2Text%3A_Recognizing_and_Describing_Arbitrary_Activities_Using_Semantic_Hierarchies_and_Zero-Shot_Recognition.html">452 iccv-2013-YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition</a></p>
<p>13 0.29326844 <a title="76-lsi-13" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>14 0.29228565 <a title="76-lsi-14" href="./iccv-2013-Progressive_Multigrid_Eigensolvers_for_Multiscale_Spectral_Segmentation.html">329 iccv-2013-Progressive Multigrid Eigensolvers for Multiscale Spectral Segmentation</a></p>
<p>15 0.28929615 <a title="76-lsi-15" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>16 0.2856217 <a title="76-lsi-16" href="./iccv-2013-Monte_Carlo_Tree_Search_for_Scheduling_Activity_Recognition.html">274 iccv-2013-Monte Carlo Tree Search for Scheduling Activity Recognition</a></p>
<p>17 0.28295937 <a title="76-lsi-17" href="./iccv-2013-Detecting_Curved_Symmetric_Parts_Using_a_Deformable_Disc_Model.html">110 iccv-2013-Detecting Curved Symmetric Parts Using a Deformable Disc Model</a></p>
<p>18 0.27368051 <a title="76-lsi-18" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>19 0.26874429 <a title="76-lsi-19" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>20 0.24652548 <a title="76-lsi-20" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.057), (7, 0.012), (12, 0.018), (26, 0.119), (31, 0.054), (35, 0.014), (40, 0.014), (42, 0.08), (48, 0.011), (64, 0.037), (73, 0.022), (86, 0.226), (89, 0.19), (95, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83019984 <a title="76-lda-1" href="./iccv-2013-YouTube2Text%3A_Recognizing_and_Describing_Arbitrary_Activities_Using_Semantic_Hierarchies_and_Zero-Shot_Recognition.html">452 iccv-2013-YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition</a></p>
<p>Author: Sergio Guadarrama, Niveda Krishnamoorthy, Girish Malkarnenkar, Subhashini Venugopalan, Raymond Mooney, Trevor Darrell, Kate Saenko</p><p>Abstract: Despite a recent push towards large-scale object recognition, activity recognition remains limited to narrow domains and small vocabularies of actions. In this paper, we tackle the challenge of recognizing and describing activities “in-the-wild”. We present a solution that takes a short video clip and outputs a brief sentence that sums up the main activity in the video, such as the actor, the action and its object. Unlike previous work, our approach works on out-of-domain actions: it does not require training videos of the exact activity. If it cannot find an accurate prediction for a pre-trained model, it finds a less specific answer that is also plausible from a pragmatic standpoint. We use semantic hierarchies learned from the data to help to choose an appropriate level of generalization, and priors learned from web-scale natural language corpora to penalize unlikely combinations of actors/actions/objects; we also use a web-scale language model to “fill in ” novel verbs, i.e. when the verb does not appear in the training set. We evaluate our method on a large YouTube corpus and demonstrate it is able to generate short sentence descriptions of video clips better than baseline approaches.</p><p>same-paper 2 0.82835478 <a title="76-lda-2" href="./iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees.html">76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</a></p>
<p>Author: Aastha Jain, Shuanak Chatterjee, René Vidal</p><p>Abstract: We propose an exact, general and efficient coarse-to-fine energy minimization strategy for semantic video segmentation. Our strategy is based on a hierarchical abstraction of the supervoxel graph that allows us to minimize an energy defined at the finest level of the hierarchy by minimizing a series of simpler energies defined over coarser graphs. The strategy is exact, i.e., it produces the same solution as minimizing over the finest graph. It is general, i.e., it can be used to minimize any energy function (e.g., unary, pairwise, and higher-order terms) with any existing energy minimization algorithm (e.g., graph cuts and belief propagation). It also gives significant speedups in inference for several datasets with varying degrees of spatio-temporal continuity. We also discuss the strengths and weaknesses of our strategy relative to existing hierarchical approaches, and the kinds of image and video data that provide the best speedups.</p><p>3 0.74666828 <a title="76-lda-3" href="./iccv-2013-Flattening_Supervoxel_Hierarchies_by_the_Uniform_Entropy_Slice.html">172 iccv-2013-Flattening Supervoxel Hierarchies by the Uniform Entropy Slice</a></p>
<p>Author: Chenliang Xu, Spencer Whitt, Jason J. Corso</p><p>Abstract: Supervoxel hierarchies provide a rich multiscale decomposition of a given video suitable for subsequent processing in video analysis. The hierarchies are typically computed by an unsupervised process that is susceptible to undersegmentation at coarse levels and over-segmentation at fine levels, which make it a challenge to adopt the hierarchies for later use. In this paper, we propose the first method to overcome this limitation and flatten the hierarchy into a single segmentation. Our method, called the uniform entropy slice, seeks a selection of supervoxels that balances the relative level of information in the selected supervoxels based on some post hoc feature criterion such as objectness. For example, with this criterion, in regions nearby objects, our method prefers finer supervoxels to capture the local details, but in regions away from any objects we prefer coarser supervoxels. We formulate the uniform entropy slice as a binary quadratic program and implement four different feature criteria, both unsupervised and supervised, to drive the flattening. Although we apply it only to supervoxel hierarchies in this paper, our method is generally applicable to segmentation tree hierarchies. Our experiments demonstrate both strong qualitative performance and superior quantitative performance to state of the art baselines on benchmark internet videos.</p><p>4 0.73262429 <a title="76-lda-4" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>Author: Chih-Yuan Yang, Ming-Hsuan Yang</p><p>Abstract: The goal of single-image super-resolution is to generate a high-quality high-resolution image based on a given low-resolution input. It is an ill-posed problem which requires exemplars or priors to better reconstruct the missing high-resolution image details. In this paper, we propose to split the feature space into numerous subspaces and collect exemplars to learn priors for each subspace, thereby creating effective mapping functions. The use of split input space facilitates both feasibility of using simple functionsfor super-resolution, and efficiency ofgenerating highresolution results. High-quality high-resolution images are reconstructed based on the effective learned priors. Experimental results demonstrate that theproposed algorithmperforms efficiently and effectively over state-of-the-art methods.</p><p>5 0.73203772 <a title="76-lda-5" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>Author: Matthias Reso, Jörn Jachalsky, Bodo Rosenhahn, Jörn Ostermann</p><p>Abstract: Superpixel algorithms represent a very useful and increasingly popular preprocessing step for a wide range of computer vision applications, as they offer the potential to boost efficiency and effectiveness. In this regards, this paper presents a highly competitive approach for temporally consistent superpixelsfor video content. The approach is based on energy-minimizing clustering utilizing a novel hybrid clustering strategy for a multi-dimensional feature space working in a global color subspace and local spatial subspaces. Moreover, a new contour evolution based strategy is introduced to ensure spatial coherency of the generated superpixels. For a thorough evaluation the proposed approach is compared to state of the art supervoxel algorithms using established benchmarks and shows a superior performance.</p><p>6 0.73161519 <a title="76-lda-6" href="./iccv-2013-Data-Driven_3D_Primitives_for_Single_Image_Understanding.html">102 iccv-2013-Data-Driven 3D Primitives for Single Image Understanding</a></p>
<p>7 0.73062527 <a title="76-lda-7" href="./iccv-2013-A_Deformable_Mixture_Parsing_Model_with_Parselets.html">8 iccv-2013-A Deformable Mixture Parsing Model with Parselets</a></p>
<p>8 0.73033023 <a title="76-lda-8" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>9 0.7286098 <a title="76-lda-9" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>10 0.72660649 <a title="76-lda-10" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>11 0.72544068 <a title="76-lda-11" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>12 0.72530693 <a title="76-lda-12" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>13 0.72520792 <a title="76-lda-13" href="./iccv-2013-A_Joint_Intensity_and_Depth_Co-sparse_Analysis_Model_for_Depth_Map_Super-resolution.html">18 iccv-2013-A Joint Intensity and Depth Co-sparse Analysis Model for Depth Map Super-resolution</a></p>
<p>14 0.72482646 <a title="76-lda-14" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>15 0.72456586 <a title="76-lda-15" href="./iccv-2013-Robust_Trajectory_Clustering_for_Motion_Segmentation.html">361 iccv-2013-Robust Trajectory Clustering for Motion Segmentation</a></p>
<p>16 0.72448993 <a title="76-lda-16" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>17 0.72373283 <a title="76-lda-17" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>18 0.72271442 <a title="76-lda-18" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>19 0.7225281 <a title="76-lda-19" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>20 0.72216195 <a title="76-lda-20" href="./iccv-2013-Image_Guided_Depth_Upsampling_Using_Anisotropic_Total_Generalized_Variation.html">209 iccv-2013-Image Guided Depth Upsampling Using Anisotropic Total Generalized Variation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
