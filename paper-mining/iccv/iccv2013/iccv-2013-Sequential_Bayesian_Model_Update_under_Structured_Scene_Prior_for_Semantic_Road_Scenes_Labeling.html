<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-386" href="#">iccv2013-386</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</h1>
<br/><p>Source: <a title="iccv-2013-386-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Levinkov_Sequential_Bayesian_Model_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Evgeny Levinkov, Mario Fritz</p><p>Abstract: Semantic road labeling is a key component of systems that aim at assisted or even autonomous driving. Considering that such systems continuously operate in the realworld, unforeseen conditions not represented in any conceivable training procedure are likely to occur on a regular basis. In order to equip systems with the ability to cope with such situations, we would like to enable adaptation to such new situations and conditions at runtime. Existing adaptive methods for image labeling either require labeled data from the new condition or even operate globally on a complete test set. None of this is a desirable mode of operation for a system as described above where new images arrive sequentially and conditions may vary. We study the effect of changing test conditions on scene labeling methods based on a new diverse street scene dataset. We propose a novel approach that can operate in such conditions and is based on a sequential Bayesian model update in order to robustly integrate the arriving images into the adapting procedure.</p><p>Reference: <a title="iccv-2013-386-reference" href="../iccv2013_reference/iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract Semantic road labeling is a key component of systems that aim at assisted or even autonomous driving. [sent-3, score-0.58]
</p><p>2 Considering that such systems continuously operate in the realworld, unforeseen conditions not represented in any conceivable training procedure are likely to occur on a regular basis. [sent-4, score-0.374]
</p><p>3 In order to equip systems with the ability to cope with such situations, we would like to enable adaptation to such new situations and conditions at runtime. [sent-5, score-0.505]
</p><p>4 Existing adaptive methods for image labeling either require labeled data from the new condition or even operate globally on a complete test set. [sent-6, score-0.539]
</p><p>5 We study the effect of changing test conditions on scene labeling methods based on a new diverse street scene dataset. [sent-8, score-0.702]
</p><p>6 We propose a novel approach that can operate in such conditions and is based on a sequential Bayesian model update in order to robustly integrate the arriving images into the adapting procedure. [sent-9, score-0.512]
</p><p>7 Introduction Driving assistance systems have been rapidly evolving lately due to a constantly increasing interest in real-world application as well as studies conducted in the field of computer vision. [sent-11, score-0.217]
</p><p>8 An important task of such systems is road scene labeling in order to derive the semantic structure of the observed scenes. [sent-12, score-0.752]
</p><p>9 Recently, there has been an increased interest in approaches of domain adaptation [11, 9] in computer vision that are able to adapt existing classifiers to new domains and conditions. [sent-15, score-0.228]
</p><p>10 Figure 1: Given an initial model, trained on existing data with groundtruth labels, our algorithm simultaneously labels images as they arrive and updates the model in a robust manner. [sent-44, score-0.184]
</p><p>11 domain, that can not be provided by the envisioned systems that continuously operate in the real-world. [sent-45, score-0.195]
</p><p>12 Existing adaptive methods [1] allow the use of machine generated labels in order to refine the classifier and help it to adapt to changing conditions. [sent-46, score-0.325]
</p><p>13 In contrast, we aim at an adaptive algorithm that is able to perform adaptation on the fly. [sent-49, score-0.271]
</p><p>14 Therefore, this paper proposes a sequential bayesian update strategy that pursues multiple model hypothesis for semantic scene labeling. [sent-50, score-0.793]
</p><p>15 The main contributions of this paper are: (1) We present a new dataset of diverse road scenes that allows us to study the effect of drastic changes between training and test feature statistic for semantic scene labeling. [sent-53, score-0.805]
</p><p>16 (2) We evaluate state-of-the-art scene labeling techniques to provide an initial benchmark on this new challenge set. [sent-54, score-0.358]
</p><p>17 (3) We propose a novel method for sequential model update in a continuous  1321  learning and prediction setting. [sent-55, score-0.363]
</p><p>18 It is based on a Bayesian update under structured scene prior. [sent-56, score-0.319]
</p><p>19 Related Work Road scenes labeling has been studied for a long time and is predominantly addressed as a labeling problem modeled by Conditional Random Fields (CRFs) [10]. [sent-59, score-0.509]
</p><p>20 Domain adaptation techniques [11, 9] can help to solve this problem, but they require at least some sample instances with ground truth labels from the target domain. [sent-66, score-0.196]
</p><p>21 In contrast, we are aiming for an algorithm which is able to perform adaptation without any possible access to ground truth labels at test-time. [sent-67, score-0.273]
</p><p>22 [1] considered the setting of using machine  generated labels at test time for street scene segmentation, but their approach requires access to the whole test set and the quality heavily depends on acceptance threshold parameter. [sent-69, score-0.622]
</p><p>23 In contrast, our method is targeted at dealing with a stream of incoming images, pursues multiple model hypothesis simultaneously and proposes a more principled way of dealing with the acceptance threshold of new samples for the model update. [sent-72, score-0.47]
</p><p>24 Sequential Model Update for Semantic Image Labeling As we aim for vision systems that continuously operate in the real-world, unforeseen conditions not represented in the training set are likely to occur. [sent-74, score-0.374]
</p><p>25 In order to equip systems with the ability to cope with such situations, we would like to enable adaptation to such new situations and conditions. [sent-75, score-0.439]
</p><p>26 There is a large body of work on adaptive learning method which allow the update ofmodels at test time. [sent-76, score-0.375]
</p><p>27 In such settings, the availability of the full test set is assumed, which is not practical for any continuously operating system. [sent-79, score-0.181]
</p><p>28 Therefore we investigate ways how to achieve a sequential model update based on lately arrived, unlabeled data. [sent-80, score-0.508]
</p><p>29 They are troubled with effects of “model drift”, which denote effects that occur when erroneous predictions on the test data are used to update the model. [sent-82, score-0.248]
</p><p>30 First, a lately arrived batch of images is labeled using the current model. [sent-88, score-0.174]
</p><p>31 In more detail, we get an output probability distribution P(x(i,j) ) from our classifier for each pixel (i, j) and the predicted class-label for it  c∗ = argc∈mYaxP(x(i,j) = c). [sent-90, score-0.208]
</p><p>32 (1)  Then, as in such setting there is no way of checking whether the given labeling is correct or not, we take features of only  those pixels, for which the following holds P(x(i,j) = c∗) > λ,  (2)  where λ is a acceptance threshold parameter. [sent-91, score-0.487]
</p><p>33 [1] who employ a pixel-wise, normalized classhistogram on the off-line data as a prior distribution to weight the output probability distribution of the classifier at testing time. [sent-104, score-0.241]
</p><p>34 Sequential Bayesian Model Update Structured Scene Prior  under  We propose a new model to leverage unlabeled data for a sequential model update for scene labeling. [sent-128, score-0.611]
</p><p>35 Consequently, scene labeling at test time will be performed by marginalization over the model distribution  p(X|Lt) =? [sent-132, score-0.502]
</p><p>36 p(X|ht)p(ht|Lt)dht,  (5)  where X is the labeling of a test image for which we want to do prediction. [sent-133, score-0.293]
</p><p>37 Pp(ir,j)  Bayesian Model Update We are interested in modeling an evolving target distribution over models in order to account for the uncertainty in the unobserved scene labels. [sent-136, score-0.304]
</p><p>38 Therefore, we model the unobserved scene labels lt of the unlabeled data ut at time step t as a latent variable. [sent-137, score-0.657]
</p><p>39 ht is a set of model hypothesis at time-set t (unobserved), lt is a set of unknown labelings (unobserved), ut denotes the set of unlabeled raw images (image features) at time-step t (observed), and S is a statical parameter, an average labeling over the training set. [sent-140, score-1.164]
</p><p>40 than sticking to a single model hypothesis, we seek to model a distribution over model hypothesis ht. [sent-141, score-0.254]
</p><p>41 Therefore we update a distribution over model hypothesis given labels p(ht|Lt). [sent-142, score-0.418]
</p><p>42 At each time step the model distribution p(ht |Lt) is represented by a set of particles with weights . [sent-153, score-0.257]
</p><p>43 Next, the particles are propagated to the next time step via p(ht |ht−1 , ut) that takes into account the existing models and |thhe unlabeled data. [sent-154, score-0.23]
</p><p>44 In our setting, we propose to do model propagation by randomly choosing a subset of images which are provided to a particular classifier to retrain as well as picking a randomized acceptance threshold λ per particle. [sent-156, score-0.364]
</p><p>45 Second, parameters like the acceptance thresholds are dealt with within the model and no hard choices have to be made. [sent-159, score-0.243]
</p><p>46 Retrain model using ( uˆt, and Lt−1  ˆlt)  Traditional tracking approaches would now follow up with a measurement in order to update the weights Similarly, we update the weight of each sample (model hypothesis) according to (7). [sent-166, score-0.374]
</p><p>47 In this equation p(ht |Lt−1) is the distribution represented by our particles after| Lthe propagation step from above and p(lt |ht−1 , S) is the product of the likelihood of the labeling time|sh the likelihood ofthe labeling given the scene labeling prior. [sent-167, score-0.983]
</p><p>48 We have to  do this in order to get a faithful estimation of performance of each of the retrained particles on the same data, which was not in turn used in the retraining of any of the particles. [sent-171, score-0.194]
</p><p>49 In our implementation we pick the acceptance threshold randomly from the interval 1/3 to 0. [sent-172, score-0.269]
</p><p>50 In fact, Figure 3 shows that already a small number of particles allows to get considerable improvements. [sent-175, score-0.24]
</p><p>51 For the Na¨ ıve adaptive approach we set the acceptance thresholding parameter λ = 0. [sent-177, score-0.307]
</p><p>52 Diverse Road Scenes Dataset In order to study the problem of adaptation we need a dataset, which exhibits considerable amount of appearance variation between the training and test set. [sent-188, score-0.396]
</p><p>53 Typical road scene datasets like [15, 2] (Figure 4, first column) already exhibits some visually difficult situations like changes in  gre (ro,dn tasm)%aAvera21 086420 4681024168 Number of particles  Figure 3: Dependency of average class error on the number of tracking particles. [sent-189, score-0.759]
</p><p>54 R, looking for images depicting roads mostly in conditions which we called “autumn” and “winter” weather conditions that are typically avoided in existing datasets. [sent-194, score-0.351]
</p><p>55 This resulted in a collection of 220 images, about half of –  which represent roads in autumn conditions and another half roads in winter conditions. [sent-197, score-0.712]
</p><p>56 We performed pixel-wise hand labeling ofthe gathered images into three classes: road (blue), sky (red), and background (green). [sent-198, score-0.643]
</p><p>57 Typical challenges include roads covered in autumn leaves or snow as well as different types of roads such as dirt and gravel roads and even images taken at night, although we leave out such issues like bad lighting, low contrast, or rain. [sent-201, score-0.819]
</p><p>58 Experimental Results In our experiments we establish a baseline on our new diverse road scene dataset and compare different non-adaptive techniques for scene segmentation that have different features to increase robustness. [sent-203, score-0.668]
</p><p>59 Then we evaluate our novel sequential Bayesian update scheme and compare it to different baselines and state-of-the-art in adaptive scene segmentation [1]. [sent-204, score-0.605]
</p><p>60 Setup and features In our implementations we employed a Random Forest [3] classifier consisting of 10 trees each having depth of at most 15 with 20% bagging of the training 1324  Figure 4: First column shows examples of road scene dataset from [15]. [sent-205, score-0.537]
</p><p>61 Other columns show examples of the new diverse road  scene  dataset exhibiting  very  different  appearances  and a wider  range  of conditions. [sent-206, score-0.523]
</p><p>62 [8] semantic image labeling algorithm on the old and the new test test. [sent-217, score-0.448]
</p><p>63 This classifier has good accuracy [14], is robust to noisy labels, and its update can be parallelized [13] and be very efficient in terms  or running time [12]. [sent-221, score-0.231]
</p><p>64 Unless stated otherwise, we used the training set from [15] for training (Figure 4, first column) and performed testing or adaptation on the new test set. [sent-222, score-0.354]
</p><p>65 Non-adaptive methods In order to show that nonadaptive methods have a limited capability of generalizing to a different and strongly varying feature distribution as presented in our new dataset, we took one of the state-ofthe-art methods for semantic image labeling of Kr ¨ahenb u¨hl et al. [sent-229, score-0.394]
</p><p>66 [8], and trained it on the training set and tested on both the old and the new test set (Table 1). [sent-230, score-0.213]
</p><p>67 The old test set has a similar appearance as the training set (Figure 4, first column), so the resulting numbers are very strong. [sent-231, score-0.219]
</p><p>68 But when we test on the new test set, the method shows strong accuracy degradations caused by the changed feature distribu-  1325  tion. [sent-232, score-0.188]
</p><p>69 Particularly, the road recognition rate gets more than 50 times worse, because background and sky have more or less similar appearance as in the training set, while appearance of the road usually does not resemble the one in the training set. [sent-233, score-0.932]
</p><p>70 We use Random Forest as an initial classifier in our implementations of adaptive methods. [sent-236, score-0.186]
</p><p>71 Fully connected CRF allows to enhance labeling and make it less noisy by enforcing consistent labels of the neighboring pixels. [sent-237, score-0.3]
</p><p>72 This method allows to get lower errors for road (3%) and sky (around 7%). [sent-238, score-0.467]
</p><p>73 In the presence of a stationary label statistic (as it is in case for road scenes), it allows for a certain degree of compensation for the changing feature distribution by enforcing an expected label structure for the unseen  data. [sent-242, score-0.606]
</p><p>74 In fact, it shows more than 5% improvement for the road class, although decreasing the detection rate of the sky class, so the average error almost doesn’t change. [sent-243, score-0.426]
</p><p>75 Global adaptive methods Global adaptive methods consider the whole test set at once and try to adapt to it. [sent-244, score-0.41]
</p><p>76 In the real world setting, when new images constantly arrive, global algorithms would have to deal with a constantly increasing test set. [sent-246, score-0.226]
</p><p>77 [1] proposed such an globally adaptive scheme for road scene segmentation. [sent-248, score-0.556]
</p><p>78 Their method uses different features and a different training set, but their training set also consists of road scenes representing comparable appearance with our training set. [sent-250, score-0.543]
</p><p>79 The main algorithmic difference is that their method performs adaptation to the whole test set at once, while our Sequential Bayesian Model Update performs sequential updates in a Bayesian formulation allowing real world application, when a fixed “test” set simply does not exist. [sent-251, score-0.47]
</p><p>80 Their method doesn’t perform well on the new dataset, as we think, because it is a global adaptive method and it considers the whole test set at once and suffers from many false positives. [sent-252, score-0.271]
</p><p>81 This gives insight to the weaknesses of global adaptive methods in contrast to our sequential method, which updates on small batches and can therefore  adapt to an evolving appearance distribution. [sent-253, score-0.488]
</p><p>82 Sequential adaptive methods As initial model for this set of experiments we use the Random Forrest model with fully connected CRF from the non-adaptive methods presented above which showed an overall error of 24. [sent-254, score-0.218]
</p><p>83 This classifier is used as the initial point for an adaptive algorithm and refined during the process of adaptation on the test set. [sent-256, score-0.406]
</p><p>84 Table 3 shows resulting numbers for adaptive methods after they have processed the whole test set. [sent-257, score-0.235]
</p><p>85 In order to provide another point of reference to previous work, we compare to a sequential update by using a method in the style of Alvarez et al. [sent-261, score-0.333]
</p><p>86 5%) approach in labeling the road (around 5%) and sky (around 3%). [sent-265, score-0.643]
</p><p>87 We found the algorithm mentioned above to be quite sensitive to the correct choice of the acceptance threshold parameter λ. [sent-269, score-0.237]
</p><p>88 Our method allows to get even better labeling for road (around 2%) and sky (around 2%) over the Na¨ ıve Model Update under Scene Prior. [sent-271, score-0.684]
</p><p>89 While we were interested in treating all classes equally, so low Average error is a good indicator, that our algorithm has improved the labeling qual1326  Table3:ComparisngUeolpqfdbua etlinf yarlepntdANBMaplevı¨ytavihersoizda+npSecMtraonl. [sent-278, score-0.217]
</p><p>90 Figure 5 shows some example of how labelings for certain images evolve as our Bayesian Model Update method processes one batch of consequent images from the test set after another. [sent-290, score-0.191]
</p><p>91 The last row represents a situation when an image from the test set looks much like from the train set, therefore our algorithm performs correct labeling in the very beginning and does it throughout the run-time. [sent-291, score-0.326]
</p><p>92 Conclusion Today’s semantic scene labeling methods show good performance if the training distribution is representative for the test scenario. [sent-297, score-0.588]
</p><p>93 We collected a challenging dataset of images which has  very different appearance statistic compared to the established scene segmentation datasets. [sent-299, score-0.247]
</p><p>94 [8] shows up to 50 times worse recognition rate of scene classes, when tested on the new set over a set of images with appearance similar to the training one. [sent-301, score-0.232]
</p><p>95 We showed that even Na¨ ıve sequential model update allows to benefit considerably from the new information at test time. [sent-302, score-0.475]
</p><p>96 Although such method shows high variance of the convergence results which depend on the initialization as well as the choice of the acceptance threshold parameter. [sent-303, score-0.237]
</p><p>97 In order to cope with this challenge, we propose a Bayesian Model Update that sequentially updates the segmentation model as new data arrives. [sent-304, score-0.225]
</p><p>98 In contrast to previous algorithm, it gains robustness by maintaining a distribution over models and avoids model drift by exploiting a scene prior. [sent-305, score-0.258]
</p><p>99 Conditional random fields: Probabilistic models for segmenting and labeling sequence data. [sent-372, score-0.217]
</p><p>100 A dynamic conditional random field model for joint labeling of object and scene classes. [sent-402, score-0.385]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('road', 0.324), ('ht', 0.314), ('lt', 0.263), ('roads', 0.219), ('labeling', 0.217), ('alvarez', 0.185), ('acceptance', 0.18), ('update', 0.172), ('sequential', 0.161), ('particles', 0.153), ('adaptation', 0.144), ('autumn', 0.129), ('adaptive', 0.127), ('bayesian', 0.121), ('scene', 0.105), ('sky', 0.102), ('lvarez', 0.096), ('ahenb', 0.095), ('ve', 0.09), ('hypothesis', 0.09), ('na', 0.084), ('operate', 0.083), ('winter', 0.079), ('unlabeled', 0.077), ('test', 0.076), ('distribution', 0.074), ('continuously', 0.073), ('situations', 0.072), ('unobserved', 0.072), ('forest', 0.069), ('hl', 0.069), ('lately', 0.068), ('semantic', 0.067), ('conditions', 0.066), ('particle', 0.066), ('labelings', 0.066), ('condensation', 0.066), ('dht', 0.064), ('levinkov', 0.064), ('unforeseen', 0.064), ('cope', 0.062), ('statistic', 0.06), ('classifier', 0.059), ('doesn', 0.059), ('diverse', 0.058), ('kr', 0.058), ('ut', 0.058), ('constantly', 0.057), ('arrived', 0.057), ('threshold', 0.057), ('updates', 0.057), ('crf', 0.055), ('pp', 0.053), ('equip', 0.053), ('evolving', 0.053), ('labels', 0.052), ('old', 0.052), ('wojek', 0.051), ('batch', 0.049), ('drift', 0.049), ('training', 0.049), ('adapt', 0.048), ('pursues', 0.047), ('considerable', 0.046), ('illuminant', 0.045), ('predominantly', 0.045), ('arrive', 0.045), ('access', 0.044), ('structured', 0.042), ('appearance', 0.042), ('stationary', 0.041), ('brostow', 0.041), ('get', 0.041), ('segmentation', 0.04), ('systems', 0.039), ('exhibits', 0.039), ('changing', 0.039), ('forests', 0.039), ('retrain', 0.038), ('deteriorate', 0.037), ('new', 0.036), ('prior', 0.034), ('predicted', 0.034), ('label', 0.034), ('conditional', 0.033), ('checking', 0.033), ('aiming', 0.033), ('like', 0.033), ('pick', 0.032), ('whole', 0.032), ('driving', 0.032), ('saenko', 0.032), ('operating', 0.032), ('around', 0.032), ('crfs', 0.031), ('connected', 0.031), ('model', 0.03), ('scenes', 0.03), ('kulis', 0.029), ('fritz', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="386-tfidf-1" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>Author: Evgeny Levinkov, Mario Fritz</p><p>Abstract: Semantic road labeling is a key component of systems that aim at assisted or even autonomous driving. Considering that such systems continuously operate in the realworld, unforeseen conditions not represented in any conceivable training procedure are likely to occur on a regular basis. In order to equip systems with the ability to cope with such situations, we would like to enable adaptation to such new situations and conditions at runtime. Existing adaptive methods for image labeling either require labeled data from the new condition or even operate globally on a complete test set. None of this is a desirable mode of operation for a system as described above where new images arrive sequentially and conditions may vary. We study the effect of changing test conditions on scene labeling methods based on a new diverse street scene dataset. We propose a novel approach that can operate in such conditions and is based on a sequential Bayesian model update in order to robustly integrate the arriving images into the adapting procedure.</p><p>2 0.14616328 <a title="386-tfidf-2" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>Author: Taegyu Lim, Seunghoon Hong, Bohyung Han, Joon Hee Han</p><p>Abstract: We propose an on-line algorithm to extract a human by foreground/background segmentation and estimate pose of the human from the videos captured by moving cameras. We claim that a virtuous cycle can be created by appropriate interactions between the two modules to solve individual problems. This joint estimation problem is divided into two subproblems, , foreground/background segmentation and pose tracking, which alternate iteratively for optimization; segmentation step generates foreground mask for human pose tracking, and human pose tracking step provides foreground response map for segmentation. The final solution is obtained when the iterative procedure converges. We evaluate our algorithm quantitatively and qualitatively in real videos involving various challenges, and present its outstandingperformance compared to the state-of-the-art techniques for segmentation and pose estimation.</p><p>3 0.12330011 <a title="386-tfidf-3" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>Author: Stefan Duffner, Christophe Garcia</p><p>Abstract: In this paper, we present a novel algorithm for fast tracking of generic objects in videos. The algorithm uses two components: a detector that makes use of the generalised Hough transform with pixel-based descriptors, and a probabilistic segmentation method based on global models for foreground and background. These components are used for tracking in a combined way, and they adapt each other in a co-training manner. Through effective model adaptation and segmentation, the algorithm is able to track objects that undergo rigid and non-rigid deformations and considerable shape and appearance variations. The proposed tracking method has been thoroughly evaluated on challenging standard videos, and outperforms state-of-theart tracking methods designed for the same task. Finally, the proposed models allow for an extremely efficient implementation, and thus tracking is very fast.</p><p>4 0.11642108 <a title="386-tfidf-4" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>Author: Ehsan Elhamifar, Guillermo Sapiro, Allen Yang, S. Shankar Sasrty</p><p>Abstract: In many image/video/web classification problems, we have access to a large number of unlabeled samples. However, it is typically expensive and time consuming to obtain labels for the samples. Active learning is the problem of progressively selecting and annotating the most informative unlabeled samples, in order to obtain a high classification performance. Most existing active learning algorithms select only one sample at a time prior to retraining the classifier. Hence, they are computationally expensive and cannot take advantage of parallel labeling systems such as Mechanical Turk. On the other hand, algorithms that allow the selection of multiple samples prior to retraining the classifier, may select samples that have significant information overlap or they involve solving a non-convex optimization. More importantly, the majority of active learning algorithms are developed for a certain classifier type such as SVM. In this paper, we develop an efficient active learning framework based on convex programming, which can select multiple samples at a time for annotation. Unlike the state of the art, our algorithm can be used in conjunction with any type of classifiers, including those of the fam- ily of the recently proposed Sparse Representation-based Classification (SRC). We use the two principles of classifier uncertainty and sample diversity in order to guide the optimization program towards selecting the most informative unlabeled samples, which have the least information overlap. Our method can incorporate the data distribution in the selection process by using the appropriate dissimilarity between pairs of samples. We show the effectiveness of our framework in person detection, scene categorization and face recognition on real-world datasets.</p><p>5 0.11576169 <a title="386-tfidf-5" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>Author: Olaf Kähler, Ian Reid</p><p>Abstract: We address the problem of 3D scene labeling in a structured learning framework. Unlike previous work which uses structured Support VectorMachines, we employ the recently described Decision Tree Field and Regression Tree Field frameworks, which learn the unary and binary terms of a Conditional Random Field from training data. We show this has significant advantages in terms of inference speed, while maintaining similar accuracy. We also demonstrate empirically the importance for overall labeling accuracy of features that make use of prior knowledge about the coarse scene layout such as the location of the ground plane. We show how this coarse layout can be estimated by our framework automatically, and that this information can be used to bootstrap improved accuracy in the detailed labeling.</p><p>6 0.10794749 <a title="386-tfidf-6" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>7 0.10745393 <a title="386-tfidf-7" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>8 0.10722726 <a title="386-tfidf-8" href="./iccv-2013-Estimating_the_3D_Layout_of_Indoor_Scenes_and_Its_Clutter_from_Depth_Sensors.html">144 iccv-2013-Estimating the 3D Layout of Indoor Scenes and Its Clutter from Depth Sensors</a></p>
<p>9 0.10716159 <a title="386-tfidf-9" href="./iccv-2013-Incorporating_Cloud_Distribution_in_Sky_Representation.html">215 iccv-2013-Incorporating Cloud Distribution in Sky Representation</a></p>
<p>10 0.10679851 <a title="386-tfidf-10" href="./iccv-2013-Domain_Adaptive_Classification.html">123 iccv-2013-Domain Adaptive Classification</a></p>
<p>11 0.10228138 <a title="386-tfidf-11" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>12 0.10159491 <a title="386-tfidf-12" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>13 0.097837478 <a title="386-tfidf-13" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>14 0.09765891 <a title="386-tfidf-14" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>15 0.0921176 <a title="386-tfidf-15" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>16 0.088001922 <a title="386-tfidf-16" href="./iccv-2013-NYC3DCars%3A_A_Dataset_of_3D_Vehicles_in_Geographic_Context.html">286 iccv-2013-NYC3DCars: A Dataset of 3D Vehicles in Geographic Context</a></p>
<p>17 0.085850246 <a title="386-tfidf-17" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>18 0.085846864 <a title="386-tfidf-18" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>19 0.08007016 <a title="386-tfidf-19" href="./iccv-2013-Detecting_Dynamic_Objects_with_Multi-view_Background_Subtraction.html">111 iccv-2013-Detecting Dynamic Objects with Multi-view Background Subtraction</a></p>
<p>20 0.077835046 <a title="386-tfidf-20" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.214), (1, -0.004), (2, -0.015), (3, -0.018), (4, 0.05), (5, -0.017), (6, -0.075), (7, 0.067), (8, -0.014), (9, -0.023), (10, -0.028), (11, -0.094), (12, -0.005), (13, 0.003), (14, 0.038), (15, -0.075), (16, -0.069), (17, -0.033), (18, -0.07), (19, -0.029), (20, -0.013), (21, -0.068), (22, 0.016), (23, 0.029), (24, -0.005), (25, -0.044), (26, 0.072), (27, 0.028), (28, 0.079), (29, -0.006), (30, 0.003), (31, 0.034), (32, 0.059), (33, 0.006), (34, -0.004), (35, -0.005), (36, -0.068), (37, 0.06), (38, -0.003), (39, 0.04), (40, -0.07), (41, 0.036), (42, -0.032), (43, 0.01), (44, 0.065), (45, -0.042), (46, -0.067), (47, -0.008), (48, -0.003), (49, -0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95510864 <a title="386-lsi-1" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>Author: Evgeny Levinkov, Mario Fritz</p><p>Abstract: Semantic road labeling is a key component of systems that aim at assisted or even autonomous driving. Considering that such systems continuously operate in the realworld, unforeseen conditions not represented in any conceivable training procedure are likely to occur on a regular basis. In order to equip systems with the ability to cope with such situations, we would like to enable adaptation to such new situations and conditions at runtime. Existing adaptive methods for image labeling either require labeled data from the new condition or even operate globally on a complete test set. None of this is a desirable mode of operation for a system as described above where new images arrive sequentially and conditions may vary. We study the effect of changing test conditions on scene labeling methods based on a new diverse street scene dataset. We propose a novel approach that can operate in such conditions and is based on a sequential Bayesian model update in order to robustly integrate the arriving images into the adapting procedure.</p><p>2 0.72235596 <a title="386-lsi-2" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>Author: Honghui Zhang, Jingdong Wang, Ping Tan, Jinglu Wang, Long Quan</p><p>Abstract: We propose an adaptive subgradient descent method to efficiently learn the parameters of CRF models for image parsing. To balance the learning efficiency and performance of the learned CRF models, the parameter learning is iteratively carried out by solving a convex optimization problem in each iteration, which integrates a proximal term to preserve the previously learned information and the large margin preference to distinguish bad labeling and the ground truth labeling. A solution of subgradient descent updating form is derived for the convex optimization problem, with an adaptively determined updating step-size. Besides, to deal with partially labeled training data, we propose a new objective constraint modeling both the labeled and unlabeled parts in the partially labeled training data for the parameter learning of CRF models. The superior learning efficiency of the proposed method is verified by the experiment results on two public datasets. We also demonstrate the powerfulness of our method for handling partially labeled training data.</p><p>3 0.66722947 <a title="386-lsi-3" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>Author: Zhiyuan Shi, Timothy M. Hospedales, Tao Xiang</p><p>Abstract: We address the problem of localisation of objects as bounding boxes in images with weak labels. This weakly supervised object localisation problem has been tackled in the past using discriminative models where each object class is localised independently from other classes. We propose a novel framework based on Bayesian joint topic modelling. Our framework has three distinctive advantages over previous works: (1) All object classes and image backgrounds are modelled jointly together in a single generative model so that “explaining away” inference can resolve ambiguity and lead to better learning and localisation. (2) The Bayesian formulation of the model enables easy integration of prior knowledge about object appearance to compensate for limited supervision. (3) Our model can be learned with a mixture of weakly labelled and unlabelled data, allowing the large volume of unlabelled images on the Internet to be exploited for learning. Extensive experiments on the challenging VOC dataset demonstrate that our approach outperforms the state-of-the-art competitors.</p><p>4 0.65054458 <a title="386-lsi-4" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>Author: Olaf Kähler, Ian Reid</p><p>Abstract: We address the problem of 3D scene labeling in a structured learning framework. Unlike previous work which uses structured Support VectorMachines, we employ the recently described Decision Tree Field and Regression Tree Field frameworks, which learn the unary and binary terms of a Conditional Random Field from training data. We show this has significant advantages in terms of inference speed, while maintaining similar accuracy. We also demonstrate empirically the importance for overall labeling accuracy of features that make use of prior knowledge about the coarse scene layout such as the location of the ground plane. We show how this coarse layout can be estimated by our framework automatically, and that this information can be used to bootstrap improved accuracy in the detailed labeling.</p><p>5 0.65026933 <a title="386-lsi-5" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>Author: Mojtaba Seyedhosseini, Mehdi Sajjadi, Tolga Tasdizen</p><p>Abstract: Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic dis- junctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance.</p><p>6 0.64459795 <a title="386-lsi-6" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>7 0.63894826 <a title="386-lsi-7" href="./iccv-2013-Incorporating_Cloud_Distribution_in_Sky_Representation.html">215 iccv-2013-Incorporating Cloud Distribution in Sky Representation</a></p>
<p>8 0.63346356 <a title="386-lsi-8" href="./iccv-2013-Characterizing_Layouts_of_Outdoor_Scenes_Using_Spatial_Topic_Processes.html">72 iccv-2013-Characterizing Layouts of Outdoor Scenes Using Spatial Topic Processes</a></p>
<p>9 0.625328 <a title="386-lsi-9" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>10 0.61987954 <a title="386-lsi-10" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<p>11 0.61312759 <a title="386-lsi-11" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>12 0.61148655 <a title="386-lsi-12" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>13 0.60478944 <a title="386-lsi-13" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>14 0.59989065 <a title="386-lsi-14" href="./iccv-2013-From_Semi-supervised_to_Transfer_Counting_of_Crowds.html">178 iccv-2013-From Semi-supervised to Transfer Counting of Crowds</a></p>
<p>15 0.59593475 <a title="386-lsi-15" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<p>16 0.59583086 <a title="386-lsi-16" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>17 0.59527194 <a title="386-lsi-17" href="./iccv-2013-Holistic_Scene_Understanding_for_3D_Object_Detection_with_RGBD_Cameras.html">201 iccv-2013-Holistic Scene Understanding for 3D Object Detection with RGBD Cameras</a></p>
<p>18 0.57350248 <a title="386-lsi-18" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>19 0.57200903 <a title="386-lsi-19" href="./iccv-2013-Learning_to_Rank_Using_Privileged_Information.html">248 iccv-2013-Learning to Rank Using Privileged Information</a></p>
<p>20 0.56743377 <a title="386-lsi-20" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.065), (7, 0.029), (26, 0.104), (31, 0.036), (40, 0.029), (42, 0.118), (48, 0.015), (64, 0.04), (73, 0.058), (89, 0.206), (95, 0.016), (98, 0.029), (99, 0.163)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89882481 <a title="386-lda-1" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<p>Author: Marc T. Law, Nicolas Thome, Matthieu Cord</p><p>Abstract: This paper introduces a novel similarity learning framework. Working with inequality constraints involving quadruplets of images, our approach aims at efficiently modeling similarity from rich or complex semantic label relationships. From these quadruplet-wise constraints, we propose a similarity learning framework relying on a convex optimization scheme. We then study how our metric learning scheme can exploit specific class relationships, such as class ranking (relative attributes), and class taxonomy. We show that classification using the learned metrics gets improved performance over state-of-the-art methods on several datasets. We also evaluate our approach in a new application to learn similarities between webpage screenshots in a fully unsupervised way.</p><p>same-paper 2 0.87526852 <a title="386-lda-2" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>Author: Evgeny Levinkov, Mario Fritz</p><p>Abstract: Semantic road labeling is a key component of systems that aim at assisted or even autonomous driving. Considering that such systems continuously operate in the realworld, unforeseen conditions not represented in any conceivable training procedure are likely to occur on a regular basis. In order to equip systems with the ability to cope with such situations, we would like to enable adaptation to such new situations and conditions at runtime. Existing adaptive methods for image labeling either require labeled data from the new condition or even operate globally on a complete test set. None of this is a desirable mode of operation for a system as described above where new images arrive sequentially and conditions may vary. We study the effect of changing test conditions on scene labeling methods based on a new diverse street scene dataset. We propose a novel approach that can operate in such conditions and is based on a sequential Bayesian model update in order to robustly integrate the arriving images into the adapting procedure.</p><p>3 0.84842026 <a title="386-lda-3" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>4 0.8480919 <a title="386-lda-4" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>5 0.84069955 <a title="386-lda-5" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>Author: Chih-Yuan Yang, Ming-Hsuan Yang</p><p>Abstract: The goal of single-image super-resolution is to generate a high-quality high-resolution image based on a given low-resolution input. It is an ill-posed problem which requires exemplars or priors to better reconstruct the missing high-resolution image details. In this paper, we propose to split the feature space into numerous subspaces and collect exemplars to learn priors for each subspace, thereby creating effective mapping functions. The use of split input space facilitates both feasibility of using simple functionsfor super-resolution, and efficiency ofgenerating highresolution results. High-quality high-resolution images are reconstructed based on the effective learned priors. Experimental results demonstrate that theproposed algorithmperforms efficiently and effectively over state-of-the-art methods.</p><p>6 0.8401832 <a title="386-lda-6" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>7 0.83983469 <a title="386-lda-7" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>8 0.83957046 <a title="386-lda-8" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>9 0.83887744 <a title="386-lda-9" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>10 0.83882624 <a title="386-lda-10" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>11 0.83872265 <a title="386-lda-11" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>12 0.83870161 <a title="386-lda-12" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>13 0.83866841 <a title="386-lda-13" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>14 0.83818507 <a title="386-lda-14" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>15 0.83802116 <a title="386-lda-15" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>16 0.83793199 <a title="386-lda-16" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>17 0.83752608 <a title="386-lda-17" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>18 0.83693761 <a title="386-lda-18" href="./iccv-2013-Distributed_Low-Rank_Subspace_Segmentation.html">122 iccv-2013-Distributed Low-Rank Subspace Segmentation</a></p>
<p>19 0.83688712 <a title="386-lda-19" href="./iccv-2013-Discriminatively_Trained_Templates_for_3D_Object_Detection%3A_A_Real_Time_Scalable_Approach.html">121 iccv-2013-Discriminatively Trained Templates for 3D Object Detection: A Real Time Scalable Approach</a></p>
<p>20 0.83688688 <a title="386-lda-20" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
