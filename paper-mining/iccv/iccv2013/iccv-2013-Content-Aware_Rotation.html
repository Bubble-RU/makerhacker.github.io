<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>90 iccv-2013-Content-Aware Rotation</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-90" href="#">iccv2013-90</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>90 iccv-2013-Content-Aware Rotation</h1>
<br/><p>Source: <a title="iccv-2013-90-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/He_Content-Aware_Rotation_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Kaiming He, Huiwen Chang, Jian Sun</p><p>Abstract: We present an image editing tool called Content-Aware Rotation. Casually shot photos can appear tilted, and are often corrected by rotation and cropping. This trivial solution may remove desired content and hurt image integrity. Instead of doing rigid rotation, we propose a warping method that creates the perception of rotation and avoids cropping. Human vision studies suggest that the perception of rotation is mainly due to horizontal/vertical lines. We design an optimization-based method that preserves the rotation of horizontal/vertical lines, maintains the completeness of the image content, and reduces the warping distortion. An efficient algorithm is developed to address the challenging optimization. We demonstrate our content-aware rotation method on a variety of practical cases.</p><p>Reference: <a title="iccv-2013-90-reference" href="../iccv2013_reference/iccv-2013-Content-Aware_Rotation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rot', 0.562), ('angl', 0.267), ('tilt', 0.209), ('warp', 0.198), ('quad', 0.18), ('perceiv', 0.163), ('seam', 0.153), ('horizon', 0.15), ('ek', 0.146), ('pencil', 0.139), ('upright', 0.138), ('mesh', 0.128), ('crop', 0.126), ('lin', 0.12), ('energy', 0.114), ('siggraph', 0.111), ('uk', 0.102), ('vertex', 0.098), ('rigid', 0.096), ('manip', 0.096)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="90-tfidf-1" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>Author: Kaiming He, Huiwen Chang, Jian Sun</p><p>Abstract: We present an image editing tool called Content-Aware Rotation. Casually shot photos can appear tilted, and are often corrected by rotation and cropping. This trivial solution may remove desired content and hurt image integrity. Instead of doing rigid rotation, we propose a warping method that creates the perception of rotation and avoids cropping. Human vision studies suggest that the perception of rotation is mainly due to horizontal/vertical lines. We design an optimization-based method that preserves the rotation of horizontal/vertical lines, maintains the completeness of the image content, and reduces the warping distortion. An efficient algorithm is developed to address the challenging optimization. We demonstrate our content-aware rotation method on a variety of practical cases.</p><p>2 0.22340757 <a title="90-tfidf-2" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>Author: Laurent Kneip, Simon Lynen</p><p>Abstract: This work makes use of a novel, recently proposed epipolar constraint for computing the relative pose between two calibrated images. By enforcing the coplanarity of epipolar plane normal vectors, it constrains the three degrees of freedom of the relative rotation between two camera views directlyâ€”independently of the translation. The present paper shows how the approach can be extended to n points, and translated into an efficient eigenvalue minimization over the three rotational degrees of freedom. Each iteration in the non-linear optimization has constant execution time, independently of the number of features. Two global optimization approaches are proposed. The first one consists of an efficient Levenberg-Marquardt scheme with randomized initial value, which already leads to stable and accurate results. The second scheme consists of a globally optimal branch-and-bound algorithm based on a bound on the eigenvalue variation derived from symmetric eigenvalue-perturbation theory. Analysis of the cost function reveals insights into the nature of a specific relative pose problem, and outlines the complexity under different conditions. The algorithm shows state-of-the-art performance w.r.t. essential-matrix based solutions, and a frameto-frame application to a video sequence immediately leads to an alternative, real-time visual odometry solution. Note: All algorithms in this paper are made available in the OpenGV library. Please visit http : / / l aurent kne ip .github . i / opengv o</p><p>3 0.22327676 <a title="90-tfidf-3" href="./iccv-2013-Efficient_and_Robust_Large-Scale_Rotation_Averaging.html">138 iccv-2013-Efficient and Robust Large-Scale Rotation Averaging</a></p>
<p>Author: Avishek Chatterjee, Venu Madhav Govindu</p><p>Abstract: In this paper we address the problem of robust and efficient averaging of relative 3D rotations. Apart from having an interesting geometric structure, robust rotation averaging addresses the need for a good initialization for largescale optimization used in structure-from-motion pipelines. Such pipelines often use unstructured image datasets harvested from the internet thereby requiring an initialization method that is robust to outliers. Our approach works on the Lie group structure of 3D rotations and solves the problem of large-scale robust rotation averaging in two ways. Firstly, we use modern ?1 optimizers to carry out robust averaging of relative rotations that is efficient, scalable and robust to outliers. In addition, we also develop a twostep method that uses the ?1 solution as an initialisation for an iteratively reweighted least squares (IRLS) approach. These methods achieve excellent results on large-scale, real world datasets and significantly outperform existing methods, i.e. the state-of-the-art discrete-continuous optimization method of [3] as well as the Weiszfeld method of [8]. We demonstrate the efficacy of our method on two large- scale real world datasets and also provide the results of the two aforementioned methods for comparison.</p><p>4 0.16907823 <a title="90-tfidf-4" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>Author: Pierre Moulon, Pascal Monasse, Renaud Marlet</p><p>Abstract: Multi-view structure from motion (SfM) estimates the position and orientation of pictures in a common 3D coordinate frame. When views are treated incrementally, this external calibration can be subject to drift, contrary to global methods that distribute residual errors evenly. We propose a new global calibration approach based on the fusion of relative motions between image pairs. We improve an existing method for robustly computing global rotations. We present an efficient a contrario trifocal tensor estimation method, from which stable and precise translation directions can be extracted. We also define an efficient translation registration method that recovers accurate camera positions. These components are combined into an original SfM pipeline. Our experiments show that, on most datasets, it outperforms in accuracy other existing incremental and global pipelines. It also achieves strikingly good running times: it is about 20 times faster than the other global method we could compare to, and as fast as the best incremental method. More importantly, it features better scalability properties.</p><p>5 0.14534971 <a title="90-tfidf-5" href="./iccv-2013-Multiview_Photometric_Stereo_Using_Planar_Mesh_Parameterization.html">284 iccv-2013-Multiview Photometric Stereo Using Planar Mesh Parameterization</a></p>
<p>Author: Jaesik Park, Sudipta N. Sinha, Yasuyuki Matsushita, Yu-Wing Tai, In So Kweon</p><p>Abstract: We propose a method for accurate 3D shape reconstruction using uncalibrated multiview photometric stereo. A coarse mesh reconstructed using multiview stereo is first parameterized using a planar mesh parameterization technique. Subsequently, multiview photometric stereo is performed in the 2D parameter domain of the mesh, where all geometric and photometric cues from multiple images can be treated uniformly. Unlike traditional methods, there is no need for merging view-dependent surface normal maps. Our key contribution is a new photometric stereo based mesh refinement technique that can efficiently reconstruct meshes with extremely fine geometric details by directly estimating a displacement texture map in the 2D parameter domain. We demonstrate that intricate surface geometry can be reconstructed using several challenging datasets containing surfaces with specular reflections, multiple albedos and complex topologies.</p><p>6 0.13129713 <a title="90-tfidf-6" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>7 0.12008673 <a title="90-tfidf-7" href="./iccv-2013-Strong_Appearance_and_Expressive_Spatial_Models_for_Human_Pose_Estimation.html">403 iccv-2013-Strong Appearance and Expressive Spatial Models for Human Pose Estimation</a></p>
<p>8 0.1140762 <a title="90-tfidf-8" href="./iccv-2013-Efficient_Hand_Pose_Estimation_from_a_Single_Depth_Image.html">133 iccv-2013-Efficient Hand Pose Estimation from a Single Depth Image</a></p>
<p>9 0.11263081 <a title="90-tfidf-9" href="./iccv-2013-Rectangling_Stereographic_Projection_for_Wide-Angle_Image_Visualization.html">346 iccv-2013-Rectangling Stereographic Projection for Wide-Angle Image Visualization</a></p>
<p>10 0.10541009 <a title="90-tfidf-10" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>11 0.10192116 <a title="90-tfidf-11" href="./iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</a></p>
<p>12 0.10174297 <a title="90-tfidf-12" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>13 0.095635995 <a title="90-tfidf-13" href="./iccv-2013-Manipulation_Pattern_Discovery%3A_A_Nonparametric_Bayesian_Approach.html">260 iccv-2013-Manipulation Pattern Discovery: A Nonparametric Bayesian Approach</a></p>
<p>14 0.095003888 <a title="90-tfidf-14" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<p>15 0.094111793 <a title="90-tfidf-15" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>16 0.094024517 <a title="90-tfidf-16" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>17 0.093756251 <a title="90-tfidf-17" href="./iccv-2013-Real-World_Normal_Map_Capture_for_Nearly_Flat_Reflective_Surfaces.html">343 iccv-2013-Real-World Normal Map Capture for Nearly Flat Reflective Surfaces</a></p>
<p>18 0.093048453 <a title="90-tfidf-18" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<p>19 0.09159413 <a title="90-tfidf-19" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>20 0.088189401 <a title="90-tfidf-20" href="./iccv-2013-SUN3D%3A_A_Database_of_Big_Spaces_Reconstructed_Using_SfM_and_Object_Labels.html">367 iccv-2013-SUN3D: A Database of Big Spaces Reconstructed Using SfM and Object Labels</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, -0.013), (2, 0.067), (3, 0.119), (4, -0.007), (5, 0.076), (6, 0.011), (7, 0.014), (8, -0.011), (9, -0.013), (10, -0.03), (11, -0.047), (12, 0.076), (13, 0.079), (14, -0.132), (15, -0.128), (16, -0.017), (17, -0.059), (18, -0.031), (19, 0.085), (20, 0.012), (21, 0.069), (22, -0.069), (23, 0.018), (24, -0.032), (25, 0.07), (26, -0.034), (27, -0.03), (28, 0.014), (29, -0.056), (30, 0.06), (31, -0.05), (32, 0.024), (33, -0.032), (34, -0.012), (35, -0.065), (36, 0.093), (37, -0.097), (38, -0.091), (39, -0.06), (40, -0.078), (41, 0.071), (42, -0.089), (43, -0.028), (44, 0.163), (45, 0.019), (46, 0.102), (47, -0.046), (48, -0.032), (49, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97281754 <a title="90-lsi-1" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>Author: Kaiming He, Huiwen Chang, Jian Sun</p><p>Abstract: We present an image editing tool called Content-Aware Rotation. Casually shot photos can appear tilted, and are often corrected by rotation and cropping. This trivial solution may remove desired content and hurt image integrity. Instead of doing rigid rotation, we propose a warping method that creates the perception of rotation and avoids cropping. Human vision studies suggest that the perception of rotation is mainly due to horizontal/vertical lines. We design an optimization-based method that preserves the rotation of horizontal/vertical lines, maintains the completeness of the image content, and reduces the warping distortion. An efficient algorithm is developed to address the challenging optimization. We demonstrate our content-aware rotation method on a variety of practical cases.</p><p>2 0.82341081 <a title="90-lsi-2" href="./iccv-2013-Efficient_and_Robust_Large-Scale_Rotation_Averaging.html">138 iccv-2013-Efficient and Robust Large-Scale Rotation Averaging</a></p>
<p>Author: Avishek Chatterjee, Venu Madhav Govindu</p><p>Abstract: In this paper we address the problem of robust and efficient averaging of relative 3D rotations. Apart from having an interesting geometric structure, robust rotation averaging addresses the need for a good initialization for largescale optimization used in structure-from-motion pipelines. Such pipelines often use unstructured image datasets harvested from the internet thereby requiring an initialization method that is robust to outliers. Our approach works on the Lie group structure of 3D rotations and solves the problem of large-scale robust rotation averaging in two ways. Firstly, we use modern ?1 optimizers to carry out robust averaging of relative rotations that is efficient, scalable and robust to outliers. In addition, we also develop a twostep method that uses the ?1 solution as an initialisation for an iteratively reweighted least squares (IRLS) approach. These methods achieve excellent results on large-scale, real world datasets and significantly outperform existing methods, i.e. the state-of-the-art discrete-continuous optimization method of [3] as well as the Weiszfeld method of [8]. We demonstrate the efficacy of our method on two large- scale real world datasets and also provide the results of the two aforementioned methods for comparison.</p><p>3 0.7694748 <a title="90-lsi-3" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>Author: Laurent Kneip, Simon Lynen</p><p>Abstract: This work makes use of a novel, recently proposed epipolar constraint for computing the relative pose between two calibrated images. By enforcing the coplanarity of epipolar plane normal vectors, it constrains the three degrees of freedom of the relative rotation between two camera views directlyâ€”independently of the translation. The present paper shows how the approach can be extended to n points, and translated into an efficient eigenvalue minimization over the three rotational degrees of freedom. Each iteration in the non-linear optimization has constant execution time, independently of the number of features. Two global optimization approaches are proposed. The first one consists of an efficient Levenberg-Marquardt scheme with randomized initial value, which already leads to stable and accurate results. The second scheme consists of a globally optimal branch-and-bound algorithm based on a bound on the eigenvalue variation derived from symmetric eigenvalue-perturbation theory. Analysis of the cost function reveals insights into the nature of a specific relative pose problem, and outlines the complexity under different conditions. The algorithm shows state-of-the-art performance w.r.t. essential-matrix based solutions, and a frameto-frame application to a video sequence immediately leads to an alternative, real-time visual odometry solution. Note: All algorithms in this paper are made available in the OpenGV library. Please visit http : / / l aurent kne ip .github . i / opengv o</p><p>4 0.75688988 <a title="90-lsi-4" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>Author: Jiaolong Yang, Hongdong Li, Yunde Jia</p><p>Abstract: Registration is a fundamental task in computer vision. The Iterative Closest Point (ICP) algorithm is one of the widely-used methods for solving the registration problem. Based on local iteration, ICP is however well-known to suffer from local minima. Its performance critically relies on the quality of initialization, and only local optimality is guaranteed. This paper provides the very first globally optimal solution to Euclidean registration of two 3D pointsets or two 3D surfaces under the L2 error. Our method is built upon ICP, but combines it with a branch-and-bound (BnB) scheme which searches the 3D motion space SE(3) efficiently. By exploiting the special structure of the underlying geometry, we derive novel upper and lower bounds for the ICP error function. The integration of local ICP and global BnB enables the new method to run efficiently in practice, and its optimality is exactly guaranteed. We also discuss extensions, addressing the issue of outlier robustness.</p><p>5 0.72695029 <a title="90-lsi-5" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>Author: Yinqiang Zheng, Yubin Kuang, Shigeki Sugimoto, Kalle Ã…strÃ¶m, Masatoshi Okutomi</p><p>Abstract: In this paper, we revisit the classical perspective-n-point (PnP) problem, and propose the first non-iterative O(n) solution that is fast, generally applicable and globally optimal. Our basic idea is to formulate the PnP problem into a functional minimization problem and retrieve all its stationary points by using the GrÂ¨ obner basis technique. The novelty lies in a non-unit quaternion representation to parameterize the rotation and a simple but elegant formulation of the PnP problem into an unconstrained optimization problem. Interestingly, the polynomial system arising from its first-order optimality condition assumes two-fold symmetry, a nice property that can be utilized to improve speed and numerical stability of a GrÂ¨ obner basis solver. Experiment results have demonstrated that, in terms of accuracy, our proposed solution is definitely better than the state-ofthe-art O(n) methods, and even comparable with the reprojection error minimization method.</p><p>6 0.69680035 <a title="90-lsi-6" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>7 0.63519394 <a title="90-lsi-7" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>8 0.59902936 <a title="90-lsi-8" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>9 0.58412468 <a title="90-lsi-9" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>10 0.56253982 <a title="90-lsi-10" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>11 0.5532034 <a title="90-lsi-11" href="./iccv-2013-Rectangling_Stereographic_Projection_for_Wide-Angle_Image_Visualization.html">346 iccv-2013-Rectangling Stereographic Projection for Wide-Angle Image Visualization</a></p>
<p>12 0.53529102 <a title="90-lsi-12" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>13 0.51190192 <a title="90-lsi-13" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>14 0.50427043 <a title="90-lsi-14" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>15 0.50333995 <a title="90-lsi-15" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>16 0.50166547 <a title="90-lsi-16" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>17 0.49695179 <a title="90-lsi-17" href="./iccv-2013-Extrinsic_Camera_Calibration_without_a_Direct_View_Using_Spherical_Mirror.html">152 iccv-2013-Extrinsic Camera Calibration without a Direct View Using Spherical Mirror</a></p>
<p>18 0.48018262 <a title="90-lsi-18" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>19 0.47068164 <a title="90-lsi-19" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>20 0.46803668 <a title="90-lsi-20" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(12, 0.018), (13, 0.069), (20, 0.092), (25, 0.068), (42, 0.186), (48, 0.138), (50, 0.012), (55, 0.025), (77, 0.085), (89, 0.012), (99, 0.215)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8695038 <a title="90-lda-1" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<p>Author: Dengxin Dai, Hayko Riemenschneider, Gerhard Schmitt, Luc Van_Gool</p><p>Abstract: There is an increased interest in the efficient creation of city models, be it virtual or as-built. We present a method for synthesizing complex, photo-realistic facade images, from a single example. After parsing the example image into its semantic components, a tiling for it is generated. Novel tilings can then be created, yielding facade textures with different dimensions or with occluded parts inpainted. A genetic algorithm guides the novel facades as well as inpainted parts to be consistent with the example, both in terms of their overall structure and their detailed textures. Promising results for multiple standard datasets in particular for the different building styles they contain demonstrate the potential of the method. â€“ â€“</p><p>same-paper 2 0.83097535 <a title="90-lda-2" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>Author: Kaiming He, Huiwen Chang, Jian Sun</p><p>Abstract: We present an image editing tool called Content-Aware Rotation. Casually shot photos can appear tilted, and are often corrected by rotation and cropping. This trivial solution may remove desired content and hurt image integrity. Instead of doing rigid rotation, we propose a warping method that creates the perception of rotation and avoids cropping. Human vision studies suggest that the perception of rotation is mainly due to horizontal/vertical lines. We design an optimization-based method that preserves the rotation of horizontal/vertical lines, maintains the completeness of the image content, and reduces the warping distortion. An efficient algorithm is developed to address the challenging optimization. We demonstrate our content-aware rotation method on a variety of practical cases.</p><p>3 0.82047939 <a title="90-lda-3" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>Author: Yanchao Yang, Ganesh Sundaramoorthi</p><p>Abstract: We present a method to track the precise shape of a dynamic object in video. Joint dynamic shape and appearance models, in which a template of the object is propagated to match the object shape and radiance in the next frame, are advantageous over methods employing global image statistics in cases of complex object radiance and cluttered background. In cases of complex 3D object motion and relative viewpoint change, self-occlusions and disocclusions of the object are prominent, and current methods employing joint shape and appearance models are unable to accurately adapt to new shape and appearance information, leading to inaccurate shape detection. In this work, we model self-occlusions and dis-occlusions in a joint shape and appearance tracking framework. Experiments on video exhibiting occlusion/dis-occlusion, complex radiance and background show that occlusion/dis-occlusion modeling leads to superior shape accuracy compared to recent methods employing joint shape/appearance models or employing global statistics.</p><p>4 0.76937342 <a title="90-lda-4" href="./iccv-2013-Joint_Subspace_Stabilization_for_Stereoscopic_Video.html">226 iccv-2013-Joint Subspace Stabilization for Stereoscopic Video</a></p>
<p>Author: Feng Liu, Yuzhen Niu, Hailin Jin</p><p>Abstract: Shaky stereoscopic video is not only unpleasant to watch but may also cause 3D fatigue. Stabilizing the left and right view of a stereoscopic video separately using a monocular stabilization method tends to both introduce undesirable vertical disparities and damage horizontal disparities, which may destroy the stereoscopic viewing experience. In this paper, we present a joint subspace stabilization method for stereoscopic video. We prove that the low-rank subspace constraint for monocular video [10] also holds for stereoscopic video. Particularly, the feature trajectories from the left and right video share the same subspace. Based on this proof, we develop a stereo subspace stabilization method that jointly computes a common subspace from the left and right video and uses it to stabilize the two videos simultaneously. Our method meets the stereoscopic constraints without 3D reconstruction or explicit left-right correspondence. We test our method on a variety of stereoscopic videos with different scene content and camera motion. The experiments show that our method achieves high-quality stabilization for stereoscopic video in a robust and efficient way.</p><p>5 0.76719534 <a title="90-lda-5" href="./iccv-2013-Correntropy_Induced_L2_Graph_for_Robust_Subspace_Clustering.html">94 iccv-2013-Correntropy Induced L2 Graph for Robust Subspace Clustering</a></p>
<p>Author: Canyi Lu, Jinhui Tang, Min Lin, Liang Lin, Shuicheng Yan, Zhouchen Lin</p><p>Abstract: In this paper, we study the robust subspace clustering problem, which aims to cluster the given possibly noisy data points into their underlying subspaces. A large pool of previous subspace clustering methods focus on the graph construction by different regularization of the representation coefficient. We instead focus on the robustness of the model to non-Gaussian noises. We propose a new robust clustering method by using the correntropy induced metric, which is robust for handling the non-Gaussian and impulsive noises. Also we further extend the method for handling the data with outlier rows/features. The multiplicative form of half-quadratic optimization is used to optimize the nonconvex correntropy objective function of the proposed models. Extensive experiments on face datasets well demonstrate that the proposed methods are more robust to corruptions and occlusions.</p><p>6 0.76640958 <a title="90-lda-6" href="./iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</a></p>
<p>7 0.76624942 <a title="90-lda-7" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>8 0.76573557 <a title="90-lda-8" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>9 0.764943 <a title="90-lda-9" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>10 0.76442134 <a title="90-lda-10" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>11 0.76276225 <a title="90-lda-11" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>12 0.76190025 <a title="90-lda-12" href="./iccv-2013-Efficient_and_Robust_Large-Scale_Rotation_Averaging.html">138 iccv-2013-Efficient and Robust Large-Scale Rotation Averaging</a></p>
<p>13 0.76170647 <a title="90-lda-13" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>14 0.7612884 <a title="90-lda-14" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>15 0.76073503 <a title="90-lda-15" href="./iccv-2013-Measuring_Flow_Complexity_in_Videos.html">263 iccv-2013-Measuring Flow Complexity in Videos</a></p>
<p>16 0.75964081 <a title="90-lda-16" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>17 0.75950849 <a title="90-lda-17" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>18 0.75942099 <a title="90-lda-18" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>19 0.75840437 <a title="90-lda-19" href="./iccv-2013-Correlation_Adaptive_Subspace_Segmentation_by_Trace_Lasso.html">93 iccv-2013-Correlation Adaptive Subspace Segmentation by Trace Lasso</a></p>
<p>20 0.75737512 <a title="90-lda-20" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
