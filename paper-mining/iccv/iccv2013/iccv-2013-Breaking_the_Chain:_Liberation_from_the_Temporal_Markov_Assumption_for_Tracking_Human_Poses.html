<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-65" href="#">iccv2013-65</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</h1>
<br/><p>Source: <a title="iccv-2013-65-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Tokola_Breaking_the_Chain_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>Reference: <a title="iccv-2013-65-reference" href="../iccv2013_reference/iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Breaking the chain: liberation from the temporal Markov assumption for tracking human poses Ryan Tokola Oak Ridge National Laboratory Oak Ridge, TN  Wongun Choi NEC Research Labs Cupertino, CA  t okol ara@ ornl . [sent-1, score-0.372]
</p><p>2 of Computer Science Stanford University  wongun @ nec  Abstract We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. [sent-3, score-0.48]
</p><p>3 edu  ral reasoning from the tracking stage to the detection stage. [sent-6, score-0.273]
</p><p>4 The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. [sent-7, score-0.92]
</p><p>5 A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. [sent-8, score-0.262]
</p><p>6 In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. [sent-9, score-1.806]
</p><p>7 Unfortunately, tracking people is difficult because people move with complex dynamics, they have unpredictable appearances, and  Figure1. [sent-15, score-0.287]
</p><p>8 Each node represents the path of a body joint through the video. [sent-22, score-0.62]
</p><p>9 For example, trajectory hypotheses with consistent colors throughout the video can be rewarded. [sent-26, score-0.458]
</p><p>10 Tracking-by-detection  Recent approaches to tracking in video are dominated by tracking-by-detection, such as in [2], which separates 22442244  the tasks of detection and tracking into two separate processes. [sent-31, score-0.417]
</p><p>11 Chain-shaped tracking-by-detection models work well when detections are reliable, but they are limited by their simplifying assumptions even though tracking is a fundamentally time-based operation, time is only used to enforce some degree of local consistency from one frame to the next. [sent-36, score-0.455]
</p><p>12 Tracking-by-selection  We present a new approach to tracking that can enforce global (long term) consistencies across an entire video, yet is even simpler than a standard chain-shaped tracking-bydetection model. [sent-42, score-0.262]
</p><p>13 Recall that a tracking-by-detection framework will generate detection hypotheses in each frame and then create a chain of associations between them. [sent-43, score-0.532]
</p><p>14 In contrast, our approach, which we call tracking-by-selection, generates a set of path hypotheses instead of detection hypotheses. [sent-44, score-0.764]
</p><p>15 Each path hypothesis is a possible trajectory through time, whereas a detection hypothesis is a possible location at a specific time. [sent-45, score-0.631]
</p><p>16 The critical aspect of trackingby-selection is that it breaks the chain of variables in traditional tracking approaches and replaces it with a single variable (see Figure 1). [sent-46, score-0.31]
</p><p>17 Information from the first frame is no longer linked only to the second frame with path hypotheses an observation in the first frame can be freely compared to observations all along the trajectory. [sent-47, score-1.034]
</p><p>18 Inference in the tracking-by-selection framework amounts to simply selecting a path hypothesis. [sent-49, score-0.426]
</p><p>19 In the case of a single-target tracking problem, inference is trivial: select the most likely path hypothesis for the target. [sent-50, score-0.863]
</p><p>20 In a multi-target tracking application, the model only requires reasoning about the relationships between targets (or body parts, in the case of tracking human poses), so inference involves selecting one path for each object. [sent-51, score-1.227]
</p><p>21 Potentials that are unary and pairwise in our model can only be expressed as higher-order potentials in other models. [sent-55, score-0.405]
</p><p>22 These potentials can enforce consistency in ways that have previously been impossible. [sent-56, score-0.317]
</p><p>23 Because tracking-by-selection is grounded in paths through time and not static locations, each path hypothesis has access to information throughout the entire video. [sent-57, score-0.694]
</p><p>24 The only way for a tracking-by-detection framework to enforce consistency across time is to build a model of the object and use the model as a prior for the remainder of the tracking procedure. [sent-58, score-0.342]
</p><p>25 Many models for tracking human poses that follow the tracking-by-detection framework must be solved with approximate inference algorithms, but the same models can be solved exactly if they are adapted to a tracking-by-selection framework. [sent-61, score-0.634]
</p><p>26 The most obvious drawback to approximate inference is that there is no guarantee that the maximum a posteriori (MAP) solution will be found, but we also show in section 4 that some approaches to approximate inference can limit the performance of a model in more subtle ways. [sent-65, score-0.41]
</p><p>27 Human pose estimation in still images Most contemporary pose estimators are indebted to the pictorial structures model [6], which introduced an efficient and effective way of modeling the relationships between body parts. [sent-69, score-0.331]
</p><p>28 [22] introduces an efficient branch-and-bound algorithm that can find exact solutions to complex models that can only be solved approximately with traditional inference methods. [sent-74, score-0.314]
</p><p>29 Tracking human poses  [10] is one of the first works to attempt a model that enforces both spatial and temporal coherence between human body parts. [sent-77, score-0.353]
</p><p>30 It performs inference in an approximate manner by alternating between spatial and temporal optimizations. [sent-78, score-0.279]
</p><p>31 This follows our reasoning that increased connectivity between observations can improve tracking, but they only add to the spatial connectivity of typical tracking models. [sent-87, score-0.386]
</p><p>32 [17] extend their cascaded pictorial structures framework to pose tracking by adding edges between body parts in time, and further refine their approach in [18]. [sent-89, score-0.447]
</p><p>33 Even though states in each frame are only con-  nected to adjacent frames, the emphasis in [18] is on approximate inference methods, which are required for their sophisticated model. [sent-90, score-0.326]
</p><p>34 [13] shares some similarities with this paper, but each path that it generates for a body part is made by finding the shortest path through a set of detections. [sent-92, score-0.972]
</p><p>35 The path has a standard Markov chain structure, in that it is only capable of enforcing consistency among adjacent frames. [sent-93, score-0.788]
</p><p>36 With our work, however, we are able to select from among a multitude of hypotheses not only a single path that is consistent over the entire video, but also pairs of paths that have consistent image features between them. [sent-94, score-0.988]
</p><p>37 Furthermore, instead of fixing paths one or two at a time, our inference jointly optimizes the selection of paths for all body parts. [sent-95, score-0.565]
</p><p>38 All of the above methods rely upon the temporal Markov assumption, and are only capable of enforcing appearance consistency between adjacent time frames. [sent-96, score-0.353]
</p><p>39 [26] is capable of enforcing global appearance consistency across many frames, but the model is so complex that the trajectories must be built one target at a time, and there are no pairwise dependencies between targets. [sent-104, score-0.357]
</p><p>40 In the first, object hypotheses are generated in a frame, which dramatically reduces the size of the space that must be searched in the second stage, in which associations are built between hypotheses to create smooth tracks. [sent-107, score-0.772]
</p><p>41 The two most important aspects of tracking-by-selection are: (a) global appearance consistency can be enforced without the need for high order potentials, and (b) trackingby-selection uses a model that is much less complex than tracking-by-selection, which makes exact inference feasible. [sent-109, score-0.34]
</p><p>42 ,  (1)  where Ψ(stp) is the unary potential for body part p at time t, Ψ(stp, sqt) is the spatial pairwise potential between parts p and at time t, and Ψ(stp, stp+1) is the temporal pairwise potential between the states of part p at time t and t + 1. [sent-121, score-0.971]
</p><p>43 q 22442266  where Ψ(xp) and Ψ(xp, xq) are the unary and pairwise potentials for path hypotheses for body part p. [sent-132, score-1.289]
</p><p>44 t(Ψ(stp,sqt))  (6)  and  are the average unary and pairwise potential across the the path hypothesis. [sent-142, score-0.816]
</p><p>45 The information that was contained in the temporal edges of a tracking-by-detection model can now be expressed as part of the unary potential of a path hypothesis, and all temporal  edges are eliminated. [sent-151, score-0.875]
</p><p>46 Unary global consistency Tracking-by-selection is capable of expressing global image consistency with a single unary potential. [sent-157, score-0.434]
</p><p>47 For example, the unary potential for a path hypothesis may include the variance of image features along the extent of the path: Ψb(xp) = −var(x1p, . [sent-158, score-0.806]
</p><p>48 , xpT),  (7)  where xtp is an image feature at the path hypothesis of body part p at time t. [sent-161, score-0.625]
</p><p>49 Naively rewarding a low color variance would most strongly support path hypotheses that stay “locked” to a part of the background, this is particularly true in the case of hands, which will naturally have some appearance variation as they move about. [sent-164, score-0.82]
</p><p>50 Basing the motion estimate on  total displacement would reward “jittery” paths, so instead we use the maximum displacement of a path over the course of a video. [sent-166, score-0.594]
</p><p>51 2 ,  (8)  A traditional tracking-by-detection model for human poses is necessarily cyclical and quite complicated, yet it is still unable to replicate these consistency and displacement features without the use of high order potentials, which would have the form Ψ(sp1, sp2, . [sent-171, score-0.3]
</p><p>52 Pairwise global consistency While unary potentials in a tracking-by-selection framework are capable of reasoning about joints over time, pairwise potentials can reason about the space between joints in time. [sent-177, score-0.963]
</p><p>53 For example, if a person has a blue shoulder, a purple elbow, and a yellow armband, we would like to enforce that shoulder and elbow are always blue and purple, and that a point between them is always yellow. [sent-178, score-0.328]
</p><p>54 To accomplish this, we consider the variance of each of N equally-spaced points between path hypotheses:  Ψb(xp,xq) = −? [sent-179, score-0.426]
</p><p>55 (n22p,q)T),  (9)  As with to our unary potential for joint color consistency, we include motion as a feature. [sent-184, score-0.373]
</p><p>56 For this potential, we use the maximum displacement of the path of the “child” joint. [sent-185, score-0.465]
</p><p>57 This means that the motion of the elbow will modify the potential for the upper arm, and the motion of the hand will modify the potential for the lower arm. [sent-186, score-0.548]
</p><p>58 Attempting to incorporate this potential into a chainshaped model would require a potential of order 2T:  Ψ(sp11  ,. [sent-187, score-0.354]
</p><p>59 Generating path hypotheses The successful generation of plausible path hypotheses is clearly of paramount importance. [sent-194, score-1.528]
</p><p>60 It must be possible to generate many path hypotheses quickly, and they must be sufficiently diverse. [sent-195, score-0.826]
</p><p>61 Otherwise, it is possible that no path hypotheses may exist close to the best solution. [sent-196, score-0.764]
</p><p>62 Instead of only building path hypotheses from the first frame forward, we initialize path hypotheses in every frame. [sent-198, score-1.607]
</p><p>63 This helps ensure that some path hypotheses will pass through every image region with a sufficiently strong detector response. [sent-199, score-0.764]
</p><p>64 In each frame, we normalize the single-frame unary potential for each joint into a probability and draw samples from it. [sent-200, score-0.341]
</p><p>65 Each sample represents the initialization of a new  path hypothesis, which is propagated forward and backward in time. [sent-201, score-0.426]
</p><p>66 The equivalent tracking-by-selection model, on the other hand, has only as many pairwise potentials as appear in a single frame of the tracking-by-detection model. [sent-218, score-0.332]
</p><p>67 The remaining “figure eight” model shown in Figure 1(b) can be exactly solved with the junction tree algorithm, but the O(n3) complexity of a straightforward application requires nexcessive memory when using a large number of path hypotheses. [sent-219, score-0.516]
</p><p>68 By  fixing the value of an elbow node, the ‘figure eight” model becomes a tree that can efficiently be solved with max-sum belief propagation. [sent-224, score-0.308]
</p><p>69 The plate in the figure represents the N trees that are generated from each of the N path hypotheses for the elbow joint. [sent-225, score-0.95]
</p><p>70 Message passing is performed once for every possible state of the fixed elbow node, and taking the maximum of the max marginals results in an exact solution. [sent-226, score-0.308]
</p><p>71 by fixing one of the nodes representing the path of an elbow, as shown in Figure 2. [sent-227, score-0.458]
</p><p>72 After the elbow node has been fixed (and therefore becomes an observation instead of a latent variable), the remainder of the model is a tree, and can therefore be efficiently solved with max-sum belief propagation. [sent-229, score-0.27]
</p><p>73 The max marginals resulting from inference on each tree can be directly compared, and the maximum of the max marginals is the solution. [sent-230, score-0.339]
</p><p>74 Inference over a model with 2,000 path hypotheses per joint takes only a couple of seconds in MATLAB when GPUoptimized functions are used. [sent-232, score-0.804]
</p><p>75 Our specific inference method is not unimportant, but instead we wish to emphasize that with tracking-by-selection the final inference procedure is only as complex as a single frame of the tracking-by-detection equivalent. [sent-234, score-0.417]
</p><p>76 Scalability Clearly, a straightforward application of tracking-byselection cannot be used with extremely long videos because a prohibitive number of path hypotheses would be required. [sent-237, score-0.8]
</p><p>77 We use the publicly available code from [18], and replace the single-frame joint hypotheses with path hypotheses to create a tracking-by-selection model. [sent-242, score-1.142]
</p><p>78 The red lines indicate the symmetrical potential between wrists, which only appear in two of the six submodels. [sent-246, score-0.269]
</p><p>79 We take this logic forward one step, and restrict our search to a set of multi-frame path hypotheses. [sent-248, score-0.426]
</p><p>80 [18] shows substantial evidence to support the claim that approximate inference can perform nearly as well as exact inference in some cases. [sent-249, score-0.466]
</p><p>81 [18] decomposes their model into an ensemble of tree-shaped submodels, performs inference on each of the submodels, and constructs a final solution by enforcing consistency between the submodels. [sent-251, score-0.39]
</p><p>82 When dual decomposition is used the final inference is exact, but excessively slow, and long-running inference sessions were terminated before convergence. [sent-252, score-0.338]
</p><p>83 To illustrate this point, we focus on one component of the unary potential for wrists. [sent-256, score-0.301]
</p><p>84 The magnitude of the response is used as a feature in the unary potential for wrists. [sent-259, score-0.301]
</p><p>85 The first is to only lightly weight the flow-based feature, and the other is to have a symmetrical repulsion potential between the two hands. [sent-264, score-0.369]
</p><p>86 To demonstrate the advantage of learning on a complete model, we re-learned parameters for the flow-based wrist feature and the symmetrical wrist potential using exact inference on our model. [sent-271, score-0.815]
</p><p>87 Because only a few model parameters needed to be learned (the unary and pairwise consistency potentials from section 3. [sent-276, score-0.519]
</p><p>88 2, the flow-based wrist feature, and the symmetrical wrist potential), training was conducted with a simple grid search over possible parameter values. [sent-278, score-0.44]
</p><p>89 For these results, 1000 path hypotheses were used for each shoulder, and 2000 path  hypotheses were used for each elbow and wrist. [sent-300, score-1.714]
</p><p>90 0 dataset, the motion of the elbows is much less significant than that of the hands, so enforcing spatio-temporal consistency will have less effect. [sent-305, score-0.298]
</p><p>91 Remember, however, that the generation of path hypotheses is stochastic. [sent-310, score-0.764]
</p><p>92 This means that one of the many path hypotheses may not be significantly affected by a brief occlusion. [sent-311, score-0.764]
</p><p>93 Testing path hypotheses Reducing the search space in a tracking problem to a relatively small set of paths is potentially troubling. [sent-314, score-1.075]
</p><p>94 After all, the solution in a tracking-by-selection framework can only be as good as the path hypotheses. [sent-315, score-0.426]
</p><p>95 To asses the quality of path hypotheses and estimate the performance ceiling of tracking-by-selection, Figure 6 shows experimental results for paths that have been selected by an oracle. [sent-316, score-0.886]
</p><p>96 It can be seen that even with only 100 paths per body joint to choose from, a solution exists that is very close to the ground truth. [sent-318, score-0.282]
</p><p>97 Results showing performance with an oracle selecting the best path with a varying number of random path hypotheses. [sent-320, score-0.852]
</p><p>98 Conclusions We have presented tracking-by-selection, a new framework for tracking human poses in video. [sent-334, score-0.298]
</p><p>99 By reasoning about path hypotheses instead of single-frame state hypotheses, racking-by-selection is capable of enforcing global consistency in ways that are intractable in traditional chain-shaped tracking-by-detection frameworks. [sent-335, score-1.163]
</p><p>100 We show that converting a human pose tracking system to a trackingby-selection model results in improved performance on challenging tracking problems. [sent-336, score-0.501]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('path', 0.426), ('hypotheses', 0.338), ('tracking', 0.189), ('elbow', 0.186), ('submodels', 0.175), ('inference', 0.169), ('potentials', 0.164), ('wrist', 0.16), ('xp', 0.159), ('unary', 0.152), ('potential', 0.149), ('paths', 0.122), ('body', 0.12), ('stp', 0.12), ('symmetrical', 0.12), ('consistency', 0.114), ('repulsion', 0.1), ('wrists', 0.1), ('xq', 0.09), ('pairwise', 0.089), ('articulated', 0.087), ('reasoning', 0.084), ('elbows', 0.083), ('chain', 0.083), ('frame', 0.079), ('hypothesis', 0.079), ('temporal', 0.074), ('conference', 0.073), ('pose', 0.073), ('shoulder', 0.072), ('joints', 0.071), ('enforcing', 0.069), ('marginals', 0.065), ('pictorial', 0.065), ('poses', 0.059), ('reward', 0.058), ('exact', 0.057), ('chainshaped', 0.056), ('rewarding', 0.056), ('sptt', 0.056), ('submodel', 0.056), ('sapp', 0.056), ('hands', 0.055), ('capable', 0.054), ('wongun', 0.05), ('solved', 0.05), ('human', 0.05), ('people', 0.049), ('trajectory', 0.047), ('collapsed', 0.046), ('markovian', 0.046), ('oak', 0.046), ('dynamical', 0.044), ('markov', 0.043), ('andriluka', 0.042), ('adjacent', 0.042), ('double', 0.042), ('joint', 0.04), ('tree', 0.04), ('intractable', 0.04), ('connectivity', 0.04), ('alternate', 0.04), ('enforce', 0.039), ('displacement', 0.039), ('video', 0.039), ('ensemble', 0.038), ('international', 0.038), ('traditional', 0.038), ('counting', 0.038), ('cycles', 0.037), ('limb', 0.037), ('tracklets', 0.037), ('pages', 0.037), ('videos', 0.036), ('berlin', 0.036), ('assistance', 0.036), ('nec', 0.036), ('approximate', 0.036), ('evidence', 0.035), ('loopy', 0.035), ('pb', 0.035), ('ieee', 0.035), ('id', 0.035), ('consistent', 0.034), ('node', 0.034), ('detections', 0.034), ('entire', 0.034), ('grounded', 0.033), ('optical', 0.033), ('observations', 0.033), ('dramatically', 0.033), ('silhouette', 0.033), ('motion', 0.032), ('pa', 0.032), ('associations', 0.032), ('fixing', 0.032), ('transition', 0.032), ('must', 0.031), ('promote', 0.031), ('purple', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="65-tfidf-1" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>2 0.29169032 <a title="65-tfidf-2" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>Author: Susanna Ricco, Carlo Tomasi</p><p>Abstract: Dense motion of image points over many video frames can provide important information about the world. However, occlusions and drift make it impossible to compute long motionpaths by merely concatenating opticalflow vectors between consecutive frames. Instead, we solve for entire paths directly, and flag the frames in which each is visible. As in previous work, we anchor each path to a unique pixel which guarantees an even spatial distribution of paths. Unlike earlier methods, we allow paths to be anchored in any frame. By explicitly requiring that at least one visible path passes within a small neighborhood of every pixel, we guarantee complete coverage of all visible points in all frames. We achieve state-of-the-art results on real sequences including both rigid and non-rigid motions with significant occlusions.</p><p>3 0.20208904 <a title="65-tfidf-3" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>Author: Min Sun, Wan Huang, Silvio Savarese</p><p>Abstract: Many methods have been proposed to solve the image classification problem for a large number of categories. Among them, methods based on tree-based representations achieve good trade-off between accuracy and test time efficiency. While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. In this work, we propose a classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy. First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. As a result, our method achieves a significant 4.65%, 5.43%, and 4.07% (relative 24.82%, 41.64%, and 109.79%) improvement in accuracy at high efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. 8) so that users can further process them.</p><p>4 0.17511089 <a title="65-tfidf-4" href="./iccv-2013-Strong_Appearance_and_Expressive_Spatial_Models_for_Human_Pose_Estimation.html">403 iccv-2013-Strong Appearance and Expressive Spatial Models for Human Pose Estimation</a></p>
<p>Author: Leonid Pishchulin, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele</p><p>Abstract: Typical approaches to articulated pose estimation combine spatial modelling of the human body with appearance modelling of body parts. This paper aims to push the state-of-the-art in articulated pose estimation in two ways. First we explore various types of appearance representations aiming to substantially improve the bodypart hypotheses. And second, we draw on and combine several recently proposed powerful ideas such as more flexible spatial models as well as image-conditioned spatial models. In a series of experiments we draw several important conclusions: (1) we show that the proposed appearance representations are complementary; (2) we demonstrate that even a basic tree-structure spatial human body model achieves state-ofthe-art performance when augmented with the proper appearance representation; and (3) we show that the combination of the best performing appearance model with a flexible image-conditioned spatial model achieves the best result, significantly improving over the state of the art, on the “Leeds Sports Poses ” and “Parse ” benchmarks.</p><p>5 0.16544321 <a title="65-tfidf-5" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>Author: Jan Stühmer, Peter Schröder, Daniel Cremers</p><p>Abstract: We propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph, in this case a geodesic shortest path tree. Specifically we make two contributions: First, we construct a geodesic shortest path tree with a distance measure that is related to the image data and the bending energy of each path in the tree. Second, we include a connectivity prior in our segmentation model, that allows to segment not only a single elongated structure, but instead a whole connected branching tree. Because both our segmentation model and the connectivity constraint are convex, a global optimal solution can be found. To this end, we generalize a recent primal-dual algorithm for continuous convex optimization to an arbitrary graph structure. To validate our method we present results on data from medical imaging in angiography and retinal blood vessel segmentation.</p><p>6 0.16488336 <a title="65-tfidf-6" href="./iccv-2013-Estimating_Human_Pose_with_Flowing_Puppets.html">143 iccv-2013-Estimating Human Pose with Flowing Puppets</a></p>
<p>7 0.15589763 <a title="65-tfidf-7" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>8 0.15395571 <a title="65-tfidf-8" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>9 0.15117839 <a title="65-tfidf-9" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>10 0.14584202 <a title="65-tfidf-10" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>11 0.14414605 <a title="65-tfidf-11" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>12 0.14013487 <a title="65-tfidf-12" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>13 0.13610734 <a title="65-tfidf-13" href="./iccv-2013-A_Non-parametric_Bayesian_Network_Prior_of_Human_Pose.html">24 iccv-2013-A Non-parametric Bayesian Network Prior of Human Pose</a></p>
<p>14 0.13301441 <a title="65-tfidf-14" href="./iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</a></p>
<p>15 0.12868868 <a title="65-tfidf-15" href="./iccv-2013-Monocular_Image_3D_Human_Pose_Estimation_under_Self-Occlusion.html">273 iccv-2013-Monocular Image 3D Human Pose Estimation under Self-Occlusion</a></p>
<p>16 0.12846152 <a title="65-tfidf-16" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>17 0.12594281 <a title="65-tfidf-17" href="./iccv-2013-Pose_Estimation_and_Segmentation_of_People_in_3D_Movies.html">322 iccv-2013-Pose Estimation and Segmentation of People in 3D Movies</a></p>
<p>18 0.12503614 <a title="65-tfidf-18" href="./iccv-2013-Allocentric_Pose_Estimation.html">46 iccv-2013-Allocentric Pose Estimation</a></p>
<p>19 0.12299445 <a title="65-tfidf-19" href="./iccv-2013-Holistic_Scene_Understanding_for_3D_Object_Detection_with_RGBD_Cameras.html">201 iccv-2013-Holistic Scene Understanding for 3D Object Detection with RGBD Cameras</a></p>
<p>20 0.12121655 <a title="65-tfidf-20" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.273), (1, -0.061), (2, 0.036), (3, 0.098), (4, 0.123), (5, -0.039), (6, -0.076), (7, 0.129), (8, -0.046), (9, 0.056), (10, -0.058), (11, -0.012), (12, -0.055), (13, 0.066), (14, 0.015), (15, 0.175), (16, -0.041), (17, -0.12), (18, -0.05), (19, 0.041), (20, 0.004), (21, -0.067), (22, 0.145), (23, -0.071), (24, -0.027), (25, -0.086), (26, 0.011), (27, -0.127), (28, 0.018), (29, -0.047), (30, -0.061), (31, -0.055), (32, 0.004), (33, -0.104), (34, 0.121), (35, 0.021), (36, -0.021), (37, -0.026), (38, 0.152), (39, -0.05), (40, -0.029), (41, 0.026), (42, 0.2), (43, 0.125), (44, 0.025), (45, -0.113), (46, 0.068), (47, -0.0), (48, 0.042), (49, -0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95821893 <a title="65-lsi-1" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>2 0.7994917 <a title="65-lsi-2" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>Author: Susanna Ricco, Carlo Tomasi</p><p>Abstract: Dense motion of image points over many video frames can provide important information about the world. However, occlusions and drift make it impossible to compute long motionpaths by merely concatenating opticalflow vectors between consecutive frames. Instead, we solve for entire paths directly, and flag the frames in which each is visible. As in previous work, we anchor each path to a unique pixel which guarantees an even spatial distribution of paths. Unlike earlier methods, we allow paths to be anchored in any frame. By explicitly requiring that at least one visible path passes within a small neighborhood of every pixel, we guarantee complete coverage of all visible points in all frames. We achieve state-of-the-art results on real sequences including both rigid and non-rigid motions with significant occlusions.</p><p>3 0.61006045 <a title="65-lsi-3" href="./iccv-2013-Estimating_Human_Pose_with_Flowing_Puppets.html">143 iccv-2013-Estimating Human Pose with Flowing Puppets</a></p>
<p>Author: Silvia Zuffi, Javier Romero, Cordelia Schmid, Michael J. Black</p><p>Abstract: We address the problem of upper-body human pose estimation in uncontrolled monocular video sequences, without manual initialization. Most current methods focus on isolated video frames and often fail to correctly localize arms and hands. Inferring pose over a video sequence is advantageous because poses of people in adjacent frames exhibit properties of smooth variation due to the nature of human and camera motion. To exploit this, previous methods have used prior knowledge about distinctive actions or generic temporal priors combined with static image likelihoods to track people in motion. Here we take a different approach based on a simple observation: Information about how a person moves from frame to frame is present in the optical flow field. We develop an approach for tracking articulated motions that “links” articulated shape models of peo- ple in adjacent frames through the dense optical flow. Key to this approach is a 2D shape model of the body that we use to compute how the body moves over time. The resulting “flowing puppets ” provide a way of integrating image evidence across frames to improve pose inference. We apply our method on a challenging dataset of TV video sequences and show state-of-the-art performance.</p><p>4 0.58811706 <a title="65-lsi-4" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>Author: Min Sun, Wan Huang, Silvio Savarese</p><p>Abstract: Many methods have been proposed to solve the image classification problem for a large number of categories. Among them, methods based on tree-based representations achieve good trade-off between accuracy and test time efficiency. While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. In this work, we propose a classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy. First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. As a result, our method achieves a significant 4.65%, 5.43%, and 4.07% (relative 24.82%, 41.64%, and 109.79%) improvement in accuracy at high efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. 8) so that users can further process them.</p><p>5 0.58203757 <a title="65-lsi-5" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>Author: Jan Stühmer, Peter Schröder, Daniel Cremers</p><p>Abstract: We propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph, in this case a geodesic shortest path tree. Specifically we make two contributions: First, we construct a geodesic shortest path tree with a distance measure that is related to the image data and the bending energy of each path in the tree. Second, we include a connectivity prior in our segmentation model, that allows to segment not only a single elongated structure, but instead a whole connected branching tree. Because both our segmentation model and the connectivity constraint are convex, a global optimal solution can be found. To this end, we generalize a recent primal-dual algorithm for continuous convex optimization to an arbitrary graph structure. To validate our method we present results on data from medical imaging in angiography and retinal blood vessel segmentation.</p><p>6 0.57370675 <a title="65-lsi-6" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>7 0.56247634 <a title="65-lsi-7" href="./iccv-2013-Monte_Carlo_Tree_Search_for_Scheduling_Activity_Recognition.html">274 iccv-2013-Monte Carlo Tree Search for Scheduling Activity Recognition</a></p>
<p>8 0.54735005 <a title="65-lsi-8" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<p>9 0.54534322 <a title="65-lsi-9" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>10 0.54373294 <a title="65-lsi-10" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>11 0.5417642 <a title="65-lsi-11" href="./iccv-2013-A_Non-parametric_Bayesian_Network_Prior_of_Human_Pose.html">24 iccv-2013-A Non-parametric Bayesian Network Prior of Human Pose</a></p>
<p>12 0.5414567 <a title="65-lsi-12" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>13 0.53244871 <a title="65-lsi-13" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>14 0.52422416 <a title="65-lsi-14" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>15 0.51281983 <a title="65-lsi-15" href="./iccv-2013-Parallel_Transport_of_Deformations_in_Shape_Space_of_Elastic_Surfaces.html">307 iccv-2013-Parallel Transport of Deformations in Shape Space of Elastic Surfaces</a></p>
<p>16 0.50436807 <a title="65-lsi-16" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>17 0.49316561 <a title="65-lsi-17" href="./iccv-2013-Strong_Appearance_and_Expressive_Spatial_Models_for_Human_Pose_Estimation.html">403 iccv-2013-Strong Appearance and Expressive Spatial Models for Human Pose Estimation</a></p>
<p>18 0.49284428 <a title="65-lsi-18" href="./iccv-2013-A_Deformable_Mixture_Parsing_Model_with_Parselets.html">8 iccv-2013-A Deformable Mixture Parsing Model with Parselets</a></p>
<p>19 0.48580119 <a title="65-lsi-19" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>20 0.48111519 <a title="65-lsi-20" href="./iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.082), (7, 0.024), (12, 0.02), (26, 0.093), (31, 0.047), (34, 0.025), (35, 0.029), (42, 0.125), (58, 0.076), (64, 0.106), (73, 0.033), (89, 0.204), (98, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95627296 <a title="65-lda-1" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>Author: João F. Henriques, João Carreira, Rui Caseiro, Jorge Batista</p><p>Abstract: Competitive sliding window detectors require vast training sets. Since a pool of natural images provides a nearly endless supply of negative samples, in the form of patches at different scales and locations, training with all the available data is considered impractical. A staple of current approaches is hard negative mining, a method of selecting relevant samples, which is nevertheless expensive. Given that samples at slightly different locations have overlapping support, there seems to be an enormous amount of duplicated work. It is natural, then, to ask whether these redundancies can be eliminated. In this paper, we show that the Gram matrix describing such data is block-circulant. We derive a transformation based on the Fourier transform that block-diagonalizes the Gram matrix, at once eliminating redundancies and partitioning the learning problem. This decomposition is valid for any dense features and several learning algorithms, and takes full advantage of modern parallel architectures. Surprisingly, it allows training with all the potential samples in sets of thousands of images. By considering the full set, we generate in a single shot the optimal solution, which is usually obtained only after several rounds of hard negative mining. We report speed gains on Caltech Pedestrians and INRIA Pedestrians of over an order of magnitude, allowing training on a desktop computer in a couple of minutes.</p><p>same-paper 2 0.94990802 <a title="65-lda-2" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>3 0.94682389 <a title="65-lda-3" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>Author: Junliang Xing, Jin Gao, Bing Li, Weiming Hu, Shuicheng Yan</p><p>Abstract: Recently, sparse representation has been introduced for robust object tracking. By representing the object sparsely, i.e., using only a few templates via ?1-norm minimization, these so-called ?1-trackers exhibit promising tracking results. In this work, we address the object template building and updating problem in these ?1-tracking approaches, which has not been fully studied. We propose to perform template updating, in a new perspective, as an online incremental dictionary learning problem, which is efficiently solved through an online optimization procedure. To guarantee the robustness and adaptability of the tracking algorithm, we also propose to build a multi-lifespan dictionary model. By building target dictionaries of different lifespans, effective object observations can be obtained to deal with the well-known drifting problem in tracking and thus improve the tracking accuracy. We derive effective observa- tion models both generatively and discriminatively based on the online multi-lifespan dictionary learning model and deploy them to the Bayesian sequential estimation framework to perform tracking. The proposed approach has been extensively evaluated on ten challenging video sequences. Experimental results demonstrate the effectiveness of the online learned templates, as well as the state-of-the-art tracking performance of the proposed approach.</p><p>4 0.94643068 <a title="65-lda-4" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>Author: Qinxun Bai, Zheng Wu, Stan Sclaroff, Margrit Betke, Camille Monnier</p><p>Abstract: We propose a randomized ensemble algorithm to model the time-varying appearance of an object for visual tracking. In contrast with previous online methods for updating classifier ensembles in tracking-by-detection, the weight vector that combines weak classifiers is treated as a random variable and the posterior distribution for the weight vector is estimated in a Bayesian manner. In essence, the weight vector is treated as a distribution that reflects the confidence among the weak classifiers used to construct and adapt the classifier ensemble. The resulting formulation models the time-varying discriminative ability among weak classifiers so that the ensembled strong classifier can adapt to the varying appearance, backgrounds, and occlusions. The formulation is tested in a tracking-by-detection implementation. Experiments on 28 challenging benchmark videos demonstrate that the proposed method can achieve results comparable to and often better than those of stateof-the-art approaches.</p><p>5 0.94316679 <a title="65-lda-5" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>Author: Fuxin Li, Taeyoung Kim, Ahmad Humayun, David Tsai, James M. Rehg</p><p>Abstract: We propose an unsupervised video segmentation approach by simultaneously tracking multiple holistic figureground segments. Segment tracks are initialized from a pool of segment proposals generated from a figure-ground segmentation algorithm. Then, online non-local appearance models are trained incrementally for each track using a multi-output regularized least squares formulation. By using the same set of training examples for all segment tracks, a computational trick allows us to track hundreds of segment tracks efficiently, as well as perform optimal online updates in closed-form. Besides, a new composite statistical inference approach is proposed for refining the obtained segment tracks, which breaks down the initial segment proposals and recombines for better ones by utilizing highorder statistic estimates from the appearance model and enforcing temporal consistency. For evaluating the algorithm, a dataset, SegTrack v2, is collected with about 1,000 frames with pixel-level annotations. The proposed framework outperforms state-of-the-art approaches in the dataset, show- ing its efficiency and robustness to challenges in different video sequences.</p><p>6 0.94047904 <a title="65-lda-6" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>7 0.93972689 <a title="65-lda-7" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>8 0.93885905 <a title="65-lda-8" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>9 0.93804562 <a title="65-lda-9" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>10 0.93718761 <a title="65-lda-10" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>11 0.93637717 <a title="65-lda-11" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>12 0.9361403 <a title="65-lda-12" href="./iccv-2013-Semantic_Transform%3A_Weakly_Supervised_Semantic_Inference_for_Relating_Visual_Attributes.html">380 iccv-2013-Semantic Transform: Weakly Supervised Semantic Inference for Relating Visual Attributes</a></p>
<p>13 0.93592477 <a title="65-lda-13" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>14 0.93574369 <a title="65-lda-14" href="./iccv-2013-Real-Time_Articulated_Hand_Pose_Estimation_Using_Semi-supervised_Transductive_Regression_Forests.html">340 iccv-2013-Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests</a></p>
<p>15 0.93474096 <a title="65-lda-15" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>16 0.93461347 <a title="65-lda-16" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>17 0.93412995 <a title="65-lda-17" href="./iccv-2013-Active_Learning_of_an_Action_Detector_from_Untrimmed_Videos.html">41 iccv-2013-Active Learning of an Action Detector from Untrimmed Videos</a></p>
<p>18 0.93293989 <a title="65-lda-18" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>19 0.93263757 <a title="65-lda-19" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>20 0.93236876 <a title="65-lda-20" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
