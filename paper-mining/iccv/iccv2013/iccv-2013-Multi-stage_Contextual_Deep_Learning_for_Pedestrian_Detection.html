<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-279" href="#">iccv2013-279</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</h1>
<br/><p>Source: <a title="iccv-2013-279-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zeng_Multi-stage_Contextual_Deep_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>Reference: <a title="iccv-2013-279-reference" href="../iccv2013_reference/iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 hk  Abstract Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. [sent-4, score-0.368]
</p><p>2 In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. [sent-6, score-0.841]
</p><p>3 It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. [sent-7, score-0.41]
</p><p>4 Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. [sent-8, score-1.255]
</p><p>5 Due to various challenges, such as variations of views, poses, lightings and occlusions, pedestrian detection is difficult and unlikely to be well solved with one simple holistic classifier. [sent-15, score-0.368]
</p><p>6 For example, the visual cue of a pedestrian with a side view is different from that with a frontal view. [sent-16, score-0.288]
</p><p>7 In order to handle the complex appearance variation of pedestrians, many approaches choose a group 1Cascading means concatenation of multiple classifiers and the output of a classifier is used as additional input to the next classifier in the cascade. [sent-18, score-0.333]
</p><p>8 Specifically in detection literature, cascaded classifiers often indicate early rejecting samples. [sent-19, score-0.516]
</p><p>9 Our proposed deep model cascades classifiers but does not early rejects samples. [sent-20, score-0.761]
</p><p>10 This architecture can deal with complex distributed samples using multiple stages of classifiers. [sent-24, score-0.255]
</p><p>11 of classifiers to make the pedestrian versus non-pedestrian decision stage by stage [49, 2]. [sent-26, score-0.875]
</p><p>12 Different classifiers take care of different portions of samples. [sent-27, score-0.221]
</p><p>13 Hard samples which cannot be well classified at early stages are used to train classifiers at later stages. [sent-29, score-0.487]
</p><p>14 Moreover, although early classifiers cannot make final decisions on hard samples, their output provides contextual information to support decisions at later stages. [sent-31, score-0.481]
</p><p>15 However, with too many parameters and relatively few training samples, the classifiers easily overfit training data. [sent-32, score-0.435]
</p><p>16 To jointly train a large number of classification parameters, we propose a deep model that can learn these classifiers together and keep the training process from overfitting in the meanwhile. [sent-33, score-0.85]
</p><p>17 Figure 1 shows its architecture, in which the outputs of classifiers are represented as hidden nodes in each layer. [sent-34, score-0.316]
</p><p>18 Each layer takes images features and the output of its previ121  ous layer as input, then outputs new decision scores. [sent-35, score-0.26]
</p><p>19 The contribution of this paper is four-folds: • The group ofclassifiers in the deep model choose training samples stage by stage. [sent-36, score-0.778]
</p><p>20 Due to the design of our training procedure, the gradients of classifier parameters at the current stage are mainly influenced by the samples misclassified by the classifiers at the previous stages. [sent-38, score-0.77]
</p><p>21 At each BP stage, the whole deep model has been initialized with a good starting point learned at the previous stage and the additional classifiers focus on the misclassified hard samples. [sent-39, score-1.051]
</p><p>22 •  The group of classifiers are jointly optimized. [sent-40, score-0.272]
</p><p>23 At each BThPe stage, pc olafs cslifaiessrsif iaetr tsh aer previous stages jointly w eaocrhk  with the classifier at the current stage in dealing with misclassified samples. [sent-41, score-0.5]
</p><p>24 eB aoth tr unsupervised pre-training pasnd to specifically designed stage-wise supervised training are used to regularize the optimization problem. [sent-43, score-0.204]
</p><p>25 With standard BP, an easy training sample can influence classifiers at any stage, since these stages are not distinguished or separately trained. [sent-45, score-0.394]
</p><p>26 Existing cascaded classifiers only pass a single score to tEhxei sntienxgt stage, wedh cil ae our deep lmy opdasesl keeps teh sec score map within a local region and it serves as contextual information to support the decision at the next stage. [sent-47, score-1.296]
</p><p>27 Most approaches consider pedestrian detection as a clas-  sification task by scanning an image with sliding windows whose sizes are changeable. [sent-53, score-0.368]
</p><p>28 The discriminative classifiers, such as boosting classifiers [49, 12, 55, 10, 11, 15] and SVM [24, 56, 36, 24, 56], seek for parameters to separate positive and negative samples. [sent-56, score-0.221]
</p><p>29 This model is then extended to cascaded classifiers in [23] to boost the computational speed. [sent-59, score-0.431]
</p><p>30 Mixture models train classifiers through supervised or unsupervised clustering. [sent-62, score-0.365]
</p><p>31 Differently, cascaded classifiers are trained with misclassified training samples stage by stage. [sent-63, score-0.916]
</p><p>32 Cascaded classifiers have two advantages: (1) they can provide piecewise linear classification hyperplanes, and (2) they help to save the computational load of sliding window object detection. [sent-64, score-0.26]
</p><p>33 While the cascade structure has worked well in many fields, the hard thresholding for each cascaded classifier discards a lot of information collected at each stage classifier. [sent-66, score-0.506]
</p><p>34 To avoid such disadvantages, recent detection approaches have used soft cascade  ×  [3, 10, 2, 9, 12], which collects the classification scores extracted by each stage of classifiers and then combines the classification scores for the final decision. [sent-67, score-0.616]
</p><p>35 However, soft cascade still learns the classifiers stage by stage without joint optimization. [sent-68, score-0.63]
</p><p>36 Classifiers at different stages cannot cooperate with each other in the training procedure. [sent-69, score-0.216]
</p><p>37 Recently, deep models have been successfully applied in hand written digit recognition [27, 26, 3 1, 37], object segmentation [34, 35], face recognition [5, 47, 57], scene understanding [43, 21], object detection [40] [41] [38] [39] and recognition [28, 30, 29, 46, 25]. [sent-70, score-0.576]
</p><p>38 [46] unsupervised learned multi-stage features with a deep model. [sent-72, score-0.538]
</p><p>39 However, they did not add an extra classifier at each stage and classification scores were not passed between stages as contextual information. [sent-73, score-0.531]
</p><p>40 However, the connection between deep models and multi-stage classifiers is unknown. [sent-76, score-0.677]
</p><p>41 This paper is complementary to the recent deep models in that we have built the connection between deep models and multi-stage classifiers, such that the cascaded classifiers can be jointly optimized. [sent-77, score-1.36]
</p><p>42 Extensive experiments in [5 1, 9] show that CSS consistently improves pedestrian detection performance. [sent-106, score-0.368]
</p><p>43 In order to make use of contextual information in local regions, detection scores in a 3 3 spatial local region of  ×× ×  r1e e1g pyramids are nus sedco irne our deep ×m 3od speal. [sent-129, score-0.856]
</p><p>44 Siailnc loec a pedestrian window contains 15 5 36 features, the 3 3 detection scores wfo cro a specific pyramid 6is f oeabttuariense,d t by filtering ttehcet ilooncal 17 7 36 feature pyramid with 15 5 36 filters. [sent-130, score-0.475]
</p><p>45 The whole architecture is built on the feature maps introduced in Section 3. [sent-137, score-0.207]
</p><p>46 We apply different filters Fi on the same feature map f and obtain different score maps si. [sent-139, score-0.252]
</p><p>47 In this figure, the number of hidden layers is 2 and 3 classifiers are used. [sent-140, score-0.322]
</p><p>48 For the sake of convenience, we regard the input layer score map s0 as h0. [sent-141, score-0.287]
</p><p>49 The contextual score map is used in our paper, but not used in [9]. [sent-143, score-0.324]
</p><p>50 The deep architecture for inference Figure 4 shows our proposed deep model. [sent-146, score-1.022]
</p><p>51 •  (∀ i ≤ L) is the score maps at layer i, which repsresen(t∀ th ie ≤ scores othfe th sceo corresponding rcl ai,ss wihfieicr. [sent-150, score-0.277]
</p><p>52 •  •  Fi+1 is the classifier at layer iused to filter the feature map and obtain the score map si+1 . [sent-157, score-0.385]
</p><p>53 Ws,i is the weights to connect score map si and hidden nWodes hi. [sent-159, score-0.241]
</p><p>54 yA mt tuhltei pinleference stage, classifier Fi+1 filters the feature map f and outputs the score map si+1 : •  si+1  =  1 + e−1Fi+1⊗f,  (2)  where ⊗ denotes the filtering operation. [sent-164, score-0.319]
</p><p>55 F0 is fixed and s0  is used as the contextual detection score information. [sent-167, score-0.357]
</p><p>56 2, si and hi−1 are fully connected to the hidden nodes in hi and we have h1  hi+1  =  =  1 + e−(Wh,11s0+Ws,1s1), 1 + e−(Wh,i+11hi+Ws,i+1si+1),∀i  (3)  ≤ L − 1(4)  Finally, the probability of a window containing a pedestrian is obtained as follows: y  =  1 + e−(Wh,L+1h1L+Ws,L+1sL+1). [sent-169, score-0.519]
</p><p>57 Stage-by-stage training of the deep model The training procedure is summarized in Algorithm 1. [sent-172, score-0.638]
</p><p>58 The deep model is first trained by excluding additional classifiers at all the layers to reach a good initialization point. [sent-174, score-0.767]
</p><p>59 At each stage t, all the existing classifiers up to layer t are jointly optimized. [sent-177, score-0.555]
</p><p>60 1 (1 and 2 in Algorithm 1): the layer-by-layer unsupervised pre-training approach tihne [2 la6y]e ir-sb uys-leady etor train the hidden-to-hidden transfer matrices Wh,i+1 . [sent-180, score-0.22]
</p><p>61 1 Set elements in Ws,i+1 and Fi+1 to be 0; 2 Unsupervised pretrain all transfer matrices Wh,i+1 ; 3 BP to fine tune all the transfer matrices Wh,i+1, while keeping Ws,i+1 and Fi+1 as 0; 4 Randomly initialize Fi+1 ; 5 for t=0 to L do  6 7 8  tU,s ie. [sent-197, score-0.283]
</p><p>62 2 (5-7 in Algorithm 1): cascaded filters Fi+1 for iS e=p 0, . [sent-204, score-0.225]
</p><p>63 In  stage t, classifiers Fi+1 and weights Ws,i+1 (∀ i≤ t) up to layer t are jointly updated. [sent-208, score-0.555]
</p><p>64 1  Analysis on Step 1  Since Ws,i is set to 0, step 1can be considered as training a deep belief net (DBN) [26] with input s0, hidden nodes hi, and label y. [sent-213, score-0.67]
</p><p>65 In this step, the DBN uses the contextual score map obtained by linear SVM as input for classifying samples. [sent-217, score-0.324]
</p><p>66 Therefore, a correctly classified sample at the previous stage does not influence the update of parameters. [sent-241, score-0.266]
</p><p>67 Therefore, with our training strategy, a new classifier is introduced at each stage to help deal with misclassified samples while the correctly classified samples have no influence on the new classifier. [sent-244, score-0.682]
</p><p>68 2, such that these classifiers can better cooperate with each other. [sent-252, score-0.264]
</p><p>69 Third, the deep model retains the contextual information of features and detection scores. [sent-253, score-0.724]
</p><p>70 The convolutional classifiers Fi use contextual features (which cover larger regions around the pedestrian with pyramids) for obtaining  the score map. [sent-254, score-0.863]
</p><p>71 The score map is the second level of contextual information, and we pass the distributions of scores in local regions to the next hidden layer. [sent-255, score-0.426]
</p><p>72 When a detection window is rejected at an early cascade stage, its features and its detection scores are not available at the next stage. [sent-258, score-0.348]
</p><p>73 We pretrain transfer matrices Wh,i first in an unsupervised way, which has been proved to provide better generalization capability [19]. [sent-261, score-0.286]
</p><p>74 At each stage, the whole network is initialized with a good point reached by previous training strategies and the additional filters deal with misclassified hard samples. [sent-265, score-0.46]
</p><p>75 Training samples will not be assigned to different classifiers according to their difficulty levels. [sent-268, score-0.284]
</p><p>76 The score map in each layer is generated in a 3 3 window and we combine 11 pyramids ewniethra ttehed m inax aim 3u×m3 score aligned wtoe b ceo mtheb icneent 1e1r of score map. [sent-274, score-0.563]
</p><p>77 Linear SVMs are used in [6, 52], kernel SVM is used in [36], and cascade classifiers are used in [50, 11, 12, 10, 9]. [sent-293, score-0.294]
</p><p>78 Contextual Boost uses cascaded classifiers but it does not optimize the classifiers jointly. [sent-296, score-0.618]
</p><p>79 2 Performance on ETHZ Figure 6 shows the experimental results on the ETHZ pedestrian dataset. [sent-302, score-0.288]
</p><p>80 As most approaches are trained on the INRIA training dataset and test on this dataset, our proposed deep model is also trained on the INIRA training dataset. [sent-303, score-0.746]
</p><p>81 ContDeepNet is our proposed multi-stage contextual deep model trained on the Caltech training dataset. [sent-307, score-0.789]
</p><p>82 ConvNet-U-MS used a deep model to learn low-level features. [sent-312, score-0.456]
</p><p>83 But it does not employ contextual score maps or multi-stage classifiers. [sent-313, score-0.313]
</p><p>84 3  Performance on TUD-Brussels  Figure 7 shows the experimental results on the TUDBrussels pedestrian dataset. [sent-316, score-0.288]
</p><p>85 We compare the performance of two 3-layer deep networks. [sent-325, score-0.456]
</p><p>86 Comparison of different deep architectures on the Caltech Test dataset. [sent-331, score-0.505]
</p><p>87 9 shows the detection samples that are correctly classified by ContDeepNet but misclassified by DeepNetNoFilter. [sent-337, score-0.384]
</p><p>88 They are selected from the 300 detection samples of the two approaches with the highest detection scores. [sent-338, score-0.223]
</p><p>89 The additional classifiers help our deep model on handling hard samples. [sent-339, score-0.71]
</p><p>90 For example, the false positives of bus light, tyre, and trunk are correctly rejected and the false negatives of pedestrians with side view, blurring effect, occlusions and riding bicy-  cles, are correctly detected. [sent-340, score-0.224]
</p><p>91 Results are obtained from the 300 detection samples of the two approaches with the highest detection scores. [sent-347, score-0.223]
</p><p>92 Results of the same architecture as our ContDeepNet but with different training strategies on the Caltech test  dataset. [sent-350, score-0.241]
</p><p>93 PretrainTransferMatrix-BP means the transfer matrices are unsupervised pretrained, and then all the parameters of the network are fine-tuned with BP. [sent-352, score-0.263]
</p><p>94 The second algorithm, denoted by PretrainTransferMatrix-BP, adopts the method introduced in [26] to unsupervised pretrain all the transfer matrices and then uses BP to fine tune the whole network. [sent-355, score-0.288]
</p><p>95 Our proposed training strategy (Multi-Stage) has the same unsupervised pretraining procedure. [sent-356, score-0.279]
</p><p>96 Conclusion In this paper, we propose a new multi-stage contextual deep model and specially designed training strategies for pedestrian detection. [sent-360, score-1.063]
</p><p>97 Contextual information from pyramids of feature maps and score maps propagate through the cascade. [sent-362, score-0.287]
</p><p>98 All the classifiers in the deep model are jointly trained through multiple stages of back-propagation. [sent-363, score-0.864]
</p><p>99 Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. [sent-592, score-0.566]
</p><p>100 A discriminative deep model for pedestrian detection with occlusion handling. [sent-634, score-0.824]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('deep', 0.456), ('pedestrian', 0.288), ('bp', 0.227), ('classifiers', 0.221), ('contdeepnet', 0.209), ('css', 0.189), ('contextual', 0.188), ('cascaded', 0.176), ('stage', 0.168), ('misclassified', 0.143), ('caltech', 0.138), ('layer', 0.115), ('architecture', 0.11), ('ouyang', 0.107), ('fi', 0.104), ('miss', 0.103), ('pyramids', 0.095), ('training', 0.091), ('score', 0.089), ('unsupervised', 0.082), ('stages', 0.082), ('detection', 0.08), ('deepnetnofilter', 0.078), ('convolutional', 0.077), ('network', 0.074), ('cascade', 0.073), ('pretrain', 0.069), ('multiftr', 0.069), ('shapelet', 0.069), ('pretraining', 0.069), ('transfer', 0.066), ('hidden', 0.065), ('multiresc', 0.064), ('samples', 0.063), ('ethz', 0.062), ('pedestrians', 0.058), ('hi', 0.057), ('classifier', 0.056), ('trained', 0.054), ('dpk', 0.052), ('nwodes', 0.052), ('enzweiler', 0.052), ('cuhk', 0.052), ('classified', 0.051), ('hog', 0.051), ('jointly', 0.051), ('ranzato', 0.05), ('doll', 0.05), ('filters', 0.049), ('architectures', 0.049), ('map', 0.047), ('correctly', 0.047), ('inria', 0.046), ('comparsion', 0.046), ('cascades', 0.045), ('hinton', 0.044), ('bins', 0.043), ('cooperate', 0.043), ('matrices', 0.041), ('wojek', 0.041), ('strategies', 0.04), ('sermanet', 0.04), ('si', 0.04), ('face', 0.04), ('early', 0.039), ('window', 0.039), ('scores', 0.037), ('fppi', 0.037), ('crosstalk', 0.037), ('kavukcuoglu', 0.037), ('strategy', 0.037), ('false', 0.036), ('layers', 0.036), ('block', 0.036), ('sake', 0.036), ('maps', 0.036), ('luo', 0.035), ('rate', 0.035), ('simulates', 0.034), ('dbn', 0.034), ('boost', 0.034), ('hard', 0.033), ('sfe', 0.033), ('cs', 0.032), ('overfit', 0.032), ('train', 0.031), ('log', 0.031), ('supervised', 0.031), ('feature', 0.031), ('hong', 0.03), ('nodes', 0.03), ('whole', 0.03), ('kong', 0.03), ('poselet', 0.03), ('decision', 0.03), ('self', 0.029), ('tlh', 0.028), ('proved', 0.028), ('belief', 0.028), ('influenced', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="279-tfidf-1" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>2 0.43762809 <a title="279-tfidf-2" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>Author: Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Feature extraction, deformation handling, occlusion handling, and classi?cation are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture1. By establishing automatic, mutual interaction among components, the deep model achieves a 9% reduction in the average miss rate compared with the current best-performing pedestrian detection approaches on the largest Caltech benchmark dataset.</p><p>3 0.24154803 <a title="279-tfidf-3" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>Author: Markus Mathias, Rodrigo Benenson, Radu Timofte, Luc Van_Gool</p><p>Abstract: Detecting partially occluded pedestrians is challenging. A common practice to maximize detection quality is to train a set of occlusion-specific classifiers, each for a certain amount and type of occlusion. Since training classifiers is expensive, only a handful are typically trained. We show that by using many occlusion-specific classifiers, we outperform previous approaches on three pedestrian datasets; INRIA, ETH, and Caltech USA. We present a new approach to train such classifiers. By reusing computations among different training stages, 16 occlusion-specific classifiers can be trained at only one tenth the cost of one full training. We show that also test time cost grows sub-linearly.</p><p>4 0.22509682 <a title="279-tfidf-4" href="./iccv-2013-Pedestrian_Parsing_via_Deep_Decompositional_Network.html">311 iccv-2013-Pedestrian Parsing via Deep Decompositional Network</a></p>
<p>Author: Ping Luo, Xiaogang Wang, Xiaoou Tang</p><p>Abstract: We propose a new Deep Decompositional Network (DDN) for parsing pedestrian images into semantic regions, such as hair, head, body, arms, and legs, where the pedestrians can be heavily occluded. Unlike existing methods based on template matching or Bayesian inference, our approach directly maps low-level visual features to the label maps of body parts with DDN, which is able to accurately estimate complex pose variations with good robustness to occlusions and background clutters. DDN jointly estimates occluded regions and segments body parts by stacking three types of hidden layers: occlusion estimation layers, completion layers, and decomposition layers. The occlusion estimation layers estimate a binary mask, indicating which part of a pedestrian is invisible. The completion layers synthesize low-level features of the invisible part from the original features and the occlusion mask. The decomposition layers directly transform the synthesized visual features to label maps. We devise a new strategy to pre-train these hidden layers, and then fine-tune the entire network using the stochastic gradient descent. Experimental results show that our approach achieves better segmentation accuracy than the state-of-the-art methods on pedestrian images with or without occlusions. Another important contribution of this paper is that it provides a large scale benchmark human parsing dataset1 that includes 3, 673 annotated samples collected from 171 surveillance videos. It is 20 times larger than existing public datasets.</p><p>5 0.22238168 <a title="279-tfidf-5" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>6 0.18087679 <a title="279-tfidf-6" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>7 0.17889552 <a title="279-tfidf-7" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>8 0.17633474 <a title="279-tfidf-8" href="./iccv-2013-A_Deep_Sum-Product_Architecture_for_Robust_Facial_Attributes_Analysis.html">7 iccv-2013-A Deep Sum-Product Architecture for Robust Facial Attributes Analysis</a></p>
<p>9 0.16773969 <a title="279-tfidf-9" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>10 0.15375373 <a title="279-tfidf-10" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>11 0.13201353 <a title="279-tfidf-11" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>12 0.13190219 <a title="279-tfidf-12" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>13 0.12786604 <a title="279-tfidf-13" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>14 0.1273867 <a title="279-tfidf-14" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>15 0.11926663 <a title="279-tfidf-15" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>16 0.11609448 <a title="279-tfidf-16" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>17 0.10443181 <a title="279-tfidf-17" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>18 0.10440324 <a title="279-tfidf-18" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>19 0.10317552 <a title="279-tfidf-19" href="./iccv-2013-Shufflets%3A_Shared_Mid-level_Parts_for_Fast_Object_Detection.html">390 iccv-2013-Shufflets: Shared Mid-level Parts for Fast Object Detection</a></p>
<p>20 0.097712062 <a title="279-tfidf-20" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.219), (1, 0.071), (2, -0.033), (3, -0.1), (4, 0.09), (5, -0.086), (6, 0.037), (7, 0.116), (8, -0.054), (9, -0.124), (10, -0.014), (11, -0.028), (12, 0.085), (13, -0.104), (14, 0.088), (15, -0.036), (16, -0.053), (17, 0.109), (18, 0.173), (19, 0.273), (20, -0.123), (21, -0.011), (22, -0.022), (23, 0.012), (24, -0.261), (25, -0.067), (26, -0.082), (27, 0.082), (28, -0.112), (29, 0.113), (30, -0.108), (31, 0.127), (32, 0.067), (33, -0.043), (34, 0.047), (35, -0.026), (36, -0.069), (37, 0.121), (38, 0.023), (39, 0.08), (40, -0.03), (41, -0.054), (42, -0.022), (43, 0.057), (44, -0.088), (45, 0.077), (46, 0.036), (47, -0.007), (48, -0.034), (49, 0.12)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94891346 <a title="279-lsi-1" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>2 0.88689435 <a title="279-lsi-2" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>Author: Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Feature extraction, deformation handling, occlusion handling, and classi?cation are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture1. By establishing automatic, mutual interaction among components, the deep model achieves a 9% reduction in the average miss rate compared with the current best-performing pedestrian detection approaches on the largest Caltech benchmark dataset.</p><p>3 0.81587392 <a title="279-lsi-3" href="./iccv-2013-Pedestrian_Parsing_via_Deep_Decompositional_Network.html">311 iccv-2013-Pedestrian Parsing via Deep Decompositional Network</a></p>
<p>Author: Ping Luo, Xiaogang Wang, Xiaoou Tang</p><p>Abstract: We propose a new Deep Decompositional Network (DDN) for parsing pedestrian images into semantic regions, such as hair, head, body, arms, and legs, where the pedestrians can be heavily occluded. Unlike existing methods based on template matching or Bayesian inference, our approach directly maps low-level visual features to the label maps of body parts with DDN, which is able to accurately estimate complex pose variations with good robustness to occlusions and background clutters. DDN jointly estimates occluded regions and segments body parts by stacking three types of hidden layers: occlusion estimation layers, completion layers, and decomposition layers. The occlusion estimation layers estimate a binary mask, indicating which part of a pedestrian is invisible. The completion layers synthesize low-level features of the invisible part from the original features and the occlusion mask. The decomposition layers directly transform the synthesized visual features to label maps. We devise a new strategy to pre-train these hidden layers, and then fine-tune the entire network using the stochastic gradient descent. Experimental results show that our approach achieves better segmentation accuracy than the state-of-the-art methods on pedestrian images with or without occlusions. Another important contribution of this paper is that it provides a large scale benchmark human parsing dataset1 that includes 3, 673 annotated samples collected from 171 surveillance videos. It is 20 times larger than existing public datasets.</p><p>4 0.65796924 <a title="279-lsi-4" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>Author: Mojtaba Seyedhosseini, Mehdi Sajjadi, Tolga Tasdizen</p><p>Abstract: Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic dis- junctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance.</p><p>5 0.64395851 <a title="279-lsi-5" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>Author: Markus Mathias, Rodrigo Benenson, Radu Timofte, Luc Van_Gool</p><p>Abstract: Detecting partially occluded pedestrians is challenging. A common practice to maximize detection quality is to train a set of occlusion-specific classifiers, each for a certain amount and type of occlusion. Since training classifiers is expensive, only a handful are typically trained. We show that by using many occlusion-specific classifiers, we outperform previous approaches on three pedestrian datasets; INRIA, ETH, and Caltech USA. We present a new approach to train such classifiers. By reusing computations among different training stages, 16 occlusion-specific classifiers can be trained at only one tenth the cost of one full training. We show that also test time cost grows sub-linearly.</p><p>6 0.63878232 <a title="279-lsi-6" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>7 0.62859166 <a title="279-lsi-7" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>8 0.58921367 <a title="279-lsi-8" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>9 0.5685882 <a title="279-lsi-9" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>10 0.55611074 <a title="279-lsi-10" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>11 0.5390929 <a title="279-lsi-11" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>12 0.53525287 <a title="279-lsi-12" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>13 0.52943146 <a title="279-lsi-13" href="./iccv-2013-A_Deep_Sum-Product_Architecture_for_Robust_Facial_Attributes_Analysis.html">7 iccv-2013-A Deep Sum-Product Architecture for Robust Facial Attributes Analysis</a></p>
<p>14 0.49633321 <a title="279-lsi-14" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>15 0.48759907 <a title="279-lsi-15" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>16 0.48442176 <a title="279-lsi-16" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>17 0.47341985 <a title="279-lsi-17" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>18 0.44362831 <a title="279-lsi-18" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>19 0.44287157 <a title="279-lsi-19" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>20 0.44279248 <a title="279-lsi-20" href="./iccv-2013-Shufflets%3A_Shared_Mid-level_Parts_for_Fast_Object_Detection.html">390 iccv-2013-Shufflets: Shared Mid-level Parts for Fast Object Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.065), (7, 0.014), (26, 0.096), (31, 0.032), (34, 0.012), (35, 0.012), (42, 0.128), (48, 0.057), (64, 0.059), (67, 0.222), (73, 0.025), (78, 0.015), (89, 0.143), (95, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79817879 <a title="279-lda-1" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>2 0.75100833 <a title="279-lda-2" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>Author: Jae-Hak Kim, Yuchao Dai, Hongdong Li, Xin Du, Jonghyuk Kim</p><p>Abstract: We present a new multi-view 3D Euclidean reconstruction method for arbitrary uncalibrated radially-symmetric cameras, which needs no calibration or any camera model parameters other than radial symmetry. It is built on the radial 1D camera model [25], a unified mathematical abstraction to different types of radially-symmetric cameras. We formulate the problem of multi-view reconstruction for radial 1D cameras as a matrix rank minimization problem. Efficient implementation based on alternating direction continuation is proposed to handle scalability issue for real-world applications. Our method applies to a wide range of omnidirectional cameras including both dioptric and catadioptric (central and non-central) cameras. Additionally, our method deals with complete and incomplete measurements under a unified framework elegantly. Experiments on both synthetic and real images from various types of cameras validate the superior performance of our new method, in terms of numerical accuracy and robustness.</p><p>3 0.74501705 <a title="279-lda-3" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>Author: Yu-Tseh Chi, Mohsen Ali, Muhammad Rushdi, Jeffrey Ho</p><p>Abstract: This paper proposes a novel approach for sparse coding that further improves upon the sparse representation-based classification (SRC) framework. The proposed framework, Affine-Constrained Group Sparse Coding (ACGSC), extends the current SRC framework to classification problems with multiple input samples. Geometrically, the affineconstrained group sparse coding essentially searches for the vector in the convex hull spanned by the input vectors that can best be sparse coded using the given dictionary. The resulting objectivefunction is still convex and can be efficiently optimized using iterative block-coordinate descent scheme that is guaranteed to converge. Furthermore, we provide a form of sparse recovery result that guarantees, at least theoretically, that the classification performance of the constrained group sparse coding should be at least as good as the group sparse coding. We have evaluated the proposed approach using three different recognition experiments that involve illumination variation of faces and textures, and face recognition under occlusions. Prelimi- nary experiments have demonstrated the effectiveness of the proposed approach, and in particular, the results from the recognition/occlusion experiment are surprisingly accurate and robust.</p><p>4 0.73876649 <a title="279-lda-4" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>Author: Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Feature extraction, deformation handling, occlusion handling, and classi?cation are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture1. By establishing automatic, mutual interaction among components, the deep model achieves a 9% reduction in the average miss rate compared with the current best-performing pedestrian detection approaches on the largest Caltech benchmark dataset.</p><p>5 0.71626133 <a title="279-lda-5" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>Author: Zhuoyuan Chen, Ying Wu</p><p>Abstract: Sparsity models have recently shown great promise in many vision tasks. Using a learned dictionary in sparsity models can in general outperform predefined bases in clean data. In practice, both training and testing data may be corrupted and contain noises and outliers. Although recent studies attempted to cope with corrupted data and achieved encouraging results in testing phase, how to handle corruption in training phase still remains a very difficult problem. In contrast to most existing methods that learn the dictionaryfrom clean data, this paper is targeted at handling corruptions and outliers in training data for dictionary learning. We propose a general method to decompose the reconstructive residual into two components: a non-sparse component for small universal noises and a sparse component for large outliers, respectively. In addition, , further analysis reveals the connection between our approach and the “partial” dictionary learning approach, updating only part of the prototypes (or informative codewords) with remaining (or noisy codewords) fixed. Experiments on synthetic data as well as real applications have shown satisfactory per- formance of this new robust dictionary learning approach.</p><p>6 0.71570927 <a title="279-lda-6" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>7 0.71071881 <a title="279-lda-7" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<p>8 0.70483488 <a title="279-lda-8" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>9 0.70436335 <a title="279-lda-9" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>10 0.70320082 <a title="279-lda-10" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>11 0.70296907 <a title="279-lda-11" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>12 0.70243812 <a title="279-lda-12" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>13 0.70053673 <a title="279-lda-13" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>14 0.69994378 <a title="279-lda-14" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>15 0.69907278 <a title="279-lda-15" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>16 0.69785762 <a title="279-lda-16" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>17 0.69775867 <a title="279-lda-17" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>18 0.69710636 <a title="279-lda-18" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>19 0.6964556 <a title="279-lda-19" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>20 0.69625294 <a title="279-lda-20" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
