<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-35" href="#">iccv2013-35</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</h1>
<br/><p>Source: <a title="iccv-2013-35-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Efrat_Accurate_Blur_Models_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Netalee Efrat, Daniel Glasner, Alexander Apartsin, Boaz Nadler, Anat Levin</p><p>Abstract: Over the past decade, single image Super-Resolution (SR) research has focused on developing sophisticated image priors, leading to significant advances. Estimating and incorporating the blur model, that relates the high-res and low-res images, has received much less attention, however. In particular, the reconstruction constraint, namely that the blurred and downsampled high-res output should approximately equal the low-res input image, has been either ignored or applied with default fixed blur models. In this work, we examine the relative importance ofthe imageprior and the reconstruction constraint. First, we show that an accurate reconstruction constraint combined with a simple gradient regularization achieves SR results almost as good as those of state-of-the-art algorithms with sophisticated image priors. Second, we study both empirically and theoretically the sensitivity of SR algorithms to the blur model assumed in the reconstruction constraint. We find that an accurate blur model is more important than a sophisticated image prior. Finally, using real camera data, we demonstrate that the default blur models of various SR algorithms may differ from the camera blur, typically leading to over- smoothed results. Our findings highlight the importance of accurately estimating camera blur in reconstructing raw low- res images acquired by an actual camera.</p><p>Reference: <a title="iccv-2013-35-reference" href="../iccv2013_reference/iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Estimating and incorporating the blur model, that relates the high-res and low-res images, has received much less attention, however. [sent-4, score-0.315]
</p><p>2 In particular, the reconstruction constraint, namely that the blurred and downsampled high-res output should approximately equal the low-res input image, has been either ignored or applied with default fixed blur models. [sent-5, score-0.63]
</p><p>3 In this work, we examine the relative importance ofthe imageprior and the reconstruction constraint. [sent-6, score-0.192]
</p><p>4 First, we show that an accurate reconstruction constraint combined with a simple gradient regularization achieves SR results almost as good as those of state-of-the-art algorithms with sophisticated image priors. [sent-7, score-0.393]
</p><p>5 Second, we study both empirically and theoretically the sensitivity of SR algorithms to the blur model assumed in the reconstruction constraint. [sent-8, score-0.591]
</p><p>6 We find that an accurate blur model is more important than a sophisticated image prior. [sent-9, score-0.393]
</p><p>7 Finally, using real camera data, we demonstrate that the default blur models of various SR algorithms may differ from the camera blur, typically leading to over-  smoothed results. [sent-10, score-0.631]
</p><p>8 Our findings highlight the importance of accurately estimating camera blur in reconstructing raw low- res images acquired by an actual camera. [sent-11, score-0.45]
</p><p>9 The second challenge is to enforce the reconstruction constraint Ax ≈ y, which implies that up to imaging noise, the recovered HR image should be consistent with the LR input. [sent-18, score-0.231]
</p><p>10 In contrast, the reconstruction constraint has received relatively little attention. [sent-21, score-0.226]
</p><p>11 Those that do often assume a predefined blur kernel. [sent-23, score-0.292]
</p><p>12 Examples include antialiasing with bicubic interpolation (Matlab’s default imresize function) [8, 27], Gaussian blur [3], Gaussian blur followed by bicubic interpolation [7], simple pixel averaging [5], and sampling without any pre-smoothing [15]. [sent-24, score-1.242]
</p><p>13 A critical concern in applying such SR algorithms to real images is how well these synthetic forward models approximate real camera blur. [sent-25, score-0.181]
</p><p>14 For example, the bicubic interpolation used by many algorithms is generally not physically feasible, as it involves negative weights. [sent-26, score-0.312]
</p><p>15 Furthermore, in most SR algorithms, the blur kernel is not an input parameter: it is coupled to various internal components which are not easily adjusted. [sent-27, score-0.516]
</p><p>16 A few single-image SR works which do attempt to estimate or take the unknown kernel into account include [3, 24, 17, 10, 11, 12]. [sent-28, score-0.224]
</p><p>17 This state of affairs naturally raises the following questions, which are the focus of our paper: i) what is the effect of an incorrect blur model on SR algorithms? [sent-29, score-0.328]
</p><p>18 ii) what is the importance of the reconstruction constraint compared to that of the image prior? [sent-30, score-0.241]
</p><p>19 First, we argue that the reconstruction constraint is at least as important as the image prior. [sent-32, score-0.203]
</p><p>20 In particular, we demonstrate that combining a simple prior, an L2 penalty on image gradients, with an accurate reconstruction constraint, provides SR results almost as good as those produced by  ×  state-of-the-art SR algorithms with sophisticated priors. [sent-33, score-0.293]
</p><p>21 Second, we empirically examine the sensitivity of several SR algorithms to the accuracy of the estimated blur ker2832  nel. [sent-34, score-0.426]
</p><p>22 We show that incorporating an accurate estimate into these algorithms improves their output, by allowing them to take full advantage of the reconstruction constraint. [sent-35, score-0.227]
</p><p>23 In contrast, when the SR algorithms utilize an inaccurate blur kernel, the resulting images are either too blurred or contain over-sharpening artifacts. [sent-36, score-0.4]
</p><p>24 For the L2 prior case, we also present a theoretical analysis explaining these phenomena, via a frequency analysis of the kernel mismatch. [sent-38, score-0.372]
</p><p>25 Finally, we demonstrate the importance of accurately estimating camera blur when applying SR to raw images captured with a real camera. [sent-39, score-0.447]
</p><p>26 We show that the default kernels used by many algorithms are not sufficiently close to the camera blur, and produce over-smoothed results. [sent-40, score-0.275]
</p><p>27 Moreover, we show that incorporating a more accurate estimate of the camera blur improves the results. [sent-41, score-0.394]
</p><p>28 The relation between x and y is typically expressed as y=k  ∗  x ↓s +n  (2)  where k denotes a blur kernel (low pass filter), ↓s denotes subsampling by factor s, and n is imaging noise. [sent-45, score-0.564]
</p><p>29 First, we need to know A, that is, to have an accurate estimate of the blur k. [sent-49, score-0.327]
</p><p>30 Moreover, some methods are patch-based and either do not enforce the global reconstruction constraint Ax ≈ y at all, or apply it only in a separate post-processing step, with a default blur kernel. [sent-61, score-0.612]
</p><p>31 In this paper we study, both qualitatively and quantitatively, the importance of an accurate blur model and the corresponding reconstruction constraint in SR algorithms. [sent-62, score-0.568]
</p><p>32 Since visual plausibility is somewhat subjective, we focus on the reconstruction task, which can be evaluated numerically against ground truth. [sent-69, score-0.156]
</p><p>33 (4) with both a Gaussian 2833  to the kernel the algorithm assumes. [sent-87, score-0.224]
</p><p>34 The rightmost column presents results of the unmodified algorithm with its default bi-cubic kernel. [sent-88, score-0.149]
</p><p>35 On the diagonal, the  On the upper right off-diagonal  im-  ages, the assumed kernel is smoother than the true one, leading to over sharpening artifacts. [sent-96, score-0.463]
</p><p>36 For the lower left, the assumed kernel is sharper than the correct one, leading to over-smoothed results. [sent-97, score-0.332]
</p><p>37 We denote by kT the true kernel used to synthesize a test LR image and by kA the kernel assumed by a SR algorithm. [sent-100, score-0.546]
</p><p>38 pixels; 4) a real camera blur kernel, estimated by capturing a known calibration target with a Canon 5D Mark II camera, shown in Fig. [sent-103, score-0.412]
</p><p>39 The algorithms of Yang, Kim, and Glasner use as default the bicubic kernel, kA = b, whereas Freeman uses kA = b ∗ g1. [sent-114, score-0.384]
</p><p>40 Unfortunately, these algorithms do not accept a kernel as one of their input parameters and adjusting them to use a different kernel is not straightforward. [sent-115, score-0.553]
</p><p>41 upsample the image in gradual steps, and defining a kernel for each intermediate step is non-trivial. [sent-117, score-0.224]
</p><p>42 Second, following [27], we introduced a reconstruction constraint with the desired kernel in post-processing. [sent-120, score-0.427]
</p><p>43 (6) is not needed for the simple regularization algorithms which already optimize the reconstruction constraint in Eq. [sent-128, score-0.292]
</p><p>44 SR was applied to the 4 test sets (prepared with different kernels kT), each time adjusting the algorithm to use a different kernel kA in reconstruction. [sent-134, score-0.296]
</p><p>45 The fifth column shows the original authors’ results, unmodified, using the default bicubic kernel. [sent-135, score-0.346]
</p><p>46 cross  section  primal  Fourier  primal  Fourier  The camera blur attenuates high frequencies more than the bicubic one. [sent-148, score-0.759]
</p><p>47 First, incorporating the reconstruction constraint with the true kernel improves accuracy. [sent-153, score-0.466]
</p><p>48 One can see this by comparing the fifth column (the original algorithm with its default kernel), with the diagonal entries, for which the reconstruction constraint uses kA = kT. [sent-154, score-0.371]
</p><p>49 Moreover, SR using an incorrect kernel drastically increases reconstruction error. [sent-156, score-0.354]
</p><p>50 In particular, when the assumed kernel is smoother than the true kernel, the recovered image is blurred. [sent-158, score-0.388]
</p><p>51 On the other hand, when the assumed kernel is sharper than the true kernel, high frequency ringing artifacts appear, as illustrated in Fig. [sent-159, score-0.493]
</p><p>52 Real images: Given the sensitivity of SR algorithms to the assumed blur kernel, it is interesting to assess their performance on raw LR images acquired by an actual camera. [sent-164, score-0.514]
</p><p>53 To this end, we captured images with a Canon 5D Mark II camera, and estimated its blur using a known calibration target (calibration details can be found in [4]). [sent-165, score-0.319]
</p><p>54 2 compares our estimated camera blur with the bicubic kernel. [sent-167, score-0.564]
</p><p>55 As seen in the Fourier domain, the camera kernel attenuates high frequencies more than the bicubic one. [sent-169, score-0.609]
</p><p>56 4) predicts that using the sharper bicubic kernel will result in over-smoothed SR images. [sent-171, score-0.478]
</p><p>57 The default implementation of various algorithms that assume a bicubic kernel indeed yields over-smoothedresults, while adjusting the algorithms to incorporate the camera kernel sharpens them. [sent-174, score-1.004]
</p><p>58 reconstruction constraint: Next, we consider the relative importance of the assumed image prior  vs. [sent-178, score-0.269]
</p><p>59 To this end, Table 2 compares all algorithms2 and their modified versions, which incorporate the reconstruction constraint, on two test sets - blurred with kT = b and with kT = b ∗ g1. [sent-180, score-0.176]
</p><p>60 All LR images were corrupted by noise at  can see the of a more sophisticated prior by comparing rows 2-3 to rows  4-6 in the left columns. [sent-192, score-0.228]
</p><p>61 Comparing the = kT images are marked in  same rows in the right columns shows the effect of using the correct blur kernel instead of the default one. [sent-193, score-0.74]
</p><p>62 The effect of using the exact blur kernel is more dominant than that of the prior. [sent-195, score-0.552]
</p><p>63 While visual comparison is somewhat subjective and one may argue in favor of one algorithm or the other, overall the results of all algorithms (except the baseline bicubic interpolation) are not significantly different. [sent-200, score-0.315]
</p><p>64 Second, the influence of different image priors is much smaller than the effect of kernel mismatch. [sent-201, score-0.3]
</p><p>65 5dB), which correspond to different image priors, to the difference of almost 2dB between the third and fourth rows, which capture the effect of using a correct kernel instead of the default bicubic one. [sent-205, score-0.582]
</p><p>66 In the two left columns all algorithms use the true kernel and hence produce comparable results. [sent-208, score-0.351]
</p><p>67 In contrast, in the two right columns, only  the sparse and L2 algorithms use the correct kernel, others use their default one. [sent-209, score-0.179]
</p><p>68 This emphasizes that an accurate reconstruction constraint can be more important than a sophisticated prior. [sent-211, score-0.304]
</p><p>69 Since this is not a trivial task most algorithms only impose the global reconstruction constraint in post-processing. [sent-216, score-0.265]
</p><p>70 In contrast, simple gradient regularization methods explicitly optimize a functional which jointly accounts for the global reconstruction constraint and the prior. [sent-217, score-0.23]
</p><p>71 [87d6 ]efault  kernel is compared with a modified one which accepts a kernel as a parameter, when applicable learns a dictionary with it, and also enforces the reconstruction constraint (RC). [sent-231, score-0.651]
</p><p>72 Most algorithms use kA = b as default, thus in the 3rd row algorithms process images with kA kT and in the 4th row adjust to the correct kernel kA = kT. [sent-234, score-0.348]
</p><p>73 Theoretical Analysis To gain further insight into the detrimental effect of kernel mismatch, let us examine SR with a simple L2 gradient  regularization (Gaussian prior) as presented in Eq. [sent-237, score-0.337]
</p><p>74 SR algorithms that assume a kernel KA in fact assume that Y and X are related via Yω = KA,ωXω  + KA,ω? [sent-253, score-0.286]
</p><p>75 The following lemma characterizes the resulting estimator and the relation between the estimated signal Xˆ and the true signal X in case of kernel mismatch (KA KT). [sent-258, score-0.54]
</p><p>76 The MAP SR estimate Xˆ, assuming a Gaussian prior on X and a kernel KA as in, Eq. [sent-264, score-0.266]
</p><p>77 (13)  In other words, an L2 prior on image gradients is a diagonal Gaussian prior in the Fourier domain, whose variance at each frequency ω is the power ofthe derivative filter. [sent-299, score-0.239]
</p><p>78 In the presence of noise with variance η2, at frequencies where σω2 ? [sent-348, score-0.136]
</p><p>79 contributes to the low frequency reconstruction at Xˆω, and visa versa. [sent-357, score-0.207]
</p><p>80 Kernel Mismatch: Next, we study the implication of the lemma when the signal was blurred with KT while the MAP  =  estimator assumed a different kernel KA KT. [sent-358, score-0.442]
</p><p>81 At high frequencies, where signal variance is lower than noise level, HA,ω ≈ 0, and kernel mismatch has little effect on the output. [sent-361, score-0.458]
</p><p>82 In contrast, at other frequencies, an incorrect kernel may have strong detrimental effects. [sent-362, score-0.25]
</p><p>83 In the first case KT,ω/KA,ω acts as a blurring filter and in the second as a sharpening filter (see Fig. [sent-365, score-0.244]
</p><p>84 βT > βA yields a Gaussian blur filter (left); βT < βA gives a sharpening filter (right). [sent-378, score-0.515]
</p><p>85 For βT > βA we obtain a Gaussian blur filter, and for βT < βA a sharpening filter (the exponent is positive). [sent-379, score-0.455]
</p><p>86 High frequencies whose expected power is below the noise variance are not amplified by the reconstruction filter. [sent-384, score-0.266]
</p><p>87 An assumed wider kernel results in ringing, and a narrow kernel in over-blurring. [sent-387, score-0.507]
</p><p>88 Kernel Uncertainty: In practice, SR algorithms may be applied to real images whose blur kernel is not precisely known. [sent-389, score-0.604]
</p><p>89 One approach, taken by several SR algorithms,  ×  is to ignore the true blur kernel, and utilize some default, such as bicubic. [sent-390, score-0.331]
</p><p>90 As noted previously, when the assumed default kernel is narrower than the true kernel, as occurs with our actual camera (see Fig. [sent-391, score-0.535]
</p><p>91 A second approach taken by various SR algorithms to cope with imprecise knowledge of the true kernel, is to give more weight to the image prior and reduce the weight of the reconstruction constraint (e. [sent-394, score-0.346]
</p><p>92 This makes such algorithms less sensitive to kernel mismatch, but also reduces the quality of their results. [sent-398, score-0.286]
</p><p>93 We now derive a principled estimation strategy to take into account kernel uncertainty. [sent-399, score-0.224]
</p><p>94 The effect of kernel uncertainty is similar to that of noise: the kernel covariance ΣK adds to the noise covariance part in Eq. [sent-423, score-0.591]
</p><p>95 If an accurate model of k can be found (a smaller-norm certainty covariance ΣK), the reconstruction accuracy is improved. [sent-427, score-0.189]
</p><p>96 Discussion In this paper, we examined the effect of two components of SR: the natural image prior and the reconstruction constraint. [sent-429, score-0.208]
</p><p>97 We showed that an accurate blur model and its corresponding reconstruction constraint are crucial to the success of SR algorithms. [sent-430, score-0.53]
</p><p>98 The influence of an accurate estimate of the blur kernel is significantly larger than that of a sophisticated prior. [sent-431, score-0.617]
</p><p>99 While existing blind motion deblurring methods can be adapted to this task, we note that SR kernel recovery is a simpler task, since the blur is a property of the sensor and is fixed for all images captured by the same camera under similar imaging conditions. [sent-433, score-0.624]
</p><p>100 As described in [4], this camera blur can be calibrated using two images of the same calibration target. [sent-434, score-0.386]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ka', 0.488), ('sr', 0.391), ('kt', 0.387), ('blur', 0.292), ('kernel', 0.224), ('bicubic', 0.205), ('reconstruction', 0.13), ('hr', 0.119), ('default', 0.117), ('sharpening', 0.103), ('glasner', 0.1), ('lr', 0.092), ('gh', 0.087), ('mismatch', 0.081), ('frequency', 0.077), ('frequencies', 0.077), ('constraint', 0.073), ('psnr', 0.069), ('camera', 0.067), ('sophisticated', 0.066), ('algorithms', 0.062), ('filter', 0.06), ('assumed', 0.059), ('signal', 0.058), ('ax', 0.055), ('fourier', 0.05), ('sharper', 0.049), ('sensitivity', 0.048), ('blurred', 0.046), ('rows', 0.045), ('ringing', 0.045), ('interpolation', 0.045), ('downsampled', 0.045), ('adjusting', 0.043), ('prepared', 0.042), ('prior', 0.042), ('apartsin', 0.041), ('efrat', 0.041), ('ghi', 0.041), ('imresize', 0.041), ('aliasing', 0.041), ('blind', 0.041), ('primal', 0.041), ('priors', 0.04), ('true', 0.039), ('ssim', 0.038), ('smoother', 0.038), ('importance', 0.038), ('superresolution', 0.037), ('gaussian', 0.037), ('attenuates', 0.036), ('wiener', 0.036), ('effect', 0.036), ('mse', 0.036), ('upsampling', 0.035), ('accurate', 0.035), ('gvi', 0.034), ('ha', 0.033), ('shrunk', 0.032), ('argmxin', 0.032), ('canon', 0.032), ('hallucination', 0.032), ('nadler', 0.032), ('unmodified', 0.032), ('noise', 0.03), ('visually', 0.03), ('theoretical', 0.029), ('variance', 0.029), ('actual', 0.029), ('kernels', 0.029), ('uncertainty', 0.029), ('lemma', 0.028), ('recovered', 0.028), ('freeman', 0.028), ('estimator', 0.027), ('diagonal', 0.027), ('regularization', 0.027), ('calibration', 0.027), ('columns', 0.026), ('somewhat', 0.026), ('real', 0.026), ('amplitude', 0.026), ('detrimental', 0.026), ('dom', 0.026), ('relation', 0.025), ('translates', 0.024), ('covariance', 0.024), ('fifth', 0.024), ('iccp', 0.024), ('raw', 0.024), ('examine', 0.024), ('synthetically', 0.023), ('pass', 0.023), ('received', 0.023), ('subjective', 0.022), ('derivative', 0.022), ('logp', 0.022), ('price', 0.022), ('levin', 0.021), ('acts', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999893 <a title="35-tfidf-1" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>Author: Netalee Efrat, Daniel Glasner, Alexander Apartsin, Boaz Nadler, Anat Levin</p><p>Abstract: Over the past decade, single image Super-Resolution (SR) research has focused on developing sophisticated image priors, leading to significant advances. Estimating and incorporating the blur model, that relates the high-res and low-res images, has received much less attention, however. In particular, the reconstruction constraint, namely that the blurred and downsampled high-res output should approximately equal the low-res input image, has been either ignored or applied with default fixed blur models. In this work, we examine the relative importance ofthe imageprior and the reconstruction constraint. First, we show that an accurate reconstruction constraint combined with a simple gradient regularization achieves SR results almost as good as those of state-of-the-art algorithms with sophisticated image priors. Second, we study both empirically and theoretically the sensitivity of SR algorithms to the blur model assumed in the reconstruction constraint. We find that an accurate blur model is more important than a sophisticated image prior. Finally, using real camera data, we demonstrate that the default blur models of various SR algorithms may differ from the camera blur, typically leading to over- smoothed results. Our findings highlight the importance of accurately estimating camera blur in reconstructing raw low- res images acquired by an actual camera.</p><p>2 0.37003887 <a title="35-tfidf-2" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>Author: Tomer Michaeli, Michal Irani</p><p>Abstract: Super resolution (SR) algorithms typically assume that the blur kernel is known (either the Point Spread Function ‘PSF’ of the camera, or some default low-pass filter, e.g. a Gaussian). However, the performance of SR methods significantly deteriorates when the assumed blur kernel deviates from the true one. We propose a general framework for “blind” super resolution. In particular, we show that: (i) Unlike the common belief, the PSF of the camera is the wrong blur kernel to use in SR algorithms. (ii) We show how the correct SR blur kernel can be recovered directly from the low-resolution image. This is done by exploiting the inherent recurrence property of small natural image patches (either internally within the same image, or externally in a collection of other natural images). In particular, we show that recurrence of small patches across scales of the low-res image (which forms the basis for single-image SR), can also be used for estimating the optimal blur kernel. This leads to significant improvement in SR results.</p><p>3 0.29335946 <a title="35-tfidf-3" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>Author: Chih-Yuan Yang, Ming-Hsuan Yang</p><p>Abstract: The goal of single-image super-resolution is to generate a high-quality high-resolution image based on a given low-resolution input. It is an ill-posed problem which requires exemplars or priors to better reconstruct the missing high-resolution image details. In this paper, we propose to split the feature space into numerous subspaces and collect exemplars to learn priors for each subspace, thereby creating effective mapping functions. The use of split input space facilitates both feasibility of using simple functionsfor super-resolution, and efficiency ofgenerating highresolution results. High-quality high-resolution images are reconstructed based on the effective learned priors. Experimental results demonstrate that theproposed algorithmperforms efficiently and effectively over state-of-the-art methods.</p><p>4 0.26241294 <a title="35-tfidf-4" href="./iccv-2013-Dynamic_Scene_Deblurring.html">129 iccv-2013-Dynamic Scene Deblurring</a></p>
<p>Author: Tae Hyun Kim, Byeongjoo Ahn, Kyoung Mu Lee</p><p>Abstract: Most conventional single image deblurring methods assume that the underlying scene is static and the blur is caused by only camera shake. In this paper, in contrast to this restrictive assumption, we address the deblurring problem of general dynamic scenes which contain multiple moving objects as well as camera shake. In case of dynamic scenes, moving objects and background have different blur motions, so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately. Thus, we propose a novel energy model designed with the weighted sum of multiple blur data models, which estimates different motion blurs and their associated pixelwise weights, and resulting sharp image. In this framework, the local weights are determined adaptively and get high values when the corresponding data models have high data fidelity. And, the weight information is used for the segmentation of the motion blur. Non-local regularization of weights are also incorporated to produce more reliable segmentation results. A convex optimization-based method is used for the solution of the proposed energy model. Exper- imental results demonstrate that our method outperforms conventional approaches in deblurring both dynamic scenes and static scenes.</p><p>5 0.20810306 <a title="35-tfidf-5" href="./iccv-2013-Deblurring_by_Example_Using_Dense_Correspondence.html">103 iccv-2013-Deblurring by Example Using Dense Correspondence</a></p>
<p>Author: Yoav Hacohen, Eli Shechtman, Dani Lischinski</p><p>Abstract: This paper presents a new method for deblurring photos using a sharp reference example that contains some shared content with the blurry photo. Most previous deblurring methods that exploit information from other photos require an accurately registered photo of the same static scene. In contrast, our method aims to exploit reference images where the shared content may have undergone substantial photometric and non-rigid geometric transformations, as these are the kind of reference images most likely to be found in personal photo albums. Our approach builds upon a recent method for examplebased deblurring using non-rigid dense correspondence (NRDC) [11] and extends it in two ways. First, we suggest exploiting information from the reference image not only for blur kernel estimation, but also as a powerful local prior for the non-blind deconvolution step. Second, we introduce a simple yet robust technique for spatially varying blur estimation, rather than assuming spatially uniform blur. Unlike the aboveprevious method, which hasproven successful only with simple deblurring scenarios, we demonstrate that our method succeeds on a variety of real-world examples. We provide quantitative and qualitative evaluation of our method and show that it outperforms the state-of-the-art.</p><p>6 0.20400813 <a title="35-tfidf-6" href="./iccv-2013-Forward_Motion_Deblurring.html">174 iccv-2013-Forward Motion Deblurring</a></p>
<p>7 0.16386808 <a title="35-tfidf-7" href="./iccv-2013-Coupled_Dictionary_and_Feature_Space_Learning_with_Applications_to_Cross-Domain_Image_Synthesis_and_Recognition.html">96 iccv-2013-Coupled Dictionary and Feature Space Learning with Applications to Cross-Domain Image Synthesis and Recognition</a></p>
<p>8 0.16154277 <a title="35-tfidf-8" href="./iccv-2013-Translating_Video_Content_to_Natural_Language_Descriptions.html">428 iccv-2013-Translating Video Content to Natural Language Descriptions</a></p>
<p>9 0.14714007 <a title="35-tfidf-9" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>10 0.14424124 <a title="35-tfidf-10" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>11 0.130142 <a title="35-tfidf-11" href="./iccv-2013-Anchored_Neighborhood_Regression_for_Fast_Example-Based_Super-Resolution.html">51 iccv-2013-Anchored Neighborhood Regression for Fast Example-Based Super-Resolution</a></p>
<p>12 0.12836732 <a title="35-tfidf-12" href="./iccv-2013-A_Joint_Intensity_and_Depth_Co-sparse_Analysis_Model_for_Depth_Map_Super-resolution.html">18 iccv-2013-A Joint Intensity and Depth Co-sparse Analysis Model for Depth Map Super-resolution</a></p>
<p>13 0.11351761 <a title="35-tfidf-13" href="./iccv-2013-Local_Signal_Equalization_for_Correspondence_Matching.html">255 iccv-2013-Local Signal Equalization for Correspondence Matching</a></p>
<p>14 0.10526152 <a title="35-tfidf-14" href="./iccv-2013-A_Framework_for_Shape_Analysis_via_Hilbert_Space_Embedding.html">10 iccv-2013-A Framework for Shape Analysis via Hilbert Space Embedding</a></p>
<p>15 0.1044926 <a title="35-tfidf-15" href="./iccv-2013-Log-Euclidean_Kernels_for_Sparse_Representation_and_Dictionary_Learning.html">257 iccv-2013-Log-Euclidean Kernels for Sparse Representation and Dictionary Learning</a></p>
<p>16 0.093586177 <a title="35-tfidf-16" href="./iccv-2013-A_Unified_Rolling_Shutter_and_Motion_Blur_Model_for_3D_Visual_Registration.html">32 iccv-2013-A Unified Rolling Shutter and Motion Blur Model for 3D Visual Registration</a></p>
<p>17 0.078176871 <a title="35-tfidf-17" href="./iccv-2013-Video_Event_Understanding_Using_Natural_Language_Descriptions.html">440 iccv-2013-Video Event Understanding Using Natural Language Descriptions</a></p>
<p>18 0.073745407 <a title="35-tfidf-18" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>19 0.073019631 <a title="35-tfidf-19" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>20 0.06869901 <a title="35-tfidf-20" href="./iccv-2013-Modeling_the_Calibration_Pipeline_of_the_Lytro_Camera_for_High_Quality_Light-Field_Image_Reconstruction.html">271 iccv-2013-Modeling the Calibration Pipeline of the Lytro Camera for High Quality Light-Field Image Reconstruction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.153), (1, -0.055), (2, -0.035), (3, -0.001), (4, -0.116), (5, 0.028), (6, -0.003), (7, -0.136), (8, 0.026), (9, -0.137), (10, -0.056), (11, -0.25), (12, 0.126), (13, -0.254), (14, -0.098), (15, 0.084), (16, 0.033), (17, -0.132), (18, -0.088), (19, -0.103), (20, -0.063), (21, 0.101), (22, 0.036), (23, 0.034), (24, -0.009), (25, 0.088), (26, 0.031), (27, -0.05), (28, -0.243), (29, -0.041), (30, -0.04), (31, -0.065), (32, 0.105), (33, -0.026), (34, -0.04), (35, 0.018), (36, -0.035), (37, -0.017), (38, 0.009), (39, -0.019), (40, 0.117), (41, -0.05), (42, 0.007), (43, 0.047), (44, -0.015), (45, -0.016), (46, -0.085), (47, -0.045), (48, -0.008), (49, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9649874 <a title="35-lsi-1" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>Author: Netalee Efrat, Daniel Glasner, Alexander Apartsin, Boaz Nadler, Anat Levin</p><p>Abstract: Over the past decade, single image Super-Resolution (SR) research has focused on developing sophisticated image priors, leading to significant advances. Estimating and incorporating the blur model, that relates the high-res and low-res images, has received much less attention, however. In particular, the reconstruction constraint, namely that the blurred and downsampled high-res output should approximately equal the low-res input image, has been either ignored or applied with default fixed blur models. In this work, we examine the relative importance ofthe imageprior and the reconstruction constraint. First, we show that an accurate reconstruction constraint combined with a simple gradient regularization achieves SR results almost as good as those of state-of-the-art algorithms with sophisticated image priors. Second, we study both empirically and theoretically the sensitivity of SR algorithms to the blur model assumed in the reconstruction constraint. We find that an accurate blur model is more important than a sophisticated image prior. Finally, using real camera data, we demonstrate that the default blur models of various SR algorithms may differ from the camera blur, typically leading to over- smoothed results. Our findings highlight the importance of accurately estimating camera blur in reconstructing raw low- res images acquired by an actual camera.</p><p>2 0.91764396 <a title="35-lsi-2" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>Author: Tomer Michaeli, Michal Irani</p><p>Abstract: Super resolution (SR) algorithms typically assume that the blur kernel is known (either the Point Spread Function ‘PSF’ of the camera, or some default low-pass filter, e.g. a Gaussian). However, the performance of SR methods significantly deteriorates when the assumed blur kernel deviates from the true one. We propose a general framework for “blind” super resolution. In particular, we show that: (i) Unlike the common belief, the PSF of the camera is the wrong blur kernel to use in SR algorithms. (ii) We show how the correct SR blur kernel can be recovered directly from the low-resolution image. This is done by exploiting the inherent recurrence property of small natural image patches (either internally within the same image, or externally in a collection of other natural images). In particular, we show that recurrence of small patches across scales of the low-res image (which forms the basis for single-image SR), can also be used for estimating the optimal blur kernel. This leads to significant improvement in SR results.</p><p>3 0.75539374 <a title="35-lsi-3" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>Author: Chih-Yuan Yang, Ming-Hsuan Yang</p><p>Abstract: The goal of single-image super-resolution is to generate a high-quality high-resolution image based on a given low-resolution input. It is an ill-posed problem which requires exemplars or priors to better reconstruct the missing high-resolution image details. In this paper, we propose to split the feature space into numerous subspaces and collect exemplars to learn priors for each subspace, thereby creating effective mapping functions. The use of split input space facilitates both feasibility of using simple functionsfor super-resolution, and efficiency ofgenerating highresolution results. High-quality high-resolution images are reconstructed based on the effective learned priors. Experimental results demonstrate that theproposed algorithmperforms efficiently and effectively over state-of-the-art methods.</p><p>4 0.65025389 <a title="35-lsi-4" href="./iccv-2013-Deblurring_by_Example_Using_Dense_Correspondence.html">103 iccv-2013-Deblurring by Example Using Dense Correspondence</a></p>
<p>Author: Yoav Hacohen, Eli Shechtman, Dani Lischinski</p><p>Abstract: This paper presents a new method for deblurring photos using a sharp reference example that contains some shared content with the blurry photo. Most previous deblurring methods that exploit information from other photos require an accurately registered photo of the same static scene. In contrast, our method aims to exploit reference images where the shared content may have undergone substantial photometric and non-rigid geometric transformations, as these are the kind of reference images most likely to be found in personal photo albums. Our approach builds upon a recent method for examplebased deblurring using non-rigid dense correspondence (NRDC) [11] and extends it in two ways. First, we suggest exploiting information from the reference image not only for blur kernel estimation, but also as a powerful local prior for the non-blind deconvolution step. Second, we introduce a simple yet robust technique for spatially varying blur estimation, rather than assuming spatially uniform blur. Unlike the aboveprevious method, which hasproven successful only with simple deblurring scenarios, we demonstrate that our method succeeds on a variety of real-world examples. We provide quantitative and qualitative evaluation of our method and show that it outperforms the state-of-the-art.</p><p>5 0.64137012 <a title="35-lsi-5" href="./iccv-2013-Dynamic_Scene_Deblurring.html">129 iccv-2013-Dynamic Scene Deblurring</a></p>
<p>Author: Tae Hyun Kim, Byeongjoo Ahn, Kyoung Mu Lee</p><p>Abstract: Most conventional single image deblurring methods assume that the underlying scene is static and the blur is caused by only camera shake. In this paper, in contrast to this restrictive assumption, we address the deblurring problem of general dynamic scenes which contain multiple moving objects as well as camera shake. In case of dynamic scenes, moving objects and background have different blur motions, so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately. Thus, we propose a novel energy model designed with the weighted sum of multiple blur data models, which estimates different motion blurs and their associated pixelwise weights, and resulting sharp image. In this framework, the local weights are determined adaptively and get high values when the corresponding data models have high data fidelity. And, the weight information is used for the segmentation of the motion blur. Non-local regularization of weights are also incorporated to produce more reliable segmentation results. A convex optimization-based method is used for the solution of the proposed energy model. Exper- imental results demonstrate that our method outperforms conventional approaches in deblurring both dynamic scenes and static scenes.</p><p>6 0.58901894 <a title="35-lsi-6" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>7 0.58493352 <a title="35-lsi-7" href="./iccv-2013-Forward_Motion_Deblurring.html">174 iccv-2013-Forward Motion Deblurring</a></p>
<p>8 0.47700679 <a title="35-lsi-8" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>9 0.46254894 <a title="35-lsi-9" href="./iccv-2013-Log-Euclidean_Kernels_for_Sparse_Representation_and_Dictionary_Learning.html">257 iccv-2013-Log-Euclidean Kernels for Sparse Representation and Dictionary Learning</a></p>
<p>10 0.4363614 <a title="35-lsi-10" href="./iccv-2013-Coupled_Dictionary_and_Feature_Space_Learning_with_Applications_to_Cross-Domain_Image_Synthesis_and_Recognition.html">96 iccv-2013-Coupled Dictionary and Feature Space Learning with Applications to Cross-Domain Image Synthesis and Recognition</a></p>
<p>11 0.43525532 <a title="35-lsi-11" href="./iccv-2013-Detecting_Irregular_Curvilinear_Structures_in_Gray_Scale_and_Color_Imagery_Using_Multi-directional_Oriented_Flux.html">112 iccv-2013-Detecting Irregular Curvilinear Structures in Gray Scale and Color Imagery Using Multi-directional Oriented Flux</a></p>
<p>12 0.43196508 <a title="35-lsi-12" href="./iccv-2013-Anchored_Neighborhood_Regression_for_Fast_Example-Based_Super-Resolution.html">51 iccv-2013-Anchored Neighborhood Regression for Fast Example-Based Super-Resolution</a></p>
<p>13 0.4257603 <a title="35-lsi-13" href="./iccv-2013-Translating_Video_Content_to_Natural_Language_Descriptions.html">428 iccv-2013-Translating Video Content to Natural Language Descriptions</a></p>
<p>14 0.42301142 <a title="35-lsi-14" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>15 0.40024084 <a title="35-lsi-15" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>16 0.38076043 <a title="35-lsi-16" href="./iccv-2013-A_Framework_for_Shape_Analysis_via_Hilbert_Space_Embedding.html">10 iccv-2013-A Framework for Shape Analysis via Hilbert Space Embedding</a></p>
<p>17 0.37642455 <a title="35-lsi-17" href="./iccv-2013-A_Joint_Intensity_and_Depth_Co-sparse_Analysis_Model_for_Depth_Map_Super-resolution.html">18 iccv-2013-A Joint Intensity and Depth Co-sparse Analysis Model for Depth Map Super-resolution</a></p>
<p>18 0.37599453 <a title="35-lsi-18" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>19 0.36594024 <a title="35-lsi-19" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>20 0.35062921 <a title="35-lsi-20" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.042), (7, 0.02), (10, 0.134), (26, 0.105), (31, 0.09), (40, 0.012), (42, 0.132), (55, 0.013), (64, 0.04), (73, 0.047), (89, 0.222), (98, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92448354 <a title="35-lda-1" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>Author: Netalee Efrat, Daniel Glasner, Alexander Apartsin, Boaz Nadler, Anat Levin</p><p>Abstract: Over the past decade, single image Super-Resolution (SR) research has focused on developing sophisticated image priors, leading to significant advances. Estimating and incorporating the blur model, that relates the high-res and low-res images, has received much less attention, however. In particular, the reconstruction constraint, namely that the blurred and downsampled high-res output should approximately equal the low-res input image, has been either ignored or applied with default fixed blur models. In this work, we examine the relative importance ofthe imageprior and the reconstruction constraint. First, we show that an accurate reconstruction constraint combined with a simple gradient regularization achieves SR results almost as good as those of state-of-the-art algorithms with sophisticated image priors. Second, we study both empirically and theoretically the sensitivity of SR algorithms to the blur model assumed in the reconstruction constraint. We find that an accurate blur model is more important than a sophisticated image prior. Finally, using real camera data, we demonstrate that the default blur models of various SR algorithms may differ from the camera blur, typically leading to over- smoothed results. Our findings highlight the importance of accurately estimating camera blur in reconstructing raw low- res images acquired by an actual camera.</p><p>2 0.91147941 <a title="35-lda-2" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>Author: Qiong Cao, Yiming Ying, Peng Li</p><p>Abstract: Recently, there is a considerable amount of efforts devoted to the problem of unconstrained face verification, where the task is to predict whether pairs of images are from the same person or not. This problem is challenging and difficult due to the large variations in face images. In this paper, we develop a novel regularization framework to learn similarity metrics for unconstrained face verification. We formulate its objective function by incorporating the robustness to the large intra-personal variations and the discriminative power of novel similarity metrics. In addition, our formulation is a convex optimization problem which guarantees the existence of its global solution. Experiments show that our proposed method achieves the state-of-the-art results on the challenging Labeled Faces in the Wild (LFW) database [10].</p><p>3 0.90820992 <a title="35-lda-3" href="./iccv-2013-Space-Time_Robust_Representation_for_Action_Recognition.html">396 iccv-2013-Space-Time Robust Representation for Action Recognition</a></p>
<p>Author: Nicolas Ballas, Yi Yang, Zhen-Zhong Lan, Bertrand Delezoide, Françoise Prêteux, Alexander Hauptmann</p><p>Abstract: We address the problem of action recognition in unconstrained videos. We propose a novel content driven pooling that leverages space-time context while being robust toward global space-time transformations. Being robust to such transformations is of primary importance in unconstrained videos where the action localizations can drastically shift between frames. Our pooling identifies regions of interest using video structural cues estimated by different saliency functions. To combine the different structural information, we introduce an iterative structure learning algorithm, WSVM (weighted SVM), that determines the optimal saliency layout ofan action model through a sparse regularizer. A new optimization method isproposed to solve the WSVM’ highly non-smooth objective function. We evaluate our approach on standard action datasets (KTH, UCF50 and HMDB). Most noticeably, the accuracy of our algorithm reaches 51.8% on the challenging HMDB dataset which outperforms the state-of-the-art of 7.3% relatively.</p><p>4 0.89407831 <a title="35-lda-4" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>5 0.89147025 <a title="35-lda-5" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>Author: Lukáš Neumann, Jiri Matas</p><p>Abstract: An unconstrained end-to-end text localization and recognition method is presented. The method introduces a novel approach for character detection and recognition which combines the advantages of sliding-window and connected component methods. Characters are detected and recognized as image regions which contain strokes of specific orientations in a specific relative position, where the strokes are efficiently detected by convolving the image gradient field with a set of oriented bar filters. Additionally, a novel character representation efficiently calculated from the values obtained in the stroke detection phase is introduced. The representation is robust to shift at the stroke level, which makes it less sensitive to intra-class variations and the noise induced by normalizing character size and positioning. The effectiveness of the representation is demonstrated by the results achieved in the classification of real-world characters using an euclidian nearestneighbor classifier trained on synthetic data in a plain form. The method was evaluated on a standard dataset, where it achieves state-of-the-art results in both text localization and recognition.</p><p>6 0.89139307 <a title="35-lda-6" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>7 0.88789368 <a title="35-lda-7" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>8 0.88581747 <a title="35-lda-8" href="./iccv-2013-A_Learning-Based_Approach_to_Reduce_JPEG_Artifacts_in_Image_Matting.html">19 iccv-2013-A Learning-Based Approach to Reduce JPEG Artifacts in Image Matting</a></p>
<p>9 0.88567907 <a title="35-lda-9" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>10 0.88443559 <a title="35-lda-10" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>11 0.88283378 <a title="35-lda-11" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>12 0.88257861 <a title="35-lda-12" href="./iccv-2013-Volumetric_Semantic_Segmentation_Using_Pyramid_Context_Features.html">447 iccv-2013-Volumetric Semantic Segmentation Using Pyramid Context Features</a></p>
<p>13 0.8819223 <a title="35-lda-13" href="./iccv-2013-Distributed_Low-Rank_Subspace_Segmentation.html">122 iccv-2013-Distributed Low-Rank Subspace Segmentation</a></p>
<p>14 0.88177043 <a title="35-lda-14" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>15 0.88166833 <a title="35-lda-15" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>16 0.88119864 <a title="35-lda-16" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>17 0.88084739 <a title="35-lda-17" href="./iccv-2013-PhotoOCR%3A_Reading_Text_in_Uncontrolled_Conditions.html">315 iccv-2013-PhotoOCR: Reading Text in Uncontrolled Conditions</a></p>
<p>18 0.88026005 <a title="35-lda-18" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>19 0.88003814 <a title="35-lda-19" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>20 0.87892199 <a title="35-lda-20" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
