<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>150 iccv-2013-Exemplar Cut</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-150" href="#">iccv2013-150</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>150 iccv-2013-Exemplar Cut</h1>
<br/><p>Source: <a title="iccv-2013-150-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Yang_Exemplar_Cut_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>Reference: <a title="iccv-2013-150-reference" href="../iccv2013_reference/iccv-2013-Exemplar_Cut_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Exemplar Cut Jimei Yang, Yi-Hsuan Tsai and Ming-Hsuan Yang University of California, Merced 5200 North Lake Road, Merced CA  { j yang4 4 , yt s ai2 , Abstract We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. [sent-1, score-1.161]
</p><p>2 For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. [sent-2, score-0.868]
</p><p>3 For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. [sent-3, score-1.192]
</p><p>4 Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. [sent-4, score-1.026]
</p><p>5 Introduction Category level object segmentation is one of the core problems in computer vision. [sent-7, score-0.255]
</p><p>6 Its main challenges lie in that small visual elements (pixels or superpixels) contain insuf-  ficient information that admits category level object recognition. [sent-8, score-0.213]
</p><p>7 One line of research aims at effectively propagating high level recognition results back to low level segmentation through superpixel neighborhood [10], high-order Conditional Random Fields (CRFs) [18] or object detector outputs [1, 27]. [sent-9, score-0.255]
</p><p>8 Another line makes efforts to generate object segmentation hypotheses so that recognition can be achieved more efficiently by classification or ranking [20]. [sent-10, score-0.472]
</p><p>9 Object segmentation hypotheses could be category independent or category specific. [sent-11, score-0.578]
</p><p>10 Recent work for category independent object segmentation [8, 6, 13] exploit hierarchical image segmentations, grouping strategies and crosscategory shape priors in order to increase the chance of recovering true object regions. [sent-12, score-0.454]
</p><p>11 As a result, such methods are likely to generate thousands of instance-level object region hypotheses which entail laborious post-processing to filter out low-quality solutions. [sent-13, score-0.359]
</p><p>12 Category specific approaches instead, [5, 17, 4] generate single object segmentation by usmhyang} @ucmerced . [sent-14, score-0.289]
</p><p>13 edu  (a) Input(b) Exemplar A(c) Exemplar B  (d) MAP solution  (e) Hypothesis A  (f) Hypothesis B  Figure 1. [sent-15, score-0.04]
</p><p>14 Generating class-specific segmentation hypotheses from exemplars (person in this example). [sent-16, score-0.555]
</p><p>15 ing efficient maximum a posteriori (MAP) inference tools (e. [sent-23, score-0.028]
</p><p>16 , graph cut [15]), which perform well when target objects appear dominantly in the images with simple backgrounds. [sent-25, score-0.435]
</p><p>17 In real-world applications, however, target objects more often appear in cluttered backgrounds with large appearance variations and interact with the objects of other categories (e. [sent-26, score-0.043]
</p><p>18 In these cases, the single MAP solution becomes less satisfactory (Figure 1(d)) due to the limited model capacity and training errors. [sent-29, score-0.115]
</p><p>19 A natural choice to resolve this issue is to generate multiple object segmentation hypotheses from classspecific models [3, 12] (Figure 1(e)(f)). [sent-30, score-0.6]
</p><p>20 This choice not only benefits from learning but also increases the probability of finding all the target objects. [sent-31, score-0.102]
</p><p>21 In this paper, we propose a hybrid parametric and nonparametric model for generating a small set of highly plausible class-specific object segmentations, thereby reducing ambiguities and computational loads for sequential clas-  sification or ranking. [sent-32, score-0.536]
</p><p>22 Towards that, we first learn a pylon model [19] to obtain the parametric object segmentation energy function. [sent-33, score-1.019]
</p><p>23 Building on a bottom-up hierarchical segmentation [2], the pylon model combines a flat CRF with a region tree. [sent-34, score-0.742]
</p><p>24 The resulting energy function remains 885577  submodular and admits efficient inference by graph cut, which brings conveniences to max-margin learning. [sent-35, score-0.233]
</p><p>25 Second, we match the test image with each exemplar by regions. [sent-36, score-0.478]
</p><p>26 For each region in the test image, we retrieve k nearest neighbors (K-NN) from the matching exemplar, so that the node potentials of the pylon model are augmented by K-NN matching scores. [sent-37, score-0.707]
</p><p>27 Therefore, an object segmentation hypothesis can be generated by solving a graph cut with the exemplar augmented energy function, which we refer as exemplar cut. [sent-38, score-1.768]
</p><p>28 Our method leverages both the generalizability of parametric models and the flexibility of nonparametric models. [sent-39, score-0.356]
</p><p>29 For example, CRFs and pylons assume that regions are classifiable in the node potentials, and labels between adjacent regions are consistent up to the Potts pairwise potentials. [sent-41, score-0.166]
</p><p>30 Under these assumptions, the MAP inference usually produces reasonably smooth labeling around the target (Figure 1(d)). [sent-42, score-0.106]
</p><p>31 The reason of missing some parts and predicting a false negative lies in that the node classifiers are less effective in handling heterogeneous appear-  ance in complex background. [sent-43, score-0.114]
</p><p>32 On the other hand, the nonparametric segmentations [24, 21, 16, 23] are more flexible to model assumptions. [sent-44, score-0.171]
</p><p>33 These methods are able to segment an image by transferring prior knowledge (e. [sent-45, score-0.14]
</p><p>34 , labels and shape masks) from retrieved exemplars or regions in a database of segmentation exemplars. [sent-47, score-0.408]
</p><p>35 However, considering the statistical instability of using exemplars, challenges arise from integrating the retrieved or matched segmentation results into a single solution. [sent-48, score-0.294]
</p><p>36 Our method avoids such issue and instead queries each exemplar to generate one segmentation hypothesis. [sent-49, score-0.763]
</p><p>37 By adjusting the pylon energy function by the exemplar matching score, we fuse the parametric and nonparametric classifiers [7] on the node potentials and still take advantage of the label consistency assumption and learned parameters on the pairwise potentials. [sent-50, score-1.594]
</p><p>38 Consequently, we increase the possibilities of correcting the mistakes of parametric models and prevent segmentation from noisy labeling. [sent-51, score-0.453]
</p><p>39 We use the intersection/union overlap scores [9] to evaluate the upper bound performance of segmentation hypotheses. [sent-53, score-0.221]
</p><p>40 The results show that the proposed exemplar cut algorithm generates better segmentation hypotheses than the MAP solution and performs favorably against the state-of-the-art methods based on parametric min cut [14], diverse M-Best solutions [3] and multiple choice learning [12]. [sent-54, score-1.935]
</p><p>41 We also analyze the performance  of hypotheses at different MAP quality levels. [sent-55, score-0.183]
</p><p>42 The results on the Graz-02 dataset suggest that exemplar cut maintains high recall rates when MAP solutions miss the target objects. [sent-56, score-0.89]
</p><p>43 Related Work As the focus of this work is generating good hypotheses for class-specific segmentation, we discuss the most related work in three aspects. [sent-58, score-0.248]
</p><p>44 The parametric min cut algorithm [14] introduces a constant value to the node potentials of the graph cut energy function, which changes the decision threshold of classifying the nodes into foreground and background. [sent-60, score-1.199]
</p><p>45 By varying the constant value, a series of graph cuts are solved to produce a set of segmentation hypotheses. [sent-61, score-0.263]
</p><p>46 This technique has been used in [6, 13] for category independent object segmentation hypotheses. [sent-62, score-0.342]
</p><p>47 As the classification thresholds are changed uniformly for all the nodes, the parametric min cut usually produces noisy segmentation results where good segments are companied by false negatives. [sent-63, score-0.857]
</p><p>48 In contrast, our exemplar cut adaptively determines the decision boundary by K-NN matching scores with exemplar regions. [sent-64, score-1.289]
</p><p>49 When the single MAP solution becomes less satisfactory, it is beneficial to find M best solutions. [sent-66, score-0.04]
</p><p>50 A potential issue is that the top M most probable solutions may be similar to each other if many noisy local minimal solutions exist close to the MAP one [28]. [sent-67, score-0.186]
</p><p>51 [3] propose to explore different local modes of the energy function by enforcing the solution diversity. [sent-69, score-0.147]
</p><p>52 In their work, the energy function is augmented with dissimilarity constraints that isolate the current solution from previous ones by a pre-defined threshold. [sent-70, score-0.29]
</p><p>53 This strategy entails a greedy algorithm to find solutions sequentially. [sent-71, score-0.095]
</p><p>54 In contrast to the dissimilarity metric that operates as a repulsive force to push the current solution away from existing ones, the matching similarity in our work performs as an attractive force that pulls the current solution towards the exemplars. [sent-72, score-0.296]
</p><p>55 This approach aims to generate multiple structured outputs [12] by learning a set of sub-models simultaneously, rather than inferring multiple solutions from a single model. [sent-74, score-0.098]
</p><p>56 Recall that we need a diverse set of segmentation hypotheses. [sent-75, score-0.251]
</p><p>57 In fact, the multiple choice learning approach realizes this objective in the training phase by discriminative clustering. [sent-77, score-0.096]
</p><p>58 It assigns the training exemplars to sub-models by evaluating their segmentation errors so that a sub-model is eventually optimized towards a subset of exemplars. [sent-78, score-0.372]
</p><p>59 This approach is constrained by the clustering structure of training exemplars and sensitive to the initialization. [sent-79, score-0.151]
</p><p>60 When the number of submodels is not properly chosen, the segmentation capabilities of learned sub-models may be imbalanced (some too strong and others too weak) so that the weak predictor degenerates in the training phase. [sent-80, score-0.341]
</p><p>61 In addition, since each sub-model governs a set of exemplars, we can also perform exemplar  cut to each sub-model of multiple choice learning. [sent-81, score-0.887]
</p><p>62 Exemplar Cut In this section, we present the proposed exemplar cut algorithm for class-specific object segmentation in details. [sent-83, score-1.038]
</p><p>63 We first introduce the underlying segmentation model and then present our approach of generating multiple segmentation hypotheses with exemplars. [sent-84, score-0.69]
</p><p>64 We use the two-class pylon model [19] as the underlying mechanism for category specific object segmentation. [sent-88, score-0.574]
</p><p>65 In Figure 2, we parse an image with a simplified two-class pylon model in a segmentation tree. [sent-89, score-0.674]
</p><p>66 Each node represents a segment at a different level and its figure/ground assignment energy is given by U(fi) in (3). [sent-91, score-0.331]
</p><p>67 The edges between the leafnodes V (fi , fj ) in (4) denotes the pairwise smoothness term. [sent-92, score-0.147]
</p><p>68 The edge between a segment and its ancestor represents the consistency constraint C(fi , fa(i) ) in (1). [sent-93, score-0.211]
</p><p>69 A labeling of the image is visualized by colored bounding boxes around the segments. [sent-94, score-0.063]
</p><p>70 The red box indicates the figure label (fi = 1) while the blue box indicates the ground label (fi = 2). [sent-95, score-0.134]
</p><p>71 The dashed box indicates the segment is not being used to explain the image (fi = 0) and all the solid boxes constitute a complete image. [sent-96, score-0.2]
</p><p>72 We first segment an image I into a hierarchical region tree S = {S1, S2 , . [sent-97, score-0.244]
</p><p>73 = We { Sindex the leaf segments efr goPmb 1 c otnot oLu,r th deet eicn-termediate segments from L + 1 to 2L − 2 and the root segment t(eth ese genmtieren image) as t+he 1 1la tsot one, −2L 2 − an 1d. [sent-101, score-0.382]
</p><p>74 Wthee raolsoot dseegnmoteen at ((ith) as nthtiere a inmceagsteo)r a osf t segment ie ,a 2ndL p− (i 1, . [sent-102, score-0.14]
</p><p>75 j )W as tlsheo shortest path from segment ito segment j. [sent-103, score-0.31]
</p><p>76 Note that segment iand its ancestor a(i) are overlapped, so we only need to keep one of them to explain the image. [sent-104, score-0.211]
</p><p>77 Each segment Si ∈ S thus could be assigned a label fi ∈ {0, 1, 2}, where fi =∈ S1 ihnudsic caotuesld t bhee foreground, bfie = f 2∈ th {0e, background, and fi = 0 not being used for explaining the image. [sent-105, score-0.734]
</p><p>78 , f2L−1 }, the pylon mduocdeel a requires tnhta lta fboerl any fle =af segment, there} i,s only one non-zero label along its path to the root node in the tree, ∀i = 1, . [sent-109, score-0.722]
</p><p>79 (1)  This constraint guarantees the complete and nonoverlapping labeling. [sent-113, score-0.037]
</p><p>80 We formulate an energy function for the pylon model similar to a conventional CRF,  = ? [sent-114, score-0.56]
</p><p>81 ) ∈N  where the unary term U(fi) specifies the cost of assigning a label fi for the segment i, and the pairwise term V (fi, fj)  instantiates the non-negative boundary cost between any two adjacent segments (i, j) ∈ N. [sent-121, score-0.565]
</p><p>82 The set of adjacent segtmweont asd jisa cdeennto steegdm by Nts (. [sent-122, score-0.082]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('exemplar', 0.478), ('pylon', 0.453), ('cut', 0.305), ('segmentation', 0.221), ('parametric', 0.204), ('hypotheses', 0.183), ('fi', 0.176), ('exemplars', 0.151), ('segment', 0.14), ('nonparametric', 0.118), ('fj', 0.11), ('energy', 0.107), ('category', 0.087), ('node', 0.084), ('potentials', 0.078), ('merced', 0.071), ('ancestor', 0.071), ('generating', 0.065), ('solutions', 0.064), ('augmented', 0.061), ('choice', 0.059), ('admits', 0.056), ('segmentations', 0.053), ('segments', 0.053), ('crfs', 0.049), ('dissimilarity', 0.049), ('satisfactory', 0.047), ('pascal', 0.046), ('map', 0.046), ('min', 0.046), ('adjacent', 0.045), ('instantiates', 0.045), ('submodels', 0.045), ('governs', 0.045), ('fboerl', 0.045), ('lta', 0.045), ('dominantly', 0.045), ('repulsive', 0.045), ('tsot', 0.045), ('ucmerced', 0.045), ('force', 0.044), ('target', 0.043), ('crf', 0.043), ('graph', 0.042), ('hypothesis', 0.042), ('crosscategory', 0.041), ('oeffi', 0.041), ('laborious', 0.041), ('plausible', 0.041), ('hybrid', 0.041), ('solution', 0.04), ('classspecific', 0.039), ('degenerates', 0.039), ('hierarchical', 0.037), ('pairwise', 0.037), ('realizes', 0.037), ('nonoverlapping', 0.037), ('graz', 0.037), ('instability', 0.037), ('asd', 0.037), ('retrieved', 0.036), ('tree', 0.036), ('entail', 0.036), ('imbalanced', 0.036), ('augments', 0.036), ('lake', 0.036), ('ficient', 0.036), ('gpb', 0.036), ('voc', 0.035), ('labeling', 0.035), ('label', 0.035), ('object', 0.034), ('pulls', 0.034), ('generalizability', 0.034), ('nts', 0.034), ('unary', 0.034), ('generate', 0.034), ('fa', 0.033), ('isolate', 0.033), ('sification', 0.033), ('box', 0.032), ('efr', 0.031), ('entails', 0.031), ('batra', 0.031), ('potts', 0.031), ('region', 0.031), ('explaining', 0.031), ('wthee', 0.031), ('diverse', 0.03), ('north', 0.03), ('ance', 0.03), ('ese', 0.03), ('issue', 0.03), ('path', 0.03), ('root', 0.03), ('decision', 0.028), ('inference', 0.028), ('boxes', 0.028), ('noisy', 0.028), ('capacity', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="150-tfidf-1" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>2 0.22742985 <a title="150-tfidf-2" href="./iccv-2013-Recognising_Human-Object_Interaction_via_Exemplar_Based_Modelling.html">344 iccv-2013-Recognising Human-Object Interaction via Exemplar Based Modelling</a></p>
<p>Author: Jian-Fang Hu, Wei-Shi Zheng, Jianhuang Lai, Shaogang Gong, Tao Xiang</p><p>Abstract: Human action can be recognised from a single still image by modelling Human-object interaction (HOI), which infers the mutual spatial structure information between human and object as well as their appearance. Existing approaches rely heavily on accurate detection of human and object, and estimation of human pose. They are thus sensitive to large variations of human poses, occlusion and unsatisfactory detection of small size objects. To overcome this limitation, a novel exemplar based approach is proposed in this work. Our approach learns a set of spatial pose-object interaction exemplars, which are density functions describing how a person is interacting with a manipulated object for different activities spatially in a probabilistic way. A representation based on our HOI exemplar thus has great potential for being robust to the errors in human/object detection and pose estimation. A new framework consists of a proposed exemplar based HOI descriptor and an activity specific matching model that learns the parameters is formulated for robust human activity recog- nition. Experiments on two benchmark activity datasets demonstrate that the proposed approach obtains state-ofthe-art performance.</p><p>3 0.18677337 <a title="150-tfidf-3" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>Author: Wei Xia, Csaba Domokos, Jian Dong, Loong-Fah Cheong, Shuicheng Yan</p><p>Abstract: Numerous existing object segmentation frameworks commonly utilize the object bounding box as a prior. In this paper, we address semantic segmentation assuming that object bounding boxes are provided by object detectors, but no training data with annotated segments are available. Based on a set of segment hypotheses, we introduce a simple voting scheme to estimate shape guidance for each bounding box. The derived shape guidance is used in the subsequent graph-cut-based figure-ground segmentation. The final segmentation result is obtained by merging the segmentation results in the bounding boxes. We conduct an extensive analysis of the effect of object bounding box accuracy. Comprehensive experiments on both the challenging PASCAL VOC object segmentation dataset and GrabCut50 image segmentation dataset show that the proposed approach achieves competitive results compared to previous detection or bounding box prior based methods, as well as other state-of-the-art semantic segmentation methods.</p><p>4 0.15678926 <a title="150-tfidf-4" href="./iccv-2013-How_Related_Exemplars_Help_Complex_Event_Detection_in_Web_Videos%3F.html">203 iccv-2013-How Related Exemplars Help Complex Event Detection in Web Videos?</a></p>
<p>Author: Yi Yang, Zhigang Ma, Zhongwen Xu, Shuicheng Yan, Alexander G. Hauptmann</p><p>Abstract: Compared to visual concepts such as actions, scenes and objects, complex event is a higher level abstraction of longer video sequences. For example, a “marriage proposal” event is described by multiple objects (e.g., ring, faces), scenes (e.g., in a restaurant, outdoor) and actions (e.g., kneeling down). The positive exemplars which exactly convey the precise semantic of an event are hard to obtain. It would be beneficial to utilize the related exemplars for complex event detection. However, the semantic correlations between related exemplars and the target event vary substantially as relatedness assessment is subjective. Two related exemplars can be about completely different events, e.g., in the TRECVID MED dataset, both bicycle riding and equestrianism are labeled as related to “attempting a bike trick” event. To tackle the subjectiveness of human assessment, our algorithm automatically evaluates how positive the related exemplars are for the detection of an event and uses them on an exemplar-specific basis. Experiments demonstrate that our algorithm is able to utilize related exemplars adaptively, and the algorithm gains good perform- z. ance for complex event detection.</p><p>5 0.14596026 <a title="150-tfidf-5" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>Author: Fuxin Li, Taeyoung Kim, Ahmad Humayun, David Tsai, James M. Rehg</p><p>Abstract: We propose an unsupervised video segmentation approach by simultaneously tracking multiple holistic figureground segments. Segment tracks are initialized from a pool of segment proposals generated from a figure-ground segmentation algorithm. Then, online non-local appearance models are trained incrementally for each track using a multi-output regularized least squares formulation. By using the same set of training examples for all segment tracks, a computational trick allows us to track hundreds of segment tracks efficiently, as well as perform optimal online updates in closed-form. Besides, a new composite statistical inference approach is proposed for refining the obtained segment tracks, which breaks down the initial segment proposals and recombines for better ones by utilizing highorder statistic estimates from the appearance model and enforcing temporal consistency. For evaluating the algorithm, a dataset, SegTrack v2, is collected with about 1,000 frames with pixel-level annotations. The proposed framework outperforms state-of-the-art approaches in the dataset, show- ing its efficiency and robustness to challenges in different video sequences.</p><p>6 0.14414605 <a title="150-tfidf-6" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>7 0.13924639 <a title="150-tfidf-7" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>8 0.13677178 <a title="150-tfidf-8" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>9 0.13398777 <a title="150-tfidf-9" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>10 0.12735835 <a title="150-tfidf-10" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>11 0.11613818 <a title="150-tfidf-11" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>12 0.11256086 <a title="150-tfidf-12" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>13 0.1125456 <a title="150-tfidf-13" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>14 0.10382664 <a title="150-tfidf-14" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>15 0.10165872 <a title="150-tfidf-15" href="./iccv-2013-Learning_Graph_Matching%3A_Oriented_to_Category_Modeling_from_Cluttered_Scenes.html">237 iccv-2013-Learning Graph Matching: Oriented to Category Modeling from Cluttered Scenes</a></p>
<p>16 0.098558284 <a title="150-tfidf-16" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>17 0.098431595 <a title="150-tfidf-17" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>18 0.095533103 <a title="150-tfidf-18" href="./iccv-2013-Action_Recognition_and_Localization_by_Hierarchical_Space-Time_Segments.html">37 iccv-2013-Action Recognition and Localization by Hierarchical Space-Time Segments</a></p>
<p>19 0.093483351 <a title="150-tfidf-19" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<p>20 0.092467338 <a title="150-tfidf-20" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.194), (1, -0.011), (2, 0.045), (3, -0.005), (4, 0.107), (5, 0.031), (6, -0.114), (7, 0.103), (8, 0.022), (9, -0.142), (10, -0.016), (11, 0.095), (12, -0.025), (13, 0.026), (14, -0.058), (15, 0.057), (16, -0.029), (17, -0.075), (18, -0.068), (19, -0.038), (20, 0.077), (21, -0.028), (22, -0.026), (23, 0.047), (24, 0.023), (25, -0.004), (26, -0.062), (27, -0.008), (28, -0.08), (29, -0.114), (30, -0.082), (31, -0.021), (32, 0.076), (33, -0.029), (34, -0.02), (35, 0.059), (36, -0.116), (37, 0.073), (38, 0.011), (39, 0.048), (40, 0.103), (41, -0.013), (42, 0.119), (43, 0.037), (44, 0.102), (45, 0.138), (46, -0.025), (47, -0.064), (48, -0.048), (49, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95962387 <a title="150-lsi-1" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>2 0.72794342 <a title="150-lsi-2" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>Author: Meng Tang, Lena Gorelick, Olga Veksler, Yuri Boykov</p><p>Abstract: Among image segmentation algorithms there are two major groups: (a) methods assuming known appearance models and (b) methods estimating appearance models jointly with segmentation. Typically, the first group optimizes appearance log-likelihoods in combination with some spacial regularization. This problem is relatively simple and many methods guarantee globally optimal results. The second group treats model parameters as additional variables transforming simple segmentation energies into highorder NP-hard functionals (Zhu-Yuille, Chan-Vese, GrabCut, etc). It is known that such methods indirectly minimize the appearance overlap between the segments. We propose a new energy term explicitly measuring L1 distance between the object and background appearance models that can be globally maximized in one graph cut. We show that in many applications our simple term makes NP-hard segmentation functionals unnecessary. Our one cut algorithm effectively replaces approximate iterative optimization techniques based on block coordinate descent.</p><p>3 0.71364534 <a title="150-lsi-3" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>Author: Masoud S. Nosrati, Shawn Andrews, Ghassan Hamarneh</p><p>Abstract: The inclusion of shape and appearance priors have proven useful for obtaining more accurate and plausible segmentations, especially for complex objects with multiple parts. In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . ca (a)Standar laΩb ehlingΩfuhnctionseting(Ωb)hΩOuirseΩtijng Figure 1: The inside vs. outside ambiguity in (a) is resolved by our containment constraint in (b). constraints using a single labeling function while maintaining global optimality. We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors.</p><p>4 0.7105822 <a title="150-lsi-4" href="./iccv-2013-A_Deformable_Mixture_Parsing_Model_with_Parselets.html">8 iccv-2013-A Deformable Mixture Parsing Model with Parselets</a></p>
<p>Author: Jian Dong, Qiang Chen, Wei Xia, Zhongyang Huang, Shuicheng Yan</p><p>Abstract: In this work, we address the problem of human parsing, namely partitioning the human body into semantic regions, by using the novel Parselet representation. Previous works often consider solving the problem of human pose estimation as the prerequisite of human parsing. We argue that these approaches cannot obtain optimal pixel level parsing due to the inconsistent targets between these tasks. In this paper, we propose to use Parselets as the building blocks of our parsing model. Parselets are a group of parsable segments which can generally be obtained by lowlevel over-segmentation algorithms and bear strong semantic meaning. We then build a Deformable Mixture Parsing Model (DMPM) for human parsing to simultaneously handle the deformation and multi-modalities of Parselets. The proposed model has two unique characteristics: (1) the possible numerous modalities of Parselet ensembles are exhibited as the “And-Or” structure of sub-trees; (2) to further solve the practical problem of Parselet occlusion or absence, we directly model the visibility property at some leaf nodes. The DMPM thus directly solves the problem of human parsing by searching for the best graph configura- tionfrom apool ofParselet hypotheses without intermediate tasks. Comprehensive evaluations demonstrate the encouraging performance of the proposed approach.</p><p>5 0.67113101 <a title="150-lsi-5" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>Author: Wei Xia, Csaba Domokos, Jian Dong, Loong-Fah Cheong, Shuicheng Yan</p><p>Abstract: Numerous existing object segmentation frameworks commonly utilize the object bounding box as a prior. In this paper, we address semantic segmentation assuming that object bounding boxes are provided by object detectors, but no training data with annotated segments are available. Based on a set of segment hypotheses, we introduce a simple voting scheme to estimate shape guidance for each bounding box. The derived shape guidance is used in the subsequent graph-cut-based figure-ground segmentation. The final segmentation result is obtained by merging the segmentation results in the bounding boxes. We conduct an extensive analysis of the effect of object bounding box accuracy. Comprehensive experiments on both the challenging PASCAL VOC object segmentation dataset and GrabCut50 image segmentation dataset show that the proposed approach achieves competitive results compared to previous detection or bounding box prior based methods, as well as other state-of-the-art semantic segmentation methods.</p><p>6 0.65217358 <a title="150-lsi-6" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>7 0.65070176 <a title="150-lsi-7" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>8 0.64620113 <a title="150-lsi-8" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>9 0.63687849 <a title="150-lsi-9" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>10 0.60111552 <a title="150-lsi-10" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<p>11 0.58142751 <a title="150-lsi-11" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>12 0.57391006 <a title="150-lsi-12" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>13 0.54962277 <a title="150-lsi-13" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>14 0.54422104 <a title="150-lsi-14" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<p>15 0.54058629 <a title="150-lsi-15" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>16 0.52915716 <a title="150-lsi-16" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>17 0.52459806 <a title="150-lsi-17" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>18 0.52165592 <a title="150-lsi-18" href="./iccv-2013-Scene_Collaging%3A_Analysis_and_Synthesis_of_Natural_Images_with_Semantic_Layers.html">375 iccv-2013-Scene Collaging: Analysis and Synthesis of Natural Images with Semantic Layers</a></p>
<p>19 0.51161498 <a title="150-lsi-19" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>20 0.50936562 <a title="150-lsi-20" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.069), (7, 0.015), (12, 0.023), (13, 0.017), (18, 0.061), (26, 0.125), (31, 0.039), (42, 0.111), (48, 0.018), (64, 0.063), (68, 0.017), (73, 0.057), (78, 0.052), (87, 0.041), (89, 0.168), (98, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94457954 <a title="150-lda-1" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>2 0.92101681 <a title="150-lda-2" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>Author: Martin Schiegg, Philipp Hanslovsky, Bernhard X. Kausler, Lars Hufnagel, Fred A. Hamprecht</p><p>Abstract: The quality of any tracking-by-assignment hinges on the accuracy of the foregoing target detection / segmentation step. In many kinds of images, errors in this first stage are unavoidable. These errors then propagate to, and corrupt, the tracking result. Our main contribution is the first probabilistic graphical model that can explicitly account for over- and undersegmentation errors even when the number of tracking targets is unknown and when they may divide, as in cell cultures. The tracking model we present implements global consistency constraints for the number of targets comprised by each detection and is solved to global optimality on reasonably large 2D+t and 3D+t datasets. In addition, we empirically demonstrate the effectiveness of a postprocessing that allows to establish target identity even across occlusion / undersegmentation. The usefulness and efficiency of this new tracking method is demonstrated on three different and challenging 2D+t and 3D+t datasets from developmental biology.</p><p>3 0.91612184 <a title="150-lda-3" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>4 0.91592264 <a title="150-lda-4" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>Author: Suyog Dutt Jain, Kristen Grauman</p><p>Abstract: The mode of manual annotation used in an interactive segmentation algorithm affects both its accuracy and easeof-use. For example, bounding boxes are fast to supply, yet may be too coarse to get good results on difficult images; freehand outlines are slower to supply and more specific, yet they may be overkill for simple images. Whereas existing methods assume a fixed form of input no matter the image, we propose to predict the tradeoff between accuracy and effort. Our approach learns whether a graph cuts segmentation will succeed if initialized with a given annotation mode, based on the image ’s visual separability and foreground uncertainty. Using these predictions, we optimize the mode of input requested on new images a user wants segmented. Whether given a single image that should be segmented as quickly as possible, or a batch of images that must be segmented within a specified time budget, we show how to select the easiest modality that will be sufficiently strong to yield high quality segmentations. Extensive results with real users and three datasets demonstrate the impact.</p><p>5 0.91479695 <a title="150-lda-5" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>Author: Matthias Reso, Jörn Jachalsky, Bodo Rosenhahn, Jörn Ostermann</p><p>Abstract: Superpixel algorithms represent a very useful and increasingly popular preprocessing step for a wide range of computer vision applications, as they offer the potential to boost efficiency and effectiveness. In this regards, this paper presents a highly competitive approach for temporally consistent superpixelsfor video content. The approach is based on energy-minimizing clustering utilizing a novel hybrid clustering strategy for a multi-dimensional feature space working in a global color subspace and local spatial subspaces. Moreover, a new contour evolution based strategy is introduced to ensure spatial coherency of the generated superpixels. For a thorough evaluation the proposed approach is compared to state of the art supervoxel algorithms using established benchmarks and shows a superior performance.</p><p>6 0.91291821 <a title="150-lda-6" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>7 0.91095459 <a title="150-lda-7" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>8 0.90842414 <a title="150-lda-8" href="./iccv-2013-Multi-attributed_Dictionary_Learning_for_Sparse_Coding.html">276 iccv-2013-Multi-attributed Dictionary Learning for Sparse Coding</a></p>
<p>9 0.90381473 <a title="150-lda-9" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>10 0.90372258 <a title="150-lda-10" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>11 0.902569 <a title="150-lda-11" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>12 0.90132326 <a title="150-lda-12" href="./iccv-2013-Capturing_Global_Semantic_Relationships_for_Facial_Action_Unit_Recognition.html">69 iccv-2013-Capturing Global Semantic Relationships for Facial Action Unit Recognition</a></p>
<p>13 0.90089536 <a title="150-lda-13" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>14 0.90086913 <a title="150-lda-14" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>15 0.90068996 <a title="150-lda-15" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>16 0.90062237 <a title="150-lda-16" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>17 0.89999032 <a title="150-lda-17" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>18 0.89906335 <a title="150-lda-18" href="./iccv-2013-From_Actemes_to_Action%3A_A_Strongly-Supervised_Representation_for_Detailed_Action_Understanding.html">175 iccv-2013-From Actemes to Action: A Strongly-Supervised Representation for Detailed Action Understanding</a></p>
<p>19 0.8990016 <a title="150-lda-19" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>20 0.89803803 <a title="150-lda-20" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
