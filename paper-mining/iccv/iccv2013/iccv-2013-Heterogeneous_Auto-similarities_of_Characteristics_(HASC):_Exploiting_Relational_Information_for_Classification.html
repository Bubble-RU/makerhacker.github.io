<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-193" href="#">iccv2013-193</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</h1>
<br/><p>Source: <a title="iccv-2013-193-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/San_Biagio_Heterogeneous_Auto-similarities_of_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Marco San_Biagio, Marco Crocco, Marco Cristani, Samuele Martelli, Vittorio Murino</p><p>Abstract: Capturing the essential characteristics of visual objects by considering how their features are inter-related is a recent philosophy of object classification. In this paper, we embed this principle in a novel image descriptor, dubbed Heterogeneous Auto-Similarities of Characteristics (HASC). HASC is applied to heterogeneous dense features maps, encoding linear relations by covariances and nonlinear associations through information-theoretic measures such as mutual information and entropy. In this way, highly complex structural information can be expressed in a compact, scale invariant and robust manner. The effectiveness of HASC is tested on many diverse detection and classification scenarios, considering objects, textures and pedestrians, on widely known benchmarks (Caltech-101, Brodatz, Daimler Multi-Cue). In all the cases, the results obtained with standard classifiers demonstrate the superiority of HASC with respect to the most adopted local feature descriptors nowadays, such as SIFT, HOG, LBP and feature covariances. In addition, HASC sets the state-of-the-art on the Brodatz texture dataset and the Daimler Multi-Cue pedestrian dataset, without exploiting ad-hoc sophisticated classifiers.</p><p>Reference: <a title="iccv-2013-193-reference" href="../iccv2013_reference/iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 it  marco  Samuele Martelli1 Vittorio Murino1,2 s amue le . [sent-7, score-0.065]
</p><p>2 HASC is applied to heterogeneous dense features maps, encoding linear relations by covariances and nonlinear associations through information-theoretic measures such as mutual information and entropy. [sent-13, score-0.178]
</p><p>3 The effectiveness of HASC is tested on many diverse detection and classification scenarios, considering objects, textures and pedestrians, on widely known benchmarks (Caltech-101, Brodatz, Daimler Multi-Cue). [sent-15, score-0.073]
</p><p>4 In all the cases, the results obtained with standard classifiers demonstrate the superiority of HASC with respect to the most adopted local feature descriptors nowadays, such as SIFT, HOG, LBP and feature  covariances. [sent-16, score-0.076]
</p><p>5 In addition, HASC sets the state-of-the-art on the Brodatz texture dataset and the Daimler Multi-Cue pedestrian dataset, without exploiting ad-hoc sophisticated classifiers. [sent-17, score-0.108]
</p><p>6 Introduction Visual object classification and recognition remains one of the most studied problems in Computer Vision and Pattern Recognition. [sent-19, score-0.033]
</p><p>7 In this domain, the design of novel feature descriptors play a crucial role, with many and heterogeneous types proposed so far. [sent-20, score-0.099]
</p><p>8 In addition to the classical ”feature-based” descriptors (SIFT [13], HOG [2], LBP histograms [20] to quote some), in the recent years a novel trend has emerged, which consists of discarding the intrin-  X Coordinate X Coordinate X Coordinate Figure 1. [sent-21, score-0.063]
</p><p>9 Example of non-linear relation between two features,  depth values and x- coordinates. [sent-22, score-0.043]
</p><p>10 The most known descriptor following this line is the covariance of features (COV) [17], in which linear correlations between features are exploited as elementary patterns. [sent-25, score-0.144]
</p><p>11 In the literature, relation-based descriptors exhibit a consistent invariance to many aspects (scale, illumination), making them ideal for object classes with high intra-class variability (as in the case of pedestrians [17]). [sent-26, score-0.062]
</p><p>12 In this paper, we pursue the relation-based approaches, designing a new descriptor which captures all the diverse relations that may hold between the characteristics of an object. [sent-27, score-0.132]
</p><p>13 To overcome this limitation, we propose a new local descriptor named Heterogeneous Auto-Similarities of Characteristics (HASC), which is able to encode at the same time linear and non-linear relations. [sent-32, score-0.066]
</p><p>14 The former are encoded by the covariance matrix of features (COV), and the latter are extracted by using information-theoretic measures, namely Entropy and Mutual Information, encoded into the here defined EMI matrix. [sent-33, score-0.062]
</p><p>15 The mutual information (MI) of two random variables, instead, captures generic dependencies including the nonlinear ones. [sent-35, score-0.071]
</p><p>16 The modeling of linear and non-linear feature dependencies makes HASC a versatile descriptor for a large range of applications, employing heterogeneous basic features. [sent-43, score-0.163]
</p><p>17 Through theoretical studies and synthetic experiments, we show that HASC is not a mere arbitrary juxtaposition of diverse elements, since joining together two descriptors does not guarantee an automatic improvement. [sent-45, score-0.116]
</p><p>18 In particular, if the two descriptors bring very similar information the overall performance may also decrease due to the well known curse of dimensionality phenomenon [3]. [sent-46, score-0.047]
</p><p>19 In the experiments, HASC was applied as a feature descriptor to different tasks: object recognition (Caltech-101 [6]), texture classification (Brodatz dataset [1]) and pedestrian detection (Daimler Multi-Cue [4]). [sent-47, score-0.225]
</p><p>20 In all the cases, employing simple discriminative classifiers, HASC obtains definitely higher performances than all the other considered descriptors (SIFT [13], COV [17], LBP [20], HOG [2]). [sent-48, score-0.142]
</p><p>21 In addition, we set the best performance on the texture classification and the multi-cue pedestrian classification tasks. [sent-50, score-0.174]
</p><p>22 2 our approach is introduced, with a short recap on the COV descriptor (Sec. [sent-54, score-0.066]
</p><p>23 1), and the definition of the EMI descriptor (Sec. [sent-56, score-0.066]
</p><p>24 3 report the comparative performances of HASC, and, finally, Sec. [sent-62, score-0.034]
</p><p>25 Covariance descriptor Let I(x, y) be a color image, possibly equipped with additional channels like depth, motion flow or thermal imaging. [sent-67, score-0.066]
</p><p>26 For a given rectangular patch P in F(x, y), containing K pixels, let {zk}k=1. [sent-69, score-0.033]
</p><p>27 The covariance descriptor of the patch P can be defined as follows:  ×  COVP=K1 − 1k? [sent-72, score-0.145]
</p><p>28 The d diagonal entries of the d d matrix COVP are the variances of each efenattruierse, o wfh theere das× thde m off-diagonal entries are the covariances between pairs of features. [sent-74, score-0.075]
</p><p>29 Since covariances belong to the Riemannian manifold Symd+, calculating distances among them amounts to project them into adequate tangent spaces, as pointed out in [15]; this brings to the (d2 + d)/2 vectorized version: covP  = vec(Proj(COVP)) = [COVP11  (3)  COVP21 COVP22 COVP31 . [sent-75, score-0.08]
</p><p>30 881100  As pointed out in [17], there are several advantages of using covariance matrices as region descriptors: they have been shown to be robust to noise, to pose change and low-dimensional; nevertheless, covariance descriptors have some limitations. [sent-80, score-0.157]
</p><p>31 More significantly, the covariance among two features is able to optimally encapsulate the features of the joint PDF only if they are  linked by a linear relation. [sent-83, score-0.115]
</p><p>32 As soon as their relation becomes non-linear, or their joint PDF distribution becomes multi-modal, the covariance loses its expressiveness since drastically different joint PDF may have very similar covariances. [sent-84, score-0.124]
</p><p>33 To overcome these drawbacks, we propose a new descriptor, based on entropy and mutual information among features, described in the next section. [sent-86, score-0.073]
</p><p>34 Entropy and mutual information descriptor The Mutual Information (MI) of a pair of random variables A, B is defined as  MI(A,B) =? [sent-89, score-0.111]
</p><p>35 Ap(a)log(p(a))da  (5)  If a finite set K of realizations pairs {A : ak , B : bk}Ikf= a1. [sent-95, score-0.046]
</p><p>36 fKin are saevtai Klab olef, rMeaIl can o bnes ses ptaimirsate {Ad as a sample mean of the quantity inside the logarithm 1:  MI(A,B) ≈K1? [sent-97, score-0.033]
</p><p>37 ,  (6)  Probabilities inside the logarithm can be estimated from the K realizations by Kernel Density Estimation (KDE) method, however such procedure is computationally demanding. [sent-100, score-0.051]
</p><p>38 In this work, a definitely faster alternative procedure to estimate probabilities has been adopted by building a joint 2D normalized histogram of values of A and B. [sent-101, score-0.088]
</p><p>39 In detail, each p(ak , bk) is estimated by taking the value of the 2D histogram bin in which the pair (ak , bk) falls; p(ak) and p(bk) are then estimated by summing up all the bins corresponding to ak or bk, respectively. [sent-102, score-0.095]
</p><p>40 Thus, the ij-th entry of the EMI matrix related to a patch P can be defined as follows: 1MI can be seen  as  the expectation of the quantity inside the logarithm. [sent-103, score-0.033]
</p><p>41 The EMI matrix depends only on two parameters: the number of bins on which the 2D histogram is calculated and the support given by the patch size, i. [sent-111, score-0.097]
</p><p>42 Each diagonal entry of the EMI matrix captures the  amount of uncertainty or unpredictability related to a given feature, whereas off-diagonal entries capture the mutual dependency between two different features. [sent-114, score-0.091]
</p><p>43 It is worth noting that mutual information accounts for the strength of mutual dependency, irrespective of the particular kind of dependency, be it linear or non-linear. [sent-115, score-0.09]
</p><p>44 Therefore we choose to build the EMI descriptor by simply vectorizing the (d2 + d)/2 different values of the matrix as follows: emiP = vec(EMIP) = [EMIP11 EMIP21 (8) EMIP22 EMIP31 . [sent-116, score-0.066]
</p><p>45 Combining COV and EMI: the HASC descriptor Based on their properties, COV and EMI descriptors are largely complementary, capturing different features of the joint underlying PDFs. [sent-122, score-0.144]
</p><p>46 On the contrary, EMI is able to encapsulate the degree of dependency among features but could not express the functional form that such dependency takes. [sent-125, score-0.098]
</p><p>47 Putting together the two descriptors in a larger feature space may boost the overall discriminative power. [sent-126, score-0.047]
</p><p>48 Calculation of 2D histograms can be efficiently addressed with the integral histograms ([14]), yielding a computational cost of O (N + BR), where B denotes the number of histogram bins. [sent-138, score-0.048]
</p><p>49 The logarithm of 2D histogram can be efficiently calculated by pre-allocating a look-up table of size N + 1and accessing the current value (O(B)); for 1D histograms the cost is by far inferior as they are calculated for each feature (not for each couple). [sent-139, score-0.113]
</p><p>50 Furthermore, considering that bin values equal to zero are dropped from the logarithm calculation, computational load is even decreased. [sent-144, score-0.052]
</p><p>51 As a result, from the features of the image, a d d COV and a d d EMI descriptors are hcere aimteadg. [sent-148, score-0.063]
</p><p>52 In the second case, the relation between the two features is based on the circle equation (non-linear relation), with two different noise intensities added to differentiate the two classes (see Fig. [sent-156, score-0.054]
</p><p>53 Due to the non-linear relationship between the features and different noise intensity on the two classes, classification results are opposite with respect to the previous experiments. [sent-158, score-0.068]
</p><p>54 In the third case, we create two different classes in which the relation between the two features is non-linear but can be fairly approximated with a linear one, and each class brings a Gaussian noise of different intensity. [sent-160, score-0.054]
</p><p>55 In this case, the performance for COV and EMI descriptors are similar, as shown in Fig. [sent-163, score-0.047]
</p><p>56 First of all, we compare HASC against the most popular feature descriptors (HOG, SIFT, LBP, COV, SSD)2 and the new EMI, in the object classification task, addressing the well known Caltech-101 dataset [6]. [sent-170, score-0.08]
</p><p>57 Furthermore, we carry out a detailed analysis of the impact of implementation details on the overall performances, drawing some conclusion on the descriptor robustness. [sent-172, score-0.066]
</p><p>58 For this reason, we focused on the Brodatz dataset, where texture patterns offer a rich compound of relations among basis features (intensity, gradients) and on multimodal pedestrian detection, considering the Daimler Multi-Cue Occluded Pedestrian Classification Benchmark Dataset [4]. [sent-178, score-0.146]
</p><p>59 In such a case, diverse sensor modalities introduce complex links between low-level cues, considering intensity, motion and depth: EMI is able in this case to 2Textons have been shown to be inferior to COV in the paper [16], so this should convince us about their inferiority w. [sent-179, score-0.061]
</p><p>60 881122  capture them, allowing HASC to definitely outperform its two main ingredients. [sent-183, score-0.042]
</p><p>61 In detail, we beat the previous best performance of [4] on Daimler Multi-Cue, by joining HASC with HOG+LBP, and the previous best performance of [12] on Brodatz. [sent-185, score-0.047]
</p><p>62 The overall underlying message is clear: HASC is able to finely encode relational class-specific information, surprisingly beating feature-based descriptions. [sent-186, score-0.047]
</p><p>63 Since relational and featuresbased descriptions are two sides of the same coin, joining them together appears to be a promising strategy, worth to be investigated in the future works. [sent-187, score-0.072]
</p><p>64 These last two features are particularly interesting, since they allow to distill relations that hold between particular cues and their spatial position. [sent-200, score-0.038]
</p><p>65 t oE adcihffe irmeangt patches c(4a ×ed4, t 8o × 1 85 0an ×d 11560 ×0 1pi6x )e ols,f sduifbfedrievindt pixel osidziefsfe (r6e0n t×p 6at0c, h3e2s ×(4 3×2 4a,n 8d× 186 a×n 1d61),6 overlapping rfeonrt h pailxfe lo sfi ztheesir (6 s0iz×e. [sent-207, score-0.034]
</p><p>66 6 0T,h 3e2 a×im3 2 h aerned 1is6 to× highlight tahpenet superior expressiveness of HASC in comparison with COV and EMI taken alone, as well as other descriptors. [sent-208, score-0.04]
</p><p>67 Moreover, to achieve the state-of-the-art on Caltech-101, it is nowadays mandatory to employ kernelized fusion of multiple descriptors [7], which would obscure the specific contribution of HASC. [sent-214, score-0.061]
</p><p>68 In this setting, the final feature vector for an image was the simple concatenation of the feature vectors for each patch and a linear SVM was used as classifier (we also applied another classifier, i. [sent-215, score-0.05]
</p><p>69 Random Forest, but it did not provide consistent improvements probably due to the relatively high dimension of the image descriptors involved). [sent-217, score-0.047]
</p><p>70 Results show that  ×  the HASC descriptor significantly outperforms all the other competitors. [sent-219, score-0.066]
</p><p>71 Classification results for the Caltech-101 dataset  On this dataset, we investigate how the size and the number of the patches employed, and the number of bins used for the EMI computation affect the overall performances. [sent-224, score-0.066]
</p><p>72 In particular, the number of patches was constrained on their size, in a way that the whole image has to be covered by patches, that overlap for half of their sizes. [sent-225, score-0.034]
</p><p>73 only one patch per image, is not very informative, no matter the number of bins adopted. [sent-230, score-0.065]
</p><p>74 The lower bound on the size of the patches is 8 8 pixels, since with lboowuenrd s oinze tsh teh sei performances degrade dramatically, as tihteh statistics employed is too scarce. [sent-231, score-0.068]
</p><p>75 For EMI the best result is achieved with 12 bins and patch size of 16 − 32; note that  awcihthie increasing 2th bei patch s pizaetc thhe s zbees ot performance ties tohba-t tained by increasing the number of bins as well. [sent-232, score-0.13]
</p><p>76 For HASC, the overall performance obviously increases and the dependence on the number of bins is dampened due to the contribution of COV (whose calculation does not imply bin quantization). [sent-233, score-0.067]
</p><p>77 The accuracy ofthe HASC and EMI descriptor versus the number of bins and patch size. [sent-236, score-0.131]
</p><p>78 The configuration with 8 8 patches aantd h a2lf8 obifn ths performs zbee. [sent-238, score-0.034]
</p><p>79 (12)  For each image, s = 100 random square patches of random sizes between 16 16 and 128 128 are extracted and tdhoem mH sAizSeCs descriptor 6is× ×c1a6lcu anladte 1d2 on ×ea12ch8 patch. [sent-253, score-0.1]
</p><p>80 rIna cthteed te anstding phase, the same number of patches is extracted on each image. [sent-254, score-0.034]
</p><p>81 For each patch, the distance between the extracted HASC descriptor and all the training HASCs is measured and the label is predicted according to the majority voting among the k = 5 nearest ones (kNN algorithm). [sent-255, score-0.066]
</p><p>82 66%, which amounts to fail on 3 images, beating the best classification score of [12] (97. [sent-259, score-0.055]
</p><p>83 Pedestrian Detection For the pedestrian classification task, we consider the Daimler Multi-Cue Occluded Pedestrian Classifica881144  (a)  (b) Figure 4. [sent-277, score-0.117]
</p><p>84 As alternative descriptors, we focus on COV and EMI descriptors as well as HOG [2] and LBP [23], already applied on this dataset [5]. [sent-286, score-0.047]
</p><p>85 For the depth and motion flow modalities, the depth value and the module of the motion flow are considered as image intensities. [sent-298, score-0.04]
</p><p>86 For each image, EMI and COV matrices are extracted on a set of patches of different size, fusing together the different modalities in a natural way, resulting in 23 23 matrices. [sent-299, score-0.057]
</p><p>87 The global feature vector, fed to a linear SVM classifier, is given by d + d2 elements of the vectorized HASC (d = 23) multiplied by the total number of patches (34), yielding a total of 17204 features. [sent-301, score-0.069]
</p><p>88 4 (a) the detection rate curves for all the descriptors are reported, showing that HASC definitely outperforms COV, EMI, HOG and LBP. [sent-305, score-0.121]
</p><p>89 The simpler one consists in joining together all LBP and HOG descriptors and feed the final feature vector to a linear SVM. [sent-308, score-0.094]
</p><p>90 Each classifier, defined by a Multi Layer Perceptron (MLP), is related to a single feature (HOG or LBP), single visual modality, and single pedestrian pose. [sent-310, score-0.084]
</p><p>91 4 (b) show that HASC definitely outperforms the combination of HOG and LBP using a linear SVM. [sent-312, score-0.042]
</p><p>92 Moreover, joining together HASC, HOG and LBP and using a linear SVM outperform the best result in [5] despite the  881155 latter is obtained with a much more complex classification scheme. [sent-313, score-0.08]
</p><p>93 This is significant, since it demonstrates how well HASC encodes exclusive aspects that the other two descriptors fail to capture. [sent-314, score-0.047]
</p><p>94 Once again the value obtained by joining together HASC + HOG + LBP improves the state-of-the-art by a factor of 1. [sent-318, score-0.047]
</p><p>95 Conclusions In this paper, we presented a novel relation-based feature descriptor, HASC, which is capable to subsume all possible dependencies between low-level dense features ofvisual entities. [sent-323, score-0.042]
</p><p>96 Our proposal represents a step ahead with respect to the state-of-the-art of the relation-based strategies for object description, represented by the covariance of features (COV). [sent-324, score-0.062]
</p><p>97 Future perspectives are essentially focused on embedding HASC into more challenging classifiers, in order to raise their best performances in diverse scenarios. [sent-327, score-0.056]
</p><p>98 Local log-euclidean covariance matrix (l2ecm) for image representation and its applications. [sent-398, score-0.046]
</p><p>99 Region covariance: A fast descriptor for detection and classification. [sent-422, score-0.084]
</p><p>100 Local features and kernels for classification of texture and object categories: A comprehensive study. [sent-469, score-0.073]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hasc', 0.732), ('emi', 0.476), ('cov', 0.302), ('lbp', 0.121), ('daimler', 0.1), ('pedestrian', 0.084), ('brodatz', 0.076), ('covp', 0.073), ('descriptor', 0.066), ('marco', 0.065), ('hog', 0.059), ('pdf', 0.055), ('heterogeneous', 0.052), ('emip', 0.049), ('descriptors', 0.047), ('joining', 0.047), ('covariance', 0.046), ('mutual', 0.045), ('covariances', 0.043), ('definitely', 0.042), ('vxx', 0.037), ('vyy', 0.037), ('patches', 0.034), ('performances', 0.034), ('mi', 0.034), ('logarithm', 0.033), ('patch', 0.033), ('classification', 0.033), ('bins', 0.032), ('dependency', 0.03), ('bk', 0.03), ('fv', 0.029), ('entropy', 0.028), ('ak', 0.028), ('vy', 0.026), ('dependencies', 0.026), ('vx', 0.025), ('expressiveness', 0.025), ('relational', 0.025), ('fmed', 0.024), ('verona', 0.024), ('texture', 0.024), ('modalities', 0.023), ('relation', 0.023), ('relations', 0.022), ('diverse', 0.022), ('characteristics', 0.022), ('tuzel', 0.022), ('beating', 0.022), ('encapsulate', 0.022), ('mlp', 0.022), ('zk', 0.021), ('iyy', 0.02), ('proj', 0.02), ('modality', 0.02), ('depth', 0.02), ('employing', 0.019), ('bin', 0.019), ('intensity', 0.019), ('hayman', 0.019), ('ixx', 0.019), ('vectorized', 0.019), ('multi', 0.018), ('pointed', 0.018), ('perceptron', 0.018), ('realizations', 0.018), ('detection', 0.018), ('riemannian', 0.018), ('pages', 0.017), ('svm', 0.017), ('twenty', 0.017), ('complementarity', 0.017), ('classifier', 0.017), ('moe', 0.017), ('fpr', 0.017), ('calculation', 0.016), ('spin', 0.016), ('enzweiler', 0.016), ('fed', 0.016), ('features', 0.016), ('alone', 0.016), ('calculated', 0.016), ('inferior', 0.016), ('italy', 0.016), ('entries', 0.016), ('histogram', 0.016), ('histograms', 0.016), ('highlight', 0.015), ('adopted', 0.015), ('classes', 0.015), ('joint', 0.015), ('porikli', 0.014), ('entities', 0.014), ('nowadays', 0.014), ('vec', 0.014), ('sift', 0.014), ('br', 0.014), ('rate', 0.014), ('classifiers', 0.014), ('lazebnik', 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="193-tfidf-1" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>Author: Marco San_Biagio, Marco Crocco, Marco Cristani, Samuele Martelli, Vittorio Murino</p><p>Abstract: Capturing the essential characteristics of visual objects by considering how their features are inter-related is a recent philosophy of object classification. In this paper, we embed this principle in a novel image descriptor, dubbed Heterogeneous Auto-Similarities of Characteristics (HASC). HASC is applied to heterogeneous dense features maps, encoding linear relations by covariances and nonlinear associations through information-theoretic measures such as mutual information and entropy. In this way, highly complex structural information can be expressed in a compact, scale invariant and robust manner. The effectiveness of HASC is tested on many diverse detection and classification scenarios, considering objects, textures and pedestrians, on widely known benchmarks (Caltech-101, Brodatz, Daimler Multi-Cue). In all the cases, the results obtained with standard classifiers demonstrate the superiority of HASC with respect to the most adopted local feature descriptors nowadays, such as SIFT, HOG, LBP and feature covariances. In addition, HASC sets the state-of-the-art on the Brodatz texture dataset and the Daimler Multi-Cue pedestrian dataset, without exploiting ad-hoc sophisticated classifiers.</p><p>2 0.068880439 <a title="193-tfidf-2" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>3 0.056789014 <a title="193-tfidf-3" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>4 0.047180824 <a title="193-tfidf-4" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>Author: Sakrapee Paisitkriangkrai, Chunhua Shen, Anton Van Den Hengel</p><p>Abstract: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). Effective cascade-based classification, for example, depends on training node classifiers that achieve the maximal detection rate at a moderate false positive rate, e.g., around 40% to 50%. We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. By optimizing for different ranges of false positive rates, the proposed method can be used to train either a single strong classifier or a node classifier forming part of a cascade classifier. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the pro- posed structured ensemble learning method.</p><p>5 0.04531436 <a title="193-tfidf-5" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: Automatic image categorization has become increasingly important with the development of Internet and the growth in the size of image databases. Although the image categorization can be formulated as a typical multiclass classification problem, two major challenges have been raised by the real-world images. On one hand, though using more labeled training data may improve the prediction performance, obtaining the image labels is a time consuming as well as biased process. On the other hand, more and more visual descriptors have been proposed to describe objects and scenes appearing in images and different features describe different aspects of the visual characteristics. Therefore, how to integrate heterogeneous visual features to do the semi-supervised learning is crucial for categorizing large-scale image data. In this paper, we propose a novel approach to integrate heterogeneous features by performing multi-modal semi-supervised classification on unlabeled as well as unsegmented images. Considering each type of feature as one modality, taking advantage of the large amoun- t of unlabeled data information, our new adaptive multimodal semi-supervised classification (AMMSS) algorithm learns a commonly shared class indicator matrix and the weights for different modalities (image features) simultaneously.</p><p>6 0.045215253 <a title="193-tfidf-6" href="./iccv-2013-HOGgles%3A_Visualizing_Object_Detection_Features.html">189 iccv-2013-HOGgles: Visualizing Object Detection Features</a></p>
<p>7 0.044439573 <a title="193-tfidf-7" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>8 0.043403171 <a title="193-tfidf-8" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>9 0.041755065 <a title="193-tfidf-9" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>10 0.041270554 <a title="193-tfidf-10" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>11 0.037892848 <a title="193-tfidf-11" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>12 0.036725689 <a title="193-tfidf-12" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>13 0.036560003 <a title="193-tfidf-13" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>14 0.036496993 <a title="193-tfidf-14" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>15 0.034849185 <a title="193-tfidf-15" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>16 0.034430638 <a title="193-tfidf-16" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>17 0.033504073 <a title="193-tfidf-17" href="./iccv-2013-Allocentric_Pose_Estimation.html">46 iccv-2013-Allocentric Pose Estimation</a></p>
<p>18 0.033470385 <a title="193-tfidf-18" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>19 0.033436511 <a title="193-tfidf-19" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>20 0.033085987 <a title="193-tfidf-20" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.094), (1, 0.008), (2, 0.002), (3, -0.025), (4, 0.004), (5, -0.004), (6, 0.0), (7, 0.013), (8, -0.02), (9, -0.029), (10, 0.009), (11, -0.02), (12, 0.025), (13, -0.015), (14, 0.043), (15, -0.014), (16, -0.004), (17, 0.005), (18, 0.039), (19, 0.059), (20, -0.007), (21, 0.021), (22, -0.014), (23, 0.015), (24, -0.014), (25, 0.028), (26, 0.013), (27, 0.027), (28, -0.013), (29, 0.044), (30, -0.005), (31, 0.024), (32, -0.008), (33, 0.018), (34, -0.006), (35, -0.027), (36, 0.004), (37, -0.014), (38, -0.002), (39, -0.012), (40, -0.009), (41, 0.005), (42, -0.066), (43, 0.032), (44, -0.027), (45, -0.024), (46, 0.005), (47, 0.002), (48, 0.011), (49, -0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89683789 <a title="193-lsi-1" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>Author: Marco San_Biagio, Marco Crocco, Marco Cristani, Samuele Martelli, Vittorio Murino</p><p>Abstract: Capturing the essential characteristics of visual objects by considering how their features are inter-related is a recent philosophy of object classification. In this paper, we embed this principle in a novel image descriptor, dubbed Heterogeneous Auto-Similarities of Characteristics (HASC). HASC is applied to heterogeneous dense features maps, encoding linear relations by covariances and nonlinear associations through information-theoretic measures such as mutual information and entropy. In this way, highly complex structural information can be expressed in a compact, scale invariant and robust manner. The effectiveness of HASC is tested on many diverse detection and classification scenarios, considering objects, textures and pedestrians, on widely known benchmarks (Caltech-101, Brodatz, Daimler Multi-Cue). In all the cases, the results obtained with standard classifiers demonstrate the superiority of HASC with respect to the most adopted local feature descriptors nowadays, such as SIFT, HOG, LBP and feature covariances. In addition, HASC sets the state-of-the-art on the Brodatz texture dataset and the Daimler Multi-Cue pedestrian dataset, without exploiting ad-hoc sophisticated classifiers.</p><p>2 0.73098975 <a title="193-lsi-2" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>3 0.7001738 <a title="193-lsi-3" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>Author: Sakrapee Paisitkriangkrai, Chunhua Shen, Anton Van Den Hengel</p><p>Abstract: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). Effective cascade-based classification, for example, depends on training node classifiers that achieve the maximal detection rate at a moderate false positive rate, e.g., around 40% to 50%. We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. By optimizing for different ranges of false positive rates, the proposed method can be used to train either a single strong classifier or a node classifier forming part of a cascade classifier. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the pro- posed structured ensemble learning method.</p><p>4 0.69681001 <a title="193-lsi-4" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>5 0.69307137 <a title="193-lsi-5" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>Author: João F. Henriques, João Carreira, Rui Caseiro, Jorge Batista</p><p>Abstract: Competitive sliding window detectors require vast training sets. Since a pool of natural images provides a nearly endless supply of negative samples, in the form of patches at different scales and locations, training with all the available data is considered impractical. A staple of current approaches is hard negative mining, a method of selecting relevant samples, which is nevertheless expensive. Given that samples at slightly different locations have overlapping support, there seems to be an enormous amount of duplicated work. It is natural, then, to ask whether these redundancies can be eliminated. In this paper, we show that the Gram matrix describing such data is block-circulant. We derive a transformation based on the Fourier transform that block-diagonalizes the Gram matrix, at once eliminating redundancies and partitioning the learning problem. This decomposition is valid for any dense features and several learning algorithms, and takes full advantage of modern parallel architectures. Surprisingly, it allows training with all the potential samples in sets of thousands of images. By considering the full set, we generate in a single shot the optimal solution, which is usually obtained only after several rounds of hard negative mining. We report speed gains on Caltech Pedestrians and INRIA Pedestrians of over an order of magnitude, allowing training on a desktop computer in a couple of minutes.</p><p>6 0.67712337 <a title="193-lsi-6" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>7 0.6342262 <a title="193-lsi-7" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>8 0.61522895 <a title="193-lsi-8" href="./iccv-2013-Shape_Index_Descriptors_Applied_to_Texture-Based_Galaxy_Analysis.html">388 iccv-2013-Shape Index Descriptors Applied to Texture-Based Galaxy Analysis</a></p>
<p>9 0.61285973 <a title="193-lsi-9" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>10 0.61133724 <a title="193-lsi-10" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>11 0.60363597 <a title="193-lsi-11" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>12 0.60268313 <a title="193-lsi-12" href="./iccv-2013-SIFTpack%3A_A_Compact_Representation_for_Efficient_SIFT_Matching.html">365 iccv-2013-SIFTpack: A Compact Representation for Efficient SIFT Matching</a></p>
<p>13 0.59350806 <a title="193-lsi-13" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>14 0.58886129 <a title="193-lsi-14" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>15 0.587466 <a title="193-lsi-15" href="./iccv-2013-Unbiased_Metric_Learning%3A_On_the_Utilization_of_Multiple_Datasets_and_Web_Images_for_Softening_Bias.html">431 iccv-2013-Unbiased Metric Learning: On the Utilization of Multiple Datasets and Web Images for Softening Bias</a></p>
<p>16 0.58626747 <a title="193-lsi-16" href="./iccv-2013-Revisiting_Example_Dependent_Cost-Sensitive_Learning_with_Decision_Trees.html">352 iccv-2013-Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees</a></p>
<p>17 0.57990062 <a title="193-lsi-17" href="./iccv-2013-Ensemble_Projection_for_Semi-supervised_Image_Classification.html">142 iccv-2013-Ensemble Projection for Semi-supervised Image Classification</a></p>
<p>18 0.57922894 <a title="193-lsi-18" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>19 0.57550007 <a title="193-lsi-19" href="./iccv-2013-The_Interestingness_of_Images.html">416 iccv-2013-The Interestingness of Images</a></p>
<p>20 0.57192755 <a title="193-lsi-20" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.056), (4, 0.024), (7, 0.034), (12, 0.01), (13, 0.016), (26, 0.063), (31, 0.046), (35, 0.013), (40, 0.016), (42, 0.078), (48, 0.017), (57, 0.24), (64, 0.039), (73, 0.034), (78, 0.012), (89, 0.154), (95, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75364667 <a title="193-lda-1" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>Author: Marco San_Biagio, Marco Crocco, Marco Cristani, Samuele Martelli, Vittorio Murino</p><p>Abstract: Capturing the essential characteristics of visual objects by considering how their features are inter-related is a recent philosophy of object classification. In this paper, we embed this principle in a novel image descriptor, dubbed Heterogeneous Auto-Similarities of Characteristics (HASC). HASC is applied to heterogeneous dense features maps, encoding linear relations by covariances and nonlinear associations through information-theoretic measures such as mutual information and entropy. In this way, highly complex structural information can be expressed in a compact, scale invariant and robust manner. The effectiveness of HASC is tested on many diverse detection and classification scenarios, considering objects, textures and pedestrians, on widely known benchmarks (Caltech-101, Brodatz, Daimler Multi-Cue). In all the cases, the results obtained with standard classifiers demonstrate the superiority of HASC with respect to the most adopted local feature descriptors nowadays, such as SIFT, HOG, LBP and feature covariances. In addition, HASC sets the state-of-the-art on the Brodatz texture dataset and the Daimler Multi-Cue pedestrian dataset, without exploiting ad-hoc sophisticated classifiers.</p><p>2 0.73067689 <a title="193-lda-2" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>Author: Samuel Schulter, Christian Leistner, Paul Wohlhart, Peter M. Roth, Horst Bischof</p><p>Abstract: We present Alternating Regression Forests (ARFs), a novel regression algorithm that learns a Random Forest by optimizing a global loss function over all trees. This interrelates the information of single trees during the training phase and results in more accurate predictions. ARFs can minimize any differentiable regression loss without sacrificing the appealing properties of Random Forests, like low computational complexity during both, training and testing. Inspired by recent developments for classification [19], we derive a new algorithm capable of dealing with different regression loss functions, discuss its properties and investigate the relations to other methods like Boosted Trees. We evaluate ARFs on standard machine learning benchmarks, where we observe better generalization power compared to both standard Random Forests and Boosted Trees. Moreover, we apply the proposed regressor to two computer vision applications: object detection and head pose estimation from depth images. ARFs outperform the Random Forest baselines in both tasks, illustrating the importance of optimizing a common loss function for all trees.</p><p>3 0.70067096 <a title="193-lda-3" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>Author: Wen-Yan Lin, Ming-Ming Cheng, Shuai Zheng, Jiangbo Lu, Nigel Crook</p><p>Abstract: We propose a generic method for obtaining nonparametric image warps from noisy point correspondences. Our formulation integrates a huber function into a motion coherence framework. This makes our fitting function especially robust to piecewise correspondence noise (where an image section is consistently mismatched). By utilizing over parameterized curves, we can generate realistic nonparametric image warps from very noisy correspondence. We also demonstrate how our algorithm can be used to help stitch images taken from a panning camera by warping the images onto a virtual push-broom camera imaging plane.</p><p>4 0.66440547 <a title="193-lda-4" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>Author: Fuxin Li, Taeyoung Kim, Ahmad Humayun, David Tsai, James M. Rehg</p><p>Abstract: We propose an unsupervised video segmentation approach by simultaneously tracking multiple holistic figureground segments. Segment tracks are initialized from a pool of segment proposals generated from a figure-ground segmentation algorithm. Then, online non-local appearance models are trained incrementally for each track using a multi-output regularized least squares formulation. By using the same set of training examples for all segment tracks, a computational trick allows us to track hundreds of segment tracks efficiently, as well as perform optimal online updates in closed-form. Besides, a new composite statistical inference approach is proposed for refining the obtained segment tracks, which breaks down the initial segment proposals and recombines for better ones by utilizing highorder statistic estimates from the appearance model and enforcing temporal consistency. For evaluating the algorithm, a dataset, SegTrack v2, is collected with about 1,000 frames with pixel-level annotations. The proposed framework outperforms state-of-the-art approaches in the dataset, show- ing its efficiency and robustness to challenges in different video sequences.</p><p>5 0.64145744 <a title="193-lda-5" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>Author: Lukáš Neumann, Jiri Matas</p><p>Abstract: An unconstrained end-to-end text localization and recognition method is presented. The method introduces a novel approach for character detection and recognition which combines the advantages of sliding-window and connected component methods. Characters are detected and recognized as image regions which contain strokes of specific orientations in a specific relative position, where the strokes are efficiently detected by convolving the image gradient field with a set of oriented bar filters. Additionally, a novel character representation efficiently calculated from the values obtained in the stroke detection phase is introduced. The representation is robust to shift at the stroke level, which makes it less sensitive to intra-class variations and the noise induced by normalizing character size and positioning. The effectiveness of the representation is demonstrated by the results achieved in the classification of real-world characters using an euclidian nearestneighbor classifier trained on synthetic data in a plain form. The method was evaluated on a standard dataset, where it achieves state-of-the-art results in both text localization and recognition.</p><p>6 0.63665819 <a title="193-lda-6" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>7 0.63653302 <a title="193-lda-7" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>8 0.63522935 <a title="193-lda-8" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>9 0.63468981 <a title="193-lda-9" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>10 0.63379824 <a title="193-lda-10" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>11 0.63367307 <a title="193-lda-11" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>12 0.63352782 <a title="193-lda-12" href="./iccv-2013-Visual_Reranking_through_Weakly_Supervised_Multi-graph_Learning.html">445 iccv-2013-Visual Reranking through Weakly Supervised Multi-graph Learning</a></p>
<p>13 0.63332856 <a title="193-lda-13" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>14 0.63305598 <a title="193-lda-14" href="./iccv-2013-PhotoOCR%3A_Reading_Text_in_Uncontrolled_Conditions.html">315 iccv-2013-PhotoOCR: Reading Text in Uncontrolled Conditions</a></p>
<p>15 0.63300997 <a title="193-lda-15" href="./iccv-2013-Detecting_Dynamic_Objects_with_Multi-view_Background_Subtraction.html">111 iccv-2013-Detecting Dynamic Objects with Multi-view Background Subtraction</a></p>
<p>16 0.63234448 <a title="193-lda-16" href="./iccv-2013-Real-Time_Articulated_Hand_Pose_Estimation_Using_Semi-supervised_Transductive_Regression_Forests.html">340 iccv-2013-Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests</a></p>
<p>17 0.63127112 <a title="193-lda-17" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>18 0.63119566 <a title="193-lda-18" href="./iccv-2013-Shortest_Paths_with_Curvature_and_Torsion.html">389 iccv-2013-Shortest Paths with Curvature and Torsion</a></p>
<p>19 0.63100445 <a title="193-lda-19" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>20 0.6306144 <a title="193-lda-20" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
