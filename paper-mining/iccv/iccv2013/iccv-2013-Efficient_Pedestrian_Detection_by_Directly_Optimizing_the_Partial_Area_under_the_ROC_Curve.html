<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-136" href="#">iccv2013-136</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</h1>
<br/><p>Source: <a title="iccv-2013-136-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Paisitkriangkrai_Efficient_Pedestrian_Detection_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Sakrapee Paisitkriangkrai, Chunhua Shen, Anton Van Den Hengel</p><p>Abstract: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). Effective cascade-based classification, for example, depends on training node classifiers that achieve the maximal detection rate at a moderate false positive rate, e.g., around 40% to 50%. We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. By optimizing for different ranges of false positive rates, the proposed method can be used to train either a single strong classifier or a node classifier forming part of a cascade classifier. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the pro- posed structured ensemble learning method.</p><p>Reference: <a title="iccv-2013-136-reference" href="../iccv2013_reference/iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. [sent-2, score-0.207]
</p><p>2 This measure is labelled as the partial area under the ROC curve (pAUC). [sent-3, score-0.207]
</p><p>3 Effective cascade-based classification, for example, depends on training node classifiers that achieve the maximal detection rate at a moderate false positive rate, e. [sent-4, score-0.436]
</p><p>4 We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. [sent-7, score-0.578]
</p><p>5 By optimizing for different ranges of false positive rates, the proposed method can be used to train either a single strong classifier or a node classifier forming part of a cascade classifier. [sent-8, score-0.599]
</p><p>6 Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the pro-  posed structured ensemble learning method. [sent-9, score-0.265]
</p><p>7 The task of object detection is to identify predefined objects in a given image using knowledge gained through analysis of a set oflabelled positive and negative exemplars. [sent-12, score-0.206]
</p><p>8 In the face and human detection literature researchers are often interested in the low false positive area of the ∗This work was in part supported by ARC grant FT120100969. [sent-16, score-0.306]
</p><p>9 This is due to the fact that object detection is a highly asymmetric classification problem as there are only a small number of target objects among millions of background patches in the single test image. [sent-21, score-0.191]
</p><p>10 A false positive rate of 10−3 per scanning window would result in thousands of false positives in a single image, which is impractical for most applications. [sent-22, score-0.413]
</p><p>11 For  many tasks, and particularly human detection, researchers also report the partial area under the ROC curve (pAUC), typically over the range 0. [sent-23, score-0.24]
</p><p>12 As the name implies, pAUC is calculated as the area under the ROC curve between two specified false positive rates (FPRs). [sent-26, score-0.303]
</p><p>13 In this paper, we present a principled approach for learning an ensemble classifier which directly optimizes the partial area under the ROC curve, where the range over which the area is calculated may be selected according to the desired application. [sent-29, score-0.529]
</p><p>14 Built upon the structured learning framework, we thus propose here a novel form of ensemble classifier which directly optimizes the partial AUC score, which we call pAUCEns. [sent-30, score-0.364]
</p><p>15 As with all other boosting algorithms, our approach learns a predictor by building an ensemble of weak classification rules in a greedy fashion. [sent-31, score-0.304]
</p><p>16 However, unlike traditional boosting, at each iteration, the proposed approach places a greater emphasis on samples which have the incorrect ordering1 to achieve the optimal partial AUC score. [sent-33, score-0.168]
</p><p>17 In other words, we want all positive samples to be ranked above all negative samples. [sent-35, score-0.175]
</p><p>18 Main contributions (1) We propose a new ensemble learning approach which explicitly optimizes the partial area under the ROC curve (pAUC) between any two given false positive rates. [sent-37, score-0.596]
</p><p>19 The approach shares similarities with conventional boosting methods, but differs significantly in that the proposed method optimizes a multivariate performance measure using structured learning. [sent-39, score-0.18]
</p><p>20 Our approach is efficient since it exploits both the efficient weak classifier training and the efficient cutting plane solver for optimizing the partial AUC score in the structural SVM setting. [sent-41, score-0.489]
</p><p>21 (2) We show that our approach is more intuitive and simpler to use than alternative algorithms, such as Asymmetric AdaBoost [23] and Cost-Sensitive AdaBoost [14], where one needs to crossvalidate the asymmetric parameter from a fixed set of dis-  crete points. [sent-42, score-0.185]
</p><p>22 Furthermore, it is unclear how one would set the asymmetric parameter in order to achieve a maximal pAUC score for a specified false positive range. [sent-43, score-0.405]
</p><p>23 To our knowledge, our approach is the first principled ensemble method that directly optimizes the partial AUC in an arbitrary false positive range [α, β] . [sent-44, score-0.585]
</p><p>24 Our pedestrian detector performs better than or on par with the state-of-the-art, despite the fact that our detector only uses two standard low-level image features. [sent-46, score-0.286]
</p><p>25 Related work Various ensemble classifiers have been proposed in the literature. [sent-47, score-0.141]
</p><p>26 Classifiers that are optimal under the symmetric cost, and thus treat false positives and negatives equally, cannot exploit this information [17, 23]. [sent-50, score-0.168]
</p><p>27 Several cost sensitive learning algorithms, where the classifier weights a positive class more heavily than a negative class, have thus been proposed. [sent-51, score-0.218]
</p><p>28 However, the authors reported that this asymmetry is immediately absorbed by the first weak classifier. [sent-53, score-0.163]
</p><p>29 In addition, one needs to carefully crossvalidate this asymmetric parameter in order to achieve the  desired result. [sent-55, score-0.185]
</p><p>30 In addition, one needs to carefully crossvalidate the asymmetric parameter in order to maximize the detection rate in a particular false positive range. [sent-59, score-0.489]
</p><p>31 Narasimhan and Agarwal develop a structural SVM based method which directly optimizes the pAUC score [16]. [sent-63, score-0.202]
</p><p>32 Building on Narasimhan and Agarwal’s work, we propose the principled fully-corrective ensemble method which directly optimizes the pAUC evaluation criterion. [sent-65, score-0.234]
</p><p>33 The approach is flexible and can be applied to an arbitrary false positive range [α, β] . [sent-66, score-0.263]
</p><p>34 To our knowledge, our approach is the first principled ensemble learning method that directly optimizes the partial AUC in a false positive range not bounded by zero. [sent-67, score-0.585]
</p><p>35 [16] train a linear structural SVM while our approach learns  the ensemble of classifiers. [sent-69, score-0.163]
</p><p>36 For pedestrian detection, HOG with the ensemble of classifiers reduces the average missrate over HOG+SVM by more than 30% [2]. [sent-70, score-0.27]
</p><p>37 Let {xi+}im=1 be the set of positive training data and {xj− }jn=1 {bxe th}e set of negative training data. [sent-76, score-0.211]
</p><p>38 Assuming that we have k possible weak learners, the output of weak learners for positive and negative data can be represented as H = (H+ , H− ) where H+ ∈ Rk×m and H−∈ Rk×n, respectively. [sent-79, score-0.477]
</p><p>39 Each column h:l of the( )m oatnri txh eH p represents tihneg output of all weak learners when applied to the training instance xl . [sent-82, score-0.265]
</p><p>40 Each row ht: of the matrix H represents the output predicted by the weak learner ? [sent-83, score-0.267]
</p><p>41 ,  (1)  and the partial AUC in the false positive range [α, β] can be written as [5, 16],  pAUC =mn(β1 − α)i? [sent-92, score-0.351]
</p><p>42 the negative instance in S−ranked in the j-th position amongst negative samples in descending order of scores. [sent-112, score-0.156]
</p><p>43 x that optimizes the pAUC in an FPR range of [α, β] . [sent-126, score-0.165]
</p><p>44 For any ordering of the training instances, the relative ordering of m positive  instances and n negative instances is represented via a matrix π ∈ {0, 1}m×n where,  πij=? [sent-128, score-0.339]
</p><p>45 The pAUC loss in the false positive range [α, β=] o f0 π iw,jit. [sent-131, score-0.263]
</p><p>46 In contrast to the previously described structured learning, we learn the scoring function, which optimizes the area under the curve between two false positive rates of the form: f(x) = wt? [sent-160, score-0.447]
</p><p>47 (tx ()·) w}tkh=e1r ed weno ∈te a set of binary weak fliecairennetrs v. [sent-163, score-0.137]
</p><p>48 Πm,n  Finding best weak learners In this section, we show how one can explicitly learn the projection function, ? [sent-202, score-0.193]
</p><p>49 ·−·  11005599  For the weak learner in the current working set, the corresponding condition in (10) is satisfied by the current so-  lution. [sent-218, score-0.267]
</p><p>50 For the weak learner that are not yet selected, they do not appear in the current restricted optimization problem and the cor? [sent-219, score-0.267]
</p><p>51 Hence the subproblem for selecting the best weak learner is: −  ? [sent-231, score-0.267]
</p><p>52 subproblem for generating the optimal weak learner at iteration t can be defined as,  ? [sent-267, score-0.267]
</p><p>53 the positive training samples (i = 1, · · · , m), the negative training samples (j = 1, · · · , n) a1n,·d· t·h ,em en),ti trhee training samples g(l s =m 1l,e 2s,· ( ·j j· ,m 1+, ·n··), respectively. [sent-313, score-0.327]
</p><p>54 s, the last equation in (12) is always valid since the weak learner set H is negation-closed [12]. [sent-319, score-0.267]
</p><p>55 best weak learner is not heuristic as the solution to (11) de? [sent-340, score-0.267]
</p><p>56 Optimizing weak learners’ coefficients We solve for the optimal w that minimizes our objective function (7). [sent-343, score-0.137]
</p><p>57 Discussion Our final ensemble classifier has a similar form as the AdaBoost-based object detector of [24]. [sent-373, score-0.222]
</p><p>58 The major difference between AdaBoost and our approach is in step and { where the weak learner’s coefficient is computed and the sample weights are updated. [sent-376, score-0.137]
</p><p>59 3sriT;nehgmtwisne cma;kutleinwagrpelhtnd † For a node in a cascade classifier, we introduce the? [sent-408, score-0.148]
</p><p>60 achieves the node learning objective;  fiers: the strong classifier [6] and the node classifier [24,27]. [sent-412, score-0.28]
</p><p>61 We use vertical and horizontal decision stumps as the weak classifier. [sent-420, score-0.196]
</p><p>62 We evaluate the partial AUC score of different algorithms at [0, 0. [sent-421, score-0.154]
</p><p>63 For each algorithm, we train a strong classifier consisting of 10 and 25 weak classifiers. [sent-423, score-0.276]
</p><p>64 We observe that pAUCEns places more emphasis on positive samples than negative samples to ensure the highest detection rate at the left-most part of the ROC curve (FPR < 0. [sent-428, score-0.428]
</p><p>65 Even though we choose the asymmetric parameter, k, from a large range of values, both CS-AdaBoost and AsymBoost perform slightly worse than our approach. [sent-430, score-0.188]
</p><p>66 However as the number of weak classifiers increases (> 50 stumps), we observe all algorithms perform similarly 2We set the threshold such that the false positive rate is 0. [sent-432, score-0.447]
</p><p>67 In the next experiment, we train a strong classifier of 10 weak classifiers and compare the performance of different classifiers at FPR of 0. [sent-447, score-0.366]
</p><p>68 We choose this value since it is the node learning goal often used in training a cascade classifier. [sent-449, score-0.18]
</p><p>69 Also we only learn 10 weak classifiers since the first node of the cascade often contains a small number of weak classifiers for real-time performance. [sent-450, score-0.512]
</p><p>70 2, we display the decision boundary of each algorithm, and display both their pAUC score (in the FPR range [0. [sent-455, score-0.142]
</p><p>71 We observe that our approach and AsymBoost have the highest detection rate at 50% false positive rate. [sent-458, score-0.324]
</p><p>72 We observe that our approach places more emphasis on positive samples near the corners (at π/4, 3π/4, −π/4 and −3π/4 angles) than  othtehe cro algorithms. [sent-460, score-0.183]
</p><p>73 We train a linear classifier as our weak learner using LIBLINEAR [8]. [sent-469, score-0.378]
</p><p>74 Comparison to other asymmetric boosting Here we compare pAUCEns against several boosting algorithms previously proposed for the problem of object detection, namely, AdaBoost with Fisher LDA post-processing [27], AsymBoost [23] and CS-AdaBoost [14]. [sent-530, score-0.274]
</p><p>75 For each algorithm, we train a strong classifier consisting of 100 weak classifiers. [sent-532, score-0.276]
</p><p>76 Pedestrian detection - Strong classifier We evaluate our approach on the pedestrian detection task. [sent-547, score-0.318]
</p><p>77 For the positive training data, we use all 2416 INRIA cropped pedestrian  images. [sent-552, score-0.244]
</p><p>78 To generate the negative training data, we first train the cascade classifier with 20 nodes using Viola and Jones’ approach. [sent-553, score-0.3]
</p><p>79 We then combine 2416 random negative windows generated in the first node with another 4832 negative windows generated in the subsequent nodes. [sent-554, score-0.229]
</p><p>80 The resulting 7248 negative windows are used for training the strong classifier. [sent-555, score-0.147]
</p><p>81 3%  Table 3: The pAUC score in the FPR range [0,β] on the training set. [sent-574, score-0.154]
</p><p>82 We use weighted linear discriminant analysis (WLDA) as weak classifiers [17]. [sent-584, score-0.182]
</p><p>83 We train 500 weak classifiers and set 5 multi-exits [18]. [sent-585, score-0.222]
</p><p>84 5] FPPI (144 false positives) and [0, 1] FPPI (288 false positives) in Table 3. [sent-603, score-0.248]
</p><p>85 We evaluate our strong classifier on TUD-  Brussels and ETH pedestrian data sets but we observe that the detection results contain a large number of false positives. [sent-620, score-0.431]
</p><p>86 10−3  10−2  10−1 100 101 102 false positives per image Figure 3: ROC curves of our approach and several state-of-the-art detectors on the INRIA test image. [sent-625, score-0.168]
</p><p>87 We train a strong classifier using HOG and COV features. [sent-626, score-0.139]
</p><p>88 as in [6, 25], we train a cascade classifier in the next section. [sent-627, score-0.204]
</p><p>89 Pedestrian detection - Cascade classifier In this sec-  ×  tion, we train a cascade classifier using our pAUCEns. [sent-628, score-0.334]
</p><p>90 We train our detector on INRIA training set and evaluate the detector on INRIA, TUD-Brussels and ETH test sets. [sent-629, score-0.182]
</p><p>91 To achieve the node learning goal of the cascade (each node achieves an extremely high detection rate (> 99%) and a moderate false positive rage (≈ 50%)), we optimize the pAUC itne th fael FeP pRo range r[a0g. [sent-632, score-0.594]
</p><p>92 We then break-down experimental results of different measures using the partial AUC score (FPPI range [0, 0. [sent-645, score-0.21]
</p><p>93 Algorithms are sorted using the partial AUC score in the FPPI range [0, 0. [sent-655, score-0.21]
</p><p>94 The proposed approach is based on optimizing the partial AUC score in the FPR range [α, β] . [sent-780, score-0.244]
</p><p>95 We plan to explore the possibility of applying the proposed approach to the multiple scales detector of [1] in order to improve the detection results of very low resolution pedestrian images. [sent-782, score-0.243]
</p><p>96 The linear combinations of biomarkers which maximize the partial area under the roc curves. [sent-881, score-0.248]
</p><p>97 A boosting method for maximizing the partial area under the roc curve. [sent-898, score-0.319]
</p><p>98 A structural svm based approach for optimizing partial auc. [sent-948, score-0.149]
</p><p>99 Fast pedestrian detection using a cascade of boosted covariance features. [sent-959, score-0.281]
</p><p>100 Fast and robust classification using asymmetric AdaBoost and a detector cascade. [sent-1027, score-0.187]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pauc', 0.677), ('fppi', 0.252), ('auc', 0.243), ('adaboost', 0.163), ('paucens', 0.142), ('weak', 0.137), ('fpr', 0.134), ('asymmetric', 0.132), ('learner', 0.13), ('pedestrian', 0.129), ('asymboost', 0.125), ('false', 0.124), ('roc', 0.12), ('optimizes', 0.109), ('ensemble', 0.096), ('cascade', 0.093), ('partial', 0.088), ('positive', 0.083), ('mhax', 0.073), ('boosting', 0.071), ('inria', 0.071), ('classifier', 0.071), ('score', 0.066), ('negative', 0.064), ('detection', 0.059), ('curve', 0.056), ('range', 0.056), ('learners', 0.056), ('detector', 0.055), ('node', 0.055), ('crossvalidate', 0.053), ('komori', 0.053), ('paisitkriangkrai', 0.053), ('svmpauc', 0.053), ('veryfast', 0.053), ('ordering', 0.052), ('cov', 0.05), ('ht', 0.047), ('ul', 0.047), ('narasimhan', 0.046), ('classifiers', 0.045), ('positives', 0.044), ('area', 0.04), ('xl', 0.04), ('train', 0.04), ('stumps', 0.039), ('ar', 0.039), ('rate', 0.038), ('protein', 0.038), ('viola', 0.037), ('hogcov', 0.036), ('lulyl', 0.036), ('paucboost', 0.036), ('proteins', 0.036), ('duality', 0.035), ('xj', 0.035), ('mn', 0.035), ('violated', 0.035), ('scoring', 0.035), ('optimizing', 0.034), ('cutting', 0.034), ('jn', 0.032), ('training', 0.032), ('qw', 0.032), ('optimize', 0.031), ('wt', 0.031), ('agarwal', 0.03), ('tokens', 0.029), ('principled', 0.029), ('strong', 0.028), ('rk', 0.028), ('shen', 0.028), ('instances', 0.028), ('samples', 0.028), ('yl', 0.028), ('sermanet', 0.028), ('structural', 0.027), ('jones', 0.027), ('hog', 0.027), ('emphasis', 0.027), ('asymmetry', 0.026), ('doll', 0.026), ('xi', 0.025), ('par', 0.025), ('mwi', 0.025), ('benenson', 0.025), ('ij', 0.025), ('places', 0.025), ('dual', 0.024), ('combinatorial', 0.023), ('labelled', 0.023), ('mathias', 0.023), ('windows', 0.023), ('performs', 0.022), ('jj', 0.022), ('bioinformatics', 0.022), ('ieee', 0.022), ('interaction', 0.021), ('decision', 0.02), ('observe', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="136-tfidf-1" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>Author: Sakrapee Paisitkriangkrai, Chunhua Shen, Anton Van Den Hengel</p><p>Abstract: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). Effective cascade-based classification, for example, depends on training node classifiers that achieve the maximal detection rate at a moderate false positive rate, e.g., around 40% to 50%. We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. By optimizing for different ranges of false positive rates, the proposed method can be used to train either a single strong classifier or a node classifier forming part of a cascade classifier. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the pro- posed structured ensemble learning method.</p><p>2 0.18033423 <a title="136-tfidf-2" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>Author: Markus Mathias, Rodrigo Benenson, Radu Timofte, Luc Van_Gool</p><p>Abstract: Detecting partially occluded pedestrians is challenging. A common practice to maximize detection quality is to train a set of occlusion-specific classifiers, each for a certain amount and type of occlusion. Since training classifiers is expensive, only a handful are typically trained. We show that by using many occlusion-specific classifiers, we outperform previous approaches on three pedestrian datasets; INRIA, ETH, and Caltech USA. We present a new approach to train such classifiers. By reusing computations among different training stages, 16 occlusion-specific classifiers can be trained at only one tenth the cost of one full training. We show that also test time cost grows sub-linearly.</p><p>3 0.15194564 <a title="136-tfidf-3" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>4 0.14662394 <a title="136-tfidf-4" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>Author: Qinxun Bai, Zheng Wu, Stan Sclaroff, Margrit Betke, Camille Monnier</p><p>Abstract: We propose a randomized ensemble algorithm to model the time-varying appearance of an object for visual tracking. In contrast with previous online methods for updating classifier ensembles in tracking-by-detection, the weight vector that combines weak classifiers is treated as a random variable and the posterior distribution for the weight vector is estimated in a Bayesian manner. In essence, the weight vector is treated as a distribution that reflects the confidence among the weak classifiers used to construct and adapt the classifier ensemble. The resulting formulation models the time-varying discriminative ability among weak classifiers so that the ensembled strong classifier can adapt to the varying appearance, backgrounds, and occlusions. The formulation is tested in a tracking-by-detection implementation. Experiments on 28 challenging benchmark videos demonstrate that the proposed method can achieve results comparable to and often better than those of stateof-the-art approaches.</p><p>5 0.1273867 <a title="136-tfidf-5" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>6 0.11911778 <a title="136-tfidf-6" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>7 0.096705928 <a title="136-tfidf-7" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>8 0.089063413 <a title="136-tfidf-8" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>9 0.084029719 <a title="136-tfidf-9" href="./iccv-2013-Write_a_Classifier%3A_Zero-Shot_Learning_Using_Purely_Textual_Descriptions.html">451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</a></p>
<p>10 0.081710458 <a title="136-tfidf-10" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>11 0.076438569 <a title="136-tfidf-11" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>12 0.076419182 <a title="136-tfidf-12" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>13 0.07632076 <a title="136-tfidf-13" href="./iccv-2013-Discriminatively_Trained_Templates_for_3D_Object_Detection%3A_A_Real_Time_Scalable_Approach.html">121 iccv-2013-Discriminatively Trained Templates for 3D Object Detection: A Real Time Scalable Approach</a></p>
<p>14 0.074800208 <a title="136-tfidf-14" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>15 0.072736964 <a title="136-tfidf-15" href="./iccv-2013-Detecting_Dynamic_Objects_with_Multi-view_Background_Subtraction.html">111 iccv-2013-Detecting Dynamic Objects with Multi-view Background Subtraction</a></p>
<p>16 0.0678747 <a title="136-tfidf-16" href="./iccv-2013-Analysis_of_Scores%2C_Datasets%2C_and_Models_in_Visual_Saliency_Prediction.html">50 iccv-2013-Analysis of Scores, Datasets, and Models in Visual Saliency Prediction</a></p>
<p>17 0.065065868 <a title="136-tfidf-17" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>18 0.064312123 <a title="136-tfidf-18" href="./iccv-2013-POP%3A_Person_Re-identification_Post-rank_Optimisation.html">305 iccv-2013-POP: Person Re-identification Post-rank Optimisation</a></p>
<p>19 0.062223461 <a title="136-tfidf-19" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>20 0.061578695 <a title="136-tfidf-20" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, 0.041), (2, -0.014), (3, -0.07), (4, 0.049), (5, -0.029), (6, 0.012), (7, 0.057), (8, -0.032), (9, -0.055), (10, -0.014), (11, -0.063), (12, 0.003), (13, -0.039), (14, 0.1), (15, -0.016), (16, -0.015), (17, 0.064), (18, 0.063), (19, 0.109), (20, -0.071), (21, -0.008), (22, -0.073), (23, 0.059), (24, -0.07), (25, -0.017), (26, -0.058), (27, 0.023), (28, -0.014), (29, -0.076), (30, -0.097), (31, 0.055), (32, -0.076), (33, 0.025), (34, 0.039), (35, -0.039), (36, 0.006), (37, 0.032), (38, -0.025), (39, -0.025), (40, 0.047), (41, 0.06), (42, -0.072), (43, 0.074), (44, -0.039), (45, -0.023), (46, -0.032), (47, -0.032), (48, 0.014), (49, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94317305 <a title="136-lsi-1" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>Author: Sakrapee Paisitkriangkrai, Chunhua Shen, Anton Van Den Hengel</p><p>Abstract: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). Effective cascade-based classification, for example, depends on training node classifiers that achieve the maximal detection rate at a moderate false positive rate, e.g., around 40% to 50%. We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. By optimizing for different ranges of false positive rates, the proposed method can be used to train either a single strong classifier or a node classifier forming part of a cascade classifier. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the pro- posed structured ensemble learning method.</p><p>2 0.85234314 <a title="136-lsi-2" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>Author: Markus Mathias, Rodrigo Benenson, Radu Timofte, Luc Van_Gool</p><p>Abstract: Detecting partially occluded pedestrians is challenging. A common practice to maximize detection quality is to train a set of occlusion-specific classifiers, each for a certain amount and type of occlusion. Since training classifiers is expensive, only a handful are typically trained. We show that by using many occlusion-specific classifiers, we outperform previous approaches on three pedestrian datasets; INRIA, ETH, and Caltech USA. We present a new approach to train such classifiers. By reusing computations among different training stages, 16 occlusion-specific classifiers can be trained at only one tenth the cost of one full training. We show that also test time cost grows sub-linearly.</p><p>3 0.84489566 <a title="136-lsi-3" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>Author: Tianfu Wu, Song-Chun Zhu</p><p>Abstract: Many object detectors, such as AdaBoost, SVM and deformable part-based models (DPM), compute additive scoring functions at a large number of windows scanned over image pyramid, thus computational efficiency is an important consideration beside accuracy performance. In this paper, we present a framework of learning cost-sensitive decision policy which is a sequence of two-sided thresholds to execute early rejection or early acceptance based on the accumulative scores at each step. A decision policy is said to be optimal if it minimizes an empirical global risk function that sums over the loss of false negatives (FN) and false positives (FP), and the cost of computation. While the risk function is very complex due to high-order connections among the two-sided thresholds, we find its upper bound can be optimized by dynamic programming (DP) efficiently and thus say the learned policy is near-optimal. Given the loss of FN and FP and the cost in three numbers, our method can produce a policy on-the-fly for Adaboost, SVM and DPM. In experiments, we show that our decision policy outperforms state-of-the-art cascade methods significantly in terms of speed with similar accuracy performance.</p><p>4 0.83135253 <a title="136-lsi-4" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>5 0.75247532 <a title="136-lsi-5" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>6 0.74147773 <a title="136-lsi-6" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>7 0.69720387 <a title="136-lsi-7" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>8 0.69643676 <a title="136-lsi-8" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>9 0.6763618 <a title="136-lsi-9" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>10 0.61557657 <a title="136-lsi-10" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>11 0.61439401 <a title="136-lsi-11" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>12 0.56966895 <a title="136-lsi-12" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>13 0.56812543 <a title="136-lsi-13" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>14 0.56183958 <a title="136-lsi-14" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>15 0.55961806 <a title="136-lsi-15" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>16 0.54067636 <a title="136-lsi-16" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>17 0.54030055 <a title="136-lsi-17" href="./iccv-2013-Learning_People_Detectors_for_Tracking_in_Crowded_Scenes.html">242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</a></p>
<p>18 0.53811896 <a title="136-lsi-18" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>19 0.53066206 <a title="136-lsi-19" href="./iccv-2013-HOGgles%3A_Visualizing_Object_Detection_Features.html">189 iccv-2013-HOGgles: Visualizing Object Detection Features</a></p>
<p>20 0.52761084 <a title="136-lsi-20" href="./iccv-2013-Revisiting_Example_Dependent_Cost-Sensitive_Learning_with_Decision_Trees.html">352 iccv-2013-Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.075), (4, 0.013), (7, 0.023), (12, 0.065), (26, 0.073), (27, 0.014), (31, 0.041), (34, 0.011), (40, 0.013), (42, 0.122), (64, 0.064), (67, 0.012), (73, 0.021), (75, 0.216), (89, 0.134)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8262471 <a title="136-lda-1" href="./iccv-2013-Learning_to_Predict_Gaze_in_Egocentric_Video.html">247 iccv-2013-Learning to Predict Gaze in Egocentric Video</a></p>
<p>Author: Yin Li, Alireza Fathi, James M. Rehg</p><p>Abstract: We present a model for gaze prediction in egocentric video by leveraging the implicit cues that exist in camera wearer’s behaviors. Specifically, we compute the camera wearer’s head motion and hand location from the video and combine them to estimate where the eyes look. We further model the dynamic behavior of the gaze, in particular fixations, as latent variables to improve the gaze prediction. Our gaze prediction results outperform the state-of-the-art algorithms by a large margin on publicly available egocentric vision datasets. In addition, we demonstrate that we get a significant performance boost in recognizing daily actions and segmenting foreground objects by plugging in our gaze predictions into state-of-the-art methods.</p><p>2 0.77144408 <a title="136-lda-2" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>Author: Hamed Kiani Galoogahi, Terence Sim, Simon Lucey</p><p>Abstract: Modern descriptors like HOG and SIFT are now commonly used in vision for pattern detection within image and video. From a signal processing perspective, this detection process can be efficiently posed as a correlation/convolution between a multi-channel image and a multi-channel detector/filter which results in a singlechannel response map indicating where the pattern (e.g. object) has occurred. In this paper, we propose a novel framework for learning a multi-channel detector/filter efficiently in the frequency domain, both in terms of training time and memory footprint, which we refer to as a multichannel correlation filter. To demonstrate the effectiveness of our strategy, we evaluate it across a number of visual detection/localization tasks where we: (i) exhibit superiorperformance to current state of the art correlation filters, and (ii) superior computational and memory efficiencies compared to state of the art spatial detectors.</p><p>same-paper 3 0.76095307 <a title="136-lda-3" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>Author: Sakrapee Paisitkriangkrai, Chunhua Shen, Anton Van Den Hengel</p><p>Abstract: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). Effective cascade-based classification, for example, depends on training node classifiers that achieve the maximal detection rate at a moderate false positive rate, e.g., around 40% to 50%. We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. By optimizing for different ranges of false positive rates, the proposed method can be used to train either a single strong classifier or a node classifier forming part of a cascade classifier. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the pro- posed structured ensemble learning method.</p><p>4 0.72363997 <a title="136-lda-4" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>Author: Chetan Arora, Amir Globerson</p><p>Abstract: This paper addresses the data assignment problem in multi frame multi object tracking in video sequences. Traditional methods employing maximum weight bipartite matching offer limited temporal modeling. It has recently been shown [6, 8, 24] that incorporating higher order temporal constraints improves the assignment solution. Finding maximum weight matching with higher order constraints is however NP-hard and the solutions proposed until now have either been greedy [8] or rely on greedy rounding of the solution obtained from spectral techniques [15]. We propose a novel algorithm to find the approximate solution to data assignment problem with higher order temporal constraints using the method of dual decomposition and the MPLP message passing algorithm [21]. We compare the proposed algorithm with an implementation of [8] and [15] and show that proposed technique provides better solution with a bound on approximation factor for each inferred solution.</p><p>5 0.71261537 <a title="136-lda-5" href="./iccv-2013-Write_a_Classifier%3A_Zero-Shot_Learning_Using_Purely_Textual_Descriptions.html">451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</a></p>
<p>Author: Mohamed Elhoseiny, Babak Saleh, Ahmed Elgammal</p><p>Abstract: The main question we address in this paper is how to use purely textual description of categories with no training images to learn visual classifiers for these categories. We propose an approach for zero-shot learning of object categories where the description of unseen categories comes in the form of typical text such as an encyclopedia entry, without the need to explicitly defined attributes. We propose and investigate two baseline formulations, based on regression and domain adaptation. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the classifier parameters for new classes. We applied the proposed approach on two fine-grained categorization datasets, and the results indicate successful classifier prediction.</p><p>6 0.70730734 <a title="136-lda-6" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>7 0.70423049 <a title="136-lda-7" href="./iccv-2013-POP%3A_Person_Re-identification_Post-rank_Optimisation.html">305 iccv-2013-POP: Person Re-identification Post-rank Optimisation</a></p>
<p>8 0.70265263 <a title="136-lda-8" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>9 0.70219588 <a title="136-lda-9" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>10 0.69481468 <a title="136-lda-10" href="./iccv-2013-Domain_Transfer_Support_Vector_Ranking_for_Person_Re-identification_without_Target_Camera_Label_Information.html">124 iccv-2013-Domain Transfer Support Vector Ranking for Person Re-identification without Target Camera Label Information</a></p>
<p>11 0.69322121 <a title="136-lda-11" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>12 0.69317061 <a title="136-lda-12" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>13 0.69012725 <a title="136-lda-13" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>14 0.68996197 <a title="136-lda-14" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>15 0.68987125 <a title="136-lda-15" href="./iccv-2013-Target-Driven_Moire_Pattern_Synthesis_by_Phase_Modulation.html">413 iccv-2013-Target-Driven Moire Pattern Synthesis by Phase Modulation</a></p>
<p>16 0.68962467 <a title="136-lda-16" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>17 0.6892606 <a title="136-lda-17" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>18 0.68845826 <a title="136-lda-18" href="./iccv-2013-Visual_Reranking_through_Weakly_Supervised_Multi-graph_Learning.html">445 iccv-2013-Visual Reranking through Weakly Supervised Multi-graph Learning</a></p>
<p>19 0.68747896 <a title="136-lda-19" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>20 0.68709481 <a title="136-lda-20" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
