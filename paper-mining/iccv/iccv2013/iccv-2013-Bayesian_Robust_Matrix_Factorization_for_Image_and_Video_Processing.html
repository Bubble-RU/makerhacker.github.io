<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-60" href="#">iccv2013-60</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</h1>
<br/><p>Source: <a title="iccv-2013-60-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Wang_Bayesian_Robust_Matrix_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><p>Reference: <a title="iccv-2013-60-reference" href="../iccv2013_reference/iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. [sent-2, score-0.158]
</p><p>2 In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. [sent-3, score-0.235]
</p><p>3 To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. [sent-4, score-0.184]
</p><p>4 For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. [sent-5, score-0.137]
</p><p>5 Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. [sent-7, score-0.15]
</p><p>6 Introduction  Finding a low-rank approximation to some given data matrix is a fundamental problem in many computer vision and machine learning applications, e. [sent-10, score-0.062]
</p><p>7 Its objective is to approximate the data matrix by a low-rank representation according to some chosen criteria. [sent-13, score-0.062]
</p><p>8 The conventional approach to matrix factorization is based on singular value decomposition (SVD). [sent-17, score-0.19]
</p><p>9 Optimality of the solution is guaranteed when the loss function is defined in terms of the l2 norm. [sent-18, score-0.048]
</p><p>10 As another issue, when the data matrix is contaminated with outliers, the estimated solution This research has been supported by General Research Fund 621310 from the Research Grants Council of Hong Kong. [sent-21, score-0.062]
</p><p>11 hk may deviate significantly from the ground truth due to sensitivity of the l2 norm to outliers. [sent-24, score-0.064]
</p><p>12 It totally ignores  the scale of the outliers and hence reduces its sensitivity to them. [sent-29, score-0.089]
</p><p>13 A common solution is to resort to convex relaxation by using the l1 norm instead. [sent-31, score-0.064]
</p><p>14 In this paper, we propose a full Bayesian formulation for robust matrix factorization which turns out to be related to a recent work called probabilistic robust matrix factorization (PRMF) [18]. [sent-35, score-0.492]
</p><p>15 Full Bayesian treatment can take advantage of full posterior density estimation instead of only using the mode of it, and thus improve the predictive performance. [sent-43, score-0.108]
</p><p>16 For many computer vision applications in which PRMF can be applied, the outliers which correspond to moving objects in the foreground usually form groups with high within-group spatial or temporal proximity. [sent-49, score-0.143]
</p><p>17 When the loss function is defined based on the l1norm, the resulting method may not be robust enough when 11778855  the number of outliers is large. [sent-55, score-0.167]
</p><p>18 Our approach goes beyond simply using the l1 norm based on point estimation. [sent-56, score-0.064]
</p><p>19 On one hand, it involves a non-convex loss with more expressive modeling power. [sent-57, score-0.048]
</p><p>20 On the other hand, as a full Bayesian method, it greatly alleviates the instability problem suffered by other methods. [sent-58, score-0.058]
</p><p>21 Related Work Enhancing model robustness in matrix factorization is by no means a new topic in the computer vision and machine learning communities. [sent-61, score-0.216]
</p><p>22 A recent breakthrough in this research topic can be attributed to principal component pursuit (PCP) [4] and stable principal component pursuit (SPCP) [23]. [sent-67, score-0.134]
</p><p>23 Besides using the l1 loss, PCP and SPCP utilize the nuclear norm for normalization. [sent-68, score-0.094]
</p><p>24 , l1-ALP [21] enforces the basis to be orthogonal while DECOLOR [22] makes the outliers contiguous using a graph cut algorithm. [sent-72, score-0.132]
</p><p>25 As for probabilistic methods, PMF [16] and BPMF [15] are two representative models for (non-robust) matrix factorization. [sent-73, score-0.084]
</p><p>26 [12] proposed a robust extension of BPMF for collaborative filtering based on Student’s t-distribution. [sent-75, score-0.061]
</p><p>27 Other methods include Bayesian robust PCA (BRPCA) [5] and variational Bayesian low-rank factorization (VBLR) [1]. [sent-78, score-0.179]
</p><p>28 Notations  ×  In this paper, I denotes an identity matrix of the proper size and AT denotes the transpose of matrix A. [sent-84, score-0.17]
</p><p>29 For matrix norm, the general lp norm is defined as ? [sent-85, score-0.126]
</p><p>30 ij |aij | and the Frobenius norm (p = 2) defined as ? [sent-96, score-0.256]
</p><p>31 Anontohrmer u (spefu =l norm eifsi tnheed dn uascle ? [sent-102, score-0.064]
</p><p>32 Brief Review of PRMF  In what follows, we assume Y = [yij] ∈ Rm×n denotes the data matrix with the exact data representation depending on the application. [sent-114, score-0.085]
</p><p>33 For example, the entire matrix Y may correspond to an m n image which is assumed tYo m bea oyf c loorwre srpaonkn. [sent-115, score-0.062]
</p><p>34 The  notation U ∈ Rm×r is used to denote the basis matrix, nVo a∈t oRnn ×Ur t∈he R coefficient matrix, and ui and vj the ith aVnd ∈ ∈ jth R rows of U and V, respectively. [sent-117, score-0.159]
</p><p>35 Each row of U and V is assumed to be mutually independent, and Y is determined by the low-rank matrix UVT (with r ? [sent-118, score-0.062]
</p><p>36 [18] proposed the PRMF model for robust matrix factorization. [sent-121, score-0.092]
</p><p>37 A longer review of PRMF can be found in the supplemental material. [sent-123, score-0.066]
</p><p>38 Its probabilistic model formulation can be related to optimization-based algorithms by adopting the maximum a posteriori (MAP) approach so that the loss function is expressed in terms of the l1 norm. [sent-125, score-0.07]
</p><p>39 Bayesian Robust Matrix Factorization In this section, we first present the graphical model and the generative process of our basic Bayesian robust matrix  factorization (BRMF) model. [sent-135, score-0.259]
</p><p>40 inverse covariance matrices) of the rows of U and V have conjugate priors (multivariate normal distribution and Wishart distribution, respectively). [sent-144, score-0.132]
</p><p>41 We use a Laplace mixture with the generalized inverse Gaussian (GIG) distribution1 as the noise model to further enhance model robustness. [sent-147, score-0.062]
</p><p>42 It has been demonstrated in [20] that using a Laplace mixture with GIG outperforms the l1 norm when it is used to define a regularizer for variable selection. [sent-148, score-0.064]
</p><p>43 We expect it to be equally superior when it plays the role of a loss function instead of a regularizer. [sent-149, score-0.048]
</p><p>44 1Readers are referred to the supplemental material for details of GIG. [sent-167, score-0.066]
</p><p>45 We can draw Λv , μv and V similarly by following steps 1 to 3. [sent-169, score-0.051]
</p><p>46 Model Inference  Since all the distributions belong to the (conjugate) exponential family, we can take advantage of the efficient Gibbs sampling to infer the posterior distributions. [sent-174, score-0.088]
</p><p>47 For more details, please refer to the supplemental material. [sent-175, score-0.066]
</p><p>48 Sample μu and Λu: Based on the conjugate prior property, it is easy to show that the joint posterior distribution is a Gaussian-Wishart distribution and hence we can sample μu, Λu as follows: μu,  Λu | U, W0, μ0,  ν0,  β0 ∼ N(μ? [sent-176, score-0.169]
</p><p>49 Sample ui: We extract all terms related to ui and then apply Bayes’ rule: ? [sent-196, score-0.117]
</p><p>50 Then we can show that: ui | Y, V, μu, Λu, T ∼ N(ui | ui? [sent-201, score-0.117]
</p><p>51 ,  (7)  11778877  where rij = yij − uiTvj and IG denotes the inverse Gaussian distribution. [sent-214, score-0.182]
</p><p>52 (8) Note that sampling directly from GIG may be inefficient, so we convert the posterior distribution to some other form which allows more efficient sampling. [sent-216, score-0.122]
</p><p>53 2 and thus the posterior distribution becomes ηi1j  ∼  IG(? [sent-219, score-0.08]
</p><p>54 tension In order to extend the basic model by assuming that the  outliers form clusters (which correspond to moving objects in the foreground in the case of background modeling), we propose an extension via placing a first-order Markov random field (MRF) in the generation of T. [sent-224, score-0.203]
</p><p>55 For example, if each entry in the data matrix represents a raw pixel in an image, it can simply be defined as its 4-connected or 8connected neighbors. [sent-233, score-0.062]
</p><p>56 For video processing, we may define the neighborhood based on both the inter-frame and intraframe relationships: if Ft (x, y) denotes the pixel (x, y) in  frame t, then its neighbors may include Ft−1 (x, y) and Ft+1 (x, y) in addition to its 4-connected or 8-connected neighbors in frame t. [sent-234, score-0.086]
</p><p>57 1,pp((ˆτ τiij | ηηiij , rriij , TT−−iij ))qq(( τˆτiij | ηηiij , rriij ))? [sent-241, score-0.076]
</p><p>58 Relationship with Existing Methods To understand better the anticipated superiority of BRMF, we compare and relate BRMF with several popular robust matrix recovery algorithms in this section. [sent-251, score-0.122]
</p><p>59 In particular, we focus on how the error residue contributes to the objective function near the optimal solution because it affects the robustness of an algorithm most directly. [sent-255, score-0.068]
</p><p>60 By the optimality conRditio =n Yfor − −e aBch method, we can eliminate E∗ and express the loss function in terms of R only. [sent-258, score-0.048]
</p><p>61 Our full Bayesian treatment is actually more flexible and powerful because the MAP version only uses the posterior mode. [sent-262, score-0.108]
</p><p>62 From the practical aspect, they are better when the deviation and number of outliers are high, which are typical conditions encountered in our applications. [sent-295, score-0.119]
</p><p>63 One problem with using nonconvex loss functions in optimization-based methods is that it may lead to unstable results especially when the data contain noise. [sent-296, score-0.087]
</p><p>64 However, these two issues do not arise in BRMF model: 1) BRMF is only non-smooth at zero, which means BRMF does not explicitly distinguish outliers from noise. [sent-299, score-0.089]
</p><p>65 These two properties allow BRMF to greatly alleviate the instability problem and tend to produce more stable results even when the noise level is high. [sent-301, score-0.068]
</p><p>66 Besides, it is difficult to incorporate a Markov extension when the variational approximation approach is used. [sent-332, score-0.052]
</p><p>67 It utilizes the beta-Bernoulli conjugate distribution, which is sparse (binary) in nature, to model the outliers and the low-rank com-  ponent. [sent-335, score-0.144]
</p><p>68 The incorporation of noise, outliers and the low-rank component makes the model quite complicated. [sent-337, score-0.108]
</p><p>69 The codes and other supplemental materials can be found in http : / /win sty . [sent-344, score-0.066]
</p><p>70 Afterwards, we collect 50 samples for approximating the posterior distribution by sampling once every two steps. [sent-354, score-0.122]
</p><p>71 As far as outlier detection is concerned, DECOLOR and MBRMF obtain the best masks, not only visually but also quantitatively, and all other algorithms except BRPCA give reasonable results. [sent-370, score-0.058]
</p><p>72 On the aspect of low-rank matrix recovery, it can be seen that MBRMF gives the best result, which is followed by DECOLOR and BRMF. [sent-372, score-0.062]
</p><p>73 Although PCP and PRMF do a fair job in detecting the outliers, they fail to recover the low-rank matrix well. [sent-373, score-0.062]
</p><p>74 We can see that MBRMF has a clear advantage over the other algorithms for both outlier detection and low-rank matrix recovery. [sent-376, score-0.099]
</p><p>75 The first row shows the outlier detection results based on the area under curve (AUC) measure and the second row shows the image recovery results based on PSNR. [sent-395, score-0.067]
</p><p>76 Specifically, given a video sequence, we want to separate the foreground objects from the background. [sent-401, score-0.079]
</p><p>77 Consequently, the background components in different frames are highly correlated (and hence the data matrix is of low rank) and the moving objects in the foreground can be regarded as outliers. [sent-403, score-0.164]
</p><p>78 For example, while an underfitting model incorrectly recognizes the dynamic background such as some waving trees as the foreground, an overfitting one incorrectly ignores the foreground we are interested in. [sent-405, score-0.103]
</p><p>79 To provide more details about the results, entire video sequences are available in the supplemental material. [sent-406, score-0.091]
</p><p>80 1  SABS Dataset  SABS [2] is a synthetic dataset suitable for background modeling research. [sent-412, score-0.049]
</p><p>81 Winer ensootleu tthioant downsampling will reduce the noise level in the NoisyNight case, so we add back the noise to make the noise level comparable to the original video data. [sent-419, score-0.145]
</p><p>82 We do not compare with other methods such as mixture of Gaussians because it has been shown in [8] that robust matrix factorization methods significantly outperform the other methods. [sent-424, score-0.22]
</p><p>83 2  Real Dataset  We now conduct experiments on some real-world video sequences commonly used in background modeling research. [sent-430, score-0.054]
</p><p>84 The first row shows the foreground masks and the second row shows the restored background images. [sent-433, score-0.083]
</p><p>85 Due to the lack of full annotation, quantitative comparison for foreground detection cannot be made. [sent-459, score-0.084]
</p><p>86 3  Robustness to Noise  We further conduct some experiments to study the robustness of different methods to various types of noise (Gaussian, Salt, Poisson, Speckle). [sent-470, score-0.066]
</p><p>87 Due to space limitations, we only show the results of fountain with additive Gaussian noise in Figure 7 and leave the rest to the supplemental material. [sent-471, score-0.129]
</p><p>88 Even though all methods except PCP perform well under the noiseless setting, only MBRMF and VBLR survive when noise is added. [sent-472, score-0.089]
</p><p>89 On the other hand, MBRMF is still very robust due mainly to its generic noise model which does not distinguish outliers from noise, as explained earlier in section 6. [sent-475, score-0.159]
</p><p>90 Conclusion and Future Work In this paper, we have proposed a novel full Bayesian model for robust matrix factorization together with a Markov extension which incorporates spatial or temporal proximity. [sent-477, score-0.281]
</p><p>91 Due to the use of conjugate priors for the model parameters, an efficient sampling algorithm can be devised for Bayesian inference. [sent-478, score-0.118]
</p><p>92 Using both synthetic and real datasets, our experiments show that the proposed methods, particularly MBRMF, outperform other state-of-the-art robust matrix factorization methods. [sent-479, score-0.24]
</p><p>93 Moreover, MBRMF remains robust even under high noise level. [sent-480, score-0.07]
</p><p>94 Moreover, in order to apply the proposed algorithms to high-resolution video and achieve real-time performance, we will also investigate random sampling techniques and GPU implementations of the algorithms in our future work. [sent-484, score-0.067]
</p><p>95 Damped Newton algorithms for matrix factorization with missing data. [sent-507, score-0.19]
</p><p>96 Efficient computation of robust low-rank matrix approximations in the presence of missing data using the l1 norm. [sent-530, score-0.092]
</p><p>97 Incremental gradient on the Grassmannian for online foreground and background separation in subsampled video. [sent-543, score-0.083]
</p><p>98 Robust l1 norm factorization in the presence of outliers and missing data by alternative convex programming. [sent-552, score-0.281]
</p><p>99 Bayesian probabilistic matrix factorization using Markov chain Monte Carlo. [sent-578, score-0.212]
</p><p>100 Moving object detection by detecting contiguous outliers in the low-rank representation. [sent-624, score-0.109]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('brmf', 0.461), ('prmf', 0.409), ('mbrmf', 0.346), ('decolor', 0.288), ('brpca', 0.231), ('pcp', 0.197), ('ij', 0.192), ('vblr', 0.173), ('factorization', 0.128), ('bayesian', 0.118), ('ui', 0.117), ('gig', 0.115), ('laplace', 0.101), ('spcp', 0.096), ('outliers', 0.089), ('iij', 0.085), ('rij', 0.08), ('uitvj', 0.077), ('supplemental', 0.066), ('norm', 0.064), ('matrix', 0.062), ('sabs', 0.058), ('yij', 0.057), ('conjugate', 0.055), ('foreground', 0.054), ('draw', 0.051), ('markov', 0.049), ('loss', 0.048), ('posterior', 0.046), ('ig', 0.046), ('residue', 0.042), ('sampling', 0.042), ('noise', 0.04), ('pq', 0.039), ('bpmf', 0.038), ('jeffreys', 0.038), ('rriij', 0.038), ('rriijj', 0.038), ('wishart', 0.038), ('outlier', 0.037), ('avnd', 0.034), ('lakshminarayanan', 0.034), ('distribution', 0.034), ('gibbs', 0.033), ('psnr', 0.032), ('treatment', 0.032), ('extension', 0.031), ('nuclear', 0.03), ('encountered', 0.03), ('full', 0.03), ('pages', 0.03), ('robust', 0.03), ('recovery', 0.03), ('background', 0.029), ('text', 0.028), ('noiseless', 0.028), ('instability', 0.028), ('eriksson', 0.027), ('principal', 0.026), ('robustness', 0.026), ('subsection', 0.025), ('video', 0.025), ('adopts', 0.024), ('mcmc', 0.023), ('brevity', 0.023), ('removal', 0.023), ('denotes', 0.023), ('additive', 0.023), ('hyperparameters', 0.023), ('basis', 0.023), ('salakhutdinov', 0.022), ('candes', 0.022), ('inverse', 0.022), ('besides', 0.022), ('auc', 0.022), ('pursuit', 0.022), ('probabilistic', 0.022), ('priors', 0.021), ('generative', 0.021), ('except', 0.021), ('demanding', 0.021), ('variational', 0.021), ('gaussian', 0.021), ('aij', 0.021), ('contiguous', 0.02), ('synthetic', 0.02), ('unstable', 0.02), ('monte', 0.02), ('overfitting', 0.02), ('neighbors', 0.019), ('enhancing', 0.019), ('sfm', 0.019), ('correlated', 0.019), ('nonconvex', 0.019), ('svd', 0.019), ('component', 0.019), ('vj', 0.019), ('rank', 0.018), ('ft', 0.018), ('graphical', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="60-tfidf-1" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><p>2 0.15647943 <a title="60-tfidf-2" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>Author: Ricardo Cabral, Fernando De_La_Torre, João P. Costeira, Alexandre Bernardino</p><p>Abstract: Low rank models have been widely usedfor the representation of shape, appearance or motion in computer vision problems. Traditional approaches to fit low rank models make use of an explicit bilinear factorization. These approaches benefit from fast numerical methods for optimization and easy kernelization. However, they suffer from serious local minima problems depending on the loss function and the amount/type of missing data. Recently, these lowrank models have alternatively been formulated as convex problems using the nuclear norm regularizer; unlike factorization methods, their numerical solvers are slow and it is unclear how to kernelize them or to impose a rank a priori. This paper proposes a unified approach to bilinear factorization and nuclear norm regularization, that inherits the benefits of both. We analyze the conditions under which these approaches are equivalent. Moreover, based on this analysis, we propose a new optimization algorithm and a “rank continuation ” strategy that outperform state-of-theart approaches for Robust PCA, Structure from Motion and Photometric Stereo with outliers and missing data.</p><p>3 0.098893538 <a title="60-tfidf-3" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>Author: Deyu Meng, Fernando De_La_Torre</p><p>Abstract: Many problems in computer vision can be posed as recovering a low-dimensional subspace from highdimensional visual data. Factorization approaches to lowrank subspace estimation minimize a loss function between an observed measurement matrix and a bilinear factorization. Most popular loss functions include the L2 and L1 losses. L2 is optimal for Gaussian noise, while L1 is for Laplacian distributed noise. However, real data is often corrupted by an unknown noise distribution, which is unlikely to be purely Gaussian or Laplacian. To address this problem, this paper proposes a low-rank matrix factorization problem with a Mixture of Gaussians (MoG) noise model. The MoG model is a universal approximator for any continuous distribution, and hence is able to model a wider range of noise distributions. The parameters of the MoG model can be estimated with a maximum likelihood method, while the subspace is computed with standard approaches. We illustrate the benefits of our approach in extensive syn- thetic and real-world experiments including structure from motion, face modeling and background subtraction.</p><p>4 0.08904013 <a title="60-tfidf-4" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>Author: Taegyu Lim, Seunghoon Hong, Bohyung Han, Joon Hee Han</p><p>Abstract: We propose an on-line algorithm to extract a human by foreground/background segmentation and estimate pose of the human from the videos captured by moving cameras. We claim that a virtuous cycle can be created by appropriate interactions between the two modules to solve individual problems. This joint estimation problem is divided into two subproblems, , foreground/background segmentation and pose tracking, which alternate iteratively for optimization; segmentation step generates foreground mask for human pose tracking, and human pose tracking step provides foreground response map for segmentation. The final solution is obtained when the iterative procedure converges. We evaluate our algorithm quantitatively and qualitatively in real videos involving various challenges, and present its outstandingperformance compared to the state-of-the-art techniques for segmentation and pose estimation.</p><p>5 0.074038856 <a title="60-tfidf-5" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>6 0.072388463 <a title="60-tfidf-6" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>7 0.069429941 <a title="60-tfidf-7" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>8 0.0685817 <a title="60-tfidf-8" href="./iccv-2013-Inferring_%22Dark_Matter%22_and_%22Dark_Energy%22_from_Videos.html">216 iccv-2013-Inferring "Dark Matter" and "Dark Energy" from Videos</a></p>
<p>9 0.067722298 <a title="60-tfidf-9" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>10 0.067498319 <a title="60-tfidf-10" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>11 0.06696827 <a title="60-tfidf-11" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>12 0.064588137 <a title="60-tfidf-12" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>13 0.059169639 <a title="60-tfidf-13" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>14 0.05569271 <a title="60-tfidf-14" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>15 0.054995608 <a title="60-tfidf-15" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>16 0.054818481 <a title="60-tfidf-16" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>17 0.05462379 <a title="60-tfidf-17" href="./iccv-2013-Perspective_Motion_Segmentation_via_Collaborative_Clustering.html">314 iccv-2013-Perspective Motion Segmentation via Collaborative Clustering</a></p>
<p>18 0.052581131 <a title="60-tfidf-18" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>19 0.049492113 <a title="60-tfidf-19" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>20 0.049294807 <a title="60-tfidf-20" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.129), (1, -0.022), (2, -0.017), (3, -0.009), (4, -0.046), (5, 0.027), (6, -0.013), (7, 0.043), (8, 0.032), (9, 0.003), (10, -0.006), (11, -0.045), (12, -0.05), (13, 0.002), (14, -0.026), (15, 0.043), (16, 0.005), (17, 0.039), (18, -0.047), (19, 0.028), (20, 0.016), (21, -0.024), (22, -0.044), (23, -0.026), (24, 0.034), (25, 0.058), (26, 0.121), (27, -0.07), (28, 0.016), (29, -0.01), (30, 0.074), (31, 0.007), (32, 0.044), (33, 0.052), (34, 0.023), (35, 0.031), (36, 0.017), (37, 0.071), (38, 0.036), (39, 0.015), (40, -0.057), (41, 0.066), (42, -0.031), (43, 0.042), (44, 0.006), (45, 0.106), (46, -0.099), (47, -0.033), (48, 0.078), (49, 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92283094 <a title="60-lsi-1" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><p>2 0.87071586 <a title="60-lsi-2" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>Author: Ricardo Cabral, Fernando De_La_Torre, João P. Costeira, Alexandre Bernardino</p><p>Abstract: Low rank models have been widely usedfor the representation of shape, appearance or motion in computer vision problems. Traditional approaches to fit low rank models make use of an explicit bilinear factorization. These approaches benefit from fast numerical methods for optimization and easy kernelization. However, they suffer from serious local minima problems depending on the loss function and the amount/type of missing data. Recently, these lowrank models have alternatively been formulated as convex problems using the nuclear norm regularizer; unlike factorization methods, their numerical solvers are slow and it is unclear how to kernelize them or to impose a rank a priori. This paper proposes a unified approach to bilinear factorization and nuclear norm regularization, that inherits the benefits of both. We analyze the conditions under which these approaches are equivalent. Moreover, based on this analysis, we propose a new optimization algorithm and a “rank continuation ” strategy that outperform state-of-theart approaches for Robust PCA, Structure from Motion and Photometric Stereo with outliers and missing data.</p><p>3 0.8568663 <a title="60-lsi-3" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>Author: Deyu Meng, Fernando De_La_Torre</p><p>Abstract: Many problems in computer vision can be posed as recovering a low-dimensional subspace from highdimensional visual data. Factorization approaches to lowrank subspace estimation minimize a loss function between an observed measurement matrix and a bilinear factorization. Most popular loss functions include the L2 and L1 losses. L2 is optimal for Gaussian noise, while L1 is for Laplacian distributed noise. However, real data is often corrupted by an unknown noise distribution, which is unlikely to be purely Gaussian or Laplacian. To address this problem, this paper proposes a low-rank matrix factorization problem with a Mixture of Gaussians (MoG) noise model. The MoG model is a universal approximator for any continuous distribution, and hence is able to model a wider range of noise distributions. The parameters of the MoG model can be estimated with a maximum likelihood method, while the subspace is computed with standard approaches. We illustrate the benefits of our approach in extensive syn- thetic and real-world experiments including structure from motion, face modeling and background subtraction.</p><p>4 0.80497086 <a title="60-lsi-4" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>Author: Tae-Hyun Oh, Hyeongwoo Kim, Yu-Wing Tai, Jean-Charles Bazin, In So Kweon</p><p>Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values. The proposed objective function implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that our approach performs better than conventional rank minimization when the number of samples is deficient, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, photometric stereo and image alignment, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.</p><p>5 0.62933385 <a title="60-lsi-5" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>Author: Caglayan Dicle, Octavia I. Camps, Mario Sznaier</p><p>Abstract: We introduce a computationally efficient algorithm for multi-object tracking by detection that addresses four main challenges: appearance similarity among targets, missing data due to targets being out of the field of view or occluded behind other objects, crossing trajectories, and camera motion. The proposed method uses motion dynamics as a cue to distinguish targets with similar appearance, minimize target mis-identification and recover missing data. Computational efficiency is achieved by using a Generalized Linear Assignment (GLA) coupled with efficient procedures to recover missing data and estimate the complexity of the underlying dynamics. The proposed approach works with tracklets of arbitrary length and does not assume a dynamical model a priori, yet it captures the overall motion dynamics of the targets. Experiments using challenging videos show that this framework can handle complex target motions, non-stationary cameras and long occlusions, on scenarios where appearance cues are not available or poor.</p><p>6 0.6171664 <a title="60-lsi-6" href="./iccv-2013-Finding_Causal_Interactions_in_Video_Sequences.html">167 iccv-2013-Finding Causal Interactions in Video Sequences</a></p>
<p>7 0.58680826 <a title="60-lsi-7" href="./iccv-2013-Automatic_Kronecker_Product_Model_Based_Detection_of_Repeated_Patterns_in_2D_Urban_Images.html">55 iccv-2013-Automatic Kronecker Product Model Based Detection of Repeated Patterns in 2D Urban Images</a></p>
<p>8 0.58064961 <a title="60-lsi-8" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>9 0.57944047 <a title="60-lsi-9" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>10 0.56093484 <a title="60-lsi-10" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>11 0.5415228 <a title="60-lsi-11" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>12 0.54027689 <a title="60-lsi-12" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>13 0.52982497 <a title="60-lsi-13" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>14 0.52940941 <a title="60-lsi-14" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>15 0.51345772 <a title="60-lsi-15" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>16 0.50876683 <a title="60-lsi-16" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>17 0.50228554 <a title="60-lsi-17" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>18 0.49099463 <a title="60-lsi-18" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>19 0.48982334 <a title="60-lsi-19" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>20 0.48473069 <a title="60-lsi-20" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.054), (7, 0.022), (26, 0.085), (27, 0.011), (31, 0.069), (42, 0.084), (44, 0.017), (48, 0.014), (64, 0.048), (73, 0.081), (78, 0.013), (84, 0.214), (89, 0.145), (98, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88563478 <a title="60-lda-1" href="./iccv-2013-Stacked_Predictive_Sparse_Coding_for_Classification_of_Distinct_Regions_in_Tumor_Histopathology.html">401 iccv-2013-Stacked Predictive Sparse Coding for Classification of Distinct Regions in Tumor Histopathology</a></p>
<p>Author: Hang Chang, Yin Zhou, Paul Spellman, Bahram Parvin</p><p>Abstract: Image-based classification ofhistology sections, in terms of distinct components (e.g., tumor, stroma, normal), provides a series of indices for tumor composition. Furthermore, aggregation of these indices, from each whole slide image (WSI) in a large cohort, can provide predictive models of the clinical outcome. However, performance of the existing techniques is hindered as a result of large technical variations and biological heterogeneities that are always present in a large cohort. We propose a system that automatically learns a series of basis functions for representing the underlying spatial distribution using stacked predictive sparse decomposition (PSD). The learned representation is then fed into the spatial pyramid matching framework (SPM) with a linear SVM classifier. The system has been evaluated for classification of (a) distinct histological components for two cohorts of tumor types, and (b) colony organization of normal and malignant cell lines in 3D cell culture models. Throughput has been increased through the utility of graphical processing unit (GPU), and evalu- ation indicates a superior performance results, compared with previous research.</p><p>same-paper 2 0.78475147 <a title="60-lda-2" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><p>3 0.77892196 <a title="60-lda-3" href="./iccv-2013-Semantically-Based_Human_Scanpath_Estimation_with_HMMs.html">381 iccv-2013-Semantically-Based Human Scanpath Estimation with HMMs</a></p>
<p>Author: Huiying Liu, Dong Xu, Qingming Huang, Wen Li, Min Xu, Stephen Lin</p><p>Abstract: We present a method for estimating human scanpaths, which are sequences of gaze shifts that follow visual attention over an image. In this work, scanpaths are modeled based on three principal factors that influence human attention, namely low-levelfeature saliency, spatialposition, and semantic content. Low-level feature saliency is formulated as transition probabilities between different image regions based on feature differences. The effect of spatial position on gaze shifts is modeled as a Levy flight with the shifts following a 2D Cauchy distribution. To account for semantic content, we propose to use a Hidden Markov Model (HMM) with a Bag-of-Visual-Words descriptor of image regions. An HMM is well-suited for this purpose in that 1) the hidden states, obtained by unsupervised learning, can represent latent semantic concepts, 2) the prior distribution of the hidden states describes visual attraction to the semantic concepts, and 3) the transition probabilities represent human gaze shift patterns. The proposed method is applied to task-driven viewing processes. Experiments and analysis performed on human eye gaze data verify the effectiveness of this method.</p><p>4 0.76512766 <a title="60-lda-4" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>Author: Tianfu Wu, Song-Chun Zhu</p><p>Abstract: Many object detectors, such as AdaBoost, SVM and deformable part-based models (DPM), compute additive scoring functions at a large number of windows scanned over image pyramid, thus computational efficiency is an important consideration beside accuracy performance. In this paper, we present a framework of learning cost-sensitive decision policy which is a sequence of two-sided thresholds to execute early rejection or early acceptance based on the accumulative scores at each step. A decision policy is said to be optimal if it minimizes an empirical global risk function that sums over the loss of false negatives (FN) and false positives (FP), and the cost of computation. While the risk function is very complex due to high-order connections among the two-sided thresholds, we find its upper bound can be optimized by dynamic programming (DP) efficiently and thus say the learned policy is near-optimal. Given the loss of FN and FP and the cost in three numbers, our method can produce a policy on-the-fly for Adaboost, SVM and DPM. In experiments, we show that our decision policy outperforms state-of-the-art cascade methods significantly in terms of speed with similar accuracy performance.</p><p>5 0.72977781 <a title="60-lda-5" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>Author: Yu Pang, Haibin Ling</p><p>Abstract: Evaluating visual tracking algorithms, or “trackers ” for short, is of great importance in computer vision. However, it is hard to “fairly” compare trackers due to many parameters need to be tuned in the experimental configurations. On the other hand, when introducing a new tracker, a recent trend is to validate it by comparing it with several existing ones. Such an evaluation may have subjective biases towards the new tracker which typically performs the best. This is mainly due to the difficulty to optimally tune all its competitors and sometimes the selected testing sequences. By contrast, little subjective bias exists towards the “second best” ones1 in the contest. This observation inspires us with a novel perspective towards inhibiting subjective bias in evaluating trackers by analyzing the results between the second bests. In particular, we first collect all tracking papers published in major computer vision venues in recent years. From these papers, after filtering out potential biases in various aspects, we create a dataset containing many records of comparison results between various visual trackers. Using these records, we derive performance rank- ings of the involved trackers by four different methods. The first two methods model the dataset as a graph and then derive the rankings over the graph, one by a rank aggregation algorithm and the other by a PageRank-like solution. The other two methods take the records as generated from sports contests and adopt widely used Elo’s and Glicko ’s rating systems to derive the rankings. The experimental results are presented and may serve as a reference for related research.</p><p>6 0.72942185 <a title="60-lda-6" href="./iccv-2013-Efficient_Hand_Pose_Estimation_from_a_Single_Depth_Image.html">133 iccv-2013-Efficient Hand Pose Estimation from a Single Depth Image</a></p>
<p>7 0.69813424 <a title="60-lda-7" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>8 0.69008428 <a title="60-lda-8" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>9 0.6891005 <a title="60-lda-9" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>10 0.68622679 <a title="60-lda-10" href="./iccv-2013-A_Learning-Based_Approach_to_Reduce_JPEG_Artifacts_in_Image_Matting.html">19 iccv-2013-A Learning-Based Approach to Reduce JPEG Artifacts in Image Matting</a></p>
<p>11 0.68582034 <a title="60-lda-11" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>12 0.68551093 <a title="60-lda-12" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>13 0.68541652 <a title="60-lda-13" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>14 0.68223965 <a title="60-lda-14" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>15 0.68160045 <a title="60-lda-15" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>16 0.6789012 <a title="60-lda-16" href="./iccv-2013-Interactive_Markerless_Articulated_Hand_Motion_Tracking_Using_RGB_and_Depth_Data.html">218 iccv-2013-Interactive Markerless Articulated Hand Motion Tracking Using RGB and Depth Data</a></p>
<p>17 0.67802048 <a title="60-lda-17" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>18 0.67746377 <a title="60-lda-18" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>19 0.67594206 <a title="60-lda-19" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>20 0.67575121 <a title="60-lda-20" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
