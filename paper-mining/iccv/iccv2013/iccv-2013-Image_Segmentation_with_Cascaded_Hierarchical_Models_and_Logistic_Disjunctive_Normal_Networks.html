<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-211" href="#">iccv2013-211</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</h1>
<br/><p>Source: <a title="iccv-2013-211-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Seyedhosseini_Image_Segmentation_with_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Mojtaba Seyedhosseini, Mehdi Sajjadi, Tolga Tasdizen</p><p>Abstract: Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic dis- junctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance.</p><p>Reference: <a title="iccv-2013-211-reference" href="../iccv2013_reference/iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 However, extracting contextual information and using it in an effective way remains a difficult problem. [sent-4, score-0.159]
</p><p>2 To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. [sent-5, score-0.513]
</p><p>3 At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. [sent-6, score-0.266]
</p><p>4 Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. [sent-7, score-0.347]
</p><p>5 We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. [sent-8, score-0.123]
</p><p>6 Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. [sent-9, score-0.281]
</p><p>7 The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. [sent-10, score-0.293]
</p><p>8 We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance. [sent-12, score-0.097]
</p><p>9 the existence of a keyboard in an image implies that there is very likely a mouse near it [27]. [sent-19, score-0.114]
</p><p>10 From the Bayesian point of view, contextual information can be interpreted as the probability image map of an object, which caries prior information in the maximum aposteriori (MAP) pixel classification problem. [sent-20, score-0.159]
</p><p>11 There have been many methods that use contextual information for image segmentation and scene understanding. [sent-21, score-0.201]
</p><p>12 [13] used the conditional random fields (CRF) to capture contextual information at multiple scales for image segmentation. [sent-23, score-0.185]
</p><p>13 The cascaded classification model [14] combines scene categorization, object detection, and multiclass image segmentation for scene understanding. [sent-28, score-0.147]
</p><p>14 In a more related work, Tu and Bai [28] introduced the autocontext algorithm, which integrates both image features and contextual information to learn a series ofclassifiers, for image segmentation. [sent-31, score-0.159]
</p><p>15 A filter bank is used to extract the image features and the output of each classifier is used as the contextual information for the next classifier in the series. [sent-32, score-0.513]
</p><p>16 We also introduce a segmentation framework that takes advantage of both input image features and contextual information. [sent-33, score-0.229]
</p><p>17 But we use a hierarchical architecture to capture contextual information at different resolutions. [sent-35, score-0.238]
</p><p>18 Moreover, this multi-resolution contextual information is learned in a supervised framework, which makes it more discriminative compared to the abovementioned methods. [sent-36, score-0.213]
</p><p>19 To our knowledge, supervised multiresolution contextual information has not previously been used in a segmentation framework. [sent-37, score-0.225]
</p><p>20 Our proposed model learns several classifiers with many 2168  fiers are learned during the bottom-up step and the red classifier is learned during the top-down step. [sent-39, score-0.275]
</p><p>21 In the cascaded hierarchical model, the red classifier is used as the first classifier of the bottom-up step of next stage. [sent-41, score-0.47]
</p><p>22 To address these problems, we propose a new probabilistic classifier, logistic disjunctive normal networks (LDNN), that can be trained efficiently. [sent-43, score-0.426]
</p><p>23 Next, a series of classifiers are trained at different resolutions from the finest resolution to the coarsest resolution. [sent-49, score-0.118]
</p><p>24 At each resolution, the classifier is trained based on the output of the previous classifier in the hierarchy and the input image at that resolution. [sent-50, score-0.487]
</p><p>25 Finally, the outputs of these classifiers are used to train a new classifier at original resolution. [sent-51, score-0.259]
</p><p>26 This classifier exploits the rich contextual information from multiple resolutions. [sent-52, score-0.319]
</p><p>27 The cascaded hierarchical model (CHM) is obtained by repeating the same procedure consecutively. [sent-53, score-0.15]
</p><p>28 Each classifier in the hierarchy has some ienatcehrn2a×l parameters Eθal,c whhclicahss are rlienartnheedh during training  θˆl = argθmlaxP(Γ(Y,l−1) | Ψ(Φ(X,l−1)),Γ(Yˆl−1,1);θl) (1) where is the output of classifier at the lower level of hierarchy. [sent-74, score-0.461]
</p><p>29 The classifier output of each level is obtained using inference  Yˆl−1  Yˆl = argYmaxP(Y | Ψ(Φ(X,l − 1)),Γ(Yˆl−1,1);θˆl). [sent-75, score-0.194]
</p><p>30 Yˆl,  (2)  The classifier output of the l’th level, creates context, i. [sent-76, score-0.194]
</p><p>31 For l = 1no prior information is used and the classifier parameters, θ1, are learned only based on the input image features. [sent-79, score-0.218]
</p><p>32 In the cumulative framework, each classifier in the l’th level of the hierarchy takes outputs of all lower level classifiers, i. [sent-82, score-0.303]
</p><p>33 The cumulative framework provides multi-resolution contextual information for each classifier in the hierarchy and thus can improve the performance. [sent-88, score-0.418]
</p><p>34 Top-down step Unlike the bottom-up step where multiple classifiers are learned, only one classifier is trained in the top-down step. [sent-91, score-0.249]
</p><p>35 Once all the classifiers are learned in the bottom-up step, a top-down path is used to feed coarser resolution contextual information into a classifier, which is trained at the finest resolution. [sent-92, score-0.307]
</p><p>36 tF poerr a r hmiesra urpcshaicmalmodel with L levels, the classifier is trained based on the 1Unless specified otherwise, upper case symbols, e. [sent-95, score-0.194]
</p><p>37 a a  2169  input image features and the outputs of stages 1 to L obtained in the bottom-up step. [sent-102, score-0.129]
</p><p>38 (3)  The output of this classifier can be obtained using the following for inference Zˆ = argYmaxP(Y | Ψ(X),Yˆ1,Ω(Yˆ2,1),. [sent-107, score-0.194]
</p><p>39 (4)  The top-down classifier takes advantage of prior information from multiple resolutions. [sent-111, score-0.16]
</p><p>40 [24] proposed multi-scale contextual model that exploits contextual information from multiple scales. [sent-114, score-0.318]
</p><p>41 The advantage of our model is that the context images are learned at different scales in a supervised framework while the multi-scale contextual model uses simple filtering to create context images at different scales. [sent-115, score-0.259]
</p><p>42 The top-down classifier ofeach stage is used as the first classifier in the bottom-up step of the next stage. [sent-120, score-0.345]
</p><p>43 For the first stage, a previous top-down step is not available, the first classifier of  the bottom-up step is learned only based on the input image features. [sent-121, score-0.218]
</p><p>44 We use ˆθsl and to denote the parameters and outputs of the l’th classifier in the bottom-up step of stage s. [sent-122, score-0.229]
</p><p>45 We also use and to denote the parameters and outputs of the classifier in the top-down step of stage s. [sent-123, score-0.229]
</p><p>46 The overall learning algorithm for the cascaded hierarchical model is described in Algorithm 1. [sent-124, score-0.15]
</p><p>47 Even though our problem formulation is general and not restricted to any specific type of classifier, in practice we need a fast and accurate classifier that is robust against overfitting. [sent-128, score-0.16]
</p><p>48 Among off-the-shelf classifiers, we consider artificial neural networks (ANN), support vector machines (SVM), and random forests (RF). [sent-129, score-0.193]
</p><p>49 SVMs offer good generalization performance, but choosing the kernel function and the kernel parameters can be time consuming since they need to be adopted for each classifier in the CHM. [sent-131, score-0.16]
</p><p>50 Random forests provide an unbiased estimate of testing error, but they are prone to overfitting in the presence of noise. [sent-156, score-0.2]
</p><p>51 4 we show that overfitting can disrupt learning in the CHM model. [sent-158, score-0.103]
</p><p>52 We introduce a fast and 2170  yet powerful probabilistic classifier that can be employed in the CHM model. [sent-159, score-0.16]
</p><p>53 Logistic Disjunctive Normal Networks Any Boolean function b : Bn → B where B = {0, 1} can be written as a disjunction o→f conjunctions =wh {ic0h, i}s also known as the disjunctive normal form [12]. [sent-161, score-0.446]
</p><p>54 Then the disjunctive nwohremreal L Lfo ∈rm R can U be ∈ ∈re Rwr aitntden L as  f˜(X) =? [sent-169, score-0.222]
</p><p>55 This formulation is also known as a fuzzy min-max neural network [26]. [sent-172, score-0.167]
</p><p>56 The most important drawback of this model is its limitation to axis aligned decision boundaries which can significantly increase the number of conjunctions necessary for a good approximation. [sent-173, score-0.143]
</p><p>57 We propose to construct a significantly more efficient approximation in disjunctive normal form by approximating X+ as the union of convex sets which are defined as the intersection of arbitrary half-spaces in Rn. [sent-174, score-0.263]
</p><p>58 s hij −(Xq) with the logistic sigmoid function σij(X)  =  1 + e−? [sent-214, score-0.179]
</p><p>59 (9)  This gives in the differentiable disjunctive normal form approximation to f  f˜(X)  = 1 −? [sent-216, score-0.295]
</p><p>60 X, is mapped to the first layer by sigmoid functions in equation (9). [sent-235, score-0.186]
</p><p>61 The first layer consists of N groups of nodes with M nodes each. [sent-236, score-0.141]
</p><p>62 ×  Each node in the second layer implements the logical negations ofthe conjunctions gi (X) in equation (10). [sent-238, score-0.37]
</p><p>63 The output layer is a single node which implements the disjunction using De Morgan’s law. [sent-239, score-0.174]
</p><p>64 Notice that the only parameters of the nae Ntwo ×rk M are DtheN weights, wijk, a thned o bnialsyes p,a bij, eotef rtshe o connections between the inputs and the first layer of sigmoid functions. [sent-241, score-0.139]
</p><p>65 Given a set of training examples T of pairs (X, y) where y denotes the desired binary class corresponding to X and a classifier f(X), the quadratic error over the training set is E(f,T) =  ? [sent-245, score-0.265]
</p><p>66 ,y) ∈T  The gradient of the error function with respect to the parameter wijk in the LDNN architecture, evaluated for the training pair (X, y), is  ∂∂wEijk= −2(y − f(X))r? [sent-248, score-0.109]
</p><p>67 Finally, the disjunctive normal form used in the the LDNN permits a very simple and intuitive initialization of the model parameters. [sent-255, score-0.263]
</p><p>68 Since each conjunction is a convex set in Rn and X+ is approximated as the union of N such conjunctions, we can view the convex sets generated by the conjunctions as sub-clusters of X+. [sent-256, score-0.169]
</p><p>69 To initialize a model with N conjunctions and M sigmoids per conjunction, we: 2171  Table 1. [sent-257, score-0.143]
</p><p>70 • Initialize the bias terms bij such that the sigmoid funcItinointisa σij (X the) btaiakse tehrem vsa blue 0. [sent-277, score-0.111]
</p><p>71 It is noteworthy that our LDNN is fundamentally different from disjunctive fuzzy nets [20]. [sent-279, score-0.314]
</p><p>72 The LDDN is a differentiable model and hence enables us to minimize an objective function while disjunctive fuzzy nets are based on prototypes and an adhoc training procedure. [sent-280, score-0.382]
</p><p>73 LDNN (Binary datasets) We compared LDNN to random forests, artificial neural networks (ANN), and SVM on three binary datasets: IJCNN [5], Wisconsin breast cancer, and PIMA diabetes [11]. [sent-287, score-0.19]
</p><p>74 We tried to decrease the random forest overfitting by tweaking the parameters as much as possible. [sent-316, score-0.202]
</p><p>75 CHM (Weizmann horse dataset) The Weizmann dataset [4] contains 328 gray scale horse images with corresponding foreground/background truth maps. [sent-334, score-0.144]
</p><p>76 We used a 24 24 LDNN as the classifier in a CHM withW eth uresee stages ×an 2d4 45 leDvNeNls per stage. [sent-349, score-0.217]
</p><p>77 37%  that removing 50% of the hidden nodes in a neural network during the training can improve the performance on the test data. [sent-366, score-0.173]
</p><p>78 Using the same idea, we randomly removed half of the nodes in the second layer and half of the nodes per group in the first layer at each iteration during the training. [sent-367, score-0.216]
</p><p>79 At test time, we used the LDNN that contains all of the nodes with their outputs square rooted to compensate for the fact that half of them were active during the training time. [sent-368, score-0.113]
</p><p>80 For comparison, we trained a CHM with random forest as the classifier. [sent-369, score-0.133]
</p><p>81 We also trained a multi-scale series of artificial neural networks (MSANN) as in [24]. [sent-371, score-0.169]
</p><p>82 The training and testing F-value at different stages of the CHM for both LDNN and random forest are shown in Figure 2. [sent-379, score-0.23]
</p><p>83 It shows how overfitting propagates through the stages of the CHM when the random forest is used as the classifier. [sent-380, score-0.259]
</p><p>84 The overfitting disrupts the learning process be-  Figure 2. [sent-381, score-0.103]
</p><p>85 The overfitting in the random forest makes it useless in the CHM architecture. [sent-383, score-0.202]
</p><p>86 CHM (mouse neuropil dataset) This dataset is a stack of 70 images from the mouse neu-  ×  ×  ropil acquired using serial block face scanning electron microscopy (SBFSEM). [sent-392, score-0.42]
</p><p>87 Testing performance of different methods for the mouse neuropil and Drosophila VNC datasets. [sent-406, score-0.235]
</p><p>88 Mouse neuropil  Method  Drosophila VNC  F-value  G-mean  F-value  G-mean  -UCM [1]  45. [sent-407, score-0.121]
</p><p>89 CHM (Drosophila VNC dataset) This dataset was released for the ISBI 2012 EM challenge [2] and contains 30 images from Drosophila first instar larva ventral nerve cord (VNC) acquired using serialsection transmission electron microscopy (ssTEM). [sent-435, score-0.152]
</p><p>90 Mouse neuropil BEL [9]  Drosophila VNC  6 hours  Weizmann horse  4 hours  −  MSANN [24]  25 days  15 days  30 days  CHM-RF  57 hours  27 hours  66 hours  CHM-LDNN  24 hours  15 hours  35 hours  and thus there is no training time for it. [sent-453, score-0.845]
</p><p>91 Conclusion We introduced a discriminative learning scheme for image segmentation, called CHM, which uses contextual information at multiple resolutions. [sent-465, score-0.159]
</p><p>92 CHM trains several classifiers at multiple resolutions and leverages the obtained results for learning a classifier at the original resolution. [sent-466, score-0.215]
</p><p>93 They are either slow in training such as ANN or prone to overfitting such as random forests. [sent-469, score-0.192]
</p><p>94 To address these problems, we proposed a novel classifier, called LDNN, which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. [sent-470, score-0.392]
</p><p>95 We thank the NCMIR Institute for providing the mouse neuropil dataset. [sent-473, score-0.235]
</p><p>96 Test results ofthe mouse neuropil dataset (first row) and the Drosophila VNC dataset (second row). [sent-491, score-0.235]
</p><p>97 Improving neural networks by preventing co-adaptation of feature detectors. [sent-589, score-0.135]
</p><p>98 Detection of neuron membranes in electron microscopy images using a serial neural network architecture. [sent-609, score-0.4]
</p><p>99 Toward holistic scene understanding: Feedback enabled cascaded classification models. [sent-648, score-0.105]
</p><p>100 Detection of neuron membranes in electron microscopy images using multi-scale context and radon-like features. [sent-664, score-0.286]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ldnn', 0.545), ('chm', 0.483), ('disjunctive', 0.222), ('classifier', 0.16), ('contextual', 0.159), ('conjunctions', 0.143), ('msann', 0.141), ('neuropil', 0.121), ('mouse', 0.114), ('vnc', 0.107), ('cascaded', 0.105), ('overfitting', 0.103), ('drosophila', 0.089), ('landsat', 0.081), ('membranes', 0.081), ('weizmann', 0.08), ('electron', 0.078), ('layer', 0.075), ('microscopy', 0.074), ('forest', 0.073), ('horse', 0.072), ('membrane', 0.072), ('hierarchy', 0.071), ('sl', 0.069), ('networks', 0.069), ('neural', 0.066), ('hours', 0.065), ('mnist', 0.065), ('sigmoid', 0.064), ('fuzzy', 0.063), ('nstage', 0.061), ('seyedhosseini', 0.061), ('logistic', 0.06), ('bel', 0.059), ('stages', 0.057), ('hij', 0.055), ('classifiers', 0.055), ('logical', 0.05), ('equation', 0.047), ('bij', 0.047), ('corel', 0.047), ('hierarchical', 0.045), ('outputs', 0.044), ('segmentation', 0.042), ('normal', 0.041), ('symbols', 0.041), ('argymaxp', 0.04), ('disjunction', 0.04), ('disjunctions', 0.04), ('jurrus', 0.04), ('mehdi', 0.04), ('pima', 0.04), ('wijk', 0.04), ('network', 0.038), ('testing', 0.038), ('qi', 0.036), ('training', 0.036), ('ijcnn', 0.036), ('cancer', 0.036), ('cascading', 0.036), ('ann', 0.035), ('architecture', 0.034), ('output', 0.034), ('rates', 0.034), ('trained', 0.034), ('anns', 0.033), ('serial', 0.033), ('nodes', 0.033), ('error', 0.033), ('forests', 0.032), ('differentiable', 0.032), ('days', 0.032), ('gi', 0.03), ('neuron', 0.03), ('learned', 0.03), ('cvprw', 0.029), ('finest', 0.029), ('morgan', 0.029), ('nets', 0.029), ('breast', 0.029), ('input', 0.028), ('cumulative', 0.028), ('tu', 0.028), ('ij', 0.028), ('undesired', 0.028), ('rf', 0.027), ('prone', 0.027), ('uci', 0.027), ('closing', 0.027), ('conjunction', 0.026), ('random', 0.026), ('operator', 0.025), ('saxena', 0.025), ('stage', 0.025), ('expert', 0.025), ('implements', 0.025), ('textonboost', 0.024), ('supervised', 0.024), ('desai', 0.023), ('context', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="211-tfidf-1" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>Author: Mojtaba Seyedhosseini, Mehdi Sajjadi, Tolga Tasdizen</p><p>Abstract: Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic dis- junctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance.</p><p>2 0.13190219 <a title="211-tfidf-2" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>3 0.085821904 <a title="211-tfidf-3" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>Author: Markus Mathias, Rodrigo Benenson, Radu Timofte, Luc Van_Gool</p><p>Abstract: Detecting partially occluded pedestrians is challenging. A common practice to maximize detection quality is to train a set of occlusion-specific classifiers, each for a certain amount and type of occlusion. Since training classifiers is expensive, only a handful are typically trained. We show that by using many occlusion-specific classifiers, we outperform previous approaches on three pedestrian datasets; INRIA, ETH, and Caltech USA. We present a new approach to train such classifiers. By reusing computations among different training stages, 16 occlusion-specific classifiers can be trained at only one tenth the cost of one full training. We show that also test time cost grows sub-linearly.</p><p>4 0.082974575 <a title="211-tfidf-4" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>Author: Min Sun, Wan Huang, Silvio Savarese</p><p>Abstract: Many methods have been proposed to solve the image classification problem for a large number of categories. Among them, methods based on tree-based representations achieve good trade-off between accuracy and test time efficiency. While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. In this work, we propose a classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy. First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. As a result, our method achieves a significant 4.65%, 5.43%, and 4.07% (relative 24.82%, 41.64%, and 109.79%) improvement in accuracy at high efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. 8) so that users can further process them.</p><p>5 0.077283993 <a title="211-tfidf-5" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>Author: Yangqing Jia, Trevor Darrell</p><p>Abstract: Recent years have witnessed the success of large-scale image classification systems that are able to identify objects among thousands of possible labels. However, it is yet unclear how general classifiers such as ones trained on ImageNet can be optimally adapted to specific tasks, each of which only covers a semantically related subset of all the objects in the world. It is inefficient and suboptimal to retrain classifiers whenever a new task is given, and is inapplicable when tasks are not given explicitly, but implicitly specified as a set of image queries. In this paper we propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a lineartime probabilistic inference algorithm, given a set of query images from a latent task. We present efficient ways to estimate parameters for the model, and an open-source toolbox to train classifiers distributedly at a large scale. Empirical results based on the ImageNet data showed significant performance increase over several baseline algorithms.</p><p>6 0.072917074 <a title="211-tfidf-6" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>7 0.071438357 <a title="211-tfidf-7" href="./iccv-2013-Volumetric_Semantic_Segmentation_Using_Pyramid_Context_Features.html">447 iccv-2013-Volumetric Semantic Segmentation Using Pyramid Context Features</a></p>
<p>8 0.070650168 <a title="211-tfidf-8" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>9 0.065692633 <a title="211-tfidf-9" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>10 0.065600142 <a title="211-tfidf-10" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>11 0.062673025 <a title="211-tfidf-11" href="./iccv-2013-From_Subcategories_to_Visual_Composites%3A_A_Multi-level_Framework_for_Object_Detection.html">179 iccv-2013-From Subcategories to Visual Composites: A Multi-level Framework for Object Detection</a></p>
<p>12 0.058609474 <a title="211-tfidf-12" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>13 0.056506224 <a title="211-tfidf-13" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>14 0.056123912 <a title="211-tfidf-14" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>15 0.05479271 <a title="211-tfidf-15" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>16 0.05322605 <a title="211-tfidf-16" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>17 0.052697811 <a title="211-tfidf-17" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>18 0.052470498 <a title="211-tfidf-18" href="./iccv-2013-Holistic_Scene_Understanding_for_3D_Object_Detection_with_RGBD_Cameras.html">201 iccv-2013-Holistic Scene Understanding for 3D Object Detection with RGBD Cameras</a></p>
<p>19 0.050317068 <a title="211-tfidf-19" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>20 0.050178364 <a title="211-tfidf-20" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.137), (1, 0.03), (2, -0.013), (3, -0.05), (4, 0.041), (5, -0.009), (6, -0.006), (7, 0.045), (8, -0.01), (9, -0.074), (10, -0.02), (11, -0.011), (12, 0.014), (13, -0.029), (14, 0.047), (15, 0.012), (16, -0.039), (17, -0.008), (18, 0.017), (19, 0.071), (20, -0.042), (21, -0.012), (22, -0.034), (23, 0.052), (24, -0.102), (25, -0.049), (26, -0.001), (27, 0.022), (28, 0.005), (29, 0.009), (30, -0.015), (31, 0.043), (32, -0.023), (33, -0.015), (34, -0.017), (35, -0.004), (36, -0.057), (37, -0.007), (38, -0.007), (39, 0.005), (40, -0.02), (41, 0.019), (42, -0.014), (43, -0.016), (44, 0.011), (45, -0.007), (46, -0.013), (47, -0.003), (48, -0.034), (49, -0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91893625 <a title="211-lsi-1" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>Author: Mojtaba Seyedhosseini, Mehdi Sajjadi, Tolga Tasdizen</p><p>Abstract: Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic dis- junctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance.</p><p>2 0.80532867 <a title="211-lsi-2" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>3 0.78619367 <a title="211-lsi-3" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>Author: Xingyu Zeng, Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Cascaded classifiers1 have been widely used in pedestrian detection and achieved great success. These classifiers are trained sequentially without joint optimization. In this paper, we propose a new deep model that can jointly train multi-stage classifiers through several stages of backpropagation. It keeps the score map output by a classifier within a local region and uses it as contextual information to support the decision at the next stage. Through a specific design of the training strategy, this deep architecture is able to simulate the cascaded classifiers by mining hard samples to train the network stage-by-stage. Each classifier handles samples at a different difficulty level. Unsupervised pre-training and specifically designed stage-wise supervised training are used to regularize the optimization problem. Both theoretical analysis and experimental results show that the training strategy helps to avoid overfitting. Experimental results on three datasets (Caltech, ETH and TUD-Brussels) show that our approach outperforms the state-of-the-art approaches.</p><p>4 0.74979138 <a title="211-lsi-4" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>Author: Piotr Dollár, C. Lawrence Zitnick</p><p>Abstract: Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets.</p><p>5 0.74416178 <a title="211-lsi-5" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>Author: Tianfu Wu, Song-Chun Zhu</p><p>Abstract: Many object detectors, such as AdaBoost, SVM and deformable part-based models (DPM), compute additive scoring functions at a large number of windows scanned over image pyramid, thus computational efficiency is an important consideration beside accuracy performance. In this paper, we present a framework of learning cost-sensitive decision policy which is a sequence of two-sided thresholds to execute early rejection or early acceptance based on the accumulative scores at each step. A decision policy is said to be optimal if it minimizes an empirical global risk function that sums over the loss of false negatives (FN) and false positives (FP), and the cost of computation. While the risk function is very complex due to high-order connections among the two-sided thresholds, we find its upper bound can be optimized by dynamic programming (DP) efficiently and thus say the learned policy is near-optimal. Given the loss of FN and FP and the cost in three numbers, our method can produce a policy on-the-fly for Adaboost, SVM and DPM. In experiments, we show that our decision policy outperforms state-of-the-art cascade methods significantly in terms of speed with similar accuracy performance.</p><p>6 0.73627996 <a title="211-lsi-6" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>7 0.71855921 <a title="211-lsi-7" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>8 0.68381172 <a title="211-lsi-8" href="./iccv-2013-Revisiting_Example_Dependent_Cost-Sensitive_Learning_with_Decision_Trees.html">352 iccv-2013-Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees</a></p>
<p>9 0.66294426 <a title="211-lsi-9" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>10 0.65653235 <a title="211-lsi-10" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>11 0.64782053 <a title="211-lsi-11" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>12 0.64639425 <a title="211-lsi-12" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>13 0.64388043 <a title="211-lsi-13" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>14 0.62853837 <a title="211-lsi-14" href="./iccv-2013-Pedestrian_Parsing_via_Deep_Decompositional_Network.html">311 iccv-2013-Pedestrian Parsing via Deep Decompositional Network</a></p>
<p>15 0.62079608 <a title="211-lsi-15" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>16 0.6127609 <a title="211-lsi-16" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>17 0.61037147 <a title="211-lsi-17" href="./iccv-2013-Volumetric_Semantic_Segmentation_Using_Pyramid_Context_Features.html">447 iccv-2013-Volumetric Semantic Segmentation Using Pyramid Context Features</a></p>
<p>18 0.61010492 <a title="211-lsi-18" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>19 0.60572708 <a title="211-lsi-19" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>20 0.60165083 <a title="211-lsi-20" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.078), (7, 0.011), (25, 0.283), (26, 0.092), (31, 0.041), (34, 0.011), (42, 0.111), (48, 0.028), (64, 0.037), (73, 0.016), (78, 0.02), (89, 0.126), (95, 0.015), (98, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.73880202 <a title="211-lda-1" href="./iccv-2013-Efficient_Image_Dehazing_with_Boundary_Constraint_and_Contextual_Regularization.html">135 iccv-2013-Efficient Image Dehazing with Boundary Constraint and Contextual Regularization</a></p>
<p>Author: Gaofeng Meng, Ying Wang, Jiangyong Duan, Shiming Xiang, Chunhong Pan</p><p>Abstract: unkown-abstract</p><p>same-paper 2 0.71877855 <a title="211-lda-2" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>Author: Mojtaba Seyedhosseini, Mehdi Sajjadi, Tolga Tasdizen</p><p>Abstract: Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic dis- junctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance.</p><p>3 0.71256238 <a title="211-lda-3" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>Author: Honghui Zhang, Jingdong Wang, Ping Tan, Jinglu Wang, Long Quan</p><p>Abstract: We propose an adaptive subgradient descent method to efficiently learn the parameters of CRF models for image parsing. To balance the learning efficiency and performance of the learned CRF models, the parameter learning is iteratively carried out by solving a convex optimization problem in each iteration, which integrates a proximal term to preserve the previously learned information and the large margin preference to distinguish bad labeling and the ground truth labeling. A solution of subgradient descent updating form is derived for the convex optimization problem, with an adaptively determined updating step-size. Besides, to deal with partially labeled training data, we propose a new objective constraint modeling both the labeled and unlabeled parts in the partially labeled training data for the parameter learning of CRF models. The superior learning efficiency of the proposed method is verified by the experiment results on two public datasets. We also demonstrate the powerfulness of our method for handling partially labeled training data.</p><p>4 0.7023986 <a title="211-lda-4" href="./iccv-2013-Parallel_Transport_of_Deformations_in_Shape_Space_of_Elastic_Surfaces.html">307 iccv-2013-Parallel Transport of Deformations in Shape Space of Elastic Surfaces</a></p>
<p>Author: Qian Xie, Sebastian Kurtek, Huiling Le, Anuj Srivastava</p><p>Abstract: Statistical shape analysis develops methods for comparisons, deformations, summarizations, and modeling of shapes in given data sets. These tasks require afundamental tool called parallel transport of tangent vectors along arbitrary paths. This tool is essential for: (1) computation of geodesic paths using either shooting or path-straightening method, (2) transferring deformations across objects, and (3) modeling of statistical variability in shapes. Using the square-root normal field (SRNF) representation of parameterized surfaces, we present a method for transporting deformations along paths in the shape space. This is difficult despite the underlying space being a vector space because the chosen (elastic) Riemannian metric is non-standard. Using a finite-basis for representing SRNFs of shapes, we derive expressions for Christoffel symbols that enable parallel transports. We demonstrate this framework using examples from shape analysis of parameterized spherical sur- faces, in the three contexts mentioned above.</p><p>5 0.6932171 <a title="211-lda-5" href="./iccv-2013-A_Simple_Model_for_Intrinsic_Image_Decomposition_with_Depth_Cues.html">30 iccv-2013-A Simple Model for Intrinsic Image Decomposition with Depth Cues</a></p>
<p>Author: Qifeng Chen, Vladlen Koltun</p><p>Abstract: We present a model for intrinsic decomposition of RGB-D images. Our approach analyzes a single RGB-D image and estimates albedo and shading fields that explain the input. To disambiguate the problem, our model estimates a number of components that jointly account for the reconstructed shading. By decomposing the shading field, we can build in assumptions about image formation that help distinguish reflectance variation from shading. These assumptions are expressed as simple nonlocal regularizers. We evaluate the model on real-world images and on a challenging synthetic dataset. The experimental results demonstrate that the presented approach outperforms prior models for intrinsic decomposition of RGB-D images.</p><p>6 0.63407779 <a title="211-lda-6" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>7 0.61259961 <a title="211-lda-7" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>8 0.58987159 <a title="211-lda-8" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>9 0.58952606 <a title="211-lda-9" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>10 0.58686268 <a title="211-lda-10" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>11 0.58672297 <a title="211-lda-11" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>12 0.58646393 <a title="211-lda-12" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>13 0.58538651 <a title="211-lda-13" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>14 0.58495682 <a title="211-lda-14" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>15 0.58461422 <a title="211-lda-15" href="./iccv-2013-Multi-attributed_Dictionary_Learning_for_Sparse_Coding.html">276 iccv-2013-Multi-attributed Dictionary Learning for Sparse Coding</a></p>
<p>16 0.58456653 <a title="211-lda-16" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>17 0.58430743 <a title="211-lda-17" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>18 0.5836392 <a title="211-lda-18" href="./iccv-2013-A_Max-Margin_Perspective_on_Sparse_Representation-Based_Classification.html">20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</a></p>
<p>19 0.58363521 <a title="211-lda-19" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>20 0.58324689 <a title="211-lda-20" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
