<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-195" href="#">iccv2013-195</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</h1>
<br/><p>Source: <a title="iccv-2013-195-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Gong_Hidden_Factor_Analysis_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Dihong Gong, Zhifeng Li, Dahua Lin, Jianzhuang Liu, Xiaoou Tang</p><p>Abstract: Age invariant face recognition has received increasing attention due to its great potential in real world applications. In spite of the great progress in face recognition techniques, reliably recognizingfaces across ages remains a difficult task. The facial appearance of a person changes substantially over time, resulting in significant intra-class variations. Hence, the key to tackle this problem is to separate the variation caused by aging from the person-specific features that are stable. Specifically, we propose a new method, calledHidden FactorAnalysis (HFA). This methodcaptures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process. Then, the observed appearance can be modeled as a combination of the components generated based on these factors. We also develop a learning algorithm that jointly estimates the latent factors and the model parameters using an EM procedure. Extensive experiments on two well-known public domain face aging datasets: MORPH (the largest public face aging database) and FGNET, clearly show that the proposed method achieves notable improvement over state-of-the-art algorithms.</p><p>Reference: <a title="iccv-2013-195-reference" href="../iccv2013_reference/iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 , China  Abstract Age invariant face recognition has received increasing attention due to its great potential in real world applications. [sent-16, score-0.369]
</p><p>2 In spite of the great progress in face recognition techniques, reliably recognizingfaces across ages remains a difficult task. [sent-17, score-0.395]
</p><p>3 The facial appearance of a person changes substantially over time, resulting in significant intra-class variations. [sent-18, score-0.135]
</p><p>4 Hence, the key to tackle this problem is to separate the variation caused by aging from the person-specific features that are stable. [sent-19, score-0.379]
</p><p>5 This methodcaptures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process. [sent-21, score-1.172]
</p><p>6 We also develop a learning algorithm that jointly estimates the latent factors and the model parameters using an EM procedure. [sent-23, score-0.136]
</p><p>7 Extensive experiments on two well-known public domain face aging datasets: MORPH (the largest public face aging database) and FGNET, clearly show that the proposed method achieves notable improvement over state-of-the-art algorithms. [sent-24, score-1.312]
</p><p>8 Introduction As an emerging research topic, age invariant face recognition has many practical applications. [sent-26, score-0.8]
</p><p>9 For example, in law enforcement, finding missing children or identifying criminals based on their mug shots on identity requires recognizing photos across ages [3,29]. [sent-27, score-0.224]
</p><p>10 In spite of the great advancement in face recognition in the past decades, age invariant  Figure 1. [sent-28, score-0.844]
</p><p>11 Example images showing the large intra-class variations due to facial aging for one of the subjects in the FG-NET database  [2]. [sent-29, score-0.518]
</p><p>12 The difficulty of this problem, to a great extent, arises from the fact that the face appearance of a person is subject to remarkable change caused by the aging process over time, as shown in Figure 1. [sent-31, score-0.697]
</p><p>13 The research on age related face image analysis has only been studied in recent years. [sent-32, score-0.699]
</p><p>14 Most existing works focus on age estimation [8, 10–12, 17, 18, 24, 28, 37, 40, 4 1] and aging simulation [7, 19, 27, 30, 3 1,35]. [sent-33, score-0.866]
</p><p>15 However, work that explicitly tackles age invariant face recognition is limited. [sent-34, score-0.8]
</p><p>16 Existing methods on age invariant face recognition roughly fall into two categories: generative approaches and the discriminative approaches. [sent-35, score-0.828]
</p><p>17 Generative methods try to synthesis face images that match the target age before recognition [7, 10, 19, 27]. [sent-36, score-0.725]
</p><p>18 They try to construct a 2-D or 3-D generative model to compensate for the aging process in face matching. [sent-37, score-0.654]
</p><p>19 These methods, however, typically suffer from 2872  difficulties in several aspects: strong parametric assumptions that lead to unrealistic synthesis results, high complexity in computation, and reliance on accurate age estimation (which is often not reliable). [sent-38, score-0.452]
</p><p>20 The method in [22] uses gradient orientation pyramid (GOP) as feature and the support vector machine (SVM) as classifier for face recogni-  tion. [sent-40, score-0.273]
</p><p>21 Some variants of RS-LDA have also been used in [14, 26] for age invariant face recognition. [sent-42, score-0.774]
</p><p>22 However, the lack of an underlying mechanism to capture facial structure across different ages may limit their generalizing performance. [sent-44, score-0.184]
</p><p>23 In this paper, we consider a new approach to ageinvariant face recognition. [sent-45, score-0.247]
</p><p>24 This approach is motivated by the belief that the facial image of a person can be expressed as combination of two components: an identity-specific component that is stable over the aging process, and the other component that reflects the aging effect. [sent-46, score-0.965]
</p><p>25 In particular, we introduce two latent factors: an identity factor and an age factor, which respectively govern the generation of these two components. [sent-47, score-0.715]
</p><p>26 Intuitively, each person is associated with a distinct identity factor, which is largely invariant over the aging process and thus can be used as a stable feature for face recognition; while the age factor changes as the person grows. [sent-48, score-1.432]
</p><p>27 For computational simplicity, we assume a linear model, where the identity components and the age components lie on two different subspaces. [sent-49, score-0.629]
</p><p>28 In this way, the problem of separating identity and age factors naturally reduces to a problem of learning the basis of these subspaces. [sent-50, score-0.637]
</p><p>29 As both the subspaces and the latent factors are unknown in the training stage, we derive an algorithm that can jointly estimate both from a set of training image, based on an  Expectation-Maximization process. [sent-51, score-0.202]
</p><p>30 In this process, the latent factors and the model parameters are iteratively updated to maximize a unified objective. [sent-52, score-0.136]
</p><p>31 In the testing, given a pair of face images with unknown ages, we compute the match score between them by inferring and comparing the posterior mean of their identity factors. [sent-53, score-0.364]
</p><p>32 Section 3 presents the HFA-based age invariant face recognition framework. [sent-56, score-0.8]
</p><p>33 Hidden Factor Analysis In this section, we propose a new model, called Hidden Factor Analysis (HFA), to address the problem of age invariant face recognition. [sent-60, score-0.774]
</p><p>34 Problem Modeling Matching facial images across ages is often necessary in real world applications. [sent-64, score-0.184]
</p><p>35 On the other hand, facial im-  ×  ages of the same person also contain intrinsic features that are relatively stable across ages. [sent-71, score-0.213]
</p><p>36 Specifically, we use vectors to represent these latent factors, and call them age factor and identity factor throughout the remaining part of the paper. [sent-73, score-0.793]
</p><p>37 For simplicity and robustness, we consider a linear generative model, which expresses a facial image as a linear combination of three components: (1) age component, (2) identity component, and (3) a noise term which would allow actual observations to deviate from model space. [sent-74, score-0.703]
</p><p>38 In particular, the age component and identify component are respectively generated from the underlying age factor and identity factor through linear transformation. [sent-75, score-1.249]
</p><p>39 is a p 1 vector that represents the latent identity fxac itosr a a w pith × p 1ri ovre cdtoisrtr tihbautti roenp roefs eNn t(s0 ,th hIe). [sent-83, score-0.185]
</p><p>40 is a q 1vector that represents the latent age factor →β  →x →y  ×  wyith is prior d1is vtericbtoutrio thna ot rfe Npr (es0,e Int)s. [sent-85, score-0.598]
</p><p>41 The basic idea of our approach is to decompose facial features into identity components and age components based on this model, which are respectively generated from the identity factors and age factors. [sent-96, score-1.372]
</p><p>42 Any face feature consists of three components: the identity component age component and noise component →ε representing noise and other variations in addition to age variations. [sent-98, score-1.402]
</p><p>43 Through the decomposition based on this model, we can simultaneously attain two goals: U −→x depends only on the subject’s identity, with which we can perform age invariant face recognition, while depends only on the subject’s age, with which we can perform age estimation. [sent-100, score-1.226]
</p><p>44 Instead, we fo-  V −→y  cus on leveraging this decomposition to improve face recognition. [sent-102, score-0.247]
</p><p>45 The summation is over all the available samples from different subjects at different age groups. [sent-116, score-0.504]
</p><p>46 Here, we adopt the coordinate ascent approach, alternately updating model parameters and latent factors with the other fixed. [sent-118, score-0.136]
</p><p>47 T  (10)  Σ  where = σ2I + UUT + V VT, Ni and Mk are the numbers of training samples for the i-th subject and the k-th age group, respectively (e. [sent-183, score-0.514]
</p><p>48 if we have 100 training samples fall into the k-th age group, then Mk is 100). [sent-185, score-0.493]
</p><p>49 (13)  1Proof for Proposition 1 is attached in supplemental materials 2Proof for Proposition 2 is attached in supplemental materials 2874  where A=  ? [sent-205, score-0.174]
</p><p>50 The supervised approach in learning the optimal factor spaces distinguishes our work from [16] [23] [4] that mostly use unsupervised way in factor analysis. [sent-253, score-0.156]
</p><p>51 Our approach can generalize to other face recognition scenarios. [sent-255, score-0.273]
</p><p>52 The proposed model in (1) decomposes the original face feature into three components: the common feature component, the variation component, and the noise component. [sent-256, score-0.299]
</p><p>53 For general applications, such as matching faces in the wild, we can replace the aging variations with other kinds of variations. [sent-258, score-0.444]
</p><p>54 HFA based Age invariant Face Recognition Framework In this section, we present our age invariant face recognition framework based on the proposed HFA model in Section 2. [sent-260, score-0.875]
</p><p>55 Local Feature Representation Local facial features have been shown to be more effec-  tive than the global facial features in representing face images at various scales and orientations. [sent-265, score-0.459]
</p><p>56 For any face image, we first divide it into a set of overlapping patches, and then apply the HOG descriptor on each patch to extract the HOG features. [sent-268, score-0.247]
</p><p>57 Illustration of the HFA based age-invariant face recognition system. [sent-280, score-0.273]
</p><p>58 At the training stage, the training faces are first grouped according to their identities and ages (corresponding to index iand k in Algorithm 1, respectively), followed by feature extraction (section 3. [sent-281, score-0.187]
</p><p>59 With each training face represented by HOG feature, we reduce the dimension of these features with slicing (three slices are shown in the figure), PCA and LDA (section 3. [sent-283, score-0.397]
</p><p>60 The final matching score is given by the cosine distance of the concatenated identity features (section 3. [sent-288, score-0.143]
</p><p>61 Face Matching After local feature representation and dimension reduction, for each face image we have several compressed slices of smaller feature vectors. [sent-301, score-0.398]
</p><p>62 In the matching process, for each pair of probe sample and gallery sample, we first compute the predictive distribution of their identity variables, as follows: P  ? [sent-303, score-0.319]
</p><p>63 The matching process of our HFA model does not need any age information of the test images. [sent-338, score-0.478]
</p><p>64 Database There are two well-known public domain databases for age invariant face recognition: MORPH [13] and FGNET [2]. [sent-343, score-0.804]
</p><p>65 The MORPH Album 1 only contains 1690 face images from 625 different subjects. [sent-345, score-0.247]
</p><p>66 The MORPH Album 2 is the largest face aging dataset available in the public domain. [sent-346, score-0.656]
</p><p>67 This dataset is composed of about 78,000 face images of 20,000 different subjects captured at different ages. [sent-347, score-0.28]
</p><p>68 Comparing to the MORPH Album 1 dataset, the MORPH Album 2 dataset has two desired attributes: (i) 2876  very large number of subjects, and (ii) large number of face images captured at different ages. [sent-348, score-0.247]
</p><p>69 The FG-NET dataset consist of 82 different individuals, with each one having multiple images (13 on average) taken at different age levels. [sent-350, score-0.452]
</p><p>70 Figure  3 shows the age range distribution for these two datasets. [sent-351, score-0.452]
</p><p>71 To train our HFA model, we first partition the training data set into several age groups. [sent-355, score-0.498]
</p><p>72 To balance the number of training samples in each age group, we partition the age into 8 groups such that each group has approximately the same number of samples, as shown in Table 2. [sent-356, score-0.969]
</p><p>73 Parameter Settings The HFA model has some free parameters: d (the dimension of the feature vector fed into the model), p (the dimension the identity factor), and q (the dimension ofthe age factor). [sent-362, score-0.724]
</p><p>74 2), as well as the size of the normalized face images (see section 3. [sent-365, score-0.247]
</p><p>75 Experiment on the MORPH Ablum 2 dataset The MORPH Album 2 dataset is the largest publicly available face aging dataset. [sent-372, score-0.626]
</p><p>76 We partition the MORPH album 2 dataset into a training set and an independent test set. [sent-375, score-0.256]
</p><p>77 The training data consists of 20,000 face images from 10,000 subjects, with each subject having two images with the largest age gap. [sent-376, score-0.742]
</p><p>78 The test data is composed of a gallery set and a probe set from the remaining 10,000 subjects. [sent-377, score-0.156]
</p><p>79 The gallery set is composed of 10,000 face images corresponding to the youngest age of these 10,000 subjects. [sent-378, score-0.755]
</p><p>80 The probe set is composed of 10,000 face images corresponding to the oldest age of these 10,000 subjects. [sent-379, score-0.799]
</p><p>81 We compare our HFA model against several state-of-theart methods for age invariant face recognition on MORPH Album 2. [sent-380, score-0.8]
</p><p>82 They include (i) FaceVACS, a leading commercial face recognition engine [5], (ii) several newly developed generative methods [7, 27] for face aging, and (iii) several newly developed discriminative methods [14,2 1,26] for direct age invariant face recognition. [sent-381, score-1.322]
</p><p>83 To our best knowledge, this is the best identification rank-1 result on such a large-scale matching scenario (using 10,000 face images as the gallery set and another 10,000 face images as the probe set from 10,000 different persons) in the MORPH Album 2 dataset. [sent-390, score-0.708]
</p><p>84 Finally, we show some examples of failed retrievals in Figure 4. [sent-391, score-0.113]
</p><p>85 While the rank-1 retrievals are not correct in these cases, the probe images appear to be more similar to the incorrect rank-1 matched images than the true images. [sent-392, score-0.203]
</p><p>86 Some examples of failed retrievals in MORPH Album 2. [sent-399, score-0.113]
</p><p>87 The first row presents the probe faces, the second row is the incorrect rank-1 matching results using our approach, and the bottom row shows the corresponding ground-truth faces for the probes. [sent-400, score-0.191]
</p><p>88 The first row presents the probe faces, the second row is the incorrect rank1 matching results using our approach, and the bottom row shows the corresponding ground-truth faces for the probes. [sent-416, score-0.191]
</p><p>89 ure 4: The rank-1 retrieved images appeared highly similar to the probe images in the incorrect matchings. [sent-417, score-0.126]
</p><p>90 Conclusion In this paper, we have proposed a hidden factor analysis (HFA) approach to address the challenging problem of age invariant face recognition. [sent-419, score-0.88]
</p><p>91 The basic idea of the HFA model is to separate the aging variations from the personspecific features for pursuing the robust age-invariant face features. [sent-420, score-0.657]
</p><p>92 Extensive experiments conducted on two public domain face aging datasets (MORPH Album 2 and FGNET) convincingly demonstrate the superiority of our HFA model over the state-of-the-art algorithms. [sent-421, score-0.656]
</p><p>93 A review of the literature on the aging adult skull and face: implications for forensic science research and applications. [sent-432, score-0.461]
</p><p>94 Face aging simulation based on NMF algorithm with sparseness constraints. [sent-469, score-0.414]
</p><p>95 Human age estimation with regression on discriminative aging manifold. [sent-475, score-0.831]
</p><p>96 Image-based human age estimation by manifold learning and locally adjusted robust regression. [sent-500, score-0.452]
</p><p>97 Acquiring linear subspaces for face recognition under variable lighting. [sent-539, score-0.295]
</p><p>98 Toward automatic  [20]  [21]  [22]  [23] [24] [25]  [26]  [27]  [28]  [29]  simulation of aging effects on face images. [sent-563, score-0.661]
</p><p>99 Learning long term face aging patterns from partially dense aging databases. [sent-656, score-1.005]
</p><p>100 Frame synchronization and multi-level subspace analysis for video based face recognition. [sent-679, score-0.292]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('age', 0.452), ('aging', 0.379), ('morph', 0.377), ('hfa', 0.366), ('face', 0.247), ('album', 0.21), ('yk', 0.16), ('tik', 0.138), ('identity', 0.117), ('facial', 0.106), ('probe', 0.1), ('fgnet', 0.098), ('ages', 0.078), ('factor', 0.078), ('retrievals', 0.077), ('invariant', 0.075), ('factors', 0.068), ('latent', 0.068), ('ykt', 0.06), ('gallery', 0.056), ('slice', 0.056), ('slices', 0.056), ('forensic', 0.053), ('expectation', 0.048), ('uut', 0.046), ('lda', 0.046), ('xi', 0.045), ('subspace', 0.045), ('dimension', 0.043), ('proposition', 0.04), ('cybern', 0.04), ('facevacs', 0.04), ('fgent', 0.04), ('klare', 0.04), ('mfda', 0.04), ('nrates', 0.04), ('ramanathan', 0.039), ('faces', 0.039), ('xit', 0.038), ('em', 0.038), ('pages', 0.036), ('component', 0.036), ('failed', 0.036), ('lanitis', 0.035), ('suo', 0.035), ('ieee', 0.035), ('simulation', 0.035), ('attached', 0.034), ('supplemental', 0.034), ('subjects', 0.033), ('utn', 0.033), ('huawei', 0.033), ('forensics', 0.033), ('identification', 0.032), ('pattern', 0.032), ('pursuing', 0.031), ('hog', 0.03), ('components', 0.03), ('public', 0.03), ('adult', 0.029), ('mug', 0.029), ('lnp', 0.029), ('slicing', 0.029), ('person', 0.029), ('transactions', 0.029), ('geng', 0.028), ('generative', 0.028), ('hidden', 0.028), ('persons', 0.027), ('matching', 0.026), ('feature', 0.026), ('tn', 0.026), ('recognition', 0.026), ('incorrect', 0.026), ('reduction', 0.025), ('iat', 0.025), ('partition', 0.024), ('mk', 0.024), ('maximization', 0.023), ('kong', 0.023), ('rand', 0.023), ('spite', 0.023), ('settings', 0.023), ('training', 0.022), ('subspaces', 0.022), ('security', 0.022), ('lc', 0.022), ('great', 0.021), ('subject', 0.021), ('fu', 0.021), ('variables', 0.021), ('fg', 0.021), ('predictive', 0.02), ('stage', 0.02), ('cuhk', 0.02), ('skin', 0.02), ('guo', 0.019), ('materials', 0.019), ('samples', 0.019), ('tang', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="195-tfidf-1" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>Author: Dihong Gong, Zhifeng Li, Dahua Lin, Jianzhuang Liu, Xiaoou Tang</p><p>Abstract: Age invariant face recognition has received increasing attention due to its great potential in real world applications. In spite of the great progress in face recognition techniques, reliably recognizingfaces across ages remains a difficult task. The facial appearance of a person changes substantially over time, resulting in significant intra-class variations. Hence, the key to tackle this problem is to separate the variation caused by aging from the person-specific features that are stable. Specifically, we propose a new method, calledHidden FactorAnalysis (HFA). This methodcaptures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process. Then, the observed appearance can be modeled as a combination of the components generated based on these factors. We also develop a learning algorithm that jointly estimates the latent factors and the model parameters using an EM procedure. Extensive experiments on two well-known public domain face aging datasets: MORPH (the largest public face aging database) and FGNET, clearly show that the proposed method achieves notable improvement over state-of-the-art algorithms.</p><p>2 0.19602165 <a title="195-tfidf-2" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>Author: Yizhe Zhang, Ming Shao, Edward K. Wong, Yun Fu</p><p>Abstract: One of the most challenging task in face recognition is to identify people with varied poses. Namely, the test faces have significantly different poses compared with the registered faces. In this paper, we propose a high-level feature learning scheme to extract pose-invariant identity feature for face recognition. First, we build a single-hiddenlayer neural network with sparse constraint, to extractposeinvariant feature in a supervised fashion. Second, we further enhance the discriminative capability of the proposed feature by using multiple random faces as the target values for multiple encoders. By enforcing the target values to be uniquefor inputfaces over differentposes, the learned highlevel feature that is represented by the neurons in the hidden layer is pose free and only relevant to the identity information. Finally, we conduct face identification on CMU MultiPIE, and verification on Labeled Faces in the Wild (LFW) databases, where identification rank-1 accuracy and face verification accuracy with ROC curve are reported. These experiments demonstrate that our model is superior to oth- er state-of-the-art approaches on handling pose variations.</p><p>3 0.18329293 <a title="195-tfidf-3" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>Author: Kristina Scherbaum, James Petterson, Rogerio S. Feris, Volker Blanz, Hans-Peter Seidel</p><p>Abstract: Face detection is an important task in computer vision and often serves as the first step for a variety of applications. State-of-the-art approaches use efficient learning algorithms and train on large amounts of manually labeled imagery. Acquiring appropriate training images, however, is very time-consuming and does not guarantee that the collected training data is representative in terms of data variability. Moreover, available data sets are often acquired under controlled settings, restricting, for example, scene illumination or 3D head pose to a narrow range. This paper takes a look into the automated generation of adaptive training samples from a 3D morphable face model. Using statistical insights, the tailored training data guarantees full data variability and is enriched by arbitrary facial attributes such as age or body weight. Moreover, it can automatically adapt to environmental constraints, such as illumination or viewing angle of recorded video footage from surveillance cameras. We use the tailored imagery to train a new many-core imple- mentation of Viola Jones ’ AdaBoost object detection framework. The new implementation is not only faster but also enables the use of multiple feature channels such as color features at training time. In our experiments we trained seven view-dependent face detectors and evaluate these on the Face Detection Data Set and Benchmark (FDDB). Our experiments show that the use of tailored training imagery outperforms state-of-the-art approaches on this challenging dataset.</p><p>4 0.16909496 <a title="195-tfidf-4" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<p>Author: Renliang Weng, Jiwen Lu, Junlin Hu, Gao Yang, Yap-Peng Tan</p><p>Abstract: Over the past two decades, a number of face recognition methods have been proposed in the literature. Most of them use holistic face images to recognize people. However, human faces are easily occluded by other objects in many real-world scenarios and we have to recognize the person of interest from his/her partial faces. In this paper, we propose a new partial face recognition approach by using feature set matching, which is able to align partial face patches to holistic gallery faces automatically and is robust to occlusions and illumination changes. Given each gallery image and probe face patch, we first detect keypoints and extract their local features. Then, we propose a Metric Learned ExtendedRobust PointMatching (MLERPM) method to discriminatively match local feature sets of a pair of gallery and probe samples. Lastly, the similarity of two faces is converted as the distance between two feature sets. Experimental results on three public face databases are presented to show the effectiveness of the proposed approach.</p><p>5 0.15252551 <a title="195-tfidf-5" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>Author: Xudong Cao, David Wipf, Fang Wen, Genquan Duan, Jian Sun</p><p>Abstract: Face verification involves determining whether a pair of facial images belongs to the same or different subjects. This problem can prove to be quite challenging in many important applications where labeled training data is scarce, e.g., family album photo organization software. Herein we propose a principled transfer learning approach for merging plentiful source-domain data with limited samples from some target domain of interest to create a classifier that ideally performs nearly as well as if rich target-domain data were present. Based upon a surprisingly simple generative Bayesian model, our approach combines a KL-divergencebased regularizer/prior with a robust likelihood function leading to a scalable implementation via the EM algorithm. As justification for our design choices, we later use principles from convex analysis to recast our algorithm as an equivalent structured rank minimization problem leading to a number of interesting insights related to solution structure and feature-transform invariance. These insights help to both explain the effectiveness of our algorithm as well as elucidate a wide variety of related Bayesian approaches. Experimental testing with challenging datasets validate the utility of the proposed algorithm.</p><p>6 0.11467555 <a title="195-tfidf-6" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>7 0.11461977 <a title="195-tfidf-7" href="./iccv-2013-Cascaded_Shape_Space_Pruning_for_Robust_Facial_Landmark_Detection.html">70 iccv-2013-Cascaded Shape Space Pruning for Robust Facial Landmark Detection</a></p>
<p>8 0.11415976 <a title="195-tfidf-8" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>9 0.11155423 <a title="195-tfidf-9" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>10 0.10532135 <a title="195-tfidf-10" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>11 0.10414705 <a title="195-tfidf-11" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>12 0.10176042 <a title="195-tfidf-12" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>13 0.10165627 <a title="195-tfidf-13" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>14 0.09442737 <a title="195-tfidf-14" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>15 0.093858153 <a title="195-tfidf-15" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>16 0.090089507 <a title="195-tfidf-16" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>17 0.085459068 <a title="195-tfidf-17" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>18 0.083303206 <a title="195-tfidf-18" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>19 0.07933116 <a title="195-tfidf-19" href="./iccv-2013-Sparse_Variation_Dictionary_Learning_for_Face_Recognition_with_a_Single_Training_Sample_per_Person.html">398 iccv-2013-Sparse Variation Dictionary Learning for Face Recognition with a Single Training Sample per Person</a></p>
<p>20 0.076842293 <a title="195-tfidf-20" href="./iccv-2013-Model_Recommendation_with_Virtual_Probes_for_Egocentric_Hand_Detection.html">267 iccv-2013-Model Recommendation with Virtual Probes for Egocentric Hand Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.148), (1, 0.035), (2, -0.089), (3, -0.092), (4, -0.04), (5, -0.086), (6, 0.223), (7, 0.102), (8, 0.031), (9, -0.005), (10, -0.018), (11, 0.027), (12, 0.043), (13, 0.016), (14, -0.04), (15, -0.018), (16, -0.028), (17, -0.009), (18, -0.029), (19, 0.012), (20, -0.055), (21, -0.081), (22, -0.005), (23, -0.094), (24, 0.038), (25, 0.045), (26, -0.028), (27, -0.012), (28, 0.033), (29, 0.053), (30, 0.035), (31, -0.026), (32, -0.007), (33, -0.005), (34, -0.035), (35, -0.093), (36, 0.0), (37, -0.013), (38, -0.04), (39, -0.011), (40, 0.052), (41, 0.03), (42, 0.062), (43, -0.066), (44, 0.032), (45, 0.014), (46, -0.058), (47, 0.008), (48, -0.037), (49, -0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9644894 <a title="195-lsi-1" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>Author: Dihong Gong, Zhifeng Li, Dahua Lin, Jianzhuang Liu, Xiaoou Tang</p><p>Abstract: Age invariant face recognition has received increasing attention due to its great potential in real world applications. In spite of the great progress in face recognition techniques, reliably recognizingfaces across ages remains a difficult task. The facial appearance of a person changes substantially over time, resulting in significant intra-class variations. Hence, the key to tackle this problem is to separate the variation caused by aging from the person-specific features that are stable. Specifically, we propose a new method, calledHidden FactorAnalysis (HFA). This methodcaptures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process. Then, the observed appearance can be modeled as a combination of the components generated based on these factors. We also develop a learning algorithm that jointly estimates the latent factors and the model parameters using an EM procedure. Extensive experiments on two well-known public domain face aging datasets: MORPH (the largest public face aging database) and FGNET, clearly show that the proposed method achieves notable improvement over state-of-the-art algorithms.</p><p>2 0.86193937 <a title="195-lsi-2" href="./iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking.html">154 iccv-2013-Face Recognition via Archetype Hull Ranking</a></p>
<p>Author: Yuanjun Xiong, Wei Liu, Deli Zhao, Xiaoou Tang</p><p>Abstract: The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat- ing its performance superior to the state-of-the-arts.</p><p>3 0.84275246 <a title="195-lsi-3" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>Author: Yizhe Zhang, Ming Shao, Edward K. Wong, Yun Fu</p><p>Abstract: One of the most challenging task in face recognition is to identify people with varied poses. Namely, the test faces have significantly different poses compared with the registered faces. In this paper, we propose a high-level feature learning scheme to extract pose-invariant identity feature for face recognition. First, we build a single-hiddenlayer neural network with sparse constraint, to extractposeinvariant feature in a supervised fashion. Second, we further enhance the discriminative capability of the proposed feature by using multiple random faces as the target values for multiple encoders. By enforcing the target values to be uniquefor inputfaces over differentposes, the learned highlevel feature that is represented by the neurons in the hidden layer is pose free and only relevant to the identity information. Finally, we conduct face identification on CMU MultiPIE, and verification on Labeled Faces in the Wild (LFW) databases, where identification rank-1 accuracy and face verification accuracy with ROC curve are reported. These experiments demonstrate that our model is superior to oth- er state-of-the-art approaches on handling pose variations.</p><p>4 0.82479835 <a title="195-lsi-4" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>Author: Kristina Scherbaum, James Petterson, Rogerio S. Feris, Volker Blanz, Hans-Peter Seidel</p><p>Abstract: Face detection is an important task in computer vision and often serves as the first step for a variety of applications. State-of-the-art approaches use efficient learning algorithms and train on large amounts of manually labeled imagery. Acquiring appropriate training images, however, is very time-consuming and does not guarantee that the collected training data is representative in terms of data variability. Moreover, available data sets are often acquired under controlled settings, restricting, for example, scene illumination or 3D head pose to a narrow range. This paper takes a look into the automated generation of adaptive training samples from a 3D morphable face model. Using statistical insights, the tailored training data guarantees full data variability and is enriched by arbitrary facial attributes such as age or body weight. Moreover, it can automatically adapt to environmental constraints, such as illumination or viewing angle of recorded video footage from surveillance cameras. We use the tailored imagery to train a new many-core imple- mentation of Viola Jones ’ AdaBoost object detection framework. The new implementation is not only faster but also enables the use of multiple feature channels such as color features at training time. In our experiments we trained seven view-dependent face detectors and evaluate these on the Face Detection Data Set and Benchmark (FDDB). Our experiments show that the use of tailored training imagery outperforms state-of-the-art approaches on this challenging dataset.</p><p>5 0.79802161 <a title="195-lsi-5" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<p>Author: Renliang Weng, Jiwen Lu, Junlin Hu, Gao Yang, Yap-Peng Tan</p><p>Abstract: Over the past two decades, a number of face recognition methods have been proposed in the literature. Most of them use holistic face images to recognize people. However, human faces are easily occluded by other objects in many real-world scenarios and we have to recognize the person of interest from his/her partial faces. In this paper, we propose a new partial face recognition approach by using feature set matching, which is able to align partial face patches to holistic gallery faces automatically and is robust to occlusions and illumination changes. Given each gallery image and probe face patch, we first detect keypoints and extract their local features. Then, we propose a Metric Learned ExtendedRobust PointMatching (MLERPM) method to discriminatively match local feature sets of a pair of gallery and probe samples. Lastly, the similarity of two faces is converted as the distance between two feature sets. Experimental results on three public face databases are presented to show the effectiveness of the proposed approach.</p><p>6 0.77855915 <a title="195-lsi-6" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>7 0.7547909 <a title="195-lsi-7" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>8 0.74749452 <a title="195-lsi-8" href="./iccv-2013-Modifying_the_Memorability_of_Face_Photographs.html">272 iccv-2013-Modifying the Memorability of Face Photographs</a></p>
<p>9 0.7464692 <a title="195-lsi-9" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>10 0.73749506 <a title="195-lsi-10" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>11 0.7318942 <a title="195-lsi-11" href="./iccv-2013-Markov_Network-Based_Unified_Classifier_for_Face_Identification.html">261 iccv-2013-Markov Network-Based Unified Classifier for Face Identification</a></p>
<p>12 0.71402758 <a title="195-lsi-12" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>13 0.71175718 <a title="195-lsi-13" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>14 0.69768709 <a title="195-lsi-14" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>15 0.6518451 <a title="195-lsi-15" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>16 0.64713472 <a title="195-lsi-16" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>17 0.64264554 <a title="195-lsi-17" href="./iccv-2013-Like_Father%2C_Like_Son%3A_Facial_Expression_Dynamics_for_Kinship_Verification.html">251 iccv-2013-Like Father, Like Son: Facial Expression Dynamics for Kinship Verification</a></p>
<p>18 0.64076132 <a title="195-lsi-18" href="./iccv-2013-Sparse_Variation_Dictionary_Learning_for_Face_Recognition_with_a_Single_Training_Sample_per_Person.html">398 iccv-2013-Sparse Variation Dictionary Learning for Face Recognition with a Single Training Sample per Person</a></p>
<p>19 0.63210344 <a title="195-lsi-19" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>20 0.59670466 <a title="195-lsi-20" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.059), (4, 0.304), (7, 0.028), (12, 0.026), (26, 0.064), (27, 0.011), (31, 0.058), (40, 0.011), (42, 0.147), (64, 0.04), (73, 0.018), (89, 0.131)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74705458 <a title="195-lda-1" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>Author: Dihong Gong, Zhifeng Li, Dahua Lin, Jianzhuang Liu, Xiaoou Tang</p><p>Abstract: Age invariant face recognition has received increasing attention due to its great potential in real world applications. In spite of the great progress in face recognition techniques, reliably recognizingfaces across ages remains a difficult task. The facial appearance of a person changes substantially over time, resulting in significant intra-class variations. Hence, the key to tackle this problem is to separate the variation caused by aging from the person-specific features that are stable. Specifically, we propose a new method, calledHidden FactorAnalysis (HFA). This methodcaptures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process. Then, the observed appearance can be modeled as a combination of the components generated based on these factors. We also develop a learning algorithm that jointly estimates the latent factors and the model parameters using an EM procedure. Extensive experiments on two well-known public domain face aging datasets: MORPH (the largest public face aging database) and FGNET, clearly show that the proposed method achieves notable improvement over state-of-the-art algorithms.</p><p>2 0.70579576 <a title="195-lda-2" href="./iccv-2013-Feature_Weighting_via_Optimal_Thresholding_for_Video_Analysis.html">163 iccv-2013-Feature Weighting via Optimal Thresholding for Video Analysis</a></p>
<p>Author: Zhongwen Xu, Yi Yang, Ivor Tsang, Nicu Sebe, Alexander G. Hauptmann</p><p>Abstract: Fusion of multiple features can boost the performance of large-scale visual classification and detection tasks like TRECVID Multimedia Event Detection (MED) competition [1]. In this paper, we propose a novel feature fusion approach, namely Feature Weighting via Optimal Thresholding (FWOT) to effectively fuse various features. FWOT learns the weights, thresholding and smoothing parameters in a joint framework to combine the decision values obtained from all the individual features and the early fusion. To the best of our knowledge, this is the first work to consider the weight and threshold factors of fusion problem simultaneously. Compared to state-of-the-art fusion algorithms, our approach achieves promising improvements on HMDB [8] action recognition dataset and CCV [5] video classification dataset. In addition, experiments on two TRECVID MED 2011 collections show that our approach outperforms the state-of-the-art fusion methods for complex event detection.</p><p>3 0.70556474 <a title="195-lda-3" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>Author: Jian Sun, Jean Ponce</p><p>Abstract: In this paper, we address the problem of learning discriminative part detectors from image sets with category labels. We propose a novel latent SVM model regularized by group sparsity to learn these part detectors. Starting from a large set of initial parts, the group sparsity regularizer forces the model to jointly select and optimize a set of discriminative part detectors in a max-margin framework. We propose a stochastic version of a proximal algorithm to solve the corresponding optimization problem. We apply the proposed method to image classification and cosegmentation, and quantitative experiments with standard benchmarks show that it matches or improves upon the state of the art.</p><p>4 0.69518197 <a title="195-lda-4" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>Author: Oren Barkan, Jonathan Weill, Lior Wolf, Hagai Aronowitz</p><p>Abstract: This paper advances descriptor-based face recognition by suggesting a novel usage of descriptors to form an over-complete representation, and by proposing a new metric learning pipeline within the same/not-same framework. First, the Over-Complete Local Binary Patterns (OCLBP) face representation scheme is introduced as a multi-scale modified version of the Local Binary Patterns (LBP) scheme. Second, we propose an efficient matrix-vector multiplication-based recognition system. The system is based on Linear Discriminant Analysis (LDA) coupled with Within Class Covariance Normalization (WCCN). This is further extended to the unsupervised case by proposing an unsupervised variant of WCCN. Lastly, we introduce Diffusion Maps (DM) for non-linear dimensionality reduction as an alternative to the Whitened Principal Component Analysis (WPCA) method which is often used in face recognition. We evaluate the proposed framework on the LFW face recognition dataset under the restricted, unrestricted and unsupervised protocols. In all three cases we achieve very competitive results.</p><p>5 0.63543117 <a title="195-lda-5" href="./iccv-2013-Category-Independent_Object-Level_Saliency_Detection.html">71 iccv-2013-Category-Independent Object-Level Saliency Detection</a></p>
<p>Author: Yangqing Jia, Mei Han</p><p>Abstract: It is known that purely low-level saliency cues such as frequency does not lead to a good salient object detection result, requiring high-level knowledge to be adopted for successful discovery of task-independent salient objects. In this paper, we propose an efficient way to combine such high-level saliency priors and low-level appearance models. We obtain the high-level saliency prior with the objectness algorithm to find potential object candidates without the need of category information, and then enforce the consistency among the salient regions using a Gaussian MRF with the weights scaled by diverse density that emphasizes the influence of potential foreground pixels. Our model obtains saliency maps that assign high scores for the whole salient object, and achieves state-of-the-art performance on benchmark datasets covering various foreground statistics.</p><p>6 0.62891257 <a title="195-lda-6" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>7 0.61145931 <a title="195-lda-7" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>8 0.60180098 <a title="195-lda-8" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>9 0.59932274 <a title="195-lda-9" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>10 0.59231281 <a title="195-lda-10" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>11 0.59191841 <a title="195-lda-11" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<p>12 0.5892278 <a title="195-lda-12" href="./iccv-2013-Semi-supervised_Learning_for_Large_Scale_Image_Cosegmentation.html">383 iccv-2013-Semi-supervised Learning for Large Scale Image Cosegmentation</a></p>
<p>13 0.58822638 <a title="195-lda-13" href="./iccv-2013-How_Related_Exemplars_Help_Complex_Event_Detection_in_Web_Videos%3F.html">203 iccv-2013-How Related Exemplars Help Complex Event Detection in Web Videos?</a></p>
<p>14 0.587551 <a title="195-lda-14" href="./iccv-2013-Visual_Reranking_through_Weakly_Supervised_Multi-graph_Learning.html">445 iccv-2013-Visual Reranking through Weakly Supervised Multi-graph Learning</a></p>
<p>15 0.58647627 <a title="195-lda-15" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>16 0.58426064 <a title="195-lda-16" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>17 0.58410531 <a title="195-lda-17" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>18 0.58396459 <a title="195-lda-18" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>19 0.58287358 <a title="195-lda-19" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>20 0.58103573 <a title="195-lda-20" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
