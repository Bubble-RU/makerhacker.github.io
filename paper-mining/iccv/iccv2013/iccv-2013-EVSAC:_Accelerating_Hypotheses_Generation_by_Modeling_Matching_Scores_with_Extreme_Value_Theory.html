<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-131" href="#">iccv2013-131</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</h1>
<br/><p>Source: <a title="iccv-2013-131-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Fragoso_EVSAC_Accelerating_Hypotheses_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>Reference: <a title="iccv-2013-131-reference" href="../iccv2013_reference/iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. [sent-3, score-0.271]
</p><p>2 In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. [sent-4, score-0.397]
</p><p>3 Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. [sent-5, score-0.35]
</p><p>4 Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. [sent-6, score-0.322]
</p><p>5 Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations. [sent-7, score-0.315]
</p><p>6 Many methods improve RANSAC by exploiting prior information such as matching scores [2, 5, 9, 19] or geometrical cues [4, 13, 16] in order to bias the generation of hypotheses (models) with matches that are more likely to be correct, hence avoiding outliers as much as possible. [sent-16, score-0.568]
</p><p>7 Our method extracts information from the matching scores that are available in many computer vision applications to compute a correctness confidence for the matches. [sent-22, score-0.473]
</p><p>8 A new probabilistic parametric model for matching scores generated by a nearest-neighbor matcher that  is based on extreme value theory [3] and which accurately models the distribution of the lowest scores. [sent-24, score-0.684]
</p><p>9 EVSAC, a novel algorithm that leverages our probabilistic framework to assign confidence values to each match in order to accelerate accurate hypothesis generation in RANSAC. [sent-26, score-0.39]
</p><p>10 Given the image correspondences and their matching scores (typically computed using a distance or similarity metric), these methods model the statistics of the scores to assess the “correctness” of a match. [sent-30, score-0.51]
</p><p>11 Note we use the term “match” to refer to a feature correspondence between the query and reference images. [sent-31, score-0.243]
</p><p>12 Several approaches that speed up the generation of hypotheses compute a correctness confidence by attempting to model the distributions of matching scores produced by correct and incorrect matches. [sent-32, score-1.017]
</p><p>13 Tordoff and Murray [19] model these distributions in Guided-MLESAC (GMLESAC) from data pre-labeled as correct and incorrect by fitting appropriate curves in an offline stage. [sent-33, score-0.416]
</p><p>14 Goshen and Shimshoni [9] model these distributions in BEEM by using a non-parametric kernel density estimation and considering Lowe’s ratio [11] as the random variable. [sent-34, score-0.192]
</p><p>15 Brahmachari and Sarkar [2] compute a confidence for every match on the fly by using the closest matching scores. [sent-35, score-0.336]
</p><p>16 22447722  Their BLOGS algorithm assigns a higher correctness confidence when the best matching score is far from the two second-best scores. [sent-36, score-0.406]
</p><p>17 PROSAC starts with a subset of good matches and progressively expands it until convergence. [sent-38, score-0.216]
</p><p>18 Specifically, they employ a heuristic that models the correct matches using information from a tail distribution and use this simple confidence metric to guide sampling. [sent-41, score-0.488]
</p><p>19 While we use their confidence values to preclassify correct/incorrect matches as input to our approach, our algorithm takes a different approach, focusing on modeling the entire nearest-neighbor matching process from all the data. [sent-42, score-0.432]
</p><p>20 By leveraging extreme value theory, we can accurately model the minima for all features and use it effectively for accelerating the hypothesis generation. [sent-43, score-0.194]
</p><p>21 Finally, there is also work that uses extreme value theory (EVT) for modeling the tail of the underlying distribu-  tion to predict the correctness of a classifier, such as MetaRecognition of Scheirer et al. [sent-44, score-0.28]
</p><p>22 In contrast, we propose a fundamentally different application of EVT that models the minimum scores produced by a nearest-neighbor feature matcher, which we represent as a stochastic process. [sent-46, score-0.311]
</p><p>23 We show that EVT can be used to estimate the distributions for both correct and incorrect matches using our proposed mixture model, which then can be used to compute confidence values to accelerate hypothesis generation. [sent-47, score-0.863]
</p><p>24 , a query and a reference image, we first detect image features (interest points or keypoints) on both using standard techniques (e. [sent-53, score-0.208]
</p><p>25 For each feature, we then compute its descriptor (SIFT [11] or SURF [1]) and use the photometric information captured in these descriptors to obtain matches or correspondences between the query image and the reference. [sent-56, score-0.45]
</p><p>26 Formally, for every query feature iwe first compute the distance between the query descriptor qi and each of the reference descriptors rj to get a matching score si,j = d(qi, rj). [sent-57, score-0.656]
</p><p>27 We then select the reference feature with the minimum score as the best match, satisfying the nearest-neighbor rule:  =  j? [sent-58, score-0.229]
</p><p>28 An inlier (correct) match is one where the associated reference and query features both specify to the same physical location in the scene, while outlier (incorrect) matches are those that refer to different features in the scene yet produced a lower matching score. [sent-63, score-0.9]
</p><p>29 Incorrect matches could be due to several factors, such as repeating textures in the scene, features in the query image that are not visible in the reference, changes of lighting or shading, and others. [sent-64, score-0.342]
</p><p>30 In fact, the majority of nearest matches found for features in real-world images are typically outliers. [sent-66, score-0.216]
</p><p>31 The processes that corrupt matches are complex and hard to model. [sent-67, score-0.216]
</p><p>32 Hence, we take a stochastic approach and model the probabilistic behavior of the matching scores. [sent-68, score-0.21]
</p><p>33 We represent the nearest-neighbor matching process as comprising two random processes: one that produces correct matches and another that produces incorrect matches for each query feature. [sent-69, score-0.973]
</p><p>34 These correct and incorrect matching scores are then merged together into the sequence {si,j }jm=1, where tthhee matching score oefr th inet oco trhreec ste mquaetcnhc e(if { ist ex}ists) may or may not be the smallest in the list. [sent-70, score-0.742]
</p><p>35 Our probabilistic model Formally, the nearest-neighbor matcher can be modeled with two stochastic processes, one producing independent correct matching scores with a distribution Fc and another producing independent incorrect matching scores with a distribution F c¯ (see Fig. [sent-74, score-1.167]
</p><p>36 Because incorrect matches can have lower scores than correct matches, there is overlap between Fc and F c¯. [sent-77, score-0.651]
</p><p>37 Therefore, the minimum score from a nearest-neighbor matcher might be produced by either Fc or F c¯. [sent-78, score-0.364]
</p><p>38 Ifwe could tell which of these two distributions produced the minimum, we would know if the minimum corresponds to a correct match or not. [sent-79, score-0.405]
</p><p>39 If we have m features in our reference image and assume that there is only one correct matching feature, then the matching process will produce m 1 “incorrect” scores mdraatwcnhi nfrgom pr odcisestrsib wutiiloln p Fro cd¯ ufcore e mac h− query cfoerarteucret”. [sent-81, score-0.701]
</p><p>40 Scionrcees our nearest-neighbor matcher will only consider the minimum score, if an incorrect score is selected as the minimum then it will follow a distribution that models the minimum of F c¯. [sent-82, score-0.688]
</p><p>41 cm(intop)Gs,vjenqury  and reference images where correct matches have been preidentified, we show the pdf’s of the matching scores for both correct (fc) and incorrect matches (g¯ c). [sent-88, score-1.186]
</p><p>42 (bottom) We pose the process of matching a query descriptor qi to a set of reference descriptors {rj}jm=1 in a probabilistic framework. [sent-89, score-0.448]
</p><p>43 First, a random process generates at most one correct matching score using cdf Fc. [sent-90, score-0.397]
</p><p>44 Another random process generates at least m 1incorrect matching scores using droisctersibsu gtieonne aFt¯ ce. [sent-91, score-0.256]
</p><p>45 s aFtro lmea tth mis l−as t1 s ientc oorfr ienc-t correct matches the minimum is taken, modeled by distribution G c¯. [sent-92, score-0.466]
</p><p>46 Finally, the minimum of these two outputs is the best matching score si,j? [sent-93, score-0.265]
</p><p>47 Our work leverages extreme value theory to model this matching process without knowing the distributions a priori, and computes the confidence that score si,j? [sent-96, score-0.571]
</p><p>48 (left) Fitted Gamma distributions to matching scores from pre-identified correct matches. [sent-118, score-0.465]
</p><p>49 (center) Fitted GEV distributions to matching scores from pre-identified incorrect matches. [sent-119, score-0.524]
</p><p>50 (right) The histograms show the distribution of all the best matching scores (which include both correct and incorrect matches) and the continuous curve shows that our mixture model of the two densities is a good fit. [sent-120, score-0.753]
</p><p>51 In all cases, SIFT matches are shown on top and SURF matches on the bottom. [sent-121, score-0.432]
</p><p>52 To model the correct matching distribution Fc, we assume that the statistics of the correct matching scores will be skewed towards the minimum since many of the stateof-the-art descriptors such as SIFT or SURF are designed to be as invariant as possible, resulting in low scores. [sent-124, score-0.775]
</p><p>53 Therefore, we can expect distributions with longer right-tails, and so we pose that the correct matching scores follow a  Gamma distribution, i. [sent-125, score-0.465]
</p><p>54 2 shows fitted corresponding distributions to a set of preidentified correct/incorrect matching scores for SIFT and SURF matches to demonstrate that the models we have selected for Fc and G c¯ are reasonable in practice. [sent-129, score-0.649]
</p><p>55 So now we have distribution Fc that produces the inlier scores and G c¯ that produces the best outlier score for each feature. [sent-130, score-0.502]
</p><p>56 We observe that the probability of selecting one distribution or the other is given by the inlier ratio ε, which states the percentage of the nearest matches that are actually inliers for all query features. [sent-132, score-0.773]
</p><p>57 can be modeled by the following mixture distribution:  +  F = εFc (1 − ε)G ¯c (3) where we use the inlier ratio ε as the mixing parameter between the two distributions. [sent-134, score-0.393]
</p><p>58 We can then use this mixture model to calculate weights or correctness confidences as a function of a matching score for every correspondence by computing the posterior probability from Eq. [sent-137, score-0.672]
</p><p>59 }in=1, and the k neareagste neighbor matching scores {si,1:k}in=1 sorted in an ascending hobroderr m mfoart every is-ctohr correspondence. [sent-144, score-0.4]
</p><p>60 Our algorithm begins by computing the distributions for correct and incorrect matches for the data provided. [sent-148, score-0.603]
</p><p>61 In order to start the process, we need a correct-match predictor to preliminarily label each match as correct or incorrect (e. [sent-149, score-0.457]
</p><p>62 We then fit a two-parameter Gamma distribution to the data identified as correct to estimate Fc. [sent-152, score-0.174]
</p><p>63 iWned  use the second nearest matching scores (instead of all the matches labeled incorrect by the predictor) since in practice this results in a better approximation of the true GEV, as if we had a perfect incorrect match detector (see Fig. [sent-161, score-0.887]
</p><p>64 , τ, is the inlier ratio computed by the predictor in step 1. [sent-214, score-0.402]
</p><p>65 We set this upper bound to the estimate of ε as in practice the predictor introduces some false-positives (false-alarms) and so the true inlier ratio must be less than or equal to this number. [sent-215, score-0.402]
</p><p>66 Intuitively, the solution to (5) is the mixture parameter that produces the lowest error between the observations (the minimum scores returned by the nearest-neighbor matcher for all query features) and the mixture model that combines our estimates for the correct and incorrect distributions. [sent-216, score-0.911]
</p><p>67 (4) to calculate a correctness confidence for each correspondence (step 6). [sent-218, score-0.293]
</p><p>68 Although the confidences determined by the posterior lead to speed ups in the convergence of the model estimation, we noticed that the overlap between distributions causes some incorrect matches to be assigned a high confidence, costing extra iterations in RANSAC. [sent-219, score-0.634]
</p><p>69 Assuming that the  predictor returns a binary vector v where 1denotes correct match and 0 otherwise, we calculate the final weights as wi = pivi , (6) where pi is the posterior for the i-th match. [sent-221, score-0.502]
</p><p>70 , all weights are zero, or when the agreement within some number of iterations did not converge to a solution, then the confidences pi computed with the posterior can be used. [sent-224, score-0.267]
</p><p>71 Finally, we use weights wi to sample matches to generate hypotheses. [sent-225, score-0.296]
</p><p>72 The second experiment measures the performance of our approach against wellestablished non-uniform sampling algorithms for the estimation task of homographies and fundamental matrices. [sent-231, score-0.194]
</p><p>73 3632  The estimation experiments consider cases ranging from a very low inlier-ratio to cases where the inlier ratio is larger, which are more commonly presented in previous work. [sent-254, score-0.34]
</p><p>74 Each Oxford dataset contains a reference image and five query images, as well as five homographies that relate the reference image and the query images. [sent-256, score-0.48]
</p><p>75 For the Oxford datasets, we exploited the homographies provided and mapped the reference image keypoints onto every query image. [sent-261, score-0.359]
</p><p>76 Subsequently, we then selected for every query keypoint the closest mapped reference keypoint with a minimum Euclidean distance less than five pixels. [sent-262, score-0.461]
</p><p>77 When no reference keypoint was found with this process, then that query keypoint did not have a true match. [sent-263, score-0.354]
</p><p>78 We then matched the keypoints on the subsequent images using their descriptors, and filtered out those query keypoints that produced a distance greater than or equal to 3 pixels from the epiline. [sent-267, score-0.299]
</p><p>79 The resulting set of matches was verified manually to ensure that only correct matches were left. [sent-268, score-0.551]
</p><p>80 Parameter estimation experiment We now present an evaluation of the performance of our algorithm to find the parameters of our probabilistic framework: ε, and the distribution parameters using the predictor from [8] only as the predictor in step 1. [sent-271, score-0.383]
</p><p>81 We compared the estimated parameters against the parameters obtained assuming that we had a perfect correct match detector. [sent-272, score-0.178]
</p><p>82 Comparison of the mixture of densities and posterior probability computed using EVSAC against the ground truth for a pair of images with SIFT matches (top row) and SURF matches (bottom row). [sent-283, score-0.679]
</p><p>83 Our density estimations fˆc and gˆ c¯ are close to the densities fc and g c¯ computed with an oracle. [sent-284, score-0.237]
</p><p>84 In the second column, we compare our estimated posterior probability ˆ p with the posterior p computed with the oracle. [sent-285, score-0.204]
</p><p>85 Next, we examine the quality of our estimation of the different probability densities and the posterior we use to compute the weights wi. [sent-288, score-0.275]
</p><p>86 In the second column, we present the posterior probabilities computed from the estimated model (continuous curves) and the posterior obtained from the ground truth (dashed curves). [sent-291, score-0.204]
</p><p>87 This means that our algorithm estimates an accu-  rate posterior that essentially maximizes the information in the matching score when computing a confidence value. [sent-292, score-0.389]
</p><p>88 We implemented the probabilistic model parameter estimation in Matlab, and produced the set of weights for every correspondence. [sent-296, score-0.235]
</p><p>89 An inlier was considered if the reprojection error of the homography was less than 5 pixels. [sent-303, score-0.35]
</p><p>90 We can observe that our algorithm (EVSAC) tends to perform overall faster when the inlier ratio is very low (see rows A, B, C, D, and E), and performs equivalent or faster than BEEM and BLOGS as soon as the inlier-ratio increased (see rows F, G, H, I). [sent-314, score-0.387]
</p><p>91 We  only considered BEEM, BLOGS, and EVSAC because the other methods did not converge when the inlier ratio was low. [sent-319, score-0.335]
</p><p>92 When the function returned more than one solution, we kept the matrix that had the biggest inlier support. [sent-327, score-0.238]
</p><p>93 A match was considered to be an inlier when  isme[c]meT150 . [sent-328, score-0.297]
</p><p>94 Convergence time as a function of the inlier ratio for SIFT matches (left) and SURF matches (right) on the OxfordTrees dataset. [sent-334, score-0.733]
</p><p>95 the distance between a query keypoint and the epiline was less than a pixel. [sent-335, score-0.199]
</p><p>96 Strecha’s multi-view dataset provided different relatively high inlier ratios; ranging from 29-43% for SIFT and SURF matches. [sent-337, score-0.238]
</p><p>97 Conclusions and future directions We have introduced a probabilistic framework that uses extreme value theory to model the statistics of the best matching scores selected by a nearest-neighbor feature matcher. [sent-344, score-0.473]
</p><p>98 We then use the posterior probability of our mixture model to compute the correctness weight for every correspondence and thereby accelerate model generation. [sent-345, score-0.4]
</p><p>99 Our homography and fundamental matrix estimation experiments showed that our algorithm (EVSAC) performs robustly and is faster than existing state-of-the-art methods (BEEM, BLOGS, PROSAC, and GMLESAC) when the  inlier-ratio is low (< 11%). [sent-346, score-0.24]
</p><p>100 This work opens the possibility of using extreme value theory for developing models for related problems that involve a minimum (or maximum) which can be cast as stochastic processes. [sent-349, score-0.273]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('evsac', 0.402), ('inlier', 0.238), ('blogs', 0.226), ('matches', 0.216), ('prosac', 0.201), ('beem', 0.2), ('surf', 0.196), ('incorrect', 0.178), ('matcher', 0.156), ('fc', 0.151), ('scores', 0.138), ('query', 0.126), ('gmlesac', 0.126), ('correctness', 0.119), ('correct', 0.119), ('ransac', 0.118), ('matching', 0.118), ('homography', 0.112), ('gev', 0.111), ('extreme', 0.108), ('posterior', 0.102), ('predictor', 0.101), ('matchnig', 0.1), ('confidence', 0.098), ('distributions', 0.09), ('cdf', 0.089), ('densities', 0.086), ('reference', 0.082), ('gamma', 0.08), ('minimum', 0.076), ('correspondences', 0.076), ('evt', 0.075), ('fragoso', 0.075), ('inliers', 0.075), ('sift', 0.074), ('keypoint', 0.073), ('score', 0.071), ('homographies', 0.064), ('ascending', 0.063), ('ratio', 0.063), ('oxford', 0.061), ('strecha', 0.061), ('produced', 0.061), ('fundamental', 0.06), ('mixture', 0.059), ('match', 0.059), ('opencv', 0.057), ('keypoints', 0.056), ('probabilistic', 0.056), ('distribution', 0.055), ('hypotheses', 0.055), ('accelerate', 0.054), ('theory', 0.053), ('sorted', 0.05), ('brahmachari', 0.05), ('gumbel', 0.05), ('metarecognition', 0.05), ('ofransac', 0.05), ('preidentified', 0.05), ('tordoff', 0.05), ('hypothesis', 0.049), ('confidences', 0.048), ('weights', 0.048), ('echet', 0.045), ('goshen', 0.045), ('raguram', 0.045), ('jm', 0.044), ('consensus', 0.042), ('generation', 0.041), ('calculate', 0.041), ('matas', 0.041), ('assess', 0.04), ('estimation', 0.039), ('chum', 0.038), ('fitted', 0.037), ('accelerating', 0.037), ('stochastic', 0.036), ('rj', 0.036), ('correspondence', 0.035), ('agreement', 0.035), ('theorem', 0.035), ('converge', 0.034), ('guided', 0.034), ('lowe', 0.034), ('scheirer', 0.034), ('qi', 0.034), ('leverages', 0.033), ('mixing', 0.033), ('si', 0.033), ('descriptors', 0.032), ('wi', 0.032), ('every', 0.031), ('experiment', 0.031), ('equivalently', 0.03), ('fly', 0.03), ('mn', 0.03), ('faster', 0.029), ('curves', 0.029), ('pdf', 0.029), ('tends', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="131-tfidf-1" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>2 0.14631754 <a title="131-tfidf-2" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>Author: Jim Braux-Zin, Romain Dupont, Adrien Bartoli</p><p>Abstract: Dense motion field estimation (typically Romain Dupont1 romain . dupont @ cea . fr Adrien Bartoli2 adrien . bart o l @ gmai l com i . 2 ISIT, Universit e´ d’Auvergne/CNRS, France sions are explicitly modeled [32, 13]. Coarse-to-fine warping improves global convergence by making the assumption that optical flow, the motion of smaller structures is similar to the motion of stereo disparity and surface registration) is a key computer vision problem. Many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, but a unified methodology is still lacking. We here introduce a general framework that robustly combines direct and feature-based matching. The feature-based cost is built around a novel robust distance function that handles keypoints and “weak” features such as segments. It allows us to use putative feature matches which may contain mismatches to guide dense motion estimation out of local minima. Our framework uses a robust direct data term (AD-Census). It is implemented with a powerful second order Total Generalized Variation regularization with external and self-occlusion reasoning. Our framework achieves state of the art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). Our framework has a modular design that customizes to specific application needs.</p><p>3 0.13282779 <a title="131-tfidf-3" href="./iccv-2013-Improving_Graph_Matching_via_Density_Maximization.html">214 iccv-2013-Improving Graph Matching via Density Maximization</a></p>
<p>Author: Chao Wang, Lei Wang, Lingqiao Liu</p><p>Abstract: Graph matching has been widely used in various applications in computer vision due to its powerful performance. However, it poses three challenges to image sparse feature matching: (1) The combinatorial nature limits the size of the possible matches; (2) It is sensitive to outliers because the objective function prefers more matches; (3) It works poorly when handling many-to-many object correspondences, due to its assumption of one single cluster for each graph. In this paper, we address these problems with a unified framework—Density Maximization. We propose a graph density local estimator (퐷퐿퐸) to measure the quality of matches. Density Maximization aims to maximize the 퐷퐿퐸 values both locally and globally. The local maximization of 퐷퐿퐸 finds the clusters of nodes as well as eliminates the outliers. The global maximization of 퐷퐿퐸 efficiently refines the matches by exploring a much larger matching space. Our Density Maximization is orthogonal to specific graph matching algorithms. Experimental evaluation demonstrates that it significantly boosts the true matches and enables graph matching to handle both outliers and many-to-many object correspondences.</p><p>4 0.12560107 <a title="131-tfidf-4" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>5 0.11794998 <a title="131-tfidf-5" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>6 0.11100237 <a title="131-tfidf-6" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<p>7 0.11006469 <a title="131-tfidf-7" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>8 0.10683004 <a title="131-tfidf-8" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>9 0.10632291 <a title="131-tfidf-9" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>10 0.10090923 <a title="131-tfidf-10" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>11 0.096678928 <a title="131-tfidf-11" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>12 0.093214393 <a title="131-tfidf-12" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>13 0.088407181 <a title="131-tfidf-13" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>14 0.087091088 <a title="131-tfidf-14" href="./iccv-2013-3DNN%3A_Viewpoint_Invariant_3D_Geometry_Matching_for_Scene_Understanding.html">1 iccv-2013-3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding</a></p>
<p>15 0.084294058 <a title="131-tfidf-15" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>16 0.081064247 <a title="131-tfidf-16" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>17 0.080215558 <a title="131-tfidf-17" href="./iccv-2013-Parsing_IKEA_Objects%3A_Fine_Pose_Estimation.html">308 iccv-2013-Parsing IKEA Objects: Fine Pose Estimation</a></p>
<p>18 0.080071405 <a title="131-tfidf-18" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>19 0.07756421 <a title="131-tfidf-19" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>20 0.075175598 <a title="131-tfidf-20" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.173), (1, -0.04), (2, -0.042), (3, -0.036), (4, 0.014), (5, 0.095), (6, 0.027), (7, -0.034), (8, -0.011), (9, 0.005), (10, 0.038), (11, 0.003), (12, 0.056), (13, 0.035), (14, 0.054), (15, 0.03), (16, 0.092), (17, -0.008), (18, 0.143), (19, -0.032), (20, 0.003), (21, -0.036), (22, -0.016), (23, -0.004), (24, 0.134), (25, -0.071), (26, 0.029), (27, 0.032), (28, -0.022), (29, -0.04), (30, 0.029), (31, 0.004), (32, 0.036), (33, -0.022), (34, 0.016), (35, -0.047), (36, 0.029), (37, -0.06), (38, 0.012), (39, 0.023), (40, 0.0), (41, 0.123), (42, 0.071), (43, 0.02), (44, -0.008), (45, 0.035), (46, 0.031), (47, -0.016), (48, -0.034), (49, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95982957 <a title="131-lsi-1" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>2 0.70693165 <a title="131-lsi-2" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>3 0.66272366 <a title="131-lsi-3" href="./iccv-2013-Fast_Neighborhood_Graph_Search_Using_Cartesian_Concatenation.html">159 iccv-2013-Fast Neighborhood Graph Search Using Cartesian Concatenation</a></p>
<p>Author: Jing Wang, Jingdong Wang, Gang Zeng, Rui Gan, Shipeng Li, Baining Guo</p><p>Abstract: In this paper, we propose a new data structure for approximate nearest neighbor search. This structure augments the neighborhoodgraph with a bridge graph. We propose to exploit Cartesian concatenation to produce a large set of vectors, called bridge vectors, from several small sets of subvectors. Each bridge vector is connected with a few reference vectors near to it, forming a bridge graph. Our approach finds nearest neighbors by simultaneously traversing the neighborhood graph and the bridge graph in the best-first strategy. The success of our approach stems from two factors: the exact nearest neighbor search over a large number of bridge vectors can be done quickly, and the reference vectors connected to a bridge (reference) vector near the query are also likely to be near the query. Experimental results on searching over large scale datasets (SIFT, GIST andHOG) show that our approach outperforms stateof-the-art ANN search algorithms in terms of efficiency and accuracy. The combination of our approach with the IVFADC system [18] also shows superior performance over the BIGANN dataset of 1 billion SIFT features compared with the best previously published result.</p><p>4 0.65325493 <a title="131-lsi-4" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>Author: Emanuele Rodolà, Andrea Torsello, Tatsuya Harada, Yasuo Kuniyoshi, Daniel Cremers</p><p>Abstract: We consider a parametrized relaxation of the widely adopted quadratic assignment problem (QAP) formulation for minimum distortion correspondence between deformable shapes. In order to control the accuracy/sparsity trade-off we introduce a weighting parameter on the combination of two existing relaxations, namely spectral and game-theoretic. This leads to the introduction of the elastic net penalty function into shape matching problems. In combination with an efficient algorithm to project onto the elastic net ball, we obtain an approach for deformable shape matching with controllable sparsity. Experiments on a standard benchmark confirm the effectiveness of the approach.</p><p>5 0.63996148 <a title="131-lsi-5" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>6 0.63950509 <a title="131-lsi-6" href="./iccv-2013-To_Aggregate_or_Not_to_aggregate%3A_Selective_Match_Kernels_for_Image_Search.html">419 iccv-2013-To Aggregate or Not to aggregate: Selective Match Kernels for Image Search</a></p>
<p>7 0.63236135 <a title="131-lsi-7" href="./iccv-2013-SIFTpack%3A_A_Compact_Representation_for_Efficient_SIFT_Matching.html">365 iccv-2013-SIFTpack: A Compact Representation for Efficient SIFT Matching</a></p>
<p>8 0.62126052 <a title="131-lsi-8" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>9 0.62091833 <a title="131-lsi-9" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>10 0.61463434 <a title="131-lsi-10" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>11 0.60351968 <a title="131-lsi-11" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>12 0.59767014 <a title="131-lsi-12" href="./iccv-2013-Improving_Graph_Matching_via_Density_Maximization.html">214 iccv-2013-Improving Graph Matching via Density Maximization</a></p>
<p>13 0.58831644 <a title="131-lsi-13" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>14 0.58357257 <a title="131-lsi-14" href="./iccv-2013-Human_Re-identification_by_Matching_Compositional_Template_with_Cluster_Sampling.html">205 iccv-2013-Human Re-identification by Matching Compositional Template with Cluster Sampling</a></p>
<p>15 0.57726043 <a title="131-lsi-15" href="./iccv-2013-Joint_Inverted_Indexing.html">221 iccv-2013-Joint Inverted Indexing</a></p>
<p>16 0.57306099 <a title="131-lsi-16" href="./iccv-2013-Person_Re-identification_by_Salience_Matching.html">313 iccv-2013-Person Re-identification by Salience Matching</a></p>
<p>17 0.56979918 <a title="131-lsi-17" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>18 0.56418514 <a title="131-lsi-18" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>19 0.56121945 <a title="131-lsi-19" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>20 0.55949783 <a title="131-lsi-20" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.052), (6, 0.015), (7, 0.021), (26, 0.065), (31, 0.049), (42, 0.125), (61, 0.215), (64, 0.034), (73, 0.062), (89, 0.237), (98, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85127032 <a title="131-lda-1" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: Automatic image categorization has become increasingly important with the development of Internet and the growth in the size of image databases. Although the image categorization can be formulated as a typical multiclass classification problem, two major challenges have been raised by the real-world images. On one hand, though using more labeled training data may improve the prediction performance, obtaining the image labels is a time consuming as well as biased process. On the other hand, more and more visual descriptors have been proposed to describe objects and scenes appearing in images and different features describe different aspects of the visual characteristics. Therefore, how to integrate heterogeneous visual features to do the semi-supervised learning is crucial for categorizing large-scale image data. In this paper, we propose a novel approach to integrate heterogeneous features by performing multi-modal semi-supervised classification on unlabeled as well as unsegmented images. Considering each type of feature as one modality, taking advantage of the large amoun- t of unlabeled data information, our new adaptive multimodal semi-supervised classification (AMMSS) algorithm learns a commonly shared class indicator matrix and the weights for different modalities (image features) simultaneously.</p><p>same-paper 2 0.84917647 <a title="131-lda-2" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>3 0.84869826 <a title="131-lda-3" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>Author: Zhiyuan Shi, Timothy M. Hospedales, Tao Xiang</p><p>Abstract: We address the problem of localisation of objects as bounding boxes in images with weak labels. This weakly supervised object localisation problem has been tackled in the past using discriminative models where each object class is localised independently from other classes. We propose a novel framework based on Bayesian joint topic modelling. Our framework has three distinctive advantages over previous works: (1) All object classes and image backgrounds are modelled jointly together in a single generative model so that “explaining away” inference can resolve ambiguity and lead to better learning and localisation. (2) The Bayesian formulation of the model enables easy integration of prior knowledge about object appearance to compensate for limited supervision. (3) Our model can be learned with a mixture of weakly labelled and unlabelled data, allowing the large volume of unlabelled images on the Internet to be exploited for learning. Extensive experiments on the challenging VOC dataset demonstrate that our approach outperforms the state-of-the-art competitors.</p><p>4 0.83116949 <a title="131-lda-4" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>Author: Manjunath Narayana, Allen Hanson, Erik Learned-Miller</p><p>Abstract: In moving camera videos, motion segmentation is commonly performed using the image plane motion of pixels, or optical flow. However, objects that are at different depths from the camera can exhibit different optical flows even if they share the same real-world motion. This can cause a depth-dependent segmentation of the scene. Our goal is to develop a segmentation algorithm that clusters pixels that have similar real-world motion irrespective of their depth in the scene. Our solution uses optical flow orientations instead of the complete vectors and exploits the well-known property that under camera translation, optical flow orientations are independent of object depth. We introduce a probabilistic model that automatically estimates the number of observed independent motions and results in a labeling that is consistent with real-world motion in the scene. The result of our system is that static objects are correctly identified as one segment, even if they are at different depths. Color features and information from previous frames in the video sequence are used to correct occasional errors due to the orientation-based segmentation. We present results on more than thirty videos from different benchmarks. The system is particularly robust on complex background scenes containing objects at significantly different depths.</p><p>5 0.79671323 <a title="131-lda-5" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>6 0.79574209 <a title="131-lda-6" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>7 0.79573345 <a title="131-lda-7" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>8 0.79545665 <a title="131-lda-8" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>9 0.79531521 <a title="131-lda-9" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>10 0.79473293 <a title="131-lda-10" href="./iccv-2013-Perspective_Motion_Segmentation_via_Collaborative_Clustering.html">314 iccv-2013-Perspective Motion Segmentation via Collaborative Clustering</a></p>
<p>11 0.79445344 <a title="131-lda-11" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>12 0.79374969 <a title="131-lda-12" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>13 0.79340106 <a title="131-lda-13" href="./iccv-2013-HOGgles%3A_Visualizing_Object_Detection_Features.html">189 iccv-2013-HOGgles: Visualizing Object Detection Features</a></p>
<p>14 0.79279786 <a title="131-lda-14" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<p>15 0.79260778 <a title="131-lda-15" href="./iccv-2013-Parsing_IKEA_Objects%3A_Fine_Pose_Estimation.html">308 iccv-2013-Parsing IKEA Objects: Fine Pose Estimation</a></p>
<p>16 0.79248893 <a title="131-lda-16" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<p>17 0.79237652 <a title="131-lda-17" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>18 0.79217398 <a title="131-lda-18" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>19 0.79208159 <a title="131-lda-19" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>20 0.7920078 <a title="131-lda-20" href="./iccv-2013-Discriminatively_Trained_Templates_for_3D_Object_Detection%3A_A_Real_Time_Scalable_Approach.html">121 iccv-2013-Discriminatively Trained Templates for 3D Object Detection: A Real Time Scalable Approach</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
