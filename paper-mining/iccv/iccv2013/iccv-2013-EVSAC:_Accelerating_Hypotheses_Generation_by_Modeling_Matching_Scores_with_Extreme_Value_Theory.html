<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-131" href="#">iccv2013-131</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</h1>
<br/><p>Source: <a title="iccv-2013-131-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Fragoso_EVSAC_Accelerating_Hypotheses_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>Reference: <a title="iccv-2013-131-reference" href="../iccv2013_reference/iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('evsac', 0.464), ('blog', 0.261), ('prosac', 0.232), ('beem', 0.232), ('surf', 0.22), ('match', 0.201), ('incorrect', 0.181), ('scor', 0.18), ('homograph', 0.176), ('fc', 0.174), ('gmlesac', 0.145), ('ransac', 0.137), ('query', 0.134), ('keypoint', 0.128), ('confid', 0.121), ('postery', 0.117), ('matchnig', 0.116), ('cdf', 0.103), ('correct', 0.1), ('gamm', 0.093)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="131-tfidf-1" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>2 0.12643234 <a title="131-tfidf-2" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>3 0.12172753 <a title="131-tfidf-3" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>Author: Basura Fernando, Tinne Tuytelaars</p><p>Abstract: In this paper we present a new method for object retrieval starting from multiple query images. The use of multiple queries allows for a more expressive formulation of the query object including, e.g., different viewpoints and/or viewing conditions. This, in turn, leads to more diverse and more accurate retrieval results. When no query images are available to the user, they can easily be retrieved from the internet using a standard image search engine. In particular, we propose a new method based on pattern mining. Using the minimal description length principle, we derive the most suitable set of patterns to describe the query object, with patterns corresponding to local feature configurations. This results in apowerful object-specific mid-level image representation. The archive can then be searched efficiently for similar images based on this representation, using a combination of two inverted file systems. Since the patterns already encode local spatial information, good results on several standard image retrieval datasets are obtained even without costly re-ranking based on geometric verification.</p><p>4 0.11171775 <a title="131-tfidf-4" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<p>Author: Renliang Weng, Jiwen Lu, Junlin Hu, Gao Yang, Yap-Peng Tan</p><p>Abstract: Over the past two decades, a number of face recognition methods have been proposed in the literature. Most of them use holistic face images to recognize people. However, human faces are easily occluded by other objects in many real-world scenarios and we have to recognize the person of interest from his/her partial faces. In this paper, we propose a new partial face recognition approach by using feature set matching, which is able to align partial face patches to holistic gallery faces automatically and is robust to occlusions and illumination changes. Given each gallery image and probe face patch, we first detect keypoints and extract their local features. Then, we propose a Metric Learned ExtendedRobust PointMatching (MLERPM) method to discriminatively match local feature sets of a pair of gallery and probe samples. Lastly, the similarity of two faces is converted as the distance between two feature sets. Experimental results on three public face databases are presented to show the effectiveness of the proposed approach.</p><p>5 0.10451914 <a title="131-tfidf-5" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<p>Author: Heng Wang, Cordelia Schmid</p><p>Abstract: Recently dense trajectories were shown to be an efficient video representation for action recognition and achieved state-of-the-art results on a variety of datasets. This paper improves their performance by taking into account camera motion to correct them. To estimate camera motion, we match feature points between frames using SURF descriptors and dense optical flow, which are shown to be complementary. These matches are, then, used to robustly estimate a homography with RANSAC. Human motion is in general different from camera motion and generates inconsistent matches. To improve the estimation, a human detector is employed to remove these matches. Given the estimated camera motion, we remove trajectories consistent with it. We also use this estimation to cancel out camera motion from the optical flow. This significantly improves motion-based descriptors, such as HOF and MBH. Experimental results onfour challenging action datasets (i.e., Hollywood2, HMDB51, Olympic Sports and UCF50) significantly outperform the current state of the art.</p><p>6 0.10411094 <a title="131-tfidf-6" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>7 0.10206617 <a title="131-tfidf-7" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>8 0.10052652 <a title="131-tfidf-8" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>9 0.099770516 <a title="131-tfidf-9" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>10 0.097872794 <a title="131-tfidf-10" href="./iccv-2013-Improving_Graph_Matching_via_Density_Maximization.html">214 iccv-2013-Improving Graph Matching via Density Maximization</a></p>
<p>11 0.09707851 <a title="131-tfidf-11" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>12 0.096473828 <a title="131-tfidf-12" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>13 0.094830334 <a title="131-tfidf-13" href="./iccv-2013-3DNN%3A_Viewpoint_Invariant_3D_Geometry_Matching_for_Scene_Understanding.html">1 iccv-2013-3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding</a></p>
<p>14 0.0864885 <a title="131-tfidf-14" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>15 0.083610594 <a title="131-tfidf-15" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>16 0.07949128 <a title="131-tfidf-16" href="./iccv-2013-Image_Retrieval_Using_Textual_Cues.html">210 iccv-2013-Image Retrieval Using Textual Cues</a></p>
<p>17 0.078391388 <a title="131-tfidf-17" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>18 0.075676747 <a title="131-tfidf-18" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>19 0.074414007 <a title="131-tfidf-19" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>20 0.073651537 <a title="131-tfidf-20" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.167), (1, -0.035), (2, -0.031), (3, 0.046), (4, 0.068), (5, 0.012), (6, 0.008), (7, -0.002), (8, -0.01), (9, -0.011), (10, -0.116), (11, 0.095), (12, 0.039), (13, -0.008), (14, -0.033), (15, -0.047), (16, -0.023), (17, -0.023), (18, -0.026), (19, 0.022), (20, -0.008), (21, 0.104), (22, 0.004), (23, 0.01), (24, -0.002), (25, -0.086), (26, 0.002), (27, 0.027), (28, 0.025), (29, -0.047), (30, 0.024), (31, -0.027), (32, 0.027), (33, 0.094), (34, -0.037), (35, -0.013), (36, 0.032), (37, -0.035), (38, -0.062), (39, -0.028), (40, 0.016), (41, 0.045), (42, 0.084), (43, 0.065), (44, -0.021), (45, 0.01), (46, 0.032), (47, 0.102), (48, -0.012), (49, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93189001 <a title="131-lsi-1" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>2 0.72786999 <a title="131-lsi-2" href="./iccv-2013-To_Aggregate_or_Not_to_aggregate%3A_Selective_Match_Kernels_for_Image_Search.html">419 iccv-2013-To Aggregate or Not to aggregate: Selective Match Kernels for Image Search</a></p>
<p>Author: Giorgos Tolias, Yannis Avrithis, Hervé Jégou</p><p>Abstract: This paper considers a family of metrics to compare images based on their local descriptors. It encompasses the VLAD descriptor and matching techniques such as Hamming Embedding. Making the bridge between these approaches leads us to propose a match kernel that takes the best of existing techniques by combining an aggregation procedure with a selective match kernel. Finally, the representation underpinning this kernel is approximated, providing a large scale image search both precise and scalable, as shown by our experiments on several benchmarks.</p><p>3 0.7117033 <a title="131-lsi-3" href="./iccv-2013-SIFTpack%3A_A_Compact_Representation_for_Efficient_SIFT_Matching.html">365 iccv-2013-SIFTpack: A Compact Representation for Efficient SIFT Matching</a></p>
<p>Author: Alexandra Gilinsky, Lihi Zelnik Manor</p><p>Abstract: Computing distances between large sets of SIFT descriptors is a basic step in numerous algorithms in computer vision. When the number of descriptors is large, as is often the case, computing these distances can be extremely time consuming. In this paper we propose the SIFTpack: a compact way of storing SIFT descriptors, which enables significantly faster calculations between sets of SIFTs than the current solutions. SIFTpack can be used to represent SIFTs densely extracted from a single image or sparsely from multiple different images. We show that the SIFTpack representation saves both storage space and run time, for both finding nearest neighbors and for computing all distances between all descriptors. The usefulness of SIFTpack is also demonstrated as an alternative implementation for K-means dictionaries of visual words.</p><p>4 0.68668938 <a title="131-lsi-4" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>5 0.68423158 <a title="131-lsi-5" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>Author: Cai-Zhi Zhu, Hervé Jégou, Shin'Ichi Satoh</p><p>Abstract: Visual object retrieval aims at retrieving, from a collection of images, all those in which a given query object appears. It is inherently asymmetric: the query object is mostly included in the database image, while the converse is not necessarily true. However, existing approaches mostly compare the images with symmetrical measures, without considering the different roles of query and database. This paper first measure the extent of asymmetry on large-scale public datasets reflecting this task. Considering the standard bag-of-words representation, we then propose new asymmetrical dissimilarities accounting for the different inlier ratios associated with query and database images. These asymmetrical measures depend on the query, yet they are compatible with an inverted file structure, without noticeably impacting search efficiency. Our experiments show the benefit of our approach, and show that the visual object retrieval task is better treated asymmetrically, in the spirit of state-of-the-art text retrieval.</p><p>6 0.65463871 <a title="131-lsi-6" href="./iccv-2013-Fast_Neighborhood_Graph_Search_Using_Cartesian_Concatenation.html">159 iccv-2013-Fast Neighborhood Graph Search Using Cartesian Concatenation</a></p>
<p>7 0.6523996 <a title="131-lsi-7" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>8 0.63912606 <a title="131-lsi-8" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>9 0.61371905 <a title="131-lsi-9" href="./iccv-2013-Offline_Mobile_Instance_Retrieval_with_a_Small_Memory_Footprint.html">294 iccv-2013-Offline Mobile Instance Retrieval with a Small Memory Footprint</a></p>
<p>10 0.60817051 <a title="131-lsi-10" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>11 0.60190123 <a title="131-lsi-11" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>12 0.60181582 <a title="131-lsi-12" href="./iccv-2013-3DNN%3A_Viewpoint_Invariant_3D_Geometry_Matching_for_Scene_Understanding.html">1 iccv-2013-3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding</a></p>
<p>13 0.60154665 <a title="131-lsi-13" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>14 0.59583145 <a title="131-lsi-14" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>15 0.59104401 <a title="131-lsi-15" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>16 0.58368641 <a title="131-lsi-16" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>17 0.58209133 <a title="131-lsi-17" href="./iccv-2013-Learning_Coupled_Feature_Spaces_for_Cross-Modal_Matching.html">235 iccv-2013-Learning Coupled Feature Spaces for Cross-Modal Matching</a></p>
<p>18 0.57902163 <a title="131-lsi-18" href="./iccv-2013-Joint_Optimization_for_Consistent_Multiple_Graph_Matching.html">224 iccv-2013-Joint Optimization for Consistent Multiple Graph Matching</a></p>
<p>19 0.57718831 <a title="131-lsi-19" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>20 0.57039624 <a title="131-lsi-20" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.027), (18, 0.014), (20, 0.092), (25, 0.034), (42, 0.099), (48, 0.18), (55, 0.03), (60, 0.019), (77, 0.073), (89, 0.355)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.76759535 <a title="131-lda-1" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>Author: Jan Lellmann, Evgeny Strekalovskiy, Sabrina Koetter, Daniel Cremers</p><p>Abstract: While total variation is among the most popular regularizers for variational problems, its extension to functions with values in a manifold is an open problem. In this paper, we propose the first algorithm to solve such problems which applies to arbitrary Riemannian manifolds. The key idea is to reformulate the variational problem as a multilabel optimization problem with an infinite number of labels. This leads to a hard optimization problem which can be approximately solved using convex relaxation techniques. The framework can be easily adapted to different manifolds including spheres and three-dimensional rotations, and allows to obtain accurate solutions even with a relatively coarse discretization. With numerous examples we demonstrate that the proposed framework can be applied to variational models that incorporate chromaticity values, normal fields, or camera trajectories.</p><p>2 0.70962715 <a title="131-lda-2" href="./iccv-2013-Network_Principles_for_SfM%3A_Disambiguating_Repeated_Structures_with_Local_Context.html">289 iccv-2013-Network Principles for SfM: Disambiguating Repeated Structures with Local Context</a></p>
<p>Author: Kyle Wilson, Noah Snavely</p><p>Abstract: Repeated features are common in urban scenes. Many objects, such as clock towers with nearly identical sides, or domes with strong radial symmetries, pose challenges for structure from motion. When similar but distinct features are mistakenly equated, the resulting 3D reconstructions can have errors ranging from phantom walls and superimposed structures to a complete failure to reconstruct. We present a new approach to solving such problems by considering the local visibility structure of such repeated features. Drawing upon network theory, we present a new way of scoring features using a measure of local clustering. Our model leads to a simple, fast, and highly scalable technique for disambiguating repeated features based on an analysis of an underlying visibility graph, without relying on explicit geometric reasoning. We demonstrate our method on several very large datasets drawn from Internet photo collections, and compare it to a more traditional geometry-based disambiguation technique.</p><p>3 0.6876539 <a title="131-lda-3" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>Author: Qiong Cao, Yiming Ying, Peng Li</p><p>Abstract: Recently, there is a considerable amount of efforts devoted to the problem of unconstrained face verification, where the task is to predict whether pairs of images are from the same person or not. This problem is challenging and difficult due to the large variations in face images. In this paper, we develop a novel regularization framework to learn similarity metrics for unconstrained face verification. We formulate its objective function by incorporating the robustness to the large intra-personal variations and the discriminative power of novel similarity metrics. In addition, our formulation is a convex optimization problem which guarantees the existence of its global solution. Experiments show that our proposed method achieves the state-of-the-art results on the challenging Labeled Faces in the Wild (LFW) database [10].</p><p>same-paper 4 0.66724849 <a title="131-lda-4" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>Author: Victor Fragoso, Pradeep Sen, Sergio Rodriguez, Matthew Turk</p><p>Abstract: Algorithms based on RANSAC that estimate models usingfeature correspondences between images can slow down tremendously when the percentage of correct correspondences (inliers) is small. In this paper, we present a probabilistic parametric model that allows us to assign confidence values for each matching correspondence and therefore accelerates the generation of hypothesis models for RANSAC under these conditions. Our framework leverages Extreme Value Theory to accurately model the statistics of matching scores produced by a nearest-neighbor feature matcher. Using a new algorithm based on this model, we are able to estimate accurate hypotheses with RANSAC at low inlier ratios significantly faster than previous stateof-the-art approaches, while still performing comparably when the number ofinliers is large. Wepresent results ofhomography and fundamental matrix estimation experiments for both SIFT and SURF matches that demonstrate that our method leads to accurate and fast model estimations.</p><p>5 0.64282334 <a title="131-lda-5" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>Author: Fan Wang, Qixing Huang, Leonidas J. Guibas</p><p>Abstract: Joint segmentation of image sets has great importance for object recognition, image classification, and image retrieval. In this paper, we aim to jointly segment a set of images starting from a small number of labeled images or none at all. To allow the images to share segmentation information with each other, we build a network that contains segmented as well as unsegmented images, and extract functional maps between connected image pairs based on image appearance features. These functional maps act as general property transporters between the images and, in particular, are used to transfer segmentations. We define and operate in a reduced functional space optimized so that the functional maps approximately satisfy cycle-consistency under composition in the network. A joint optimization framework is proposed to simultaneously generate all segmentation functions over the images so that they both align with local segmentation cues in each particular image, and agree with each other under network transportation. This formulation allows us to extract segmentations even with no training data, but can also exploit such data when available. The collective effect of the joint processing using functional maps leads to accurate information sharing among images and yields superior segmentation results, as shown on the iCoseg, MSRC, and PASCAL data sets.</p><p>6 0.63425225 <a title="131-lda-6" href="./iccv-2013-Domain_Adaptive_Classification.html">123 iccv-2013-Domain Adaptive Classification</a></p>
<p>7 0.62555116 <a title="131-lda-7" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>8 0.60079068 <a title="131-lda-8" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<p>9 0.58112448 <a title="131-lda-9" href="./iccv-2013-Complementary_Projection_Hashing.html">83 iccv-2013-Complementary Projection Hashing</a></p>
<p>10 0.57499129 <a title="131-lda-10" href="./iccv-2013-Joint_Learning_of_Discriminative_Prototypes_and_Large_Margin_Nearest_Neighbor_Classifiers.html">222 iccv-2013-Joint Learning of Discriminative Prototypes and Large Margin Nearest Neighbor Classifiers</a></p>
<p>11 0.57408333 <a title="131-lda-11" href="./iccv-2013-Unsupervised_Domain_Adaptation_by_Domain_Invariant_Projection.html">435 iccv-2013-Unsupervised Domain Adaptation by Domain Invariant Projection</a></p>
<p>12 0.57368064 <a title="131-lda-12" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>13 0.56955421 <a title="131-lda-13" href="./iccv-2013-Subpixel_Scanning_Invariant_to_Indirect_Lighting_Using_Quadratic_Code_Length.html">407 iccv-2013-Subpixel Scanning Invariant to Indirect Lighting Using Quadratic Code Length</a></p>
<p>14 0.56942368 <a title="131-lda-14" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>15 0.56631702 <a title="131-lda-15" href="./iccv-2013-Frustratingly_Easy_NBNN_Domain_Adaptation.html">181 iccv-2013-Frustratingly Easy NBNN Domain Adaptation</a></p>
<p>16 0.56327355 <a title="131-lda-16" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>17 0.56312084 <a title="131-lda-17" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>18 0.56064892 <a title="131-lda-18" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>19 0.5605762 <a title="131-lda-19" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>20 0.56022972 <a title="131-lda-20" href="./iccv-2013-Discovering_Details_and_Scene_Structure_with_Hierarchical_Iconoid_Shift.html">117 iccv-2013-Discovering Details and Scene Structure with Hierarchical Iconoid Shift</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
