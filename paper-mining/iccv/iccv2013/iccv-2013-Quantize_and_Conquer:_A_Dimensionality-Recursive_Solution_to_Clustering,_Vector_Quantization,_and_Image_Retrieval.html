<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-333" href="#">iccv2013-333</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</h1>
<br/><p>Source: <a title="iccv-2013-333-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Avrithis_Quantize_and_Conquer_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yannis Avrithis</p><p>Abstract: Inspired by the close relation between nearest neighbor search and clustering in high-dimensional spaces as well as the success of one helping to solve the other, we introduce a new paradigm where both problems are solved simultaneously. Our solution is recursive, not in the size of input data but in the number of dimensions. One result is a clustering algorithm that is tuned to small codebooks but does not need all data in memory at the same time and is practically constant in the data size. As a by-product, a tree structure performs either exact or approximate quantization on trained centroids, the latter being not very precise but extremely fast. A lesser contribution is a new indexing scheme for image retrieval that exploits multiple small codebooks to provide an arbitrarily fine partition of the descriptor space. Large scale experiments on public datasets exhibit state of the art performance and remarkable generalization.</p><p>Reference: <a title="iccv-2013-333-reference" href="../iccv2013_reference/iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 One result is a clustering algorithm that is tuned to small codebooks but does not need all data in memory at the same time and is practically constant in the data size. [sent-3, score-0.332]
</p><p>2 As a by-product, a tree structure performs either exact or approximate quantization on trained centroids, the latter being not very precise but extremely fast. [sent-4, score-0.36]
</p><p>3 A lesser contribution is a new indexing scheme for image retrieval that exploits multiple small codebooks to provide an arbitrarily fine partition of the descriptor space. [sent-5, score-0.614]
</p><p>4 Introduction We often visualize a clustering process in two dimensions  as in Figure 1, where a number of centroids partition the underlying space into Voronoi cells. [sent-8, score-0.646]
</p><p>5 Even with k-means, which is arguably the fastest alternative at large scale, the cost is dominated by the assignment of data points to the nearest centroid. [sent-9, score-0.27]
</p><p>6 In the 2D discrete space of Figure 1, one may envision solving first the inverse problem of computing a distance map on the entire 2D grid, which could then respond to assignment queries by lookup. [sent-11, score-0.299]
</p><p>7 By analogy, one may envision image retrieval as a propagation process on this grid, where query descriptors serve as source points and a local distance map is generated around these points. [sent-12, score-0.45]
</p><p>8 Indexed images have their descriptors distributed on the grid and only those at a specific range from source points are retrieved. [sent-13, score-0.192]
</p><p>9 Weighting of points is possible based on the distance to nearest query point, as specified by the position on the grid where they are found. [sent-14, score-0.442]
</p><p>10 This is exactly our contribution in this work: we use a 2D discrete grid not just as an analogy but to actually solve clustering or search problems in higher-dimensional spaces. [sent-20, score-0.382]
</p><p>11 The two “dimensions” that we see in fact capture the discrete topology of two subspaces SL, SR, each of d dimensions, that decompose S into a Cartesian product S = SL SR. [sent-22, score-0.217]
</p><p>12 In a clustering setting, and assuming that we see centroids as point sources and do compute a distance map via  propagation from the sources to the entire grid, it is possible to obtain a triangulation as a by-product, having the cluster centroids as vertices as in Figure 1. [sent-23, score-0.996]
</p><p>13 In a retrieval setting, we do not even need a single codebook for the entire descriptor space. [sent-26, score-0.493]
</p><p>14 two or four subvectors, each or which is assigned to a smaller codebook [12]. [sent-32, score-0.309]
</p><p>15 Searching is then possible by first finding nearest neighbors in each individual codebook [2]. [sent-33, score-0.496]
</p><p>16 Related work and contribution Following the success of bag-of-words image retrieval over fine codebooks [20], several attempts have been made to alleviate loss incurred by quantization, including e. [sent-36, score-0.413]
</p><p>17 multiple assignment [21], learning even finer codebooks [14], or embedding more descriptor information [10]. [sent-38, score-0.386]
</p><p>18 At the other extreme of a single codebook, scalar quantization [4] offers a lightweight alternative that cannot be turned into indexing. [sent-41, score-0.291]
</p><p>19 What has captured our attention is that both [12] and [2] require a number of sub-quantizers that are assumed to be trained by an independent clustering algorithm, as well as a way to search into the small individual codebooks, possibly using an independent nearest neighbor search algorithm. [sent-46, score-0.464]
</p><p>20 On the other hand, it is known that clustering for large codebook construction benefits by approximate nearest neighbor (ANN) search, e. [sent-47, score-0.718]
</p><p>21 Using a second order index makes search appear much like local distance propagation on a 2D grid, except that raw/column ordering on the grid are local, i. [sent-53, score-0.342]
</p><p>22 If the codebooks and consequently the grid are small compared to the number of data points, it makes sense to propagate from centroids to the entire grid rather than to make queries in the opposite direction. [sent-57, score-0.965]
</p><p>23 We introduce a new clustering paradigm where nearest neighbor search is handled by distance propagation on a grid. [sent-60, score-0.577]
</p><p>24 We exploit the recursive nature of the algorithm to formulate a tree structure that provides approximate or exact vector quantization. [sent-65, score-0.228]
</p><p>25 It is probably the first time to perform vector quantization by lookup in up to 64 dimensions. [sent-67, score-0.207]
</p><p>26 We explore the use of a higher-order index in the context of image retrieval where we suggest a simple search alternative to existing solutions that scales to effective codebook size up to 256 and multiple assignment neighborhoods of up to 228 cells. [sent-69, score-0.6]
</p><p>27 Optimized product  quantization [6] develops the same idea independently, but also offers a parametric solution that optimizes prior to clustering, which could be combined with our work. [sent-71, score-0.328]
</p><p>28 State of the art work on image retrieval focuses on postprocessing and re-ranking methods to improve precision, for instance query expansion [5, 1], geometry [20, 19, 25], feature augmentation [27, 1], or k-NN re-ranking [25, 22]. [sent-72, score-0.22]
</p><p>29 Such studies are beyond the scope of this work, which focuses on potential improvements from codebook design and descriptor nearest neighbor search. [sent-73, score-0.6]
</p><p>30 Dimensionality-recursive clustering The basic procedural part of our clustering algorithm is kmeans. [sent-77, score-0.202]
</p><p>31 This includes random initialization for a predetermined number of centroids, as well as iterative assignment of points to centroids and centroid update to optimally represent the underlying points. [sent-78, score-0.64]
</p><p>32 The base case: one dimension Given a set X of N data points lying on a bounded interval I [a, b) of R and a target number K > 1of centroids, we = first construct a uniform partition {x0, . [sent-83, score-0.198]
</p><p>33 bTyh ep a(rdtiisticorentineg) V Zor ionntooi V coerlol nVoki of centroid ck ∈ C is the set of points z quantized to ck, Vk = {z ∈ Z : q(z) = ck}. [sent-138, score-0.326]
</p><p>34 (5)  Literally computing Voronoi cells is an easy task in one dimension: because centroids are ordered, we find all midpoints between successive centroids. [sent-139, score-0.497]
</p><p>35 id ck ∈ C simply requires weighted averaging of points over its ∈Vor Cono siim mcepll y V rek,q ck  ← ? [sent-152, score-0.309]
</p><p>36 More formally, assume a 2d-dimensional space S decomposed into a product SL SR of d-dimensional subspaces SL, SR, a set X of N× d aSta points lying on an interval I= IL IR of S, and a target number K > 1 of centroids in I×. [sent-168, score-0.613]
</p><p>37 Also assume that the corresponding sets of projected points XL, XR have been clustered, giving rise to two sets of centroids CL, CR, each of cardinality J. [sent-170, score-0.473]
</p><p>38 The problem in the assignment step is to quantize each point z ∈ Z to the nearest centroid q(z) ∈ C. [sent-184, score-0.325]
</p><p>39 At termination, we map centroids to the nearest points in Z (via (8)) and approximate q(x) for all x ∈ X (section 4. [sent-189, score-0.622]
</p><p>40 This takes log2 D levels of recursion and its output is not merely a set of centroids  ×  2xL, xR are d-tuples; (xL, xR) is their concatenation into a 2d-tuple. [sent-198, score-0.474]
</p><p>41 333000222666  and a corresponding set of labels for the data points, but a tree structure that can perform approximate or exact nearest neighbor search over the centroids, as discussed in section 4. [sent-199, score-0.452]
</p><p>42 An interesting aspect of this new clustering paradigm is that not all data are required in memory at the same time: whenever probability distribution f is available over Z, we are free to discard labels qL(xL), qR(xR), while data points xL, xR are never actually stored. [sent-201, score-0.228]
</p><p>43 This is equivalent to computing a adilsltza nc ∈e map over Z× Cwith C as source points, and can be solved efficiently by distance propagation using a fast marching method [24]. [sent-208, score-0.203]
</p><p>44 Our algorithm, called product propagation (PP), is reminiscent of Dijkstra’s algorithm as any fast marching variant and is outlined in Algorithm 1. [sent-212, score-0.278]
</p><p>45 Centroids are sampled on the grid initially and mapped again to the grid at termination. [sent-217, score-0.314]
</p><p>46 The bottleneck of the entire clustering algorithm is distance propagation: with a binary heap for the priority queue, the time complexity of propagation on a K K grid eis, Othe(eK tim2 elo cgo Kmp),l wxhityere o e irso tphaeg amtiaoxnim oanl degree oKf the graph. [sent-228, score-0.46]
</p><p>47 To limit the queue length, we prune edges as shown in line 24, where threshold τ is specified as a fraction ofthe average distance of all centroids to all bins. [sent-230, score-0.466]
</p><p>48 There is no guarantee that the entire grid will be explored at termination under pruning, but in practice we have verified that with τ = 0. [sent-231, score-0.184]
</p><p>49 Dimensionality-recursive quantization The outcome of clustering as described so far is a set of centroids, a set of data labels, and a graph representing a neighborhood system. [sent-234, score-0.308]
</p><p>50 Clustering of one space relies on clustering of two underlying subspaces, 333000222777  and this recursive implementation gives rise to a tree structure: each produced codebook is a node in the tree and an one-dimensional codebook is a leaf. [sent-236, score-0.945]
</p><p>51 Each codebook is equipped with appropriate information to recursively respond to approximate or exact nearest neighbor queries over its centroids, simply by delegating queries to its child nodes and aggregating. [sent-238, score-0.94]
</p><p>52 Approximate quantization In one dimension, a given new point x in interval I can be mapped to z = h(x) ∈ Z, exactly as we did during training p(e2d). [sent-243, score-0.321]
</p><p>53 ∗ H H[he(nxce)] a∈ l aCf vcoiad escboaloakr quantization followed by lookup. [sent-247, score-0.207]
</p><p>54 In the general 2d-dimensional case, given a new point x = (xL, xR) ∈ I, the child codebooks can generate approximations )of ∈ ∈qL I(,x thLe), c cqhRil(dxR co)d respectively. [sent-248, score-0.275]
</p><p>55 Tnherisa gives rise to a point z = h(x) on the grid (8). [sent-249, score-0.181]
</p><p>56 Vector qh(uxa)n]t ∈iza Ctio vnia vsiiam a sequence of scalar quantization and lookup operations achieves unprecedented  speed as we shall see in section 6. [sent-251, score-0.252]
</p><p>57 Still, this kind of vector quantization is enough for training purposes. [sent-258, score-0.207]
</p><p>58 Exact quantization In one dimension, each leaf codebook stores the original K scalar centroids, so given a new point x ∈ I can respond it swciathla a cKen-vtreocitdosr, soof squared ndiewstan pcoiens tδ x(x ∈, c I) i=t (axn csp)2o nodf x titoh a all K Kce-nvtercotoidrs o c s∈q uCa. [sent-262, score-0.656]
</p><p>59 oIn a tlhl ec e rnectruoridsivse c case, given a new point x = (xL, xR) ∈ I, the node first requests from its child codebooks )th ∈e squared Euclidean distances δL(xL, zL), δR(xR, zR), for all zL ∈ CL and all zR ∈ CR. [sent-263, score-0.326]
</p><p>60 (10)  The idea is similar to product quantization [12] which employs only one level of decomposition. [sent-266, score-0.289]
</p><p>61 It is exact  because node centroids are not arbitrary vectors but quantized and stored as coordinates on the grid. [sent-269, score-0.497]
</p><p>62 Image indexing and retrieval Applied to nearest neighbor search or image retrieval, our approach is tuned to rather small codebooks that can however quantize subspaces of the target descriptor space. [sent-271, score-0.891]
</p><p>63 As it stands, this representation is the same with product quantization [12]. [sent-277, score-0.289]
</p><p>64 However, instead of storing quantized labels per input data, it is possible to invert the representation when n is small, actually storing input data per label. [sent-278, score-0.206]
</p><p>65 As explained in section 6, we attempt larger n where full inversion is not possible because the effective codebook size Jn becomes prohibitive. [sent-281, score-0.309]
</p><p>66 In our experiments for instance, we keep J2 cells for inverted indexing in two dimensions, and embed the labels for the remaining two dimensions along with data. [sent-284, score-0.293]
</p><p>67 Because of the extremely fine partition, multiple cells need to be looked up, in the spirit of multiple assignment [21]. [sent-290, score-0.234]
</p><p>68 That is, choose the k nearest neighbors per codebook for each query vector by the exact search (section 4. [sent-291, score-0.697]
</p><p>69 2), and then search among the kn possible neighbor cell combinations. [sent-292, score-0.267]
</p><p>70 3In the context of clustering in section 3, these are referred to as bins, while (Voronoi) cells are collections of bins, one per centroid. [sent-294, score-0.182]
</p><p>71 333000222888  One solution is the multi-sequence algorithm of [2], a simplified version of distance propagation in two dimensions, which visits cells in ascending order of distance from  the query cell. [sent-296, score-0.399]
</p><p>72 However, it needs to explicitly store state per cell and this is prohibitive for large kn, especially for image retrieval where thousands of queries are needed. [sent-297, score-0.25]
</p><p>73 This choice approximates the neighboring cells visited by the multi-sequence algorithm but avoids the kn storage and is much faster especially for large n, because neighbors are precomputed. [sent-307, score-0.192]
</p><p>74 Entries found in all neighboring cells are weighted by an asymmetric distance between uncompressed query vectors and quantized database vectors. [sent-308, score-0.287]
</p><p>75 , xn−1), each of the k-nearest neighbors zji ∈ Ci in codebook ifor j = 0, . [sent-312, score-0.428]
</p><p>76 In other words, the cell contains a list of candidate neighbors and sum (13) is used to verify whether an entry belongs to a true neighbor or not. [sent-332, score-0.23]
</p><p>77 On-line applications like nearest neighbor search and image retrieval mainly serve as validation. [sent-337, score-0.427]
</p><p>78 Codebook setup and training times for varying codebook size K. [sent-342, score-0.309]
</p><p>79 , for K = 16K, we get 214 = 16K (target codebook size) for d = 32, which is trained on a 211 211 = 2048 2048 grid, since codebooks at the previous leve×l d2 = 1 260 are ×of 2 s0i4ze8 211. [sent-346, score-0.54]
</p><p>80 Datasets and evaluation protocol  We apply our methods to specific object retrieval and evaluate on two public datasets, namely Oxford buildings [20] and Paris [21], containing 5062 and 6412 images, as well as 55 queries each. [sent-351, score-0.206]
</p><p>81 We train codebooks on both datasets and evaluate retrieval performance on the same or on different datasets. [sent-352, score-0.359]
</p><p>82 , the proportion of queries for which the nearest neighbor is ranked in the first R positions [12]. [sent-363, score-0.313]
</p><p>83 As discussed in the retrieval experiments, we choose to focus on fourth order indices, that is, we decompose the 128-dimensional SIFT descriptor space into n = 4 32-dimensional subspaces. [sent-369, score-0.22]
</p><p>84 Table 1 shows the setup of the training process for varying target codebook size K. [sent-370, score-0.309]
</p><p>85 The size Kd of each child codebook increases with the dimensionality d of the underlying subspace. [sent-371, score-0.392]
</p><p>86 It is clearly seen that the training time depends explicitly on the codebook size at d = 16, which determines the size of the grid where the root codebook is trained. [sent-372, score-0.757]
</p><p>87 Vector quantization times per point for varying codebook size, averaged over the N = 75K SIFT descriptors of the 55 cropped query images of Oxford 5K. [sent-386, score-0.608]
</p><p>88 Recall@R performance of approximate vector quantization for varying codebook size, averaged over the query images of Oxford 5K. [sent-388, score-0.681]
</p><p>89 The above reveals that the bottleneck of the algorithm is distance propagation on the grid. [sent-389, score-0.176]
</p><p>90 Our exact quantization comes at a speed that offers a practical alternative over other approximate schemes, and this is exactly what we have used to label images for indexing. [sent-400, score-0.406]
</p><p>91 118ms per point on average at the same setup for a 4K codebook using 200 checks, corresponding roughly to a precision of 98%. [sent-402, score-0.309]
</p><p>92 66 with codebooks of size up to 65K2, where behavior is not much different than a standard inverted file and training times become an obstacle. [sent-408, score-0.308]
</p><p>93 Although there is still space for experiments, we have decided to move on to the unexplored area of a fourth order index with codebook size J4. [sent-409, score-0.309]
</p><p>94 mAP performance versus k-nearest neighbors in our fourth order indexing scheme for varying codebook size on Oxford 5K, also trained on Oxford 5K. [sent-411, score-0.454]
</p><p>95 It appears that the space partition becomes so fine that mAP continues to increase for large number of neighbors k, and the only limit is the search time. [sent-414, score-0.256]
</p><p>96 Discussion We have investigated the relation between nearest neighbor search and clustering in high dimensional spaces, providing deeper insight and a new paradigm that may open new directions in numerous applications. [sent-428, score-0.438]
</p><p>97 a single recursive data structure is enough for all related problems, from codebook construction and database labeling, to indexing and search. [sent-434, score-0.46]
</p><p>98 Nearest neighbor search is another application we are currently investigating. [sent-437, score-0.181]
</p><p>99 Transform coding for fast approximate nearest neighbor search in high dimensions. [sent-457, score-0.372]
</p><p>100 Hello neighbor: Accurate object retrieval with k-reciprocal nearest neighbors. [sent-573, score-0.246]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('centroids', 0.378), ('codebook', 0.309), ('codebooks', 0.231), ('xr', 0.21), ('quantization', 0.207), ('xl', 0.168), ('zr', 0.147), ('grid', 0.139), ('oxford', 0.133), ('retrieval', 0.128), ('ck', 0.128), ('zl', 0.119), ('nearest', 0.118), ('neighbor', 0.117), ('voronoi', 0.11), ('clustering', 0.101), ('assignment', 0.099), ('propagation', 0.099), ('recursion', 0.096), ('query', 0.092), ('product', 0.082), ('cells', 0.081), ('cartesian', 0.08), ('cl', 0.079), ('queries', 0.078), ('inverted', 0.077), ('indexing', 0.076), ('recursive', 0.075), ('drc', 0.075), ('quantized', 0.074), ('approximate', 0.073), ('centroid', 0.071), ('neighbors', 0.069), ('partition', 0.069), ('ql', 0.068), ('egou', 0.067), ('subspaces', 0.064), ('sl', 0.064), ('marching', 0.064), ('search', 0.064), ('chum', 0.063), ('cr', 0.062), ('mk', 0.059), ('dimensions', 0.059), ('douze', 0.058), ('perdoch', 0.058), ('descriptor', 0.056), ('vk', 0.055), ('fine', 0.054), ('points', 0.053), ('squared', 0.051), ('drq', 0.05), ('zji', 0.05), ('zor', 0.05), ('qr', 0.049), ('storing', 0.048), ('queue', 0.048), ('sr', 0.047), ('ascending', 0.047), ('termination', 0.045), ('exact', 0.045), ('scalar', 0.045), ('respond', 0.044), ('mikulik', 0.044), ('heap', 0.044), ('cell', 0.044), ('child', 0.044), ('rise', 0.042), ('exactly', 0.042), ('kn', 0.042), ('avrithis', 0.041), ('zb', 0.041), ('dimension', 0.04), ('distance', 0.04), ('offers', 0.039), ('underlying', 0.039), ('midpoints', 0.038), ('oin', 0.038), ('envision', 0.038), ('subvectors', 0.038), ('paradigm', 0.038), ('quantize', 0.037), ('bottleneck', 0.037), ('inducing', 0.037), ('mapped', 0.036), ('remarkable', 0.036), ('interval', 0.036), ('decompose', 0.036), ('actually', 0.036), ('tree', 0.035), ('replacement', 0.035), ('topology', 0.035), ('bi', 0.035), ('sift', 0.034), ('jn', 0.034), ('qe', 0.034), ('distractor', 0.034), ('recursively', 0.034), ('variant', 0.033), ('bins', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="333-tfidf-1" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>Author: Yannis Avrithis</p><p>Abstract: Inspired by the close relation between nearest neighbor search and clustering in high-dimensional spaces as well as the success of one helping to solve the other, we introduce a new paradigm where both problems are solved simultaneously. Our solution is recursive, not in the size of input data but in the number of dimensions. One result is a clustering algorithm that is tuned to small codebooks but does not need all data in memory at the same time and is practically constant in the data size. As a by-product, a tree structure performs either exact or approximate quantization on trained centroids, the latter being not very precise but extremely fast. A lesser contribution is a new indexing scheme for image retrieval that exploits multiple small codebooks to provide an arbitrarily fine partition of the descriptor space. Large scale experiments on public datasets exhibit state of the art performance and remarkable generalization.</p><p>2 0.20303845 <a title="333-tfidf-2" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>Author: Masakazu Iwamura, Tomokazu Sato, Koichi Kise</p><p>Abstract: Approximate nearest neighbor search (ANNS) is a basic and important technique used in many tasks such as object recognition. It involves two processes: selecting nearest neighbor candidates and performing a brute-force search of these candidates. Only the former though has scope for improvement. In most existing methods, it approximates the space by quantization. It then calculates all the distances between the query and all the quantized values (e.g., clusters or bit sequences), and selects a fixed number of candidates close to the query. The performance of the method is evaluated based on accuracy as a function of the number of candidates. This evaluation seems rational but poses a serious problem; it ignores the computational cost of the process of selection. In this paper, we propose a new ANNS method that takes into account costs in the selection process. Whereas existing methods employ computationally expensive techniques such as comparative sort and heap, the proposed method does not. This realizes a significantly more efficient search. We have succeeded in reducing computation times by one-third compared with the state-of-the- art on an experiment using 100 million SIFT features.</p><p>3 0.19775257 <a title="333-tfidf-3" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>4 0.18140498 <a title="333-tfidf-4" href="./iccv-2013-Fast_Neighborhood_Graph_Search_Using_Cartesian_Concatenation.html">159 iccv-2013-Fast Neighborhood Graph Search Using Cartesian Concatenation</a></p>
<p>Author: Jing Wang, Jingdong Wang, Gang Zeng, Rui Gan, Shipeng Li, Baining Guo</p><p>Abstract: In this paper, we propose a new data structure for approximate nearest neighbor search. This structure augments the neighborhoodgraph with a bridge graph. We propose to exploit Cartesian concatenation to produce a large set of vectors, called bridge vectors, from several small sets of subvectors. Each bridge vector is connected with a few reference vectors near to it, forming a bridge graph. Our approach finds nearest neighbors by simultaneously traversing the neighborhood graph and the bridge graph in the best-first strategy. The success of our approach stems from two factors: the exact nearest neighbor search over a large number of bridge vectors can be done quickly, and the reference vectors connected to a bridge (reference) vector near the query are also likely to be near the query. Experimental results on searching over large scale datasets (SIFT, GIST andHOG) show that our approach outperforms stateof-the-art ANN search algorithms in terms of efficiency and accuracy. The combination of our approach with the IVFADC system [18] also shows superior performance over the BIGANN dataset of 1 billion SIFT features compared with the best previously published result.</p><p>5 0.16844629 <a title="333-tfidf-5" href="./iccv-2013-Semantic-Aware_Co-indexing_for_Image_Retrieval.html">378 iccv-2013-Semantic-Aware Co-indexing for Image Retrieval</a></p>
<p>Author: Shiliang Zhang, Ming Yang, Xiaoyu Wang, Yuanqing Lin, Qi Tian</p><p>Abstract: Inverted indexes in image retrieval not only allow fast access to database images but also summarize all knowledge about the database, so that their discriminative capacity largely determines the retrieval performance. In this paper, for vocabulary tree based image retrieval, we propose a semantic-aware co-indexing algorithm to jointly San Antonio, TX 78249 . j dl@gmai l com qit ian@cs .ut sa . edu . The query embed two strong cues into the inverted indexes: 1) local invariant features that are robust to delineate low-level image contents, and 2) semantic attributes from large-scale object recognition that may reveal image semantic meanings. For an initial set of inverted indexes of local features, we utilize 1000 semantic attributes to filter out isolated images and insert semantically similar images to the initial set. Encoding these two distinct cues together effectively enhances the discriminative capability of inverted indexes. Such co-indexing operations are totally off-line and introduce small computation overhead to online query cause only local features but no semantic attributes are used for query. Experiments and comparisons with recent retrieval methods on 3 datasets, i.e., UKbench, Holidays, Oxford5K, and 1.3 million images from Flickr as distractors, manifest the competitive performance of our method 1.</p><p>6 0.14890809 <a title="333-tfidf-6" href="./iccv-2013-Offline_Mobile_Instance_Retrieval_with_a_Small_Memory_Footprint.html">294 iccv-2013-Offline Mobile Instance Retrieval with a Small Memory Footprint</a></p>
<p>7 0.14677811 <a title="333-tfidf-7" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>8 0.1433053 <a title="333-tfidf-8" href="./iccv-2013-Stable_Hyper-pooling_and_Query_Expansion_for_Event_Detection.html">400 iccv-2013-Stable Hyper-pooling and Query Expansion for Event Detection</a></p>
<p>9 0.13557719 <a title="333-tfidf-9" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>10 0.10645352 <a title="333-tfidf-10" href="./iccv-2013-Neighbor-to-Neighbor_Search_for_Fast_Coding_of_Feature_Vectors.html">287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</a></p>
<p>11 0.1050637 <a title="333-tfidf-11" href="./iccv-2013-Joint_Inverted_Indexing.html">221 iccv-2013-Joint Inverted Indexing</a></p>
<p>12 0.10391226 <a title="333-tfidf-12" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>13 0.10236792 <a title="333-tfidf-13" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>14 0.099950433 <a title="333-tfidf-14" href="./iccv-2013-To_Aggregate_or_Not_to_aggregate%3A_Selective_Match_Kernels_for_Image_Search.html">419 iccv-2013-To Aggregate or Not to aggregate: Selective Match Kernels for Image Search</a></p>
<p>15 0.086134136 <a title="333-tfidf-15" href="./iccv-2013-Image_Retrieval_Using_Textual_Cues.html">210 iccv-2013-Image Retrieval Using Textual Cues</a></p>
<p>16 0.085786387 <a title="333-tfidf-16" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>17 0.085668288 <a title="333-tfidf-17" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>18 0.081808709 <a title="333-tfidf-18" href="./iccv-2013-Co-segmentation_by_Composition.html">74 iccv-2013-Co-segmentation by Composition</a></p>
<p>19 0.078967579 <a title="333-tfidf-19" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>20 0.077102214 <a title="333-tfidf-20" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.2), (1, 0.044), (2, -0.062), (3, -0.081), (4, -0.032), (5, 0.213), (6, -0.02), (7, 0.001), (8, -0.077), (9, 0.033), (10, 0.067), (11, 0.004), (12, 0.026), (13, 0.061), (14, 0.049), (15, 0.02), (16, 0.11), (17, -0.123), (18, 0.126), (19, -0.075), (20, -0.024), (21, -0.032), (22, 0.023), (23, 0.031), (24, -0.08), (25, -0.005), (26, -0.004), (27, -0.037), (28, -0.017), (29, 0.02), (30, -0.01), (31, 0.014), (32, 0.027), (33, 0.058), (34, 0.026), (35, 0.065), (36, 0.033), (37, -0.138), (38, 0.019), (39, 0.063), (40, 0.013), (41, 0.048), (42, 0.003), (43, -0.014), (44, -0.115), (45, -0.043), (46, -0.06), (47, -0.047), (48, 0.031), (49, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96323007 <a title="333-lsi-1" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>Author: Yannis Avrithis</p><p>Abstract: Inspired by the close relation between nearest neighbor search and clustering in high-dimensional spaces as well as the success of one helping to solve the other, we introduce a new paradigm where both problems are solved simultaneously. Our solution is recursive, not in the size of input data but in the number of dimensions. One result is a clustering algorithm that is tuned to small codebooks but does not need all data in memory at the same time and is practically constant in the data size. As a by-product, a tree structure performs either exact or approximate quantization on trained centroids, the latter being not very precise but extremely fast. A lesser contribution is a new indexing scheme for image retrieval that exploits multiple small codebooks to provide an arbitrarily fine partition of the descriptor space. Large scale experiments on public datasets exhibit state of the art performance and remarkable generalization.</p><p>2 0.85112613 <a title="333-lsi-2" href="./iccv-2013-Fast_Neighborhood_Graph_Search_Using_Cartesian_Concatenation.html">159 iccv-2013-Fast Neighborhood Graph Search Using Cartesian Concatenation</a></p>
<p>Author: Jing Wang, Jingdong Wang, Gang Zeng, Rui Gan, Shipeng Li, Baining Guo</p><p>Abstract: In this paper, we propose a new data structure for approximate nearest neighbor search. This structure augments the neighborhoodgraph with a bridge graph. We propose to exploit Cartesian concatenation to produce a large set of vectors, called bridge vectors, from several small sets of subvectors. Each bridge vector is connected with a few reference vectors near to it, forming a bridge graph. Our approach finds nearest neighbors by simultaneously traversing the neighborhood graph and the bridge graph in the best-first strategy. The success of our approach stems from two factors: the exact nearest neighbor search over a large number of bridge vectors can be done quickly, and the reference vectors connected to a bridge (reference) vector near the query are also likely to be near the query. Experimental results on searching over large scale datasets (SIFT, GIST andHOG) show that our approach outperforms stateof-the-art ANN search algorithms in terms of efficiency and accuracy. The combination of our approach with the IVFADC system [18] also shows superior performance over the BIGANN dataset of 1 billion SIFT features compared with the best previously published result.</p><p>3 0.83320177 <a title="333-lsi-3" href="./iccv-2013-Joint_Inverted_Indexing.html">221 iccv-2013-Joint Inverted Indexing</a></p>
<p>Author: Yan Xia, Kaiming He, Fang Wen, Jian Sun</p><p>Abstract: Inverted indexing is a popular non-exhaustive solution to large scale search. An inverted file is built by a quantizer such as k-means or a tree structure. It has been found that multiple inverted files, obtained by multiple independent random quantizers, are able to achieve practically good recall and speed. Instead of computing the multiple quantizers independently, we present a method that creates them jointly. Our method jointly optimizes all codewords in all quantizers. Then it assigns these codewords to the quantizers. In experiments this method shows significant improvement over various existing methods that use multiple independent quantizers. On the one-billion set of SIFT vectors, our method is faster and more accurate than a recent state-of-the-art inverted indexing method.</p><p>4 0.81908906 <a title="333-lsi-4" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>5 0.81766045 <a title="333-lsi-5" href="./iccv-2013-To_Aggregate_or_Not_to_aggregate%3A_Selective_Match_Kernels_for_Image_Search.html">419 iccv-2013-To Aggregate or Not to aggregate: Selective Match Kernels for Image Search</a></p>
<p>Author: Giorgos Tolias, Yannis Avrithis, Hervé Jégou</p><p>Abstract: This paper considers a family of metrics to compare images based on their local descriptors. It encompasses the VLAD descriptor and matching techniques such as Hamming Embedding. Making the bridge between these approaches leads us to propose a match kernel that takes the best of existing techniques by combining an aggregation procedure with a selective match kernel. Finally, the representation underpinning this kernel is approximated, providing a large scale image search both precise and scalable, as shown by our experiments on several benchmarks.</p><p>6 0.8117103 <a title="333-lsi-6" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>7 0.7970562 <a title="333-lsi-7" href="./iccv-2013-Offline_Mobile_Instance_Retrieval_with_a_Small_Memory_Footprint.html">294 iccv-2013-Offline Mobile Instance Retrieval with a Small Memory Footprint</a></p>
<p>8 0.75238591 <a title="333-lsi-8" href="./iccv-2013-Stable_Hyper-pooling_and_Query_Expansion_for_Event_Detection.html">400 iccv-2013-Stable Hyper-pooling and Query Expansion for Event Detection</a></p>
<p>9 0.73201191 <a title="333-lsi-9" href="./iccv-2013-Neighbor-to-Neighbor_Search_for_Fast_Coding_of_Feature_Vectors.html">287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</a></p>
<p>10 0.71617144 <a title="333-lsi-10" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>11 0.71117723 <a title="333-lsi-11" href="./iccv-2013-Semantic-Aware_Co-indexing_for_Image_Retrieval.html">378 iccv-2013-Semantic-Aware Co-indexing for Image Retrieval</a></p>
<p>12 0.69708896 <a title="333-lsi-12" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>13 0.6962657 <a title="333-lsi-13" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>14 0.68418097 <a title="333-lsi-14" href="./iccv-2013-SIFTpack%3A_A_Compact_Representation_for_Efficient_SIFT_Matching.html">365 iccv-2013-SIFTpack: A Compact Representation for Efficient SIFT Matching</a></p>
<p>15 0.58208001 <a title="333-lsi-15" href="./iccv-2013-Visual_Semantic_Complex_Network_for_Web_Images.html">446 iccv-2013-Visual Semantic Complex Network for Web Images</a></p>
<p>16 0.56393403 <a title="333-lsi-16" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>17 0.5636813 <a title="333-lsi-17" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>18 0.55938733 <a title="333-lsi-18" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<p>19 0.54321986 <a title="333-lsi-19" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>20 0.53548151 <a title="333-lsi-20" href="./iccv-2013-Discovering_Details_and_Scene_Structure_with_Hierarchical_Iconoid_Shift.html">117 iccv-2013-Discovering Details and Scene Structure with Hierarchical Iconoid Shift</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.106), (7, 0.025), (13, 0.27), (26, 0.081), (27, 0.012), (31, 0.034), (35, 0.014), (42, 0.095), (48, 0.01), (64, 0.03), (73, 0.04), (89, 0.185), (95, 0.01), (98, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88792163 <a title="333-lda-1" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>Author: Jan Stühmer, Peter Schröder, Daniel Cremers</p><p>Abstract: We propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph, in this case a geodesic shortest path tree. Specifically we make two contributions: First, we construct a geodesic shortest path tree with a distance measure that is related to the image data and the bending energy of each path in the tree. Second, we include a connectivity prior in our segmentation model, that allows to segment not only a single elongated structure, but instead a whole connected branching tree. Because both our segmentation model and the connectivity constraint are convex, a global optimal solution can be found. To this end, we generalize a recent primal-dual algorithm for continuous convex optimization to an arbitrary graph structure. To validate our method we present results on data from medical imaging in angiography and retinal blood vessel segmentation.</p><p>same-paper 2 0.84073967 <a title="333-lda-2" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>Author: Yannis Avrithis</p><p>Abstract: Inspired by the close relation between nearest neighbor search and clustering in high-dimensional spaces as well as the success of one helping to solve the other, we introduce a new paradigm where both problems are solved simultaneously. Our solution is recursive, not in the size of input data but in the number of dimensions. One result is a clustering algorithm that is tuned to small codebooks but does not need all data in memory at the same time and is practically constant in the data size. As a by-product, a tree structure performs either exact or approximate quantization on trained centroids, the latter being not very precise but extremely fast. A lesser contribution is a new indexing scheme for image retrieval that exploits multiple small codebooks to provide an arbitrarily fine partition of the descriptor space. Large scale experiments on public datasets exhibit state of the art performance and remarkable generalization.</p><p>3 0.82495624 <a title="333-lda-3" href="./iccv-2013-Estimating_the_Material_Properties_of_Fabric_from_Video.html">145 iccv-2013-Estimating the Material Properties of Fabric from Video</a></p>
<p>Author: Katherine L. Bouman, Bei Xiao, Peter Battaglia, William T. Freeman</p><p>Abstract: Passively estimating the intrinsic material properties of deformable objects moving in a natural environment is essential for scene understanding. We present a framework to automatically analyze videos of fabrics moving under various unknown wind forces, and recover two key material properties of the fabric: stiffness and area weight. We extend features previously developed to compactly represent static image textures to describe video textures, such as fabric motion. A discriminatively trained regression model is then used to predict the physical properties of fabric from these features. The success of our model is demonstrated on a new, publicly available database offabric videos with corresponding measured ground truth material properties. We show that our predictions are well correlated with ground truth measurements of stiffness and density for the fabrics. Our contributions include: (a) a database that can be used for training and testing algorithms for passively predicting fabric properties from video, (b) an algorithm for predicting the material properties of fabric from a video, and (c) a perceptual study of humans’ ability to estimate the material properties of fabric from videos and images.</p><p>4 0.79459023 <a title="333-lda-4" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>Author: Ramazan Gokberk Cinbis, Jakob Verbeek, Cordelia Schmid</p><p>Abstract: We present an object detection system based on the Fisher vector (FV) image representation computed over SIFT and color descriptors. For computational and storage efficiency, we use a recent segmentation-based method to generate class-independent object detection hypotheses, in combination with data compression techniques. Our main contribution is a method to produce tentative object segmentation masks to suppress background clutter in the features. Re-weighting the local image features based on these masks is shown to improve object detection significantly. We also exploit contextual features in the form of a full-image FV descriptor, and an inter-category rescoring mechanism. Our experiments on the PASCAL VOC 2007 and 2010 datasets show that our detector improves over the current state-of-the-art detection results.</p><p>5 0.77944213 <a title="333-lda-5" href="./iccv-2013-Monocular_Image_3D_Human_Pose_Estimation_under_Self-Occlusion.html">273 iccv-2013-Monocular Image 3D Human Pose Estimation under Self-Occlusion</a></p>
<p>Author: Ibrahim Radwan, Abhinav Dhall, Roland Goecke</p><p>Abstract: In this paper, an automatic approach for 3D pose reconstruction from a single image is proposed. The presence of human body articulation, hallucinated parts and cluttered background leads to ambiguity during the pose inference, which makes the problem non-trivial. Researchers have explored various methods based on motion and shading in order to reduce the ambiguity and reconstruct the 3D pose. The key idea of our algorithm is to impose both kinematic and orientation constraints. The former is imposed by projecting a 3D model onto the input image and pruning the parts, which are incompatible with the anthropomorphism. The latter is applied by creating synthetic views via regressing the input view to multiple oriented views. After applying the constraints, the 3D model is projected onto the initial and synthetic views, which further reduces the ambiguity. Finally, we borrow the direction of the unambiguous parts from the synthetic views to the initial one, which results in the 3D pose. Quantitative experiments are performed on the HumanEva-I dataset and qualitatively on unconstrained images from the Image Parse dataset. The results show the robustness of the proposed approach to accurately reconstruct the 3D pose form a single image.</p><p>6 0.70560378 <a title="333-lda-6" href="./iccv-2013-Shortest_Paths_with_Curvature_and_Torsion.html">389 iccv-2013-Shortest Paths with Curvature and Torsion</a></p>
<p>7 0.69559753 <a title="333-lda-7" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<p>8 0.69492304 <a title="333-lda-8" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>9 0.69375432 <a title="333-lda-9" href="./iccv-2013-Neighbor-to-Neighbor_Search_for_Fast_Coding_of_Feature_Vectors.html">287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</a></p>
<p>10 0.69343752 <a title="333-lda-10" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>11 0.68894541 <a title="333-lda-11" href="./iccv-2013-Local_Signal_Equalization_for_Correspondence_Matching.html">255 iccv-2013-Local Signal Equalization for Correspondence Matching</a></p>
<p>12 0.68811172 <a title="333-lda-12" href="./iccv-2013-Detecting_Avocados_to_Zucchinis%3A_What_Have_We_Done%2C_and_Where_Are_We_Going%3F.html">109 iccv-2013-Detecting Avocados to Zucchinis: What Have We Done, and Where Are We Going?</a></p>
<p>13 0.68619597 <a title="333-lda-13" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>14 0.68557638 <a title="333-lda-14" href="./iccv-2013-Codemaps_-_Segment%2C_Classify_and_Search_Objects_Locally.html">77 iccv-2013-Codemaps - Segment, Classify and Search Objects Locally</a></p>
<p>15 0.68522513 <a title="333-lda-15" href="./iccv-2013-NEIL%3A_Extracting_Visual_Knowledge_from_Web_Data.html">285 iccv-2013-NEIL: Extracting Visual Knowledge from Web Data</a></p>
<p>16 0.68380278 <a title="333-lda-16" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>17 0.68093187 <a title="333-lda-17" href="./iccv-2013-To_Aggregate_or_Not_to_aggregate%3A_Selective_Match_Kernels_for_Image_Search.html">419 iccv-2013-To Aggregate or Not to aggregate: Selective Match Kernels for Image Search</a></p>
<p>18 0.68031216 <a title="333-lda-18" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>19 0.67757767 <a title="333-lda-19" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>20 0.67745829 <a title="333-lda-20" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
