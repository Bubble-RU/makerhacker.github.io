<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-27" href="#">iccv2013-27</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</h1>
<br/><p>Source: <a title="iccv-2013-27-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Bartoli_A_Robust_Analytical_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Adrien Bartoli, Daniel Pizarro, Toby Collins</p><p>Abstract: We study the uncalibrated isometric Shape-fromTemplate problem, that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown. Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. This was achieved through two key steps. First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. We use a variational framework, implemented using a smooth function basis and sampled local deformation models. The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy – slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods.</p><p>Reference: <a title="iccv-2013-27-reference" href="../iccv2013_reference/iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. [sent-2, score-0.99]
</p><p>2 First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. [sent-4, score-0.28]
</p><p>3 Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. [sent-5, score-0.864]
</p><p>4 We use a variational framework, implemented using a smooth function basis and sampled local deformation models. [sent-6, score-0.203]
</p><p>5 The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. [sent-7, score-0.725]
</p><p>6 Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy  –  slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods. [sent-8, score-1.391]
</p><p>7 Introduction 3D reconstruction from a single image and a template (a known 3D view of the surface) has been researched actively over the past decade. [sent-10, score-0.158]
</p><p>8 Recovering the 3D deformation is equivalent to recovering the shape as seen in the input image. [sent-12, score-0.226]
</p><p>9 An important instance of SfT is IsoSfT, where the 3D deformation is distance-preserving, in other words, an isometry. [sent-14, score-0.17]
</p><p>10 We are here interested in C-IsoSfT, the IsoSfT problem which takes an uncalibrated image as input and includes camera calibration as an unknown. [sent-17, score-0.306]
</p><p>11 We give a general framework and a detailled solution to the most important practical case where all camera parameters are known (the principal point, aspect ratio and skew) but the focal length. [sent-18, score-0.593]
</p><p>12 For most applications of SfT, being able to estimate the focal length online is the most important case since it allows one to zoom in and out while filming the deformable surface. [sent-19, score-0.745]
</p><p>13 More specifically, we contribute with the first robust  analytical solution to recover 3D shape and the camera’s focal length. [sent-20, score-0.734]
</p><p>14 We implemented our theory using putative keypoint correspondences as inputs. [sent-21, score-0.145]
</p><p>15 Our implementation discards erroneous correspondences and is entirely analytical in that it does not involve numerical optimization. [sent-22, score-0.238]
</p><p>16 Our analytical solution is based on a variational problem formulation with general template formulation. [sent-25, score-0.38]
</p><p>17 This allows us to derive an operator which locally maps an image warp to an uncalibrated solution to 3D shape. [sent-27, score-0.272]
</p><p>18 In a second step, we robustly solve for the focal length and upgrade 3D shape globally. [sent-28, score-0.75]
</p><p>19 Both steps involve analytical solutions and are extremely fast to compute. [sent-29, score-0.245]
</p><p>20 State of the Art Existing SfT methods can be broadly classified into three categories: (C1) analytical solutions, (C2) convex optimization and (C3) nonconvex optimization. [sent-54, score-0.173]
</p><p>21 None of [2, 4] copes with mismatches, and none lends itself to camera calibration (perspective projection does not allow one to factor out the focal length, and thus to compute an uncalibrated solution). [sent-58, score-0.864]
</p><p>22 The most successful relaxation is the so-called inextensibility,  which upper bounds the Euclidean distance between a pair of points by its true geodesic distance computed from the template [8]. [sent-62, score-0.155]
</p><p>23 Methods in (C3) estimate a quasi-isometric deformation, which is a nonconvex constraint, while minimizing the reprojection error [3]. [sent-68, score-0.231]
</p><p>24 Finally, a recent paper has also shown that the focal length could be calibrated in SfT [1]. [sent-70, score-0.737]
</p><p>25 The key idea is to sample a set of admissible focal lengths, solve SfT for each of them and keep the one minimizing some consistency measure. [sent-71, score-0.501]
</p><p>26 This is achieved by first solving the problem locally to get an initial uncalibrated shape and then estimating the focal length. [sent-73, score-0.749]
</p><p>27 Each formulation has a data constraint called the reprojection constraint and a prior called the deformation constraint. [sent-78, score-0.448]
</p><p>28 Modeling and 3D Formulation In the SfT problem, one has a 3D shape template R ⊂ R3 wnh tihceh S may rboeb represented as a parametric msuprlfaatcee Rwi t⊂h an embedding ζ ∈ C2 (Ω, R3) from a parameterization space bΩe d⊂i Rg2 ζ. [sent-85, score-0.267]
</p><p>29 ∈Giv Cen one image of the deformed 3D shape SΩ, ⊂the Runknowns are (i) the 3D deformation Ψ ∈ Csh2a p(Re, SR,3 )th etha utn brings Rs a rtoe S (i,) a tnhde ( 3iiD) th deef camera projection( Rfu,nRctio)n th hΠat ∈ b rPin. [sent-86, score-0.351]
</p><p>30 Oeruar practical solution estimates solely the focal length which is the most important intrinsic of the pinhole camera. [sent-89, score-0.759]
</p><p>31 We  model them as an image warp η ∈ C2 (Ω, R2), though they may eall tsohe e bme represented by keypoint matches [9]. [sent-92, score-0.157]
</p><p>32 The reprojection constraint (1) is obvious by construction (see figure 1). [sent-96, score-0.187]
</p><p>33 The deformation constraint (2) means that the Jacobian matrix of Ψ in the tangent plane at any point of R has to be a columntohrteh toannogremntal mlaantreix a. [sent-97, score-0.252]
</p><p>34 t Tanhyis mouinstt ohfo lRd f hoars sΨ t oto b represent an isometric deformation of R. [sent-98, score-0.306]
</p><p>35 The template shape may have an arbitrary topology and parameterization. [sent-109, score-0.184]
</p><p>36 Tη = ϕ = Π ◦T ζ ϕ ( rde pfro rjmeact io n ) ( 45) We observe that the result does not depend on the actual template’s embedding but on its metric tensor only. [sent-112, score-0.21]
</p><p>37 The reprojection constraint (4) is obtained by substituting the definition (3) of ϕ in the reprojection constraint (1). [sent-114, score-0.374]
</p><p>38 The deformation constraint (5) is obtained by differentiating the definition (3) of ϕ, giving ∇ϕ = (∇Ψ ◦ ζ)∇ζ, and multiplying it by its transpose to  ∇η adj (T ζ)∇η? [sent-115, score-0.404]
</p><p>39 ,  where adj is the adjugate matrix (the transpose of the cofactor matrix, adj (A) = det(A)A−1). [sent-125, score-0.282]
</p><p>40 The reprojection constraints (4) and (6) are just the same. [sent-127, score-0.138]
</p><p>41 As for the deformation constraint (7), we invoke Cholesky decomposition of the metric  =def  tensor T ζ. [sent-128, score-0.259]
</p><p>42 996633  We differentiate the reprojection constraint (6) and multiply it to the right by Γ−1 : ∇η Γ−1  = (∇Π  ◦  ϕ)∇ϕΓ−1. [sent-140, score-0.225]
</p><p>43 We then multiply each side of the equation by its transpose to the right, yielding: (∇Π +(∇Π  ◦  ◦  ϕ)(∇Π  ◦  ϕ)? [sent-144, score-0.171]
</p><p>44 This idse tt(heT general equation of C-IsoSfT w atith e general template parameterization. [sent-151, score-0.198]
</p><p>45 Local Uncalibrated Solution We now derive a practical solution to uncalibrated reconstruction which can be computed locally. [sent-153, score-0.26]
</p><p>46 We use a pinhole  camera with unknown focal length f ∈ R+. [sent-154, score-0.775]
</p><p>47 Our method first solves for α as an uncalibrated solution to C-IsoSfT, then calibrates f, and finally returns ϕ. [sent-168, score-0.23]
</p><p>48 It allows us to solve for ϕX = ηαx and ϕY = ηαy while the deformation constraint (7) allows us to  =def  solve for α. [sent-174, score-0.219]
</p><p>49 (8)  Theorem 1 Equation (8) has a unique solution for α and at most two solutions for ν, each of them corresponding to a solution for the normal ξ, given by: α  =  ν±  =  ξ±  =  ? [sent-178, score-0.161]
</p><p>50 We will use the normal as a clue to avoid local degeneracies when estimating the focal length. [sent-198, score-0.588]
</p><p>51 (u v) and the deformation (coRnust)ra×in(tR R(2v)) )t o= fi dnealti(zRe )thRe de(riuva×tiovn). [sent-220, score-0.17]
</p><p>52 Focal Length Calibration Our main result in this section is to compute the focal length analytically from the uncalibrated solution α. [sent-262, score-0.949]
</p><p>53 Basic Equations Starting from the point-tangent formulation (proposition 2), we use the reprojection constraint (4) to establish:  ϕ =α1? [sent-265, score-0.229]
</p><p>54 ation in the deformation constraint (5) then leads to:  f2T α−=α ? [sent-283, score-0.219]
</p><p>55 4 l2e we nodb t∇aαin the following analytical ∇soαluTtio αn∇ foαr f:=  5. [sent-298, score-0.139]
</p><p>56 (15)  Criterion (14) is derived from the isometric deformation constraint. [sent-311, score-0.306]
</p><p>57 It expresses the fact that at every point, the length of an infinitesimal step in any direction is preserved. [sent-312, score-0.222]
</p><p>58 To be more general, we can prove that it preserves the length of every 2D curve lying on the template shape. [sent-313, score-0.321]
</p><p>59 This is easily shown using the definition (3) of deformation constraint (2): ? [sent-322, score-0.219]
</p><p>60 Degenerate cases arise when the focal length cannot be estimated uniquely from the data. [sent-332, score-0.694]
</p><p>61 αT =his 0 was a kisn otow sna degenerate case in plane-based camera calibration [11]. [sent-337, score-0.192]
</p><p>62 be greater than some minimal angle r ∈ R+ for a point to stably contribute to focal length negstliem ra t∈ioRn . [sent-340, score-0.694]
</p><p>63 r oAmt l 5o%cal t osc 5a0le% sh, the support region Ω¯k,h ⊂ Ω is circular with diameter s and centred on the template keypoint qk. [sent-391, score-0.195]
</p><p>64 aTrh we iltohca dil ascmaelete trrsa d aensdoff stability and deformation complexity: larger scale improves stability but increase sensitivity to high-frequency surface deformation. [sent-392, score-0.261]
</p><p>65 We estimate the PWP scale factor ak,h and a focal length estimate fk,h for every warp in the pool. [sent-399, score-0.788]
</p><p>66 This is obtained by fitting a TPS to= an ∇esαtimate of) αk,h at each keypoint in Ω¯k,h computed using the equation directly above. [sent-406, score-0.137]
</p><p>67 We have a large number of candidate focal length estimates. [sent-425, score-0.694]
</p><p>68 ρg  We typically use 1% of the image size for g, and solve the problem by sampling focal length estimates. [sent-431, score-0.694]
</p><p>69 For every putative feature match k, we select the largest local scale sh whose local focal length estimate fk,h agrees with the robust estimate by testing ρg fk,h). [sent-440, score-0.877]
</p><p>70 Compared Methods and Measured Errors We compared 7 methods built on 3 base methods from the 3 categories outlined in §2: (C1) PWP (our proposed analytical tfergaomrieewso orukt)l,i n(Ced2) in nS §L2Z: ((Ca convex method [10]) and (C3) REF (iterative nonlinear refinement [3]). [sent-445, score-0.165]
</p><p>71 For a method, the leading letter may be U or C: U means that the focal length is estimated by our method or refined and C means that the true focal length (for simulated data) or the focal obtained by static calibration (for real data) is used. [sent-446, score-1.999]
</p><p>72 ×  We measured the average depth error in mm and the relative focal length error in %. [sent-448, score-0.793]
</p><p>73 The default parameters were a focal length of 800 pixels, an image noise of 1. [sent-452, score-0.694]
</p><p>74 We observe in the first column of graphs that the focal length error is always below 10% for the proposed analytical solution U-PWP. [sent-456, score-0.904]
</p><p>75 It has a minimum for a focal length of around 600 pixels. [sent-458, score-0.694]
</p><p>76 explained by the fact that for short focal lengths the PWP approximation tends to be less accurate, while large focal lengths tend to be ill-constrained since they cancel perspective. [sent-551, score-1.058]
</p><p>77 Shape and focal length refinement by U-REF-SHAPE-F always improve on the results of U-PWP. [sent-552, score-0.72]
</p><p>78 Moreover, it minimizes the reprojection error, which is physically meaningful. [sent-555, score-0.138]
</p><p>79 We observe that the depth error of uncalibrated methods  increases with the focal length while the error of calibrated methods is approximately steady or decreases. [sent-556, score-1.028]
</p><p>80 All methods are sensitive to the focal length accuracy. [sent-558, score-0.694]
</p><p>81 The first one is U-PWP, U-SLZ and U-REF-SHAPE, which use the focal length estimated by U-PWP. [sent-560, score-0.694]
</p><p>82 They are outperformed by UREF-SHAPE-F which refines this focal length estimate, and forms the second group. [sent-561, score-0.694]
</p><p>83 We detected 2923 SIFT keypoints in the template and 9472 in the input image, from which we obtained 2923 putative matches, filtered down to 617 after spatial consistency was enforced. [sent-571, score-0.237]
</p><p>84 For the input image, the groundtruth focal length was 2727. [sent-572, score-0.765]
</p><p>85 The histogram of local focal length estimates is shown in figure 3. [sent-574, score-0.694]
</p><p>86 The focal length we estimated with U-PWP is 2668. [sent-575, score-0.694]
</p><p>87 Once the focal length was robustly estimated we took the number of matches down to 612 by checking that their focal length es-  timate was correct at one scale at least. [sent-581, score-1.482]
</p><p>88 We observe that the isolated matches which were kept have a large local scale, while matches in dense keypoint areas may have a smaller scale, especially if the deformation is important. [sent-583, score-0.333]
</p><p>89 FfTro uemcalfUleo-ncPalWgtlPehn gth5%(in%oftemplatesize)50%  Histogram of local focal length estimates  Selected local feature scales  Figure 3. [sent-592, score-0.694]
</p><p>90 The groundtruth shape and constant focal length were provided. [sent-597, score-0.821]
</p><p>91 We observe that for U-PWP the focal length error is generally below 10%, while for U-REF-SHAPE-F it is generally  below 5%. [sent-598, score-0.727]
</p><p>92 U-REF-SHAPE-F is the best performing of the uncalibrated methods, reaching almost the same accuracy as the calibrated methods, except at those frames where the pose is degenerate. [sent-606, score-0.235]
</p><p>93 996677  Groundtruth Proposed analytical solution (U-PWP) Color-coded depth er or in Ω0 12 0 m mmmmm Figure 4. [sent-607, score-0.21]
</p><p>94 Ω  60 groundtruth U-PWP 90 groundtruth U-PWP Figure 5. [sent-610, score-0.142]
</p><p>95 Conclusion We have proposed the first method which solves the Isometric Shape-from-Template problem analytically while recovering the camera’s focal length. [sent-613, score-0.526]
</p><p>96 Our experimental results show that the method gives sensible estimates: the focal length error was less than 10% in most cases. [sent-615, score-0.727]
</p><p>97 We showed that using the true focal length with our PWP model leads to a depth error comparable to state of the art algorithms, including nonlinear refinement ofthe reprojection error (we recall that the proposed method does not use numerical optimization). [sent-616, score-1.032]
</p><p>98 The focal length estimate is sensitive to noise in near degenerate configurations. [sent-617, score-0.798]
</p><p>99 Template-based isometric deformable 3D reconstruction with sampling-based focal length self-calibration. [sent-627, score-0.86]
</p><p>100 On template-based reconstruction from a single view: Analytical solutions and proofs of well-posedness for developable, isometric and conformal surfaces. [sent-634, score-0.21]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('focal', 0.501), ('def', 0.34), ('sft', 0.265), ('pwp', 0.253), ('length', 0.193), ('uncalibrated', 0.192), ('deformation', 0.17), ('analytical', 0.139), ('reprojection', 0.138), ('isosft', 0.138), ('isometric', 0.136), ('template', 0.128), ('adj', 0.122), ('det', 0.114), ('qk', 0.107), ('proposition', 0.092), ('degenerate', 0.078), ('putative', 0.078), ('wp', 0.077), ('groundtruth', 0.071), ('equation', 0.07), ('bartoli', 0.068), ('keypoint', 0.067), ('lemma', 0.064), ('calibration', 0.06), ('fp', 0.06), ('projection', 0.057), ('cushion', 0.057), ('shape', 0.056), ('camera', 0.054), ('arrive', 0.054), ('jacobian', 0.053), ('piecewise', 0.053), ('simulated', 0.05), ('constraint', 0.049), ('proof', 0.049), ('warps', 0.049), ('matches', 0.048), ('mismatches', 0.047), ('deef', 0.046), ('degeneracies', 0.046), ('inextensible', 0.046), ('nscales', 0.046), ('pfro', 0.046), ('rjmeact', 0.046), ('timate', 0.046), ('numerical', 0.045), ('solutions', 0.044), ('embedding', 0.044), ('calibrated', 0.043), ('warp', 0.042), ('formulation', 0.042), ('normal', 0.041), ('perriollat', 0.041), ('cvlab', 0.041), ('tensor', 0.04), ('parameterization', 0.039), ('solution', 0.038), ('multiply', 0.038), ('transpose', 0.038), ('formulations', 0.038), ('developable', 0.038), ('eca', 0.038), ('latin', 0.038), ('extremely', 0.037), ('monocular', 0.037), ('lk', 0.036), ('nonconvex', 0.034), ('rde', 0.034), ('tps', 0.034), ('depth', 0.033), ('variational', 0.033), ('error', 0.033), ('surface', 0.033), ('tangent', 0.033), ('pizarro', 0.033), ('pk', 0.032), ('degeneracy', 0.031), ('instantiate', 0.031), ('keypoints', 0.031), ('reconstruction', 0.03), ('art', 0.03), ('stability', 0.029), ('erroneous', 0.029), ('singular', 0.029), ('infinitesimal', 0.029), ('oinn', 0.028), ('lengths', 0.028), ('pinhole', 0.027), ('relaxation', 0.027), ('match', 0.027), ('refinement', 0.026), ('sh', 0.026), ('estimate', 0.026), ('deformed', 0.025), ('analytically', 0.025), ('involve', 0.025), ('giving', 0.025), ('side', 0.025), ('zoom', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000011 <a title="27-tfidf-1" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>Author: Adrien Bartoli, Daniel Pizarro, Toby Collins</p><p>Abstract: We study the uncalibrated isometric Shape-fromTemplate problem, that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown. Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. This was achieved through two key steps. First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. We use a variational framework, implemented using a smooth function basis and sampled local deformation models. The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy – slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods.</p><p>2 0.31175774 <a title="27-tfidf-2" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>3 0.18175904 <a title="27-tfidf-3" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>4 0.13546814 <a title="27-tfidf-4" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>5 0.12243074 <a title="27-tfidf-5" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>6 0.10613351 <a title="27-tfidf-6" href="./iccv-2013-A_Generic_Deformation_Model_for_Dense_Non-rigid_Surface_Registration%3A_A_Higher-Order_MRF-Based_Approach.html">16 iccv-2013-A Generic Deformation Model for Dense Non-rigid Surface Registration: A Higher-Order MRF-Based Approach</a></p>
<p>7 0.095387816 <a title="27-tfidf-7" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>8 0.090111159 <a title="27-tfidf-8" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>9 0.090051807 <a title="27-tfidf-9" href="./iccv-2013-Text_Localization_in_Natural_Images_Using_Stroke_Feature_Transform_and_Text_Covariance_Descriptors.html">415 iccv-2013-Text Localization in Natural Images Using Stroke Feature Transform and Text Covariance Descriptors</a></p>
<p>10 0.087700225 <a title="27-tfidf-10" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>11 0.07954479 <a title="27-tfidf-11" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>12 0.07708668 <a title="27-tfidf-12" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>13 0.074900858 <a title="27-tfidf-13" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>14 0.074406408 <a title="27-tfidf-14" href="./iccv-2013-Refractive_Structure-from-Motion_on_Underwater_Images.html">348 iccv-2013-Refractive Structure-from-Motion on Underwater Images</a></p>
<p>15 0.07312689 <a title="27-tfidf-15" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>16 0.070957214 <a title="27-tfidf-16" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>17 0.069864646 <a title="27-tfidf-17" href="./iccv-2013-Discriminatively_Trained_Templates_for_3D_Object_Detection%3A_A_Real_Time_Scalable_Approach.html">121 iccv-2013-Discriminatively Trained Templates for 3D Object Detection: A Real Time Scalable Approach</a></p>
<p>18 0.069455251 <a title="27-tfidf-18" href="./iccv-2013-Real-World_Normal_Map_Capture_for_Nearly_Flat_Reflective_Surfaces.html">343 iccv-2013-Real-World Normal Map Capture for Nearly Flat Reflective Surfaces</a></p>
<p>19 0.068306118 <a title="27-tfidf-19" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>20 0.066641748 <a title="27-tfidf-20" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, -0.123), (2, -0.06), (3, 0.007), (4, -0.04), (5, 0.023), (6, 0.038), (7, -0.061), (8, 0.021), (9, -0.014), (10, 0.009), (11, 0.001), (12, -0.079), (13, 0.017), (14, 0.089), (15, 0.079), (16, 0.112), (17, 0.149), (18, 0.013), (19, -0.028), (20, 0.091), (21, -0.031), (22, -0.063), (23, -0.002), (24, -0.037), (25, -0.016), (26, 0.056), (27, 0.045), (28, -0.124), (29, 0.004), (30, -0.056), (31, 0.02), (32, -0.019), (33, 0.016), (34, -0.025), (35, -0.093), (36, -0.078), (37, -0.077), (38, 0.011), (39, 0.063), (40, 0.027), (41, -0.025), (42, 0.081), (43, -0.042), (44, -0.026), (45, 0.004), (46, 0.113), (47, -0.054), (48, 0.057), (49, -0.107)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95779067 <a title="27-lsi-1" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>Author: Adrien Bartoli, Daniel Pizarro, Toby Collins</p><p>Abstract: We study the uncalibrated isometric Shape-fromTemplate problem, that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown. Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. This was achieved through two key steps. First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. We use a variational framework, implemented using a smooth function basis and sampled local deformation models. The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy – slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods.</p><p>2 0.83538836 <a title="27-lsi-2" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>3 0.82615423 <a title="27-lsi-3" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>4 0.78901589 <a title="27-lsi-4" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>Author: Yinqiang Zheng, Yubin Kuang, Shigeki Sugimoto, Kalle Åström, Masatoshi Okutomi</p><p>Abstract: In this paper, we revisit the classical perspective-n-point (PnP) problem, and propose the first non-iterative O(n) solution that is fast, generally applicable and globally optimal. Our basic idea is to formulate the PnP problem into a functional minimization problem and retrieve all its stationary points by using the Gr¨ obner basis technique. The novelty lies in a non-unit quaternion representation to parameterize the rotation and a simple but elegant formulation of the PnP problem into an unconstrained optimization problem. Interestingly, the polynomial system arising from its first-order optimality condition assumes two-fold symmetry, a nice property that can be utilized to improve speed and numerical stability of a Gr¨ obner basis solver. Experiment results have demonstrated that, in terms of accuracy, our proposed solution is definitely better than the state-ofthe-art O(n) methods, and even comparable with the reprojection error minimization method.</p><p>5 0.71484482 <a title="27-lsi-5" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>Author: R. Melo, M. Antunes, J.P. Barreto, G. Falcão, N. Gonçalves</p><p>Abstract: Estimating the amount and center ofdistortionfrom lines in the scene has been addressed in the literature by the socalled “plumb-line ” approach. In this paper we propose a new geometric method to estimate not only the distortion parameters but the entire camera calibration (up to an “angular” scale factor) using a minimum of 3 lines. We propose a new framework for the unsupervised simultaneous detection of natural image of lines and camera parameters estimation, enabling a robust calibration from a single image. Comparative experiments with existing automatic approaches for the distortion estimation and with ground truth data are presented.</p><p>6 0.64034736 <a title="27-lsi-6" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>7 0.62815303 <a title="27-lsi-7" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>8 0.62287742 <a title="27-lsi-8" href="./iccv-2013-Extrinsic_Camera_Calibration_without_a_Direct_View_Using_Spherical_Mirror.html">152 iccv-2013-Extrinsic Camera Calibration without a Direct View Using Spherical Mirror</a></p>
<p>9 0.59658569 <a title="27-lsi-9" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>10 0.58414739 <a title="27-lsi-10" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>11 0.56110233 <a title="27-lsi-11" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>12 0.55911708 <a title="27-lsi-12" href="./iccv-2013-Refractive_Structure-from-Motion_on_Underwater_Images.html">348 iccv-2013-Refractive Structure-from-Motion on Underwater Images</a></p>
<p>13 0.5522486 <a title="27-lsi-13" href="./iccv-2013-Rectangling_Stereographic_Projection_for_Wide-Angle_Image_Visualization.html">346 iccv-2013-Rectangling Stereographic Projection for Wide-Angle Image Visualization</a></p>
<p>14 0.54981971 <a title="27-lsi-14" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>15 0.53535187 <a title="27-lsi-15" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>16 0.52575123 <a title="27-lsi-16" href="./iccv-2013-A_Generic_Deformation_Model_for_Dense_Non-rigid_Surface_Registration%3A_A_Higher-Order_MRF-Based_Approach.html">16 iccv-2013-A Generic Deformation Model for Dense Non-rigid Surface Registration: A Higher-Order MRF-Based Approach</a></p>
<p>17 0.51564372 <a title="27-lsi-17" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>18 0.51107168 <a title="27-lsi-18" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>19 0.51023567 <a title="27-lsi-19" href="./iccv-2013-Geometric_Registration_Based_on_Distortion_Estimation.html">183 iccv-2013-Geometric Registration Based on Distortion Estimation</a></p>
<p>20 0.48968375 <a title="27-lsi-20" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.033), (6, 0.016), (7, 0.098), (26, 0.051), (27, 0.029), (31, 0.036), (34, 0.011), (40, 0.015), (42, 0.108), (48, 0.011), (64, 0.03), (71, 0.205), (73, 0.085), (89, 0.154), (95, 0.012), (98, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81380284 <a title="27-lda-1" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>Author: Adrien Bartoli, Daniel Pizarro, Toby Collins</p><p>Abstract: We study the uncalibrated isometric Shape-fromTemplate problem, that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown. Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. This was achieved through two key steps. First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. We use a variational framework, implemented using a smooth function basis and sampled local deformation models. The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy – slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods.</p><p>2 0.73459828 <a title="27-lda-2" href="./iccv-2013-Minimal_Basis_Facility_Location_for_Subspace_Segmentation.html">264 iccv-2013-Minimal Basis Facility Location for Subspace Segmentation</a></p>
<p>Author: Choon-Meng Lee, Loong-Fah Cheong</p><p>Abstract: In contrast to the current motion segmentation paradigm that assumes independence between the motion subspaces, we approach the motion segmentation problem by seeking the parsimonious basis set that can represent the data. Our formulation explicitly looks for the overlap between subspaces in order to achieve a minimal basis representation. This parsimonious basis set is important for the performance of our model selection scheme because the sharing of basis results in savings of model complexity cost. We propose the use of affinity propagation based method to determine the number of motion. The key lies in the incorporation of a global cost model into the factor graph, serving the role of model complexity. The introduction of this global cost model requires additional message update in the factor graph. We derive an efficient update for the new messages associated with this global cost model. An important step in the use of affinity propagation is the subspace hypotheses generation. We use the row-sparse convex proxy solution as an initialization strategy. We further encourage the selection of subspace hypotheses with shared basis by integrat- ing a discount scheme that lowers the factor graph facility cost based on shared basis. We verified the model selection and classification performance of our proposed method on both the original Hopkins 155 dataset and the more balanced Hopkins 380 dataset.</p><p>3 0.72110981 <a title="27-lda-3" href="./iccv-2013-Translating_Video_Content_to_Natural_Language_Descriptions.html">428 iccv-2013-Translating Video Content to Natural Language Descriptions</a></p>
<p>Author: Marcus Rohrbach, Wei Qiu, Ivan Titov, Stefan Thater, Manfred Pinkal, Bernt Schiele</p><p>Abstract: Humans use rich natural language to describe and communicate visual perceptions. In order to provide natural language descriptions for visual content, this paper combines two important ingredients. First, we generate a rich semantic representation of the visual content including e.g. object and activity labels. To predict the semantic representation we learn a CRF to model the relationships between different components of the visual input. And second, we propose to formulate the generation of natural language as a machine translation problem using the semantic representation as source language and the generated sentences as target language. For this we exploit the power of a parallel corpus of videos and textual descriptions and adapt statistical machine translation to translate between our two languages. We evaluate our video descriptions on the TACoS dataset [23], which contains video snippets aligned with sentence descriptions. Using automatic evaluation and human judgments we show significant improvements over several baseline approaches, motivated by prior work. Our translation approach also shows improvements over related work on an image description task.</p><p>4 0.716214 <a title="27-lda-4" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>5 0.7098701 <a title="27-lda-5" href="./iccv-2013-From_Semi-supervised_to_Transfer_Counting_of_Crowds.html">178 iccv-2013-From Semi-supervised to Transfer Counting of Crowds</a></p>
<p>Author: Chen Change Loy, Shaogang Gong, Tao Xiang</p><p>Abstract: Regression-based techniques have shown promising results for people counting in crowded scenes. However, most existing techniques require expensive and laborious data annotation for model training. In this study, we propose to address this problem from three perspectives: (1) Instead of exhaustively annotating every single frame, the most informative frames are selected for annotation automatically and actively. (2) Rather than learning from only labelled data, the abundant unlabelled data are exploited. (3) Labelled data from other scenes are employed to further alleviate the burden for data annotation. All three ideas are implemented in a unified active and semi-supervised regression framework with ability to perform transfer learning, by exploiting the underlying geometric structure of crowd patterns via manifold analysis. Extensive experiments validate the effectiveness of our approach.</p><p>6 0.70925719 <a title="27-lda-6" href="./iccv-2013-Image_Set_Classification_Using_Holistic_Multiple_Order_Statistics_Features_and_Localized_Multi-kernel_Metric_Learning.html">212 iccv-2013-Image Set Classification Using Holistic Multiple Order Statistics Features and Localized Multi-kernel Metric Learning</a></p>
<p>7 0.70631444 <a title="27-lda-7" href="./iccv-2013-Text_Localization_in_Natural_Images_Using_Stroke_Feature_Transform_and_Text_Covariance_Descriptors.html">415 iccv-2013-Text Localization in Natural Images Using Stroke Feature Transform and Text Covariance Descriptors</a></p>
<p>8 0.70608646 <a title="27-lda-8" href="./iccv-2013-No_Matter_Where_You_Are%3A_Flexible_Graph-Guided_Multi-task_Learning_for_Multi-view_Head_Pose_Classification_under_Target_Motion.html">291 iccv-2013-No Matter Where You Are: Flexible Graph-Guided Multi-task Learning for Multi-view Head Pose Classification under Target Motion</a></p>
<p>9 0.70031631 <a title="27-lda-9" href="./iccv-2013-Active_Learning_of_an_Action_Detector_from_Untrimmed_Videos.html">41 iccv-2013-Active Learning of an Action Detector from Untrimmed Videos</a></p>
<p>10 0.6996842 <a title="27-lda-10" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>11 0.69175833 <a title="27-lda-11" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>12 0.68872565 <a title="27-lda-12" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>13 0.68574923 <a title="27-lda-13" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>14 0.68480182 <a title="27-lda-14" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>15 0.68257648 <a title="27-lda-15" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>16 0.68081337 <a title="27-lda-16" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>17 0.6782918 <a title="27-lda-17" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>18 0.67792135 <a title="27-lda-18" href="./iccv-2013-Spoken_Attributes%3A_Mixing_Binary_and_Relative_Attributes_to_Say_the_Right_Thing.html">399 iccv-2013-Spoken Attributes: Mixing Binary and Relative Attributes to Say the Right Thing</a></p>
<p>19 0.67653477 <a title="27-lda-19" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>20 0.67593622 <a title="27-lda-20" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
