<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-168" href="#">iccv2013-168</a> knowledge-graph by maker-knowledge-mining</p><h1>168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</h1>
<br/><p>Source: <a title="iccv-2013-168-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Pang_Finding_the_Best_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yu Pang, Haibin Ling</p><p>Abstract: Evaluating visual tracking algorithms, or “trackers ” for short, is of great importance in computer vision. However, it is hard to “fairly” compare trackers due to many parameters need to be tuned in the experimental configurations. On the other hand, when introducing a new tracker, a recent trend is to validate it by comparing it with several existing ones. Such an evaluation may have subjective biases towards the new tracker which typically performs the best. This is mainly due to the difficulty to optimally tune all its competitors and sometimes the selected testing sequences. By contrast, little subjective bias exists towards the “second best” ones1 in the contest. This observation inspires us with a novel perspective towards inhibiting subjective bias in evaluating trackers by analyzing the results between the second bests. In particular, we first collect all tracking papers published in major computer vision venues in recent years. From these papers, after filtering out potential biases in various aspects, we create a dataset containing many records of comparison results between various visual trackers. Using these records, we derive performance rank- ings of the involved trackers by four different methods. The first two methods model the dataset as a graph and then derive the rankings over the graph, one by a rank aggregation algorithm and the other by a PageRank-like solution. The other two methods take the records as generated from sports contests and adopt widely used Elo’s and Glicko ’s rating systems to derive the rankings. The experimental results are presented and may serve as a reference for related research.</p><p>Reference: <a title="iccv-2013-168-reference" href="../iccv2013_reference/iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('track', 0.562), ('contest', 0.373), ('glicko', 0.253), ('record', 0.249), ('rank', 0.248), ('elo', 0.19), ('bias', 0.138), ('eid', 0.103), ('mock', 0.101), ('sport', 0.098), ('unbias', 0.097), ('sij', 0.088), ('pam', 0.078), ('aggreg', 0.074), ('scor', 0.074), ('outcom', 0.071), ('kwon', 0.069), ('dick', 0.067), ('wij', 0.066), ('rat', 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000002 <a title="168-tfidf-1" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>2 0.33803722 <a title="168-tfidf-2" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>3 0.3158021 <a title="168-tfidf-3" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>4 0.30850297 <a title="168-tfidf-4" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>5 0.30067545 <a title="168-tfidf-5" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>6 0.27542573 <a title="168-tfidf-6" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>7 0.2751984 <a title="168-tfidf-7" href="./iccv-2013-Tracking_Revisited_Using_RGBD_Camera%3A_Unified_Benchmark_and_Baselines.html">424 iccv-2013-Tracking Revisited Using RGBD Camera: Unified Benchmark and Baselines</a></p>
<p>8 0.26891151 <a title="168-tfidf-8" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>9 0.24115288 <a title="168-tfidf-9" href="./iccv-2013-Initialization-Insensitive_Visual_Tracking_through_Voting_with_Salient_Local_Features.html">217 iccv-2013-Initialization-Insensitive Visual Tracking through Voting with Salient Local Features</a></p>
<p>10 0.23891896 <a title="168-tfidf-10" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>11 0.23541993 <a title="168-tfidf-11" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>12 0.22980948 <a title="168-tfidf-12" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>13 0.22898361 <a title="168-tfidf-13" href="./iccv-2013-Learning_People_Detectors_for_Tracking_in_Crowded_Scenes.html">242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</a></p>
<p>14 0.22303596 <a title="168-tfidf-14" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<p>15 0.21102157 <a title="168-tfidf-15" href="./iccv-2013-Network_Principles_for_SfM%3A_Disambiguating_Repeated_Structures_with_Local_Context.html">289 iccv-2013-Network Principles for SfM: Disambiguating Repeated Structures with Local Context</a></p>
<p>16 0.18875766 <a title="168-tfidf-16" href="./iccv-2013-Real-Time_Body_Tracking_with_One_Depth_Camera_and_Inertial_Sensors.html">341 iccv-2013-Real-Time Body Tracking with One Depth Camera and Inertial Sensors</a></p>
<p>17 0.16927779 <a title="168-tfidf-17" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>18 0.16561122 <a title="168-tfidf-18" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>19 0.15177982 <a title="168-tfidf-19" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>20 0.14024703 <a title="168-tfidf-20" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.25), (1, 0.038), (2, 0.152), (3, -0.201), (4, -0.053), (5, -0.223), (6, -0.341), (7, 0.066), (8, -0.115), (9, 0.093), (10, 0.002), (11, 0.072), (12, -0.083), (13, 0.051), (14, -0.027), (15, 0.035), (16, 0.083), (17, -0.021), (18, 0.071), (19, -0.062), (20, 0.016), (21, 0.004), (22, -0.034), (23, 0.088), (24, 0.034), (25, -0.025), (26, -0.018), (27, 0.018), (28, 0.065), (29, -0.011), (30, 0.029), (31, -0.017), (32, -0.008), (33, 0.042), (34, -0.002), (35, 0.025), (36, 0.03), (37, 0.044), (38, 0.026), (39, -0.032), (40, 0.024), (41, -0.002), (42, -0.04), (43, 0.005), (44, 0.042), (45, -0.014), (46, -0.01), (47, -0.004), (48, 0.076), (49, -0.04)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99389291 <a title="168-lsi-1" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>2 0.91810179 <a title="168-lsi-2" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>3 0.91636276 <a title="168-lsi-3" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>4 0.90065277 <a title="168-lsi-4" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>5 0.87159032 <a title="168-lsi-5" href="./iccv-2013-Network_Principles_for_SfM%3A_Disambiguating_Repeated_Structures_with_Local_Context.html">289 iccv-2013-Network Principles for SfM: Disambiguating Repeated Structures with Local Context</a></p>
<p>6 0.86113209 <a title="168-lsi-6" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>7 0.85963535 <a title="168-lsi-7" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>8 0.78565419 <a title="168-lsi-8" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>9 0.78105497 <a title="168-lsi-9" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>10 0.77762377 <a title="168-lsi-10" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>11 0.77698541 <a title="168-lsi-11" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>12 0.74988264 <a title="168-lsi-12" href="./iccv-2013-Initialization-Insensitive_Visual_Tracking_through_Voting_with_Salient_Local_Features.html">217 iccv-2013-Initialization-Insensitive Visual Tracking through Voting with Salient Local Features</a></p>
<p>13 0.74950862 <a title="168-lsi-13" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<p>14 0.74134815 <a title="168-lsi-14" href="./iccv-2013-Tracking_Revisited_Using_RGBD_Camera%3A_Unified_Benchmark_and_Baselines.html">424 iccv-2013-Tracking Revisited Using RGBD Camera: Unified Benchmark and Baselines</a></p>
<p>15 0.69763404 <a title="168-lsi-15" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>16 0.63368052 <a title="168-lsi-16" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>17 0.63006753 <a title="168-lsi-17" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>18 0.60739267 <a title="168-lsi-18" href="./iccv-2013-Learning_People_Detectors_for_Tracking_in_Crowded_Scenes.html">242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</a></p>
<p>19 0.59557992 <a title="168-lsi-19" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<p>20 0.59379804 <a title="168-lsi-20" href="./iccv-2013-Relative_Attributes_for_Large-Scale_Abandoned_Object_Detection.html">350 iccv-2013-Relative Attributes for Large-Scale Abandoned Object Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(12, 0.012), (13, 0.137), (20, 0.095), (25, 0.041), (26, 0.013), (40, 0.211), (42, 0.132), (48, 0.175), (55, 0.012), (60, 0.023), (77, 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82364422 <a title="168-lda-1" href="./iccv-2013-Analysis_of_Scores%2C_Datasets%2C_and_Models_in_Visual_Saliency_Prediction.html">50 iccv-2013-Analysis of Scores, Datasets, and Models in Visual Saliency Prediction</a></p>
<p>same-paper 2 0.82262439 <a title="168-lda-2" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>3 0.80514038 <a title="168-lda-3" href="./iccv-2013-Saliency_Detection%3A_A_Boolean_Map_Approach.html">369 iccv-2013-Saliency Detection: A Boolean Map Approach</a></p>
<p>4 0.80138969 <a title="168-lda-4" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>5 0.78601646 <a title="168-lda-5" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>6 0.78430057 <a title="168-lda-6" href="./iccv-2013-PhotoOCR%3A_Reading_Text_in_Uncontrolled_Conditions.html">315 iccv-2013-PhotoOCR: Reading Text in Uncontrolled Conditions</a></p>
<p>7 0.78177524 <a title="168-lda-7" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>8 0.77965963 <a title="168-lda-8" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>9 0.77943414 <a title="168-lda-9" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>10 0.77927375 <a title="168-lda-10" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>11 0.77923417 <a title="168-lda-11" href="./iccv-2013-Action_Recognition_and_Localization_by_Hierarchical_Space-Time_Segments.html">37 iccv-2013-Action Recognition and Localization by Hierarchical Space-Time Segments</a></p>
<p>12 0.77621984 <a title="168-lda-12" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>13 0.77368027 <a title="168-lda-13" href="./iccv-2013-Measuring_Flow_Complexity_in_Videos.html">263 iccv-2013-Measuring Flow Complexity in Videos</a></p>
<p>14 0.77357888 <a title="168-lda-14" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>15 0.77202487 <a title="168-lda-15" href="./iccv-2013-Live_Metric_3D_Reconstruction_on_Mobile_Phones.html">254 iccv-2013-Live Metric 3D Reconstruction on Mobile Phones</a></p>
<p>16 0.77137494 <a title="168-lda-16" href="./iccv-2013-Supervised_Binary_Hash_Code_Learning_with_Jensen_Shannon_Divergence.html">409 iccv-2013-Supervised Binary Hash Code Learning with Jensen Shannon Divergence</a></p>
<p>17 0.77094042 <a title="168-lda-17" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>18 0.76949918 <a title="168-lda-18" href="./iccv-2013-Unsupervised_Random_Forest_Manifold_Alignment_for_Lipreading.html">437 iccv-2013-Unsupervised Random Forest Manifold Alignment for Lipreading</a></p>
<p>19 0.7685492 <a title="168-lda-19" href="./iccv-2013-How_Related_Exemplars_Help_Complex_Event_Detection_in_Web_Videos%3F.html">203 iccv-2013-How Related Exemplars Help Complex Event Detection in Web Videos?</a></p>
<p>20 0.76842636 <a title="168-lda-20" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
