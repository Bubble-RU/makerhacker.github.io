<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-149" href="#">iccv2013-149</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</h1>
<br/><p>Source: <a title="iccv-2013-149-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zhou_Exemplar-Based_Graph_Matching_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Feng Zhou, Jonathan Brandt, Zhe Lin</p><p>Abstract: Localizing facial landmarks is a fundamental step in facial image analysis. However, the problem is still challenging due to the large variability in pose and appearance, and the existence ofocclusions in real-worldface images. In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. Compared to conventional algorithms, EGM has three advantages: (1) an affine-invariant shape constraint is learned online from similar exemplars to better adapt to the test face; (2) the optimal landmark configuration can be directly obtained by solving a graph matching problem with the learned shape constraint; (3) the graph matching problem can be optimized efficiently by linear programming. To our best knowledge, this is the first attempt to apply a graph matching technique for facial landmark localization. Experiments on several challenging datasets demonstrate the advantages of EGM over state-of-the-art methods.</p><p>Reference: <a title="iccv-2013-149-reference" href="../iccv2013_reference/iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com Abstract Localizing facial landmarks is a fundamental step in facial image analysis. [sent-3, score-0.69]
</p><p>2 In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. [sent-5, score-0.594]
</p><p>3 To our best knowledge, this is the first attempt to apply a graph matching technique for facial landmark localization. [sent-7, score-0.594]
</p><p>4 , face alignment) is a critical component in many computer vision applications such as face recognition [34], face reconstruction [20], expression recognition [25] and expression re-targeting [19]. [sent-13, score-0.254]
</p><p>5 However, accurately localizing facial landmark points in real-world, cluttered images is still a challenging problem due to the large variability in pose and appearance, and the existence of occlusions. [sent-15, score-0.561]
</p><p>6 1a, how can we accurately localize the facial landmarks in the chin area even though it is partially occluded? [sent-17, score-0.539]
</p><p>7 Conventional algorithms for face alignment typically proceed by fitting a joint shape model to regions around each feature point. [sent-18, score-0.195]
</p><p>8 Following the pioneering work on the active shape model (ASM) [7], a number of shape models Jonathan Brandt, Zhe Lin Adobe Research San Jose, CA 95110 { jbrandt , z l @ adobe . [sent-19, score-0.232]
</p><p>9 Despite the fact that the chin area is partially occluded, EGM still accurately locates the facial landmarks. [sent-21, score-0.273]
</p><p>10 EGM first finds similar exemplars through a RANSAC step. [sent-22, score-0.133]
</p><p>11 These exemplars are then used to generate (a) candidate positions for landmarks and to learn (b) an affine-invariant shape constraint, where the position of each landmark (e. [sent-23, score-0.84]
</p><p>12 By combining these two sources, EGM solves a graph matching problem to obtain (c) the optimal landmark positions. [sent-26, score-0.412]
</p><p>13 Among them, parametric models such as point distribution model (PDM) have been shown to be effective in governing the layout of facial landmarks. [sent-28, score-0.244]
</p><p>14 In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. [sent-30, score-0.594]
</p><p>15 Unlike previous face alignment algorithms, EGM models the layout of the facial landmarks as a graph in a  non-parametric way. [sent-31, score-0.657]
</p><p>16 Compared to conventional methods, EGM has three advantages: (1) the shape constraint (Fig. [sent-34, score-0.184]
</p><p>17 Related work Early work on facial landmark localization [12] often treated the problem as a special case ofthe object part detection problem. [sent-38, score-0.468]
</p><p>18 However, general detection methods are not suitable in detecting facial landmarks because only a few salient landmarks (e. [sent-39, score-0.754]
</p><p>19 According to the type of shape constraint inherently imposed, previous work can be categorized into two groups: parametric methods and non-parametric methods. [sent-43, score-0.184]
</p><p>20 Active shape model (ASM) [7] and active appearance  model (AAM) [5] are the two most representative face alignment models using parametric shape constraints. [sent-44, score-0.336]
</p><p>21 In ASM, a point distribution model captures the shape variation of a set of landmark points. [sent-45, score-0.357]
</p><p>22 Due to the robustness of patch detectors to global illumination variation and occlusion, CLM have been widely used in detecting and tracking facial landmarks in challenging cases. [sent-50, score-0.521]
</p><p>23 Although the great flexibility in constraining facial landmarks, parametric shape models are difficult to optimize due to the non-convex nature of the problem. [sent-51, score-0.319]
</p><p>24 In the second case, the global layout of facial landmarks is constrained in a non-parametric manner. [sent-55, score-0.507]
</p><p>25 The most relevant work to our method is the exemplar approach [2], where RANSAC was employed to efficiently sample exemplar shapes. [sent-67, score-0.19]
</p><p>26 A major limitation of [2] is that the position of each landmark is independently inferred by a greedy fusion procedure. [sent-68, score-0.332]
</p><p>27 In contrast, our method estimates all the landmarks jointly with a shape constraint learned online. [sent-69, score-0.452]
</p><p>28 Our solution is globally optimal and satisfies the global shape constraints automatically. [sent-71, score-0.133]
</p><p>29 The shape constraints we use here are learned online from similar examplars, hence they are adaptive to the pose of the test face. [sent-72, score-0.16]
</p><p>30 Overview of the proposed system In this section, we describe the proposed system for localizing facial landmarks. [sent-74, score-0.245]
</p><p>31 Training: In the first offline step, we train individual landmark detectors based on support vector regressor (SVR). [sent-77, score-0.297]
</p><p>32 RANSAC: We search for a set of similar exemplars in the training dataset to generate candidates positions for landmarks based on a RANSAC algorithm similar to [2]. [sent-82, score-0.467]
</p><p>33 3d) by the RANSAC, we solve an efficient quadratic programming problem to obtain a shape constraint adaptively for the test face. [sent-87, score-0.195]
</p><p>34 Matching: By combining the candidate position and the learned shape constraints, we solve an efficient graph matching problem based to find the optimal landmark positions using linear programming. [sent-89, score-0.613]
</p><p>35 The last two steps of learning and matching are the main contributions of the proposed exemplar graph matching (EGM) algorithm. [sent-90, score-0.28]
</p><p>36 Pipeline of the proposed system for detecting facial landmarks. [sent-93, score-0.222]
</p><p>37 3a for the landmark positions of an example image. [sent-103, score-0.28]
</p><p>38 Throughout the rest of the paper, we will denote (see notation1) the number of landmarks as k (e. [sent-104, score-0.266]
</p><p>39 The coordinates of landmarks on the training image and test image are denoted as p ∈ R2 and q ∈ R2 respectively. [sent-107, score-0.266]
</p><p>40 Exemplar-based graph matching This section describes exemplar-based graph matching (EGM), the main component of our system for localizing facial landmarks. [sent-109, score-0.497]
</p><p>41 3d), EGM aims to find the optimal subset of candidates in two steps: (1) learning an affine-invariant shape constraint online from the retrieved similar exemplars and (2) solving a graph matching problem to find the optimal candidates. [sent-112, score-0.533]
</p><p>42 Learning As mentioned before, use of a shape constraint is crucial for face alignment because the detector is usually not reliable and the local response may vary due to the change in pose and the existence of occlusions. [sent-115, score-0.351]
</p><p>43 A common choice of shape constraint is the point distribution model (PDM), in which the variances of facial landmarks are jointly modeled by a covariance matrix. [sent-116, score-0.632]
</p><p>44 To overcome these limitations, we adopt an affine-invariant shape constraint (AISC) originally proposed in [22] for object matching. [sent-136, score-0.162]
</p><p>45 Compared to PDM, AISC has two advantages: (1) the constraint is affine-invariant, making the system more robust to pose variation; (2) based on AISC, the matching step can be formalized as a graph matching problem, which can be efficiently solved by LP. [sent-137, score-0.297]
</p><p>46 Suppose that a shape consists of k landmarks denoted by P = [p1, · · · , pk] and the cth landmark pc can be reconstructed by th,e·· l·in ,epar combination of its neighbors as, pc = Pwc, where wc ∈ Rk denotes the weights ofthe other k−1 landmarks to reco∈ns Rtruct pc. [sent-139, score-1.011]
</p><p>47 In this paper, we extend AISC for face alignment and we formalize the problem oflearning wc as follows. [sent-141, score-0.164]
</p><p>48 Each exemplar consists of k landmarks, Pi = [pi1, · · · , pik] , where pci is the 2-D coordinate of the cth landm,a·r·k· ,frpom the ith exemplar. [sent-143, score-0.18]
</p><p>49 For each landmark c ∈ {1, · · · , k}, we aim to umn vector x. [sent-144, score-0.264]
</p><p>50 4a, where a large area around chin is occluded and few confident landmarks exist below the top of the mouth. [sent-161, score-0.335]
</p><p>51 By increasing η, larger weights could be assigned to non-local landmarks (e. [sent-162, score-0.284]
</p><p>52 In the extreme case, when η → ∞, all landmarks are of equal importance. [sent-165, score-0.266]
</p><p>53 Matching Given the generated landmark candidate sets from the RANSAC step, we aim to select a single candidate for each landmark such that the corresponding global configuration best fits to the shape constraint W learned from the exemplars. [sent-172, score-0.83]
</p><p>54 The size of landmark is proportional to its contribution in reconstruction. [sent-176, score-0.264]
</p><p>55 (a) Weights learned for the mouth-top landmark with different settings of η. [sent-177, score-0.288]
</p><p>56 (b) Weights learned for other landmarks using η = 103. [sent-178, score-0.29]
</p><p>57 (d) The landmark-candidate association matrix (G), where each candidate (column) is only associated to one landmark (row). [sent-184, score-0.333]
</p><p>58 nown to be associated with one of the k landmarks in th? [sent-188, score-0.266]
</p><p>59 Each of the 8 points can be considered as one facial landmark candidate, and each of the 4 colors denotes one landmark label. [sent-193, score-0.732]
</p><p>60 Given the candidates (Q, G, A) and the shape constraint (W), the problem consists of finding the optimal correspondence (X) that minimizes the following error:  ? [sent-198, score-0.236]
</p><p>61 However, EGM significantly dif11002288  fers from [2] in the step of inferring the final landmark positions. [sent-250, score-0.28]
</p><p>62 In [2], the final position of each landmark is indepen-  dently obtained by a weighted averaging of the candidate points. [sent-251, score-0.332]
</p><p>63 This greedy approach is sensitive to the outliers existed in the exemplar and candidate set. [sent-252, score-0.173]
</p><p>64 In contrast, EGM jointly infers the position for all the landmarks by solving a graph matching problem with an affine-invariant shape constraint learned online from similar examplars. [sent-253, score-0.612]
</p><p>65 Due to the robustness of the shape constraint and the effectiveness of the graph matching step, EGM obtained much more accurate landmarks than [2] did in all the experiments. [sent-254, score-0.554]
</p><p>66 Although similar in spirit, our shape constraint differs from [22] in three important aspects: (1) In [22], the weights are learned from a single exemplar. [sent-255, score-0.204]
</p><p>67 Without sufficient constraints, however, there are infinite choices of weights for reconstructing one landmark by more than 3 neighbors. [sent-256, score-0.282]
</p><p>68 In addition, the weights learned from one exemplar might not generalize well to a non-rigidly deformed face (e. [sent-257, score-0.202]
</p><p>69 The wc is not only unique but also more robust in capturing various non-rigid facial poses contained in the exemplar set. [sent-262, score-0.361]
</p><p>70 (2) The object shape in [22] is represented by a sparse graph, where the landmark is influenced by its nearby neighbors. [sent-263, score-0.357]
</p><p>71 However, in many cases, the local structure of a landmark can be distorted by noise and occlusion. [sent-264, score-0.264]
</p><p>72 (3) With proper regularization, all the other k − 1 landmarks make important contribution in tthhee o retchoern kstru −ct 1io lna odfm eaarkchs mlanakdmea imrkp. [sent-266, score-0.266]
</p><p>73 LFPW dataset The LFPW dataset [2] consists of images downloaded from internet and the images contain a wide range of poses, lighting conditions and facial expressions. [sent-272, score-0.204]
</p><p>74 , ASM) depending on a good initialization, EGM computes the facial landmarks by directly solving a combinatorial problem. [sent-284, score-0.47]
</p><p>75 To be fair in comparison, we fixed the parameter setting in the RANSAC step and used the same set of candidates and exemplar images for both EGM and [2]. [sent-287, score-0.163]
</p><p>76 In particular, EGM outperformed [2] by a large margin in the landmarks around the nose tip (19 ∼ 21) and the chin (27 ∼ 2m9a)r, ws ahreorue appearance tfiepat (u1r9es ∼ are frequently uhinnre (li2a7ble ∼. [sent-291, score-0.352]
</p><p>77 Because of the affineinvariant shape constraint and the global LP-based optimization, EGM more robustly handles these areas than the greedy fusion method proposed in [2]. [sent-293, score-0.212]
</p><p>78 For the landmarks around eyebrows (1 ∼ 8), our method outperformed [2] by a somunadll margin. [sent-294, score-0.266]
</p><p>79 We expect that training the landmark detectors using the author’s original training data would further boost the performance of our method significantly. [sent-297, score-0.297]
</p><p>80 Based on the Matlab function linprog, the matching step took 9 secs for selecting the optimal landmarks from more than 3000 candidates. [sent-303, score-0.387]
</p><p>81 In our experiment, we trained our landmark detectors on the LFPW dataset and tested EGM on all the 1521 images. [sent-310, score-0.297]
</p><p>82 To evaluate the result, we used 17 landmarks marked for the FGNet project, and used in the me17 error measure as defined in [9]. [sent-313, score-0.266]
</p><p>83 Following the common protocol used in [2, 4], we computed for each landmark a fixed offset by exhaustively matching with the ground-truth label. [sent-314, score-0.344]
</p><p>84 (a) Results of EGM and the exemplar approach [2] on example faces, where the landmarks  denoted as yellow triangles are the ones largely improved by EGM. [sent-337, score-0.431]
</p><p>85 (c) Two worse examples  (in the  1st  column), where EGM cannot accurately locate the landmarks denoted as yellow triangles because of very few exemplar images available in LFPW with similar exaggerated expressions. [sent-339, score-0.41]
</p><p>86 With the same set of exemplars and detectors, EGM greatly improved the greedy fusion step proposed in [2]. [sent-343, score-0.199]
</p><p>87 Similar to BioID, we trained our landmark detectors on the LFPW dataset. [sent-348, score-0.297]
</p><p>88 To report a quantitative result, we re-labeled2 348 images with the same 29 landmarks as LFPW. [sent-350, score-0.266]
</p><p>89 Our method was much more accurate than [2] in detecting facial landmarks (especially the yellow triangles) in challenging images with large variation in pose and expressions. [sent-358, score-0.537]
</p><p>90 The result clearly illustrates the benefit of using the proposed graph matching method with affine-invariant shape constraints over the greedy fusion method proposed in [2]. [sent-363, score-0.288]
</p><p>91 With only few similar exemplars, it is very difficult to learn a shape constraint particularly for the mouth of the test image shown in the first column. [sent-369, score-0.18]
</p><p>92 Conclusions This paper presents exemplar-based graph matching (EGM), a robust framework for facial landmark localization. [sent-371, score-0.594]
</p><p>93 Therefore, we conjecture that we can improve EGM by clustering facial shapes to refine the exemplars returned by the RANSAC. [sent-375, score-0.337]
</p><p>94 In addition, the RANSAC step may be further improved by a component-based facial part matching instead of the matching between entire faces. [sent-376, score-0.338]
</p><p>95 A generative shape regularization model for robust face alignment. [sent-521, score-0.158]
</p><p>96 AAM  derived face representations for robust facial action recognition. [sent-598, score-0.269]
</p><p>97 Locating facial features with an extended active shape model. [sent-613, score-0.323]
</p><p>98 Detector of facial landmarks learned by the structured output svm. [sent-643, score-0.494]
</p><p>99 Fully automatic facial feature point detection using Gabor feature based boosted classifiers. [sent-656, score-0.221]
</p><p>100 Face detection, pose estimation, and landmark localization in the wild. [sent-678, score-0.291]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('egm', 0.779), ('landmarks', 0.266), ('landmark', 0.264), ('facial', 0.204), ('exemplars', 0.133), ('lfpw', 0.122), ('ransac', 0.099), ('exemplar', 0.095), ('shape', 0.093), ('bioid', 0.088), ('chin', 0.069), ('constraint', 0.069), ('helen', 0.068), ('graph', 0.067), ('asm', 0.066), ('face', 0.065), ('wc', 0.062), ('aisc', 0.061), ('matching', 0.059), ('gci', 0.059), ('pdm', 0.054), ('candidates', 0.052), ('candidate', 0.05), ('qxt', 0.05), ('cth', 0.042), ('localizing', 0.041), ('mrf', 0.038), ('alignment', 0.037), ('faces', 0.037), ('lp', 0.035), ('response', 0.035), ('beetlh', 0.033), ('detectors', 0.033), ('programming', 0.033), ('sped', 0.029), ('aam', 0.028), ('greedy', 0.028), ('discretize', 0.028), ('lucey', 0.028), ('triangles', 0.027), ('cootes', 0.027), ('pose', 0.027), ('active', 0.026), ('axt', 0.026), ('pci', 0.026), ('xci', 0.026), ('existence', 0.025), ('cristinacce', 0.024), ('clm', 0.024), ('secs', 0.024), ('learned', 0.024), ('advantages', 0.024), ('wen', 0.023), ('brandt', 0.023), ('parametric', 0.022), ('optimal', 0.022), ('regression', 0.022), ('yellow', 0.022), ('liang', 0.022), ('conventional', 0.022), ('fusion', 0.022), ('valstar', 0.022), ('ofusing', 0.022), ('trust', 0.021), ('largely', 0.021), ('offset', 0.021), ('adobe', 0.02), ('expression', 0.02), ('affine', 0.02), ('rk', 0.02), ('saragih', 0.02), ('association', 0.019), ('ik', 0.019), ('integer', 0.019), ('qp', 0.019), ('letters', 0.019), ('illustrates', 0.019), ('reconstruction', 0.019), ('constrained', 0.019), ('detecting', 0.018), ('globally', 0.018), ('weights', 0.018), ('layout', 0.018), ('position', 0.018), ('instance', 0.018), ('mouth', 0.018), ('boosted', 0.017), ('ith', 0.017), ('xij', 0.017), ('hou', 0.017), ('bounding', 0.017), ('nose', 0.017), ('elastic', 0.017), ('ur', 0.016), ('configuration', 0.016), ('step', 0.016), ('geometrical', 0.016), ('online', 0.016), ('positions', 0.016), ('decade', 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="149-tfidf-1" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>Author: Feng Zhou, Jonathan Brandt, Zhe Lin</p><p>Abstract: Localizing facial landmarks is a fundamental step in facial image analysis. However, the problem is still challenging due to the large variability in pose and appearance, and the existence ofocclusions in real-worldface images. In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. Compared to conventional algorithms, EGM has three advantages: (1) an affine-invariant shape constraint is learned online from similar exemplars to better adapt to the test face; (2) the optimal landmark configuration can be directly obtained by solving a graph matching problem with the learned shape constraint; (3) the graph matching problem can be optimized efficiently by linear programming. To our best knowledge, this is the first attempt to apply a graph matching technique for facial landmark localization. Experiments on several challenging datasets demonstrate the advantages of EGM over state-of-the-art methods.</p><p>2 0.378001 <a title="149-tfidf-2" href="./iccv-2013-Cascaded_Shape_Space_Pruning_for_Robust_Facial_Landmark_Detection.html">70 iccv-2013-Cascaded Shape Space Pruning for Robust Facial Landmark Detection</a></p>
<p>Author: Xiaowei Zhao, Shiguang Shan, Xiujuan Chai, Xilin Chen</p><p>Abstract: In this paper, we propose a novel cascaded face shape space pruning algorithm for robust facial landmark detection. Through progressively excluding the incorrect candidate shapes, our algorithm can accurately and efficiently achieve the globally optimal shape configuration. Specifically, individual landmark detectors are firstly applied to eliminate wrong candidates for each landmark. Then, the candidate shape space is further pruned by jointly removing incorrect shape configurations. To achieve this purpose, a discriminative structure classifier is designed to assess the candidate shape configurations. Based on the learned discriminative structure classifier, an efficient shape space pruning strategy is proposed to quickly reject most incorrect candidate shapes while preserve the true shape. The proposed algorithm is carefully evaluated on a large set of real world face images. In addition, comparison results on the publicly available BioID and LFW face databases demonstrate that our algorithm outperforms some state-of-the-art algorithms.</p><p>3 0.33393735 <a title="149-tfidf-3" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>Author: Xiang Yu, Junzhou Huang, Shaoting Zhang, Wang Yan, Dimitris N. Metaxas</p><p>Abstract: This paper addresses the problem of facial landmark localization and tracking from a single camera. We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. For face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. By introducing 3D face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. For deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. The second step uses component-wise active contours to discriminatively refine the subtle shape variation. Our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. Extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. All results demonstrate that our approach has certain advantages over state-of-theart methods in handling pose variations1.</p><p>4 0.17048521 <a title="149-tfidf-4" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>Author: Yen-Lin Chen, Hsiang-Tao Wu, Fuhao Shi, Xin Tong, Jinxiang Chai</p><p>Abstract: This paper presents an automatic and robust approach that accurately captures high-quality 3D facial performances using a single RGBD camera. The key of our approach is to combine the power of automatic facial feature detection and image-based 3D nonrigid registration techniques for 3D facial reconstruction. In particular, we develop a robust and accurate image-based nonrigid registration algorithm that incrementally deforms a 3D template mesh model to best match observed depth image data and important facial features detected from single RGBD images. The whole process is fully automatic and robust because it is based on single frame facial registration framework. The system is flexible because it does not require any strong 3D facial priors such as blendshape models. We demonstrate the power of our approach by capturing a wide range of 3D facial expressions using a single RGBD camera and achieve state-of-the-art accuracy by comparing against alternative methods.</p><p>5 0.14052592 <a title="149-tfidf-5" href="./iccv-2013-Robust_Face_Landmark_Estimation_under_Occlusion.html">355 iccv-2013-Robust Face Landmark Estimation under Occlusion</a></p>
<p>Author: Xavier P. Burgos-Artizzu, Pietro Perona, Piotr Dollár</p><p>Abstract: Human faces captured in real-world conditions present large variations in shape and occlusions due to differences in pose, expression, use of accessories such as sunglasses and hats and interactions with objects (e.g. food). Current face landmark estimation approaches struggle under such conditions since theyfail toprovide aprincipled way ofhandling outliers. We propose a novel method, called Robust Cascaded Pose Regression (RCPR) which reduces exposure to outliers by detecting occlusions explicitly and using robust shape-indexed features. We show that RCPR improves on previous landmark estimation methods on three popular face datasets (LFPW, LFW and HELEN). We further explore RCPR ’s performance by introducing a novel face dataset focused on occlusion, composed of 1,007 faces presenting a wide range of occlusion patterns. RCPR reduces failure cases by half on all four datasets, at the same time as it detects face occlusions with a 80/40% precision/recall.</p><p>6 0.13247132 <a title="149-tfidf-6" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>7 0.12540177 <a title="149-tfidf-7" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>8 0.11520594 <a title="149-tfidf-8" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>9 0.10324166 <a title="149-tfidf-9" href="./iccv-2013-How_Related_Exemplars_Help_Complex_Event_Detection_in_Web_Videos%3F.html">203 iccv-2013-How Related Exemplars Help Complex Event Detection in Web Videos?</a></p>
<p>10 0.10261318 <a title="149-tfidf-10" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>11 0.10134273 <a title="149-tfidf-11" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>12 0.099418037 <a title="149-tfidf-12" href="./iccv-2013-Like_Father%2C_Like_Son%3A_Facial_Expression_Dynamics_for_Kinship_Verification.html">251 iccv-2013-Like Father, Like Son: Facial Expression Dynamics for Kinship Verification</a></p>
<p>13 0.097054213 <a title="149-tfidf-13" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>14 0.09571375 <a title="149-tfidf-14" href="./iccv-2013-Optimization_Problems_for_Fast_AAM_Fitting_in-the-Wild.html">302 iccv-2013-Optimization Problems for Fast AAM Fitting in-the-Wild</a></p>
<p>15 0.094930477 <a title="149-tfidf-15" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>16 0.089979798 <a title="149-tfidf-16" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<p>17 0.086632498 <a title="149-tfidf-17" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>18 0.084890053 <a title="149-tfidf-18" href="./iccv-2013-Recognising_Human-Object_Interaction_via_Exemplar_Based_Modelling.html">344 iccv-2013-Recognising Human-Object Interaction via Exemplar Based Modelling</a></p>
<p>19 0.084879339 <a title="149-tfidf-19" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>20 0.084648401 <a title="149-tfidf-20" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.154), (1, -0.01), (2, -0.071), (3, -0.071), (4, 0.016), (5, -0.123), (6, 0.238), (7, 0.088), (8, -0.018), (9, -0.042), (10, -0.055), (11, 0.112), (12, 0.05), (13, 0.033), (14, -0.027), (15, 0.034), (16, 0.095), (17, 0.024), (18, -0.067), (19, -0.137), (20, 0.058), (21, 0.095), (22, -0.009), (23, 0.17), (24, 0.053), (25, -0.079), (26, 0.057), (27, -0.11), (28, -0.018), (29, -0.087), (30, -0.077), (31, 0.025), (32, 0.001), (33, 0.067), (34, 0.035), (35, 0.104), (36, -0.028), (37, -0.072), (38, 0.001), (39, 0.064), (40, -0.055), (41, -0.135), (42, 0.034), (43, 0.001), (44, 0.033), (45, 0.037), (46, 0.02), (47, -0.063), (48, 0.058), (49, 0.091)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92813456 <a title="149-lsi-1" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>Author: Feng Zhou, Jonathan Brandt, Zhe Lin</p><p>Abstract: Localizing facial landmarks is a fundamental step in facial image analysis. However, the problem is still challenging due to the large variability in pose and appearance, and the existence ofocclusions in real-worldface images. In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. Compared to conventional algorithms, EGM has three advantages: (1) an affine-invariant shape constraint is learned online from similar exemplars to better adapt to the test face; (2) the optimal landmark configuration can be directly obtained by solving a graph matching problem with the learned shape constraint; (3) the graph matching problem can be optimized efficiently by linear programming. To our best knowledge, this is the first attempt to apply a graph matching technique for facial landmark localization. Experiments on several challenging datasets demonstrate the advantages of EGM over state-of-the-art methods.</p><p>2 0.88872075 <a title="149-lsi-2" href="./iccv-2013-Cascaded_Shape_Space_Pruning_for_Robust_Facial_Landmark_Detection.html">70 iccv-2013-Cascaded Shape Space Pruning for Robust Facial Landmark Detection</a></p>
<p>Author: Xiaowei Zhao, Shiguang Shan, Xiujuan Chai, Xilin Chen</p><p>Abstract: In this paper, we propose a novel cascaded face shape space pruning algorithm for robust facial landmark detection. Through progressively excluding the incorrect candidate shapes, our algorithm can accurately and efficiently achieve the globally optimal shape configuration. Specifically, individual landmark detectors are firstly applied to eliminate wrong candidates for each landmark. Then, the candidate shape space is further pruned by jointly removing incorrect shape configurations. To achieve this purpose, a discriminative structure classifier is designed to assess the candidate shape configurations. Based on the learned discriminative structure classifier, an efficient shape space pruning strategy is proposed to quickly reject most incorrect candidate shapes while preserve the true shape. The proposed algorithm is carefully evaluated on a large set of real world face images. In addition, comparison results on the publicly available BioID and LFW face databases demonstrate that our algorithm outperforms some state-of-the-art algorithms.</p><p>3 0.85100025 <a title="149-lsi-3" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>Author: Xiang Yu, Junzhou Huang, Shaoting Zhang, Wang Yan, Dimitris N. Metaxas</p><p>Abstract: This paper addresses the problem of facial landmark localization and tracking from a single camera. We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. For face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. By introducing 3D face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. For deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. The second step uses component-wise active contours to discriminatively refine the subtle shape variation. Our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. Extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. All results demonstrate that our approach has certain advantages over state-of-theart methods in handling pose variations1.</p><p>4 0.76398551 <a title="149-lsi-4" href="./iccv-2013-Like_Father%2C_Like_Son%3A_Facial_Expression_Dynamics_for_Kinship_Verification.html">251 iccv-2013-Like Father, Like Son: Facial Expression Dynamics for Kinship Verification</a></p>
<p>Author: Hamdi Dibeklioglu, Albert Ali Salah, Theo Gevers</p><p>Abstract: Kinship verification from facial appearance is a difficult problem. This paper explores the possibility of employing facial expression dynamics in this problem. By using features that describe facial dynamics and spatio-temporal appearance over smile expressions, we show that it is possible to improve the state ofthe art in thisproblem, and verify that it is indeed possible to recognize kinship by resemblance of facial expressions. The proposed method is tested on different kin relationships. On the average, 72.89% verification accuracy is achieved on spontaneous smiles.</p><p>5 0.70850056 <a title="149-lsi-5" href="./iccv-2013-Robust_Face_Landmark_Estimation_under_Occlusion.html">355 iccv-2013-Robust Face Landmark Estimation under Occlusion</a></p>
<p>Author: Xavier P. Burgos-Artizzu, Pietro Perona, Piotr Dollár</p><p>Abstract: Human faces captured in real-world conditions present large variations in shape and occlusions due to differences in pose, expression, use of accessories such as sunglasses and hats and interactions with objects (e.g. food). Current face landmark estimation approaches struggle under such conditions since theyfail toprovide aprincipled way ofhandling outliers. We propose a novel method, called Robust Cascaded Pose Regression (RCPR) which reduces exposure to outliers by detecting occlusions explicitly and using robust shape-indexed features. We show that RCPR improves on previous landmark estimation methods on three popular face datasets (LFPW, LFW and HELEN). We further explore RCPR ’s performance by introducing a novel face dataset focused on occlusion, composed of 1,007 faces presenting a wide range of occlusion patterns. RCPR reduces failure cases by half on all four datasets, at the same time as it detects face occlusions with a 80/40% precision/recall.</p><p>6 0.64046556 <a title="149-lsi-6" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>7 0.62495714 <a title="149-lsi-7" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>8 0.52638829 <a title="149-lsi-8" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>9 0.51157326 <a title="149-lsi-9" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>10 0.50337392 <a title="149-lsi-10" href="./iccv-2013-Modifying_the_Memorability_of_Face_Photographs.html">272 iccv-2013-Modifying the Memorability of Face Photographs</a></p>
<p>11 0.4965798 <a title="149-lsi-11" href="./iccv-2013-Discovering_Details_and_Scene_Structure_with_Hierarchical_Iconoid_Shift.html">117 iccv-2013-Discovering Details and Scene Structure with Hierarchical Iconoid Shift</a></p>
<p>12 0.49510279 <a title="149-lsi-12" href="./iccv-2013-Facial_Action_Unit_Event_Detection_by_Cascade_of_Tasks.html">155 iccv-2013-Facial Action Unit Event Detection by Cascade of Tasks</a></p>
<p>13 0.4772464 <a title="149-lsi-13" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>14 0.47585386 <a title="149-lsi-14" href="./iccv-2013-Optimization_Problems_for_Fast_AAM_Fitting_in-the-Wild.html">302 iccv-2013-Optimization Problems for Fast AAM Fitting in-the-Wild</a></p>
<p>15 0.45481548 <a title="149-lsi-15" href="./iccv-2013-Capturing_Global_Semantic_Relationships_for_Facial_Action_Unit_Recognition.html">69 iccv-2013-Capturing Global Semantic Relationships for Facial Action Unit Recognition</a></p>
<p>16 0.38688457 <a title="149-lsi-16" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>17 0.38159767 <a title="149-lsi-17" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>18 0.37712893 <a title="149-lsi-18" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>19 0.34650767 <a title="149-lsi-19" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>20 0.34525076 <a title="149-lsi-20" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.057), (7, 0.013), (26, 0.059), (27, 0.01), (31, 0.043), (34, 0.012), (40, 0.011), (42, 0.218), (48, 0.013), (50, 0.142), (64, 0.042), (73, 0.034), (78, 0.041), (89, 0.191), (98, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9139241 <a title="149-lda-1" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>Author: Feng Zhou, Jonathan Brandt, Zhe Lin</p><p>Abstract: Localizing facial landmarks is a fundamental step in facial image analysis. However, the problem is still challenging due to the large variability in pose and appearance, and the existence ofocclusions in real-worldface images. In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. Compared to conventional algorithms, EGM has three advantages: (1) an affine-invariant shape constraint is learned online from similar exemplars to better adapt to the test face; (2) the optimal landmark configuration can be directly obtained by solving a graph matching problem with the learned shape constraint; (3) the graph matching problem can be optimized efficiently by linear programming. To our best knowledge, this is the first attempt to apply a graph matching technique for facial landmark localization. Experiments on several challenging datasets demonstrate the advantages of EGM over state-of-the-art methods.</p><p>2 0.89279306 <a title="149-lda-2" href="./iccv-2013-Attribute_Pivots_for_Guiding_Relevance_Feedback_in_Image_Search.html">54 iccv-2013-Attribute Pivots for Guiding Relevance Feedback in Image Search</a></p>
<p>Author: Adriana Kovashka, Kristen Grauman</p><p>Abstract: In interactive image search, a user iteratively refines his results by giving feedback on exemplar images. Active selection methods aim to elicit useful feedback, but traditional approaches suffer from expensive selection criteria and cannot predict informativeness reliably due to the imprecision of relevance feedback. To address these drawbacks, we propose to actively select “pivot” exemplars for which feedback in the form of a visual comparison will most reduce the system’s uncertainty. For example, the system might ask, “Is your target image more or less crowded than this image? ” Our approach relies on a series of binary search trees in relative attribute space, together with a selection function that predicts the information gain were the user to compare his envisioned target to the next node deeper in a given attribute ’s tree. It makes interactive search more efficient than existing strategies—both in terms of the system ’s selection time as well as the user’s feedback effort.</p><p>3 0.89255822 <a title="149-lda-3" href="./iccv-2013-Latent_Multitask_Learning_for_View-Invariant_Action_Recognition.html">231 iccv-2013-Latent Multitask Learning for View-Invariant Action Recognition</a></p>
<p>Author: Behrooz Mahasseni, Sinisa Todorovic</p><p>Abstract: This paper presents an approach to view-invariant action recognition, where human poses and motions exhibit large variations across different camera viewpoints. When each viewpoint of a given set of action classes is specified as a learning task then multitask learning appears suitable for achieving view invariance in recognition. We extend the standard multitask learning to allow identifying: (1) latent groupings of action views (i.e., tasks), and (2) discriminative action parts, along with joint learning of all tasks. This is because it seems reasonable to expect that certain distinct views are more correlated than some others, and thus identifying correlated views could improve recognition. Also, part-based modeling is expected to improve robustness against self-occlusion when actors are imaged from different views. Results on the benchmark datasets show that we outperform standard multitask learning by 21.9%, and the state-of-the-art alternatives by 4.5–6%.</p><p>4 0.88964587 <a title="149-lda-4" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<p>Author: Dengxin Dai, Hayko Riemenschneider, Gerhard Schmitt, Luc Van_Gool</p><p>Abstract: There is an increased interest in the efficient creation of city models, be it virtual or as-built. We present a method for synthesizing complex, photo-realistic facade images, from a single example. After parsing the example image into its semantic components, a tiling for it is generated. Novel tilings can then be created, yielding facade textures with different dimensions or with occluded parts inpainted. A genetic algorithm guides the novel facades as well as inpainted parts to be consistent with the example, both in terms of their overall structure and their detailed textures. Promising results for multiple standard datasets in particular for the different building styles they contain demonstrate the potential of the method. – –</p><p>5 0.88923681 <a title="149-lda-5" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>Author: Pierre Moulon, Pascal Monasse, Renaud Marlet</p><p>Abstract: Multi-view structure from motion (SfM) estimates the position and orientation of pictures in a common 3D coordinate frame. When views are treated incrementally, this external calibration can be subject to drift, contrary to global methods that distribute residual errors evenly. We propose a new global calibration approach based on the fusion of relative motions between image pairs. We improve an existing method for robustly computing global rotations. We present an efficient a contrario trifocal tensor estimation method, from which stable and precise translation directions can be extracted. We also define an efficient translation registration method that recovers accurate camera positions. These components are combined into an original SfM pipeline. Our experiments show that, on most datasets, it outperforms in accuracy other existing incremental and global pipelines. It also achieves strikingly good running times: it is about 20 times faster than the other global method we could compare to, and as fast as the best incremental method. More importantly, it features better scalability properties.</p><p>6 0.88776904 <a title="149-lda-6" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>7 0.88716924 <a title="149-lda-7" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>8 0.88608217 <a title="149-lda-8" href="./iccv-2013-Allocentric_Pose_Estimation.html">46 iccv-2013-Allocentric Pose Estimation</a></p>
<p>9 0.88404846 <a title="149-lda-9" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>10 0.88388193 <a title="149-lda-10" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>11 0.88222188 <a title="149-lda-11" href="./iccv-2013-Attribute_Adaptation_for_Personalized_Image_Search.html">52 iccv-2013-Attribute Adaptation for Personalized Image Search</a></p>
<p>12 0.88210744 <a title="149-lda-12" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>13 0.88043672 <a title="149-lda-13" href="./iccv-2013-Sparse_Variation_Dictionary_Learning_for_Face_Recognition_with_a_Single_Training_Sample_per_Person.html">398 iccv-2013-Sparse Variation Dictionary Learning for Face Recognition with a Single Training Sample per Person</a></p>
<p>14 0.88032937 <a title="149-lda-14" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>15 0.88025802 <a title="149-lda-15" href="./iccv-2013-Correlation_Adaptive_Subspace_Segmentation_by_Trace_Lasso.html">93 iccv-2013-Correlation Adaptive Subspace Segmentation by Trace Lasso</a></p>
<p>16 0.8799125 <a title="149-lda-16" href="./iccv-2013-Implied_Feedback%3A_Learning_Nuances_of_User_Behavior_in_Image_Search.html">213 iccv-2013-Implied Feedback: Learning Nuances of User Behavior in Image Search</a></p>
<p>17 0.87958914 <a title="149-lda-17" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>18 0.87940258 <a title="149-lda-18" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>19 0.87920099 <a title="149-lda-19" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>20 0.87861544 <a title="149-lda-20" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
