<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>154 iccv-2013-Face Recognition via Archetype Hull Ranking</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-154" href="#">iccv2013-154</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>154 iccv-2013-Face Recognition via Archetype Hull Ranking</h1>
<br/><p>Source: <a title="iccv-2013-154-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Xiong_Face_Recognition_via_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yuanjun Xiong, Wei Liu, Deli Zhao, Xiaoou Tang</p><p>Abstract: The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat- ing its performance superior to the state-of-the-arts.</p><p>Reference: <a title="iccv-2013-154-reference" href="../iccv2013_reference/iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com l i  Abstract The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. [sent-10, score-0.865]
</p><p>2 In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. [sent-11, score-1.177]
</p><p>3 Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. [sent-12, score-1.733]
</p><p>4 The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. [sent-13, score-1.974]
</p><p>5 After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. [sent-14, score-0.636]
</p><p>6 We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat-  ing its performance superior to the state-of-the-arts. [sent-15, score-0.398]
</p><p>7 Introduction The primary purpose of face analysis is to compute a robust and effective similarity measure between any input pair of face images. [sent-17, score-0.374]
</p><p>8 Such a measure is expected to suppress intra-personal face variations due to varying expressions, poses, and illumination conditions. [sent-18, score-0.188]
</p><p>9 Nowadays, rapidly growing face image resources stemming from online photo albums as well as social networks provide new opportunities and meanwhile pose new challenges to existing face processing approaches. [sent-19, score-0.304]
</p><p>10 How can we take advantage of the gigantic amount of face information on the Web? [sent-20, score-0.152]
</p><p>11 One feasible approach is to upgrade current face processing systems by augmenting web-crawled face images into their training datasets, which therefore requires the face systems to be easy for re-training and scalable to accommodate massive web data. [sent-21, score-0.553]
</p><p>12 We view face images as points in the image space, where the polytope composed of a few archetype faces encloses almost all points. [sent-33, score-0.807]
</p><p>13 Any point can be represented by a convex combination of the archetypes, and these archetypes hence form a convex hull of the entire point set. [sent-34, score-0.942]
</p><p>14 To pursue the scalability, we leverage a small set of archetype exemplars to represent a large training set of face images. [sent-35, score-0.814]
</p><p>15 These archetypes constitute a convex hull which encompasses most faces in the training set. [sent-36, score-0.968]
</p><p>16 To the best of our knowledge, the archetype hull model has not been applied to the face area. [sent-37, score-1.017]
</p><p>17 The use of archetypes along with the produced archetype hull may open up a new avenue to enable traditional face processing approaches scale up to  massive face datasets. [sent-38, score-1.845]
</p><p>18 1 showcases face archetypes and an archetype hull to model face images. [sent-40, score-1.796]
</p><p>19 In this paper, we seek such archetypes using an efficient simplex volume maximization algorithm. [sent-41, score-0.725]
</p><p>20 Subsequently, we build a scalable graph by virtue of the archetypes whose size is much smaller than the training data size. [sent-42, score-0.72]
</p><p>21 Moreover, we propose a novel graph-based ranking framework which explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. [sent-43, score-0.803]
</p><p>22 The archetype hull ranking is then applied to every block of face images, leading to a blockwise similar585  ity measure between any face pair through comparing two different rank vectors with respect to the same archetype hull. [sent-44, score-2.08]
</p><p>23 After integrating blockwise similarity measurements with learned importance weights, we eventually achieve a sensible face similarity measure that is readily applicable to both face recognition and verification tasks. [sent-45, score-0.675]
</p><p>24 We evaluate the face similarity measure in terms of experiments carried out on three benchmark face databases Multi-PIE [7], Pubfig83 [20], and LFW [9], and demonstrate that the performance of the proposed face similarity measure is superior to the state-of-the-arts. [sent-46, score-0.62]
</p><p>25 Related Work In the face recognition literature, a large number of subspace methods [25][3][19][17][26][27][13][8][28] working  on holistic facial features have been proposed. [sent-48, score-0.211]
</p><p>26 The local descriptors attempt to extract distinctive features of image textures like SIFT [18] or local micro-patterns of face shapes like LBP [1]. [sent-50, score-0.164]
</p><p>27 The success of sparse representation [30] in face recognition has inspired the face community to consider the sparse properties of the subspaces hidden in face image ensembles. [sent-52, score-0.474]
</p><p>28 Nevertheless, the subspace sparsity holds if there are sufficient face examples in each class to cover intra-personal variations, which could not be satisfied under unconstrained recognition environments such as the LFW database. [sent-53, score-0.197]
</p><p>29 As mentioned before, one of the major challenges of modern face recognition is the explosive growth of face data. [sent-54, score-0.322]
</p><p>30 In this paper, we employ the Anchor Graph model to deal with large quantities of face images since it scales linearly with the training set size in terms of both space and time complexities. [sent-58, score-0.175]
</p><p>31 , so-called archetypes, such that the typical patterns of this group of objects are covered in the archetypes and the other objects are simply emulations or combinations of the archetypes. [sent-63, score-0.627]
</p><p>32 Concept of Archetypes The concept of archetypes actually exists in a variety of disciplines including literature, philosophy, psychology, marketing [12], and statistics [6]. [sent-66, score-0.645]
</p><p>33 The idea of archetypes is recently introduced into pattern recognition [23] and informatics [24][21]. [sent-67, score-0.645]
</p><p>34 Understanding the concept of archetypes in face recognition is intuitive: people can easily remember someone with a very distinctive facial appearance; some people are thought of being very similar to a few distinctive faces. [sent-68, score-0.832]
</p><p>35 Such phenomena serve as the evidence of identifying archetypes and correlating unknown faces to known archetypes in a recognition process. [sent-69, score-1.286]
</p><p>36 Mathematically, the convex hull of archetypes encompasses almost all points in a data set, and the archetypes inherently reside on the border of the point cloud formed by the data set. [sent-70, score-1.558]
</p><p>37 To exploit the idea of archetypes along with their produced archetype hull, there are two core problems: 1) how to find the archetypes, and 2) how to correlate one input sample with the archetypes. [sent-71, score-1.287]
</p><p>38 Archetype Seeking The time efficiency of finding archetypes is an important concern. [sent-74, score-0.627]
</p><p>39 puting a convex hull enclosing X is as high as O ? [sent-78, score-0.282]
</p><p>40 high-dimensional descriptors, exactly solving this convex hull problem quickly becomes computationally intractable. [sent-83, score-0.282]
</p><p>41 To this end, a few algorithms have been designed to achieve approximate solutions, of which the simplex volume maximization algorithm [24] can provide a good approximate solution in a linear time complexity O(n). [sent-84, score-0.098]
</p><p>42 Given a point set X = {xi ∈ Rd}in=1, we intend to search for m archetypes UX = = {uj ∈∈ X}jm=1 whose convex hull forms an (m − 1)Usim =ple {xu in geometry. [sent-85, score-0.921]
</p><p>43 Output:  The  m  archetypes  U  =  {u}  encloses most training samples in X, we can project any input sample x ∈ tr Raind onngt osa mS,p thereby obtaining a new (lossy) representation ∈o fR x oinn oter Sm,s t hoefr etbhey s otbotraeidn archetypes oins s Uy. [sent-118, score-1.317]
</p><p>44 Through a simple archetype hull projection, we acquire the new representation Uz(x) for any input sample x, where the coefficient vector z(x) directly reveals that which archetypes are relevant to the input x (zj (x) > 0 implies  fwtduohjke,l+ms1rw=qau? [sent-130, score-1.531]
</p><p>45 Note that this sample may be an unseen sample outside the set of available training samples, and that these archetypes can be stored in memory for real-time computations. [sent-159, score-0.694]
</p><p>46 =m1θj= 1⎬⎫ (3) 587 ⎡the trainin⎤g data X and the archetypes U, that is, Z =  ⎡⎣zz? [sent-166, score-0.627]
</p><p>47 (5)  L¯ = I (I − = I (I −  By means of this normalized Anchor Graph Laplacian L¯, we propose a novel graph-based ranking framework which is capable of scaling up the well-known manifold ranking  ? [sent-180, score-0.198]
</p><p>48 The area surrounded by a dashed line denotes the current archetype hull produced by the currently chosen  The last subfigure shows the final archetype hull which encloses almost all data points, and shows a data point x that is  represented by a convex combination of three archetypes. [sent-255, score-1.803]
</p><p>49 The original objective of manifold ranking is fm∈Rinn (1 − α)? [sent-257, score-0.108]
</p><p>50 (6) into the context of the archetype hull described in eq. [sent-262, score-0.865]
</p><p>51 t( X10) t ob aetcwcoeemnp any input x and m archetypes in U. [sent-304, score-0.627]
</p><p>52 It is worthwhile to clarify that our archetype hull ranking approach differs from the ranking approach proposed in [3 1] in the sense that our aim is to solve rank scores (r) on  much fewer archetypes while the latter directly solves full rank scores (f) on entire training samples. [sent-312, score-1.771]
</p><p>53 The flowchart of obtaining the proposed face similarity measure. [sent-330, score-0.212]
</p><p>54 In detail, we divide each face image into a fixed number of blocks, then extract low-level features from each block, and seek archetypes in block-level feature spaces by applying Algorithm 1. [sent-332, score-0.779]
</p><p>55 In this section, we propose to tackle face recognition and verification together using the archetype hull ranking approach proposed in Section 4. [sent-333, score-1.177]
</p><p>56 First, we acquire a blockwise face similarity measure through harnessing the results of the archetype hull ranking in an unsupervised or supervised manner. [sent-334, score-1.403]
</p><p>57 Then, we achieve a holistic face similarity  measure by integrating blockwise similarity measurements with equal or learned importance weights. [sent-335, score-0.448]
</p><p>58 The flowchart of our face modeling approach is plotted in Fig. [sent-336, score-0.166]
</p><p>59 1  Unsupervised Approaches  Here we present two approaches for attaining blockwise similarity measures. [sent-342, score-0.167]
</p><p>60 Given any pair of feature vectors (q1, q2) at the k-th block position in face images, the baseline similarity measure is formulated as  Sbkasic(q1,  q2)  = z? [sent-345, score-0.244]
</p><p>61 The baseline measure merely takes advantage of archetype hull projection, and essentially takes the intersection between the resulting sparse coefficient vectors z(q1) , z(q2) as the similarity. [sent-348, score-0.889]
</p><p>62 By virtue of archetype hull ranking, we herewith obtain two rank vectors rα (q1) , rα (q2) which can capture the more reliable relevancy between q1, q2 and the archetypes in Uk. [sent-349, score-1.566]
</p><p>63 between q1 and q2’s relevant archetypes disclosed by the archetype hull ranking with respect to the queries q1 and q2. [sent-367, score-1.582]
</p><p>64 2  Supervised Approaches  Now we intend to leverage the label information of the training set Xk as well as the archetypes in Uk. [sent-370, score-0.675]
</p><p>65 Like the previous hsuicbhse ccotirornes, we propose atwrcoh supervised approaches which access the label matrix H in yielding blockwise similarity measures. [sent-392, score-0.241]
</p><p>66 For any sample q, the archetype hull projection results in the convex reconstruction scheme q ≈ Uz(q), rweshiuclhts mi no ttihveat ceosn us t roe cmonaksetr uthctei assumption t h≈at Usuzc(hq a  scheme is preserved in the label space. [sent-394, score-0.926]
</p><p>67 (13) offers a semantic similarity measure, we try to discover a more discriminative semantic similarity measure by controlling the archetype hull ranking. [sent-405, score-1.003]
</p><p>68 ) T, we can refine q’s relevant archetypes and thereby re-estimate the label vector of q as  RR˜(αq  Yˆα(q) =? [sent-426, score-0.64]
</p><p>69 (16) implies that wit⎣h the ⎦optimal param⎣eter α∗, the⎦ archetype hull ranking yields the discriminative semantic similarity measure in eq. [sent-451, score-1.036]
</p><p>70 bk=1Skb(qk1,qk2),  (17)  ×  where the blockwise similarity measure Sk (, ) can be the two unsupervised measures in eqs. [sent-457, score-0.223]
</p><p>71 k2/n2) (λ > 0) to achieve the holistic face similarity measure as  ? [sent-472, score-0.238]
</p><p>72 Experiments We conduct experiments on three widely used benchmark face databases Multi-PIE [7], Pubfig83 [20], and LFW [9]. [sent-488, score-0.19]
</p><p>73 The face recognition experiments on Multi-PIE and Pubfig83 are conducted under a gallery-query recognition mode. [sent-489, score-0.188]
</p><p>74 For the face verification experiments on LFW, we follow the unsupervised protocol of the LFW benchmark for evaluations. [sent-490, score-0.248]
</p><p>75 For all datasets, each face image is divided into 8 10 blocks, and a 59-dimensional uniform LBP [1] i sn teoxt 8ra ×ct e1d0 f brloomck esa,c ahn bdlo ac 5k9 as ifmaceinals ifoenaatulr uens. [sent-491, score-0.152]
</p><p>76 i oWrem apply t[h1e]  two proposed supervised approaches (called as “supervised basic AHR” and “supervised AHR”) for face recognition, and the two proposed unsupervised approaches (called as “unsupervised basic AHR” and “unsupervised AHR”) for face verification, respectively. [sent-492, score-0.385]
</p><p>77 We first study the influences of different types of archetypes on the face recognition accuracy achieved by our proposed “supervised basic AHR” and “supervised AHR”. [sent-496, score-0.797]
</p><p>78 This group of experimental results demonstrate that the archetype seeking algorithm always produces the archetypes of the best quality, which lead to the highest recognition accuracy for both “supervised basic AHR” and “supervised AHR”. [sent-498, score-1.302]
</p><p>79 The number of archetypes m is also an important factor to affecting the recognition/verification performance. [sent-500, score-0.627]
</p><p>80 To shed light on the effect of varying m, we conduct recognition and verification experiments with varying m and show the corresponding results in Figs. [sent-501, score-0.108]
</p><p>81 Comparison of different types of archetypes on the MultiPIE dataset. [sent-505, score-0.627]
</p><p>82 We conduct face recognition experiments on the Multi-PIE and Pubfig83 datasets. [sent-526, score-0.184]
</p><p>83 All face images are uniformly aligned according to an affine transform. [sent-527, score-0.152]
</p><p>84 The recognition accuracy achieved by our approaches with varying archetype proportions m/n on the Multi-PIE and Pubfig83 datasets. [sent-536, score-0.646]
</p><p>85 The verification accuracy achieved by our approaches with a varying number m of archetypes on the LFW dataset. [sent-539, score-0.691]
</p><p>86 The ROC curves of face verification approaches with the standard unsupervised LFW protocol. [sent-548, score-0.236]
</p><p>87 Conclusions In this paper, the geometric archetype hull model is leveraged into face modeling. [sent-553, score-1.017]
</p><p>88 Based on a scalable graph characterized by a compact set of archetypes, we propose an archetype-driven ranking framework that can scale up to massive datasets. [sent-554, score-0.178]
</p><p>89 This framework generates a rank vector over the archetype hull, which well captures the relevance between any query and the archetypes. [sent-555, score-0.687]
</p><p>90 The archetype hull ranking is then carried out on each block of face images, leading to a blockwise face similarity measure. [sent-556, score-1.448]
</p><p>91 By integrating blockwise similarity measurements with learned importance weights, a sensible face similarity measure is eventually yielded. [sent-557, score-0.453]
</p><p>92 The performance of the face similarity measure is corroborated through recognition and verification experiments performed on three benchmark face databases. [sent-558, score-0.456]
</p><p>93 Face description with local binary patterns: Application to face recognition. [sent-567, score-0.152]
</p><p>94 Efficient  processing  of mrfs  592 for unconstrained-  [3]  [4] [5] [6] [7] [8] [9]  [10] [11] [12]  [13] [14] [15] [16] [17]  [18] [19]  pose face recognition. [sent-573, score-0.152]
</p><p>95 Labeled faces in the wild: A database for studying face recognition in unconstrained environments. [sent-629, score-0.197]
</p><p>96 Noise resistant graph ranking for improved web image search. [sent-676, score-0.116]
</p><p>97 Null space approach of fisher discriminant analysis for face recognition. [sent-692, score-0.152]
</p><p>98 Scaling up biologically-inspired computer vision: A case study in unconstrained face recognition on facebook. [sent-710, score-0.183]
</p><p>99 Yes we can: simplex volume maximization for descriptive web-scale matrix factorization. [sent-733, score-0.098]
</p><p>100 Effective unconstrained face recognition by combining multiple descriptors and learned background statistics. [sent-761, score-0.183]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('archetypes', 0.627), ('archetype', 0.616), ('hull', 0.249), ('ahr', 0.194), ('face', 0.152), ('blockwise', 0.121), ('ranking', 0.09), ('lfw', 0.077), ('simplex', 0.061), ('verification', 0.052), ('supervised', 0.049), ('anchor', 0.046), ('uk', 0.046), ('similarity', 0.046), ('archetypal', 0.046), ('skahr', 0.046), ('seeking', 0.041), ('rank', 0.038), ('massive', 0.034), ('convex', 0.033), ('unsupervised', 0.032), ('yy', 0.03), ('xi', 0.029), ('scalable', 0.028), ('lbp', 0.027), ('eigenfaces', 0.026), ('uz', 0.026), ('persons', 0.026), ('graph', 0.026), ('encloses', 0.025), ('xk', 0.025), ('uj', 0.024), ('acquire', 0.024), ('measure', 0.024), ('training', 0.023), ('exemplars', 0.023), ('lark', 0.023), ('sbkasic', 0.023), ('usim', 0.023), ('block', 0.022), ('encompasses', 0.022), ('fisherfaces', 0.022), ('sensible', 0.021), ('di', 0.021), ('relevancy', 0.02), ('volume', 0.019), ('recognition', 0.018), ('relevance', 0.018), ('manifold', 0.018), ('maximization', 0.018), ('marketing', 0.018), ('tpami', 0.017), ('cuhk', 0.017), ('zr', 0.017), ('affinity', 0.016), ('rj', 0.016), ('holistic', 0.016), ('virtue', 0.016), ('rn', 0.016), ('integrating', 0.015), ('produced', 0.015), ('measurements', 0.015), ('query', 0.015), ('sample', 0.015), ('hh', 0.015), ('subspace', 0.014), ('conduct', 0.014), ('rr', 0.014), ('stored', 0.014), ('faces', 0.014), ('expressions', 0.014), ('liu', 0.014), ('correlate', 0.014), ('flowchart', 0.014), ('refers', 0.014), ('hong', 0.013), ('label', 0.013), ('accomplish', 0.013), ('jm', 0.013), ('laplacian', 0.013), ('importance', 0.013), ('kong', 0.013), ('gallery', 0.013), ('unconstrained', 0.013), ('xiong', 0.013), ('intend', 0.012), ('benchmark', 0.012), ('varying', 0.012), ('psychology', 0.012), ('zj', 0.012), ('yielding', 0.012), ('blocks', 0.012), ('distinctive', 0.012), ('databases', 0.012), ('accommodate', 0.012), ('thee', 0.011), ('bk', 0.011), ('semantic', 0.011), ('facial', 0.011), ('rm', 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="154-tfidf-1" href="./iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking.html">154 iccv-2013-Face Recognition via Archetype Hull Ranking</a></p>
<p>Author: Yuanjun Xiong, Wei Liu, Deli Zhao, Xiaoou Tang</p><p>Abstract: The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat- ing its performance superior to the state-of-the-arts.</p><p>2 0.10243884 <a title="154-tfidf-2" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>Author: Qiong Cao, Yiming Ying, Peng Li</p><p>Abstract: Recently, there is a considerable amount of efforts devoted to the problem of unconstrained face verification, where the task is to predict whether pairs of images are from the same person or not. This problem is challenging and difficult due to the large variations in face images. In this paper, we develop a novel regularization framework to learn similarity metrics for unconstrained face verification. We formulate its objective function by incorporating the robustness to the large intra-personal variations and the discriminative power of novel similarity metrics. In addition, our formulation is a convex optimization problem which guarantees the existence of its global solution. Experiments show that our proposed method achieves the state-of-the-art results on the challenging Labeled Faces in the Wild (LFW) database [10].</p><p>3 0.093865998 <a title="154-tfidf-3" href="./iccv-2013-From_Point_to_Set%3A_Extend_the_Learning_of_Distance_Metrics.html">177 iccv-2013-From Point to Set: Extend the Learning of Distance Metrics</a></p>
<p>Author: Pengfei Zhu, Lei Zhang, Wangmeng Zuo, David Zhang</p><p>Abstract: Most of the current metric learning methods are proposed for point-to-point distance (PPD) based classification. In many computer vision tasks, however, we need to measure the point-to-set distance (PSD) and even set-to-set distance (SSD) for classification. In this paper, we extend the PPD based Mahalanobis distance metric learning to PSD and SSD based ones, namely point-to-set distance metric learning (PSDML) and set-to-set distance metric learning (SSDML), and solve them under a unified optimization framework. First, we generate positive and negative sample pairs by computing the PSD and SSD between training samples. Then, we characterize each sample pair by its covariance matrix, and propose a covariance kernel based discriminative function. Finally, we tackle the PSDML and SSDMLproblems by using standard support vector machine solvers, making the metric learning very efficient for multiclass visual classification tasks. Experiments on gender classification, digit recognition, object categorization and face recognition show that the proposed metric learning methods can effectively enhance the performance of PSD and SSD based classification.</p><p>4 0.089067474 <a title="154-tfidf-4" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>Author: Yizhe Zhang, Ming Shao, Edward K. Wong, Yun Fu</p><p>Abstract: One of the most challenging task in face recognition is to identify people with varied poses. Namely, the test faces have significantly different poses compared with the registered faces. In this paper, we propose a high-level feature learning scheme to extract pose-invariant identity feature for face recognition. First, we build a single-hiddenlayer neural network with sparse constraint, to extractposeinvariant feature in a supervised fashion. Second, we further enhance the discriminative capability of the proposed feature by using multiple random faces as the target values for multiple encoders. By enforcing the target values to be uniquefor inputfaces over differentposes, the learned highlevel feature that is represented by the neurons in the hidden layer is pose free and only relevant to the identity information. Finally, we conduct face identification on CMU MultiPIE, and verification on Labeled Faces in the Wild (LFW) databases, where identification rank-1 accuracy and face verification accuracy with ROC curve are reported. These experiments demonstrate that our model is superior to oth- er state-of-the-art approaches on handling pose variations.</p><p>5 0.079614654 <a title="154-tfidf-5" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>Author: Yu-Tseh Chi, Mohsen Ali, Muhammad Rushdi, Jeffrey Ho</p><p>Abstract: This paper proposes a novel approach for sparse coding that further improves upon the sparse representation-based classification (SRC) framework. The proposed framework, Affine-Constrained Group Sparse Coding (ACGSC), extends the current SRC framework to classification problems with multiple input samples. Geometrically, the affineconstrained group sparse coding essentially searches for the vector in the convex hull spanned by the input vectors that can best be sparse coded using the given dictionary. The resulting objectivefunction is still convex and can be efficiently optimized using iterative block-coordinate descent scheme that is guaranteed to converge. Furthermore, we provide a form of sparse recovery result that guarantees, at least theoretically, that the classification performance of the constrained group sparse coding should be at least as good as the group sparse coding. We have evaluated the proposed approach using three different recognition experiments that involve illumination variation of faces and textures, and face recognition under occlusions. Prelimi- nary experiments have demonstrated the effectiveness of the proposed approach, and in particular, the results from the recognition/occlusion experiment are surprisingly accurate and robust.</p><p>6 0.079001524 <a title="154-tfidf-6" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>7 0.072039694 <a title="154-tfidf-7" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>8 0.068624012 <a title="154-tfidf-8" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<p>9 0.067274369 <a title="154-tfidf-9" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>10 0.063812345 <a title="154-tfidf-10" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>11 0.061544143 <a title="154-tfidf-11" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>12 0.060273033 <a title="154-tfidf-12" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>13 0.056988172 <a title="154-tfidf-13" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>14 0.056075767 <a title="154-tfidf-14" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>15 0.05452092 <a title="154-tfidf-15" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>16 0.054086749 <a title="154-tfidf-16" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>17 0.053749189 <a title="154-tfidf-17" href="./iccv-2013-Visual_Reranking_through_Weakly_Supervised_Multi-graph_Learning.html">445 iccv-2013-Visual Reranking through Weakly Supervised Multi-graph Learning</a></p>
<p>18 0.053579867 <a title="154-tfidf-18" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>19 0.053502705 <a title="154-tfidf-19" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>20 0.049151137 <a title="154-tfidf-20" href="./iccv-2013-Cascaded_Shape_Space_Pruning_for_Robust_Facial_Landmark_Detection.html">70 iccv-2013-Cascaded Shape Space Pruning for Robust Facial Landmark Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.089), (1, 0.029), (2, -0.055), (3, -0.065), (4, -0.031), (5, -0.015), (6, 0.106), (7, 0.05), (8, 0.009), (9, -0.0), (10, -0.014), (11, 0.023), (12, 0.015), (13, 0.003), (14, -0.006), (15, -0.004), (16, -0.024), (17, -0.015), (18, -0.012), (19, 0.002), (20, -0.02), (21, -0.054), (22, 0.009), (23, -0.069), (24, 0.026), (25, 0.057), (26, 0.014), (27, 0.018), (28, 0.012), (29, 0.073), (30, 0.016), (31, -0.036), (32, -0.022), (33, -0.014), (34, -0.006), (35, -0.023), (36, -0.011), (37, -0.009), (38, -0.005), (39, -0.034), (40, 0.025), (41, -0.033), (42, 0.012), (43, 0.001), (44, 0.014), (45, -0.012), (46, 0.022), (47, 0.014), (48, -0.053), (49, -0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9392159 <a title="154-lsi-1" href="./iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking.html">154 iccv-2013-Face Recognition via Archetype Hull Ranking</a></p>
<p>Author: Yuanjun Xiong, Wei Liu, Deli Zhao, Xiaoou Tang</p><p>Abstract: The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat- ing its performance superior to the state-of-the-arts.</p><p>2 0.85210758 <a title="154-lsi-2" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>Author: Dihong Gong, Zhifeng Li, Dahua Lin, Jianzhuang Liu, Xiaoou Tang</p><p>Abstract: Age invariant face recognition has received increasing attention due to its great potential in real world applications. In spite of the great progress in face recognition techniques, reliably recognizingfaces across ages remains a difficult task. The facial appearance of a person changes substantially over time, resulting in significant intra-class variations. Hence, the key to tackle this problem is to separate the variation caused by aging from the person-specific features that are stable. Specifically, we propose a new method, calledHidden FactorAnalysis (HFA). This methodcaptures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process. Then, the observed appearance can be modeled as a combination of the components generated based on these factors. We also develop a learning algorithm that jointly estimates the latent factors and the model parameters using an EM procedure. Extensive experiments on two well-known public domain face aging datasets: MORPH (the largest public face aging database) and FGNET, clearly show that the proposed method achieves notable improvement over state-of-the-art algorithms.</p><p>3 0.81665891 <a title="154-lsi-3" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>Author: Qiong Cao, Yiming Ying, Peng Li</p><p>Abstract: Recently, there is a considerable amount of efforts devoted to the problem of unconstrained face verification, where the task is to predict whether pairs of images are from the same person or not. This problem is challenging and difficult due to the large variations in face images. In this paper, we develop a novel regularization framework to learn similarity metrics for unconstrained face verification. We formulate its objective function by incorporating the robustness to the large intra-personal variations and the discriminative power of novel similarity metrics. In addition, our formulation is a convex optimization problem which guarantees the existence of its global solution. Experiments show that our proposed method achieves the state-of-the-art results on the challenging Labeled Faces in the Wild (LFW) database [10].</p><p>4 0.79645288 <a title="154-lsi-4" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>Author: Yizhe Zhang, Ming Shao, Edward K. Wong, Yun Fu</p><p>Abstract: One of the most challenging task in face recognition is to identify people with varied poses. Namely, the test faces have significantly different poses compared with the registered faces. In this paper, we propose a high-level feature learning scheme to extract pose-invariant identity feature for face recognition. First, we build a single-hiddenlayer neural network with sparse constraint, to extractposeinvariant feature in a supervised fashion. Second, we further enhance the discriminative capability of the proposed feature by using multiple random faces as the target values for multiple encoders. By enforcing the target values to be uniquefor inputfaces over differentposes, the learned highlevel feature that is represented by the neurons in the hidden layer is pose free and only relevant to the identity information. Finally, we conduct face identification on CMU MultiPIE, and verification on Labeled Faces in the Wild (LFW) databases, where identification rank-1 accuracy and face verification accuracy with ROC curve are reported. These experiments demonstrate that our model is superior to oth- er state-of-the-art approaches on handling pose variations.</p><p>5 0.79593992 <a title="154-lsi-5" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>Author: Oren Barkan, Jonathan Weill, Lior Wolf, Hagai Aronowitz</p><p>Abstract: This paper advances descriptor-based face recognition by suggesting a novel usage of descriptors to form an over-complete representation, and by proposing a new metric learning pipeline within the same/not-same framework. First, the Over-Complete Local Binary Patterns (OCLBP) face representation scheme is introduced as a multi-scale modified version of the Local Binary Patterns (LBP) scheme. Second, we propose an efficient matrix-vector multiplication-based recognition system. The system is based on Linear Discriminant Analysis (LDA) coupled with Within Class Covariance Normalization (WCCN). This is further extended to the unsupervised case by proposing an unsupervised variant of WCCN. Lastly, we introduce Diffusion Maps (DM) for non-linear dimensionality reduction as an alternative to the Whitened Principal Component Analysis (WPCA) method which is often used in face recognition. We evaluate the proposed framework on the LFW face recognition dataset under the restricted, unrestricted and unsupervised protocols. In all three cases we achieve very competitive results.</p><p>6 0.78179413 <a title="154-lsi-6" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>7 0.77818382 <a title="154-lsi-7" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>8 0.7737543 <a title="154-lsi-8" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>9 0.76162148 <a title="154-lsi-9" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<p>10 0.70963579 <a title="154-lsi-10" href="./iccv-2013-Modifying_the_Memorability_of_Face_Photographs.html">272 iccv-2013-Modifying the Memorability of Face Photographs</a></p>
<p>11 0.70765662 <a title="154-lsi-11" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>12 0.69720638 <a title="154-lsi-12" href="./iccv-2013-Markov_Network-Based_Unified_Classifier_for_Face_Identification.html">261 iccv-2013-Markov Network-Based Unified Classifier for Face Identification</a></p>
<p>13 0.69452477 <a title="154-lsi-13" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>14 0.65851682 <a title="154-lsi-14" href="./iccv-2013-Sparse_Variation_Dictionary_Learning_for_Face_Recognition_with_a_Single_Training_Sample_per_Person.html">398 iccv-2013-Sparse Variation Dictionary Learning for Face Recognition with a Single Training Sample per Person</a></p>
<p>15 0.64717406 <a title="154-lsi-15" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>16 0.61207294 <a title="154-lsi-16" href="./iccv-2013-Simultaneous_Clustering_and_Tracklet_Linking_for_Multi-face_Tracking_in_Videos.html">393 iccv-2013-Simultaneous Clustering and Tracklet Linking for Multi-face Tracking in Videos</a></p>
<p>17 0.60883093 <a title="154-lsi-17" href="./iccv-2013-Complex_3D_General_Object_Reconstruction_from_Line_Drawings.html">84 iccv-2013-Complex 3D General Object Reconstruction from Line Drawings</a></p>
<p>18 0.57805979 <a title="154-lsi-18" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>19 0.56891423 <a title="154-lsi-19" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>20 0.55965453 <a title="154-lsi-20" href="./iccv-2013-From_Point_to_Set%3A_Extend_the_Learning_of_Distance_Metrics.html">177 iccv-2013-From Point to Set: Extend the Learning of Distance Metrics</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.058), (4, 0.017), (7, 0.022), (12, 0.018), (13, 0.012), (26, 0.056), (31, 0.03), (40, 0.023), (42, 0.131), (48, 0.017), (64, 0.043), (73, 0.02), (77, 0.011), (78, 0.019), (80, 0.26), (89, 0.11), (98, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75447154 <a title="154-lda-1" href="./iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking.html">154 iccv-2013-Face Recognition via Archetype Hull Ranking</a></p>
<p>Author: Yuanjun Xiong, Wei Liu, Deli Zhao, Xiaoou Tang</p><p>Abstract: The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat- ing its performance superior to the state-of-the-arts.</p><p>2 0.68563384 <a title="154-lda-2" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>3 0.62633193 <a title="154-lda-3" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>Author: Weixin Li, Qian Yu, Ajay Divakaran, Nuno Vasconcelos</p><p>Abstract: The problem of adaptively selecting pooling regions for the classification of complex video events is considered. Complex events are defined as events composed of several characteristic behaviors, whose temporal configuration can change from sequence to sequence. A dynamic pooling operator is defined so as to enable a unified solution to the problems of event specific video segmentation, temporal structure modeling, and event detection. Video is decomposed into segments, and the segments most informative for detecting a given event are identified, so as to dynamically determine the pooling operator most suited for each sequence. This dynamic pooling is implemented by treating the locations of characteristic segments as hidden information, which is inferred, on a sequence-by-sequence basis, via a large-margin classification rule with latent variables. Although the feasible set of segment selections is combinatorial, it is shown that a globally optimal solution to the inference problem can be obtained efficiently, through the solution of a series of linear programs. Besides the coarselevel location of segments, a finer model of video struc- ture is implemented by jointly pooling features of segmenttuples. Experimental evaluation demonstrates that the re- sulting event detector has state-of-the-art performance on challenging video datasets.</p><p>4 0.62294334 <a title="154-lda-4" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>Author: Chenglong Bao, Jian-Feng Cai, Hui Ji</p><p>Abstract: In recent years, how to learn a dictionary from input images for sparse modelling has been one very active topic in image processing and recognition. Most existing dictionary learning methods consider an over-complete dictionary, e.g. the K-SVD method. Often they require solving some minimization problem that is very challenging in terms of computational feasibility and efficiency. However, if the correlations among dictionary atoms are not well constrained, the redundancy of the dictionary does not necessarily improve the performance of sparse coding. This paper proposed a fast orthogonal dictionary learning method for sparse image representation. With comparable performance on several image restoration tasks, the proposed method is much more computationally efficient than the over-complete dictionary based learning methods.</p><p>5 0.61259186 <a title="154-lda-5" href="./iccv-2013-Multiview_Photometric_Stereo_Using_Planar_Mesh_Parameterization.html">284 iccv-2013-Multiview Photometric Stereo Using Planar Mesh Parameterization</a></p>
<p>Author: Jaesik Park, Sudipta N. Sinha, Yasuyuki Matsushita, Yu-Wing Tai, In So Kweon</p><p>Abstract: We propose a method for accurate 3D shape reconstruction using uncalibrated multiview photometric stereo. A coarse mesh reconstructed using multiview stereo is first parameterized using a planar mesh parameterization technique. Subsequently, multiview photometric stereo is performed in the 2D parameter domain of the mesh, where all geometric and photometric cues from multiple images can be treated uniformly. Unlike traditional methods, there is no need for merging view-dependent surface normal maps. Our key contribution is a new photometric stereo based mesh refinement technique that can efficiently reconstruct meshes with extremely fine geometric details by directly estimating a displacement texture map in the 2D parameter domain. We demonstrate that intricate surface geometry can be reconstructed using several challenging datasets containing surfaces with specular reflections, multiple albedos and complex topologies.</p><p>6 0.59345704 <a title="154-lda-6" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>7 0.59008271 <a title="154-lda-7" href="./iccv-2013-Attribute_Pivots_for_Guiding_Relevance_Feedback_in_Image_Search.html">54 iccv-2013-Attribute Pivots for Guiding Relevance Feedback in Image Search</a></p>
<p>8 0.58923709 <a title="154-lda-8" href="./iccv-2013-Sparse_Variation_Dictionary_Learning_for_Face_Recognition_with_a_Single_Training_Sample_per_Person.html">398 iccv-2013-Sparse Variation Dictionary Learning for Face Recognition with a Single Training Sample per Person</a></p>
<p>9 0.58760649 <a title="154-lda-9" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>10 0.58751774 <a title="154-lda-10" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>11 0.58634436 <a title="154-lda-11" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>12 0.58588654 <a title="154-lda-12" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>13 0.58587241 <a title="154-lda-13" href="./iccv-2013-Domain_Transfer_Support_Vector_Ranking_for_Person_Re-identification_without_Target_Camera_Label_Information.html">124 iccv-2013-Domain Transfer Support Vector Ranking for Person Re-identification without Target Camera Label Information</a></p>
<p>14 0.58548141 <a title="154-lda-14" href="./iccv-2013-Attribute_Adaptation_for_Personalized_Image_Search.html">52 iccv-2013-Attribute Adaptation for Personalized Image Search</a></p>
<p>15 0.58536565 <a title="154-lda-15" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>16 0.58473909 <a title="154-lda-16" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>17 0.58470637 <a title="154-lda-17" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>18 0.58431691 <a title="154-lda-18" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>19 0.58387935 <a title="154-lda-19" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>20 0.5833953 <a title="154-lda-20" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
