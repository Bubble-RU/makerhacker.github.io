<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-15" href="#">iccv2013-15</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</h1>
<br/><p>Source: <a title="iccv-2013-15-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Chen_A_Generalized_Low-Rank_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yi-Lei Chen, Chiou-Ting Hsu</p><p>Abstract: In this paper, we propose a novel low-rank appearance model for removing rain streaks. Different from previous work, our method needs neither rain pixel detection nor time-consuming dictionary learning stage. Instead, as rain streaks usually reveal similar and repeated patterns on imaging scene, we propose and generalize a low-rank model from matrix to tensor structure in order to capture the spatio-temporally correlated rain streaks. With the appearance model, we thus remove rain streaks from image/video (and also other high-order image structure) in a unified way. Our experimental results demonstrate competitive (or even better) visual quality and efficient run-time in comparison with state of the art.</p><p>Reference: <a title="iccv-2013-15-reference" href="../iccv2013_reference/iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com Abstract In this paper, we propose a novel low-rank appearance model for removing rain streaks. [sent-2, score-0.884]
</p><p>2 Different from previous work, our method needs neither rain pixel detection nor time-consuming dictionary learning stage. [sent-3, score-0.892]
</p><p>3 Instead, as rain streaks usually reveal similar and repeated patterns on imaging scene, we propose and generalize a low-rank model from matrix to tensor structure in order to capture the spatio-temporally correlated rain streaks. [sent-4, score-2.227]
</p><p>4 With the appearance model, we thus remove rain streaks from image/video (and also other high-order image structure) in a unified way. [sent-5, score-1.25]
</p><p>5 dehazing), rain removal might be the most challenging one because raindrops usually lead to dense streaks with unpredictable behaviors (e. [sent-11, score-1.399]
</p><p>6 Since these dense streaks introduce additional gradients and would hinder the detection of reliable features, rain removal is indeed crucial and indispensible for in-depth image analysis. [sent-14, score-1.342]
</p><p>7 al [1-4] first devoted to build the appearance model of rain streak and propose to detect rain pixels in video. [sent-16, score-1.953]
</p><p>8 As pointed out in [1], falling raindrops produce rain streaks with properties in both rain appearance and dynamic motion. [sent-17, score-2.19]
</p><p>9 The chromaticity [5] and shape [6] of rain streaks were also considered in other research. [sent-18, score-1.234]
</p><p>10 al [7] adopted frequency domain analysis to model rain and snow, and Bossu et. [sent-20, score-0.88]
</p><p>11 al [8] utilized histogram of orientation to detect rain or snow streaks. [sent-21, score-0.915]
</p><p>12 tw  Considering rain removal on one single frame, Kang et. [sent-31, score-0.967]
</p><p>13 al [9] proposed an image decomposition-based method to remove rain streaks without referring to temporal features. [sent-32, score-1.248]
</p><p>14 They first removed low-frequency content of raining images, and then self-learned two dictionaries followed by sparse coding to decompose one image patch into rain streak and high-frequency content. [sent-33, score-1.181]
</p><p>15 Recently, a guided-image-filter (GIF) based method [10] was proposed for rain removal on one single color image. [sent-36, score-0.977]
</p><p>16 Since the proposed non-rain prior only roughly captures the  image content, removal of large raindrops would also over-smooth the edges and textures. [sent-38, score-0.155]
</p><p>17 Different from existing methods, in this paper, we propose a novel low-rank rain appearance model on 2-D images, and generalize our model to high-order image structure (e. [sent-40, score-0.908]
</p><p>18 Based on this model, we then propose to decompose the corrupted input into rain streak component, rain-free component, and imaging noise. [sent-44, score-1.105]
</p><p>19 , rain detection, subtraction of low frequency content) which may causes other side effects, and also needs no dictionary learning because the low-rank model inherently captures the subspace spanned by rain 11996688  streak patterns. [sent-47, score-1.999]
</p><p>20 Inspired by [10], we also propose a GIF-based detail enhancement by reusing the estimated imaging noise. [sent-48, score-0.07]
</p><p>21 The experiments of image/video rain removal will show both the effectiveness and efficiency of our approach. [sent-49, score-0.967]
</p><p>22 1 to explain our motivation: a rainy scene usually contains similar patterns of rain streak in different local patches. [sent-53, score-1.116]
</p><p>23 With this observation, our goal is to model the patch dependency in an elegant way. [sent-54, score-0.05]
</p><p>24 In this paper, we assume this dependency is linear and propose to use  low-rank model to characterize the appearance of rain streaks. [sent-55, score-0.916]
</p><p>25 Although the success of low-rank property has been shown in modeling the image background [11] and noise-free [12] patches, no investigation for rain streak pattern has been studied. [sent-56, score-1.069]
</p><p>26 We will show that our generalization improves both the performance and applicability in image/video rain removal. [sent-62, score-0.868]
</p><p>27 Notations and tensor basics We summarize the notations used in this paper: lower case letters (? [sent-65, score-0.062]
</p><p>28 As to tensor operation, the mode-k unfolding of a tensor X? [sent-104, score-0.074]
</p><p>29 Appearance model of rain streaks We consider an image ? [sent-133, score-1.234]
</p><p>30 captured in a rainy scene as the addition of rain streaks ? [sent-134, score-1.259]
</p><p>31 S , (1) In equation (1), the key to successful factorization is to effectively characterize the rain streaks ? [sent-141, score-1.291]
</p><p>32 Instead of modeling the appearance of each raindrop, here we first give two observations on common rain streaks: i Rain streaks usually have similar directions in the same imaging environment. [sent-143, score-1.291]
</p><p>33 ii Raindrops, which fall at a nearly constant speed, reveal similar rain streaks for a period of time. [sent-144, score-1.234]
</p><p>34 The first observation indicates the similarity between rains streaks at different spatial locations, and the second implies the repeatability of rain streaks along time axis. [sent-146, score-1.621]
</p><p>35 Both  observations suggest high spatio-temporal correlation between rain streaks in a rainy scene. [sent-147, score-1.269]
</p><p>36 On the other hand, once the image is corrupted by rain streaks, their patch dependency would obviously increase because of those superposed rain streak patterns. [sent-151, score-2.002]
</p><p>37 This strong evidence verifies our observations in patch level. [sent-152, score-0.047]
</p><p>38 Therefore, we define a rain streak pattern as one local image patch and assume a bag of patches collected from image/video are linearly dependent. [sent-153, score-1.128]
</p><p>39 In this paper, we modify the patch map process [13] to capture the patch dependency. [sent-154, score-0.086]
</p><p>40 Different from [13], we further consider the patch structure across two non-overlapping patches and generalize this mapping to high order image structure: i P: ? [sent-198, score-0.083]
</p><p>41 Note that, our patch map function using overlapping patches may bring additive bias to the objective costs. [sent-235, score-0.069]
</p><p>42 Image/video rain removal Using the low-rank rain appearance model defined in section 2, we propose a generalized rain removal method. [sent-255, score-2.831]
</p><p>43 Finally, we propose a simple but effective rain removal method incorporating with an efficient detail enhancement in section 3. [sent-265, score-1.004]
</p><p>44 Rain streak estimation on 2-D images In section 2, we have proposed a low-rank model for the common appearance of rain streak pattern. [sent-269, score-1.286]
</p><p>45 Note that, although TV has been used to generate piecewise-smooth “cartoon” layer [14] of images, it tends to characterize edge-aware structure regardless of small-scale features (e. [sent-306, score-0.051]
</p><p>46 Instead, the role of TV regularization is to discriminate most of natural image content from highly-patterned rain streaks and thus facilitate the ill-posed factorization in equation (1). [sent-310, score-1.298]
</p><p>47 (5)  Equation (5) is an NP-hard rank minimization problem because the matrix rank is difficult to approximate. [sent-344, score-0.103]
</p><p>48 To make it tractable, most existing methods [11-13] used the tightest convex envelope of matrix rank - Schatten 1-norm, also called nuclear norm, to replace the rank function. [sent-345, score-0.124]
</p><p>49 1 could guarantee global optimum for convex problems, a recent study in [15] pointed out that the non-convex penalty ( 0 ? [sent-382, score-0.048]
</p><p>50 Following the update rule of IALM, we could obtain at least one global or  local optimum of equation (7) by ? [sent-568, score-0.079]
</p><p>51 (10)  To make equation (10) tractable, we could rewrite the noise term ? [sent-690, score-0.052]
</p><p>52 Recall that our proposed patch map function allows overlapping patches and hence there is a bias between the two objective costs. [sent-713, score-0.069]
</p><p>53 Using the generalized shrinkage operation [15], we have ? [sent-787, score-0.047]
</p><p>54 (16)  To demonstrate the effectiveness of our model, we give the estimated rain streaks of some 2-D raining images (released by [9]) in Fig. [sent-1042, score-1.295]
</p><p>55 The results show that our method accurately captures flexible rain streaks from heavy/light rains or with different directions. [sent-1044, score-1.255]
</p><p>56 In addition, almost no image content is mistakenly estimated as rain streaks. [sent-1045, score-0.906]
</p><p>57 The 1st row shows the original raining images and the 2nd row shows their rain streaks estimated by our method. [sent-1047, score-1.295]
</p><p>58 Rain streaks estimation on high-order images We generalize equation (5) into high-order images by replacing rank? [sent-1050, score-0.418]
</p><p>59 Thanks to the success of tensor trace norm recently developed in [21], we propose to extend the Schatten p-norm from matrix to tensor in our model. [sent-1103, score-0.099]
</p><p>60 , we replace the 2-D FFT operator in equation (15) by ? [sent-1407, score-0.048]
</p><p>61 Note that, although our proposed model inherently characterize the appearance of rain streaks with various image dimensions, similar image patches along time axis (especially captured by a static camera) may also exhibit low-rank structure and severely degrades the performance. [sent-1584, score-1.327]
</p><p>62 11997711  To avoid IR capturing image content, after the patch map process, we conduct random patch permutation on each 2-D image to alleviate the temporal consistency. [sent-1585, score-0.105]
</p><p>63 Rain streaks removal When using the rain-free image ? [sent-1588, score-0.465]
</p><p>64 S as our rain removal result, we observe that the noise layer also contains little image content or details. [sent-1589, score-1.015]
</p><p>65 (a) (b) (c) (d) Figure 4: Four synthetic raining images. [sent-1607, score-0.049]
</p><p>66 All images and video frames are resized into 256x256, and we empirically determine the patch size r as16 and the patch offset as 12 to balance the tradeoff between visual quality and efficiency. [sent-1610, score-0.088]
</p><p>67 Rain removal on monochromatic images We use four synthetic raining images (see Fig. [sent-1643, score-0.169]
</p><p>68 5 removes more rain streaks and achieves better visual quality. [sent-1655, score-1.248]
</p><p>69 The reason can  Figure 6: The estimated rank of rain streak patterns using p=1 and p=0. [sent-1656, score-1.139]
</p><p>70 6, where smaller p more significantly reduces the patch rank under similar average of magnitudes. [sent-1659, score-0.083]
</p><p>71 Since smaller p means a better approximation of matrix rank, it is superior to capture the underlying rain streak patterns and is also less sensitive to image content. [sent-1660, score-1.092]
</p><p>72 5 (k)), we also follow the same procedure to subtract the low-frequency part (bilateral filtering results of raining image) from our two rain-removed images. [sent-1662, score-0.049]
</p><p>73 When comparing  the rain streaks and HF content, we observe that [9] could preserve small-scale features very well but tends to lose edge structure similar to rain streak pattern (see the red rectangles). [sent-1666, score-2.337]
</p><p>74 Although our method may lose small-scale features, we could still use the proposed detail enhancement to compensate such information. [sent-1669, score-0.061]
</p><p>75 These results again verify our model in the ability of single-frame-based rain removal. [sent-1673, score-0.868]
</p><p>76 Rain removal on color images and videos  We use three video sequences, including the “heavy rain” released by [2], the “mag” released by [3], and the “forrest” released by [7], to evaluate our method. [sent-1687, score-0.216]
</p><p>77 As to the case of single color image, we pick one frame from “heavy rain” to  conduct rain removal, and also implement the GIF-based 11997722  3rd  4th  content (the column), and imaging noise (the column). [sent-1688, score-0.954]
</p><p>78 7 (b)-(c) and their estimated rain streaks in Fig. [sent-1694, score-1.246]
</p><p>79 Although we have fine-tuned the GIF parameters, [10] still obtains over-smooth result with inaccurate rain streaks because their proposed guidance image only estimates rough image content. [sent-1696, score-1.25]
</p><p>80 In contrast, our method removes rain streaks much accurately. [sent-1697, score-1.248]
</p><p>81 As to the case of video rain removal, all of the results could be found in our supplementary files. [sent-1698, score-0.896]
</p><p>82 Here we also show the same frame in the image-based case and its corresponding rain streaks in Fig. [sent-1699, score-1.246]
</p><p>83 Because now we further suppress the temporal gradients by  equation (17), the rain-free image (Fig. [sent-1701, score-0.052]
</p><p>84 7(d)) contains almost no rain streaks and achieves better visual quality in comparison with our image-based result (Fig. [sent-1702, score-1.234]
</p><p>85 The two-stage rain removal usually leads to flickering artifacts if rain pixels are not completely detected (please refer to our video results for comparison). [sent-1714, score-1.859]
</p><p>86 9, although our method removes more accurate “rain streak”, some of the large raindrops still remain. [sent-1718, score-0.07]
</p><p>87 However, this result is expected because our goal is to remove dense rain streaks instead of raindrops. [sent-1719, score-1.234]
</p><p>88 Finally, as pointed out in [5], raindrops bring similar changes for three color channels at different pixels. [sent-1720, score-0.082]
</p><p>89 We find that our rain streak layer is nearly monochromatic when conducting our method on the whole color image/video (see the video result “heavy rain”); i. [sent-1721, score-1.136]
</p><p>90 The run time of bilateral filtering and our rain removal on each image is about 1. [sent-1731, score-0.979]
</p><p>91 This result shows that our method is much more efficient than [9] in the single-frame-based rain removal and also achieves competitive or even better quality. [sent-1735, score-0.967]
</p><p>92 : first subtracting the temporally mean-filtered  (a) (b) (c)  Figure 10: (a) The rain dictionary ? [sent-1759, score-0.892]
</p><p>93 learned from “heavy rain”, and the estimated rain streaks (b) without ? [sent-1760, score-1.246]
</p><p>94 10 (c), indeed improves the estimated rain streak layer substantially. [sent-1766, score-1.103]
</p><p>95 Conclusion In this paper, we propose a generalized model, which utilizes the nice properties of low-rank pattern, for common rain streak appearance. [sent-1768, score-1.082]
</p><p>96 The proposed model characterizes the spatio-temporally correlated rain streaks, and thus could tackle both image and video rain removal. [sent-1769, score-1.79]
</p><p>97 Rain removal in videos by combining temporal and chromatic properties. [sent-1816, score-0.128]
</p><p>98 Using the shape characteristics of rain to identify and remove rain from video. [sent-1822, score-1.736]
</p><p>99 Removing rain and snow in as single image using guided filter. [sent-1862, score-0.934]
</p><p>100 The augmented lagrange multiplier method for exact recover of corrupted low-rank matrices. [sent-1915, score-0.049]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rain', 0.868), ('streaks', 0.366), ('streak', 0.201), ('removal', 0.099), ('ir', 0.059), ('raindrops', 0.056), ('raining', 0.049), ('tv', 0.048), ('snow', 0.047), ('rank', 0.046), ('fft', 0.043), ('gif', 0.042), ('schatten', 0.042), ('argmin', 0.041), ('equation', 0.038), ('patch', 0.037), ('tensor', 0.037), ('garg', 0.036), ('released', 0.031), ('ialm', 0.028), ('vif', 0.026), ('content', 0.026), ('rainy', 0.025), ('dictionary', 0.024), ('singular', 0.022), ('shrinkage', 0.022), ('patches', 0.022), ('rectangles', 0.022), ('layer', 0.022), ('bossu', 0.021), ('monochromatic', 0.021), ('rains', 0.021), ('imaging', 0.021), ('detail', 0.02), ('heavy', 0.019), ('guided', 0.019), ('characterize', 0.019), ('barnum', 0.019), ('mag', 0.019), ('optimum', 0.018), ('enlarged', 0.018), ('forrest', 0.017), ('hf', 0.017), ('enhancement', 0.017), ('conduct', 0.017), ('folding', 0.016), ('characterizes', 0.016), ('appearance', 0.016), ('inherently', 0.016), ('letters', 0.016), ('guidance', 0.016), ('pointed', 0.016), ('cartoon', 0.016), ('corrupted', 0.015), ('chromatic', 0.015), ('ncc', 0.015), ('could', 0.014), ('removes', 0.014), ('discriminability', 0.014), ('generalize', 0.014), ('bregman', 0.014), ('lagrange', 0.014), ('temporal', 0.014), ('trace', 0.014), ('video', 0.014), ('generalized', 0.013), ('dependency', 0.013), ('modify', 0.012), ('estimated', 0.012), ('frequency', 0.012), ('operation', 0.012), ('tip', 0.012), ('bilateral', 0.012), ('frame', 0.012), ('patterns', 0.012), ('accordingly', 0.011), ('matrix', 0.011), ('nuclear', 0.011), ('correlated', 0.01), ('svd', 0.01), ('structure', 0.01), ('lose', 0.01), ('kang', 0.01), ('multiplier', 0.01), ('severely', 0.01), ('replace', 0.01), ('observations', 0.01), ('augmented', 0.01), ('bias', 0.01), ('color', 0.01), ('usually', 0.01), ('spanned', 0.01), ('update', 0.009), ('basics', 0.009), ('calligraphic', 0.009), ('decompositionbased', 0.009), ('hautiere', 0.009), ('hinder', 0.009), ('lathauwer', 0.009), ('raindrop', 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="15-tfidf-1" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>Author: Yi-Lei Chen, Chiou-Ting Hsu</p><p>Abstract: In this paper, we propose a novel low-rank appearance model for removing rain streaks. Different from previous work, our method needs neither rain pixel detection nor time-consuming dictionary learning stage. Instead, as rain streaks usually reveal similar and repeated patterns on imaging scene, we propose and generalize a low-rank model from matrix to tensor structure in order to capture the spatio-temporally correlated rain streaks. With the appearance model, we thus remove rain streaks from image/video (and also other high-order image structure) in a unified way. Our experimental results demonstrate competitive (or even better) visual quality and efficient run-time in comparison with state of the art.</p><p>2 0.34796023 <a title="15-tfidf-2" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>Author: David Eigen, Dilip Krishnan, Rob Fergus</p><p>Abstract: Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle, or outdoor security cameras mounted inside a protective enclosure. At capture time, defocus can be used to remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the window. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We collect a dataset of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions.</p><p>3 0.039674267 <a title="15-tfidf-3" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>4 0.039272759 <a title="15-tfidf-4" href="./iccv-2013-Discriminant_Tracking_Using_Tensor_Representation_with_Semi-supervised_Improvement.html">119 iccv-2013-Discriminant Tracking Using Tensor Representation with Semi-supervised Improvement</a></p>
<p>Author: Jin Gao, Junliang Xing, Weiming Hu, Steve Maybank</p><p>Abstract: Visual tracking has witnessed growing methods in object representation, which is crucial to robust tracking. The dominant mechanism in object representation is using image features encoded in a vector as observations to perform tracking, without considering that an image is intrinsically a matrix, or a 2nd-order tensor. Thus approaches following this mechanism inevitably lose a lot of useful information, and therefore cannot fully exploit the spatial correlations within the 2D image ensembles. In this paper, we address an image as a 2nd-order tensor in its original form, and find a discriminative linear embedding space approximation to the original nonlinear submanifold embedded in the tensor space based on the graph embedding framework. We specially design two graphs for characterizing the intrinsic local geometrical structure of the tensor space, so as to retain more discriminant information when reducing the dimension along certain tensor dimensions. However, spatial correlations within a tensor are not limited to the elements along these dimensions. This means that some part of the discriminant information may not be encoded in the embedding space. We introduce a novel technique called semi-supervised improvement to iteratively adjust the embedding space to compensate for the loss of discriminant information, hence improving the performance of our tracker. Experimental results on challenging videos demonstrate the effectiveness and robustness of the proposed tracker.</p><p>5 0.035995476 <a title="15-tfidf-5" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>Author: Chenglong Bao, Jian-Feng Cai, Hui Ji</p><p>Abstract: In recent years, how to learn a dictionary from input images for sparse modelling has been one very active topic in image processing and recognition. Most existing dictionary learning methods consider an over-complete dictionary, e.g. the K-SVD method. Often they require solving some minimization problem that is very challenging in terms of computational feasibility and efficiency. However, if the correlations among dictionary atoms are not well constrained, the redundancy of the dictionary does not necessarily improve the performance of sparse coding. This paper proposed a fast orthogonal dictionary learning method for sparse image representation. With comparable performance on several image restoration tasks, the proposed method is much more computationally efficient than the over-complete dictionary based learning methods.</p><p>6 0.034243342 <a title="15-tfidf-6" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>7 0.033657216 <a title="15-tfidf-7" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>8 0.031246508 <a title="15-tfidf-8" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>9 0.027710941 <a title="15-tfidf-9" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>10 0.027177287 <a title="15-tfidf-10" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>11 0.025294576 <a title="15-tfidf-11" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>12 0.023798198 <a title="15-tfidf-12" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>13 0.023694152 <a title="15-tfidf-13" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>14 0.022513457 <a title="15-tfidf-14" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>15 0.021169046 <a title="15-tfidf-15" href="./iccv-2013-Exploiting_Reflection_Change_for_Automatic_Reflection_Removal.html">151 iccv-2013-Exploiting Reflection Change for Automatic Reflection Removal</a></p>
<p>16 0.021010967 <a title="15-tfidf-16" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>17 0.020036759 <a title="15-tfidf-17" href="./iccv-2013-Efficient_Image_Dehazing_with_Boundary_Constraint_and_Contextual_Regularization.html">135 iccv-2013-Efficient Image Dehazing with Boundary Constraint and Contextual Regularization</a></p>
<p>18 0.019581353 <a title="15-tfidf-18" href="./iccv-2013-Shape_Anchors_for_Data-Driven_Multi-view_Reconstruction.html">387 iccv-2013-Shape Anchors for Data-Driven Multi-view Reconstruction</a></p>
<p>19 0.019458966 <a title="15-tfidf-19" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>20 0.019267736 <a title="15-tfidf-20" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.056), (1, -0.006), (2, -0.015), (3, -0.009), (4, -0.037), (5, -0.009), (6, -0.006), (7, -0.004), (8, 0.004), (9, -0.018), (10, -0.004), (11, -0.017), (12, 0.009), (13, 0.01), (14, -0.028), (15, 0.012), (16, -0.008), (17, 0.006), (18, 0.02), (19, 0.043), (20, -0.01), (21, 0.007), (22, 0.003), (23, -0.029), (24, -0.058), (25, 0.028), (26, 0.03), (27, -0.061), (28, -0.03), (29, 0.007), (30, 0.008), (31, -0.011), (32, 0.061), (33, 0.071), (34, -0.01), (35, 0.044), (36, 0.029), (37, -0.029), (38, 0.107), (39, 0.019), (40, -0.142), (41, -0.035), (42, -0.025), (43, -0.082), (44, 0.066), (45, 0.085), (46, 0.05), (47, 0.081), (48, 0.068), (49, -0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90085602 <a title="15-lsi-1" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>Author: Yi-Lei Chen, Chiou-Ting Hsu</p><p>Abstract: In this paper, we propose a novel low-rank appearance model for removing rain streaks. Different from previous work, our method needs neither rain pixel detection nor time-consuming dictionary learning stage. Instead, as rain streaks usually reveal similar and repeated patterns on imaging scene, we propose and generalize a low-rank model from matrix to tensor structure in order to capture the spatio-temporally correlated rain streaks. With the appearance model, we thus remove rain streaks from image/video (and also other high-order image structure) in a unified way. Our experimental results demonstrate competitive (or even better) visual quality and efficient run-time in comparison with state of the art.</p><p>2 0.80160487 <a title="15-lsi-2" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>Author: David Eigen, Dilip Krishnan, Rob Fergus</p><p>Abstract: Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle, or outdoor security cameras mounted inside a protective enclosure. At capture time, defocus can be used to remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the window. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We collect a dataset of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions.</p><p>3 0.68820983 <a title="15-lsi-3" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>4 0.50506568 <a title="15-lsi-4" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>Author: Yaron Eshet, Simon Korman, Eyal Ofek, Shai Avidan</p><p>Abstract: We extend patch based methods to work on patches in 3D space. We start with Coherency Sensitive Hashing [12] (CSH), which is an algorithm for matching patches between two RGB images, and extend it to work with RGBD images. This is done by warping all 3D patches to a common virtual plane in which CSH is performed. To avoid noise due to warping of patches of various normals and depths, we estimate a group of dominant planes and compute CSH on each plane separately, before merging the matching patches. The result is DCSH - an algorithm that matches world (3D) patches in order to guide the search for image plane matches. An independent contribution is an extension of CSH, which we term Social-CSH. It allows a major speedup of the k nearest neighbor (kNN) version of CSH - its runtime growing linearly, rather than quadratically, in k. Social-CSH is used as a subcomponent of DCSH when many NNs are required, as in the case of image denoising. We show the benefits ofusing depth information to image reconstruction and image denoising, demonstrated on several RGBD images.</p><p>5 0.49426445 <a title="15-lsi-5" href="./iccv-2013-A_Learning-Based_Approach_to_Reduce_JPEG_Artifacts_in_Image_Matting.html">19 iccv-2013-A Learning-Based Approach to Reduce JPEG Artifacts in Image Matting</a></p>
<p>Author: Inchang Choi, Sunyeong Kim, Michael S. Brown, Yu-Wing Tai</p><p>Abstract: Single image matting techniques assume high-quality input images. The vast majority of images on the web and in personal photo collections are encoded using JPEG compression. JPEG images exhibit quantization artifacts that adversely affect the performance of matting algorithms. To address this situation, we propose a learning-based post-processing method to improve the alpha mattes extracted from JPEG images. Our approach learns a set of sparse dictionaries from training examples that are used to transfer details from high-quality alpha mattes to alpha mattes corrupted by JPEG compression. Three different dictionaries are defined to accommodate different object structure (long hair, short hair, and sharp boundaries). A back-projection criteria combined within an MRF framework is used to automatically select the best dictionary to apply on the object’s local boundary. We demonstrate that our method can produces superior results over existing state-of-the-art matting algorithms on a variety of inputs and compression levels.</p><p>6 0.48706704 <a title="15-lsi-6" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>7 0.48344421 <a title="15-lsi-7" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>8 0.43130025 <a title="15-lsi-8" href="./iccv-2013-Exploiting_Reflection_Change_for_Automatic_Reflection_Removal.html">151 iccv-2013-Exploiting Reflection Change for Automatic Reflection Removal</a></p>
<p>9 0.42492667 <a title="15-lsi-9" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>10 0.37828496 <a title="15-lsi-10" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>11 0.37716982 <a title="15-lsi-11" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>12 0.37389487 <a title="15-lsi-12" href="./iccv-2013-Motion-Aware_KNN_Laplacian_for_Video_Matting.html">275 iccv-2013-Motion-Aware KNN Laplacian for Video Matting</a></p>
<p>13 0.36867389 <a title="15-lsi-13" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>14 0.35386479 <a title="15-lsi-14" href="./iccv-2013-Pedestrian_Parsing_via_Deep_Decompositional_Network.html">311 iccv-2013-Pedestrian Parsing via Deep Decompositional Network</a></p>
<p>15 0.3464067 <a title="15-lsi-15" href="./iccv-2013-Shape_Anchors_for_Data-Driven_Multi-view_Reconstruction.html">387 iccv-2013-Shape Anchors for Data-Driven Multi-view Reconstruction</a></p>
<p>16 0.33851632 <a title="15-lsi-16" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>17 0.3214924 <a title="15-lsi-17" href="./iccv-2013-Matching_Dry_to_Wet_Materials.html">262 iccv-2013-Matching Dry to Wet Materials</a></p>
<p>18 0.31180403 <a title="15-lsi-18" href="./iccv-2013-Efficient_Image_Dehazing_with_Boundary_Constraint_and_Contextual_Regularization.html">135 iccv-2013-Efficient Image Dehazing with Boundary Constraint and Contextual Regularization</a></p>
<p>19 0.30581841 <a title="15-lsi-19" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>20 0.28737912 <a title="15-lsi-20" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.039), (7, 0.011), (23, 0.014), (26, 0.053), (27, 0.017), (31, 0.044), (35, 0.011), (42, 0.1), (48, 0.02), (64, 0.034), (73, 0.06), (89, 0.12), (90, 0.301), (98, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.68188953 <a title="15-lda-1" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>Author: Yi-Lei Chen, Chiou-Ting Hsu</p><p>Abstract: In this paper, we propose a novel low-rank appearance model for removing rain streaks. Different from previous work, our method needs neither rain pixel detection nor time-consuming dictionary learning stage. Instead, as rain streaks usually reveal similar and repeated patterns on imaging scene, we propose and generalize a low-rank model from matrix to tensor structure in order to capture the spatio-temporally correlated rain streaks. With the appearance model, we thus remove rain streaks from image/video (and also other high-order image structure) in a unified way. Our experimental results demonstrate competitive (or even better) visual quality and efficient run-time in comparison with state of the art.</p><p>2 0.58490986 <a title="15-lda-2" href="./iccv-2013-Real-Time_Body_Tracking_with_One_Depth_Camera_and_Inertial_Sensors.html">341 iccv-2013-Real-Time Body Tracking with One Depth Camera and Inertial Sensors</a></p>
<p>Author: Thomas Helten, Meinard Müller, Hans-Peter Seidel, Christian Theobalt</p><p>Abstract: In recent years, the availability of inexpensive depth cameras, such as the Microsoft Kinect, has boosted the research in monocular full body skeletal pose tracking. Unfortunately, existing trackers often fail to capture poses where a single camera provides insufficient data, such as non-frontal poses, and all other poses with body part occlusions. In this paper, we present a novel sensor fusion approach for real-time full body tracking that succeeds in such difficult situations. It takes inspiration from previous tracking solutions, and combines a generative tracker and a discriminative tracker retrieving closest poses in a database. In contrast to previous work, both trackers employ data from a low number of inexpensive body-worn inertial sensors. These sensors provide reliable and complementary information when the monocular depth information alone is not sufficient. We also contribute by new algorithmic solutions to best fuse depth and inertial data in both trackers. One is a new visibility model to determine global body pose, occlusions and usable depth correspondences and to decide what data modality to use for discriminative tracking. We also contribute with a new inertial-basedpose retrieval, and an adapted late fusion step to calculate the final body pose.</p><p>3 0.58307916 <a title="15-lda-3" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>Author: Emanuele Rodolà, Andrea Torsello, Tatsuya Harada, Yasuo Kuniyoshi, Daniel Cremers</p><p>Abstract: We consider a parametrized relaxation of the widely adopted quadratic assignment problem (QAP) formulation for minimum distortion correspondence between deformable shapes. In order to control the accuracy/sparsity trade-off we introduce a weighting parameter on the combination of two existing relaxations, namely spectral and game-theoretic. This leads to the introduction of the elastic net penalty function into shape matching problems. In combination with an efficient algorithm to project onto the elastic net ball, we obtain an approach for deformable shape matching with controllable sparsity. Experiments on a standard benchmark confirm the effectiveness of the approach.</p><p>4 0.57115579 <a title="15-lda-4" href="./iccv-2013-Robust_Subspace_Clustering_via_Half-Quadratic_Minimization.html">360 iccv-2013-Robust Subspace Clustering via Half-Quadratic Minimization</a></p>
<p>Author: Yingya Zhang, Zhenan Sun, Ran He, Tieniu Tan</p><p>Abstract: Subspace clustering has important and wide applications in computer vision and pattern recognition. It is a challenging task to learn low-dimensional subspace structures due to the possible errors (e.g., noise and corruptions) existing in high-dimensional data. Recent subspace clustering methods usually assume a sparse representation of corrupted errors and correct the errors iteratively. However large corruptions in real-world applications can not be well addressed by these methods. A novel optimization model for robust subspace clustering is proposed in this paper. The objective function of our model mainly includes two parts. The first part aims to achieve a sparse representation of each high-dimensional data point with other data points. The second part aims to maximize the correntropy between a given data point and its low-dimensional representation with other points. Correntropy is a robust measure so that the influence of large corruptions on subspace clustering can be greatly suppressed. An extension of our method with explicit introduction of representation error terms into the model is also proposed. Half-quadratic minimization is provided as an efficient solution to the proposed robust subspace clustering formulations. Experimental results on Hopkins 155 dataset and Extended Yale Database B demonstrate that our method outperforms state-of-the-art subspace clustering methods.</p><p>5 0.56574345 <a title="15-lda-5" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>Author: Hua Wang, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: Representing the raw input of a data set by a set of relevant codes is crucial to many computer vision applications. Due to the intrinsic sparse property of real-world data, dictionary learning, in which the linear decomposition of a data point uses a set of learned dictionary bases, i.e., codes, has demonstrated state-of-the-art performance. However, traditional dictionary learning methods suffer from three weaknesses: sensitivity to noisy and outlier samples, difficulty to determine the optimal dictionary size, and incapability to incorporate supervision information. In this paper, we address these weaknesses by learning a Semi-Supervised Robust Dictionary (SSR-D). Specifically, we use the ℓ2,0+ norm as the loss function to improve the robustness against outliers, and develop a new structured sparse regularization com, , tom. . cai@sydney . edu . au , heng@uta .edu make the learning tasks easier to deal with and reduce the computational cost. For example, in image tagging, instead of using the raw pixel-wise features, semi-local or patch- based features, such as SIFT and geometric blur, are usually more desirable to achieve better performance. In practice, finding a set of compact features bases, also referred to as dictionary, with enhanced representative and discriminative power, plays a significant role in building a successful computer vision system. In this paper, we explore this important problem by proposing a novel formulation and its solution for learning Semi-Supervised Robust Dictionary (SSRD), where we examine the challenges in dictionary learning, and seek opportunities to overcome them and improve the dictionary qualities. 1.1. Challenges in Dictionary Learning to incorporate the supervision information in dictionary learning, without incurring additional parameters. Moreover, the optimal dictionary size is automatically learned from the input data. Minimizing the derived objective function is challenging because it involves many non-smooth ℓ2,0+ -norm terms. We present an efficient algorithm to solve the problem with a rigorous proof of the convergence of the algorithm. Extensive experiments are presented to show the superior performance of the proposed method.</p><p>6 0.54979718 <a title="15-lda-6" href="./iccv-2013-Fast_Neighborhood_Graph_Search_Using_Cartesian_Concatenation.html">159 iccv-2013-Fast Neighborhood Graph Search Using Cartesian Concatenation</a></p>
<p>7 0.51729113 <a title="15-lda-7" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>8 0.5131616 <a title="15-lda-8" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>9 0.51064521 <a title="15-lda-9" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>10 0.50973558 <a title="15-lda-10" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>11 0.50956464 <a title="15-lda-11" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>12 0.50952262 <a title="15-lda-12" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>13 0.50814688 <a title="15-lda-13" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>14 0.50706303 <a title="15-lda-14" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>15 0.50671101 <a title="15-lda-15" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>16 0.50651956 <a title="15-lda-16" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>17 0.50646722 <a title="15-lda-17" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>18 0.50614917 <a title="15-lda-18" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<p>19 0.50614727 <a title="15-lda-19" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>20 0.50611377 <a title="15-lda-20" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
