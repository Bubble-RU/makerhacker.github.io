<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-42" href="#">iccv2013-42</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</h1>
<br/><p>Source: <a title="iccv-2013-42-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Roig_Active_MAP_Inference_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Gemma Roig, Xavier Boix, Roderick De_Nijs, Sebastian Ramos, Koljia Kuhnlenz, Luc Van_Gool</p><p>Abstract: Most MAP inference algorithms for CRFs optimize an energy function knowing all the potentials. In this paper, we focus on CRFs where the computational cost of instantiating the potentials is orders of magnitude higher than MAP inference. This is often the case in semantic image segmentation, where most potentials are instantiated by slow classifiers fed with costly features. We introduce Active MAP inference 1) to on-the-fly select a subset of potentials to be instantiated in the energy function, leaving the rest of the parameters of the potentials unknown, and 2) to estimate the MAP labeling from such incomplete energy function. Results for semantic segmentation benchmarks, namely PASCAL VOC 2010 [5] and MSRC-21 [19], show that Active MAP inference achieves similar levels of accuracy but with major efficiency gains.</p><p>Reference: <a title="iccv-2013-42-reference" href="../iccv2013_reference/iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ch on  Abstract Most MAP inference algorithms for CRFs optimize an energy function knowing all the potentials. [sent-5, score-0.407]
</p><p>2 In this paper, we focus on CRFs where the computational cost of instantiating the potentials is orders of magnitude higher than MAP inference. [sent-6, score-0.719]
</p><p>3 This is often the case in semantic image segmentation, where most potentials are instantiated by slow classifiers fed with costly features. [sent-7, score-0.792]
</p><p>4 We introduce Active MAP inference 1) to on-the-fly select a subset of potentials to be instantiated in the energy function, leaving the rest of the parameters of the potentials unknown, and 2) to estimate the MAP labeling from such incomplete energy function. [sent-8, score-1.885]
</p><p>5 Results for semantic segmentation benchmarks, namely PASCAL VOC 2010 [5] and MSRC-21 [19], show that Active MAP inference achieves similar levels of accuracy but with major efficiency gains. [sent-9, score-0.368]
</p><p>6 Introduction In many state-of-the-art methods for semantic segmentation, contextual information plays a central role. [sent-11, score-0.201]
</p><p>7 A suc-  cessful trend has been to encode the contextual constraints with a Conditional Random Field (CRF) [11], by modeling the interactions between different regions and scales of the image. [sent-12, score-0.133]
</p><p>8 Most methods use sophisticated potentials between different neighboring regions [7, 21], and the state-of-theart has been boosted with the use of high-order potentials in hierarchical CRFs [2, 9, 17]. [sent-13, score-0.882]
</p><p>9 Another common way to include contextual information has been to extend image descriptors with contextual cues [6, 8, 15], or also, combining semantic classifiers fed from different contextual features [4, 13, 14]. [sent-14, score-0.518]
</p><p>10 It is a remarkable feat the balance struck between accuracy and efficiency by the semantic texton forests of Shotton et al. [sent-15, score-0.112]
</p><p>11 [12] ask the provocative question: ‘Are spatial and global constraints really necessary for segmentation? [sent-18, score-0.041]
</p><p>12 ’ From the experimental results, they conclude that the CRF structures boost performance when the features only encode local in-  Figure 1. [sent-19, score-0.044]
</p><p>13 Active MAP selects the potentials to instantiate that maximize the expected reward. [sent-22, score-0.596]
</p><p>14 Also, it estimates the MAP labeling from the incomplete energy function. [sent-23, score-0.461]
</p><p>15 formation, whereas the further gain is very little when the features already encode contextual information. [sent-24, score-0.133]
</p><p>16 This begs the question whether we can really benefit from CRFs in semantic segmentation when using such powerful features that already encode context. [sent-25, score-0.306]
</p><p>17 We present a novel use of CRFs for semantic segmentation. [sent-26, score-0.112]
</p><p>18 We exploit CRFs to estimate the semantic labeling without computing the descriptors and classifiers everywhere in the image. [sent-27, score-0.349]
</p><p>19 Given a budget of time, it decides which potentials to compute. [sent-28, score-0.517]
</p><p>20 This is because the computational burden of instantiating  the potentials that extract descriptors and apply classifiers, which can be much higher than MAP inference for most of the energy functions in the literature [2, 6, 12]. [sent-30, score-1.09]
</p><p>21 We introduce a relation between CRFs with some unknown unary potentials, which correspond to the features and classifiers that we do not compute, and the Perturb-andMAP (PM) random field model [16]. [sent-31, score-0.295]
</p><p>22 We build our MAP inference algorithm - coined Active MAP inference - based on this finding. [sent-32, score-0.406]
</p><p>23 We use the term ‘active’ because during inference it selects which potentials to instantiate on-the-fly. [sent-33, score-0.783]
</p><p>24 This stands in contrast to previous MAP inference methods, which first execute the features/classifiers that instantiate 2233 1122  Original  100%  20%  5%  Figure 2. [sent-34, score-0.342]
</p><p>25 Active MAP inference using observing different amounts of unary potentials. [sent-36, score-0.294]
</p><p>26 Results are obtained by selecting the unary potentials with the expected labeling change. [sent-37, score-0.706]
</p><p>27 Surprisingly, seeing the instantiation of the CRF energy function and MAP-CRF inference as two joint steps received little attention in the community. [sent-39, score-0.467]
</p><p>28 In a serie of experiments, we show that active MAP inference successfully exploits spatial consistency to avoid evaluating the classifiers and features everywhere. [sent-40, score-0.427]
</p><p>29 It obtains comparable results to instantiating all the potentials in the CRF for the PASCAL VOC 2010 segmentation challenge [5] and for the MSRC-21 dataset [19], but with major efficiency gains. [sent-41, score-0.752]
</p><p>30 1 we illustrate some results on semantic segmentation obtained with active MAP inference. [sent-43, score-0.342]
</p><p>31 Active MAP Inference in CRFs  This section describes the approach for active MAP inference. [sent-45, score-0.161]
</p><p>32 Its formulation uses a CRF to model the probability density distribution expressing the likeliness of a certain labeling. [sent-46, score-0.158]
</p><p>33 uti Loent, Gan =d X (V t,hEe) s beet othfe r garnadpohm t hvaatri raebplreess or sn soudcehs of the graph. [sent-48, score-0.04]
</p><p>34 i} T hine welehmichen it s∈ o Vf V, an arde t ihned eicleems oefnt ths eof n oEd are tih. [sent-52, score-0.06]
</p><p>35 tWse o fdEe no atree an instance of the random variables as x = {xi}, where xi atank einss a vnacleue o ffr tohme a sndeto omf d viasrciraebtele lsa absel xs L =. [sent-55, score-0.112]
</p><p>36 {Txhu}s,, x ∈e LeN x, twakithes N a vthaleu cardinality to off fV d. [sent-56, score-0.037]
</p><p>37 e probability density distributionW oef a labeling m|θo)de alse dth ewi pthro tbhaeb graph Gn. [sent-58, score-0.316]
</p><p>38 ), Athcec probability density that satisfies the Markov properties with respect to the graph G is a Gibbs distribution. [sent-62, score-0.158]
</p><p>39 Thus, P(x|θ) can be written as the normalized negative exponential of an energy function Eθ (x) = θTφ(x), in which φ(x) = (φ1(x), . [sent-63, score-0.22]
</p><p>40 , φM(x))T is the vector of potentials, or the socalled sufficient statistics, and θ ∈ RM are the parameters ocafl tlehed potentials. [sent-66, score-0.035]
</p><p>41 tWateis use ,t ahen dc aθno ∈ni Rcal over-complete representation, in which {φi (x)} are built using indicator functrieosnesn ttahtaiot na,l ilonww us hto{ express trheeb energy fgunincdtiiocant as suuncchlinear combination of the potentials (c. [sent-67, score-0.787]
</p><p>42 yA ms uinsiumali,z we categorize the potentials of thex energy function depending  on the number of random variables that they involve: unary and pairwise. [sent-75, score-0.805]
</p><p>43 In the case of semantic segmentation, there is a node defined for each pixel or superpixel in the image. [sent-76, score-0.112]
</p><p>44 The parameters of θ related to the unary potentials are typically the result of evaluating classifiers fed with features extracted from the image. [sent-77, score-0.722]
</p><p>45 The pairwise and high-order potentials use some a priori assumptions like the smoothness of the labeling. [sent-78, score-0.441]
</p><p>46 It is important to note that the instantiation of θ might be orders of magnitude more computationally expensive than MAP inference. [sent-79, score-0.096]
</p><p>47 Usually, state-of-the-art methods for semantic segmentation use features and classifiers that take minutes to compute for a single image [2, 6, 12]. [sent-80, score-0.26]
</p><p>48 At testing phase, the common way to proceed is to instantiate θ, and then to run an off-the-shelf MAP inference algorithm to obtain the most probable labeling. [sent-81, score-0.388]
</p><p>49 T elheem computational gain comes sferloemct endo tb computing all classifiers and features needed to fully instantiate θ. [sent-84, score-0.274]
</p><p>50 Even though we do not have the complete energy function anymore because part of θ is unknown, we will show in the sequel that we can still estimate x? [sent-85, score-0.304]
</p><p>51 concept eofδ s ∈el e{c0te,1d} parameters in our notation, i. [sent-88, score-0.035]
</p><p>52 (1)  Note that with this notation we can still easily express the initial formulation that instantiates all parameters, using δ = 1and θ1, where 1is a vector of ones. [sent-96, score-0.153]
</p><p>53 With missing parameters, the energy function does not represent the initial labeling problem anymore. [sent-97, score-0.413]
</p><p>54 It would be wrong to replace the unknown parameters by 0, or any value indicating that ‘the potential is missing’ . [sent-98, score-0.148]
</p><p>55 There is no guarantee that, in doing so, the new energy function would assign energy values similar to the ones given by the complete energy. [sent-99, score-0.484]
</p><p>56 Given a budget of time, Active MAP inference instantiates a subset of the potentials (δ), and only with them, it computes the complete MAP labeling (x? [sent-101, score-0.987]
</p><p>57 Finally, we show results for the application of semantic image segmentation, where we save the cost of instantiating all the unary potentials. [sent-106, score-0.461]
</p><p>58 Active MAP inference is more general and can also be applied in many other applications. [sent-107, score-0.187]
</p><p>59 Recently, Papandreou and Yuille introduced the PM random field [16], which is a model that allows for generating samples, built around the effective MAP inference algorithms in CRF. [sent-111, score-0.224]
</p><p>60 PM is based on injecting noise in the energy function to perturb it, and then, it calculates the frequency that labelings are the MAP of the perturbed energy. [sent-114, score-0.616]
</p><p>61 ∈ RM be the raarend tohem MvaArPiab olef tthheat p iet tisu rubseedd eton perturb tth ? [sent-116, score-0.298]
</p><p>62 We denote the perturbed parameters of the energy as θ˜ = θ + ? [sent-121, score-0.365]
</p><p>63 For each perturbed θ˜, we can infer a MAP labeling. [sent-123, score-0.11]
</p><p>64 The different θ˜s that yield the same MAP labeling x, can be grouped together. [sent-124, score-0.158]
</p><p>65 (2)  Analogously, we can define the set of perturbations ? [sent-130, score-0.052]
</p><p>66 ,  (3)  Intuitively, the PM calculates how frequent is that a labeling x is the MAP labeling, when injecting noise to the energy function. [sent-151, score-0.506]
</p><p>67 Even though calculating the exact value of fPM (x; θ) might be not feasible for most practical cases, note that we can easily draw samples from a PM distribution by simply doing MAP inference on a perturbed energy. [sent-152, score-0.342]
</p><p>68 For a complete explanation of the PM random field we refer the reader to the paper [16]. [sent-153, score-0.081]
</p><p>69 MAP Inference for Incomplete Energies This section aims at estimating the labeling from the incomplete energy function. [sent-155, score-0.461]
</p><p>70 We assume that δ is given, and the potentials indicated by δ have been instantiated. [sent-156, score-0.441]
</p><p>71 Relation to Perturb-and-MAP Rather than filling in the energy function by inventing the unknown parameters or setting them to a learned constant value, we use P(θ|θδ) to model them. [sent-159, score-0.327]
</p><p>72 P(θ|θδ) is tshtaen probability eth uaste eth Pe parameters oofd tehle potentials θt|akθe the values θ given θδ. [sent-160, score-0.673]
</p><p>73 The CRF models the probability of the labeling, but it does not directly model P(θ|θδ). [sent-161, score-0.079]
</p><p>74 In order tlaob aell einvgi,at beu tth iet l daockes so nf an deirxeaccttl expression (fθo|rθ θP(θ|θδ), we use a vmioatdee tlh teo l approximate cit , e xrepfreersrseido nto f as f(θθ (|θθ|δ, π), where π are the parameters of the model. [sent-162, score-0.194]
</p><p>75 Changing θ in the energy function produces different MAP labelings, x? [sent-165, score-0.22]
</p><p>76 f o=re ,x P|θ(δθ) tθo define such probability on x? [sent-170, score-0.079]
</p><p>77 P(θ|θδ)dθ,  (4)  where I[·] is the indicator function. [sent-179, score-0.056]
</p><p>78 (4) can be seen as a nhaertuer Ia[l· way teo cnadliccualtaotre Pun(cXtio? [sent-181, score-0.037]
</p><p>79 θ (4δ)), sainnc bee i st accumulates the probability density of P=(θ x|θ|θδ) with θ yielding mtheu amtiensi tmheum pr energy labeling equal (tθo x. [sent-184, score-0.578]
</p><p>80 The integral explores all complete energy functions, Eθ (x), and for each of them, it checks whether the MAP labeling is x or not. [sent-185, score-0.422]
</p><p>81 In case it is equal to x, the corresponding probability density of P(θ|θδ) is accumulated into the final probability. [sent-186, score-0.158]
</p><p>82 = x|θδ) is indeed a PM random field, from which we can easily draw samples. [sent-190, score-0.045]
</p><p>83 Let f(Pθ|Mδ (,xπ|)δ,, aμnd) b fe t(hθe|δ d,eπn-) sity dmiestarnib euqtiuoanl of a P ∈M R Rmodel with energy Eμ(x), hi. [sent-194, score-0.253]
</p><p>84 d tehneenergy with parameter μ ∈ RM, and the perturbations are drawn from ? [sent-196, score-0.052]
</p><p>85 Observe that the density distribution of the PM model in Prop. [sent-202, score-0.079]
</p><p>86 ∈ RM such that x minimizes wtheh energy −fu μnc itsio thne E(μ+? [sent-207, score-0.26]
</p><p>87 t t+his μ |PδM,π d)i,s wtrihbiucthio ins reproduces the definition of P(X? [sent-215, score-0.037]
</p><p>88 The parameters for this model are the mean and( θth|δe, πsta). [sent-231, score-0.035]
</p><p>89 nd Tahrde pdaervamiateitoenr,s rfeorfer thriesd mtoo as μ ∈ RM and σ ∈ RM respectively, where for notation simplicity π din σdica ∈te Rs both μ and σ. [sent-232, score-0.037]
</p><p>90 Specifically, we define fθ (θ|δ, π) such that, if the parameter of the potential is unkno(wθn|δ ,(δπi = s 0c)h, it is a univariate Gaussian distribution, centered at μi and deviation σi. [sent-234, score-0.041]
</p><p>91 Otherwise it is consistent with the instantiated potential, fθ (θi |δi = 1, πi) = I[θi = θδii], where I[·] is the indicator functi|oδn. [sent-235, score-0.156]
</p><p>92 The algorithm starts from δ = 0, and it sequentially determines which potential to compute next, until the time budget, ttotal, expires. [sent-243, score-0.041]
</p><p>93 We denote the known potentials at time t as θδt . [sent-244, score-0.441]
</p><p>94 The algorithm ranks the unknown potentials with a score, and thus prioritizes the potentials in the time budget. [sent-245, score-1.035]
</p><p>95 This is done by selecting the potentials with higher score. [sent-246, score-0.441]
</p><p>96 We define Sδit as the expected reward of instantiating the potential i. [sent-250, score-0.376]
</p><p>97 , wwhheicrhe tish eth eex pGeacutesdsi vaan umeo idsel o voefr t θhe ∼ poste? [sent-265, score-0.079]
</p><p>98 R(·) is the reward of instantiating θi = θ, and site etv taolu θa. [sent-271, score-0.37]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('potentials', 0.441), ('instantiating', 0.242), ('crfs', 0.221), ('energy', 0.22), ('crf', 0.194), ('inference', 0.187), ('pm', 0.184), ('px', 0.162), ('fpm', 0.161), ('active', 0.161), ('labeling', 0.158), ('map', 0.157), ('instantiate', 0.155), ('rm', 0.114), ('semantic', 0.112), ('perturbed', 0.11), ('unary', 0.107), ('instantiated', 0.1), ('perturb', 0.096), ('reward', 0.093), ('contextual', 0.089), ('incomplete', 0.083), ('instantiates', 0.081), ('density', 0.079), ('probability', 0.079), ('classifiers', 0.079), ('budget', 0.076), ('injecting', 0.075), ('unknown', 0.072), ('segmentation', 0.069), ('argx', 0.067), ('labelings', 0.062), ('instantiation', 0.06), ('eof', 0.06), ('fed', 0.06), ('oxf', 0.058), ('indicator', 0.056), ('calculates', 0.053), ('perturbations', 0.052), ('iet', 0.052), ('probable', 0.046), ('draw', 0.045), ('complete', 0.044), ('encode', 0.044), ('bee', 0.042), ('really', 0.041), ('potential', 0.041), ('ranks', 0.041), ('alue', 0.04), ('anymore', 0.04), ('beet', 0.04), ('begs', 0.04), ('endo', 0.04), ('functi', 0.04), ('gemma', 0.04), ('itsio', 0.04), ('nxg', 0.04), ('papandreou', 0.04), ('prioritizes', 0.04), ('qx', 0.04), ('rior', 0.04), ('tohem', 0.04), ('tohme', 0.04), ('tshtaen', 0.04), ('tthheat', 0.04), ('voefr', 0.04), ('xly', 0.04), ('eth', 0.039), ('ln', 0.038), ('pe', 0.038), ('reproduces', 0.037), ('beu', 0.037), ('ffr', 0.037), ('olef', 0.037), ('thex', 0.037), ('tphoes', 0.037), ('unkno', 0.037), ('vthaleu', 0.037), ('teo', 0.037), ('field', 0.037), ('notation', 0.037), ('orders', 0.036), ('parameters', 0.035), ('ahen', 0.035), ('argminx', 0.035), ('etv', 0.035), ('len', 0.035), ('lsa', 0.035), ('ltoe', 0.035), ('pam', 0.035), ('tarlow', 0.035), ('ttioo', 0.035), ('missing', 0.035), ('express', 0.035), ('sity', 0.033), ('ddis', 0.033), ('xavier', 0.033), ('tth', 0.033), ('barcelona', 0.032), ('coined', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="42-tfidf-1" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>Author: Gemma Roig, Xavier Boix, Roderick De_Nijs, Sebastian Ramos, Koljia Kuhnlenz, Luc Van_Gool</p><p>Abstract: Most MAP inference algorithms for CRFs optimize an energy function knowing all the potentials. In this paper, we focus on CRFs where the computational cost of instantiating the potentials is orders of magnitude higher than MAP inference. This is often the case in semantic image segmentation, where most potentials are instantiated by slow classifiers fed with costly features. We introduce Active MAP inference 1) to on-the-fly select a subset of potentials to be instantiated in the energy function, leaving the rest of the parameters of the potentials unknown, and 2) to estimate the MAP labeling from such incomplete energy function. Results for semantic segmentation benchmarks, namely PASCAL VOC 2010 [5] and MSRC-21 [19], show that Active MAP inference achieves similar levels of accuracy but with major efficiency gains.</p><p>2 0.1978907 <a title="42-tfidf-2" href="./iccv-2013-Holistic_Scene_Understanding_for_3D_Object_Detection_with_RGBD_Cameras.html">201 iccv-2013-Holistic Scene Understanding for 3D Object Detection with RGBD Cameras</a></p>
<p>Author: Dahua Lin, Sanja Fidler, Raquel Urtasun</p><p>Abstract: In this paper, we tackle the problem of indoor scene understanding using RGBD data. Towards this goal, we propose a holistic approach that exploits 2D segmentation, 3D geometry, as well as contextual relations between scenes and objects. Specifically, we extend the CPMC [3] framework to 3D in order to generate candidate cuboids, and develop a conditional random field to integrate information from different sources to classify the cuboids. With this formulation, scene classification and 3D object recognition are coupled and can be jointly solved through probabilistic inference. We test the effectiveness of our approach on the challenging NYU v2 dataset. The experimental results demonstrate that through effective evidence integration and holistic reasoning, our approach achieves substantial improvement over the state-of-the-art.</p><p>3 0.18726686 <a title="42-tfidf-3" href="./iccv-2013-Estimating_the_3D_Layout_of_Indoor_Scenes_and_Its_Clutter_from_Depth_Sensors.html">144 iccv-2013-Estimating the 3D Layout of Indoor Scenes and Its Clutter from Depth Sensors</a></p>
<p>Author: Jian Zhang, Chen Kan, Alexander G. Schwing, Raquel Urtasun</p><p>Abstract: In this paper we propose an approach to jointly estimate the layout ofrooms as well as the clutterpresent in the scene using RGB-D data. Towards this goal, we propose an effective model that is able to exploit both depth and appearance features, which are complementary. Furthermore, our approach is efficient as we exploit the inherent decomposition of additive potentials. We demonstrate the effectiveness of our approach on the challenging NYU v2 dataset and show that employing depth reduces the layout error by 6% and the clutter estimation by 13%.</p><p>4 0.15589763 <a title="42-tfidf-4" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>5 0.13677178 <a title="42-tfidf-5" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>6 0.13400194 <a title="42-tfidf-6" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>7 0.12411442 <a title="42-tfidf-7" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>8 0.12054215 <a title="42-tfidf-8" href="./iccv-2013-Learning_the_Visual_Interpretation_of_Sentences.html">246 iccv-2013-Learning the Visual Interpretation of Sentences</a></p>
<p>9 0.11276389 <a title="42-tfidf-9" href="./iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees.html">76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</a></p>
<p>10 0.10449314 <a title="42-tfidf-10" href="./iccv-2013-3D_Scene_Understanding_by_Voxel-CRF.html">2 iccv-2013-3D Scene Understanding by Voxel-CRF</a></p>
<p>11 0.097837478 <a title="42-tfidf-11" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>12 0.09753003 <a title="42-tfidf-12" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>13 0.086507075 <a title="42-tfidf-13" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>14 0.086465538 <a title="42-tfidf-14" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>15 0.084300019 <a title="42-tfidf-15" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>16 0.083222352 <a title="42-tfidf-16" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>17 0.082772925 <a title="42-tfidf-17" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>18 0.078946047 <a title="42-tfidf-18" href="./iccv-2013-Box_in_the_Box%3A_Joint_3D_Layout_and_Object_Reasoning_from_Single_Images.html">64 iccv-2013-Box in the Box: Joint 3D Layout and Object Reasoning from Single Images</a></p>
<p>19 0.078214526 <a title="42-tfidf-19" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>20 0.077416733 <a title="42-tfidf-20" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.17), (1, -0.014), (2, 0.01), (3, -0.015), (4, 0.087), (5, 0.024), (6, -0.095), (7, 0.046), (8, 0.012), (9, -0.137), (10, -0.01), (11, 0.06), (12, -0.015), (13, 0.036), (14, 0.03), (15, 0.024), (16, -0.102), (17, -0.054), (18, -0.092), (19, -0.058), (20, -0.063), (21, -0.038), (22, -0.029), (23, -0.013), (24, 0.025), (25, -0.085), (26, 0.112), (27, 0.004), (28, -0.011), (29, 0.002), (30, -0.055), (31, -0.017), (32, 0.088), (33, -0.025), (34, 0.098), (35, -0.065), (36, -0.12), (37, 0.003), (38, -0.018), (39, 0.093), (40, -0.043), (41, -0.039), (42, 0.111), (43, 0.06), (44, 0.038), (45, 0.033), (46, -0.006), (47, -0.051), (48, 0.008), (49, -0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97447318 <a title="42-lsi-1" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>Author: Gemma Roig, Xavier Boix, Roderick De_Nijs, Sebastian Ramos, Koljia Kuhnlenz, Luc Van_Gool</p><p>Abstract: Most MAP inference algorithms for CRFs optimize an energy function knowing all the potentials. In this paper, we focus on CRFs where the computational cost of instantiating the potentials is orders of magnitude higher than MAP inference. This is often the case in semantic image segmentation, where most potentials are instantiated by slow classifiers fed with costly features. We introduce Active MAP inference 1) to on-the-fly select a subset of potentials to be instantiated in the energy function, leaving the rest of the parameters of the potentials unknown, and 2) to estimate the MAP labeling from such incomplete energy function. Results for semantic segmentation benchmarks, namely PASCAL VOC 2010 [5] and MSRC-21 [19], show that Active MAP inference achieves similar levels of accuracy but with major efficiency gains.</p><p>2 0.68740463 <a title="42-lsi-2" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>Author: Honghui Zhang, Jingdong Wang, Ping Tan, Jinglu Wang, Long Quan</p><p>Abstract: We propose an adaptive subgradient descent method to efficiently learn the parameters of CRF models for image parsing. To balance the learning efficiency and performance of the learned CRF models, the parameter learning is iteratively carried out by solving a convex optimization problem in each iteration, which integrates a proximal term to preserve the previously learned information and the large margin preference to distinguish bad labeling and the ground truth labeling. A solution of subgradient descent updating form is derived for the convex optimization problem, with an adaptively determined updating step-size. Besides, to deal with partially labeled training data, we propose a new objective constraint modeling both the labeled and unlabeled parts in the partially labeled training data for the parameter learning of CRF models. The superior learning efficiency of the proposed method is verified by the experiment results on two public datasets. We also demonstrate the powerfulness of our method for handling partially labeled training data.</p><p>3 0.67046237 <a title="42-lsi-3" href="./iccv-2013-Estimating_the_3D_Layout_of_Indoor_Scenes_and_Its_Clutter_from_Depth_Sensors.html">144 iccv-2013-Estimating the 3D Layout of Indoor Scenes and Its Clutter from Depth Sensors</a></p>
<p>Author: Jian Zhang, Chen Kan, Alexander G. Schwing, Raquel Urtasun</p><p>Abstract: In this paper we propose an approach to jointly estimate the layout ofrooms as well as the clutterpresent in the scene using RGB-D data. Towards this goal, we propose an effective model that is able to exploit both depth and appearance features, which are complementary. Furthermore, our approach is efficient as we exploit the inherent decomposition of additive potentials. We demonstrate the effectiveness of our approach on the challenging NYU v2 dataset and show that employing depth reduces the layout error by 6% and the clutter estimation by 13%.</p><p>4 0.63212097 <a title="42-lsi-4" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>Author: Masoud S. Nosrati, Shawn Andrews, Ghassan Hamarneh</p><p>Abstract: The inclusion of shape and appearance priors have proven useful for obtaining more accurate and plausible segmentations, especially for complex objects with multiple parts. In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . ca (a)Standar laΩb ehlingΩfuhnctionseting(Ωb)hΩOuirseΩtijng Figure 1: The inside vs. outside ambiguity in (a) is resolved by our containment constraint in (b). constraints using a single labeling function while maintaining global optimality. We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors.</p><p>5 0.61934412 <a title="42-lsi-5" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>6 0.61492622 <a title="42-lsi-6" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>7 0.61231512 <a title="42-lsi-7" href="./iccv-2013-Holistic_Scene_Understanding_for_3D_Object_Detection_with_RGBD_Cameras.html">201 iccv-2013-Holistic Scene Understanding for 3D Object Detection with RGBD Cameras</a></p>
<p>8 0.60143894 <a title="42-lsi-8" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>9 0.59948534 <a title="42-lsi-9" href="./iccv-2013-Box_in_the_Box%3A_Joint_3D_Layout_and_Object_Reasoning_from_Single_Images.html">64 iccv-2013-Box in the Box: Joint 3D Layout and Object Reasoning from Single Images</a></p>
<p>10 0.56904697 <a title="42-lsi-10" href="./iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees.html">76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</a></p>
<p>11 0.56838953 <a title="42-lsi-11" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>12 0.55529004 <a title="42-lsi-12" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>13 0.54469377 <a title="42-lsi-13" href="./iccv-2013-3D_Scene_Understanding_by_Voxel-CRF.html">2 iccv-2013-3D Scene Understanding by Voxel-CRF</a></p>
<p>14 0.52939492 <a title="42-lsi-14" href="./iccv-2013-Characterizing_Layouts_of_Outdoor_Scenes_Using_Spatial_Topic_Processes.html">72 iccv-2013-Characterizing Layouts of Outdoor Scenes Using Spatial Topic Processes</a></p>
<p>15 0.51688683 <a title="42-lsi-15" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>16 0.50510699 <a title="42-lsi-16" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>17 0.49996752 <a title="42-lsi-17" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>18 0.49492478 <a title="42-lsi-18" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>19 0.48470882 <a title="42-lsi-19" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>20 0.48002061 <a title="42-lsi-20" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.043), (7, 0.019), (12, 0.014), (16, 0.231), (26, 0.099), (27, 0.012), (31, 0.047), (40, 0.017), (42, 0.1), (48, 0.01), (64, 0.036), (73, 0.036), (89, 0.236), (98, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87073278 <a title="42-lda-1" href="./iccv-2013-PM-Huber%3A_PatchMatch_with_Huber_Regularization_for_Stereo_Matching.html">304 iccv-2013-PM-Huber: PatchMatch with Huber Regularization for Stereo Matching</a></p>
<p>Author: Philipp Heise, Sebastian Klose, Brian Jensen, Alois Knoll</p><p>Abstract: Most stereo correspondence algorithms match support windows at integer-valued disparities and assume a constant disparity value within the support window. The recently proposed PatchMatch stereo algorithm [7] overcomes this limitation of previous algorithms by directly estimating planes. This work presents a method that integrates the PatchMatch stereo algorithm into a variational smoothing formulation using quadratic relaxation. The resulting algorithm allows the explicit regularization of the disparity and normal gradients using the estimated plane parameters. Evaluation of our method in the Middlebury benchmark shows that our method outperforms the traditional integer-valued disparity strategy as well as the original algorithm and its variants in sub-pixel accurate disparity estimation.</p><p>2 0.86167252 <a title="42-lda-2" href="./iccv-2013-From_Point_to_Set%3A_Extend_the_Learning_of_Distance_Metrics.html">177 iccv-2013-From Point to Set: Extend the Learning of Distance Metrics</a></p>
<p>Author: Pengfei Zhu, Lei Zhang, Wangmeng Zuo, David Zhang</p><p>Abstract: Most of the current metric learning methods are proposed for point-to-point distance (PPD) based classification. In many computer vision tasks, however, we need to measure the point-to-set distance (PSD) and even set-to-set distance (SSD) for classification. In this paper, we extend the PPD based Mahalanobis distance metric learning to PSD and SSD based ones, namely point-to-set distance metric learning (PSDML) and set-to-set distance metric learning (SSDML), and solve them under a unified optimization framework. First, we generate positive and negative sample pairs by computing the PSD and SSD between training samples. Then, we characterize each sample pair by its covariance matrix, and propose a covariance kernel based discriminative function. Finally, we tackle the PSDML and SSDMLproblems by using standard support vector machine solvers, making the metric learning very efficient for multiclass visual classification tasks. Experiments on gender classification, digit recognition, object categorization and face recognition show that the proposed metric learning methods can effectively enhance the performance of PSD and SSD based classification.</p><p>same-paper 3 0.85407102 <a title="42-lda-3" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>Author: Gemma Roig, Xavier Boix, Roderick De_Nijs, Sebastian Ramos, Koljia Kuhnlenz, Luc Van_Gool</p><p>Abstract: Most MAP inference algorithms for CRFs optimize an energy function knowing all the potentials. In this paper, we focus on CRFs where the computational cost of instantiating the potentials is orders of magnitude higher than MAP inference. This is often the case in semantic image segmentation, where most potentials are instantiated by slow classifiers fed with costly features. We introduce Active MAP inference 1) to on-the-fly select a subset of potentials to be instantiated in the energy function, leaving the rest of the parameters of the potentials unknown, and 2) to estimate the MAP labeling from such incomplete energy function. Results for semantic segmentation benchmarks, namely PASCAL VOC 2010 [5] and MSRC-21 [19], show that Active MAP inference achieves similar levels of accuracy but with major efficiency gains.</p><p>4 0.85301405 <a title="42-lda-4" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>Author: Yaron Eshet, Simon Korman, Eyal Ofek, Shai Avidan</p><p>Abstract: We extend patch based methods to work on patches in 3D space. We start with Coherency Sensitive Hashing [12] (CSH), which is an algorithm for matching patches between two RGB images, and extend it to work with RGBD images. This is done by warping all 3D patches to a common virtual plane in which CSH is performed. To avoid noise due to warping of patches of various normals and depths, we estimate a group of dominant planes and compute CSH on each plane separately, before merging the matching patches. The result is DCSH - an algorithm that matches world (3D) patches in order to guide the search for image plane matches. An independent contribution is an extension of CSH, which we term Social-CSH. It allows a major speedup of the k nearest neighbor (kNN) version of CSH - its runtime growing linearly, rather than quadratically, in k. Social-CSH is used as a subcomponent of DCSH when many NNs are required, as in the case of image denoising. We show the benefits ofusing depth information to image reconstruction and image denoising, demonstrated on several RGBD images.</p><p>5 0.82029027 <a title="42-lda-5" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>Author: Nianjuan Jiang, Zhaopeng Cui, Ping Tan</p><p>Abstract: We present a linear method for global camera pose registration from pairwise relative poses encoded in essential matrices. Our method minimizes an approximate geometric error to enforce the triangular relationship in camera triplets. This formulation does not suffer from the typical ‘unbalanced scale ’ problem in linear methods relying on pairwise translation direction constraints, i.e. an algebraic error; nor the system degeneracy from collinear motion. In the case of three cameras, our method provides a good linear approximation of the trifocal tensor. It can be directly scaled up to register multiple cameras. The results obtained are accurate for point triangulation and can serve as a good initialization for final bundle adjustment. We evaluate the algorithm performance with different types of data and demonstrate its effectiveness. Our system produces good accuracy, robustness, and outperforms some well-known systems on efficiency.</p><p>6 0.81206965 <a title="42-lda-6" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>7 0.77563536 <a title="42-lda-7" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>8 0.77170658 <a title="42-lda-8" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>9 0.77003825 <a title="42-lda-9" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>10 0.7694701 <a title="42-lda-10" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>11 0.7679466 <a title="42-lda-11" href="./iccv-2013-Volumetric_Semantic_Segmentation_Using_Pyramid_Context_Features.html">447 iccv-2013-Volumetric Semantic Segmentation Using Pyramid Context Features</a></p>
<p>12 0.76780158 <a title="42-lda-12" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>13 0.76731968 <a title="42-lda-13" href="./iccv-2013-A_Joint_Intensity_and_Depth_Co-sparse_Analysis_Model_for_Depth_Map_Super-resolution.html">18 iccv-2013-A Joint Intensity and Depth Co-sparse Analysis Model for Depth Map Super-resolution</a></p>
<p>14 0.76625234 <a title="42-lda-14" href="./iccv-2013-Shape_Anchors_for_Data-Driven_Multi-view_Reconstruction.html">387 iccv-2013-Shape Anchors for Data-Driven Multi-view Reconstruction</a></p>
<p>15 0.76584876 <a title="42-lda-15" href="./iccv-2013-Image_Guided_Depth_Upsampling_Using_Anisotropic_Total_Generalized_Variation.html">209 iccv-2013-Image Guided Depth Upsampling Using Anisotropic Total Generalized Variation</a></p>
<p>16 0.76576692 <a title="42-lda-16" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>17 0.76566136 <a title="42-lda-17" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>18 0.76550663 <a title="42-lda-18" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<p>19 0.76529789 <a title="42-lda-19" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>20 0.76529151 <a title="42-lda-20" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
