<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-364" href="#">iccv2013-364</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</h1>
<br/><p>Source: <a title="iccv-2013-364-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Liu_SGTD_Structure_Gradient_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Qiegen Liu, Jianbo Liu, Pei Dong, Dong Liang</p><p>Abstract: This paper presents a novel structure gradient and texture decorrelating regularization (SGTD) for image decomposition. The motivation of the idea is under the assumption that the structure gradient and texture components should be properly decorrelated for a successful decomposition. The proposed model consists of the data fidelity term, total variation regularization and the SGTD regularization. An augmented Lagrangian method is proposed to address this optimization issue, by first transforming the unconstrained problem to an equivalent constrained problem and then applying an alternating direction method to iteratively solve the subproblems. Experimental results demonstrate that the proposed method presents better or comparable performance as state-of-the-art methods do.</p><p>Reference: <a title="iccv-2013-364-reference" href="../iccv2013_reference/iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Lauterbur Research Center for Biomedical Imaging, SIAT, China 3School of Information Technologies, the University of Sydney, Australia  Abstract This paper presents a novel structure gradient and texture decorrelating regularization (SGTD) for image decomposition. [sent-2, score-0.486]
</p><p>2 The motivation of the idea is under the assumption that the structure gradient and texture components should be properly decorrelated for a successful decomposition. [sent-3, score-0.341]
</p><p>3 The proposed model consists of the data fidelity term, total variation regularization and the SGTD regularization. [sent-4, score-0.109]
</p><p>4 An augmented Lagrangian method is proposed to address this optimization issue, by first transforming the unconstrained problem to an equivalent constrained problem and then applying an alternating direction method to iteratively solve the subproblems. [sent-5, score-0.107]
</p><p>5 Introduction Image decomposition defined as separating an image f as the sum of two independent components f = x v, usu-  +  ally is the first step to the solution ofmany image processing tasks like inpainting [2], demosaicing [15] and registration [12]. [sent-8, score-0.176]
</p><p>6 This component contains main large-scale structure features of the image, and can be used for feature detection, segmentation and object recognition. [sent-10, score-0.055]
</p><p>7 Another component v usually represented by a small-scale oscillatory function and having some periodicity nature, captures texture and possibly noise, and thus is suitable for solving various texturedepended applications e. [sent-11, score-0.235]
</p><p>8 Variational approach is the most popular approach to address the image decomposition problem. [sent-14, score-0.128]
</p><p>9 The common part in this approach is often related to total variation (TV) minimization. [sent-15, score-0.058]
</p><p>10 It can be seen ithsa tat kTeVn-L ov2 emro adlle lp performs decomposition by modeling etehen cartoon component x with TV semi-norm and using the L2norm for oscillating features v = f − x. [sent-43, score-0.624]
</p><p>11 Starting from this mnoormdel f, trh oes strategies faotru improving image decomposition can be divided into three approaches, based on searching the suitable model for texture, cartoon or for both texture and cartoon. [sent-44, score-0.754]
</p><p>12 The first approach devotes to modifying the norm on the texture component. [sent-45, score-0.261]
</p><p>13 It was proved that G corresponds to a space of oscillating functions, and thus is better suited to model textures. [sent-47, score-0.053]
</p><p>14 Particularly, by replacing the L2 norm on data fidelity (i. [sent-49, score-0.052]
</p><p>15 texture component) with the L1 norm, the importance of TV-L1 model in image decomposition has attracted many researchers [10, 3, 25]. [sent-51, score-0.337]
</p><p>16 The second approach, focusing on modifying the norm on the TV measure, encompasses methods such as weighted least squares (WLS) [5] and L0 gradient minimization [22]. [sent-54, score-0.102]
</p><p>17 Though still depending on gradient images, these two methods differ from the TV-L2 decomposition model on regularization term and specific optimization steps, and do not suit  texture separation very well. [sent-55, score-0.45]
</p><p>18 Inspired by the observation that a major edge of cartoon in a local window contributes 11008811  more similar-direction gradients than textures with complex patterns, Xu et al. [sent-56, score-0.445]
</p><p>19 [6] introduced relative total variation (RTV) regularization for extracting structure from texture. [sent-57, score-0.113]
</p><p>20 The experimental results demonstrate that RTV can make main structures stand out by combining general windowed total variation and novel windowed inherent variation. [sent-58, score-0.143]
</p><p>21 Unlike the above two approaches that enhance the decomposition by modifying texture norm or cartoon norm individually, a “structural decorrelating” approach for image decomposition has attracted much attention and presented impressive performance recently. [sent-59, score-0.961]
</p><p>22 The methods in this stream directly predefined the decorrelation measure between the structure and texture components. [sent-60, score-0.238]
</p><p>23 [16] improved the OSV method by introducing the penalty of correlation coefficient between structure and texture components. [sent-62, score-0.279]
</p><p>24 [18] used the angle deviation error (ADE) based orthogonality measure to improve the spatial filter for better separating the cartoon and texture parts. [sent-64, score-0.644]
</p><p>25 Well-decomposed performance is achieved by adding a novel structure gradient and texture decorrelating (SGTD) regularizer to the TV-L2 model. [sent-68, score-0.539]
</p><p>26 Specifically, this proposed regularizer aims to enforce that the correlation between structure gradient and texture components is minimal instead of the correlation between structure and texture components. [sent-69, score-0.671]
</p><p>27 With regard to the new regularizer, texture and main structure exhibit appropriate decorrelated properties, making them surprisingly decomposable. [sent-70, score-0.265]
</p><p>28 A robust numerical solver named alternating direction method is proposed to decompose the original highly nonconvex optimization problem into several subproblems, and find the fast and robust solutions. [sent-71, score-0.107]
</p><p>29 In Section 2, we will present our new regularizer and model for image decomposition. [sent-73, score-0.079]
</p><p>30 In Section 3, an efficient algorithm for solving the proposed model will be derived by applying alternating minimization. [sent-74, score-0.046]
</p><p>31 SGTD: Structure Gradient and Texture Decorrelating Regularizer and Model In this section, the structure gradient and texture decorrelating (SGTD) regularizer and its corresponding decomposition model will be derived. [sent-78, score-0.667]
</p><p>32 Structure Gradient and Texture Decorrelating (SGTD) Regularizer Intuitively, for a successful decomposition, any given feature in an image should be considered as either a cartoon feature or a textural feature. [sent-84, score-0.451]
</p><p>33 Therefore, the correlation between the cartoon and texture components of a decomposition should be low, i. [sent-85, score-0.8]
</p><p>34 nce the texture part has an inherent zero mean while the cartoon does not. [sent-93, score-0.643]
</p><p>35 In order to help address this issue, we propose an alternative way by minimizing |fi − xi | · ? [sent-94, score-0.042]
</p><p>36 tion, which makes the gradient images have inherent zero mean since this operation for one pixel could be either positive or negative. [sent-101, score-0.067]
</p><p>37 Therefore, our proposed regularizer suggests the gradient magnitude of the cartoon and texture component are generated from independent process and thus are uncorrelated. [sent-102, score-0.81]
</p><p>38 Theoretically, the SGTD regularizer can be approximately viewed as a window based correlation coefficient with size of two between the texture component and the cartoon component. [sent-103, score-0.772]
</p><p>39 in=21  representing cartoon variable in a window of size two, and [fi−1 −xi−1 , fi−xi] denotes the corresponding texture variables −wxith zero mean, then the absolute value of correction coefficient between the two random variables X and Y is  |ρXY| =? [sent-106, score-0.664]
</p><p>40 i | 2σxσf−x 2σxσf−x Similarly as in DOSV, by assuming that the standard deviations σx and σf−x are not the functions of xi, the absolute value of correction coefficient in pixel ican approximate the SGTD regularizer. [sent-124, score-0.038]
</p><p>41 1 for example, we can find that the range of the cartoon and texture components may not at the same or near scale (one is 0. [sent-126, score-0.652]
</p><p>42 Fortunately, the range of the magnitudes of cartoon gradient and texture components are close to each other (one is 0. [sent-129, score-0.702]
</p><p>43 It can be seen that the magnitude images of cartoon gradient and texture components in Fig. [sent-132, score-0.731]
</p><p>44 This observation suggests that these two components are highly uncorrelated and thus are suitable for cartoon + texture decomposition. [sent-134, score-0.652]
</p><p>45 (a)(b)(c): The input image, cartoon + texture decomposition results. [sent-147, score-0.754]
</p><p>46 (d)(e)(f): gradient magnitude image of the cartoon component, the magnitude of texture component and their SGTD values. [sent-148, score-0.76]
</p><p>47 This example numerically validates that for an appropriate decomposition of cartoon and texture components, the coherent between the gradient cartoon and texture is small. [sent-150, score-1.43]
</p><p>48 SGTD Regularization Model In this subsection, a new decomposition model involv-  ing the SGTD regularizer is presented. [sent-153, score-0.207]
</p><p>49 The second term favors that the structure part to be sparse in the gradient domain. [sent-166, score-0.079]
</p><p>50 The effect of more powerfully decomposing cartoon and texture is introduced by the third term, which measures the correlated quality between the gradient of structural component and the textural component. [sent-167, score-0.77]
</p><p>51 Compared to the TV-L2 moedel, the new added term alleviates the drawback introduced by only using TV regularizer and makes the proposed model be able to handle images containing complex patterns. [sent-168, score-0.079]
</p><p>52 The perfect separation of various meaningful cartoon and texture patterns may come from the proposed nonlinear reformulation of the model. [sent-181, score-0.746]
</p><p>53 (3)  In this form, it can be observed that our model can be seen as a weighted TV-L1 model with the weight wi = |fi xi | . [sent-194, score-0.042]
</p><p>54 Moreover, it allows more freedom and robustness than TV-L1, benefited from the nonlinear reformulation. [sent-196, score-0.055]
</p><p>55 2 illustrates one challenging example for decomposition since the texture of the input image Zebra has a wide range of sizes. [sent-198, score-0.337]
</p><p>56 We can see that the non-textural parts such as slow changes of the gray level values and non-textural parts of the background cannot be appropriately separated from the texture by tuning the parameter of TV-L1 . [sent-199, score-0.305]
</p><p>57 An interesting phenomenon is that by varying the parameters μ and η, the proposed model can not only provide the traditional decomposition result shown in Fig. [sent-201, score-0.128]
</p><p>58 2(c), but also yield meaningful decomposition as depicted in Fig. [sent-202, score-0.156]
</p><p>59 In summary, our model can be viewed as a weighted TV-L1 model, and thus provide more freedom to deal with various image processing tasks. [sent-205, score-0.044]
</p><p>60 In this subsection, an augmented Lagrangian (AL) method is proposed to solve the problem. [sent-211, score-0.042]
</p><p>61 Problem (∈4) R can ib =e s 1o,l·v·e·d , vnia the standard augmented Lagrangian method. [sent-230, score-0.042]
</p><p>62 3(b) displays the intermediate structure images obtained at the 3-th, 5-th, and 7-th iteration, where we can find the proposed method quickly updates the cartoon image in iterations. [sent-312, score-0.469]
</p><p>63 It indicates the effectiveness of the alternating strategy adopted by our  method. [sent-313, score-0.046]
</p><p>64 Experimental Results In this section, we evaluate the performance of SGTD on several experiments under the scenario of decompostion, which aims to investigate the effect of imposing structural incoherence (when working on the color images, the extension is the same as that in [19]). [sent-315, score-0.038]
</p><p>65 As both parameters increasing, the results approximate to the traditional decomposition task. [sent-338, score-0.128]
</p><p>66 The well-performed separation to various types of meaningful cartoon and texture patterns under different parameter values indicates the diverse usage of the proposed method. [sent-339, score-0.734]
</p><p>67 Decomposition Comparison with State-of-theart Methods on Standard Images When visually evaluating the performance of decomposition method, one important criterion is to consider how strong the remaining parts of one component on the image of another component [18]. [sent-342, score-0.2]
</p><p>68 5(a) that TV-L1 method cannot completely eliminate the texture from the table cover, while there are apparent cartoon edges on the texture image. [sent-344, score-0.897]
</p><p>69 AD-aBLMV-ADE and RTV methods can eliminate the texture from the cartoon image, but the slow changes of gray level values shown in the region of table leg are also apparent on the texture image. [sent-346, score-0.932]
</p><p>70 The proposed method successfully eliminates the texture from the cartoon while visually almost no cartoon parts appearing on the texture image 3The results using DOSV and ADE based method are copied from [18] directly for a fair comparison since the implementations are not public. [sent-347, score-1.272]
</p><p>71 The wellperformed separation to various types of meaningful cartoon and texture patterns indicates the diverse usage of the proposed method. [sent-354, score-0.713]
</p><p>72 5(d)), and thus gives the best separation results and exhibits contrast-preserving feature. [sent-358, score-0.058]
</p><p>73 It can be seen that DOSV performs worst since it cannot eliminate the larger texture parts without blurring the cartoon. [sent-361, score-0.258]
</p><p>74 RTV performs poorly with some texture parts remaining on the cartoon, while some nontextural parts such as slow changes of gray level values and the background are apparent on the texture image. [sent-362, score-0.56]
</p><p>75 It is possibly due to the limitation that RTV cannot distinguish between structure and texture that are similar in scales. [sent-363, score-0.238]
</p><p>76 AD-aBLMV-ADE performs slightly better than the RTV method by eliminating most of the texture on the animal but the nontextural parts such as the background are still apparent on the texture image. [sent-364, score-0.53]
</p><p>77 When applying three decomposition models OSV, TV-L1 and SGTD to the image of “4-textures” depicted in Fig. [sent-366, score-0.128]
</p><p>78 7, the parameter values were adjusted aiming to extract the woven texture (the upper right part) accurately. [sent-367, score-0.23]
</p><p>79 7 exhibits the difference of the three  methods in decomposition capability. [sent-369, score-0.149]
</p><p>80 8(c), the grass part in the image is better removed from the cartoon part by the proposed SGTD as shown in Fig. [sent-390, score-0.417]
</p><p>81 8(e), the ripple can be well-separated from the texture part by tuning the parameter of our method, thus the tiger may be easier to be segmented from the image [4]. [sent-393, score-0.254]
</p><p>82 It can be observed that the performance of removing texture from the cross stitch by both methods is very similar, while our method preserves more fine details than RTV on the background. [sent-399, score-0.225]
</p><p>83 Although this method makes use of local signed gradients and the relative total variation (RTV) exhibits special properties, it fails to preserve some fine structures com-  pared to our method shown in Fig. [sent-404, score-0.095]
</p><p>84 Finally, we show an example where the texture is highly non-uniform and anisotropic. [sent-407, score-0.209]
</p><p>85 It is clear that the structure parts such as of the cheek and hair of the girl are better preserved in the result of SGTD than that of RTV. [sent-410, score-0.07]
</p><p>86 Besides, the decomposition of SGTD preserves the contrast between the girl and the background better. [sent-411, score-0.149]
</p><p>87 Conclusion In this paper, a decorrelating regularizer for extracting meaningful structure from texture was proposed. [sent-414, score-0.517]
</p><p>88 The image decomposition results were improved by forcing incoherence between the gradient magnitude of the cartoon and texture components. [sent-415, score-0.853]
</p><p>89 Additionally, the proposed model allows a high level of freedom and robustness due to the nonlinear formulation. [sent-417, score-0.055]
</p><p>90 With the aid of augmented Lagrangian and alternating direction methods, the original non-linear problem was transformed into a set of subproblems that are much easier to be solved with both accuracy and efficiency. [sent-418, score-0.125]
</p><p>91 An augmented lagrangian approach to the constrained optimization formulation of imaging inverse problems. [sent-427, score-0.122]
</p><p>92 An multi-scale augmented lagrangian approach to general dictionary learning for image denosing. [sent-473, score-0.105]
</p><p>93 Oscillating patterns in image processing and nonlinear evolution equations: the fifteenth Dean Jacqueline B. [sent-484, score-0.077]
</p><p>94 Image decomposition and restoration using total variation minimization and the l1 norm. [sent-495, score-0.186]
</p><p>95 Decorrelating the structure and texture components of a variational decomposition model. [sent-528, score-0.417]
</p><p>96 Augmented lagrangian alternating direction method for matrix separation based on low-rank factorization. [sent-534, score-0.165]
</p><p>97 Adaptive image decomposition into cartoon and texture parts optimized by the orthogonality criterion. [sent-539, score-0.792]
</p><p>98 Alternating direction algorithm for total variation deconvolution in image deconstrution. [sent-544, score-0.077]
</p><p>99 Modeling textures with total variation minimization and oscillating patterns in image processing. [sent-551, score-0.161]
</p><p>100 Image cartoon-texture decomposition and feature selection using the total variation regularized l 1 functional. [sent-585, score-0.186]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sgtd', 0.669), ('cartoon', 0.417), ('rtv', 0.304), ('texture', 0.209), ('dix', 0.186), ('decorrelating', 0.172), ('dosv', 0.137), ('decomposition', 0.128), ('osv', 0.08), ('regularizer', 0.079), ('xk', 0.068), ('argmxin', 0.066), ('lagrangian', 0.063), ('oscillating', 0.053), ('gradient', 0.05), ('zk', 0.049), ('osher', 0.049), ('yk', 0.046), ('alternating', 0.046), ('yik', 0.046), ('fi', 0.043), ('adm', 0.042), ('augmented', 0.042), ('xi', 0.042), ('separation', 0.037), ('variation', 0.035), ('zebra', 0.035), ('barbara', 0.035), ('fishmosaic', 0.034), ('goldfarb', 0.034), ('nontextural', 0.034), ('pompeii', 0.034), ('shahidi', 0.034), ('szolgay', 0.034), ('vese', 0.034), ('windowed', 0.034), ('wotao', 0.034), ('textural', 0.034), ('nonlinear', 0.033), ('apparent', 0.033), ('tv', 0.032), ('yi', 0.032), ('dxk', 0.03), ('dixk', 0.03), ('meyer', 0.03), ('ade', 0.029), ('magnitude', 0.029), ('structure', 0.029), ('eliminate', 0.029), ('textures', 0.028), ('meaningful', 0.028), ('norm', 0.027), ('rudin', 0.027), ('decorrelated', 0.027), ('component', 0.026), ('components', 0.026), ('regularization', 0.026), ('rof', 0.025), ('modifying', 0.025), ('transactions', 0.025), ('animal', 0.025), ('fidelity', 0.025), ('variational', 0.025), ('tiger', 0.024), ('bsds', 0.024), ('displays', 0.023), ('scientific', 0.023), ('total', 0.023), ('subsection', 0.023), ('patterns', 0.022), ('numerical', 0.022), ('processing', 0.022), ('mathematical', 0.022), ('freedom', 0.022), ('girl', 0.021), ('exhibits', 0.021), ('parameter', 0.021), ('coefficient', 0.021), ('parts', 0.02), ('sgn', 0.02), ('incoherence', 0.02), ('correlation', 0.02), ('solver', 0.02), ('siam', 0.019), ('zi', 0.019), ('direction', 0.019), ('slow', 0.018), ('orthogonality', 0.018), ('journal', 0.018), ('structural', 0.018), ('subproblems', 0.018), ('inherent', 0.017), ('imaging', 0.017), ('gray', 0.017), ('correction', 0.017), ('additionally', 0.017), ('decomposing', 0.016), ('fine', 0.016), ('al', 0.016), ('dong', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="364-tfidf-1" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>Author: Qiegen Liu, Jianbo Liu, Pei Dong, Dong Liang</p><p>Abstract: This paper presents a novel structure gradient and texture decorrelating regularization (SGTD) for image decomposition. The motivation of the idea is under the assumption that the structure gradient and texture components should be properly decorrelated for a successful decomposition. The proposed model consists of the data fidelity term, total variation regularization and the SGTD regularization. An augmented Lagrangian method is proposed to address this optimization issue, by first transforming the unconstrained problem to an equivalent constrained problem and then applying an alternating direction method to iteratively solve the subproblems. Experimental results demonstrate that the proposed method presents better or comparable performance as state-of-the-art methods do.</p><p>2 0.065974638 <a title="364-tfidf-2" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>Author: Jia Xu, Vamsi K. Ithapu, Lopamudra Mukherjee, James M. Rehg, Vikas Singh</p><p>Abstract: We study the problem of online subspace learning in the context of sequential observations involving structured perturbations. In online subspace learning, the observations are an unknown mixture of two components presented to the model sequentially the main effect which pertains to the subspace and a residual/error term. If no additional requirement is imposed on the residual, it often corresponds to noise terms in the signal which were unaccounted for by the main effect. To remedy this, one may impose ‘structural’ contiguity, which has the intended effect of leveraging the secondary terms as a covariate that helps the estimation of the subspace itself, instead of merely serving as a noise residual. We show that the corresponding online estimation procedure can be written as an approximate optimization process on a Grassmannian. We propose an efficient numerical solution, GOSUS, Grassmannian Online Subspace Updates with Structured-sparsity, for this problem. GOSUS is expressive enough in modeling both homogeneous perturbations of the subspace and structural contiguities of outliers, and after certain manipulations, solvable — via an alternating direction method of multipliers (ADMM). We evaluate the empirical performance of this algorithm on two problems of interest: online background subtraction and online multiple face tracking, and demonstrate that it achieves competitive performance with the state-of-the-art in near real time.</p><p>3 0.056371693 <a title="364-tfidf-3" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>Author: Chang Ma, Zhongqian Dong, Tingting Jiang, Yizhou Wang, Wen Gao</p><p>Abstract: In thispaper, wepropose a novelperception-based shape decomposition method which aims to decompose a shape into semantically meaningful parts. In addition to three popular perception rules (the Minima rule, the Short-cut rule and the Convexity rule) in shape decomposition, we propose a new rule named part-similarity rule to encourage consistent partition of similar parts. The problem is formulated as a quadratically constrained quadratic program (QCQP) problem and is solved by a trust-region method. Experiment results on MPEG-7 dataset show that we can get a more consistent shape decomposition with human perception compared with other state-of-the-art methods both qualitatively and quantitatively. Finally, we show the advantage of semantic parts over non-meaningful parts in object detection on the ETHZ dataset.</p><p>4 0.056351811 <a title="364-tfidf-4" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>Author: Carlos Fernandez-Granda, Emmanuel J. Candès</p><p>Abstract: We present a framework to super-resolve planar regions found in urban scenes and other man-made environments by taking into account their 3D geometry. Such regions have highly structured straight edges, but this prior is challenging to exploit due to deformations induced by the projection onto the imaging plane. Our method factors out such deformations by using recently developed tools based on convex optimization to learn a transform that maps the image to a domain where its gradient has a simple group-sparse structure. This allows to obtain a novel convex regularizer that enforces global consistency constraints between the edges of the image. Computational experiments with real images show that this data-driven approach to the design of regularizers promoting transform-invariant group sparsity is very effective at high super-resolution factors. We view our approach as complementary to most recent superresolution methods, which tend to focus on hallucinating high-frequency textures.</p><p>5 0.053528007 <a title="364-tfidf-5" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>Author: Jan Lellmann, Evgeny Strekalovskiy, Sabrina Koetter, Daniel Cremers</p><p>Abstract: While total variation is among the most popular regularizers for variational problems, its extension to functions with values in a manifold is an open problem. In this paper, we propose the first algorithm to solve such problems which applies to arbitrary Riemannian manifolds. The key idea is to reformulate the variational problem as a multilabel optimization problem with an infinite number of labels. This leads to a hard optimization problem which can be approximately solved using convex relaxation techniques. The framework can be easily adapted to different manifolds including spheres and three-dimensional rotations, and allows to obtain accurate solutions even with a relatively coarse discretization. With numerous examples we demonstrate that the proposed framework can be applied to variational models that incorporate chromaticity values, normal fields, or camera trajectories.</p><p>6 0.051250432 <a title="364-tfidf-6" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>7 0.047891464 <a title="364-tfidf-7" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>8 0.047095299 <a title="364-tfidf-8" href="./iccv-2013-Decomposing_Bag_of_Words_Histograms.html">104 iccv-2013-Decomposing Bag of Words Histograms</a></p>
<p>9 0.04310438 <a title="364-tfidf-9" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>10 0.042248826 <a title="364-tfidf-10" href="./iccv-2013-A_Simple_Model_for_Intrinsic_Image_Decomposition_with_Depth_Cues.html">30 iccv-2013-A Simple Model for Intrinsic Image Decomposition with Depth Cues</a></p>
<p>11 0.041650638 <a title="364-tfidf-11" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<p>12 0.040334728 <a title="364-tfidf-12" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>13 0.038754761 <a title="364-tfidf-13" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>14 0.037498962 <a title="364-tfidf-14" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>15 0.036887892 <a title="364-tfidf-15" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>16 0.035162035 <a title="364-tfidf-16" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>17 0.033976842 <a title="364-tfidf-17" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>18 0.033541877 <a title="364-tfidf-18" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>19 0.033237431 <a title="364-tfidf-19" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>20 0.033104513 <a title="364-tfidf-20" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.087), (1, -0.014), (2, -0.019), (3, -0.018), (4, -0.035), (5, 0.008), (6, -0.005), (7, 0.006), (8, 0.014), (9, -0.043), (10, -0.009), (11, -0.011), (12, -0.008), (13, -0.013), (14, 0.001), (15, 0.017), (16, -0.002), (17, 0.015), (18, -0.003), (19, 0.026), (20, 0.014), (21, 0.014), (22, -0.032), (23, -0.041), (24, 0.01), (25, 0.041), (26, 0.047), (27, -0.011), (28, 0.021), (29, -0.037), (30, 0.049), (31, -0.003), (32, -0.008), (33, 0.035), (34, 0.021), (35, -0.021), (36, 0.002), (37, -0.023), (38, 0.024), (39, -0.018), (40, 0.014), (41, -0.012), (42, 0.022), (43, 0.012), (44, 0.057), (45, 0.054), (46, -0.026), (47, 0.013), (48, 0.009), (49, -0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89334333 <a title="364-lsi-1" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>Author: Qiegen Liu, Jianbo Liu, Pei Dong, Dong Liang</p><p>Abstract: This paper presents a novel structure gradient and texture decorrelating regularization (SGTD) for image decomposition. The motivation of the idea is under the assumption that the structure gradient and texture components should be properly decorrelated for a successful decomposition. The proposed model consists of the data fidelity term, total variation regularization and the SGTD regularization. An augmented Lagrangian method is proposed to address this optimization issue, by first transforming the unconstrained problem to an equivalent constrained problem and then applying an alternating direction method to iteratively solve the subproblems. Experimental results demonstrate that the proposed method presents better or comparable performance as state-of-the-art methods do.</p><p>2 0.69588619 <a title="364-lsi-2" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>Author: Qiong Yan, Xiaoyong Shen, Li Xu, Shaojie Zhuo, Xiaopeng Zhang, Liang Shen, Jiaya Jia</p><p>Abstract: Color, infrared, and flash images captured in different fields can be employed to effectively eliminate noise and other visual artifacts. We propose a two-image restoration framework considering input images in different fields, for example, one noisy color image and one dark-flashed nearinfrared image. The major issue in such a framework is to handle structure divergence and find commonly usable edges and smooth transition for visually compelling image reconstruction. We introduce a scale map as a competent representation to explicitly model derivative-level confidence and propose new functions and a numerical solver to effectively infer it following new structural observations. Our method is general and shows a principled way for cross-field restoration.</p><p>3 0.68618602 <a title="364-lsi-3" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>Author: Mithun Das Gupta, Sanjeev Kumar</p><p>Abstract: In this paper, we investigate the properties of Lp norm (p ≤ 1) within a projection framework. We start with the (KpK T≤ equations of the neoctni-olnin efraarm optimization problem a thnde then use its key properties to arrive at an algorithm for Lp norm projection on the non-negative simplex. We compare with L1projection which needs prior knowledge of the true norm, as well as hard thresholding based sparsificationproposed in recent compressed sensing literature. We show performance improvements compared to these techniques across different vision applications.</p><p>4 0.6841135 <a title="364-lsi-4" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>Author: Tae-Hyun Oh, Hyeongwoo Kim, Yu-Wing Tai, Jean-Charles Bazin, In So Kweon</p><p>Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values. The proposed objective function implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that our approach performs better than conventional rank minimization when the number of samples is deficient, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, photometric stereo and image alignment, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.</p><p>5 0.66519099 <a title="364-lsi-5" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><p>6 0.66265452 <a title="364-lsi-6" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>7 0.65627795 <a title="364-lsi-7" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>8 0.654347 <a title="364-lsi-8" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>9 0.65169626 <a title="364-lsi-9" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>10 0.61819726 <a title="364-lsi-10" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>11 0.5986374 <a title="364-lsi-11" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>12 0.58894444 <a title="364-lsi-12" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>13 0.58671749 <a title="364-lsi-13" href="./iccv-2013-Toward_Guaranteed_Illumination_Models_for_Non-convex_Objects.html">422 iccv-2013-Toward Guaranteed Illumination Models for Non-convex Objects</a></p>
<p>14 0.58475816 <a title="364-lsi-14" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>15 0.57257015 <a title="364-lsi-15" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>16 0.56155074 <a title="364-lsi-16" href="./iccv-2013-Automatic_Kronecker_Product_Model_Based_Detection_of_Repeated_Patterns_in_2D_Urban_Images.html">55 iccv-2013-Automatic Kronecker Product Model Based Detection of Repeated Patterns in 2D Urban Images</a></p>
<p>17 0.56144112 <a title="364-lsi-17" href="./iccv-2013-Progressive_Multigrid_Eigensolvers_for_Multiscale_Spectral_Segmentation.html">329 iccv-2013-Progressive Multigrid Eigensolvers for Multiscale Spectral Segmentation</a></p>
<p>18 0.55290604 <a title="364-lsi-18" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>19 0.54775929 <a title="364-lsi-19" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>20 0.54475754 <a title="364-lsi-20" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.051), (7, 0.019), (12, 0.011), (23, 0.276), (26, 0.05), (31, 0.05), (40, 0.023), (42, 0.1), (48, 0.04), (64, 0.03), (73, 0.055), (78, 0.01), (89, 0.138), (95, 0.02), (98, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72201711 <a title="364-lda-1" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>Author: Qiegen Liu, Jianbo Liu, Pei Dong, Dong Liang</p><p>Abstract: This paper presents a novel structure gradient and texture decorrelating regularization (SGTD) for image decomposition. The motivation of the idea is under the assumption that the structure gradient and texture components should be properly decorrelated for a successful decomposition. The proposed model consists of the data fidelity term, total variation regularization and the SGTD regularization. An augmented Lagrangian method is proposed to address this optimization issue, by first transforming the unconstrained problem to an equivalent constrained problem and then applying an alternating direction method to iteratively solve the subproblems. Experimental results demonstrate that the proposed method presents better or comparable performance as state-of-the-art methods do.</p><p>2 0.67792159 <a title="364-lda-2" href="./iccv-2013-Network_Principles_for_SfM%3A_Disambiguating_Repeated_Structures_with_Local_Context.html">289 iccv-2013-Network Principles for SfM: Disambiguating Repeated Structures with Local Context</a></p>
<p>Author: Kyle Wilson, Noah Snavely</p><p>Abstract: Repeated features are common in urban scenes. Many objects, such as clock towers with nearly identical sides, or domes with strong radial symmetries, pose challenges for structure from motion. When similar but distinct features are mistakenly equated, the resulting 3D reconstructions can have errors ranging from phantom walls and superimposed structures to a complete failure to reconstruct. We present a new approach to solving such problems by considering the local visibility structure of such repeated features. Drawing upon network theory, we present a new way of scoring features using a measure of local clustering. Our model leads to a simple, fast, and highly scalable technique for disambiguating repeated features based on an analysis of an underlying visibility graph, without relying on explicit geometric reasoning. We demonstrate our method on several very large datasets drawn from Internet photo collections, and compare it to a more traditional geometry-based disambiguation technique.</p><p>3 0.65672874 <a title="364-lda-3" href="./iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</a></p>
<p>Author: Elisabeta Marinoiu, Dragos Papava, Cristian Sminchisescu</p><p>Abstract: Human motion analysis in images and video is a central computer vision problem. Yet, there are no studies that reveal how humans perceive other people in images and how accurate they are. In this paper we aim to unveil some of the processing–as well as the levels of accuracy–involved in the 3D perception of people from images by assessing the human performance. Our contributions are: (1) the construction of an experimental apparatus that relates perception and measurement, in particular the visual and kinematic performance with respect to 3D ground truth when the human subject is presented an image of a person in a given pose; (2) the creation of a dataset containing images, articulated 2D and 3D pose ground truth, as well as synchronized eye movement recordings of human subjects, shown a variety of human body configurations, both easy and difficult, as well as their ‘re-enacted’ 3D poses; (3) quantitative analysis revealing the human performance in 3D pose reenactment tasks, the degree of stability in the visual fixation patterns of human subjects, and the way it correlates with different poses. We also discuss the implications of our find- ings for the construction of visual human sensing systems.</p><p>4 0.62923986 <a title="364-lda-4" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>Author: Tianzhu Zhang, Bernard Ghanem, Si Liu, Changsheng Xu, Narendra Ahuja</p><p>Abstract: In this paper, we propose a low-rank sparse coding (LRSC) method that exploits local structure information among features in an image for the purpose of image-level classification. LRSC represents densely sampled SIFT descriptors, in a spatial neighborhood, collectively as lowrank, sparse linear combinations of codewords. As such, it casts the feature coding problem as a low-rank matrix learning problem, which is different from previous methods that encode features independently. This LRSC has a number of attractive properties. (1) It encourages sparsity in feature codes, locality in codebook construction, and low-rankness for spatial consistency. (2) LRSC encodes local features jointly by considering their low-rank structure information, and is computationally attractive. We evaluate the LRSC by comparing its performance on a set of challenging benchmarks with that of 7 popular coding and other state-of-theart methods. Our experiments show that by representing local features jointly, LRSC not only outperforms the state-ofthe-art in classification accuracy but also improves the time complexity of methods that use a similar sparse linear repre- sentation model for feature coding [36].</p><p>5 0.62691766 <a title="364-lda-5" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>Author: Heng Yang, Ioannis Patras</p><p>Abstract: In this paper we propose a method for the localization of multiple facial features on challenging face images. In the regression forests (RF) framework, observations (patches) that are extracted at several image locations cast votes for the localization of several facial features. In order to filter out votes that are not relevant, we pass them through two types of sieves, that are organised in a cascade, and which enforce geometric constraints. The first sieve filters out votes that are not consistent with a hypothesis for the location of the face center. Several sieves of the second type, one associated with each individual facial point, filter out distant votes. We propose a method that adjusts onthe-fly the proximity threshold of each second type sieve by applying a classifier which, based on middle-level features extracted from voting maps for the facial feature in question, makes a sequence of decisions on whether the threshold should be reduced or not. We validate our proposed method on two challenging datasets with images collected from the Internet in which we obtain state of the art results without resorting to explicit facial shape models. We also show the benefits of our method for proximity threshold adjustment especially on ’difficult’ face images.</p><p>6 0.58274639 <a title="364-lda-6" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>7 0.57346696 <a title="364-lda-7" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>8 0.5726406 <a title="364-lda-8" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>9 0.57226306 <a title="364-lda-9" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>10 0.57026422 <a title="364-lda-10" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>11 0.57008851 <a title="364-lda-11" href="./iccv-2013-Perspective_Motion_Segmentation_via_Collaborative_Clustering.html">314 iccv-2013-Perspective Motion Segmentation via Collaborative Clustering</a></p>
<p>12 0.56978643 <a title="364-lda-12" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>13 0.56976688 <a title="364-lda-13" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>14 0.56950951 <a title="364-lda-14" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<p>15 0.56928748 <a title="364-lda-15" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>16 0.56876987 <a title="364-lda-16" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<p>17 0.56857693 <a title="364-lda-17" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>18 0.56856185 <a title="364-lda-18" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>19 0.56845933 <a title="364-lda-19" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>20 0.56835598 <a title="364-lda-20" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
