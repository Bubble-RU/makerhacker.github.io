<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-436" href="#">iccv2013-436</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</h1>
<br/><p>Source: <a title="iccv-2013-436-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Melo_Unsupervised_Intrinsic_Calibration_2013_ICCV_paper.pdf">pdf</a></p><p>Author: R. Melo, M. Antunes, J.P. Barreto, G. Falcão, N. Gonçalves</p><p>Abstract: Estimating the amount and center ofdistortionfrom lines in the scene has been addressed in the literature by the socalled “plumb-line ” approach. In this paper we propose a new geometric method to estimate not only the distortion parameters but the entire camera calibration (up to an “angular” scale factor) using a minimum of 3 lines. We propose a new framework for the unsupervised simultaneous detection of natural image of lines and camera parameters estimation, enabling a robust calibration from a single image. Comparative experiments with existing automatic approaches for the distortion estimation and with ground truth data are presented.</p><p>Reference: <a title="iccv-2013-436-reference" href="../iccv2013_reference/iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Unsupervised intrinsic calibration from a single frame using a ”plumb-line” approach R. [sent-1, score-0.468]
</p><p>2 In this paper we propose a new geometric method to estimate not only the distortion parameters but the entire camera calibration (up to an “angular” scale factor) using a minimum of 3 lines. [sent-8, score-0.885]
</p><p>3 We propose a new framework for the unsupervised simultaneous detection of natural image of lines and camera parameters estimation, enabling a robust calibration from a single image. [sent-9, score-0.802]
</p><p>4 Comparative experiments with existing automatic approaches for the distortion estimation and with ground truth data are presented. [sent-10, score-0.328]
</p><p>5 Introduction We investigate the problem of fully calibrating an image with significant distortion without requiring any type of manual supervision. [sent-12, score-0.336]
</p><p>6 A solution for automatic, single frame calibration is specially relevant in the case of images mined from the internet, for which knowing the camera parame-  ters can be useful for multiple tasks. [sent-13, score-0.619]
</p><p>7 The article considers the case of cameras with distortion that can be described by the 1-parameter division model (DM) [7, 11], and assumes that the imaged scene has a reasonable number of straight lines. [sent-15, score-0.47]
</p><p>8 We propose for the first time a calibration algorithm that, given the image of 3 lines, it estimates the distortion, principal point, aspect ratio, and skew. [sent-16, score-0.543]
</p><p>9 Such result is not surprising if we consider that the division model has obvious resemblances with the stereographic projection used to describe the para-catadioptric sensor [3], and that para-catadioptric cameras can be fully  calibrated from a minimum of 3 line images [4]. [sent-17, score-0.346]
</p><p>10 Nevertheless, and to the best ofour knowledge, the possibility ofcalibrating the intrinsics of dioptric camera with distortion from 3 lines has never been reported. [sent-18, score-0.558]
</p><p>11 the EXIF tag, the nominal field-of-view) and only knowing the distortion in pixels still enables accurate distortion compensation with the focal length being chosen as a function of the desired resolution for the output perspective [20]. [sent-22, score-0.672]
</p><p>12 The main contribution of the paper is a processing pipeline that receives as input a set of image contours, selects the ones that are likely to be projections of lines, and outputs both the detected lines and the camera calibration parameters (see Fig. [sent-23, score-0.773]
</p><p>13 While standard ”plumb-line” calibration requires user intervention for selecting the image edges that are projection of lines, our method carries this operation in a fully automatic manner. [sent-25, score-0.572]
</p><p>14 For the uncalibrated case we use contour triplets to establish different calibration hypothesis that give raise to different UFL instances. [sent-29, score-0.58]
</p><p>15 This provides an efficient, robust manner of simultaneously detecting the line contours and finding the camera calibration. [sent-31, score-0.279]
</p><p>16 The reason for this is that the detected arc contours are usually small and, under strong occlusion, it is difficult to obtain plausible conic estimation [4] and, consequently, plausible calibration hypothesis to be used in the (UFL)-(HFL) framework. [sent-34, score-0.861]
</p><p>17 Related work The geometric calibration of cameras with distortion is a well-studied topic, with several methods and approaches being described in the literature [22]. [sent-38, score-0.81]
</p><p>18 However, none of these solutions is well suited for the automatic calibration of images mined from the internet. [sent-39, score-0.525]
</p><p>19 showed in [1] that it is possible to fully calibrate a camera with distortion using a single image of a chessboard pattern. [sent-42, score-0.421]
</p><p>20 Since we are addressing the calibration of images of natural scenes, this approach is also no solution for our problem. [sent-43, score-0.468]
</p><p>21 Given a single image, the algorithm enables to recover the distortion parameters and the principal point whenever the scene has two patterns orthogonal to each other. [sent-46, score-0.362]
</p><p>22 Contrary to what happens with conventional perspective cameras, in the case of cameras with distortion it is possible to recover calibration information from the projection of 3D lines in random position [22]. [sent-49, score-1.02]
</p><p>23 Since lines are features that often appear in natural images, with special relevance in the case of man-made environments, line-based calibration is an appealing proposition. [sent-50, score-0.627]
</p><p>24 The first contributions in camera calibration using the so-called “plumb-line” constraint go back to the 70’s when Brown suggested to model the distortion by a polynomial and estimate its parameters by straightening up the lines in the image [8]. [sent-51, score-1.014]
</p><p>25 He concluded that, similarly to para-catadioptric cameras, the lines in 3D are projected into a family of conic curves that intersect in two points and satisfy an harmonic conjugate relation with two other points [4]. [sent-55, score-0.594]
</p><p>26 He also showed that the conic where a line is projected has only two independent degrees-of-freedom (DOF) and that, if the center is known, then it is possible to estimate and correct the image distortion using a single line. [sent-56, score-0.685]
</p><p>27 proposed an algorithm for computing both the distortion parameter and the principal point from an image of 3 lines [24] using an algebraic interpretation of the division model. [sent-59, score-0.565]
</p><p>28 [9] suggested an algo-  rithm for automatically detecting lines and accomplishing the calibration following the methods of [24]. [sent-62, score-0.627]
</p><p>29 The structure of the paper is as follows: section 2 introduces some background notions, section 3 addresses the problem of camera calibration from 3 lines and section 4 addresses the problem of line extraction from calibrated images. [sent-64, score-0.884]
</p><p>30 In section 5 we present the unsupervised calibration algorithm and section 6 shows the experimental results. [sent-65, score-0.534]
</p><p>31 Points, lines and conics are represented in homogeneous coordinates. [sent-75, score-0.514]
</p><p>32 Background concepts  Throughout this article we will model the camera distortion using the so called division model [7, 11], where ξ is the negative parameter that quantifies the amount of distortion. [sent-78, score-0.454]
</p><p>33 h() is the radial distortion function that maps undistorted points u in P2 into distorted points d in P2: d  ∼  h(u)  ∼  ( 2u1  2u2  u3  + ? [sent-79, score-0.436]
</p><p>34 The distortion function 1transforms a line n into the conic Ω given by [3]:  Ω =⎝⎛ξn 2013 ξn20n23 Nn 2 13⎠⎞. [sent-82, score-0.685]
</p><p>35 (2)  It has been shown in [3] that Ω is the distorted image of a world line iff it passes through the circular points I and J, and points r+ and r−are harmonic conjugates [21] with respect to Ω:  ⎨⎧⎪rIJT +TΩ IJr−= 0 0 w it h JrI± = = ( ( 1 1i−0i )0±T? [sent-83, score-0.322]
</p><p>36 Condition for a conic to be the image of a line The conic Ω where a line is imaged is now given by transforming the result of equation 2 by the intrinsic parameters K, as shown in Fig. [sent-113, score-0.905]
</p><p>37 Since projective transformations preserve incidence and cross-ratio relations, the conic Ω must intersect the line at infinity in points I? [sent-115, score-0.648]
</p><p>38 Therefore, a conic is the image of a line iff it verifies Φω = 0, with ωT being its representation in P5 and Φ being the 3 6 matrix:  Φ =⎡⎣( a cs 2x −+− ia aη2 2) 2 a cs x +−cy ia c1 y2c0 xc0 y0 1⎦⎤(5) with  ? [sent-119, score-0.431]
</p><p>39 If the calibration parameters of the camera are known, then the conic Ω can be estimated from N ≥ 2 image points using constrained least squares [13], with equation 5 giving the set of 3 linear constraints. [sent-125, score-0.92]
</p><p>40 Minimal solution for the calibration From equation 5, we observe that the images of lines lie in a 2D subspace S of P5 that encodes the calibration. [sent-128, score-0.693]
</p><p>41 We now show how to recover the calibration parameters from 3 line images ω1, ω2 and ω3 (Fig. [sent-129, score-0.621]
</p><p>42 If the projection of a 3D line is correctly estimated in the image plane, intersecting it with the line at infinity defines points I? [sent-131, score-0.448]
</p><p>43 The principal point (cx , cy) and distortion parameter are encoded in the third orthogonal vector to the subspace of 539  (a)? [sent-138, score-0.349]
</p><p>44 Figure 2: Intersecting projections of 3D lines with the line  at  infinity. [sent-144, score-0.327]
</p><p>45 Given tree line images, we can determine this subspace and compute Λ by parametrizing the null space of the lines as follows:  N(ω1,  ω2,  ω3) = K1V1 + K2V2 + K3V3  (7)  with Φ ∈ N(ω1 , ω2 , ω3). [sent-146, score-0.353]
</p><p>46 We are only able to determine the ratio η between ξ and f2, that can be understood as the distortion parameter expressed in pixels rather than in mm. [sent-151, score-0.308]
</p><p>47 Nevertheless this coupled parameter enables to rectify the image distortion (as shown in the experiments). [sent-152, score-0.301]
</p><p>48 We can verify that, considering a fourth line projection ω4, puts no further constraints to the calibration problem. [sent-154, score-0.658]
</p><p>49 The conic curve must satisfy two linear con-  straints since it must pass by points I? [sent-155, score-0.363]
</p><p>50 This means that only 2 of the 5 DOF of the conic curve are really independent and they refer to the orientation of the plane containing the original line in 3D (see [3]). [sent-158, score-0.407]
</p><p>51 Thus, we conclude that line images ωi, with i > 3, bring no additional information about the camera calibration and it is impossible to decouple the focal length f from the distortion parameter ξ using exclusively line features. [sent-159, score-1.162]
</p><p>52 The calibration solution demonstrated above enables to determine the back-projection directions up to an angular multiplicative factor. [sent-160, score-0.521]
</p><p>53 The joint effect of noise and strong partial occlusion makes the estimation of the conic very uncertain [2]. [sent-168, score-0.303]
</p><p>54 2c we can see that the arrangement of the initial conics does not comply with the constrains derived in section 3. [sent-170, score-0.355]
</p><p>55 In this case the conics do not intersect  Ωi(0)  the line at infinity in two unique points and the harmonic relations with respect to points r? [sent-172, score-0.707]
</p><p>56 We start by estimating the likely location of the conics intersection with the line at infinity (steps 1 to 3) and then the conics a re-estimated from the corresponding image points enforcing the incidence with points I? [sent-176, score-1.024]
</p><p>57 The calibration estimation of steps 1 to 6 is sub-optimal and is used as initialization for a final iterative optimization step. [sent-180, score-0.52]
</p><p>58 (8)  ×  with G being a 6 3 matrix that encodes the calibration parameters and m being the 3 1 vector encoding the orientation of the plane that contains the line [3]. [sent-188, score-0.621]
</p><p>59 Given the conics ωi and the matrix G, computed with the calibration initialization, the corresponding vector mi is determined linearly. [sent-189, score-0.823]
</p><p>60 Let be contour point j = 1···Ni belonging to the ith conic wi. [sent-190, score-0.303]
</p><p>61 The bundle adjustment of the calibration parameters is carried by minimizing the function of equation 9:  qj(i)  f =a,s,cxm,ciyn,η,mi ? [sent-191, score-0.524]
</p><p>62 the camera is skewless and has square pixels), then the 3 first steps can be skipped and the calibration carried trough 4 to 7. [sent-200, score-0.58]
</p><p>63 Line extraction from a calibrated image Let us assume a calibrated image with distortion for which we want to detect projections of world straight lines. [sent-202, score-0.461]
</p><p>64 We start by applying a standard edge detector [10], followed by a connected components algorithm in order to obtain several contours ei that are line projection candidates. [sent-203, score-0.38]
</p><p>65 We  aim at identifying the contours ei that support conics ωj lying on the 2D subspace S ∈ P5 defined by the calibration parameters. [sent-204, score-1.025]
</p><p>66 This can be seen as a multi-model fitting problem where the models are the conics ωj consistent with the calibration and we want to assign to each contour ei a model (or discard the contour in case it does not fit any model). [sent-205, score-0.986]
</p><p>67 Consider a set V0 comprising M possible facility locations, the cost ci0j for assigning the facility ωj0 to the customer ei and the cost vj0 for opening the particular facility ωj0. [sent-210, score-1.207]
</p><p>68 Intersect each conic with the line at infinity and obtain Ii? [sent-217, score-0.469]
</p><p>69 (Re)-estimate the conics using constrained least squares [13], forcing them to intersect I? [sent-227, score-0.41]
</p><p>70 Given the conics Ωi=1···3 compute a basis for the null space N and determine the Λ vector by solving equation 7. [sent-231, score-0.42]
</p><p>71 Refine the calibration result by minimizing equation 8 using iterative optimization (equation 9). [sent-235, score-0.502]
</p><p>72 goal of the UFL problem is to select a subset of V0 such that each customer is served by one facility and the sum of the customer-facility costs plus the sum of facility opening costs is minimized. [sent-236, score-0.87]
</p><p>73 The objective is to assign to each segment ei an image conic ωj0 ∈ V0 using as few unique models as possible. [sent-258, score-0.385]
</p><p>74 Consider that the segments ei are the customers and the putative conics ωj0 are the facilities. [sent-259, score-0.565]
</p><p>75 Let the cost ci0j be the root mean square geometric distance between points of ei and conic ωj0. [sent-260, score-0.468]
</p><p>76 The goal is to select a subset of conics in V0 such that sum of the consistency measures ci0j and the costs vj0 is minimized, which corresponds to the minimization of Eq. [sent-262, score-0.407]
</p><p>77 It can be seen that the line extraction al-  gorithm successfully identifies the correct lines and clusters disconnected segments in the same line. [sent-266, score-0.329]
</p><p>78 Unsupervised  Plumb-line  calibration using  RANSAC-UFL In the previous section we presented an algorithm that, given the calibration, detects and estimates distorted world lines projections. [sent-268, score-0.69]
</p><p>79 This section considers the unsupervised calibration of the camera, which consists in simultaneously determining a suitable set of calibration parameters along with the corresponding world line projections in the image. [sent-269, score-1.226]
</p><p>80 Consider a set of M facility locations V0 and L storage facilities V1. [sent-274, score-0.425]
</p><p>81 In addition to the costs vj0 and ci0j described in the previous section, we now add the cost vj1 for opening the storage facility Γk1, and the cost cj1k associated with the facility Γk1 supplying the facility ωj0. [sent-275, score-1.136]
</p><p>82 11 are that if a facility ωj0 is closed in layer 0, then ωj0 will not need to be stocked by a storage facility Γj1, whereas if a facility ωj0 is open, then it must be stocked by a facility in layer 1. [sent-289, score-1.524]
</p><p>83 Γk1 are calibration hypothesis and ωj0 are conics estimated  from segments ei constrained by the associated calibration. [sent-292, score-1.0]
</p><p>84 Since only one calibration Γk1 is desirable, the penalization vk1 should be very high. [sent-301, score-0.499]
</p><p>85 For each generated Γk1 we compute the M conics ωj0 that are consistent with the calibration Γk1 and minimize the geometric distance of ei to ωj0 (the method described in section 3. [sent-303, score-0.962]
</p><p>86 Our HFL formulation retrieves a single calibration by setting the connection costs cj1k between ωj0 and Γk1 as  cj1k=? [sent-325, score-0.52]
</p><p>87 Being formulated as a HFL problem, the unsupervised calibration algorithm can be computationally intensive if the number of segments ei and/or the number of calibration hypothesis Γk is high. [sent-329, score-1.179]
</p><p>88 We show that our HFL problem can be efficiently solved as a minimization over a calibration dependent function fΓ1k (x0), which in turn is the result of solving the UFL problem (please refer to the supplementary material for details): N  fΓ1k(x0) = mx0in? [sent-330, score-0.468]
</p><p>89 The RANSAC-UFL randomly samples triplets of connected components, generating calibration hypothesis Γk1. [sent-340, score-0.55]
</p><p>90 The calibration with the lowest UFL energy fΓ1k (x0) is the output of the unsupervised calibration. [sent-343, score-0.534]
</p><p>91 Experimental results To evaluate our unsupervised calibration accuracy we compared the camera parameters estimation in 8 image of a cluttered environment against ground truth calibration obtained with [1]. [sent-345, score-1.138]
</p><p>92 7, we compare our approach with [9] by correcting the radial distortion in some images dominated by straight world lines, showing that out approach outperforms [9] for the estimation of the center and amount of distortion in both robustness and accuracy. [sent-351, score-0.714]
</p><p>93 For each scene we show the segment ei on the top and the resulting distortion correction in the bottom. [sent-365, score-0.428]
</p><p>94 Conclusion In this work we have proposed a new method for the calibration of a camera using a minimum of 3 natural lines in a single image. [sent-367, score-0.714]
</p><p>95 Our work is based on a solid geometric interpretation of the line projection under the division model in perspective cameras and is able to estimate the principal point, aspect ratio, skew angle and a coupled parameter of the distortion and focal distance. [sent-368, score-0.809]
</p><p>96 For unsupervised camera calibration, we devised a framework for the joint line detection and calibration parameters estimation from a single image, that has been tested in challenging situations. [sent-369, score-0.801]
</p><p>97 General central projection systems, modeling, calibration and visual servoing. [sent-386, score-0.548]
</p><p>98 Solving the uncapacitated facility location problem using message passing algorithms. [sent-474, score-0.366]
</p><p>99 A new solution for camera calibration and real-time image distortion correction in medical endoscopy - initial technical evaluation. [sent-496, score-0.874]
</p><p>100 A simple method of radial distortion correction with centre of distortion estimation. [sent-525, score-0.66]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('calibration', 0.468), ('conics', 0.355), ('facility', 0.323), ('distortion', 0.278), ('conic', 0.276), ('ufl', 0.259), ('hfl', 0.251), ('lines', 0.159), ('line', 0.131), ('barreto', 0.111), ('ei', 0.109), ('camera', 0.087), ('skew', 0.078), ('lifted', 0.069), ('unsupervised', 0.066), ('facilities', 0.065), ('radial', 0.063), ('bukhari', 0.063), ('stocked', 0.063), ('infinity', 0.062), ('division', 0.061), ('contours', 0.061), ('projection', 0.059), ('lazic', 0.056), ('intersect', 0.055), ('costs', 0.052), ('customer', 0.051), ('cy', 0.047), ('uncapacited', 0.042), ('correction', 0.041), ('focal', 0.041), ('principal', 0.039), ('calibrated', 0.039), ('segments', 0.039), ('opening', 0.038), ('harmonic', 0.038), ('storage', 0.037), ('coimbra', 0.037), ('projections', 0.037), ('calibrating', 0.036), ('cx', 0.036), ('aspect', 0.036), ('imaged', 0.035), ('cameras', 0.034), ('dioptric', 0.034), ('customers', 0.034), ('givoni', 0.034), ('mined', 0.034), ('straight', 0.034), ('world', 0.034), ('equation', 0.034), ('calibrate', 0.034), ('triplets', 0.033), ('points', 0.033), ('intersecting', 0.032), ('incidence', 0.032), ('projective', 0.032), ('subspace', 0.032), ('jk', 0.031), ('null', 0.031), ('served', 0.031), ('exif', 0.031), ('penalization', 0.031), ('geometric', 0.03), ('ratio', 0.03), ('knowing', 0.03), ('multiplicative', 0.03), ('hypothesis', 0.029), ('distorted', 0.029), ('putative', 0.028), ('algebraic', 0.028), ('qt', 0.028), ('article', 0.028), ('contour', 0.027), ('must', 0.027), ('estimation', 0.027), ('ml', 0.027), ('frey', 0.027), ('decouple', 0.026), ('steps', 0.025), ('manhattan', 0.024), ('iff', 0.024), ('sturm', 0.023), ('uncalibrated', 0.023), ('automatic', 0.023), ('enables', 0.023), ('location', 0.023), ('fully', 0.022), ('tag', 0.022), ('perspective', 0.022), ('vanishing', 0.022), ('parameters', 0.022), ('lens', 0.022), ('dof', 0.022), ('central', 0.021), ('layer', 0.021), ('cost', 0.02), ('message', 0.02), ('unifying', 0.02), ('connected', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="436-tfidf-1" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>Author: R. Melo, M. Antunes, J.P. Barreto, G. Falcão, N. Gonçalves</p><p>Abstract: Estimating the amount and center ofdistortionfrom lines in the scene has been addressed in the literature by the socalled “plumb-line ” approach. In this paper we propose a new geometric method to estimate not only the distortion parameters but the entire camera calibration (up to an “angular” scale factor) using a minimum of 3 lines. We propose a new framework for the unsupervised simultaneous detection of natural image of lines and camera parameters estimation, enabling a robust calibration from a single image. Comparative experiments with existing automatic approaches for the distortion estimation and with ground truth data are presented.</p><p>2 0.27579275 <a title="436-tfidf-2" href="./iccv-2013-Minimal_Basis_Facility_Location_for_Subspace_Segmentation.html">264 iccv-2013-Minimal Basis Facility Location for Subspace Segmentation</a></p>
<p>Author: Choon-Meng Lee, Loong-Fah Cheong</p><p>Abstract: In contrast to the current motion segmentation paradigm that assumes independence between the motion subspaces, we approach the motion segmentation problem by seeking the parsimonious basis set that can represent the data. Our formulation explicitly looks for the overlap between subspaces in order to achieve a minimal basis representation. This parsimonious basis set is important for the performance of our model selection scheme because the sharing of basis results in savings of model complexity cost. We propose the use of affinity propagation based method to determine the number of motion. The key lies in the incorporation of a global cost model into the factor graph, serving the role of model complexity. The introduction of this global cost model requires additional message update in the factor graph. We derive an efficient update for the new messages associated with this global cost model. An important step in the use of affinity propagation is the subspace hypotheses generation. We use the row-sparse convex proxy solution as an initialization strategy. We further encourage the selection of subspace hypotheses with shared basis by integrat- ing a discount scheme that lowers the factor graph facility cost based on shared basis. We verified the model selection and classification performance of our proposed method on both the original Hopkins 155 dataset and the more balanced Hopkins 380 dataset.</p><p>3 0.19076987 <a title="436-tfidf-3" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>4 0.16995393 <a title="436-tfidf-4" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>Author: Jae-Hak Kim, Yuchao Dai, Hongdong Li, Xin Du, Jonghyuk Kim</p><p>Abstract: We present a new multi-view 3D Euclidean reconstruction method for arbitrary uncalibrated radially-symmetric cameras, which needs no calibration or any camera model parameters other than radial symmetry. It is built on the radial 1D camera model [25], a unified mathematical abstraction to different types of radially-symmetric cameras. We formulate the problem of multi-view reconstruction for radial 1D cameras as a matrix rank minimization problem. Efficient implementation based on alternating direction continuation is proposed to handle scalability issue for real-world applications. Our method applies to a wide range of omnidirectional cameras including both dioptric and catadioptric (central and non-central) cameras. Additionally, our method deals with complete and incomplete measurements under a unified framework elegantly. Experiments on both synthetic and real images from various types of cameras validate the superior performance of our new method, in terms of numerical accuracy and robustness.</p><p>5 0.15725809 <a title="436-tfidf-5" href="./iccv-2013-Lifting_3D_Manhattan_Lines_from_a_Single_Image.html">250 iccv-2013-Lifting 3D Manhattan Lines from a Single Image</a></p>
<p>Author: Srikumar Ramalingam, Matthew Brand</p><p>Abstract: We propose a novel and an efficient method for reconstructing the 3D arrangement of lines extracted from a single image, using vanishing points, orthogonal structure, and an optimization procedure that considers all plausible connectivity constraints between lines. Line detection identifies a large number of salient lines that intersect or nearly intersect in an image, but relatively a few of these apparent junctions correspond to real intersections in the 3D scene. We use linear programming (LP) to identify a minimal set of least-violated connectivity constraints that are sufficient to unambiguously reconstruct the 3D lines. In contrast to prior solutions that primarily focused on well-behaved synthetic line drawings with severely restricting assumptions, we develop an algorithm that can work on real images. The algorithm produces line reconstruction by identifying 95% correct connectivity constraints in York Urban database, with a total computation time of 1 second per image.</p><p>6 0.12838513 <a title="436-tfidf-6" href="./iccv-2013-Real-World_Normal_Map_Capture_for_Nearly_Flat_Reflective_Surfaces.html">343 iccv-2013-Real-World Normal Map Capture for Nearly Flat Reflective Surfaces</a></p>
<p>7 0.12463311 <a title="436-tfidf-7" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>8 0.11741505 <a title="436-tfidf-8" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>9 0.1120016 <a title="436-tfidf-9" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>10 0.10844391 <a title="436-tfidf-10" href="./iccv-2013-Modeling_the_Calibration_Pipeline_of_the_Lytro_Camera_for_High_Quality_Light-Field_Image_Reconstruction.html">271 iccv-2013-Modeling the Calibration Pipeline of the Lytro Camera for High Quality Light-Field Image Reconstruction</a></p>
<p>11 0.10594846 <a title="436-tfidf-11" href="./iccv-2013-Extrinsic_Camera_Calibration_without_a_Direct_View_Using_Spherical_Mirror.html">152 iccv-2013-Extrinsic Camera Calibration without a Direct View Using Spherical Mirror</a></p>
<p>12 0.10313336 <a title="436-tfidf-12" href="./iccv-2013-Rectangling_Stereographic_Projection_for_Wide-Angle_Image_Visualization.html">346 iccv-2013-Rectangling Stereographic Projection for Wide-Angle Image Visualization</a></p>
<p>13 0.10170691 <a title="436-tfidf-13" href="./iccv-2013-Elastic_Fragments_for_Dense_Scene_Reconstruction.html">139 iccv-2013-Elastic Fragments for Dense Scene Reconstruction</a></p>
<p>14 0.08908245 <a title="436-tfidf-14" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>15 0.087700225 <a title="436-tfidf-15" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>16 0.079086438 <a title="436-tfidf-16" href="./iccv-2013-Space-Time_Tradeoffs_in_Photo_Sequencing.html">397 iccv-2013-Space-Time Tradeoffs in Photo Sequencing</a></p>
<p>17 0.075756282 <a title="436-tfidf-17" href="./iccv-2013-Refractive_Structure-from-Motion_on_Underwater_Images.html">348 iccv-2013-Refractive Structure-from-Motion on Underwater Images</a></p>
<p>18 0.072963312 <a title="436-tfidf-18" href="./iccv-2013-Geometric_Registration_Based_on_Distortion_Estimation.html">183 iccv-2013-Geometric Registration Based on Distortion Estimation</a></p>
<p>19 0.07176955 <a title="436-tfidf-19" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>20 0.071721479 <a title="436-tfidf-20" href="./iccv-2013-Camera_Alignment_Using_Trajectory_Intersections_in_Unsynchronized_Videos.html">68 iccv-2013-Camera Alignment Using Trajectory Intersections in Unsynchronized Videos</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.139), (1, -0.113), (2, -0.048), (3, 0.017), (4, -0.031), (5, 0.057), (6, 0.026), (7, -0.073), (8, 0.066), (9, -0.009), (10, 0.052), (11, -0.024), (12, -0.132), (13, 0.013), (14, 0.007), (15, 0.047), (16, 0.078), (17, 0.147), (18, -0.021), (19, 0.0), (20, 0.024), (21, -0.114), (22, -0.044), (23, -0.025), (24, -0.049), (25, 0.022), (26, -0.023), (27, -0.041), (28, -0.081), (29, -0.03), (30, -0.067), (31, 0.052), (32, -0.04), (33, -0.05), (34, -0.102), (35, -0.016), (36, -0.08), (37, -0.083), (38, 0.042), (39, -0.04), (40, 0.139), (41, -0.06), (42, 0.041), (43, -0.023), (44, -0.032), (45, -0.005), (46, 0.025), (47, -0.054), (48, 0.04), (49, -0.003)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96065146 <a title="436-lsi-1" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>Author: R. Melo, M. Antunes, J.P. Barreto, G. Falcão, N. Gonçalves</p><p>Abstract: Estimating the amount and center ofdistortionfrom lines in the scene has been addressed in the literature by the socalled “plumb-line ” approach. In this paper we propose a new geometric method to estimate not only the distortion parameters but the entire camera calibration (up to an “angular” scale factor) using a minimum of 3 lines. We propose a new framework for the unsupervised simultaneous detection of natural image of lines and camera parameters estimation, enabling a robust calibration from a single image. Comparative experiments with existing automatic approaches for the distortion estimation and with ground truth data are presented.</p><p>2 0.81625152 <a title="436-lsi-2" href="./iccv-2013-Rectangling_Stereographic_Projection_for_Wide-Angle_Image_Visualization.html">346 iccv-2013-Rectangling Stereographic Projection for Wide-Angle Image Visualization</a></p>
<p>Author: Che-Han Chang, Min-Chun Hu, Wen-Huang Cheng, Yung-Yu Chuang</p><p>Abstract: This paper proposes a new projection model for mapping a hemisphere to a plane. Such a model can be useful for viewing wide-angle images. Our model consists of two steps. In the first step, the hemisphere is projected onto a swung surface constructed by a circular profile and a rounded rectangular trajectory. The second step maps the projected image on the swung surface onto the image plane through the perspective projection. We also propose a method for automatically determining proper parameters for the projection model based on image content. The proposed model has several advantages. It is simple, efficient and easy to control. Most importantly, it makes a better compromise between distortion minimization and line preserving than popular projection models, such as stereographic and Pannini projections. Experiments and analysis demonstrate the effectiveness of our model.</p><p>3 0.81277686 <a title="436-lsi-3" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>4 0.79397804 <a title="436-lsi-4" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>5 0.7899586 <a title="436-lsi-5" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>Author: Lilian Calvet, Pierre Gurdjos</p><p>Abstract: This work aims at introducing a new unified Structurefrom-Motion (SfM) paradigm in which images of circular point-pairs can be combined with images of natural points. An imaged circular point-pair encodes the 2D Euclidean structure of a world plane and can easily be derived from the image of a planar shape, especially those including circles. A classical SfM method generally runs two steps: first a projective factorization of all matched image points (into projective cameras and points) and second a camera selfcalibration that updates the obtained world from projective to Euclidean. This work shows how to introduce images of circular points in these two SfM steps while its key contribution is to provide the theoretical foundations for combining “classical” linear self-calibration constraints with additional ones derived from such images. We show that the two proposed SfM steps clearly contribute to better results than the classical approach. We validate our contributions on synthetic and real images.</p><p>6 0.76934063 <a title="436-lsi-6" href="./iccv-2013-Extrinsic_Camera_Calibration_without_a_Direct_View_Using_Spherical_Mirror.html">152 iccv-2013-Extrinsic Camera Calibration without a Direct View Using Spherical Mirror</a></p>
<p>7 0.76288146 <a title="436-lsi-7" href="./iccv-2013-Refractive_Structure-from-Motion_on_Underwater_Images.html">348 iccv-2013-Refractive Structure-from-Motion on Underwater Images</a></p>
<p>8 0.75716567 <a title="436-lsi-8" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>9 0.7354303 <a title="436-lsi-9" href="./iccv-2013-Lifting_3D_Manhattan_Lines_from_a_Single_Image.html">250 iccv-2013-Lifting 3D Manhattan Lines from a Single Image</a></p>
<p>10 0.73193896 <a title="436-lsi-10" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>11 0.66101903 <a title="436-lsi-11" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>12 0.60766417 <a title="436-lsi-12" href="./iccv-2013-Real-World_Normal_Map_Capture_for_Nearly_Flat_Reflective_Surfaces.html">343 iccv-2013-Real-World Normal Map Capture for Nearly Flat Reflective Surfaces</a></p>
<p>13 0.56730491 <a title="436-lsi-13" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>14 0.55106807 <a title="436-lsi-14" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>15 0.54861474 <a title="436-lsi-15" href="./iccv-2013-Space-Time_Tradeoffs_in_Photo_Sequencing.html">397 iccv-2013-Space-Time Tradeoffs in Photo Sequencing</a></p>
<p>16 0.54129118 <a title="436-lsi-16" href="./iccv-2013-Complex_3D_General_Object_Reconstruction_from_Line_Drawings.html">84 iccv-2013-Complex 3D General Object Reconstruction from Line Drawings</a></p>
<p>17 0.53461552 <a title="436-lsi-17" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>18 0.50329322 <a title="436-lsi-18" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>19 0.49348864 <a title="436-lsi-19" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>20 0.47750348 <a title="436-lsi-20" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.058), (7, 0.051), (12, 0.013), (26, 0.074), (27, 0.029), (31, 0.056), (34, 0.01), (42, 0.113), (64, 0.04), (68, 0.147), (71, 0.05), (73, 0.028), (89, 0.2), (98, 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90133131 <a title="436-lda-1" href="./iccv-2013-How_Related_Exemplars_Help_Complex_Event_Detection_in_Web_Videos%3F.html">203 iccv-2013-How Related Exemplars Help Complex Event Detection in Web Videos?</a></p>
<p>Author: Yi Yang, Zhigang Ma, Zhongwen Xu, Shuicheng Yan, Alexander G. Hauptmann</p><p>Abstract: Compared to visual concepts such as actions, scenes and objects, complex event is a higher level abstraction of longer video sequences. For example, a “marriage proposal” event is described by multiple objects (e.g., ring, faces), scenes (e.g., in a restaurant, outdoor) and actions (e.g., kneeling down). The positive exemplars which exactly convey the precise semantic of an event are hard to obtain. It would be beneficial to utilize the related exemplars for complex event detection. However, the semantic correlations between related exemplars and the target event vary substantially as relatedness assessment is subjective. Two related exemplars can be about completely different events, e.g., in the TRECVID MED dataset, both bicycle riding and equestrianism are labeled as related to “attempting a bike trick” event. To tackle the subjectiveness of human assessment, our algorithm automatically evaluates how positive the related exemplars are for the detection of an event and uses them on an exemplar-specific basis. Experiments demonstrate that our algorithm is able to utilize related exemplars adaptively, and the algorithm gains good perform- z. ance for complex event detection.</p><p>same-paper 2 0.89088202 <a title="436-lda-2" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>Author: R. Melo, M. Antunes, J.P. Barreto, G. Falcão, N. Gonçalves</p><p>Abstract: Estimating the amount and center ofdistortionfrom lines in the scene has been addressed in the literature by the socalled “plumb-line ” approach. In this paper we propose a new geometric method to estimate not only the distortion parameters but the entire camera calibration (up to an “angular” scale factor) using a minimum of 3 lines. We propose a new framework for the unsupervised simultaneous detection of natural image of lines and camera parameters estimation, enabling a robust calibration from a single image. Comparative experiments with existing automatic approaches for the distortion estimation and with ground truth data are presented.</p><p>3 0.88335437 <a title="436-lda-3" href="./iccv-2013-Learning_Coupled_Feature_Spaces_for_Cross-Modal_Matching.html">235 iccv-2013-Learning Coupled Feature Spaces for Cross-Modal Matching</a></p>
<p>Author: Kaiye Wang, Ran He, Wei Wang, Liang Wang, Tieniu Tan</p><p>Abstract: Cross-modal matching has recently drawn much attention due to the widespread existence of multimodal data. It aims to match data from different modalities, and generally involves two basic problems: the measure of relevance and coupled feature selection. Most previous works mainly focus on solving the first problem. In this paper, we propose a novel coupled linear regression framework to deal with both problems. Our method learns two projection matrices to map multimodal data into a common feature space, in which cross-modal data matching can be performed. And in the learning procedure, the ?21-norm penalties are imposed on the two projection matrices separately, which leads to select relevant and discriminative features from coupled feature spaces simultaneously. A trace norm is further imposed on the projected data as a low-rank constraint, which enhances the relevance of different modal data with connections. We also present an iterative algorithm based on halfquadratic minimization to solve the proposed regularized linear regression problem. The experimental results on two challenging cross-modal datasets demonstrate that the proposed method outperforms the state-of-the-art approaches.</p><p>4 0.86837339 <a title="436-lda-4" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>Author: Fan Wang, Qixing Huang, Leonidas J. Guibas</p><p>Abstract: Joint segmentation of image sets has great importance for object recognition, image classification, and image retrieval. In this paper, we aim to jointly segment a set of images starting from a small number of labeled images or none at all. To allow the images to share segmentation information with each other, we build a network that contains segmented as well as unsegmented images, and extract functional maps between connected image pairs based on image appearance features. These functional maps act as general property transporters between the images and, in particular, are used to transfer segmentations. We define and operate in a reduced functional space optimized so that the functional maps approximately satisfy cycle-consistency under composition in the network. A joint optimization framework is proposed to simultaneously generate all segmentation functions over the images so that they both align with local segmentation cues in each particular image, and agree with each other under network transportation. This formulation allows us to extract segmentations even with no training data, but can also exploit such data when available. The collective effect of the joint processing using functional maps leads to accurate information sharing among images and yields superior segmentation results, as shown on the iCoseg, MSRC, and PASCAL data sets.</p><p>5 0.8572014 <a title="436-lda-5" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>Author: Adrien Bartoli, Daniel Pizarro, Toby Collins</p><p>Abstract: We study the uncalibrated isometric Shape-fromTemplate problem, that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown. Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. This was achieved through two key steps. First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. We use a variational framework, implemented using a smooth function basis and sampled local deformation models. The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy – slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods.</p><p>6 0.85461998 <a title="436-lda-6" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<p>7 0.8495748 <a title="436-lda-7" href="./iccv-2013-Minimal_Basis_Facility_Location_for_Subspace_Segmentation.html">264 iccv-2013-Minimal Basis Facility Location for Subspace Segmentation</a></p>
<p>8 0.84827363 <a title="436-lda-8" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>9 0.84479731 <a title="436-lda-9" href="./iccv-2013-No_Matter_Where_You_Are%3A_Flexible_Graph-Guided_Multi-task_Learning_for_Multi-view_Head_Pose_Classification_under_Target_Motion.html">291 iccv-2013-No Matter Where You Are: Flexible Graph-Guided Multi-task Learning for Multi-view Head Pose Classification under Target Motion</a></p>
<p>10 0.84272063 <a title="436-lda-10" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>11 0.84219128 <a title="436-lda-11" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>12 0.84171993 <a title="436-lda-12" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>13 0.840675 <a title="436-lda-13" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>14 0.84056133 <a title="436-lda-14" href="./iccv-2013-Translating_Video_Content_to_Natural_Language_Descriptions.html">428 iccv-2013-Translating Video Content to Natural Language Descriptions</a></p>
<p>15 0.83945572 <a title="436-lda-15" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>16 0.83886349 <a title="436-lda-16" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>17 0.83816969 <a title="436-lda-17" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>18 0.83812737 <a title="436-lda-18" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>19 0.8379578 <a title="436-lda-19" href="./iccv-2013-PhotoOCR%3A_Reading_Text_in_Uncontrolled_Conditions.html">315 iccv-2013-PhotoOCR: Reading Text in Uncontrolled Conditions</a></p>
<p>20 0.83766812 <a title="436-lda-20" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
