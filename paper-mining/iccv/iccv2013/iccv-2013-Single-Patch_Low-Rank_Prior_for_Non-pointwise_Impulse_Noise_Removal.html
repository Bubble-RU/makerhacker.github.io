<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-394" href="#">iccv2013-394</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</h1>
<br/><p>Source: <a title="iccv-2013-394-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Wang_Single-Patch_Low-Rank_Prior_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>Reference: <a title="iccv-2013-394-reference" href="../iccv2013_reference/iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Single-patch low-rank prior for non-pointwise impulse noise removal Ruixuan Wang Emanuele Trucco School of Computing, University of Dundee, UK {ruixuanwang , manue lt rucco} @ comput ing . [sent-1, score-0.769]
</p><p>2 uk  Abstract This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. [sent-4, score-0.654]
</p><p>3 Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e. [sent-5, score-0.917]
</p><p>4 Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise. [sent-10, score-0.576]
</p><p>5 Introduction This paper aims to remove random-valued impulse noise (RVIN) with varying sizes and irregular shapes (so called ‘non-pointwise’ RVIN, e. [sent-12, score-0.784]
</p><p>6 While the original matrix recovery framework has been recently used for image and video denoising [11], it requires multiple similar image patches, with each patch vectorized as a column in the matrix. [sent-17, score-0.564]
</p><p>7 patches wpixithelisn) a single image a lnikde ltoy collaboratively and effectively remove traditional (singlepixel) RVIN. [sent-21, score-0.281]
</p><p>8 Related work  We briefly discuss related work on impulse noise removal and low-rank matrix recovery; see [2] and [12] for recent, comprehensive reviews on denoising. [sent-29, score-0.801]
</p><p>9 There are mainly two types of impulse noise: salt-andpepper noise (black or white), and RVIN (any gray value). [sent-30, score-0.665]
</p><p>10 , adaptive center weighted median filter (ACWMF) [4], rankordered absolute difference (ROAD) noise detector followed by a trilateral filtering [9], and a logarithmic version of the ROAD followed by edge-preserving regularization (EPR) for pixel restoration (ROLD-EPR) [7]. [sent-34, score-0.261]
</p><p>11 , when noise is structured rather than single-pixel, the overall noisy removal will be limited. [sent-39, score-0.254]
</p><p>12 Given the excellent performance of non-local methods [2, 5], learned sparse models [8, 18], and the combination of both [6, 17] for random Gaussian noise, they were explored for impulse noise as well [20, 22]. [sent-40, score-0.699]
</p><p>13 , self-similarity) to group similar image patches together, followed by collaborative filtering [2, 5]. [sent-43, score-0.247]
</p><p>14 Sparse methods also use redundant information by assuming each patch can be well approximated by a linear combination of a small subset of patches (‘words’) within a large dictionary. [sent-44, score-0.473]
</p><p>15 , 8 8 pixels) as it may become datifcfihcu silzt eto is f liinmdi multiple 8sim ×il 8ar p larger-size patches within an image for non-local methods, and to represent a ooppyyrriigghhtt  11007733  larger-size patch by a linear combination of other patches for sparse methods. [sent-48, score-0.688]
</p><p>16 Crucially, impulse noise often needs to be detected first to reduce the effect of noisy pixels on patch matching and dictionary learning. [sent-49, score-1.05]
</p><p>17 Similar to twostage methods, the overall accuracy of impulse noise removal is largely limited by the performance of the initial impulse noise location. [sent-50, score-1.427]
</p><p>18 A joint low-rank and sparse matrix recovery framework was recently used to detect and remove impulse noise simultaneously [11], remove background, and remove shadows and specularities from face images [3]. [sent-51, score-1.051]
</p><p>19 , 10 10 to 40 40) image patch from images of natural or mg. [sent-56, score-0.265]
</p><p>20 a,n 1-0m×a1d0e objects or scenes p(waticthhin fr our experiments, see Section 6), if rotated by a characteristic orientation defined later, has a low-rank approximation with texture details (including edges) well preserved (see Section 6. [sent-57, score-0.381]
</p><p>21 L∗ can be considered a low-rank matrix due to the lowrank prior for single patches (Section 6. [sent-61, score-0.349]
</p><p>22 Also, since the number of pixels corrupted by impulse noise is generally much smaller than the total number of pixels, S∗ is a sparse matrix. [sent-63, score-0.822]
</p><p>23 While the above optimization framework has been used for image and video denoising [11], each image patch was ∗  ×× ×  considered as a column in a matrix. [sent-87, score-0.391]
</p><p>24 (a) A synthetic clean image patch of size 40 40 pixels with (raa)nk A 2 sy0. [sent-90, score-0.347]
</p><p>25 n (hbe)t Ac c synthetic noisy patch by adding a eslmsa wliltehr (3 3 pixels) non-pointwise RVIN at the top-left corner and a larger x(9e ×s) 9 n pixels) one aer RouVnIdN th ate t cheen ttoepr. [sent-91, score-0.324]
</p><p>26 Now more specifically, using larger-size patches in the multi-patch method will generally make multiple patches less similar to each other and hence lead to over smoothing of the current patch (Figures 9 and 10). [sent-94, score-0.631]
</p><p>27 Compared to the multi-patch method, our method requires no search as it considers a single patch as the matrix P and the patch size can be larger (e. [sent-95, score-0.61]
</p><p>28 ×M 41o)re w importantly, using largersize patches allows us to remove non-pointwise RVIN. [sent-98, score-0.25]
</p><p>29 , with much higher intensity value than the signal) non-pointwise impulse noise exists, the true solutions S∗ and L∗ often correspond to a much larger λ? [sent-109, score-0.686]
</p><p>30 1 (due to the set of higher impulse noise mvaulcuehs) la arngedr modestly smaller ? [sent-111, score-0.697]
</p><p>31 , E1(L∗ , S∗) > E1 and the non-pointwise impulse noise will remain, to some extent, in the estimated optimal signal (Figure 1c). [sent-115, score-0.73]
</p><p>32 Hence we propose a generalized version of the optimization framework to denoise an image patch effectively in the presence of non-pointwise (multi-pixel) RVIN: ∗  dˆSe  sˆLm. [sent-116, score-0.296]
</p><p>33 W can encode the initially estimated spatial distribution of impulse noise in the image patch. [sent-127, score-0.718]
</p><p>34 Initial estimates, obtained by any impulse noise detector, correspond to entries in W with values close to 0. [sent-128, score-0.751]
</p><p>35 1, bweilclamu soer (ea lti lkeealyst part ospf)o tnhde higher impulse enor iλse? [sent-131, score-0.547]
</p><p>36 First, the candidate impulse Algorithm  1  APG  method  to  minimize  Equation  Algorithm 1APG method to minimize Equation (2)  (2)  Input: P, W, λ. [sent-171, score-0.587]
</p><p>37 Output:  L  = max(ρμk,μ);  ←  L,S  ←  S  noise locations in an image patch are estimated by any of the methods suggested below to obtain a binary weighting matrix W0, in which each entry is set to 1 at the initially estimated impulse noise pixels and 0 elsewhere. [sent-174, score-1.366]
</p><p>38 Consequently, eth 1e entries of W at or near the initially estimated impulse noise locations will have smaller values than elsewhere. [sent-177, score-0.848]
</p><p>39 In practice, the binary matrix W0 can be generated by any existing impulse noise detectors (e. [sent-178, score-0.724]
</p><p>40 Characteristic orientation for each patch One potential issue in denoising methods is edge blurring and loss of sharpness. [sent-185, score-0.486]
</p><p>41 For example, even a patch with a simple pattern may have a high rank (Figure 2, patch in blue rectangle). [sent-187, score-0.611]
</p><p>42 In this case, the low-rank approximation of the patch will blur the sharp edge (Figure 2b). [sent-188, score-0.326]
</p><p>43 Instead, if we can find a low-rank patch (Figure 2, patch in yellow rectangle) by rotating around the target image point, 11007755  (a)  (b)  ×× (c)  Figure 2: Effect of characteristic orientation on low-rank patch approximation. [sent-189, score-1.021]
</p><p>44 (b) A low-rank (rank 15) approximation of a 41 41 image patch around t(hraen image acpepnrteoxr. [sent-191, score-0.326]
</p><p>45 m(ca)t iTohne o olfow a- 4ra1n ×k (4r1an ikm a1)g approximation of an oriented image patch around the same point. [sent-192, score-0.387]
</p><p>46 the low-rank approximation of this patch will more likely preserve the sharpness of the edges (Figure 2c). [sent-193, score-0.465]
</p><p>47 Similar observations apply for patches with other texture patterns like corners, and experiments (Figure 8) show the importance of characteristic orientation in denoising. [sent-194, score-0.434]
</p><p>48 Based on the assumption that the optimally oriented patch is low-rank, we expect that the difference between the oriented patch and its low-rank approximation will be minimum at the optimal (‘characteristic’) orientation. [sent-195, score-0.733]
</p><p>49 To compute the latter, let P(θ) denote an oriented m n image patch haet a given image position, n ro otariteendt eadnt miclo ×c knw iimseby an orientation angle θ with respect to the image row direction, and the low-rank approximation (to a fixed quality level) of P(θ). [sent-196, score-0.482]
</p><p>50 Then the characteristic orientation at the current image position can be estimated as  P˜(θ)  ˆθ = argθ∈ m[i0n,π]d(θ) = argθ m∈[0i,nπ]m1n? [sent-197, score-0.253]
</p><p>51 Such a simple, threshold-free approximation proved effective enough to find reliably the characteristic orientation for each image patch (see Section 6. [sent-214, score-0.552]
</p><p>52 z Feo 4r1 a ×n i4m1 pixels ahn sdi z5e0 %64 overlapped by neighboring patches along 4b1ot phi dxeirlesc atniodn 5s,0 totally lita ptapkedes approximately 3 minutes to generate the denoised image. [sent-240, score-0.416]
</p><p>53 Since each image pixel is often covered by multiple patches, the final denoised value at each pixel in the image is averaged from the corresponding denoised pixels in these multiple patches. [sent-241, score-0.453]
</p><p>54 Low-rank prior in single patches We illustrate the experimental foundation of the lowrank prior for small noise-free image patches. [sent-244, score-0.317]
</p><p>55 In practice, due to noise, an image patch as a matrix is seldom lowrank. [sent-245, score-0.324]
</p><p>56 However, if the assumption of low-rank prior is true, the column-wise signal variation in an image patch should be mostly preserved in a much lower-dimensional space, and the low-rank approximation should preserve meaningful textural details. [sent-246, score-0.539]
</p><p>57 , rotated to their characteristic orientations) patches with sizes 21 21 and 41 41pixels were generated fpraotmch eeasc whi dtha tsaizseets by ×un2i1fo arnmd sampling xine lesa wche image. [sent-250, score-0.39]
</p><p>58 Every patch siisg fniarlst v decomposed by mSV ×D nan idm atghee minimum number lˆ of singular values necessary to preserve the predefined level of signal variation is determined by lˆ =  argminJ∈[1,min(m,n)]{β  < ? [sent-252, score-0.408]
</p><p>59 histogram can be easily generated recording the frequency of patches with a particular rank value. [sent-261, score-0.264]
</p><p>60 The cumulative rank histogram in Figure (3a) (thinner blue line) shows that when preserving 95% of the column-wise signal variations, about 90% image patches have low-rank approximations with rank equal or smaller than 11. [sent-262, score-0.415]
</p><p>61 9, more than 98% image patches have low-rank approximations with rank equal or smaller than 10. [sent-264, score-0.296]
</p><p>62 This shows that most oriented patches can be approximated by their low-rank versions which keep most signal variations. [sent-266, score-0.282]
</p><p>63 The second test shows that low-rank patch approxima11007766  × ×× (a)  (b)  Figure 3: Low-rank prior in image patches with size (a) 21 21 (from Caltech256) and (b) 41 41 pixels (from SceneCategory15). [sent-267, score-0.557]
</p><p>64 (a)  (b)  Figure 4: Average rank value of each cluster for image patches with size (a) 21 21 (from Caltech256) and (b) p4a1 c×h e4s1 pixels i(zfero (ma) SceneCategory15). [sent-268, score-0.346]
</p><p>65 95, most clusters have average rank values less than 10 for 21 21 patches a hnadv ele assv ethraagne e2 r0a nfokr v4a1l u×e 4s1 l patches. [sent-274, score-0.288]
</p><p>66 Within each such cluster, the highest-rank (lˆ) image patch was chosen to represent the most complex visual pattern. [sent-277, score-0.265]
</p><p>67 It can be observed that, even for the patches with most complex texture patterns, the textural details have all been preserved in the lowrank approximations. [sent-279, score-0.375]
</p><p>68 In addition, when adding RVIN to the image patches by corrupting 5% pixels in each patch, Figure 4 (dashed curves) also shows that the average rank values increased. [sent-282, score-0.349]
</p><p>69 The proposed low-rank matrix recovery framework just makes use of this observation for removing noise from image patches. [sent-285, score-0.298]
</p><p>70 Determination of characteristic orientation The first test here checks whether the determination of characteristic orientation is invariant to changes in patch sizes. [sent-288, score-0.808]
</p><p>71 As an example, we use an image patch (Figure 6a top) from a noisy and low-contrast underwater hydrocolonoscopy image (Figure 8a). [sent-289, score-0.515]
</p><p>72 Figure (6) shows that for a large range of patch sizes (e. [sent-290, score-0.317]
</p><p>73 This invariance to patch sizes is especially beneficial to denoising images with textures at different scales. [sent-295, score-0.443]
</p><p>74 The second test checks whether the orientation determination is robust to noisy patches. [sent-296, score-0.245]
</p><p>75 Given an image patch (Figure 7 top left), Figure (7) shows that the estimate of the characteristic orientation is robust to RVIN noise, even if 30% of image pixels have been damaged by RVIN. [sent-297, score-0.552]
</p><p>76 (a) An original low-contrast 41 41 image patch (top) and the oArnien otreigdi nvaelrs loiown- c(boontttroamst) 4 4(1b e×tte 4r1 1v i mewag on pmatocnhit (otorp). [sent-305, score-0.287]
</p><p>77 )(b an) dd t(θhe) over all possible orientation angles with three patch sizes. [sent-306, score-0.36]
</p><p>78 Top row (left to right): original image patch, oriented patches with noise sparsity level at 0. [sent-308, score-0.42]
</p><p>79 Bottom: estimated characteristic orientation with varying noise sparsity levels, with mean (solid curve) and standard deviation (dotted curve) values from 10 runs. [sent-316, score-0.431]
</p><p>80 In the denoised result, based on the proposed matrix recovery framework, certain edges have been blurred when using SIFT-orientation method (Figure 8e). [sent-318, score-0.345]
</p><p>81 While sampling error is introduced to the oriented patches due to rotation of the original patches, the image quality loss due to sampling error appears to be much smaller compared to image enhancement due to noise removal from the oriented patches. [sent-320, score-0.554]
</p><p>82 This is supported by Figures 8d-8f, which shows that both orientation methods perform better than without using any orientation determination (Figure 8d). [sent-321, score-0.252]
</p><p>83 Removal of impulse noise To evaluate our method quantitatively, RVIN with different sizes (e. [sent-324, score-0.717]
</p><p>84 Four denoising methods were chosen for comparison: the median filtering as the baseline method, the ROLDEPR method [7], the multi-patch low-rank matrix recovery method (MPLR) [11], and the proposed method without applying the weighting matrix W (henceforth ‘Proposed \W’). [sent-336, score-0.452]
</p><p>85 For MPLR, all the parameters were set as suggested in [11], except that four different patch sizes (i. [sent-342, score-0.317]
</p><p>86 i,l anr patches were 8s,e1ar6c,h3e2d} ()t wo generate a nd2 1 ×0 1 ad1 dmitaitornixa)l across the whole image when denoising each image patch. [sent-346, score-0.309]
</p><p>87 The highest PSNR over the different patch sizes was reported. [sent-347, score-0.338]
</p><p>88 For our method, the patch size was fixed to 31 √× 31, tphoer highest PouSNr mRe was reported over ed iwffaesr feinxte λd =o 3s1/×√3311,, where s ∈ {1. [sent-348, score-0.307]
</p><p>89 Particle removal in hydrocolonoscopy images  The proposed denoising method is also capable of removing particles in hydrocolonoscopy images, where the particles with various sizes (maximumly 15 15 pixels) were suspended riino water, creating non-pointwise RpixVeINls). [sent-404, score-0.886]
</p><p>90 Figure 10 displays an  ××  exemplar hydrocolonoscopy image and the denoised result with the MPLR and the proposed method. [sent-406, score-0.363]
</p><p>91 The patch size is 41 41 for the proposed method and 16 16 for the MPLR 4m1e×tho4d1 fino ro rthdeer p rtoo remove large-size particles. [sent-407, score-0.353]
</p><p>92 The ‘Proposed \W’ can preserve sharpness e b 1ut0 cca annndot 1 remove large-size particles effectively (Figure 10e and 10f). [sent-409, score-0.293]
</p><p>93 The proposed method can remove  (a)  (b)  (c) Figure 9: Part of denoised images from different methods  ××  with noise size (a) 1 1, (b) 2 2, and (c) 3 3 pixels. [sent-410, score-0.378]
</p><p>94 Conclusions  This paper has introduced a low-rank prior for small oriented (rotated by a characteristic orientation angle) noise11007799  (a)(b)  (c)(d) (e)(f) (g)(h) Figure 10: Removal of particles suspended in a hydrocolonoscopy image. [sent-416, score-0.647]
</p><p>95 (b) De-  ×  noised image by MPLR with patch size 16 16 pixels. [sent-418, score-0.286]
</p><p>96 The low-rank prior suggests that a single patch can be effectively denoised within a low-rank matrix recovery framework. [sent-424, score-0.646]
</p><p>97 Without resorting to other similar patches, the single-patch method can effectively remove non-pointwise RVIN within a generalized low-rank matrix recovery framework, and encode the initial estimation of noise locations effectively. [sent-425, score-0.4]
</p><p>98 Removing random Gaussian noise and video denoising will be explored as future work. [sent-427, score-0.244]
</p><p>99 A universal noise removal algorithm with an impulse detector. [sent-485, score-0.742]
</p><p>100 A restoration algorithm for images contaminated by mixed gaussian plus random-valued impulse noise. [sent-573, score-0.61]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('impulse', 0.547), ('rvin', 0.425), ('patch', 0.265), ('hydrocolonoscopy', 0.191), ('patches', 0.183), ('denoised', 0.172), ('mplr', 0.17), ('apg', 0.141), ('characteristic', 0.131), ('denoising', 0.126), ('noise', 0.118), ('orientation', 0.095), ('recovery', 0.092), ('ykl', 0.085), ('yks', 0.085), ('rank', 0.081), ('lowrank', 0.08), ('particles', 0.078), ('removal', 0.077), ('remove', 0.067), ('prof', 0.064), ('suspended', 0.064), ('determination', 0.062), ('preserve', 0.061), ('pixels', 0.061), ('approximation', 0.061), ('oriented', 0.061), ('matrix', 0.059), ('noisy', 0.059), ('psnr', 0.059), ('sharpness', 0.056), ('lk', 0.055), ('sizes', 0.052), ('sk', 0.048), ('preserved', 0.045), ('entry', 0.045), ('barbara', 0.043), ('restoration', 0.043), ('acwmf', 0.043), ('dundee', 0.043), ('gkl', 0.043), ('roldepr', 0.043), ('textural', 0.042), ('median', 0.041), ('tip', 0.041), ('entries', 0.041), ('weighting', 0.04), ('signal', 0.038), ('gks', 0.038), ('sparsity', 0.036), ('filtering', 0.035), ('egiazarian', 0.035), ('equation', 0.034), ('sparse', 0.034), ('locations', 0.033), ('water', 0.033), ('smaller', 0.032), ('accelerated', 0.032), ('lena', 0.031), ('effectively', 0.031), ('proximal', 0.031), ('tk', 0.03), ('corrupted', 0.03), ('crucially', 0.03), ('removing', 0.029), ('collaborative', 0.029), ('checks', 0.029), ('katkovnik', 0.029), ('foi', 0.028), ('road', 0.028), ('prior', 0.027), ('estimated', 0.027), ('initially', 0.026), ('nonlocal', 0.025), ('probably', 0.025), ('redundant', 0.025), ('texture', 0.025), ('rotated', 0.024), ('values', 0.024), ('spacing', 0.024), ('pixel', 0.024), ('norm', 0.023), ('eto', 0.023), ('nuclear', 0.022), ('noticed', 0.022), ('edges', 0.022), ('mairal', 0.022), ('original', 0.022), ('gradient', 0.022), ('elad', 0.022), ('convex', 0.022), ('size', 0.021), ('highest', 0.021), ('oth', 0.021), ('correspond', 0.021), ('careful', 0.02), ('gaussian', 0.02), ('minimum', 0.02), ('minimize', 0.02), ('largely', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="394-tfidf-1" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>2 0.18083788 <a title="394-tfidf-2" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>Author: Xiangfei Kong, Kuan Li, Qingxiong Yang, Liu Wenyin, Ming-Hsuan Yang</p><p>Abstract: This paper proposes a new non-reference image quality metric that can be adopted by the state-of-the-art image/video denoising algorithms for auto-denoising. The proposed metric is extremely simple and can be implemented in four lines of Matlab code1. The basic assumption employed by the proposed metric is that the noise should be independent of the original image. A direct measurement of this dependence is, however, impractical due to the relatively low accuracy of existing denoising method. The proposed metric thus aims at maximizing the structure similarity between the input noisy image and the estimated image noise around homogeneous regions and the structure similarity between the input noisy image and the denoised image around highly-structured regions, and is computed as the linear correlation coefficient of the two corresponding structure similarity maps. Numerous experimental results demonstrate that the proposed metric not only outperforms the current state-of-the-art non-reference quality metric quantitatively and qualitatively, but also better maintains temporal coherence when used for video denoising. ˜</p><p>3 0.16539359 <a title="394-tfidf-3" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>Author: Yaron Eshet, Simon Korman, Eyal Ofek, Shai Avidan</p><p>Abstract: We extend patch based methods to work on patches in 3D space. We start with Coherency Sensitive Hashing [12] (CSH), which is an algorithm for matching patches between two RGB images, and extend it to work with RGBD images. This is done by warping all 3D patches to a common virtual plane in which CSH is performed. To avoid noise due to warping of patches of various normals and depths, we estimate a group of dominant planes and compute CSH on each plane separately, before merging the matching patches. The result is DCSH - an algorithm that matches world (3D) patches in order to guide the search for image plane matches. An independent contribution is an extension of CSH, which we term Social-CSH. It allows a major speedup of the k nearest neighbor (kNN) version of CSH - its runtime growing linearly, rather than quadratically, in k. Social-CSH is used as a subcomponent of DCSH when many NNs are required, as in the case of image denoising. We show the benefits ofusing depth information to image reconstruction and image denoising, demonstrated on several RGBD images.</p><p>4 0.15483272 <a title="394-tfidf-4" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>5 0.11446773 <a title="394-tfidf-5" href="./iccv-2013-Shape_Anchors_for_Data-Driven_Multi-view_Reconstruction.html">387 iccv-2013-Shape Anchors for Data-Driven Multi-view Reconstruction</a></p>
<p>Author: Andrew Owens, Jianxiong Xiao, Antonio Torralba, William Freeman</p><p>Abstract: We present a data-driven method for building dense 3D reconstructions using a combination of recognition and multi-view cues. Our approach is based on the idea that there are image patches that are so distinctive that we can accurately estimate their latent 3D shapes solely using recognition. We call these patches shape anchors, and we use them as the basis of a multi-view reconstruction system that transfers dense, complex geometry between scenes. We “anchor” our 3D interpretation from these patches, using them to predict geometry for parts of the scene that are relatively ambiguous. The resulting algorithm produces dense reconstructions from stereo point clouds that are sparse and noisy, and we demonstrate it on a challenging dataset of real-world, indoor scenes.</p><p>6 0.11279063 <a title="394-tfidf-6" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>7 0.11108253 <a title="394-tfidf-7" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>8 0.092965364 <a title="394-tfidf-8" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>9 0.085410401 <a title="394-tfidf-9" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>10 0.083298855 <a title="394-tfidf-10" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>11 0.076221958 <a title="394-tfidf-11" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>12 0.075073116 <a title="394-tfidf-12" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>13 0.074206807 <a title="394-tfidf-13" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>14 0.073652215 <a title="394-tfidf-14" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>15 0.071219131 <a title="394-tfidf-15" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>16 0.070956744 <a title="394-tfidf-16" href="./iccv-2013-Anchored_Neighborhood_Regression_for_Fast_Example-Based_Super-Resolution.html">51 iccv-2013-Anchored Neighborhood Regression for Fast Example-Based Super-Resolution</a></p>
<p>17 0.068881966 <a title="394-tfidf-17" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>18 0.066626169 <a title="394-tfidf-18" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>19 0.055970959 <a title="394-tfidf-19" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>20 0.055369135 <a title="394-tfidf-20" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.14), (1, -0.035), (2, -0.048), (3, -0.017), (4, -0.093), (5, -0.012), (6, -0.021), (7, -0.019), (8, -0.003), (9, -0.049), (10, -0.015), (11, -0.043), (12, 0.034), (13, -0.009), (14, -0.004), (15, 0.029), (16, -0.025), (17, -0.02), (18, -0.002), (19, 0.064), (20, -0.003), (21, 0.039), (22, -0.031), (23, -0.022), (24, -0.011), (25, 0.122), (26, 0.091), (27, -0.062), (28, -0.076), (29, -0.054), (30, -0.012), (31, 0.003), (32, 0.092), (33, 0.186), (34, -0.022), (35, -0.058), (36, 0.09), (37, -0.06), (38, 0.157), (39, -0.096), (40, -0.145), (41, 0.083), (42, -0.058), (43, -0.076), (44, 0.146), (45, 0.067), (46, -0.002), (47, 0.035), (48, 0.081), (49, -0.086)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96425438 <a title="394-lsi-1" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>2 0.80391335 <a title="394-lsi-2" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>Author: Yi-Lei Chen, Chiou-Ting Hsu</p><p>Abstract: In this paper, we propose a novel low-rank appearance model for removing rain streaks. Different from previous work, our method needs neither rain pixel detection nor time-consuming dictionary learning stage. Instead, as rain streaks usually reveal similar and repeated patterns on imaging scene, we propose and generalize a low-rank model from matrix to tensor structure in order to capture the spatio-temporally correlated rain streaks. With the appearance model, we thus remove rain streaks from image/video (and also other high-order image structure) in a unified way. Our experimental results demonstrate competitive (or even better) visual quality and efficient run-time in comparison with state of the art.</p><p>3 0.78642583 <a title="394-lsi-3" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>Author: Xiangfei Kong, Kuan Li, Qingxiong Yang, Liu Wenyin, Ming-Hsuan Yang</p><p>Abstract: This paper proposes a new non-reference image quality metric that can be adopted by the state-of-the-art image/video denoising algorithms for auto-denoising. The proposed metric is extremely simple and can be implemented in four lines of Matlab code1. The basic assumption employed by the proposed metric is that the noise should be independent of the original image. A direct measurement of this dependence is, however, impractical due to the relatively low accuracy of existing denoising method. The proposed metric thus aims at maximizing the structure similarity between the input noisy image and the estimated image noise around homogeneous regions and the structure similarity between the input noisy image and the denoised image around highly-structured regions, and is computed as the linear correlation coefficient of the two corresponding structure similarity maps. Numerous experimental results demonstrate that the proposed metric not only outperforms the current state-of-the-art non-reference quality metric quantitatively and qualitatively, but also better maintains temporal coherence when used for video denoising. ˜</p><p>4 0.76128197 <a title="394-lsi-4" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>Author: Yaron Eshet, Simon Korman, Eyal Ofek, Shai Avidan</p><p>Abstract: We extend patch based methods to work on patches in 3D space. We start with Coherency Sensitive Hashing [12] (CSH), which is an algorithm for matching patches between two RGB images, and extend it to work with RGBD images. This is done by warping all 3D patches to a common virtual plane in which CSH is performed. To avoid noise due to warping of patches of various normals and depths, we estimate a group of dominant planes and compute CSH on each plane separately, before merging the matching patches. The result is DCSH - an algorithm that matches world (3D) patches in order to guide the search for image plane matches. An independent contribution is an extension of CSH, which we term Social-CSH. It allows a major speedup of the k nearest neighbor (kNN) version of CSH - its runtime growing linearly, rather than quadratically, in k. Social-CSH is used as a subcomponent of DCSH when many NNs are required, as in the case of image denoising. We show the benefits ofusing depth information to image reconstruction and image denoising, demonstrated on several RGBD images.</p><p>5 0.75046945 <a title="394-lsi-5" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>6 0.69990599 <a title="394-lsi-6" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>7 0.58983576 <a title="394-lsi-7" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>8 0.55255777 <a title="394-lsi-8" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>9 0.54432362 <a title="394-lsi-9" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>10 0.54106218 <a title="394-lsi-10" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>11 0.51686835 <a title="394-lsi-11" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>12 0.51022828 <a title="394-lsi-12" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>13 0.47865236 <a title="394-lsi-13" href="./iccv-2013-A_Learning-Based_Approach_to_Reduce_JPEG_Artifacts_in_Image_Matting.html">19 iccv-2013-A Learning-Based Approach to Reduce JPEG Artifacts in Image Matting</a></p>
<p>14 0.45205873 <a title="394-lsi-14" href="./iccv-2013-Shape_Anchors_for_Data-Driven_Multi-view_Reconstruction.html">387 iccv-2013-Shape Anchors for Data-Driven Multi-view Reconstruction</a></p>
<p>15 0.44867352 <a title="394-lsi-15" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>16 0.43451521 <a title="394-lsi-16" href="./iccv-2013-Anchored_Neighborhood_Regression_for_Fast_Example-Based_Super-Resolution.html">51 iccv-2013-Anchored Neighborhood Regression for Fast Example-Based Super-Resolution</a></p>
<p>17 0.42742771 <a title="394-lsi-17" href="./iccv-2013-Efficient_Image_Dehazing_with_Boundary_Constraint_and_Contextual_Regularization.html">135 iccv-2013-Efficient Image Dehazing with Boundary Constraint and Contextual Regularization</a></p>
<p>18 0.41896421 <a title="394-lsi-18" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>19 0.41887459 <a title="394-lsi-19" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>20 0.41292772 <a title="394-lsi-20" href="./iccv-2013-Local_Signal_Equalization_for_Correspondence_Matching.html">255 iccv-2013-Local Signal Equalization for Correspondence Matching</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.039), (7, 0.012), (26, 0.086), (31, 0.051), (42, 0.079), (48, 0.012), (64, 0.027), (73, 0.436), (89, 0.124), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83588439 <a title="394-lda-1" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>2 0.8128348 <a title="394-lda-2" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>Author: Qiong Yan, Xiaoyong Shen, Li Xu, Shaojie Zhuo, Xiaopeng Zhang, Liang Shen, Jiaya Jia</p><p>Abstract: Color, infrared, and flash images captured in different fields can be employed to effectively eliminate noise and other visual artifacts. We propose a two-image restoration framework considering input images in different fields, for example, one noisy color image and one dark-flashed nearinfrared image. The major issue in such a framework is to handle structure divergence and find commonly usable edges and smooth transition for visually compelling image reconstruction. We introduce a scale map as a competent representation to explicitly model derivative-level confidence and propose new functions and a numerical solver to effectively infer it following new structural observations. Our method is general and shows a principled way for cross-field restoration.</p><p>3 0.74085003 <a title="394-lda-3" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>Author: Ernesto Brau, Jinyan Guan, Kyle Simek, Luca Del Pero, Colin Reimer Dawson, Kobus Barnard</p><p>Abstract: Jinyan Guan† j guan1 @ emai l ari z ona . edu . Kyle Simek† ks imek@ emai l ari z ona . edu . Colin Reimer Dawson‡ cdaws on@ emai l ari z ona . edu . ‡School of Information University of Arizona Kobus Barnard‡ kobus @ s i sta . ari z ona . edu ∗School of Informatics University of Edinburgh for tracking an unknown and changing number of people in a scene using video taken from a single, fixed viewpoint. We develop a Bayesian modeling approach for tracking people in 3D from monocular video with unknown cameras. Modeling in 3D provides natural explanations for occlusions and smoothness discontinuities that result from projection, and allows priors on velocity and smoothness to be grounded in physical quantities: meters and seconds vs. pixels and frames. We pose the problem in the context of data association, in which observations are assigned to tracks. A correct application of Bayesian inference to multitarget tracking must address the fact that the model’s dimension changes as tracks are added or removed, and thus, posterior densities of different hypotheses are not comparable. We address this by marginalizing out the trajectory parameters so the resulting posterior over data associations has constant dimension. This is made tractable by using (a) Gaussian process priors for smooth trajectories and (b) approximately Gaussian likelihood functions. Our approach provides a principled method for incorporating multiple sources of evidence; we present results using both optical flow and object detector outputs. Results are comparable to recent work on 3D tracking and, unlike others, our method requires no pre-calibrated cameras.</p><p>4 0.7174865 <a title="394-lda-4" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>5 0.69423318 <a title="394-lda-5" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>Author: Jim Braux-Zin, Romain Dupont, Adrien Bartoli</p><p>Abstract: Dense motion field estimation (typically Romain Dupont1 romain . dupont @ cea . fr Adrien Bartoli2 adrien . bart o l @ gmai l com i . 2 ISIT, Universit e´ d’Auvergne/CNRS, France sions are explicitly modeled [32, 13]. Coarse-to-fine warping improves global convergence by making the assumption that optical flow, the motion of smaller structures is similar to the motion of stereo disparity and surface registration) is a key computer vision problem. Many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, but a unified methodology is still lacking. We here introduce a general framework that robustly combines direct and feature-based matching. The feature-based cost is built around a novel robust distance function that handles keypoints and “weak” features such as segments. It allows us to use putative feature matches which may contain mismatches to guide dense motion estimation out of local minima. Our framework uses a robust direct data term (AD-Census). It is implemented with a powerful second order Total Generalized Variation regularization with external and self-occlusion reasoning. Our framework achieves state of the art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). Our framework has a modular design that customizes to specific application needs.</p><p>6 0.58788407 <a title="394-lda-6" href="./iccv-2013-Spoken_Attributes%3A_Mixing_Binary_and_Relative_Attributes_to_Say_the_Right_Thing.html">399 iccv-2013-Spoken Attributes: Mixing Binary and Relative Attributes to Say the Right Thing</a></p>
<p>7 0.58147043 <a title="394-lda-7" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>8 0.58109999 <a title="394-lda-8" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>9 0.56509995 <a title="394-lda-9" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>10 0.54826891 <a title="394-lda-10" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>11 0.51838392 <a title="394-lda-11" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>12 0.5175851 <a title="394-lda-12" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>13 0.50825274 <a title="394-lda-13" href="./iccv-2013-Exploiting_Reflection_Change_for_Automatic_Reflection_Removal.html">151 iccv-2013-Exploiting Reflection Change for Automatic Reflection Removal</a></p>
<p>14 0.50805146 <a title="394-lda-14" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>15 0.505952 <a title="394-lda-15" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>16 0.50133127 <a title="394-lda-16" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>17 0.49738306 <a title="394-lda-17" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>18 0.49655601 <a title="394-lda-18" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>19 0.49583048 <a title="394-lda-19" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>20 0.4931218 <a title="394-lda-20" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
