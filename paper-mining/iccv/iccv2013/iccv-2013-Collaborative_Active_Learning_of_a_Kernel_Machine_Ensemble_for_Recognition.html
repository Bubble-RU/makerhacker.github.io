<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-80" href="#">iccv2013-80</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</h1>
<br/><p>Source: <a title="iccv-2013-80-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Hua_Collaborative_Active_Learning_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Gang Hua, Chengjiang Long, Ming Yang, Yan Gao</p><p>Abstract: Active learning is an effective way of engaging users to interactively train models for visual recognition. The vast majority of previous works, if not all of them, focused on active learning with a single human oracle. The problem of active learning with multiple oracles in a collaborative setting has not been well explored. Moreover, most of the previous works assume that the labels provided by the human oracles are noise free, which may often be violated in reality. We present a collaborative computational model for active learning with multiple human oracles. It leads to not only an ensemble kernel machine that is robust to label noises, but also a principled label quality measure to online detect irresponsible labelers. Instead of running independent active learning processes for each individual human oracle, our model captures the inherent correlations among the labelers through shared data among them. Our simulation experiments and experiments with real crowd-sourced noisy labels demonstrated the efficacy of our model.</p><p>Reference: <a title="iccv-2013-80-reference" href="../iccv2013_reference/iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('irrespons', 0.511), ('collab', 0.365), ('label', 0.307), ('xk', 0.196), ('mial', 0.171), ('crowdsourc', 0.154), ('fi', 0.144), ('ensembl', 0.133), ('meerk', 0.132), ('xnew', 0.113), ('learn', 0.106), ('act', 0.105), ('imagenet', 0.099), ('pool', 0.097), ('amazon', 0.091), ('crl', 0.085), ('lils', 0.085), ('conf', 0.081), ('xj', 0.078), ('ki', 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="80-tfidf-1" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>Author: Gang Hua, Chengjiang Long, Ming Yang, Yan Gao</p><p>Abstract: Active learning is an effective way of engaging users to interactively train models for visual recognition. The vast majority of previous works, if not all of them, focused on active learning with a single human oracle. The problem of active learning with multiple oracles in a collaborative setting has not been well explored. Moreover, most of the previous works assume that the labels provided by the human oracles are noise free, which may often be violated in reality. We present a collaborative computational model for active learning with multiple human oracles. It leads to not only an ensemble kernel machine that is robust to label noises, but also a principled label quality measure to online detect irresponsible labelers. Instead of running independent active learning processes for each individual human oracle, our model captures the inherent correlations among the labelers through shared data among them. Our simulation experiments and experiments with real crowd-sourced noisy labels demonstrated the efficacy of our model.</p><p>2 0.41924459 <a title="80-tfidf-2" href="./iccv-2013-Active_Visual_Recognition_with_Expertise_Estimation_in_Crowdsourcing.html">43 iccv-2013-Active Visual Recognition with Expertise Estimation in Crowdsourcing</a></p>
<p>Author: Chengjiang Long, Gang Hua, Ashish Kapoor</p><p>Abstract: We present a noise resilient probabilistic model for active learning of a Gaussian process classifier from crowds, i.e., a set of noisy labelers. It explicitly models both the overall label noises and the expertise level of each individual labeler in two levels of flip models. Expectation propagation is adopted for efficient approximate Bayesian inference of our probabilistic model for classification, based on which, a generalized EM algorithm is derived to estimate both the global label noise and the expertise of each individual labeler. The probabilistic nature of our model immediately allows the adoption of the prediction entropy and estimated expertise for active selection of data sample to be labeled, and active selection of high quality labelers to label the data, respectively. We apply the proposed model for three visual recognition tasks, i.e, object category recognition, gender recognition, and multi-modal activity recognition, on three datasets with real crowd-sourced labels from Amazon Mechanical Turk. The experiments clearly demonstrated the efficacy of the proposed model.</p><p>3 0.14022224 <a title="80-tfidf-3" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>Author: Ehsan Elhamifar, Guillermo Sapiro, Allen Yang, S. Shankar Sasrty</p><p>Abstract: In many image/video/web classification problems, we have access to a large number of unlabeled samples. However, it is typically expensive and time consuming to obtain labels for the samples. Active learning is the problem of progressively selecting and annotating the most informative unlabeled samples, in order to obtain a high classification performance. Most existing active learning algorithms select only one sample at a time prior to retraining the classifier. Hence, they are computationally expensive and cannot take advantage of parallel labeling systems such as Mechanical Turk. On the other hand, algorithms that allow the selection of multiple samples prior to retraining the classifier, may select samples that have significant information overlap or they involve solving a non-convex optimization. More importantly, the majority of active learning algorithms are developed for a certain classifier type such as SVM. In this paper, we develop an efficient active learning framework based on convex programming, which can select multiple samples at a time for annotation. Unlike the state of the art, our algorithm can be used in conjunction with any type of classifiers, including those of the fam- ily of the recently proposed Sparse Representation-based Classification (SRC). We use the two principles of classifier uncertainty and sample diversity in order to guide the optimization program towards selecting the most informative unlabeled samples, which have the least information overlap. Our method can incorporate the data distribution in the selection process by using the appropriate dissimilarity between pairs of samples. We show the effectiveness of our framework in person detection, scene categorization and face recognition on real-world datasets.</p><p>4 0.10797181 <a title="80-tfidf-4" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>Author: Guoqing Zhou, Qing Wang</p><p>Abstract: Optimization using the L∞ norm has been becoming an effective way to solve parameter estimation problems in multiview geometry. But the computational cost increases rapidly with the size of measurement data. Although some strategies have been presented to improve the efficiency of L∞ optimization, it is still an open issue. In the paper, we propose a novel approach under theframework ofenhanced continuous tabu search (ECTS) for generic parameter estimation in multiview geometry. ECTS is an optimization method in the domain of artificial intelligence, which has an interesting ability of covering a wide solution space by promoting the search far away from current solution and consecutively decreasing the possibility of trapping in the local minima. Taking the triangulation as an example, we propose the corresponding ways in the key steps of ECTS, diversification and intensification. We also present theoretical proof to guarantee the global convergence of search with probability one. Experimental results have validated that the ECTS based approach can obtain global optimum efficiently, especially for large scale dimension of parameter. Potentially, the novel ECTS based algorithm can be applied in many applications of multiview geometry.</p><p>5 0.1039004 <a title="80-tfidf-5" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>Author: Yangqing Jia, Trevor Darrell</p><p>Abstract: Recent years have witnessed the success of large-scale image classification systems that are able to identify objects among thousands of possible labels. However, it is yet unclear how general classifiers such as ones trained on ImageNet can be optimally adapted to specific tasks, each of which only covers a semantically related subset of all the objects in the world. It is inefficient and suboptimal to retrain classifiers whenever a new task is given, and is inapplicable when tasks are not given explicitly, but implicitly specified as a set of image queries. In this paper we propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a lineartime probabilistic inference algorithm, given a set of query images from a latent task. We present efficient ways to estimate parameters for the model, and an open-source toolbox to train classifiers distributedly at a large scale. Empirical results based on the ImageNet data showed significant performance increase over several baseline algorithms.</p><p>6 0.099976286 <a title="80-tfidf-6" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>7 0.099100634 <a title="80-tfidf-7" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>8 0.099070273 <a title="80-tfidf-8" href="./iccv-2013-Active_Learning_of_an_Action_Detector_from_Untrimmed_Videos.html">41 iccv-2013-Active Learning of an Action Detector from Untrimmed Videos</a></p>
<p>9 0.093142159 <a title="80-tfidf-9" href="./iccv-2013-Ensemble_Projection_for_Semi-supervised_Image_Classification.html">142 iccv-2013-Ensemble Projection for Semi-supervised Image Classification</a></p>
<p>10 0.092514522 <a title="80-tfidf-10" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>11 0.085826509 <a title="80-tfidf-11" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>12 0.083220392 <a title="80-tfidf-12" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>13 0.081900313 <a title="80-tfidf-13" href="./iccv-2013-Video_Event_Understanding_Using_Natural_Language_Descriptions.html">440 iccv-2013-Video Event Understanding Using Natural Language Descriptions</a></p>
<p>14 0.080896892 <a title="80-tfidf-14" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>15 0.077456407 <a title="80-tfidf-15" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>16 0.076885529 <a title="80-tfidf-16" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>17 0.076284222 <a title="80-tfidf-17" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>18 0.07623063 <a title="80-tfidf-18" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>19 0.076011539 <a title="80-tfidf-19" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>20 0.075878359 <a title="80-tfidf-20" href="./iccv-2013-Finding_Actors_and_Actions_in_Movies.html">166 iccv-2013-Finding Actors and Actions in Movies</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.192), (1, -0.051), (2, -0.078), (3, -0.037), (4, 0.015), (5, -0.041), (6, 0.09), (7, -0.018), (8, -0.109), (9, -0.048), (10, 0.027), (11, -0.058), (12, -0.069), (13, 0.025), (14, 0.057), (15, 0.051), (16, 0.057), (17, -0.017), (18, 0.029), (19, -0.02), (20, 0.017), (21, 0.046), (22, 0.072), (23, -0.004), (24, -0.019), (25, -0.005), (26, 0.007), (27, -0.126), (28, 0.042), (29, -0.086), (30, 0.094), (31, -0.034), (32, -0.078), (33, 0.043), (34, 0.157), (35, 0.02), (36, 0.154), (37, -0.01), (38, 0.027), (39, 0.008), (40, -0.024), (41, 0.005), (42, 0.022), (43, -0.039), (44, -0.106), (45, 0.022), (46, 0.059), (47, -0.047), (48, -0.062), (49, 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97204792 <a title="80-lsi-1" href="./iccv-2013-Active_Visual_Recognition_with_Expertise_Estimation_in_Crowdsourcing.html">43 iccv-2013-Active Visual Recognition with Expertise Estimation in Crowdsourcing</a></p>
<p>Author: Chengjiang Long, Gang Hua, Ashish Kapoor</p><p>Abstract: We present a noise resilient probabilistic model for active learning of a Gaussian process classifier from crowds, i.e., a set of noisy labelers. It explicitly models both the overall label noises and the expertise level of each individual labeler in two levels of flip models. Expectation propagation is adopted for efficient approximate Bayesian inference of our probabilistic model for classification, based on which, a generalized EM algorithm is derived to estimate both the global label noise and the expertise of each individual labeler. The probabilistic nature of our model immediately allows the adoption of the prediction entropy and estimated expertise for active selection of data sample to be labeled, and active selection of high quality labelers to label the data, respectively. We apply the proposed model for three visual recognition tasks, i.e, object category recognition, gender recognition, and multi-modal activity recognition, on three datasets with real crowd-sourced labels from Amazon Mechanical Turk. The experiments clearly demonstrated the efficacy of the proposed model.</p><p>same-paper 2 0.96683705 <a title="80-lsi-2" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>Author: Gang Hua, Chengjiang Long, Ming Yang, Yan Gao</p><p>Abstract: Active learning is an effective way of engaging users to interactively train models for visual recognition. The vast majority of previous works, if not all of them, focused on active learning with a single human oracle. The problem of active learning with multiple oracles in a collaborative setting has not been well explored. Moreover, most of the previous works assume that the labels provided by the human oracles are noise free, which may often be violated in reality. We present a collaborative computational model for active learning with multiple human oracles. It leads to not only an ensemble kernel machine that is robust to label noises, but also a principled label quality measure to online detect irresponsible labelers. Instead of running independent active learning processes for each individual human oracle, our model captures the inherent correlations among the labelers through shared data among them. Our simulation experiments and experiments with real crowd-sourced noisy labels demonstrated the efficacy of our model.</p><p>3 0.86079562 <a title="80-lsi-3" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>Author: Ehsan Elhamifar, Guillermo Sapiro, Allen Yang, S. Shankar Sasrty</p><p>Abstract: In many image/video/web classification problems, we have access to a large number of unlabeled samples. However, it is typically expensive and time consuming to obtain labels for the samples. Active learning is the problem of progressively selecting and annotating the most informative unlabeled samples, in order to obtain a high classification performance. Most existing active learning algorithms select only one sample at a time prior to retraining the classifier. Hence, they are computationally expensive and cannot take advantage of parallel labeling systems such as Mechanical Turk. On the other hand, algorithms that allow the selection of multiple samples prior to retraining the classifier, may select samples that have significant information overlap or they involve solving a non-convex optimization. More importantly, the majority of active learning algorithms are developed for a certain classifier type such as SVM. In this paper, we develop an efficient active learning framework based on convex programming, which can select multiple samples at a time for annotation. Unlike the state of the art, our algorithm can be used in conjunction with any type of classifiers, including those of the fam- ily of the recently proposed Sparse Representation-based Classification (SRC). We use the two principles of classifier uncertainty and sample diversity in order to guide the optimization program towards selecting the most informative unlabeled samples, which have the least information overlap. Our method can incorporate the data distribution in the selection process by using the appropriate dissimilarity between pairs of samples. We show the effectiveness of our framework in person detection, scene categorization and face recognition on real-world datasets.</p><p>4 0.81939948 <a title="80-lsi-4" href="./iccv-2013-Handling_Uncertain_Tags_in_Visual_Recognition.html">191 iccv-2013-Handling Uncertain Tags in Visual Recognition</a></p>
<p>Author: Arash Vahdat, Greg Mori</p><p>Abstract: Gathering accurate training data for recognizing a set of attributes or tags on images or videos is a challenge. Obtaining labels via manual effort or from weakly-supervised data typically results in noisy training labels. We develop the FlipSVM, a novel algorithm for handling these noisy, structured labels. The FlipSVM models label noise by “flipping ” labels on training examples. We show empirically that the FlipSVM is effective on images-and-attributes and video tagging datasets.</p><p>5 0.81399852 <a title="80-lsi-5" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>Author: Bo Wang, Zhuowen Tu, John K. Tsotsos</p><p>Abstract: In graph-based semi-supervised learning approaches, the classification rate is highly dependent on the size of the availabel labeled data, as well as the accuracy of the similarity measures. Here, we propose a semi-supervised multi-class/multi-label classification scheme, dynamic label propagation (DLP), which performs transductive learning through propagation in a dynamic process. Existing semi-supervised classification methods often have difficulty in dealing with multi-class/multi-label problems due to the lack in consideration of label correlation; our algorithm instead emphasizes dynamic metric fusion with label information. Significant improvement over the state-of-the-art methods is observed on benchmark datasets for both multiclass and multi-label tasks.</p><p>6 0.76804203 <a title="80-lsi-6" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>7 0.73711473 <a title="80-lsi-7" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>8 0.72695822 <a title="80-lsi-8" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>9 0.72671539 <a title="80-lsi-9" href="./iccv-2013-From_Semi-supervised_to_Transfer_Counting_of_Crowds.html">178 iccv-2013-From Semi-supervised to Transfer Counting of Crowds</a></p>
<p>10 0.71584016 <a title="80-lsi-10" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>11 0.71365523 <a title="80-lsi-11" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<p>12 0.70760298 <a title="80-lsi-12" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<p>13 0.7038098 <a title="80-lsi-13" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>14 0.69441819 <a title="80-lsi-14" href="./iccv-2013-Action_Recognition_with_Actons.html">38 iccv-2013-Action Recognition with Actons</a></p>
<p>15 0.69200104 <a title="80-lsi-15" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>16 0.68194085 <a title="80-lsi-16" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>17 0.67947525 <a title="80-lsi-17" href="./iccv-2013-Ensemble_Projection_for_Semi-supervised_Image_Classification.html">142 iccv-2013-Ensemble Projection for Semi-supervised Image Classification</a></p>
<p>18 0.67442018 <a title="80-lsi-18" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>19 0.67220205 <a title="80-lsi-19" href="./iccv-2013-From_Point_to_Set%3A_Extend_the_Learning_of_Distance_Metrics.html">177 iccv-2013-From Point to Set: Extend the Learning of Distance Metrics</a></p>
<p>20 0.66065675 <a title="80-lsi-20" href="./iccv-2013-Active_Learning_of_an_Action_Detector_from_Untrimmed_Videos.html">41 iccv-2013-Active Learning of an Action Detector from Untrimmed Videos</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(12, 0.121), (13, 0.06), (20, 0.072), (25, 0.027), (42, 0.111), (48, 0.152), (50, 0.015), (55, 0.018), (60, 0.018), (77, 0.064), (86, 0.227), (89, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.72814375 <a title="80-lda-1" href="./iccv-2013-Video_Synopsis_by_Heterogeneous_Multi-source_Correlation.html">443 iccv-2013-Video Synopsis by Heterogeneous Multi-source Correlation</a></p>
<p>Author: Xiatian Zhu, Chen Change Loy, Shaogang Gong</p><p>Abstract: Generating coherent synopsis for surveillance video stream remains a formidable challenge due to the ambiguity and uncertainty inherent to visual observations. In contrast to existing video synopsis approaches that rely on visual cues alone, we propose a novel multi-source synopsis framework capable of correlating visual data and independent non-visual auxiliary information to better describe and summarise subtlephysical events in complex scenes. Specifically, our unsupervised framework is capable of seamlessly uncovering latent correlations among heterogeneous types of data sources, despite the non-trivial heteroscedasticity and dimensionality discrepancy problems. Additionally, the proposed model is robust to partial or missing non-visual information. We demonstrate the effectiveness of our framework on two crowded public surveillance datasets.</p><p>same-paper 2 0.71292126 <a title="80-lda-2" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>Author: Gang Hua, Chengjiang Long, Ming Yang, Yan Gao</p><p>Abstract: Active learning is an effective way of engaging users to interactively train models for visual recognition. The vast majority of previous works, if not all of them, focused on active learning with a single human oracle. The problem of active learning with multiple oracles in a collaborative setting has not been well explored. Moreover, most of the previous works assume that the labels provided by the human oracles are noise free, which may often be violated in reality. We present a collaborative computational model for active learning with multiple human oracles. It leads to not only an ensemble kernel machine that is robust to label noises, but also a principled label quality measure to online detect irresponsible labelers. Instead of running independent active learning processes for each individual human oracle, our model captures the inherent correlations among the labelers through shared data among them. Our simulation experiments and experiments with real crowd-sourced noisy labels demonstrated the efficacy of our model.</p><p>3 0.7015245 <a title="80-lda-3" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>Author: Qiegen Liu, Jianbo Liu, Pei Dong, Dong Liang</p><p>Abstract: This paper presents a novel structure gradient and texture decorrelating regularization (SGTD) for image decomposition. The motivation of the idea is under the assumption that the structure gradient and texture components should be properly decorrelated for a successful decomposition. The proposed model consists of the data fidelity term, total variation regularization and the SGTD regularization. An augmented Lagrangian method is proposed to address this optimization issue, by first transforming the unconstrained problem to an equivalent constrained problem and then applying an alternating direction method to iteratively solve the subproblems. Experimental results demonstrate that the proposed method presents better or comparable performance as state-of-the-art methods do.</p><p>4 0.6999138 <a title="80-lda-4" href="./iccv-2013-Automatic_Kronecker_Product_Model_Based_Detection_of_Repeated_Patterns_in_2D_Urban_Images.html">55 iccv-2013-Automatic Kronecker Product Model Based Detection of Repeated Patterns in 2D Urban Images</a></p>
<p>Author: Juan Liu, Emmanouil Psarakis, Ioannis Stamos</p><p>Abstract: Repeated patterns (such as windows, tiles, balconies and doors) are prominent and significant features in urban scenes. Therefore, detection of these repeated patterns becomes very important for city scene analysis. This paper attacks the problem of repeated patterns detection in a precise, efficient and automatic way, by combining traditional feature extraction followed by a Kronecker product lowrank modeling approach. Our method is tailored for 2D images of building fac ¸ades. We have developed algorithms for automatic selection ofa representative texture withinfa ¸cade images using vanishing points and Harris corners. After rectifying the input images, we describe novel algorithms that extract repeated patterns by using Kronecker product based modeling that is based on a solid theoretical foundation. Our approach is unique and has not ever been used for fac ¸ade analysis. We have tested our algorithms in a large set of images.</p><p>5 0.69492769 <a title="80-lda-5" href="./iccv-2013-3D_Scene_Understanding_by_Voxel-CRF.html">2 iccv-2013-3D Scene Understanding by Voxel-CRF</a></p>
<p>Author: Byung-Soo Kim, Pushmeet Kohli, Silvio Savarese</p><p>Abstract: Scene understanding is an important yet very challenging problem in computer vision. In the past few years, researchers have taken advantage of the recent diffusion of depth-RGB (RGB-D) cameras to help simplify the problem of inferring scene semantics. However, while the added 3D geometry is certainly useful to segment out objects with different depth values, it also adds complications in that the 3D geometry is often incorrect because of noisy depth measurements and the actual 3D extent of the objects is usually unknown because of occlusions. In this paper we propose a new method that allows us to jointly refine the 3D reconstruction of the scene (raw depth values) while accurately segmenting out the objects or scene elements from the 3D reconstruction. This is achieved by introducing a new model which we called Voxel-CRF. The Voxel-CRF model is based on the idea of constructing a conditional random field over a 3D volume of interest which captures the semantic and 3D geometric relationships among different elements (voxels) of the scene. Such model allows to jointly estimate (1) a dense voxel-based 3D reconstruction and (2) the semantic labels associated with each voxel even in presence of par- tial occlusions using an approximate yet efficient inference strategy. We evaluated our method on the challenging NYU Depth dataset (Version 1and 2). Experimental results show that our method achieves competitive accuracy in inferring scene semantics and visually appealing results in improving the quality of the 3D reconstruction. We also demonstrate an interesting application of object removal and scene completion from RGB-D images.</p><p>6 0.68853182 <a title="80-lda-6" href="./iccv-2013-From_Point_to_Set%3A_Extend_the_Learning_of_Distance_Metrics.html">177 iccv-2013-From Point to Set: Extend the Learning of Distance Metrics</a></p>
<p>7 0.68519092 <a title="80-lda-7" href="./iccv-2013-Active_Visual_Recognition_with_Expertise_Estimation_in_Crowdsourcing.html">43 iccv-2013-Active Visual Recognition with Expertise Estimation in Crowdsourcing</a></p>
<p>8 0.6778211 <a title="80-lda-8" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>9 0.66998595 <a title="80-lda-9" href="./iccv-2013-Modifying_the_Memorability_of_Face_Photographs.html">272 iccv-2013-Modifying the Memorability of Face Photographs</a></p>
<p>10 0.66906279 <a title="80-lda-10" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>11 0.66547042 <a title="80-lda-11" href="./iccv-2013-Co-segmentation_by_Composition.html">74 iccv-2013-Co-segmentation by Composition</a></p>
<p>12 0.65480453 <a title="80-lda-12" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>13 0.65178466 <a title="80-lda-13" href="./iccv-2013-Compositional_Models_for_Video_Event_Detection%3A_A_Multiple_Kernel_Learning_Latent_Variable_Approach.html">85 iccv-2013-Compositional Models for Video Event Detection: A Multiple Kernel Learning Latent Variable Approach</a></p>
<p>14 0.64866132 <a title="80-lda-14" href="./iccv-2013-Supervised_Binary_Hash_Code_Learning_with_Jensen_Shannon_Divergence.html">409 iccv-2013-Supervised Binary Hash Code Learning with Jensen Shannon Divergence</a></p>
<p>15 0.6469031 <a title="80-lda-15" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>16 0.64664513 <a title="80-lda-16" href="./iccv-2013-Correlation_Adaptive_Subspace_Segmentation_by_Trace_Lasso.html">93 iccv-2013-Correlation Adaptive Subspace Segmentation by Trace Lasso</a></p>
<p>17 0.64571679 <a title="80-lda-17" href="./iccv-2013-Semantically-Based_Human_Scanpath_Estimation_with_HMMs.html">381 iccv-2013-Semantically-Based Human Scanpath Estimation with HMMs</a></p>
<p>18 0.64560318 <a title="80-lda-18" href="./iccv-2013-Live_Metric_3D_Reconstruction_on_Mobile_Phones.html">254 iccv-2013-Live Metric 3D Reconstruction on Mobile Phones</a></p>
<p>19 0.64415783 <a title="80-lda-19" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<p>20 0.64364636 <a title="80-lda-20" href="./iccv-2013-Shortest_Paths_with_Curvature_and_Torsion.html">389 iccv-2013-Shortest Paths with Curvature and Torsion</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
