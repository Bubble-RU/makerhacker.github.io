<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-165" href="#">iccv2013-165</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</h1>
<br/><p>Source: <a title="iccv-2013-165-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Sun_Find_the_Best_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Min Sun, Wan Huang, Silvio Savarese</p><p>Abstract: Many methods have been proposed to solve the image classification problem for a large number of categories. Among them, methods based on tree-based representations achieve good trade-off between accuracy and test time efficiency. While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. In this work, we propose a classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy. First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. As a result, our method achieves a significant 4.65%, 5.43%, and 4.07% (relative 24.82%, 41.64%, and 109.79%) improvement in accuracy at high efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. 8) so that users can further process them.</p><p>Reference: <a title="iccv-2013-165-reference" href="../iccv2013_reference/iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. [sent-10, score-0.674]
</p><p>2 We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. [sent-11, score-0.431]
</p><p>3 First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. [sent-13, score-0.388]
</p><p>4 Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. [sent-14, score-0.361]
</p><p>5 79%) improvement in accuracy at high  efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. [sent-21, score-0.336]
</p><p>6 Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. [sent-22, score-0.719]
</p><p>7 In order to achieve test time efficiency, a greedy prediction algorithm is used to progressively reduce the number of classes by applying the classifiers from the top to the bottom level in the hierarchy. [sent-31, score-0.468]
</p><p>8 In order to achieve high accuracy, most methods focus on learning the tree-shaped hierarchy and the corresponding set of classifiers. [sent-33, score-0.477]
</p><p>9 The prediction algorithm only explores one single path in the tree-shaped hierarchy; and the path is greedily selected according to the order of the classifiers applied (Fig. [sent-35, score-0.832]
</p><p>10 This implies that errors made at a higher level in the hierarchy cannot be corrected later. [sent-37, score-0.451]
</p><p>11 We convert the greedy prediction model into a “Best Path Model”, where the objective is to find the best path in the tree-shaped hierarchy corresponding to the maximum sum of the classifiers responses. [sent-44, score-1.06]
</p><p>12 We further propose a novel branch-and-bound-like searching approach to efficiently find the best path without exploring the whole tree nor greedily pruning out classes (Fig. [sent-48, score-0.5]
</p><p>13 Both the bounds and the model parameters can be jointly learned using an extended SSVM formulation with additional bound constraints (Eq. [sent-51, score-0.32]
</p><p>14 By preserving both the joint training strategy of the one-versus-all methods, and the hierarchical organization of classes in “tree-based” methods, we show that i) our best accuracy outperforms the accuracy of the one-versusall method [33] (Sec. [sent-58, score-0.281]
</p><p>15 6); ii) our method achieves better trade-off between efficiency and accuracy than the state-ofthe-art greedy tree-based method [14]. [sent-59, score-0.339]
</p><p>16 Finally, our branch•  and-bound-like algorithm naturally ranks the paths in the hierarchy to maintain a diverse set of class predictions without significantly increasing the complexity (Fig. [sent-67, score-0.986]
</p><p>17 [11, 4, 2, 3, 16, 14, 6, 30, 23, 35] propose different methods to automatically build the hierarchy of classes. [sent-89, score-0.415]
</p><p>18 Notice that, no matter how the hierarchies are obtained, most of them rely on a greedy algorithm to explore one single path in the hierarchy for class prediction and train the classifier at each node of the hierarchy separately (except [5]). [sent-91, score-1.886]
</p><p>19 [10] propose the first method connecting class selective rejection with hierarchical visual classification so that they can generate object class labels at different levels in the hierarchy while guaranteeing an arbitrarily high accuracy. [sent-101, score-0.633]
</p><p>20 It ranks hypotheses at different levels and naturally maintains a diverse set of class predictions (properties described in Sec. [sent-103, score-0.353]
</p><p>21 Recently, [14] propose to learn a relaxed hierarchy which explores the trade-off between efficiency and accuracy. [sent-106, score-0.659]
</p><p>22 In the relaxed hierarchy, a unique class is allowed to appear at more than one nodes at the same level which means some classes are ignored when learning the hierarchy at a certain level. [sent-107, score-0.764]
</p><p>23 In this paper, we explore the trade-off by finding the best path in the hierarchy (Sec. [sent-112, score-0.729]
</p><p>24 In the experiments, we achieve a better trade-off between efficiency and accuracy by combining the relax hierarchy with our method (Fig. [sent-118, score-0.683]
</p><p>25 Our Model Recall that our goal is to design a classifier for image hierarchies which achieves a better trade-off between efficiency and accuracy. [sent-129, score-0.366]
</p><p>26 , K} into a tree-shaped hierarchy T = {V, E} with a set of nodes V and a set ofedges E. [sent-137, score-0.469]
</p><p>27 Each node v ∈ V is associated with a set of classes Kv ⊂ K. [sent-138, score-0.309]
</p><p>28 The edges connect each node v ∈ V to N child nodes Cv = {cev}e∈{1,. [sent-139, score-0.342]
</p><p>29 The model requires that the set of classes Kc at every child node is a subset of the classes Kv at its parent node (i. [sent-147, score-0.674]
</p><p>30 The algorithm explores a single path in the tree from the root node until a leaf node is reached as follows. [sent-154, score-1.097]
</p><p>31 Starting from the root node (with index v = 1), the edge e corresponding to the largest classifier score is selected (i. [sent-155, score-0.332]
</p><p>32 , e = arg maxj Svj (x)), and the algorithm proceeds to the  ∀c  child node cve. [sent-157, score-0.288]
</p><p>33 The same selection procedure is iteratively applied to all the child nodes visited until a leaf node is reached. [sent-158, score-0.533]
</p><p>34 Thus, the predicted path P can be represented by the starting node v = 1 concatenated with the sequence of selected edges [e1, . [sent-159, score-0.553]
</p><p>35 However, this also implies that errors made at a higher level in the hierarchy cannot be corrected later (Fig. [sent-170, score-0.451]
</p><p>36 Most of the “tree-based” methods [11, 2, 14] address the two issues described above by learning the hierarchy of classes to avoid i) making mistakes by the greedy algorithms and/or ii) training classifiers using very few data by limiting the depth of the hierarchy. [sent-176, score-0.78]
</p><p>37 Instead of focusing on learning hierarchy, our proposed method addresses these two issues with a given hierarchy while maintaining the efficiency of class predictions. [sent-177, score-0.623]
</p><p>38 , Sve (x) = xTwve), we define a scoring function SP (x) for each path P = [v1; e1, . [sent-182, score-0.321]
</p><p>39 , vL+1 } is the sequence of node indices visited in the tree according to the path P. [sent-191, score-0.652]
</p><p>40 We propose to learn a model such that the class prediction of an input x is the class KvL+1 associated to the leaf node vL+1 of the path P∗ with the highest score. [sent-192, score-0.903]
</p><p>41 P∗ =  argP m∈aPx1  SP(x) ,  (1)  where P1 is the set of all the paths in the tree starting from the root node v = 1to a leaf node. [sent-193, score-0.791]
</p><p>42 The best path model can be considered as a special case of one-versus-all SVM since the accumulated sum of the classifiers parameters along each path can be treated as the classifiers parameters for a class in the one-versusall SVM. [sent-195, score-0.862]
</p><p>43 The important difference is that the tree structure enforces the parameters of two paths to be partially shared according to the overlap of the paths. [sent-196, score-0.32]
</p><p>44 In other words, our proposed model utilizes the knowledge of the hierarchy to share the parameters between classes so that classes closer in the hierarchy have more similar parameters. [sent-197, score-0.984]
</p><p>45 Efficient Prediction  Instead of exploring all the paths in the tree, our branchand-bound-like algorithm explores only a few paths in the tree and typically finishes in “sublinear” time. [sent-205, score-0.575]
</p><p>46 Branch-and-Bound-Like (BB-Like) Search Although the number of paths is large |P1|, only a few paths are worth exploring. [sent-208, score-0.422]
</p><p>47 The branch-and-bound (BB) framework [ 19] allows us to do this while guarantee finding the best path if a valid bound is given. [sent-211, score-0.508]
</p><p>48 , eL] is defined as a route with increasing levels in the hierarchy from node v to a leaf node following the sequence of selected edges [e1, . [sent-215, score-1.04]
</p><p>49 , eF] starting from the node v with length F (not necessarily reaching a leaf node) (Fig. [sent-225, score-0.433]
</p><p>50 Panel (d) shows the definition of segment (red edges), path (green lines from root to leaf), and branch (a collections of paths). [sent-275, score-0.536]
</p><p>51 Algorithm 1 Efficient Branch and Bound Prediction Require: input x ∈ RD, tree T , scoring function S, and  node-wise upper bound {Uv }v Ensure: P∗ = arg maxP∈P SP (x) 1: Initialize Q as an empty priority queue. [sent-276, score-0.481]
</p><p>52 2: Set node index ˆv = 1, branch as = P1 and accumulated score = 0 (Starting from root node). [sent-277, score-0.501]
</p><p>53 Uˆ(x)  For each branch, we calculate the upper bound of the highest score that a path in the branch could take for input x. [sent-288, score-0.797]
</p><p>54 At the beginning of the search, we start with a branch corresponding to the set of paths in the whole tree P1 = [1; ) (See line 2 in Algorithm 1). [sent-289, score-0.504]
</p><p>55 Then, we continuously split the working branch Pˆ to N sub-branches { e)}e 1 (See line 4 in Algorithm 1), and update the upper bound Uˆ(x) (See line 7 in Algorithm 1). [sent-290, score-0.516]
</p><p>56 Therefore, the working branch always corresponds  Pˆ  [Pˆ  to the one with the highest upper bound (See line 10 in Algorithm 1). [sent-292, score-0.516]
</p><p>57 The search terminates when it has identified a branch consisting of one single path (i. [sent-293, score-0.527]
</p><p>58 , == 1) with a score that is at least as good as the upper bound of all remaining candidate branches (See line 11 in Algorithm 1). [sent-295, score-0.394]
</p><p>59 The best-first manner guarantees that the best path has been found. [sent-296, score-0.281]
</p><p>60 Bound Calculation We assume that each node v caches the upper bound Uv of paths in branch Pv starting from node v to a leaf node can take. [sent-309, score-1.624]
</p><p>61 , eF] and the upper bound Uv cached at the last node of the segment [1; e1, . [sent-316, score-0.648]
</p><p>62 The tightest possible upper bound cached per node is input dependent Uv (x) and can be obtained by evaluating all the classifiers in the tree with the given input x. [sent-320, score-0.818]
</p><p>63 Therefore, we propose an input independent upper bound Uv estimated from the training inputs X defined as,  Uˆ(x)  Uv = xm∈aXxUv(x) . [sent-323, score-0.366]
</p><p>64 Notice that Uv is not guaranteed to be a valid bound since Uv is possible to be smaller than the upper bound Uv ( xˆ) of an unseen testing input xˆ. [sent-325, score-0.559]
</p><p>65 Although the BB algorithm terminates when the best path is found, much more information is kept in the queue Q (in Algorithm 1) which ranks the evaluated branches. [sent-330, score-0.371]
</p><p>66 We show that the rank naturally maintains a diverse set of predictions consisting of both branches sharing similar path segments (e. [sent-331, score-0.659]
</p><p>67 , cats and dogs) and branches with very different path segments (e. [sent-333, score-0.343]
</p><p>68 For example, a user would rather see a diverse set of predictions and select the most suitable one, than to see a similar set of predictions where all predictions might not be suitable. [sent-337, score-0.333]
</p><p>69 In the next section, we describe how to learn the model parameters using a Structured SVM formulation with the  option to jointly learn the node-wise upper bound Uv as well. [sent-339, score-0.372]
</p><p>70 Structured SVM Learning The scoring function can be learned using a Structured SVM (SSVM) formulation where the structured output P encodes the path in the tree-shaped hierarchy. [sent-341, score-0.355]
</p><p>71 Considering that we have a set of training inputs and the ground truth path in the tree {xm, Pm}m=1∼M, we solve the following SSVM problem, minW,ξm s. [sent-342, score-0.424]
</p><p>72 mξm SPm (xm; W) − SP(xm; W) ≥ Δ(P; Pm) − ξm, ∀m, ∀P ∈ P ,  (3)  where W = {Wv}v∈V is a vector concatenation of edgewise model parameters, Δ(P; Pm) is a loss function measuring incorrectness of the estimated path P, and λ controls the relative weight of the sum of the violation term (? [sent-345, score-0.334]
</p><p>73 Instead of learning the model param-  =  eters then estimating the node-wise upper bound U = {Uv }v, we can extend the SSVM problem in Eq. [sent-352, score-0.362]
</p><p>74 Uv m  v  SPm (xm; W) − SP(xm; W) ≥ Δ(P; Pm) − ξm,∀m,∀P  i) Valid bound ii) Reduction rate  ∀Pˆ  ∈  P1  SPˆ(xm; W) ≤ Uv, ∈ Pv, ∀v ∈ V Uv ≥ γUcve , ∀v ∈ V, ∀e ∈ 1 ∼ N , (4)  where γ is the rate of reduction of the bound Uv. [sent-357, score-0.486]
</p><p>75 The scores SPˆ (xm; W); ∈ Pv of paths starting from node v must be lower than the node-wise upper bound Uv . [sent-360, score-0.815]
</p><p>76 The upper bound Ucev of a child node should be smaller than the bound Uv of a parent node by a factor of γ. [sent-362, score-1.079]
</p><p>77 Notice that the color-coded nodes denote models with different degree of relaxation (ρ) trained without bound reduction rate constraints. [sent-368, score-0.377]
</p><p>78 4, the estimated upper bound is typically smaller than the real one since there are fewer active set of constraints. [sent-376, score-0.332]
</p><p>79 Therefore, we increase the upper bound by 10% while applying our BB-Like algorithm in order to find more hard examples. [sent-377, score-0.332]
</p><p>80 For testing efficiency, since each node in the tree model is a linear classifier with equal complexity, the overall testing efficiency depends on the number of classifier’s ? [sent-385, score-0.516]
</p><p>81 1for definition) (x-axis) calculated for our method (pink-solid), relax hierarchy [14] (blue-dash), and one-versus-all SVM (black-dot) on Caltech-256. [sent-402, score-0.479]
</p><p>82 The relaxed hierarchy method [14] is a very strong baseline since it outperforms many other “tree-based” method [24, 16]. [sent-418, score-0.502]
</p><p>83 Therefore, five hierarchies corresponding to relaxed degree ρ = {0. [sent-419, score-0.275]
</p><p>84 We first verify the branch-and-bound-like algorithm improves the efficiency without sacrificing much  1to rank 5 predictions using  ρ  = 0. [sent-426, score-0.292]
</p><p>85 6aAMlxe tH)hioedrachy1  Figure 6: Trade-off between accuracy (y-axis) and relative complexity (x-axis) calculated for our method (pink-solid), relax hierarchy [14] (blue-dash), and one-versus-all SVM (black-dot) on Sun-397. [sent-437, score-0.646]
</p><p>86 5 demonstrates that the accuracy from rank one to rank five predictions increases 10% while the complexity increases sublinearly. [sent-458, score-0.379]
</p><p>87 plexity (x-axis) calculated for our method learned with bound constraints (pink-solid), without bound constraints (red-solid), relax hierarchy [14] (blue-dash), and one-versus-all SVM (black-dot) on ImageNet. [sent-485, score-0.933]
</p><p>88 Moreover, models learned with bound constraints (pinksolid) outperform models learned without bound constraints  (red-solid). [sent-502, score-0.454]
</p><p>89 We also apply our method on hierarchy learned by [2] and achieve similar improvement (See technical report [27]). [sent-503, score-0.481]
</p><p>90 Conclusion We propose an efficient and accurate classifier for image hierarchies which achieves a better trade-off between efficiency and accuracy. [sent-505, score-0.366]
</p><p>91 Finally, our BB-Like algorithm naturally maintains a diverse set of class predictions without significantly increasing the complexity. [sent-515, score-0.295]
</p><p>92 Discriminative learning of relaxed hierarchy for large-scale visual recognition. [sent-626, score-0.532]
</p><p>93 In each panel, we show the testing image and the rank one or two paths on the left. [sent-754, score-0.297]
</p><p>94 On the right, we order the classes from left to right according to the prediction confidence in each leaf node since a leaf node contains multiple classes in the relaxed hierarchy. [sent-757, score-1.126]
</p><p>95 Panel (a) shows the ideal case when the rank one path (red) reaches the leaf node containing the correct class (Egyptian cat) and the class prediction in the leaf node is correct. [sent-758, score-1.413]
</p><p>96 Panel (b,c) demonstrate that our BB-Like algorithm naturally ranks the paths to keep a diverse set of class predictions. [sent-759, score-0.423]
</p><p>97 Panel (b) gives an example that the rank one (red) and the rank two (green) paths are nearby in the hierarchy (long overlapping segment). [sent-761, score-0.798]
</p><p>98 In this case, the rank two (green) path reaches the leaf node which successfully predicts the correct class (Four Poster). [sent-762, score-0.856]
</p><p>99 Panel (c) gives an example that the rank one (red) and the rank two (green) paths are far from each other in the hierarchy (short overlapping segment). [sent-763, score-0.798]
</p><p>100 In this case, the rank two (green) path reaches the leaf node which successfully predicts the correct class (Doormat). [sent-764, score-0.856]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hierarchy', 0.415), ('path', 0.281), ('node', 0.232), ('bound', 0.227), ('uv', 0.216), ('paths', 0.211), ('branch', 0.184), ('ssvm', 0.181), ('leaf', 0.161), ('hierarchies', 0.154), ('panel', 0.152), ('greedy', 0.13), ('xm', 0.12), ('efficiency', 0.113), ('tree', 0.109), ('upper', 0.105), ('prediction', 0.099), ('imagenet', 0.098), ('ef', 0.098), ('classifiers', 0.094), ('predictions', 0.093), ('pm', 0.092), ('sublinear', 0.091), ('sp', 0.09), ('relaxed', 0.087), ('rank', 0.086), ('classes', 0.077), ('notice', 0.077), ('recreate', 0.077), ('pv', 0.07), ('class', 0.065), ('llc', 0.064), ('relax', 0.064), ('classifier', 0.062), ('branches', 0.062), ('accuracy', 0.059), ('ranks', 0.058), ('svm', 0.057), ('child', 0.056), ('complexity', 0.055), ('kv', 0.054), ('diverse', 0.054), ('nodes', 0.054), ('relative', 0.053), ('multiclass', 0.053), ('bounds', 0.053), ('hierarchical', 0.052), ('cached', 0.051), ('shingt', 0.051), ('sunmin', 0.051), ('xtwve', 0.051), ('deng', 0.048), ('maintains', 0.048), ('accumulated', 0.047), ('el', 0.046), ('beygelzimer', 0.045), ('langford', 0.045), ('minw', 0.045), ('bb', 0.045), ('explores', 0.044), ('sacrificed', 0.042), ('sun', 0.042), ('convert', 0.041), ('jointly', 0.04), ('scoring', 0.04), ('starting', 0.04), ('wtw', 0.04), ('tightness', 0.04), ('root', 0.038), ('sve', 0.038), ('achieves', 0.037), ('organizes', 0.036), ('level', 0.036), ('classification', 0.036), ('localityconstrained', 0.035), ('naturally', 0.035), ('ii', 0.035), ('degree', 0.034), ('wv', 0.034), ('maxp', 0.034), ('training', 0.034), ('improvement', 0.034), ('structured', 0.034), ('explore', 0.033), ('segment', 0.033), ('greedily', 0.033), ('achieve', 0.032), ('reduction', 0.032), ('terminates', 0.032), ('cv', 0.032), ('griffin', 0.032), ('usage', 0.031), ('reaches', 0.031), ('inefficient', 0.03), ('learning', 0.03), ('relaxation', 0.03), ('deep', 0.03), ('search', 0.03), ('visited', 0.03), ('kc', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999923 <a title="165-tfidf-1" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>Author: Min Sun, Wan Huang, Silvio Savarese</p><p>Abstract: Many methods have been proposed to solve the image classification problem for a large number of categories. Among them, methods based on tree-based representations achieve good trade-off between accuracy and test time efficiency. While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. In this work, we propose a classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy. First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. As a result, our method achieves a significant 4.65%, 5.43%, and 4.07% (relative 24.82%, 41.64%, and 109.79%) improvement in accuracy at high efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. 8) so that users can further process them.</p><p>2 0.23951186 <a title="165-tfidf-2" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>Author: Susanna Ricco, Carlo Tomasi</p><p>Abstract: Dense motion of image points over many video frames can provide important information about the world. However, occlusions and drift make it impossible to compute long motionpaths by merely concatenating opticalflow vectors between consecutive frames. Instead, we solve for entire paths directly, and flag the frames in which each is visible. As in previous work, we anchor each path to a unique pixel which guarantees an even spatial distribution of paths. Unlike earlier methods, we allow paths to be anchored in any frame. By explicitly requiring that at least one visible path passes within a small neighborhood of every pixel, we guarantee complete coverage of all visible points in all frames. We achieve state-of-the-art results on real sequences including both rigid and non-rigid motions with significant occlusions.</p><p>3 0.20208904 <a title="165-tfidf-3" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>4 0.19997491 <a title="165-tfidf-4" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>Author: Yangqing Jia, Trevor Darrell</p><p>Abstract: Recent years have witnessed the success of large-scale image classification systems that are able to identify objects among thousands of possible labels. However, it is yet unclear how general classifiers such as ones trained on ImageNet can be optimally adapted to specific tasks, each of which only covers a semantically related subset of all the objects in the world. It is inefficient and suboptimal to retrain classifiers whenever a new task is given, and is inapplicable when tasks are not given explicitly, but implicitly specified as a set of image queries. In this paper we propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a lineartime probabilistic inference algorithm, given a set of query images from a latent task. We present efficient ways to estimate parameters for the model, and an open-source toolbox to train classifiers distributedly at a large scale. Empirical results based on the ImageNet data showed significant performance increase over several baseline algorithms.</p><p>5 0.19482461 <a title="165-tfidf-5" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>Author: Vicente Ordonez, Jia Deng, Yejin Choi, Alexander C. Berg, Tamara L. Berg</p><p>Abstract: Entry level categories the labels people will use to name an object were originally defined and studied by psychologists in the 1980s. In this paper we study entrylevel categories at a large scale and learn the first models for predicting entry-level categories for images. Our models combine visual recognition predictions with proxies for word “naturalness ” mined from the enormous amounts of text on the web. We demonstrate the usefulness of our models for predicting nouns (entry-level words) associated with images by people. We also learn mappings between concepts predicted by existing visual recognition systems and entry-level concepts that could be useful for improving human-focused applications such as natural language image description or retrieval. – –</p><p>6 0.19345599 <a title="165-tfidf-6" href="./iccv-2013-Flattening_Supervoxel_Hierarchies_by_the_Uniform_Entropy_Slice.html">172 iccv-2013-Flattening Supervoxel Hierarchies by the Uniform Entropy Slice</a></p>
<p>7 0.18215375 <a title="165-tfidf-7" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>8 0.16249232 <a title="165-tfidf-8" href="./iccv-2013-YouTube2Text%3A_Recognizing_and_Describing_Arbitrary_Activities_Using_Semantic_Hierarchies_and_Zero-Shot_Recognition.html">452 iccv-2013-YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition</a></p>
<p>9 0.14060436 <a title="165-tfidf-9" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>10 0.12801 <a title="165-tfidf-10" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>11 0.12261664 <a title="165-tfidf-11" href="./iccv-2013-Box_in_the_Box%3A_Joint_3D_Layout_and_Object_Reasoning_from_Single_Images.html">64 iccv-2013-Box in the Box: Joint 3D Layout and Object Reasoning from Single Images</a></p>
<p>12 0.11885776 <a title="165-tfidf-12" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>13 0.11764824 <a title="165-tfidf-13" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>14 0.11593612 <a title="165-tfidf-14" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>15 0.1127236 <a title="165-tfidf-15" href="./iccv-2013-Handling_Occlusions_with_Franken-Classifiers.html">190 iccv-2013-Handling Occlusions with Franken-Classifiers</a></p>
<p>16 0.10694591 <a title="165-tfidf-16" href="./iccv-2013-Shufflets%3A_Shared_Mid-level_Parts_for_Fast_Object_Detection.html">390 iccv-2013-Shufflets: Shared Mid-level Parts for Fast Object Detection</a></p>
<p>17 0.097498834 <a title="165-tfidf-17" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>18 0.094835036 <a title="165-tfidf-18" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>19 0.093628816 <a title="165-tfidf-19" href="./iccv-2013-Monte_Carlo_Tree_Search_for_Scheduling_Activity_Recognition.html">274 iccv-2013-Monte Carlo Tree Search for Scheduling Activity Recognition</a></p>
<p>20 0.088532709 <a title="165-tfidf-20" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.214), (1, 0.073), (2, -0.027), (3, -0.063), (4, 0.091), (5, 0.044), (6, -0.066), (7, 0.044), (8, 0.027), (9, -0.126), (10, -0.087), (11, -0.01), (12, -0.033), (13, 0.079), (14, 0.136), (15, 0.137), (16, -0.039), (17, -0.111), (18, -0.012), (19, 0.12), (20, -0.087), (21, -0.056), (22, -0.025), (23, 0.06), (24, -0.148), (25, -0.109), (26, -0.014), (27, -0.105), (28, 0.001), (29, -0.071), (30, 0.096), (31, -0.12), (32, -0.17), (33, -0.093), (34, 0.031), (35, -0.05), (36, -0.059), (37, 0.035), (38, 0.127), (39, -0.155), (40, -0.075), (41, 0.006), (42, 0.18), (43, 0.102), (44, 0.064), (45, -0.094), (46, 0.003), (47, 0.008), (48, 0.053), (49, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95622432 <a title="165-lsi-1" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>Author: Min Sun, Wan Huang, Silvio Savarese</p><p>Abstract: Many methods have been proposed to solve the image classification problem for a large number of categories. Among them, methods based on tree-based representations achieve good trade-off between accuracy and test time efficiency. While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. In this work, we propose a classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy. First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. As a result, our method achieves a significant 4.65%, 5.43%, and 4.07% (relative 24.82%, 41.64%, and 109.79%) improvement in accuracy at high efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. 8) so that users can further process them.</p><p>2 0.6620127 <a title="165-lsi-2" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>Author: Vicente Ordonez, Jia Deng, Yejin Choi, Alexander C. Berg, Tamara L. Berg</p><p>Abstract: Entry level categories the labels people will use to name an object were originally defined and studied by psychologists in the 1980s. In this paper we study entrylevel categories at a large scale and learn the first models for predicting entry-level categories for images. Our models combine visual recognition predictions with proxies for word “naturalness ” mined from the enormous amounts of text on the web. We demonstrate the usefulness of our models for predicting nouns (entry-level words) associated with images by people. We also learn mappings between concepts predicted by existing visual recognition systems and entry-level concepts that could be useful for improving human-focused applications such as natural language image description or retrieval. – –</p><p>3 0.63132906 <a title="165-lsi-3" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>Author: Susanna Ricco, Carlo Tomasi</p><p>Abstract: Dense motion of image points over many video frames can provide important information about the world. However, occlusions and drift make it impossible to compute long motionpaths by merely concatenating opticalflow vectors between consecutive frames. Instead, we solve for entire paths directly, and flag the frames in which each is visible. As in previous work, we anchor each path to a unique pixel which guarantees an even spatial distribution of paths. Unlike earlier methods, we allow paths to be anchored in any frame. By explicitly requiring that at least one visible path passes within a small neighborhood of every pixel, we guarantee complete coverage of all visible points in all frames. We achieve state-of-the-art results on real sequences including both rigid and non-rigid motions with significant occlusions.</p><p>4 0.62707651 <a title="165-lsi-4" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>Author: Christoph Straehle, Ullrich Koethe, Fred A. Hamprecht</p><p>Abstract: We propose a scheme that allows to partition an image into a previously unknown number of segments, using only minimal supervision in terms of a few must-link and cannotlink annotations. We make no use of regional data terms, learning instead what constitutes a likely boundary between segments. Since boundaries are only implicitly specified through cannot-link constraints, this is a hard and nonconvex latent variable problem. We address this problem in a greedy fashion using a randomized decision tree on features associated with interpixel edges. We use a structured purity criterion during tree construction and also show how a backtracking strategy can be used to prevent the greedy search from ending up in poor local optima. The proposed strategy is compared with prior art on natural images.</p><p>5 0.56254649 <a title="165-lsi-5" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>6 0.55616581 <a title="165-lsi-6" href="./iccv-2013-Revisiting_Example_Dependent_Cost-Sensitive_Learning_with_Decision_Trees.html">352 iccv-2013-Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees</a></p>
<p>7 0.52621073 <a title="165-lsi-7" href="./iccv-2013-Monte_Carlo_Tree_Search_for_Scheduling_Activity_Recognition.html">274 iccv-2013-Monte Carlo Tree Search for Scheduling Activity Recognition</a></p>
<p>8 0.52363294 <a title="165-lsi-8" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>9 0.52048695 <a title="165-lsi-9" href="./iccv-2013-Flattening_Supervoxel_Hierarchies_by_the_Uniform_Entropy_Slice.html">172 iccv-2013-Flattening Supervoxel Hierarchies by the Uniform Entropy Slice</a></p>
<p>10 0.5145846 <a title="165-lsi-10" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>11 0.51342088 <a title="165-lsi-11" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>12 0.51133448 <a title="165-lsi-12" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>13 0.50552571 <a title="165-lsi-13" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>14 0.49744251 <a title="165-lsi-14" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>15 0.47962931 <a title="165-lsi-15" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>16 0.47574365 <a title="165-lsi-16" href="./iccv-2013-YouTube2Text%3A_Recognizing_and_Describing_Arbitrary_Activities_Using_Semantic_Hierarchies_and_Zero-Shot_Recognition.html">452 iccv-2013-YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition</a></p>
<p>17 0.46853939 <a title="165-lsi-17" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>18 0.4683052 <a title="165-lsi-18" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>19 0.45932281 <a title="165-lsi-19" href="./iccv-2013-Parallel_Transport_of_Deformations_in_Shape_Space_of_Elastic_Surfaces.html">307 iccv-2013-Parallel Transport of Deformations in Shape Space of Elastic Surfaces</a></p>
<p>20 0.4513801 <a title="165-lsi-20" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.101), (7, 0.021), (12, 0.013), (26, 0.097), (31, 0.043), (34, 0.022), (42, 0.136), (48, 0.013), (50, 0.117), (64, 0.07), (73, 0.032), (77, 0.011), (89, 0.201), (98, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94487864 <a title="165-lda-1" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<p>Author: Dengxin Dai, Hayko Riemenschneider, Gerhard Schmitt, Luc Van_Gool</p><p>Abstract: There is an increased interest in the efficient creation of city models, be it virtual or as-built. We present a method for synthesizing complex, photo-realistic facade images, from a single example. After parsing the example image into its semantic components, a tiling for it is generated. Novel tilings can then be created, yielding facade textures with different dimensions or with occluded parts inpainted. A genetic algorithm guides the novel facades as well as inpainted parts to be consistent with the example, both in terms of their overall structure and their detailed textures. Promising results for multiple standard datasets in particular for the different building styles they contain demonstrate the potential of the method. – –</p><p>2 0.93879145 <a title="165-lda-2" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>Author: Salil Tambe, Ashok Veeraraghavan, Amit Agrawal</p><p>Abstract: Current Light Field (LF) cameras offer fixed resolution in space, time and angle which is decided a-priori and is independent of the scene. These cameras either trade-off spatial resolution to capture single-shot LF [20, 27, 12] or tradeoff temporal resolution by assuming a static scene to capture high spatial resolution LF [18, 3]. Thus, capturing high spatial resolution LF video for dynamic scenes remains an open and challenging problem. We present the concept, design and implementation of a LF video camera that allows capturing high resolution LF video. The spatial, angular and temporal resolution are not fixed a-priori and we exploit the scene-specific redundancy in space, time and angle. Our reconstruction is motion-aware and offers a continuum of resolution tradeoff with increasing motion in the scene. The key idea is (a) to design efficient multiplexing matrices that allow resolution tradeoffs, (b) use dictionary learning and sparse repre- sentations for robust reconstruction, and (c) perform local motion-aware adaptive reconstruction. We perform extensive analysis and characterize the performance of our motion-aware reconstruction algorithm. We show realistic simulations using a graphics simulator as well as real results using a LCoS based programmable camera. We demonstrate novel results such as high resolution digital refocusing for dynamic moving objects.</p><p>3 0.92391068 <a title="165-lda-3" href="./iccv-2013-Facial_Action_Unit_Event_Detection_by_Cascade_of_Tasks.html">155 iccv-2013-Facial Action Unit Event Detection by Cascade of Tasks</a></p>
<p>Author: Xiaoyu Ding, Wen-Sheng Chu, Fernando De_La_Torre, Jeffery F. Cohn, Qiao Wang</p><p>Abstract: Automatic facial Action Unit (AU) detection from video is a long-standing problem in facial expression analysis. AU detection is typically posed as a classification problem between frames or segments of positive examples and negative ones, where existing work emphasizes the use of different features or classifiers. In this paper, we propose a method called Cascade of Tasks (CoT) that combines the use ofdifferent tasks (i.e., , frame, segment and transition)for AU event detection. We train CoT in a sequential manner embracing diversity, which ensures robustness and generalization to unseen data. In addition to conventional framebased metrics that evaluate frames independently, we propose a new event-based metric to evaluate detection performance at event-level. We show how the CoT method consistently outperforms state-of-the-art approaches in both frame-based and event-based metrics, across three public datasets that differ in complexity: CK+, FERA and RUFACS.</p><p>same-paper 4 0.92389274 <a title="165-lda-4" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>Author: Min Sun, Wan Huang, Silvio Savarese</p><p>Abstract: Many methods have been proposed to solve the image classification problem for a large number of categories. Among them, methods based on tree-based representations achieve good trade-off between accuracy and test time efficiency. While focusing on learning a tree-shaped hierarchy and the corresponding set of classifiers, most of them [11, 2, 14] use a greedy prediction algorithm for test time efficiency. We argue that the dramatic decrease in accuracy at high efficiency is caused by the specific design choice of the learning and greedy prediction algorithms. In this work, we propose a classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy. First, we convert the classification problem as finding the best path in the hierarchy, and a novel branchand-bound-like algorithm is introduced to efficiently search for the best path. Second, we jointly train the classifiers using a novel Structured SVM (SSVM) formulation with additional bound constraints. As a result, our method achieves a significant 4.65%, 5.43%, and 4.07% (relative 24.82%, 41.64%, and 109.79%) improvement in accuracy at high efficiency compared to state-of-the-art greedy “tree-based” methods [14] on Caltech-256 [15], SUN [32] and ImageNet 1K [9] dataset, respectively. Finally, we show that our branch-and-bound-like algorithm naturally ranks the paths in the hierarchy (Fig. 8) so that users can further process them.</p><p>5 0.92313921 <a title="165-lda-5" href="./iccv-2013-Robust_Trajectory_Clustering_for_Motion_Segmentation.html">361 iccv-2013-Robust Trajectory Clustering for Motion Segmentation</a></p>
<p>Author: Feng Shi, Zhong Zhou, Jiangjian Xiao, Wei Wu</p><p>Abstract: Due to occlusions and objects ’ non-rigid deformation in the scene, the obtained motion trajectories from common trackers may contain a number of missing or mis-associated entries. To cluster such corrupted point based trajectories into multiple motions is still a hard problem. In this paper, we present an approach that exploits temporal and spatial characteristics from tracked points to facilitate segmentation of incomplete and corrupted trajectories, thereby obtain highly robust results against severe data missing and noises. Our method first uses the Discrete Cosine Transform (DCT) bases as a temporal smoothness constraint on trajectory projection to ensure the validity of resulting components to repair pathological trajectories. Then, based on an observation that the trajectories of foreground and background in a scene may have different spatial distributions, we propose a two-stage clustering strategy that first performs foreground-background separation then segments remaining foreground trajectories. We show that, with this new clustering strategy, sequences with complex motions can be accurately segmented by even using a simple trans- lational model. Finally, a series of experiments on Hopkins 155 dataset andBerkeley motion segmentation dataset show the advantage of our method over other state-of-the-art motion segmentation algorithms in terms of both effectiveness and robustness.</p><p>6 0.91253632 <a title="165-lda-6" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>7 0.90937907 <a title="165-lda-7" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>8 0.90784556 <a title="165-lda-8" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>9 0.90706736 <a title="165-lda-9" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>10 0.90701169 <a title="165-lda-10" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>11 0.90677959 <a title="165-lda-11" href="./iccv-2013-Frustratingly_Easy_NBNN_Domain_Adaptation.html">181 iccv-2013-Frustratingly Easy NBNN Domain Adaptation</a></p>
<p>12 0.90652156 <a title="165-lda-12" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>13 0.90647882 <a title="165-lda-13" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>14 0.90647095 <a title="165-lda-14" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>15 0.90615988 <a title="165-lda-15" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>16 0.90555263 <a title="165-lda-16" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>17 0.90547204 <a title="165-lda-17" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>18 0.90531474 <a title="165-lda-18" href="./iccv-2013-Domain_Adaptive_Classification.html">123 iccv-2013-Domain Adaptive Classification</a></p>
<p>19 0.90529835 <a title="165-lda-19" href="./iccv-2013-NEIL%3A_Extracting_Visual_Knowledge_from_Web_Data.html">285 iccv-2013-NEIL: Extracting Visual Knowledge from Web Data</a></p>
<p>20 0.90520811 <a title="165-lda-20" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
