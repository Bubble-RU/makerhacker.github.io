<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>265 iccv-2013-Mining Motion Atoms and Phrases for Complex Action Recognition</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-265" href="#">iccv2013-265</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>265 iccv-2013-Mining Motion Atoms and Phrases for Complex Action Recognition</h1>
<br/><p>Source: <a title="iccv-2013-265-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Wang_Mining_Motion_Atoms_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Limin Wang, Yu Qiao, Xiaoou Tang</p><p>Abstract: This paper proposes motion atom and phrase as a midlevel temporal “part” for representing and classifying complex action. Motion atom is defined as an atomic part of action, and captures the motion information of action video in a short temporal scale. Motion phrase is a temporal composite of multiple motion atoms with an AND/OR structure, which further enhances the discriminative ability of motion atoms by incorporating temporal constraints in a longer scale. Specifically, given a set of weakly labeled action videos, we firstly design a discriminative clustering method to automatically discovera set ofrepresentative motion atoms. Then, based on these motion atoms, we mine effective motion phrases with high discriminative and representativepower. We introduce a bottom-upphrase construction algorithm and a greedy selection method for this mining task. We examine the classification performance of the motion atom and phrase based representation on two complex action datasets: Olympic Sports and UCF50. Experimental results show that our method achieves superior performance over recent published methods on both datasets.</p><p>Reference: <a title="iccv-2013-265-reference" href="../iccv2013_reference/iccv-2013-Mining_Motion_Atoms_and_Phrases_for_Complex_Action_Recognition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('atom', 0.591), ('phrase', 0.524), ('phrases', 0.467), ('mot', 0.171), ('temp', 0.149), ('olymp', 0.121), ('sport', 0.108), ('act', 0.077), ('unit', 0.065), ('video', 0.061), ('motionlet', 0.053), ('vi', 0.048), ('qiao', 0.046), ('complex', 0.045), ('min', 0.034), ('respons', 0.033), ('seg', 0.033), ('discovery', 0.031), ('jump', 0.03), ('hjm', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="265-tfidf-1" href="./iccv-2013-Mining_Motion_Atoms_and_Phrases_for_Complex_Action_Recognition.html">265 iccv-2013-Mining Motion Atoms and Phrases for Complex Action Recognition</a></p>
<p>2 0.31767803 <a title="265-tfidf-2" href="./iccv-2013-Modeling_4D_Human-Object_Interactions_for_Event_and_Object_Recognition.html">268 iccv-2013-Modeling 4D Human-Object Interactions for Event and Object Recognition</a></p>
<p>3 0.31214306 <a title="265-tfidf-3" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>4 0.24773864 <a title="265-tfidf-4" href="./iccv-2013-From_Subcategories_to_Visual_Composites%3A_A_Multi-level_Framework_for_Object_Detection.html">179 iccv-2013-From Subcategories to Visual Composites: A Multi-level Framework for Object Detection</a></p>
<p>5 0.23327166 <a title="265-tfidf-5" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>6 0.22150889 <a title="265-tfidf-6" href="./iccv-2013-Offline_Mobile_Instance_Retrieval_with_a_Small_Memory_Footprint.html">294 iccv-2013-Offline Mobile Instance Retrieval with a Small Memory Footprint</a></p>
<p>7 0.21706435 <a title="265-tfidf-7" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>8 0.19790192 <a title="265-tfidf-8" href="./iccv-2013-Recognising_Human-Object_Interaction_via_Exemplar_Based_Modelling.html">344 iccv-2013-Recognising Human-Object Interaction via Exemplar Based Modelling</a></p>
<p>9 0.16379611 <a title="265-tfidf-9" href="./iccv-2013-Dictionary_Learning_and_Sparse_Coding_on_Grassmann_Manifolds%3A_An_Extrinsic_Solution.html">114 iccv-2013-Dictionary Learning and Sparse Coding on Grassmann Manifolds: An Extrinsic Solution</a></p>
<p>10 0.15822175 <a title="265-tfidf-10" href="./iccv-2013-A_Max-Margin_Perspective_on_Sparse_Representation-Based_Classification.html">20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</a></p>
<p>11 0.15508114 <a title="265-tfidf-11" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>12 0.13228691 <a title="265-tfidf-12" href="./iccv-2013-Multi-attributed_Dictionary_Learning_for_Sparse_Coding.html">276 iccv-2013-Multi-attributed Dictionary Learning for Sparse Coding</a></p>
<p>13 0.12900609 <a title="265-tfidf-13" href="./iccv-2013-Event_Detection_in_Complex_Scenes_Using_Interval_Temporal_Constraints.html">146 iccv-2013-Event Detection in Complex Scenes Using Interval Temporal Constraints</a></p>
<p>14 0.12848708 <a title="265-tfidf-14" href="./iccv-2013-Log-Euclidean_Kernels_for_Sparse_Representation_and_Dictionary_Learning.html">257 iccv-2013-Log-Euclidean Kernels for Sparse Representation and Dictionary Learning</a></p>
<p>15 0.12528801 <a title="265-tfidf-15" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>16 0.12040482 <a title="265-tfidf-16" href="./iccv-2013-Video_Event_Understanding_Using_Natural_Language_Descriptions.html">440 iccv-2013-Video Event Understanding Using Natural Language Descriptions</a></p>
<p>17 0.10572352 <a title="265-tfidf-17" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<p>18 0.099388465 <a title="265-tfidf-18" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<p>19 0.093960255 <a title="265-tfidf-19" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>20 0.090898186 <a title="265-tfidf-20" href="./iccv-2013-Anchored_Neighborhood_Regression_for_Fast_Example-Based_Super-Resolution.html">51 iccv-2013-Anchored Neighborhood Regression for Fast Example-Based Super-Resolution</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.143), (1, -0.034), (2, -0.026), (3, -0.092), (4, 0.039), (5, 0.008), (6, 0.109), (7, 0.049), (8, -0.022), (9, -0.163), (10, 0.093), (11, -0.042), (12, -0.146), (13, 0.039), (14, 0.079), (15, 0.061), (16, -0.337), (17, -0.064), (18, 0.101), (19, 0.014), (20, -0.011), (21, 0.067), (22, -0.046), (23, 0.152), (24, 0.063), (25, -0.107), (26, 0.02), (27, 0.051), (28, -0.103), (29, 0.06), (30, 0.078), (31, 0.025), (32, -0.008), (33, -0.122), (34, -0.059), (35, -0.119), (36, -0.094), (37, 0.004), (38, 0.171), (39, -0.002), (40, -0.038), (41, 0.144), (42, 0.068), (43, -0.013), (44, 0.1), (45, -0.079), (46, 0.043), (47, 0.071), (48, 0.074), (49, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88609588 <a title="265-lsi-1" href="./iccv-2013-Mining_Motion_Atoms_and_Phrases_for_Complex_Action_Recognition.html">265 iccv-2013-Mining Motion Atoms and Phrases for Complex Action Recognition</a></p>
<p>2 0.69034892 <a title="265-lsi-2" href="./iccv-2013-Modeling_4D_Human-Object_Interactions_for_Event_and_Object_Recognition.html">268 iccv-2013-Modeling 4D Human-Object Interactions for Event and Object Recognition</a></p>
<p>3 0.59016931 <a title="265-lsi-3" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>4 0.54305226 <a title="265-lsi-4" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>5 0.50824177 <a title="265-lsi-5" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>6 0.49531791 <a title="265-lsi-6" href="./iccv-2013-A_Max-Margin_Perspective_on_Sparse_Representation-Based_Classification.html">20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</a></p>
<p>7 0.46994516 <a title="265-lsi-7" href="./iccv-2013-Event_Detection_in_Complex_Scenes_Using_Interval_Temporal_Constraints.html">146 iccv-2013-Event Detection in Complex Scenes Using Interval Temporal Constraints</a></p>
<p>8 0.45810947 <a title="265-lsi-8" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>9 0.4167791 <a title="265-lsi-9" href="./iccv-2013-Recognising_Human-Object_Interaction_via_Exemplar_Based_Modelling.html">344 iccv-2013-Recognising Human-Object Interaction via Exemplar Based Modelling</a></p>
<p>10 0.40734556 <a title="265-lsi-10" href="./iccv-2013-ACTIVE%3A_Activity_Concept_Transitions_in_Video_Event_Classification.html">4 iccv-2013-ACTIVE: Activity Concept Transitions in Video Event Classification</a></p>
<p>11 0.39482263 <a title="265-lsi-11" href="./iccv-2013-Video_Event_Understanding_Using_Natural_Language_Descriptions.html">440 iccv-2013-Video Event Understanding Using Natural Language Descriptions</a></p>
<p>12 0.39390901 <a title="265-lsi-12" href="./iccv-2013-Manipulation_Pattern_Discovery%3A_A_Nonparametric_Bayesian_Approach.html">260 iccv-2013-Manipulation Pattern Discovery: A Nonparametric Bayesian Approach</a></p>
<p>13 0.38944778 <a title="265-lsi-13" href="./iccv-2013-Dictionary_Learning_and_Sparse_Coding_on_Grassmann_Manifolds%3A_An_Extrinsic_Solution.html">114 iccv-2013-Dictionary Learning and Sparse Coding on Grassmann Manifolds: An Extrinsic Solution</a></p>
<p>14 0.38674662 <a title="265-lsi-14" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<p>15 0.3856453 <a title="265-lsi-15" href="./iccv-2013-Learning_View-Invariant_Sparse_Representations_for_Cross-View_Action_Recognition.html">244 iccv-2013-Learning View-Invariant Sparse Representations for Cross-View Action Recognition</a></p>
<p>16 0.37898716 <a title="265-lsi-16" href="./iccv-2013-Learning_Slow_Features_for_Behaviour_Analysis.html">243 iccv-2013-Learning Slow Features for Behaviour Analysis</a></p>
<p>17 0.37165096 <a title="265-lsi-17" href="./iccv-2013-Monte_Carlo_Tree_Search_for_Scheduling_Activity_Recognition.html">274 iccv-2013-Monte Carlo Tree Search for Scheduling Activity Recognition</a></p>
<p>18 0.36427459 <a title="265-lsi-18" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>19 0.36158893 <a title="265-lsi-19" href="./iccv-2013-Latent_Multitask_Learning_for_View-Invariant_Action_Recognition.html">231 iccv-2013-Latent Multitask Learning for View-Invariant Action Recognition</a></p>
<p>20 0.36126685 <a title="265-lsi-20" href="./iccv-2013-Action_Recognition_with_Actons.html">38 iccv-2013-Action Recognition with Actons</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.042), (20, 0.069), (25, 0.019), (42, 0.166), (48, 0.141), (50, 0.014), (55, 0.011), (60, 0.014), (66, 0.289), (77, 0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72368288 <a title="265-lda-1" href="./iccv-2013-Mining_Motion_Atoms_and_Phrases_for_Complex_Action_Recognition.html">265 iccv-2013-Mining Motion Atoms and Phrases for Complex Action Recognition</a></p>
<p>2 0.70832473 <a title="265-lda-2" href="./iccv-2013-Semi-dense_Visual_Odometry_for_a_Monocular_Camera.html">382 iccv-2013-Semi-dense Visual Odometry for a Monocular Camera</a></p>
<p>3 0.66863281 <a title="265-lda-3" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>4 0.65429413 <a title="265-lda-4" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>5 0.65218329 <a title="265-lda-5" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>6 0.65201151 <a title="265-lda-6" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>7 0.65138328 <a title="265-lda-7" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>8 0.65121078 <a title="265-lda-8" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>9 0.65119606 <a title="265-lda-9" href="./iccv-2013-A_General_Two-Step_Approach_to_Learning-Based_Hashing.html">13 iccv-2013-A General Two-Step Approach to Learning-Based Hashing</a></p>
<p>10 0.64986897 <a title="265-lda-10" href="./iccv-2013-Minimal_Basis_Facility_Location_for_Subspace_Segmentation.html">264 iccv-2013-Minimal Basis Facility Location for Subspace Segmentation</a></p>
<p>11 0.64823937 <a title="265-lda-11" href="./iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</a></p>
<p>12 0.64751887 <a title="265-lda-12" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>13 0.6474371 <a title="265-lda-13" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>14 0.64691383 <a title="265-lda-14" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>15 0.64667529 <a title="265-lda-15" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>16 0.64595765 <a title="265-lda-16" href="./iccv-2013-Efficient_and_Robust_Large-Scale_Rotation_Averaging.html">138 iccv-2013-Efficient and Robust Large-Scale Rotation Averaging</a></p>
<p>17 0.64528358 <a title="265-lda-17" href="./iccv-2013-Estimating_Human_Pose_with_Flowing_Puppets.html">143 iccv-2013-Estimating Human Pose with Flowing Puppets</a></p>
<p>18 0.64495575 <a title="265-lda-18" href="./iccv-2013-Robust_Subspace_Clustering_via_Half-Quadratic_Minimization.html">360 iccv-2013-Robust Subspace Clustering via Half-Quadratic Minimization</a></p>
<p>19 0.64472574 <a title="265-lda-19" href="./iccv-2013-Joint_Subspace_Stabilization_for_Stereoscopic_Video.html">226 iccv-2013-Joint Subspace Stabilization for Stereoscopic Video</a></p>
<p>20 0.64456153 <a title="265-lda-20" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
