<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 iccv-2013-Discriminant Tracking Using Tensor Representation with Semi-supervised Improvement</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-119" href="#">iccv2013-119</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>119 iccv-2013-Discriminant Tracking Using Tensor Representation with Semi-supervised Improvement</h1>
<br/><p>Source: <a title="iccv-2013-119-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Gao_Discriminant_Tracking_Using_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Jin Gao, Junliang Xing, Weiming Hu, Steve Maybank</p><p>Abstract: Visual tracking has witnessed growing methods in object representation, which is crucial to robust tracking. The dominant mechanism in object representation is using image features encoded in a vector as observations to perform tracking, without considering that an image is intrinsically a matrix, or a 2nd-order tensor. Thus approaches following this mechanism inevitably lose a lot of useful information, and therefore cannot fully exploit the spatial correlations within the 2D image ensembles. In this paper, we address an image as a 2nd-order tensor in its original form, and find a discriminative linear embedding space approximation to the original nonlinear submanifold embedded in the tensor space based on the graph embedding framework. We specially design two graphs for characterizing the intrinsic local geometrical structure of the tensor space, so as to retain more discriminant information when reducing the dimension along certain tensor dimensions. However, spatial correlations within a tensor are not limited to the elements along these dimensions. This means that some part of the discriminant information may not be encoded in the embedding space. We introduce a novel technique called semi-supervised improvement to iteratively adjust the embedding space to compensate for the loss of discriminant information, hence improving the performance of our tracker. Experimental results on challenging videos demonstrate the effectiveness and robustness of the proposed tracker.</p><p>Reference: <a title="iccv-2013-119-reference" href="../iccv2013_reference/iccv-2013-Discriminant_Tracking_Using_Tensor_Representation_with_Semi-supervised_Improvement_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 i a  Abstract Visual tracking has witnessed growing methods in object representation, which is crucial to robust tracking. [sent-2, score-0.188]
</p><p>2 The dominant mechanism in object representation is using image features encoded in a vector as observations to perform tracking, without considering that an image is intrinsically a matrix, or a 2nd-order tensor. [sent-3, score-0.195]
</p><p>3 Thus approaches following this mechanism inevitably lose a lot of useful information, and therefore cannot fully exploit the spatial correlations within the 2D image ensembles. [sent-4, score-0.184]
</p><p>4 In this paper, we address an image as a 2nd-order tensor in its original form, and find a discriminative linear embedding space approximation to the original nonlinear submanifold embedded in the tensor space based on the graph embedding framework. [sent-5, score-2.269]
</p><p>5 We specially design two graphs for characterizing the intrinsic local geometrical structure of the tensor space, so as to retain more discriminant information when reducing the dimension along certain tensor dimensions. [sent-6, score-2.128]
</p><p>6 However, spatial correlations within a tensor are not limited to the elements along these dimensions. [sent-7, score-0.944]
</p><p>7 This means that some part  of the discriminant information may not be encoded in the embedding space. [sent-8, score-0.485]
</p><p>8 We introduce a novel technique called semi-supervised improvement to iteratively adjust the embedding space to compensate for the loss of discriminant information, hence improving the performance of our tracker. [sent-9, score-0.604]
</p><p>9 Introduction Robust visual tracking is an essential component of many practical computer vision applications such as surveillance, vehicle navigation, and human computer interface. [sent-12, score-0.129]
</p><p>10 Despite much effort resulting in many novel trackers, tracking generic objects remains a challenging problem . [sent-13, score-0.129]
</p><p>11 partial occlusions, illumination changes, cluttered and moving backgrounds) appearance variations (see a more detailed discussion in [3 1]). [sent-22, score-0.038]
</p><p>12 Many tracking systems construct an adaptive appearance model based on the collected image patches in previous frames. [sent-23, score-0.167]
</p><p>13 This model is used to find the most likely image patch in the current frame. [sent-24, score-0.052]
</p><p>14 There are many object representation methods proposed for visual tracking. [sent-26, score-0.044]
</p><p>15 Some tracking approaches [21, 35] adopt holistic gray-scale image-asvector representation. [sent-27, score-0.129]
</p><p>16 1 minimization based visual tracking approaches [17, 18, 3, 34, 33], which  exploit the sparse representation of the image patch. [sent-29, score-0.173]
</p><p>17 [8, 9] construct multiple basic appearance models by sparse principal component analysis (SPCA) of a set of feature templates (e. [sent-31, score-0.038]
</p><p>18 These representation methods ignore that an image is intrinsically a matrix, or a 2nd-order tensor. [sent-34, score-0.152]
</p><p>19 In [2, 10] only Haar-like features used, but great improvements are achieved by novel appearance models. [sent-37, score-0.038]
</p><p>20 [12, 15] only use HOGs but apply novel appearance models to achieve good results. [sent-39, score-0.038]
</p><p>21 [1] robustly combine multiple patch votes with each image patch represented by only gray-scale histogram features. [sent-41, score-0.104]
</p><p>22 These representation methods have their own advantages for their specifically designed appearance models. [sent-42, score-0.082]
</p><p>23 However, a lot ofuseful information is missed when extracting features. [sent-43, score-0.075]
</p><p>24 image-as-matrix representation) can retain much more useful information because the original image data structure is preserved. [sent-46, score-0.046]
</p><p>25 [29, 7, 27]) on tensor11556699  based subspace learning, particularly for face recognition. [sent-49, score-0.051]
</p><p>26 Also, many previous visual tracking approaches use the tensor concept. [sent-50, score-0.917]
</p><p>27 [13, 25, 24]) conduct PCA in the mode-k flattened matrix; others (e. [sent-53, score-0.077]
</p><p>28 [26, 11]) adopt covariance tracking technique [19] in the mode-k flattened ma-  trix. [sent-55, score-0.241]
</p><p>29 Additionally, the dimension reduction based subspace learning methods used in [13, 25, 24] ignore a very important problem proposed in [27]. [sent-57, score-0.186]
</p><p>30 The problem is that correlations within a tensor are not limited to the elements along certain tensor dimensions. [sent-58, score-1.732]
</p><p>31 Some part of the discriminant information may not be encoded in the first few dimensions of the derived subspace. [sent-59, score-0.247]
</p><p>32 This may lead to subspace learning degradations and result in tracking distractions. [sent-60, score-0.215]
</p><p>33 [27] propose to rearrange elements in the tensor to solve the subspace learning degradation problem, the exhaustive element rearranging makes it unsuitable for real-time tracking. [sent-64, score-1.011]
</p><p>34 Inspired by these findings, we propose a new discriminant tracking approach which adopts a 2nd-order tensor (image-as-matrix) representation. [sent-65, score-1.146]
</p><p>35 Then, we  embed the target and background tensor samples into two specially designed graphs, so that the object can be effectively separated from the background in the graph embedding framework for dimension reduction. [sent-67, score-1.201]
</p><p>36 It is noted that, this approach can be extended by using higher-order tensor representation (e. [sent-68, score-0.832]
</p><p>37 3rd-order tensor with a feature vector for each pixel, see [25, 24, 26, 11] for more details), although we only use gray-scale image-as-matrix representation. [sent-70, score-0.788]
</p><p>38 Because the correlations within a 2nd-order tensor are not limited to the elements along particular columns and rows, the discriminative embedding space derived from dimension reduction may not encode enough of the discriminant information. [sent-71, score-1.489]
</p><p>39 We improve the classification accuracy of our tensor representation based tracking approach by using the available unlabeled tensor samples. [sent-72, score-1.851]
</p><p>40 By this improvement, we can adjust the discriminative embedding space so that most of the discriminant information is encoded in it. [sent-74, score-0.589]
</p><p>41 At each iteration, a number of unlabeled tensor samples are selected and used to learn a new discriminative embedding space. [sent-76, score-1.207]
</p><p>42 The learned embedding spaces from different iterations and the one trained using only the labeled samples are combined linearly to form a final adjusted embedding space which encodes most of the discriminant information. [sent-77, score-0.706]
</p><p>43 That is to say, we make use of the unlabeled samples in an inductive fashion, which is very different from most semi-supervised tracking approaches (e. [sent-78, score-0.306]
</p><p>44 [6, 10, 12]), in which all the unla-  beled samples are used for training without selection. [sent-80, score-0.086]
</p><p>45 The new semi-supervised improvement technique adopts a novel strategy to address the two questions: 1) how to select the unlabeled samples; 2) what class labels should be assigned to the selected unlabeled samples. [sent-81, score-0.324]
</p><p>46 It is also very different from some margin improving techniques, where the unlabeled samples with the highest classification confidences are selected and the class labels that are predicted by the current classifier are assigned to them, as in Selftraining [20], ASSEMBLE [4]. [sent-82, score-0.25]
</p><p>47 These techniques may increase the classification margin, but they do not provide any novel information to adjust the discriminative embedding space. [sent-83, score-0.342]
</p><p>48 We plug the margin improving technique ASSEMBLE into our system and make a direct comparison with our method in Section 3. [sent-84, score-0.142]
</p><p>49 We elaborate the important components of the proposed approach in this section, in particular the tensor based linear embedding and derivation of the proposed semi-supervised improvement technique. [sent-88, score-1.07]
</p><p>50 Before all of these, we first review some terminology for tensor operations. [sent-89, score-0.854]
</p><p>51 Terminology for tensor operations A tensor is a higher order generalization of a vector (1storder tensor) and a matrix (2nd-order tensor). [sent-92, score-1.576]
</p><p>52 A tensor is a multilinear mapping over a set of vector spaces. [sent-93, score-0.823]
</p><p>53 ×mn  order tensor is denoted as A ∈ Rm1 ×m2 , and its eorledmeren tetns are represented by ai1,. [sent-97, score-0.788]
</p><p>54 The inner product of two nth-order tensors is defined as  ? [sent-101, score-0.062]
</p><p>55 , and the distance bettwheee nno rAm a onfd A AB i ss ? [sent-131, score-0.066]
</p><p>56 2,n adn-dor tdheer dtiesntsaoncr case, ttwhee norm aisn cda Blled is st ? [sent-138, score-0.139]
</p><p>57 T nhoer mm iosd cea-llke dv tehceto Frrso are uths en rcomlu amndn vectors o ? [sent-145, score-0.044]
</p><p>58 The inverse operation osf rmomode fl-kat flattening i tse nmsoorde A-k. [sent-153, score-0.112]
</p><p>59 folding, which restores the original tensor A from A(k) . [sent-154, score-0.829]
</p><p>60 ×mn  11557700  Figure 1: Block diagram of the proposed tracker. [sent-161, score-0.028]
</p><p>61 MA(k) , sfooll boew ceodm by mtedod beyk folding. [sent-188, score-0.044]
</p><p>62 Note that for tensors and matrices of the appropriate sizes, A U V = A ×n V U and (pAro p×r tUe) s i×z V, A A= ×A ×U ( ×VUV). [sent-189, score-0.062]
</p><p>63 M =or eA d ×etaiVls o ×f the tensor algebra are given =in A[23×]. [sent-190, score-0.816]
</p><p>64 Tensor based linear embedding  Previous work has demonstrated that the image variations of many objects can be modeled by low dimensional linear spaces. [sent-193, score-0.238]
</p><p>65 However, the typical algorithms either only consider an image as a high dimensional vector, or can not fully detect the intrinsic local geometrical and discriminative structure of the collected image patches in the tensor form. [sent-194, score-0.94]
</p><p>66 Then, a particular question arises: how to find an effective linear embedding space approximation to the original nonlinear submanifold embedded in the tensor space. [sent-195, score-1.199]
</p><p>67 Graph embedding for dimension reduction [28, 22] provides us an innovation to this question in the sense of local isometry. [sent-196, score-0.381]
</p><p>68 Generally case: We express the training sample set in the tensor form as {Xi ∈ Rm1 , i= 1, 2, . [sent-197, score-0.788]
</p><p>69 We build two graphs: an Mintrinsi⊆c graph G and a penalty graph Gp to model the local geometrical dan ad pdeinscalrtiymin gartaipvhe sGtructure of M. [sent-206, score-0.142]
</p><p>70 edtr Wcalp bned th deis edge weight tmruactrtuicrees ooff ? [sent-208, score-0.083]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tensor', 0.788), ('embedding', 0.238), ('discriminant', 0.188), ('tracking', 0.129), ('mn', 0.118), ('unlabeled', 0.102), ('correlations', 0.089), ('mk', 0.089), ('submanifold', 0.082), ('flattening', 0.077), ('flattened', 0.077), ('hogs', 0.074), ('geometrical', 0.072), ('adjust', 0.067), ('assemble', 0.066), ('terminology', 0.066), ('tensors', 0.062), ('encoded', 0.059), ('intrinsically', 0.055), ('specially', 0.053), ('ignore', 0.053), ('patch', 0.052), ('graphs', 0.051), ('subspace', 0.051), ('retain', 0.046), ('dimension', 0.045), ('beled', 0.044), ('bned', 0.044), ('ceodm', 0.044), ('distractions', 0.044), ('junliang', 0.044), ('lxing', 0.044), ('ofuseful', 0.044), ('selftraining', 0.044), ('spca', 0.044), ('uths', 0.044), ('vuv', 0.044), ('weiming', 0.044), ('representation', 0.044), ('improvement', 0.044), ('intrinsic', 0.043), ('samples', 0.042), ('margin', 0.042), ('adopts', 0.041), ('dcs', 0.041), ('haarlike', 0.041), ('alk', 0.041), ('bky', 0.041), ('restores', 0.041), ('elements', 0.04), ('folding', 0.039), ('tue', 0.039), ('cda', 0.039), ('deis', 0.039), ('ina', 0.039), ('appearance', 0.038), ('reduction', 0.037), ('discriminative', 0.037), ('mechanism', 0.037), ('rearrange', 0.037), ('rearranging', 0.037), ('tdheer', 0.037), ('embedded', 0.036), ('sor', 0.035), ('multilinear', 0.035), ('tse', 0.035), ('rob', 0.035), ('degradations', 0.035), ('onfd', 0.035), ('graph', 0.035), ('technique', 0.035), ('nlpr', 0.034), ('norm', 0.033), ('inductive', 0.033), ('innovation', 0.033), ('plug', 0.033), ('hea', 0.033), ('confidences', 0.032), ('improving', 0.032), ('cas', 0.031), ('nno', 0.031), ('lot', 0.031), ('aisn', 0.03), ('hue', 0.03), ('witnessed', 0.03), ('crucial', 0.029), ('unsuitable', 0.029), ('degradation', 0.029), ('adam', 0.029), ('diagram', 0.028), ('algebra', 0.028), ('question', 0.028), ('nonlinear', 0.027), ('along', 0.027), ('inevitably', 0.027), ('kwon', 0.027), ('navigation', 0.027), ('grabner', 0.027), ('characterizing', 0.027), ('extrinsic', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="119-tfidf-1" href="./iccv-2013-Discriminant_Tracking_Using_Tensor_Representation_with_Semi-supervised_Improvement.html">119 iccv-2013-Discriminant Tracking Using Tensor Representation with Semi-supervised Improvement</a></p>
<p>Author: Jin Gao, Junliang Xing, Weiming Hu, Steve Maybank</p><p>Abstract: Visual tracking has witnessed growing methods in object representation, which is crucial to robust tracking. The dominant mechanism in object representation is using image features encoded in a vector as observations to perform tracking, without considering that an image is intrinsically a matrix, or a 2nd-order tensor. Thus approaches following this mechanism inevitably lose a lot of useful information, and therefore cannot fully exploit the spatial correlations within the 2D image ensembles. In this paper, we address an image as a 2nd-order tensor in its original form, and find a discriminative linear embedding space approximation to the original nonlinear submanifold embedded in the tensor space based on the graph embedding framework. We specially design two graphs for characterizing the intrinsic local geometrical structure of the tensor space, so as to retain more discriminant information when reducing the dimension along certain tensor dimensions. However, spatial correlations within a tensor are not limited to the elements along these dimensions. This means that some part of the discriminant information may not be encoded in the embedding space. We introduce a novel technique called semi-supervised improvement to iteratively adjust the embedding space to compensate for the loss of discriminant information, hence improving the performance of our tracker. Experimental results on challenging videos demonstrate the effectiveness and robustness of the proposed tracker.</p><p>2 0.40299323 <a title="119-tfidf-2" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>Author: Miao Zhang, Chris Ding</p><p>Abstract: Many tensor based algorithms have been proposed for the study of high dimensional data in a large variety ofcomputer vision and machine learning applications. However, most of the existing tensor analysis approaches are based on Frobenius norm, which makes them sensitive to outliers, because they minimize the sum of squared errors and enlarge the influence of both outliers and large feature noises. In this paper, we propose a robust Tucker tensor decomposition model (RTD) to suppress the influence of outliers, which uses L1-norm loss function. Yet, the optimization on L1-norm based tensor analysis is much harder than standard tensor decomposition. In this paper, we propose a simple and efficient algorithm to solve our RTD model. Moreover, tensor factorization-based image storage needs much less space than PCA based methods. We carry out extensive experiments to evaluate the proposed algorithm, and verify the robustness against image occlusions. Both numerical and visual results show that our RTD model is consistently better against the existence of outliers than previous tensor and PCA methods.</p><p>3 0.15046419 <a title="119-tfidf-3" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>Author: Pierre Moulon, Pascal Monasse, Renaud Marlet</p><p>Abstract: Multi-view structure from motion (SfM) estimates the position and orientation of pictures in a common 3D coordinate frame. When views are treated incrementally, this external calibration can be subject to drift, contrary to global methods that distribute residual errors evenly. We propose a new global calibration approach based on the fusion of relative motions between image pairs. We improve an existing method for robustly computing global rotations. We present an efficient a contrario trifocal tensor estimation method, from which stable and precise translation directions can be extracted. We also define an efficient translation registration method that recovers accurate camera positions. These components are combined into an original SfM pipeline. Our experiments show that, on most datasets, it outperforms in accuracy other existing incremental and global pipelines. It also achieves strikingly good running times: it is about 20 times faster than the other global method we could compare to, and as fast as the best incremental method. More importantly, it features better scalability properties.</p><p>4 0.093428701 <a title="119-tfidf-4" href="./iccv-2013-Efficient_Higher-Order_Clustering_on_the_Grassmann_Manifold.html">134 iccv-2013-Efficient Higher-Order Clustering on the Grassmann Manifold</a></p>
<p>Author: Suraj Jain, Venu Madhav Govindu</p><p>Abstract: The higher-order clustering problem arises when data is drawn from multiple subspaces or when observations fit a higher-order parametric model. Most solutions to this problem either decompose higher-order similarity measures for use in spectral clustering or explicitly use low-rank matrix representations. In this paper we present our approach of Sparse Grassmann Clustering (SGC) that combines attributes of both categories. While we decompose the higherorder similarity tensor, we cluster data by directly finding a low dimensional representation without explicitly building a similarity matrix. By exploiting recent advances in online estimation on the Grassmann manifold (GROUSE) we develop an efficient and accurate algorithm that works with individual columns of similarities or partial observations thereof. Since it avoids the storage and decomposition of large similarity matrices, our method is efficient, scalable and has low memory requirements even for large-scale data. We demonstrate the performance of our SGC method on a variety of segmentation problems including planar seg- mentation of Kinect depth maps and motion segmentation of the Hopkins 155 dataset for which we achieve performance comparable to the state-of-the-art.</p><p>5 0.09098848 <a title="119-tfidf-5" href="./iccv-2013-Directed_Acyclic_Graph_Kernels_for_Action_Recognition.html">116 iccv-2013-Directed Acyclic Graph Kernels for Action Recognition</a></p>
<p>Author: Ling Wang, Hichem Sahbi</p><p>Abstract: One of the trends of action recognition consists in extracting and comparing mid-level features which encode visual and motion aspects of objects into scenes. However, when scenes contain high-level semantic actions with many interacting parts, these mid-level features are not sufficient to capture high level structures as well as high order causal relationships between moving objects resulting into a clear drop in performances. In this paper, we address this issue and we propose an alternative action recognition method based on a novel graph kernel. In the main contributions of this work, we first describe actions in videos using directed acyclic graphs (DAGs), that naturally encode pairwise interactions between moving object parts, and then we compare these DAGs by analyzing the spectrum of their sub-patterns that capture complex higher order interactions. This extraction and comparison process is computationally tractable, re- sulting from the acyclic property of DAGs, and it also defines a positive semi-definite kernel. When plugging the latter into support vector machines, we obtain an action recognition algorithm that overtakes related work, including graph-based methods, on a standard evaluation dataset.</p><p>6 0.082578972 <a title="119-tfidf-6" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>7 0.079698123 <a title="119-tfidf-7" href="./iccv-2013-Log-Euclidean_Kernels_for_Sparse_Representation_and_Dictionary_Learning.html">257 iccv-2013-Log-Euclidean Kernels for Sparse Representation and Dictionary Learning</a></p>
<p>8 0.078239053 <a title="119-tfidf-8" href="./iccv-2013-Curvature-Aware_Regularization_on_Riemannian_Submanifolds.html">100 iccv-2013-Curvature-Aware Regularization on Riemannian Submanifolds</a></p>
<p>9 0.076150075 <a title="119-tfidf-9" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>10 0.07237263 <a title="119-tfidf-10" href="./iccv-2013-Image_Guided_Depth_Upsampling_Using_Anisotropic_Total_Generalized_Variation.html">209 iccv-2013-Image Guided Depth Upsampling Using Anisotropic Total Generalized Variation</a></p>
<p>11 0.072131701 <a title="119-tfidf-11" href="./iccv-2013-Image_Set_Classification_Using_Holistic_Multiple_Order_Statistics_Features_and_Localized_Multi-kernel_Metric_Learning.html">212 iccv-2013-Image Set Classification Using Holistic Multiple Order Statistics Features and Localized Multi-kernel Metric Learning</a></p>
<p>12 0.071297921 <a title="119-tfidf-12" href="./iccv-2013-Parallel_Transport_of_Deformations_in_Shape_Space_of_Elastic_Surfaces.html">307 iccv-2013-Parallel Transport of Deformations in Shape Space of Elastic Surfaces</a></p>
<p>13 0.070497945 <a title="119-tfidf-13" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>14 0.06932345 <a title="119-tfidf-14" href="./iccv-2013-Automatic_Kronecker_Product_Model_Based_Detection_of_Repeated_Patterns_in_2D_Urban_Images.html">55 iccv-2013-Automatic Kronecker Product Model Based Detection of Repeated Patterns in 2D Urban Images</a></p>
<p>15 0.067976907 <a title="119-tfidf-15" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>16 0.066437095 <a title="119-tfidf-16" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>17 0.0631129 <a title="119-tfidf-17" href="./iccv-2013-Online_Robust_Non-negative_Dictionary_Learning_for_Visual_Tracking.html">298 iccv-2013-Online Robust Non-negative Dictionary Learning for Visual Tracking</a></p>
<p>18 0.061394382 <a title="119-tfidf-18" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>19 0.060744751 <a title="119-tfidf-19" href="./iccv-2013-Recursive_Estimation_of_the_Stein_Center_of_SPD_Matrices_and_Its_Applications.html">347 iccv-2013-Recursive Estimation of the Stein Center of SPD Matrices and Its Applications</a></p>
<p>20 0.059889626 <a title="119-tfidf-20" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.132), (1, -0.009), (2, -0.037), (3, -0.013), (4, -0.055), (5, 0.011), (6, -0.024), (7, 0.069), (8, 0.017), (9, 0.024), (10, -0.029), (11, -0.069), (12, -0.03), (13, 0.018), (14, 0.077), (15, 0.013), (16, 0.039), (17, 0.002), (18, -0.007), (19, 0.014), (20, 0.001), (21, 0.056), (22, -0.048), (23, -0.038), (24, 0.007), (25, 0.071), (26, 0.039), (27, 0.068), (28, -0.091), (29, 0.091), (30, -0.042), (31, -0.061), (32, -0.08), (33, 0.031), (34, 0.038), (35, 0.126), (36, 0.115), (37, 0.081), (38, -0.138), (39, 0.142), (40, -0.1), (41, 0.048), (42, 0.037), (43, 0.065), (44, 0.073), (45, -0.039), (46, -0.205), (47, 0.246), (48, 0.147), (49, -0.157)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94869834 <a title="119-lsi-1" href="./iccv-2013-Discriminant_Tracking_Using_Tensor_Representation_with_Semi-supervised_Improvement.html">119 iccv-2013-Discriminant Tracking Using Tensor Representation with Semi-supervised Improvement</a></p>
<p>Author: Jin Gao, Junliang Xing, Weiming Hu, Steve Maybank</p><p>Abstract: Visual tracking has witnessed growing methods in object representation, which is crucial to robust tracking. The dominant mechanism in object representation is using image features encoded in a vector as observations to perform tracking, without considering that an image is intrinsically a matrix, or a 2nd-order tensor. Thus approaches following this mechanism inevitably lose a lot of useful information, and therefore cannot fully exploit the spatial correlations within the 2D image ensembles. In this paper, we address an image as a 2nd-order tensor in its original form, and find a discriminative linear embedding space approximation to the original nonlinear submanifold embedded in the tensor space based on the graph embedding framework. We specially design two graphs for characterizing the intrinsic local geometrical structure of the tensor space, so as to retain more discriminant information when reducing the dimension along certain tensor dimensions. However, spatial correlations within a tensor are not limited to the elements along these dimensions. This means that some part of the discriminant information may not be encoded in the embedding space. We introduce a novel technique called semi-supervised improvement to iteratively adjust the embedding space to compensate for the loss of discriminant information, hence improving the performance of our tracker. Experimental results on challenging videos demonstrate the effectiveness and robustness of the proposed tracker.</p><p>2 0.86995161 <a title="119-lsi-2" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>Author: Miao Zhang, Chris Ding</p><p>Abstract: Many tensor based algorithms have been proposed for the study of high dimensional data in a large variety ofcomputer vision and machine learning applications. However, most of the existing tensor analysis approaches are based on Frobenius norm, which makes them sensitive to outliers, because they minimize the sum of squared errors and enlarge the influence of both outliers and large feature noises. In this paper, we propose a robust Tucker tensor decomposition model (RTD) to suppress the influence of outliers, which uses L1-norm loss function. Yet, the optimization on L1-norm based tensor analysis is much harder than standard tensor decomposition. In this paper, we propose a simple and efficient algorithm to solve our RTD model. Moreover, tensor factorization-based image storage needs much less space than PCA based methods. We carry out extensive experiments to evaluate the proposed algorithm, and verify the robustness against image occlusions. Both numerical and visual results show that our RTD model is consistently better against the existence of outliers than previous tensor and PCA methods.</p><p>3 0.61983591 <a title="119-lsi-3" href="./iccv-2013-Recursive_Estimation_of_the_Stein_Center_of_SPD_Matrices_and_Its_Applications.html">347 iccv-2013-Recursive Estimation of the Stein Center of SPD Matrices and Its Applications</a></p>
<p>Author: Hesamoddin Salehian, Guang Cheng, Baba C. Vemuri, Jeffrey Ho</p><p>Abstract: Symmetric positive-definite (SPD) matrices are ubiquitous in Computer Vision, Machine Learning and Medical Image Analysis. Finding the center/average of a population of such matrices is a common theme in many algorithms such as clustering, segmentation, principal geodesic analysis, etc. The center of a population of such matrices can be defined using a variety of distance/divergence measures as the minimizer of the sum of squared distances/divergences from the unknown center to the members of the population. It is well known that the computation of the Karcher mean for the space of SPD matrices which is a negativelycurved Riemannian manifold is computationally expensive. Recently, the LogDet divergence-based center was shown to be a computationally attractive alternative. However, the LogDet-based mean of more than two matrices can not be computed in closed form, which makes it computationally less attractive for large populations. In this paper we present a novel recursive estimator for center based on the Stein distance which is the square root of the LogDet di– vergence that is significantly faster than the batch mode computation of this center. The key theoretical contribution is a closed-form solution for the weighted Stein center of two SPD matrices, which is used in the recursive computation of the Stein center for a population of SPD matrices. Additionally, we show experimental evidence of the convergence of our recursive Stein center estimator to the batch mode Stein center. We present applications of our recursive estimator to K-means clustering and image indexing depicting significant time gains over corresponding algorithms that use the batch mode computations. For the latter application, we develop novel hashing functions using the Stein distance and apply it to publicly available data sets, and experimental results have shown favorable com– ∗This research was funded in part by the NIH grant NS066340 to BCV. †Corresponding author parisons to other competing methods.</p><p>4 0.51435399 <a title="119-lsi-4" href="./iccv-2013-Log-Euclidean_Kernels_for_Sparse_Representation_and_Dictionary_Learning.html">257 iccv-2013-Log-Euclidean Kernels for Sparse Representation and Dictionary Learning</a></p>
<p>Author: Peihua Li, Qilong Wang, Wangmeng Zuo, Lei Zhang</p><p>Abstract: The symmetric positive de?nite (SPD) matrices have been widely used in image and vision problems. Recently there are growing interests in studying sparse representation (SR) of SPD matrices, motivated by the great success of SR for vector data. Though the space of SPD matrices is well-known to form a Lie group that is a Riemannian manifold, existing work fails to take full advantage of its geometric structure. This paper attempts to tackle this problem by proposing a kernel based method for SR and dictionary learning (DL) of SPD matrices. We disclose that the space of SPD matrices, with the operations of logarithmic multiplication and scalar logarithmic multiplication de?ned in the Log-Euclidean framework, is a complete inner product space. We can thus develop a broad family of kernels that satis?es Mercer’s condition. These kernels characterize the geodesic distance and can be computed ef?ciently. We also consider the geometric structure in the DL process by updating atom matrices in the Riemannian space instead of in the Euclidean space. The proposed method is evaluated with various vision problems and shows notable per- formance gains over state-of-the-arts.</p><p>5 0.47230822 <a title="119-lsi-5" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>Author: Pierre Moulon, Pascal Monasse, Renaud Marlet</p><p>Abstract: Multi-view structure from motion (SfM) estimates the position and orientation of pictures in a common 3D coordinate frame. When views are treated incrementally, this external calibration can be subject to drift, contrary to global methods that distribute residual errors evenly. We propose a new global calibration approach based on the fusion of relative motions between image pairs. We improve an existing method for robustly computing global rotations. We present an efficient a contrario trifocal tensor estimation method, from which stable and precise translation directions can be extracted. We also define an efficient translation registration method that recovers accurate camera positions. These components are combined into an original SfM pipeline. Our experiments show that, on most datasets, it outperforms in accuracy other existing incremental and global pipelines. It also achieves strikingly good running times: it is about 20 times faster than the other global method we could compare to, and as fast as the best incremental method. More importantly, it features better scalability properties.</p><p>6 0.45678341 <a title="119-lsi-6" href="./iccv-2013-A_Novel_Earth_Mover%27s_Distance_Methodology_for_Image_Matching_with_Gaussian_Mixture_Models.html">25 iccv-2013-A Novel Earth Mover's Distance Methodology for Image Matching with Gaussian Mixture Models</a></p>
<p>7 0.44363296 <a title="119-lsi-7" href="./iccv-2013-Automatic_Kronecker_Product_Model_Based_Detection_of_Repeated_Patterns_in_2D_Urban_Images.html">55 iccv-2013-Automatic Kronecker Product Model Based Detection of Repeated Patterns in 2D Urban Images</a></p>
<p>8 0.40136054 <a title="119-lsi-8" href="./iccv-2013-Efficient_and_Robust_Large-Scale_Rotation_Averaging.html">138 iccv-2013-Efficient and Robust Large-Scale Rotation Averaging</a></p>
<p>9 0.37842155 <a title="119-lsi-9" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>10 0.37011918 <a title="119-lsi-10" href="./iccv-2013-Efficient_Higher-Order_Clustering_on_the_Grassmann_Manifold.html">134 iccv-2013-Efficient Higher-Order Clustering on the Grassmann Manifold</a></p>
<p>11 0.36996216 <a title="119-lsi-11" href="./iccv-2013-Image_Set_Classification_Using_Holistic_Multiple_Order_Statistics_Features_and_Localized_Multi-kernel_Metric_Learning.html">212 iccv-2013-Image Set Classification Using Holistic Multiple Order Statistics Features and Localized Multi-kernel Metric Learning</a></p>
<p>12 0.3497785 <a title="119-lsi-12" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>13 0.33171421 <a title="119-lsi-13" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>14 0.31620407 <a title="119-lsi-14" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<p>15 0.30459538 <a title="119-lsi-15" href="./iccv-2013-Target-Driven_Moire_Pattern_Synthesis_by_Phase_Modulation.html">413 iccv-2013-Target-Driven Moire Pattern Synthesis by Phase Modulation</a></p>
<p>16 0.2989876 <a title="119-lsi-16" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>17 0.29587191 <a title="119-lsi-17" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>18 0.29573286 <a title="119-lsi-18" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>19 0.29169241 <a title="119-lsi-19" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>20 0.28933752 <a title="119-lsi-20" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.063), (7, 0.017), (26, 0.077), (31, 0.039), (35, 0.33), (40, 0.019), (42, 0.132), (64, 0.054), (73, 0.019), (89, 0.154)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85122538 <a title="119-lda-1" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>Author: Kaiming He, Huiwen Chang, Jian Sun</p><p>Abstract: We present an image editing tool called Content-Aware Rotation. Casually shot photos can appear tilted, and are often corrected by rotation and cropping. This trivial solution may remove desired content and hurt image integrity. Instead of doing rigid rotation, we propose a warping method that creates the perception of rotation and avoids cropping. Human vision studies suggest that the perception of rotation is mainly due to horizontal/vertical lines. We design an optimization-based method that preserves the rotation of horizontal/vertical lines, maintains the completeness of the image content, and reduces the warping distortion. An efficient algorithm is developed to address the challenging optimization. We demonstrate our content-aware rotation method on a variety of practical cases.</p><p>same-paper 2 0.77155459 <a title="119-lda-2" href="./iccv-2013-Discriminant_Tracking_Using_Tensor_Representation_with_Semi-supervised_Improvement.html">119 iccv-2013-Discriminant Tracking Using Tensor Representation with Semi-supervised Improvement</a></p>
<p>Author: Jin Gao, Junliang Xing, Weiming Hu, Steve Maybank</p><p>Abstract: Visual tracking has witnessed growing methods in object representation, which is crucial to robust tracking. The dominant mechanism in object representation is using image features encoded in a vector as observations to perform tracking, without considering that an image is intrinsically a matrix, or a 2nd-order tensor. Thus approaches following this mechanism inevitably lose a lot of useful information, and therefore cannot fully exploit the spatial correlations within the 2D image ensembles. In this paper, we address an image as a 2nd-order tensor in its original form, and find a discriminative linear embedding space approximation to the original nonlinear submanifold embedded in the tensor space based on the graph embedding framework. We specially design two graphs for characterizing the intrinsic local geometrical structure of the tensor space, so as to retain more discriminant information when reducing the dimension along certain tensor dimensions. However, spatial correlations within a tensor are not limited to the elements along these dimensions. This means that some part of the discriminant information may not be encoded in the embedding space. We introduce a novel technique called semi-supervised improvement to iteratively adjust the embedding space to compensate for the loss of discriminant information, hence improving the performance of our tracker. Experimental results on challenging videos demonstrate the effectiveness and robustness of the proposed tracker.</p><p>3 0.7485249 <a title="119-lda-3" href="./iccv-2013-Decomposing_Bag_of_Words_Histograms.html">104 iccv-2013-Decomposing Bag of Words Histograms</a></p>
<p>Author: Ankit Gandhi, Karteek Alahari, C.V. Jawahar</p><p>Abstract: We aim to decompose a global histogram representation of an image into histograms of its associated objects and regions. This task is formulated as an optimization problem, given a set of linear classifiers, which can effectively discriminate the object categories present in the image. Our decomposition bypasses harder problems associated with accurately localizing and segmenting objects. We evaluate our method on a wide variety of composite histograms, and also compare it with MRF-based solutions. In addition to merely measuring the accuracy of decomposition, we also show the utility of the estimated object and background histograms for the task of image classification on the PASCAL VOC 2007 dataset.</p><p>4 0.71173185 <a title="119-lda-4" href="./iccv-2013-Strong_Appearance_and_Expressive_Spatial_Models_for_Human_Pose_Estimation.html">403 iccv-2013-Strong Appearance and Expressive Spatial Models for Human Pose Estimation</a></p>
<p>Author: Leonid Pishchulin, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele</p><p>Abstract: Typical approaches to articulated pose estimation combine spatial modelling of the human body with appearance modelling of body parts. This paper aims to push the state-of-the-art in articulated pose estimation in two ways. First we explore various types of appearance representations aiming to substantially improve the bodypart hypotheses. And second, we draw on and combine several recently proposed powerful ideas such as more flexible spatial models as well as image-conditioned spatial models. In a series of experiments we draw several important conclusions: (1) we show that the proposed appearance representations are complementary; (2) we demonstrate that even a basic tree-structure spatial human body model achieves state-ofthe-art performance when augmented with the proper appearance representation; and (3) we show that the combination of the best performing appearance model with a flexible image-conditioned spatial model achieves the best result, significantly improving over the state of the art, on the “Leeds Sports Poses ” and “Parse ” benchmarks.</p><p>5 0.64945507 <a title="119-lda-5" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>Author: Yen-Lin Chen, Hsiang-Tao Wu, Fuhao Shi, Xin Tong, Jinxiang Chai</p><p>Abstract: This paper presents an automatic and robust approach that accurately captures high-quality 3D facial performances using a single RGBD camera. The key of our approach is to combine the power of automatic facial feature detection and image-based 3D nonrigid registration techniques for 3D facial reconstruction. In particular, we develop a robust and accurate image-based nonrigid registration algorithm that incrementally deforms a 3D template mesh model to best match observed depth image data and important facial features detected from single RGBD images. The whole process is fully automatic and robust because it is based on single frame facial registration framework. The system is flexible because it does not require any strong 3D facial priors such as blendshape models. We demonstrate the power of our approach by capturing a wide range of 3D facial expressions using a single RGBD camera and achieve state-of-the-art accuracy by comparing against alternative methods.</p><p>6 0.63767606 <a title="119-lda-6" href="./iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</a></p>
<p>7 0.63523138 <a title="119-lda-7" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>8 0.59593189 <a title="119-lda-8" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>9 0.59272176 <a title="119-lda-9" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>10 0.5896979 <a title="119-lda-10" href="./iccv-2013-Real-Time_Articulated_Hand_Pose_Estimation_Using_Semi-supervised_Transductive_Regression_Forests.html">340 iccv-2013-Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests</a></p>
<p>11 0.58966112 <a title="119-lda-11" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>12 0.58931601 <a title="119-lda-12" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>13 0.58862281 <a title="119-lda-13" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>14 0.58799791 <a title="119-lda-14" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>15 0.58671403 <a title="119-lda-15" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>16 0.58601058 <a title="119-lda-16" href="./iccv-2013-Semi-supervised_Learning_for_Large_Scale_Image_Cosegmentation.html">383 iccv-2013-Semi-supervised Learning for Large Scale Image Cosegmentation</a></p>
<p>17 0.58489931 <a title="119-lda-17" href="./iccv-2013-Progressive_Multigrid_Eigensolvers_for_Multiscale_Spectral_Segmentation.html">329 iccv-2013-Progressive Multigrid Eigensolvers for Multiscale Spectral Segmentation</a></p>
<p>18 0.58342773 <a title="119-lda-18" href="./iccv-2013-Frustratingly_Easy_NBNN_Domain_Adaptation.html">181 iccv-2013-Frustratingly Easy NBNN Domain Adaptation</a></p>
<p>19 0.5823105 <a title="119-lda-19" href="./iccv-2013-A_Simple_Model_for_Intrinsic_Image_Decomposition_with_Depth_Cues.html">30 iccv-2013-A Simple Model for Intrinsic Image Decomposition with Depth Cues</a></p>
<p>20 0.5816673 <a title="119-lda-20" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
