<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-187" href="#">iccv2013-187</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</h1>
<br/><p>Source: <a title="iccv-2013-187-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Chen_Group_Norm_for_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Daozheng Chen, Dhruv Batra, William T. Freeman</p><p>Abstract: Latent variables models have been applied to a number of computer vision problems. However, the complexity of the latent space is typically left as a free design choice. A larger latent space results in a more expressive model, but such models are prone to overfitting and are slower to perform inference with. The goal of this paper is to regularize the complexity of the latent space and learn which hidden states are really relevant for prediction. Specifically, we propose using group-sparsity-inducing regularizers such as ?1-?2 to estimate the parameters of Structured SVMs with unstructured latent variables. Our experiments on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model.</p><p>Reference: <a title="iccv-2013-187-reference" href="../iccv2013_reference/iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 However, the complexity of the latent space is typically left as a free design choice. [sent-7, score-0.48]
</p><p>2 A larger latent space results in a more expressive model, but such models are prone to overfitting and are slower to perform inference with. [sent-8, score-0.506]
</p><p>3 The goal of this paper is to regularize the complexity of the latent space and learn which hidden states are really relevant for prediction. [sent-9, score-0.725]
</p><p>4 2 to estimate the parameters of Structured SVMs with unstructured latent variables. [sent-12, score-0.497]
</p><p>5 Our experiments on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model. [sent-13, score-0.825]
</p><p>6 image features) and latent or hidden variables not observed in the training data (e. [sent-25, score-0.65]
</p><p>7 These hidden variables may provide a low-dimensional embedding of the input or help set up a mixture model where complex input-output dependencies are composed of simpler ones. [sent-28, score-0.314]
</p><p>8 For example, in the mixture of Deformable-Part Model (DPM) [14], latent variables are part locations & mixture component ids that allow modelling of multiple plausible articulations of the object. [sent-29, score-0.909]
</p><p>9 In handwritten digit recognition, deformations of digit im–  ∗Current affiliation: Yahoo! [sent-30, score-0.653]
</p><p>10 ages, such as rotation, can be modelled as latent variables to improve recognition accuracy [27, 18]. [sent-32, score-0.533]
</p><p>11 In document retrieval, the total ranking order of all documents related to a query can be modeled as a latent variable to help produce a higher number relevant documents in top k returned results. [sent-33, score-0.641]
</p><p>12 Unfortunately, training latent variable models is notoriously problematic since it typically involves a difficult non-convex optimization problem. [sent-35, score-0.606]
</p><p>13 [18] have presented curriculum learning schemes that train latent variable models in an easy-to-difficult manner, by initially pruning away difficult examples in the dataset. [sent-40, score-0.627]
</p><p>14 At a high-level, our goal is to study the modellingoptimization tradeoffin designing latent variable models for computer vision problems. [sent-42, score-0.572]
</p><p>15 From a modelling perspective, we would like to design models with ever more complex latent variables, e. [sent-43, score-0.506]
</p><p>16 In most existing models, the complexity of the latent variable space (e. [sent-47, score-0.582]
</p><p>17 number of mixture components in a DPM [14]) is typically left as a free design choice that is hand-tuned. [sent-49, score-0.218]
</p><p>18 Thus, the question we seek to answer is: Is there a principled way to learn the complexity of the latent space? [sent-50, score-0.516]
</p><p>19 In this paper, we address this question for a specific model Structured SVMs with unstructured latent variables, i. [sent-52, score-0.497]
</p><p>20 linear models with an exponentially large (structured) output space, but an enumerable latent variable space. [sent-54, score-0.654]
</p><p>21 An example of such a model would be DPM [14] –  where the latent space indexes the mixture component ids, and thus the goal is to learn the number of mixtures in a DPM from data. [sent-55, score-0.642]
</p><p>22 We propose the use of group-sparsity inducing norms 409  variable indicates the rotation angle that must be corrected for before extracting features. [sent-56, score-0.27]
</p><p>23 For object detection, the latent variable is the  component id in the mixture of deformable part models. [sent-57, score-0.809]
</p><p>24 The parameter vector is partitioned into groups corresponding to different latent states. [sent-58, score-0.505]
</p><p>25 Parameters for non-informative states become zero under such regularizers allowing us to select meaningful states for prediction. [sent-59, score-0.26]
</p><p>26 2 to estimate the parameters of such a model, thereby regularizing the complexity of the latent space. [sent-62, score-0.48]
</p><p>27 1 norm at a group level and encourages groups of variables to be sparse. [sent-66, score-0.412]
</p><p>28 Specifically, we divide the latent variable state space into different groups, among which the group norm is induced. [sent-67, score-0.862]
</p><p>29 Since the group norm encourages group-sparsity, this allows simultaneous parameter estimation as well as state selection. [sent-68, score-0.356]
</p><p>30 [18], in that they prune out difficult training examples to make the nonconvex optimization easier, while we prune out difficult (or irrelevant) latent states. [sent-72, score-0.571]
</p><p>31 We perform two sets of experiments: handwritten digit recognition on MNIST and object detection on the PASCAL VOC 2007 dataset [12]. [sent-73, score-0.367]
</p><p>32 Our first set of experiments show that our approach is indeed able to prune the complexity of latent space, resulting in a model that allows significantly faster inference at test time without drop in accuracy over a complete (non-sparse) model. [sent-74, score-0.53]
</p><p>33 Our second set of experiments show that our approach is able to learn a better model by adapting the complexity of the latent variable space to the category being trained. [sent-75, score-0.618]
</p><p>34 In the generative setting, the goal is to explain the data with a low-dimensional latent structure. [sent-82, score-0.437]
</p><p>35 More recently, a number of discriminative latent models such as Hidden  Conditional Random Field [23], Latent SVMs [14] and Latent Structured SVMs (LSSVMs) [27] have been proposed. [sent-84, score-0.47]
</p><p>36 Note that for all the models above, the latent variables and their state space are predefined and fixed. [sent-88, score-0.608]
</p><p>37 Our approach, on the other hand, aims for parameter estimation as well as discovery of meaningful latent variable states. [sent-89, score-0.608]
</p><p>38 [5], which attempts to identify the graphical model structure assuming that latent and observed variables are jointly Gaussian. [sent-91, score-0.533]
</p><p>39 Our work is different in that we are interested in prediction via a sparse latent model and not identification of such a model. [sent-92, score-0.558]
</p><p>40 [3] applied the group norm to build a word dictionary in bag-of-words document representations widely used in text, image, and video processing. [sent-106, score-0.315]
</p><p>41 [16] used the group norm to learn a latent space factorization into shared and private information. [sent-108, score-0.754]
</p><p>42 [15] used group norms for sparse representation based classification, for face recognition. [sent-110, score-0.242]
</p><p>43 [1] provides a comprehensive description of group norms and its applications. [sent-112, score-0.21]
</p><p>44 To the best of our knowledge, this is the first work to use structured norms in the context of latent variable selection in Latent (Structured) SVMs. [sent-113, score-0.767]
</p><p>45 A number of recent works have looked at the broad problem of reducing the number of parameters in DPMs, by part-sharing [21], representing part filters as a linear combination of basis filters [22] or sparse-coding part filters [25]. [sent-115, score-0.252]
</p><p>46 We believe this is the first work to look at learning the number mixture components in a DPM. [sent-116, score-0.218]
</p><p>47 Wheree d xi t∈e rXa niisn tghe d aitnapu ast fDeat =ure { (vxector, yi ∈i ∈Y [isn }th,e w(hpeosrseib xly ∈stru Xctu isre dth) output label and hi ∈ H∈ ∈is Y Yth ies lthateen (pt ovsasriibablyle s tfrourc ttuhree dit)h o udatptau-t point. [sent-129, score-0.615]
</p><p>48 For ex∈am Hple i,s i tnh ed liagtiet n rtec voagrinaitbiloen, f xi hise tihe original image, yi ∈ {0, 1, . [sent-130, score-0.198]
</p><p>49 , 9} is the true digit label and hi ∈ {−60◦ , −4∈5◦ { , . [sent-133, score-0.654]
</p><p>50 The linear prediction rule of LSSVMs is of the following form:  f(x) = (y,hm)∈aYx×H w · φ(x,y,h),  (1)  where φ(x, y, h) is the joint feature vector that encodes the relationship between the input, hidden and output variables, and w is the model parameter vector. [sent-141, score-0.205]
</p><p>51 In digit recognition, this joint feature vector is the vector representation of the image x rotated by an angle corresponding to h. [sent-142, score-0.368]
</p><p>52 Note that the loss function may additionally depend on the predicted latent variables, i. [sent-147, score-0.496]
</p><p>53 The parameter vector w is learned by minimizing the (regularized) loss of the prediction on the training dataset D. [sent-150, score-0.215]
</p><p>54 e that for each training instance i, the ground-truth yi and its best latent variable prediction (argmaxhi∈H w · φ(xi, yi , hi)) have a higher score than all other label∈s Hawnd· lφa(texnt variable assignment pairs ( y¯i, ¯hi) by a soft margin of Δ(yi, yˆi , ˆ yi). [sent-161, score-1.028]
</p><p>55 The next section describes our proposed group norm modification to the LSSVM and LSVM models, and Sec411  tion 5 describes how parameter learning can be performed in the presence of this modification. [sent-183, score-0.436]
</p><p>56 Inducing Group Norm for State Learning We focus on models with an enumerable latent space, i. [sent-185, score-0.552]
</p><p>57 H = {1, · · · , P} is the set of all possible latent configiu. [sent-187, score-0.437]
</p><p>58 {S1u,c·h· ·a , sPet} o isf tsthaete sse tc oanf a blel pthoses sibetl eo lfa atelln t po cosnsifbiglerotation angles in digit recognition, or the set of mixture components in a DPM object detection model. [sent-190, score-0.633]
</p><p>59 Recall that our goal is to regularize the complexity of the latent space and learn which hidden states are really relevant for the prediction problem. [sent-191, score-0.814]
</p><p>60 2  norm in the regularizer Ω(w) in problem (2) and (3) to learn meaningful latent states. [sent-194, score-0.701]
</p><p>61 We start by describing a modification to the linear prediction rule in problem (2) that makes it easier to encode the group structure of latent states. [sent-196, score-0.706]
</p><p>62 This gives us a natural way to select the latent states most useful for prediction. [sent-237, score-0.526]
</p><p>63 In a manner similar to Elastic Nets [30], we can also use the group norm in combination with the ? [sent-238, score-0.281]
</p><p>64 (6)  Such a regularizer has the effect of both the original regularizer and the group norm. [sent-243, score-0.248]
</p><p>65 The next section describes the algorithm for parameter learning in LSSVMs with group norm regularizers. [sent-247, score-0.356]
</p><p>66 Intuitively, replacing gi (w) by gi (w, hi) i·m φp(xlies that we enforce the margin not with respect to the best latent assignment for the ground-truth yi, rather only the current latent assignment of hi. [sent-265, score-1.096]
</p><p>67 (9)  This step is fairly straightforward and involves assigning the latent variables to their optimal states given the current setting of w(t) . [sent-274, score-0.676]
</p><p>68 Experiment We performed two sets ofexperiments: handwritten digit recognition on MNIST and object detection on the PASCAL VOC 2007 dataset [12]. [sent-328, score-0.367]
</p><p>69 The second set of experiments show that that we are able to learn a better model by adapting the complexity of the latent space to the category being trained. [sent-330, score-0.516]
</p><p>70 Each digit is represented as a vector x of pixel grayscale values. [sent-335, score-0.286]
</p><p>71 The goal is to predict the digit label y ∈ Y = {0, 1, · · · , 9}. [sent-336, score-0.286]
</p><p>72 Specifically, they consider rotation as a hidden variable taking values in a set of 11 angles uniformly distributed from −60◦ to 60◦, i. [sent-341, score-0.314]
</p><p>73 ,(xn,yn)}, convergence criteria 1: t ← 0 2: rte ←pea 0t 3: for i= 1to n do 4: {#Find best latent assignment hi. [sent-355, score-0.437]
</p><p>74 We work with the MNIST dataset [19], and perform binary classification on four difficult digit pairs (1-vs-7, 2-vs7, 3-vs-8, 8-vs-9). [sent-379, score-0.286]
</p><p>75 The training data for each digit contains about 6000 images and the testing data contains approximately 1000 images. [sent-380, score-0.32]
</p><p>76 We tried different values of C, and the prediction accuracies were fairly similar. [sent-382, score-0.213]
</p><p>77 2-norms for many angles are completely zero, and only a subset of angles actually remain to contribute to the final prediction. [sent-387, score-0.258]
</p><p>78 Our sparse model essentially selects 5, 8, 7, and 9 angles in total for digit pairs 1-7, 2-7, 3-8, and 8-9 respectively. [sent-388, score-0.447]
</p><p>79 This is a significant reduction from the hidden space of 22 angles per digit pair in the original model. [sent-389, score-0.498]
</p><p>80 Table 1 shows prediction accuracy vs the number of angles used. [sent-390, score-0.218]
</p><p>81 In fact, using only 8 angles for each digit pair, we can achieve prediction accuracies similar to those using the entire set of angles. [sent-396, score-0.574]
</p><p>82 2 norm of the parameter vectors for different angles over the 4 digit pairs. [sent-399, score-0.587]
</p><p>83 Each component in the mixture is a star-structured part model consisting of a root filter, part filters, and part displacements vectors. [sent-417, score-0.358]
</p><p>84 The score of a component at a particular location and scale in the image is defined as the sum of scores for root and part filters minus the deformation cost of placing part filters in the image. [sent-418, score-0.307]
</p><p>85 Each component is bilaterally symmetric and thus an n-component mixture really has 2n-members. [sent-419, score-0.206]
</p><p>86 The goal of our experiments is to select and learn a sparse mixture model with only a subset of components. [sent-422, score-0.203]
</p><p>87 Stage 2 concatenates the parameters of all components and learns a mixture model of root filters. [sent-439, score-0.299]
</p><p>88 Stage 3 adds the part and displacement parameters for each component and learns the final mixture model. [sent-440, score-0.205]
</p><p>89 We applied the group norm to stage 2 of the learning process so that we can select a subset of components to do learning in stage 3. [sent-442, score-0.46]
</p><p>90 detector [14] vs the number of components for the ‘cat’ category, trained on VOC 2007 t rainval and tested on te st. [sent-446, score-0.199]
</p><p>91 Only root+part accuracies are shown (no bounding box prediction or context rescoring is performed). [sent-447, score-0.318]
</p><p>92 We can see that te st accuracies increase at first then decrease while t rainval accuracies increase monotonically, which is a classical sign of overfitting. [sent-448, score-0.256]
</p><p>93 The results are based on root+part model only (no bounding box prediction or context rescoring is performed). [sent-462, score-0.248]
</p><p>94 Some components that are very similar to others are removed by the group norm. [sent-474, score-0.225]
</p><p>95 The mixture of root model before and after the training by ? [sent-486, score-0.25]
</p><p>96 We also ran the bounding box prediction and context rescoring steps the sake of completeness, and observe similar trends. [sent-497, score-0.248]
</p><p>97 Summary We address the problem of estimating the parameters of latent variable models as well as discovering meaningful states for the latent variables. [sent-499, score-1.134]
</p><p>98 We address this problem in the context of SVMs with structured output variables and unstructured (enumerable) latent variables via an ? [sent-501, score-0.806]
</p><p>99 Our experiments on handwritten digit recognition show that our approach is able to effectively reduce the size of latent variable state space and thus reduce the inference time with no loss of accuracy compared to using the full latent state space. [sent-504, score-1.486]
</p><p>100 Recent work on visual subcategories [9] has argued that a larger number of mixture components can lead to improved 415  rnoc= u564or12m3ts+p(λ. [sent-507, score-0.254]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('latent', 0.437), ('hi', 0.368), ('digit', 0.286), ('lssvm', 0.146), ('group', 0.142), ('norm', 0.139), ('lssvms', 0.137), ('mixture', 0.135), ('yi', 0.132), ('angles', 0.129), ('gi', 0.111), ('svms', 0.11), ('dpm', 0.105), ('variable', 0.102), ('variables', 0.096), ('states', 0.089), ('prediction', 0.089), ('bengio', 0.087), ('voc', 0.086), ('hidden', 0.083), ('components', 0.083), ('enumerable', 0.082), ('rainval', 0.082), ('structured', 0.082), ('handwritten', 0.081), ('root', 0.081), ('wp', 0.076), ('wh', 0.071), ('accuracies', 0.07), ('norms', 0.068), ('xi', 0.066), ('deformable', 0.065), ('nci', 0.063), ('kumar', 0.063), ('inducing', 0.06), ('unstructured', 0.06), ('filters', 0.06), ('loss', 0.059), ('rescoring', 0.056), ('royal', 0.055), ('argmaxhi', 0.055), ('cni', 0.055), ('curriculum', 0.055), ('maxhi', 0.055), ('fairly', 0.054), ('cccp', 0.054), ('regularizer', 0.053), ('mnist', 0.053), ('prune', 0.05), ('ttuhree', 0.049), ('stage', 0.048), ('sparsity', 0.047), ('regularizers', 0.046), ('descent', 0.045), ('monotonically', 0.044), ('wm', 0.043), ('complexity', 0.043), ('felzenszwalb', 0.043), ('selection', 0.043), ('describes', 0.042), ('state', 0.042), ('whi', 0.042), ('chandrasekaran', 0.042), ('rotated', 0.042), ('gr', 0.041), ('angle', 0.04), ('umd', 0.039), ('society', 0.038), ('modification', 0.038), ('mi', 0.038), ('really', 0.037), ('prone', 0.036), ('modelling', 0.036), ('subcategories', 0.036), ('val', 0.036), ('part', 0.036), ('learn', 0.036), ('meaningful', 0.036), ('context', 0.035), ('cat', 0.035), ('behaves', 0.035), ('jia', 0.035), ('groups', 0.035), ('box', 0.035), ('component', 0.034), ('training', 0.034), ('documents', 0.034), ('document', 0.034), ('te', 0.034), ('pascal', 0.034), ('convex', 0.033), ('models', 0.033), ('subgradient', 0.033), ('abstraction', 0.033), ('xh', 0.033), ('parameter', 0.033), ('bounding', 0.033), ('stuck', 0.032), ('sparse', 0.032), ('bach', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="187-tfidf-1" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>Author: Daozheng Chen, Dhruv Batra, William T. Freeman</p><p>Abstract: Latent variables models have been applied to a number of computer vision problems. However, the complexity of the latent space is typically left as a free design choice. A larger latent space results in a more expressive model, but such models are prone to overfitting and are slower to perform inference with. The goal of this paper is to regularize the complexity of the latent space and learn which hidden states are really relevant for prediction. Specifically, we propose using group-sparsity-inducing regularizers such as ?1-?2 to estimate the parameters of Structured SVMs with unstructured latent variables. Our experiments on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model.</p><p>2 0.25902802 <a title="187-tfidf-2" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<p>Author: Qiang Zhou, Gang Wang, Kui Jia, Qi Zhao</p><p>Abstract: Sharing knowledge for multiple related machine learning tasks is an effective strategy to improve the generalization performance. In this paper, we investigate knowledge sharing across categories for action recognition in videos. The motivation is that many action categories are related, where common motion pattern are shared among them (e.g. diving and high jump share the jump motion). We propose a new multi-task learning method to learn latent tasks shared across categories, and reconstruct a classifier for each category from these latent tasks. Compared to previous methods, our approach has two advantages: (1) The learned latent tasks correspond to basic motionpatterns instead offull actions, thus enhancing discrimination power of the classifiers. (2) Categories are selected to share information with a sparsity regularizer, avoidingfalselyforcing all categories to share knowledge. Experimental results on multiplepublic data sets show that the proposed approach can effectively transfer knowledge between different action categories to improve the performance of conventional single task learning methods.</p><p>3 0.21733689 <a title="187-tfidf-3" href="./iccv-2013-Compositional_Models_for_Video_Event_Detection%3A_A_Multiple_Kernel_Learning_Latent_Variable_Approach.html">85 iccv-2013-Compositional Models for Video Event Detection: A Multiple Kernel Learning Latent Variable Approach</a></p>
<p>Author: Arash Vahdat, Kevin Cannons, Greg Mori, Sangmin Oh, Ilseo Kim</p><p>Abstract: We present a compositional model for video event detection. A video is modeled using a collection of both global and segment-level features and kernel functions are employed for similarity comparisons. The locations of salient, discriminative video segments are treated as a latent variable, allowing the model to explicitly ignore portions of the video that are unimportant for classification. A novel, multiple kernel learning (MKL) latent support vector machine (SVM) is defined, that is used to combine and re-weight multiple feature types in a principled fashion while simultaneously operating within the latent variable framework. The compositional nature of the proposed model allows it to respond directly to the challenges of temporal clutter and intra-class variation, which are prevalent in unconstrained internet videos. Experimental results on the TRECVID Multimedia Event Detection 2011 (MED11) dataset demonstrate the efficacy of the method.</p><p>4 0.20399064 <a title="187-tfidf-4" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>Author: Yangqing Jia, Trevor Darrell</p><p>Abstract: Recent years have witnessed the success of large-scale image classification systems that are able to identify objects among thousands of possible labels. However, it is yet unclear how general classifiers such as ones trained on ImageNet can be optimally adapted to specific tasks, each of which only covers a semantically related subset of all the objects in the world. It is inefficient and suboptimal to retrain classifiers whenever a new task is given, and is inapplicable when tasks are not given explicitly, but implicitly specified as a set of image queries. In this paper we propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a lineartime probabilistic inference algorithm, given a set of query images from a latent task. We present efficient ways to estimate parameters for the model, and an open-source toolbox to train classifiers distributedly at a large scale. Empirical results based on the ImageNet data showed significant performance increase over several baseline algorithms.</p><p>5 0.19022368 <a title="187-tfidf-5" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>Author: Ross Girshick, Jitendra Malik</p><p>Abstract: In this paper, we show how to train a deformable part model (DPM) fast—typically in less than 20 minutes, or four times faster than the current fastest method—while maintaining high average precision on the PASCAL VOC datasets. At the core of our approach is “latent LDA,” a novel generalization of linear discriminant analysis for learning latent variable models. Unlike latent SVM, latent LDA uses efficient closed-form updates and does not require an expensive search for hard negative examples. Our approach also acts as a springboard for a detailed experimental study of DPM training. We isolate and quantify the impact of key training factors for the first time (e.g., How important are discriminative SVM filters? How important is joint parameter estimation? How many negative images are needed for training?). Our findings yield useful insights for researchers working with Markov random fields and partbased models, and have practical implications for speeding up tasks such as model selection.</p><p>6 0.1549442 <a title="187-tfidf-6" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>7 0.14895828 <a title="187-tfidf-7" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>8 0.14782199 <a title="187-tfidf-8" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>9 0.13839039 <a title="187-tfidf-9" href="./iccv-2013-Understanding_High-Level_Semantics_by_Modeling_Traffic_Patterns.html">433 iccv-2013-Understanding High-Level Semantics by Modeling Traffic Patterns</a></p>
<p>10 0.13629533 <a title="187-tfidf-10" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>11 0.13230595 <a title="187-tfidf-11" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>12 0.1256714 <a title="187-tfidf-12" href="./iccv-2013-From_Subcategories_to_Visual_Composites%3A_A_Multi-level_Framework_for_Object_Detection.html">179 iccv-2013-From Subcategories to Visual Composites: A Multi-level Framework for Object Detection</a></p>
<p>13 0.12422174 <a title="187-tfidf-13" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>14 0.12098096 <a title="187-tfidf-14" href="./iccv-2013-Latent_Space_Sparse_Subspace_Clustering.html">232 iccv-2013-Latent Space Sparse Subspace Clustering</a></p>
<p>15 0.11522391 <a title="187-tfidf-15" href="./iccv-2013-Modeling_Occlusion_by_Discriminative_AND-OR_Structures.html">269 iccv-2013-Modeling Occlusion by Discriminative AND-OR Structures</a></p>
<p>16 0.11138581 <a title="187-tfidf-16" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<p>17 0.10762506 <a title="187-tfidf-17" href="./iccv-2013-Shufflets%3A_Shared_Mid-level_Parts_for_Fast_Object_Detection.html">390 iccv-2013-Shufflets: Shared Mid-level Parts for Fast Object Detection</a></p>
<p>18 0.10759526 <a title="187-tfidf-18" href="./iccv-2013-Event_Recognition_in_Photo_Collections_with_a_Stopwatch_HMM.html">147 iccv-2013-Event Recognition in Photo Collections with a Stopwatch HMM</a></p>
<p>19 0.10459285 <a title="187-tfidf-19" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>20 0.10376889 <a title="187-tfidf-20" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.246), (1, 0.102), (2, -0.029), (3, -0.031), (4, 0.019), (5, -0.009), (6, -0.032), (7, 0.056), (8, -0.029), (9, -0.134), (10, -0.0), (11, -0.072), (12, -0.109), (13, -0.088), (14, -0.029), (15, 0.001), (16, 0.011), (17, 0.098), (18, 0.07), (19, 0.012), (20, -0.051), (21, 0.055), (22, -0.058), (23, -0.101), (24, 0.05), (25, -0.05), (26, 0.108), (27, -0.112), (28, 0.149), (29, 0.052), (30, 0.084), (31, 0.053), (32, -0.104), (33, 0.032), (34, 0.015), (35, -0.065), (36, 0.011), (37, 0.149), (38, 0.063), (39, -0.072), (40, 0.083), (41, -0.054), (42, 0.097), (43, -0.136), (44, -0.01), (45, 0.017), (46, 0.056), (47, 0.09), (48, -0.089), (49, 0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9814744 <a title="187-lsi-1" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>Author: Daozheng Chen, Dhruv Batra, William T. Freeman</p><p>Abstract: Latent variables models have been applied to a number of computer vision problems. However, the complexity of the latent space is typically left as a free design choice. A larger latent space results in a more expressive model, but such models are prone to overfitting and are slower to perform inference with. The goal of this paper is to regularize the complexity of the latent space and learn which hidden states are really relevant for prediction. Specifically, we propose using group-sparsity-inducing regularizers such as ?1-?2 to estimate the parameters of Structured SVMs with unstructured latent variables. Our experiments on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model.</p><p>2 0.80811727 <a title="187-lsi-2" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>Author: Ross Girshick, Jitendra Malik</p><p>Abstract: In this paper, we show how to train a deformable part model (DPM) fast—typically in less than 20 minutes, or four times faster than the current fastest method—while maintaining high average precision on the PASCAL VOC datasets. At the core of our approach is “latent LDA,” a novel generalization of linear discriminant analysis for learning latent variable models. Unlike latent SVM, latent LDA uses efficient closed-form updates and does not require an expensive search for hard negative examples. Our approach also acts as a springboard for a detailed experimental study of DPM training. We isolate and quantify the impact of key training factors for the first time (e.g., How important are discriminative SVM filters? How important is joint parameter estimation? How many negative images are needed for training?). Our findings yield useful insights for researchers working with Markov random fields and partbased models, and have practical implications for speeding up tasks such as model selection.</p><p>3 0.74147147 <a title="187-lsi-3" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<p>Author: Qiang Zhou, Gang Wang, Kui Jia, Qi Zhao</p><p>Abstract: Sharing knowledge for multiple related machine learning tasks is an effective strategy to improve the generalization performance. In this paper, we investigate knowledge sharing across categories for action recognition in videos. The motivation is that many action categories are related, where common motion pattern are shared among them (e.g. diving and high jump share the jump motion). We propose a new multi-task learning method to learn latent tasks shared across categories, and reconstruct a classifier for each category from these latent tasks. Compared to previous methods, our approach has two advantages: (1) The learned latent tasks correspond to basic motionpatterns instead offull actions, thus enhancing discrimination power of the classifiers. (2) Categories are selected to share information with a sparsity regularizer, avoidingfalselyforcing all categories to share knowledge. Experimental results on multiplepublic data sets show that the proposed approach can effectively transfer knowledge between different action categories to improve the performance of conventional single task learning methods.</p><p>4 0.6974116 <a title="187-lsi-4" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>Author: Yangqing Jia, Trevor Darrell</p><p>Abstract: Recent years have witnessed the success of large-scale image classification systems that are able to identify objects among thousands of possible labels. However, it is yet unclear how general classifiers such as ones trained on ImageNet can be optimally adapted to specific tasks, each of which only covers a semantically related subset of all the objects in the world. It is inefficient and suboptimal to retrain classifiers whenever a new task is given, and is inapplicable when tasks are not given explicitly, but implicitly specified as a set of image queries. In this paper we propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a lineartime probabilistic inference algorithm, given a set of query images from a latent task. We present efficient ways to estimate parameters for the model, and an open-source toolbox to train classifiers distributedly at a large scale. Empirical results based on the ImageNet data showed significant performance increase over several baseline algorithms.</p><p>5 0.66940761 <a title="187-lsi-5" href="./iccv-2013-Learning_Slow_Features_for_Behaviour_Analysis.html">243 iccv-2013-Learning Slow Features for Behaviour Analysis</a></p>
<p>Author: Lazaros Zafeiriou, Mihalis A. Nicolaou, Stefanos Zafeiriou, Symeon Nikitidis, Maja Pantic</p><p>Abstract: A recently introduced latent feature learning technique for time varying dynamic phenomena analysis is the socalled Slow Feature Analysis (SFA). SFA is a deterministic component analysis technique for multi-dimensional sequences that by minimizing the variance of the first order time derivative approximation of the input signal finds uncorrelated projections that extract slowly-varying features ordered by their temporal consistency and constancy. In this paper, we propose a number of extensions in both the deterministic and the probabilistic SFA optimization frameworks. In particular, we derive a novel deterministic SFA algorithm that is able to identify linear projections that extract the common slowest varying features of two or more sequences. In addition, we propose an Expectation Maximization (EM) algorithm to perform inference in a probabilistic formulation of SFA and similarly extend it in order to handle two and more time varying data sequences. Moreover, we demonstrate that the probabilistic SFA (EMSFA) algorithm that discovers the common slowest varying latent space of multiple sequences can be combined with dynamic time warping techniques for robust sequence timealignment. The proposed SFA algorithms were applied for facial behavior analysis demonstrating their usefulness and appropriateness for this task.</p><p>6 0.65530586 <a title="187-lsi-6" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>7 0.64190322 <a title="187-lsi-7" href="./iccv-2013-Compositional_Models_for_Video_Event_Detection%3A_A_Multiple_Kernel_Learning_Latent_Variable_Approach.html">85 iccv-2013-Compositional Models for Video Event Detection: A Multiple Kernel Learning Latent Variable Approach</a></p>
<p>8 0.63453275 <a title="187-lsi-8" href="./iccv-2013-Shufflets%3A_Shared_Mid-level_Parts_for_Fast_Object_Detection.html">390 iccv-2013-Shufflets: Shared Mid-level Parts for Fast Object Detection</a></p>
<p>9 0.61988127 <a title="187-lsi-9" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>10 0.58711255 <a title="187-lsi-10" href="./iccv-2013-From_Subcategories_to_Visual_Composites%3A_A_Multi-level_Framework_for_Object_Detection.html">179 iccv-2013-From Subcategories to Visual Composites: A Multi-level Framework for Object Detection</a></p>
<p>11 0.5660063 <a title="187-lsi-11" href="./iccv-2013-Handling_Uncertain_Tags_in_Visual_Recognition.html">191 iccv-2013-Handling Uncertain Tags in Visual Recognition</a></p>
<p>12 0.56043357 <a title="187-lsi-12" href="./iccv-2013-Learning_to_Rank_Using_Privileged_Information.html">248 iccv-2013-Learning to Rank Using Privileged Information</a></p>
<p>13 0.55024904 <a title="187-lsi-13" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>14 0.54769868 <a title="187-lsi-14" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>15 0.54639137 <a title="187-lsi-15" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>16 0.54566312 <a title="187-lsi-16" href="./iccv-2013-Modeling_Occlusion_by_Discriminative_AND-OR_Structures.html">269 iccv-2013-Modeling Occlusion by Discriminative AND-OR Structures</a></p>
<p>17 0.53933287 <a title="187-lsi-17" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>18 0.53663015 <a title="187-lsi-18" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>19 0.53562492 <a title="187-lsi-19" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>20 0.51095885 <a title="187-lsi-20" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.052), (7, 0.022), (12, 0.017), (26, 0.087), (27, 0.011), (31, 0.085), (34, 0.019), (35, 0.014), (42, 0.136), (48, 0.018), (64, 0.056), (73, 0.029), (78, 0.012), (89, 0.178), (95, 0.02), (96, 0.16), (98, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93755597 <a title="187-lda-1" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>2 0.9025588 <a title="187-lda-2" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<p>Author: Shahriar Shariat, Vladimir Pavlovic</p><p>Abstract: The problem of human activity recognition is a central problem in many real-world applications. In this paper we propose a fast and effective segmental alignmentbased method that is able to classify activities and interactions in complex environments. We empirically show that such model is able to recover the alignment that leads to improved similarity measures within sequence classes and hence, raises the classification performance. We also apply a bounding technique on the histogram distances to reduce the computation of the otherwise exhaustive search.</p><p>3 0.88250297 <a title="187-lda-3" href="./iccv-2013-Correlation_Adaptive_Subspace_Segmentation_by_Trace_Lasso.html">93 iccv-2013-Correlation Adaptive Subspace Segmentation by Trace Lasso</a></p>
<p>Author: Canyi Lu, Jiashi Feng, Zhouchen Lin, Shuicheng Yan</p><p>Abstract: This paper studies the subspace segmentation problem. Given a set of data points drawn from a union of subspaces, the goal is to partition them into their underlying subspaces they were drawn from. The spectral clustering method is used as the framework. It requires to find an affinity matrix which is close to block diagonal, with nonzero entries corresponding to the data point pairs from the same subspace. In this work, we argue that both sparsity and the grouping effect are important for subspace segmentation. A sparse affinity matrix tends to be block diagonal, with less connections between data points from different subspaces. The grouping effect ensures that the highly corrected data which are usually from the same subspace can be grouped together. Sparse Subspace Clustering (SSC), by using ?1-minimization, encourages sparsity for data selection, but it lacks of the grouping effect. On the contrary, Low-RankRepresentation (LRR), by rank minimization, and Least Squares Regression (LSR), by ?2-regularization, exhibit strong grouping effect, but they are short in subset selection. Thus the obtained affinity matrix is usually very sparse by SSC, yet very dense by LRR and LSR. In this work, we propose the Correlation Adaptive Subspace Segmentation (CASS) method by using trace Lasso. CASS is a data correlation dependent method which simultaneously performs automatic data selection and groups correlated data together. It can be regarded as a method which adaptively balances SSC and LSR. Both theoretical and experimental results show the effectiveness of CASS.</p><p>same-paper 4 0.88068271 <a title="187-lda-4" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>Author: Daozheng Chen, Dhruv Batra, William T. Freeman</p><p>Abstract: Latent variables models have been applied to a number of computer vision problems. However, the complexity of the latent space is typically left as a free design choice. A larger latent space results in a more expressive model, but such models are prone to overfitting and are slower to perform inference with. The goal of this paper is to regularize the complexity of the latent space and learn which hidden states are really relevant for prediction. Specifically, we propose using group-sparsity-inducing regularizers such as ?1-?2 to estimate the parameters of Structured SVMs with unstructured latent variables. Our experiments on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model.</p><p>5 0.87134057 <a title="187-lda-5" href="./iccv-2013-Live_Metric_3D_Reconstruction_on_Mobile_Phones.html">254 iccv-2013-Live Metric 3D Reconstruction on Mobile Phones</a></p>
<p>Author: Petri Tanskanen, Kalin Kolev, Lorenz Meier, Federico Camposeco, Olivier Saurer, Marc Pollefeys</p><p>Abstract: unkown-abstract</p><p>6 0.83773881 <a title="187-lda-6" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>7 0.83660221 <a title="187-lda-7" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<p>8 0.83541334 <a title="187-lda-8" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>9 0.83154535 <a title="187-lda-9" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>10 0.83152664 <a title="187-lda-10" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>11 0.83134973 <a title="187-lda-11" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>12 0.8306123 <a title="187-lda-12" href="./iccv-2013-Bayesian_Joint_Topic_Modelling_for_Weakly_Supervised_Object_Localisation.html">59 iccv-2013-Bayesian Joint Topic Modelling for Weakly Supervised Object Localisation</a></p>
<p>13 0.82853764 <a title="187-lda-13" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<p>14 0.82828623 <a title="187-lda-14" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>15 0.82795358 <a title="187-lda-15" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>16 0.82738274 <a title="187-lda-16" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>17 0.82715654 <a title="187-lda-17" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>18 0.82514936 <a title="187-lda-18" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>19 0.82497382 <a title="187-lda-19" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>20 0.82492572 <a title="187-lda-20" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
