<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>87 iccv-2013-Conservation Tracking</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-87" href="#">iccv2013-87</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>87 iccv-2013-Conservation Tracking</h1>
<br/><p>Source: <a title="iccv-2013-87-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Schiegg_Conservation_Tracking_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Martin Schiegg, Philipp Hanslovsky, Bernhard X. Kausler, Lars Hufnagel, Fred A. Hamprecht</p><p>Abstract: The quality of any tracking-by-assignment hinges on the accuracy of the foregoing target detection / segmentation step. In many kinds of images, errors in this first stage are unavoidable. These errors then propagate to, and corrupt, the tracking result. Our main contribution is the first probabilistic graphical model that can explicitly account for over- and undersegmentation errors even when the number of tracking targets is unknown and when they may divide, as in cell cultures. The tracking model we present implements global consistency constraints for the number of targets comprised by each detection and is solved to global optimality on reasonably large 2D+t and 3D+t datasets. In addition, we empirically demonstrate the effectiveness of a postprocessing that allows to establish target identity even across occlusion / undersegmentation. The usefulness and efficiency of this new tracking method is demonstrated on three different and challenging 2D+t and 3D+t datasets from developmental biology.</p><p>Reference: <a title="iccv-2013-87-reference" href="../iccv2013_reference/iccv-2013-Conservation_Tracking_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 These errors then propagate to, and corrupt, the tracking result. [sent-8, score-0.218]
</p><p>2 Our main contribution is the first probabilistic graphical model that can explicitly account for over- and undersegmentation errors even when the number of tracking targets is unknown and when they may divide, as in cell cultures. [sent-9, score-0.851]
</p><p>3 The tracking model we present implements global consistency constraints for the number of targets comprised by each detection and is solved to global optimality on reasonably large 2D+t and 3D+t datasets. [sent-10, score-0.449]
</p><p>4 The usefulness and efficiency of this new tracking method is demonstrated on three different and  challenging 2D+t and 3D+t datasets from developmental biology. [sent-12, score-0.211]
</p><p>5 Introduction The tracking of multiple dividing targets is a challenging computer vision problem and has useful application e. [sent-14, score-0.351]
</p><p>6 Due to the occurrence of object divisions at any time, the number of targets for each time step is unknown even if user-specified for a subset of frames. [sent-17, score-0.325]
</p><p>7 Multi-object tracking in general may be implemented as a two-step pipeline consisting of a detection/segmentation step and a data association or assignment/tracking step [18]. [sent-18, score-0.224]
</p><p>8 Such approaches, however, are obviously susceptible to errors in the detection step which are propagated to the tracking model and typically cannot be corrected downstream. [sent-19, score-0.341]
</p><p>9 Therefore, the ultimate goal of data association tracking is European Molecular Biology Laboratory (EMBL) 69117 Heidelberg, Germany hufnage l embl . [sent-20, score-0.3]
</p><p>10 Right: Excerpt of the proposed factor graph showing the three detection variables for the connected component at time t: Red variables are indicators for a division event. [sent-23, score-0.58]
</p><p>11 The other variables, taken together,  represent the number of targets covered by a detection but they can also represent the other depicted scenarios such as disappearance or “demerging”. [sent-24, score-0.269]
</p><p>12 to address detection and data association jointly such that both steps can maximally benefit from each other and information can be propagated from more to less obvious parts of 2928  Figure 2: Tiny excerpt of dataset B with its almost indistinguishable objects. [sent-27, score-0.233]
</p><p>13 Due to low contrast, multiple cells are segmented as only one connected component (undersegmentation) as pointed out in the middle row. [sent-29, score-0.178]
</p><p>14 Our tracking model (bottom row) can handle such errors and preserves the target identities as indicated by colors (see the three previously merged cells in t = 52) by fitting the correct number of Gaussians (ellipses) to detections containing multiple objects. [sent-30, score-0.669]
</p><p>15 Furthermore, the proposed factor graph can handle false detections (oversegmentation) as indicated by the black  detection in frame 42 (bottom row). [sent-31, score-0.473]
</p><p>16 There are first approaches addressing joint detection and tracking [16, 17], but none of them has been extended to deal with dividing objects. [sent-33, score-0.366]
</p><p>17 Given that the tracking of multiple dividing objects already is an NP-hard problem [14] in itself, joint detection and assignment is harder still. [sent-34, score-0.453]
</p><p>18 As a first step into this direction, we propose a model that handles detection errors explicitly in the tracking step and can even correct most of them. [sent-35, score-0.346]
</p><p>19 1 and can be categorized into over- and undersegmentation errors occurring due to low contrast or noise in the images. [sent-37, score-0.258]
</p><p>20 Oversegmentation may result in false detections whereas undersegmentation could lead to the appearance and vanishing of tracks or to accidental track merging. [sent-40, score-0.483]
</p><p>21 In this context, the divisibility of the objects is particularly challenging since demerging due to previous merging must be distinguished from object division. [sent-41, score-0.214]
</p><p>22 Note that we will differentiate between object division and object demerging throughout the paper. [sent-42, score-0.288]
</p><p>23 We present the first method which explicitly models all of the potential segmentation errors outlined above in one probabilistic graphical model. [sent-43, score-0.246]
</p><p>24 The proposed factor graph models conservation laws for the number of objects contained in each detection to ensure global consistency of the solution. [sent-44, score-0.783]
</p><p>25 In this way, temporarily merged targets can be resolved under identity preservation even for objects which are merged during longer sequences. [sent-48, score-0.538]
</p><p>26 We commence with the review of prior art and propose the tracking framework and particularly the construction of the factor graph in Sec. [sent-53, score-0.321]
</p><p>27 Related Work Existing tracking approaches can broadly be categorized into three: (i) space-time segmentation, (ii) state space models, and (iii) tracking-by-assignment. [sent-59, score-0.166]
</p><p>28 Tracking-by-assignment gracefully handles multiple, and even dividing objects; on the downside, object properties such as object velocity need to be implemented using factors that are higher order in time. [sent-63, score-0.156]
</p><p>29 The tracking of undersegmented objects was first described in [11] and soon extended to deal with fragmentation (false positive detections) [2]. [sent-65, score-0.391]
</p><p>30 Furthermore, the authors in [8] account for both dividing objects and undersegmentation, and exploit local evidence in pairs of frames to find undersegmented objects. [sent-68, score-0.335]
</p><p>31 The structure of our graphical model also builds on the network flow formulation in [19]. [sent-70, score-0.171]
</p><p>32 Note, however, that allowing for object division no longer permits to do inference via an ordinary network flow computation as in [19]. [sent-71, score-0.235]
</p><p>33 Instead, admitting divisions necessarily turns the problem into an integer flow problem with homologous arcs (i. [sent-72, score-0.288]
</p><p>34 Moreover, the only model which handles the tracking of dividing objects in a global probabilistic framework is the  graphical model presented in [5]. [sent-76, score-0.59]
</p><p>35 While oversegmentation is addressed in terms of false detections, it cannot deal with undersegmentation such as merged objects. [sent-77, score-0.434]
</p><p>36 Tracking Divisible Objects in spite of Overand Undersegmentation The purpose of this work is to track dividing objects based on an error-prone segmentation. [sent-79, score-0.201]
</p><p>37 We therefore model data association in a probabilistic graphical model [6] where we explicitly handle over- and undersegmentation errors (cf. [sent-80, score-0.465]
</p><p>38 ontraugsoitng  Figure 3: Factor graph for one detection Xit with two incoming and two outgoing transition candidates: One detection Xit is represented by two multi-state variables, Vit and Ait, to allow for vanishing and appearance, respectively. [sent-84, score-0.421]
</p><p>39 yH oebrjee, ctthse a brelac akss squares implement conservation laws, i. [sent-95, score-0.254]
</p><p>40 In this way, each segmented region is assigned the number of objects it contains while conservation laws across subsequent detections guarantee global consistency. [sent-99, score-0.697]
</p><p>41 Finally, each detection is partitioned into its inferred number of objects by fitting a Gaussian mixture model such that post-hoc linking yields identity preservation for temporarily merged targets. [sent-100, score-0.402]
</p><p>42 It should be noted that we distinguish between the terms object and detection which denote one target and one connected component, respectively, where a detection may comprise multiple objects. [sent-101, score-0.234]
</p><p>43 In the following, we describe our tracking workflow in detail for which a schematic overview is depicted in Fig. [sent-102, score-0.252]
</p><p>44 , m} and a vanishing vari-  In particular, each detection pearance able  Vit  Ait ∈ {0, . [sent-111, score-0.166]
</p><p>45 they estimate the division probability and a probability mass function of the number of objects contained in each detection. [sent-125, score-0.309]
</p><p>46 These potentials are then used in the proposed factor graph (cf. [sent-126, score-0.195]
</p><p>47 3) to find a globally consistent tracking solution (here, tracks are indicated by colors). [sent-128, score-0.201]
</p><p>48 The  appearance  and vanishing vari-  ables of one detection are connected by ψdet  (Ati, Vit , fit) =  =⎪⎩⎧⎪ ⎪ ⎪⎨ ⎪− ∞−ln ,? [sent-132, score-0.228]
</p><p>49 1): Vit = Ait = k indicates that Xit comprises k objects (and Xit is a false detection if k = 0); Vit = 0, Ait > 0 means that the object(s) in Xit is/are appearing in this time step (i. [sent-143, score-0.226]
</p><p>50 Here, the design parameters wapp and wvan penalize spontaneous appearance and vanishing. [sent-146, score-0.236]
</p><p>51 In our experiments, we deal with cell tracking and therefore utilize domain specific features for cell division. [sent-153, score-0.58]
</p><p>52 Division nodes are only added if the respective detection has at least two potential successors in the next time frame and the score from the division detection classifier is above some small threshold. [sent-159, score-0.365]
</p><p>53 The third category of random variables in the proposed graphical model, the transition variables Titj ∈ {0, . [sent-160, score-0.289]
</p><p>54 Local evidence for pairs of detections Xit, Xjt+1 is injected by  Pˆ(Titj= k | dtij) =⎧⎨e1x −p e? [sent-165, score-0.176]
</p><p>55 For instance, the conservation law for the outgoing transitions of Xit is ψout(Ati, Titj0 , . [sent-184, score-0.286]
</p><p>56 (3)  Furtherm⎪⎩ore, since sparse objects may lead to isolated (sub-)paths in the graphical model, i. [sent-194, score-0.184]
</p><p>57 paths where only one transition between two detections is possible, we sub-  sume variables in such paths in tracklets and set their unary potential to the sum of the single detections’ unaries plus their transition potentials for each possible configuration. [sent-196, score-0.528]
</p><p>58 Resolving Merged Objects The inferred result of the described factor graph yields  the number of objects covered by one detection Xit and the number of objects Titj transferred between two detections Xit, Xjt+1 in adjacent time steps. [sent-210, score-0.625]
</p><p>59 Identities of individual objects are amalgamated into a cluster whenever undersegmentation leads to seeming mergers. [sent-211, score-0.293]
</p><p>60 Given the number ofobjects k contained in detection Xit, we fit a Gaussian mixture model with k normal distributions N(μl , Σl) of unknown weight πl to the connected componNen(tμ with pixels/voxels {x1, . [sent-213, score-0.179]
</p><p>61 We modify this merger resolving factor graph by setting all Ait = Vit = 1, i. [sent-240, score-0.206]
</p><p>62 This graphical model is again solved to global optimality and its solution hence preserves identities of objects, even for long sequences of merged objects. [sent-243, score-0.359]
</p><p>63 Ctrioonss Correlation for Region Center Correc-  Most tracking-by-assignment approaches penalize displacements of objects in terms of squared distance between objects of adjacent time frames. [sent-246, score-0.237]
</p><p>64 The transition prior φtr can then be computed based on the detection centers corrected by those offsets to find the displacement relative to the motion of the object’s neighborhood. [sent-255, score-0.229]
</p><p>65 Table 1: Cell tracking results on dataset A: precision (= TPT +P FP), recall (= TPT +P FN), andf-measure (= 2·pprerecc. [sent-272, score-0.166]
</p><p>66 ) for the overall pairwise eve)n,t asn (dmf-omvee,a appearance, disappearance, divisions) and divisions in particular. [sent-276, score-0.254]
</p><p>67 Experiments and Results Cell tracking is a natural application for the tracking of dividing objects, particularly challenging due to their almost texture-less appearances, which makes them nearly indistinguishable from each other. [sent-284, score-0.481]
</p><p>68 Especially in dense cell populations, undersegmentation is a common cause for errors. [sent-286, score-0.413]
</p><p>69 Furthermore, the density of cell populations due to their diverging stages in the developmental process of the embryo are highly diverging. [sent-289, score-0.353]
</p><p>70 In all experiments, we use random forests [3] each comprising 100 trees grown to purity as classifiers for cell number φdet and cell mitosis, φdiv. [sent-290, score-0.449]
</p><p>71 ≤ For 3 a fair comparison, we used the same cell number classifier in our method and the competitive model. [sent-292, score-0.207]
</p><p>72 2 W,3e6 t2a×ke9 9t4he× published segmentation of this dataset and its gold standard to compare with the recently published cell tracking model by Kausler et al. [sent-297, score-0.467]
</p><p>73 Their segmentation contains no merged objects and thus, we set in our model the maximal number of objects per detection to one, i. [sent-299, score-0.431]
</p><p>74 In this experiment, we use the cell detection classifier of [5] and set our parameters to α = 25, wapp = 50, wvan = 50, wtr = 13, wdiv = 28, where the latter two parameters weight the transition and division priors versus the detection prior. [sent-302, score-0.972]
</p><p>75 The f-measure for divisions in [5] is slightly better than ours, namely 0. [sent-310, score-0.254]
</p><p>76 90, which is due to their model making assumptions about minimal durations between division events (cf. [sent-312, score-0.191]
</p><p>77 Due to the embryonic development, the cell population is now much denser than in dataset B, resulting in a high number of undersegmented objects (cf. [sent-316, score-0.396]
</p><p>78 The design parameters in our factor graph for the case of allowing maximally 4 cells in one detection (i. [sent-323, score-0.315]
</p><p>79 m = 4) are set to α = 5, wapp = 100, wvan = 100, wtr = 24, wdiv = 36. [sent-325, score-0.356]
</p><p>80 2) show that our method outperforms the cell tracking model in [5]. [sent-330, score-0.373]
</p><p>81 06 ofthe competitive model, the explicit modeling and distinction of demerging and dividing together with the probabilistic division prior φdiv brings a boost in the detection of mitotic events. [sent-333, score-0.54]
</p><p>82 Besides, due to the consideration of all detections of all frames in one holistic model and due to the conservation laws posed, our factor graph can accurately (precision of 0. [sent-334, score-0.691]
</p><p>83 68, our framework can resolve the original –  –  –  –  2933  Table 2: Cell tracking results on datasets B and C: Our model with a different number of objects in one detection allowed (m = 1to m = 4) can best handle the under-/oversegmentation errors occurring in these datasets. [sent-338, score-0.391]
</p><p>84 Here, merged objects are only counted as true positives if the true number (≥ 2) of objects in the connected component is found. [sent-339, score-0.362]
</p><p>85 Finally, resolved mergers inntdeidc aastes t,r uheo wpo many so if th thee merged objects ≥ha 2v)e o bfe eonb erecstosl ivned th teo cthoneinre original midpeonntietnites i saf ftoeur demerging. [sent-340, score-0.4]
</p><p>86 (re*)s oNlvoetde  that in Classifiers only, it is only evaluated whether the particular cell is dividing whereas in the tracking models, we go beyond that and additionally require the correct links to the daughter cells. [sent-341, score-0.538]
</p><p>87 The ground truth of dataset B (dataset C) contains 56,029 (34,985) moves, 216 (440) divisions, 1,878 (1,189) mergers, and 1,466 (533) resolved mergers events. [sent-342, score-0.187]
</p><p>88 In particular, the associations between the distinct objects after demerging are evaluated as true positives only if they link to the true respective objects before merging  –  possibly over long sequences  of  being merged. [sent-348, score-0.333]
</p><p>89 In our model, we again treat  each connected component as one detection and set the parameters (for m  =  4) to α  =  5, wapp  =  100, wvan  =  100, wtr = 10, wdiv = 16. [sent-350, score-0.504]
</p><p>90 76 for divisions and mergers) improves significantly over the results of the rather weak local division and merger classifiers (0. [sent-353, score-0.466]
</p><p>91 The results of mergers and divisions seem to depend more on the parameter setting, however, the standard deviation is only 0. [sent-361, score-0.381]
</p><p>92 The results of our model can be further improved by designing even more features for object classification and division detection. [sent-364, score-0.161]
</p><p>93 This additional local evidence can then be put into global context within the factor graph. [sent-365, score-0.158]
</p><p>94 It should be noted that the object classification and division detection modules can be fully adopted to the particular application domain. [sent-366, score-0.247]
</p><p>95 Conclusion We have proposed a probabilistic graphical model which due to the explicit modeling of global conservation laws can robustly correct errors from a previous detection step. [sent-368, score-0.711]
</p><p>96 We have shown that the proposed factor graph can outperform a recently published cell tracking method on sequences of proliferating cells in a dense populations thanks –  –  to the consideration of over- and undersegmentation errors. [sent-369, score-0.867]
</p><p>97 In addition, our model can partition and track previously merged objects while preserving their original identities. [sent-370, score-0.213]
</p><p>98 Multi-class object tracking algorithm that handles fragmentation and grouping. [sent-389, score-0.244]
</p><p>99 Coupled minimum-cost flow cell tracking for high-throughput quantitative analysis. [sent-460, score-0.407]
</p><p>100 Global data association for multi-object tracking using network flows. [sent-507, score-0.264]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xit', 0.423), ('conservation', 0.254), ('divisions', 0.254), ('cell', 0.207), ('undersegmentation', 0.206), ('vit', 0.169), ('tracking', 0.166), ('division', 0.161), ('xjt', 0.153), ('detections', 0.144), ('laws', 0.138), ('ait', 0.134), ('demerging', 0.127), ('mergers', 0.127), ('merged', 0.126), ('dividing', 0.114), ('titj', 0.102), ('undersegmented', 0.102), ('wapp', 0.102), ('wvan', 0.102), ('graphical', 0.097), ('factor', 0.094), ('objects', 0.087), ('detection', 0.086), ('vanishing', 0.08), ('embl', 0.076), ('wdiv', 0.076), ('wtr', 0.076), ('transition', 0.076), ('drosophila', 0.075), ('cells', 0.074), ('identities', 0.072), ('targets', 0.071), ('disappearance', 0.068), ('connected', 0.062), ('graph', 0.061), ('heidelberg', 0.06), ('resolved', 0.06), ('populations', 0.059), ('association', 0.058), ('variables', 0.058), ('excerpt', 0.054), ('false', 0.053), ('probabilistic', 0.052), ('errors', 0.052), ('daughter', 0.051), ('divisible', 0.051), ('ilastik', 0.051), ('kausler', 0.051), ('merger', 0.051), ('mitocheck', 0.051), ('mitosis', 0.051), ('wittbrodt', 0.051), ('xlt', 0.051), ('dit', 0.05), ('gold', 0.049), ('oversegmentation', 0.049), ('segmentation', 0.045), ('developmental', 0.045), ('tpt', 0.045), ('depicted', 0.044), ('handles', 0.042), ('segmented', 0.042), ('lou', 0.042), ('embryo', 0.042), ('workflow', 0.042), ('network', 0.04), ('potentials', 0.04), ('itj', 0.039), ('koethe', 0.039), ('shitrit', 0.039), ('det', 0.038), ('corrected', 0.037), ('temporarily', 0.036), ('fragmentation', 0.036), ('inferred', 0.035), ('comprising', 0.035), ('indicated', 0.035), ('fruit', 0.035), ('indistinguishable', 0.035), ('unary', 0.034), ('flow', 0.034), ('tracklets', 0.034), ('paths', 0.033), ('furthermore', 0.033), ('cross', 0.032), ('global', 0.032), ('respective', 0.032), ('evidence', 0.032), ('preservation', 0.032), ('outgoing', 0.032), ('penalize', 0.032), ('offset', 0.032), ('optimality', 0.032), ('contained', 0.031), ('adjacent', 0.031), ('comprised', 0.03), ('mass', 0.03), ('centers', 0.03), ('events', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="87-tfidf-1" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>Author: Martin Schiegg, Philipp Hanslovsky, Bernhard X. Kausler, Lars Hufnagel, Fred A. Hamprecht</p><p>Abstract: The quality of any tracking-by-assignment hinges on the accuracy of the foregoing target detection / segmentation step. In many kinds of images, errors in this first stage are unavoidable. These errors then propagate to, and corrupt, the tracking result. Our main contribution is the first probabilistic graphical model that can explicitly account for over- and undersegmentation errors even when the number of tracking targets is unknown and when they may divide, as in cell cultures. The tracking model we present implements global consistency constraints for the number of targets comprised by each detection and is solved to global optimality on reasonably large 2D+t and 3D+t datasets. In addition, we empirically demonstrate the effectiveness of a postprocessing that allows to establish target identity even across occlusion / undersegmentation. The usefulness and efficiency of this new tracking method is demonstrated on three different and challenging 2D+t and 3D+t datasets from developmental biology.</p><p>2 0.1685371 <a title="87-tfidf-2" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>Author: Dapeng Chen, Zejian Yuan, Yang Wu, Geng Zhang, Nanning Zheng</p><p>Abstract: Representation is a fundamental problem in object tracking. Conventional methods track the target by describing its local or global appearance. In this paper we present that, besides the two paradigms, the composition of local region histograms can also provide diverse and important object cues. We use cells to extract local appearance, and construct complex cells to integrate the information from cells. With different spatial arrangements of cells, complex cells can explore various contextual information at multiple scales, which is important to improve the tracking performance. We also develop a novel template-matching algorithm for object tracking, where the template is composed of temporal varying cells and has two layers to capture the target and background appearance respectively. An adaptive weight is associated with each complex cell to cope with occlusion as well as appearance variation. A fusion weight is associated with each complex cell type to preserve the global distinctiveness. Our algorithm is evaluated on 25 challenging sequences, and the results not only confirm the contribution of each component in our tracking system, but also outperform other competing trackers.</p><p>3 0.1536568 <a title="87-tfidf-3" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>Author: Ernesto Brau, Jinyan Guan, Kyle Simek, Luca Del Pero, Colin Reimer Dawson, Kobus Barnard</p><p>Abstract: Jinyan Guan† j guan1 @ emai l ari z ona . edu . Kyle Simek† ks imek@ emai l ari z ona . edu . Colin Reimer Dawson‡ cdaws on@ emai l ari z ona . edu . ‡School of Information University of Arizona Kobus Barnard‡ kobus @ s i sta . ari z ona . edu ∗School of Informatics University of Edinburgh for tracking an unknown and changing number of people in a scene using video taken from a single, fixed viewpoint. We develop a Bayesian modeling approach for tracking people in 3D from monocular video with unknown cameras. Modeling in 3D provides natural explanations for occlusions and smoothness discontinuities that result from projection, and allows priors on velocity and smoothness to be grounded in physical quantities: meters and seconds vs. pixels and frames. We pose the problem in the context of data association, in which observations are assigned to tracks. A correct application of Bayesian inference to multitarget tracking must address the fact that the model’s dimension changes as tracks are added or removed, and thus, posterior densities of different hypotheses are not comparable. We address this by marginalizing out the trajectory parameters so the resulting posterior over data associations has constant dimension. This is made tractable by using (a) Gaussian process priors for smooth trajectories and (b) approximately Gaussian likelihood functions. Our approach provides a principled method for incorporating multiple sources of evidence; we present results using both optical flow and object detector outputs. Results are comparable to recent work on 3D tracking and, unlike others, our method requires no pre-calibrated cameras.</p><p>4 0.14762104 <a title="87-tfidf-4" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>Author: Aleksandr V. Segal, Ian Reid</p><p>Abstract: We propose a novel parametrization of the data association problem for multi-target tracking. In our formulation, the number of targets is implicitly inferred together with the data association, effectively solving data association and model selection as a single inference problem. The novel formulation allows us to interpret data association and tracking as a single Switching Linear Dynamical System (SLDS). We compute an approximate posterior solution to this problem using a dynamic programming/message passing technique. This inference-based approach allows us to incorporate richer probabilistic models into the tracking system. In particular, we incorporate inference over inliers/outliers and track termination times into the system. We evaluate our approach on publicly available datasets and demonstrate results competitive with, and in some cases exceeding the state of the art.</p><p>5 0.11720198 <a title="87-tfidf-5" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>Author: K.C. Amit Kumar, Christophe De_Vleeschouwer</p><p>Abstract: Given a set of plausible detections, detected at each time instant independently, we investigate how to associate them across time. This is done by propagating labels on a set of graphs that capture how the spatio-temporal and the appearance cues promote the assignment of identical or distinct labels to a pair of nodes. The graph construction is driven by the locally linear embedding (LLE) of either the spatio-temporal or the appearance features associated to the detections. Interestingly, the neighborhood of a node in each appearance graph is defined to include all nodes for which the appearance feature is available (except the ones that coexist at the same time). This allows to connect the nodes that share the same appearance even if they are temporally distant, which gives our framework the uncommon ability to exploit the appearance features that are available only sporadically along the sequence of detections. Once the graphs have been defined, the multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured by each of the graphs. This results into a difference of convex program that can be efficiently solved. Experiments are performed on a basketball and several well-known pedestrian datasets in order to validate the effectiveness of the proposed solution.</p><p>6 0.11571268 <a title="87-tfidf-6" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>7 0.10165446 <a title="87-tfidf-7" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>8 0.098452441 <a title="87-tfidf-8" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>9 0.097023062 <a title="87-tfidf-9" href="./iccv-2013-Tracking_Revisited_Using_RGBD_Camera%3A_Unified_Benchmark_and_Baselines.html">424 iccv-2013-Tracking Revisited Using RGBD Camera: Unified Benchmark and Baselines</a></p>
<p>10 0.088545047 <a title="87-tfidf-10" href="./iccv-2013-Learning_People_Detectors_for_Tracking_in_Crowded_Scenes.html">242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</a></p>
<p>11 0.086191773 <a title="87-tfidf-11" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<p>12 0.082914792 <a title="87-tfidf-12" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>13 0.0810868 <a title="87-tfidf-13" href="./iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</a></p>
<p>14 0.079919904 <a title="87-tfidf-14" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>15 0.078238547 <a title="87-tfidf-15" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>16 0.077027246 <a title="87-tfidf-16" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>17 0.073915251 <a title="87-tfidf-17" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>18 0.073670827 <a title="87-tfidf-18" href="./iccv-2013-Decomposing_Bag_of_Words_Histograms.html">104 iccv-2013-Decomposing Bag of Words Histograms</a></p>
<p>19 0.068562709 <a title="87-tfidf-19" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>20 0.067674644 <a title="87-tfidf-20" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.186), (1, -0.038), (2, 0.024), (3, 0.024), (4, 0.052), (5, -0.018), (6, -0.063), (7, 0.11), (8, -0.031), (9, 0.037), (10, -0.04), (11, -0.07), (12, 0.037), (13, 0.075), (14, 0.048), (15, 0.016), (16, 0.027), (17, 0.033), (18, -0.035), (19, -0.014), (20, -0.049), (21, -0.029), (22, 0.017), (23, -0.037), (24, -0.002), (25, -0.0), (26, -0.006), (27, -0.096), (28, -0.026), (29, 0.016), (30, 0.025), (31, 0.041), (32, 0.03), (33, 0.008), (34, -0.009), (35, 0.045), (36, 0.018), (37, -0.11), (38, 0.004), (39, 0.056), (40, 0.014), (41, 0.022), (42, -0.001), (43, -0.017), (44, -0.116), (45, -0.082), (46, 0.025), (47, -0.03), (48, -0.049), (49, -0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9140144 <a title="87-lsi-1" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>Author: Martin Schiegg, Philipp Hanslovsky, Bernhard X. Kausler, Lars Hufnagel, Fred A. Hamprecht</p><p>Abstract: The quality of any tracking-by-assignment hinges on the accuracy of the foregoing target detection / segmentation step. In many kinds of images, errors in this first stage are unavoidable. These errors then propagate to, and corrupt, the tracking result. Our main contribution is the first probabilistic graphical model that can explicitly account for over- and undersegmentation errors even when the number of tracking targets is unknown and when they may divide, as in cell cultures. The tracking model we present implements global consistency constraints for the number of targets comprised by each detection and is solved to global optimality on reasonably large 2D+t and 3D+t datasets. In addition, we empirically demonstrate the effectiveness of a postprocessing that allows to establish target identity even across occlusion / undersegmentation. The usefulness and efficiency of this new tracking method is demonstrated on three different and challenging 2D+t and 3D+t datasets from developmental biology.</p><p>2 0.83714622 <a title="87-lsi-2" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>Author: Aleksandr V. Segal, Ian Reid</p><p>Abstract: We propose a novel parametrization of the data association problem for multi-target tracking. In our formulation, the number of targets is implicitly inferred together with the data association, effectively solving data association and model selection as a single inference problem. The novel formulation allows us to interpret data association and tracking as a single Switching Linear Dynamical System (SLDS). We compute an approximate posterior solution to this problem using a dynamic programming/message passing technique. This inference-based approach allows us to incorporate richer probabilistic models into the tracking system. In particular, we incorporate inference over inliers/outliers and track termination times into the system. We evaluate our approach on publicly available datasets and demonstrate results competitive with, and in some cases exceeding the state of the art.</p><p>3 0.8045367 <a title="87-lsi-3" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>Author: Ernesto Brau, Jinyan Guan, Kyle Simek, Luca Del Pero, Colin Reimer Dawson, Kobus Barnard</p><p>Abstract: Jinyan Guan† j guan1 @ emai l ari z ona . edu . Kyle Simek† ks imek@ emai l ari z ona . edu . Colin Reimer Dawson‡ cdaws on@ emai l ari z ona . edu . ‡School of Information University of Arizona Kobus Barnard‡ kobus @ s i sta . ari z ona . edu ∗School of Informatics University of Edinburgh for tracking an unknown and changing number of people in a scene using video taken from a single, fixed viewpoint. We develop a Bayesian modeling approach for tracking people in 3D from monocular video with unknown cameras. Modeling in 3D provides natural explanations for occlusions and smoothness discontinuities that result from projection, and allows priors on velocity and smoothness to be grounded in physical quantities: meters and seconds vs. pixels and frames. We pose the problem in the context of data association, in which observations are assigned to tracks. A correct application of Bayesian inference to multitarget tracking must address the fact that the model’s dimension changes as tracks are added or removed, and thus, posterior densities of different hypotheses are not comparable. We address this by marginalizing out the trajectory parameters so the resulting posterior over data associations has constant dimension. This is made tractable by using (a) Gaussian process priors for smooth trajectories and (b) approximately Gaussian likelihood functions. Our approach provides a principled method for incorporating multiple sources of evidence; we present results using both optical flow and object detector outputs. Results are comparable to recent work on 3D tracking and, unlike others, our method requires no pre-calibrated cameras.</p><p>4 0.70628828 <a title="87-lsi-4" href="./iccv-2013-Discriminative_Label_Propagation_for_Multi-object_Tracking_with_Sporadic_Appearance_Features.html">120 iccv-2013-Discriminative Label Propagation for Multi-object Tracking with Sporadic Appearance Features</a></p>
<p>Author: K.C. Amit Kumar, Christophe De_Vleeschouwer</p><p>Abstract: Given a set of plausible detections, detected at each time instant independently, we investigate how to associate them across time. This is done by propagating labels on a set of graphs that capture how the spatio-temporal and the appearance cues promote the assignment of identical or distinct labels to a pair of nodes. The graph construction is driven by the locally linear embedding (LLE) of either the spatio-temporal or the appearance features associated to the detections. Interestingly, the neighborhood of a node in each appearance graph is defined to include all nodes for which the appearance feature is available (except the ones that coexist at the same time). This allows to connect the nodes that share the same appearance even if they are temporally distant, which gives our framework the uncommon ability to exploit the appearance features that are available only sporadically along the sequence of detections. Once the graphs have been defined, the multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured by each of the graphs. This results into a difference of convex program that can be efficiently solved. Experiments are performed on a basketball and several well-known pedestrian datasets in order to validate the effectiveness of the proposed solution.</p><p>5 0.67340863 <a title="87-lsi-5" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>Author: Chetan Arora, Amir Globerson</p><p>Abstract: This paper addresses the data assignment problem in multi frame multi object tracking in video sequences. Traditional methods employing maximum weight bipartite matching offer limited temporal modeling. It has recently been shown [6, 8, 24] that incorporating higher order temporal constraints improves the assignment solution. Finding maximum weight matching with higher order constraints is however NP-hard and the solutions proposed until now have either been greedy [8] or rely on greedy rounding of the solution obtained from spectral techniques [15]. We propose a novel algorithm to find the approximate solution to data assignment problem with higher order temporal constraints using the method of dual decomposition and the MPLP message passing algorithm [21]. We compare the proposed algorithm with an implementation of [8] and [15] and show that proposed technique provides better solution with a bound on approximation factor for each inferred solution.</p><p>6 0.67207932 <a title="87-lsi-6" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>7 0.67027122 <a title="87-lsi-7" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>8 0.66771054 <a title="87-lsi-8" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>9 0.62116838 <a title="87-lsi-9" href="./iccv-2013-Understanding_High-Level_Semantics_by_Modeling_Traffic_Patterns.html">433 iccv-2013-Understanding High-Level Semantics by Modeling Traffic Patterns</a></p>
<p>10 0.60764968 <a title="87-lsi-10" href="./iccv-2013-Pyramid_Coding_for_Functional_Scene_Element_Recognition_in_Video_Scenes.html">331 iccv-2013-Pyramid Coding for Functional Scene Element Recognition in Video Scenes</a></p>
<p>11 0.60727084 <a title="87-lsi-11" href="./iccv-2013-Simultaneous_Clustering_and_Tracklet_Linking_for_Multi-face_Tracking_in_Videos.html">393 iccv-2013-Simultaneous Clustering and Tracklet Linking for Multi-face Tracking in Videos</a></p>
<p>12 0.60050952 <a title="87-lsi-12" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>13 0.59677827 <a title="87-lsi-13" href="./iccv-2013-Network_Principles_for_SfM%3A_Disambiguating_Repeated_Structures_with_Local_Context.html">289 iccv-2013-Network Principles for SfM: Disambiguating Repeated Structures with Local Context</a></p>
<p>14 0.58083928 <a title="87-lsi-14" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>15 0.57157916 <a title="87-lsi-15" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>16 0.56249797 <a title="87-lsi-16" href="./iccv-2013-Learning_People_Detectors_for_Tracking_in_Crowded_Scenes.html">242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</a></p>
<p>17 0.56132346 <a title="87-lsi-17" href="./iccv-2013-Finding_the_Best_from_the_Second_Bests_-_Inhibiting_Subjective_Bias_in_Evaluation_of_Visual_Tracking_Algorithms.html">168 iccv-2013-Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms</a></p>
<p>18 0.55862451 <a title="87-lsi-18" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>19 0.55250204 <a title="87-lsi-19" href="./iccv-2013-Dynamic_Probabilistic_Volumetric_Models.html">128 iccv-2013-Dynamic Probabilistic Volumetric Models</a></p>
<p>20 0.53530192 <a title="87-lsi-20" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.041), (7, 0.014), (18, 0.259), (26, 0.093), (31, 0.044), (34, 0.028), (40, 0.013), (42, 0.103), (64, 0.081), (73, 0.038), (78, 0.012), (89, 0.143), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.77260643 <a title="87-lda-1" href="./iccv-2013-Conservation_Tracking.html">87 iccv-2013-Conservation Tracking</a></p>
<p>Author: Martin Schiegg, Philipp Hanslovsky, Bernhard X. Kausler, Lars Hufnagel, Fred A. Hamprecht</p><p>Abstract: The quality of any tracking-by-assignment hinges on the accuracy of the foregoing target detection / segmentation step. In many kinds of images, errors in this first stage are unavoidable. These errors then propagate to, and corrupt, the tracking result. Our main contribution is the first probabilistic graphical model that can explicitly account for over- and undersegmentation errors even when the number of tracking targets is unknown and when they may divide, as in cell cultures. The tracking model we present implements global consistency constraints for the number of targets comprised by each detection and is solved to global optimality on reasonably large 2D+t and 3D+t datasets. In addition, we empirically demonstrate the effectiveness of a postprocessing that allows to establish target identity even across occlusion / undersegmentation. The usefulness and efficiency of this new tracking method is demonstrated on three different and challenging 2D+t and 3D+t datasets from developmental biology.</p><p>2 0.66839355 <a title="87-lda-2" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>3 0.63955438 <a title="87-lda-3" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>Author: Junliang Xing, Jin Gao, Bing Li, Weiming Hu, Shuicheng Yan</p><p>Abstract: Recently, sparse representation has been introduced for robust object tracking. By representing the object sparsely, i.e., using only a few templates via ?1-norm minimization, these so-called ?1-trackers exhibit promising tracking results. In this work, we address the object template building and updating problem in these ?1-tracking approaches, which has not been fully studied. We propose to perform template updating, in a new perspective, as an online incremental dictionary learning problem, which is efficiently solved through an online optimization procedure. To guarantee the robustness and adaptability of the tracking algorithm, we also propose to build a multi-lifespan dictionary model. By building target dictionaries of different lifespans, effective object observations can be obtained to deal with the well-known drifting problem in tracking and thus improve the tracking accuracy. We derive effective observa- tion models both generatively and discriminatively based on the online multi-lifespan dictionary learning model and deploy them to the Bayesian sequential estimation framework to perform tracking. The proposed approach has been extensively evaluated on ten challenging video sequences. Experimental results demonstrate the effectiveness of the online learned templates, as well as the state-of-the-art tracking performance of the proposed approach.</p><p>4 0.63588667 <a title="87-lda-4" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>Author: Fuxin Li, Taeyoung Kim, Ahmad Humayun, David Tsai, James M. Rehg</p><p>Abstract: We propose an unsupervised video segmentation approach by simultaneously tracking multiple holistic figureground segments. Segment tracks are initialized from a pool of segment proposals generated from a figure-ground segmentation algorithm. Then, online non-local appearance models are trained incrementally for each track using a multi-output regularized least squares formulation. By using the same set of training examples for all segment tracks, a computational trick allows us to track hundreds of segment tracks efficiently, as well as perform optimal online updates in closed-form. Besides, a new composite statistical inference approach is proposed for refining the obtained segment tracks, which breaks down the initial segment proposals and recombines for better ones by utilizing highorder statistic estimates from the appearance model and enforcing temporal consistency. For evaluating the algorithm, a dataset, SegTrack v2, is collected with about 1,000 frames with pixel-level annotations. The proposed framework outperforms state-of-the-art approaches in the dataset, show- ing its efficiency and robustness to challenges in different video sequences.</p><p>5 0.63469046 <a title="87-lda-5" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>Author: Aleksandr V. Segal, Ian Reid</p><p>Abstract: We propose a novel parametrization of the data association problem for multi-target tracking. In our formulation, the number of targets is implicitly inferred together with the data association, effectively solving data association and model selection as a single inference problem. The novel formulation allows us to interpret data association and tracking as a single Switching Linear Dynamical System (SLDS). We compute an approximate posterior solution to this problem using a dynamic programming/message passing technique. This inference-based approach allows us to incorporate richer probabilistic models into the tracking system. In particular, we incorporate inference over inliers/outliers and track termination times into the system. We evaluate our approach on publicly available datasets and demonstrate results competitive with, and in some cases exceeding the state of the art.</p><p>6 0.63318884 <a title="87-lda-6" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>7 0.63247418 <a title="87-lda-7" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>8 0.63161433 <a title="87-lda-8" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>9 0.63054717 <a title="87-lda-9" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>10 0.63049138 <a title="87-lda-10" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>11 0.63032943 <a title="87-lda-11" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>12 0.62974262 <a title="87-lda-12" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>13 0.62865913 <a title="87-lda-13" href="./iccv-2013-A_Flexible_Scene_Representation_for_3D_Reconstruction_Using_an_RGB-D_Camera.html">9 iccv-2013-A Flexible Scene Representation for 3D Reconstruction Using an RGB-D Camera</a></p>
<p>14 0.62853515 <a title="87-lda-14" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>15 0.62800854 <a title="87-lda-15" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>16 0.62747288 <a title="87-lda-16" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>17 0.62704754 <a title="87-lda-17" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>18 0.62608367 <a title="87-lda-18" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>19 0.6255523 <a title="87-lda-19" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>20 0.6254971 <a title="87-lda-20" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
