<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-171" href="#">iccv2013-171</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</h1>
<br/><p>Source: <a title="iccv-2013-171-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Fix_Structured_Learning_of_2013_ICCV_paper.pdf">pdf</a></p><p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>Reference: <a title="iccv-2013-171-reference" href="../iccv2013_reference/iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. [sent-2, score-0.958]
</p><p>2 SoS functions can naturally express higher order priors involving, e. [sent-3, score-0.163]
</p><p>3 Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. [sent-6, score-0.218]
</p><p>4 We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. [sent-7, score-0.181]
</p><p>5 We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. [sent-8, score-0.835]
</p><p>6 Introduction Discrete optimization methods such as graph cuts [5, 19] have proven to be quite effective for many computer vision problems, including stereo [5], interactive segmentation [28] and texture synthesis [21]. [sent-13, score-0.216]
</p><p>7 The optimization problem behind graph cuts is a special case of submodular optimization that can be solved exactly using max flow [19]. [sent-14, score-0.832]
</p><p>8 1 Graph cuts, however, are limited by their reliance on firstorder priors involving pairs of pixels, whereas there is considerable interest in expressing priors that rely on local image patches such as the popular Field of Experts model [27]. [sent-15, score-0.13]
</p><p>9 In this paper we focus on an important generalization of the functions that graph cuts can minimize. [sent-16, score-0.235]
</p><p>10 These higherorder functions, which [18] called Sum-of-Submodular (SoS), can be efficiently solved with a variant of max flow [6]. [sent-17, score-0.207]
</p><p>11 Rather than addressing the question of which existing higher order priors  can be expressed as an SoS function, we take a discriminative learning approach and effectively search the space of SoS functions with the goal of finding a higher order prior that gives strong results on our training set. [sent-19, score-0.218]
</p><p>12 1 Our main contribution is to introduce the first learning method for training such SoS functions, and to demonstrate the effectiveness of this approach for interactive segmentation using learned higher order priors. [sent-20, score-0.134]
</p><p>13 Sum-of-Submodular functions and priors A submodular function f : 2V → R on a set V satisfies f(S∩T) +f(S∪T) ≤ f(S) +f(T→) fo Rr oalnl S a, sTet ⊆ V V sa . [sent-29, score-0.674]
</p><p>14 Refsoearr Cch ⊆ on higher-order priors calls→ →C ∈R iCs a clique u[1la4r. [sent-32, score-0.221]
</p><p>15 Of course, a sum of submodular functions is itself submodular, so we could use general submodular optimization to minimize an SoS function. [sent-36, score-1.12]
</p><p>16 However, general submodular optimization is O(n6) [26] (which is impractical for lowlevel vision problems), whereas we may be able to exploit the neighborhood structure C to do better. [sent-37, score-0.511]
</p><p>17 For example, if athlle t nhee cliques are pairs t(u|rCe| C= t o2) d tohe b energy ofurn ecxtiaomnp ilse refaellrr tehde ctol as regular aanirds t(|hCe problem can ebrge yre fduunccetdio tno i max flow [19]. [sent-38, score-0.351]
</p><p>18 As mentioned, this is the underlying technique used in the popular graph cuts approach [5, 21, 28]. [sent-39, score-0.137]
</p><p>19 The most common approach to solving higher-order priors with graph cuts, which involves transformation to pairwise cliques, in practice almost always produces non-submodular functions that cannot be solved exactly [8, 14]. [sent-41, score-0.239]
</p><p>20 In this paper, we will learn submodular discriminant functions. [sent-47, score-0.591]
</p><p>21 Prior work on learning submodular functions falls into three categories: submodular function regression [3], maximization of submodular discriminant functions, and minimization of submodular discriminant functions. [sent-48, score-2.355]
</p><p>22 Learning of submodular discriminant functions where a prediction is computed through maximization has widespread use in information retrieval, where submodularity models diversity in the ranking of a search engine [35, 24] or in an automatically generated abstract [29]. [sent-49, score-0.763]
</p><p>23 While exact (monotone) submodular maximization is intractible, approximate inference using a simple greedy algorithm has approximation guarantees and generally excellent performance in practice. [sent-50, score-0.541]
</p><p>24 The models considered in this paper use submodular discriminant functions where a prediction is computed through minimization. [sent-51, score-0.733]
</p><p>25 In contrast, SVM-struct training using cutting planes for regular MRFs [30] allows graph cut inference also during training, and [7, 20, 30] show that this approach has interesting approximation properties even for the multi-class case where graph cut inference is only approximate. [sent-56, score-0.228]
</p><p>26 [9] is similar to this paper, in that it uses cutting planes to learn submodular functions, though it only considers the pairwise case. [sent-57, score-0.57]
</p><p>27 SoS minimization In this section, we briefly summarize how an SoS function can be minimized by means of a submodular flow network (section 3. [sent-62, score-0.704]
</p><p>28 SoS minimization via submodular flow Submodular flow is similar to the max flow problem, in that there is a network of nodes and arcs on which we want to push flow from s to t. [sent-67, score-1.379]
</p><p>29 However, the notion of residual  capacity will be slightly modified from that of standard max flow. [sent-68, score-0.219]
</p><p>30 As in theW max felgoiwn w redituhc atio nne tfworo Graph =Cu (tVs, t∪ he {res are source asn idn sink arcs (s, i) and (i, t) for every i ∈ V . [sent-71, score-0.288]
</p><p>31 Additionally, for esainckh clique C,i), athnedre ( iis, an arc v(ie, rjy) Ci ∈for V e . [sent-72, score-0.265]
</p><p>32 y2, Every arc a ∈ A also has an assocfoiart eeadc hres i,idju ∈al capacity ca. [sent-74, score-0.189]
</p><p>33 The residual capacities of the interior arcs will be chosen so that the fC are always nonnegative. [sent-79, score-0.375]
</p><p>34 Given a flow φ, de{ffine( Sthe) |s iet ∈ ∈o fS r,ejs ∈i d/u Sal} arcs Aφ as all  arcs a with ca > 0. [sent-81, score-0.522]
</p><p>35 An augmenting path is an s − t path along arcs in Aφ. [sent-82, score-0.392]
</p><p>36 he A following tthinegor peamth o isf [ a1n n8 ]s te −ll st hpoatwh to optimize f by computing a flow in G. [sent-84, score-0.175]
</p><p>37 Let φ be a feasible flow such that there is no augmenting path from s to t. [sent-87, score-0.277]
</p><p>38 Let S∗ be the set of all i ∈ V reachable from s along arcs in Aφ. [sent-88, score-0.191]
</p><p>39 IBFS for Submodular Flow Incremental Breadth First Search (IBFS) [11], which is the state of the art in max flow methods for vision applications, improves the algorithm of [4] to guarantee polynomial time complexity. [sent-92, score-0.184]
</p><p>40 We now show how to modify IBFS to compute a maximum submodular flow in G. [sent-93, score-0.651]
</p><p>41 IBFS is an augmenting paths algorithm: at each step, it finds a path from s to t with positive residual capacity, and pushes flow along it. [sent-94, score-0.437]
</p><p>42 Additionally, each augmenting path found is a shortest s-t path in Aφ. [sent-95, score-0.201]
</p><p>43 Two invariants are maintained: •  •  For every iin S, the unique path from s to iin S is a sFhoorrt eevsetr sy-i i path ,i tnh Aφ. [sent-97, score-0.282]
</p><p>44 For every iin T, the unique path from ito t in T is a sFhoorrt eevsetr iy-t i path i,n th Aφ. [sent-98, score-0.23]
</p><p>45 To grow S, we scan through the vertices at distance Ds away from s, and examine each out-arc (i, j) with positive residual capacity. [sent-101, score-0.12]
</p><p>46 If j is in T, then we found an augmenting path from s to t via the arc (i, j), so we can push flow on it. [sent-103, score-0.431]
</p><p>47 The operation of pushing flow may saturate some arcs (and cause previously saturated arcs to become unsaturated). [sent-104, score-0.561]
</p><p>48 If the parent arc of iin the tree S or T becomes saturated, then ibecomes an orphan. [sent-105, score-0.175]
</p><p>49 The details of the adoption step are similar to the relabel operation of the Push-Relabel algorithm, in that we search all potential parent arcs in Aφ for the neighbor with the lowest distance label, and make that node our new parent. [sent-107, score-0.267]
</p><p>50 In order to apply IBFS to the submodular flow problem, all the basic datastructures still make sense: we have a graph where the arcs a have residual capacities ca, and a maximum flow has been found if and only if there is no longer any augmenting path from s to t. [sent-108, score-1.346]
</p><p>51 The main change for the submodular flow problem is that when we increase flow on an edge (i, j)C, instead of just affecting the residual capacity of that arc and the reverse arc, we may also change the residual capacities of other arcs  (i0, j0)C for i0, j0 ∈ C. [sent-109, score-1.481]
</p><p>52 If (a, b)C was previously saturated, but now has residual capacity as a result of increasing flow along (c, d), then (1) either a = d or there was an arc (a, d) ∈ Aφ (acn,dd ()2, )t heeinthe (1r) b e =ith c or =the dre o was an arc a(cn, ab)r c∈ ( Aφ. [sent-113, score-0.533]
</p><p>53 Increasing flow on an edge never creates a shortcut between s and i, or from ito t. [sent-116, score-0.167]
</p><p>54 A push operation may cause some edges to become saturated, but this is the same problem as in the normal max flow case, and any orpans so created will be fixed in the adoption step. [sent-120, score-0.278]
</p><p>55 Therefore, all invariants of the IBFS algorithm are maintained, even in the submodular flow case. [sent-121, score-0.691]
</p><p>56 One final property of the IBFS algorithm involves the use of the “current arc heuristic”, which is a mechanism for avoiding iterating through all possible potential parents when performing an adoption step. [sent-122, score-0.158]
</p><p>57 In the case of Submodular Flows, it is also the case that whenever we create new residual arcs we maintain all invariants related to this current arc heuristic, so the same speedup applies here. [sent-123, score-0.46]
</p><p>58 However, note finding residual capacity of an arc (i, j)C requires minimizing fC(S) for S separating i and j. [sent-128, score-0.284]
</p><p>59 Overall, we add O(2k) work at each basic step of IBFS, so if we have m cliques the total runtime is O(n2m2k). [sent-131, score-0.134]
</p><p>60 This runtime is better than the augmenting paths algorithm of [2] which takes time O(nm22k). [sent-132, score-0.135]
</p><p>61 We then decribe a general class of SoS discriminant functions which can be learned by SVM-struct (section 4. [sent-137, score-0.178]
</p><p>62 Stated another way, for each example xi, the correct prediction yi should have low discriminant value, while incorrect predictions y¯i with large loss should have high discriminant values. [sent-161, score-0.287]
</p><p>63 Let’s begin with the simplest case oflearning a discriminant function fC,w(S) = wTΨ(S), defined only on a single clique and which does not depend on the input x. [sent-180, score-0.236]
</p><p>64 Intuitively, our parameters w will correspond to the table of values of the clique function fC, and our feature vector Ψ will be chosen so that wS = fC (S). [sent-181, score-0.156]
</p><p>65 Recall that f is submodular if and only if f(A ∪ B) + f(A ∩ B) ≤ fth(aAt) f + is f su(bBm)o. [sent-186, score-0.511]
</p><p>66 dThulearre ifofr aen,d fC,w i isf s fu(bAmo∪dBu)la+r iff a(And∩ only ≤if the parameters satisfy wA∪B  + wA∩B  ≤ wA  + wB : ∀A, B ⊆ C  (5)  These are just linear constraints in w, so we can add them as additional constraints to Quadratic Program 1. [sent-187, score-0.124]
</p><p>67 There are  O(2|C|) of them, but each clique has 2|C| parameters, so this does not increase the asymptotic size of the QP. [sent-188, score-0.194]
</p><p>68 By choosing feature vector ΨT(S) = δT(S) and adding the linear constraints (5) to Quadratic Program 1, the learned discriminant function fw (S) is the maximum margin function fC, where fC is allowed to vary over all possible submodular functions f : 2C → R. [sent-191, score-0.802]
</p><p>69 By adding constraints (5) to the QP, we ensure that the optimal solution w is defines a submodular fw. [sent-193, score-0.564]
</p><p>70 Conversely, for any submodular function fC, there is a feasible w defined by wT = fC (T), so the optimal solution to the QP must be the maximum-margin such function. [sent-194, score-0.511]
</p><p>71 With feature vector Ψdata and adding linear constraints (5) to QP 1, the learned discriminant function is the maximum margin function fC (S)Φ(x), where fC is allowed to vary over all possible submodular functions. [sent-219, score-0.644]
</p><p>72 Because Φ(x) is nonnegative, constraints (5) ensure that the discriminant function is again submodular. [sent-221, score-0.11]
</p><p>73 With feature vector Ψsos, and adding a copy of the constraints (5) for each clique C, the learned fw is the maximum margin f of the form f(x,S) =  XfC(S)ΦC(x) XC∈C  (6)  where the fC can vary over all possible submodular functions on the cliques C. [sent-227, score-0.96]
</p><p>74 Solving the quadratic program The n-slack formulation for SSVMs (QP 1) makes intuitive sense, from the point of view of minimizing the misprediction error on the training set. [sent-230, score-0.138]
</p><p>75 (7) Ψ ensure that fw is SoS, then as long as ∆  Since the features factors as a sum over the cliques C (for instance, the Hamming lso asss ais s suumch o a rfu thncet ciolniq)u, ethse Cn ((f7o)r can a bnec seo, ltvheed H wamithSubmodular IBFS. [sent-251, score-0.142]
</p><p>76 Note that this also allows us to add arbitrary additional features for learning the unary potentials as well. [sent-252, score-0.163]
</p><p>77 Generalization to multi-label prediction Submodular functions are intrinsically binary functions. [sent-256, score-0.168]
</p><p>78 If every binary subproblem of computing the optimal expansion move is an SoS problem, we will call the original multi-label energy function an SoS expansion energy. [sent-258, score-0.185]
</p><p>79 For a clique C and PlabCe∈l ‘, define C‘ = {i | yi = ‘}→, i. [sent-261, score-0.239]
</p><p>80 If all the clique functions are of the form fC(yC)  = Xg‘(C‘)  (8)  X‘∈L  where each  g‘  is submodular, then any expansion move for  the multi-label energy function f will be SoS. [sent-268, score-0.363]
</p><p>81 We can write B(S) in terms of the clique functions and sets C‘ as  B(S) =XC∈C? [sent-274, score-0.281]
</p><p>82 (9)  We use a fact from the theory of submodular functions: if f(S) is submodular, then for any fixed T both f(T ∪ S) and ff((ST) )\ i Ss )s are aoldsou saur,b tmheondu folrar a. [sent-276, score-0.511]
</p><p>83 These functions generalize commonly used multi-label clique functions, including the Pn Potts model [m1u6l]t. [sent-280, score-0.254]
</p><p>84 We can write this as an SoS expansion energy by lettiPng g‘(S) = λi − λmax if S = C and otherwise 0. [sent-283, score-0.136]
</p><p>85 [9] gives a class of submodular multilabel functions with exact inference (but which is smaller than the class just proposed). [sent-289, score-0.639]
</p><p>86 Experimental Results In order to evaluate our algorithms, we focused on binary denoising and interactive segmentation. [sent-292, score-0.128]
</p><p>87 For both the denoising and segmentation applications, we significantly improve on the accuracy of the hand-tuned energy functions. [sent-296, score-0.136]
</p><p>88 Binary denoising  ×  ×× ×  Our binary denoising dataset consists of a set of 20 black and white images. [sent-299, score-0.126]
</p><p>89 There is a single parameter λ, which is the tradeoff between the unary energy and the smoothness term. [sent-304, score-0.119]
</p><p>90 Our learned prior includes the same unary terms and clique structure, but instead of the square-root smoothness prior, wPe learn a cliquPe function g to get an MRF ESVM(y) = Pi |yi − xi | + PC∈C g(yC). [sent-306, score-0.239]
</p><p>91 Note that each clique has theP same energy aPs every other, so this is analogous to a gPraph cuts prior wPhere each pairwise edge has the same attractive potential. [sent-307, score-0.342]
</p><p>92 Automatically learning parameters allows us to add a large number of learned unary features to the CRF. [sent-335, score-0.114]
</p><p>93 Our general S3SVM method can incorporate higherorder priors instead of just pairwise ones. [sent-338, score-0.121]
</p><p>94 c hT ion o thbetain the benefits of the contrast-sensitive pairwise potentials for the higher-order case, we cluster the x and y gradient responses of each patch into 50 clusters, and learn one submodular potential for each cluster. [sent-342, score-0.593]
</p><p>95 Note that S3SVM automatically allows learning the entire energy function, including the clique potentials and unary potentials (which come from the data) simultaneously. [sent-343, score-0.398]
</p><p>96 Our implementation, which used the submodular flow algorithm based on IBFS discussed in section 3. [sent-349, score-0.651]
</p><p>97 A push/relabel framework for submodular flows and its refinement for 0-1 submodular  [11]  [12]  [13]  [14] [15]  [16]  [17] [18]  [19] [20]  [21]  flows. [sent-430, score-1.05]
</p><p>98 What energy functions can be minimized via graph cuts? [sent-494, score-0.225]
</p><p>99 Learning mixtures of submodular shells with application to document summarization. [sent-529, score-0.511]
</p><p>100 A faster strongly polynomial time algorithm for submodular function minimization. [sent-542, score-0.511]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sos', 0.54), ('submodular', 0.511), ('ibfs', 0.216), ('arcs', 0.191), ('fc', 0.166), ('clique', 0.156), ('flow', 0.14), ('arc', 0.109), ('qp', 0.102), ('functions', 0.098), ('residual', 0.095), ('cuts', 0.094), ('capacities', 0.089), ('yi', 0.083), ('cliques', 0.082), ('capacity', 0.08), ('discriminant', 0.08), ('augmenting', 0.073), ('priors', 0.065), ('path', 0.064), ('corollary', 0.064), ('wt', 0.062), ('fw', 0.06), ('unary', 0.06), ('energy', 0.059), ('potts', 0.056), ('interactive', 0.052), ('associative', 0.052), ('expansion', 0.05), ('denoising', 0.05), ('adoption', 0.049), ('taskar', 0.049), ('potentials', 0.049), ('mrfs', 0.048), ('chatalbashev', 0.048), ('structural', 0.046), ('push', 0.045), ('grabcut', 0.045), ('max', 0.044), ('prediction', 0.044), ('graph', 0.043), ('markov', 0.041), ('quadratic', 0.04), ('invariants', 0.04), ('pn', 0.039), ('iin', 0.039), ('saturated', 0.039), ('paths', 0.039), ('asymptotic', 0.038), ('eevsetr', 0.036), ('misprediction', 0.036), ('sfhoorrt', 0.036), ('xfc', 0.036), ('crfs', 0.035), ('isf', 0.035), ('joachims', 0.035), ('yn', 0.034), ('pairwise', 0.033), ('program', 0.032), ('svmstruct', 0.032), ('opencv', 0.031), ('reverse', 0.031), ('constraints', 0.03), ('inference', 0.03), ('training', 0.03), ('submodularity', 0.03), ('add', 0.029), ('generic', 0.029), ('yc', 0.028), ('minimization', 0.028), ('nne', 0.028), ('kohli', 0.028), ('flows', 0.028), ('segmentation', 0.027), ('slack', 0.027), ('structured', 0.027), ('ito', 0.027), ('parent', 0.027), ('xc', 0.027), ('write', 0.027), ('svms', 0.026), ('binary', 0.026), ('violated', 0.026), ('regular', 0.026), ('ds', 0.026), ('finds', 0.026), ('cutting', 0.026), ('minimized', 0.025), ('whenever', 0.025), ('grow', 0.025), ('wa', 0.025), ('theorem', 0.025), ('learning', 0.025), ('sink', 0.025), ('runtime', 0.023), ('hamming', 0.023), ('xi', 0.023), ('higherorder', 0.023), ('adding', 0.023), ('tpami', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="171-tfidf-1" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>2 0.10761403 <a title="171-tfidf-2" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>Author: Christoph Vogel, Konrad Schindler, Stefan Roth</p><p>Abstract: Estimating dense 3D scene flow from stereo sequences remains a challenging task, despite much progress in both classical disparity and 2D optical flow estimation. To overcome the limitations of existing techniques, we introduce a novel model that represents the dynamic 3D scene by a collection of planar, rigidly moving, local segments. Scene flow estimation then amounts to jointly estimating the pixelto-segment assignment, and the 3D position, normal vector, and rigid motion parameters of a plane for each segment. The proposed energy combines an occlusion-sensitive data term with appropriate shape, motion, and segmentation regularizers. Optimization proceeds in two stages: Starting from an initial superpixelization, we estimate the shape and motion parameters of all segments by assigning a proposal from a set of moving planes. Then the pixel-to-segment assignment is updated, while holding the shape and motion parameters of the moving planes fixed. We demonstrate the benefits of our model on different real-world image sets, including the challenging KITTI benchmark. We achieve leading performance levels, exceeding competing 3D scene flow methods, and even yielding better 2D motion estimates than all tested dedicated optical flow techniques.</p><p>3 0.10079422 <a title="171-tfidf-3" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>Author: Meng Tang, Lena Gorelick, Olga Veksler, Yuri Boykov</p><p>Abstract: Among image segmentation algorithms there are two major groups: (a) methods assuming known appearance models and (b) methods estimating appearance models jointly with segmentation. Typically, the first group optimizes appearance log-likelihoods in combination with some spacial regularization. This problem is relatively simple and many methods guarantee globally optimal results. The second group treats model parameters as additional variables transforming simple segmentation energies into highorder NP-hard functionals (Zhu-Yuille, Chan-Vese, GrabCut, etc). It is known that such methods indirectly minimize the appearance overlap between the segments. We propose a new energy term explicitly measuring L1 distance between the object and background appearance models that can be globally maximized in one graph cut. We show that in many applications our simple term makes NP-hard segmentation functionals unnecessary. Our one cut algorithm effectively replaces approximate iterative optimization techniques based on block coordinate descent.</p><p>4 0.093915962 <a title="171-tfidf-4" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>Author: Igor Gridchyn, Vladimir Kolmogorov</p><p>Abstract: The problem of minimizing the Potts energy function frequently occurs in computer vision applications. One way to tackle this NP-hard problem was proposed by Kovtun [20, 21]. It identifies a part of an optimal solution by running k maxflow computations, where k is the number of labels. The number of “labeled” pixels can be significant in some applications, e.g. 50-93% in our tests for stereo. We show how to reduce the runtime to O(log k) maxflow computations (or one parametric maxflow computation). Furthermore, the output of our algorithm allows to speed-up the subsequent alpha expansion for the unlabeled part, or can be used as it is for time-critical applications. To derive our technique, we generalize the algorithm of Felzenszwalb et al. [7] for Tree Metrics. We also show a connection to k-submodular functions from combinatorial optimization, and discuss k-submodular relaxations for general energy functions.</p><p>5 0.091543764 <a title="171-tfidf-5" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>6 0.082017906 <a title="171-tfidf-6" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>7 0.078214526 <a title="171-tfidf-7" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>8 0.073924087 <a title="171-tfidf-8" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>9 0.073345505 <a title="171-tfidf-9" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>10 0.072988503 <a title="171-tfidf-10" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>11 0.072586842 <a title="171-tfidf-11" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>12 0.071935415 <a title="171-tfidf-12" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>13 0.069803752 <a title="171-tfidf-13" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>14 0.06939353 <a title="171-tfidf-14" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>15 0.064459242 <a title="171-tfidf-15" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>16 0.062179081 <a title="171-tfidf-16" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>17 0.061389443 <a title="171-tfidf-17" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>18 0.060961653 <a title="171-tfidf-18" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>19 0.059618942 <a title="171-tfidf-19" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>20 0.059264041 <a title="171-tfidf-20" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.149), (1, -0.011), (2, -0.012), (3, -0.008), (4, 0.019), (5, 0.048), (6, -0.059), (7, 0.039), (8, 0.026), (9, -0.074), (10, -0.058), (11, 0.034), (12, 0.055), (13, 0.014), (14, 0.034), (15, 0.053), (16, -0.059), (17, -0.026), (18, -0.017), (19, 0.026), (20, 0.051), (21, -0.045), (22, -0.008), (23, -0.027), (24, 0.044), (25, -0.041), (26, 0.053), (27, -0.037), (28, 0.007), (29, 0.008), (30, -0.032), (31, -0.0), (32, 0.055), (33, 0.033), (34, 0.003), (35, 0.008), (36, -0.048), (37, 0.066), (38, 0.03), (39, -0.038), (40, -0.009), (41, -0.032), (42, 0.051), (43, 0.041), (44, 0.07), (45, -0.029), (46, -0.001), (47, -0.073), (48, -0.041), (49, -0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9357295 <a title="171-lsi-1" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>2 0.77278608 <a title="171-lsi-2" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>Author: Igor Gridchyn, Vladimir Kolmogorov</p><p>Abstract: The problem of minimizing the Potts energy function frequently occurs in computer vision applications. One way to tackle this NP-hard problem was proposed by Kovtun [20, 21]. It identifies a part of an optimal solution by running k maxflow computations, where k is the number of labels. The number of “labeled” pixels can be significant in some applications, e.g. 50-93% in our tests for stereo. We show how to reduce the runtime to O(log k) maxflow computations (or one parametric maxflow computation). Furthermore, the output of our algorithm allows to speed-up the subsequent alpha expansion for the unlabeled part, or can be used as it is for time-critical applications. To derive our technique, we generalize the algorithm of Felzenszwalb et al. [7] for Tree Metrics. We also show a connection to k-submodular functions from combinatorial optimization, and discuss k-submodular relaxations for general energy functions.</p><p>3 0.71951413 <a title="171-lsi-3" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>Author: Jan Stühmer, Peter Schröder, Daniel Cremers</p><p>Abstract: We propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph, in this case a geodesic shortest path tree. Specifically we make two contributions: First, we construct a geodesic shortest path tree with a distance measure that is related to the image data and the bending energy of each path in the tree. Second, we include a connectivity prior in our segmentation model, that allows to segment not only a single elongated structure, but instead a whole connected branching tree. Because both our segmentation model and the connectivity constraint are convex, a global optimal solution can be found. To this end, we generalize a recent primal-dual algorithm for continuous convex optimization to an arbitrary graph structure. To validate our method we present results on data from medical imaging in angiography and retinal blood vessel segmentation.</p><p>4 0.69060367 <a title="171-lsi-4" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>Author: Gemma Roig, Xavier Boix, Roderick De_Nijs, Sebastian Ramos, Koljia Kuhnlenz, Luc Van_Gool</p><p>Abstract: Most MAP inference algorithms for CRFs optimize an energy function knowing all the potentials. In this paper, we focus on CRFs where the computational cost of instantiating the potentials is orders of magnitude higher than MAP inference. This is often the case in semantic image segmentation, where most potentials are instantiated by slow classifiers fed with costly features. We introduce Active MAP inference 1) to on-the-fly select a subset of potentials to be instantiated in the energy function, leaving the rest of the parameters of the potentials unknown, and 2) to estimate the MAP labeling from such incomplete energy function. Results for semantic segmentation benchmarks, namely PASCAL VOC 2010 [5] and MSRC-21 [19], show that Active MAP inference achieves similar levels of accuracy but with major efficiency gains.</p><p>5 0.65848118 <a title="171-lsi-5" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>Author: Honghui Zhang, Jingdong Wang, Ping Tan, Jinglu Wang, Long Quan</p><p>Abstract: We propose an adaptive subgradient descent method to efficiently learn the parameters of CRF models for image parsing. To balance the learning efficiency and performance of the learned CRF models, the parameter learning is iteratively carried out by solving a convex optimization problem in each iteration, which integrates a proximal term to preserve the previously learned information and the large margin preference to distinguish bad labeling and the ground truth labeling. A solution of subgradient descent updating form is derived for the convex optimization problem, with an adaptively determined updating step-size. Besides, to deal with partially labeled training data, we propose a new objective constraint modeling both the labeled and unlabeled parts in the partially labeled training data for the parameter learning of CRF models. The superior learning efficiency of the proposed method is verified by the experiment results on two public datasets. We also demonstrate the powerfulness of our method for handling partially labeled training data.</p><p>6 0.62612623 <a title="171-lsi-6" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>7 0.61575544 <a title="171-lsi-7" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>8 0.61511326 <a title="171-lsi-8" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>9 0.60254836 <a title="171-lsi-9" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>10 0.59987605 <a title="171-lsi-10" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>11 0.57610059 <a title="171-lsi-11" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>12 0.55963403 <a title="171-lsi-12" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>13 0.54524666 <a title="171-lsi-13" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>14 0.52299631 <a title="171-lsi-14" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>15 0.52268642 <a title="171-lsi-15" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<p>16 0.52043962 <a title="171-lsi-16" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>17 0.51691258 <a title="171-lsi-17" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<p>18 0.51471758 <a title="171-lsi-18" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>19 0.51377386 <a title="171-lsi-19" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>20 0.51357937 <a title="171-lsi-20" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.084), (7, 0.018), (26, 0.087), (31, 0.048), (35, 0.02), (40, 0.017), (42, 0.121), (48, 0.02), (64, 0.036), (73, 0.032), (80, 0.212), (89, 0.161), (95, 0.013), (98, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85761571 <a title="171-lda-1" href="./iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking.html">154 iccv-2013-Face Recognition via Archetype Hull Ranking</a></p>
<p>Author: Yuanjun Xiong, Wei Liu, Deli Zhao, Xiaoou Tang</p><p>Abstract: The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat- ing its performance superior to the state-of-the-arts.</p><p>same-paper 2 0.83486611 <a title="171-lda-2" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>3 0.77738816 <a title="171-lda-3" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>Author: Weixin Li, Qian Yu, Ajay Divakaran, Nuno Vasconcelos</p><p>Abstract: The problem of adaptively selecting pooling regions for the classification of complex video events is considered. Complex events are defined as events composed of several characteristic behaviors, whose temporal configuration can change from sequence to sequence. A dynamic pooling operator is defined so as to enable a unified solution to the problems of event specific video segmentation, temporal structure modeling, and event detection. Video is decomposed into segments, and the segments most informative for detecting a given event are identified, so as to dynamically determine the pooling operator most suited for each sequence. This dynamic pooling is implemented by treating the locations of characteristic segments as hidden information, which is inferred, on a sequence-by-sequence basis, via a large-margin classification rule with latent variables. Although the feasible set of segment selections is combinatorial, it is shown that a globally optimal solution to the inference problem can be obtained efficiently, through the solution of a series of linear programs. Besides the coarselevel location of segments, a finer model of video struc- ture is implemented by jointly pooling features of segmenttuples. Experimental evaluation demonstrates that the re- sulting event detector has state-of-the-art performance on challenging video datasets.</p><p>4 0.77332509 <a title="171-lda-4" href="./iccv-2013-Multiview_Photometric_Stereo_Using_Planar_Mesh_Parameterization.html">284 iccv-2013-Multiview Photometric Stereo Using Planar Mesh Parameterization</a></p>
<p>Author: Jaesik Park, Sudipta N. Sinha, Yasuyuki Matsushita, Yu-Wing Tai, In So Kweon</p><p>Abstract: We propose a method for accurate 3D shape reconstruction using uncalibrated multiview photometric stereo. A coarse mesh reconstructed using multiview stereo is first parameterized using a planar mesh parameterization technique. Subsequently, multiview photometric stereo is performed in the 2D parameter domain of the mesh, where all geometric and photometric cues from multiple images can be treated uniformly. Unlike traditional methods, there is no need for merging view-dependent surface normal maps. Our key contribution is a new photometric stereo based mesh refinement technique that can efficiently reconstruct meshes with extremely fine geometric details by directly estimating a displacement texture map in the 2D parameter domain. We demonstrate that intricate surface geometry can be reconstructed using several challenging datasets containing surfaces with specular reflections, multiple albedos and complex topologies.</p><p>5 0.75825518 <a title="171-lda-5" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>Author: Chenglong Bao, Jian-Feng Cai, Hui Ji</p><p>Abstract: In recent years, how to learn a dictionary from input images for sparse modelling has been one very active topic in image processing and recognition. Most existing dictionary learning methods consider an over-complete dictionary, e.g. the K-SVD method. Often they require solving some minimization problem that is very challenging in terms of computational feasibility and efficiency. However, if the correlations among dictionary atoms are not well constrained, the redundancy of the dictionary does not necessarily improve the performance of sparse coding. This paper proposed a fast orthogonal dictionary learning method for sparse image representation. With comparable performance on several image restoration tasks, the proposed method is much more computationally efficient than the over-complete dictionary based learning methods.</p><p>6 0.74345368 <a title="171-lda-6" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>7 0.74196804 <a title="171-lda-7" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>8 0.74159455 <a title="171-lda-8" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>9 0.74074197 <a title="171-lda-9" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>10 0.74018919 <a title="171-lda-10" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>11 0.73975617 <a title="171-lda-11" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>12 0.73929435 <a title="171-lda-12" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>13 0.73871624 <a title="171-lda-13" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>14 0.73865098 <a title="171-lda-14" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>15 0.73857921 <a title="171-lda-15" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>16 0.73847544 <a title="171-lda-16" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>17 0.73834163 <a title="171-lda-17" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>18 0.73773324 <a title="171-lda-18" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>19 0.73763204 <a title="171-lda-19" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>20 0.73728335 <a title="171-lda-20" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
