<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-171" href="#">iccv2013-171</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</h1>
<br/><p>Source: <a title="iccv-2013-171-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Fix_Structured_Learning_of_2013_ICCV_paper.pdf">pdf</a></p><p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>Reference: <a title="iccv-2013-171-reference" href="../iccv2013_reference/iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('submodul', 0.566), ('sos', 0.453), ('arc', 0.252), ('ibf', 0.234), ('cliqu', 0.228), ('fc', 0.18), ('capac', 0.149), ('flow', 0.146), ('qp', 0.111), ('cut', 0.094), ('path', 0.093), ('resid', 0.085), ('yi', 0.085), ('corol', 0.069), ('wt', 0.067), ('fw', 0.066), ('energy', 0.064), ('push', 0.054), ('mrfs', 0.052), ('chatalbashev', 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="171-tfidf-1" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>2 0.12161732 <a title="171-tfidf-2" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>Author: Meng Tang, Lena Gorelick, Olga Veksler, Yuri Boykov</p><p>Abstract: Among image segmentation algorithms there are two major groups: (a) methods assuming known appearance models and (b) methods estimating appearance models jointly with segmentation. Typically, the first group optimizes appearance log-likelihoods in combination with some spacial regularization. This problem is relatively simple and many methods guarantee globally optimal results. The second group treats model parameters as additional variables transforming simple segmentation energies into highorder NP-hard functionals (Zhu-Yuille, Chan-Vese, GrabCut, etc). It is known that such methods indirectly minimize the appearance overlap between the segments. We propose a new energy term explicitly measuring L1 distance between the object and background appearance models that can be globally maximized in one graph cut. We show that in many applications our simple term makes NP-hard segmentation functionals unnecessary. Our one cut algorithm effectively replaces approximate iterative optimization techniques based on block coordinate descent.</p><p>3 0.12146062 <a title="171-tfidf-3" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>Author: Christoph Vogel, Konrad Schindler, Stefan Roth</p><p>Abstract: Estimating dense 3D scene flow from stereo sequences remains a challenging task, despite much progress in both classical disparity and 2D optical flow estimation. To overcome the limitations of existing techniques, we introduce a novel model that represents the dynamic 3D scene by a collection of planar, rigidly moving, local segments. Scene flow estimation then amounts to jointly estimating the pixelto-segment assignment, and the 3D position, normal vector, and rigid motion parameters of a plane for each segment. The proposed energy combines an occlusion-sensitive data term with appropriate shape, motion, and segmentation regularizers. Optimization proceeds in two stages: Starting from an initial superpixelization, we estimate the shape and motion parameters of all segments by assigning a proposal from a set of moving planes. Then the pixel-to-segment assignment is updated, while holding the shape and motion parameters of the moving planes fixed. We demonstrate the benefits of our model on different real-world image sets, including the challenging KITTI benchmark. We achieve leading performance levels, exceeding competing 3D scene flow methods, and even yielding better 2D motion estimates than all tested dedicated optical flow techniques.</p><p>4 0.099038504 <a title="171-tfidf-4" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>Author: Ryan Tokola, Wongun Choi, Silvio Savarese</p><p>Abstract: We present an approach to multi-target tracking that has expressive potential beyond the capabilities of chainshaped hidden Markov models, yet has significantly reduced complexity. Our framework, which we call tracking-byselection, is similar to tracking-by-detection in that it separates the tasks of detection and tracking, but it shifts tempo-labs . com Stanford, CA ssi lvio @ st an ford . edu ral reasoning from the tracking stage to the detection stage. The core feature of tracking-by-selection is that it reasons about path hypotheses that traverse the entire video instead of a chain of single-frame object hypotheses. A traditional chain-shaped tracking-by-detection model is only able to promote consistency between one frame and the next. In tracking-by-selection, path hypotheses exist across time, and encouraging long-term temporal consistency is as simple as rewarding path hypotheses with consistent image features. One additional advantage of tracking-by-selection is that it results in a dramatically simplified model that can be solved exactly. We adapt an existing tracking-by-detection model to the tracking-by-selectionframework, and show improvedperformance on a challenging dataset (introduced in [18]).</p><p>5 0.095089547 <a title="171-tfidf-5" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>Author: Susanna Ricco, Carlo Tomasi</p><p>Abstract: Dense motion of image points over many video frames can provide important information about the world. However, occlusions and drift make it impossible to compute long motionpaths by merely concatenating opticalflow vectors between consecutive frames. Instead, we solve for entire paths directly, and flag the frames in which each is visible. As in previous work, we anchor each path to a unique pixel which guarantees an even spatial distribution of paths. Unlike earlier methods, we allow paths to be anchored in any frame. By explicitly requiring that at least one visible path passes within a small neighborhood of every pixel, we guarantee complete coverage of all visible points in all frames. We achieve state-of-the-art results on real sequences including both rigid and non-rigid motions with significant occlusions.</p><p>6 0.087401256 <a title="171-tfidf-6" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>7 0.087370351 <a title="171-tfidf-7" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>8 0.083897226 <a title="171-tfidf-8" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>9 0.083224639 <a title="171-tfidf-9" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>10 0.081311263 <a title="171-tfidf-10" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>11 0.075684585 <a title="171-tfidf-11" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>12 0.075257897 <a title="171-tfidf-12" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>13 0.073339701 <a title="171-tfidf-13" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>14 0.070507884 <a title="171-tfidf-14" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>15 0.067815967 <a title="171-tfidf-15" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>16 0.066163518 <a title="171-tfidf-16" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>17 0.06575688 <a title="171-tfidf-17" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>18 0.064962693 <a title="171-tfidf-18" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>19 0.064461172 <a title="171-tfidf-19" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>20 0.06429629 <a title="171-tfidf-20" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.152), (1, -0.012), (2, 0.001), (3, -0.032), (4, 0.038), (5, 0.025), (6, 0.055), (7, -0.029), (8, -0.038), (9, 0.092), (10, 0.003), (11, -0.025), (12, -0.011), (13, -0.031), (14, 0.004), (15, -0.072), (16, -0.012), (17, -0.007), (18, -0.033), (19, -0.041), (20, -0.021), (21, 0.047), (22, -0.08), (23, -0.093), (24, 0.053), (25, -0.015), (26, 0.017), (27, -0.064), (28, 0.028), (29, 0.013), (30, 0.047), (31, -0.001), (32, -0.014), (33, -0.009), (34, -0.006), (35, -0.004), (36, 0.022), (37, -0.023), (38, 0.076), (39, 0.015), (40, 0.025), (41, 0.063), (42, -0.024), (43, -0.01), (44, -0.047), (45, -0.026), (46, 0.05), (47, -0.012), (48, -0.048), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91044939 <a title="171-lsi-1" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>2 0.73491198 <a title="171-lsi-2" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>Author: Igor Gridchyn, Vladimir Kolmogorov</p><p>Abstract: The problem of minimizing the Potts energy function frequently occurs in computer vision applications. One way to tackle this NP-hard problem was proposed by Kovtun [20, 21]. It identifies a part of an optimal solution by running k maxflow computations, where k is the number of labels. The number of “labeled” pixels can be significant in some applications, e.g. 50-93% in our tests for stereo. We show how to reduce the runtime to O(log k) maxflow computations (or one parametric maxflow computation). Furthermore, the output of our algorithm allows to speed-up the subsequent alpha expansion for the unlabeled part, or can be used as it is for time-critical applications. To derive our technique, we generalize the algorithm of Felzenszwalb et al. [7] for Tree Metrics. We also show a connection to k-submodular functions from combinatorial optimization, and discuss k-submodular relaxations for general energy functions.</p><p>3 0.73252267 <a title="171-lsi-3" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>Author: Jan Stühmer, Peter Schröder, Daniel Cremers</p><p>Abstract: We propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph, in this case a geodesic shortest path tree. Specifically we make two contributions: First, we construct a geodesic shortest path tree with a distance measure that is related to the image data and the bending energy of each path in the tree. Second, we include a connectivity prior in our segmentation model, that allows to segment not only a single elongated structure, but instead a whole connected branching tree. Because both our segmentation model and the connectivity constraint are convex, a global optimal solution can be found. To this end, we generalize a recent primal-dual algorithm for continuous convex optimization to an arbitrary graph structure. To validate our method we present results on data from medical imaging in angiography and retinal blood vessel segmentation.</p><p>4 0.72302997 <a title="171-lsi-4" href="./iccv-2013-Shortest_Paths_with_Curvature_and_Torsion.html">389 iccv-2013-Shortest Paths with Curvature and Torsion</a></p>
<p>Author: Petter Strandmark, Johannes Ulén, Fredrik Kahl, Leo Grady</p><p>Abstract: This paper describes a method of finding thin, elongated structures in images and volumes. We use shortest paths to minimize very general functionals of higher-order curve properties, such as curvature and torsion. Our globally optimal method uses line graphs and its runtime is polynomial in the size of the discretization, often in the order of seconds on a single computer. To our knowledge, we are the first to perform experiments in three dimensions with curvature and torsion regularization. The largest graphs we process have almost one hundred billion arcs. Experiments on medical images and in multi-view reconstruction show the significance and practical usefulness of regularization based on curvature while torsion is still only tractable for small-scale problems.</p><p>5 0.65667677 <a title="171-lsi-5" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>Author: Carl Olsson, Johannes Ulén, Yuri Boykov, Vladimir Kolmogorov</p><p>Abstract: Energies with high-order non-submodular interactions have been shown to be very useful in vision due to their high modeling power. Optimization of such energies, however, is generally NP-hard. A naive approach that works for small problem instances is exhaustive search, that is, enumeration of all possible labelings of the underlying graph. We propose a general minimization approach for large graphs based on enumeration of labelings of certain small patches. This partial enumeration technique reduces complex highorder energy formulations to pairwise Constraint Satisfaction Problems with unary costs (uCSP), which can be efficiently solved using standard methods like TRW-S. Our approach outperforms a number of existing state-of-the-art algorithms on well known difficult problems (e.g. curvature regularization, stereo, deconvolution); it gives near global minimum and better speed. Our main application of interest is curvature regularization. In the context of segmentation, our partial enumeration technique allows to evaluate curvature directly on small patches using a novel integral geometry approach. 1</p><p>6 0.63998437 <a title="171-lsi-6" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>7 0.62554985 <a title="171-lsi-7" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>8 0.62361127 <a title="171-lsi-8" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>9 0.60527843 <a title="171-lsi-9" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>10 0.5929845 <a title="171-lsi-10" href="./iccv-2013-Optimal_Orthogonal_Basis_and_Image_Assimilation%3A_Motion_Modeling.html">301 iccv-2013-Optimal Orthogonal Basis and Image Assimilation: Motion Modeling</a></p>
<p>11 0.58585763 <a title="171-lsi-11" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>12 0.57972008 <a title="171-lsi-12" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>13 0.57971257 <a title="171-lsi-13" href="./iccv-2013-On_the_Mean_Curvature_Flow_on_Graphs_with_Applications_in_Image_and_Manifold_Processing.html">296 iccv-2013-On the Mean Curvature Flow on Graphs with Applications in Image and Manifold Processing</a></p>
<p>14 0.56930465 <a title="171-lsi-14" href="./iccv-2013-Detecting_Irregular_Curvilinear_Structures_in_Gray_Scale_and_Color_Imagery_Using_Multi-directional_Oriented_Flux.html">112 iccv-2013-Detecting Irregular Curvilinear Structures in Gray Scale and Color Imagery Using Multi-directional Oriented Flux</a></p>
<p>15 0.55083352 <a title="171-lsi-15" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>16 0.55072969 <a title="171-lsi-16" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>17 0.54881561 <a title="171-lsi-17" href="./iccv-2013-Higher_Order_Matching_for_Consistent_Multiple_Target_Tracking.html">200 iccv-2013-Higher Order Matching for Consistent Multiple Target Tracking</a></p>
<p>18 0.5385685 <a title="171-lsi-18" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>19 0.53621405 <a title="171-lsi-19" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>20 0.53360075 <a title="171-lsi-20" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(12, 0.012), (13, 0.068), (20, 0.105), (25, 0.028), (28, 0.015), (33, 0.017), (42, 0.104), (46, 0.297), (48, 0.111), (55, 0.014), (60, 0.017), (77, 0.122)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70888221 <a title="171-lda-1" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow [19] has had significant impact in computer vision [5, 21, 28]. In this paper we address the important class of sum-of-submodular (SoS) functions [2, 18], which can be efficiently minimized via a variant of max flow called submodular flow [6]. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach [15, 34] and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems [11] can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCVimplementation ofthe GrabCut interactive seg- mentation technique [28], which uses hand-tuned parameters instead of machine learning. On a standard dataset [12] our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.</p><p>2 0.69737923 <a title="171-lda-2" href="./iccv-2013-Recursive_Estimation_of_the_Stein_Center_of_SPD_Matrices_and_Its_Applications.html">347 iccv-2013-Recursive Estimation of the Stein Center of SPD Matrices and Its Applications</a></p>
<p>Author: Hesamoddin Salehian, Guang Cheng, Baba C. Vemuri, Jeffrey Ho</p><p>Abstract: Symmetric positive-definite (SPD) matrices are ubiquitous in Computer Vision, Machine Learning and Medical Image Analysis. Finding the center/average of a population of such matrices is a common theme in many algorithms such as clustering, segmentation, principal geodesic analysis, etc. The center of a population of such matrices can be defined using a variety of distance/divergence measures as the minimizer of the sum of squared distances/divergences from the unknown center to the members of the population. It is well known that the computation of the Karcher mean for the space of SPD matrices which is a negativelycurved Riemannian manifold is computationally expensive. Recently, the LogDet divergence-based center was shown to be a computationally attractive alternative. However, the LogDet-based mean of more than two matrices can not be computed in closed form, which makes it computationally less attractive for large populations. In this paper we present a novel recursive estimator for center based on the Stein distance which is the square root of the LogDet di– vergence that is significantly faster than the batch mode computation of this center. The key theoretical contribution is a closed-form solution for the weighted Stein center of two SPD matrices, which is used in the recursive computation of the Stein center for a population of SPD matrices. Additionally, we show experimental evidence of the convergence of our recursive Stein center estimator to the batch mode Stein center. We present applications of our recursive estimator to K-means clustering and image indexing depicting significant time gains over corresponding algorithms that use the batch mode computations. For the latter application, we develop novel hashing functions using the Stein distance and apply it to publicly available data sets, and experimental results have shown favorable com– ∗This research was funded in part by the NIH grant NS066340 to BCV. †Corresponding author parisons to other competing methods.</p><p>3 0.67687118 <a title="171-lda-3" href="./iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking.html">154 iccv-2013-Face Recognition via Archetype Hull Ranking</a></p>
<p>Author: Yuanjun Xiong, Wei Liu, Deli Zhao, Xiaoou Tang</p><p>Abstract: The archetype hull model is playing an important role in large-scale data analytics and mining, but rarely applied to vision problems. In this paper, we migrate such a geometric model to address face recognition and verification together through proposing a unified archetype hull ranking framework. Upon a scalable graph characterized by a compact set of archetype exemplars whose convex hull encompasses most of the training images, the proposed framework explicitly captures the relevance between any query and the stored archetypes, yielding a rank vector over the archetype hull. The archetype hull ranking is then executed on every block of face images to generate a blockwise similarity measure that is achieved by comparing two different rank vectors with respect to the same archetype hull. After integrating blockwise similarity measurements with learned importance weights, we accomplish a sensible face similarity measure which can support robust and effective face recognition and verification. We evaluate the face similarity measure in terms of experiments performed on three benchmark face databases Multi-PIE, Pubfig83, and LFW, demonstrat- ing its performance superior to the state-of-the-arts.</p><p>4 0.66058081 <a title="171-lda-4" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>Author: Caglayan Dicle, Octavia I. Camps, Mario Sznaier</p><p>Abstract: We introduce a computationally efficient algorithm for multi-object tracking by detection that addresses four main challenges: appearance similarity among targets, missing data due to targets being out of the field of view or occluded behind other objects, crossing trajectories, and camera motion. The proposed method uses motion dynamics as a cue to distinguish targets with similar appearance, minimize target mis-identification and recover missing data. Computational efficiency is achieved by using a Generalized Linear Assignment (GLA) coupled with efficient procedures to recover missing data and estimate the complexity of the underlying dynamics. The proposed approach works with tracklets of arbitrary length and does not assume a dynamical model a priori, yet it captures the overall motion dynamics of the targets. Experiments using challenging videos show that this framework can handle complex target motions, non-stationary cameras and long occlusions, on scenarios where appearance cues are not available or poor.</p><p>5 0.65432876 <a title="171-lda-5" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<p>Author: Thomas Berg, Peter N. Belhumeur</p><p>Abstract: How do you tell a blackbirdfrom a crow? There has been great progress toward automatic methods for visual recognition, including fine-grained visual categorization in which the classes to be distinguished are very similar. In a task such as bird species recognition, automatic recognition systems can now exceed the performance of non-experts – most people are challenged to name a couple dozen bird species, let alone identify them. This leads us to the question, “Can a recognition system show humans what to look for when identifying classes (in this case birds)? ” In the context of fine-grained visual categorization, we show that we can automatically determine which classes are most visually similar, discover what visual features distinguish very similar classes, and illustrate the key features in a way meaningful to humans. Running these methods on a dataset of bird images, we can generate a visual field guide to birds which includes a tree of similarity that displays the similarity relations between all species, pages for each species showing the most similar other species, and pages for each pair of similar species illustrating their differences.</p><p>6 0.60293901 <a title="171-lda-6" href="./iccv-2013-Revisiting_Example_Dependent_Cost-Sensitive_Learning_with_Decision_Trees.html">352 iccv-2013-Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees</a></p>
<p>7 0.60007167 <a title="171-lda-7" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>8 0.58602184 <a title="171-lda-8" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>9 0.5849669 <a title="171-lda-9" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>10 0.58051991 <a title="171-lda-10" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>11 0.57961005 <a title="171-lda-11" href="./iccv-2013-Event_Detection_in_Complex_Scenes_Using_Interval_Temporal_Constraints.html">146 iccv-2013-Event Detection in Complex Scenes Using Interval Temporal Constraints</a></p>
<p>12 0.57830656 <a title="171-lda-12" href="./iccv-2013-Coarse-to-Fine_Semantic_Video_Segmentation_Using_Supervoxel_Trees.html">76 iccv-2013-Coarse-to-Fine Semantic Video Segmentation Using Supervoxel Trees</a></p>
<p>13 0.5780527 <a title="171-lda-13" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>14 0.57743025 <a title="171-lda-14" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>15 0.57610273 <a title="171-lda-15" href="./iccv-2013-Finding_Causal_Interactions_in_Video_Sequences.html">167 iccv-2013-Finding Causal Interactions in Video Sequences</a></p>
<p>16 0.57559502 <a title="171-lda-16" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>17 0.57500744 <a title="171-lda-17" href="./iccv-2013-Constant_Time_Weighted_Median_Filtering_for_Stereo_Matching_and_Beyond.html">88 iccv-2013-Constant Time Weighted Median Filtering for Stereo Matching and Beyond</a></p>
<p>18 0.57449168 <a title="171-lda-18" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>19 0.57425982 <a title="171-lda-19" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>20 0.57416284 <a title="171-lda-20" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
