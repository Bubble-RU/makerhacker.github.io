<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>301 iccv-2013-Optimal Orthogonal Basis and Image Assimilation: Motion Modeling</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-301" href="#">iccv2013-301</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>301 iccv-2013-Optimal Orthogonal Basis and Image Assimilation: Motion Modeling</h1>
<br/><p>Source: <a title="iccv-2013-301-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Huot_Optimal_Orthogonal_Basis_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Etienne Huot, Giuseppe Papari, Isabelle Herlin</p><p>Abstract: This paper describes modeling and numerical computation of orthogonal bases, which are used to describe images and motion fields. Motion estimation from image data is then studied on subspaces spanned by these bases. A reduced model is obtained as the Galerkin projection on these subspaces of a physical model, based on Euler and optical flow equations. A data assimilation method is studied, which assimilates coefficients of image data in the reduced model in order to estimate motion coefficients. The approach is first quantified on synthetic data: it demonstrates the interest of model reduction as a compromise between results quality and computational cost. Results obtained on real data are then displayed so as to illustrate the method.</p><p>Reference: <a title="iccv-2013-301-reference" href="../iccv2013_reference/iccv-2013-Optimal_Orthogonal_Basis_and_Image_Assimilation%3A_Motion_Modeling_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 fr  Giuseppe Papari Lithicon Norway AS NORWAY papari @ l ithi con . [sent-3, score-0.06]
</p><p>2 fr s le  Abstract This paper describes modeling and numerical computation of orthogonal bases, which are used to describe images and motion fields. [sent-6, score-0.28]
</p><p>3 Motion estimation from image data is then studied on subspaces spanned by these bases. [sent-7, score-0.147]
</p><p>4 A reduced model is obtained as the Galerkin projection on these subspaces of a physical model, based on Euler and optical flow equations. [sent-8, score-0.351]
</p><p>5 A data assimilation method is studied, which assimilates coefficients of image data in the reduced model in order to estimate motion coefficients. [sent-9, score-0.777]
</p><p>6 The approach is first quantified on synthetic data: it demonstrates the interest of model reduction as a compromise between results quality and computational cost. [sent-10, score-0.074]
</p><p>7 Results obtained on real data are then displayed so as to illustrate the method. [sent-11, score-0.159]
</p><p>8 A powerful class of methods for this  task is based on data assimilation (DA), which emerged in this field less than ten years ago [1, 16, 20], after being widely used in remote sensing, geophysical and meteorological applications [4, 14, 21]. [sent-14, score-0.745]
</p><p>9 DA relies on the use of numerical models obtained by discretizing and approximating highly complex and non linear geophysical models. [sent-15, score-0.138]
</p><p>10 The issue of model reduction, obtained when projecting the dynamic equations on a subspace, arises in a natural way when studying the numerical analysis literature [10, 17]. [sent-16, score-0.116]
</p><p>11 [5] apply model reduction for estimating flow dynamics from particle image velocimery measures with a data assimilation method. [sent-18, score-0.59]
</p><p>12 However, their reduction method does not allow to either constrain properties on motion fields or to apply specific boundary conditions. [sent-22, score-0.296]
</p><p>13 In this paper, a novel projection basis is proposed (Section 3), which is derived by an optimality criterion, that takes into account the shape of the basin in which the water flows, and some desirable properties of the concerned motion, such as smoothness and zero divergence. [sent-23, score-0.283]
</p><p>14 These waveforms are applied, by means of a Galerkin projection,  ×  to obtain a reduced model of the fluid dynamic system under study which is used for image assimilation (Section 2). [sent-24, score-1.082]
</p><p>15 Model reduction and data assimilation In this section, the full and reduced model of the physical system under study are reviewed (Subsection 2. [sent-27, score-0.697]
</p><p>16 1), and the variational approach to image assimilation is described (Subsection 2. [sent-28, score-0.539]
</p><p>17 Dynamic model In the following, a numerical procedure for the solution of the fluid dynamic equations is presented, which is based on the Galerkin projection of the state vector on motion and image subspaces spanned by given families of projection functions. [sent-32, score-0.696]
</p><p>18 As the concern is motion estimation from these data, the state vector X is composed of a 2D vector field w(r), which represents the horizontal velocity of the water, and a scalar field Is (r), which represents the surface temperature of the water. [sent-35, score-0.672]
</p><p>19 The latter is also called pseudo-image in the image assimilation literature. [sent-36, score-0.507]
</p><p>20 mparison between the state vector and the real image obse? [sent-42, score-0.095]
</p><p>21 This equation is now projected i(nwto · ∇the) subspaces spanned by the orthogonal bases Φ = {φi (r)}i=1. [sent-45, score-0.317]
</p><p>22 As Φ are Ψ are orthogonal bases, we obtain:  age subspaces, dinegfin theed by: ? [sent-73, score-0.05]
</p><p>23 ting Is (t) on the basis Ψ, B(k) the K  K matrix whose (i, j) element is:  B(k)i,j=? [sent-105, score-0.1]
</p><p>24 K A reduced state vector is defined as XR(t)  (7) =  ? [sent-117, score-0.213]
</p><p>25 ,  and System (7) is summarized by:  ddXtR(t) + MR(XR(t)) = 0  (8)  the reduced model MR being the Galerkin projection of the full model M on bases Φ and  Ψ. [sent-119, score-0.361]
</p><p>26 Data assimilation Motion estimation will be obtained by means of data assimilation in the reduced model described in the previous subsection, where the reduced state vector XR satisfies the evolution equation (8). [sent-122, score-1.458]
</p><p>27 Observations, denoted by the vector Y(t), are linked to the state vector by an observation operator H: Y(t) = HXR(t) + ? [sent-123, score-0.173]
</p><p>28 R(t) (9) where H is the projection operator that maps XR(t) → b(t). [sent-124, score-0.124]
</p><p>29 Some heuristics are usually available on the value of the state vector at date 0. [sent-128, score-0.125]
</p><p>30 This is described by the background value XRb of the state vector:  XR(0) = XRb + ? [sent-129, score-0.062]
</p><p>31 For a posteriori estimation of 33334536  XR(0) given the observations, the following cost functional J needs to be minimized:  J(XR(0)) =? [sent-135, score-0.075]
</p><p>32 Definition of optimal bases In this section, the proposed projection bases for motion and image spaces are introduced as solutions of an ad hoc constrained minimization problem. [sent-148, score-0.556]
</p><p>33 1), and it is then particularized to the case of motion estimation (Subsection 3. [sent-150, score-0.193]
</p><p>34 Continuous formulation of the projection basis Let F be a Hilbert functional space, with given inner product ? [sent-154, score-0.213]
</p><p>35 , ψn the optimal waveforms, that are solutions of the following constrained minimization problem:  ⎪⎨ ⎪⎧ ⎪ (B? [sent-167, score-0.067]
</p><p>36 n  (15)  where B is a linear operator on F and δj,k is the delta Kronwehcekreer symbol. [sent-173, score-0.045]
</p><p>37 , ψn that arise from (15) coincide with the n first solutions of the following progressive unbounded minimization problem:  ⎪⎧⎨⎪ ⎩⎪ ⎪. [sent-189, score-0.067]
</p><p>38 = a rg ψ m ∈ Fi n B Q B (ψ ),|ψ |2 = 1 ,ψ ⊥ ψj1,∀<(16k) In practice, the proposed waveforms are computed as eigenfunctions of a symmetric square matrix which is calculated from the discretized versions of the operators L and cBu. [sent-191, score-0.432]
</p><p>39 Given the definition of Ω, the bases are depending on the choice of the functional Q tahned operator B de, wpehnicdhin hga oven t toh e be c hdoeificnee odf fi tnh eor fduenr cttoi ensure tahned required properties hoafv image ea dndef mineodtio inn ofiredlders. [sent-197, score-0.363]
</p><p>40 t As to the scalar waveforms that we use for image sub-  space, we consider solutions of the minimization problem (16), with: Q(ψ) ? [sent-198, score-0.584]
</p><p>41 Ω|∇ψ(r)|2dr  for ψ : Ω → R being a scalar vector field and B(ψ) applying :N Ωeum →an Rn boundary caolnardi vteiocntos on image d Ba(tψa. [sent-200, score-0.257]
</p><p>42 E apx-amples of the resulting waveforms are displayed in Fig. [sent-201, score-0.547]
</p><p>43 2, reconstructions obtained with bases of 50, 100 and 500 elements are displayed. [sent-204, score-0.171]
</p><p>44 number of elements according to the size of studied structures on images. [sent-208, score-0.072]
</p><p>45 As to vector waveforms related to the motion subspace, we will still consider solutions of the minimization problem (16), with: Q(φ) ? [sent-209, score-0.64]
</p><p>46 As to the operator B :(φ Ω), →diff Rerent situations may be defined. [sent-212, score-0.045]
</p><p>47 3, in which vector fields are represented by streamlines. [sent-216, score-0.062]
</p><p>48 The projection bases proposed in this subsection have some similarity with the wavelets described in [12, 13], which have been used for optical flow estimation [6, 7]. [sent-217, score-0.601]
</p><p>49 Specifically, a family of bi-orthogonal diadic projection functions is derived in [12, 13] as the curl of standard biorthogonal wavelets, on a square domain. [sent-218, score-0.132]
</p><p>50 Several mathematical properties of those wavelets are described: the curl of these bi-orthogonal wavelets are still bi-orthogonal, and they satisfy the Dirichlet conditions on the boundaries ofthe  Figure2. [sent-219, score-0.433]
</p><p>51 Topt bot m:Asateli mage nditsreconstrucion with 50, 100, and 500 elements respectively. [sent-220, score-0.077]
</p><p>52 However, unlike the projection basis proposed here,  the wavelets proposed in [12, 13] are not suitable to represent vector fields that are defined on an irregular domain Ω, since the boundary conditions are not met on the boundary ∂Ω in the case where Ω is not square. [sent-222, score-0.497]
</p><p>53 is sufficiently small in the initial condition, it is not guaranteed that it will stay small when a simulation is run with the reduced model. [sent-231, score-0.17]
</p><p>54 As well known, errors in the boundary condition cause the simulation to become unstable after a certain number of time steps. [sent-232, score-0.094]
</p><p>55 by [12, 13], which is overcome by the projection basis proposed in this article. [sent-235, score-0.179]
</p><p>56 In addition, in [12, 13] only vector waveforms are proposed, therefore their framework cannot be used to represent the pseudo-image component of the state vector. [sent-236, score-0.483]
</p><p>57 In contrast, the framework presented here can be used both for vector and scalar components of the state vector. [sent-237, score-0.224]
</p><p>58 Results on motion estimation  The reduced model obtained with the scalar basis for images and the divergence-free basis for motion fields has been used for estimating motion on a sequence of six satellite images acquired by NOAA/AVHRR sensors on May 14th and 15th 2005. [sent-239, score-1.175]
</p><p>59 The number of elements for the scalar basis is 240 and the one of the vector basis is 24. [sent-242, score-0.404]
</p><p>60 As no ground-truth is available for satellite data, a twinexperiment is first defined in order to quantify the method. [sent-246, score-0.171]
</p><p>61 A simulation is performed with the motion field displayed in Fig. [sent-247, score-0.416]
</p><p>62 For a clearer rendering of the motion, arrows that represent the velocity field are superposed to the usual color representation. [sent-250, score-0.103]
</p><p>63 Statistics of that motion field are given in Table 1: minimal, maximal and average values  Figure4. [sent-251, score-0.205]
</p><p>64 Four elements ψnof the scalar basis, for n = 30, n = 60, n = 120, and n = 240. [sent-254, score-0.171]
</p><p>65 Statistics on the norm of the initial motion field. [sent-261, score-0.152]
</p><p>66 The simulation provides a sequence of six pseudo-images, taken at same dates than the real acquisitions. [sent-263, score-0.052]
</p><p>67 These pseudo-images are then assimilated with the reduced model in order to estimate the underlying motion. [sent-264, score-0.167]
</p><p>68 Value at date 0, named estimation, is displayed in Fig. [sent-265, score-0.189]
</p><p>69 The error between motion estimations and ground-truth is quantified in Table 2. [sent-269, score-0.189]
</p><p>70 1 58 0 a L2 regularisation of motion [11, 18] or on a second-order regularisation of the divergence [3, 19]. [sent-284, score-0.258]
</p><p>71 In order to bet-  ter visualize the differences between methods, we defined five characteristics points on the first observation, which are displayed as red crosses on Fig. [sent-285, score-0.159]
</p><p>72 These characteristic points are then advected by the ground-truth motion field (displayed in red), the one obtained with our method (displayed in green), and the result of Sun et al. [sent-287, score-0.317]
</p><p>73 The characteristic points obtained at the end of the whole advection process are visualized on the last observation on Fig. [sent-290, score-0.112]
</p><p>74 The color of the ellipse surrounding each set of points gives an additional information on the quality of the result: a green ellipse codes that our method gives the best result, while a blue one means that Sun’s algorithm provides a better result. [sent-292, score-0.068]
</p><p>75 The sequence of real satellite observations partly displayed on Fig. [sent-293, score-0.365]
</p><p>76 4 has then been processed for estimating its motion with the reduced model. [sent-294, score-0.27]
</p><p>77 An additional experiment has been conducted with a scalar basis of size 120. [sent-297, score-0.229]
</p><p>78 This demonstrates that if small scales of image data are not taken into account in the basis, motion can not be correctly retrieved. [sent-298, score-0.152]
</p><p>79 On the other hand, experiment with a scalar basis of size 480 demonstrates that further increasing the subspace dimension does not allow to improve results and has for consequence to increase the size of the reduced model and com-  putational cost. [sent-299, score-0.385]
</p><p>80 The right number of elements should be chosen accordingly to the size of the spatial structures that impact motion. [sent-300, score-0.072]
</p><p>81 10 displays the result obtained when satellite images are assimilated with the full model described by System (1). [sent-302, score-0.255]
</p><p>82 As the full model considers a local description of motion, under the divergencefree constraint, global characteristics such as the two main vortices are underestimated, due to smoothing created by the data assimilation process. [sent-303, score-0.542]
</p><p>83 On the other hand, having determined the size of motion basis in accordance to the minimal size of structures to be retrieved allows a better modeling and a good retrieval of these vortices. [sent-304, score-0.282]
</p><p>84 8 have been advected by Sun motion field (displayed on top of Fig. [sent-306, score-0.284]
</p><p>85 Positions on the last observation are displayed on Fig. [sent-310, score-0.159]
</p><p>86 Figure 12 displays a second satellite sequence of Sea Surface Temperature images acquired on July 27th and 28th 2007. [sent-312, score-0.202]
</p><p>87 Figure 13 provides results of motion estimation: Sun et al. [sent-313, score-0.152]
</p><p>88 Again, it can be observed that structures are better assessed and retrieved by the reduced model. [sent-315, score-0.186]
</p><p>89 Conclusion and Perspectives The main contribution of the paper is the new set of orthogonal projection functions introduced for reduced models. [sent-317, score-0.247]
</p><p>90 The new waveforms have been obtained by maximizing  smoothness while imposing desirable properties, such as zero divergence and suitable boundary conditions. [sent-318, score-0.43]
</p><p>91 The proposed waveforms enable us to write down a reduced model, which has been used for image assimilation. [sent-319, score-0.506]
</p><p>92 As we see from the experimental results, structures are better assessed with our approach, while computational cost becomes low, even for large size basins. [sent-320, score-0.068]
</p><p>93 A major perspective of this work concerns the improvement of the properties imposed to the image and motion bases. [sent-321, score-0.188]
</p><p>94 As to scalar waveforms, for the image subspace, constraints to allow finer scales at positions of fine structures will be investigated from a long term satellite images data base. [sent-322, score-0.33]
</p><p>95 As to vector waveforms, for the motion subspace, we will investigate how to use a data base of analysis, obtained by data assimilation in an oceanographic model, to derive properties to be imposed to the basis elements. [sent-323, score-0.828]
</p><p>96 Wavelets to reconstruct turbulence multifractals from experimental image  sequences. [sent-377, score-0.089]
</p><p>97 [9]  [10]  [11] [12]  [13]  mal motion estimation. [sent-392, score-0.152]
</p><p>98 Learning reduced models for motion estimation on long temporal image sequences. [sent-397, score-0.311]
</p><p>99 Variational algorithms for analysis and assimilation of meteorological observations: theoretical aspects. [sent-426, score-0.596]
</p><p>100 A semiLagrangian discontinuous Galerkin method for scalar advection by incompressible flows. [sent-451, score-0.208]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('assimilation', 0.507), ('waveforms', 0.388), ('xr', 0.189), ('wavelets', 0.172), ('satellite', 0.171), ('displayed', 0.159), ('motion', 0.152), ('galerkin', 0.149), ('xrb', 0.149), ('scalar', 0.129), ('bases', 0.129), ('hxr', 0.119), ('reduced', 0.118), ('basis', 0.1), ('subsection', 0.092), ('corpetti', 0.089), ('erian', 0.089), ('herlin', 0.089), ('meteorological', 0.089), ('turbulence', 0.089), ('advected', 0.079), ('advection', 0.079), ('projection', 0.079), ('numerical', 0.078), ('fluid', 0.069), ('subspaces', 0.066), ('temperature', 0.066), ('sun', 0.062), ('state', 0.062), ('adamo', 0.06), ('drifi', 0.06), ('geophysical', 0.06), ('harouna', 0.06), ('herzet', 0.06), ('huot', 0.06), ('kadri', 0.06), ('norway', 0.06), ('papari', 0.06), ('tellus', 0.06), ('sea', 0.056), ('field', 0.053), ('regularisation', 0.053), ('curl', 0.053), ('papadakis', 0.053), ('simulation', 0.052), ('velocity', 0.05), ('orthogonal', 0.05), ('assimilated', 0.049), ('emin', 0.049), ('flow', 0.046), ('operator', 0.045), ('eigenfunctions', 0.044), ('tained', 0.044), ('adjoint', 0.044), ('july', 0.043), ('optical', 0.042), ('boundary', 0.042), ('elements', 0.042), ('estimation', 0.041), ('proceedings', 0.041), ('spanned', 0.04), ('evolution', 0.04), ('basin', 0.038), ('assessed', 0.038), ('inri', 0.038), ('equations', 0.038), ('subspace', 0.038), ('reduction', 0.037), ('lb', 0.037), ('quantified', 0.037), ('remote', 0.036), ('horn', 0.036), ('kj', 0.036), ('journal', 0.036), ('properties', 0.036), ('bot', 0.035), ('minimization', 0.035), ('full', 0.035), ('observations', 0.035), ('ellipse', 0.034), ('functional', 0.034), ('ab', 0.033), ('international', 0.033), ('vector', 0.033), ('characteristic', 0.033), ('variational', 0.032), ('equation', 0.032), ('solutions', 0.032), ('tahned', 0.031), ('dynamical', 0.031), ('acquired', 0.031), ('date', 0.03), ('water', 0.03), ('structures', 0.03), ('fi', 0.03), ('fields', 0.029), ('france', 0.028), ('mr', 0.028), ('middle', 0.028), ('definition', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="301-tfidf-1" href="./iccv-2013-Optimal_Orthogonal_Basis_and_Image_Assimilation%3A_Motion_Modeling.html">301 iccv-2013-Optimal Orthogonal Basis and Image Assimilation: Motion Modeling</a></p>
<p>Author: Etienne Huot, Giuseppe Papari, Isabelle Herlin</p><p>Abstract: This paper describes modeling and numerical computation of orthogonal bases, which are used to describe images and motion fields. Motion estimation from image data is then studied on subspaces spanned by these bases. A reduced model is obtained as the Galerkin projection on these subspaces of a physical model, based on Euler and optical flow equations. A data assimilation method is studied, which assimilates coefficients of image data in the reduced model in order to estimate motion coefficients. The approach is first quantified on synthetic data: it demonstrates the interest of model reduction as a compromise between results quality and computational cost. Results obtained on real data are then displayed so as to illustrate the method.</p><p>2 0.088330038 <a title="301-tfidf-2" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>Author: Christoph Vogel, Konrad Schindler, Stefan Roth</p><p>Abstract: Estimating dense 3D scene flow from stereo sequences remains a challenging task, despite much progress in both classical disparity and 2D optical flow estimation. To overcome the limitations of existing techniques, we introduce a novel model that represents the dynamic 3D scene by a collection of planar, rigidly moving, local segments. Scene flow estimation then amounts to jointly estimating the pixelto-segment assignment, and the 3D position, normal vector, and rigid motion parameters of a plane for each segment. The proposed energy combines an occlusion-sensitive data term with appropriate shape, motion, and segmentation regularizers. Optimization proceeds in two stages: Starting from an initial superpixelization, we estimate the shape and motion parameters of all segments by assigning a proposal from a set of moving planes. Then the pixel-to-segment assignment is updated, while holding the shape and motion parameters of the moving planes fixed. We demonstrate the benefits of our model on different real-world image sets, including the challenging KITTI benchmark. We achieve leading performance levels, exceeding competing 3D scene flow methods, and even yielding better 2D motion estimates than all tested dedicated optical flow techniques.</p><p>3 0.079391979 <a title="301-tfidf-3" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>Author: Tae Hyun Kim, Hee Seok Lee, Kyoung Mu Lee</p><p>Abstract: Many state-of-the-art optical flow estimation algorithms optimize the data and regularization terms to solve ill-posed problems. In this paper, in contrast to the conventional optical flow framework that uses a single or fixed data model, we study a novel framework that employs locally varying data term that adaptively combines different multiple types of data models. The locally adaptive data term greatly reduces the matching ambiguity due to the complementary nature of the multiple data models. The optimal number of complementary data models is learnt by minimizing the redundancy among them under the minimum description length constraint (MDL). From these chosen data models, a new optical flow estimation energy model is designed with the weighted sum of the multiple data models, and a convex optimization-based highly effective and practical solution thatfinds the opticalflow, as well as the weights isproposed. Comparative experimental results on the Middlebury optical flow benchmark show that the proposed method using the complementary data models outperforms the state-ofthe art methods.</p><p>4 0.075996131 <a title="301-tfidf-4" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>Author: Jim Braux-Zin, Romain Dupont, Adrien Bartoli</p><p>Abstract: Dense motion field estimation (typically Romain Dupont1 romain . dupont @ cea . fr Adrien Bartoli2 adrien . bart o l @ gmai l com i . 2 ISIT, Universit e´ d’Auvergne/CNRS, France sions are explicitly modeled [32, 13]. Coarse-to-fine warping improves global convergence by making the assumption that optical flow, the motion of smaller structures is similar to the motion of stereo disparity and surface registration) is a key computer vision problem. Many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, but a unified methodology is still lacking. We here introduce a general framework that robustly combines direct and feature-based matching. The feature-based cost is built around a novel robust distance function that handles keypoints and “weak” features such as segments. It allows us to use putative feature matches which may contain mismatches to guide dense motion estimation out of local minima. Our framework uses a robust direct data term (AD-Census). It is implemented with a powerful second order Total Generalized Variation regularization with external and self-occlusion reasoning. Our framework achieves state of the art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). Our framework has a modular design that customizes to specific application needs.</p><p>5 0.074610054 <a title="301-tfidf-5" href="./iccv-2013-Robust_Trajectory_Clustering_for_Motion_Segmentation.html">361 iccv-2013-Robust Trajectory Clustering for Motion Segmentation</a></p>
<p>Author: Feng Shi, Zhong Zhou, Jiangjian Xiao, Wei Wu</p><p>Abstract: Due to occlusions and objects ’ non-rigid deformation in the scene, the obtained motion trajectories from common trackers may contain a number of missing or mis-associated entries. To cluster such corrupted point based trajectories into multiple motions is still a hard problem. In this paper, we present an approach that exploits temporal and spatial characteristics from tracked points to facilitate segmentation of incomplete and corrupted trajectories, thereby obtain highly robust results against severe data missing and noises. Our method first uses the Discrete Cosine Transform (DCT) bases as a temporal smoothness constraint on trajectory projection to ensure the validity of resulting components to repair pathological trajectories. Then, based on an observation that the trajectories of foreground and background in a scene may have different spatial distributions, we propose a two-stage clustering strategy that first performs foreground-background separation then segments remaining foreground trajectories. We show that, with this new clustering strategy, sequences with complex motions can be accurately segmented by even using a simple trans- lational model. Finally, a series of experiments on Hopkins 155 dataset andBerkeley motion segmentation dataset show the advantage of our method over other state-of-the-art motion segmentation algorithms in terms of both effectiveness and robustness.</p><p>6 0.07350827 <a title="301-tfidf-6" href="./iccv-2013-Online_Motion_Segmentation_Using_Dynamic_Label_Propagation.html">297 iccv-2013-Online Motion Segmentation Using Dynamic Label Propagation</a></p>
<p>7 0.073298477 <a title="301-tfidf-7" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>8 0.072449617 <a title="301-tfidf-8" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<p>9 0.06961026 <a title="301-tfidf-9" href="./iccv-2013-Perspective_Motion_Segmentation_via_Collaborative_Clustering.html">314 iccv-2013-Perspective Motion Segmentation via Collaborative Clustering</a></p>
<p>10 0.06880334 <a title="301-tfidf-10" href="./iccv-2013-Measuring_Flow_Complexity_in_Videos.html">263 iccv-2013-Measuring Flow Complexity in Videos</a></p>
<p>11 0.067529991 <a title="301-tfidf-11" href="./iccv-2013-Latent_Space_Sparse_Subspace_Clustering.html">232 iccv-2013-Latent Space Sparse Subspace Clustering</a></p>
<p>12 0.06751617 <a title="301-tfidf-12" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>13 0.066240914 <a title="301-tfidf-13" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>14 0.064630739 <a title="301-tfidf-14" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>15 0.064203031 <a title="301-tfidf-15" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>16 0.062083155 <a title="301-tfidf-16" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<p>17 0.061505377 <a title="301-tfidf-17" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>18 0.057337608 <a title="301-tfidf-18" href="./iccv-2013-Mining_Motion_Atoms_and_Phrases_for_Complex_Action_Recognition.html">265 iccv-2013-Mining Motion Atoms and Phrases for Complex Action Recognition</a></p>
<p>19 0.057048924 <a title="301-tfidf-19" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>20 0.056181919 <a title="301-tfidf-20" href="./iccv-2013-Robust_Subspace_Clustering_via_Half-Quadratic_Minimization.html">360 iccv-2013-Robust Subspace Clustering via Half-Quadratic Minimization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.131), (1, -0.051), (2, -0.022), (3, 0.04), (4, -0.06), (5, 0.058), (6, -0.001), (7, 0.039), (8, 0.074), (9, 0.023), (10, 0.002), (11, -0.026), (12, 0.014), (13, -0.012), (14, -0.006), (15, 0.018), (16, -0.011), (17, 0.035), (18, 0.042), (19, -0.009), (20, 0.039), (21, -0.015), (22, 0.046), (23, 0.01), (24, -0.025), (25, -0.029), (26, 0.054), (27, -0.03), (28, 0.029), (29, -0.033), (30, -0.023), (31, 0.004), (32, -0.006), (33, 0.022), (34, -0.027), (35, -0.03), (36, 0.017), (37, -0.04), (38, -0.011), (39, 0.001), (40, 0.029), (41, -0.026), (42, 0.02), (43, 0.002), (44, -0.047), (45, -0.006), (46, -0.002), (47, -0.019), (48, 0.013), (49, -0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94722652 <a title="301-lsi-1" href="./iccv-2013-Optimal_Orthogonal_Basis_and_Image_Assimilation%3A_Motion_Modeling.html">301 iccv-2013-Optimal Orthogonal Basis and Image Assimilation: Motion Modeling</a></p>
<p>Author: Etienne Huot, Giuseppe Papari, Isabelle Herlin</p><p>Abstract: This paper describes modeling and numerical computation of orthogonal bases, which are used to describe images and motion fields. Motion estimation from image data is then studied on subspaces spanned by these bases. A reduced model is obtained as the Galerkin projection on these subspaces of a physical model, based on Euler and optical flow equations. A data assimilation method is studied, which assimilates coefficients of image data in the reduced model in order to estimate motion coefficients. The approach is first quantified on synthetic data: it demonstrates the interest of model reduction as a compromise between results quality and computational cost. Results obtained on real data are then displayed so as to illustrate the method.</p><p>2 0.71205956 <a title="301-lsi-2" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>Author: Tae Hyun Kim, Hee Seok Lee, Kyoung Mu Lee</p><p>Abstract: Many state-of-the-art optical flow estimation algorithms optimize the data and regularization terms to solve ill-posed problems. In this paper, in contrast to the conventional optical flow framework that uses a single or fixed data model, we study a novel framework that employs locally varying data term that adaptively combines different multiple types of data models. The locally adaptive data term greatly reduces the matching ambiguity due to the complementary nature of the multiple data models. The optimal number of complementary data models is learnt by minimizing the redundancy among them under the minimum description length constraint (MDL). From these chosen data models, a new optical flow estimation energy model is designed with the weighted sum of the multiple data models, and a convex optimization-based highly effective and practical solution thatfinds the opticalflow, as well as the weights isproposed. Comparative experimental results on the Middlebury optical flow benchmark show that the proposed method using the complementary data models outperforms the state-ofthe art methods.</p><p>3 0.69728202 <a title="301-lsi-3" href="./iccv-2013-Measuring_Flow_Complexity_in_Videos.html">263 iccv-2013-Measuring Flow Complexity in Videos</a></p>
<p>Author: Saad Ali</p><p>Abstract: In this paper a notion of flow complexity that measures the amount of interaction among objects is introduced and an approach to compute it directly from a video sequence is proposed. The approach employs particle trajectories as the input representation of motion and maps it into a ‘braid’ based representation. The mapping is based on the observation that 2D trajectories of particles take the form of a braid in space-time due to the intermingling among particles over time. As a result of this mapping, the problem of estimating the flow complexity from particle trajectories becomes the problem of estimating braid complexity, which in turn can be computed by measuring the topological entropy of a braid. For this purpose recently developed mathematical tools from braid theory are employed which allow rapid computation of topological entropy of braids. The approach is evaluated on a dataset consisting of open source videos depicting variations in terms of types of moving objects, scene layout, camera view angle, motion patterns, and object densities. The results show that the proposed approach is able to quantify the complexity of the flow, and at the same time provides useful insights about the sources of the complexity.</p><p>4 0.66010207 <a title="301-lsi-4" href="./iccv-2013-Perspective_Motion_Segmentation_via_Collaborative_Clustering.html">314 iccv-2013-Perspective Motion Segmentation via Collaborative Clustering</a></p>
<p>Author: Zhuwen Li, Jiaming Guo, Loong-Fah Cheong, Steven Zhiying Zhou</p><p>Abstract: This paper addresses real-world challenges in the motion segmentation problem, including perspective effects, missing data, and unknown number of motions. It first formulates the 3-D motion segmentation from two perspective views as a subspace clustering problem, utilizing the epipolar constraint of an image pair. It then combines the point correspondence information across multiple image frames via a collaborative clustering step, in which tight integration is achieved via a mixed norm optimization scheme. For model selection, wepropose an over-segment and merge approach, where the merging step is based on the property of the ?1-norm ofthe mutual sparse representation oftwo oversegmented groups. The resulting algorithm can deal with incomplete trajectories and perspective effects substantially better than state-of-the-art two-frame and multi-frame methods. Experiments on a 62-clip dataset show the significant superiority of the proposed idea in both segmentation accuracy and model selection.</p><p>5 0.63900453 <a title="301-lsi-5" href="./iccv-2013-Minimal_Basis_Facility_Location_for_Subspace_Segmentation.html">264 iccv-2013-Minimal Basis Facility Location for Subspace Segmentation</a></p>
<p>Author: Choon-Meng Lee, Loong-Fah Cheong</p><p>Abstract: In contrast to the current motion segmentation paradigm that assumes independence between the motion subspaces, we approach the motion segmentation problem by seeking the parsimonious basis set that can represent the data. Our formulation explicitly looks for the overlap between subspaces in order to achieve a minimal basis representation. This parsimonious basis set is important for the performance of our model selection scheme because the sharing of basis results in savings of model complexity cost. We propose the use of affinity propagation based method to determine the number of motion. The key lies in the incorporation of a global cost model into the factor graph, serving the role of model complexity. The introduction of this global cost model requires additional message update in the factor graph. We derive an efficient update for the new messages associated with this global cost model. An important step in the use of affinity propagation is the subspace hypotheses generation. We use the row-sparse convex proxy solution as an initialization strategy. We further encourage the selection of subspace hypotheses with shared basis by integrat- ing a discount scheme that lowers the factor graph facility cost based on shared basis. We verified the model selection and classification performance of our proposed method on both the original Hopkins 155 dataset and the more balanced Hopkins 380 dataset.</p><p>6 0.6267885 <a title="301-lsi-6" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>7 0.6114735 <a title="301-lsi-7" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>8 0.60810804 <a title="301-lsi-8" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>9 0.6051622 <a title="301-lsi-9" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>10 0.59788626 <a title="301-lsi-10" href="./iccv-2013-Two-Point_Gait%3A_Decoupling_Gait_from_Body_Shape.html">430 iccv-2013-Two-Point Gait: Decoupling Gait from Body Shape</a></p>
<p>11 0.58969241 <a title="301-lsi-11" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>12 0.58912605 <a title="301-lsi-12" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>13 0.58685338 <a title="301-lsi-13" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>14 0.58284211 <a title="301-lsi-14" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<p>15 0.57754475 <a title="301-lsi-15" href="./iccv-2013-Efficient_Higher-Order_Clustering_on_the_Grassmann_Manifold.html">134 iccv-2013-Efficient Higher-Order Clustering on the Grassmann Manifold</a></p>
<p>16 0.57689101 <a title="301-lsi-16" href="./iccv-2013-Online_Motion_Segmentation_Using_Dynamic_Label_Propagation.html">297 iccv-2013-Online Motion Segmentation Using Dynamic Label Propagation</a></p>
<p>17 0.56659764 <a title="301-lsi-17" href="./iccv-2013-Estimating_the_Material_Properties_of_Fabric_from_Video.html">145 iccv-2013-Estimating the Material Properties of Fabric from Video</a></p>
<p>18 0.56173635 <a title="301-lsi-18" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>19 0.55944419 <a title="301-lsi-19" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>20 0.55864656 <a title="301-lsi-20" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.052), (7, 0.028), (26, 0.074), (31, 0.043), (34, 0.017), (40, 0.02), (42, 0.123), (48, 0.012), (64, 0.034), (73, 0.06), (79, 0.284), (89, 0.149)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.744259 <a title="301-lda-1" href="./iccv-2013-Optimal_Orthogonal_Basis_and_Image_Assimilation%3A_Motion_Modeling.html">301 iccv-2013-Optimal Orthogonal Basis and Image Assimilation: Motion Modeling</a></p>
<p>Author: Etienne Huot, Giuseppe Papari, Isabelle Herlin</p><p>Abstract: This paper describes modeling and numerical computation of orthogonal bases, which are used to describe images and motion fields. Motion estimation from image data is then studied on subspaces spanned by these bases. A reduced model is obtained as the Galerkin projection on these subspaces of a physical model, based on Euler and optical flow equations. A data assimilation method is studied, which assimilates coefficients of image data in the reduced model in order to estimate motion coefficients. The approach is first quantified on synthetic data: it demonstrates the interest of model reduction as a compromise between results quality and computational cost. Results obtained on real data are then displayed so as to illustrate the method.</p><p>2 0.69019055 <a title="301-lda-2" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>Author: Yi Sun, Xiaogang Wang, Xiaoou Tang</p><p>Abstract: This paper proposes a hybrid convolutional network (ConvNet)-Restricted Boltzmann Machine (RBM) model for face verification in wild conditions. A key contribution of this work is to directly learn relational visual features, which indicate identity similarities, from raw pixels of face pairs with a hybrid deep network. The deep ConvNets in our model mimic the primary visual cortex to jointly extract local relational visual features from two face images compared with the learned filter pairs. These relational features are further processed through multiple layers to extract high-level and global features. Multiple groups of ConvNets are constructed in order to achieve robustness and characterize face similarities from different aspects. The top-layerRBMperforms inferencefrom complementary high-level features extracted from different ConvNet groups with a two-level average pooling hierarchy. The entire hybrid deep network is jointly fine-tuned to optimize for the task of face verification. Our model achieves competitive face verification performance on the LFW dataset.</p><p>3 0.61412597 <a title="301-lda-3" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>Author: Hongteng Xu, Hongyuan Zha</p><p>Abstract: Data sparsity has been a thorny issuefor manifold-based image synthesis, and in this paper we address this critical problem by leveraging ideas from transfer learning. Specifically, we propose methods based on generating auxiliary data in the form of synthetic samples using transformations of the original sparse samples. To incorporate the auxiliary data, we propose a weighted data synthesis method, which adaptively selects from the generated samples for inclusion during the manifold learning process via a weighted iterative algorithm. To demonstrate the feasibility of the proposed method, we apply it to the problem of face image synthesis from sparse samples. Compared with existing methods, the proposed method shows encouraging results with good performance improvements.</p><p>4 0.61189395 <a title="301-lda-4" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>5 0.61088562 <a title="301-lda-5" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>6 0.61020887 <a title="301-lda-6" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>7 0.60912061 <a title="301-lda-7" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>8 0.60896385 <a title="301-lda-8" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>9 0.60803175 <a title="301-lda-9" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>10 0.60801542 <a title="301-lda-10" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>11 0.60790485 <a title="301-lda-11" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>12 0.60754776 <a title="301-lda-12" href="./iccv-2013-Distributed_Low-Rank_Subspace_Segmentation.html">122 iccv-2013-Distributed Low-Rank Subspace Segmentation</a></p>
<p>13 0.60734856 <a title="301-lda-13" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>14 0.60703993 <a title="301-lda-14" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>15 0.60693383 <a title="301-lda-15" href="./iccv-2013-Coherent_Object_Detection_with_3D_Geometric_Context_from_a_Single_Image.html">79 iccv-2013-Coherent Object Detection with 3D Geometric Context from a Single Image</a></p>
<p>16 0.60644436 <a title="301-lda-16" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>17 0.60625154 <a title="301-lda-17" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>18 0.60598016 <a title="301-lda-18" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>19 0.60588777 <a title="301-lda-19" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>20 0.60566807 <a title="301-lda-20" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
