<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-450" href="#">iccv2013-450</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</h1>
<br/><p>Source: <a title="iccv-2013-450-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Iwamura_What_is_the_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Masakazu Iwamura, Tomokazu Sato, Koichi Kise</p><p>Abstract: Approximate nearest neighbor search (ANNS) is a basic and important technique used in many tasks such as object recognition. It involves two processes: selecting nearest neighbor candidates and performing a brute-force search of these candidates. Only the former though has scope for improvement. In most existing methods, it approximates the space by quantization. It then calculates all the distances between the query and all the quantized values (e.g., clusters or bit sequences), and selects a fixed number of candidates close to the query. The performance of the method is evaluated based on accuracy as a function of the number of candidates. This evaluation seems rational but poses a serious problem; it ignores the computational cost of the process of selection. In this paper, we propose a new ANNS method that takes into account costs in the selection process. Whereas existing methods employ computationally expensive techniques such as comparative sort and heap, the proposed method does not. This realizes a significantly more efficient search. We have succeeded in reducing computation times by one-third compared with the state-of-the- art on an experiment using 100 million SIFT features.</p><p>Reference: <a title="iccv-2013-450-reference" href="../iccv2013_reference/iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp  Abstract Approximate nearest neighbor search (ANNS) is a basic and important technique used in many tasks such as object recognition. [sent-5, score-0.197]
</p><p>2 It involves two processes: selecting nearest neighbor candidates and performing a brute-force search of these candidates. [sent-6, score-0.515]
</p><p>3 It then calculates all the distances between the query and all the quantized values (e. [sent-9, score-0.239]
</p><p>4 , clusters or bit sequences), and selects a fixed number of candidates close to the query. [sent-11, score-0.38]
</p><p>5 We have succeeded in reducing computation times by one-third compared with the state-of-the-  art on an experiment using 100 million SIFT features. [sent-17, score-0.28]
</p><p>6 Introduction Finding the nearest neighbor (NN) of a given query, called nearest neighbor search (NNS), is a simple but important task. [sent-19, score-0.354]
</p><p>7 An approximate nearest neighbor search (ANNS) is an NNS in which an approximation is introduced. [sent-20, score-0.228]
</p><p>8 Taking into account the relationship between accuracy and computation times is inherent in NNS problems. [sent-24, score-0.141]
</p><p>9 , calculating all the distances between the query and the data. [sent-27, score-0.239]
</p><p>10 A way to reduce computation times is to reduce the data submitted to the brute-force search. [sent-29, score-0.141]
</p><p>11 Lengthy computation times in selecting the NN candidates negates the advantage in reducing the data. [sent-32, score-0.459]
</p><p>12 By not being accurate in selecting NN candidates, the number of NN candidates needs augmenting to compensate for the low accuracy. [sent-33, score-0.318]
</p><p>13 The number of candidates determines computation times for brute-force searches. [sent-36, score-0.42]
</p><p>14 However, it is independent of the computation times of the selection process. [sent-37, score-0.214]
</p><p>15 Hence papers ignoring the computation time of the selection process tackle only a part of the ANNS problem1 . [sent-38, score-0.204]
</p><p>16 Imagine that there are 푛 data and a task to find NN candidates of size 푘 (푘 < 푛). [sent-46, score-0.279]
</p><p>17 This is 1 One might believe that computation times for the selection process can be ignored in comparison with that for the brute-force search. [sent-50, score-0.214]
</p><p>18 However, a good ANNS method reduces the computation times for brute-force searches. [sent-51, score-0.141]
</p><p>19 As a result, these computation times are not the dominant factor. [sent-52, score-0.141]
</p><p>20 However, there is a faster sort algorithm—the bucket sort. [sent-55, score-0.176]
</p><p>21 Thus if we can prepare appropriate buckets, the selection of NN candidates can be much faster. [sent-57, score-0.352]
</p><p>22 This makes sense because our purpose is just finding NN candidates; there is no need to arrange buckets in the ascending order of their distances. [sent-58, score-0.2]
</p><p>23 The proposed method is named bucket distance hashing (BDH). [sent-60, score-0.243]
</p><p>24 In the experiments, we compared the proposed method with various representative ANNS methods on the same platform with respect to the criterion, recall as a function of computation time, in addition to the commonly used criterion, recall as a function of the number of candidates. [sent-61, score-0.248]
</p><p>25 Hash-based data dependent approach The data dependent methods can be categorized into those performing the selection of NN candidates in the Euclidean space and the Hamming space. [sent-83, score-0.44]
</p><p>26 Selection in the Euclidean space In this category, the methods use quantization and data compression techniques. [sent-84, score-0.167]
</p><p>27 Vector quantization (VQ) is used in some ANNS methods such as VQ-index [27] and IVFADC [12]. [sent-85, score-0.141]
</p><p>28 The process can be regarded as equivalent to scalar quantization (SQ). [sent-89, score-0.141]
</p><p>29 Their use helps reduce memory usage and computation times in Hammingdistance calculations because of the efficient bitwise XOR operation. [sent-93, score-0.141]
</p><p>30 Among them, spectral hashing (SH) [29] is a representative method. [sent-97, score-0.165]
</p><p>31 A baseline method for finding NN candidates in Hamming space is the linear search which, while fast, is intractable when applied to large datasets. [sent-100, score-0.345]
</p><p>32 However, the number of data having the same Hamming distance to the query explode as the distance increases, which prevents the NN candidate selection process from being efficient [3 1]. [sent-102, score-0.38]
</p><p>33 We applied the proposed selection method of NN candidates to SH. [sent-106, score-0.352]
</p><p>34 IVFADC IVFADC [12] indexes data using VQ in selecting NN candidates efficiently. [sent-114, score-0.342]
</p><p>35 Data are divided into clusters using the k-means clustering algorithm. [sent-115, score-0.151]
</p><p>36 Given a query, the clusters close to the query are searched and data belonging to the clusters are selected as NN candidates. [sent-116, score-0.392]
</p><p>37 There is a possibility that some data close to the query are not included in the NN candidates. [sent-117, score-0.157]
</p><p>38 However, VQ is known to be the best quantization method in respect to quantization error for the 33552369  same number of clusters [5]. [sent-118, score-0.383]
</p><p>39 PQ is an intermediate quantization method between SQ and VQ; a vector space is divided into subspaces and then VQ is applied to the subvectors in each subspace. [sent-123, score-0.291]
</p><p>40 Nevertheless, computation times to achieve the same recall can be reduced with the multi-sequence algorithm (MSA). [sent-125, score-0.209]
</p><p>41 Referring to the figure, there are four clusters in the subspace 1 and three clusters in the subspace 2. [sent-127, score-0.428]
</p><p>42 The centroids of the clusters are represented by 퐶푗푖, where 푖 labels each subspace and 푗 labels a cluster in the 푖-th subspace. [sent-128, score-0.424]
</p><p>43 Initially, the squared distances between the query denoted by a star and the centroids in the subspaces are calculated. [sent-129, score-0.581]
</p><p>44 The squared distance in the original space is given by the sum of the squared distances in the subspaces. [sent-130, score-0.36]
</p><p>45 Then, if all the distances in the original space are calculated, the centroids close to the query in the original space are found. [sent-131, score-0.457]
</p><p>46 However, it is not necessary to calculate all the distances in the original space, because centroids in subspaces with large distances cannot contribute to the process. [sent-132, score-0.404]
</p><p>47 In MSA, the squared distances in each subspace are sorted first. [sent-135, score-0.297]
</p><p>48 Then, the centroids in the subspaces are examined in ascending order of distance. [sent-136, score-0.339]
</p><p>49 2(a), the first cluster examined is the direct product 퐶11 퐶12 whose squared dis-  ××× ×  tance is 2. [sent-138, score-0.222]
</p><p>50 The neighboring cluster×s 퐶퐶12 퐶12 and 퐶11 퐶22 are selected as candidates to be examin×ed퐶 퐶in the next× ×tu퐶rn. [sent-139, score-0.312]
</p><p>51 Figure 2(b) shows the next step when the candidate cluster 퐶21 퐶12 whose squared distance is 3 is selected because its squared distance is the smallest among the candidates. [sent-140, score-0.455]
</p><p>52 Then, the cluster 퐶31 퐶12 whose squared distance is 6 is selected as a new can×di 퐶date. [sent-141, score-0.227]
</p><p>53 The reason that the cluster 퐶21 퐶22 (with squared distance of 5 but hidden in the figure)× ×is 퐶 퐶not selected as a candidate is that at least one candidate is guaranteed to have a smaller distance than the cluster (see [2] for more detail). [sent-142, score-0.427]
</p><p>54 This process lasts until a sufficient number of NN candidates is obtained. [sent-143, score-0.279]
</p><p>55 As seen above, MSA compares the distances between clusters and arranges them in ascending order of distance. [sent-144, score-0.229]
</p><p>56 We shall show that space division into  Figure 1: Overview of the inverted multi-index (IMI) when the feature space is divided into two. [sent-150, score-0.153]
</p><p>57 The clusters in magenta represent those already selected and those in cyan are to be examined in the next turn. [sent-153, score-0.187]
</p><p>58 1, the key idea of the proposed method is to select NN candidates without comparing data or clusters. [sent-159, score-0.279]
</p><p>59 In the figure, paths from query (Q) to the centroids (C) in the original space are drawn. [sent-163, score-0.424]
</p><p>60 The left and right halves of the paths represent the squared distances {푑푖푗 } between the query and centroids in subspaces 1 and  2, respectively. [sent-164, score-0.656]
</p><p>61 Then, an upper bound of the squared distance is determined. [sent-166, score-0.288]
</p><p>62 QSquearyedQistancde s13421 = b251e twenSquad re32 1d= 831distanceChsebCoertiwngetr oanidls pinace the query and centroids in subspace 1  the query and centroids in subspace 2  Figure 3: Overview of the proposed method when the feature space is divided into two. [sent-169, score-0.948]
</p><p>63 Paths from query (Q) to centroids (C) in the original space are drawn. [sent-172, score-0.349]
</p><p>64 All the paths whose total distances are less than an upper bound are selected in the following process. [sent-174, score-0.328]
</p><p>65 Figure 4 illustrates the proposed algorithm when the upper bound of the squared distance is 8. [sent-175, score-0.288]
</p><p>66 In (a), when the upper bound is set at 8, the path with 푑41 = 11 is immediately removed because the path distance is larger than the upper bound. [sent-177, score-0.374]
</p><p>67 Hereafter, each path in the subspace 1 (left half) is examined. [sent-178, score-0.179]
</p><p>68 As the difference between the path distance and the upper bound is 7, the paths with 푑12 = 1and 푑22 = 3 on the subspace 2 (right half) are selected as NN candidates. [sent-180, score-0.473]
</p><p>69 As the difference between the path distance and the upper bound is 6, the paths with 푑12 = 1 and 푑22 = 3 on the subspace 2 (right half) are selected as NN candidates. [sent-182, score-0.473]
</p><p>70 As the difference between the path distance and the upper bound is 3, the paths with 푑12 = 1and 푑22 = 3 on the subspace 2 (right half) are selected as NN candidates. [sent-184, score-0.473]
</p><p>71 Let 푁 and 퐷 be the number of data, and the dimensionality of query and data, respectively. [sent-191, score-0.182]
</p><p>72 The purpose here is to divide data into 푘푖 clusters in the 푖-th subspace, and determine {푘푖} and the centroids of the clusters in subspaces. [sent-215, score-0.368]
</p><p>73 Then, the quantiza33553381  Algorithm 1: Adaptive quantization with automatic parameter tuning. [sent-218, score-0.141]
</p><p>74 This algorithm finds the number 푁bkt of buckets which are closest to the number 푁 of data. [sent-219, score-0.154]
</p><p>75 (2)  Because a large quantization error causes a large estima-  tion error in distance, we take up the strategy of minimizing the largest quantization error 퐸max in the subspaces. [sent-224, score-0.282]
</p><p>76 It increases the number of clusters in the subspace having the largest quantization error, and ends when the total number of buckets approaches the number of data. [sent-226, score-0.509]
</p><p>77 As a result, the feature space is divided into 푁bkt buckets, which corresponds to the hash size of the multi-dimensional hash table. [sent-227, score-0.238]
</p><p>78 If the number 푘푖 of clusters in a subspace is 1, the quantization error in the subspace is less than 퐸max. [sent-230, score-0.468]
</p><p>79 Input: 푖: index of subspace, 푑: partial bucket distance 1  Output: 푛: the number of NN candidates if 푖 < 푚 then  1 120349endfonrdaielfnt퐿dheR푯≤a푗et푑au=d+roin {푑tℎh1푗푚e,bℎ &u2c;푑,k⋅+e t⋅ 푑aw,sℎ푗푚h푛o<;s}ea푈hnadtsh tevnalnuemisberof 4. [sent-246, score-0.418]
</p><p>80 Efficient selection of NN candidates Let 푐 be the number of NN candidates required. [sent-248, score-0.631]
</p><p>81 We propose an algorithm to select at least 푐 NN candidates with the smallest estimated distances in a step-by-step manner. [sent-249, score-0.385]
</p><p>82 Algorithm 2 finds buckets whose distances are in the range between the lower bound 퐿 and upper bound 푈 of the estimated distance, calling recursively Algorithm 3. [sent-253, score-0.456]
</p><p>83 The initial values of 퐿 and 푈 are 0 and the squared distance between the query and the nearest bucket, respectively. [sent-254, score-0.382]
</p><p>84 As long as the number 푛 of the 33553392  NN candidates obtained so far is less than 푐, the process is repeated with updated search regions. [sent-255, score-0.319]
</p><p>85 We experimentally explored the best parameters for each method, and determined ones which achieved the best performance in the criterion, recall as a function of computation time. [sent-266, score-0.145]
</p><p>86 For the former, 1 million, 10 million and 100 million datasets were used; 1000 data were used as queries. [sent-269, score-0.204]
</p><p>87 For the latter, 100 thousand, 1 million and 10 million datasets were used; the first data in the first 1000 categories (1000 data in total) were removed  from the datasets and used as queries. [sent-270, score-0.204]
</p><p>88 Experiment 1: Recall vs computation time We compared the methods in the criterion, recall as a function of computation time. [sent-278, score-0.282]
</p><p>89 Computation time is defined as the average computation time required to obtain an answer from the time the query is given. [sent-279, score-0.309]
</p><p>90 Accuracies for small 2 Although LSH [4], spectral hashing [29], transform coding [3] were examined, their performance was too poor. [sent-280, score-0.155]
</p><p>91 edu/mi t / t iny/data/ computation times were relatively low because of limitations in measuring computation times. [sent-296, score-0.218]
</p><p>92 Letting 퐺 be the number of clusters in the original space, IVFADC needs time 퐺 for the distance c√alculation in selecting NN candidates√. [sent-310, score-0.213]
</p><p>93 IMI ne√eds time 2√퐺 for distance calculation, and time √퐺log √퐺 in sorting the distances in the subspaces. [sent-311, score-0.206]
</p><p>94 Experiment 2: Recall vs number of candidates We also compared the methods in the commonly used criterion, recall as a function of the number of candidates. [sent-314, score-0.382]
</p><p>95 Conclusions In the approximate nearest neighbor search (ANNS) process, only the selection of nearest neighbor candidates has any leeway for improvement. [sent-319, score-0.737]
</p><p>96 Because taking the computation time into  account is inherent in the ANNS problem, researches ignoring computation time have only a limited impact. [sent-321, score-0.233]
</p><p>97 That is, although the goal of NN candidate selection is simply finding NN candidates, it employs unnecessary processes such as comparative sort and heap. [sent-323, score-0.171]
</p><p>98 In an experiment using 100 million SIFT features, the proposed method succeeded in reducing the computation time by one third compared with the state-of-theart; the proposed method was two times faster in 90% recall, and 2. [sent-327, score-0.346]
</p><p>99 Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. [sent-342, score-0.292]
</p><p>100 Transform coding for fast approximate nearest neighbor search in high dimensions. [sent-353, score-0.253]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('anns', 0.387), ('imi', 0.346), ('nn', 0.296), ('candidates', 0.279), ('ivfadc', 0.264), ('centroids', 0.166), ('query', 0.157), ('buckets', 0.154), ('quantization', 0.141), ('bdh', 0.124), ('bkt', 0.124), ('subspace', 0.113), ('nns', 0.11), ('hashing', 0.104), ('squared', 0.102), ('million', 0.102), ('msa', 0.102), ('vq', 0.102), ('clusters', 0.101), ('kise', 0.099), ('gist', 0.094), ('bucket', 0.091), ('flann', 0.088), ('distances', 0.082), ('neighbor', 0.082), ('bound', 0.082), ('hash', 0.081), ('computation', 0.077), ('paths', 0.075), ('nearest', 0.075), ('jst', 0.074), ('subspaces', 0.074), ('selection', 0.073), ('lsh', 0.071), ('recall', 0.068), ('path', 0.066), ('iwamura', 0.066), ('times', 0.064), ('pq', 0.062), ('indexing', 0.057), ('upper', 0.056), ('sift', 0.054), ('candidate', 0.054), ('examined', 0.053), ('hamming', 0.053), ('ms', 0.052), ('inverted', 0.051), ('divided', 0.05), ('lacer', 0.05), ('qd', 0.05), ('distance', 0.048), ('ascending', 0.046), ('criterion', 0.045), ('cluster', 0.044), ('sort', 0.044), ('faster', 0.041), ('search', 0.04), ('selecting', 0.039), ('tuning', 0.039), ('overview', 0.038), ('pointed', 0.037), ('succeeded', 0.037), ('essence', 0.036), ('representative', 0.035), ('vs', 0.035), ('half', 0.034), ('referring', 0.034), ('sq', 0.034), ('proceeds', 0.033), ('selected', 0.033), ('indyk', 0.032), ('rce', 0.032), ('approximate', 0.031), ('eigenvalues', 0.031), ('dependent', 0.031), ('procrustean', 0.029), ('hereafter', 0.029), ('ignoring', 0.029), ('randomized', 0.028), ('priority', 0.028), ('egou', 0.027), ('sorting', 0.026), ('spectral', 0.026), ('space', 0.026), ('time', 0.025), ('descending', 0.025), ('former', 0.025), ('dimensionality', 0.025), ('coding', 0.025), ('md', 0.025), ('smallest', 0.024), ('tiny', 0.024), ('bits', 0.024), ('indexes', 0.024), ('codes', 0.024), ('product', 0.023), ('douze', 0.023), ('min', 0.023), ('branch', 0.022), ('componen', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="450-tfidf-1" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>Author: Masakazu Iwamura, Tomokazu Sato, Koichi Kise</p><p>Abstract: Approximate nearest neighbor search (ANNS) is a basic and important technique used in many tasks such as object recognition. It involves two processes: selecting nearest neighbor candidates and performing a brute-force search of these candidates. Only the former though has scope for improvement. In most existing methods, it approximates the space by quantization. It then calculates all the distances between the query and all the quantized values (e.g., clusters or bit sequences), and selects a fixed number of candidates close to the query. The performance of the method is evaluated based on accuracy as a function of the number of candidates. This evaluation seems rational but poses a serious problem; it ignores the computational cost of the process of selection. In this paper, we propose a new ANNS method that takes into account costs in the selection process. Whereas existing methods employ computationally expensive techniques such as comparative sort and heap, the proposed method does not. This realizes a significantly more efficient search. We have succeeded in reducing computation times by one-third compared with the state-of-the- art on an experiment using 100 million SIFT features.</p><p>2 0.24110834 <a title="450-tfidf-2" href="./iccv-2013-Fast_Neighborhood_Graph_Search_Using_Cartesian_Concatenation.html">159 iccv-2013-Fast Neighborhood Graph Search Using Cartesian Concatenation</a></p>
<p>Author: Jing Wang, Jingdong Wang, Gang Zeng, Rui Gan, Shipeng Li, Baining Guo</p><p>Abstract: In this paper, we propose a new data structure for approximate nearest neighbor search. This structure augments the neighborhoodgraph with a bridge graph. We propose to exploit Cartesian concatenation to produce a large set of vectors, called bridge vectors, from several small sets of subvectors. Each bridge vector is connected with a few reference vectors near to it, forming a bridge graph. Our approach finds nearest neighbors by simultaneously traversing the neighborhood graph and the bridge graph in the best-first strategy. The success of our approach stems from two factors: the exact nearest neighbor search over a large number of bridge vectors can be done quickly, and the reference vectors connected to a bridge (reference) vector near the query are also likely to be near the query. Experimental results on searching over large scale datasets (SIFT, GIST andHOG) show that our approach outperforms stateof-the-art ANN search algorithms in terms of efficiency and accuracy. The combination of our approach with the IVFADC system [18] also shows superior performance over the BIGANN dataset of 1 billion SIFT features compared with the best previously published result.</p><p>3 0.20820954 <a title="450-tfidf-3" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>4 0.20303845 <a title="450-tfidf-4" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>Author: Yannis Avrithis</p><p>Abstract: Inspired by the close relation between nearest neighbor search and clustering in high-dimensional spaces as well as the success of one helping to solve the other, we introduce a new paradigm where both problems are solved simultaneously. Our solution is recursive, not in the size of input data but in the number of dimensions. One result is a clustering algorithm that is tuned to small codebooks but does not need all data in memory at the same time and is practically constant in the data size. As a by-product, a tree structure performs either exact or approximate quantization on trained centroids, the latter being not very precise but extremely fast. A lesser contribution is a new indexing scheme for image retrieval that exploits multiple small codebooks to provide an arbitrarily fine partition of the descriptor space. Large scale experiments on public datasets exhibit state of the art performance and remarkable generalization.</p><p>5 0.19819763 <a title="450-tfidf-5" href="./iccv-2013-Complementary_Projection_Hashing.html">83 iccv-2013-Complementary Projection Hashing</a></p>
<p>Author: Zhongming Jin, Yao Hu, Yue Lin, Debing Zhang, Shiding Lin, Deng Cai, Xuelong Li</p><p>Abstract: Recently, hashing techniques have been widely applied to solve the approximate nearest neighbors search problem in many vision applications. Generally, these hashing approaches generate 2c buckets, where c is the length of the hash code. A good hashing method should satisfy the following two requirements: 1) mapping the nearby data points into the same bucket or nearby (measured by xue long l i opt . ac . cn @ a(a)b(b) the Hamming distance) buckets. 2) all the data points are evenly distributed among all the buckets. In this paper, we propose a novel algorithm named Complementary Projection Hashing (CPH) to find the optimal hashing functions which explicitly considers the above two requirements. Specifically, CPHaims at sequentiallyfinding a series ofhyperplanes (hashing functions) which cross the sparse region of the data. At the same time, the data points are evenly distributed in the hypercubes generated by these hyperplanes. The experiments comparing with the state-of-the-art hashing methods demonstrate the effectiveness of the proposed method.</p><p>6 0.19533756 <a title="450-tfidf-6" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>7 0.16209348 <a title="450-tfidf-7" href="./iccv-2013-Large-Scale_Video_Hashing_via_Structure_Learning.html">229 iccv-2013-Large-Scale Video Hashing via Structure Learning</a></p>
<p>8 0.13912387 <a title="450-tfidf-8" href="./iccv-2013-A_General_Two-Step_Approach_to_Learning-Based_Hashing.html">13 iccv-2013-A General Two-Step Approach to Learning-Based Hashing</a></p>
<p>9 0.13347907 <a title="450-tfidf-9" href="./iccv-2013-Semantic-Aware_Co-indexing_for_Image_Retrieval.html">378 iccv-2013-Semantic-Aware Co-indexing for Image Retrieval</a></p>
<p>10 0.12895291 <a title="450-tfidf-10" href="./iccv-2013-Supervised_Binary_Hash_Code_Learning_with_Jensen_Shannon_Divergence.html">409 iccv-2013-Supervised Binary Hash Code Learning with Jensen Shannon Divergence</a></p>
<p>11 0.12632854 <a title="450-tfidf-11" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>12 0.12298372 <a title="450-tfidf-12" href="./iccv-2013-Learning_Hash_Codes_with_Listwise_Supervision.html">239 iccv-2013-Learning Hash Codes with Listwise Supervision</a></p>
<p>13 0.10932431 <a title="450-tfidf-13" href="./iccv-2013-Stable_Hyper-pooling_and_Query_Expansion_for_Event_Detection.html">400 iccv-2013-Stable Hyper-pooling and Query Expansion for Event Detection</a></p>
<p>14 0.10151697 <a title="450-tfidf-14" href="./iccv-2013-Neighbor-to-Neighbor_Search_for_Fast_Coding_of_Feature_Vectors.html">287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</a></p>
<p>15 0.095085301 <a title="450-tfidf-15" href="./iccv-2013-Robust_Subspace_Clustering_via_Half-Quadratic_Minimization.html">360 iccv-2013-Robust Subspace Clustering via Half-Quadratic Minimization</a></p>
<p>16 0.09361659 <a title="450-tfidf-16" href="./iccv-2013-Latent_Space_Sparse_Subspace_Clustering.html">232 iccv-2013-Latent Space Sparse Subspace Clustering</a></p>
<p>17 0.08816617 <a title="450-tfidf-17" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>18 0.086427897 <a title="450-tfidf-18" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>19 0.085283592 <a title="450-tfidf-19" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>20 0.084331758 <a title="450-tfidf-20" href="./iccv-2013-Joint_Inverted_Indexing.html">221 iccv-2013-Joint Inverted Indexing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.151), (1, 0.055), (2, -0.082), (3, -0.102), (4, -0.051), (5, 0.276), (6, 0.026), (7, 0.021), (8, -0.136), (9, 0.106), (10, 0.026), (11, 0.049), (12, -0.002), (13, 0.014), (14, -0.002), (15, 0.028), (16, 0.034), (17, -0.079), (18, 0.043), (19, -0.025), (20, -0.033), (21, 0.006), (22, 0.048), (23, -0.01), (24, -0.036), (25, -0.078), (26, -0.048), (27, -0.045), (28, -0.016), (29, -0.056), (30, -0.06), (31, 0.01), (32, 0.037), (33, -0.005), (34, 0.061), (35, 0.009), (36, 0.011), (37, -0.063), (38, 0.076), (39, -0.016), (40, -0.022), (41, 0.064), (42, 0.085), (43, 0.007), (44, -0.018), (45, -0.068), (46, -0.021), (47, -0.022), (48, 0.075), (49, 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95471644 <a title="450-lsi-1" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>Author: Masakazu Iwamura, Tomokazu Sato, Koichi Kise</p><p>Abstract: Approximate nearest neighbor search (ANNS) is a basic and important technique used in many tasks such as object recognition. It involves two processes: selecting nearest neighbor candidates and performing a brute-force search of these candidates. Only the former though has scope for improvement. In most existing methods, it approximates the space by quantization. It then calculates all the distances between the query and all the quantized values (e.g., clusters or bit sequences), and selects a fixed number of candidates close to the query. The performance of the method is evaluated based on accuracy as a function of the number of candidates. This evaluation seems rational but poses a serious problem; it ignores the computational cost of the process of selection. In this paper, we propose a new ANNS method that takes into account costs in the selection process. Whereas existing methods employ computationally expensive techniques such as comparative sort and heap, the proposed method does not. This realizes a significantly more efficient search. We have succeeded in reducing computation times by one-third compared with the state-of-the- art on an experiment using 100 million SIFT features.</p><p>2 0.78419334 <a title="450-lsi-2" href="./iccv-2013-Random_Grids%3A_Fast_Approximate_Nearest_Neighbors_and_Range_Searching_for_Image_Search.html">337 iccv-2013-Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search</a></p>
<p>Author: Dror Aiger, Efi Kokiopoulou, Ehud Rivlin</p><p>Abstract: We propose two solutions for both nearest neighbors and range search problems. For the nearest neighbors problem, we propose a c-approximate solutionfor the restricted version ofthe decisionproblem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descriptors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. Our algorithms are trivial to parallelize. In the experiments conducted, running on couple of million im- ages, our algorithms show meaningful speed-ups when compared with the above mentioned methods.</p><p>3 0.77725565 <a title="450-lsi-3" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>Author: Xu Wang, Stefan Atev, John Wright, Gilad Lerman</p><p>Abstract: The problem of efficiently deciding which of a database of models is most similar to a given input query arises throughout modern computer vision. Motivated by applications in recognition, image retrieval and optimization, there has been significant recent interest in the variant of this problem in which the database models are linear subspaces and the input is either a point or a subspace. Current approaches to this problem have poor scaling in high dimensions, and may not guarantee sublinear query complexity. We present a new approach to approximate nearest subspace search, based on a simple, new locality sensitive hash for subspaces. Our approach allows point-tosubspace query for a database of subspaces of arbitrary dimension d, in a time that depends sublinearly on the number of subspaces in the database. The query complexity of our algorithm is linear in the ambient dimension D, allow- ing it to be directly applied to high-dimensional imagery data. Numerical experiments on model problems in image repatching and automatic face recognition confirm the advantages of our algorithm in terms of both speed and accuracy.</p><p>4 0.77568817 <a title="450-lsi-4" href="./iccv-2013-Joint_Inverted_Indexing.html">221 iccv-2013-Joint Inverted Indexing</a></p>
<p>Author: Yan Xia, Kaiming He, Fang Wen, Jian Sun</p><p>Abstract: Inverted indexing is a popular non-exhaustive solution to large scale search. An inverted file is built by a quantizer such as k-means or a tree structure. It has been found that multiple inverted files, obtained by multiple independent random quantizers, are able to achieve practically good recall and speed. Instead of computing the multiple quantizers independently, we present a method that creates them jointly. Our method jointly optimizes all codewords in all quantizers. Then it assigns these codewords to the quantizers. In experiments this method shows significant improvement over various existing methods that use multiple independent quantizers. On the one-billion set of SIFT vectors, our method is faster and more accurate than a recent state-of-the-art inverted indexing method.</p><p>5 0.75374508 <a title="450-lsi-5" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>Author: Yannis Avrithis</p><p>Abstract: Inspired by the close relation between nearest neighbor search and clustering in high-dimensional spaces as well as the success of one helping to solve the other, we introduce a new paradigm where both problems are solved simultaneously. Our solution is recursive, not in the size of input data but in the number of dimensions. One result is a clustering algorithm that is tuned to small codebooks but does not need all data in memory at the same time and is practically constant in the data size. As a by-product, a tree structure performs either exact or approximate quantization on trained centroids, the latter being not very precise but extremely fast. A lesser contribution is a new indexing scheme for image retrieval that exploits multiple small codebooks to provide an arbitrarily fine partition of the descriptor space. Large scale experiments on public datasets exhibit state of the art performance and remarkable generalization.</p><p>6 0.75184608 <a title="450-lsi-6" href="./iccv-2013-Fast_Neighborhood_Graph_Search_Using_Cartesian_Concatenation.html">159 iccv-2013-Fast Neighborhood Graph Search Using Cartesian Concatenation</a></p>
<p>7 0.69440019 <a title="450-lsi-7" href="./iccv-2013-Stable_Hyper-pooling_and_Query_Expansion_for_Event_Detection.html">400 iccv-2013-Stable Hyper-pooling and Query Expansion for Event Detection</a></p>
<p>8 0.62888056 <a title="450-lsi-8" href="./iccv-2013-Complementary_Projection_Hashing.html">83 iccv-2013-Complementary Projection Hashing</a></p>
<p>9 0.61662501 <a title="450-lsi-9" href="./iccv-2013-Mining_Multiple_Queries_for_Image_Retrieval%3A_On-the-Fly_Learning_of_an_Object-Specific_Mid-level_Representation.html">266 iccv-2013-Mining Multiple Queries for Image Retrieval: On-the-Fly Learning of an Object-Specific Mid-level Representation</a></p>
<p>10 0.61382008 <a title="450-lsi-10" href="./iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</a></p>
<p>11 0.59054297 <a title="450-lsi-11" href="./iccv-2013-Offline_Mobile_Instance_Retrieval_with_a_Small_Memory_Footprint.html">294 iccv-2013-Offline Mobile Instance Retrieval with a Small Memory Footprint</a></p>
<p>12 0.57658422 <a title="450-lsi-12" href="./iccv-2013-To_Aggregate_or_Not_to_aggregate%3A_Selective_Match_Kernels_for_Image_Search.html">419 iccv-2013-To Aggregate or Not to aggregate: Selective Match Kernels for Image Search</a></p>
<p>13 0.57632601 <a title="450-lsi-13" href="./iccv-2013-Supervised_Binary_Hash_Code_Learning_with_Jensen_Shannon_Divergence.html">409 iccv-2013-Supervised Binary Hash Code Learning with Jensen Shannon Divergence</a></p>
<p>14 0.57268721 <a title="450-lsi-14" href="./iccv-2013-Learning_Hash_Codes_with_Listwise_Supervision.html">239 iccv-2013-Learning Hash Codes with Listwise Supervision</a></p>
<p>15 0.57046735 <a title="450-lsi-15" href="./iccv-2013-Neighbor-to-Neighbor_Search_for_Fast_Coding_of_Feature_Vectors.html">287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</a></p>
<p>16 0.54168397 <a title="450-lsi-16" href="./iccv-2013-Large-Scale_Video_Hashing_via_Structure_Learning.html">229 iccv-2013-Large-Scale Video Hashing via Structure Learning</a></p>
<p>17 0.53689259 <a title="450-lsi-17" href="./iccv-2013-Visual_Semantic_Complex_Network_for_Web_Images.html">446 iccv-2013-Visual Semantic Complex Network for Web Images</a></p>
<p>18 0.53315914 <a title="450-lsi-18" href="./iccv-2013-Semantic-Aware_Co-indexing_for_Image_Retrieval.html">378 iccv-2013-Semantic-Aware Co-indexing for Image Retrieval</a></p>
<p>19 0.50691199 <a title="450-lsi-19" href="./iccv-2013-A_General_Two-Step_Approach_to_Learning-Based_Hashing.html">13 iccv-2013-A General Two-Step Approach to Learning-Based Hashing</a></p>
<p>20 0.49744785 <a title="450-lsi-20" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.103), (7, 0.032), (12, 0.015), (13, 0.025), (26, 0.068), (27, 0.023), (31, 0.052), (42, 0.097), (64, 0.038), (73, 0.029), (74, 0.21), (78, 0.011), (89, 0.187), (98, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84778726 <a title="450-lda-1" href="./iccv-2013-Learning_Hash_Codes_with_Listwise_Supervision.html">239 iccv-2013-Learning Hash Codes with Listwise Supervision</a></p>
<p>Author: Jun Wang, Wei Liu, Andy X. Sun, Yu-Gang Jiang</p><p>Abstract: Hashing techniques have been intensively investigated in the design of highly efficient search engines for largescale computer vision applications. Compared with prior approximate nearest neighbor search approaches like treebased indexing, hashing-based search schemes have prominent advantages in terms of both storage and computational efficiencies. Moreover, the procedure of devising hash functions can be easily incorporated into sophisticated machine learning tools, leading to data-dependent and task-specific compact hash codes. Therefore, a number of learning paradigms, ranging from unsupervised to supervised, have been applied to compose appropriate hash functions. How- ever, most of the existing hash function learning methods either treat hash function design as a classification problem or generate binary codes to satisfy pairwise supervision, and have not yet directly optimized the search accuracy. In this paper, we propose to leverage listwise supervision into a principled hash function learning framework. In particular, the ranking information is represented by a set of rank triplets that can be used to assess the quality of ranking. Simple linear projection-based hash functions are solved efficiently through maximizing the ranking quality over the training data. We carry out experiments on large image datasets with size up to one million and compare with the state-of-the-art hashing techniques. The extensive results corroborate that our learned hash codes via listwise supervision can provide superior search accuracy without incurring heavy computational overhead.</p><p>same-paper 2 0.83811861 <a title="450-lda-2" href="./iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</a></p>
<p>Author: Masakazu Iwamura, Tomokazu Sato, Koichi Kise</p><p>Abstract: Approximate nearest neighbor search (ANNS) is a basic and important technique used in many tasks such as object recognition. It involves two processes: selecting nearest neighbor candidates and performing a brute-force search of these candidates. Only the former though has scope for improvement. In most existing methods, it approximates the space by quantization. It then calculates all the distances between the query and all the quantized values (e.g., clusters or bit sequences), and selects a fixed number of candidates close to the query. The performance of the method is evaluated based on accuracy as a function of the number of candidates. This evaluation seems rational but poses a serious problem; it ignores the computational cost of the process of selection. In this paper, we propose a new ANNS method that takes into account costs in the selection process. Whereas existing methods employ computationally expensive techniques such as comparative sort and heap, the proposed method does not. This realizes a significantly more efficient search. We have succeeded in reducing computation times by one-third compared with the state-of-the- art on an experiment using 100 million SIFT features.</p><p>3 0.81215602 <a title="450-lda-3" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>Author: Ross Girshick, Jitendra Malik</p><p>Abstract: In this paper, we show how to train a deformable part model (DPM) fast—typically in less than 20 minutes, or four times faster than the current fastest method—while maintaining high average precision on the PASCAL VOC datasets. At the core of our approach is “latent LDA,” a novel generalization of linear discriminant analysis for learning latent variable models. Unlike latent SVM, latent LDA uses efficient closed-form updates and does not require an expensive search for hard negative examples. Our approach also acts as a springboard for a detailed experimental study of DPM training. We isolate and quantify the impact of key training factors for the first time (e.g., How important are discriminative SVM filters? How important is joint parameter estimation? How many negative images are needed for training?). Our findings yield useful insights for researchers working with Markov random fields and partbased models, and have practical implications for speeding up tasks such as model selection.</p><p>4 0.81013453 <a title="450-lda-4" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>Author: Supreeth Achar, Stephen T. Nuske, Srinivasa G. Narasimhan</p><p>Abstract: Separating the direct and global components of radiance can aid shape recovery algorithms and can provide useful information about materials in a scene. Practical methods for finding the direct and global components use multiple images captured under varying illumination patterns and require the scene, light source and camera to remain stationary during the image acquisition process. In this paper, we develop a motion compensation method that relaxes this condition and allows direct-global separation to beperformed on video sequences of dynamic scenes captured by moving projector-camera systems. Key to our method is being able to register frames in a video sequence to each other in the presence of time varying, high frequency active illumination patterns. We compare our motion compensated method to alternatives such as single shot separation and frame interleaving as well as ground truth. We present results on challenging video sequences that include various types of motions and deformations in scenes that contain complex materials like fabric, skin, leaves and wax.</p><p>5 0.80492425 <a title="450-lda-5" href="./iccv-2013-Distributed_Low-Rank_Subspace_Segmentation.html">122 iccv-2013-Distributed Low-Rank Subspace Segmentation</a></p>
<p>Author: Ameet Talwalkar, Lester Mackey, Yadong Mu, Shih-Fu Chang, Michael I. Jordan</p><p>Abstract: Vision problems ranging from image clustering to motion segmentation to semi-supervised learning can naturally be framed as subspace segmentation problems, in which one aims to recover multiple low-dimensional subspaces from noisy and corrupted input data. Low-Rank Representation (LRR), a convex formulation of the subspace segmentation problem, is provably and empirically accurate on small problems but does not scale to the massive sizes of modern vision datasets. Moreover, past work aimed at scaling up low-rank matrix factorization is not applicable to LRR given its non-decomposable constraints. In this work, we propose a novel divide-and-conquer algorithm for large-scale subspace segmentation that can cope with LRR ’s non-decomposable constraints and maintains LRR ’s strong recovery guarantees. This has immediate implications for the scalability of subspace segmentation, which we demonstrate on a benchmark face recognition dataset and in simulations. We then introduce novel applications of LRR-based subspace segmentation to large-scale semisupervised learning for multimedia event detection, concept detection, and image tagging. In each case, we obtain stateof-the-art results and order-of-magnitude speed ups.</p><p>6 0.80482125 <a title="450-lda-6" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>7 0.75998008 <a title="450-lda-7" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>8 0.75970984 <a title="450-lda-8" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>9 0.75841963 <a title="450-lda-9" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>10 0.75743914 <a title="450-lda-10" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<p>11 0.75600016 <a title="450-lda-11" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>12 0.75484306 <a title="450-lda-12" href="./iccv-2013-Large-Scale_Video_Hashing_via_Structure_Learning.html">229 iccv-2013-Large-Scale Video Hashing via Structure Learning</a></p>
<p>13 0.75481892 <a title="450-lda-13" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>14 0.7533958 <a title="450-lda-14" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>15 0.75319839 <a title="450-lda-15" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>16 0.75274611 <a title="450-lda-16" href="./iccv-2013-PhotoOCR%3A_Reading_Text_in_Uncontrolled_Conditions.html">315 iccv-2013-PhotoOCR: Reading Text in Uncontrolled Conditions</a></p>
<p>17 0.75237763 <a title="450-lda-17" href="./iccv-2013-Video_Synopsis_by_Heterogeneous_Multi-source_Correlation.html">443 iccv-2013-Video Synopsis by Heterogeneous Multi-source Correlation</a></p>
<p>18 0.75209081 <a title="450-lda-18" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>19 0.75207394 <a title="450-lda-19" href="./iccv-2013-Style-Aware_Mid-level_Representation_for_Discovering_Visual_Connections_in_Space_and_Time.html">406 iccv-2013-Style-Aware Mid-level Representation for Discovering Visual Connections in Space and Time</a></p>
<p>20 0.75179207 <a title="450-lda-20" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
