<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-196" href="#">iccv2013-196</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</h1>
<br/><p>Source: <a title="iccv-2013-196-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Tian_Hierarchical_Data-Driven_Descent_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>Reference: <a title="iccv-2013-196-reference" href="../iccv2013_reference/iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. [sent-5, score-1.261]
</p><p>2 The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees. [sent-8, score-0.622]
</p><p>3 However, estimating the parameters of nonrigid deformation is hard due to its high-dimensionality and strong nonconvexity. [sent-11, score-0.531]
</p><p>4 They show that if a generative model for deformation is available, then the training samples can be generated by simply deforming the template using parameters from a particular distribuSrinivasa G. [sent-18, score-0.852]
</p><p>5 Our hierarchical framework for deformation estimation achieves O(C1d + C2 log 1/? [sent-29, score-0.575]
</p><p>6 A constant number of samples per iteration is needed in [17]. [sent-32, score-0.259]
</p><p>7 The number of samples needed is a constant for the first few iterations, and then decays double exponentially for our algorithm. [sent-33, score-0.303]
</p><p>8 Intuitively, this approach captures the group-like structure in deformation and uses the train-  O(Cd  ing samples which are far away from the test image for prediction. [sent-40, score-0.623]
</p><p>9 Their approach shows good empirical results for local deformation, but fails to capture general deformation that contains both global and local components (e. [sent-41, score-0.505]
</p><p>10 In this paper, we develop a top-down hierarchical structure for deformation estimation with global optimality guarantee. [sent-44, score-0.634]
</p><p>11 First, the deformation field is parameterized so that the deformation happening within a local image patch can be predicted by the content of that patch, reducing the dimensionality. [sent-45, score-1.087]
</p><p>12 Then, we model the relationship between the image content and the deformation parameters using a novel criterion. [sent-46, score-0.472]
</p><p>13 With this criterion, all patches at different locations and scales can be regarded as predictors with guaranteed worst-case precisions. [sent-47, score-0.16]
</p><p>14 Finally, combining these predic22228888  tors together in a top-down hierarchical manner leads to an overall predictor that can handle large and high-dimensional deformation with both local and global components. [sent-48, score-0.572]
</p><p>15 In particular, the number of samples required in each iteration stays constant for the first few iterations (layers of hierarchy), and then decays double exponentially (Fig. [sent-52, score-0.262]
</p><p>16 Our work not only has strong theoretical foundations, but also demonstrates good quantitative and qualitative results on real video sequences containing different types of deformation, including clothing and water surface deformations as well as medical images of internal organs. [sent-59, score-0.333]
</p><p>17 Regression-based approaches aim to learn a mapping from the distorted image to the deformation parameters using labeled training samples. [sent-66, score-0.705]
</p><p>18 (a)-(b) The deformation field is controlled by a set of landmarks on the template image. [sent-115, score-0.777]
</p><p>19 The Image Deformation Model  Denote T as the template image and Ip as the distorted image with deformation parameters p. [sent-121, score-0.794]
</p><p>20 The deformation field W(x; p) maps the pixel location x on the template to the pixel location W(x; p) on the distorted image Ip: Ip(W(x; p)) = T(x)  (1)  We locally parameterize the deformation field W(x; p) at any 2D point x by a weighted linear combination of displacements p = [p(1) , p(2) , . [sent-122, score-1.422]
</p><p>21 , bK (x)] is a Kdimensional row vector of weighting factors on location x from K landmarks, p is a K-by-2 matrix storing 2K displacement components and p(i) is a 2-dimensional deformation vector for landmark i. [sent-129, score-0.613]
</p><p>22 Due to strong correlations between nearby landmark displacements, the dimensionality d of the warping field could be much lower than 2K. [sent-130, score-0.179]
</p><p>23 2 is an over-parameterization of the deformation field W(x; p),  which leads to further reduction of training samples needed. [sent-140, score-0.71]
</p><p>24 1, given the parameter p, one can generate the deformed image Ip from the template T. [sent-143, score-0.248]
</p><p>25 This is done by assigning every pixel y of the deformed image Ip with the pixel value on location x = W−1 (y; p) of the template T. [sent-144, score-0.214]
</p><p>26 Choosing different parameters {pi} gives many training samples {(pi , Ipi ) }. [sent-145, score-0.244]
</p><p>27 , sam22228899  ple complexity) to achieve the globally optimal prediction of the unknown parameter for a distorted test image. [sent-149, score-0.386]
</p><p>28 The Relationship between Image Evidence and Distortion Parameters Suppose we have training samples {p, Ip} and want to predict tohsee parameter rfaoirn a gte ssta image {Ip w,Iith} an dun wkannotw ton true parameter p1. [sent-152, score-0.262]
</p><p>29 This can be represented by the following Lipchitz conditions proposed in [17]: L1ΔI ≤ Δp ≤ L2ΔI  (3)  where, L1 and L2 are two constants that are dependent on the template T. [sent-156, score-0.166]
</p><p>30 [17] shows that the ratio L2/L1 is a charactistic for samples complexity for guaranteed Nearest Neighbor prediction. [sent-157, score-0.268]
</p><p>31 For simple images that contain one salient object with a clear background, L2/L1 is small and a few samples suffice. [sent-158, score-0.151]
</p><p>32 For difficult images with repetitive patterns, L2/L1 is large and a lot of samples are needed to distinguish among locally similar-looking structures. [sent-159, score-0.351]
</p><p>33 Adding noise to a distorted image Ip changes iatsg appearance nb uoti neo tto i tas parameters. [sent-165, score-0.19]
</p><p>34 In both cases, [17] gives a trivial (infinite) bound on sample complexity and global optimality cannot be guaranteed. [sent-172, score-0.228]
</p><p>35 I(R) is the patch within R and S = S(x, r) is the subset of landmarks whose displacements p(S) influence the patch content I(R). [sent-175, score-0.395]
</p><p>36 4 holds only for deformation within the acceptance range r, i. [sent-226, score-0.528]
</p><p>37 image ciso nate pnrta cIt(icRa)l is no longer related to the local patch deformation p(S). [sent-232, score-0.571]
</p><p>38 Therefore, we assume:  Assumption 2 (Degrees of Freedom for Patches) The local degrees of freedom of a patch (x, r) is min(d, 2|S|). [sent-242, score-0.222]
</p><p>39 Guaranteed Prediction using Nearest Neighbor Now let us study how the relaxed Lipchitz condition helps Nearest Neighbor prediction. [sent-245, score-0.149]
</p><p>40 We wish to know how well patch (x, r) can predict the deformation p(S) within its acceptance range r (i. [sent-246, score-0.627]
</p><p>41 Without any training samples, we can trivially s||et th≤e prediction tˆp a(nSy) =ai 0and get a worst-case guaranteed prediction error of r. [sent-249, score-0.355]
</p><p>42 Now the problem is: if we want to obtain a slightly better prediction, how many training samples do we need? [sent-250, score-0.194]
</p><p>43 It shows that if the relaxed Lipchitz condition (Eqn. [sent-252, score-0.149]
</p><p>44 4) holds, then a Nearest Neighbor prediction with 1/α samples per dimension will always reduce the error by a factor of γ < 1: Theorem 1(Guaranteed Nearest Neighbor) Given a distorted image Ip with |p||∞ ≤ r, then with N(x,r) = min  ? [sent-253, score-0.462]
</p><p>45 (5)  number of samples uniformly distributed in the hypercube [−r, r]2|S|, we can compute a prediction ˆ p(S) so that | pˆ(S) − p(S)|| ≤ γr  (6)  using Nearest Neighbor in the region R with image metric. [sent-259, score-0.321]
</p><p>46 Proof Sketch We first fill the 2|S|-dimensional hypercPurobeo f[− Srk,e rt]c2h|S| W weith fi r(s1t/α fil)l2|S th| training samples uniformly. [sent-260, score-0.194]
</p><p>47 If the local deformation is d-dimensional with d < 2|S| , thenIf i t h etu lrnosc olu dte tfhoartm only a ssm d-aldli mfreacntsiioonn aolf wthiteh hypercube are sampled and css ? [sent-272, score-0.58]
</p><p>48 6, now both α and γ have their physical meanings: α is the inverse of sample complexity per dimension, while γ is the inverse of prediction accuracy. [sent-281, score-0.204]
</p><p>49 3, this trade-off reflects the difficulty level of images for deformation prediction (See Sec. [sent-285, score-0.593]
</p><p>50 Within the same layer t, scale of patches is fixed and denoted as rt. [sent-291, score-0.156]
</p><p>51 1:INPUT Training samples Tr(x,r) ≡ {(pi,Ii)} for 2: 3: 4: 5:  eIaNcPhU UimTa gTera pinaitcnhg ( sxa,m mrp). [sent-294, score-0.151]
</p><p>52 6: 7: 8: 9: 10: 11: 12: 13: 14:  for Patch (xj , rt) within layer t do Sj = S(xj , rt), Rj = R(xj , rt) Find the Nearest Neighbor i∗ for patch I(Rj) : i∗ = arg mini∈Tr(x,r) |Ic(Rj ) − Ii (Rj ) | Set the estimation ˜ pj→i (Sj) =) pi∗ (Sj). [sent-298, score-0.21]
</p><p>53 For the first iteration, the test image Itest is directly compared with the training samples generated from the entire image with scale r1 to obtain the Nearest Neighbor prediction pˆ1 . [sent-305, score-0.315]
</p><p>54 Then for the second iteration, we have a slightly less distorted image Itest (W(x, pˆ1 )), from which we estimate p − pˆ1 . [sent-306, score-0.19]
</p><p>55 1will converge to the globally optimal solution (Theorem 2), while the required number of samples is O(C1d + C2 log 1/? [sent-310, score-0.228]
</p><p>56 Note that a less distorted image Itest (W(x; pˆt−1)), as the input of layer t, is not necessarily the same as a distorted image Ip− pˆt−1 generated directly from the template image. [sent-312, score-0.623]
</p><p>57 Work flow of our hierarchical algorithm for deformation estimation. [sent-367, score-0.539]
</p><p>58 On Layer 1, a global prediction is made and the estimation is updated. [sent-368, score-0.154]
</p><p>59 On Layer 2, local deformation is estimated and aggregated. [sent-369, score-0.472]
</p><p>60 givenby[Tian dNar simhan,IJCV2012] [N1=16, N2=30]  [N1=15, N2=24]  [N1=14, N2=41 ]  [N1=14, N2=40]  [N1=13, N2=41 ]  [N1=13, N2=45]  [N1=12, N2=40]  (b) Hard Images for deformation estimation. [sent-376, score-0.472]
</p><p>61 Exemplar images and the theoretical bounds for the number of samples needed per dimension. [sent-378, score-0.259]
</p><p>62 Top Row: Images with a salient object and clean background require only a few samples per dimension. [sent-382, score-0.151]
</p><p>63 Bottom Row: Images with repetitive patterns require more samples per dimension. [sent-383, score-0.323]
</p><p>64 Proof Sketch From Theorem 1, from the top layer, after each layer the residue is contracted by at least γ¯. [sent-385, score-0.155]
</p><p>65 Theorem 3 (The Number of Samples Needed) The total number N of samples needed is bounded by: N ≤ C3C1d + C2 log1/ ¯γ 1/? [sent-387, score-0.225]
</p><p>66 Twheellre afsor |Se,| ,t dhee nrueamsbee bry o af samples ¯γ needed stays the same until 2|S| ≈ d, and then goes down double-exponentially. [sent-392, score-0.297]
</p><p>67 uTnhteilor 2e|Sm| |1 gives nthde tnheumngb oere osf d samples batl any pleonveeln otiaf tlhlye. [sent-393, score-0.201]
</p><p>68 The supplementary report [16] shows that the summation of the samples at all levels is a fast decaying series bounded by Eqn. [sent-395, score-0.151]
</p><p>69 Empirical Upper Bounds For Images Given a spectific template and a specific family of deformation, we can generate many deformed images and their parameters (pi, Ipi ), compute all-pair image/parameter distances {Δpi , ΔIi} and estimate the monotonous curve γ = tγa(nαce) sli {keΔ Fig. [sent-398, score-0.308]
</p><p>70 T}h aisn curve can help predict tohues t chuerovree tγic=a l difficulties of images for deformation estimation. [sent-400, score-0.506]
</p><p>71 We randomly generate 1000 deformed samples and compute all-pair distances. [sent-408, score-0.233]
</p><p>72 The deformation is 2D translation and in-plane rotation (d = 3) up to ±π/8. [sent-409, score-0.472]
</p><p>73 Note that images with a salient object and uniform background requires fewer samples, while images with repetitive patterns and  cluttered backgrounds require more. [sent-415, score-0.172]
</p><p>74 To obtain the same level of accuracy of our approach with 400 samples, [17] requires 10000 samples or more. [sent-463, score-0.151]
</p><p>75 For all the experiments, our approach adopts a hierarchical structure using a grid of 256 landmarks with ¯γ = 0. [sent-468, score-0.196]
</p><p>76 While our theory gives an upper bound of the sample complexity, practically 350 training samples over all layers suffice for good performance. [sent-471, score-0.428]
</p><p>77 Convergence Behavior We artificially distorted 100 images with a 20dimensional global warping field specified in [17]. [sent-474, score-0.302]
</p><p>78 For each  image, its 10 distorted versions are generated with random parameters, which are estimated using Data-driven Descent (TN) [17] and using our approach. [sent-475, score-0.19]
</p><p>79 Note that the strong drop in error shows that our method achieves very high accuracy by adding very few samples once it starts to work. [sent-479, score-0.151]
</p><p>80 Deformation Estimation on Repetitive Patterns We further test our approach on synthetic data containing distorted repetitive patterns, and compare it with previ$? [sent-484, score-0.316]
</p><p>81 Starting from initialization, the algorithm applies predictors of different layers to estimate the landmark locations. [sent-528, score-0.238]
</p><p>82 From an undistorted template (240-by-240), we generate a dataset of 200 distorted images, each with labeled 49 points. [sent-531, score-0.322]
</p><p>83 The deformation field is created by random  Gaussian noise without temporal continuity. [sent-532, score-0.516]
</p><p>84 The overall degree of freedom for this dataset is very high (50 dimensions are needed to achieve < 1pixel reconstruction error). [sent-533, score-0.149]
</p><p>85 It is in general impossible to have sufficient number of samples for global optimality conditions to be satisfied. [sent-534, score-0.246]
</p><p>86 LK and TN use a local parametric deformation model. [sent-537, score-0.472]
</p><p>87 LK, FF and TN compute dense deformations and our hierarchy outputs 256 predicted landmarks, from which 49 landmark locations are interpolated. [sent-539, score-0.194]
</p><p>88 Due to repetitive patterns, previous approaches fail to estimate the landmarks correctly. [sent-546, score-0.255]
</p><p>89 The prediction of ESR is restricted to be on the linear shape subspace spanned by the training samples. [sent-548, score-0.164]
</p><p>90 Thus, it is insufficient to use the template to capture the subspace of a complex deformation field. [sent-549, score-0.604]
</p><p>91 When more layers are switched off, the algorithm is unable to identify global deformation and is essentially the same as local template matching at each landmark. [sent-611, score-0.771]
</p><p>92 Performance on synthetic data if the first L layer of predictors are switched off, showing the bottom layers play a critical role for performance. [sent-632, score-0.29]
</p><p>93 8 demonstrates how prediction from coarse layers (large patch) help the lower layer (small patch) find correct correspondences in repetitive patterns, justifying the hierarchy. [sent-635, score-0.451]
</p><p>94 Real Experiments We also apply our framework to real world scenarios such as water distortion, cloth deformation and registration of medical images. [sent-637, score-0.851]
</p><p>95 We captured the cloth sequence in the 5th row of Fig. [sent-650, score-0.199]
</p><p>96 10, we use temporal information by adding training samples generated from perturbing the final estimation of the previous frame. [sent-654, score-0.194]
</p><p>97 In comparison, SIFT+RANSAC only obtains a sparse set of distinctive matches, not enough for estimating a nonrigid deformation (even if we are using Thin-Plate Spline). [sent-660, score-0.531]
</p><p>98 TN can capture detailed local deformations but not global shifts of the cloth without modeling the relationship between local patches. [sent-661, score-0.246]
</p><p>99 Each  row is a video sequence, two from underwater imaging, two from cloth deformation and the final one is from medical imaging. [sent-826, score-0.803]
</p><p>100 Eachrowisa video, two from cloth deformation and one from underwater imaging. [sent-832, score-0.674]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('deformation', 0.472), ('lipchitz', 0.239), ('distorted', 0.19), ('cloth', 0.158), ('samples', 0.151), ('itest', 0.149), ('tn', 0.144), ('template', 0.132), ('landmarks', 0.129), ('ip', 0.126), ('repetitive', 0.126), ('prediction', 0.121), ('neighbor', 0.12), ('theorem', 0.113), ('layer', 0.111), ('lk', 0.108), ('landmark', 0.1), ('patch', 0.099), ('ff', 0.099), ('layers', 0.093), ('nearest', 0.091), ('descent', 0.089), ('rms', 0.089), ('medical', 0.088), ('deformed', 0.082), ('condition', 0.081), ('rt', 0.08), ('esr', 0.079), ('pi', 0.077), ('klt', 0.077), ('water', 0.076), ('tian', 0.076), ('freedom', 0.075), ('needed', 0.074), ('guaranteed', 0.07), ('displacements', 0.068), ('relaxed', 0.068), ('hierarchical', 0.067), ('datadriven', 0.066), ('sj', 0.065), ('optimality', 0.062), ('monotonous', 0.06), ('rdim', 0.06), ('samplep', 0.06), ('yuandong', 0.06), ('css', 0.059), ('nonrigid', 0.059), ('registration', 0.057), ('rj', 0.057), ('acceptance', 0.056), ('deformations', 0.055), ('practically', 0.055), ('spline', 0.054), ('deforming', 0.054), ('forbes', 0.053), ('ransac', 0.051), ('gives', 0.05), ('hypercube', 0.049), ('degrees', 0.048), ('complexity', 0.047), ('sketch', 0.046), ('ipi', 0.046), ('clothing', 0.046), ('patterns', 0.046), ('ic', 0.045), ('predictors', 0.045), ('patches', 0.045), ('decays', 0.044), ('residue', 0.044), ('underwater', 0.044), ('field', 0.044), ('training', 0.043), ('row', 0.041), ('globally', 0.041), ('sift', 0.041), ('switched', 0.041), ('cmu', 0.04), ('predictions', 0.039), ('ave', 0.039), ('hierarchy', 0.039), ('contour', 0.039), ('af', 0.039), ('salzmann', 0.038), ('narasimhan', 0.038), ('mini', 0.037), ('pittsburgh', 0.037), ('sample', 0.036), ('says', 0.036), ('log', 0.036), ('bases', 0.035), ('warping', 0.035), ('constant', 0.034), ('sequences', 0.034), ('theoretical', 0.034), ('constants', 0.034), ('parameter', 0.034), ('curve', 0.034), ('global', 0.033), ('estimators', 0.033), ('stays', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999928 <a title="196-tfidf-1" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>2 0.23187597 <a title="196-tfidf-2" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>Author: Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Feature extraction, deformation handling, occlusion handling, and classi?cation are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture1. By establishing automatic, mutual interaction among components, the deep model achieves a 9% reduction in the average miss rate compared with the current best-performing pedestrian detection approaches on the largest Caltech benchmark dataset.</p><p>3 0.19497454 <a title="196-tfidf-3" href="./iccv-2013-A_Generic_Deformation_Model_for_Dense_Non-rigid_Surface_Registration%3A_A_Higher-Order_MRF-Based_Approach.html">16 iccv-2013-A Generic Deformation Model for Dense Non-rigid Surface Registration: A Higher-Order MRF-Based Approach</a></p>
<p>Author: Yun Zeng, Chaohui Wang, Xianfeng Gu, Dimitris Samaras, Nikos Paragios</p><p>Abstract: We propose a novel approach for dense non-rigid 3D surface registration, which brings together Riemannian geometry and graphical models. To this end, we first introduce a generic deformation model, called Canonical Distortion Coefficients (CDCs), by characterizing the deformation of every point on a surface using the distortions along its two principle directions. This model subsumes the deformation groups commonly used in surface registration such as isometry and conformality, and is able to handle more complex deformations. We also derive its discrete counterpart which can be computed very efficiently in a closed form. Based on these, we introduce a higher-order Markov Random Field (MRF) model which seamlessly integrates our deformation model and a geometry/texture similarity metric. Then we jointly establish the optimal correspondences for all the points via maximum a posteriori (MAP) inference. Moreover, we develop a parallel optimization algorithm to efficiently perform the inference for the proposed higher-order MRF model. The resulting registration algorithm outperforms state-of-the-art methods in both dense non-rigid 3D surface registration and tracking.</p><p>4 0.17039528 <a title="196-tfidf-4" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>5 0.16336571 <a title="196-tfidf-5" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>Author: Yen-Lin Chen, Hsiang-Tao Wu, Fuhao Shi, Xin Tong, Jinxiang Chai</p><p>Abstract: This paper presents an automatic and robust approach that accurately captures high-quality 3D facial performances using a single RGBD camera. The key of our approach is to combine the power of automatic facial feature detection and image-based 3D nonrigid registration techniques for 3D facial reconstruction. In particular, we develop a robust and accurate image-based nonrigid registration algorithm that incrementally deforms a 3D template mesh model to best match observed depth image data and important facial features detected from single RGBD images. The whole process is fully automatic and robust because it is based on single frame facial registration framework. The system is flexible because it does not require any strong 3D facial priors such as blendshape models. We demonstrate the power of our approach by capturing a wide range of 3D facial expressions using a single RGBD camera and achieve state-of-the-art accuracy by comparing against alternative methods.</p><p>6 0.14697737 <a title="196-tfidf-6" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>7 0.13546814 <a title="196-tfidf-7" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>8 0.1254254 <a title="196-tfidf-8" href="./iccv-2013-Cascaded_Shape_Space_Pruning_for_Robust_Facial_Landmark_Detection.html">70 iccv-2013-Cascaded Shape Space Pruning for Robust Facial Landmark Detection</a></p>
<p>9 0.1217397 <a title="196-tfidf-9" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>10 0.11104446 <a title="196-tfidf-10" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>11 0.10732624 <a title="196-tfidf-11" href="./iccv-2013-Geometric_Registration_Based_on_Distortion_Estimation.html">183 iccv-2013-Geometric Registration Based on Distortion Estimation</a></p>
<p>12 0.10343806 <a title="196-tfidf-12" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>13 0.10238176 <a title="196-tfidf-13" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>14 0.094930477 <a title="196-tfidf-14" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>15 0.091994412 <a title="196-tfidf-15" href="./iccv-2013-Discriminatively_Trained_Templates_for_3D_Object_Detection%3A_A_Real_Time_Scalable_Approach.html">121 iccv-2013-Discriminatively Trained Templates for 3D Object Detection: A Real Time Scalable Approach</a></p>
<p>16 0.088523567 <a title="196-tfidf-16" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>17 0.08705166 <a title="196-tfidf-17" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>18 0.086531527 <a title="196-tfidf-18" href="./iccv-2013-Elastic_Fragments_for_Dense_Scene_Reconstruction.html">139 iccv-2013-Elastic Fragments for Dense Scene Reconstruction</a></p>
<p>19 0.084346093 <a title="196-tfidf-19" href="./iccv-2013-Parallel_Transport_of_Deformations_in_Shape_Space_of_Elastic_Surfaces.html">307 iccv-2013-Parallel Transport of Deformations in Shape Space of Elastic Surfaces</a></p>
<p>20 0.083549991 <a title="196-tfidf-20" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.233), (1, -0.068), (2, -0.057), (3, -0.039), (4, -0.029), (5, -0.027), (6, 0.061), (7, 0.019), (8, -0.02), (9, -0.052), (10, -0.066), (11, 0.043), (12, 0.041), (13, 0.022), (14, 0.093), (15, 0.048), (16, 0.085), (17, 0.086), (18, 0.077), (19, -0.036), (20, 0.044), (21, 0.081), (22, -0.01), (23, 0.077), (24, -0.13), (25, -0.084), (26, 0.07), (27, 0.11), (28, -0.094), (29, 0.024), (30, -0.022), (31, -0.078), (32, 0.111), (33, 0.035), (34, 0.149), (35, -0.021), (36, -0.1), (37, 0.053), (38, 0.117), (39, -0.03), (40, 0.006), (41, 0.03), (42, 0.035), (43, -0.115), (44, -0.005), (45, -0.035), (46, 0.09), (47, -0.025), (48, 0.062), (49, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93941307 <a title="196-lsi-1" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>2 0.76849222 <a title="196-lsi-2" href="./iccv-2013-A_Generic_Deformation_Model_for_Dense_Non-rigid_Surface_Registration%3A_A_Higher-Order_MRF-Based_Approach.html">16 iccv-2013-A Generic Deformation Model for Dense Non-rigid Surface Registration: A Higher-Order MRF-Based Approach</a></p>
<p>Author: Yun Zeng, Chaohui Wang, Xianfeng Gu, Dimitris Samaras, Nikos Paragios</p><p>Abstract: We propose a novel approach for dense non-rigid 3D surface registration, which brings together Riemannian geometry and graphical models. To this end, we first introduce a generic deformation model, called Canonical Distortion Coefficients (CDCs), by characterizing the deformation of every point on a surface using the distortions along its two principle directions. This model subsumes the deformation groups commonly used in surface registration such as isometry and conformality, and is able to handle more complex deformations. We also derive its discrete counterpart which can be computed very efficiently in a closed form. Based on these, we introduce a higher-order Markov Random Field (MRF) model which seamlessly integrates our deformation model and a geometry/texture similarity metric. Then we jointly establish the optimal correspondences for all the points via maximum a posteriori (MAP) inference. Moreover, we develop a parallel optimization algorithm to efficiently perform the inference for the proposed higher-order MRF model. The resulting registration algorithm outperforms state-of-the-art methods in both dense non-rigid 3D surface registration and tracking.</p><p>3 0.70911038 <a title="196-lsi-3" href="./iccv-2013-Geometric_Registration_Based_on_Distortion_Estimation.html">183 iccv-2013-Geometric Registration Based on Distortion Estimation</a></p>
<p>Author: Wei Zeng, Mayank Goswami, Feng Luo, Xianfeng Gu</p><p>Abstract: Surface registration plays a fundamental role in many applications in computer vision and aims at finding a oneto-one correspondence between surfaces. Conformal mapping based surface registration methods conformally map 2D/3D surfaces onto 2D canonical domains and perform the matching on the 2D plane. This registration framework reduces dimensionality, and the result is intrinsic to Riemannian metric and invariant under isometric deformation. However, conformal mapping will be affected by inconsistent boundaries and non-isometric deformations of surfaces. In this work, we quantify the effects of boundary variation and non-isometric deformation to conformal mappings, and give the theoretical upper bounds for the distortions of conformal mappings under these two factors. Besides giving the thorough theoretical proofs of the theorems, we verified them by concrete experiments using 3D human facial scans with dynamic expressions and varying boundaries. Furthermore, we used the distortion estimates for reducing search range in feature matching of surface registration applications. The experimental results are consistent with the theoreticalpredictions and also demonstrate the performance improvements in feature tracking.</p><p>4 0.67745847 <a title="196-lsi-4" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>5 0.5996232 <a title="196-lsi-5" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>Author: Wanli Ouyang, Xiaogang Wang</p><p>Abstract: Feature extraction, deformation handling, occlusion handling, and classi?cation are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture1. By establishing automatic, mutual interaction among components, the deep model achieves a 9% reduction in the average miss rate compared with the current best-performing pedestrian detection approaches on the largest Caltech benchmark dataset.</p><p>6 0.59714973 <a title="196-lsi-6" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>7 0.55863065 <a title="196-lsi-7" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>8 0.53643012 <a title="196-lsi-8" href="./iccv-2013-Parallel_Transport_of_Deformations_in_Shape_Space_of_Elastic_Surfaces.html">307 iccv-2013-Parallel Transport of Deformations in Shape Space of Elastic Surfaces</a></p>
<p>9 0.51029342 <a title="196-lsi-9" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>10 0.50386894 <a title="196-lsi-10" href="./iccv-2013-Elastic_Fragments_for_Dense_Scene_Reconstruction.html">139 iccv-2013-Elastic Fragments for Dense Scene Reconstruction</a></p>
<p>11 0.49796095 <a title="196-lsi-11" href="./iccv-2013-Automatic_Registration_of_RGB-D_Scans_via_Salient_Directions.html">56 iccv-2013-Automatic Registration of RGB-D Scans via Salient Directions</a></p>
<p>12 0.49235401 <a title="196-lsi-12" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>13 0.48883358 <a title="196-lsi-13" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>14 0.46094164 <a title="196-lsi-14" href="./iccv-2013-Person_Re-identification_by_Salience_Matching.html">313 iccv-2013-Person Re-identification by Salience Matching</a></p>
<p>15 0.46049011 <a title="196-lsi-15" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>16 0.44374269 <a title="196-lsi-16" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>17 0.4367505 <a title="196-lsi-17" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>18 0.43394744 <a title="196-lsi-18" href="./iccv-2013-Pedestrian_Parsing_via_Deep_Decompositional_Network.html">311 iccv-2013-Pedestrian Parsing via Deep Decompositional Network</a></p>
<p>19 0.42986324 <a title="196-lsi-19" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>20 0.42512625 <a title="196-lsi-20" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.047), (7, 0.018), (26, 0.115), (31, 0.065), (33, 0.043), (34, 0.017), (35, 0.01), (40, 0.011), (42, 0.113), (48, 0.013), (64, 0.054), (66, 0.013), (73, 0.09), (89, 0.199), (93, 0.01), (98, 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96019846 <a title="196-lda-1" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>2 0.94969708 <a title="196-lda-2" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>3 0.94836724 <a title="196-lda-3" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><p>4 0.94739902 <a title="196-lda-4" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>Author: Chih-Yuan Yang, Ming-Hsuan Yang</p><p>Abstract: The goal of single-image super-resolution is to generate a high-quality high-resolution image based on a given low-resolution input. It is an ill-posed problem which requires exemplars or priors to better reconstruct the missing high-resolution image details. In this paper, we propose to split the feature space into numerous subspaces and collect exemplars to learn priors for each subspace, thereby creating effective mapping functions. The use of split input space facilitates both feasibility of using simple functionsfor super-resolution, and efficiency ofgenerating highresolution results. High-quality high-resolution images are reconstructed based on the effective learned priors. Experimental results demonstrate that theproposed algorithmperforms efficiently and effectively over state-of-the-art methods.</p><p>5 0.94337147 <a title="196-lda-5" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>Author: Xiangfei Kong, Kuan Li, Qingxiong Yang, Liu Wenyin, Ming-Hsuan Yang</p><p>Abstract: This paper proposes a new non-reference image quality metric that can be adopted by the state-of-the-art image/video denoising algorithms for auto-denoising. The proposed metric is extremely simple and can be implemented in four lines of Matlab code1. The basic assumption employed by the proposed metric is that the noise should be independent of the original image. A direct measurement of this dependence is, however, impractical due to the relatively low accuracy of existing denoising method. The proposed metric thus aims at maximizing the structure similarity between the input noisy image and the estimated image noise around homogeneous regions and the structure similarity between the input noisy image and the denoised image around highly-structured regions, and is computed as the linear correlation coefficient of the two corresponding structure similarity maps. Numerous experimental results demonstrate that the proposed metric not only outperforms the current state-of-the-art non-reference quality metric quantitatively and qualitatively, but also better maintains temporal coherence when used for video denoising. ˜</p><p>6 0.9397856 <a title="196-lda-6" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>7 0.93887675 <a title="196-lda-7" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>8 0.93811667 <a title="196-lda-8" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>9 0.93802285 <a title="196-lda-9" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>10 0.93788522 <a title="196-lda-10" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>11 0.93749958 <a title="196-lda-11" href="./iccv-2013-Collaborative_Active_Learning_of_a_Kernel_Machine_Ensemble_for_Recognition.html">80 iccv-2013-Collaborative Active Learning of a Kernel Machine Ensemble for Recognition</a></p>
<p>12 0.93744302 <a title="196-lda-12" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>13 0.93645436 <a title="196-lda-13" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>14 0.93624282 <a title="196-lda-14" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>15 0.93575197 <a title="196-lda-15" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>16 0.93550289 <a title="196-lda-16" href="./iccv-2013-Progressive_Multigrid_Eigensolvers_for_Multiscale_Spectral_Segmentation.html">329 iccv-2013-Progressive Multigrid Eigensolvers for Multiscale Spectral Segmentation</a></p>
<p>17 0.93505144 <a title="196-lda-17" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>18 0.93382496 <a title="196-lda-18" href="./iccv-2013-Exploiting_Reflection_Change_for_Automatic_Reflection_Removal.html">151 iccv-2013-Exploiting Reflection Change for Automatic Reflection Removal</a></p>
<p>19 0.93325847 <a title="196-lda-19" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>20 0.9316566 <a title="196-lda-20" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
