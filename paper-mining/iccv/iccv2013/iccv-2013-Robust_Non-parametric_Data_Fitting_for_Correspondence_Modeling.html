<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-358" href="#">iccv2013-358</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</h1>
<br/><p>Source: <a title="iccv-2013-358-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Lin_Robust_Non-parametric_Data_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Wen-Yan Lin, Ming-Ming Cheng, Shuai Zheng, Jiangbo Lu, Nigel Crook</p><p>Abstract: We propose a generic method for obtaining nonparametric image warps from noisy point correspondences. Our formulation integrates a huber function into a motion coherence framework. This makes our fitting function especially robust to piecewise correspondence noise (where an image section is consistently mismatched). By utilizing over parameterized curves, we can generate realistic nonparametric image warps from very noisy correspondence. We also demonstrate how our algorithm can be used to help stitch images taken from a panning camera by warping the images onto a virtual push-broom camera imaging plane.</p><p>Reference: <a title="iccv-2013-358-reference" href="../iccv2013_reference/iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Our formulation integrates a huber function into a motion coherence framework. [sent-2, score-0.489]
</p><p>2 This makes our fitting function especially robust to piecewise correspondence noise (where an image section is consistently mismatched). [sent-3, score-0.87]
</p><p>3 By utilizing over parameterized curves, we can generate realistic nonparametric image warps from very noisy correspondence. [sent-4, score-0.455]
</p><p>4 We also demonstrate how our algorithm can be used to help stitch images taken from a panning camera by warping the images onto a virtual push-broom camera imaging plane. [sent-5, score-0.468]
</p><p>5 Introduction Fitting a warp or transformation field onto an image section is a long standing computer vision and graphics problem and lies at the heart of many novel image synthesis algorithms. [sent-7, score-0.192]
</p><p>6 While there are many techniques for establishing correspondence between images [24, 23, 13], converting them into a coherent warp remains a significant problem. [sent-8, score-0.451]
</p><p>7 For specific applications or correspondence types, there  have been many proposals regarding how outlying correspondence can be removed [3 1] or correspondence jointly estimated with the warp [21]. [sent-9, score-0.86]
</p><p>8 What is lacking is a generic, computationally simple method to robustly establish a nonparametric warp from noisy correspondence. [sent-10, score-0.424]
</p><p>9 To date the most commonly used generic techniques for fitting warps to correspondences take the form of rigid affine or homographic transforms. [sent-11, score-0.914]
</p><p>10 These warps are parametric, with the small parameter size providing robustness to noise and outliers. [sent-12, score-0.31]
</p><p>11 While parametric techniques are very robust, many real world scenarios involve complex motions that would benefit from less restrictive parameterization. [sent-13, score-0.123]
</p><p>12 We pose this warping problem as a data fitting question: How is it possible to robustly compute a non-parametric fitting function across noisy scatter points? [sent-14, score-1.327]
</p><p>13 ”The direct fitting of a fully flexible non-parametric function would almost certainly result in difficulties defining and removing outliers. [sent-15, score-0.481]
</p><p>14 This would be especially difInputs  Warping Results  Overlays Results  flow correspondences [23], allowing a visually pleasing warp. [sent-16, score-0.118]
</p><p>15 ficult for piece-wise outlier corruption where certain image sections are consistently matched incorrectly. [sent-17, score-0.281]
</p><p>16 However, we note that by including an additional constraint requiring data to form a smooth curve, outliers (especially piece-wise outliers) can then be readily defined. [sent-18, score-0.284]
</p><p>17 While loosing some modeling flexibility, such a scheme has the potential to provide a level of robustness similar to parametric affine and homographic fitting while providing significantly greater flexibility. [sent-19, score-0.764]
</p><p>18 We propose a non-parametric function fitting approach that is based upon the motion coherence formulation discussed by Yuille and Grywacz [41], Myronenko et al. [sent-20, score-0.702]
</p><p>19 We observe that the original proofs based upon L2 correspondence fitting can be adapted to a robust huber loss  function. [sent-22, score-0.864]
</p><p>20 The resultant formulation computes a smooth, best fit curve for a noisy point set by minimizing a simple convex cost. [sent-23, score-0.254]
</p><p>21 With a simple Median Absolute Deviation thresholding to replace the RANSAC [11], our proposed algorithm’s enforcement of overall smoothness makes it especially adept at handling piece-wise noise in which certain data sections are corrupted in a coherent manner. [sent-24, score-0.438]
</p><p>22 When we integrate our 1-dimensional curve fitting into the over parametrized warping scheme proposed by Lin et al. [sent-25, score-0.918]
</p><p>23 [22, 29], we can compute coherent warps from noisy image correspondences. [sent-27, score-0.397]
</p><p>24 ooppyyrriigghhtt  22337766  As our warping technique is defined in terms of nonparametric curve fitting, rather than correspondence reestimation, it lends itself naturally to image re-projection problems. [sent-29, score-0.847]
</p><p>25 In particular, it allows orthographic image projection from noisy depth estimates. [sent-30, score-0.146]
</p><p>26 This is especially useful for mosaicking long lateral image sequences taken by a panning camera. [sent-31, score-0.392]
</p><p>27 To summarize, our contributions are as follows: •  •  We propose a non-parametric curve fitting technique tWhaet pisr oropobusest ato n piecewise entroicise c. [sent-32, score-0.707]
</p><p>28 We incorporate the technique into a high dimensional smoothly varying warping suceh einmtoe ath hatig gahll odwims compu-  tation of visually compelling image warps from noisy correspondence in a simple minimization framework. [sent-33, score-0.958]
</p><p>29 •  We demonstrate a panning mosaicking algorithm that integrates images f praonmn a laterally translating camera by stitching them to a push-broom mosaicking plane. [sent-34, score-0.653]
</p><p>30 Related Works Non-parametric data fitting and its associated image warping is a large and well researched computer vision field. [sent-36, score-0.748]
</p><p>31 Works range from self occlusion surface fitting [3 1], full frame internet image warping [21], bio-medical contour registration [28], non-rigid surface reconstruction [36, 34], as-rigid-as-possible shape manipulation [18] and non-rigid 3-D object warping [39]. [sent-37, score-1.08]
</p><p>32 Non-rigid fitting also encompasses the wide range of flow based works, [23, 25, 17, 6] and piecewise segment fitting techniques [3, 37]. [sent-38, score-1.036]
</p><p>33 However, most works focus on custom applications to specific problems and their adaptation to a generic non-parametric correspondence fitting scheme is unclear since they integrate many different aspects (matching cost, descriptor information and smoothness term) within a single system. [sent-39, score-0.913]
</p><p>34 The issue of adapting non-rigid matching techniques to correspondence fitting is considered in the subsequent paragraph. [sent-40, score-0.682]
</p><p>35 Non-rigid correspondence estimation algorithms such as Chui et al. [sent-41, score-0.233]
</p><p>36 in mixed optical flow, thin-plate spline computation [40], Myronenko et al. [sent-43, score-0.227]
</p><p>37 in smoothly  varying affine [22], iteratively compute a smooth warping surface and do not assume known correspondences. [sent-45, score-0.601]
</p><p>38 These formulations can also be readily adapted from correspondence discovery to the simpler correspondence fitting problem by redefining the matching choices into a binary match or no-match decision. [sent-46, score-1.018]
</p><p>39 However, we note that if the task is simply to decide between a match and non-match, we can eliminate the complex iterative correspondence estimation procedure that is vulnerable to local minimums. [sent-48, score-0.273]
</p><p>40 In this paper, we adapt the motion coherence formulation [28] such that  : outliers A B C Figure 2. [sent-49, score-0.377]
</p><p>41 While the outlier points in B can be potentially fitted using a spline, their outlier status becomes much less ambiguous if we define the problem as a smooth curve fitting. [sent-50, score-0.525]
</p><p>42 the matching cost is penalized with a simple huber function. [sent-51, score-0.222]
</p><p>43 This adaptation allows a simple convex cost that can be minimized to find the desired warping field. [sent-52, score-0.376]
</p><p>44 Our work also bears close relation to spline fitting tech-  niques such as Reinsch [35], Akima [2], Garcia [15]. [sent-53, score-0.716]
</p><p>45 Unlike spline fitting, we require our fitted function to be a smooth curve. [sent-54, score-0.437]
</p><p>46 This is less flexible than a spline, but it allows the fitting of a trend through piece-wise outlier corruption. [sent-55, score-0.526]
</p><p>47 Formulation We pose the correspondence modeling problem as one of robust non-parametric curve fitting. [sent-58, score-0.345]
</p><p>48 Traditionally, nonparametric function estimation is viewed as more unstable than its parametrized cousin. [sent-59, score-0.189]
</p><p>49 We feel that this is in large part due to the difficulty in defining noise and outliers in a non-parametric setting. [sent-60, score-0.215]
</p><p>50 In particular piece-wise noise in which a section of the signal is corrupted consistently can be difficult to handle. [sent-61, score-0.156]
</p><p>51 However, by reducing the non-parametric space to a smaller one consisting of smooth continuous functions, such outliers can be well defined as illustrated in Figure 2. [sent-62, score-0.234]
</p><p>52 As such, we propose a non-parametric curve fitting that is robust to piecewise corruption and extend our results to the creation of smooth warps from noisy correspondences. [sent-63, score-1.168]
</p><p>53 Our proposed solution can provide high stability levels usually only associated with parametric algorithms. [sent-64, score-0.084]
</p><p>54 Using Motion Coherence to formulate a function fitting problem The problem is formulated as the fitting of a smooth  function to data. [sent-67, score-0.969]
</p><p>55 Given a set of N scatter points {pj , qˆj }, wfuhnecrteio pj are aDta-. [sent-68, score-0.205]
</p><p>56 d Gimievnesnio an saelt tv oefcNt ors s canatdte qˆj are tssca {lpars. [sent-69, score-0.106]
</p><p>57 W}e, assume that data comes from a linear combination of K smooth functions fk (p), corrupted with noise. [sent-70, score-0.461]
</p><p>58 1 22337777  represents noise and ajk are given weight values for the linear combination of fk (. [sent-76, score-0.236]
</p><p>59 ) functions are composed of two terms, fk (p) = Hk + φk (p). [sent-79, score-0.246]
</p><p>60 Hk is a scalar offset and φk (p) is a smooth function with motion coherence smoothness penalty [41, 28] given as follows nj  Ψk=? [sent-80, score-0.494]
</p><p>61 ), while g(ω) is the Fourier transform of a Gaussian with spatial distribution γ. [sent-84, score-0.038]
</p><p>62 ) functions consistent with the given {pj , qˆj } data points. [sent-88, score-0.056]
</p><p>63 ) represents some cost function that penalizes deviation of the estimated function predictions from given ˆq estimates. [sent-102, score-0.043]
</p><p>64 Throughout this paper, we use the huber function in Eqn. [sent-103, score-0.144]
</p><p>65 λ represents the weight given to the smoothness constraint Ψk. [sent-105, score-0.091]
</p><p>66 The cost E can be re-expressed in terms of a finite number of wk, Hk using Eqn. [sent-106, score-0.09]
</p><p>67 Directly minimizing E with respect to functions fk (. [sent-109, score-0.246]
</p><p>68 However, motion coherence can reduce the problem to an optimization over a finite number of variables. [sent-111, score-0.301]
</p><p>69 A brief summary is as follows: Note the Fourier transform relation, φk (p) = ? [sent-112, score-0.038]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fitting', 0.41), ('warping', 0.29), ('correspondence', 0.233), ('warps', 0.229), ('spline', 0.227), ('coherence', 0.198), ('fk', 0.19), ('mosaicking', 0.187), ('smooth', 0.149), ('huber', 0.144), ('pj', 0.136), ('panning', 0.127), ('ajkfk', 0.124), ('homographic', 0.124), ('nonparametric', 0.122), ('warp', 0.115), ('curve', 0.112), ('noisy', 0.104), ('myronenko', 0.102), ('piecewise', 0.096), ('smoothness', 0.091), ('outliers', 0.085), ('parametric', 0.084), ('outlier', 0.081), ('hk', 0.081), ('fourier', 0.076), ('scatter', 0.069), ('corruption', 0.068), ('parametrized', 0.067), ('corrupted', 0.066), ('coherent', 0.064), ('fitted', 0.061), ('smoothly', 0.061), ('generic', 0.056), ('functions', 0.056), ('affine', 0.056), ('motion', 0.056), ('twhaet', 0.055), ('loosing', 0.055), ('mismatched', 0.055), ('brookes', 0.055), ('nigel', 0.055), ('shuai', 0.055), ('redefining', 0.055), ('saelt', 0.055), ('laterally', 0.055), ('integrates', 0.053), ('adept', 0.051), ('nir', 0.051), ('ooppyyrriigghhtt', 0.051), ('ors', 0.051), ('ficult', 0.051), ('stitch', 0.051), ('readily', 0.05), ('wills', 0.048), ('researched', 0.048), ('feel', 0.048), ('pisr', 0.048), ('chui', 0.048), ('finite', 0.047), ('noise', 0.046), ('outlying', 0.046), ('garcia', 0.046), ('twheit', 0.046), ('surface', 0.045), ('consistently', 0.044), ('stitching', 0.044), ('robustly', 0.044), ('cost', 0.043), ('adaptation', 0.043), ('orthographic', 0.042), ('enforcement', 0.042), ('flow', 0.041), ('custom', 0.041), ('tation', 0.041), ('ato', 0.041), ('bears', 0.041), ('status', 0.041), ('especially', 0.041), ('heart', 0.04), ('proofs', 0.04), ('encompasses', 0.04), ('vulnerable', 0.04), ('techniques', 0.039), ('integrate', 0.039), ('lends', 0.039), ('lacking', 0.039), ('transform', 0.038), ('relation', 0.038), ('formulation', 0.038), ('adapted', 0.037), ('sections', 0.037), ('lateral', 0.037), ('standing', 0.037), ('pleasing', 0.036), ('gk', 0.036), ('defining', 0.036), ('flexible', 0.035), ('providing', 0.035), ('penalized', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="358-tfidf-1" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>Author: Wen-Yan Lin, Ming-Ming Cheng, Shuai Zheng, Jiangbo Lu, Nigel Crook</p><p>Abstract: We propose a generic method for obtaining nonparametric image warps from noisy point correspondences. Our formulation integrates a huber function into a motion coherence framework. This makes our fitting function especially robust to piecewise correspondence noise (where an image section is consistently mismatched). By utilizing over parameterized curves, we can generate realistic nonparametric image warps from very noisy correspondence. We also demonstrate how our algorithm can be used to help stitch images taken from a panning camera by warping the images onto a virtual push-broom camera imaging plane.</p><p>2 0.16729282 <a title="358-tfidf-2" href="./iccv-2013-Optimization_Problems_for_Fast_AAM_Fitting_in-the-Wild.html">302 iccv-2013-Optimization Problems for Fast AAM Fitting in-the-Wild</a></p>
<p>Author: Georgios Tzimiropoulos, Maja Pantic</p><p>Abstract: We describe a very simple framework for deriving the most-well known optimization problems in Active Appearance Models (AAMs), and most importantly for providing efficient solutions. Our formulation results in two optimization problems for fast and exact AAM fitting, and one new algorithm which has the important advantage of being applicable to 3D. We show that the dominant cost for both forward and inverse algorithms is a few times mN which is the cost of projecting an image onto the appearance subspace. This makes both algorithms not only computationally realizable but also very attractive speed-wise for most current systems. Because exact AAM fitting is no longer computationally prohibitive, we trained AAMs in-the-wild with the goal of investigating whether AAMs benefit from such a training process. Our results show that although we did not use sophisticated shape priors, robust features or robust norms for improving performance, AAMs perform notably well and in some cases comparably with current state-ofthe-art methods. We provide Matlab source code for training, fitting and reproducing the results presented in this paper at ht tp ://ibug. . doc . i . a c . uk/resources. c</p><p>3 0.15427649 <a title="358-tfidf-3" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>4 0.14732467 <a title="358-tfidf-4" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>Author: Jim Braux-Zin, Romain Dupont, Adrien Bartoli</p><p>Abstract: Dense motion field estimation (typically Romain Dupont1 romain . dupont @ cea . fr Adrien Bartoli2 adrien . bart o l @ gmai l com i . 2 ISIT, Universit e´ d’Auvergne/CNRS, France sions are explicitly modeled [32, 13]. Coarse-to-fine warping improves global convergence by making the assumption that optical flow, the motion of smaller structures is similar to the motion of stereo disparity and surface registration) is a key computer vision problem. Many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, but a unified methodology is still lacking. We here introduce a general framework that robustly combines direct and feature-based matching. The feature-based cost is built around a novel robust distance function that handles keypoints and “weak” features such as segments. It allows us to use putative feature matches which may contain mismatches to guide dense motion estimation out of local minima. Our framework uses a robust direct data term (AD-Census). It is implemented with a powerful second order Total Generalized Variation regularization with external and self-occlusion reasoning. Our framework achieves state of the art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). Our framework has a modular design that customizes to specific application needs.</p><p>5 0.10850026 <a title="358-tfidf-5" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>Author: Philippe Weinzaepfel, Jerome Revaud, Zaid Harchaoui, Cordelia Schmid</p><p>Abstract: Optical flow computation is a key component in many computer vision systems designed for tasks such as action detection or activity recognition. However, despite several major advances over the last decade, handling large displacement in optical flow remains an open problem. Inspired by the large displacement optical flow of Brox & Malik [6], our approach, termed DeepFlow, blends a matching algorithm with a variational approach for optical flow. We propose a descriptor matching algorithm, tailored to the optical flow problem, that allows to boost performance on fast motions. The matching algorithm builds upon a multi-stage architecture with 6 layers, interleaving convolutions and max-pooling, a construction akin to deep convolutional nets. Using dense sampling, it allows to efficiently retrieve quasi-dense correspondences, and enjoys a built-in smoothing effect on descriptors matches, a valuable assetfor integration into an energy minimizationframework for optical flow estimation. DeepFlow efficiently handles large displacements occurring in realistic videos, and shows competitive performance on optical flow benchmarks. Furthermore, it sets a new state-of-the-art on the MPI-Sintel dataset [8].</p><p>6 0.10028015 <a title="358-tfidf-6" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>7 0.099201947 <a title="358-tfidf-7" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<p>8 0.093814582 <a title="358-tfidf-8" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>9 0.085556775 <a title="358-tfidf-9" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>10 0.084335655 <a title="358-tfidf-10" href="./iccv-2013-Point-Based_3D_Reconstruction_of_Thin_Objects.html">319 iccv-2013-Point-Based 3D Reconstruction of Thin Objects</a></p>
<p>11 0.080601096 <a title="358-tfidf-11" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>12 0.078829713 <a title="358-tfidf-12" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>13 0.078384809 <a title="358-tfidf-13" href="./iccv-2013-Depth_from_Combining_Defocus_and_Correspondence_Using_Light-Field_Cameras.html">108 iccv-2013-Depth from Combining Defocus and Correspondence Using Light-Field Cameras</a></p>
<p>14 0.077043369 <a title="358-tfidf-14" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>15 0.07685709 <a title="358-tfidf-15" href="./iccv-2013-Local_Signal_Equalization_for_Correspondence_Matching.html">255 iccv-2013-Local Signal Equalization for Correspondence Matching</a></p>
<p>16 0.072123311 <a title="358-tfidf-16" href="./iccv-2013-Perspective_Motion_Segmentation_via_Collaborative_Clustering.html">314 iccv-2013-Perspective Motion Segmentation via Collaborative Clustering</a></p>
<p>17 0.069572553 <a title="358-tfidf-17" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>18 0.066451818 <a title="358-tfidf-18" href="./iccv-2013-Parsing_IKEA_Objects%3A_Fine_Pose_Estimation.html">308 iccv-2013-Parsing IKEA Objects: Fine Pose Estimation</a></p>
<p>19 0.06612289 <a title="358-tfidf-19" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>20 0.065097503 <a title="358-tfidf-20" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.148), (1, -0.096), (2, -0.039), (3, 0.032), (4, -0.042), (5, 0.026), (6, 0.023), (7, -0.021), (8, 0.051), (9, 0.003), (10, -0.026), (11, 0.035), (12, 0.062), (13, -0.016), (14, 0.042), (15, 0.021), (16, 0.007), (17, 0.064), (18, 0.063), (19, -0.004), (20, 0.079), (21, 0.029), (22, -0.019), (23, -0.024), (24, 0.094), (25, -0.061), (26, 0.065), (27, 0.057), (28, 0.002), (29, -0.087), (30, 0.03), (31, -0.053), (32, 0.066), (33, 0.066), (34, 0.04), (35, 0.007), (36, -0.001), (37, -0.03), (38, 0.078), (39, -0.072), (40, -0.039), (41, -0.001), (42, -0.137), (43, 0.048), (44, 0.042), (45, 0.031), (46, 0.014), (47, 0.117), (48, -0.105), (49, 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97075027 <a title="358-lsi-1" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>Author: Wen-Yan Lin, Ming-Ming Cheng, Shuai Zheng, Jiangbo Lu, Nigel Crook</p><p>Abstract: We propose a generic method for obtaining nonparametric image warps from noisy point correspondences. Our formulation integrates a huber function into a motion coherence framework. This makes our fitting function especially robust to piecewise correspondence noise (where an image section is consistently mismatched). By utilizing over parameterized curves, we can generate realistic nonparametric image warps from very noisy correspondence. We also demonstrate how our algorithm can be used to help stitch images taken from a panning camera by warping the images onto a virtual push-broom camera imaging plane.</p><p>2 0.71563667 <a title="358-lsi-2" href="./iccv-2013-Optimization_Problems_for_Fast_AAM_Fitting_in-the-Wild.html">302 iccv-2013-Optimization Problems for Fast AAM Fitting in-the-Wild</a></p>
<p>Author: Georgios Tzimiropoulos, Maja Pantic</p><p>Abstract: We describe a very simple framework for deriving the most-well known optimization problems in Active Appearance Models (AAMs), and most importantly for providing efficient solutions. Our formulation results in two optimization problems for fast and exact AAM fitting, and one new algorithm which has the important advantage of being applicable to 3D. We show that the dominant cost for both forward and inverse algorithms is a few times mN which is the cost of projecting an image onto the appearance subspace. This makes both algorithms not only computationally realizable but also very attractive speed-wise for most current systems. Because exact AAM fitting is no longer computationally prohibitive, we trained AAMs in-the-wild with the goal of investigating whether AAMs benefit from such a training process. Our results show that although we did not use sophisticated shape priors, robust features or robust norms for improving performance, AAMs perform notably well and in some cases comparably with current state-ofthe-art methods. We provide Matlab source code for training, fitting and reproducing the results presented in this paper at ht tp ://ibug. . doc . i . a c . uk/resources. c</p><p>3 0.65003705 <a title="358-lsi-3" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>Author: Xin Cheng, Sridha Sridharan, Jason Saragih, Simon Lucey</p><p>Abstract: Active Appearance Models (AAMs) employ a paradigm of inverting a synthesis model of how an object can vary in terms of shape and appearance. As a result, the ability of AAMs to register an unseen object image is intrinsically linked to two factors. First, how well the synthesis model can reconstruct the object image. Second, the degrees of freedom in the model. Fewer degrees of freedom yield a higher likelihood of good fitting performance. In this paper we look at how these seemingly contrasting factors can complement one another for the problem of AAM fitting of an ensemble of images stemming from a constrained set (e.g. an ensemble of face images of the same person).</p><p>4 0.62930793 <a title="358-lsi-4" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>5 0.61151916 <a title="358-lsi-5" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>Author: Jim Braux-Zin, Romain Dupont, Adrien Bartoli</p><p>Abstract: Dense motion field estimation (typically Romain Dupont1 romain . dupont @ cea . fr Adrien Bartoli2 adrien . bart o l @ gmai l com i . 2 ISIT, Universit e´ d’Auvergne/CNRS, France sions are explicitly modeled [32, 13]. Coarse-to-fine warping improves global convergence by making the assumption that optical flow, the motion of smaller structures is similar to the motion of stereo disparity and surface registration) is a key computer vision problem. Many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, but a unified methodology is still lacking. We here introduce a general framework that robustly combines direct and feature-based matching. The feature-based cost is built around a novel robust distance function that handles keypoints and “weak” features such as segments. It allows us to use putative feature matches which may contain mismatches to guide dense motion estimation out of local minima. Our framework uses a robust direct data term (AD-Census). It is implemented with a powerful second order Total Generalized Variation regularization with external and self-occlusion reasoning. Our framework achieves state of the art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). Our framework has a modular design that customizes to specific application needs.</p><p>6 0.56527078 <a title="358-lsi-6" href="./iccv-2013-Locally_Affine_Sparse-to-Dense_Matching_for_Motion_and_Occlusion_Estimation.html">256 iccv-2013-Locally Affine Sparse-to-Dense Matching for Motion and Occlusion Estimation</a></p>
<p>7 0.52653414 <a title="358-lsi-7" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>8 0.51805335 <a title="358-lsi-8" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>9 0.50779736 <a title="358-lsi-9" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>10 0.50501269 <a title="358-lsi-10" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>11 0.4964081 <a title="358-lsi-11" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>12 0.48481441 <a title="358-lsi-12" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>13 0.48408306 <a title="358-lsi-13" href="./iccv-2013-Local_Signal_Equalization_for_Correspondence_Matching.html">255 iccv-2013-Local Signal Equalization for Correspondence Matching</a></p>
<p>14 0.47121057 <a title="358-lsi-14" href="./iccv-2013-Automatic_Registration_of_RGB-D_Scans_via_Salient_Directions.html">56 iccv-2013-Automatic Registration of RGB-D Scans via Salient Directions</a></p>
<p>15 0.46631134 <a title="358-lsi-15" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>16 0.46479937 <a title="358-lsi-16" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>17 0.45653483 <a title="358-lsi-17" href="./iccv-2013-Elastic_Fragments_for_Dense_Scene_Reconstruction.html">139 iccv-2013-Elastic Fragments for Dense Scene Reconstruction</a></p>
<p>18 0.4543927 <a title="358-lsi-18" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>19 0.4484179 <a title="358-lsi-19" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>20 0.4477222 <a title="358-lsi-20" href="./iccv-2013-Piecewise_Rigid_Scene_Flow.html">317 iccv-2013-Piecewise Rigid Scene Flow</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.044), (7, 0.025), (26, 0.063), (31, 0.088), (42, 0.065), (48, 0.012), (57, 0.177), (64, 0.042), (73, 0.126), (89, 0.243), (95, 0.014), (98, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88287187 <a title="358-lda-1" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>Author: Wen-Yan Lin, Ming-Ming Cheng, Shuai Zheng, Jiangbo Lu, Nigel Crook</p><p>Abstract: We propose a generic method for obtaining nonparametric image warps from noisy point correspondences. Our formulation integrates a huber function into a motion coherence framework. This makes our fitting function especially robust to piecewise correspondence noise (where an image section is consistently mismatched). By utilizing over parameterized curves, we can generate realistic nonparametric image warps from very noisy correspondence. We also demonstrate how our algorithm can be used to help stitch images taken from a panning camera by warping the images onto a virtual push-broom camera imaging plane.</p><p>2 0.85948157 <a title="358-lda-2" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>Author: Marco San_Biagio, Marco Crocco, Marco Cristani, Samuele Martelli, Vittorio Murino</p><p>Abstract: Capturing the essential characteristics of visual objects by considering how their features are inter-related is a recent philosophy of object classification. In this paper, we embed this principle in a novel image descriptor, dubbed Heterogeneous Auto-Similarities of Characteristics (HASC). HASC is applied to heterogeneous dense features maps, encoding linear relations by covariances and nonlinear associations through information-theoretic measures such as mutual information and entropy. In this way, highly complex structural information can be expressed in a compact, scale invariant and robust manner. The effectiveness of HASC is tested on many diverse detection and classification scenarios, considering objects, textures and pedestrians, on widely known benchmarks (Caltech-101, Brodatz, Daimler Multi-Cue). In all the cases, the results obtained with standard classifiers demonstrate the superiority of HASC with respect to the most adopted local feature descriptors nowadays, such as SIFT, HOG, LBP and feature covariances. In addition, HASC sets the state-of-the-art on the Brodatz texture dataset and the Daimler Multi-Cue pedestrian dataset, without exploiting ad-hoc sophisticated classifiers.</p><p>3 0.84065926 <a title="358-lda-3" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>Author: Jim Braux-Zin, Romain Dupont, Adrien Bartoli</p><p>Abstract: Dense motion field estimation (typically Romain Dupont1 romain . dupont @ cea . fr Adrien Bartoli2 adrien . bart o l @ gmai l com i . 2 ISIT, Universit e´ d’Auvergne/CNRS, France sions are explicitly modeled [32, 13]. Coarse-to-fine warping improves global convergence by making the assumption that optical flow, the motion of smaller structures is similar to the motion of stereo disparity and surface registration) is a key computer vision problem. Many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, but a unified methodology is still lacking. We here introduce a general framework that robustly combines direct and feature-based matching. The feature-based cost is built around a novel robust distance function that handles keypoints and “weak” features such as segments. It allows us to use putative feature matches which may contain mismatches to guide dense motion estimation out of local minima. Our framework uses a robust direct data term (AD-Census). It is implemented with a powerful second order Total Generalized Variation regularization with external and self-occlusion reasoning. Our framework achieves state of the art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). Our framework has a modular design that customizes to specific application needs.</p><p>4 0.83567947 <a title="358-lda-4" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>5 0.83556348 <a title="358-lda-5" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>Author: Ernesto Brau, Jinyan Guan, Kyle Simek, Luca Del Pero, Colin Reimer Dawson, Kobus Barnard</p><p>Abstract: Jinyan Guan† j guan1 @ emai l ari z ona . edu . Kyle Simek† ks imek@ emai l ari z ona . edu . Colin Reimer Dawson‡ cdaws on@ emai l ari z ona . edu . ‡School of Information University of Arizona Kobus Barnard‡ kobus @ s i sta . ari z ona . edu ∗School of Informatics University of Edinburgh for tracking an unknown and changing number of people in a scene using video taken from a single, fixed viewpoint. We develop a Bayesian modeling approach for tracking people in 3D from monocular video with unknown cameras. Modeling in 3D provides natural explanations for occlusions and smoothness discontinuities that result from projection, and allows priors on velocity and smoothness to be grounded in physical quantities: meters and seconds vs. pixels and frames. We pose the problem in the context of data association, in which observations are assigned to tracks. A correct application of Bayesian inference to multitarget tracking must address the fact that the model’s dimension changes as tracks are added or removed, and thus, posterior densities of different hypotheses are not comparable. We address this by marginalizing out the trajectory parameters so the resulting posterior over data associations has constant dimension. This is made tractable by using (a) Gaussian process priors for smooth trajectories and (b) approximately Gaussian likelihood functions. Our approach provides a principled method for incorporating multiple sources of evidence; we present results using both optical flow and object detector outputs. Results are comparable to recent work on 3D tracking and, unlike others, our method requires no pre-calibrated cameras.</p><p>6 0.82753932 <a title="358-lda-6" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>7 0.82103229 <a title="358-lda-7" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>8 0.81900758 <a title="358-lda-8" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>9 0.81509507 <a title="358-lda-9" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>10 0.81068832 <a title="358-lda-10" href="./iccv-2013-Motion-Aware_KNN_Laplacian_for_Video_Matting.html">275 iccv-2013-Motion-Aware KNN Laplacian for Video Matting</a></p>
<p>11 0.80999267 <a title="358-lda-11" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>12 0.80950755 <a title="358-lda-12" href="./iccv-2013-Understanding_High-Level_Semantics_by_Modeling_Traffic_Patterns.html">433 iccv-2013-Understanding High-Level Semantics by Modeling Traffic Patterns</a></p>
<p>13 0.80750358 <a title="358-lda-13" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>14 0.80689144 <a title="358-lda-14" href="./iccv-2013-Exploiting_Reflection_Change_for_Automatic_Reflection_Removal.html">151 iccv-2013-Exploiting Reflection Change for Automatic Reflection Removal</a></p>
<p>15 0.80686688 <a title="358-lda-15" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>16 0.80572039 <a title="358-lda-16" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>17 0.80047703 <a title="358-lda-17" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>18 0.79950702 <a title="358-lda-18" href="./iccv-2013-Image_Guided_Depth_Upsampling_Using_Anisotropic_Total_Generalized_Variation.html">209 iccv-2013-Image Guided Depth Upsampling Using Anisotropic Total Generalized Variation</a></p>
<p>19 0.79868102 <a title="358-lda-19" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>20 0.79832149 <a title="358-lda-20" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
