<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>404 iccv-2013-Structured Forests for Fast Edge Detection</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-404" href="#">iccv2013-404</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>404 iccv-2013-Structured Forests for Fast Edge Detection</h1>
<br/><p>Source: <a title="iccv-2013-404-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Dollar_Structured_Forests_for_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Piotr Dollár, C. Lawrence Zitnick</p><p>Abstract: Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets.</p><p>Reference: <a title="iccv-2013-404-reference" href="../iccv2013_reference/iccv-2013-Structured_Forests_for_Fast_Edge_Detection_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. [sent-4, score-0.376]
</p><p>2 We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. [sent-5, score-0.965]
</p><p>3 Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. [sent-6, score-0.974]
</p><p>4 The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. [sent-7, score-0.733]
</p><p>5 Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets. [sent-8, score-0.743]
</p><p>6 Traditional approaches to edge detection use a variety of methods for computing color gradient magnitudes followed by non-maximal suppression [5, 14, 38]. [sent-12, score-0.475]
</p><p>7 State-of-the-art approaches to edge detection [1, 3 1, 21] use a variety of features as input, including brightness, color and texture gradients computed over multiple scales. [sent-14, score-0.475]
</p><p>8 Since visually salient edges correspond to a variety of visual phenomena, finding a unified approach to edge detection is difficult. [sent-16, score-0.488]
</p><p>9 Motivated by this observation several recent papers have explored the use of learning techniques for edge detection [9, 37, 21]. [sent-17, score-0.474]
</p><p>10 The independent edge predictions may then be combined using global reasoning [37, 1, 3 1]. [sent-28, score-0.401]
</p><p>11 Recently, a family of learning approaches called structured  learning [26] has been applied to problems exhibiting similar characteristics. [sent-31, score-0.391]
</p><p>12 For instance, [20] applies structured learning to the problem of semantic image labeling for which local image labels are also highly interdependent. [sent-32, score-0.474]
</p><p>13 In this paper we propose a generalized structured learning approach that we apply to edge detection. [sent-33, score-0.697]
</p><p>14 This approach allows us to take advantage of the inherent structure in edge patches, while being surprisingly computationally efficient. [sent-34, score-0.343]
</p><p>15 We can compute edge maps in realtime, which is orders of magnitude faster than competing state-of-the-art approaches. [sent-35, score-0.583]
</p><p>16 A random forest framework is used to capture the structured information [20]. [sent-36, score-0.484]
</p><p>17 We formulate the problem of edge detection as predicting local segmentation masks given input image patches. [sent-37, score-0.53]
</p><p>18 Our novel approach to learn11884411  ing decision trees uses structured labels to determine the splitting function at each branch in the tree. [sent-38, score-0.783]
</p><p>19 The structured labels are robustly mapped to a discrete space on which standard information gain measures may be evaluated. [sent-39, score-0.558]
</p><p>20 Each forest predicts a patch of edge pixel labels that are aggregated across the image to compute our final edge map, see Figure 1. [sent-40, score-1.01]
</p><p>21 We demonstrate the potential of our approach as a general purpose edge detector by showing the strong cross dataset generalization of our learned edge models. [sent-42, score-0.793]
</p><p>22 Related work  In this section we discuss related work in edge detection and structured learning. [sent-45, score-0.754]
</p><p>23 Edge detection: Numerous papers have been written on edge detection over the past 50 years. [sent-46, score-0.437]
</p><p>24 The popular Canny detector [5] finds the peak gradient magnitude orthogonal to the edge direction. [sent-48, score-0.471]
</p><p>25 An evaluation of various low-level edge detectors can be found in [3] and an overview in [38]. [sent-49, score-0.343]
</p><p>26 More recently, the works of [24, 22, 1] explore edge detection in the presence of textures. [sent-50, score-0.437]
</p><p>27 Several techniques have explored the use of learning for edge detection [9, 37, 22, 3 1, 21]. [sent-51, score-0.474]
</p><p>28 [37] combine low-, mid- and high-level cues and show improved results for object-specific edge detection. [sent-55, score-0.343]
</p><p>29 [21] propose an edge detection approach that classifies edge patches into sketch tokens using random forest classifiers, that, like in our work, attempt to capture local edge structure. [sent-61, score-1.555]
</p><p>30 Sketch tokens bear resemblance to earlier work on shapemes [30] but are computed directly from color image patches rather than from precomputed edge maps. [sent-62, score-0.534]
</p><p>31 In contrast to previous work, we do not require the use of pre-defined classes of edge patches. [sent-64, score-0.343]
</p><p>32 This allows us to learn more subtle variations in edge structure and leads to a more accurate and efficient algorithm. [sent-65, score-0.343]
</p><p>33 Our structured random forests differ from these works in several respects. [sent-69, score-0.616]
</p><p>34 First, we assume that only the output space is structured and operate on a standard input space. [sent-70, score-0.384]
</p><p>35 On the other hand, common approaches for structured prediction learn parameters to a scoring function, and to obtain a prediction, an optimization over the output space must be performed [35, 26]. [sent-72, score-0.465]
</p><p>36 In contrast, inference using our structured random forest is straightforward, general and fast (same as for standard random forests). [sent-74, score-0.525]
</p><p>37 [20] on learning random forests for structured class labels for the specific case where the output labels represent a semantic image labeling for an image patch. [sent-76, score-0.927]
</p><p>38 is that given a color image patch, the leaf node reached in a tree is independent of the structured semantic labels, and any type of output can be stored at each leaf. [sent-78, score-0.788]
</p><p>39 Building  on this idea, we propose a general learning framework for structured output forests that can be used with a broad class of output spaces and we apply our framework to learning an accurate and fast edge detector. [sent-79, score-1.186]
</p><p>40 Random Decision Forests We begin with a review of random decision forests [4, 15]. [sent-81, score-0.489]
</p><p>41 The notation in [7] is sufficiently general to support our extension to random forests with structured outputs. [sent-84, score-0.616]
</p><p>42 A decision tree ft (x) classifies a sample x ∈ X by recursively branching left (oxr) )ri cglahsts difoiwesn a th saem trpelee xun ∈til X Xa l beyaf r encoudreis reached. [sent-85, score-0.302]
</p><p>43 The output of the tree on an input x is the prediction stored at the leaf reached by x, which may be a target label y ∈ Y aort tah dei lsetarfib ruetaiocnh eodv ebyr t xhe, wlahbiechls mY. [sent-88, score-0.363]
</p><p>44 ×  A decision forest is an ensemble of T independent trees ft. [sent-94, score-0.623]
</p><p>45 Given a sample x, the predictions ft (x) from the set of trees are combined using an ensemble model into a single output. [sent-95, score-0.365]
</p><p>46 The leaf node reached by the tree depends only on the input x, and while predictions of multiple trees must be merged in some useful way (the ensemble model), any type of output y can be stored at each leaf. [sent-98, score-0.765]
</p><p>47 This allows use ofcomplex output spaces Y, including structured outputs sase oobfcseormvepdle ebxyo KuotpnutstscphiaecdeesrY Yet, ianl. [sent-99, score-0.444]
</p><p>48 While prediction is straightforward, training random decision forests with structured Y is more challenging. [sent-101, score-0.895]
</p><p>49 cri Wbee our generalization to learning with structured outputs in §3. [sent-103, score-0.404]
</p><p>50 Training stops wwithhen d aat am Saximum depth is reached or if information gain or training set size fall below fixed thresholds. [sent-110, score-0.302]
</p><p>51 Randomness and Optimality Individual decision trees exhibit high variance and tend to overfit [17, 4, 15]. [sent-144, score-0.379]
</p><p>52 Decision forests ameliorate this by training multiple de-correlated trees and combining their output. [sent-145, score-0.489]
</p><p>53 Diversity of trees can be obtained either by randomly subsampling the data used to train each tree [4] or randomly subsampling the features and splits used to train each node [17]. [sent-147, score-0.472]
</p><p>54 Ienre ee Xffec =t, accuracy of individual trees is sacrificed in favor of a high diversity ensemble [15]. [sent-154, score-0.307]
</p><p>55 Leveraging similar intuition allows us to introduce an approximate information gain criterion for structured labels, described next, and leads to our generalized structured forest formulation. [sent-155, score-0.915]
</p><p>56 Structured Random Forests In this section we extend random decision forests to general structured output spaces Y. [sent-157, score-0.933]
</p><p>57 Training random forests with structured labels poses two main challenges. [sent-163, score-0.703]
</p><p>58 First, structured output spaces are often high dimensional and complex. [sent-164, score-0.444]
</p><p>59 Thus scoring numerous candidate splits directly over structured labels may be prohibitively expensive. [sent-165, score-0.495]
</p><p>60 Second, and more critically, information gain over structured labels may not be well defined. [sent-166, score-0.514]
</p><p>61 tr Bayin minagp epainchg node we can leverage existing random forest training procedures to learn structured random forests effectively. [sent-182, score-0.909]
</p><p>62 However, for many structured output spaces, iinlacrliutydin ovge trho Ys. [sent-184, score-0.384]
</p><p>63 Y  ×  Wede bdyes acr stibraei gthhtef proposed approach Zin more detail next and return to its application to edge detection in §4. [sent-188, score-0.437]
</p><p>64 We map a set of structured labels y ∈ Y into a discrete set Wofe l mabaepls a c s ∈t Cf, s twruhceturer eCd =lab {el1s, . [sent-228, score-0.448]
</p><p>65 However, we only need to compute the medoid for small n (either for training a leaf node or merging the output of multiple trees), so having a coarse distance metric suffices to select a representative element yk. [sent-256, score-0.372]
</p><p>66 r cFtoirc ee,x daommpalien, in edge detection we use the default ensemble model during  training but utilize a custom approach for merging outputs over multiple overlapping image patches. [sent-261, score-0.67]
</p><p>67 Edge Detection In this section we describe how we apply our structured forest formulation to the task of edge detection. [sent-263, score-0.786]
</p><p>68 The task is to label each pixel with a binary variable indicating whether the pixel contains an edge or not. [sent-265, score-0.431]
</p><p>69 Similar to the task of semantic image labeling [20], the labels within a small image patch are highly interdependent, providing a promising candidate problem for our structured forest approach. [sent-266, score-0.63]
</p><p>70 Given an image patch, its annotation can be specified either as a segmentation mask indicating segment membership for each pixel (defined up to a permutation) or a binary edge map. [sent-268, score-0.495]
</p><p>71 Input features: Our learning approach predicts a structured 16 16 segmentation mask from a larger 32 32 image 1pa6t ×ch. [sent-282, score-0.462]
</p><p>72 Inspired by the edge detection, k r)es −ult xs oif Lim,k e)t, asel. [sent-285, score-0.343]
</p><p>73 Ensemble model: Random forests achieve robust results by combining the output of multiple decorrelated trees. [sent-332, score-0.325]
</p><p>74 t cioann mbea askvsera yge ∈d tYo yisie dldif fai suoltft, edge response. [sent-335, score-0.343]
</p><p>75 Taking ∈ad Yvantage of a decision tree’s ability to store arbitrary information at the leaf nodes, in addition to the learned segmentation mask y we also store the corresponding edge map y? [sent-336, score-0.714]
</p><p>76 The surprising efficiency of our approach derives from the use of structured labels that capture information for an entire image neighborhood, reducing the number of decision trees T that need to be evaluated per pixel. [sent-340, score-0.783]
</p><p>77 We compute our structured output densely on the image with a stride of 2 pixels, thus with 16 16 output patches, each pixel receives  1p6ix2eTls/,4 t ≈us 6 w4iTth h p 1re6d×ic1t6ion osu. [sent-341, score-0.495]
</p><p>78 Since both the inputs and outputs of each tree overlap, we train 2T total trees and evaluate an alternating set of T trees at each adjacent location. [sent-344, score-0.454]
</p><p>79 Multiscale detection: Inspired by the work of Ren [28], we implement a multiscale version of our edge detector. [sent-346, score-0.39]
</p><p>80 Given an input image I, we run our structured edge detector on the original, half, and double resolution version of I and average the result ofthe three edge maps after resizing to the original image dimensions. [sent-347, score-1.06]
</p><p>81 Although somewhat inefficient, the approach noticeably improves edge quality. [sent-348, score-0.38]
</p><p>82 , image and channel blurring), and decision forest parameters (stopping criteria, number of trees, m and k). [sent-352, score-0.381]
</p><p>83 Three variants of SE are shown utilizing either single (SS) or multiscale (MS) detection with variable number of evaluated trees T. [sent-357, score-0.33]
</p><p>84 We conclude by demonstrating the cross dataset generalization of our approach by testing on each dataset using decision forests learned on the other. [sent-362, score-0.498]
</p><p>85 Prior to evaluation, we apply a standard non-maximal suppression technique to our edge maps to obtain thinned edges [5]. [sent-367, score-0.394]
</p><p>86 For SESS we show two results with T = 1and T = 4 evaluated decision trees at each location. [sent-370, score-0.379]
</p><p>87 In comparison to other learning-based approaches to edge detection, we considerably outperform [9] which computes edges independently at each pixel given its surround-  ×  ing image patch. [sent-382, score-0.488]
</p><p>88 This may be the result of sketch tokens using a fixed set of classes for selecting split criterion at each node, whereas our structured forests can captured finer patch edge structure. [sent-384, score-1.226]
</p><p>89 Ren and Bo [3 1] adopted the data for edge detection allowing for testing edge detectors using multiple modalities including RGB, depth, and RGBD. [sent-386, score-0.78]
</p><p>90 In Table 3 we show results where we tested on NYU using structured forests trained on BSDS500 and tested on BSDS500 using structured forests trained on NYU. [sent-408, score-1.15]
</p><p>91 We believe this provides strong evidence that our approach could serve as a general purpose edge detector. [sent-411, score-0.343]
</p><p>92 This may enable new applications that require high-quality edge detection and efficiency. [sent-414, score-0.437]
</p><p>93 Our approach to learning structured decision trees may  be applied to a variety of problems. [sent-416, score-0.733]
</p><p>94 Given that many vision applications contain structured data, there is significant potential for structured forests in other applications. [sent-420, score-0.892]
</p><p>95 In conclusion, we propose a structured learning approach to edge detection. [sent-421, score-0.697]
</p><p>96 We describe a general purpose method for learning structured random decision forest that robustly uses structured labels to select splits in the trees. [sent-422, score-1.172]
</p><p>97 We demonstrate state-of-the-art accuracies on two edge detection datasets, while being orders of magnitude faster than most competing state-of-the-art methods. [sent-423, score-0.677]
</p><p>98 On the quantitative evaluation of edge detection schemes and their comparison with human performance. [sent-513, score-0.437]
</p><p>99 Structured class-labels in random forests for semantic image labelling. [sent-555, score-0.332]
</p><p>100 Discriminative sparse image models for class-specific edge detection and image interpretation. [sent-570, score-0.437]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('edge', 0.343), ('structured', 0.317), ('forests', 0.258), ('decision', 0.19), ('trees', 0.189), ('scg', 0.175), ('nyu', 0.13), ('forest', 0.126), ('bsds', 0.124), ('tokens', 0.12), ('ensemble', 0.118), ('gain', 0.11), ('channels', 0.097), ('contour', 0.096), ('detection', 0.094), ('labels', 0.087), ('node', 0.084), ('gpb', 0.083), ('orders', 0.08), ('tree', 0.076), ('runtime', 0.076), ('sketch', 0.076), ('leaf', 0.073), ('ods', 0.073), ('medoid', 0.072), ('magnitude', 0.071), ('doll', 0.07), ('py', 0.068), ('output', 0.067), ('patch', 0.067), ('fowlkes', 0.066), ('ren', 0.066), ('channel', 0.065), ('sj', 0.064), ('depth', 0.063), ('mapping', 0.061), ('kontschieder', 0.06), ('spaces', 0.06), ('se', 0.06), ('zkj', 0.058), ('predictions', 0.058), ('splits', 0.057), ('detector', 0.057), ('segmentation', 0.056), ('rgbd', 0.056), ('realtime', 0.056), ('faster', 0.055), ('randomness', 0.055), ('mask', 0.052), ('reached', 0.052), ('sjl', 0.052), ('wweh', 0.052), ('catanzaro', 0.052), ('gy', 0.052), ('edges', 0.051), ('generalization', 0.05), ('considerably', 0.05), ('yo', 0.05), ('zk', 0.05), ('aw', 0.049), ('stored', 0.048), ('prediction', 0.047), ('multiscale', 0.047), ('interdependent', 0.046), ('criterion', 0.045), ('tae', 0.045), ('shannon', 0.045), ('entropy', 0.045), ('discrete', 0.044), ('pixel', 0.044), ('rgb', 0.044), ('training', 0.042), ('po', 0.042), ('random', 0.041), ('tyo', 0.041), ('pca', 0.041), ('downsample', 0.04), ('nde', 0.04), ('custom', 0.039), ('color', 0.038), ('learning', 0.037), ('somewhat', 0.037), ('masks', 0.037), ('tro', 0.036), ('classifies', 0.036), ('sy', 0.036), ('ey', 0.036), ('ha', 0.035), ('aat', 0.035), ('merging', 0.034), ('competing', 0.034), ('scoring', 0.034), ('yw', 0.034), ('critical', 0.034), ('pedestrian', 0.033), ('subsampling', 0.033), ('critically', 0.033), ('semantic', 0.033), ('pami', 0.033), ('patches', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="404-tfidf-1" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>Author: Piotr Dollár, C. Lawrence Zitnick</p><p>Abstract: Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets.</p><p>2 0.30579615 <a title="404-tfidf-2" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>Author: Christoph Straehle, Ullrich Koethe, Fred A. Hamprecht</p><p>Abstract: We propose a scheme that allows to partition an image into a previously unknown number of segments, using only minimal supervision in terms of a few must-link and cannotlink annotations. We make no use of regional data terms, learning instead what constitutes a likely boundary between segments. Since boundaries are only implicitly specified through cannot-link constraints, this is a hard and nonconvex latent variable problem. We address this problem in a greedy fashion using a randomized decision tree on features associated with interpixel edges. We use a structured purity criterion during tree construction and also show how a backtracking strategy can be used to prevent the greedy search from ending up in poor local optima. The proposed strategy is compared with prior art on natural images.</p><p>3 0.18046387 <a title="404-tfidf-3" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>4 0.178784 <a title="404-tfidf-4" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>Author: Samuel Schulter, Christian Leistner, Paul Wohlhart, Peter M. Roth, Horst Bischof</p><p>Abstract: We present Alternating Regression Forests (ARFs), a novel regression algorithm that learns a Random Forest by optimizing a global loss function over all trees. This interrelates the information of single trees during the training phase and results in more accurate predictions. ARFs can minimize any differentiable regression loss without sacrificing the appealing properties of Random Forests, like low computational complexity during both, training and testing. Inspired by recent developments for classification [19], we derive a new algorithm capable of dealing with different regression loss functions, discuss its properties and investigate the relations to other methods like Boosted Trees. We evaluate ARFs on standard machine learning benchmarks, where we observe better generalization power compared to both standard Random Forests and Boosted Trees. Moreover, we apply the proposed regressor to two computer vision applications: object detection and head pose estimation from depth images. ARFs outperform the Random Forest baselines in both tasks, illustrating the importance of optimizing a common loss function for all trees.</p><p>5 0.16046248 <a title="404-tfidf-5" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>Author: Olaf Kähler, Ian Reid</p><p>Abstract: We address the problem of 3D scene labeling in a structured learning framework. Unlike previous work which uses structured Support VectorMachines, we employ the recently described Decision Tree Field and Regression Tree Field frameworks, which learn the unary and binary terms of a Conditional Random Field from training data. We show this has significant advantages in terms of inference speed, while maintaining similar accuracy. We also demonstrate empirically the importance for overall labeling accuracy of features that make use of prior knowledge about the coarse scene layout such as the location of the ground plane. We show how this coarse layout can be estimated by our framework automatically, and that this information can be used to bootstrap improved accuracy in the detailed labeling.</p><p>6 0.14077242 <a title="404-tfidf-6" href="./iccv-2013-Revisiting_Example_Dependent_Cost-Sensitive_Learning_with_Decision_Trees.html">352 iccv-2013-Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees</a></p>
<p>7 0.12398446 <a title="404-tfidf-7" href="./iccv-2013-Unsupervised_Random_Forest_Manifold_Alignment_for_Lipreading.html">437 iccv-2013-Unsupervised Random Forest Manifold Alignment for Lipreading</a></p>
<p>8 0.12325359 <a title="404-tfidf-8" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>9 0.11885776 <a title="404-tfidf-9" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>10 0.11625835 <a title="404-tfidf-10" href="./iccv-2013-Real-Time_Articulated_Hand_Pose_Estimation_Using_Semi-supervised_Transductive_Regression_Forests.html">340 iccv-2013-Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests</a></p>
<p>11 0.10745513 <a title="404-tfidf-11" href="./iccv-2013-Efficient_Hand_Pose_Estimation_from_a_Single_Depth_Image.html">133 iccv-2013-Efficient Hand Pose Estimation from a Single Depth Image</a></p>
<p>12 0.10272715 <a title="404-tfidf-12" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>13 0.10098956 <a title="404-tfidf-13" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>14 0.095538415 <a title="404-tfidf-14" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>15 0.093360513 <a title="404-tfidf-15" href="./iccv-2013-Video_Synopsis_by_Heterogeneous_Multi-source_Correlation.html">443 iccv-2013-Video Synopsis by Heterogeneous Multi-source Correlation</a></p>
<p>16 0.0921176 <a title="404-tfidf-16" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>17 0.091106564 <a title="404-tfidf-17" href="./iccv-2013-Tracking_Revisited_Using_RGBD_Camera%3A_Unified_Benchmark_and_Baselines.html">424 iccv-2013-Tracking Revisited Using RGBD Camera: Unified Benchmark and Baselines</a></p>
<p>18 0.090386577 <a title="404-tfidf-18" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>19 0.089825302 <a title="404-tfidf-19" href="./iccv-2013-Holistic_Scene_Understanding_for_3D_Object_Detection_with_RGBD_Cameras.html">201 iccv-2013-Holistic Scene Understanding for 3D Object Detection with RGBD Cameras</a></p>
<p>20 0.089512348 <a title="404-tfidf-20" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.259), (1, -0.01), (2, -0.016), (3, -0.056), (4, 0.07), (5, 0.006), (6, -0.059), (7, 0.033), (8, -0.025), (9, -0.12), (10, -0.043), (11, 0.005), (12, 0.004), (13, 0.02), (14, 0.104), (15, 0.08), (16, -0.051), (17, -0.149), (18, -0.032), (19, 0.108), (20, -0.096), (21, 0.054), (22, -0.064), (23, 0.12), (24, -0.07), (25, 0.015), (26, -0.02), (27, 0.067), (28, 0.014), (29, -0.133), (30, 0.044), (31, 0.069), (32, -0.093), (33, 0.094), (34, -0.092), (35, 0.062), (36, -0.047), (37, -0.012), (38, -0.012), (39, -0.073), (40, -0.008), (41, 0.005), (42, -0.057), (43, -0.051), (44, 0.014), (45, -0.101), (46, -0.077), (47, -0.001), (48, -0.009), (49, -0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96538532 <a title="404-lsi-1" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>Author: Piotr Dollár, C. Lawrence Zitnick</p><p>Abstract: Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets.</p><p>2 0.88155645 <a title="404-lsi-2" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>Author: Samuel Schulter, Christian Leistner, Paul Wohlhart, Peter M. Roth, Horst Bischof</p><p>Abstract: We present Alternating Regression Forests (ARFs), a novel regression algorithm that learns a Random Forest by optimizing a global loss function over all trees. This interrelates the information of single trees during the training phase and results in more accurate predictions. ARFs can minimize any differentiable regression loss without sacrificing the appealing properties of Random Forests, like low computational complexity during both, training and testing. Inspired by recent developments for classification [19], we derive a new algorithm capable of dealing with different regression loss functions, discuss its properties and investigate the relations to other methods like Boosted Trees. We evaluate ARFs on standard machine learning benchmarks, where we observe better generalization power compared to both standard Random Forests and Boosted Trees. Moreover, we apply the proposed regressor to two computer vision applications: object detection and head pose estimation from depth images. ARFs outperform the Random Forest baselines in both tasks, illustrating the importance of optimizing a common loss function for all trees.</p><p>3 0.84199923 <a title="404-lsi-3" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>Author: Christoph Straehle, Ullrich Koethe, Fred A. Hamprecht</p><p>Abstract: We propose a scheme that allows to partition an image into a previously unknown number of segments, using only minimal supervision in terms of a few must-link and cannotlink annotations. We make no use of regional data terms, learning instead what constitutes a likely boundary between segments. Since boundaries are only implicitly specified through cannot-link constraints, this is a hard and nonconvex latent variable problem. We address this problem in a greedy fashion using a randomized decision tree on features associated with interpixel edges. We use a structured purity criterion during tree construction and also show how a backtracking strategy can be used to prevent the greedy search from ending up in poor local optima. The proposed strategy is compared with prior art on natural images.</p><p>4 0.8118729 <a title="404-lsi-4" href="./iccv-2013-Random_Forests_of_Local_Experts_for_Pedestrian_Detection.html">336 iccv-2013-Random Forests of Local Experts for Pedestrian Detection</a></p>
<p>Author: Javier Marín, David Vázquez, Antonio M. López, Jaume Amores, Bastian Leibe</p><p>Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.</p><p>5 0.80848533 <a title="404-lsi-5" href="./iccv-2013-Revisiting_Example_Dependent_Cost-Sensitive_Learning_with_Decision_Trees.html">352 iccv-2013-Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees</a></p>
<p>Author: Oisin Mac Aodha, Gabriel J. Brostow</p><p>Abstract: Typical approaches to classification treat class labels as disjoint. For each training example, it is assumed that there is only one class label that correctly describes it, and that all other labels are equally bad. We know however, that good and bad labels are too simplistic in many scenarios, hurting accuracy. In the realm of example dependent costsensitive learning, each label is instead a vector representing a data point’s affinity for each of the classes. At test time, our goal is not to minimize the misclassification rate, but to maximize that affinity. We propose a novel example dependent cost-sensitive impurity measure for decision trees. Our experiments show that this new impurity measure improves test performance while still retaining the fast test times of standard classification trees. We compare our approach to classification trees and other cost-sensitive methods on three computer vision problems, tracking, descriptor matching, and optical flow, and show improvements in all three domains.</p><p>6 0.73087007 <a title="404-lsi-6" href="./iccv-2013-Unsupervised_Random_Forest_Manifold_Alignment_for_Lipreading.html">437 iccv-2013-Unsupervised Random Forest Manifold Alignment for Lipreading</a></p>
<p>7 0.69116497 <a title="404-lsi-7" href="./iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</a></p>
<p>8 0.66716993 <a title="404-lsi-8" href="./iccv-2013-Efficient_3D_Scene_Labeling_Using_Fields_of_Trees.html">132 iccv-2013-Efficient 3D Scene Labeling Using Fields of Trees</a></p>
<p>9 0.63087708 <a title="404-lsi-9" href="./iccv-2013-Drosophila_Embryo_Stage_Annotation_Using_Label_Propagation.html">125 iccv-2013-Drosophila Embryo Stage Annotation Using Label Propagation</a></p>
<p>10 0.62738436 <a title="404-lsi-10" href="./iccv-2013-Find_the_Best_Path%3A_An_Efficient_and_Accurate_Classifier_for_Image_Hierarchies.html">165 iccv-2013-Find the Best Path: An Efficient and Accurate Classifier for Image Hierarchies</a></p>
<p>11 0.60564119 <a title="404-lsi-11" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>12 0.60124046 <a title="404-lsi-12" href="./iccv-2013-Video_Synopsis_by_Heterogeneous_Multi-source_Correlation.html">443 iccv-2013-Video Synopsis by Heterogeneous Multi-source Correlation</a></p>
<p>13 0.59186202 <a title="404-lsi-13" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>14 0.58633673 <a title="404-lsi-14" href="./iccv-2013-Example-Based_Facade_Texture_Synthesis.html">148 iccv-2013-Example-Based Facade Texture Synthesis</a></p>
<p>15 0.57200569 <a title="404-lsi-15" href="./iccv-2013-Efficient_Pedestrian_Detection_by_Directly_Optimizing_the_Partial_Area_under_the_ROC_Curve.html">136 iccv-2013-Efficient Pedestrian Detection by Directly Optimizing the Partial Area under the ROC Curve</a></p>
<p>16 0.56471729 <a title="404-lsi-16" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>17 0.56021821 <a title="404-lsi-17" href="./iccv-2013-Detecting_Irregular_Curvilinear_Structures_in_Gray_Scale_and_Color_Imagery_Using_Multi-directional_Oriented_Flux.html">112 iccv-2013-Detecting Irregular Curvilinear Structures in Gray Scale and Color Imagery Using Multi-directional Oriented Flux</a></p>
<p>18 0.54007035 <a title="404-lsi-18" href="./iccv-2013-Multi-scale_Topological_Features_for_Hand_Posture_Representation_and_Analysis.html">278 iccv-2013-Multi-scale Topological Features for Hand Posture Representation and Analysis</a></p>
<p>19 0.53741664 <a title="404-lsi-19" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>20 0.53327328 <a title="404-lsi-20" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.106), (7, 0.021), (13, 0.013), (26, 0.115), (31, 0.059), (40, 0.036), (42, 0.097), (48, 0.022), (64, 0.032), (73, 0.045), (89, 0.173), (93, 0.137), (95, 0.014), (98, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89876807 <a title="404-lda-1" href="./iccv-2013-Detecting_Avocados_to_Zucchinis%3A_What_Have_We_Done%2C_and_Where_Are_We_Going%3F.html">109 iccv-2013-Detecting Avocados to Zucchinis: What Have We Done, and Where Are We Going?</a></p>
<p>Author: Olga Russakovsky, Jia Deng, Zhiheng Huang, Alexander C. Berg, Li Fei-Fei</p><p>Abstract: The growth of detection datasets and the multiple directions of object detection research provide both an unprecedented need and a great opportunity for a thorough evaluation of the current state of the field of categorical object detection. In this paper we strive to answer two key questions. First, where are we currently as a field: what have we done right, what still needs to be improved? Second, where should we be going in designing the next generation of object detectors? Inspired by the recent work of Hoiem et al. [10] on the standard PASCAL VOC detection dataset, we perform a large-scale study on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) data. First, we quantitatively demonstrate that this dataset provides many of the same detection challenges as the PASCAL VOC. Due to its scale of 1000 object categories, ILSVRC also provides an excellent testbed for understanding the performance of detectors as a function of several key properties of the object classes. We conduct a series of analyses looking at how different detection methods perform on a number of imagelevel and object-class-levelproperties such as texture, color, deformation, and clutter. We learn important lessons of the current object detection methods and propose a number of insights for designing the next generation object detectors.</p><p>same-paper 2 0.89714187 <a title="404-lda-2" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>Author: Piotr Dollár, C. Lawrence Zitnick</p><p>Abstract: Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets.</p><p>3 0.86240339 <a title="404-lda-3" href="./iccv-2013-Image_Guided_Depth_Upsampling_Using_Anisotropic_Total_Generalized_Variation.html">209 iccv-2013-Image Guided Depth Upsampling Using Anisotropic Total Generalized Variation</a></p>
<p>Author: David Ferstl, Christian Reinbacher, Rene Ranftl, Matthias Ruether, Horst Bischof</p><p>Abstract: In this work we present a novel method for the challenging problem of depth image upsampling. Modern depth cameras such as Kinect or Time of Flight cameras deliver dense, high quality depth measurements but are limited in their lateral resolution. To overcome this limitation we formulate a convex optimization problem using higher order regularization for depth image upsampling. In this optimization an anisotropic diffusion tensor, calculated from a high resolution intensity image, is used to guide the upsampling. We derive a numerical algorithm based on a primaldual formulation that is efficiently parallelized and runs at multiple frames per second. We show that this novel upsampling clearly outperforms state of the art approaches in terms of speed and accuracy on the widely used Middlebury 2007 datasets. Furthermore, we introduce novel datasets with highly accurate groundtruth, which, for the first time, enable to benchmark depth upsampling methods using real sensor data.</p><p>4 0.85852545 <a title="404-lda-4" href="./iccv-2013-Directed_Acyclic_Graph_Kernels_for_Action_Recognition.html">116 iccv-2013-Directed Acyclic Graph Kernels for Action Recognition</a></p>
<p>Author: Ling Wang, Hichem Sahbi</p><p>Abstract: One of the trends of action recognition consists in extracting and comparing mid-level features which encode visual and motion aspects of objects into scenes. However, when scenes contain high-level semantic actions with many interacting parts, these mid-level features are not sufficient to capture high level structures as well as high order causal relationships between moving objects resulting into a clear drop in performances. In this paper, we address this issue and we propose an alternative action recognition method based on a novel graph kernel. In the main contributions of this work, we first describe actions in videos using directed acyclic graphs (DAGs), that naturally encode pairwise interactions between moving object parts, and then we compare these DAGs by analyzing the spectrum of their sub-patterns that capture complex higher order interactions. This extraction and comparison process is computationally tractable, re- sulting from the acyclic property of DAGs, and it also defines a positive semi-definite kernel. When plugging the latter into support vector machines, we obtain an action recognition algorithm that overtakes related work, including graph-based methods, on a standard evaluation dataset.</p><p>5 0.85207999 <a title="404-lda-5" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>Author: Ming-Ming Cheng, Jonathan Warrell, Wen-Yan Lin, Shuai Zheng, Vibhav Vineet, Nigel Crook</p><p>Abstract: Detecting visually salient regions in images is one of the fundamental problems in computer vision. We propose a novel method to decompose an image into large scale perceptually homogeneous elements for efficient salient region detection, using a soft image abstraction representation. By considering both appearance similarity and spatial distribution of image pixels, the proposed representation abstracts out unnecessary image details, allowing the assignment of comparable saliency values across similar regions, and producing perceptually accurate salient region detection. We evaluate our salient region detection approach on the largest publicly available dataset with pixel accurate annotations. The experimental results show that the proposed method outperforms 18 alternate methods, reducing the mean absolute error by 25.2% compared to the previous best result, while being computationally more efficient.</p><p>6 0.85112131 <a title="404-lda-6" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<p>7 0.85085225 <a title="404-lda-7" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>8 0.849383 <a title="404-lda-8" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>9 0.84895307 <a title="404-lda-9" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>10 0.8470304 <a title="404-lda-10" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>11 0.84667778 <a title="404-lda-11" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>12 0.84666204 <a title="404-lda-12" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>13 0.84499902 <a title="404-lda-13" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>14 0.84456748 <a title="404-lda-14" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>15 0.84439272 <a title="404-lda-15" href="./iccv-2013-A_Convex_Optimization_Framework_for_Active_Learning.html">6 iccv-2013-A Convex Optimization Framework for Active Learning</a></p>
<p>16 0.84412777 <a title="404-lda-16" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>17 0.84410399 <a title="404-lda-17" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>18 0.84386438 <a title="404-lda-18" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>19 0.84319943 <a title="404-lda-19" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>20 0.84304953 <a title="404-lda-20" href="./iccv-2013-A_Max-Margin_Perspective_on_Sparse_Representation-Based_Classification.html">20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
