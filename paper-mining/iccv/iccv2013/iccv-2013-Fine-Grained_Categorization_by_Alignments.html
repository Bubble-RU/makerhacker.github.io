<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>169 iccv-2013-Fine-Grained Categorization by Alignments</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-169" href="#">iccv2013-169</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>169 iccv-2013-Fine-Grained Categorization by Alignments</h1>
<br/><p>Source: <a title="iccv-2013-169-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Gavves_Fine-Grained_Categorization_by_2013_ICCV_paper.pdf">pdf</a></p><p>Author: E. Gavves, B. Fernando, C.G.M. Snoek, A.W.M. Smeulders, T. Tuytelaars</p><p>Abstract: The aim of this paper is fine-grained categorization without human interaction. Different from prior work, which relies on detectors for specific object parts, we propose to localize distinctive details by roughly aligning the objects using just the overall shape, since implicit to fine-grained categorization is the existence of a super-class shape shared among all classes. The alignments are then used to transfer part annotations from training images to test images (supervised alignment), or to blindly yet consistently segment the object in a number of regions (unsupervised alignment). We furthermore argue that in the distinction of finegrained sub-categories, classification-oriented encodings like Fisher vectors are better suited for describing localized information than popular matching oriented features like HOG. We evaluate the method on the CU-2011 Birds and Stanford Dogs fine-grained datasets, outperforming the state-of-the-art.</p><p>Reference: <a title="iccv-2013-169-reference" href="../iccv2013_reference/iccv-2013-Fine-Grained_Categorization_by_Alignments_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fish', 0.491), ('bird', 0.395), ('align', 0.353), ('unsuperv', 0.186), ('superv', 0.169), ('dog', 0.165), ('mask', 0.155), ('beak', 0.119), ('hog', 0.115), ('stanford', 0.113), ('branson', 0.106), ('ancil', 0.101), ('pict', 0.1), ('ax', 0.096), ('princip', 0.08), ('templ', 0.08), ('rough', 0.078), ('orac', 0.078), ('categ', 0.077), ('ellips', 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="169-tfidf-1" href="./iccv-2013-Fine-Grained_Categorization_by_Alignments.html">169 iccv-2013-Fine-Grained Categorization by Alignments</a></p>
<p>Author: E. Gavves, B. Fernando, C.G.M. Snoek, A.W.M. Smeulders, T. Tuytelaars</p><p>Abstract: The aim of this paper is fine-grained categorization without human interaction. Different from prior work, which relies on detectors for specific object parts, we propose to localize distinctive details by roughly aligning the objects using just the overall shape, since implicit to fine-grained categorization is the existence of a super-class shape shared among all classes. The alignments are then used to transfer part annotations from training images to test images (supervised alignment), or to blindly yet consistently segment the object in a number of regions (unsupervised alignment). We furthermore argue that in the distinction of finegrained sub-categories, classification-oriented encodings like Fisher vectors are better suited for describing localized information than popular matching oriented features like HOG. We evaluate the method on the CU-2011 Birds and Stanford Dogs fine-grained datasets, outperforming the state-of-the-art.</p><p>2 0.28894079 <a title="169-tfidf-2" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>Author: Yuning Chai, Victor Lempitsky, Andrew Zisserman</p><p>Abstract: We propose a new method for the task of fine-grained visual categorization. The method builds a model of the baselevel category that can be fitted to images, producing highquality foreground segmentation and mid-level part localizations. The model can be learnt from the typical datasets available for fine-grained categorization, where the only annotation provided is a loose bounding box around the instance (e.g. bird) in each image. Both segmentation and part localizations are then used to encode the image content into a highly-discriminative visual signature. The model is symbiotic in that part discovery/localization is helped by segmentation and, conversely, the segmentation is helped by the detection (e.g. part layout). Our model builds on top of the part-based object category detector of Felzenszwalb et al., and also on the powerful GrabCut segmentation algorithm of Rother et al., and adds a simple spatial saliency coupling between them. In our evaluation, the model improves the categorization accuracy over the state-of-the-art. It also improves over what can be achieved with an analogous system that runs segmentation and part-localization independently.</p><p>3 0.2505627 <a title="169-tfidf-3" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>Author: Ramazan Gokberk Cinbis, Jakob Verbeek, Cordelia Schmid</p><p>Abstract: We present an object detection system based on the Fisher vector (FV) image representation computed over SIFT and color descriptors. For computational and storage efficiency, we use a recent segmentation-based method to generate class-independent object detection hypotheses, in combination with data compression techniques. Our main contribution is a method to produce tentative object segmentation masks to suppress background clutter in the features. Re-weighting the local image features based on these masks is shown to improve object detection significantly. We also exploit contextual features in the form of a full-image FV descriptor, and an inter-category rescoring mechanism. Our experiments on the PASCAL VOC 2007 and 2010 datasets show that our detector improves over the current state-of-the-art detection results.</p><p>4 0.23754758 <a title="169-tfidf-4" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>Author: Ning Zhang, Ryan Farrell, Forrest Iandola, Trevor Darrell</p><p>Abstract: Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.</p><p>5 0.22901893 <a title="169-tfidf-5" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<p>Author: Thomas Berg, Peter N. Belhumeur</p><p>Abstract: How do you tell a blackbirdfrom a crow? There has been great progress toward automatic methods for visual recognition, including fine-grained visual categorization in which the classes to be distinguished are very similar. In a task such as bird species recognition, automatic recognition systems can now exceed the performance of non-experts – most people are challenged to name a couple dozen bird species, let alone identify them. This leads us to the question, “Can a recognition system show humans what to look for when identifying classes (in this case birds)? ” In the context of fine-grained visual categorization, we show that we can automatically determine which classes are most visually similar, discover what visual features distinguish very similar classes, and illustrate the key features in a way meaningful to humans. Running these methods on a dataset of bird images, we can generate a visual field guide to birds which includes a tree of similarity that displays the similarity relations between all species, pages for each species showing the most similar other species, and pages for each pair of similar species illustrating their differences.</p><p>6 0.22783269 <a title="169-tfidf-6" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<p>7 0.2032062 <a title="169-tfidf-7" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>8 0.18195179 <a title="169-tfidf-8" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>9 0.17964265 <a title="169-tfidf-9" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>10 0.15167645 <a title="169-tfidf-10" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>11 0.15048477 <a title="169-tfidf-11" href="./iccv-2013-Write_a_Classifier%3A_Zero-Shot_Learning_Using_Purely_Textual_Descriptions.html">451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</a></p>
<p>12 0.14648297 <a title="169-tfidf-12" href="./iccv-2013-Codemaps_-_Segment%2C_Classify_and_Search_Objects_Locally.html">77 iccv-2013-Codemaps - Segment, Classify and Search Objects Locally</a></p>
<p>13 0.14552262 <a title="169-tfidf-13" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>14 0.13107644 <a title="169-tfidf-14" href="./iccv-2013-Detecting_Dynamic_Objects_with_Multi-view_Background_Subtraction.html">111 iccv-2013-Detecting Dynamic Objects with Multi-view Background Subtraction</a></p>
<p>15 0.13051179 <a title="169-tfidf-15" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<p>16 0.12758808 <a title="169-tfidf-16" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>17 0.12413289 <a title="169-tfidf-17" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>18 0.12073615 <a title="169-tfidf-18" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>19 0.11831988 <a title="169-tfidf-19" href="./iccv-2013-SYM-FISH%3A_A_Symmetry-Aware_Flip_Invariant_Sketch_Histogram_Shape_Descriptor.html">368 iccv-2013-SYM-FISH: A Symmetry-Aware Flip Invariant Sketch Histogram Shape Descriptor</a></p>
<p>20 0.11811897 <a title="169-tfidf-20" href="./iccv-2013-Parsing_IKEA_Objects%3A_Fine_Pose_Estimation.html">308 iccv-2013-Parsing IKEA Objects: Fine Pose Estimation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.267), (1, -0.033), (2, -0.082), (3, -0.067), (4, -0.011), (5, 0.014), (6, 0.079), (7, -0.126), (8, 0.053), (9, -0.127), (10, 0.034), (11, 0.044), (12, 0.17), (13, 0.142), (14, -0.005), (15, 0.066), (16, -0.035), (17, 0.058), (18, -0.045), (19, -0.173), (20, 0.101), (21, -0.02), (22, 0.04), (23, -0.021), (24, 0.031), (25, -0.058), (26, -0.123), (27, 0.006), (28, 0.067), (29, -0.034), (30, -0.044), (31, 0.086), (32, -0.189), (33, -0.013), (34, -0.112), (35, 0.032), (36, -0.107), (37, 0.133), (38, -0.068), (39, -0.042), (40, -0.089), (41, 0.088), (42, -0.054), (43, 0.084), (44, 0.051), (45, 0.04), (46, -0.063), (47, -0.006), (48, -0.07), (49, -0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92766076 <a title="169-lsi-1" href="./iccv-2013-Fine-Grained_Categorization_by_Alignments.html">169 iccv-2013-Fine-Grained Categorization by Alignments</a></p>
<p>Author: E. Gavves, B. Fernando, C.G.M. Snoek, A.W.M. Smeulders, T. Tuytelaars</p><p>Abstract: The aim of this paper is fine-grained categorization without human interaction. Different from prior work, which relies on detectors for specific object parts, we propose to localize distinctive details by roughly aligning the objects using just the overall shape, since implicit to fine-grained categorization is the existence of a super-class shape shared among all classes. The alignments are then used to transfer part annotations from training images to test images (supervised alignment), or to blindly yet consistently segment the object in a number of regions (unsupervised alignment). We furthermore argue that in the distinction of finegrained sub-categories, classification-oriented encodings like Fisher vectors are better suited for describing localized information than popular matching oriented features like HOG. We evaluate the method on the CU-2011 Birds and Stanford Dogs fine-grained datasets, outperforming the state-of-the-art.</p><p>2 0.83913988 <a title="169-lsi-2" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<p>Author: Thomas Berg, Peter N. Belhumeur</p><p>Abstract: How do you tell a blackbirdfrom a crow? There has been great progress toward automatic methods for visual recognition, including fine-grained visual categorization in which the classes to be distinguished are very similar. In a task such as bird species recognition, automatic recognition systems can now exceed the performance of non-experts – most people are challenged to name a couple dozen bird species, let alone identify them. This leads us to the question, “Can a recognition system show humans what to look for when identifying classes (in this case birds)? ” In the context of fine-grained visual categorization, we show that we can automatically determine which classes are most visually similar, discover what visual features distinguish very similar classes, and illustrate the key features in a way meaningful to humans. Running these methods on a dataset of bird images, we can generate a visual field guide to birds which includes a tree of similarity that displays the similarity relations between all species, pages for each species showing the most similar other species, and pages for each pair of similar species illustrating their differences.</p><p>3 0.74121332 <a title="169-lsi-3" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>Author: Yuning Chai, Victor Lempitsky, Andrew Zisserman</p><p>Abstract: We propose a new method for the task of fine-grained visual categorization. The method builds a model of the baselevel category that can be fitted to images, producing highquality foreground segmentation and mid-level part localizations. The model can be learnt from the typical datasets available for fine-grained categorization, where the only annotation provided is a loose bounding box around the instance (e.g. bird) in each image. Both segmentation and part localizations are then used to encode the image content into a highly-discriminative visual signature. The model is symbiotic in that part discovery/localization is helped by segmentation and, conversely, the segmentation is helped by the detection (e.g. part layout). Our model builds on top of the part-based object category detector of Felzenszwalb et al., and also on the powerful GrabCut segmentation algorithm of Rother et al., and adds a simple spatial saliency coupling between them. In our evaluation, the model improves the categorization accuracy over the state-of-the-art. It also improves over what can be achieved with an analogous system that runs segmentation and part-localization independently.</p><p>4 0.71611053 <a title="169-lsi-4" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>Author: Ning Zhang, Ryan Farrell, Forrest Iandola, Trevor Darrell</p><p>Abstract: Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.</p><p>5 0.70254302 <a title="169-lsi-5" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>Author: Lingxi Xie, Qi Tian, Richang Hong, Shuicheng Yan, Bo Zhang</p><p>Abstract: As a special topic in computer vision, , fine-grained visual categorization (FGVC) has been attracting growing attention these years. Different with traditional image classification tasks in which objects have large inter-class variation, the visual concepts in the fine-grained datasets, such as hundreds of bird species, often have very similar semantics. Due to the large inter-class similarity, it is very difficult to classify the objects without locating really discriminative features, therefore it becomes more important for the algorithm to make full use of the part information in order to train a robust model. In this paper, we propose a powerful flowchart named Hierarchical Part Matching (HPM) to cope with finegrained classification tasks. We extend the Bag-of-Features (BoF) model by introducing several novel modules to integrate into image representation, including foreground inference and segmentation, Hierarchical Structure Learn- ing (HSL), and Geometric Phrase Pooling (GPP). We verify in experiments that our algorithm achieves the state-ofthe-art classification accuracy in the Caltech-UCSD-Birds200-2011 dataset by making full use of the ground-truth part annotations.</p><p>6 0.64741313 <a title="169-lsi-6" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>7 0.61575258 <a title="169-lsi-7" href="./iccv-2013-Codemaps_-_Segment%2C_Classify_and_Search_Objects_Locally.html">77 iccv-2013-Codemaps - Segment, Classify and Search Objects Locally</a></p>
<p>8 0.60354173 <a title="169-lsi-8" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<p>9 0.59848022 <a title="169-lsi-9" href="./iccv-2013-From_Subcategories_to_Visual_Composites%3A_A_Multi-level_Framework_for_Object_Detection.html">179 iccv-2013-From Subcategories to Visual Composites: A Multi-level Framework for Object Detection</a></p>
<p>10 0.58988822 <a title="169-lsi-10" href="./iccv-2013-Segmentation_Driven_Object_Detection_with_Fisher_Vectors.html">377 iccv-2013-Segmentation Driven Object Detection with Fisher Vectors</a></p>
<p>11 0.5870015 <a title="169-lsi-11" href="./iccv-2013-Detecting_Avocados_to_Zucchinis%3A_What_Have_We_Done%2C_and_Where_Are_We_Going%3F.html">109 iccv-2013-Detecting Avocados to Zucchinis: What Have We Done, and Where Are We Going?</a></p>
<p>12 0.55559087 <a title="169-lsi-12" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>13 0.53451133 <a title="169-lsi-13" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>14 0.52888751 <a title="169-lsi-14" href="./iccv-2013-Shufflets%3A_Shared_Mid-level_Parts_for_Fast_Object_Detection.html">390 iccv-2013-Shufflets: Shared Mid-level Parts for Fast Object Detection</a></p>
<p>15 0.52765816 <a title="169-lsi-15" href="./iccv-2013-Shape_Index_Descriptors_Applied_to_Texture-Based_Galaxy_Analysis.html">388 iccv-2013-Shape Index Descriptors Applied to Texture-Based Galaxy Analysis</a></p>
<p>16 0.52327895 <a title="169-lsi-16" href="./iccv-2013-Style-Aware_Mid-level_Representation_for_Discovering_Visual_Connections_in_Space_and_Time.html">406 iccv-2013-Style-Aware Mid-level Representation for Discovering Visual Connections in Space and Time</a></p>
<p>17 0.52223545 <a title="169-lsi-17" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>18 0.51791692 <a title="169-lsi-18" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>19 0.51440889 <a title="169-lsi-19" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>20 0.51182795 <a title="169-lsi-20" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.069), (20, 0.11), (25, 0.019), (28, 0.017), (42, 0.117), (48, 0.264), (55, 0.012), (60, 0.011), (77, 0.199), (78, 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95452559 <a title="169-lda-1" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>Author: Ivan Sipiran, Benjamin Bustos</p><p>Abstract: This paper presents a hierarchical method for finding correspondences in non-rigid shapes. We propose a new representation for 3D meshes: the decomposition tree. This structure characterizes the recursive decomposition process of a mesh into regions of interest and keypoints. The internal nodes contain regions of interest (which may be recursively decomposed) and the leaf nodes contain the keypoints to be matched. We also propose a hierarchical matching algorithm that performs in a level-wise manner. The matching process is guided by the similarity between regions in high levels of the tree, until reaching the keypoints stored in the leaves. This allows us to reduce the search space of correspondences, making also the matching process efficient. We evaluate the effectiveness of our approach using the SHREC’2010 robust correspondence benchmark. In addition, we show that our results outperform the state of the art.</p><p>2 0.95112669 <a title="169-lda-2" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>Author: Ning Zhang, Ryan Farrell, Forrest Iandola, Trevor Darrell</p><p>Abstract: Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.</p><p>3 0.9494673 <a title="169-lda-3" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>Author: Honghui Zhang, Jingdong Wang, Ping Tan, Jinglu Wang, Long Quan</p><p>Abstract: We propose an adaptive subgradient descent method to efficiently learn the parameters of CRF models for image parsing. To balance the learning efficiency and performance of the learned CRF models, the parameter learning is iteratively carried out by solving a convex optimization problem in each iteration, which integrates a proximal term to preserve the previously learned information and the large margin preference to distinguish bad labeling and the ground truth labeling. A solution of subgradient descent updating form is derived for the convex optimization problem, with an adaptively determined updating step-size. Besides, to deal with partially labeled training data, we propose a new objective constraint modeling both the labeled and unlabeled parts in the partially labeled training data for the parameter learning of CRF models. The superior learning efficiency of the proposed method is verified by the experiment results on two public datasets. We also demonstrate the powerfulness of our method for handling partially labeled training data.</p><p>4 0.94901204 <a title="169-lda-4" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<p>Author: David Weiss, Benjamin Sapp, Ben Taskar</p><p>Abstract: Ben Taskar University of Washington Seattle, WA t as kar @ c s . washingt on . edu In many cases, the predictive power of structured models for for complex vision tasks is limited by a trade-off between the expressiveness and the computational tractability of the model. However, choosing this trade-off statically a priori is suboptimal, as images and videos in different settings vary tremendously in complexity. On the other hand, choosing the trade-off dynamically requires knowledge about the accuracy of different structured models on any given example. In this work, we propose a novel two-tier architecture that provides dynamic speed/accuracy trade-offs through a simple type of introspection. Our approach, which we call dynamic structured model selection (DMS), leverages typically intractable features in structured learning problems in order to automatically determine ’ which of several models should be used at test-time in order to maximize accuracy under a fixed budgetary constraint. We demonstrate DMS on two sequential modeling vision tasks, and we establish a new state-of-the-art in human pose estimation in video with an implementation that is roughly 23 faster than the prevaino uims sptleanmdeanrtda implementation.</p><p>5 0.94809449 <a title="169-lda-5" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>Author: Xiao Cai, Feiping Nie, Weidong Cai, Heng Huang</p><p>Abstract: In multi-label image annotations, because each image is associated to multiple categories, the semantic terms (label classes) are not mutually exclusive. Previous research showed that such label correlations can largely boost the annotation accuracy. However, all existing methods only directly apply the label correlation matrix to enhance the label inference and assignment without further learning the structural information among classes. In this paper, we model the label correlations using the relational graph, and propose a novel graph structured sparse learning model to incorporate the topological constraints of relation graph in multi-label classifications. As a result, our new method will capture and utilize the hidden class structures in relational graph to improve the annotation results. In proposed objective, a large number of structured sparsity-inducing norms are utilized, thus the optimization becomes difficult. To solve this problem, we derive an efficient optimization algorithm with proved convergence. We perform extensive experiments on six multi-label image annotation benchmark data sets. In all empirical results, our new method shows better annotation results than the state-of-the-art approaches.</p><p>6 0.94773543 <a title="169-lda-6" href="./iccv-2013-Modeling_4D_Human-Object_Interactions_for_Event_and_Object_Recognition.html">268 iccv-2013-Modeling 4D Human-Object Interactions for Event and Object Recognition</a></p>
<p>7 0.94685662 <a title="169-lda-7" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>8 0.94630551 <a title="169-lda-8" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>9 0.94487512 <a title="169-lda-9" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>10 0.94209629 <a title="169-lda-10" href="./iccv-2013-Lifting_3D_Manhattan_Lines_from_a_Single_Image.html">250 iccv-2013-Lifting 3D Manhattan Lines from a Single Image</a></p>
<p>11 0.9404732 <a title="169-lda-11" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>12 0.93998957 <a title="169-lda-12" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>13 0.93949276 <a title="169-lda-13" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>14 0.93930233 <a title="169-lda-14" href="./iccv-2013-Pose_Estimation_and_Segmentation_of_People_in_3D_Movies.html">322 iccv-2013-Pose Estimation and Segmentation of People in 3D Movies</a></p>
<p>15 0.93917024 <a title="169-lda-15" href="./iccv-2013-Shape_Anchors_for_Data-Driven_Multi-view_Reconstruction.html">387 iccv-2013-Shape Anchors for Data-Driven Multi-view Reconstruction</a></p>
<p>16 0.93857729 <a title="169-lda-16" href="./iccv-2013-3D_Scene_Understanding_by_Voxel-CRF.html">2 iccv-2013-3D Scene Understanding by Voxel-CRF</a></p>
<p>17 0.93805057 <a title="169-lda-17" href="./iccv-2013-Constant_Time_Weighted_Median_Filtering_for_Stereo_Matching_and_Beyond.html">88 iccv-2013-Constant Time Weighted Median Filtering for Stereo Matching and Beyond</a></p>
<p>18 0.93796754 <a title="169-lda-18" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>19 0.93703622 <a title="169-lda-19" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>20 0.93687528 <a title="169-lda-20" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
