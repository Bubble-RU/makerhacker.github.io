<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-451" href="#">iccv2013-451</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</h1>
<br/><p>Source: <a title="iccv-2013-451-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Elhoseiny_Write_a_Classifier_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Mohamed Elhoseiny, Babak Saleh, Ahmed Elgammal</p><p>Abstract: The main question we address in this paper is how to use purely textual description of categories with no training images to learn visual classifiers for these categories. We propose an approach for zero-shot learning of object categories where the description of unseen categories comes in the form of typical text such as an encyclopedia entry, without the need to explicitly defined attributes. We propose and investigate two baseline formulations, based on regression and domain adaptation. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the classifier parameters for new classes. We applied the proposed approach on two fine-grained categorization datasets, and the results indicate successful classifier prediction.</p><p>Reference: <a title="iccv-2013-451-reference" href="../iccv2013_reference/iccv-2013-Write_a_Classifier%3A_Zero-Shot_Learning_Using_Purely_Textual_Descriptions_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tgp', 0.326), ('unseen', 0.268), ('auc', 0.259), ('text', 0.216), ('bird', 0.211), ('domain', 0.192), ('regress', 0.173), ('preg', 0.173), ('clsi', 0.163), ('kc', 0.151), ('transf', 0.145), ('nsc', 0.134), ('predict', 0.133), ('class', 0.13), ('kt', 0.116), ('flow', 0.115), ('categ', 0.114), ('wikiped', 0.102), ('amend', 0.101), ('classem', 0.096)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999917 <a title="451-tfidf-1" href="./iccv-2013-Write_a_Classifier%3A_Zero-Shot_Learning_Using_Purely_Textual_Descriptions.html">451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</a></p>
<p>Author: Mohamed Elhoseiny, Babak Saleh, Ahmed Elgammal</p><p>Abstract: The main question we address in this paper is how to use purely textual description of categories with no training images to learn visual classifiers for these categories. We propose an approach for zero-shot learning of object categories where the description of unseen categories comes in the form of typical text such as an encyclopedia entry, without the need to explicitly defined attributes. We propose and investigate two baseline formulations, based on regression and domain adaptation. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the classifier parameters for new classes. We applied the proposed approach on two fine-grained categorization datasets, and the results indicate successful classifier prediction.</p><p>2 0.23926978 <a title="451-tfidf-2" href="./iccv-2013-Domain_Adaptive_Classification.html">123 iccv-2013-Domain Adaptive Classification</a></p>
<p>Author: Fatemeh Mirrashed, Mohammad Rastegari</p><p>Abstract: We propose an unsupervised domain adaptation method that exploits intrinsic compact structures of categories across different domains using binary attributes. Our method directly optimizes for classification in the target domain. The key insight is finding attributes that are discriminative across categories and predictable across domains. We achieve a performance that significantly exceeds the state-of-the-art results on standard benchmarks. In fact, in many cases, our method reaches the same-domain performance, the upper bound, in unsupervised domain adaptation scenarios.</p><p>3 0.16914965 <a title="451-tfidf-3" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>Author: Vicente Ordonez, Jia Deng, Yejin Choi, Alexander C. Berg, Tamara L. Berg</p><p>Abstract: Entry level categories the labels people will use to name an object were originally defined and studied by psychologists in the 1980s. In this paper we study entrylevel categories at a large scale and learn the first models for predicting entry-level categories for images. Our models combine visual recognition predictions with proxies for word “naturalness ” mined from the enormous amounts of text on the web. We demonstrate the usefulness of our models for predicting nouns (entry-level words) associated with images by people. We also learn mappings between concepts predicted by existing visual recognition systems and entry-level concepts that could be useful for improving human-focused applications such as natural language image description or retrieval. – –</p><p>4 0.15648954 <a title="451-tfidf-4" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<p>Author: Basura Fernando, Amaury Habrard, Marc Sebban, Tinne Tuytelaars</p><p>Abstract: In this paper, we introduce a new domain adaptation (DA) algorithm where the source and target domains are represented by subspaces described by eigenvectors. In this context, our method seeks a domain adaptation solution by learning a mapping function which aligns the source subspace with the target one. We show that the solution of the corresponding optimization problem can be obtained in a simple closed form, leading to an extremely fast algorithm. We use a theoretical result to tune the unique hyperparameter corresponding to the size of the subspaces. We run our method on various datasets and show that, despite its intrinsic simplicity, it outperforms state of the art DA methods.</p><p>5 0.15048477 <a title="451-tfidf-5" href="./iccv-2013-Fine-Grained_Categorization_by_Alignments.html">169 iccv-2013-Fine-Grained Categorization by Alignments</a></p>
<p>Author: E. Gavves, B. Fernando, C.G.M. Snoek, A.W.M. Smeulders, T. Tuytelaars</p><p>Abstract: The aim of this paper is fine-grained categorization without human interaction. Different from prior work, which relies on detectors for specific object parts, we propose to localize distinctive details by roughly aligning the objects using just the overall shape, since implicit to fine-grained categorization is the existence of a super-class shape shared among all classes. The alignments are then used to transfer part annotations from training images to test images (supervised alignment), or to blindly yet consistently segment the object in a number of regions (unsupervised alignment). We furthermore argue that in the distinction of finegrained sub-categories, classification-oriented encodings like Fisher vectors are better suited for describing localized information than popular matching oriented features like HOG. We evaluate the method on the CU-2011 Birds and Stanford Dogs fine-grained datasets, outperforming the state-of-the-art.</p><p>6 0.14971608 <a title="451-tfidf-6" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>7 0.14863864 <a title="451-tfidf-7" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>8 0.1328807 <a title="451-tfidf-8" href="./iccv-2013-Semantic_Transform%3A_Weakly_Supervised_Semantic_Inference_for_Relating_Visual_Attributes.html">380 iccv-2013-Semantic Transform: Weakly Supervised Semantic Inference for Relating Visual Attributes</a></p>
<p>9 0.13019644 <a title="451-tfidf-9" href="./iccv-2013-Attribute_Adaptation_for_Personalized_Image_Search.html">52 iccv-2013-Attribute Adaptation for Personalized Image Search</a></p>
<p>10 0.12895547 <a title="451-tfidf-10" href="./iccv-2013-Attribute_Dominance%3A_What_Pops_Out%3F.html">53 iccv-2013-Attribute Dominance: What Pops Out?</a></p>
<p>11 0.12697718 <a title="451-tfidf-11" href="./iccv-2013-A_Unified_Probabilistic_Approach_Modeling_Relationships_between_Attributes_and_Objects.html">31 iccv-2013-A Unified Probabilistic Approach Modeling Relationships between Attributes and Objects</a></p>
<p>12 0.123959 <a title="451-tfidf-12" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<p>13 0.12381857 <a title="451-tfidf-13" href="./iccv-2013-Unsupervised_Domain_Adaptation_by_Domain_Invariant_Projection.html">435 iccv-2013-Unsupervised Domain Adaptation by Domain Invariant Projection</a></p>
<p>14 0.12362412 <a title="451-tfidf-14" href="./iccv-2013-Unbiased_Metric_Learning%3A_On_the_Utilization_of_Multiple_Datasets_and_Web_Images_for_Softening_Bias.html">431 iccv-2013-Unbiased Metric Learning: On the Utilization of Multiple Datasets and Web Images for Softening Bias</a></p>
<p>15 0.11215895 <a title="451-tfidf-15" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<p>16 0.1114124 <a title="451-tfidf-16" href="./iccv-2013-YouTube2Text%3A_Recognizing_and_Describing_Arbitrary_Activities_Using_Semantic_Hierarchies_and_Zero-Shot_Recognition.html">452 iccv-2013-YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition</a></p>
<p>17 0.1086256 <a title="451-tfidf-17" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>18 0.10656524 <a title="451-tfidf-18" href="./iccv-2013-Learning_the_Visual_Interpretation_of_Sentences.html">246 iccv-2013-Learning the Visual Interpretation of Sentences</a></p>
<p>19 0.10351309 <a title="451-tfidf-19" href="./iccv-2013-Video_Event_Understanding_Using_Natural_Language_Descriptions.html">440 iccv-2013-Video Event Understanding Using Natural Language Descriptions</a></p>
<p>20 0.10284757 <a title="451-tfidf-20" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.227), (1, -0.075), (2, -0.169), (3, -0.044), (4, -0.03), (5, 0.043), (6, 0.025), (7, -0.002), (8, -0.094), (9, -0.063), (10, 0.009), (11, 0.014), (12, 0.028), (13, 0.038), (14, 0.159), (15, 0.008), (16, 0.099), (17, -0.012), (18, -0.148), (19, -0.026), (20, 0.046), (21, 0.004), (22, -0.051), (23, -0.078), (24, -0.129), (25, 0.036), (26, -0.177), (27, -0.023), (28, 0.01), (29, -0.002), (30, 0.006), (31, 0.044), (32, -0.054), (33, -0.09), (34, -0.095), (35, 0.036), (36, -0.054), (37, 0.04), (38, 0.088), (39, 0.042), (40, -0.01), (41, 0.055), (42, 0.015), (43, -0.002), (44, 0.048), (45, -0.04), (46, -0.028), (47, -0.013), (48, -0.013), (49, -0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90318727 <a title="451-lsi-1" href="./iccv-2013-Write_a_Classifier%3A_Zero-Shot_Learning_Using_Purely_Textual_Descriptions.html">451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</a></p>
<p>Author: Mohamed Elhoseiny, Babak Saleh, Ahmed Elgammal</p><p>Abstract: The main question we address in this paper is how to use purely textual description of categories with no training images to learn visual classifiers for these categories. We propose an approach for zero-shot learning of object categories where the description of unseen categories comes in the form of typical text such as an encyclopedia entry, without the need to explicitly defined attributes. We propose and investigate two baseline formulations, based on regression and domain adaptation. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the classifier parameters for new classes. We applied the proposed approach on two fine-grained categorization datasets, and the results indicate successful classifier prediction.</p><p>2 0.73691577 <a title="451-lsi-2" href="./iccv-2013-Domain_Adaptive_Classification.html">123 iccv-2013-Domain Adaptive Classification</a></p>
<p>Author: Fatemeh Mirrashed, Mohammad Rastegari</p><p>Abstract: We propose an unsupervised domain adaptation method that exploits intrinsic compact structures of categories across different domains using binary attributes. Our method directly optimizes for classification in the target domain. The key insight is finding attributes that are discriminative across categories and predictable across domains. We achieve a performance that significantly exceeds the state-of-the-art results on standard benchmarks. In fact, in many cases, our method reaches the same-domain performance, the upper bound, in unsupervised domain adaptation scenarios.</p><p>3 0.72268337 <a title="451-lsi-3" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>Author: Vicente Ordonez, Jia Deng, Yejin Choi, Alexander C. Berg, Tamara L. Berg</p><p>Abstract: Entry level categories the labels people will use to name an object were originally defined and studied by psychologists in the 1980s. In this paper we study entrylevel categories at a large scale and learn the first models for predicting entry-level categories for images. Our models combine visual recognition predictions with proxies for word “naturalness ” mined from the enormous amounts of text on the web. We demonstrate the usefulness of our models for predicting nouns (entry-level words) associated with images by people. We also learn mappings between concepts predicted by existing visual recognition systems and entry-level concepts that could be useful for improving human-focused applications such as natural language image description or retrieval. – –</p><p>4 0.69475055 <a title="451-lsi-4" href="./iccv-2013-Frustratingly_Easy_NBNN_Domain_Adaptation.html">181 iccv-2013-Frustratingly Easy NBNN Domain Adaptation</a></p>
<p>Author: Tatiana Tommasi, Barbara Caputo</p><p>Abstract: Over the last years, several authors have signaled that state of the art categorization methods fail to perform well when trained and tested on data from different databases. The general consensus in the literature is that this issue, known as domain adaptation and/or dataset bias, is due to a distribution mismatch between data collections. Methods addressing it go from max-margin classifiers to learning how to modify the features and obtain a more robust representation. The large majority of these works use BOW feature descriptors, and learning methods based on imageto-image distance functions. Following the seminal work of [6], in this paper we challenge these two assumptions. We experimentally show that using the NBNN classifier over existing domain adaptation databases achieves always very strong performances. We build on this result, and present an NBNN-based domain adaptation algorithm that learns iteratively a class metric while inducing, for each sample, a large margin separation among classes. To the best of our knowledge, this is the first work casting the domain adaptation problem within the NBNN framework. Experiments show that our method achieves the state of the art, both in the unsupervised and semi-supervised settings.</p><p>5 0.68000931 <a title="451-lsi-5" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<p>Author: Thomas Berg, Peter N. Belhumeur</p><p>Abstract: How do you tell a blackbirdfrom a crow? There has been great progress toward automatic methods for visual recognition, including fine-grained visual categorization in which the classes to be distinguished are very similar. In a task such as bird species recognition, automatic recognition systems can now exceed the performance of non-experts – most people are challenged to name a couple dozen bird species, let alone identify them. This leads us to the question, “Can a recognition system show humans what to look for when identifying classes (in this case birds)? ” In the context of fine-grained visual categorization, we show that we can automatically determine which classes are most visually similar, discover what visual features distinguish very similar classes, and illustrate the key features in a way meaningful to humans. Running these methods on a dataset of bird images, we can generate a visual field guide to birds which includes a tree of similarity that displays the similarity relations between all species, pages for each species showing the most similar other species, and pages for each pair of similar species illustrating their differences.</p><p>6 0.67698503 <a title="451-lsi-6" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<p>7 0.66841274 <a title="451-lsi-7" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>8 0.64081824 <a title="451-lsi-8" href="./iccv-2013-Unsupervised_Domain_Adaptation_by_Domain_Invariant_Projection.html">435 iccv-2013-Unsupervised Domain Adaptation by Domain Invariant Projection</a></p>
<p>9 0.62999183 <a title="451-lsi-9" href="./iccv-2013-Learning_the_Visual_Interpretation_of_Sentences.html">246 iccv-2013-Learning the Visual Interpretation of Sentences</a></p>
<p>10 0.61442423 <a title="451-lsi-10" href="./iccv-2013-Learning_to_Rank_Using_Privileged_Information.html">248 iccv-2013-Learning to Rank Using Privileged Information</a></p>
<p>11 0.60577101 <a title="451-lsi-11" href="./iccv-2013-Unbiased_Metric_Learning%3A_On_the_Utilization_of_Multiple_Datasets_and_Web_Images_for_Softening_Bias.html">431 iccv-2013-Unbiased Metric Learning: On the Utilization of Multiple Datasets and Web Images for Softening Bias</a></p>
<p>12 0.5949176 <a title="451-lsi-12" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<p>13 0.59434611 <a title="451-lsi-13" href="./iccv-2013-Cross-View_Action_Recognition_over_Heterogeneous_Feature_Spaces.html">99 iccv-2013-Cross-View Action Recognition over Heterogeneous Feature Spaces</a></p>
<p>14 0.59332263 <a title="451-lsi-14" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>15 0.58962566 <a title="451-lsi-15" href="./iccv-2013-Translating_Video_Content_to_Natural_Language_Descriptions.html">428 iccv-2013-Translating Video Content to Natural Language Descriptions</a></p>
<p>16 0.58702445 <a title="451-lsi-16" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>17 0.58240646 <a title="451-lsi-17" href="./iccv-2013-Domain_Transfer_Support_Vector_Ranking_for_Person_Re-identification_without_Target_Camera_Label_Information.html">124 iccv-2013-Domain Transfer Support Vector Ranking for Person Re-identification without Target Camera Label Information</a></p>
<p>18 0.57335311 <a title="451-lsi-18" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>19 0.57298273 <a title="451-lsi-19" href="./iccv-2013-Video_Synopsis_by_Heterogeneous_Multi-source_Correlation.html">443 iccv-2013-Video Synopsis by Heterogeneous Multi-source Correlation</a></p>
<p>20 0.57124329 <a title="451-lsi-20" href="./iccv-2013-Coupled_Dictionary_and_Feature_Space_Learning_with_Applications_to_Cross-Domain_Image_Synthesis_and_Recognition.html">96 iccv-2013-Coupled Dictionary and Feature Space Learning with Applications to Cross-Domain Image Synthesis and Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.012), (13, 0.078), (20, 0.09), (25, 0.02), (26, 0.025), (28, 0.024), (33, 0.023), (42, 0.089), (48, 0.163), (55, 0.013), (77, 0.098), (89, 0.015), (92, 0.286)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.75457716 <a title="451-lda-1" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>Author: Lilian Calvet, Pierre Gurdjos</p><p>Abstract: This work aims at introducing a new unified Structurefrom-Motion (SfM) paradigm in which images of circular point-pairs can be combined with images of natural points. An imaged circular point-pair encodes the 2D Euclidean structure of a world plane and can easily be derived from the image of a planar shape, especially those including circles. A classical SfM method generally runs two steps: first a projective factorization of all matched image points (into projective cameras and points) and second a camera selfcalibration that updates the obtained world from projective to Euclidean. This work shows how to introduce images of circular points in these two SfM steps while its key contribution is to provide the theoretical foundations for combining “classical” linear self-calibration constraints with additional ones derived from such images. We show that the two proposed SfM steps clearly contribute to better results than the classical approach. We validate our contributions on synthetic and real images.</p><p>same-paper 2 0.69683576 <a title="451-lda-2" href="./iccv-2013-Write_a_Classifier%3A_Zero-Shot_Learning_Using_Purely_Textual_Descriptions.html">451 iccv-2013-Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</a></p>
<p>Author: Mohamed Elhoseiny, Babak Saleh, Ahmed Elgammal</p><p>Abstract: The main question we address in this paper is how to use purely textual description of categories with no training images to learn visual classifiers for these categories. We propose an approach for zero-shot learning of object categories where the description of unseen categories comes in the form of typical text such as an encyclopedia entry, without the need to explicitly defined attributes. We propose and investigate two baseline formulations, based on regression and domain adaptation. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the classifier parameters for new classes. We applied the proposed approach on two fine-grained categorization datasets, and the results indicate successful classifier prediction.</p><p>3 0.65182388 <a title="451-lda-3" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>Author: Oren Barkan, Jonathan Weill, Lior Wolf, Hagai Aronowitz</p><p>Abstract: This paper advances descriptor-based face recognition by suggesting a novel usage of descriptors to form an over-complete representation, and by proposing a new metric learning pipeline within the same/not-same framework. First, the Over-Complete Local Binary Patterns (OCLBP) face representation scheme is introduced as a multi-scale modified version of the Local Binary Patterns (LBP) scheme. Second, we propose an efficient matrix-vector multiplication-based recognition system. The system is based on Linear Discriminant Analysis (LDA) coupled with Within Class Covariance Normalization (WCCN). This is further extended to the unsupervised case by proposing an unsupervised variant of WCCN. Lastly, we introduce Diffusion Maps (DM) for non-linear dimensionality reduction as an alternative to the Whitened Principal Component Analysis (WPCA) method which is often used in face recognition. We evaluate the proposed framework on the LFW face recognition dataset under the restricted, unrestricted and unsupervised protocols. In all three cases we achieve very competitive results.</p><p>4 0.65092212 <a title="451-lda-4" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>Author: Susanna Ricco, Carlo Tomasi</p><p>Abstract: Dense motion of image points over many video frames can provide important information about the world. However, occlusions and drift make it impossible to compute long motionpaths by merely concatenating opticalflow vectors between consecutive frames. Instead, we solve for entire paths directly, and flag the frames in which each is visible. As in previous work, we anchor each path to a unique pixel which guarantees an even spatial distribution of paths. Unlike earlier methods, we allow paths to be anchored in any frame. By explicitly requiring that at least one visible path passes within a small neighborhood of every pixel, we guarantee complete coverage of all visible points in all frames. We achieve state-of-the-art results on real sequences including both rigid and non-rigid motions with significant occlusions.</p><p>5 0.63501513 <a title="451-lda-5" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>Author: Christoph Straehle, Ullrich Koethe, Fred A. Hamprecht</p><p>Abstract: We propose a scheme that allows to partition an image into a previously unknown number of segments, using only minimal supervision in terms of a few must-link and cannotlink annotations. We make no use of regional data terms, learning instead what constitutes a likely boundary between segments. Since boundaries are only implicitly specified through cannot-link constraints, this is a hard and nonconvex latent variable problem. We address this problem in a greedy fashion using a randomized decision tree on features associated with interpixel edges. We use a structured purity criterion during tree construction and also show how a backtracking strategy can be used to prevent the greedy search from ending up in poor local optima. The proposed strategy is compared with prior art on natural images.</p><p>6 0.62910891 <a title="451-lda-6" href="./iccv-2013-Constant_Time_Weighted_Median_Filtering_for_Stereo_Matching_and_Beyond.html">88 iccv-2013-Constant Time Weighted Median Filtering for Stereo Matching and Beyond</a></p>
<p>7 0.62867975 <a title="451-lda-7" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>8 0.62646168 <a title="451-lda-8" href="./iccv-2013-Shortest_Paths_with_Curvature_and_Torsion.html">389 iccv-2013-Shortest Paths with Curvature and Torsion</a></p>
<p>9 0.62545967 <a title="451-lda-9" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>10 0.6254341 <a title="451-lda-10" href="./iccv-2013-Slice_Sampling_Particle_Belief_Propagation.html">395 iccv-2013-Slice Sampling Particle Belief Propagation</a></p>
<p>11 0.62529051 <a title="451-lda-11" href="./iccv-2013-3D_Scene_Understanding_by_Voxel-CRF.html">2 iccv-2013-3D Scene Understanding by Voxel-CRF</a></p>
<p>12 0.62484968 <a title="451-lda-12" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>13 0.62461102 <a title="451-lda-13" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>14 0.62397242 <a title="451-lda-14" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>15 0.62388873 <a title="451-lda-15" href="./iccv-2013-From_Large_Scale_Image_Categorization_to_Entry-Level_Categories.html">176 iccv-2013-From Large Scale Image Categorization to Entry-Level Categories</a></p>
<p>16 0.62344986 <a title="451-lda-16" href="./iccv-2013-Supervised_Binary_Hash_Code_Learning_with_Jensen_Shannon_Divergence.html">409 iccv-2013-Supervised Binary Hash Code Learning with Jensen Shannon Divergence</a></p>
<p>17 0.62325126 <a title="451-lda-17" href="./iccv-2013-Spoken_Attributes%3A_Mixing_Binary_and_Relative_Attributes_to_Say_the_Right_Thing.html">399 iccv-2013-Spoken Attributes: Mixing Binary and Relative Attributes to Say the Right Thing</a></p>
<p>18 0.62315387 <a title="451-lda-18" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>19 0.62304908 <a title="451-lda-19" href="./iccv-2013-Attribute_Adaptation_for_Personalized_Image_Search.html">52 iccv-2013-Attribute Adaptation for Personalized Image Search</a></p>
<p>20 0.62256926 <a title="451-lda-20" href="./iccv-2013-Monte_Carlo_Tree_Search_for_Scheduling_Activity_Recognition.html">274 iccv-2013-Monte Carlo Tree Search for Scheduling Activity Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
