<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-321" href="#">iccv2013-321</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</h1>
<br/><p>Source: <a title="iccv-2013-321-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Yu_Pose-Free_Facial_Landmark_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Xiang Yu, Junzhou Huang, Shaoting Zhang, Wang Yan, Dimitris N. Metaxas</p><p>Abstract: This paper addresses the problem of facial landmark localization and tracking from a single camera. We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. For face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. By introducing 3D face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. For deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. The second step uses component-wise active contours to discriminatively refine the subtle shape variation. Our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. Extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. All results demonstrate that our approach has certain advantages over state-of-theart methods in handling pose variations1.</p><p>Reference: <a title="iccv-2013-321-reference" href="../iccv2013_reference/iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu Abstract This paper addresses the problem of facial landmark localization and tracking from a single camera. [sent-10, score-0.72]
</p><p>2 We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. [sent-11, score-0.954]
</p><p>3 For face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. [sent-12, score-0.442]
</p><p>4 By introducing 3D face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. [sent-13, score-0.957]
</p><p>5 Our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. [sent-16, score-0.697]
</p><p>6 Extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. [sent-17, score-0.254]
</p><p>7 Introduction Facial landmark localization and tracking have been studied for many years in computer vision. [sent-20, score-0.524]
</p><p>8 Landmark localization addresses the problem of matching a group of predefined 2D landmarks to a given facial image. [sent-21, score-0.609]
</p><p>9 Landmark tracking is to continuously capture the predefined landmarks in a facial image sequence. [sent-22, score-0.534]
</p><p>10 Such tasks are prerequisite for many applications, such as face recognition, facial expression analysis, 3D face modeling, video editing, etc. [sent-23, score-0.542]
</p><p>11 Initialization is the first and key step in landmark localization and tracking. [sent-33, score-0.492]
</p><p>12 In addi-  tion, even before initialization, most alignment algorithms [10, 11, 18, 26, 3 1] require to locate face region from face detectors [19]. [sent-37, score-0.456]
</p><p>13 Though they are widely used in many facial applications, they may lack flexibility of handling large facial pose variations. [sent-38, score-0.471]
</p><p>14 Although multi-view face shape models [6, 34, 35] partially solve the pose variation problem, they cannot cover unlimited possibilities of view changes. [sent-39, score-0.342]
</p><p>15 Since most pose estimators [4, 24] are based on face detectors, which makes the problem recursive, a better choice is to train fast and accurate facial anchor point detectors. [sent-45, score-0.473]
</p><p>16 By exhaustive local search, Constrained Local Model (CLM) [8, 26, 30] is expected to pull the landmarks out of local minima. [sent-51, score-0.333]
</p><p>17 A group sparse learning method is proposed to automatically select the optimized  anchor points. [sent-54, score-0.212]
</p><p>18 Then a two-level cascaded deformable shape model is presented to search global optimal positions. [sent-55, score-0.392]
</p><p>19 Starting from Zhu and Ramanan’s work [36], we set up weights for each landmark patch in the part mixture model indicat11 994444  ing the likelihood of choosing these parts. [sent-56, score-0.52]
</p><p>20 With initialized landmarks, we firstly perform mean-shift search on pre-trained response map for each landmark with CLM, pulling the landmarks into the convergence basin globally. [sent-58, score-0.862]
</p><p>21 1) The proposed optimized mixtures and two-step cascaded deformable shape model achieve real-time performance in facial landmark tracking. [sent-64, score-1.176]
</p><p>22 2) The proposed twostep cascaded deformable shape model enhances the flexibility to capture subtle shape variations from classical parametric shape models by integrating component-wise active contours. [sent-65, score-0.735]
</p><p>23 3) Extensive experiments have been conducted to demonstrate that our pose-free landmark fitting framework consistently achieves more significant results comparing to state-of-the-art methods on not only laboratory environmental face databases but also face-in-the-wild databases. [sent-66, score-0.718]
</p><p>24 However, the size of parts pool in their model is large, which impedes the potential for real-time landmark tracking. [sent-76, score-0.427]
</p><p>25 But it is difficult to represent face shapes merely using linear shape combination or appearance subspace in extremely varying views . [sent-79, score-0.324]
</p><p>26 To alleviate the varying view problem, multiview shape models [6, 35] were proposed either by local search to estimate the head pose or by incrementally combining models from different views. [sent-81, score-0.235]
</p><p>27 Nonparametric shape regression is another way for shape  registration. [sent-82, score-0.27]
</p><p>28 [20] trained directional classifiers to discriminatively search facial components. [sent-87, score-0.223]
</p><p>29 Pose or shape fern regressors [3, 10] was proposed to handle different shape variations. [sent-88, score-0.242]
</p><p>30 In contrast, our framework simultaneously tackles face detection and landmark initialization using proposed optimized anchor point detectors. [sent-92, score-0.808]
</p><p>31 The framework deals with arbitrary head pose conditions by introducing 3D shape model. [sent-93, score-0.208]
</p><p>32 It achieves real time performance due to the group sparse selection and cascaded two-stage deformation strategy. [sent-94, score-0.259]
</p><p>33 Robust Initialization Mixtures  via Optimized  Part  Before shape alignment or landmark tracking, robust initialization promotes the performance and prevents the fitting process from falling into local minima. [sent-96, score-0.712]
</p><p>34 A max-margin method is used to learn the weights for the landmark detector. [sent-99, score-0.427]
</p><p>35 Mixtures of Part Model  Every facial landmark with predefined patch neighborhood is a part. [sent-102, score-0.662]
</p><p>36 Same landmark in different viewpoints may be different parts. [sent-103, score-0.427]
</p><p>37 As a consequence, the landmarks of a face are a mixture of those parts. [sent-104, score-0.533]
</p><p>38 Pose-free facial landmark initialization using Procrustes analysis on 3D reference shape and detected optimized part mixture. [sent-146, score-0.871]
</p><p>39 wijgk  gi(sj,sk) =  are the weights controlling the shape displacement function defined as Φijgk (sj , sk) = (dx, dy, dx2 , dy2), where (dx, dy) = sk − sj . [sent-160, score-0.268]
</p><p>40 Such quadratic deformation cost controls the model− −w sith only four parameters and has shown its effectiveness in face alignment [36]. [sent-161, score-0.291]
</p><p>41 Given an image I, for each possible configuration of landmark positions, we evaluate the score of each configuration in each viewpoint. [sent-169, score-0.427]
</p><p>42 Thus the landmark positions can be obtained by maximizing Equation 2. [sent-171, score-0.461]
</p><p>43 Gtrioonup Sparse Learning for Landmark SelecFacial landmarks are usually defined manually without any consistent rules. [sent-174, score-0.306]
</p><p>44 We intend to automatically select those landmarks which well represent facial structure while the number of landmarks meets real-time requirement for inference. [sent-177, score-0.808]
</p><p>45 The chosen landmarks are sparse because only several key positions are needed to depict the component. [sent-178, score-0.404]
</p><p>46 However, within each landmark patch, every pixel contributes to the feature descriptor. [sent-180, score-0.427]
</p><p>47 , w˜ t], w˜ t is a portion of the reorganized form of w˜ , each of which stands for the regularized weights within one landmark patch. [sent-210, score-0.427]
</p><p>48 Two-step Cascaded Deformable Model With initial anchor points detection, we use general Procrustes analysis to project our 3D shape model [32] onto the facial image. [sent-215, score-0.373]
</p><p>49 Assuming the aligning of neighborhood landmarks conditionally independent,  we apply Bayesian inference to build a probabilistic model. [sent-219, score-0.339]
</p><p>50 Further assuming the response map of each landmark patch mixture of Gaussian, we propose a two-step cascaded deformable shape model to refine the locations of landmarks. [sent-220, score-0.917]
</p><p>51 1, we have defined the landmarks as vector s = [s1, . [sent-224, score-0.306]
</p><p>52 , sN], each landmark sj is formed by concatenating the x and y coordinates. [sent-227, score-0.527]
</p><p>53 [7], ASM represents face shapes by a mean shape and a linear combination of k selected shape basis, s = s + Qu, where s is the mean shape vector, sQh =pe [Q ba1s , . [sent-231, score-0.536]
</p><p>54 sj  sj  = aR( s¯j + Quj) + T  (4)  is one of the defined landmarks, R is a rotation matrix,  a is a scaling factor and T is the shift vector. [sent-239, score-0.2]
</p><p>55 The PDM provides us a way to depict arbitrary shape from a mean shape by deforming the parameter P = {a, R, u, T}. [sent-240, score-0.275]
</p><p>56 , vN] to indicate the likelihood of alignment, v = 1means landmarks are well aligned and v = 0 means not. [sent-248, score-0.306]
</p><p>57 From Equation 6 to Equation 7, we assume that the degree of landmark i’s alignment is independent to other landmarks’ alignment given current landmarks’ positions and the image. [sent-253, score-0.627]
</p><p>58 ϕ i}s the feature descriptor  of landmark patch i, ϑ and b are the regressor weights trained from collected positive and negative samples. [sent-256, score-0.496]
</p><p>59 Given a near-optimal landmark si, we intend to search its neighborhood to get the optimal alignment likelihood. [sent-262, score-0.537]
</p><p>60 We aim to take external force constrain to push the landmarks in each component aligning to its global minimum. [sent-292, score-0.422]
</p><p>61 Experiments To evaluate our method, we introduce five main face databases used in our experiments, i. [sent-323, score-0.216]
</p><p>62 (a) TSPM landmark model with 68 red dots as landmark positions and blue rectangles as local patches. [sent-340, score-0.888]
</p><p>63 (b) The Optimized Mixture model with only 17 red-dot landmarks and blue rectangles as local patches. [sent-341, score-0.306]
</p><p>64 database, we use the landmarks from database annotation which are common in all the algorithms. [sent-342, score-0.332]
</p><p>65 We firstly verify the group sparse learning selection based landmark detectors by comparing to the Tree Structure Part Model (TSPM) [36] algorithm. [sent-343, score-0.53]
</p><p>66 We then raise the near-frontal face alignment comparison with Multi-view ASMs [18], CLM [26], Oxford landmark detector [11] and TSPM. [sent-344, score-0.722]
</p><p>67 In addition, our method is potentially capable of tracking facial landmarks because of its fast update between two consecutive frames. [sent-347, score-0.563]
</p><p>68 We test it on talking face video [1] and compare it with CLM and Multi-ASM algorithms. [sent-348, score-0.27]
</p><p>69 Quantitatively, the alignment error is measured by the distance from ground truth normalized by the distance of two centers of eyes for frontal face databases. [sent-349, score-0.32]
</p><p>70 For those non-frontal databases, in which case not all two pupils are visible, we normalize the error by the square root of face size, reflected by the rectangle hull of aligned landmarks. [sent-350, score-0.237]
</p><p>71 Tree Structure Part Model Zhu and Ramanan [36] proposed a tree structure part model to simultaneously detect face and localize landmarks. [sent-354, score-0.212]
</p><p>72 The optimized model attempts to capture the most significant anchor points while omitting the intermediate landmarks, which reduces the risk of error propagation from misaligned landmarks. [sent-360, score-0.23]
</p><p>73 Percentage of images less than given relative error level of TSPM and the proposed optimized mixtures on AFW and LFPW datasets and average running time per image. [sent-362, score-0.252]
</p><p>74 One reason is that the number of simplified model landmarks is less, hence with less possibility of misalignment. [sent-369, score-0.306]
</p><p>75 Comparison with Previous Work We compare our approach (optimized mixtures with cascaded deformable shape model) with the following methods. [sent-376, score-0.47]
</p><p>76 (1) Multi-view ASMs [18], (2) Constrained local model (CLM) [26], (3) Oxford facial landmark detector [11], (4)  tree structure part model (TSPM) [36]. [sent-377, score-0.662]
</p><p>77 For nonfrontal comparison, we hard code ground truth face rectangle to Multi-ASMs, CLM and Oxford as face detection results because in those cases such methods may fail to locate  nAfFirogtcsOa. [sent-380, score-0.398]
</p><p>78 Cumulative error distribution curves for landmark localization on near-frontal images. [sent-396, score-0.556]
</p><p>79 The percentage is the ratio of error less than 5% of ground truth face size. [sent-400, score-0.237]
</p><p>80 The near-frontal is defined as faces with yaw angle varying from −45◦ to 45◦, in which case all landmarks are vvaisriybilneg. [sent-407, score-0.362]
</p><p>81 For fair comparison, we provide ideal face bounding boxes for compared methods , CLM, Multi-ASM and Oxford, as they may fail to detect faces in side-view face images. [sent-429, score-0.402]
</p><p>82 0% of total face volume within relative error 5% on LFW, 81. [sent-432, score-0.237]
</p><p>83 Cumulative error distribution curves for landmark localization on face-in-the-wild databases. [sent-467, score-0.556]
</p><p>84 Evaluation on Talking Face Video We claim that the proposed method (optimized mixtures with cascaded deformable shape model) has potential to track videos and image sequences. [sent-475, score-0.47]
</p><p>85 The reason is that in our model, initialization is simplified from TSPM which is claimed real-time detection performance and the two-step cascaded strategy is based on mean-shift and componentwise active contour. [sent-476, score-0.359]
</p><p>86 Percentage of talking face image frames less than given relative error level and Mean Average Pixel Error (MAPE) in pixels. [sent-479, score-0.334]
</p><p>87 352P19E  Since TSPM is a detection based method without any plug-in of tracking strategy, we only compare the results on  talking face video with CLM and Multi-ASM, which are able to raise video tracking. [sent-484, score-0.366]
</p><p>88 The relative error is defined as the fraction of average localization error over pupil distance. [sent-485, score-0.227]
</p><p>89 Conclusion We present a two-stage cascaded deformable shape fitting method for face landmark localization and tracking. [sent-489, score-1.067]
</p><p>90 By introducing 3D shape model with optimized mixtures of  Figure 5. [sent-490, score-0.309]
</p><p>91 Average landmark tracking error in pixels of talking face  video from frame 500 to frame 1000. [sent-491, score-0.793]
</p><p>92 It also outperforms CLM and Multi-ASM in face landmark tracking. [sent-494, score-0.6]
</p><p>93 Labeled faces in the wild: A database for studying face recognition in un-  [17] [18]  [19] [20] [21] [22] [23] [24]  [25] [26] [27]  [28]  [29]  constrained environments. [sent-598, score-0.288]
</p><p>94 A component based deformable model for generalized face alignment. [sent-610, score-0.266]
</p><p>95 Detector of facial landmarks learned by the strctured output svm. [sent-661, score-0.502]
</p><p>96 The best of both worlds: Combining 3d deformable models with active shape models. [sent-676, score-0.283]
</p><p>97 A 3d facial expression database for facial behavior research. [sent-696, score-0.418]
</p><p>98 Explicit occlusion detection based deformable fitting for facial landmark localization. [sent-703, score-0.778]
</p><p>99 Sparse shape composition: A new framework for shape prior modeling. [sent-712, score-0.242]
</p><p>100 Face detection, pose estimation and landmark localization in the wild. [sent-724, score-0.54]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('landmark', 0.427), ('tspm', 0.416), ('landmarks', 0.306), ('multipie', 0.206), ('facial', 0.196), ('afw', 0.184), ('clm', 0.184), ('lfpw', 0.184), ('face', 0.173), ('cascaded', 0.151), ('mape', 0.125), ('shape', 0.121), ('mixtures', 0.105), ('sj', 0.1), ('lfw', 0.097), ('talking', 0.097), ('deformable', 0.093), ('optimized', 0.083), ('alignment', 0.083), ('ar', 0.077), ('active', 0.069), ('localization', 0.065), ('error', 0.064), ('wild', 0.062), ('vi', 0.061), ('yi', 0.057), ('faces', 0.056), ('anchor', 0.056), ('equation', 0.056), ('asm', 0.055), ('mixture', 0.054), ('metaxas', 0.051), ('oxford', 0.051), ('pose', 0.048), ('sk', 0.047), ('lip', 0.046), ('cristinacce', 0.046), ('cootes', 0.045), ('initialization', 0.044), ('databases', 0.043), ('group', 0.042), ('corners', 0.042), ('argpmaxp', 0.042), ('componentwise', 0.042), ('ijgk', 0.042), ('jtj', 0.042), ('nearfrontal', 0.042), ('wijq', 0.042), ('procrustes', 0.04), ('basin', 0.04), ('tree', 0.039), ('head', 0.039), ('raise', 0.039), ('patch', 0.039), ('martinez', 0.038), ('environmental', 0.038), ('fitting', 0.037), ('asms', 0.037), ('rivera', 0.037), ('uricar', 0.037), ('ijq', 0.037), ('aam', 0.035), ('deformation', 0.035), ('pupil', 0.034), ('pdm', 0.034), ('fgr', 0.034), ('positions', 0.034), ('ei', 0.034), ('mouth', 0.033), ('depict', 0.033), ('aligning', 0.033), ('constrained', 0.033), ('tracking', 0.032), ('conforms', 0.032), ('response', 0.032), ('flexibility', 0.031), ('sparse', 0.031), ('firstly', 0.03), ('huang', 0.03), ('dy', 0.03), ('regressor', 0.03), ('merely', 0.03), ('potentially', 0.029), ('boosted', 0.029), ('claimed', 0.028), ('parametric', 0.028), ('qi', 0.028), ('constrain', 0.028), ('regression', 0.028), ('external', 0.028), ('valstar', 0.027), ('force', 0.027), ('locate', 0.027), ('exhaustive', 0.027), ('wy', 0.027), ('misaligned', 0.027), ('search', 0.027), ('database', 0.026), ('ramanan', 0.025), ('detection', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="321-tfidf-1" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>Author: Xiang Yu, Junzhou Huang, Shaoting Zhang, Wang Yan, Dimitris N. Metaxas</p><p>Abstract: This paper addresses the problem of facial landmark localization and tracking from a single camera. We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. For face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. By introducing 3D face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. For deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. The second step uses component-wise active contours to discriminatively refine the subtle shape variation. Our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. Extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. All results demonstrate that our approach has certain advantages over state-of-theart methods in handling pose variations1.</p><p>2 0.52575356 <a title="321-tfidf-2" href="./iccv-2013-Cascaded_Shape_Space_Pruning_for_Robust_Facial_Landmark_Detection.html">70 iccv-2013-Cascaded Shape Space Pruning for Robust Facial Landmark Detection</a></p>
<p>Author: Xiaowei Zhao, Shiguang Shan, Xiujuan Chai, Xilin Chen</p><p>Abstract: In this paper, we propose a novel cascaded face shape space pruning algorithm for robust facial landmark detection. Through progressively excluding the incorrect candidate shapes, our algorithm can accurately and efficiently achieve the globally optimal shape configuration. Specifically, individual landmark detectors are firstly applied to eliminate wrong candidates for each landmark. Then, the candidate shape space is further pruned by jointly removing incorrect shape configurations. To achieve this purpose, a discriminative structure classifier is designed to assess the candidate shape configurations. Based on the learned discriminative structure classifier, an efficient shape space pruning strategy is proposed to quickly reject most incorrect candidate shapes while preserve the true shape. The proposed algorithm is carefully evaluated on a large set of real world face images. In addition, comparison results on the publicly available BioID and LFW face databases demonstrate that our algorithm outperforms some state-of-the-art algorithms.</p><p>3 0.33393735 <a title="321-tfidf-3" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>Author: Feng Zhou, Jonathan Brandt, Zhe Lin</p><p>Abstract: Localizing facial landmarks is a fundamental step in facial image analysis. However, the problem is still challenging due to the large variability in pose and appearance, and the existence ofocclusions in real-worldface images. In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. Compared to conventional algorithms, EGM has three advantages: (1) an affine-invariant shape constraint is learned online from similar exemplars to better adapt to the test face; (2) the optimal landmark configuration can be directly obtained by solving a graph matching problem with the learned shape constraint; (3) the graph matching problem can be optimized efficiently by linear programming. To our best knowledge, this is the first attempt to apply a graph matching technique for facial landmark localization. Experiments on several challenging datasets demonstrate the advantages of EGM over state-of-the-art methods.</p><p>4 0.22596279 <a title="321-tfidf-4" href="./iccv-2013-Robust_Face_Landmark_Estimation_under_Occlusion.html">355 iccv-2013-Robust Face Landmark Estimation under Occlusion</a></p>
<p>Author: Xavier P. Burgos-Artizzu, Pietro Perona, Piotr Dollár</p><p>Abstract: Human faces captured in real-world conditions present large variations in shape and occlusions due to differences in pose, expression, use of accessories such as sunglasses and hats and interactions with objects (e.g. food). Current face landmark estimation approaches struggle under such conditions since theyfail toprovide aprincipled way ofhandling outliers. We propose a novel method, called Robust Cascaded Pose Regression (RCPR) which reduces exposure to outliers by detecting occlusions explicitly and using robust shape-indexed features. We show that RCPR improves on previous landmark estimation methods on three popular face datasets (LFPW, LFW and HELEN). We further explore RCPR ’s performance by introducing a novel face dataset focused on occlusion, composed of 1,007 faces presenting a wide range of occlusion patterns. RCPR reduces failure cases by half on all four datasets, at the same time as it detects face occlusions with a 80/40% precision/recall.</p><p>5 0.2163768 <a title="321-tfidf-5" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>Author: Yizhe Zhang, Ming Shao, Edward K. Wong, Yun Fu</p><p>Abstract: One of the most challenging task in face recognition is to identify people with varied poses. Namely, the test faces have significantly different poses compared with the registered faces. In this paper, we propose a high-level feature learning scheme to extract pose-invariant identity feature for face recognition. First, we build a single-hiddenlayer neural network with sparse constraint, to extractposeinvariant feature in a supervised fashion. Second, we further enhance the discriminative capability of the proposed feature by using multiple random faces as the target values for multiple encoders. By enforcing the target values to be uniquefor inputfaces over differentposes, the learned highlevel feature that is represented by the neurons in the hidden layer is pose free and only relevant to the identity information. Finally, we conduct face identification on CMU MultiPIE, and verification on Labeled Faces in the Wild (LFW) databases, where identification rank-1 accuracy and face verification accuracy with ROC curve are reported. These experiments demonstrate that our model is superior to oth- er state-of-the-art approaches on handling pose variations.</p><p>6 0.19555597 <a title="321-tfidf-6" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>7 0.19439264 <a title="321-tfidf-7" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>8 0.18781933 <a title="321-tfidf-8" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>9 0.18210556 <a title="321-tfidf-9" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>10 0.1475873 <a title="321-tfidf-10" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>11 0.14697737 <a title="321-tfidf-11" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>12 0.13852699 <a title="321-tfidf-12" href="./iccv-2013-Optimization_Problems_for_Fast_AAM_Fitting_in-the-Wild.html">302 iccv-2013-Optimization Problems for Fast AAM Fitting in-the-Wild</a></p>
<p>13 0.13271384 <a title="321-tfidf-13" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>14 0.13027522 <a title="321-tfidf-14" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>15 0.12928088 <a title="321-tfidf-15" href="./iccv-2013-Like_Father%2C_Like_Son%3A_Facial_Expression_Dynamics_for_Kinship_Verification.html">251 iccv-2013-Like Father, Like Son: Facial Expression Dynamics for Kinship Verification</a></p>
<p>16 0.11551894 <a title="321-tfidf-16" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<p>17 0.11075829 <a title="321-tfidf-17" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>18 0.10417838 <a title="321-tfidf-18" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>19 0.10362781 <a title="321-tfidf-19" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>20 0.10201098 <a title="321-tfidf-20" href="./iccv-2013-A_Framework_for_Shape_Analysis_via_Hilbert_Space_Embedding.html">10 iccv-2013-A Framework for Shape Analysis via Hilbert Space Embedding</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.211), (1, -0.008), (2, -0.103), (3, -0.111), (4, -0.002), (5, -0.192), (6, 0.338), (7, 0.147), (8, -0.032), (9, -0.021), (10, -0.052), (11, 0.152), (12, 0.071), (13, 0.008), (14, -0.035), (15, 0.045), (16, 0.085), (17, 0.025), (18, -0.087), (19, -0.148), (20, 0.038), (21, 0.097), (22, -0.003), (23, 0.167), (24, -0.003), (25, -0.064), (26, 0.084), (27, -0.117), (28, 0.011), (29, -0.059), (30, -0.072), (31, 0.011), (32, -0.034), (33, 0.016), (34, 0.071), (35, 0.104), (36, -0.05), (37, -0.081), (38, 0.025), (39, 0.033), (40, -0.102), (41, -0.13), (42, -0.028), (43, -0.006), (44, -0.023), (45, -0.012), (46, 0.066), (47, -0.026), (48, 0.032), (49, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94898921 <a title="321-lsi-1" href="./iccv-2013-Cascaded_Shape_Space_Pruning_for_Robust_Facial_Landmark_Detection.html">70 iccv-2013-Cascaded Shape Space Pruning for Robust Facial Landmark Detection</a></p>
<p>Author: Xiaowei Zhao, Shiguang Shan, Xiujuan Chai, Xilin Chen</p><p>Abstract: In this paper, we propose a novel cascaded face shape space pruning algorithm for robust facial landmark detection. Through progressively excluding the incorrect candidate shapes, our algorithm can accurately and efficiently achieve the globally optimal shape configuration. Specifically, individual landmark detectors are firstly applied to eliminate wrong candidates for each landmark. Then, the candidate shape space is further pruned by jointly removing incorrect shape configurations. To achieve this purpose, a discriminative structure classifier is designed to assess the candidate shape configurations. Based on the learned discriminative structure classifier, an efficient shape space pruning strategy is proposed to quickly reject most incorrect candidate shapes while preserve the true shape. The proposed algorithm is carefully evaluated on a large set of real world face images. In addition, comparison results on the publicly available BioID and LFW face databases demonstrate that our algorithm outperforms some state-of-the-art algorithms.</p><p>same-paper 2 0.94658619 <a title="321-lsi-2" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>Author: Xiang Yu, Junzhou Huang, Shaoting Zhang, Wang Yan, Dimitris N. Metaxas</p><p>Abstract: This paper addresses the problem of facial landmark localization and tracking from a single camera. We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. For face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. By introducing 3D face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. For deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. The second step uses component-wise active contours to discriminatively refine the subtle shape variation. Our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. Extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. All results demonstrate that our approach has certain advantages over state-of-theart methods in handling pose variations1.</p><p>3 0.90588188 <a title="321-lsi-3" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>Author: Feng Zhou, Jonathan Brandt, Zhe Lin</p><p>Abstract: Localizing facial landmarks is a fundamental step in facial image analysis. However, the problem is still challenging due to the large variability in pose and appearance, and the existence ofocclusions in real-worldface images. In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization. Compared to conventional algorithms, EGM has three advantages: (1) an affine-invariant shape constraint is learned online from similar exemplars to better adapt to the test face; (2) the optimal landmark configuration can be directly obtained by solving a graph matching problem with the learned shape constraint; (3) the graph matching problem can be optimized efficiently by linear programming. To our best knowledge, this is the first attempt to apply a graph matching technique for facial landmark localization. Experiments on several challenging datasets demonstrate the advantages of EGM over state-of-the-art methods.</p><p>4 0.81040567 <a title="321-lsi-4" href="./iccv-2013-Robust_Face_Landmark_Estimation_under_Occlusion.html">355 iccv-2013-Robust Face Landmark Estimation under Occlusion</a></p>
<p>Author: Xavier P. Burgos-Artizzu, Pietro Perona, Piotr Dollár</p><p>Abstract: Human faces captured in real-world conditions present large variations in shape and occlusions due to differences in pose, expression, use of accessories such as sunglasses and hats and interactions with objects (e.g. food). Current face landmark estimation approaches struggle under such conditions since theyfail toprovide aprincipled way ofhandling outliers. We propose a novel method, called Robust Cascaded Pose Regression (RCPR) which reduces exposure to outliers by detecting occlusions explicitly and using robust shape-indexed features. We show that RCPR improves on previous landmark estimation methods on three popular face datasets (LFPW, LFW and HELEN). We further explore RCPR ’s performance by introducing a novel face dataset focused on occlusion, composed of 1,007 faces presenting a wide range of occlusion patterns. RCPR reduces failure cases by half on all four datasets, at the same time as it detects face occlusions with a 80/40% precision/recall.</p><p>5 0.80863279 <a title="321-lsi-5" href="./iccv-2013-Like_Father%2C_Like_Son%3A_Facial_Expression_Dynamics_for_Kinship_Verification.html">251 iccv-2013-Like Father, Like Son: Facial Expression Dynamics for Kinship Verification</a></p>
<p>Author: Hamdi Dibeklioglu, Albert Ali Salah, Theo Gevers</p><p>Abstract: Kinship verification from facial appearance is a difficult problem. This paper explores the possibility of employing facial expression dynamics in this problem. By using features that describe facial dynamics and spatio-temporal appearance over smile expressions, we show that it is possible to improve the state ofthe art in thisproblem, and verify that it is indeed possible to recognize kinship by resemblance of facial expressions. The proposed method is tested on different kin relationships. On the average, 72.89% verification accuracy is achieved on spontaneous smiles.</p><p>6 0.74266261 <a title="321-lsi-6" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>7 0.67243993 <a title="321-lsi-7" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>8 0.64833868 <a title="321-lsi-8" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>9 0.62908715 <a title="321-lsi-9" href="./iccv-2013-Modifying_the_Memorability_of_Face_Photographs.html">272 iccv-2013-Modifying the Memorability of Face Photographs</a></p>
<p>10 0.61265343 <a title="321-lsi-10" href="./iccv-2013-Optimization_Problems_for_Fast_AAM_Fitting_in-the-Wild.html">302 iccv-2013-Optimization Problems for Fast AAM Fitting in-the-Wild</a></p>
<p>11 0.54177874 <a title="321-lsi-11" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>12 0.53572911 <a title="321-lsi-12" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>13 0.5301351 <a title="321-lsi-13" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>14 0.51855731 <a title="321-lsi-14" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>15 0.48905098 <a title="321-lsi-15" href="./iccv-2013-Facial_Action_Unit_Event_Detection_by_Cascade_of_Tasks.html">155 iccv-2013-Facial Action Unit Event Detection by Cascade of Tasks</a></p>
<p>16 0.48842245 <a title="321-lsi-16" href="./iccv-2013-Capturing_Global_Semantic_Relationships_for_Facial_Action_Unit_Recognition.html">69 iccv-2013-Capturing Global Semantic Relationships for Facial Action Unit Recognition</a></p>
<p>17 0.47169182 <a title="321-lsi-17" href="./iccv-2013-Discovering_Details_and_Scene_Structure_with_Hierarchical_Iconoid_Shift.html">117 iccv-2013-Discovering Details and Scene Structure with Hierarchical Iconoid Shift</a></p>
<p>18 0.42659169 <a title="321-lsi-18" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>19 0.40442678 <a title="321-lsi-19" href="./iccv-2013-Face_Recognition_via_Archetype_Hull_Ranking.html">154 iccv-2013-Face Recognition via Archetype Hull Ranking</a></p>
<p>20 0.40392226 <a title="321-lsi-20" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.055), (7, 0.015), (13, 0.012), (26, 0.072), (31, 0.045), (34, 0.01), (35, 0.026), (42, 0.223), (62, 0.166), (64, 0.048), (73, 0.033), (78, 0.024), (89, 0.182)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92053306 <a title="321-lda-1" href="./iccv-2013-Sparse_Variation_Dictionary_Learning_for_Face_Recognition_with_a_Single_Training_Sample_per_Person.html">398 iccv-2013-Sparse Variation Dictionary Learning for Face Recognition with a Single Training Sample per Person</a></p>
<p>Author: Meng Yang, Luc Van_Gool, Lei Zhang</p><p>Abstract: Face recognition (FR) with a single training sample per person (STSPP) is a very challenging problem due to the lack of information to predict the variations in the query sample. Sparse representation based classification has shown interesting results in robust FR; however, its performance will deteriorate much for FR with STSPP. To address this issue, in this paper we learn a sparse variation dictionary from a generic training set to improve the query sample representation by STSPP. Instead of learning from the generic training set independently w.r.t. the gallery set, the proposed sparse variation dictionary learning (SVDL) method is adaptive to the gallery set by jointly learning a projection to connect the generic training set with the gallery set. The learnt sparse variation dictionary can be easily integrated into the framework of sparse representation based classification so that various variations in face images, including illumination, expression, occlusion, pose, etc., can be better handled. Experiments on the large-scale CMU Multi-PIE, FRGC and LFW databases demonstrate the promising performance of SVDL on FR with STSPP.</p><p>same-paper 2 0.89642 <a title="321-lda-2" href="./iccv-2013-Pose-Free_Facial_Landmark_Fitting_via_Optimized_Part_Mixtures_and_Cascaded_Deformable_Shape_Model.html">321 iccv-2013-Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model</a></p>
<p>Author: Xiang Yu, Junzhou Huang, Shaoting Zhang, Wang Yan, Dimitris N. Metaxas</p><p>Abstract: This paper addresses the problem of facial landmark localization and tracking from a single camera. We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. For face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. By introducing 3D face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. For deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. The second step uses component-wise active contours to discriminatively refine the subtle shape variation. Our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. Extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. All results demonstrate that our approach has certain advantages over state-of-theart methods in handling pose variations1.</p><p>3 0.89595377 <a title="321-lda-3" href="./iccv-2013-Curvature-Aware_Regularization_on_Riemannian_Submanifolds.html">100 iccv-2013-Curvature-Aware Regularization on Riemannian Submanifolds</a></p>
<p>Author: Kwang In Kim, James Tompkin, Christian Theobalt</p><p>Abstract: One fundamental assumption in object recognition as well as in other computer vision and pattern recognition problems is that the data generation process lies on a manifold and that it respects the intrinsic geometry of the manifold. This assumption is held in several successful algorithms for diffusion and regularization, in particular, in graph-Laplacian-based algorithms. We claim that the performance of existing algorithms can be improved if we additionally account for how the manifold is embedded within the ambient space, i.e., if we consider the extrinsic geometry of the manifold. We present a procedure for characterizing the extrinsic (as well as intrinsic) curvature of a manifold M which is described by a sampled point cloud in a high-dimensional Euclidean space. Once estimated, we use this characterization in general diffusion and regularization on M, and form a new regularizer on a point cloud. The resulting re-weighted graph Laplacian demonstrates superior performance over classical graph Laplacian in semisupervised learning and spectral clustering.</p><p>4 0.88375968 <a title="321-lda-4" href="./iccv-2013-Automatic_Kronecker_Product_Model_Based_Detection_of_Repeated_Patterns_in_2D_Urban_Images.html">55 iccv-2013-Automatic Kronecker Product Model Based Detection of Repeated Patterns in 2D Urban Images</a></p>
<p>Author: Juan Liu, Emmanouil Psarakis, Ioannis Stamos</p><p>Abstract: Repeated patterns (such as windows, tiles, balconies and doors) are prominent and significant features in urban scenes. Therefore, detection of these repeated patterns becomes very important for city scene analysis. This paper attacks the problem of repeated patterns detection in a precise, efficient and automatic way, by combining traditional feature extraction followed by a Kronecker product lowrank modeling approach. Our method is tailored for 2D images of building fac ¸ades. We have developed algorithms for automatic selection ofa representative texture withinfa ¸cade images using vanishing points and Harris corners. After rectifying the input images, we describe novel algorithms that extract repeated patterns by using Kronecker product based modeling that is based on a solid theoretical foundation. Our approach is unique and has not ever been used for fac ¸ade analysis. We have tested our algorithms in a large set of images.</p><p>5 0.86529791 <a title="321-lda-5" href="./iccv-2013-Latent_Multitask_Learning_for_View-Invariant_Action_Recognition.html">231 iccv-2013-Latent Multitask Learning for View-Invariant Action Recognition</a></p>
<p>Author: Behrooz Mahasseni, Sinisa Todorovic</p><p>Abstract: This paper presents an approach to view-invariant action recognition, where human poses and motions exhibit large variations across different camera viewpoints. When each viewpoint of a given set of action classes is specified as a learning task then multitask learning appears suitable for achieving view invariance in recognition. We extend the standard multitask learning to allow identifying: (1) latent groupings of action views (i.e., tasks), and (2) discriminative action parts, along with joint learning of all tasks. This is because it seems reasonable to expect that certain distinct views are more correlated than some others, and thus identifying correlated views could improve recognition. Also, part-based modeling is expected to improve robustness against self-occlusion when actors are imaged from different views. Results on the benchmark datasets show that we outperform standard multitask learning by 21.9%, and the state-of-the-art alternatives by 4.5–6%.</p><p>6 0.86494589 <a title="321-lda-6" href="./iccv-2013-Attribute_Pivots_for_Guiding_Relevance_Feedback_in_Image_Search.html">54 iccv-2013-Attribute Pivots for Guiding Relevance Feedback in Image Search</a></p>
<p>7 0.8640728 <a title="321-lda-7" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>8 0.86061013 <a title="321-lda-8" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>9 0.85947299 <a title="321-lda-9" href="./iccv-2013-Allocentric_Pose_Estimation.html">46 iccv-2013-Allocentric Pose Estimation</a></p>
<p>10 0.85916948 <a title="321-lda-10" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>11 0.85844886 <a title="321-lda-11" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>12 0.85645902 <a title="321-lda-12" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>13 0.8552649 <a title="321-lda-13" href="./iccv-2013-Implied_Feedback%3A_Learning_Nuances_of_User_Behavior_in_Image_Search.html">213 iccv-2013-Implied Feedback: Learning Nuances of User Behavior in Image Search</a></p>
<p>14 0.85512626 <a title="321-lda-14" href="./iccv-2013-Correlation_Adaptive_Subspace_Segmentation_by_Trace_Lasso.html">93 iccv-2013-Correlation Adaptive Subspace Segmentation by Trace Lasso</a></p>
<p>15 0.85413575 <a title="321-lda-15" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>16 0.85351849 <a title="321-lda-16" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>17 0.85265034 <a title="321-lda-17" href="./iccv-2013-Attribute_Adaptation_for_Personalized_Image_Search.html">52 iccv-2013-Attribute Adaptation for Personalized Image Search</a></p>
<p>18 0.85254037 <a title="321-lda-18" href="./iccv-2013-Finding_Causal_Interactions_in_Video_Sequences.html">167 iccv-2013-Finding Causal Interactions in Video Sequences</a></p>
<p>19 0.85244834 <a title="321-lda-19" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>20 0.85240585 <a title="321-lda-20" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
