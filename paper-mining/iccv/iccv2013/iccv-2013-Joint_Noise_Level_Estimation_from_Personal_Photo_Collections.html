<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-223" href="#">iccv2013-223</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</h1>
<br/><p>Source: <a title="iccv-2013-223-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Shih_Joint_Noise_Level_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>Reference: <a title="iccv-2013-223-reference" href="../iccv2013_reference/iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. [sent-2, score-1.102]
</p><p>2 Photos in a personal album are likely to contain several faces of the same people. [sent-3, score-0.389]
</p><p>3 While some of these photos would be clean and high quality, others may be corrupted by noise. [sent-4, score-0.296]
</p><p>4 Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. [sent-5, score-1.42]
</p><p>5 Specifically, we compare geometrically and photometrically aligned face images of the same person. [sent-6, score-0.101]
</p><p>6 Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. [sent-7, score-0.998]
</p><p>7 We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. [sent-8, score-0.071]
</p><p>8 The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. [sent-9, score-0.993]
</p><p>9 The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative  noise levels, which allows for a pairwise factorization of the probability distribution. [sent-10, score-1.646]
</p><p>10 We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. [sent-11, score-0.653]
</p><p>11 Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study. [sent-12, score-1.59]
</p><p>12 Introduction People capture more photos today then ever before, thanks to the rapid proliferation of mobile devices with cameras. [sent-14, score-0.411]
</p><p>13 A common problem among personal photos is the presence of noise, especially in photos captured in low light using mobile cameras. [sent-15, score-0.654]
</p><p>14 Recent progress in image denoising has been impressive [2, 3], but many of these methods require accurate image noise levels as input parameters. [sent-16, score-1.006]
</p><p>15 1 shows that these noise parameters can have a significant im-  2MIT  CSAIL  Figure 1: BM3D denoising using various noise parameters. [sent-18, score-1.313]
</p><p>16 Our result is the sharpest while still being noise-free. [sent-21, score-0.066]
</p><p>17 (d) Insuf-  ficiently denoised BM3D result for under-estimated noise. [sent-23, score-0.205]
</p><p>18 Estimating the noise level from a single image is fundamentally ill-posed. [sent-25, score-0.628]
</p><p>19 Existing methods for noise estimation from a single image [7, 10, 16] often make certain assumptions about the underlying image model. [sent-26, score-0.614]
</p><p>20 Even if the noise model is appropriate, it can still be challenging to estimate the true noise level, because separating noise from the unknown noise-free reference image remains underconstrained. [sent-27, score-1.677]
</p><p>21 Our work is based on the observation that the lack of a noise-free reference image can be dealt with by processing all photos in an album jointly. [sent-28, score-0.406]
</p><p>22 This is in contrast to previous 2896  methods, which focus on individually estimating noise levels from single images. [sent-29, score-0.875]
</p><p>23 Most personal photo albums consist of multiple faces of the same people, occurring under different conditions, e. [sent-30, score-0.509]
</p><p>24 The key idea is to estimate the relative noise between these images, and then treat the comparatively cleaner images as references for obtaining absolute noise levels in all images. [sent-33, score-1.673]
</p><p>25 We propose a two-stage algorithm to jointly determine the noise levels for all face images in an album. [sent-34, score-0.9]
</p><p>26 In the first stage, we estimate the most probable relative noise levels between each image pair, and show that this can be done by  combining relative variances over corresponding patches in a probabilistic fashion. [sent-35, score-1.21]
</p><p>27 In the second stage, we employ a pairwise Markov random field, conditioned upon the relative noise levels obtained in the previous step to model the joint probability over all absolute noise levels. [sent-36, score-1.837]
</p><p>28 Thisjoint optimization is then solved using weighted least squares over a fully connected graph, where each node represents a face image, and each edge represents the relative noise level between a pair of images. [sent-37, score-0.928]
</p><p>29 Quantitatively, we show that our method performs better than Liu et al’s method [7] on synthetic noisy data. [sent-38, score-0.039]
</p><p>30 On real world data, we show how to use it to perform automatic parameter selection for the state-of-the-art BM3D denoising algorithm [3]. [sent-39, score-0.265]
</p><p>31 1 demonstrates a denoising result generated by BM3D using our automatically estimated noise parameter and shows comparisons. [sent-43, score-0.789]
</p><p>32 Related Work Proper knowledge of image noise level can be crucial for many denoising algorithms. [sent-45, score-0.853]
</p><p>33 One can obtain the noise level for known cameras if both the EXIF file and raw image are available [4]. [sent-46, score-0.628]
</p><p>34 But in practice, this information may not always be present, requiring estimation of noise directly from images. [sent-47, score-0.614]
</p><p>35 Estimating noise levels from a single image relies on assumed image models, such as the piecewise linear  model in [7], or needs to restore the clean noise-free image simultaneously with estimation [9], which can be ill-posed. [sent-48, score-0.96]
</p><p>36 By contrast, we use multiple images of the same subject, which makes the estimation problem relatively well-posed and results in better accuracy. [sent-49, score-0.09]
</p><p>37 [10] obtain good results by first convolving the image with a Laplacian filter, and then separating noise from the edges for estimation. [sent-51, score-0.623]
</p><p>38 However their method tends to degrade when the images have more textured regions. [sent-52, score-0.06]
</p><p>39 [16] exploit scale invariance in natural statistics, and improved the estimation accuracy over textured images by analyzing kurtosis varia-  Figure 2: Illustration of our algorithm. [sent-54, score-0.247]
</p><p>40 (a) Patch-based estimation of relative noise ρij pools estimates overs a small number of patch pairs: P A, P B, P C in this ex−  −  −  ample. [sent-55, score-0.855]
</p><p>41 r( ob)f A pbatscohlu pteai rnso:is Pe le −v eAls, Pσ2i are e,sPtim −at Ced i by jointly optimizing over a fully connected graph. [sent-56, score-0.152]
</p><p>42 An alternative to noise estimation is to select the parameter by maximizing certain subjective non-reference quality measurement of the denoised output [15]. [sent-59, score-0.877]
</p><p>43 These subjective measurements can produce high quality results, but require dense sampling of the noise parameter space, which increases the computational cost. [sent-60, score-0.648]
</p><p>44 There has been other work on exploiting faces for image enhancement. [sent-61, score-0.073]
</p><p>45 Shah and Kwatra [13] exploit albums and photo bursts for facial expression enhancement. [sent-64, score-0.42]
</p><p>46 The ultimate application of our work is also enhancement (by denoising). [sent-65, score-0.082]
</p><p>47 However, our main contribution lies in estimating the noise. [sent-66, score-0.074]
</p><p>48 Two-stage Joint Noise Level Estimation Our method works on multiple face images of the same person captured under various noise levels. [sent-68, score-0.625]
</p><p>49 Given a collection of n face images {Zi}i=1:n from an album, all containing t nhe f uacseer’ ism faagcees, our goal is to estimate the noise levels for all those images jointly1 . [sent-69, score-0.991]
</p><p>50 the noise is assumed independent of the image content, with zero mean and fixed variance. [sent-72, score-0.524]
</p><p>51 For now, we treat these as single channel images. [sent-73, score-0.046]
</p><p>52 Color channels are incorporated by taking the the mean variance across all color channels2, except for the normalization procedure described in section 3. [sent-74, score-0.055]
</p><p>53 Each observed image Zi can be 1We describe collection of face images in section 3. [sent-76, score-0.101]
</p><p>54 4 2This can be improved by considering noise variation across color channels and by pixel intensity, but we leave that for future work. [sent-77, score-0.579]
</p><p>55 2897  modeled as: Zi = Xi + Ni  (1)  where Xi is the underlying (unknown) clean image, and Ni is the noise layer, with the noise at pixel p denoted by: ηip ∼ N(0, σi2) . [sent-78, score-1.131]
</p><p>56 (2) To determine the noise parameters {σi}i=1:n for all images, we dwetaenrmt tion em thaexi nmoiizsee tphaer joint probability given face images:  {σi2} = {νi∗} ={ aνrkg}k m=1a:xnP(ν1,ν2,. [sent-79, score-0.793]
</p><p>57 While single image noise estimation methods focus on individually modeling P(νi |Zi), we aim to model the joint distribution over {νi}i=1:n given the  image s meto d{Zeli t}hie=1 j:onin. [sent-86, score-0.811]
</p><p>58 Wt deis tfurirbthuetiro nfo ocuvse on pair-wise interactiimoansg eb setewt {eeZn images, where each image pair i,j is used to estimate the relative noise between those images, denoted by ρij . [sent-87, score-0.82]
</p><p>59 This relative noise acts as a latent variable in our formulation, and allows us to simplify the joint noise estimation into a two stage process, as described below. [sent-88, score-1.521]
</p><p>60 Denoting the sets {νi} as ν, {Zi} as Z, and {ρij } as ρ, the DReHnSo oinfg Eq. [sent-89, score-0.055]
</p><p>61 4 marginalizes over all possible values of ρij for all i,j, which makes the optimization intractable. [sent-92, score-0.061]
</p><p>62 Therefore, instead of marginalizing, we assume a unimodal distribution, allowing Eq. [sent-93, score-0.057]
</p><p>63 4 to be approximated via sampling at the most likely ρ conditioned upon Z. [sent-94, score-0.137]
</p><p>64 3 as: ν∗ = arg max P(ν| Z) ν  ≈  arg max P(ν| Z, ρ∗ )P(ρ∗ |Z) (5) νm  s. [sent-96, score-0.32]
</p><p>65 5 and 6 can be decoupled into a two-stage optimization problem. [sent-99, score-0.049]
</p><p>66 1), we perform relative noise estimation between image pairs, where the relative noise ρij provides a probabilistic estimate of σi2 − σj2. [sent-101, score-1.533]
</p><p>67 Once the relative noise between image pairs is obtaine−d, we solve for the absolute noise level estimates σi2 in the second stage (section 3. [sent-102, score-1.554]
</p><p>68 2) by optimizing over a fully connected graph of all valid images. [sent-103, score-0.094]
</p><p>69 6, we employ a directed graphical model as illustrated in Fig. [sent-109, score-0.062]
</p><p>70 3 to decompose P(ρ| Z) into pairwise ste irlmluss:t P(ρ|Z) =  ? [sent-110, score-0.086]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('noise', 0.524), ('denoising', 0.265), ('levels', 0.217), ('photos', 0.213), ('personal', 0.169), ('ij', 0.165), ('album', 0.147), ('relative', 0.145), ('denoised', 0.139), ('albums', 0.139), ('zi', 0.139), ('stage', 0.129), ('photo', 0.128), ('arg', 0.108), ('face', 0.101), ('estimation', 0.09), ('clean', 0.083), ('subjective', 0.08), ('conditioned', 0.077), ('absolute', 0.076), ('estimating', 0.074), ('faces', 0.073), ('joint', 0.071), ('ficiently', 0.066), ('bursts', 0.066), ('rnso', 0.066), ('sharpest', 0.066), ('pact', 0.066), ('eals', 0.066), ('meto', 0.066), ('obtaine', 0.066), ('xnp', 0.066), ('level', 0.064), ('employ', 0.062), ('proliferation', 0.061), ('ced', 0.061), ('marginalizes', 0.061), ('textured', 0.06), ('individually', 0.06), ('upon', 0.06), ('mobile', 0.059), ('jointly', 0.058), ('hui', 0.057), ('nhe', 0.057), ('kurtosis', 0.057), ('deis', 0.057), ('tphaer', 0.057), ('unimodal', 0.057), ('separating', 0.056), ('probabilistic', 0.056), ('channels', 0.055), ('exif', 0.055), ('oinfg', 0.055), ('troy', 0.055), ('zoran', 0.055), ('content', 0.054), ('connected', 0.054), ('predominantly', 0.052), ('max', 0.052), ('pools', 0.051), ('csail', 0.051), ('estimate', 0.049), ('conditioning', 0.049), ('cleaner', 0.049), ('decoupled', 0.049), ('maxp', 0.049), ('pairs', 0.047), ('facial', 0.047), ('restore', 0.046), ('dealt', 0.046), ('hie', 0.046), ('treat', 0.046), ('marginalizing', 0.045), ('nfo', 0.045), ('ste', 0.045), ('estimates', 0.045), ('quality', 0.044), ('weakness', 0.044), ('ni', 0.044), ('convolving', 0.043), ('comparatively', 0.043), ('ism', 0.043), ('people', 0.043), ('joshi', 0.042), ('ultimate', 0.042), ('pairwise', 0.041), ('shah', 0.041), ('kwatra', 0.041), ('fully', 0.04), ('probability', 0.04), ('enhancement', 0.04), ('file', 0.04), ('today', 0.04), ('fundamentally', 0.04), ('exploit', 0.04), ('synthetic', 0.039), ('acts', 0.038), ('devices', 0.038), ('probable', 0.037), ('variances', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="223-tfidf-1" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>2 0.25277129 <a title="223-tfidf-2" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>Author: Xiangfei Kong, Kuan Li, Qingxiong Yang, Liu Wenyin, Ming-Hsuan Yang</p><p>Abstract: This paper proposes a new non-reference image quality metric that can be adopted by the state-of-the-art image/video denoising algorithms for auto-denoising. The proposed metric is extremely simple and can be implemented in four lines of Matlab code1. The basic assumption employed by the proposed metric is that the noise should be independent of the original image. A direct measurement of this dependence is, however, impractical due to the relatively low accuracy of existing denoising method. The proposed metric thus aims at maximizing the structure similarity between the input noisy image and the estimated image noise around homogeneous regions and the structure similarity between the input noisy image and the denoised image around highly-structured regions, and is computed as the linear correlation coefficient of the two corresponding structure similarity maps. Numerous experimental results demonstrate that the proposed metric not only outperforms the current state-of-the-art non-reference quality metric quantitatively and qualitatively, but also better maintains temporal coherence when used for video denoising. ˜</p><p>3 0.17609163 <a title="223-tfidf-3" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>Author: Ira Kemelmacher-Shlizerman</p><p>Abstract: In thispaper wepresent a new concept ofbuilding a morphable model directly from photos on the Internet. Morphable models have shown very impressive results more than a decade ago, and could potentially have a huge impact on all aspects of face modeling and recognition. One of the challenges, however, is to capture and register 3D laser scans of large number of people and facial expressions. Nowadays, there are enormous amounts of face photos on the Internet, large portion of which has semantic labels. We propose a framework to build a morphable model directly from photos, the framework includes dense registration of Internet photos, as well as, new single view shape reconstruction and modification algorithms.</p><p>4 0.17075311 <a title="223-tfidf-4" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>Author: Tal Hassner</p><p>Abstract: We present a data-driven method for estimating the 3D shapes of faces viewed in single, unconstrained photos (aka “in-the-wild”). Our method was designed with an emphasis on robustness and efficiency with the explicit goal of deployment in real-world applications which reconstruct and display faces in 3D. Our key observation is that for many practical applications, warping the shape of a reference face to match the appearance of a query, is enough to produce realistic impressions of the query ’s 3D shape. Doing so, however, requires matching visual features between the (possibly very different) query and reference images, while ensuring that a plausible face shape is produced. To this end, we describe an optimization process which seeks to maximize the similarity of appearances and depths, jointly, to those of a reference model. We describe our system for monocular face shape reconstruction and present both qualitative and quantitative experiments, comparing our method against alternative systems, and demonstrating its capabilities. Finally, as a testament to its suitability for real-world applications, we offer an open, online implementation of our system, providing unique means – of instant 3D viewing of faces appearing in web photos.</p><p>5 0.15483272 <a title="223-tfidf-5" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>6 0.15001643 <a title="223-tfidf-6" href="./iccv-2013-Event_Recognition_in_Photo_Collections_with_a_Stopwatch_HMM.html">147 iccv-2013-Event Recognition in Photo Collections with a Stopwatch HMM</a></p>
<p>7 0.11947387 <a title="223-tfidf-7" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>8 0.11904607 <a title="223-tfidf-8" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>9 0.10041983 <a title="223-tfidf-9" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>10 0.098740637 <a title="223-tfidf-10" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>11 0.095096678 <a title="223-tfidf-11" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>12 0.09442737 <a title="223-tfidf-12" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>13 0.091521196 <a title="223-tfidf-13" href="./iccv-2013-Random_Faces_Guided_Sparse_Many-to-One_Encoder_for_Pose-Invariant_Face_Recognition.html">335 iccv-2013-Random Faces Guided Sparse Many-to-One Encoder for Pose-Invariant Face Recognition</a></p>
<p>14 0.091293074 <a title="223-tfidf-14" href="./iccv-2013-Deblurring_by_Example_Using_Dense_Correspondence.html">103 iccv-2013-Deblurring by Example Using Dense Correspondence</a></p>
<p>15 0.08265312 <a title="223-tfidf-15" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>16 0.081948534 <a title="223-tfidf-16" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>17 0.081675261 <a title="223-tfidf-17" href="./iccv-2013-NYC3DCars%3A_A_Dataset_of_3D_Vehicles_in_Geographic_Context.html">286 iccv-2013-NYC3DCars: A Dataset of 3D Vehicles in Geographic Context</a></p>
<p>18 0.079139754 <a title="223-tfidf-18" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>19 0.074038856 <a title="223-tfidf-19" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>20 0.071858749 <a title="223-tfidf-20" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, -0.036), (2, -0.081), (3, -0.061), (4, -0.029), (5, -0.046), (6, 0.118), (7, -0.009), (8, 0.039), (9, -0.018), (10, -0.04), (11, -0.032), (12, 0.028), (13, 0.024), (14, -0.064), (15, 0.027), (16, -0.02), (17, -0.019), (18, -0.02), (19, 0.063), (20, -0.023), (21, -0.057), (22, -0.041), (23, -0.048), (24, 0.0), (25, 0.078), (26, 0.119), (27, -0.085), (28, -0.031), (29, 0.002), (30, 0.05), (31, 0.069), (32, 0.104), (33, 0.143), (34, -0.033), (35, -0.07), (36, 0.196), (37, 0.052), (38, 0.066), (39, -0.046), (40, -0.129), (41, 0.166), (42, 0.04), (43, -0.066), (44, 0.165), (45, 0.041), (46, -0.017), (47, -0.014), (48, -0.05), (49, -0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98647797 <a title="223-lsi-1" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>2 0.78227752 <a title="223-lsi-2" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>Author: Xiangfei Kong, Kuan Li, Qingxiong Yang, Liu Wenyin, Ming-Hsuan Yang</p><p>Abstract: This paper proposes a new non-reference image quality metric that can be adopted by the state-of-the-art image/video denoising algorithms for auto-denoising. The proposed metric is extremely simple and can be implemented in four lines of Matlab code1. The basic assumption employed by the proposed metric is that the noise should be independent of the original image. A direct measurement of this dependence is, however, impractical due to the relatively low accuracy of existing denoising method. The proposed metric thus aims at maximizing the structure similarity between the input noisy image and the estimated image noise around homogeneous regions and the structure similarity between the input noisy image and the denoised image around highly-structured regions, and is computed as the linear correlation coefficient of the two corresponding structure similarity maps. Numerous experimental results demonstrate that the proposed metric not only outperforms the current state-of-the-art non-reference quality metric quantitatively and qualitatively, but also better maintains temporal coherence when used for video denoising. ˜</p><p>3 0.75837791 <a title="223-lsi-3" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>Author: Ruixuan Wang, Emanuele Trucco</p><p>Abstract: This paper introduces a ‘low-rank prior’ for small oriented noise-free image patches: considering an oriented patch as a matrix, a low-rank matrix approximation is enough to preserve the texture details in the properly oriented patch. Based on this prior, we propose a single-patch method within a generalized joint low-rank and sparse matrix recovery framework to simultaneously detect and remove non-pointwise random-valued impulse noise (e.g., very small blobs). A weighting matrix is incorporated in the framework to encode an initial estimate of the spatial noise distribution. An accelerated proximal gradient method is adapted to estimate the optimal noise-free image patches. Experiments show the effectiveness of our framework in removing non-pointwise random-valued impulse noise.</p><p>4 0.66568643 <a title="223-lsi-4" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>Author: Deyu Meng, Fernando De_La_Torre</p><p>Abstract: Many problems in computer vision can be posed as recovering a low-dimensional subspace from highdimensional visual data. Factorization approaches to lowrank subspace estimation minimize a loss function between an observed measurement matrix and a bilinear factorization. Most popular loss functions include the L2 and L1 losses. L2 is optimal for Gaussian noise, while L1 is for Laplacian distributed noise. However, real data is often corrupted by an unknown noise distribution, which is unlikely to be purely Gaussian or Laplacian. To address this problem, this paper proposes a low-rank matrix factorization problem with a Mixture of Gaussians (MoG) noise model. The MoG model is a universal approximator for any continuous distribution, and hence is able to model a wider range of noise distributions. The parameters of the MoG model can be estimated with a maximum likelihood method, while the subspace is computed with standard approaches. We illustrate the benefits of our approach in extensive syn- thetic and real-world experiments including structure from motion, face modeling and background subtraction.</p><p>5 0.61276567 <a title="223-lsi-5" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>Author: David Eigen, Dilip Krishnan, Rob Fergus</p><p>Abstract: Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle, or outdoor security cameras mounted inside a protective enclosure. At capture time, defocus can be used to remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the window. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We collect a dataset of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions.</p><p>6 0.60177022 <a title="223-lsi-6" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>7 0.59447902 <a title="223-lsi-7" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>8 0.56313467 <a title="223-lsi-8" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>9 0.55806297 <a title="223-lsi-9" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>10 0.55700576 <a title="223-lsi-10" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>11 0.53315842 <a title="223-lsi-11" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>12 0.52995944 <a title="223-lsi-12" href="./iccv-2013-Face_Recognition_Using_Face_Patch_Networks.html">153 iccv-2013-Face Recognition Using Face Patch Networks</a></p>
<p>13 0.48988476 <a title="223-lsi-13" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>14 0.48878476 <a title="223-lsi-14" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>15 0.45714244 <a title="223-lsi-15" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>16 0.45592868 <a title="223-lsi-16" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>17 0.45494866 <a title="223-lsi-17" href="./iccv-2013-Viewing_Real-World_Faces_in_3D.html">444 iccv-2013-Viewing Real-World Faces in 3D</a></p>
<p>18 0.44574448 <a title="223-lsi-18" href="./iccv-2013-Efficient_Image_Dehazing_with_Boundary_Constraint_and_Contextual_Regularization.html">135 iccv-2013-Efficient Image Dehazing with Boundary Constraint and Contextual Regularization</a></p>
<p>19 0.43564621 <a title="223-lsi-19" href="./iccv-2013-Efficient_and_Robust_Large-Scale_Rotation_Averaging.html">138 iccv-2013-Efficient and Robust Large-Scale Rotation Averaging</a></p>
<p>20 0.43153614 <a title="223-lsi-20" href="./iccv-2013-NYC3DCars%3A_A_Dataset_of_3D_Vehicles_in_Geographic_Context.html">286 iccv-2013-NYC3DCars: A Dataset of 3D Vehicles in Geographic Context</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.091), (7, 0.015), (26, 0.077), (31, 0.043), (32, 0.167), (42, 0.144), (64, 0.037), (73, 0.114), (89, 0.225), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90490472 <a title="223-lda-1" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>Author: Yichang Shih, Vivek Kwatra, Troy Chinen, Hui Fang, Sergey Ioffe</p><p>Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using “BM3D”, and evaluate the quality of denoising on real-world photos through a user study.</p><p>2 0.89302588 <a title="223-lda-2" href="./iccv-2013-Codemaps_-_Segment%2C_Classify_and_Search_Objects_Locally.html">77 iccv-2013-Codemaps - Segment, Classify and Search Objects Locally</a></p>
<p>Author: Zhenyang Li, Efstratios Gavves, Koen E.A. van_de_Sande, Cees G.M. Snoek, Arnold W.M. Smeulders</p><p>Abstract: In this paper we aim for segmentation and classification of objects. We propose codemaps that are a joint formulation of the classification score and the local neighborhood it belongs to in the image. We obtain the codemap by reordering the encoding, pooling and classification steps over lattice elements. Other than existing linear decompositions who emphasize only the efficiency benefits for localized search, we make three novel contributions. As a preliminary, we provide a theoretical generalization of the sufficient mathematical conditions under which image encodings and classification becomes locally decomposable. As first novelty we introduce ℓ2 normalization for arbitrarily shaped image regions, which is fast enough for semantic segmentation using our Fisher codemaps. Second, using the same lattice across images, we propose kernel pooling which embeds nonlinearities into codemaps for object classification by explicit or approximate feature mappings. Results demonstrate that ℓ2 normalized Fisher codemaps improve the state-of-the-art in semantic segmentation for PAS- CAL VOC. For object classification the addition of nonlinearities brings us on par with the state-of-the-art, but is 3x faster. Because of the codemaps ’ inherent efficiency, we can reach significant speed-ups for localized search as well. We exploit the efficiency gain for our third novelty: object segment retrieval using a single query image only.</p><p>3 0.88908464 <a title="223-lda-3" href="./iccv-2013-Local_Signal_Equalization_for_Correspondence_Matching.html">255 iccv-2013-Local Signal Equalization for Correspondence Matching</a></p>
<p>Author: Derek Bradley, Thabo Beeler</p><p>Abstract: Correspondence matching is one of the most common problems in computer vision, and it is often solved using photo-consistency of local regions. These approaches typically assume that the frequency content in the local region is consistent in the image pair, such that matching is performed on similar signals. However, in many practical situations this is not the case, for example with low depth of field cameras a scene point may be out of focus in one view and in-focus in the other, causing a mismatch of frequency signals. Furthermore, this mismatch can vary spatially over the entire image. In this paper we propose a local signal equalization approach for correspondence matching. Using a measure of local image frequency, we equalize local signals using an efficient scale-space image representation such that their frequency contents are optimally suited for matching. Our approach allows better correspondence matching, which we demonstrate with a number of stereo reconstruction examples on synthetic and real datasets.</p><p>4 0.87272286 <a title="223-lda-4" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>Author: Zhiwu Huang, Xiaowei Zhao, Shiguang Shan, Ruiping Wang, Xilin Chen</p><p>Abstract: The Still-to-Video (S2V) face recognition systems typically need to match faces in low-quality videos captured under unconstrained conditions against high quality still face images, which is very challenging because of noise, image blur, lowface resolutions, varying headpose, complex lighting, and alignment difficulty. To address the problem, one solution is to select the frames of ‘best quality ’ from videos (hereinafter called quality alignment in this paper). Meanwhile, the faces in the selected frames should also be geometrically aligned to the still faces offline well-aligned in the gallery. In this paper, we discover that the interactions among the three tasks–quality alignment, geometric alignment and face recognition–can benefit from each other, thus should be performed jointly. With this in mind, we propose a Coupling Alignments with Recognition (CAR) method to tightly couple these tasks via low-rank regularized sparse representation in a unified framework. Our method makes the three tasks promote mutually by a joint optimization in an Augmented Lagrange Multiplier routine. Extensive , experiments on two challenging S2V datasets demonstrate that our method outperforms the state-of-the-art methods impressively.</p><p>5 0.85840213 <a title="223-lda-5" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>Author: Yangqing Jia, Trevor Darrell</p><p>Abstract: Recent years have witnessed the success of large-scale image classification systems that are able to identify objects among thousands of possible labels. However, it is yet unclear how general classifiers such as ones trained on ImageNet can be optimally adapted to specific tasks, each of which only covers a semantically related subset of all the objects in the world. It is inefficient and suboptimal to retrain classifiers whenever a new task is given, and is inapplicable when tasks are not given explicitly, but implicitly specified as a set of image queries. In this paper we propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a lineartime probabilistic inference algorithm, given a set of query images from a latent task. We present efficient ways to estimate parameters for the model, and an open-source toolbox to train classifiers distributedly at a large scale. Empirical results based on the ImageNet data showed significant performance increase over several baseline algorithms.</p><p>6 0.85834908 <a title="223-lda-6" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>7 0.85822642 <a title="223-lda-7" href="./iccv-2013-Spoken_Attributes%3A_Mixing_Binary_and_Relative_Attributes_to_Say_the_Right_Thing.html">399 iccv-2013-Spoken Attributes: Mixing Binary and Relative Attributes to Say the Right Thing</a></p>
<p>8 0.85733616 <a title="223-lda-8" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>9 0.85282141 <a title="223-lda-9" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>10 0.85242367 <a title="223-lda-10" href="./iccv-2013-Perspective_Motion_Segmentation_via_Collaborative_Clustering.html">314 iccv-2013-Perspective Motion Segmentation via Collaborative Clustering</a></p>
<p>11 0.85069799 <a title="223-lda-11" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>12 0.85063827 <a title="223-lda-12" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>13 0.85049099 <a title="223-lda-13" href="./iccv-2013-Discriminatively_Trained_Templates_for_3D_Object_Detection%3A_A_Real_Time_Scalable_Approach.html">121 iccv-2013-Discriminatively Trained Templates for 3D Object Detection: A Real Time Scalable Approach</a></p>
<p>14 0.85002035 <a title="223-lda-14" href="./iccv-2013-Single-Patch_Low-Rank_Prior_for_Non-pointwise_Impulse_Noise_Removal.html">394 iccv-2013-Single-Patch Low-Rank Prior for Non-pointwise Impulse Noise Removal</a></p>
<p>15 0.85001099 <a title="223-lda-15" href="./iccv-2013-Semi-supervised_Robust_Dictionary_Learning_via_Efficient_l-Norms_Minimization.html">384 iccv-2013-Semi-supervised Robust Dictionary Learning via Efficient l-Norms Minimization</a></p>
<p>16 0.84991747 <a title="223-lda-16" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<p>17 0.84987557 <a title="223-lda-17" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>18 0.84921974 <a title="223-lda-18" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>19 0.84881288 <a title="223-lda-19" href="./iccv-2013-Optical_Flow_via_Locally_Adaptive_Fusion_of_Complementary_Data_Costs.html">300 iccv-2013-Optical Flow via Locally Adaptive Fusion of Complementary Data Costs</a></p>
<p>20 0.84831172 <a title="223-lda-20" href="./iccv-2013-Distributed_Low-Rank_Subspace_Segmentation.html">122 iccv-2013-Distributed Low-Rank Subspace Segmentation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
