<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>244 iccv-2013-Learning View-Invariant Sparse Representations for Cross-View Action Recognition</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-244" href="#">iccv2013-244</a> knowledge-graph by maker-knowledge-mining</p><h1>244 iccv-2013-Learning View-Invariant Sparse Representations for Cross-View Action Recognition</h1>
<br/><p>Source: <a title="iccv-2013-244-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zheng_Learning_View-Invariant_Sparse_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Jingjing Zheng, Zhuolin Jiang</p><p>Abstract: We present an approach to jointly learn a set of viewspecific dictionaries and a common dictionary for crossview action recognition. The set of view-specific dictionaries is learned for specific views while the common dictionary is shared across different views. Our approach represents videos in each view using both the corresponding view-specific dictionary and the common dictionary. More importantly, it encourages the set of videos taken from different views of the same action to have similar sparse representations. In this way, we can align view-specific features in the sparse feature spaces spanned by the viewspecific dictionary set and transfer the view-shared features in the sparse feature space spanned by the common dictionary. Meanwhile, the incoherence between the common dictionary and the view-specific dictionary set enables us to exploit the discrimination information encoded in viewspecific features and view-shared features separately. In addition, the learned common dictionary not only has the capability to represent actions from unseen views, but also , makes our approach effective in a semi-supervised setting where no correspondence videos exist and only a few labels exist in the target view. Extensive experiments using the multi-view IXMAS dataset demonstrate that our approach outperforms many recent approaches for cross-view action recognition.</p><p>Reference: <a title="iccv-2013-244-reference" href="../iccv2013_reference/iccv-2013-Learning_View-Invariant_Sparse_Representations_for_Cross-View_Action_Recognition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dv', 0.314), ('yiv', 0.288), ('dxiv', 0.26), ('item', 0.237), ('dkv', 0.195), ('viewspec', 0.186), ('view', 0.184), ('video', 0.176), ('act', 0.17), ('qiv', 0.162), ('yv', 0.154), ('dj', 0.133), ('dtdv', 0.13), ('dvziv', 0.13), ('target', 0.123), ('orph', 0.115), ('incoh', 0.111), ('sourc', 0.108), ('ds', 0.106), ('qi', 0.102)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="244-tfidf-1" href="./iccv-2013-Learning_View-Invariant_Sparse_Representations_for_Cross-View_Action_Recognition.html">244 iccv-2013-Learning View-Invariant Sparse Representations for Cross-View Action Recognition</a></p>
<p>2 0.14593259 <a title="244-tfidf-2" href="./iccv-2013-Cross-View_Action_Recognition_over_Heterogeneous_Feature_Spaces.html">99 iccv-2013-Cross-View Action Recognition over Heterogeneous Feature Spaces</a></p>
<p>3 0.14127453 <a title="244-tfidf-3" href="./iccv-2013-Latent_Multitask_Learning_for_View-Invariant_Action_Recognition.html">231 iccv-2013-Latent Multitask Learning for View-Invariant Action Recognition</a></p>
<p>4 0.13619672 <a title="244-tfidf-4" href="./iccv-2013-Paper_Doll_Parsing%3A_Retrieving_Similar_Styles_to_Parse_Clothing_Items.html">306 iccv-2013-Paper Doll Parsing: Retrieving Similar Styles to Parse Clothing Items</a></p>
<p>5 0.12084582 <a title="244-tfidf-5" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>6 0.11817394 <a title="244-tfidf-6" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>7 0.11520788 <a title="244-tfidf-7" href="./iccv-2013-Active_Learning_of_an_Action_Detector_from_Untrimmed_Videos.html">41 iccv-2013-Active Learning of an Action Detector from Untrimmed Videos</a></p>
<p>8 0.11176176 <a title="244-tfidf-8" href="./iccv-2013-Video_Event_Understanding_Using_Natural_Language_Descriptions.html">440 iccv-2013-Video Event Understanding Using Natural Language Descriptions</a></p>
<p>9 0.11003858 <a title="244-tfidf-9" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<p>10 0.10791446 <a title="244-tfidf-10" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>11 0.10218729 <a title="244-tfidf-11" href="./iccv-2013-Modeling_4D_Human-Object_Interactions_for_Event_and_Object_Recognition.html">268 iccv-2013-Modeling 4D Human-Object Interactions for Event and Object Recognition</a></p>
<p>12 0.097922012 <a title="244-tfidf-12" href="./iccv-2013-Initialization-Insensitive_Visual_Tracking_through_Voting_with_Salient_Local_Features.html">217 iccv-2013-Initialization-Insensitive Visual Tracking through Voting with Salient Local Features</a></p>
<p>13 0.095084399 <a title="244-tfidf-13" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>14 0.094002061 <a title="244-tfidf-14" href="./iccv-2013-Domain_Adaptive_Classification.html">123 iccv-2013-Domain Adaptive Classification</a></p>
<p>15 0.09192653 <a title="244-tfidf-15" href="./iccv-2013-Action_Recognition_and_Localization_by_Hierarchical_Space-Time_Segments.html">37 iccv-2013-Action Recognition and Localization by Hierarchical Space-Time Segments</a></p>
<p>16 0.090174079 <a title="244-tfidf-16" href="./iccv-2013-Mining_Motion_Atoms_and_Phrases_for_Complex_Action_Recognition.html">265 iccv-2013-Mining Motion Atoms and Phrases for Complex Action Recognition</a></p>
<p>17 0.089712977 <a title="244-tfidf-17" href="./iccv-2013-Domain_Transfer_Support_Vector_Ranking_for_Person_Re-identification_without_Target_Camera_Label_Information.html">124 iccv-2013-Domain Transfer Support Vector Ranking for Person Re-identification without Target Camera Label Information</a></p>
<p>18 0.089220189 <a title="244-tfidf-18" href="./iccv-2013-Unsupervised_Domain_Adaptation_by_Domain_Invariant_Projection.html">435 iccv-2013-Unsupervised Domain Adaptation by Domain Invariant Projection</a></p>
<p>19 0.087665029 <a title="244-tfidf-19" href="./iccv-2013-Monocular_Image_3D_Human_Pose_Estimation_under_Self-Occlusion.html">273 iccv-2013-Monocular Image 3D Human Pose Estimation under Self-Occlusion</a></p>
<p>20 0.083644785 <a title="244-tfidf-20" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.192), (1, -0.03), (2, -0.013), (3, -0.034), (4, 0.02), (5, -0.022), (6, 0.043), (7, 0.055), (8, -0.046), (9, -0.102), (10, 0.03), (11, -0.052), (12, -0.111), (13, 0.03), (14, 0.138), (15, 0.025), (16, -0.078), (17, -0.083), (18, -0.059), (19, 0.022), (20, 0.063), (21, 0.044), (22, 0.018), (23, -0.034), (24, -0.012), (25, -0.07), (26, 0.009), (27, 0.024), (28, -0.094), (29, 0.011), (30, -0.023), (31, 0.025), (32, -0.002), (33, 0.009), (34, 0.014), (35, 0.048), (36, -0.032), (37, 0.053), (38, 0.038), (39, -0.022), (40, -0.037), (41, -0.056), (42, -0.004), (43, -0.102), (44, -0.02), (45, 0.076), (46, 0.029), (47, -0.053), (48, -0.083), (49, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92334509 <a title="244-lsi-1" href="./iccv-2013-Learning_View-Invariant_Sparse_Representations_for_Cross-View_Action_Recognition.html">244 iccv-2013-Learning View-Invariant Sparse Representations for Cross-View Action Recognition</a></p>
<p>2 0.81761569 <a title="244-lsi-2" href="./iccv-2013-Latent_Multitask_Learning_for_View-Invariant_Action_Recognition.html">231 iccv-2013-Latent Multitask Learning for View-Invariant Action Recognition</a></p>
<p>3 0.79361832 <a title="244-lsi-3" href="./iccv-2013-Cross-View_Action_Recognition_over_Heterogeneous_Feature_Spaces.html">99 iccv-2013-Cross-View Action Recognition over Heterogeneous Feature Spaces</a></p>
<p>4 0.69235367 <a title="244-lsi-4" href="./iccv-2013-ACTIVE%3A_Activity_Concept_Transitions_in_Video_Event_Classification.html">4 iccv-2013-ACTIVE: Activity Concept Transitions in Video Event Classification</a></p>
<p>5 0.69198823 <a title="244-lsi-5" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>6 0.68828571 <a title="244-lsi-6" href="./iccv-2013-Video_Synopsis_by_Heterogeneous_Multi-source_Correlation.html">443 iccv-2013-Video Synopsis by Heterogeneous Multi-source Correlation</a></p>
<p>7 0.67816341 <a title="244-lsi-7" href="./iccv-2013-Action_Recognition_with_Actons.html">38 iccv-2013-Action Recognition with Actons</a></p>
<p>8 0.66171753 <a title="244-lsi-8" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>9 0.65389323 <a title="244-lsi-9" href="./iccv-2013-Video_Event_Understanding_Using_Natural_Language_Descriptions.html">440 iccv-2013-Video Event Understanding Using Natural Language Descriptions</a></p>
<p>10 0.6503635 <a title="244-lsi-10" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<p>11 0.64372647 <a title="244-lsi-11" href="./iccv-2013-Active_Learning_of_an_Action_Detector_from_Untrimmed_Videos.html">41 iccv-2013-Active Learning of an Action Detector from Untrimmed Videos</a></p>
<p>12 0.64355683 <a title="244-lsi-12" href="./iccv-2013-Modeling_4D_Human-Object_Interactions_for_Event_and_Object_Recognition.html">268 iccv-2013-Modeling 4D Human-Object Interactions for Event and Object Recognition</a></p>
<p>13 0.63566059 <a title="244-lsi-13" href="./iccv-2013-Learning_to_Share_Latent_Tasks_for_Action_Recognition.html">249 iccv-2013-Learning to Share Latent Tasks for Action Recognition</a></p>
<p>14 0.63193423 <a title="244-lsi-14" href="./iccv-2013-Coupled_Dictionary_and_Feature_Space_Learning_with_Applications_to_Cross-Domain_Image_Synthesis_and_Recognition.html">96 iccv-2013-Coupled Dictionary and Feature Space Learning with Applications to Cross-Domain Image Synthesis and Recognition</a></p>
<p>15 0.6272167 <a title="244-lsi-15" href="./iccv-2013-Monte_Carlo_Tree_Search_for_Scheduling_Activity_Recognition.html">274 iccv-2013-Monte Carlo Tree Search for Scheduling Activity Recognition</a></p>
<p>16 0.61298633 <a title="244-lsi-16" href="./iccv-2013-Finding_Actors_and_Actions_in_Movies.html">166 iccv-2013-Finding Actors and Actions in Movies</a></p>
<p>17 0.60749233 <a title="244-lsi-17" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>18 0.6073879 <a title="244-lsi-18" href="./iccv-2013-From_Semi-supervised_to_Transfer_Counting_of_Crowds.html">178 iccv-2013-From Semi-supervised to Transfer Counting of Crowds</a></p>
<p>19 0.60161018 <a title="244-lsi-19" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<p>20 0.59820312 <a title="244-lsi-20" href="./iccv-2013-From_Actemes_to_Action%3A_A_Strongly-Supervised_Representation_for_Detailed_Action_Understanding.html">175 iccv-2013-From Actemes to Action: A Strongly-Supervised Representation for Detailed Action Understanding</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.032), (20, 0.07), (25, 0.016), (34, 0.379), (42, 0.119), (48, 0.2), (55, 0.037), (77, 0.036), (89, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.67275292 <a title="244-lda-1" href="./iccv-2013-Joint_Learning_of_Discriminative_Prototypes_and_Large_Margin_Nearest_Neighbor_Classifiers.html">222 iccv-2013-Joint Learning of Discriminative Prototypes and Large Margin Nearest Neighbor Classifiers</a></p>
<p>same-paper 2 0.64774007 <a title="244-lda-2" href="./iccv-2013-Learning_View-Invariant_Sparse_Representations_for_Cross-View_Action_Recognition.html">244 iccv-2013-Learning View-Invariant Sparse Representations for Cross-View Action Recognition</a></p>
<p>3 0.62810683 <a title="244-lda-3" href="./iccv-2013-Multi-attributed_Dictionary_Learning_for_Sparse_Coding.html">276 iccv-2013-Multi-attributed Dictionary Learning for Sparse Coding</a></p>
<p>4 0.60697114 <a title="244-lda-4" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>5 0.54648876 <a title="244-lda-5" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>6 0.54597002 <a title="244-lda-6" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>7 0.54526907 <a title="244-lda-7" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>8 0.54503506 <a title="244-lda-8" href="./iccv-2013-Dynamic_Scene_Deblurring.html">129 iccv-2013-Dynamic Scene Deblurring</a></p>
<p>9 0.54473579 <a title="244-lda-9" href="./iccv-2013-Modeling_Occlusion_by_Discriminative_AND-OR_Structures.html">269 iccv-2013-Modeling Occlusion by Discriminative AND-OR Structures</a></p>
<p>10 0.54439557 <a title="244-lda-10" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>11 0.54399914 <a title="244-lda-11" href="./iccv-2013-Discriminant_Tracking_Using_Tensor_Representation_with_Semi-supervised_Improvement.html">119 iccv-2013-Discriminant Tracking Using Tensor Representation with Semi-supervised Improvement</a></p>
<p>12 0.54397529 <a title="244-lda-12" href="./iccv-2013-Manipulation_Pattern_Discovery%3A_A_Nonparametric_Bayesian_Approach.html">260 iccv-2013-Manipulation Pattern Discovery: A Nonparametric Bayesian Approach</a></p>
<p>13 0.54390061 <a title="244-lda-13" href="./iccv-2013-Calibration-Free_Gaze_Estimation_Using_Human_Gaze_Patterns.html">67 iccv-2013-Calibration-Free Gaze Estimation Using Human Gaze Patterns</a></p>
<p>14 0.54378676 <a title="244-lda-14" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>15 0.54349291 <a title="244-lda-15" href="./iccv-2013-Saliency_Detection_via_Dense_and_Sparse_Reconstruction.html">372 iccv-2013-Saliency Detection via Dense and Sparse Reconstruction</a></p>
<p>16 0.54315364 <a title="244-lda-16" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>17 0.54312754 <a title="244-lda-17" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<p>18 0.54311651 <a title="244-lda-18" href="./iccv-2013-Robust_Feature_Set_Matching_for_Partial_Face_Recognition.html">356 iccv-2013-Robust Feature Set Matching for Partial Face Recognition</a></p>
<p>19 0.54305619 <a title="244-lda-19" href="./iccv-2013-Style-Aware_Mid-level_Representation_for_Discovering_Visual_Connections_in_Space_and_Time.html">406 iccv-2013-Style-Aware Mid-level Representation for Discovering Visual Connections in Space and Time</a></p>
<p>20 0.54294938 <a title="244-lda-20" href="./iccv-2013-Salient_Region_Detection_by_UFO%3A_Uniqueness%2C_Focusness_and_Objectness.html">374 iccv-2013-Salient Region Detection by UFO: Uniqueness, Focusness and Objectness</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
