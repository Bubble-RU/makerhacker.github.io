<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-107" href="#">iccv2013-107</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</h1>
<br/><p>Source: <a title="iccv-2013-107-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zhang_Deformable_Part_Descriptors_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Ning Zhang, Ryan Farrell, Forrest Iandola, Trevor Darrell</p><p>Abstract: Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.</p><p>Reference: <a title="iccv-2013-107-reference" href="../iccv2013_reference/iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. [sent-7, score-0.235]
</p><p>2 Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. [sent-8, score-0.278]
</p><p>3 This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. [sent-9, score-0.338]
</p><p>4 The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. [sent-11, score-0.671]
</p><p>5 These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. [sent-12, score-0.371]
</p><p>6 As described in [23], what often differentiates basic-level categories is the presence or absence of parts (e. [sent-16, score-0.183]
</p><p>7 an elephant has 4 legs and a trunk), whereas subordinate categories are more often discriminated by subtle variations in the shape, size and/or appearance properties of these parts (e. [sent-18, score-0.239]
</p><p>8 Localizing and describing the object’s parts therefore becomes central to uncovering its fine-grained identity. [sent-21, score-0.185]
</p><p>9 Several approaches have been proposed for localizing and describing object parts in fine-grained domains. [sent-22, score-0.279]
</p><p>10 This paradigm seeks to discount variations in pose, articulation and camera viewing angle by localizing semantic object parts and extracting appearance features with respect to those localized parts. [sent-26, score-0.488]
</p><p>11 In these approaches part localization was accomplished using Poselets [11, 10], which require computationally-expensive filter ensembles for part localization as well as extensive supervision. [sent-27, score-0.481]
</p><p>12 While this method is relatively effective for front-facing cats and dogs, subjects in other domains (such as birds and people) often exhibit greater variation in pose and appearance and can be far more difficult to segment from their surroundings (see examples in Figure 1). [sent-32, score-0.286]
</p><p>13 In this work, we introduce deformable part descriptors (DPD), a robust and efficient framework for posenormalized description based on DPM parts and demonstrate its effectiveness for both fine-grained recognition and attribute prediction (see Figure 2). [sent-33, score-0.697]
</p><p>14 We propose two deformable part descriptors: the DPD-strong leverages the semantics inherent in strongly-supervised DPM parts; the DPD-weak exploits semantic annotations to learn crosscomponent correspondences, computing pose-normalized descriptors from weakly-supervised DPM parts. [sent-34, score-0.749]
</p><p>15 We present state-of-the-art results in evaluating our approach on standard fine-grained and domain-specific attribute datasets including the Caltech-UCSD birds dataset [13] and Human Attributes dataset [10]. [sent-35, score-0.339]
</p><p>16 An end-to-end open-source implementation of our method has been released with this paper and is available at http : / / dpd . [sent-36, score-0.426]
</p><p>17 While they work well for generally homogeneous objects such as dogs and cats, head-seeded segmentation-based descriptors often fail for other domains such as birds and humans. [sent-41, score-0.287]
</p><p>18 The ground truth segmentation is overlaid in red; the grab-cut based segmentation [38], seeded with the head as foreground and everything outside the bounding box  as background, is overlaid in white. [sent-43, score-0.275]
</p><p>19 The right column shows our part localization results using the strongly-supervised DPM. [sent-44, score-0.203]
</p><p>20 These domains include: dog breed classification [26, 29, 37], subordinate categories of flowers [2, 1, 33, 34] and plants [4, 39], recognition of invertebrates [32], fine-grained classification on subsets of ImageNet [16] such as fungi [15], and species-level categorization of birds [23, 46]. [sent-51, score-0.347]
</p><p>21 A very recent and closely related contribution is the Part-based One-vs-One Features (POOF) proposed by Berg and Belhumeur [6] which leverages robust keypoint predic-  tion learning a descriptor coordinate frame for each pair of keypoints. [sent-58, score-0.156]
</p><p>22 Some techniques use humans-in-the-loop, asking human annotators to click on object parts, answer questions regarding object attributes [13], or mark the region that best differentiates two confusing categories [17]. [sent-60, score-0.176]
</p><p>23 Relevant subsequent work on attributes includes that of Parikh and Grauman [35] exploring relative attribute strength and that of Berg et al. [sent-68, score-0.26]
</p><p>24 Perhaps the most closely related work on attribute prediction is Bourdev et al. [sent-71, score-0.22]
</p><p>25 [10], which uses features extracted from Poselet [11, 9] activations to predict nine binary attributes on images of humans. [sent-72, score-0.179]
</p><p>26 The object is represented by a coarse root HOG filter and several higher resolution part filters. [sent-79, score-0.177]
</p><p>27 Strongly-supervised DPM While the limited supervision required for the DPM is advantageous, the latent parts provide no semantic information about the object which makes pose-normalization challenging. [sent-83, score-0.403]
</p><p>28 Related work has used strong supervision to train DPMs for human pose estimation [41, 44], part localization [12] and object detection [3]. [sent-84, score-0.298]
</p><p>29 While these methods focus on detection, our objective is different, pooling semantic part features across components to derive a pose-normalized representation. [sent-85, score-0.55]
</p><p>30 The first descriptor (top row) applies a strongly-supervised DPM [3] for part localization and then performs pose-normalization by pooling features from these inherently semantic parts. [sent-89, score-0.593]
</p><p>31 The pose-normalized features Ψpn in Equation 3 can be used for either fine-grained recognition or attribute prediction (as indicated by the dotted arrows). [sent-90, score-0.22]
</p><p>32 The second descriptor employs a weakly-supervised DPM [24] for part localization and then uses a learned semantic correspondence model to pool features from the component-specific localized latent parts into semantic regions (the pose-normalized descriptor Ψpn) shared by all components. [sent-91, score-0.982]
</p><p>33 In the part to region pooling (the black, yellow, magenta, and cyan lines), wider lines indicate  higher weight. [sent-92, score-0.287]
</p><p>34 We use object part annotations and aim to localize the semantic parts for pose-normalized descriptors. [sent-95, score-0.602]
</p><p>35 Instead of initializing the fixed-size part filters heuristically (energy maximization), we initialize the part filters by using semantic part annotations. [sent-96, score-0.688]
</p><p>36 After training the mixture of root filters, we process the training images to get the component assignment for each training example. [sent-98, score-0.185]
</p><p>37 Then, for each component c, the part filters of this component are initialized at the average relative locations with average size among all the examples with component assignment c. [sent-99, score-0.341]
</p><p>38 Unlike [3], we do not impose constraints on part overlap during training. [sent-100, score-0.2]
</p><p>39 O(p0 (I) ,bbox) > δ Z(I) = (c(I),p0(I),  · · ·  ,pn(I))  (2)  where c(I) is the component assignment, p0 (I) is the predicted bounding box, pi (I) is the predicted location of part pi and O(p0, bbox) is the overlap between the predicted bounding box and ground truth bounding box. [sent-109, score-0.681]
</p><p>40 Given the part localizations, we show below how to form DPM-based pose-normalized descriptors and pool them across components, in a manner analogous to what the Pose-pooling Kernel (PPK) [47] does via Poselets. [sent-112, score-0.272]
</p><p>41 Deformable Part Descriptors (DPD) We use the deformable part model (DPM)’s demonstrated effectiveness for detecting objects as a foundation for our pose-normalized approach to fine-grained recognition and attribute prediction. [sent-114, score-0.419]
</p><p>42 We do this as a faster and more  reliable alternative to Poselets which were previously proposed for pose-normalization in both fine-grained recognition [23, 47] and attribute prediction [10]. [sent-115, score-0.22]
</p><p>43 [36, 37] trained a DPM model to locate a cat’s or a dog’s head and then used this detection both to describe the head appearance and to seed a segmentation which would recover the rest of the body (See Figure 1). [sent-118, score-0.313]
</p><p>44 Our goal is to use DPM to localize the parts and pool the pose-normalized image features induced by the part locations. [sent-119, score-0.324]
</p><p>45 This decomposition generally equates to localizing semantic parts and then describing them. [sent-123, score-0.483]
</p><p>46 e,p n(Pojw)}, de pif(ijn)edae n po tisneg-  normalized representation with R semantic pooling regions R = {r1, r2 , . [sent-132, score-0.353]
</p><p>47 (3)  where Ψ(I, rl) is the pooled image feature for semantic region rl and Ψ(I, r0) is the image feature inside the root filter or bounding box and we concatenate the image features together to get the final pose-normalized representation Ψpn. [sent-140, score-0.485]
</p><p>48 For each part , we seek to determine which pose-normalized pooling region or regions {rl} the features Ψ(I, ) sphoooulilndg g be r mapped rin rteog. [sent-142, score-0.287]
</p><p>49 oFnosr strongly-supervised ΨD(PIM,p, we use the semantic part annotations and it is straightforward to pool the corresponding part descriptor across different components by setting the semantic regions the same as the semantic parts from the strong DPM, i. [sent-143, score-1.332]
</p><p>50 Weakly-supervised DPD Using a weak DPM, the latent parts of different components have no explicit semantic correlation, nor is such correspondence guaranteed to exist. [sent-154, score-0.522]
</p><p>51 We have explored two options for dealing with this: one based on a per-component appearance representation with no semantic parts; the other leverages additional annotations to estimate semantic correspondence of the latent parts across components. [sent-155, score-0.778]
</p><p>52 The training and test sets are partitioned into subsets according to which component fires on them. [sent-157, score-0.187]
</p><p>53 First, the parts carry no semantic information (though this is not inherently necessary). [sent-160, score-0.343]
</p><p>54 By providing semantic annotations at training time, we can model semantic correspondence between the latent parts of different components. [sent-166, score-0.771]
</p><p>55 In effect, we learn the semantic identity of each latent part in the model and can thus pool features to a global pose-normalized model, independent of which component fires during detection. [sent-167, score-0.593]
</p><p>56 We model the pose-normalization as a weighted bipartite graph G = (P, R, W) where ∈ W indicates the degree to which , the i-th part of component c(j) contributes to rl . [sent-168, score-0.295]
</p><p>57 os Aenlentos)t,a trieocnt-s angular regions e(a kse uyspeodin nttos (traasin u Strong rDaiPnM Po) or any ,o rtehcet-r type of semantic labels. [sent-174, score-0.204]
</p><p>58 In our example, we use the keypoint annotations included with the CUB201 1 dataset [42] and H3D dataset [11]. [sent-175, score-0.262]
</p><p>59 (6)  where ρkl ∈ [0, 1] indicates a specified semantic relevance for annotat∈ion [0 ak itno region rl (e. [sent-178, score-0.434]
</p><p>60 Let Ijk be the set of training images that have semantic annLoettat Iion ak and where c(j) is the component which fires. [sent-188, score-0.432]
</p><p>61 (7)  It is worth noting that the training set need not be exhaustively labeled with semantic annotations. [sent-192, score-0.247]
</p><p>62 For the strongly-supervised DPD, we use the annotated semantic parts to get Ψpn for training and part localization from Equation 2 for testing; for the weaklysupervised DPD, we utilize Ψpn from Equation 2 for both training and testing. [sent-197, score-0.676]
</p><p>63 In such cases, we can use the classifier trained on the feature descriptor inside the bounding box Ψ(I, r0) without any pose-normalization. [sent-200, score-0.178]
</p><p>64 We conduct experiments on the commonly used fine-grained benchmark Caltech-UCSD bird dataset [42] as well as the Berkeley Human Attribute dataset from [10]. [sent-203, score-0.179]
</p><p>65 An open-source version of our end-to-end DPD implementation is available at http : / / dpd . [sent-205, score-0.426]
</p><p>66 Implementation Details Image Features and Classification After predicting the part regions via DPM, we use kernel descriptors [8] to extract feature vectors for final classification. [sent-211, score-0.225]
</p><p>67 5, 1} and Pl ρkl = 1; in other words, each semanti∈c part ak ,is1 a}ss aoncdiaPted with one or more regions rl (in a few cases it is shared Pbetween two, such as the shoulder between head and torso regions). [sent-219, score-0.502]
</p><p>68 This represents partitioning the semantic parts A amongst the pooling regions R. [sent-220, score-0.492]
</p><p>69 While the optimal method would likely model these spatial distributions with respect to , we relax this and simply record the fraction of semantically annotated images which have ak, for which c(j) fires and where ak has high overlap with (or falls  within) pi(j). [sent-223, score-0.279]
</p><p>70 Following [23], we use two semantic parts for the bird dataset: head and body. [sent-227, score-0.584]
</p><p>71 CUB200-2010 The initial version of the CUB200 dataset contains 6033 images of 200 different bird species in North America. [sent-229, score-0.191]
</p><p>72 Each image in the dataset has a bounding box annotation but no other annotation is provided. [sent-232, score-0.249]
</p><p>73 In order to train the strong DPM with semantic parts, we manually annotate the part locations for the training images, i. [sent-233, score-0.426]
</p><p>74 If one of the parts is not visible, we mark its visibility state as  0. [sent-236, score-0.179]
</p><p>75 Given those annotations on training images, we train a strong DPM with 5 components, each with these two parts. [sent-237, score-0.205]
</p><p>76 One baseline is to use the same image descriptors used by our methods inside the bounding box but without any pose normalization, i. [sent-241, score-0.282]
</p><p>77 Oracle is akin to DPD-strong but uses the ground truth head and body locations. [sent-249, score-0.179]
</p><p>78 This dataset contains 11,788 images of the same 200 bird species as CUB200-2010. [sent-254, score-0.191]
</p><p>79 We train both a weak DPM and a strong DPM to facilitate part localization. [sent-256, score-0.239]
</p><p>80 For the strong DPM, we  train a mixture of five components, each with two parts and we partition the keypoint annotations to generate the head and body part annotations. [sent-257, score-0.687]
</p><p>81 Specifically, we choose the semantic part annotations as the minimum rectangular region to cover the part’s specified subset of keypoints. [sent-258, score-0.463]
</p><p>82 This strong DPM enables part localization with the following accuracies: the head part with 45. [sent-259, score-0.516]
</p><p>83 Here we mark a correct prediction when the predicted part box and the ground truth part box have an overlap over 0. [sent-264, score-0.574]
</p><p>84 For the weak DPM, we train a mixture of three components, each with 8 parts and using pooling as described in Equation 5. [sent-266, score-0.348]
</p><p>85 The pooling weights learned for the bird model are  527. [sent-267, score-0.256]
</p><p>86 In each weight matrix, rows correspond to the semantic regions that the eight latent parts (columns) are pooled to. [sent-287, score-0.403]
</p><p>87 To understand the contribution of individual DPM parts to the classification accuracy, we blind a DPD-strong to individual semantic parts in an ablation study. [sent-298, score-0.482]
</p><p>88 We find that localizing the head part of the bird is especially important: removing the head part, the CUB200-201 1 accuracy falls to 43. [sent-300, score-0.607]
</p><p>89 In terms of other published work on this dataset, PPK [47] makes use of Poselet activations to generate pose-normalized representation and achieves a 773344  Per-component  gives the results when using the per-component  pooling method discussed in the beginning of Section 3. [sent-303, score-0.185]
</p><p>90 89% enabled both by accurate part (keypoint) localization and through the training  of thousands of classifiers. [sent-312, score-0.246]
</p><p>91 ,W 0e} use ptehec iHve3Dly data to train a strong DPM with 3 components and 3 semantic parts (head, torso and legs) and a weak DPM with 3 components and 8 parts. [sent-321, score-0.562]
</p><p>92 Example pooling weights learned for the weak DPM are visualized in the lower part of Figure 3. [sent-322, score-0.347]
</p><p>93 Similar to the CUB200-201 1 dataset, the semantic part annotations are generated from the keypoint annotations available from H3D. [sent-323, score-0.653]
</p><p>94 We then test on both the training and test images of the human attributes dataset to localize the parts and get pose-normalized image descriptors for attribute prediction. [sent-324, score-0.565]
</p><p>95 We use mean AP instead of mean accuracy for this dataset because the percentage of positive examples for each attribute is quite  varied. [sent-330, score-0.204]
</p><p>96 We described two such pose-normalized methods, respectively applicable to strongly-supervised and weakly-supervised variants of deformable part models. [sent-370, score-0.251]
</p><p>97 The first method exploits the semantics inherent in the stronglysupervised DPM’s parts, pooling them directly to form a pose-normalized descriptor. [sent-371, score-0.232]
</p><p>98 The second uses semantic annotations to learn cross-component correspondences between parts of the weakly-supervised DPM. [sent-372, score-0.503]
</p><p>99 We have evaluated the proposed DPD methods, surpassing the previous state-of-the-art performance on standard datasets for both fine-grained recognition and attribute prediction. [sent-374, score-0.168]
</p><p>100 Poof: Part-based one-vs-one features for finegrained categorization, face verication, and attribute estimation. [sent-428, score-0.243]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dpd', 0.426), ('dpm', 0.389), ('semantic', 0.204), ('attribute', 0.168), ('pooling', 0.149), ('parts', 0.139), ('part', 0.138), ('head', 0.134), ('ak', 0.129), ('annotations', 0.121), ('deformable', 0.113), ('bird', 0.107), ('rl', 0.101), ('birds', 0.099), ('localizing', 0.094), ('attributes', 0.092), ('fires', 0.088), ('descriptors', 0.087), ('dpds', 0.085), ('kl', 0.085), ('cats', 0.079), ('finegrained', 0.075), ('pn', 0.075), ('pi', 0.073), ('parkhi', 0.073), ('bourdev', 0.072), ('box', 0.072), ('ij', 0.071), ('kdes', 0.07), ('keypoint', 0.069), ('bounding', 0.069), ('jl', 0.067), ('localization', 0.065), ('poselet', 0.065), ('overlap', 0.062), ('poselets', 0.061), ('latent', 0.06), ('weak', 0.06), ('components', 0.059), ('subordinate', 0.058), ('berg', 0.057), ('sfar', 0.057), ('farrell', 0.056), ('component', 0.056), ('poof', 0.055), ('pose', 0.054), ('domains', 0.054), ('ijk', 0.053), ('prediction', 0.052), ('nine', 0.051), ('categorization', 0.051), ('localized', 0.051), ('leverages', 0.05), ('angelova', 0.05), ('placements', 0.05), ('ppk', 0.05), ('dog', 0.049), ('belhumeur', 0.049), ('species', 0.048), ('dogs', 0.047), ('flower', 0.047), ('pool', 0.047), ('stronglysupervised', 0.047), ('dxi', 0.047), ('equation', 0.046), ('describing', 0.046), ('branson', 0.045), ('wi', 0.045), ('body', 0.045), ('differentiates', 0.044), ('weaklysupervised', 0.044), ('vantage', 0.044), ('azizpour', 0.044), ('dyi', 0.044), ('training', 0.043), ('jacobs', 0.043), ('maji', 0.042), ('convolutional', 0.042), ('elephant', 0.042), ('tricos', 0.042), ('lj', 0.042), ('strong', 0.041), ('mark', 0.04), ('deng', 0.04), ('correspondences', 0.039), ('nilsback', 0.039), ('filter', 0.039), ('yao', 0.038), ('descriptor', 0.037), ('semantics', 0.036), ('berkeley', 0.036), ('ensembles', 0.036), ('activations', 0.036), ('breed', 0.036), ('dpms', 0.036), ('rke', 0.036), ('annotation', 0.036), ('dataset', 0.036), ('filters', 0.035), ('krause', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="107-tfidf-1" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>Author: Ning Zhang, Ryan Farrell, Forrest Iandola, Trevor Darrell</p><p>Abstract: Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.</p><p>2 0.31496489 <a title="107-tfidf-2" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>Author: Yuning Chai, Victor Lempitsky, Andrew Zisserman</p><p>Abstract: We propose a new method for the task of fine-grained visual categorization. The method builds a model of the baselevel category that can be fitted to images, producing highquality foreground segmentation and mid-level part localizations. The model can be learnt from the typical datasets available for fine-grained categorization, where the only annotation provided is a loose bounding box around the instance (e.g. bird) in each image. Both segmentation and part localizations are then used to encode the image content into a highly-discriminative visual signature. The model is symbiotic in that part discovery/localization is helped by segmentation and, conversely, the segmentation is helped by the detection (e.g. part layout). Our model builds on top of the part-based object category detector of Felzenszwalb et al., and also on the powerful GrabCut segmentation algorithm of Rother et al., and adds a simple spatial saliency coupling between them. In our evaluation, the model improves the categorization accuracy over the state-of-the-art. It also improves over what can be achieved with an analogous system that runs segmentation and part-localization independently.</p><p>3 0.26048747 <a title="107-tfidf-3" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>Author: Jungseock Joo, Shuo Wang, Song-Chun Zhu</p><p>Abstract: We present a part-based approach to the problem of human attribute recognition from a single image of a human body. To recognize the attributes of human from the body parts, it is important to reliably detect the parts. This is a challenging task due to the geometric variation such as articulation and view-point changes as well as the appearance variation of the parts arisen from versatile clothing types. The prior works have primarily focused on handling . edu . cn ???????????? geometric variation by relying on pre-trained part detectors or pose estimators, which require manual part annotation, but the appearance variation has been relatively neglected in these works. This paper explores the importance of the appearance variation, which is directly related to the main task, attribute recognition. To this end, we propose to learn a rich appearance part dictionary of human with significantly less supervision by decomposing image lattice into overlapping windows at multiscale and iteratively refining local appearance templates. We also present quantitative results in which our proposed method outperforms the existing approaches.</p><p>4 0.22072378 <a title="107-tfidf-4" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<p>Author: Jiongxin Liu, Peter N. Belhumeur</p><p>Abstract: In this paper, we propose a novel approach for bird part localization, targeting fine-grained categories with wide variations in appearance due to different poses (including aspect and orientation) and subcategories. As it is challenging to represent such variations across a large set of diverse samples with tractable parametric models, we turn to individual exemplars. Specifically, we extend the exemplarbased models in [4] by enforcing pose and subcategory consistency at the parts. During training, we build posespecific detectors scoring part poses across subcategories, and subcategory-specific detectors scoring part appearance across poses. At the testing stage, likely exemplars are matched to the image, suggesting part locations whose pose and subcategory consistency are well-supported by the image cues. From these hypotheses, part configuration can be predicted with very high accuracy. Experimental results demonstrate significantperformance gainsfrom our method on an extensive dataset: CUB-200-2011 [30], for both localization and classification tasks.</p><p>5 0.20838307 <a title="107-tfidf-5" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>Author: Ross Girshick, Jitendra Malik</p><p>Abstract: In this paper, we show how to train a deformable part model (DPM) fast—typically in less than 20 minutes, or four times faster than the current fastest method—while maintaining high average precision on the PASCAL VOC datasets. At the core of our approach is “latent LDA,” a novel generalization of linear discriminant analysis for learning latent variable models. Unlike latent SVM, latent LDA uses efficient closed-form updates and does not require an expensive search for hard negative examples. Our approach also acts as a springboard for a detailed experimental study of DPM training. We isolate and quantify the impact of key training factors for the first time (e.g., How important are discriminative SVM filters? How important is joint parameter estimation? How many negative images are needed for training?). Our findings yield useful insights for researchers working with Markov random fields and partbased models, and have practical implications for speeding up tasks such as model selection.</p><p>6 0.20651241 <a title="107-tfidf-6" href="./iccv-2013-A_Unified_Probabilistic_Approach_Modeling_Relationships_between_Attributes_and_Objects.html">31 iccv-2013-A Unified Probabilistic Approach Modeling Relationships between Attributes and Objects</a></p>
<p>7 0.20294988 <a title="107-tfidf-7" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>8 0.18996106 <a title="107-tfidf-8" href="./iccv-2013-Strong_Appearance_and_Expressive_Spatial_Models_for_Human_Pose_Estimation.html">403 iccv-2013-Strong Appearance and Expressive Spatial Models for Human Pose Estimation</a></p>
<p>9 0.18899383 <a title="107-tfidf-9" href="./iccv-2013-Fine-Grained_Categorization_by_Alignments.html">169 iccv-2013-Fine-Grained Categorization by Alignments</a></p>
<p>10 0.17678957 <a title="107-tfidf-10" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>11 0.17425822 <a title="107-tfidf-11" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>12 0.16052657 <a title="107-tfidf-12" href="./iccv-2013-Modeling_Occlusion_by_Discriminative_AND-OR_Structures.html">269 iccv-2013-Modeling Occlusion by Discriminative AND-OR Structures</a></p>
<p>13 0.15196484 <a title="107-tfidf-13" href="./iccv-2013-Attribute_Adaptation_for_Personalized_Image_Search.html">52 iccv-2013-Attribute Adaptation for Personalized Image Search</a></p>
<p>14 0.15155016 <a title="107-tfidf-14" href="./iccv-2013-Semantic_Transform%3A_Weakly_Supervised_Semantic_Inference_for_Relating_Visual_Attributes.html">380 iccv-2013-Semantic Transform: Weakly Supervised Semantic Inference for Relating Visual Attributes</a></p>
<p>15 0.15145625 <a title="107-tfidf-15" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>16 0.14895828 <a title="107-tfidf-16" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>17 0.14859478 <a title="107-tfidf-17" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>18 0.14221278 <a title="107-tfidf-18" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<p>19 0.14209753 <a title="107-tfidf-19" href="./iccv-2013-Detecting_Dynamic_Objects_with_Multi-view_Background_Subtraction.html">111 iccv-2013-Detecting Dynamic Objects with Multi-view Background Subtraction</a></p>
<p>20 0.1361836 <a title="107-tfidf-20" href="./iccv-2013-No_Matter_Where_You_Are%3A_Flexible_Graph-Guided_Multi-task_Learning_for_Multi-view_Head_Pose_Classification_under_Target_Motion.html">291 iccv-2013-No Matter Where You Are: Flexible Graph-Guided Multi-task Learning for Multi-view Head Pose Classification under Target Motion</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.283), (1, 0.123), (2, 0.01), (3, -0.129), (4, 0.217), (5, -0.096), (6, -0.093), (7, -0.031), (8, 0.018), (9, -0.015), (10, 0.053), (11, 0.075), (12, -0.089), (13, -0.196), (14, -0.116), (15, -0.007), (16, 0.075), (17, 0.119), (18, 0.125), (19, -0.012), (20, 0.04), (21, 0.126), (22, 0.019), (23, 0.007), (24, 0.024), (25, 0.077), (26, -0.001), (27, -0.064), (28, 0.073), (29, 0.046), (30, 0.086), (31, -0.108), (32, -0.043), (33, -0.043), (34, -0.047), (35, -0.041), (36, 0.04), (37, -0.022), (38, 0.041), (39, 0.023), (40, -0.013), (41, -0.051), (42, 0.081), (43, -0.023), (44, -0.019), (45, 0.065), (46, 0.026), (47, 0.048), (48, 0.017), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97013074 <a title="107-lsi-1" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>Author: Ning Zhang, Ryan Farrell, Forrest Iandola, Trevor Darrell</p><p>Abstract: Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.</p><p>2 0.83866328 <a title="107-lsi-2" href="./iccv-2013-Fine-Grained_Categorization_by_Alignments.html">169 iccv-2013-Fine-Grained Categorization by Alignments</a></p>
<p>Author: E. Gavves, B. Fernando, C.G.M. Snoek, A.W.M. Smeulders, T. Tuytelaars</p><p>Abstract: The aim of this paper is fine-grained categorization without human interaction. Different from prior work, which relies on detectors for specific object parts, we propose to localize distinctive details by roughly aligning the objects using just the overall shape, since implicit to fine-grained categorization is the existence of a super-class shape shared among all classes. The alignments are then used to transfer part annotations from training images to test images (supervised alignment), or to blindly yet consistently segment the object in a number of regions (unsupervised alignment). We furthermore argue that in the distinction of finegrained sub-categories, classification-oriented encodings like Fisher vectors are better suited for describing localized information than popular matching oriented features like HOG. We evaluate the method on the CU-2011 Birds and Stanford Dogs fine-grained datasets, outperforming the state-of-the-art.</p><p>3 0.80478311 <a title="107-lsi-3" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>Author: Yuning Chai, Victor Lempitsky, Andrew Zisserman</p><p>Abstract: We propose a new method for the task of fine-grained visual categorization. The method builds a model of the baselevel category that can be fitted to images, producing highquality foreground segmentation and mid-level part localizations. The model can be learnt from the typical datasets available for fine-grained categorization, where the only annotation provided is a loose bounding box around the instance (e.g. bird) in each image. Both segmentation and part localizations are then used to encode the image content into a highly-discriminative visual signature. The model is symbiotic in that part discovery/localization is helped by segmentation and, conversely, the segmentation is helped by the detection (e.g. part layout). Our model builds on top of the part-based object category detector of Felzenszwalb et al., and also on the powerful GrabCut segmentation algorithm of Rother et al., and adds a simple spatial saliency coupling between them. In our evaluation, the model improves the categorization accuracy over the state-of-the-art. It also improves over what can be achieved with an analogous system that runs segmentation and part-localization independently.</p><p>4 0.80156744 <a title="107-lsi-4" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>Author: Jungseock Joo, Shuo Wang, Song-Chun Zhu</p><p>Abstract: We present a part-based approach to the problem of human attribute recognition from a single image of a human body. To recognize the attributes of human from the body parts, it is important to reliably detect the parts. This is a challenging task due to the geometric variation such as articulation and view-point changes as well as the appearance variation of the parts arisen from versatile clothing types. The prior works have primarily focused on handling . edu . cn ???????????? geometric variation by relying on pre-trained part detectors or pose estimators, which require manual part annotation, but the appearance variation has been relatively neglected in these works. This paper explores the importance of the appearance variation, which is directly related to the main task, attribute recognition. To this end, we propose to learn a rich appearance part dictionary of human with significantly less supervision by decomposing image lattice into overlapping windows at multiscale and iteratively refining local appearance templates. We also present quantitative results in which our proposed method outperforms the existing approaches.</p><p>5 0.77519846 <a title="107-lsi-5" href="./iccv-2013-From_Subcategories_to_Visual_Composites%3A_A_Multi-level_Framework_for_Object_Detection.html">179 iccv-2013-From Subcategories to Visual Composites: A Multi-level Framework for Object Detection</a></p>
<p>Author: Tian Lan, Michalis Raptis, Leonid Sigal, Greg Mori</p><p>Abstract: The appearance of an object changes profoundly with pose, camera view and interactions of the object with other objects in the scene. This makes it challenging to learn detectors based on an object-level label (e.g., “car”). We postulate that having a richer set oflabelings (at different levels of granularity) for an object, including finer-grained subcategories, consistent in appearance and view, and higherorder composites – contextual groupings of objects consistent in their spatial layout and appearance, can significantly alleviate these problems. However, obtaining such a rich set of annotations, including annotation of an exponentially growing set of object groupings, is simply not feasible. We propose a weakly-supervised framework for object detection where we discover subcategories and the composites automatically with only traditional object-level category labels as input. To this end, we first propose an exemplar-SVM-based clustering approach, with latent SVM refinement, that discovers a variable length set of discriminative subcategories for each object class. We then develop a structured model for object detection that captures interactions among object subcategories and automatically discovers semantically meaningful and discriminatively relevant visual composites. We show that this model produces state-of-the-art performance on UIUC phrase object detection benchmark.</p><p>6 0.77246916 <a title="107-lsi-6" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>7 0.76901567 <a title="107-lsi-7" href="./iccv-2013-Bird_Part_Localization_Using_Exemplar-Based_Models_with_Enforced_Pose_and_Subcategory_Consistency.html">62 iccv-2013-Bird Part Localization Using Exemplar-Based Models with Enforced Pose and Subcategory Consistency</a></p>
<p>8 0.76421845 <a title="107-lsi-8" href="./iccv-2013-How_Do_You_Tell_a_Blackbird_from_a_Crow%3F.html">202 iccv-2013-How Do You Tell a Blackbird from a Crow?</a></p>
<p>9 0.75658596 <a title="107-lsi-9" href="./iccv-2013-Building_Part-Based_Object_Detectors_via_3D_Geometry.html">66 iccv-2013-Building Part-Based Object Detectors via 3D Geometry</a></p>
<p>10 0.73723459 <a title="107-lsi-10" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>11 0.71920341 <a title="107-lsi-11" href="./iccv-2013-Shufflets%3A_Shared_Mid-level_Parts_for_Fast_Object_Detection.html">390 iccv-2013-Shufflets: Shared Mid-level Parts for Fast Object Detection</a></p>
<p>12 0.68797821 <a title="107-lsi-12" href="./iccv-2013-NEIL%3A_Extracting_Visual_Knowledge_from_Web_Data.html">285 iccv-2013-NEIL: Extracting Visual Knowledge from Web Data</a></p>
<p>13 0.68633187 <a title="107-lsi-13" href="./iccv-2013-Detecting_Avocados_to_Zucchinis%3A_What_Have_We_Done%2C_and_Where_Are_We_Going%3F.html">109 iccv-2013-Detecting Avocados to Zucchinis: What Have We Done, and Where Are We Going?</a></p>
<p>14 0.67902166 <a title="107-lsi-14" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>15 0.67782849 <a title="107-lsi-15" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>16 0.66858935 <a title="107-lsi-16" href="./iccv-2013-Modeling_Occlusion_by_Discriminative_AND-OR_Structures.html">269 iccv-2013-Modeling Occlusion by Discriminative AND-OR Structures</a></p>
<p>17 0.66597509 <a title="107-lsi-17" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>18 0.63910747 <a title="107-lsi-18" href="./iccv-2013-Style-Aware_Mid-level_Representation_for_Discovering_Visual_Connections_in_Space_and_Time.html">406 iccv-2013-Style-Aware Mid-level Representation for Discovering Visual Connections in Space and Time</a></p>
<p>19 0.6319899 <a title="107-lsi-19" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>20 0.61626095 <a title="107-lsi-20" href="./iccv-2013-What_Do_You_Do%3F_Occupation_Recognition_in_a_Photo_via_Social_Context.html">449 iccv-2013-What Do You Do? Occupation Recognition in a Photo via Social Context</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.057), (4, 0.127), (7, 0.019), (12, 0.019), (26, 0.104), (31, 0.034), (34, 0.059), (35, 0.027), (40, 0.012), (42, 0.087), (48, 0.012), (55, 0.032), (64, 0.07), (73, 0.036), (77, 0.011), (78, 0.024), (89, 0.177), (95, 0.013), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88872927 <a title="107-lda-1" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>Author: Ning Zhang, Ryan Farrell, Forrest Iandola, Trevor Darrell</p><p>Abstract: Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.</p><p>2 0.88166183 <a title="107-lda-2" href="./iccv-2013-Feature_Weighting_via_Optimal_Thresholding_for_Video_Analysis.html">163 iccv-2013-Feature Weighting via Optimal Thresholding for Video Analysis</a></p>
<p>Author: Zhongwen Xu, Yi Yang, Ivor Tsang, Nicu Sebe, Alexander G. Hauptmann</p><p>Abstract: Fusion of multiple features can boost the performance of large-scale visual classification and detection tasks like TRECVID Multimedia Event Detection (MED) competition [1]. In this paper, we propose a novel feature fusion approach, namely Feature Weighting via Optimal Thresholding (FWOT) to effectively fuse various features. FWOT learns the weights, thresholding and smoothing parameters in a joint framework to combine the decision values obtained from all the individual features and the early fusion. To the best of our knowledge, this is the first work to consider the weight and threshold factors of fusion problem simultaneously. Compared to state-of-the-art fusion algorithms, our approach achieves promising improvements on HMDB [8] action recognition dataset and CCV [5] video classification dataset. In addition, experiments on two TRECVID MED 2011 collections show that our approach outperforms the state-of-the-art fusion methods for complex event detection.</p><p>3 0.88122892 <a title="107-lda-3" href="./iccv-2013-Learning_Discriminative_Part_Detectors_for_Image_Classification_and_Cosegmentation.html">236 iccv-2013-Learning Discriminative Part Detectors for Image Classification and Cosegmentation</a></p>
<p>Author: Jian Sun, Jean Ponce</p><p>Abstract: In this paper, we address the problem of learning discriminative part detectors from image sets with category labels. We propose a novel latent SVM model regularized by group sparsity to learn these part detectors. Starting from a large set of initial parts, the group sparsity regularizer forces the model to jointly select and optimize a set of discriminative part detectors in a max-margin framework. We propose a stochastic version of a proximal algorithm to solve the corresponding optimization problem. We apply the proposed method to image classification and cosegmentation, and quantitative experiments with standard benchmarks show that it matches or improves upon the state of the art.</p><p>4 0.87766051 <a title="107-lda-4" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>Author: Oren Barkan, Jonathan Weill, Lior Wolf, Hagai Aronowitz</p><p>Abstract: This paper advances descriptor-based face recognition by suggesting a novel usage of descriptors to form an over-complete representation, and by proposing a new metric learning pipeline within the same/not-same framework. First, the Over-Complete Local Binary Patterns (OCLBP) face representation scheme is introduced as a multi-scale modified version of the Local Binary Patterns (LBP) scheme. Second, we propose an efficient matrix-vector multiplication-based recognition system. The system is based on Linear Discriminant Analysis (LDA) coupled with Within Class Covariance Normalization (WCCN). This is further extended to the unsupervised case by proposing an unsupervised variant of WCCN. Lastly, we introduce Diffusion Maps (DM) for non-linear dimensionality reduction as an alternative to the Whitened Principal Component Analysis (WPCA) method which is often used in face recognition. We evaluate the proposed framework on the LFW face recognition dataset under the restricted, unrestricted and unsupervised protocols. In all three cases we achieve very competitive results.</p><p>5 0.86880654 <a title="107-lda-5" href="./iccv-2013-Hidden_Factor_Analysis_for_Age_Invariant_Face_Recognition.html">195 iccv-2013-Hidden Factor Analysis for Age Invariant Face Recognition</a></p>
<p>Author: Dihong Gong, Zhifeng Li, Dahua Lin, Jianzhuang Liu, Xiaoou Tang</p><p>Abstract: Age invariant face recognition has received increasing attention due to its great potential in real world applications. In spite of the great progress in face recognition techniques, reliably recognizingfaces across ages remains a difficult task. The facial appearance of a person changes substantially over time, resulting in significant intra-class variations. Hence, the key to tackle this problem is to separate the variation caused by aging from the person-specific features that are stable. Specifically, we propose a new method, calledHidden FactorAnalysis (HFA). This methodcaptures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process. Then, the observed appearance can be modeled as a combination of the components generated based on these factors. We also develop a learning algorithm that jointly estimates the latent factors and the model parameters using an EM procedure. Extensive experiments on two well-known public domain face aging datasets: MORPH (the largest public face aging database) and FGNET, clearly show that the proposed method achieves notable improvement over state-of-the-art algorithms.</p><p>6 0.86117768 <a title="107-lda-6" href="./iccv-2013-Category-Independent_Object-Level_Saliency_Detection.html">71 iccv-2013-Category-Independent Object-Level Saliency Detection</a></p>
<p>7 0.858069 <a title="107-lda-7" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>8 0.85516673 <a title="107-lda-8" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>9 0.85449862 <a title="107-lda-9" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>10 0.84507865 <a title="107-lda-10" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>11 0.84486943 <a title="107-lda-11" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>12 0.84319818 <a title="107-lda-12" href="./iccv-2013-A_Unified_Probabilistic_Approach_Modeling_Relationships_between_Attributes_and_Objects.html">31 iccv-2013-A Unified Probabilistic Approach Modeling Relationships between Attributes and Objects</a></p>
<p>13 0.84092808 <a title="107-lda-13" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>14 0.83725333 <a title="107-lda-14" href="./iccv-2013-Visual_Reranking_through_Weakly_Supervised_Multi-graph_Learning.html">445 iccv-2013-Visual Reranking through Weakly Supervised Multi-graph Learning</a></p>
<p>15 0.83705693 <a title="107-lda-15" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>16 0.83698702 <a title="107-lda-16" href="./iccv-2013-Human_Attribute_Recognition_by_Rich_Appearance_Dictionary.html">204 iccv-2013-Human Attribute Recognition by Rich Appearance Dictionary</a></p>
<p>17 0.83667701 <a title="107-lda-17" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>18 0.83644134 <a title="107-lda-18" href="./iccv-2013-Style-Aware_Mid-level_Representation_for_Discovering_Visual_Connections_in_Space_and_Time.html">406 iccv-2013-Style-Aware Mid-level Representation for Discovering Visual Connections in Space and Time</a></p>
<p>19 0.83609498 <a title="107-lda-19" href="./iccv-2013-Breaking_the_Chain%3A_Liberation_from_the_Temporal_Markov_Assumption_for_Tracking_Human_Poses.html">65 iccv-2013-Breaking the Chain: Liberation from the Temporal Markov Assumption for Tracking Human Poses</a></p>
<p>20 0.83516991 <a title="107-lda-20" href="./iccv-2013-Event_Detection_in_Complex_Scenes_Using_Interval_Temporal_Constraints.html">146 iccv-2013-Event Detection in Complex Scenes Using Interval Temporal Constraints</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
