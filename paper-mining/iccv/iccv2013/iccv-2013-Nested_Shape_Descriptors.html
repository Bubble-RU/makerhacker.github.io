<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>288 iccv-2013-Nested Shape Descriptors</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-288" href="#">iccv2013-288</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>288 iccv-2013-Nested Shape Descriptors</h1>
<br/><p>Source: <a title="iccv-2013-288-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Byrne_Nested_Shape_Descriptors_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Jeffrey Byrne, Jianbo Shi</p><p>Abstract: In this paper, we propose a new family of binary local feature descriptors called nested shape descriptors. These descriptors are constructed by pooling oriented gradients over a large geometric structure called the Hawaiian earring, which is constructed with a nested correlation structure that enables a new robust local distance function called the nesting distance. This distance function is unique to the nested descriptor and provides robustness to outliers from order statistics. In this paper, we define the nested shape descriptor family and introduce a specific member called the seed-of-life descriptor. We perform a trade study to determine optimal descriptor parameters for the task of image matching. Finally, we evaluate performance compared to state-of-the-art local feature descriptors on the VGGAffine image matching benchmark, showing significant performance gains. Our descriptor is thefirst binary descriptor to outperform SIFT on this benchmark.</p><p>Reference: <a title="iccv-2013-288-reference" href="../iccv2013_reference/iccv-2013-Nested_Shape_Descriptors_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract In this paper, we propose a new family of binary local feature descriptors called nested shape descriptors. [sent-3, score-0.836]
</p><p>2 These descriptors are constructed by pooling oriented gradients over a large geometric structure called the Hawaiian earring, which is constructed with a nested correlation structure that enables a new robust local distance function called the nesting distance. [sent-4, score-1.59]
</p><p>3 This distance function is unique to the nested descriptor and provides robustness to outliers from order statistics. [sent-5, score-0.828]
</p><p>4 In this paper, we define the nested shape descriptor family and introduce a specific member called the seed-of-life descriptor. [sent-6, score-0.908]
</p><p>5 We perform a trade study to determine optimal descriptor parameters for the task of image matching. [sent-7, score-0.247]
</p><p>6 Our descriptor is thefirst binary descriptor to outperform SIFT on this benchmark. [sent-9, score-0.407]
</p><p>7 It is well known that for the task ofimage matching, descriptors constructed with larger support outperform descriptors with smaller support [20, 8, 3, 17, 15]. [sent-16, score-0.33]
</p><p>8 (left) Hawaiian earrings with k-fold rotational symmetry define a member of the nested shape descriptor family called the seed-oflife descriptor (right) Two Hawaiian earrings substructures in the seed-of-life descriptor are highlighted in grey. [sent-18, score-1.576]
</p><p>9 For example, there may be arbitrarily large outliers in the descriptor due to occlusions and geometric variation effects far from the descriptor center. [sent-20, score-0.417]
</p><p>10 In this paper, we introduce nested shape descriptors to address this tradeoff. [sent-22, score-0.699]
</p><p>11 A nested shape descriptor (NSD) is a family of binary local feature descriptors constructed by pooling oriented and scaled gradients over a large geometric structure called an Hawaiian earring. [sent-23, score-1.211]
</p><p>12 An example of the nested shape descriptor is shown in figure 1. [sent-24, score-0.789]
</p><p>13 Each descrip-  tor has global support covering the entire image, and the structure of the descriptor exhibits fractal self-similarity in scale. [sent-25, score-0.252]
</p><p>14 This correlated nested structure enables new a robust distance function called the nesting distance. [sent-26, score-1.25]
</p><p>15 The nesting distance uses order statistics for robustness to outliers while maintaining a descriptor with global support. [sent-27, score-0.881]
</p><p>16 1201  •  •  Binary: NSDs are binary, which enables for compact storage :a NndS Dalslo awres bthinea nesting hdi estnaanbclee st foo use a pfaacstt Hamming distance, without sacrificing matching performance. [sent-30, score-0.646]
</p><p>17 Robust local distance function: The nesting distance iRs a quadratic dloisctaaln dcies tfaunnccet ifounn:cTt iohne tnheastt nisg r odibsutsant ctoe corruption of the descriptor due to occlusions, geometric variations or lighting. [sent-31, score-0.942]
</p><p>18 In this paper, we provide sufficient conditions for construction of a nested shape descriptor using key concepts of cumulative nested pooling and log spiral normalization. [sent-32, score-1.538]
</p><p>19 We perform a trade study to determine optimal descriptor parameters for the task of image matching. [sent-33, score-0.247]
</p><p>20 Recent work has focused on introducing binary features from local comparison tests [3, 8, 17, 15] which enables fast distance metric based on Hamming distance and faster derivatives [13]. [sent-40, score-0.218]
</p><p>21 A taxonomy for comparing and contrasting local feature descriptors can be described in terms of five criteria: preprocessing, support, pooling, normalization and descriptor distance. [sent-42, score-0.334]
</p><p>22 Preprocessing refers to the filtering performed on the input image, support patterns are the geometric struc-  ture used for constructing the descriptor and pooling is the aggregation of filter responses over the support structure. [sent-43, score-0.383]
</p><p>23 Using this taxonomy, the nested shape descriptor is most closely related to DAISY, BRISK and FREAK. [sent-45, score-0.789]
</p><p>24 In the taxonomy of [16], the nesting distance is per-exemplar (“where”), online (“when”) using order statistics (“how”) without requiring any offline training. [sent-51, score-0.719]
</p><p>25 Nested Shape Descriptors In this section, we describe the construction of nested shape descriptors. [sent-53, score-0.615]
</p><p>26 NSD are constructed by first defining  the nested pooling structure (section 3. [sent-54, score-0.672]
</p><p>27 We provide definitions for this construction and show how the nested shape descriptor is constructed from these pieces (section 3. [sent-56, score-0.816]
</p><p>28 4), which uses the properties of the nested descriptor to provide robust distance function. [sent-59, score-0.801]
</p><p>29 Finally, we define a specific member of the nested shape descriptor family called the seed-of-life descriptor (section 3. [sent-60, score-1.082]
</p><p>30 The nested descriptor and nesting distance are compared to a generic grid descriptor (e. [sent-64, score-1.581]
</p><p>31 The red X’s and green checkmarks show where a grid descriptor is corrupted due to the scene variation, which leads to poor matching performance. [sent-67, score-0.261]
</p><p>32 For these cases, the NSD and nesting distance are able to select the best subset of supports during matching to provide robustness to these scene variations. [sent-68, score-0.789]
</p><p>33 Given a pair of descriptors, the nesting distance computes a weighted sum of the best k coordinate matches. [sent-71, score-0.661]
</p><p>34 The nesting  distance relies on nesting, such that all supports are linked by exactly one point in the center of the descriptor. [sent-75, score-0.797]
</p><p>35 Hawaiian Earrings and Nested Pooling Nested shape descriptors represent shape using cumulative pooling of oriented gradients within Hawaiian earrings. [sent-80, score-0.335]
</p><p>36 Figure 1 (right) shows an example of the Hawaiian 1202  distance selects the best subset of supports in the nested descriptor that cover only the object (green checkmarks). [sent-81, score-0.9]
</p><p>37 (middle) Viewpoint changes for long and thin foreground structures introduce errors in grid descriptor matching due to large changes in the background. [sent-82, score-0.219]
</p><p>38 The nesting distance selects the subset of supports during matching that cover the foreground and are the correct scale to allow for background variation. [sent-83, score-0.789]
</p><p>39 (right) Scale changes without scale invariant detectors introduce errors in grid descriptor matching due to changes in local support. [sent-84, score-0.235]
</p><p>40 The nesting distance uses a subset of both large and small scale supports, ignoring intermediate scale supports with corruption. [sent-85, score-0.76]
</p><p>41 earring substructure formed by a nested set of circles all intersecting at exactly one point at the center. [sent-86, score-0.703]
</p><p>42 The Hawaiian earring is a nested structure analogous to Matryoshka or Russian nesting dolls, where each smaller doll fits neatly inside the next larger doll. [sent-87, score-1.258]
</p><p>43 Hawaiian earrings may be combined into sets such that each earring is called a lobe. [sent-88, score-0.27]
</p><p>44 Each lobe exhibits scale symmetry and all earrings intersect at exactly one point in the center. [sent-89, score-0.232]
</p><p>45 For example, in figure 1(right), the two lobes highlighted in grey are Hawaiian earrings K6 (1) and K6 (4) and the two largest circles are referenced as supports K6 (1, 4) and K6 (4, 4). [sent-97, score-0.327]
</p><p>46 Nested Shape Descriptors A nested shape descriptor D at interest point p is defined by nested pooling, logarithmic spiral normalization and binarization of oriented gradients B over a nested support Kn. [sent-100, score-2.2]
</p><p>47 01 iofthdˆe(ir,wjis,ek) > 0  (3)  Equation (1) is nested pooling. [sent-102, score-0.556]
</p><p>48 The descriptor d(i, j,k) is the pooled response for orientation subband i, lobe j and lobe scale k. [sent-104, score-0.319]
</p><p>49 Observe that the bandpass octave scale s is equal to the Hawaiian earring support radius k. [sent-105, score-0.253]
</p><p>50 As the support radius increases, the pooling support contains the next smaller support, resulting in nested pooling within a lobe. [sent-107, score-0.865]
</p><p>51 A nested support set Kn exhibits a logarithmic spiral when considering neighboring supports. [sent-113, score-0.791]
</p><p>52 A nested shape descriptor can be binarized by computing the sign of (2). [sent-120, score-0.789]
</p><p>53 This constructs a nested shape descriptor with binary entries. [sent-121, score-0.829]
</p><p>54 (top) Logarithmic spiral property of the nested shape descriptor provides normalization and binarization. [sent-124, score-0.914]
</p><p>55 (bottom) An NSD is formed at each interest point by (left) nested pooling of scaled and oriented gradients and (right) logspiral difference and binarization. [sent-126, score-0.71]
</p><p>56 pooling is equivalent to pooling of fixed radius over scales  ×  of a steerable pyramid [19], which is analogous to a “flattening” of a pyramid representation of scaled and oriented gradients. [sent-127, score-0.325]
</p><p>57 The final nested shape descriptor D is a binary vector of length (R |K| |K|) for R orientation bands over |vKec| loorb oefs aenndg |hK (|R supports per floobre R. [sent-128, score-0.982]
</p><p>58 The Seed-of-Life Descriptor The nested shape descriptors in section 3. [sent-132, score-0.699]
</p><p>59 In this section, we define a specific member of this family called the seed-of-life nested shape descriptor or simply the seedof-life descriptor. [sent-135, score-0.908]
</p><p>60 The seed-of-life descriptor is a nested shape descriptor such that the nested pooling Kn is defined using a rotationally symmetric geometric structure called the seed-oflife. [sent-136, score-1.661]
</p><p>61 ber of the nested shape descriptor family since it exhibits rotational symmetry where Hawaiian earring lobes are spaced uniformly in angle. [sent-143, score-1.095]
</p><p>62 Nesting Distance The nesting distance is a robust quadratic local distance function [16] unique to NSDs based on order statistics. [sent-147, score-0.748]
</p><p>63 Given two nested descriptors p and q, the nesting distance d(p, q) uses order statistics to partition the supports of two nested descriptors into inliers and outliers by sorting the squared differences up to a given maximum order k. [sent-148, score-2.145]
</p><p>64 Then,  ×  the nesting distance is equivalent to computing the conditional Gaussian distribution of inliers given outliers. [sent-149, score-0.722]
</p><p>65 Let p and q be two nested descriptors of length n. [sent-163, score-0.64]
</p><p>66 dLifefet trhenisc partition )b e represented by selection −  1204  points between the reference image (middle) and the observed image using the nesting distance (left) and Euclidean distance (right). [sent-165, score-0.749]
</p><p>67 The Euclidean distance is affected by occlusions at the image boundary (left ellipse) resulting in local misalignments, while the nested distance  is more robust to these occlusion effects. [sent-166, score-0.736]
</p><p>68 Then, the nesting distance d is  d(p, q, Λ, k) = (p −q)T(I  −S(k+1,n))ΛS(1,k)(p −q) (6)  where Lambda is an optional quadratic weighting matrix. [sent-168, score-0.661]
</p><p>69 Furthermore, if k = n and Λ = I then the nesting distance is equivalent to the Euclidean distance. [sent-170, score-0.68]
</p><p>70 If the nesting distance is of the form (6), then it is equivalent to an unnormalizednegative log likelihood ofa conditional Gaussian distribution for inliers given outliers. [sent-173, score-0.722]
</p><p>71 The nesting distance was designed specifically for the structure of the nested shape descriptor. [sent-182, score-1.276]
</p><p>72 Therefore, this enables the use of order statistics to partition the supports into inliers and outliers, since all supports have one point in common. [sent-185, score-0.276]
</p><p>73 The nesting distance cannot be used for descriptors with support constructed on a log-polar or Cartesian grid. [sent-186, score-0.822]
</p><p>74 Figure 4 shows an example of the benefits of the nesting distance for image matching. [sent-191, score-0.661]
</p><p>75 We extract interest points using an edge based detector, compute nested descriptors at each point, then perform greedy minimum distance assignment from the reference to the observation using either the  nesting distance or Euclidean distance. [sent-192, score-1.372]
</p><p>76 This example shows that the nested distance is more robust to occlusions at the image border than the Euclidean distance. [sent-193, score-0.649]
</p><p>77 Finally, The nesting distance has two useful properties that are proven in the supplementary material. [sent-194, score-0.661]
</p><p>78 First, the nesting distance is non-metric, since it does not satisfy identity or the triangle inequality properties. [sent-195, score-0.661]
</p><p>79 Second, the nesting distance is robust up to corruption of n k coordinates. [sent-197, score-0.661]
</p><p>80 Experimental Results In this section, we provide experimental results for the nested shape descriptor and nesting distance for the task of image matching. [sent-199, score-1.45]
</p><p>81 First, we perform a trade study using the new experimental protocol of similarity stereo matching to determine an optimal set of descriptor parameters for the seed-of-life descriptor. [sent-200, score-0.343]
</p><p>82 Next, we compare results for the seed-of-life and binary seed-of-life descriptor for the standard VGG-Affine benchmark [12] against SIFT [9] and BRISK [8]. [sent-201, score-0.214]
</p><p>83 Finally, we show results on a challeng1205  Both SOL and BSOL outperform SIFT and BRISK, and Binary-SOL is the first binary descriptor to outperform SIFT on this benchmark. [sent-202, score-0.252]
</p><p>84 VGG-Affine We show comparative performance for local feature descriptor matching on the VGG-Affine benchmark [12]. [sent-208, score-0.219]
</p><p>85 We compare the performance of seed-of-life (SOL) and binary SOL descriptor (section 3. [sent-213, score-0.214]
</p><p>86 Both SOL and Binary SOL use the Euclidean  (and Hamming) distance, as we evaluate the effect of the nesting distance separately in section 4. [sent-217, score-0.661]
</p><p>87 Furthermore, the binary SOL and SOL descriptor perform equally, which shows that the binarization provides a more compact descriptor without sacrificing performance. [sent-227, score-0.442]
</p><p>88 VGG-Affine and Local Distance Functions Next, we performed a comparison of the nesting distance vs. [sent-230, score-0.661]
</p><p>89 This evaluation was proposed to demonstrate the relative benefit of the nesting distance over the Euclidean distance baseline. [sent-232, score-0.732]
</p><p>90 All distortion classes showed improved performance of the nesting distance over Euclidean. [sent-234, score-0.69]
</p><p>91 This result summarizes the known tradeoff between descriptor support and matching performance as was discussed in section 1. [sent-264, score-0.253]
</p><p>92 Automated Helicopter Landing In this section, we describe an application of the nested shape descriptors to the problem of visual landing of a ro-  tary wing platform. [sent-274, score-0.789]
</p><p>93 Seed-of-life descriptors are used to estimate the position and orientation of a candidate landing zone during approach and landing. [sent-275, score-0.276]
</p><p>94 Visual pose estimation for landing is the problem of estimating the 6-DOF position and orientation of a moving landing zone relative to a vehicle with suitable accuracy for safe landing. [sent-276, score-0.282]
</p><p>95 Application of the nested shape descriptors to visual landing zone pose estimation. [sent-280, score-0.858]
</p><p>96 We com-  pared the estimated landing zone position to differential GPS ground truth and results show that the nested shape descriptors achieve 2σ position errors in X, Y and Z of less than 1ft during the descent and landing. [sent-282, score-0.858]
</p><p>97 Conclusions In this paper, we introduced the nested shape descriptor family and the associated nesting distance, and showed performance of the seed-of-life descriptor for the task of image matching. [sent-284, score-1.601]
</p><p>98 Results show that this is the first binary descriptor to outperform SIFT on the standard VGG-Affine benchmark. [sent-285, score-0.233]
</p><p>99 Furthermore, the NSD binary descriptor significantly outperforms BRISK, a state-of-the-art binary descriptor. [sent-286, score-0.254]
</p><p>100 Evaluation of the nesting distance  on  VGG-Affine dataset. [sent-314, score-0.661]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nesting', 0.59), ('nested', 0.556), ('hawaiian', 0.281), ('descriptor', 0.174), ('nsd', 0.161), ('earrings', 0.125), ('earring', 0.112), ('spiral', 0.104), ('brisk', 0.104), ('supports', 0.099), ('landing', 0.09), ('pooling', 0.089), ('descriptors', 0.084), ('sol', 0.074), ('distance', 0.071), ('lobes', 0.069), ('zone', 0.069), ('shape', 0.059), ('logarithmic', 0.053), ('support', 0.05), ('trade', 0.05), ('family', 0.048), ('stereo', 0.046), ('checkmarks', 0.042), ('lobe', 0.042), ('navair', 0.042), ('nsds', 0.042), ('inliers', 0.042), ('daisy', 0.04), ('binary', 0.04), ('taxonomy', 0.039), ('sift', 0.039), ('member', 0.038), ('freak', 0.037), ('octave', 0.035), ('called', 0.033), ('orientation', 0.033), ('radius', 0.031), ('euclidean', 0.031), ('hamming', 0.03), ('distortion', 0.029), ('matching', 0.029), ('rotational', 0.029), ('exhibits', 0.028), ('ebyrne', 0.028), ('subband', 0.028), ('steerable', 0.028), ('binarization', 0.027), ('sacrificing', 0.027), ('constructed', 0.027), ('outliers', 0.027), ('eight', 0.025), ('bandpass', 0.025), ('approved', 0.025), ('chog', 0.025), ('helicopter', 0.025), ('bark', 0.025), ('subbands', 0.025), ('oriented', 0.025), ('analyzed', 0.024), ('kn', 0.024), ('scales', 0.023), ('diminishing', 0.023), ('study', 0.023), ('life', 0.022), ('occlusions', 0.022), ('flattening', 0.022), ('orb', 0.022), ('bands', 0.021), ('substructures', 0.021), ('normalization', 0.021), ('protocol', 0.021), ('scaled', 0.021), ('surf', 0.021), ('geometric', 0.02), ('mikolajczyk', 0.02), ('symmetry', 0.02), ('uth', 0.02), ('faster', 0.02), ('release', 0.02), ('center', 0.02), ('darpa', 0.019), ('statistics', 0.019), ('outperform', 0.019), ('equivalent', 0.019), ('gradients', 0.019), ('tuytelaars', 0.018), ('circles', 0.018), ('partition', 0.017), ('exactly', 0.017), ('april', 0.017), ('grid', 0.016), ('contract', 0.016), ('ofimage', 0.016), ('elegant', 0.016), ('middlebury', 0.016), ('local', 0.016), ('developments', 0.016), ('grey', 0.016), ('aperture', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="288-tfidf-1" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>Author: Jeffrey Byrne, Jianbo Shi</p><p>Abstract: In this paper, we propose a new family of binary local feature descriptors called nested shape descriptors. These descriptors are constructed by pooling oriented gradients over a large geometric structure called the Hawaiian earring, which is constructed with a nested correlation structure that enables a new robust local distance function called the nesting distance. This distance function is unique to the nested descriptor and provides robustness to outliers from order statistics. In this paper, we define the nested shape descriptor family and introduce a specific member called the seed-of-life descriptor. We perform a trade study to determine optimal descriptor parameters for the task of image matching. Finally, we evaluate performance compared to state-of-the-art local feature descriptors on the VGGAffine image matching benchmark, showing significant performance gains. Our descriptor is thefirst binary descriptor to outperform SIFT on this benchmark.</p><p>2 0.058985963 <a title="288-tfidf-2" href="./iccv-2013-Stable_Hyper-pooling_and_Query_Expansion_for_Event_Detection.html">400 iccv-2013-Stable Hyper-pooling and Query Expansion for Event Detection</a></p>
<p>Author: Matthijs Douze, Jérôme Revaud, Cordelia Schmid, Hervé Jégou</p><p>Abstract: This paper makes two complementary contributions to event retrieval in large collections of videos. First, we propose hyper-pooling strategies that encode the frame descriptors into a representation of the video sequence in a stable manner. Our best choices compare favorably with regular pooling techniques based on k-means quantization. Second, we introduce a technique to improve the ranking. It can be interpreted either as a query expansion method or as a similarity adaptation based on the local context of the query video descriptor. Experiments on public benchmarks show that our methods are complementary and improve event retrieval results, without sacrificing efficiency.</p><p>3 0.056296561 <a title="288-tfidf-3" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>Author: Zhenyu Guo, Z. Jane Wang</p><p>Abstract: Digital images nowadays show large appearance variabilities on picture styles, in terms of color tone, contrast, vignetting, and etc. These ‘picture styles’ are directly related to the scene radiance, image pipeline of the camera, and post processing functions (e.g., photography effect filters). Due to the complexity and nonlinearity of these factors, popular gradient-based image descriptors generally are not invariant to different picture styles, which could degrade the performance for object recognition. Given that images shared online or created by individual users are taken with a wide range of devices and may be processed by various post processing functions, to find a robust object recognition system is useful and challenging. In this paper, we investigate the influence of picture styles on object recognition by making a connection between image descriptors and a pixel mapping function g, and accordingly propose an adaptive approach based on a g-incorporated kernel descriptor and multiple kernel learning, without estimating or specifying the image styles used in training and testing. We conduct experiments on the Domain Adaptation data set, the Oxford Flower data set, and several variants of the Flower data set by introducing popular photography effects through post-processing. The results demonstrate that theproposedmethod consistently yields recognition improvements over standard descriptors in all studied cases.</p><p>4 0.055950116 <a title="288-tfidf-4" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<p>Author: Federico Tombari, Alessandro Franchi, Luigi Di_Stefano</p><p>Abstract: Object detection in images withstanding significant clutter and occlusion is still a challenging task whenever the object surface is characterized by poor informative content. We propose to tackle this problem by a compact and distinctive representation of groups of neighboring line segments aggregated over limited spatial supports and invariant to rotation, translation and scale changes. Peculiarly, our proposal allows for leveraging on the inherent strengths of descriptor-based approaches, i.e. robustness to occlusion and clutter and scalability with respect to the size of the model library, also when dealing with scarcely textured objects.</p><p>5 0.055447385 <a title="288-tfidf-5" href="./iccv-2013-Dynamic_Pooling_for_Complex_Event_Recognition.html">127 iccv-2013-Dynamic Pooling for Complex Event Recognition</a></p>
<p>Author: Weixin Li, Qian Yu, Ajay Divakaran, Nuno Vasconcelos</p><p>Abstract: The problem of adaptively selecting pooling regions for the classification of complex video events is considered. Complex events are defined as events composed of several characteristic behaviors, whose temporal configuration can change from sequence to sequence. A dynamic pooling operator is defined so as to enable a unified solution to the problems of event specific video segmentation, temporal structure modeling, and event detection. Video is decomposed into segments, and the segments most informative for detecting a given event are identified, so as to dynamically determine the pooling operator most suited for each sequence. This dynamic pooling is implemented by treating the locations of characteristic segments as hidden information, which is inferred, on a sequence-by-sequence basis, via a large-margin classification rule with latent variables. Although the feasible set of segment selections is combinatorial, it is shown that a globally optimal solution to the inference problem can be obtained efficiently, through the solution of a series of linear programs. Besides the coarselevel location of segments, a finer model of video struc- ture is implemented by jointly pooling features of segmenttuples. Experimental evaluation demonstrates that the re- sulting event detector has state-of-the-art performance on challenging video datasets.</p><p>6 0.055346273 <a title="288-tfidf-6" href="./iccv-2013-DeepFlow%3A_Large_Displacement_Optical_Flow_with_Deep_Matching.html">105 iccv-2013-DeepFlow: Large Displacement Optical Flow with Deep Matching</a></p>
<p>7 0.055309098 <a title="288-tfidf-7" href="./iccv-2013-Latent_Task_Adaptation_with_Large-Scale_Hierarchies.html">233 iccv-2013-Latent Task Adaptation with Large-Scale Hierarchies</a></p>
<p>8 0.055229124 <a title="288-tfidf-8" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>9 0.050655339 <a title="288-tfidf-9" href="./iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</a></p>
<p>10 0.048495378 <a title="288-tfidf-10" href="./iccv-2013-Action_Recognition_with_Improved_Trajectories.html">39 iccv-2013-Action Recognition with Improved Trajectories</a></p>
<p>11 0.04701487 <a title="288-tfidf-11" href="./iccv-2013-Space-Time_Robust_Representation_for_Action_Recognition.html">396 iccv-2013-Space-Time Robust Representation for Action Recognition</a></p>
<p>12 0.046199635 <a title="288-tfidf-12" href="./iccv-2013-SYM-FISH%3A_A_Symmetry-Aware_Flip_Invariant_Sketch_Histogram_Shape_Descriptor.html">368 iccv-2013-SYM-FISH: A Symmetry-Aware Flip Invariant Sketch Histogram Shape Descriptor</a></p>
<p>13 0.046129532 <a title="288-tfidf-13" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>14 0.041960772 <a title="288-tfidf-14" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>15 0.041187067 <a title="288-tfidf-15" href="./iccv-2013-Co-segmentation_by_Composition.html">74 iccv-2013-Co-segmentation by Composition</a></p>
<p>16 0.040447708 <a title="288-tfidf-16" href="./iccv-2013-Deformable_Part_Descriptors_for_Fine-Grained_Recognition_and_Attribute_Prediction.html">107 iccv-2013-Deformable Part Descriptors for Fine-Grained Recognition and Attribute Prediction</a></p>
<p>17 0.040224079 <a title="288-tfidf-17" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>18 0.038889408 <a title="288-tfidf-18" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>19 0.038626026 <a title="288-tfidf-19" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>20 0.038502317 <a title="288-tfidf-20" href="./iccv-2013-PM-Huber%3A_PatchMatch_with_Huber_Regularization_for_Stereo_Matching.html">304 iccv-2013-PM-Huber: PatchMatch with Huber Regularization for Stereo Matching</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.096), (1, -0.014), (2, -0.006), (3, -0.01), (4, 0.005), (5, 0.035), (6, 0.005), (7, -0.015), (8, -0.027), (9, -0.02), (10, 0.005), (11, 0.021), (12, 0.019), (13, -0.003), (14, 0.004), (15, -0.013), (16, 0.031), (17, 0.03), (18, 0.062), (19, 0.007), (20, 0.057), (21, -0.001), (22, -0.017), (23, -0.013), (24, 0.001), (25, 0.008), (26, 0.014), (27, 0.023), (28, -0.001), (29, 0.033), (30, 0.004), (31, -0.015), (32, -0.037), (33, 0.0), (34, -0.002), (35, 0.034), (36, 0.003), (37, -0.08), (38, 0.03), (39, 0.003), (40, -0.014), (41, 0.051), (42, -0.021), (43, 0.034), (44, -0.01), (45, 0.032), (46, 0.003), (47, -0.024), (48, -0.001), (49, -0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.908014 <a title="288-lsi-1" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>Author: Jeffrey Byrne, Jianbo Shi</p><p>Abstract: In this paper, we propose a new family of binary local feature descriptors called nested shape descriptors. These descriptors are constructed by pooling oriented gradients over a large geometric structure called the Hawaiian earring, which is constructed with a nested correlation structure that enables a new robust local distance function called the nesting distance. This distance function is unique to the nested descriptor and provides robustness to outliers from order statistics. In this paper, we define the nested shape descriptor family and introduce a specific member called the seed-of-life descriptor. We perform a trade study to determine optimal descriptor parameters for the task of image matching. Finally, we evaluate performance compared to state-of-the-art local feature descriptors on the VGGAffine image matching benchmark, showing significant performance gains. Our descriptor is thefirst binary descriptor to outperform SIFT on this benchmark.</p><p>2 0.65328121 <a title="288-lsi-2" href="./iccv-2013-SIFTpack%3A_A_Compact_Representation_for_Efficient_SIFT_Matching.html">365 iccv-2013-SIFTpack: A Compact Representation for Efficient SIFT Matching</a></p>
<p>Author: Alexandra Gilinsky, Lihi Zelnik Manor</p><p>Abstract: Computing distances between large sets of SIFT descriptors is a basic step in numerous algorithms in computer vision. When the number of descriptors is large, as is often the case, computing these distances can be extremely time consuming. In this paper we propose the SIFTpack: a compact way of storing SIFT descriptors, which enables significantly faster calculations between sets of SIFTs than the current solutions. SIFTpack can be used to represent SIFTs densely extracted from a single image or sparsely from multiple different images. We show that the SIFTpack representation saves both storage space and run time, for both finding nearest neighbors and for computing all distances between all descriptors. The usefulness of SIFTpack is also demonstrated as an alternative implementation for K-means dictionaries of visual words.</p><p>3 0.64990878 <a title="288-lsi-3" href="./iccv-2013-Codemaps_-_Segment%2C_Classify_and_Search_Objects_Locally.html">77 iccv-2013-Codemaps - Segment, Classify and Search Objects Locally</a></p>
<p>Author: Zhenyang Li, Efstratios Gavves, Koen E.A. van_de_Sande, Cees G.M. Snoek, Arnold W.M. Smeulders</p><p>Abstract: In this paper we aim for segmentation and classification of objects. We propose codemaps that are a joint formulation of the classification score and the local neighborhood it belongs to in the image. We obtain the codemap by reordering the encoding, pooling and classification steps over lattice elements. Other than existing linear decompositions who emphasize only the efficiency benefits for localized search, we make three novel contributions. As a preliminary, we provide a theoretical generalization of the sufficient mathematical conditions under which image encodings and classification becomes locally decomposable. As first novelty we introduce ℓ2 normalization for arbitrarily shaped image regions, which is fast enough for semantic segmentation using our Fisher codemaps. Second, using the same lattice across images, we propose kernel pooling which embeds nonlinearities into codemaps for object classification by explicit or approximate feature mappings. Results demonstrate that ℓ2 normalized Fisher codemaps improve the state-of-the-art in semantic segmentation for PAS- CAL VOC. For object classification the addition of nonlinearities brings us on par with the state-of-the-art, but is 3x faster. Because of the codemaps ’ inherent efficiency, we can reach significant speed-ups for localized search as well. We exploit the efficiency gain for our third novelty: object segment retrieval using a single query image only.</p><p>4 0.6396454 <a title="288-lsi-4" href="./iccv-2013-Shape_Index_Descriptors_Applied_to_Texture-Based_Galaxy_Analysis.html">388 iccv-2013-Shape Index Descriptors Applied to Texture-Based Galaxy Analysis</a></p>
<p>Author: Kim Steenstrup Pedersen, Kristoffer Stensbo-Smidt, Andrew Zirm, Christian Igel</p><p>Abstract: A texture descriptor based on the shape index and the accompanying curvedness measure is proposed, and it is evaluated for the automated analysis of astronomical image data. A representative sample of images of low-redshift galaxies from the Sloan Digital Sky Survey (SDSS) serves as a testbed. The goal of applying texture descriptors to these data is to extract novel information about galaxies; information which is often lost in more traditional analysis. In this study, we build a regression model for predicting a spectroscopic quantity, the specific star-formation rate (sSFR). As texture features we consider multi-scale gradient orientation histograms as well as multi-scale shape index histograms, which lead to a new descriptor. Our results show that we can successfully predict spectroscopic quantities from the texture in optical multi-band images. We successfully recover the observed bi-modal distribution of galaxies into quiescent and star-forming. The state-ofthe-art for predicting the sSFR is a color-based physical model. We significantly improve its accuracy by augmenting the model with texture information. This study is thefirst step towards enabling the quantification of physical galaxy properties from imaging data alone.</p><p>5 0.63803732 <a title="288-lsi-5" href="./iccv-2013-To_Aggregate_or_Not_to_aggregate%3A_Selective_Match_Kernels_for_Image_Search.html">419 iccv-2013-To Aggregate or Not to aggregate: Selective Match Kernels for Image Search</a></p>
<p>Author: Giorgos Tolias, Yannis Avrithis, Hervé Jégou</p><p>Abstract: This paper considers a family of metrics to compare images based on their local descriptors. It encompasses the VLAD descriptor and matching techniques such as Hamming Embedding. Making the bridge between these approaches leads us to propose a match kernel that takes the best of existing techniques by combining an aggregation procedure with a selective match kernel. Finally, the representation underpinning this kernel is approximated, providing a large scale image search both precise and scalable, as shown by our experiments on several benchmarks.</p><p>6 0.63125145 <a title="288-lsi-6" href="./iccv-2013-Neighbor-to-Neighbor_Search_for_Fast_Coding_of_Feature_Vectors.html">287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</a></p>
<p>7 0.59872317 <a title="288-lsi-7" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<p>8 0.58566493 <a title="288-lsi-8" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<p>9 0.58245724 <a title="288-lsi-9" href="./iccv-2013-EVSAC%3A_Accelerating_Hypotheses_Generation_by_Modeling_Matching_Scores_with_Extreme_Value_Theory.html">131 iccv-2013-EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores with Extreme Value Theory</a></p>
<p>10 0.58127815 <a title="288-lsi-10" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>11 0.57843179 <a title="288-lsi-11" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>12 0.5724526 <a title="288-lsi-12" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>13 0.57024503 <a title="288-lsi-13" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>14 0.56427985 <a title="288-lsi-14" href="./iccv-2013-Stable_Hyper-pooling_and_Query_Expansion_for_Event_Detection.html">400 iccv-2013-Stable Hyper-pooling and Query Expansion for Event Detection</a></p>
<p>15 0.56043291 <a title="288-lsi-15" href="./iccv-2013-Fine-Grained_Categorization_by_Alignments.html">169 iccv-2013-Fine-Grained Categorization by Alignments</a></p>
<p>16 0.55746448 <a title="288-lsi-16" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>17 0.54684293 <a title="288-lsi-17" href="./iccv-2013-Hierarchical_Part_Matching_for_Fine-Grained_Visual_Categorization.html">198 iccv-2013-Hierarchical Part Matching for Fine-Grained Visual Categorization</a></p>
<p>18 0.54660165 <a title="288-lsi-18" href="./iccv-2013-A_Fully_Hierarchical_Approach_for_Finding_Correspondences_in_Non-rigid_Shapes.html">11 iccv-2013-A Fully Hierarchical Approach for Finding Correspondences in Non-rigid Shapes</a></p>
<p>19 0.53651577 <a title="288-lsi-19" href="./iccv-2013-Decomposing_Bag_of_Words_Histograms.html">104 iccv-2013-Decomposing Bag of Words Histograms</a></p>
<p>20 0.53250319 <a title="288-lsi-20" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.074), (7, 0.03), (26, 0.05), (31, 0.029), (34, 0.011), (36, 0.233), (40, 0.012), (42, 0.068), (48, 0.015), (57, 0.041), (64, 0.04), (73, 0.051), (89, 0.175), (98, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82639813 <a title="288-lda-1" href="./iccv-2013-Shape_Index_Descriptors_Applied_to_Texture-Based_Galaxy_Analysis.html">388 iccv-2013-Shape Index Descriptors Applied to Texture-Based Galaxy Analysis</a></p>
<p>Author: Kim Steenstrup Pedersen, Kristoffer Stensbo-Smidt, Andrew Zirm, Christian Igel</p><p>Abstract: A texture descriptor based on the shape index and the accompanying curvedness measure is proposed, and it is evaluated for the automated analysis of astronomical image data. A representative sample of images of low-redshift galaxies from the Sloan Digital Sky Survey (SDSS) serves as a testbed. The goal of applying texture descriptors to these data is to extract novel information about galaxies; information which is often lost in more traditional analysis. In this study, we build a regression model for predicting a spectroscopic quantity, the specific star-formation rate (sSFR). As texture features we consider multi-scale gradient orientation histograms as well as multi-scale shape index histograms, which lead to a new descriptor. Our results show that we can successfully predict spectroscopic quantities from the texture in optical multi-band images. We successfully recover the observed bi-modal distribution of galaxies into quiescent and star-forming. The state-ofthe-art for predicting the sSFR is a color-based physical model. We significantly improve its accuracy by augmenting the model with texture information. This study is thefirst step towards enabling the quantification of physical galaxy properties from imaging data alone.</p><p>same-paper 2 0.79371899 <a title="288-lda-2" href="./iccv-2013-Nested_Shape_Descriptors.html">288 iccv-2013-Nested Shape Descriptors</a></p>
<p>Author: Jeffrey Byrne, Jianbo Shi</p><p>Abstract: In this paper, we propose a new family of binary local feature descriptors called nested shape descriptors. These descriptors are constructed by pooling oriented gradients over a large geometric structure called the Hawaiian earring, which is constructed with a nested correlation structure that enables a new robust local distance function called the nesting distance. This distance function is unique to the nested descriptor and provides robustness to outliers from order statistics. In this paper, we define the nested shape descriptor family and introduce a specific member called the seed-of-life descriptor. We perform a trade study to determine optimal descriptor parameters for the task of image matching. Finally, we evaluate performance compared to state-of-the-art local feature descriptors on the VGGAffine image matching benchmark, showing significant performance gains. Our descriptor is thefirst binary descriptor to outperform SIFT on this benchmark.</p><p>3 0.726717 <a title="288-lda-3" href="./iccv-2013-What_Do_You_Do%3F_Occupation_Recognition_in_a_Photo_via_Social_Context.html">449 iccv-2013-What Do You Do? Occupation Recognition in a Photo via Social Context</a></p>
<p>Author: Ming Shao, Liangyue Li, Yun Fu</p><p>Abstract: In this paper, we investigate the problem of recognizing occupations of multiple people with arbitrary poses in a photo. Previous work utilizing single person ’s nearly frontal clothing information and fore/background context preliminarily proves that occupation recognition is computationally feasible in computer vision. However, in practice, multiple people with arbitrary poses are common in a photo, and recognizing their occupations is even more challenging. We argue that with appropriately built visual attributes, co-occurrence, and spatial configuration model that is learned through structure SVM, we can recognize multiple people ’s occupations in a photo simultaneously. To evaluate our method’s performance, we conduct extensive experiments on a new well-labeled occupation database with 14 representative occupations and over 7K images. Results on this database validate our method’s effectiveness and show that occupation recognition is solvable in a more general case.</p><p>4 0.68115592 <a title="288-lda-4" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>Author: Marco San_Biagio, Marco Crocco, Marco Cristani, Samuele Martelli, Vittorio Murino</p><p>Abstract: Capturing the essential characteristics of visual objects by considering how their features are inter-related is a recent philosophy of object classification. In this paper, we embed this principle in a novel image descriptor, dubbed Heterogeneous Auto-Similarities of Characteristics (HASC). HASC is applied to heterogeneous dense features maps, encoding linear relations by covariances and nonlinear associations through information-theoretic measures such as mutual information and entropy. In this way, highly complex structural information can be expressed in a compact, scale invariant and robust manner. The effectiveness of HASC is tested on many diverse detection and classification scenarios, considering objects, textures and pedestrians, on widely known benchmarks (Caltech-101, Brodatz, Daimler Multi-Cue). In all the cases, the results obtained with standard classifiers demonstrate the superiority of HASC with respect to the most adopted local feature descriptors nowadays, such as SIFT, HOG, LBP and feature covariances. In addition, HASC sets the state-of-the-art on the Brodatz texture dataset and the Daimler Multi-Cue pedestrian dataset, without exploiting ad-hoc sophisticated classifiers.</p><p>5 0.67542541 <a title="288-lda-5" href="./iccv-2013-Robust_Non-parametric_Data_Fitting_for_Correspondence_Modeling.html">358 iccv-2013-Robust Non-parametric Data Fitting for Correspondence Modeling</a></p>
<p>Author: Wen-Yan Lin, Ming-Ming Cheng, Shuai Zheng, Jiangbo Lu, Nigel Crook</p><p>Abstract: We propose a generic method for obtaining nonparametric image warps from noisy point correspondences. Our formulation integrates a huber function into a motion coherence framework. This makes our fitting function especially robust to piecewise correspondence noise (where an image section is consistently mismatched). By utilizing over parameterized curves, we can generate realistic nonparametric image warps from very noisy correspondence. We also demonstrate how our algorithm can be used to help stitch images taken from a panning camera by warping the images onto a virtual push-broom camera imaging plane.</p><p>6 0.67321903 <a title="288-lda-6" href="./iccv-2013-Alternating_Regression_Forests_for_Object_Detection_and_Pose_Estimation.html">47 iccv-2013-Alternating Regression Forests for Object Detection and Pose Estimation</a></p>
<p>7 0.66682714 <a title="288-lda-7" href="./iccv-2013-Structured_Forests_for_Fast_Edge_Detection.html">404 iccv-2013-Structured Forests for Fast Edge Detection</a></p>
<p>8 0.66679084 <a title="288-lda-8" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>9 0.66663063 <a title="288-lda-9" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>10 0.6664362 <a title="288-lda-10" href="./iccv-2013-Learning_Graphs_to_Match.html">238 iccv-2013-Learning Graphs to Match</a></p>
<p>11 0.66561496 <a title="288-lda-11" href="./iccv-2013-Constructing_Adaptive_Complex_Cells_for_Robust_Visual_Tracking.html">89 iccv-2013-Constructing Adaptive Complex Cells for Robust Visual Tracking</a></p>
<p>12 0.6652956 <a title="288-lda-12" href="./iccv-2013-BOLD_Features_to_Detect_Texture-less_Objects.html">57 iccv-2013-BOLD Features to Detect Texture-less Objects</a></p>
<p>13 0.66468966 <a title="288-lda-13" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>14 0.66456652 <a title="288-lda-14" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>15 0.66394114 <a title="288-lda-15" href="./iccv-2013-Visual_Reranking_through_Weakly_Supervised_Multi-graph_Learning.html">445 iccv-2013-Visual Reranking through Weakly Supervised Multi-graph Learning</a></p>
<p>16 0.66378939 <a title="288-lda-16" href="./iccv-2013-Large-Scale_Video_Hashing_via_Structure_Learning.html">229 iccv-2013-Large-Scale Video Hashing via Structure Learning</a></p>
<p>17 0.66316891 <a title="288-lda-17" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>18 0.66295058 <a title="288-lda-18" href="./iccv-2013-Video_Co-segmentation_for_Meaningful_Action_Extraction.html">439 iccv-2013-Video Co-segmentation for Meaningful Action Extraction</a></p>
<p>19 0.66271079 <a title="288-lda-19" href="./iccv-2013-Online_Motion_Segmentation_Using_Dynamic_Label_Propagation.html">297 iccv-2013-Online Motion Segmentation Using Dynamic Label Propagation</a></p>
<p>20 0.66261154 <a title="288-lda-20" href="./iccv-2013-Semi-dense_Visual_Odometry_for_a_Monocular_Camera.html">382 iccv-2013-Semi-dense Visual Odometry for a Monocular Camera</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
