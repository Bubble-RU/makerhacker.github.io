<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>330 iccv-2013-Proportion Priors for Image Sequence Segmentation</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-330" href="#">iccv2013-330</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>330 iccv-2013-Proportion Priors for Image Sequence Segmentation</h1>
<br/><p>Source: <a title="iccv-2013-330-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Nieuwenhuis_Proportion_Priors_for_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>Reference: <a title="iccv-2013-330-reference" href="../iccv2013_reference/iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc. [sent-2, score-0.186]
</p><p>2 We propose different ways to impose such priors in a Bayesian framework for image segmentation. [sent-4, score-0.313]
</p><p>3 We show that near-optimal solutions can be computed using convex relaxation techniques. [sent-5, score-0.334]
</p><p>4 Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. [sent-6, score-0.664]
</p><p>5 They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e. [sent-7, score-0.11]
</p><p>6 The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second. [sent-10, score-0.297]
</p><p>7 Image Sequence Segmentation Automatic image sequence segmentation denotes the task of jointly segmenting one or several objects from a series of images taken under different view points, lighting conditions and background scenes. [sent-14, score-0.299]
</p><p>8 The difficulty lies in the fact that none of the objects’ properties is guaranteed to be preserved over time. [sent-15, score-0.089]
</p><p>9 Both the geometry and the photometry of the objects of interest may change from one image to the next. [sent-16, score-0.038]
</p><p>10 Changing illumination affects the observed color model, different viewpoints lead to different object scales and possibly self-occlusions, whole parts of the object can even vanish from the image, and objects may occlude each other in the case of multiple foreground objects. [sent-17, score-0.271]
</p><p>11 Moreover, articulations and non-rigid deformations give rise to substantial shape changes. [sent-18, score-0.211]
</p><p>12 Multi-label segmentation with length regularity  Multi-label segmentation with proportion priors Figure 1. [sent-20, score-0.705]
</p><p>13 Proportion priors allow to constrain the relative size between different object parts (e. [sent-21, score-0.397]
</p><p>14 They enable stable segmentations over long image sequences, preventing the seeping out of regions into the background (e. [sent-24, score-0.236]
</p><p>15 the green hair region) or the removal of semantically important small parts (e. [sent-26, score-0.146]
</p><p>16 and exploiting information which is shared among the images is a challenging task. [sent-29, score-0.037]
</p><p>17 In general, the co-segmentation problem deals with the situation that we have no knowledge on the object ofinterest besides that it appears in all images. [sent-30, score-0.095]
</p><p>18 To make the problem tractable many approaches introduced at least some kind of prior knowledge based on training data or user scribbles [1, 12, 7, 21]. [sent-31, score-0.112]
</p><p>19 The resulting optimization problems are often iterative and hard to optimize [12, 19, 11, 20] leading to runtimes of several seconds or even minutes. [sent-32, score-0.115]
</p><p>20 For complex real-world image sequences the task of leveraging  relevant shared information for co-segmentation remains an open challenge. [sent-33, score-0.037]
</p><p>21 In this paper, we propose a Bayesian framework for multi-region co-segmentation which allows to impose learned proportion priors — see Figure 1. [sent-34, score-0.574]
</p><p>22 We show that near-optimal solutions can be efficiently computed by means of convex relaxation techniques. [sent-35, score-0.334]
</p><p>23 Unfortunately, this limits the applicability to rigid objects observed from similar viewpoints. [sent-39, score-0.061]
</p><p>24 Upon strong viewpoint changes, articulations or non-rigid deformations, the arising segmentations are too different in their shape to be accounted for. [sent-40, score-0.198]
</p><p>25 —  —  Color similarity: On the other extreme are methods which make no assumptions on shape similarity, but which strongly rely on similarity of color or feature distributions [19, 11, 6, 1, 21, 5]. [sent-42, score-0.156]
</p><p>26 Recent approaches relax these assumptions, requiring less color similarity [7] and instead derive high level knowledge on object properties such as object subspaces [12] or region correspondences [20]. [sent-44, score-0.201]
</p><p>27 To increase the stability of segmentation results, it was suggested [8] to impose shape moment constraints into variational segmentation methods. [sent-46, score-0.391]
</p><p>28 Since these constraints are absolute, they are not invariant to changes in scale, viewpoint, occlusions or multiple object instances and are thus not applicable to the general co-segmentation problem. [sent-47, score-0.133]
</p><p>29 The central idea is to tackle the problem in a multilabel framework where an object, say an athlete, is made up of multiple components (the various limbs of the body). [sent-51, score-0.106]
</p><p>30 While the object may undergo substantial changes — rigid body motion, articulation, non-rigid deformation — what is typ-  ically preserved is the relative size of object parts (e. [sent-52, score-0.648]
</p><p>31 the head to the entire body), the object part proportions. [sent-54, score-0.12]
</p><p>32 We formulate image sequence segmentation as a problem of Bayesian inference and introduce proportion priors to restrict the relative size of object parts. [sent-55, score-0.801]
</p><p>33 This approach comes with the following advantages: • It can handle overlapping color distributions, moderately Ivtar ciaanb hlea lighting lcaopnpdinitgion cos,l vra driisoturisb object mscoadleesr taenldy multiple foreground objects. [sent-56, score-0.239]
</p><p>34 The proposed ratio constraints preserve small or elongated object parts. [sent-57, score-0.19]
</p><p>35 • It extends recent convex relaxation techniques [9, 2, 23] Ifrto emxt emnudlsti rleabceeln segmentation taot imonult teilcahbneilq sequence segmentation. [sent-58, score-0.579]
</p><p>36 We present an efficient optimization scheme which can be parallelized with runtimes of around one second to compute pixel-accurate segmentations. [sent-59, score-0.168]
</p><p>37 • The approach yields state-of-the-art results on the ICoseg bTehnec ahpmparorka cfohr y iseulbddsi svitsaitbe-loe object sequences. [sent-60, score-0.055]
</p><p>38 Multilabel Image Sequence Segmentation Let I Ω → R3 denote an input image of the sequence : defiLneetd I on tΩhe → →do Rmain Ω ⊆ R2. [sent-62, score-0.078]
</p><p>39 The task of segmentation is dtoe partition thhee d image? [sent-63, score-0.121]
</p><p>40 plane Rinto a set of n pairwise disjoint regions Ωi s. [sent-64, score-0.048]
</p><p>41 tpheu n regions ienagch l pixel belongs nto}: Ωi = {x ? [sent-75, score-0.048]
</p><p>42 can compute nsu tchhe a segmentation by maximizing the condi? [sent-79, score-0.161]
</p><p>43 l  (1)  lm  It combines the observation likelihood P(I | l) (typically favoring a ceosl tohre-b oabsesedr region aiksesloihcoiaotidon P)( Iw |itlh) prior kanlloyw fal-edge P(l) regarding what kinds of partitionings are more or leedsgse likely. [sent-82, score-0.15]
</p><p>44 In the case of image sequence segmentation, commonly used color and boundary length priors are often insufficient to obtain good results. [sent-83, score-0.332]
</p><p>45 Secondly, the color distributions of object and background may have substantial overlap and may exhibit strong variations across images. [sent-85, score-0.312]
</p><p>46 In order to stabilize the segmentation process against color and lighting variations, pose changes and substantial non-rigid deformations, and in order to leverage it to a parsing of objects into their semantic components, we propose to introduce proportion priors into the optimization problem. [sent-86, score-0.801]
</p><p>47 Framework for Proportion Preserving Priors In the following, we will introduce proportion priors as a means to impose information on the relative size of respective object parts. [sent-89, score-0.713]
</p><p>48 Whereas the absolute size of parts will vary with viewing angle and distance from the camera, their relative size is typically well preserved – i. [sent-90, score-0.27]
</p><p>49 the size of the head is typically 10% of the size of the entire body. [sent-92, score-0.147]
</p><p>50 Let us assume that the object we want to segment can be divided into n−1 sub-regions (e. [sent-93, score-0.055]
</p><p>51 head, feet, body and bhaen ddisv)i dwedith i ntthoe nn−-th1 region denoting t. [sent-95, score-0.12]
</p><p>52 Then in the Bayesian framework, the prior P(l) = iPm(aΩg1e , . [sent-97, score-0.072]
</p><p>53 constraint relates the size Ωi of the i-th region to the size ? [sent-110, score-0.121]
</p><p>54 tation we want to impose regions of short boundary length Per(Ωi), whose ratios additionally follow a learned (or specified) ratio probability distribution Pp  P(Ωi|Ωn) =C1exp? [sent-114, score-0.546]
</p><p>55 Finally, we assume each background Ωn to be equally likely a priori, so that P(Ωn) = const. [sent-117, score-0.059]
</p><p>56 uInalsltyea lidk of maximizing tPh(aItP| l)(PΩ(l) in (1) we minimize its negative logarithm manizdin ogb Ptai(nI |tlh)eP energy  E(Ω1 , . [sent-118, score-0.04]
</p><p>57 Contribution: Proportion Preserving Priors In this section we propose two different proportion preserving priors: the uniform distribution prior and the Laplace distribution prior. [sent-133, score-0.541]
</p><p>58 Both assume that the ratios of the object parts follow a specific distribution Pp(ri) whose parameters are se fsotlimloawte ad sfpreomcif sample bdauttaio, ni. [sent-134, score-0.401]
</p><p>59 sample segmentations from which ratio samples can be obtained. [sent-136, score-0.226]
</p><p>60 To convert the energy in (5) to a convex optimization problem in Section 2. [sent-137, score-0.252]
</p><p>61 3, the key challenge is to express the terms −log Pp(ri) in (5) as a convex function of the varitaebrlmess ai := P|Ωi |/|Ω|, which denote the fraction of the size of region =Ωi | Ωwi|/th| respect tho dtheneo image fsraizceti. [sent-138, score-0.617]
</p><p>62 Uniform Distribution Prior  (6)  As a first case, we assume a uniform distribution of the ratios ri over a specific interval [li , hi] . [sent-145, score-0.671]
</p><p>63 The left and right boundaries li and hi are computed from training data by means of maximum likelihood estimation, which assigns li and hi the minimum and maximum values of the sample ratios, respectively. [sent-146, score-0.226]
</p><p>64 ≤ hi,  (7)  Since −log Pp is either constant or infinity, this prior corresponds tloo 2g(nP −1) constraints in the optimization problem: li(1 − an) ≤ ai ≤ hi(1 − an)  ∀1 ≤ i  < n. [sent-149, score-0.389]
</p><p>65 (8)  These relative ratio constraints are linear and thus convex in terms of the ai. [sent-150, score-0.39]
</p><p>66 The advantage of this prior is the simple computation and the convexity of the constraints. [sent-151, score-0.072]
</p><p>67 Yet, in the case of large variations of the ratios ri in the sample data (i. [sent-152, score-0.579]
</p><p>68 2  Laplace Distribution Prior  The Laplace distribution prior penalizes deviations of the ratios ri from their median r¯i . [sent-158, score-0.705]
</p><p>69 In this way, the influence of ratio sample outliers on the constraints is limited. [sent-159, score-0.135]
</p><p>70 We  assume the following Laplace distribution  Pp(ri) =2σ1iexp? [sent-160, score-0.054]
</p><p>71 g the prior with respect to the other terms, we get the energy  of the  ? [sent-170, score-0.112]
</p><p>72 (10)  Unfortunately, after replacing ri by (6), this function is not convex in ai and an. [sent-172, score-0.834]
</p><p>73 For example, for ri < r¯i we obtain Ep(ri) = σμi ( r¯i −1−aain ), which is not convex in an for fixed ai. [sent-173, score-0.555]
</p><p>74 To make globa1l− oaptimization possible, in the following we propose two methods to convexify this prior. [sent-174, score-0.046]
</p><p>75 First, we consider the convex relaxation of Ep as a function Ep(ai , an), i. [sent-176, score-0.334]
</p><p>76 The definition domain of Ep is naturally given by ai , an ≥ 0 and ai + an 1, where the latter inequality follows fr≥om 0 ? [sent-179, score-0.607]
</p><p>77 ≤ ≤ W 1e, wobhtaeirne tthhee convex relaxation  ≤  E1 :=  σμi? [sent-181, score-0.334]
</p><p>78 22333300  In contrast to the Laplace prior (10) this approximation is convex. [sent-189, score-0.072]
</p><p>79 However, E1 is minimal not only for ai = r¯i (1 − an) but also for an = 1, ai = 0, i. [sent-190, score-0.558]
</p><p>80 Thus, this prior is biased towards smaller foreground object areas. [sent-193, score-0.18]
</p><p>81 This can be understood as an additional compactness prior which removes cluttered background regions, but sometimes also parts of the objects. [sent-194, score-0.187]
</p><p>82 As shown in the last paragraph, even the greatest convex lower bound E1 is too small. [sent-196, score-0.251]
</p><p>83 As a second convexification method we propose a convex upper bound on Ep. [sent-198, score-0.297]
</p><p>84 Note that Ep does not have a lowest upper bound, in contrast to the convex relaxation case. [sent-199, score-0.334]
</p><p>85 To arrive at one possible solution, the idea is to write Ep in (10) by replacing the ratios ri by the ai in (6)  Ep=σμi? [sent-200, score-0.858]
</p><p>86 ·√1 −1 an and apply Young’s inequality pq ≤ 41εp2 + εq2, valid for aanlld p, q ∈ly R Y oaunndg arbitrary ε >y p0q ( w≤e choose ε = 10 in the experiments). [sent-204, score-0.092]
</p><p>87 nIdt i asr equivalent >to 0 0( ( 2√1εp −oo√seεεq )2 = ≥ 1 00. [sent-205, score-0.038]
</p><p>88 (12)  This energy is convex: the first addend is a linear transformation of the convex function (x,y) → ∈ R,y > 0, and the second one is obviously convex in an ∈ [0, 1). [sent-209, score-0.503]
</p><p>89 ation ai ≈ r¯i (1 − an) regardless of the size of the object. [sent-211, score-0.32]
</p><p>90 It also avo≈ids¯ r large background regions as E2 → ∞ for an → 1, which can be alleviated by using a small→ ε. [sent-212, score-0.107]
</p><p>91 Since (12) is used for all 1 ≤ i < n, for optimization it willS i bnec eco (1n2v)e nisie unste tdo decouple th ie < ais f froorm o an using nth iet dual representation 1 = supβ≥ ? [sent-213, score-0.092]
</p><p>92 froer txh e= l 0ft a hnadnβ yd =siαd 0e, asn dde fains ezder aos f ∞or xx r=y y y∈ <= R 0 , 0? [sent-217, score-0.086]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ri', 0.343), ('ai', 0.279), ('proportion', 0.261), ('ratios', 0.236), ('convex', 0.212), ('ep', 0.208), ('laplace', 0.206), ('priors', 0.202), ('pp', 0.15), ('segmentations', 0.129), ('relaxation', 0.122), ('segmentation', 0.121), ('runtimes', 0.115), ('hi', 0.113), ('impose', 0.111), ('multilabel', 0.106), ('ratio', 0.097), ('preserved', 0.089), ('substantial', 0.084), ('body', 0.081), ('sequence', 0.078), ('munich', 0.073), ('prior', 0.072), ('jn', 0.071), ('articulations', 0.069), ('feet', 0.067), ('head', 0.065), ('preserving', 0.062), ('distributions', 0.062), ('bayesian', 0.061), ('rigid', 0.061), ('background', 0.059), ('deformations', 0.058), ('parts', 0.056), ('object', 0.055), ('articulation', 0.055), ('distribution', 0.054), ('foreground', 0.053), ('parallelized', 0.053), ('color', 0.052), ('hands', 0.051), ('hair', 0.05), ('inequality', 0.049), ('germany', 0.049), ('regions', 0.048), ('convexification', 0.046), ('dtheneo', 0.046), ('convexify', 0.046), ('rinto', 0.046), ('froorm', 0.046), ('tshizaet', 0.046), ('bnec', 0.046), ('taot', 0.046), ('aain', 0.046), ('froer', 0.046), ('nieuwenhuis', 0.046), ('winhge', 0.046), ('ao', 0.044), ('relative', 0.043), ('ipm', 0.043), ('strekalovskiy', 0.043), ('aanlld', 0.043), ('convexvision', 0.043), ('ically', 0.043), ('puting', 0.043), ('condi', 0.043), ('assumptions', 0.042), ('lighting', 0.041), ('size', 0.041), ('secondly', 0.04), ('energy', 0.04), ('changes', 0.04), ('german', 0.04), ('wills', 0.04), ('ifi', 0.04), ('ene', 0.04), ('aos', 0.04), ('nsu', 0.04), ('organs', 0.04), ('logpp', 0.04), ('ofinterest', 0.04), ('evgeny', 0.04), ('tph', 0.04), ('icsi', 0.04), ('scribbles', 0.04), ('semantically', 0.04), ('bound', 0.039), ('region', 0.039), ('regarding', 0.039), ('transformation', 0.039), ('uniform', 0.038), ('reconsider', 0.038), ('photometry', 0.038), ('atnhed', 0.038), ('thhies', 0.038), ('vra', 0.038), ('asr', 0.038), ('firstly', 0.038), ('constraints', 0.038), ('shared', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999994 <a title="330-tfidf-1" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>2 0.11828555 <a title="330-tfidf-2" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>Author: Taegyu Lim, Seunghoon Hong, Bohyung Han, Joon Hee Han</p><p>Abstract: We propose an on-line algorithm to extract a human by foreground/background segmentation and estimate pose of the human from the videos captured by moving cameras. We claim that a virtuous cycle can be created by appropriate interactions between the two modules to solve individual problems. This joint estimation problem is divided into two subproblems, , foreground/background segmentation and pose tracking, which alternate iteratively for optimization; segmentation step generates foreground mask for human pose tracking, and human pose tracking step provides foreground response map for segmentation. The final solution is obtained when the iterative procedure converges. We evaluate our algorithm quantitatively and qualitatively in real videos involving various challenges, and present its outstandingperformance compared to the state-of-the-art techniques for segmentation and pose estimation.</p><p>3 0.10151596 <a title="330-tfidf-3" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>Author: Wei Xia, Csaba Domokos, Jian Dong, Loong-Fah Cheong, Shuicheng Yan</p><p>Abstract: Numerous existing object segmentation frameworks commonly utilize the object bounding box as a prior. In this paper, we address semantic segmentation assuming that object bounding boxes are provided by object detectors, but no training data with annotated segments are available. Based on a set of segment hypotheses, we introduce a simple voting scheme to estimate shape guidance for each bounding box. The derived shape guidance is used in the subsequent graph-cut-based figure-ground segmentation. The final segmentation result is obtained by merging the segmentation results in the bounding boxes. We conduct an extensive analysis of the effect of object bounding box accuracy. Comprehensive experiments on both the challenging PASCAL VOC object segmentation dataset and GrabCut50 image segmentation dataset show that the proposed approach achieves competitive results compared to previous detection or bounding box prior based methods, as well as other state-of-the-art semantic segmentation methods.</p><p>4 0.098710962 <a title="330-tfidf-4" href="./iccv-2013-Deterministic_Fitting_of_Multiple_Structures_Using_Iterative_MaxFS_with_Inlier_Scale_Estimation.html">113 iccv-2013-Deterministic Fitting of Multiple Structures Using Iterative MaxFS with Inlier Scale Estimation</a></p>
<p>Author: Kwang Hee Lee, Sang Wook Lee</p><p>Abstract: unkown-abstract</p><p>5 0.098654851 <a title="330-tfidf-5" href="./iccv-2013-Strong_Appearance_and_Expressive_Spatial_Models_for_Human_Pose_Estimation.html">403 iccv-2013-Strong Appearance and Expressive Spatial Models for Human Pose Estimation</a></p>
<p>Author: Leonid Pishchulin, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele</p><p>Abstract: Typical approaches to articulated pose estimation combine spatial modelling of the human body with appearance modelling of body parts. This paper aims to push the state-of-the-art in articulated pose estimation in two ways. First we explore various types of appearance representations aiming to substantially improve the bodypart hypotheses. And second, we draw on and combine several recently proposed powerful ideas such as more flexible spatial models as well as image-conditioned spatial models. In a series of experiments we draw several important conclusions: (1) we show that the proposed appearance representations are complementary; (2) we demonstrate that even a basic tree-structure spatial human body model achieves state-ofthe-art performance when augmented with the proper appearance representation; and (3) we show that the combination of the best performing appearance model with a flexible image-conditioned spatial model achieves the best result, significantly improving over the state of the art, on the “Leeds Sports Poses ” and “Parse ” benchmarks.</p><p>6 0.094656996 <a title="330-tfidf-6" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>7 0.094160184 <a title="330-tfidf-7" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>8 0.089969002 <a title="330-tfidf-8" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>9 0.084667623 <a title="330-tfidf-9" href="./iccv-2013-Total_Variation_Regularization_for_Functions_with_Values_in_a_Manifold.html">421 iccv-2013-Total Variation Regularization for Functions with Values in a Manifold</a></p>
<p>10 0.082818314 <a title="330-tfidf-10" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>11 0.082588792 <a title="330-tfidf-11" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>12 0.082105443 <a title="330-tfidf-12" href="./iccv-2013-Co-segmentation_by_Composition.html">74 iccv-2013-Co-segmentation by Composition</a></p>
<p>13 0.08153826 <a title="330-tfidf-13" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>14 0.080566309 <a title="330-tfidf-14" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>15 0.08030647 <a title="330-tfidf-15" href="./iccv-2013-CoDeL%3A_A_Human_Co-detection_and_Labeling_Framework.html">75 iccv-2013-CoDeL: A Human Co-detection and Labeling Framework</a></p>
<p>16 0.080290608 <a title="330-tfidf-16" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>17 0.078773081 <a title="330-tfidf-17" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>18 0.077826783 <a title="330-tfidf-18" href="./iccv-2013-Bayesian_3D_Tracking_from_Monocular_Video.html">58 iccv-2013-Bayesian 3D Tracking from Monocular Video</a></p>
<p>19 0.075713575 <a title="330-tfidf-19" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<p>20 0.075420365 <a title="330-tfidf-20" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.2), (1, -0.04), (2, 0.01), (3, 0.005), (4, 0.034), (5, 0.001), (6, -0.052), (7, 0.064), (8, 0.028), (9, -0.056), (10, 0.007), (11, 0.038), (12, -0.023), (13, -0.039), (14, -0.025), (15, 0.061), (16, 0.008), (17, -0.003), (18, -0.032), (19, -0.045), (20, 0.082), (21, -0.017), (22, 0.0), (23, -0.062), (24, 0.004), (25, 0.026), (26, 0.069), (27, -0.021), (28, 0.043), (29, -0.006), (30, 0.004), (31, 0.006), (32, 0.044), (33, 0.037), (34, 0.015), (35, 0.009), (36, -0.041), (37, 0.106), (38, 0.03), (39, -0.026), (40, 0.075), (41, 0.118), (42, 0.054), (43, 0.019), (44, 0.018), (45, 0.026), (46, 0.015), (47, -0.041), (48, -0.028), (49, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96135604 <a title="330-lsi-1" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>2 0.76934403 <a title="330-lsi-2" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>Author: Masoud S. Nosrati, Shawn Andrews, Ghassan Hamarneh</p><p>Abstract: The inclusion of shape and appearance priors have proven useful for obtaining more accurate and plausible segmentations, especially for complex objects with multiple parts. In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . ca (a)Standar laΩb ehlingΩfuhnctionseting(Ωb)hΩOuirseΩtijng Figure 1: The inside vs. outside ambiguity in (a) is resolved by our containment constraint in (b). constraints using a single labeling function while maintaining global optimality. We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors.</p><p>3 0.73540545 <a title="330-lsi-3" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>Author: Fan Wang, Qixing Huang, Leonidas J. Guibas</p><p>Abstract: Joint segmentation of image sets has great importance for object recognition, image classification, and image retrieval. In this paper, we aim to jointly segment a set of images starting from a small number of labeled images or none at all. To allow the images to share segmentation information with each other, we build a network that contains segmented as well as unsegmented images, and extract functional maps between connected image pairs based on image appearance features. These functional maps act as general property transporters between the images and, in particular, are used to transfer segmentations. We define and operate in a reduced functional space optimized so that the functional maps approximately satisfy cycle-consistency under composition in the network. A joint optimization framework is proposed to simultaneously generate all segmentation functions over the images so that they both align with local segmentation cues in each particular image, and agree with each other under network transportation. This formulation allows us to extract segmentations even with no training data, but can also exploit such data when available. The collective effect of the joint processing using functional maps leads to accurate information sharing among images and yields superior segmentation results, as shown on the iCoseg, MSRC, and PASCAL data sets.</p><p>4 0.72219986 <a title="330-lsi-4" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>Author: Meng Tang, Lena Gorelick, Olga Veksler, Yuri Boykov</p><p>Abstract: Among image segmentation algorithms there are two major groups: (a) methods assuming known appearance models and (b) methods estimating appearance models jointly with segmentation. Typically, the first group optimizes appearance log-likelihoods in combination with some spacial regularization. This problem is relatively simple and many methods guarantee globally optimal results. The second group treats model parameters as additional variables transforming simple segmentation energies into highorder NP-hard functionals (Zhu-Yuille, Chan-Vese, GrabCut, etc). It is known that such methods indirectly minimize the appearance overlap between the segments. We propose a new energy term explicitly measuring L1 distance between the object and background appearance models that can be globally maximized in one graph cut. We show that in many applications our simple term makes NP-hard segmentation functionals unnecessary. Our one cut algorithm effectively replaces approximate iterative optimization techniques based on block coordinate descent.</p><p>5 0.68926895 <a title="330-lsi-5" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>6 0.66285241 <a title="330-lsi-6" href="./iccv-2013-A_Deformable_Mixture_Parsing_Model_with_Parselets.html">8 iccv-2013-A Deformable Mixture Parsing Model with Parselets</a></p>
<p>7 0.64516175 <a title="330-lsi-7" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>8 0.64131564 <a title="330-lsi-8" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>9 0.64090413 <a title="330-lsi-9" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>10 0.63822758 <a title="330-lsi-10" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>11 0.63633108 <a title="330-lsi-11" href="./iccv-2013-Co-segmentation_by_Composition.html">74 iccv-2013-Co-segmentation by Composition</a></p>
<p>12 0.63237387 <a title="330-lsi-12" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>13 0.61387479 <a title="330-lsi-13" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>14 0.61183447 <a title="330-lsi-14" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>15 0.60750008 <a title="330-lsi-15" href="./iccv-2013-A_Method_of_Perceptual-Based_Shape_Decomposition.html">21 iccv-2013-A Method of Perceptual-Based Shape Decomposition</a></p>
<p>16 0.60107493 <a title="330-lsi-16" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>17 0.5986495 <a title="330-lsi-17" href="./iccv-2013-Progressive_Multigrid_Eigensolvers_for_Multiscale_Spectral_Segmentation.html">329 iccv-2013-Progressive Multigrid Eigensolvers for Multiscale Spectral Segmentation</a></p>
<p>18 0.59488791 <a title="330-lsi-18" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>19 0.59334177 <a title="330-lsi-19" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<p>20 0.58778065 <a title="330-lsi-20" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.048), (7, 0.043), (26, 0.114), (31, 0.042), (40, 0.018), (42, 0.165), (48, 0.015), (64, 0.059), (73, 0.061), (87, 0.119), (89, 0.204), (98, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94169503 <a title="330-lda-1" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>2 0.93365914 <a title="330-lda-2" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>Author: Carl Olsson, Johannes Ulén, Yuri Boykov, Vladimir Kolmogorov</p><p>Abstract: Energies with high-order non-submodular interactions have been shown to be very useful in vision due to their high modeling power. Optimization of such energies, however, is generally NP-hard. A naive approach that works for small problem instances is exhaustive search, that is, enumeration of all possible labelings of the underlying graph. We propose a general minimization approach for large graphs based on enumeration of labelings of certain small patches. This partial enumeration technique reduces complex highorder energy formulations to pairwise Constraint Satisfaction Problems with unary costs (uCSP), which can be efficiently solved using standard methods like TRW-S. Our approach outperforms a number of existing state-of-the-art algorithms on well known difficult problems (e.g. curvature regularization, stereo, deconvolution); it gives near global minimum and better speed. Our main application of interest is curvature regularization. In the context of segmentation, our partial enumeration technique allows to evaluate curvature directly on small patches using a novel integral geometry approach. 1</p><p>3 0.91425622 <a title="330-lda-3" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>Author: Hongteng Xu, Hongyuan Zha</p><p>Abstract: Data sparsity has been a thorny issuefor manifold-based image synthesis, and in this paper we address this critical problem by leveraging ideas from transfer learning. Specifically, we propose methods based on generating auxiliary data in the form of synthetic samples using transformations of the original sparse samples. To incorporate the auxiliary data, we propose a weighted data synthesis method, which adaptively selects from the generated samples for inclusion during the manifold learning process via a weighted iterative algorithm. To demonstrate the feasibility of the proposed method, we apply it to the problem of face image synthesis from sparse samples. Compared with existing methods, the proposed method shows encouraging results with good performance improvements.</p><p>4 0.91054648 <a title="330-lda-4" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>Author: Jimei Yang, Yi-Hsuan Tsai, Ming-Hsuan Yang</p><p>Abstract: We present a hybrid parametric and nonparametric algorithm, exemplar cut, for generating class-specific object segmentation hypotheses. For the parametric part, we train a pylon model on a hierarchical region tree as the energy function for segmentation. For the nonparametric part, we match the input image with each exemplar by using regions to obtain a score which augments the energy function from the pylon model. Our method thus generates a set of highly plausible segmentation hypotheses by solving a series of exemplar augmented graph cuts. Experimental results on the Graz and PASCAL datasets show that the proposed algorithm achievesfavorable segmentationperformance against the state-of-the-art methods in terms of visual quality and accuracy.</p><p>5 0.90932202 <a title="330-lda-5" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>Author: Chenglong Bao, Jian-Feng Cai, Hui Ji</p><p>Abstract: In recent years, how to learn a dictionary from input images for sparse modelling has been one very active topic in image processing and recognition. Most existing dictionary learning methods consider an over-complete dictionary, e.g. the K-SVD method. Often they require solving some minimization problem that is very challenging in terms of computational feasibility and efficiency. However, if the correlations among dictionary atoms are not well constrained, the redundancy of the dictionary does not necessarily improve the performance of sparse coding. This paper proposed a fast orthogonal dictionary learning method for sparse image representation. With comparable performance on several image restoration tasks, the proposed method is much more computationally efficient than the over-complete dictionary based learning methods.</p><p>6 0.90824533 <a title="330-lda-6" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>7 0.90344179 <a title="330-lda-7" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>8 0.90244204 <a title="330-lda-8" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>9 0.90123457 <a title="330-lda-9" href="./iccv-2013-Distributed_Low-Rank_Subspace_Segmentation.html">122 iccv-2013-Distributed Low-Rank Subspace Segmentation</a></p>
<p>10 0.90083873 <a title="330-lda-10" href="./iccv-2013-Probabilistic_Elastic_Part_Model_for_Unsupervised_Face_Detector_Adaptation.html">328 iccv-2013-Probabilistic Elastic Part Model for Unsupervised Face Detector Adaptation</a></p>
<p>11 0.9007864 <a title="330-lda-11" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>12 0.90072399 <a title="330-lda-12" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>13 0.90042675 <a title="330-lda-13" href="./iccv-2013-Joint_Noise_Level_Estimation_from_Personal_Photo_Collections.html">223 iccv-2013-Joint Noise Level Estimation from Personal Photo Collections</a></p>
<p>14 0.9004072 <a title="330-lda-14" href="./iccv-2013-Regionlets_for_Generic_Object_Detection.html">349 iccv-2013-Regionlets for Generic Object Detection</a></p>
<p>15 0.90003252 <a title="330-lda-15" href="./iccv-2013-Fast_Face_Detector_Training_Using_Tailored_Views.html">157 iccv-2013-Fast Face Detector Training Using Tailored Views</a></p>
<p>16 0.89985687 <a title="330-lda-16" href="./iccv-2013-Adapting_Classification_Cascades_to_New_Domains.html">44 iccv-2013-Adapting Classification Cascades to New Domains</a></p>
<p>17 0.89947391 <a title="330-lda-17" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>18 0.8993932 <a title="330-lda-18" href="./iccv-2013-Sieving_Regression_Forest_Votes_for_Facial_Feature_Detection_in_the_Wild.html">391 iccv-2013-Sieving Regression Forest Votes for Facial Feature Detection in the Wild</a></p>
<p>19 0.89937377 <a title="330-lda-19" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>20 0.89837903 <a title="330-lda-20" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
