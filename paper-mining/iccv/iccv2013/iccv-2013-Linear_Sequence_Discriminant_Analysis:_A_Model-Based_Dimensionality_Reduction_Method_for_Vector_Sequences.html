<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-253" href="#">iccv2013-253</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</h1>
<br/><p>Source: <a title="iccv-2013-253-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Su_Linear_Sequence_Discriminant_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Bing Su, Xiaoqing Ding</p><p>Abstract: Dimensionality reduction for vectors in sequences is challenging since labels are attached to sequences as a whole. This paper presents a model-based dimensionality reduction method for vector sequences, namely linear sequence discriminant analysis (LSDA), which attempts to find a subspace in which sequences of the same class are projected together while those of different classes are projected as far as possible. For each sequence class, an HMM is built from states of which statistics are extracted. Means of these states are linked in order to form a mean sequence, and the variance of the sequence class is defined as the sum of all variances of component states. LSDA then learns a transformation by maximizing the separability between sequence classes and at the same time minimizing the within-sequence class scatter. DTW distance between mean sequences is used to measure the separability between sequence classes. We show that the optimization problem can be approximately transformed into an eigen decomposition problem. LDA can be seen as a special case of LSDA by considering non-sequential vectors as sequences of length one. The effectiveness of the proposed LSDA is demonstrated on two individual sequence datasets from UCI machine learning repository as well as two concatenate sequence datasets: APTI Arabic printed text database and IFN/ENIT Arabic handwriting database.</p><p>Reference: <a title="iccv-2013-253-reference" href="../iccv2013_reference/iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn  Abstract Dimensionality reduction for vectors in sequences is challenging since labels are attached to sequences as a whole. [sent-5, score-0.507]
</p><p>2 For each sequence class, an HMM is built from states of which statistics are extracted. [sent-7, score-0.313]
</p><p>3 Means of these states are linked in order to form a mean sequence, and the variance of the sequence class is defined as the sum of all variances of component states. [sent-8, score-0.492]
</p><p>4 LSDA then learns a transformation by maximizing the separability between sequence classes and at the same time minimizing the within-sequence class scatter. [sent-9, score-0.373]
</p><p>5 DTW distance between mean sequences is used to measure the separability between sequence classes. [sent-10, score-0.441]
</p><p>6 LDA can be seen as a special case of LSDA by  considering non-sequential vectors as sequences of length one. [sent-12, score-0.271]
</p><p>7 The effectiveness of the proposed LSDA is demonstrated on two individual sequence datasets from UCI machine learning repository as well as two concatenate sequence datasets: APTI Arabic printed text database and IFN/ENIT Arabic handwriting database. [sent-13, score-0.756]
</p><p>8 Introduction The targets of interest are represented with vector sequences in many computer vision and pattern recognition applications, including speech signal processing [10], online and offline handwriting recognition [3, 16], video analysis and synthesis of human motion [30]. [sent-15, score-0.449]
</p><p>9 Depending on how sequences are associated with class labels, vector sequences can be categorized into two main types: individual vector sequences and concatenate vector sequences. [sent-17, score-0.861]
</p><p>10 Each individual vector sequence corresponds to only one pattern and can be treated as individual objects, the goal of classification is to predict a single class label for it. [sent-18, score-0.365]
</p><p>11 Each concatenate vector sequence is a concatenation of several individual vector sequences and no natural notions of segments are available. [sent-19, score-0.53]
</p><p>12 For both types of sequences, reducing the dimensionality of the vectors in sequences is necessary to discard irrelevant  information and obtain more robust estimation of parameters from the computational perspective. [sent-21, score-0.307]
</p><p>13 The goal of dimensionality reduction (DR) for vector sequences in this paper is to map the high-dimensional vectors in sequences to a space of fewer dimensions such that discriminative information is preserved, resulting in sequences of lower dimensional vectors. [sent-22, score-0.777]
</p><p>14 Although unsupervised DR techniques such as PCA can be performed by treating all vectors equally without considering if they come from the same sequence or not, supervised methods can often achieve better performances. [sent-24, score-0.241]
</p><p>15 Various discriminant analysis techniques have been proposed [13, 11, 3 1], but they can not be directly applied to vector sequences for two reasons. [sent-25, score-0.269]
</p><p>16 First, it is hard to define the statistics such as mean and variance of classes since the samples are sequences, and second, the supervised information is difficult to utilize. [sent-26, score-0.185]
</p><p>17 Vectors in a sequence can neither be considered as individual samples with the same class label because they are not independent and may vary greatly, nor can they be concatenated to form a long vector since the lengths of different sequences can be different. [sent-27, score-0.537]
</p><p>18 In this paper, we propose a model-based DR method for both types of vector sequences, namely linear sequence discriminant analysis (LSDA). [sent-28, score-0.239]
</p><p>19 An HMM is built for 888899  each sequence class, mean and variance are extracted from each state of the HMM. [sent-30, score-0.325]
</p><p>20 These means are linked in order to form a sequence, which can be considered as the mean sequence of the class. [sent-31, score-0.209]
</p><p>21 Since the whole vector sequences are attached with class labels, it is hoped that sequences can be maximally separated into different classes after transformation of vectors. [sent-32, score-0.583]
</p><p>22 Some statistics of vector sequences can be obtained by a category of approaches which employ dynamic system models. [sent-37, score-0.277]
</p><p>23 In these approaches [8, 26, 19], a vector sequence is considered as a series of observations generated by an underlying dynamic system, and the parameters or properties of the model can be used as some measures of statistics of the sequence class. [sent-38, score-0.434]
</p><p>24 Although statistics of sequences classes are well explored, the label information is not suitable utilized, for states within the same HMM are not independent and a true label is associated with the whole state sequence instead of a state. [sent-41, score-0.593]
</p><p>25 Although these methods also perform DR for vectors in sequences, they can only be applied to multi-modal sequences for alignment and can not be extended to multi-sequence classes for classification. [sent-44, score-0.319]
</p><p>26 In [21], a sequence kernel DR approach combining spatial, temporal and periodic information is proposed for time series data, where labels are associated with the vectors in long time series. [sent-46, score-0.241]
</p><p>27 The task there is to predict a class label for each frame, which is different from that of this paper to detect what patterns occur and the order of appearance in concatenate vector sequences. [sent-47, score-0.19]
</p><p>28 For vector sequences with unequal length, dynamic time warping [20] is the most widely used distance measure. [sent-51, score-0.293]
</p><p>29 휋푥 = [휋푥1, 휋2푥, ⋅ ⋅ ⋅ , 휋푇푥]푇 ∈ {1 : 푁푥}푇×1 and 휋푦 = [휋푦1, 휋2푦, ⋅ ⋅ ⋅ , 휋푇푦]푇∈ ,{⋅1⋅ : ,푁휋푦}푇×∈1 d {e1no :t 푁e th}e aligned indexes betwe,e⋅n⋅ ⋅v ,ec휋tors ∈in { sequence X and Y, respectively. [sent-59, score-0.192]
</p><p>30 Linear sequence discriminant analysis This section presents the proposed LSDA, which considers the general 퐶-class classification problem. [sent-63, score-0.215]
</p><p>31 HMM-based Statistics of sequence classes For individual sequences, each sequence class has a set of sequence samples for training. [sent-68, score-0.679]
</p><p>32 is the number of vectors in the 푛-th sequence sample of class 푖˜. [sent-72, score-0.301]
</p><p>33 We build a left-to-right HMM with self-loops for each sequence class. [sent-75, score-0.162]
</p><p>34 This topology can represent the evolution of sequences and is consistent with the constraints of DTW, which only allows translate to the vector itself or to the next vector for both sequences in one step. [sent-76, score-0.472]
</p><p>35 We use = to denote the HMM associated  u푖푛˜(푝)  푃푛푖˜  S푖˜ [s˜[푖1],s[푖˜2],⋅⋅⋅s[푖˜퐿푖˜]] with class푖˜, where 퐿푖˜is the number of states in S푖˜, and s[푖˜푙] is the 푙-th state of S푖˜. [sent-77, score-0.175]
</p><p>36 Hereinafter the index of a state in the sequence model will always appears in square brackets. [sent-79, score-0.236]
</p><p>37 1, the sequence sample of class 푖˜ is generated by the corresponding HMM with each  U푖푛˜ S푖˜,  889900  Figure 1. [sent-81, score-0.247]
</p><p>38 We put vectors in all sequence samples of  class푖˜ aligned to state s[푖˜푙] of S푖˜into a collection set V푖˜[푙] = {u˜푖푛(푝)∣U푖푛˜ ∈ 푖˜, u푖푛˜(푝) ∈ s푖˜[푙]}, thus each state is represented  winit h i as s se t . [sent-84, score-0.421]
</p><p>39 The mean vectors {m˜[푖푙], 푙 = 1, ⋅⋅⋅ ,퐿˜푖} corresponding to states {s˜[푖푙], 푙 = 1, 퐿푖˜} of the same class model S푖˜ are linked in order to form a sequence m푖˜ = [m˜[푖1] ,m[푖˜2],⋅⋅⋅ ,m˜[푖퐿푖˜]], which can be seen as themeanor template of class 푖˜. [sent-89, score-0.554]
</p><p>40 However, to train an HMM for each class, no pre-segmentation of concatenate sequence into individual sequences is needed. [sent-91, score-0.482]
</p><p>41 The strategy is to build an HMM for each sequence class, and the concatenate level model is obtained by concatenating the component HMMs. [sent-92, score-0.243]
</p><p>42 The alignment between vectors and states of HMMs is obtained as a by-product of this process. [sent-94, score-0.194]
</p><p>43 The following extraction of mean sequences and variances are the same as in the case of individual sequences. [sent-95, score-0.315]
</p><p>44 Objective function and optimization DR for vector sequences aims at finding a linear transformation W ∈ , by which the dimension 푑 of original vector ∈ ℝ푑 is reduced to 푑′:  y푖푛˜(푝)  =  ℝd×d′ u푖푛˜(푝) W푇u푖푛˜(푝) ∈ ℝ푑′. [sent-98, score-0.291]
</p><p>45 so  original sequences  {U˜푖푛∣U푖푛˜  [u푖˜푛(1),u푖푛˜(2),⋅⋅⋅u푖푛˜(푃푛푖˜)] ∈ ℝ푑×푃˜푛푖,푛 = 1, 푁푖˜,푖˜ = 1˜, 퐶˜} are transformed into {Y˜푛푖∣Y푛푖˜ = [y푖˜푛(1),y푛푖˜(2), ⋅⋅⋅y푖푛˜(푃푘푖˜)]∈ ℝ푑′×푃푖˜푛,푛 = 1, ⋅⋅⋅ ,푁˜푖,푖˜ = 1˜, 퐶˜}. [sent-99, score-0.213]
</p><p>46 ⋅⋅⋅ ,  =  ⋅⋅⋅ ,  ⋅⋅⋅ ,  ⋅W⋅⋅e , hope that sequences of the same class are projected together while those of different classes are projected as far as possible. [sent-100, score-0.311]
</p><p>47 In this vein, LSDA determines a linear transformation by maximizing the Fisher criterion such that the separability between sequence classes is maximized at the same time the within-sequence class scatter is minimized. [sent-101, score-0.44]
</p><p>48 The sum of pairwise DTW distances between mean sequences of classes can be considered as a measure of separability between sequence classes. [sent-102, score-0.456]
</p><p>49 We define the transformed mean sequence of class 푖˜ as: =  W푇m푖˜  [W푇m푖[˜1] , W푇m[푖˜2],  W푇m[푖˜퐿푖˜]]. [sent-103, score-0.292]
</p><p>50 B푠(Π) depends on the set of all possible alignment indication matrixes of all sequence pairs. [sent-134, score-0.247]
</p><p>51 B푠 (Π∗) can be considered as the between sequence scatter matrix. [sent-137, score-0.229]
</p><p>52 Relationship with LDA LDA can be seen as a special case of LSDA by considering non-sequential vectors as sequences of only one vector. [sent-143, score-0.246]
</p><p>53 The mean sequence and variance are essentially the mean vector and variance of that class. [sent-145, score-0.324]
</p><p>54 For any two classes, there is only one possible aligned path between two mean sequences both contain one vector, so the between-sequence scatter is actually the between-class scatter defined in LDA. [sent-146, score-0.38]
</p><p>55 When an HMM with only one state is trained for each  class whose samples are sequences, LSDA degenerates into the method that views all vectors in a sequence as individual samples with the same class label. [sent-151, score-0.588]
</p><p>56 For example, the covariance of each state can be attached to the corresponding component of the related mean sequence, and the Euclidean distance can be replaced with the Chernoff distance according to [13] when calculating the DTW distance to tackle heteroscedastic data. [sent-153, score-0.216]
</p><p>57 Each sequence class can also be divided into subclasses following the idea of [31] to adapt to various data distributions. [sent-154, score-0.266]
</p><p>58 We further note that the mean sequence and variance can be extracted by other generative models, such as cluster generative statistical dynamic time warping [2]. [sent-160, score-0.289]
</p><p>59 We can see that only those state pairs that can reflect the difference between two sequence models are used to calculate the matrix B푠 (Π∗ ). [sent-162, score-0.236]
</p><p>60 For instance, two classifiers, HMM and DTW, are used as classifiers for individual sequences in section 4. [sent-168, score-0.259]
</p><p>61 DTW only need to be implemented once for each sequence class pair with respect to LSDA, the computation cost increases linearly with the number of states for each HMM. [sent-171, score-0.348]
</p><p>62 Experiments on individual sequences In this section we evaluate the effectiveness of LSDA on individual sequences. [sent-175, score-0.286]
</p><p>63 Experiments are carried out on two individual sequence datasets from the UCI Machine Learning Repository [17]. [sent-176, score-0.228]
</p><p>64 The Spoken Arabic Digits dataset consists of 8800 vector sequences from ten classes. [sent-178, score-0.235]
</p><p>65 The vectors in sequences contain 13 mel-frequency cepstrum coefficients. [sent-179, score-0.246]
</p><p>66 The length of sequences varies from 4 to 93 frames. [sent-181, score-0.217]
</p><p>67 The High-quality recordings of Australian sign language signs (HAS) dataset [12] contains 2565 vector sequences of Auslan (Australian Sian Language) signs captured from a native signer using high-  quality position trackers. [sent-182, score-0.328]
</p><p>68 The length of sample sequences varies with an average length of approximately 57 frames, and 22 attributes were extracted from each frame. [sent-184, score-0.242]
</p><p>69 For the Spoken Arabic Digits dataset, the data has already been divided into a training set of 6600 samples with 660 samples per class and a test set of 2200 samples with 220 samples per class. [sent-186, score-0.212]
</p><p>70 For both datasets, we compared the proposed LSDA to two baselines: unsupervised PCA and supervised LDA by considering each state as individual classes as introduced in section 2 (denoted as state-LDA). [sent-190, score-0.18]
</p><p>71 A new test sequence is matched to templates of all classes, and the class of the template with the highest similarity is determined as the label of the sequence. [sent-193, score-0.267]
</p><p>72 For HMM, an HMM is built for each sequence class. [sent-194, score-0.182]
</p><p>73 The likelihood of a new sequence is estimated by each HMM, and the class related to the HMM with the highest score is assigned as the label. [sent-195, score-0.247]
</p><p>74 A primary HMM with 4 states and a mixture of 5 Gaussian densities for each state was built to obtain statistics. [sent-203, score-0.225]
</p><p>75 Each character model had a right to left topology with self-loops and one state skipping transitions permitted, which was shared by HMMs for both alignment and classification. [sent-228, score-0.266]
</p><p>76 Then the HMM-  based training and lexicon-free recognition were performed with 4 states for each character model and a mixture of 3 Gaussians per state. [sent-233, score-0.236]
</p><p>77 Two performance measures were calculated: the word recognition rate and the character accuracy rate. [sent-237, score-0.238]
</p><p>78 The character accuracy rate is calculated as follows: the total number of labels in reference transcriptions minus the substitution errors, deletion errors and insertion errors, and then divided by the total number of character labels. [sent-239, score-0.277]
</p><p>79 (a) Word recognition rate and (b) character accuracy rate on APTI database with font ”Arabic Transparent”,  ”24”. [sent-279, score-0.261]
</p><p>80 Preliminary HMMs for obtaining statistics and final HMMs for lexicon-driven recognition shared the same topology with various numbers of states and 5 Gaussian densities per state. [sent-283, score-0.223]
</p><p>81 The total 178 character models were grouped into 98 models, and the number of states after adaptation was set to 0. [sent-286, score-0.244]
</p><p>82 3 shows the word recognition rate on test set d and test set e by using set abc ofthe IFN/ENIT database as training sets. [sent-289, score-0.16]
</p><p>83 Comparison of several advanced Arabic handwriting recognition systems on the IFN/ENIT dataset. [sent-301, score-0.187]
</p><p>84 The final HMMs were trained with various numbers of states and 5 Gaussian densities per state to perform recognition on the commonly used partitions abc-de and abcd-e of the IFN/ENIT dataset. [sent-305, score-0.227]
</p><p>85 The word recognition rates of our method together with two Arabic handwriting systems are shown in table 2. [sent-306, score-0.258]
</p><p>86 These systems for comparison include RWTH-OCR and UPV  PRHLT - the winner of ICDAR 2011 and ICFHR 2010 Arabic handwriting competition [15, 14], respectively. [sent-307, score-0.165]
</p><p>87 Conclusions In this paper we have presented a model-based dimensionality reduction method for vector sequences, LSDA, 889955  which projects vectors in sequences into a subspace such that sequences as a whole can be maximally separated into different classes. [sent-316, score-0.562]
</p><p>88 LSDA can discover differences and improve discrimination in the latent space between sequence classes. [sent-317, score-0.162]
</p><p>89 LDA can be considered as a special case of LSDA, while LSDA can be seen as LDA performed in a  pseudo-model space where points represent sequences by using DTW distance instead of Euclidean distance. [sent-318, score-0.211]
</p><p>90 We have demonstrated the effectiveness of LSDA in classifying both individual sequence data and concatenate sequence data. [sent-319, score-0.452]
</p><p>91 Guide to OCR for Arabic scripts, chapter Arabic handwriting recognition using bernoulli HMMs. [sent-328, score-0.214]
</p><p>92 The writer independent online handwriting recognition system frog on hand and cluster generative statistical dynamic time warping. [sent-333, score-0.249]
</p><p>93 Ocr-driven writer identification and adaptation in an hmm handwriting recognition system. [sent-344, score-0.49]
</p><p>94 Guide to OCRforArabic scripts, chapter RWTH OCR: A large vocabulary optical character recognition system for Arabic scripts. [sent-356, score-0.162]
</p><p>95 Linear dimensionality reduction via a heteroscedastic extension of lda: the chernoff criterion. [sent-395, score-0.162]
</p><p>96 Combining slanted-frame classifiers for improved hmmbased arabic handwriting recognition. [sent-413, score-0.652]
</p><p>97 A model-based sequence similarity with application to handwritten word spotting. [sent-439, score-0.274]
</p><p>98 Impact of character models choice on arabic text recognition performance. [sent-458, score-0.623]
</p><p>99 A new arabic printed text image database and evaluation protocols. [sent-467, score-0.569]
</p><p>100 A novel baselineindependent feature set for arabic handwriting recognition. [sent-474, score-0.632]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lsda', 0.589), ('arabic', 0.467), ('hmm', 0.242), ('dtw', 0.224), ('sequences', 0.192), ('handwriting', 0.165), ('sequence', 0.162), ('apti', 0.138), ('character', 0.113), ('hmms', 0.111), ('states', 0.101), ('lda', 0.096), ('mwax', 0.085), ('class', 0.085), ('concatenate', 0.081), ('state', 0.074), ('word', 0.071), ('scatter', 0.067), ('icdar', 0.065), ('dr', 0.061), ('icfhr', 0.061), ('dimensionality', 0.061), ('vectors', 0.054), ('discriminant', 0.053), ('variances', 0.052), ('argner', 0.052), ('spoken', 0.051), ('individual', 0.047), ('matrixes', 0.046), ('printed', 0.046), ('variance', 0.045), ('separability', 0.044), ('handwritten', 0.041), ('topology', 0.04), ('digits', 0.04), ('reduction', 0.039), ('alignment', 0.039), ('repository', 0.037), ('database', 0.035), ('alimi', 0.035), ('dmiension', 0.035), ('ingold', 0.035), ('kanoun', 0.035), ('slimane', 0.035), ('uci', 0.034), ('classes', 0.034), ('signs', 0.032), ('rate', 0.032), ('dynamic', 0.031), ('hamsici', 0.031), ('writer', 0.031), ('chernoff', 0.031), ('competitions', 0.031), ('heteroscedastic', 0.031), ('attached', 0.03), ('adaptation', 0.03), ('aligned', 0.03), ('statistics', 0.03), ('densities', 0.03), ('htk', 0.028), ('samples', 0.027), ('warping', 0.027), ('chapter', 0.027), ('degenerates', 0.027), ('native', 0.027), ('font', 0.027), ('transformation', 0.026), ('series', 0.025), ('reduced', 0.025), ('length', 0.025), ('supervised', 0.025), ('pami', 0.025), ('univariate', 0.024), ('vector', 0.024), ('mean', 0.024), ('pca', 0.024), ('speech', 0.024), ('linked', 0.023), ('scripts', 0.023), ('lexicon', 0.023), ('ocr', 0.023), ('dimensions', 0.023), ('maximizing', 0.022), ('recognition', 0.022), ('language', 0.021), ('text', 0.021), ('transformed', 0.021), ('urtasun', 0.021), ('transparent', 0.021), ('template', 0.02), ('splits', 0.02), ('built', 0.02), ('dim', 0.02), ('classifiers', 0.02), ('diagram', 0.02), ('rescaled', 0.019), ('divided', 0.019), ('carried', 0.019), ('ten', 0.019), ('distance', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="253-tfidf-1" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>Author: Bing Su, Xiaoqing Ding</p><p>Abstract: Dimensionality reduction for vectors in sequences is challenging since labels are attached to sequences as a whole. This paper presents a model-based dimensionality reduction method for vector sequences, namely linear sequence discriminant analysis (LSDA), which attempts to find a subspace in which sequences of the same class are projected together while those of different classes are projected as far as possible. For each sequence class, an HMM is built from states of which statistics are extracted. Means of these states are linked in order to form a mean sequence, and the variance of the sequence class is defined as the sum of all variances of component states. LSDA then learns a transformation by maximizing the separability between sequence classes and at the same time minimizing the within-sequence class scatter. DTW distance between mean sequences is used to measure the separability between sequence classes. We show that the optimization problem can be approximately transformed into an eigen decomposition problem. LDA can be seen as a special case of LSDA by considering non-sequential vectors as sequences of length one. The effectiveness of the proposed LSDA is demonstrated on two individual sequence datasets from UCI machine learning repository as well as two concatenate sequence datasets: APTI Arabic printed text database and IFN/ENIT Arabic handwriting database.</p><p>2 0.11749323 <a title="253-tfidf-2" href="./iccv-2013-Handwritten_Word_Spotting_with_Corrected_Attributes.html">192 iccv-2013-Handwritten Word Spotting with Corrected Attributes</a></p>
<p>Author: Jon Almazán, Albert Gordo, Alicia Fornés, Ernest Valveny</p><p>Abstract: We propose an approach to multi-writer word spotting, where the goal is to find a query word in a dataset comprised of document images. We propose an attributes-based approach that leads to a low-dimensional, fixed-length representation of the word images that is fast to compute and, especially, fast to compare. This approach naturally leads to an unified representation of word images and strings, which seamlessly allows one to indistinctly perform queryby-example, where the query is an image, and query-bystring, where the query is a string. We also propose a calibration scheme to correct the attributes scores based on Canonical Correlation Analysis that greatly improves the results on a challenging dataset. We test our approach on two public datasets showing state-of-the-art results.</p><p>3 0.11337462 <a title="253-tfidf-3" href="./iccv-2013-PhotoOCR%3A_Reading_Text_in_Uncontrolled_Conditions.html">315 iccv-2013-PhotoOCR: Reading Text in Uncontrolled Conditions</a></p>
<p>Author: Alessandro Bissacco, Mark Cummins, Yuval Netzer, Hartmut Neven</p><p>Abstract: We describe PhotoOCR, a system for text extraction from images. Our particular focus is reliable text extraction from smartphone imagery, with the goal of text recognition as a user input modality similar to speech recognition. Commercially available OCR performs poorly on this task. Recent progress in machine learning has substantially improved isolated character classification; we build on this progress by demonstrating a complete OCR system using these techniques. We also incorporate modern datacenter-scale distributed language modelling. Our approach is capable of recognizing text in a variety of challenging imaging conditions where traditional OCR systems fail, notably in the presence of substantial blur, low resolution, low contrast, high image noise and other distortions. It also operates with low latency; mean processing time is 600 ms per image. We evaluate our system on public benchmark datasets for text extraction and outperform all previously reported results, more than halving the error rate on multiple benchmarks. The system is currently in use in many applications at Google, and is available as a user input modality in Google Translate for Android.</p><p>4 0.1111109 <a title="253-tfidf-4" href="./iccv-2013-Semantically-Based_Human_Scanpath_Estimation_with_HMMs.html">381 iccv-2013-Semantically-Based Human Scanpath Estimation with HMMs</a></p>
<p>Author: Huiying Liu, Dong Xu, Qingming Huang, Wen Li, Min Xu, Stephen Lin</p><p>Abstract: We present a method for estimating human scanpaths, which are sequences of gaze shifts that follow visual attention over an image. In this work, scanpaths are modeled based on three principal factors that influence human attention, namely low-levelfeature saliency, spatialposition, and semantic content. Low-level feature saliency is formulated as transition probabilities between different image regions based on feature differences. The effect of spatial position on gaze shifts is modeled as a Levy flight with the shifts following a 2D Cauchy distribution. To account for semantic content, we propose to use a Hidden Markov Model (HMM) with a Bag-of-Visual-Words descriptor of image regions. An HMM is well-suited for this purpose in that 1) the hidden states, obtained by unsupervised learning, can represent latent semantic concepts, 2) the prior distribution of the hidden states describes visual attraction to the semantic concepts, and 3) the transition probabilities represent human gaze shift patterns. The proposed method is applied to task-driven viewing processes. Experiments and analysis performed on human eye gaze data verify the effectiveness of this method.</p><p>5 0.10846071 <a title="253-tfidf-5" href="./iccv-2013-Recognizing_Text_with_Perspective_Distortion_in_Natural_Scenes.html">345 iccv-2013-Recognizing Text with Perspective Distortion in Natural Scenes</a></p>
<p>Author: Trung Quy Phan, Palaiahnakote Shivakumara, Shangxuan Tian, Chew Lim Tan</p><p>Abstract: This paper presents an approach to text recognition in natural scene images. Unlike most existing works which assume that texts are horizontal and frontal parallel to the image plane, our method is able to recognize perspective texts of arbitrary orientations. For individual character recognition, we adopt a bag-of-keypoints approach, in which Scale Invariant Feature Transform (SIFT) descriptors are extracted densely and quantized using a pre-trained vocabulary. Following [1, 2], the context information is utilized through lexicons. We formulate word recognition as finding the optimal alignment between the set of characters and the list of lexicon words. Furthermore, we introduce a new dataset called StreetViewText-Perspective, which contains texts in street images with a great variety of viewpoints. Experimental results on public datasets and the proposed dataset show that our method significantly outperforms the state-of-the-art on perspective texts of arbitrary orientations.</p><p>6 0.10151362 <a title="253-tfidf-6" href="./iccv-2013-Image_Retrieval_Using_Textual_Cues.html">210 iccv-2013-Image Retrieval Using Textual Cues</a></p>
<p>7 0.091454163 <a title="253-tfidf-7" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>8 0.083137259 <a title="253-tfidf-8" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<p>9 0.082930729 <a title="253-tfidf-9" href="./iccv-2013-Fingerspelling_Recognition_with_Semi-Markov_Conditional_Random_Fields.html">170 iccv-2013-Fingerspelling Recognition with Semi-Markov Conditional Random Fields</a></p>
<p>10 0.069802538 <a title="253-tfidf-10" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<p>11 0.066827439 <a title="253-tfidf-11" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>12 0.063351162 <a title="253-tfidf-12" href="./iccv-2013-Dynamic_Structured_Model_Selection.html">130 iccv-2013-Dynamic Structured Model Selection</a></p>
<p>13 0.062919229 <a title="253-tfidf-13" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>14 0.062683605 <a title="253-tfidf-14" href="./iccv-2013-Learning_Maximum_Margin_Temporal_Warping_for_Action_Recognition.html">240 iccv-2013-Learning Maximum Margin Temporal Warping for Action Recognition</a></p>
<p>15 0.05623227 <a title="253-tfidf-15" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<p>16 0.051166322 <a title="253-tfidf-16" href="./iccv-2013-Latent_Space_Sparse_Subspace_Clustering.html">232 iccv-2013-Latent Space Sparse Subspace Clustering</a></p>
<p>17 0.051045135 <a title="253-tfidf-17" href="./iccv-2013-Training_Deformable_Part_Models_with_Decorrelated_Features.html">426 iccv-2013-Training Deformable Part Models with Decorrelated Features</a></p>
<p>18 0.049267914 <a title="253-tfidf-18" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>19 0.047278102 <a title="253-tfidf-19" href="./iccv-2013-ACTIVE%3A_Activity_Concept_Transitions_in_Video_Event_Classification.html">4 iccv-2013-ACTIVE: Activity Concept Transitions in Video Event Classification</a></p>
<p>20 0.044149581 <a title="253-tfidf-20" href="./iccv-2013-Robust_Trajectory_Clustering_for_Motion_Segmentation.html">361 iccv-2013-Robust Trajectory Clustering for Motion Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.118), (1, 0.043), (2, -0.004), (3, -0.008), (4, 0.003), (5, 0.034), (6, 0.02), (7, 0.01), (8, -0.001), (9, 0.003), (10, 0.107), (11, -0.079), (12, 0.043), (13, 0.039), (14, 0.016), (15, 0.027), (16, -0.049), (17, 0.048), (18, -0.059), (19, 0.023), (20, 0.04), (21, 0.034), (22, -0.002), (23, -0.034), (24, -0.023), (25, -0.021), (26, -0.007), (27, 0.04), (28, 0.046), (29, 0.063), (30, 0.037), (31, 0.007), (32, -0.018), (33, 0.017), (34, -0.007), (35, -0.013), (36, -0.064), (37, -0.047), (38, 0.088), (39, -0.033), (40, 0.016), (41, 0.04), (42, -0.021), (43, 0.064), (44, -0.02), (45, -0.041), (46, 0.021), (47, 0.048), (48, -0.008), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89578515 <a title="253-lsi-1" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>Author: Bing Su, Xiaoqing Ding</p><p>Abstract: Dimensionality reduction for vectors in sequences is challenging since labels are attached to sequences as a whole. This paper presents a model-based dimensionality reduction method for vector sequences, namely linear sequence discriminant analysis (LSDA), which attempts to find a subspace in which sequences of the same class are projected together while those of different classes are projected as far as possible. For each sequence class, an HMM is built from states of which statistics are extracted. Means of these states are linked in order to form a mean sequence, and the variance of the sequence class is defined as the sum of all variances of component states. LSDA then learns a transformation by maximizing the separability between sequence classes and at the same time minimizing the within-sequence class scatter. DTW distance between mean sequences is used to measure the separability between sequence classes. We show that the optimization problem can be approximately transformed into an eigen decomposition problem. LDA can be seen as a special case of LSDA by considering non-sequential vectors as sequences of length one. The effectiveness of the proposed LSDA is demonstrated on two individual sequence datasets from UCI machine learning repository as well as two concatenate sequence datasets: APTI Arabic printed text database and IFN/ENIT Arabic handwriting database.</p><p>2 0.73760903 <a title="253-lsi-2" href="./iccv-2013-Recognizing_Text_with_Perspective_Distortion_in_Natural_Scenes.html">345 iccv-2013-Recognizing Text with Perspective Distortion in Natural Scenes</a></p>
<p>Author: Trung Quy Phan, Palaiahnakote Shivakumara, Shangxuan Tian, Chew Lim Tan</p><p>Abstract: This paper presents an approach to text recognition in natural scene images. Unlike most existing works which assume that texts are horizontal and frontal parallel to the image plane, our method is able to recognize perspective texts of arbitrary orientations. For individual character recognition, we adopt a bag-of-keypoints approach, in which Scale Invariant Feature Transform (SIFT) descriptors are extracted densely and quantized using a pre-trained vocabulary. Following [1, 2], the context information is utilized through lexicons. We formulate word recognition as finding the optimal alignment between the set of characters and the list of lexicon words. Furthermore, we introduce a new dataset called StreetViewText-Perspective, which contains texts in street images with a great variety of viewpoints. Experimental results on public datasets and the proposed dataset show that our method significantly outperforms the state-of-the-art on perspective texts of arbitrary orientations.</p><p>3 0.69286817 <a title="253-lsi-3" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>Author: Lukáš Neumann, Jiri Matas</p><p>Abstract: An unconstrained end-to-end text localization and recognition method is presented. The method introduces a novel approach for character detection and recognition which combines the advantages of sliding-window and connected component methods. Characters are detected and recognized as image regions which contain strokes of specific orientations in a specific relative position, where the strokes are efficiently detected by convolving the image gradient field with a set of oriented bar filters. Additionally, a novel character representation efficiently calculated from the values obtained in the stroke detection phase is introduced. The representation is robust to shift at the stroke level, which makes it less sensitive to intra-class variations and the noise induced by normalizing character size and positioning. The effectiveness of the representation is demonstrated by the results achieved in the classification of real-world characters using an euclidian nearestneighbor classifier trained on synthetic data in a plain form. The method was evaluated on a standard dataset, where it achieves state-of-the-art results in both text localization and recognition.</p><p>4 0.68492508 <a title="253-lsi-4" href="./iccv-2013-PhotoOCR%3A_Reading_Text_in_Uncontrolled_Conditions.html">315 iccv-2013-PhotoOCR: Reading Text in Uncontrolled Conditions</a></p>
<p>Author: Alessandro Bissacco, Mark Cummins, Yuval Netzer, Hartmut Neven</p><p>Abstract: We describe PhotoOCR, a system for text extraction from images. Our particular focus is reliable text extraction from smartphone imagery, with the goal of text recognition as a user input modality similar to speech recognition. Commercially available OCR performs poorly on this task. Recent progress in machine learning has substantially improved isolated character classification; we build on this progress by demonstrating a complete OCR system using these techniques. We also incorporate modern datacenter-scale distributed language modelling. Our approach is capable of recognizing text in a variety of challenging imaging conditions where traditional OCR systems fail, notably in the presence of substantial blur, low resolution, low contrast, high image noise and other distortions. It also operates with low latency; mean processing time is 600 ms per image. We evaluate our system on public benchmark datasets for text extraction and outperform all previously reported results, more than halving the error rate on multiple benchmarks. The system is currently in use in many applications at Google, and is available as a user input modality in Google Translate for Android.</p><p>5 0.65826887 <a title="253-lsi-5" href="./iccv-2013-Handwritten_Word_Spotting_with_Corrected_Attributes.html">192 iccv-2013-Handwritten Word Spotting with Corrected Attributes</a></p>
<p>Author: Jon Almazán, Albert Gordo, Alicia Fornés, Ernest Valveny</p><p>Abstract: We propose an approach to multi-writer word spotting, where the goal is to find a query word in a dataset comprised of document images. We propose an attributes-based approach that leads to a low-dimensional, fixed-length representation of the word images that is fast to compute and, especially, fast to compare. This approach naturally leads to an unified representation of word images and strings, which seamlessly allows one to indistinctly perform queryby-example, where the query is an image, and query-bystring, where the query is a string. We also propose a calibration scheme to correct the attributes scores based on Canonical Correlation Analysis that greatly improves the results on a challenging dataset. We test our approach on two public datasets showing state-of-the-art results.</p><p>6 0.6489861 <a title="253-lsi-6" href="./iccv-2013-Text_Localization_in_Natural_Images_Using_Stroke_Feature_Transform_and_Text_Covariance_Descriptors.html">415 iccv-2013-Text Localization in Natural Images Using Stroke Feature Transform and Text Covariance Descriptors</a></p>
<p>7 0.60174179 <a title="253-lsi-7" href="./iccv-2013-Image_Retrieval_Using_Textual_Cues.html">210 iccv-2013-Image Retrieval Using Textual Cues</a></p>
<p>8 0.59094799 <a title="253-lsi-8" href="./iccv-2013-Fingerspelling_Recognition_with_Semi-Markov_Conditional_Random_Fields.html">170 iccv-2013-Fingerspelling Recognition with Semi-Markov Conditional Random Fields</a></p>
<p>9 0.54565668 <a title="253-lsi-9" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>10 0.51083702 <a title="253-lsi-10" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<p>11 0.48791158 <a title="253-lsi-11" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<p>12 0.44543588 <a title="253-lsi-12" href="./iccv-2013-Heterogeneous_Auto-similarities_of_Characteristics_%28HASC%29%3A_Exploiting_Relational_Information_for_Classification.html">193 iccv-2013-Heterogeneous Auto-similarities of Characteristics (HASC): Exploiting Relational Information for Classification</a></p>
<p>13 0.44273645 <a title="253-lsi-13" href="./iccv-2013-Learning_Coupled_Feature_Spaces_for_Cross-Modal_Matching.html">235 iccv-2013-Learning Coupled Feature Spaces for Cross-Modal Matching</a></p>
<p>14 0.44047996 <a title="253-lsi-14" href="./iccv-2013-Fast_High_Dimensional_Vector_Multiplication_Face_Recognition.html">158 iccv-2013-Fast High Dimensional Vector Multiplication Face Recognition</a></p>
<p>15 0.43718594 <a title="253-lsi-15" href="./iccv-2013-Stacked_Predictive_Sparse_Coding_for_Classification_of_Distinct_Regions_in_Tumor_Histopathology.html">401 iccv-2013-Stacked Predictive Sparse Coding for Classification of Distinct Regions in Tumor Histopathology</a></p>
<p>16 0.43639123 <a title="253-lsi-16" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<p>17 0.43592021 <a title="253-lsi-17" href="./iccv-2013-Low-Rank_Sparse_Coding_for_Image_Classification.html">258 iccv-2013-Low-Rank Sparse Coding for Image Classification</a></p>
<p>18 0.42253923 <a title="253-lsi-18" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>19 0.41791493 <a title="253-lsi-19" href="./iccv-2013-Learning_Slow_Features_for_Behaviour_Analysis.html">243 iccv-2013-Learning Slow Features for Behaviour Analysis</a></p>
<p>20 0.41648698 <a title="253-lsi-20" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.059), (4, 0.01), (7, 0.044), (12, 0.017), (26, 0.066), (27, 0.016), (31, 0.058), (34, 0.024), (42, 0.075), (63, 0.221), (64, 0.079), (72, 0.012), (73, 0.042), (84, 0.027), (89, 0.107), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73673701 <a title="253-lda-1" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>Author: Bing Su, Xiaoqing Ding</p><p>Abstract: Dimensionality reduction for vectors in sequences is challenging since labels are attached to sequences as a whole. This paper presents a model-based dimensionality reduction method for vector sequences, namely linear sequence discriminant analysis (LSDA), which attempts to find a subspace in which sequences of the same class are projected together while those of different classes are projected as far as possible. For each sequence class, an HMM is built from states of which statistics are extracted. Means of these states are linked in order to form a mean sequence, and the variance of the sequence class is defined as the sum of all variances of component states. LSDA then learns a transformation by maximizing the separability between sequence classes and at the same time minimizing the within-sequence class scatter. DTW distance between mean sequences is used to measure the separability between sequence classes. We show that the optimization problem can be approximately transformed into an eigen decomposition problem. LDA can be seen as a special case of LSDA by considering non-sequential vectors as sequences of length one. The effectiveness of the proposed LSDA is demonstrated on two individual sequence datasets from UCI machine learning repository as well as two concatenate sequence datasets: APTI Arabic printed text database and IFN/ENIT Arabic handwriting database.</p><p>2 0.67553097 <a title="253-lda-2" href="./iccv-2013-Saliency_Detection%3A_A_Boolean_Map_Approach.html">369 iccv-2013-Saliency Detection: A Boolean Map Approach</a></p>
<p>Author: Jianming Zhang, Stan Sclaroff</p><p>Abstract: A novel Boolean Map based Saliency (BMS) model is proposed. An image is characterized by a set of binary images, which are generated by randomly thresholding the image ’s color channels. Based on a Gestalt principle of figure-ground segregation, BMS computes saliency maps by analyzing the topological structure of Boolean maps. BMS is simple to implement and efficient to run. Despite its simplicity, BMS consistently achieves state-of-the-art performance compared with ten leading methods on five eye tracking datasets. Furthermore, BMS is also shown to be advantageous in salient object detection.</p><p>3 0.61294949 <a title="253-lda-3" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>Author: S. Karthikeyan, Vignesh Jagadeesh, Renuka Shenoy, Miguel Ecksteinz, B.S. Manjunath</p><p>Abstract: Eye movement studies have confirmed that overt attention is highly biased towards faces and text regions in images. In this paper we explore a novel problem of predicting face and text regions in images using eye tracking data from multiple subjects. The problem is challenging as we aim to predict the semantics (face/text/background) only from eye tracking data without utilizing any image information. The proposed algorithm spatially clusters eye tracking data obtained in an image into different coherent groups and subsequently models the likelihood of the clusters containing faces and text using afully connectedMarkov Random Field (MRF). Given the eye tracking datafrom a test image, itpredicts potential face/head (humans, dogs and cats) and text locations reliably. Furthermore, the approach can be used to select regions of interest for further analysis by object detectors for faces and text. The hybrid eye position/object detector approach achieves better detection performance and reduced computation time compared to using only the object detection algorithm. We also present a new eye tracking dataset on 300 images selected from ICDAR, Street-view, Flickr and Oxford-IIIT Pet Dataset from 15 subjects.</p><p>4 0.60730642 <a title="253-lda-4" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>Author: Junliang Xing, Jin Gao, Bing Li, Weiming Hu, Shuicheng Yan</p><p>Abstract: Recently, sparse representation has been introduced for robust object tracking. By representing the object sparsely, i.e., using only a few templates via ?1-norm minimization, these so-called ?1-trackers exhibit promising tracking results. In this work, we address the object template building and updating problem in these ?1-tracking approaches, which has not been fully studied. We propose to perform template updating, in a new perspective, as an online incremental dictionary learning problem, which is efficiently solved through an online optimization procedure. To guarantee the robustness and adaptability of the tracking algorithm, we also propose to build a multi-lifespan dictionary model. By building target dictionaries of different lifespans, effective object observations can be obtained to deal with the well-known drifting problem in tracking and thus improve the tracking accuracy. We derive effective observa- tion models both generatively and discriminatively based on the online multi-lifespan dictionary learning model and deploy them to the Bayesian sequential estimation framework to perform tracking. The proposed approach has been extensively evaluated on ten challenging video sequences. Experimental results demonstrate the effectiveness of the online learned templates, as well as the state-of-the-art tracking performance of the proposed approach.</p><p>5 0.60582417 <a title="253-lda-5" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>Author: Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, Philip S. Yu</p><p>Abstract: Transfer learning is established as an effective technology in computer visionfor leveraging rich labeled data in the source domain to build an accurate classifier for the target domain. However, most prior methods have not simultaneously reduced the difference in both the marginal distribution and conditional distribution between domains. In this paper, we put forward a novel transfer learning approach, referred to as Joint Distribution Adaptation (JDA). Specifically, JDA aims to jointly adapt both the marginal distribution and conditional distribution in a principled dimensionality reduction procedure, and construct new feature representation that is effective and robustfor substantial distribution difference. Extensive experiments verify that JDA can significantly outperform several state-of-the-art methods on four types of cross-domain image classification problems.</p><p>6 0.60425472 <a title="253-lda-6" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>7 0.60287732 <a title="253-lda-7" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>8 0.60275531 <a title="253-lda-8" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>9 0.60272551 <a title="253-lda-9" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>10 0.60228443 <a title="253-lda-10" href="./iccv-2013-Latent_Data_Association%3A_Bayesian_Model_Selection_for_Multi-target_Tracking.html">230 iccv-2013-Latent Data Association: Bayesian Model Selection for Multi-target Tracking</a></p>
<p>11 0.60023838 <a title="253-lda-11" href="./iccv-2013-Text_Localization_in_Natural_Images_Using_Stroke_Feature_Transform_and_Text_Covariance_Descriptors.html">415 iccv-2013-Text Localization in Natural Images Using Stroke Feature Transform and Text Covariance Descriptors</a></p>
<p>12 0.60020381 <a title="253-lda-12" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>13 0.60006404 <a title="253-lda-13" href="./iccv-2013-Orderless_Tracking_through_Model-Averaged_Posterior_Estimation.html">303 iccv-2013-Orderless Tracking through Model-Averaged Posterior Estimation</a></p>
<p>14 0.59955025 <a title="253-lda-14" href="./iccv-2013-Semantic_Transform%3A_Weakly_Supervised_Semantic_Inference_for_Relating_Visual_Attributes.html">380 iccv-2013-Semantic Transform: Weakly Supervised Semantic Inference for Relating Visual Attributes</a></p>
<p>15 0.59918493 <a title="253-lda-15" href="./iccv-2013-Real-Time_Articulated_Hand_Pose_Estimation_Using_Semi-supervised_Transductive_Regression_Forests.html">340 iccv-2013-Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests</a></p>
<p>16 0.59877139 <a title="253-lda-16" href="./iccv-2013-Incorporating_Cloud_Distribution_in_Sky_Representation.html">215 iccv-2013-Incorporating Cloud Distribution in Sky Representation</a></p>
<p>17 0.59871209 <a title="253-lda-17" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>18 0.59802955 <a title="253-lda-18" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>19 0.59745872 <a title="253-lda-19" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>20 0.59702408 <a title="253-lda-20" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
