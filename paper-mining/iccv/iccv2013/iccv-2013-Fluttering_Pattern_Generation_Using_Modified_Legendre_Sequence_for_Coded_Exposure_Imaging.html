<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-173" href="#">iccv2013-173</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</h1>
<br/><p>Source: <a title="iccv-2013-173-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Jeon_Fluttering_Pattern_Generation_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>Reference: <a title="iccv-2013-173-reference" href="../iccv2013_reference/iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('legendr', 0.549), ('expos', 0.4), ('deblur', 0.335), ('flut', 0.29), ('merit', 0.262), ('sequ', 0.246), ('mtf', 0.195), ('autocorrel', 0.13), ('shut', 0.118), ('flip', 0.099), ('bin', 0.099), ('mccloskey', 0.088), ('append', 0.079), ('fc', 0.073), ('blur', 0.071), ('aperiod', 0.071), ('deconvolv', 0.064), ('rask', 0.058), ('transact', 0.051), ('ui', 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="173-tfidf-1" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>2 0.27245921 <a title="173-tfidf-2" href="./iccv-2013-Deblurring_by_Example_Using_Dense_Correspondence.html">103 iccv-2013-Deblurring by Example Using Dense Correspondence</a></p>
<p>Author: Yoav Hacohen, Eli Shechtman, Dani Lischinski</p><p>Abstract: This paper presents a new method for deblurring photos using a sharp reference example that contains some shared content with the blurry photo. Most previous deblurring methods that exploit information from other photos require an accurately registered photo of the same static scene. In contrast, our method aims to exploit reference images where the shared content may have undergone substantial photometric and non-rigid geometric transformations, as these are the kind of reference images most likely to be found in personal photo albums. Our approach builds upon a recent method for examplebased deblurring using non-rigid dense correspondence (NRDC) [11] and extends it in two ways. First, we suggest exploiting information from the reference image not only for blur kernel estimation, but also as a powerful local prior for the non-blind deconvolution step. Second, we introduce a simple yet robust technique for spatially varying blur estimation, rather than assuming spatially uniform blur. Unlike the aboveprevious method, which hasproven successful only with simple deblurring scenarios, we demonstrate that our method succeeds on a variety of real-world examples. We provide quantitative and qualitative evaluation of our method and show that it outperforms the state-of-the-art.</p><p>3 0.26098746 <a title="173-tfidf-3" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>Author: Mohit Gupta, Daisuke Iso, Shree K. Nayar</p><p>Abstract: Exposure bracketing for high dynamic range (HDR) imaging involves capturing several images of the scene at different exposures. If either the camera or the scene moves during capture, the captured images must be registered. Large exposure differences between bracketed images lead to inaccurate registration, resulting in artifacts such as ghosting (multiple copies of scene objects) and blur. We present two techniques, one for image capture (Fibonacci exposure bracketing) and one for image registration (generalized registration), to prevent such motion-related artifacts. Fibonacci bracketing involves capturing a sequence of images such that each exposure time is the sum of the previous N(N > 1) exposures. Generalized registration involves estimating motion between sums of contiguous sets of frames, instead of between individual frames. Together, the two techniques ensure that motion is always estimated betweenframes of the same total exposure time. This results in HDR images and videos which have both a large dynamic range andminimal motion-relatedartifacts. We show, by results for several real-world indoor and outdoor scenes, that theproposed approach significantly outperforms several ex- isting bracketing schemes.</p><p>4 0.25559893 <a title="173-tfidf-4" href="./iccv-2013-Dynamic_Scene_Deblurring.html">129 iccv-2013-Dynamic Scene Deblurring</a></p>
<p>Author: Tae Hyun Kim, Byeongjoo Ahn, Kyoung Mu Lee</p><p>Abstract: Most conventional single image deblurring methods assume that the underlying scene is static and the blur is caused by only camera shake. In this paper, in contrast to this restrictive assumption, we address the deblurring problem of general dynamic scenes which contain multiple moving objects as well as camera shake. In case of dynamic scenes, moving objects and background have different blur motions, so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately. Thus, we propose a novel energy model designed with the weighted sum of multiple blur data models, which estimates different motion blurs and their associated pixelwise weights, and resulting sharp image. In this framework, the local weights are determined adaptively and get high values when the corresponding data models have high data fidelity. And, the weight information is used for the segmentation of the motion blur. Non-local regularization of weights are also incorporated to produce more reliable segmentation results. A convex optimization-based method is used for the solution of the proposed energy model. Exper- imental results demonstrate that our method outperforms conventional approaches in deblurring both dynamic scenes and static scenes.</p><p>5 0.22779396 <a title="173-tfidf-5" href="./iccv-2013-Forward_Motion_Deblurring.html">174 iccv-2013-Forward Motion Deblurring</a></p>
<p>Author: Shicheng Zheng, Li Xu, Jiaya Jia</p><p>Abstract: We handle a special type of motion blur considering that cameras move primarily forward or backward. Solving this type of blur is of unique practical importance since nearly all car, traffic and bike-mounted cameras follow out-ofplane translational motion. We start with the study of geometric models and analyze the difficulty of existing methods to deal with them. We also propose a solution accounting for depth variation. Homographies associated with different 3D planes are considered and solved for in an optimization framework. Our method is verified on several natural image examples that cannot be satisfyingly dealt with by previous methods.</p><p>6 0.17656723 <a title="173-tfidf-6" href="./iccv-2013-A_Unified_Rolling_Shutter_and_Motion_Blur_Model_for_3D_Visual_Registration.html">32 iccv-2013-A Unified Rolling Shutter and Motion Blur Model for 3D Visual Registration</a></p>
<p>7 0.1710898 <a title="173-tfidf-7" href="./iccv-2013-Rolling_Shutter_Stereo.html">363 iccv-2013-Rolling Shutter Stereo</a></p>
<p>8 0.086387053 <a title="173-tfidf-8" href="./iccv-2013-Street_View_Motion-from-Structure-from-Motion.html">402 iccv-2013-Street View Motion-from-Structure-from-Motion</a></p>
<p>9 0.079261929 <a title="173-tfidf-9" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>10 0.061173711 <a title="173-tfidf-10" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>11 0.061096549 <a title="173-tfidf-11" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>12 0.058758382 <a title="173-tfidf-12" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>13 0.058310311 <a title="173-tfidf-13" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>14 0.056419063 <a title="173-tfidf-14" href="./iccv-2013-Depth_from_Combining_Defocus_and_Correspondence_Using_Light-Field_Cameras.html">108 iccv-2013-Depth from Combining Defocus and Correspondence Using Light-Field Cameras</a></p>
<p>15 0.052319728 <a title="173-tfidf-15" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>16 0.049879484 <a title="173-tfidf-16" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>17 0.049532369 <a title="173-tfidf-17" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>18 0.046559475 <a title="173-tfidf-18" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>19 0.039873671 <a title="173-tfidf-19" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>20 0.039467923 <a title="173-tfidf-20" href="./iccv-2013-Local_Signal_Equalization_for_Correspondence_Matching.html">255 iccv-2013-Local Signal Equalization for Correspondence Matching</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.094), (1, -0.008), (2, 0.045), (3, 0.052), (4, 0.021), (5, 0.062), (6, 0.026), (7, 0.069), (8, -0.137), (9, -0.036), (10, 0.198), (11, 0.167), (12, 0.057), (13, -0.059), (14, -0.16), (15, -0.014), (16, 0.045), (17, -0.095), (18, 0.005), (19, 0.03), (20, -0.045), (21, 0.065), (22, 0.102), (23, 0.001), (24, -0.047), (25, -0.069), (26, 0.076), (27, -0.01), (28, 0.042), (29, 0.069), (30, 0.057), (31, 0.094), (32, -0.046), (33, -0.092), (34, 0.075), (35, -0.136), (36, 0.027), (37, 0.046), (38, 0.007), (39, 0.035), (40, 0.034), (41, -0.002), (42, -0.013), (43, -0.093), (44, -0.0), (45, -0.01), (46, -0.106), (47, 0.016), (48, 0.08), (49, 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91291279 <a title="173-lsi-1" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>2 0.78309721 <a title="173-lsi-2" href="./iccv-2013-A_Unified_Rolling_Shutter_and_Motion_Blur_Model_for_3D_Visual_Registration.html">32 iccv-2013-A Unified Rolling Shutter and Motion Blur Model for 3D Visual Registration</a></p>
<p>Author: Maxime Meilland, Tom Drummond, Andrew I. Comport</p><p>Abstract: Motion blur and rolling shutter deformations both inhibit visual motion registration, whether it be due to a moving sensor or a moving target. Whilst both deformations exist simultaneously, no models have been proposed to handle them together. Furthermore, neither deformation has been consideredpreviously in the context of monocularfullimage 6 degrees of freedom registration or RGB-D structure and motion. As will be shown, rolling shutter deformation is observed when a camera moves faster than a single pixel in parallax between subsequent scan-lines. Blur is a function of the pixel exposure time and the motion vector. In this paper a complete dense 3D registration model will be derived to accountfor both motion blur and rolling shutter deformations simultaneously. Various approaches will be compared with respect to ground truth and live real-time performance will be demonstratedfor complex scenarios where both blur and shutter deformations are dominant.</p><p>3 0.70042098 <a title="173-lsi-3" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>Author: Mohit Gupta, Daisuke Iso, Shree K. Nayar</p><p>Abstract: Exposure bracketing for high dynamic range (HDR) imaging involves capturing several images of the scene at different exposures. If either the camera or the scene moves during capture, the captured images must be registered. Large exposure differences between bracketed images lead to inaccurate registration, resulting in artifacts such as ghosting (multiple copies of scene objects) and blur. We present two techniques, one for image capture (Fibonacci exposure bracketing) and one for image registration (generalized registration), to prevent such motion-related artifacts. Fibonacci bracketing involves capturing a sequence of images such that each exposure time is the sum of the previous N(N > 1) exposures. Generalized registration involves estimating motion between sums of contiguous sets of frames, instead of between individual frames. Together, the two techniques ensure that motion is always estimated betweenframes of the same total exposure time. This results in HDR images and videos which have both a large dynamic range andminimal motion-relatedartifacts. We show, by results for several real-world indoor and outdoor scenes, that theproposed approach significantly outperforms several ex- isting bracketing schemes.</p><p>4 0.66758478 <a title="173-lsi-4" href="./iccv-2013-Forward_Motion_Deblurring.html">174 iccv-2013-Forward Motion Deblurring</a></p>
<p>Author: Shicheng Zheng, Li Xu, Jiaya Jia</p><p>Abstract: We handle a special type of motion blur considering that cameras move primarily forward or backward. Solving this type of blur is of unique practical importance since nearly all car, traffic and bike-mounted cameras follow out-ofplane translational motion. We start with the study of geometric models and analyze the difficulty of existing methods to deal with them. We also propose a solution accounting for depth variation. Homographies associated with different 3D planes are considered and solved for in an optimization framework. Our method is verified on several natural image examples that cannot be satisfyingly dealt with by previous methods.</p><p>5 0.65241987 <a title="173-lsi-5" href="./iccv-2013-Dynamic_Scene_Deblurring.html">129 iccv-2013-Dynamic Scene Deblurring</a></p>
<p>Author: Tae Hyun Kim, Byeongjoo Ahn, Kyoung Mu Lee</p><p>Abstract: Most conventional single image deblurring methods assume that the underlying scene is static and the blur is caused by only camera shake. In this paper, in contrast to this restrictive assumption, we address the deblurring problem of general dynamic scenes which contain multiple moving objects as well as camera shake. In case of dynamic scenes, moving objects and background have different blur motions, so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately. Thus, we propose a novel energy model designed with the weighted sum of multiple blur data models, which estimates different motion blurs and their associated pixelwise weights, and resulting sharp image. In this framework, the local weights are determined adaptively and get high values when the corresponding data models have high data fidelity. And, the weight information is used for the segmentation of the motion blur. Non-local regularization of weights are also incorporated to produce more reliable segmentation results. A convex optimization-based method is used for the solution of the proposed energy model. Exper- imental results demonstrate that our method outperforms conventional approaches in deblurring both dynamic scenes and static scenes.</p><p>6 0.63952708 <a title="173-lsi-6" href="./iccv-2013-Deblurring_by_Example_Using_Dense_Correspondence.html">103 iccv-2013-Deblurring by Example Using Dense Correspondence</a></p>
<p>7 0.55110806 <a title="173-lsi-7" href="./iccv-2013-Rolling_Shutter_Stereo.html">363 iccv-2013-Rolling Shutter Stereo</a></p>
<p>8 0.33770978 <a title="173-lsi-8" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>9 0.33364293 <a title="173-lsi-9" href="./iccv-2013-Street_View_Motion-from-Structure-from-Motion.html">402 iccv-2013-Street View Motion-from-Structure-from-Motion</a></p>
<p>10 0.32860398 <a title="173-lsi-10" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>11 0.29732916 <a title="173-lsi-11" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>12 0.27259535 <a title="173-lsi-12" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>13 0.26608646 <a title="173-lsi-13" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>14 0.24590595 <a title="173-lsi-14" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>15 0.24540633 <a title="173-lsi-15" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>16 0.23496972 <a title="173-lsi-16" href="./iccv-2013-Learning_Slow_Features_for_Behaviour_Analysis.html">243 iccv-2013-Learning Slow Features for Behaviour Analysis</a></p>
<p>17 0.2326012 <a title="173-lsi-17" href="./iccv-2013-Subpixel_Scanning_Invariant_to_Indirect_Lighting_Using_Quadratic_Code_Length.html">407 iccv-2013-Subpixel Scanning Invariant to Indirect Lighting Using Quadratic Code Length</a></p>
<p>18 0.22944066 <a title="173-lsi-18" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>19 0.22844903 <a title="173-lsi-19" href="./iccv-2013-Target-Driven_Moire_Pattern_Synthesis_by_Phase_Modulation.html">413 iccv-2013-Target-Driven Moire Pattern Synthesis by Phase Modulation</a></p>
<p>20 0.22772433 <a title="173-lsi-20" href="./iccv-2013-Space-Time_Tradeoffs_in_Photo_Sequencing.html">397 iccv-2013-Space-Time Tradeoffs in Photo Sequencing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.062), (14, 0.356), (20, 0.121), (25, 0.015), (32, 0.022), (33, 0.012), (42, 0.082), (44, 0.02), (48, 0.095), (55, 0.013), (60, 0.015), (77, 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.59956801 <a title="173-lda-1" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>Author: Jae-Hak Kim, Yuchao Dai, Hongdong Li, Xin Du, Jonghyuk Kim</p><p>Abstract: We present a new multi-view 3D Euclidean reconstruction method for arbitrary uncalibrated radially-symmetric cameras, which needs no calibration or any camera model parameters other than radial symmetry. It is built on the radial 1D camera model [25], a unified mathematical abstraction to different types of radially-symmetric cameras. We formulate the problem of multi-view reconstruction for radial 1D cameras as a matrix rank minimization problem. Efficient implementation based on alternating direction continuation is proposed to handle scalability issue for real-world applications. Our method applies to a wide range of omnidirectional cameras including both dioptric and catadioptric (central and non-central) cameras. Additionally, our method deals with complete and incomplete measurements under a unified framework elegantly. Experiments on both synthetic and real images from various types of cameras validate the superior performance of our new method, in terms of numerical accuracy and robustness.</p><p>same-paper 2 0.59270525 <a title="173-lda-2" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>3 0.59037751 <a title="173-lda-3" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>4 0.53870952 <a title="173-lda-4" href="./iccv-2013-Handwritten_Word_Spotting_with_Corrected_Attributes.html">192 iccv-2013-Handwritten Word Spotting with Corrected Attributes</a></p>
<p>Author: Jon Almazán, Albert Gordo, Alicia Fornés, Ernest Valveny</p><p>Abstract: We propose an approach to multi-writer word spotting, where the goal is to find a query word in a dataset comprised of document images. We propose an attributes-based approach that leads to a low-dimensional, fixed-length representation of the word images that is fast to compute and, especially, fast to compare. This approach naturally leads to an unified representation of word images and strings, which seamlessly allows one to indistinctly perform queryby-example, where the query is an image, and query-bystring, where the query is a string. We also propose a calibration scheme to correct the attributes scores based on Canonical Correlation Analysis that greatly improves the results on a challenging dataset. We test our approach on two public datasets showing state-of-the-art results.</p><p>5 0.46078351 <a title="173-lda-5" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>Author: Lukáš Neumann, Jiri Matas</p><p>Abstract: An unconstrained end-to-end text localization and recognition method is presented. The method introduces a novel approach for character detection and recognition which combines the advantages of sliding-window and connected component methods. Characters are detected and recognized as image regions which contain strokes of specific orientations in a specific relative position, where the strokes are efficiently detected by convolving the image gradient field with a set of oriented bar filters. Additionally, a novel character representation efficiently calculated from the values obtained in the stroke detection phase is introduced. The representation is robust to shift at the stroke level, which makes it less sensitive to intra-class variations and the noise induced by normalizing character size and positioning. The effectiveness of the representation is demonstrated by the results achieved in the classification of real-world characters using an euclidian nearestneighbor classifier trained on synthetic data in a plain form. The method was evaluated on a standard dataset, where it achieves state-of-the-art results in both text localization and recognition.</p><p>6 0.45801547 <a title="173-lda-6" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>7 0.45675921 <a title="173-lda-7" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>8 0.45631647 <a title="173-lda-8" href="./iccv-2013-Learning_Near-Optimal_Cost-Sensitive_Decision_Policy_for_Object_Detection.html">241 iccv-2013-Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection</a></p>
<p>9 0.4539904 <a title="173-lda-9" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<p>10 0.45238531 <a title="173-lda-10" href="./iccv-2013-A_Flexible_Scene_Representation_for_3D_Reconstruction_Using_an_RGB-D_Camera.html">9 iccv-2013-A Flexible Scene Representation for 3D Reconstruction Using an RGB-D Camera</a></p>
<p>11 0.4499867 <a title="173-lda-11" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>12 0.44941306 <a title="173-lda-12" href="./iccv-2013-Quantize_and_Conquer%3A_A_Dimensionality-Recursive_Solution_to_Clustering%2C_Vector_Quantization%2C_and_Image_Retrieval.html">333 iccv-2013-Quantize and Conquer: A Dimensionality-Recursive Solution to Clustering, Vector Quantization, and Image Retrieval</a></p>
<p>13 0.44870943 <a title="173-lda-13" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>14 0.44811222 <a title="173-lda-14" href="./iccv-2013-Video_Motion_for_Every_Visible_Point.html">441 iccv-2013-Video Motion for Every Visible Point</a></p>
<p>15 0.44574207 <a title="173-lda-15" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<p>16 0.44329518 <a title="173-lda-16" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>17 0.44323632 <a title="173-lda-17" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>18 0.44309992 <a title="173-lda-18" href="./iccv-2013-Fast_Subspace_Search_via_Grassmannian_Based_Hashing.html">162 iccv-2013-Fast Subspace Search via Grassmannian Based Hashing</a></p>
<p>19 0.44300735 <a title="173-lda-19" href="./iccv-2013-Supervised_Binary_Hash_Code_Learning_with_Jensen_Shannon_Divergence.html">409 iccv-2013-Supervised Binary Hash Code Learning with Jensen Shannon Divergence</a></p>
<p>20 0.44292659 <a title="173-lda-20" href="./iccv-2013-Video_Synopsis_by_Heterogeneous_Multi-source_Correlation.html">443 iccv-2013-Video Synopsis by Heterogeneous Multi-source Correlation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
