<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-173" href="#">iccv2013-173</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</h1>
<br/><p>Source: <a title="iccv-2013-173-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Jeon_Fluttering_Pattern_Generation_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>Reference: <a title="iccv-2013-173-reference" href="../iccv2013_reference/iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 kr  Abstract Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. [sent-9, score-1.467]
</p><p>2 Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes. [sent-12, score-1.425]
</p><p>3 Introduction Image deblurring is one of the most traditional problems in computer vision, in which the goal is to recover a latent sharp image from an image blurred due to the motion of the subject or the camera. [sent-14, score-0.345]
</p><p>4 A key element in the coded exposure imaging is the generation of the fluttering pattern of the shutter (binary sequence). [sent-19, score-1.217]
</p><p>5 In previous work, a near optimal binary sequence is computed through a randomized linear search [1, 2, 19] or a priority search [16] over the space of potential sequences. [sent-20, score-0.406]
</p><p>6 While these methods are applicable for generating short sequences, they are not suitable for computing long binary sequences because of the large search space. [sent-21, score-0.322]
</p><p>7 Finding binary sequences with low autocorrelation is a deeply studied problem in the field of information theory and physics because it relates to many applications in telecommunications (e. [sent-22, score-0.376]
</p><p>8 Among many methods for generating the binary sequence, the Legendre sequence has shown some advantages over other methods, especially in terms of the 11000011  computational time and the autocorrelation measure [9]. [sent-27, score-0.485]
</p><p>9 In this paper, we introduce a new algorithm for generat-  ing binary sequences for the coded exposure imaging using the Legendre sequence. [sent-28, score-1.075]
</p><p>10 We show that the concept ofthe low autocorrelation binary sequence can be applied for generating the fluttering pattern of the shutter, and propose a new algorithm that modifies the Legendre sequence to make it suitable for the coded exposure problem. [sent-29, score-1.71]
</p><p>11 Our new algorithm consistently generates better binary sequences for the coded exposure problem in much shorter time (several orders of magnitude), yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes (Fig. [sent-30, score-1.572]
</p><p>12 Our algorithm holds significant advantages especially when the sequence length is large, in which case the previous methods fail to find good binary codes due to the exponentially growing search space. [sent-32, score-0.477]
</p><p>13 After reviewing previous work in Section 2, we introduce the coded exposure imaging concept and explain the measure of a good binary sequence developed in the field of Information Theory as well as its adaptation to coded exposure in Section 3. [sent-34, score-1.999]
</p><p>14 Then a modified Legendre sequence for coded exposure is proposed in Section 4. [sent-35, score-1.036]
</p><p>15 proposed a solution for defocus blur by using the coded aperture and the sparse natural image prior to produce sharper edges and reduce undesirable ringing artifacts. [sent-44, score-0.466]
</p><p>16 introduced the coded exposure photography, a motion deblurring method using the fluttered shutter. [sent-47, score-1.129]
</p><p>17 Rather than having the shutter open for the entire exposure duration, they flutter the camera’s shutter open and closed during the exposure with a binary pseudo-random sequence [19]. [sent-48, score-1.296]
</p><p>18 presented a spatially varying PSF estimation algorithm which jointly utilizes a coded exposure camera and simple user interactions in [24], while McCloskey et al. [sent-51, score-0.813]
</p><p>19 further addressed the problem of motion deblurring using the coded exposure by analyzing the design and the estimation of the coded exposure PSF in [17]. [sent-52, score-1.873]
</p><p>20 The idea of coded exposure photography has also been extended to the resolution enhancement application in [1]. [sent-53, score-0.932]
</p><p>21 As expected, the fluttering pattern of the camera shut-  ter plays a critical role in determining the performance of the coded exposure imaging. [sent-54, score-1.041]
</p><p>22 McCloskey presented the idea that the shutter sequence must be dependent on the object velocity and proposed a method for computing the velocity-dependent sequences in [16]. [sent-56, score-0.439]
</p><p>23 Natural image statistics are incorporated in generating binary sequences for coded aperture [27] and coded exposure [17]. [sent-58, score-1.5]
</p><p>24 To overcome this limitation, we introduce an algorithm for computing binary sequences suited for long sequences using Legendre sequence. [sent-60, score-0.369]
</p><p>25 The principal idea behind the coded exposure is to improve the invertibility of the imaging process (the invertibility of the smearing matrix A) through the fluttered shutter (see Fig. [sent-64, score-1.111]
</p><p>26 Denoting a binary sequence of length n as U = [u0, . [sent-66, score-0.4]
</p><p>27 U  Um  −1  where F(U) is the discrete Fourier transform of the binary sequence aUn)d i sit tsh aeb dsioslcuretet ev Faoluuer |eFr (tUran) |s fios a magnitude royf frequency response osofl binary sequence |(M isT aF m: Magondituuldateio onf Transfer Function). [sent-71, score-0.64]
</p><p>28 In information theory, the merit factor is widely used as the criterion of “goodness” for binary sequences whose aperiodic autocorrelations are collectively small. [sent-76, score-0.695]
</p><p>29 For a binary  sequence U = [u0, u1, · is defined as follows:  · ·  , un−1] , the merit factor M(U)  M(U) =2? [sent-77, score-0.728]
</p><p>30 i=0  (3)  The merit factor is closely related to the signal to selfgenerated noise ratio, which corresponds to the deconvolution noise in the coded exposure imaging. [sent-83, score-1.263]
</p><p>31 In [10], the relation between the merit factor and the spectral properties of the sequence is denoted as  k? [sent-84, score-0.624]
</p><p>32 (4) shows that the merit factor measures how much the amplitude spectrum of the sequence deviates from the constant value n, therefore a sequence with a higher merit factor has a flatter MTF. [sent-90, score-1.297]
</p><p>33 This corresponds to condition (ii) of the binary sequence measure for coded exposure and we can rewrite the merit factor as follows:  M(U) =? [sent-91, score-1.541]
</p><p>34 Coded Factor While the merit factor is a good criterion for measuring the MTF variance, it can make the amplitude spectrum partially peaky as shown in Fig. [sent-96, score-0.499]
</p><p>35 (3) is derived with the binary sequence taking the value {−1, 1}. [sent-100, score-0.32]
</p><p>36 However, the binary sequence feo tra tkhien cgo tdheed v exposure ,s1ho}u. [sent-101, score-0.708]
</p><p>37 Figure 2: Coded exposure and the measure of a good binary sequence. [sent-125, score-0.526]
</p><p>38 (b) By using the coded exposure, the information are preserved and the deblurring problem becomes invertible. [sent-127, score-0.667]
</p><p>39 (c) The merit factor is a good measure of the variance of the MTF (deconvolution noise), but it may make the spectrum partially peaky. [sent-128, score-0.472]
</p><p>40 (d) The proposing coded factor is a good measure of a binary sequence that minimizes the variance of the MTF while maximizing the lowest MTF value. [sent-129, score-0.894]
</p><p>41 If we change the sequence ui ∈ {−1, 1} to uˆi ∈ {0, 1} by substituting 0 for  −1, the aperiodic a1u,t1oc}o torre uˆ lat∈ion { 0o,f1 U} bisy computed as n  ak  = 4 aˆk+ 4 mˆ  −? [sent-131, score-0.345]
</p><p>42 5, winh tihceh bsuepcopmlemese 0n awryith m thaete assumption t (h7a),t t mhˆ e sequence 5is, balanced with equal number of zeros and ones for optimal autocorrelation properties [12]. [sent-140, score-0.315]
</p><p>43 Therefore, we use the following equation for computing the merit factor from a binary sequence of 0’s and 1  ’s. [sent-141, score-0.728]
</p><p>44 ot Tho ote drmeasl into account and return the maximum coded factor FC. [sent-150, score-0.54]
</p><p>45 The Legendre sequence [7] is a binary sequence with a high merit factor and it is among the most popular choices for generating binary sequences in many different fields. [sent-152, score-1.221]
</p><p>46 The Legendre sequence of a prime length n is defined as  ui=? [sent-153, score-0.369]
</p><p>47 Advantages of using the Legendre sequence over a random binary sequence search for the coded exposure include higher quality sequences with high merit factor as well as much less computational load since the Legendre sequence is solved in a closed form. [sent-166, score-2.143]
</p><p>48 Although the Legendre sequence would insure high merit factor M(U), it does not guarantee the highest coded factor since it does not consider |F(U) | . [sent-167, score-1.164]
</p><p>49 The merit factor of a Legendre sequence can be improved by rotating the sequence in a cyclic manner as shown in [8]. [sent-171, score-0.869]
</p><p>50 For a given sequence U, an r-rotated Legendre sequence Vr is defined as  Vr = (Ur+1:n; U1:r) ,  (10)  where Ui:j is the sub-sequence of U from the ith to the jth element and (; ) represents an operator for concatenating two sequences. [sent-172, score-0.457]
</p><p>51 We search for the enhanced sequence in terms of the coded factor among all candidate sequences Vr (0 ≤ r ≤ n − 1). [sent-173, score-0.924]
</p><p>52 proved that appending the initial part of a rotated Legendre sequence to itself could improve the merit factor of the sequence. [sent-176, score-0.747]
</p><p>53 We adopt the appending operation to improve the sequence quality as well as to resolve a restraint of Legendre sequence that it is only defined for a length of a prime number. [sent-177, score-0.733]
</p><p>54 From an r-rotated Legendre sequence Vr, a t-appended Legendre sequence is obtained by appending the first t 1Note that either {0, 1} or {−1, 1} quence vtea tlhuae as itshhoewr {n0 0i,n1 [1}8 o]. [sent-178, score-0.56]
</p><p>55 Using tthoe i sequence appending operation, the modified Legendre sequence with a length m can be generated from any rotated Legendre sequence with a prime length n for m2 ≤ n ≤ m. [sent-180, score-1.049]
</p><p>56 In a recent work [3], Baden presented an efficient optimization method of the merit factor of binary sequences by deriving a formulation for measuring the change in the merit factor by a change of value in an element (flipping) in  the sequence. [sent-182, score-1.068]
</p><p>57 represents the convolution operator, Λ = [a1, · · · , am] is an aperiodic autocorrelation of the binary sequence Y of length m, and γ indicates the reversal of a sequence where yjγ = ym−j+1. [sent-187, score-0.775]
</p><p>58 (11), a candidate set of element indices that are expected to improve the merit factor is chosen as Δ1 = {j |δj > 0} . [sent-189, score-0.452]
</p><p>59 (12)  To extend the above optimization method to the coded factor, we compute the change in the minimum of MTF by a single-element flip as follows:  κj=? [sent-190, score-0.428]
</p><p>60 Since Δ1 is related to the merit factor and Δ2 is relate∪dΔ Δto the MTF minimum, the new candidate set Δ includes potential element indexes that can improve the coded factor FC (Eq. [sent-197, score-0.992]
</p><p>61 Algorithm Summary Our framework for generating a binary sequence for the coded exposure imaging is summarized in Algorithm 2. [sent-201, score-1.218]
</p><p>62 (9) 5: Vi = Rotating(Ui) 6: Yi = Appending(Vi) 7: end for 8: O = Yi with the highest coded factor 9: = Optimization by Flipping(O) in Algorithm 1 10: return Oˆ 11: end procedure  Oˆ  m (n = {ni | m2 ≤ ni ≤ m, ni is prime number}). [sent-206, score-0.691]
</p><p>63 We then mfind (n nth =e r {in-ro|tate≤d Legendre sequence using tbheer rotating operation for each Legendre sequence and apply the appending operation for all the rotated sequences to make length m sequences. [sent-207, score-0.831]
</p><p>64 Among the candidate sequences, we select a sequence with the highest coded factor and perform the optimization using the flipping operation. [sent-208, score-0.857]
</p><p>65 Experiments To evaluate the performance of the proposed algorithm, we conducted many coded exposure deblurring experiments using both synthetic and real-world dataset. [sent-212, score-1.086]
</p><p>66 For our method and the method [19], binary sequences of length [40, 50, · · · , 200] were generated. [sent-216, score-0.307]
</p><p>67 To first show the effectiveness of the coded factor as a measure of a good binary sequence for coded exposure, we compared deblurring results using the binary sequences generated by the merit factor and the coded factor, which  is shown in Fig. [sent-246, score-2.627]
</p><p>68 The sequences generated by the coded factor shows stable performance while the sequences generated by the merit factor sometimes work poorly especially in terms of the SSIM due to the peaky spectrum as previously shown in Fig. [sent-248, score-1.292]
</p><p>69 However, our method consistently produces good binary sequences for the coded exposure imaging and the difference in the performance amplifies as the sequence 3sites. [sent-253, score-1.333]
</p><p>70 87653190 7S9e0qu1nc0e1L30ngt1hCM5o0edrit1F7a0ct1o9r0 Figure 4: Comparison of the merit factor and the coded factor as a measure of a good binary sequence. [sent-258, score-1.086]
</p><p>71 When the sequence length is big, the other methods fail to find good sequences due to the large search space. [sent-260, score-0.463]
</p><p>72 This issue of the sequence length is an important one since longer sequences are necessary for larger motion blurs  or faster moving objects [1, 16]. [sent-261, score-0.44]
</p><p>73 Real-world results We implemented the coded exposure photography using the PointGrey Flea3 camera, which supports the Trigger mode 5 that enables multiple pulse-width trigger with a single readout. [sent-265, score-0.87]
</p><p>74 In our implementation, each shutter chop is 1ms long, so a fluttering pattern of length 100 has 100 ms capture time. [sent-266, score-0.448]
</p><p>75 6 show two examples of the deblurring results using the coded exposure with the fluttering patterns generated by various methods. [sent-269, score-1.309]
</p><p>76 As expected, deblurring results using the modified Legendre sequence returns the sharpest images, enabling the contents to be read as opposed to other results where the contents remain difficult to interpret. [sent-270, score-0.547]
</p><p>77 7 shows another example of our coded exposure imaging in action, imaging static objects from a fast moving camera. [sent-272, score-0.899]
</p><p>78 The work in [1] showed that the coded exposure imag-  Figure 7: Our coded exposure imaging in action. [sent-274, score-1.645]
</p><p>79 ing is not only effective for the motion deblurring but also for the resolution enhancement. [sent-276, score-0.312]
</p><p>80 k T ∗h sere foforr ae, they emphasized the importance of a long binary sequence as mentioned previously. [sent-278, score-0.361]
</p><p>81 8 compares the performance of the resolution enhancement using different binary sequences of length 120, and as expected, the sequence generated by our method shows better visual quality in both the deblurring and the resolution enhancement. [sent-280, score-0.937]
</p><p>82 9, we compare the deblurring performance with the same exposure time, but with different sequence lengths. [sent-282, score-0.862]
</p><p>83 The sequences of length 40 and 120 generated by the pro-  posed method are used for this experiment  and we control  the single chop time to make the exposure time the same under different sequence lengths. [sent-283, score-0.869]
</p><p>84 9, the  deblurred image with the longer sequence preserves more spatial frequencies of the blurred image than the shorter sequence. [sent-285, score-0.337]
</p><p>85 The difference in the performance amplifies as the sequence length increases; our method consistently generates good binary codes for the coded exposure imaging. [sent-287, score-1.272]
</p><p>86 (Ns= 108)(d) Proposed Figure 6: Comparison of the deblurring performance with the fluttering patterns of length 100 generated by various methods. [sent-341, score-0.592]
</p><p>87 (a)(b) Figure 9: Comparison of the deblurring performance with different sequence lengths under the same exposure. [sent-343, score-0.474]
</p><p>88 (a) sequence length = 40, 1 chop duration = 3 ms. [sent-344, score-0.355]
</p><p>89 Discussion We have presented a new method for computing the fluttering sequence for the coded exposure photography by modifying the Legendre sequence. [sent-347, score-1.276]
</p><p>90 We validated the efficiency of our algorithm through various experiments, and we were able to achieve better deblurring and resolution enhancement performance without any prior by using the binary codes generated using our algorithm. [sent-348, score-0.498]
</p><p>91 (b) Captured images with different fluttering patterns of length 120. [sent-386, score-0.312]
</p><p>92 Coded exposure deblurring: Optimized codes for psf estimation and invertibility. [sent-402, score-0.456]
</p><p>93 Efficient optimization of the merit factor of long binary sequences. [sent-407, score-0.531]
</p><p>94 Binary sequences with merit  [5]  [6]  [7] [8]  [9] [10]  [11]  [12]  [13]  [14]  [15] [16]  factor greater than 6. [sent-414, score-0.531]
</p><p>95 A survey of the merit factor problem for binary sequences. [sent-449, score-0.512]
</p><p>96 The merit factor of binary sequences related to difference sets. [sent-459, score-0.635]
</p><p>97 A class of balanced binary sequences with optimal autocorrelation properties. [sent-470, score-0.326]
</p><p>98 Image and depth from a conventional camera with a coded aperture. [sent-478, score-0.425]
</p><p>99 Design and estimation of coded exposure point spread functions. [sent-500, score-0.797]
</p><p>100 Trace representation of legendre sequences of mersenne prime period. [sent-511, score-0.659]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('legendre', 0.463), ('coded', 0.409), ('exposure', 0.388), ('merit', 0.277), ('deblurring', 0.258), ('sequence', 0.216), ('fluttering', 0.209), ('mtf', 0.164), ('factor', 0.131), ('sequences', 0.123), ('appending', 0.106), ('binary', 0.104), ('shutter', 0.1), ('autocorrelation', 0.099), ('flipping', 0.082), ('length', 0.08), ('mccloskey', 0.075), ('prime', 0.073), ('blurred', 0.066), ('fc', 0.062), ('aperiodic', 0.06), ('deconvolution', 0.058), ('photography', 0.054), ('fluttered', 0.053), ('imaging', 0.051), ('generating', 0.05), ('raskar', 0.049), ('enhancement', 0.048), ('transactions', 0.043), ('ui', 0.042), ('invertibility', 0.04), ('chop', 0.04), ('ni', 0.039), ('ssim', 0.037), ('vr', 0.036), ('psf', 0.035), ('theory', 0.035), ('resolution', 0.033), ('psnr', 0.033), ('codes', 0.033), ('deblurred', 0.033), ('agrawal', 0.031), ('synthetic', 0.031), ('borwein', 0.03), ('kodak', 0.03), ('smearing', 0.03), ('spectrum', 0.03), ('rotating', 0.029), ('ak', 0.027), ('lossless', 0.026), ('mmiinn', 0.026), ('search', 0.026), ('contents', 0.025), ('element', 0.025), ('amplifies', 0.024), ('peaky', 0.024), ('yj', 0.024), ('levin', 0.023), ('jensen', 0.023), ('modified', 0.023), ('patterns', 0.023), ('emphasized', 0.022), ('kaist', 0.022), ('ringing', 0.022), ('quence', 0.022), ('shorter', 0.022), ('generated', 0.022), ('operation', 0.022), ('suite', 0.021), ('motion', 0.021), ('proceedings', 0.02), ('quality', 0.02), ('ieee', 0.02), ('conference', 0.019), ('candidate', 0.019), ('long', 0.019), ('duration', 0.019), ('chung', 0.019), ('pattern', 0.019), ('flip', 0.019), ('amplitude', 0.019), ('trigger', 0.019), ('un', 0.018), ('good', 0.018), ('korea', 0.018), ('defocus', 0.018), ('fergus', 0.017), ('rotated', 0.017), ('load', 0.017), ('randomized', 0.017), ('priority', 0.017), ('aperture', 0.017), ('inversion', 0.017), ('generation', 0.016), ('finding', 0.016), ('measure', 0.016), ('camera', 0.016), ('yy', 0.015), ('physics', 0.015), ('graphics', 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="173-tfidf-1" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>2 0.18290216 <a title="173-tfidf-2" href="./iccv-2013-Deblurring_by_Example_Using_Dense_Correspondence.html">103 iccv-2013-Deblurring by Example Using Dense Correspondence</a></p>
<p>Author: Yoav Hacohen, Eli Shechtman, Dani Lischinski</p><p>Abstract: This paper presents a new method for deblurring photos using a sharp reference example that contains some shared content with the blurry photo. Most previous deblurring methods that exploit information from other photos require an accurately registered photo of the same static scene. In contrast, our method aims to exploit reference images where the shared content may have undergone substantial photometric and non-rigid geometric transformations, as these are the kind of reference images most likely to be found in personal photo albums. Our approach builds upon a recent method for examplebased deblurring using non-rigid dense correspondence (NRDC) [11] and extends it in two ways. First, we suggest exploiting information from the reference image not only for blur kernel estimation, but also as a powerful local prior for the non-blind deconvolution step. Second, we introduce a simple yet robust technique for spatially varying blur estimation, rather than assuming spatially uniform blur. Unlike the aboveprevious method, which hasproven successful only with simple deblurring scenarios, we demonstrate that our method succeeds on a variety of real-world examples. We provide quantitative and qualitative evaluation of our method and show that it outperforms the state-of-the-art.</p><p>3 0.17471211 <a title="173-tfidf-3" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>Author: Mohit Gupta, Daisuke Iso, Shree K. Nayar</p><p>Abstract: Exposure bracketing for high dynamic range (HDR) imaging involves capturing several images of the scene at different exposures. If either the camera or the scene moves during capture, the captured images must be registered. Large exposure differences between bracketed images lead to inaccurate registration, resulting in artifacts such as ghosting (multiple copies of scene objects) and blur. We present two techniques, one for image capture (Fibonacci exposure bracketing) and one for image registration (generalized registration), to prevent such motion-related artifacts. Fibonacci bracketing involves capturing a sequence of images such that each exposure time is the sum of the previous N(N > 1) exposures. Generalized registration involves estimating motion between sums of contiguous sets of frames, instead of between individual frames. Together, the two techniques ensure that motion is always estimated betweenframes of the same total exposure time. This results in HDR images and videos which have both a large dynamic range andminimal motion-relatedartifacts. We show, by results for several real-world indoor and outdoor scenes, that theproposed approach significantly outperforms several ex- isting bracketing schemes.</p><p>4 0.17238469 <a title="173-tfidf-4" href="./iccv-2013-Dynamic_Scene_Deblurring.html">129 iccv-2013-Dynamic Scene Deblurring</a></p>
<p>Author: Tae Hyun Kim, Byeongjoo Ahn, Kyoung Mu Lee</p><p>Abstract: Most conventional single image deblurring methods assume that the underlying scene is static and the blur is caused by only camera shake. In this paper, in contrast to this restrictive assumption, we address the deblurring problem of general dynamic scenes which contain multiple moving objects as well as camera shake. In case of dynamic scenes, moving objects and background have different blur motions, so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately. Thus, we propose a novel energy model designed with the weighted sum of multiple blur data models, which estimates different motion blurs and their associated pixelwise weights, and resulting sharp image. In this framework, the local weights are determined adaptively and get high values when the corresponding data models have high data fidelity. And, the weight information is used for the segmentation of the motion blur. Non-local regularization of weights are also incorporated to produce more reliable segmentation results. A convex optimization-based method is used for the solution of the proposed energy model. Exper- imental results demonstrate that our method outperforms conventional approaches in deblurring both dynamic scenes and static scenes.</p><p>5 0.1629843 <a title="173-tfidf-5" href="./iccv-2013-Forward_Motion_Deblurring.html">174 iccv-2013-Forward Motion Deblurring</a></p>
<p>Author: Shicheng Zheng, Li Xu, Jiaya Jia</p><p>Abstract: We handle a special type of motion blur considering that cameras move primarily forward or backward. Solving this type of blur is of unique practical importance since nearly all car, traffic and bike-mounted cameras follow out-ofplane translational motion. We start with the study of geometric models and analyze the difficulty of existing methods to deal with them. We also propose a solution accounting for depth variation. Homographies associated with different 3D planes are considered and solved for in an optimization framework. Our method is verified on several natural image examples that cannot be satisfyingly dealt with by previous methods.</p><p>6 0.12142143 <a title="173-tfidf-6" href="./iccv-2013-A_Unified_Rolling_Shutter_and_Motion_Blur_Model_for_3D_Visual_Registration.html">32 iccv-2013-A Unified Rolling Shutter and Motion Blur Model for 3D Visual Registration</a></p>
<p>7 0.11574343 <a title="173-tfidf-7" href="./iccv-2013-Rolling_Shutter_Stereo.html">363 iccv-2013-Rolling Shutter Stereo</a></p>
<p>8 0.11168343 <a title="173-tfidf-8" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>9 0.073953032 <a title="173-tfidf-9" href="./iccv-2013-Street_View_Motion-from-Structure-from-Motion.html">402 iccv-2013-Street View Motion-from-Structure-from-Motion</a></p>
<p>10 0.068833165 <a title="173-tfidf-10" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>11 0.066827439 <a title="173-tfidf-11" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>12 0.046066996 <a title="173-tfidf-12" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>13 0.043174621 <a title="173-tfidf-13" href="./iccv-2013-Concurrent_Action_Detection_with_Structural_Prediction.html">86 iccv-2013-Concurrent Action Detection with Structural Prediction</a></p>
<p>14 0.042877767 <a title="173-tfidf-14" href="./iccv-2013-Depth_from_Combining_Defocus_and_Correspondence_Using_Light-Field_Cameras.html">108 iccv-2013-Depth from Combining Defocus and Correspondence Using Light-Field Cameras</a></p>
<p>15 0.042827826 <a title="173-tfidf-15" href="./iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</a></p>
<p>16 0.041368585 <a title="173-tfidf-16" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>17 0.040451579 <a title="173-tfidf-17" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<p>18 0.039267506 <a title="173-tfidf-18" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>19 0.036914866 <a title="173-tfidf-19" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>20 0.036042187 <a title="173-tfidf-20" href="./iccv-2013-Robust_Trajectory_Clustering_for_Motion_Segmentation.html">361 iccv-2013-Robust Trajectory Clustering for Motion Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.093), (1, -0.048), (2, -0.016), (3, 0.031), (4, -0.04), (5, 0.036), (6, 0.013), (7, -0.068), (8, 0.033), (9, -0.021), (10, -0.029), (11, -0.127), (12, 0.091), (13, -0.146), (14, -0.08), (15, 0.083), (16, 0.03), (17, -0.004), (18, -0.045), (19, -0.046), (20, -0.039), (21, -0.046), (22, -0.051), (23, -0.045), (24, -0.056), (25, -0.102), (26, -0.103), (27, -0.022), (28, 0.111), (29, -0.003), (30, 0.012), (31, -0.019), (32, 0.02), (33, 0.084), (34, 0.058), (35, 0.025), (36, -0.046), (37, 0.014), (38, 0.025), (39, 0.015), (40, 0.041), (41, 0.066), (42, 0.04), (43, 0.025), (44, -0.027), (45, 0.018), (46, 0.054), (47, 0.019), (48, 0.019), (49, -0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93927711 <a title="173-lsi-1" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>2 0.73358512 <a title="173-lsi-2" href="./iccv-2013-A_Unified_Rolling_Shutter_and_Motion_Blur_Model_for_3D_Visual_Registration.html">32 iccv-2013-A Unified Rolling Shutter and Motion Blur Model for 3D Visual Registration</a></p>
<p>Author: Maxime Meilland, Tom Drummond, Andrew I. Comport</p><p>Abstract: Motion blur and rolling shutter deformations both inhibit visual motion registration, whether it be due to a moving sensor or a moving target. Whilst both deformations exist simultaneously, no models have been proposed to handle them together. Furthermore, neither deformation has been consideredpreviously in the context of monocularfullimage 6 degrees of freedom registration or RGB-D structure and motion. As will be shown, rolling shutter deformation is observed when a camera moves faster than a single pixel in parallax between subsequent scan-lines. Blur is a function of the pixel exposure time and the motion vector. In this paper a complete dense 3D registration model will be derived to accountfor both motion blur and rolling shutter deformations simultaneously. Various approaches will be compared with respect to ground truth and live real-time performance will be demonstratedfor complex scenarios where both blur and shutter deformations are dominant.</p><p>3 0.69362462 <a title="173-lsi-3" href="./iccv-2013-Dynamic_Scene_Deblurring.html">129 iccv-2013-Dynamic Scene Deblurring</a></p>
<p>Author: Tae Hyun Kim, Byeongjoo Ahn, Kyoung Mu Lee</p><p>Abstract: Most conventional single image deblurring methods assume that the underlying scene is static and the blur is caused by only camera shake. In this paper, in contrast to this restrictive assumption, we address the deblurring problem of general dynamic scenes which contain multiple moving objects as well as camera shake. In case of dynamic scenes, moving objects and background have different blur motions, so the segmentation of the motion blur is required for deblurring each distinct blur motion accurately. Thus, we propose a novel energy model designed with the weighted sum of multiple blur data models, which estimates different motion blurs and their associated pixelwise weights, and resulting sharp image. In this framework, the local weights are determined adaptively and get high values when the corresponding data models have high data fidelity. And, the weight information is used for the segmentation of the motion blur. Non-local regularization of weights are also incorporated to produce more reliable segmentation results. A convex optimization-based method is used for the solution of the proposed energy model. Exper- imental results demonstrate that our method outperforms conventional approaches in deblurring both dynamic scenes and static scenes.</p><p>4 0.6787526 <a title="173-lsi-4" href="./iccv-2013-Deblurring_by_Example_Using_Dense_Correspondence.html">103 iccv-2013-Deblurring by Example Using Dense Correspondence</a></p>
<p>Author: Yoav Hacohen, Eli Shechtman, Dani Lischinski</p><p>Abstract: This paper presents a new method for deblurring photos using a sharp reference example that contains some shared content with the blurry photo. Most previous deblurring methods that exploit information from other photos require an accurately registered photo of the same static scene. In contrast, our method aims to exploit reference images where the shared content may have undergone substantial photometric and non-rigid geometric transformations, as these are the kind of reference images most likely to be found in personal photo albums. Our approach builds upon a recent method for examplebased deblurring using non-rigid dense correspondence (NRDC) [11] and extends it in two ways. First, we suggest exploiting information from the reference image not only for blur kernel estimation, but also as a powerful local prior for the non-blind deconvolution step. Second, we introduce a simple yet robust technique for spatially varying blur estimation, rather than assuming spatially uniform blur. Unlike the aboveprevious method, which hasproven successful only with simple deblurring scenarios, we demonstrate that our method succeeds on a variety of real-world examples. We provide quantitative and qualitative evaluation of our method and show that it outperforms the state-of-the-art.</p><p>5 0.65533817 <a title="173-lsi-5" href="./iccv-2013-Forward_Motion_Deblurring.html">174 iccv-2013-Forward Motion Deblurring</a></p>
<p>Author: Shicheng Zheng, Li Xu, Jiaya Jia</p><p>Abstract: We handle a special type of motion blur considering that cameras move primarily forward or backward. Solving this type of blur is of unique practical importance since nearly all car, traffic and bike-mounted cameras follow out-ofplane translational motion. We start with the study of geometric models and analyze the difficulty of existing methods to deal with them. We also propose a solution accounting for depth variation. Homographies associated with different 3D planes are considered and solved for in an optimization framework. Our method is verified on several natural image examples that cannot be satisfyingly dealt with by previous methods.</p><p>6 0.63026369 <a title="173-lsi-6" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>7 0.54828084 <a title="173-lsi-7" href="./iccv-2013-Rolling_Shutter_Stereo.html">363 iccv-2013-Rolling Shutter Stereo</a></p>
<p>8 0.41654265 <a title="173-lsi-8" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<p>9 0.40243766 <a title="173-lsi-9" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>10 0.40191948 <a title="173-lsi-10" href="./iccv-2013-Compensating_for_Motion_during_Direct-Global_Separation.html">82 iccv-2013-Compensating for Motion during Direct-Global Separation</a></p>
<p>11 0.39331222 <a title="173-lsi-11" href="./iccv-2013-Street_View_Motion-from-Structure-from-Motion.html">402 iccv-2013-Street View Motion-from-Structure-from-Motion</a></p>
<p>12 0.38012394 <a title="173-lsi-12" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>13 0.3653056 <a title="173-lsi-13" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<p>14 0.34983236 <a title="173-lsi-14" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>15 0.34738827 <a title="173-lsi-15" href="./iccv-2013-Subpixel_Scanning_Invariant_to_Indirect_Lighting_Using_Quadratic_Code_Length.html">407 iccv-2013-Subpixel Scanning Invariant to Indirect Lighting Using Quadratic Code Length</a></p>
<p>16 0.34589407 <a title="173-lsi-16" href="./iccv-2013-Modeling_the_Calibration_Pipeline_of_the_Lytro_Camera_for_High_Quality_Light-Field_Image_Reconstruction.html">271 iccv-2013-Modeling the Calibration Pipeline of the Lytro Camera for High Quality Light-Field Image Reconstruction</a></p>
<p>17 0.34472495 <a title="173-lsi-17" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>18 0.32767501 <a title="173-lsi-18" href="./iccv-2013-Learning_Slow_Features_for_Behaviour_Analysis.html">243 iccv-2013-Learning Slow Features for Behaviour Analysis</a></p>
<p>19 0.32415724 <a title="173-lsi-19" href="./iccv-2013-Structured_Light_in_Sunlight.html">405 iccv-2013-Structured Light in Sunlight</a></p>
<p>20 0.31905273 <a title="173-lsi-20" href="./iccv-2013-Efficient_Image_Dehazing_with_Boundary_Constraint_and_Contextual_Regularization.html">135 iccv-2013-Efficient Image Dehazing with Boundary Constraint and Contextual Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.063), (7, 0.014), (26, 0.073), (27, 0.011), (31, 0.061), (34, 0.011), (42, 0.075), (48, 0.011), (55, 0.025), (64, 0.063), (73, 0.036), (78, 0.01), (89, 0.136), (96, 0.279), (98, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.77080351 <a title="173-lda-1" href="./iccv-2013-Fluttering_Pattern_Generation_Using_Modified_Legendre_Sequence_for_Coded_Exposure_Imaging.html">173 iccv-2013-Fluttering Pattern Generation Using Modified Legendre Sequence for Coded Exposure Imaging</a></p>
<p>Author: Hae-Gon Jeon, Joon-Young Lee, Yudeog Han, Seon Joo Kim, In So Kweon</p><p>Abstract: Finding a good binary sequence is critical in determining theperformance ofthe coded exposure imaging, butprevious methods mostly rely on a random search for finding the binary codes, which could easily fail to find good long sequences due to the exponentially growing search space. In this paper, we present a new computationally efficient algorithm for generating the binary sequence, which is especially well suited for longer sequences. We show that the concept of the low autocorrelation binary sequence that has been well exploited in the information theory community can be applied for generating the fluttering patterns of the shutter, propose a new measure of a good binary sequence, and present a new algorithm by modifying the Legendre sequence for the coded exposure imaging. Experiments using both synthetic and real data show that our new algorithm consistently generates better binary sequencesfor the coded exposure problem, yielding better deblurring and resolution enhancement results compared to the previous methods for generating the binary codes.</p><p>2 0.72637594 <a title="173-lda-2" href="./iccv-2013-A_New_Adaptive_Segmental_Matching_Measure_for_Human_Activity_Recognition.html">22 iccv-2013-A New Adaptive Segmental Matching Measure for Human Activity Recognition</a></p>
<p>Author: Shahriar Shariat, Vladimir Pavlovic</p><p>Abstract: The problem of human activity recognition is a central problem in many real-world applications. In this paper we propose a fast and effective segmental alignmentbased method that is able to classify activities and interactions in complex environments. We empirically show that such model is able to recover the alignment that leads to improved similarity measures within sequence classes and hence, raises the classification performance. We also apply a bounding technique on the histogram distances to reduce the computation of the otherwise exhaustive search.</p><p>3 0.67017883 <a title="173-lda-3" href="./iccv-2013-Live_Metric_3D_Reconstruction_on_Mobile_Phones.html">254 iccv-2013-Live Metric 3D Reconstruction on Mobile Phones</a></p>
<p>Author: Petri Tanskanen, Kalin Kolev, Lorenz Meier, Federico Camposeco, Olivier Saurer, Marc Pollefeys</p><p>Abstract: unkown-abstract</p><p>4 0.66136694 <a title="173-lda-4" href="./iccv-2013-Correlation_Adaptive_Subspace_Segmentation_by_Trace_Lasso.html">93 iccv-2013-Correlation Adaptive Subspace Segmentation by Trace Lasso</a></p>
<p>Author: Canyi Lu, Jiashi Feng, Zhouchen Lin, Shuicheng Yan</p><p>Abstract: This paper studies the subspace segmentation problem. Given a set of data points drawn from a union of subspaces, the goal is to partition them into their underlying subspaces they were drawn from. The spectral clustering method is used as the framework. It requires to find an affinity matrix which is close to block diagonal, with nonzero entries corresponding to the data point pairs from the same subspace. In this work, we argue that both sparsity and the grouping effect are important for subspace segmentation. A sparse affinity matrix tends to be block diagonal, with less connections between data points from different subspaces. The grouping effect ensures that the highly corrected data which are usually from the same subspace can be grouped together. Sparse Subspace Clustering (SSC), by using ?1-minimization, encourages sparsity for data selection, but it lacks of the grouping effect. On the contrary, Low-RankRepresentation (LRR), by rank minimization, and Least Squares Regression (LSR), by ?2-regularization, exhibit strong grouping effect, but they are short in subset selection. Thus the obtained affinity matrix is usually very sparse by SSC, yet very dense by LRR and LSR. In this work, we propose the Correlation Adaptive Subspace Segmentation (CASS) method by using trace Lasso. CASS is a data correlation dependent method which simultaneously performs automatic data selection and groups correlated data together. It can be regarded as a method which adaptively balances SSC and LSR. Both theoretical and experimental results show the effectiveness of CASS.</p><p>5 0.63744456 <a title="173-lda-5" href="./iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</a></p>
<p>Author: Daozheng Chen, Dhruv Batra, William T. Freeman</p><p>Abstract: Latent variables models have been applied to a number of computer vision problems. However, the complexity of the latent space is typically left as a free design choice. A larger latent space results in a more expressive model, but such models are prone to overfitting and are slower to perform inference with. The goal of this paper is to regularize the complexity of the latent space and learn which hidden states are really relevant for prediction. Specifically, we propose using group-sparsity-inducing regularizers such as ?1-?2 to estimate the parameters of Structured SVMs with unstructured latent variables. Our experiments on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model.</p><p>6 0.5813244 <a title="173-lda-6" href="./iccv-2013-Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.html">438 iccv-2013-Unsupervised Visual Domain Adaptation Using Subspace Alignment</a></p>
<p>7 0.57706749 <a title="173-lda-7" href="./iccv-2013-Style-Aware_Mid-level_Representation_for_Discovering_Visual_Connections_in_Space_and_Time.html">406 iccv-2013-Style-Aware Mid-level Representation for Discovering Visual Connections in Space and Time</a></p>
<p>8 0.57562947 <a title="173-lda-8" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>9 0.5753265 <a title="173-lda-9" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>10 0.57422239 <a title="173-lda-10" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>11 0.57347995 <a title="173-lda-11" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>12 0.5720011 <a title="173-lda-12" href="./iccv-2013-Topology-Constrained_Layered_Tracking_with_Latent_Flow.html">420 iccv-2013-Topology-Constrained Layered Tracking with Latent Flow</a></p>
<p>13 0.57148159 <a title="173-lda-13" href="./iccv-2013-Class-Specific_Simplex-Latent_Dirichlet_Allocation_for_Image_Classification.html">73 iccv-2013-Class-Specific Simplex-Latent Dirichlet Allocation for Image Classification</a></p>
<p>14 0.57046831 <a title="173-lda-14" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>15 0.5703944 <a title="173-lda-15" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>16 0.57014889 <a title="173-lda-16" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>17 0.5701279 <a title="173-lda-17" href="./iccv-2013-Linear_Sequence_Discriminant_Analysis%3A_A_Model-Based_Dimensionality_Reduction_Method_for_Vector_Sequences.html">253 iccv-2013-Linear Sequence Discriminant Analysis: A Model-Based Dimensionality Reduction Method for Vector Sequences</a></p>
<p>18 0.56915492 <a title="173-lda-18" href="./iccv-2013-Real-Time_Articulated_Hand_Pose_Estimation_Using_Semi-supervised_Transductive_Regression_Forests.html">340 iccv-2013-Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests</a></p>
<p>19 0.56901062 <a title="173-lda-19" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>20 0.56890714 <a title="173-lda-20" href="./iccv-2013-Group_Sparsity_and_Geometry_Constrained_Dictionary_Learning_for_Action_Recognition_from_Depth_Maps.html">188 iccv-2013-Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
