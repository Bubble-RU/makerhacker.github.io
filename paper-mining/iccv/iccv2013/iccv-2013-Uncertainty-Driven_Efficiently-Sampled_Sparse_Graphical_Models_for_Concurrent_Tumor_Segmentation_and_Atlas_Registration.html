<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-432" href="#">iccv2013-432</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</h1>
<br/><p>Source: <a title="iccv-2013-432-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Parisot_Uncertainty-Driven_Efficiently-Sampled_Sparse_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Sarah Parisot, William Wells_III, Stéphane Chemouny, Hugues Duffau, Nikos Paragios</p><p>Abstract: Graph-based methods have become popular in recent years and have successfully addressed tasks like segmentation and deformable registration. Their main strength is optimality of the obtained solution while their main limitation is the lack of precision due to the grid-like representations and the discrete nature of the quantized search space. In this paper we introduce a novel approach for combined segmentation/registration of brain tumors that adapts graph and sampling resolution according to the image content. To this end we estimate the segmentation and registration marginals towards adaptive graph resolution and intelligent definition of the search space. This information is considered in a hierarchical framework where uncertainties are propagated in a natural manner. State of the art results in the joint segmentation/registration of brain images with low-grade gliomas demonstrate the potential of our approach.</p><p>Reference: <a title="iccv-2013-432-reference" href="../iccv2013_reference/iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper we introduce a novel approach for combined segmentation/registration of brain tumors that adapts graph and sampling resolution according to the image content. [sent-3, score-0.457]
</p><p>2 To this end we estimate the segmentation and registration marginals towards adaptive graph resolution and intelligent definition of the search space. [sent-4, score-1.058]
</p><p>3 This information is considered in a hierarchical framework where uncertainties are propagated in a natural manner. [sent-5, score-0.176]
</p><p>4 Introduction Combined atlas based tumor segmentation and registration is an active research field. [sent-8, score-1.232]
</p><p>5 In [11] a discrete formulation was proposed for one-shot atlas-based registration and segmentation of brain tumors. [sent-10, score-0.897]
</p><p>6 sparse quantization of the search space, (ii) the constraints on the form of the graph structure, the number of nodes and their connectivity in order to keep the computational burden manageable. [sent-13, score-0.189]
</p><p>7 Despite the enormous amount of work in segmentation and registration, estimating the uncertainty in the result has little prior work. [sent-14, score-0.339]
</p><p>8 Early work on point-based registration using the iterate closed point algorithm [13, 16] have associated the contribution of the sam-  ples in the matching process according to their matching uncertainty. [sent-17, score-0.459]
</p><p>9 This idea was further explored in the context of segmentation by deformation using implicit shape representations [17] of brain structures as well as more recently in [7] where a statistical interpretation was proposed for voxellike decisions. [sent-18, score-0.458]
</p><p>10 These ideas were explored in [5] towards adaptive sampling of the label space according to the directional uncertainties of the current solution. [sent-20, score-0.377]
</p><p>11 The 641  most closely related work can be found in [5, 11] and in [15] where an alternative method to combine multipleresolution grids in deformable registration was proposed towards content-driven interpolation. [sent-24, score-0.569]
</p><p>12 The proposed hierar-  chical formulation exploits the form of the objective function to determine registration and segmentation uncertainties. [sent-25, score-0.705]
</p><p>13 They are then used to improve the precision of the sampling and determine the resolution of the graph at subsequent finer resolution levels. [sent-26, score-0.401]
</p><p>14 This is achieved with a hierarchical graph where nodes and decisions taken at coarse resolution level are linked and penalize deviations of decision for ”dependent” nodes at the fine resolution level. [sent-27, score-0.726]
</p><p>15 The resulting formulation addresses the two problems in a stochastic manner and deals with one of the most important limitations of discrete methods, that is, adaptive graph partition of the domain and adaptive local quantization of the label space. [sent-28, score-0.313]
</p><p>16 The method was tested with promising results on the segmentation of low grade gliomas. [sent-29, score-0.267]
</p><p>17 Section 2 briefly reviews the concurrent segmentation and registration formulation of [11], while Section 3 focuses on the estimation of uncertainties using the graph beliefs and their propagation to an adaptive hierarchical construction of the combined graphical model. [sent-31, score-1.013]
</p><p>18 Joint  Registration  and  Segmentation  Method Let us consider a target volume V, a subject featuring a tumor, and a healthy atlas A, defined on the domain Ω. [sent-34, score-0.216]
</p><p>19 In the task of image registration, we aim at finding a trans-  formation 풯 that will map the source image to the target image: 푉 (x) = 퐴(풯 (x))) (1) The presence of the tumor renders the registration more difficult since it has no correspondences in the atlas. [sent-35, score-1.065]
</p><p>20 To deal with this issue, we aim at identifying the tumor area concurrently to the registration, i. [sent-36, score-0.481]
</p><p>21 eW ime adopt a eFrreee 1 F coorrmre sDpoenfodr-s mation approach [14] where a uniformly spaced sparse grid 풢 ⊂ Ω is superimposed to the image. [sent-39, score-0.209]
</p><p>22 The deformation and segmentation ewriimll pboes eevda tlou tatheed i on gtehe. [sent-40, score-0.282]
</p><p>23 grid’s cfoornmtroalti points, then evaluated on the whole image domain by interpolation: 풯 (x)  = x +∑휂(∥x − p∥)dp  (2)  ∑푝∈풢 풮(x) =  ∑휂(∥x − p∥)푠p  (3)  ∑푝∈풢  where dp and 푠p are node p’s displacement vector and segmentation label respectively, and 휂(. [sent-41, score-0.484]
</p><p>24 ) is the projection function defining the influence of each grid control point over the image’s voxels. [sent-42, score-0.177]
</p><p>25 In order to estimate the optimal segmentation map 풮(x) andI nde ofrodremra totio esnt ifmiealdte e풯 th (xe) o pitni a one sghmoetn optimization, we adopt a drmisacrteioten fMiealdrk 풯ov ( R)a innd aom on eF siehldot (oMptRimFi)z approach [11]. [sent-43, score-0.272]
</p><p>26 Let us consider a predefined discrete displacement set = {d1, . [sent-44, score-0.204]
</p><p>27 To each grid node p, we seek to assign a 풟labe =l 푙푝 ∈ ℒ = {}1. [sent-47, score-0.207]
</p><p>28 I cno tmhepu ttuem ao sri area, we ceaansnuorte rely on wtheise similarity measure due to the absence of correspondences between tumor and healthy tissue. [sent-55, score-0.597]
</p><p>29 The tumor 푝푡푚 and background 푝푏푔 probabilities have been evaluated a priori via boosting [4]. [sent-59, score-0.481]
</p><p>30 In [11] a compositional approach was considered where several MRF optimizations are performed at coarse to fine grid resolutions. [sent-61, score-0.209]
</p><p>31 d Eventually, fiteheld grid’s resolution is refined, and another series of optimizations are performed at a higher resolution. [sent-63, score-0.177]
</p><p>32 Due to the joint registration and segmentation space, the computational complexity ofthe method increases quadratically at fine resolution levels, increasing running time while decreasing guarantees on the optimality of the obtained solution. [sent-64, score-0.847]
</p><p>33 In practice, the use of high-resolution grids (that is a necessity for precise segmentation) is prohibited, while at the same time sampling of the deformation space becomes an issue when seeking high resolution deformations. [sent-65, score-0.385]
</p><p>34 Both issues can be addressed using uncertainties towards sparse graphs in terms of structure and directional sampling of the deformation space. [sent-66, score-0.333]
</p><p>35 Uncertainty Driven Discrete Sampling We now describe the content driven grid construction and segmentation propagation. [sent-68, score-0.417]
</p><p>36 t cOu∈r goal is to define the optimal displacement set for registration as well as the resolution of the next grid level 풢푗+1 of maximal resolution r2e푀so u−ti 1o n× o f2 t푁he − ne 1x × g i2d푃 l −vel 1. [sent-72, score-1.149]
</p><p>37 sis W teha dte efainceh anno idnet cj ghraasp a direct spatial correspondence pj+1 ∈ 풢푗+1 . [sent-74, score-0.242]
</p><p>38 [1]) is defin∈ed 풢 by connecting cj to pj+1 a풩nd(. [sent-77, score-0.242]
</p><p>39 For our problem, we impose a non optimal label 푘 to the control point cj to evaluate the cost of a label swap:  Ψ푐푗,푘,푖 =푙, m푙푐푗in=푘퐸푟푒푔,푠푒푔(l∣푉,퐴 ∘ 풯푖−1)  (9)  A label 푘 belonging to the same segmentation class  푠푙푐표푗푝푡  푠푘 = represents a local perturbation from the optimal displacement. [sent-81, score-0.683]
</p><p>40 The directions towards which the energy weakly varies represent the local anisotropy and uncertainty of the registration. [sent-82, score-0.201]
</p><p>41 Indeed, a small variation of the energy suggest that the labels are almost as likely, while a strong  Figure 1: Visual representation of the grid refinement from level j (left) to level j+1 (right). [sent-83, score-0.355]
</p><p>42 Grid resampling: the nodes that have direct correspondences appear in white, and the  new nodes and edges are red. [sent-84, score-0.326]
</p><p>43 The edges connecting the 2 grids represent the nodes ’ neighborhood. [sent-85, score-0.193]
</p><p>44 We adopt an intelligent displacement sampling based on the density’s covariance scale and main axes, that indicates the directions where the uncertainty is maximum and a thorough sampling is necessary. [sent-89, score-0.516]
</p><p>45 Note that for the tumor label, and when the parameter 훼 is low (dominant segmentation term), the local likelihoods are not ofinterest since the registration is mostly driven by the pairwise cost. [sent-90, score-1.206]
</p><p>46 The next step is to define the grid sampling and segmentation propagation at the next resolution level. [sent-91, score-0.586]
</p><p>47 To this end, we call 풢푗+1,푚푎푥 the maximum resolution at level 푗 + 1 waned adellfin 풢e a function 풜푗+1 : 풢푗+1 → {0, 1}, characterizing nthee an foudnec taiocntiv풜a tion. [sent-92, score-0.185]
</p><p>48 The first term imposes that nodes in 풢푗+1,푚푎푥 that have a direct correspondent cj t∈ n 풢푗,푚푎푥 (풢same spatial coordinates) are activated if their correspondent is (풜푗 (cj ) = 1). [sent-95, score-0.587]
</p><p>49 The remaining ndod ifes th are ceoithrreers apoctnivdaetnetd i fso (r풜 segmentation (퐴푠 (p) = 1) or registration (퐴푟 (p) = 1). [sent-96, score-0.68]
</p><p>50 Given the strong interdependencies between segmentation and registration, a node activated for registration is also activated for segmentation and vice versa. [sent-97, score-1.197]
</p><p>51 The registration activation is based on the local homogeneity of the region reachable by the node. [sent-98, score-0.514]
</p><p>52 15 05 0510 5 (b) Figure 2: Registration uncertainty for one control point: (a) Min marginal values per displacement label (blue: low, red: high energy) and associated covariance matrix centered at the optimal label. [sent-101, score-0.421]
</p><p>53 For all nodes cj ∈ 풢푗, we compute the energy range over all displacement lab∈el 풢s:  푅(cj) =푘∈ℒ,m푠푘a=x푠푙푐표푗푝푡Ψcj,푘,푖−푘∈ℒ,m푠푘i=n푠푙푐표푗푝푡Ψcj,푘,푖 We define the node activation criterion as follows:  (12)  퐴푟(p) = 퐻⎝⎛cj∈∑풩푖(p)푁1푅(cj) − 휇⎠⎞  (13)  where 퐻(. [sent-105, score-0.712]
</p><p>54 ) is the hea⎝viside function, 푁 is the⎠ number of nodes in 풩(p) and 휇 is the mean value of the min marginals range over (alpl )n oanddes 휇 i ins 풢푗 . [sent-106, score-0.254]
</p><p>55 Am enaonde v ailnu 풢푗+1 wei mll i bne m maactrigviantaelds rifa tnhgee mean energy range among dites neighbors is higher than the mean range over all nodes , i. [sent-107, score-0.226]
</p><p>56 Similarly, the node activation for segmentation is guided by the min marginals. [sent-110, score-0.361]
</p><p>57 We rely on the segmentation uncertainty, computed by evaluating the global energy variation when the segmentation label changes. [sent-111, score-0.545]
</p><p>58 We compute  Figure 3: Displacement set resampling for one control point: (a) Original isotropic displacement set. [sent-112, score-0.235]
</p><p>59 (b) Uncertainty driven displacement set, following the brain boundaries. [sent-113, score-0.351]
</p><p>60 the segmentation likelihood for a segmentation label S by marginalizing the max-marginals over all labels:  푃푠푒푔(cj∣푆) =∑푙∑∈ℒ,푠푙=e푆xepx(p−(Ψ−cΨj,c푙,j푡,)푙,푡)  (14)  We exploit the binary labe∑ling to evaluate the node’s segmentation uncertainty as: 푈(cj) = 1− ∣푃푠푒푔(cj ∣푆) − 0. [sent-114, score-0.861]
</p><p>61 5∣  (15)  Using this formulation, 푈(cj) is minimum when the optimal segmentation label is the most likely label, and maxi-  mum when both labels are equally probable. [sent-115, score-0.329]
</p><p>62 If a node’s segmentation is certain, it should be propagated, while an uncertain segmentation should not influence the decisions at the next level. [sent-116, score-0.51]
</p><p>63 The penalty will be important if the segmentation decisions at level 푗 were highly reliable and low otherwise. [sent-118, score-0.303]
</p><p>64 644  The node activation criterion for segmentation relies on this inter levels potential by activating the nodes that are not strongly penalized or equally penalized for both labels:  퐴푠(p) = 퐻⎛⎝? [sent-119, score-0.653]
</p><p>65 This tienr m풢 evacluaante bse tchoen mean segmentation ceo nnofiddeesn icne over all  × ××  nodes connected to p, taking into account the value of the segmentation label. [sent-136, score-0.587]
</p><p>66 It activates nodes whose neighbors’ segmentations are uncertain or if the neighborhood consists of different labels that are equally confident (implying that the node is localized at a tumor’s boundary). [sent-137, score-0.292]
</p><p>67 Eventually, we rewrite the MRF energy at level 푗 and iteration 푖:  퐸푟푒푔,푠푒푔(푙∣푉,퐴 ∘ 풯푖−1,풢푗) =∣풢1푗∣푝∑∈풢푉푝(푙푝∣푉,퐴 ∘ 풯푖−1)  +∑푝∈풢푞∈∑풩(푝)푉푝푞,(푙푝,푙푞) +푝∑∈풢푗푐∈∑풩(푝)푁1푉푢푐푦(푙푐푗−1,푙푝푗)  (18)  where N is the number of nodes in 풢푗−1 in the neighborhwohoedr eo fN Nn oisde th p n∈u 퐺푗 . [sent-138, score-0.242]
</p><p>68 Experimental Validation  Our data set consisted of 102 3D MRI FLAIR volumes of patients featuring low grade gliomas. [sent-140, score-0.209]
</p><p>69 The volumes’ sizes ranged from 256 256 24 to 512 512 33, and resolution ffrroomm 025. [sent-142, score-0.183]
</p><p>70 The healthy brain template for registration was a 3D MRI FLAIR volume of size 256 256 24, tainodn r weasoslu at 3iDon M0. [sent-152, score-0.686]
</p><p>71 In order to preserve the contrast between tumor and background, we opted for a simple regularization method, where all images were set to the same median and interquartile range as the reference template. [sent-158, score-0.481]
</p><p>72 Prior to performing the deformable registration, all volumes were rigidly registered to the healthy template. [sent-159, score-0.208]
</p><p>73 Segmentation prior We constructed the segmentation probability prior using the Gentle adaboost algorithm [4]. [sent-162, score-0.221]
</p><p>74 Implementation Our incremental approach consisted of 4 grid levels and  ××  3 image levels where the resolution of the image increases with the grid’s resolution. [sent-168, score-0.399]
</p><p>75 At the fourth grid level, the image’s resolution remains the same. [sent-169, score-0.294]
</p><p>76 The grid’s resolution was progressively refined from 9 9 5 to 65 65 37. [sent-170, score-0.208]
</p><p>77 015, so that the presence of the tumor has an increasing impact on the registration, and the finest level focuses solely on segmentation. [sent-173, score-0.553]
</p><p>78 This enables to first focus on the registration of the brain’s main structures, when the resolution of the grid and the image is low enough for the presence of the tumor to have a limited impact. [sent-174, score-1.264]
</p><p>79 휆 was set to 20 and relaxed in the tumor area to allow for the strong displacements that can be caused by a tumor. [sent-177, score-0.528]
</p><p>80 The local registration uncertainties are evaluated during the first iteration, where we adopt a dense displacement sampling, with 5 sampling steps in each direction (133 1labels). [sent-181, score-0.86]
</p><p>81 In the following level, we adopt a sparse sampling, the displacement labels being sampled along the uncertainty covariance axes (31 labels). [sent-182, score-0.383]
</p><p>82 In the last  level, the displacement set is simply refined by reducing the maximum displacement, still sampled along the covariance’s main axes. [sent-184, score-0.184]
</p><p>83 [5] shows the percentage of activated nodes with respect to the maximal resolution possible and visual examples are 645  last 2 levels of the incremental approach. [sent-191, score-0.47]
</p><p>84 Nodes are activated in the presence of brain structures and around the tumor boundary, and their number is significantly lower than the total number of potential nodes (20% of activated nodes in the last level). [sent-195, score-1.216]
</p><p>85 The Dice score, false positive rate, true positive rate and mean absolute distance (MAD) between contours were evaluated with respect to the manual segmentations of the tumor and ventricles outside the tumor area. [sent-199, score-0.99]
</p><p>86 [6] shows boxplots of the different segmentation scores for the 3 different methods and registration results are shown in Fig. [sent-201, score-0.732]
</p><p>87 Our method shows equivalent results for both segmentation and registration with a much lower complexity, while a uniform grid of the same complexity yields lower quality registrations and poorly detected tumors. [sent-203, score-0.831]
</p><p>88 Figure 5: Mean percentage of activated nodes per level. [sent-206, score-0.265]
</p><p>89 Discussion In this paper we have proposed a novel stochastic formulation for combined atlas registration and tumor segmentation where the obtained solutions are associated with covariance matrices efficiently determined through the graph  marginals. [sent-208, score-1.383]
</p><p>90 The method explores the registration and segmentation uncertainties towards efficient sampling of the discrete deformation space and for the adaptive piece-wise regular refinement of the grid structure. [sent-209, score-1.268]
</p><p>91 The proposed formulation provides a statistical interpretation of the solution, while preliminary results demonstrate that the performance remains about the same while considering a much smaller content-adaptive finer resolution graph. [sent-210, score-0.197]
</p><p>92 Relying on sparse content adaptive grids can further improve the quality of the results by enabling to reach locally voxel level resolu646  0 0 0. [sent-211, score-0.219]
</p><p>93 Going beyond tumor segmentation, applying such a formulation to atlas-based segmentation is an interesting clinical perspective. [sent-217, score-0.727]
</p><p>94 Dense deformation field estimation for atlasbased segmentation of pathological MR brain images. [sent-228, score-0.429]
</p><p>95 Incorporating parameter uncertainty in bayesian segmentation models: Application to hippocampal subfield volumetry. [sent-272, score-0.339]
</p><p>96 Joint tumor segmentation and dense deformable registration of brain mr images. [sent-302, score-1.379]
</p><p>97 A brain tumor segmentation framework based on outlier detection. [sent-309, score-0.849]
</p><p>98 Image registration based on thin-plate splines and local estimates of anisotropic landmark localization uncertainties. [sent-313, score-0.459]
</p><p>99 Nonrigid registration using free-form deformations: Application to breast mr images. [sent-322, score-0.496]
</p><p>100 An uncertaintydriven hybrid of intensity-based and feature-based registration with application to retinal and lung ct images. [sent-344, score-0.459]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tumor', 0.481), ('registration', 0.459), ('cj', 0.242), ('segmentation', 0.221), ('displacement', 0.159), ('grid', 0.151), ('brain', 0.147), ('uncertainties', 0.145), ('nodes', 0.145), ('resolution', 0.143), ('activated', 0.12), ('uncertainty', 0.118), ('volumes', 0.094), ('miccai', 0.083), ('marginals', 0.08), ('healthy', 0.08), ('voxel', 0.072), ('atlas', 0.071), ('sampling', 0.071), ('dlp', 0.064), ('deformation', 0.061), ('dice', 0.06), ('mad', 0.06), ('adaptive', 0.057), ('node', 0.056), ('energy', 0.055), ('inter', 0.055), ('activation', 0.055), ('boxplots', 0.052), ('flair', 0.052), ('intrasense', 0.052), ('jsrhigh', 0.052), ('jsrlow', 0.052), ('montpellier', 0.052), ('mri', 0.052), ('tumors', 0.052), ('ucy', 0.052), ('resampling', 0.05), ('france', 0.049), ('label', 0.048), ('grids', 0.048), ('displacements', 0.047), ('grade', 0.046), ('tziritas', 0.046), ('covariance', 0.045), ('driven', 0.045), ('discrete', 0.045), ('graph', 0.044), ('deformed', 0.043), ('level', 0.042), ('decisions', 0.04), ('labe', 0.04), ('ranged', 0.04), ('correspondent', 0.04), ('progressively', 0.04), ('paragios', 0.038), ('stochastic', 0.037), ('mr', 0.037), ('necessity', 0.037), ('correspondences', 0.036), ('komodakis', 0.035), ('consisted', 0.035), ('levels', 0.035), ('labels', 0.035), ('deformable', 0.034), ('optimizations', 0.034), ('featuring', 0.034), ('discontinuities', 0.033), ('graphical', 0.033), ('superimposed', 0.032), ('marginalizing', 0.032), ('target', 0.031), ('propagated', 0.031), ('presence', 0.03), ('mrf', 0.03), ('refinement', 0.03), ('concurrent', 0.029), ('min', 0.029), ('statistical', 0.029), ('penalized', 0.029), ('source', 0.028), ('towards', 0.028), ('uncertain', 0.028), ('energies', 0.028), ('potential', 0.028), ('directional', 0.028), ('segmentations', 0.028), ('maximal', 0.027), ('neighbors', 0.026), ('control', 0.026), ('intelligent', 0.026), ('adopt', 0.026), ('segmented', 0.026), ('precise', 0.025), ('refined', 0.025), ('formulation', 0.025), ('optimal', 0.025), ('fine', 0.024), ('seeks', 0.024), ('eventually', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="432-tfidf-1" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>Author: Sarah Parisot, William Wells_III, Stéphane Chemouny, Hugues Duffau, Nikos Paragios</p><p>Abstract: Graph-based methods have become popular in recent years and have successfully addressed tasks like segmentation and deformable registration. Their main strength is optimality of the obtained solution while their main limitation is the lack of precision due to the grid-like representations and the discrete nature of the quantized search space. In this paper we introduce a novel approach for combined segmentation/registration of brain tumors that adapts graph and sampling resolution according to the image content. To this end we estimate the segmentation and registration marginals towards adaptive graph resolution and intelligent definition of the search space. This information is considered in a hierarchical framework where uncertainties are propagated in a natural manner. State of the art results in the joint segmentation/registration of brain images with low-grade gliomas demonstrate the potential of our approach.</p><p>2 0.25392947 <a title="432-tfidf-2" href="./iccv-2013-Stacked_Predictive_Sparse_Coding_for_Classification_of_Distinct_Regions_in_Tumor_Histopathology.html">401 iccv-2013-Stacked Predictive Sparse Coding for Classification of Distinct Regions in Tumor Histopathology</a></p>
<p>Author: Hang Chang, Yin Zhou, Paul Spellman, Bahram Parvin</p><p>Abstract: Image-based classification ofhistology sections, in terms of distinct components (e.g., tumor, stroma, normal), provides a series of indices for tumor composition. Furthermore, aggregation of these indices, from each whole slide image (WSI) in a large cohort, can provide predictive models of the clinical outcome. However, performance of the existing techniques is hindered as a result of large technical variations and biological heterogeneities that are always present in a large cohort. We propose a system that automatically learns a series of basis functions for representing the underlying spatial distribution using stacked predictive sparse decomposition (PSD). The learned representation is then fed into the spatial pyramid matching framework (SPM) with a linear SVM classifier. The system has been evaluated for classification of (a) distinct histological components for two cohorts of tumor types, and (b) colony organization of normal and malignant cell lines in 3D cell culture models. Throughput has been increased through the utility of graphical processing unit (GPU), and evalu- ation indicates a superior performance results, compared with previous research.</p><p>3 0.15679692 <a title="432-tfidf-3" href="./iccv-2013-Automatic_Registration_of_RGB-D_Scans_via_Salient_Directions.html">56 iccv-2013-Automatic Registration of RGB-D Scans via Salient Directions</a></p>
<p>Author: Bernhard Zeisl, Kevin Köser, Marc Pollefeys</p><p>Abstract: We address the problem of wide-baseline registration of RGB-D data, such as photo-textured laser scans without any artificial targets or prediction on the relative motion. Our approach allows to fully automatically register scans taken in GPS-denied environments such as urban canyon, industrial facilities or even indoors. We build upon image features which are plenty, localized well and much more discriminative than geometry features; however, they suffer from viewpoint distortions and request for normalization. We utilize the principle of salient directions present in the geometry and propose to extract (several) directions from the distribution of surface normals or other cues such as observable symmetries. Compared to previous work we pose no requirements on the scanned scene (like containing large textured planes) and can handle arbitrary surface shapes. Rendering the whole scene from these repeatable directions using an orthographic camera generates textures which are identical up to 2D similarity transformations. This ambiguity is naturally handled by 2D features and allows to find stable correspondences among scans. For geometric pose estimation from tentative matches we propose a fast and robust 2 point sample consensus scheme integrating an early rejection phase. We evaluate our approach on different challenging real world scenes.</p><p>4 0.14980492 <a title="432-tfidf-4" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>Author: Jiaolong Yang, Hongdong Li, Yunde Jia</p><p>Abstract: Registration is a fundamental task in computer vision. The Iterative Closest Point (ICP) algorithm is one of the widely-used methods for solving the registration problem. Based on local iteration, ICP is however well-known to suffer from local minima. Its performance critically relies on the quality of initialization, and only local optimality is guaranteed. This paper provides the very first globally optimal solution to Euclidean registration of two 3D pointsets or two 3D surfaces under the L2 error. Our method is built upon ICP, but combines it with a branch-and-bound (BnB) scheme which searches the 3D motion space SE(3) efficiently. By exploiting the special structure of the underlying geometry, we derive novel upper and lower bounds for the ICP error function. The integration of local ICP and global BnB enables the new method to run efficiently in practice, and its optimality is exactly guaranteed. We also discuss extensions, addressing the issue of outlier robustness.</p><p>5 0.13882931 <a title="432-tfidf-5" href="./iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</a></p>
<p>Author: Yen-Lin Chen, Hsiang-Tao Wu, Fuhao Shi, Xin Tong, Jinxiang Chai</p><p>Abstract: This paper presents an automatic and robust approach that accurately captures high-quality 3D facial performances using a single RGBD camera. The key of our approach is to combine the power of automatic facial feature detection and image-based 3D nonrigid registration techniques for 3D facial reconstruction. In particular, we develop a robust and accurate image-based nonrigid registration algorithm that incrementally deforms a 3D template mesh model to best match observed depth image data and important facial features detected from single RGBD images. The whole process is fully automatic and robust because it is based on single frame facial registration framework. The system is flexible because it does not require any strong 3D facial priors such as blendshape models. We demonstrate the power of our approach by capturing a wide range of 3D facial expressions using a single RGBD camera and achieve state-of-the-art accuracy by comparing against alternative methods.</p><p>6 0.13763596 <a title="432-tfidf-6" href="./iccv-2013-A_Generic_Deformation_Model_for_Dense_Non-rigid_Surface_Registration%3A_A_Higher-Order_MRF-Based_Approach.html">16 iccv-2013-A Generic Deformation Model for Dense Non-rigid Surface Registration: A Higher-Order MRF-Based Approach</a></p>
<p>7 0.13430548 <a title="432-tfidf-7" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>8 0.13293046 <a title="432-tfidf-8" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>9 0.11544882 <a title="432-tfidf-9" href="./iccv-2013-Elastic_Fragments_for_Dense_Scene_Reconstruction.html">139 iccv-2013-Elastic Fragments for Dense Scene Reconstruction</a></p>
<p>10 0.11441527 <a title="432-tfidf-10" href="./iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</a></p>
<p>11 0.11423044 <a title="432-tfidf-11" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<p>12 0.10712317 <a title="432-tfidf-12" href="./iccv-2013-Geometric_Registration_Based_on_Distortion_Estimation.html">183 iccv-2013-Geometric Registration Based on Distortion Estimation</a></p>
<p>13 0.10343806 <a title="432-tfidf-13" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>14 0.10117516 <a title="432-tfidf-14" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>15 0.097022295 <a title="432-tfidf-15" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<p>16 0.092564672 <a title="432-tfidf-16" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>17 0.091597736 <a title="432-tfidf-17" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>18 0.090388246 <a title="432-tfidf-18" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>19 0.089835472 <a title="432-tfidf-19" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>20 0.088281453 <a title="432-tfidf-20" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.191), (1, -0.083), (2, -0.009), (3, -0.004), (4, 0.012), (5, 0.034), (6, -0.048), (7, 0.03), (8, 0.052), (9, -0.093), (10, -0.053), (11, 0.079), (12, 0.023), (13, 0.065), (14, 0.077), (15, 0.065), (16, 0.035), (17, 0.004), (18, -0.026), (19, -0.059), (20, 0.075), (21, 0.032), (22, -0.024), (23, 0.098), (24, -0.051), (25, -0.088), (26, -0.007), (27, 0.078), (28, 0.033), (29, 0.031), (30, 0.083), (31, -0.12), (32, 0.109), (33, -0.027), (34, 0.008), (35, -0.059), (36, -0.034), (37, 0.114), (38, 0.123), (39, 0.205), (40, 0.135), (41, 0.124), (42, -0.051), (43, -0.021), (44, 0.01), (45, -0.083), (46, -0.021), (47, 0.062), (48, -0.055), (49, -0.125)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93788016 <a title="432-lsi-1" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>Author: Sarah Parisot, William Wells_III, Stéphane Chemouny, Hugues Duffau, Nikos Paragios</p><p>Abstract: Graph-based methods have become popular in recent years and have successfully addressed tasks like segmentation and deformable registration. Their main strength is optimality of the obtained solution while their main limitation is the lack of precision due to the grid-like representations and the discrete nature of the quantized search space. In this paper we introduce a novel approach for combined segmentation/registration of brain tumors that adapts graph and sampling resolution according to the image content. To this end we estimate the segmentation and registration marginals towards adaptive graph resolution and intelligent definition of the search space. This information is considered in a hierarchical framework where uncertainties are propagated in a natural manner. State of the art results in the joint segmentation/registration of brain images with low-grade gliomas demonstrate the potential of our approach.</p><p>2 0.67407018 <a title="432-lsi-2" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>Author: Jiaolong Yang, Hongdong Li, Yunde Jia</p><p>Abstract: Registration is a fundamental task in computer vision. The Iterative Closest Point (ICP) algorithm is one of the widely-used methods for solving the registration problem. Based on local iteration, ICP is however well-known to suffer from local minima. Its performance critically relies on the quality of initialization, and only local optimality is guaranteed. This paper provides the very first globally optimal solution to Euclidean registration of two 3D pointsets or two 3D surfaces under the L2 error. Our method is built upon ICP, but combines it with a branch-and-bound (BnB) scheme which searches the 3D motion space SE(3) efficiently. By exploiting the special structure of the underlying geometry, we derive novel upper and lower bounds for the ICP error function. The integration of local ICP and global BnB enables the new method to run efficiently in practice, and its optimality is exactly guaranteed. We also discuss extensions, addressing the issue of outlier robustness.</p><p>3 0.67008895 <a title="432-lsi-3" href="./iccv-2013-A_Generic_Deformation_Model_for_Dense_Non-rigid_Surface_Registration%3A_A_Higher-Order_MRF-Based_Approach.html">16 iccv-2013-A Generic Deformation Model for Dense Non-rigid Surface Registration: A Higher-Order MRF-Based Approach</a></p>
<p>Author: Yun Zeng, Chaohui Wang, Xianfeng Gu, Dimitris Samaras, Nikos Paragios</p><p>Abstract: We propose a novel approach for dense non-rigid 3D surface registration, which brings together Riemannian geometry and graphical models. To this end, we first introduce a generic deformation model, called Canonical Distortion Coefficients (CDCs), by characterizing the deformation of every point on a surface using the distortions along its two principle directions. This model subsumes the deformation groups commonly used in surface registration such as isometry and conformality, and is able to handle more complex deformations. We also derive its discrete counterpart which can be computed very efficiently in a closed form. Based on these, we introduce a higher-order Markov Random Field (MRF) model which seamlessly integrates our deformation model and a geometry/texture similarity metric. Then we jointly establish the optimal correspondences for all the points via maximum a posteriori (MAP) inference. Moreover, we develop a parallel optimization algorithm to efficiently perform the inference for the proposed higher-order MRF model. The resulting registration algorithm outperforms state-of-the-art methods in both dense non-rigid 3D surface registration and tracking.</p><p>4 0.63026124 <a title="432-lsi-4" href="./iccv-2013-Geometric_Registration_Based_on_Distortion_Estimation.html">183 iccv-2013-Geometric Registration Based on Distortion Estimation</a></p>
<p>Author: Wei Zeng, Mayank Goswami, Feng Luo, Xianfeng Gu</p><p>Abstract: Surface registration plays a fundamental role in many applications in computer vision and aims at finding a oneto-one correspondence between surfaces. Conformal mapping based surface registration methods conformally map 2D/3D surfaces onto 2D canonical domains and perform the matching on the 2D plane. This registration framework reduces dimensionality, and the result is intrinsic to Riemannian metric and invariant under isometric deformation. However, conformal mapping will be affected by inconsistent boundaries and non-isometric deformations of surfaces. In this work, we quantify the effects of boundary variation and non-isometric deformation to conformal mappings, and give the theoretical upper bounds for the distortions of conformal mappings under these two factors. Besides giving the thorough theoretical proofs of the theorems, we verified them by concrete experiments using 3D human facial scans with dynamic expressions and varying boundaries. Furthermore, we used the distortion estimates for reducing search range in feature matching of surface registration applications. The experimental results are consistent with the theoreticalpredictions and also demonstrate the performance improvements in feature tracking.</p><p>5 0.58700395 <a title="432-lsi-5" href="./iccv-2013-Multiple_Non-rigid_Surface_Detection_and_Registration.html">283 iccv-2013-Multiple Non-rigid Surface Detection and Registration</a></p>
<p>Author: Yi Wu, Yoshihisa Ijiri, Ming-Hsuan Yang</p><p>Abstract: Detecting and registering nonrigid surfaces are two important research problems for computer vision. Much work has been done with the assumption that there exists only one instance in the image. In this work, we propose an algorithm that detects and registers multiple nonrigid instances of given objects in a cluttered image. Specifically, after we use low level feature points to obtain the initial matches between templates and the input image, a novel high-order affinity graph is constructed to model the consistency of local topology. A hierarchical clustering approach is then used to locate the nonrigid surfaces. To remove the outliers in the cluster, we propose a deterministic annealing approach based on the Thin Plate Spline (TPS) model. The proposed method achieves high accuracy even when the number of outliers is nineteen times larger than the inliers. As the matches may appear sparsely in each instance, we propose a TPS based match growing approach to propagate the matches. Finally, an approach that fuses feature and appearance information is proposed to register each nonrigid surface. Extensive experiments and evaluations demonstrate that the proposed algorithm achieves promis- ing results in detecting and registering multiple non-rigid surfaces in a cluttered scene.</p><p>6 0.57744598 <a title="432-lsi-6" href="./iccv-2013-Volumetric_Semantic_Segmentation_Using_Pyramid_Context_Features.html">447 iccv-2013-Volumetric Semantic Segmentation Using Pyramid Context Features</a></p>
<p>7 0.5677157 <a title="432-lsi-7" href="./iccv-2013-Elastic_Fragments_for_Dense_Scene_Reconstruction.html">139 iccv-2013-Elastic Fragments for Dense Scene Reconstruction</a></p>
<p>8 0.52843219 <a title="432-lsi-8" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>9 0.52537328 <a title="432-lsi-9" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>10 0.50330824 <a title="432-lsi-10" href="./iccv-2013-Progressive_Multigrid_Eigensolvers_for_Multiscale_Spectral_Segmentation.html">329 iccv-2013-Progressive Multigrid Eigensolvers for Multiscale Spectral Segmentation</a></p>
<p>11 0.50090015 <a title="432-lsi-11" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>12 0.49726108 <a title="432-lsi-12" href="./iccv-2013-Stacked_Predictive_Sparse_Coding_for_Classification_of_Distinct_Regions_in_Tumor_Histopathology.html">401 iccv-2013-Stacked Predictive Sparse Coding for Classification of Distinct Regions in Tumor Histopathology</a></p>
<p>13 0.49227586 <a title="432-lsi-13" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>14 0.490753 <a title="432-lsi-14" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>15 0.48529053 <a title="432-lsi-15" href="./iccv-2013-Automatic_Registration_of_RGB-D_Scans_via_Salient_Directions.html">56 iccv-2013-Automatic Registration of RGB-D Scans via Salient Directions</a></p>
<p>16 0.47136158 <a title="432-lsi-16" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<p>17 0.43711641 <a title="432-lsi-17" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>18 0.42530882 <a title="432-lsi-18" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>19 0.4251824 <a title="432-lsi-19" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>20 0.42015225 <a title="432-lsi-20" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.043), (7, 0.011), (12, 0.011), (26, 0.11), (27, 0.01), (28, 0.252), (31, 0.034), (40, 0.017), (42, 0.079), (48, 0.011), (64, 0.034), (73, 0.067), (89, 0.208), (95, 0.012), (98, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81618804 <a title="432-lda-1" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>Author: Sarah Parisot, William Wells_III, Stéphane Chemouny, Hugues Duffau, Nikos Paragios</p><p>Abstract: Graph-based methods have become popular in recent years and have successfully addressed tasks like segmentation and deformable registration. Their main strength is optimality of the obtained solution while their main limitation is the lack of precision due to the grid-like representations and the discrete nature of the quantized search space. In this paper we introduce a novel approach for combined segmentation/registration of brain tumors that adapts graph and sampling resolution according to the image content. To this end we estimate the segmentation and registration marginals towards adaptive graph resolution and intelligent definition of the search space. This information is considered in a hierarchical framework where uncertainties are propagated in a natural manner. State of the art results in the joint segmentation/registration of brain images with low-grade gliomas demonstrate the potential of our approach.</p><p>2 0.75162566 <a title="432-lda-2" href="./iccv-2013-Event_Detection_in_Complex_Scenes_Using_Interval_Temporal_Constraints.html">146 iccv-2013-Event Detection in Complex Scenes Using Interval Temporal Constraints</a></p>
<p>Author: Yifan Zhang, Qiang Ji, Hanqing Lu</p><p>Abstract: In complex scenes with multiple atomic events happening sequentially or in parallel, detecting each individual event separately may not always obtain robust and reliable result. It is essential to detect them in a holistic way which incorporates the causality and temporal dependency among them to compensate the limitation of current computer vision techniques. In this paper, we propose an interval temporal constrained dynamic Bayesian network to extendAllen ’s interval algebra network (IAN) [2]from a deterministic static model to a probabilistic dynamic system, which can not only capture the complex interval temporal relationships, but also model the evolution dynamics and handle the uncertainty from the noisy visual observation. In the model, the topology of the IAN on each time slice and the interlinks between the time slices are discovered by an advanced structure learning method. The duration of the event and the unsynchronized time lags between two correlated event intervals are captured by a duration model, so that we can better determine the temporal boundary of the event. Empirical results on two real world datasets show the power of the proposed interval temporal constrained model.</p><p>3 0.71369958 <a title="432-lda-3" href="./iccv-2013-Hierarchical_Data-Driven_Descent_for_Efficient_Optimal_Deformation_Estimation.html">196 iccv-2013-Hierarchical Data-Driven Descent for Efficient Optimal Deformation Estimation</a></p>
<p>Author: Yuandong Tian, Srinivasa G. Narasimhan</p><p>Abstract: Real-world surfaces such as clothing, water and human body deform in complex ways. The image distortions observed are high-dimensional and non-linear, making it hard to estimate these deformations accurately. The recent datadriven descent approach [17] applies Nearest Neighbor estimators iteratively on a particular distribution of training samples to obtain a globally optimal and dense deformation field between a template and a distorted image. In this work, we develop a hierarchical structure for the Nearest Neighbor estimators, each of which can have only a local image support. We demonstrate in both theory and practice that this algorithm has several advantages over the nonhierarchical version: it guarantees global optimality with significantly fewer training samples, is several orders faster, provides a metric to decide whether a given image is “hard” (or “easy ”) requiring more (or less) samples, and can handle more complex scenes that include both global motion and local deformation. The proposed algorithm successfully tracks a broad range of non-rigid scenes including water, clothing, and medical images, and compares favorably against several other deformation estimation and tracking approaches that do not provide optimality guarantees.</p><p>4 0.70619923 <a title="432-lda-4" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>Author: Manjunath Narayana, Allen Hanson, Erik Learned-Miller</p><p>Abstract: In moving camera videos, motion segmentation is commonly performed using the image plane motion of pixels, or optical flow. However, objects that are at different depths from the camera can exhibit different optical flows even if they share the same real-world motion. This can cause a depth-dependent segmentation of the scene. Our goal is to develop a segmentation algorithm that clusters pixels that have similar real-world motion irrespective of their depth in the scene. Our solution uses optical flow orientations instead of the complete vectors and exploits the well-known property that under camera translation, optical flow orientations are independent of object depth. We introduce a probabilistic model that automatically estimates the number of observed independent motions and results in a labeling that is consistent with real-world motion in the scene. The result of our system is that static objects are correctly identified as one segment, even if they are at different depths. Color features and information from previous frames in the video sequence are used to correct occasional errors due to the orientation-based segmentation. We present results on more than thirty videos from different benchmarks. The system is particularly robust on complex background scenes containing objects at significantly different depths.</p><p>5 0.70484298 <a title="432-lda-5" href="./iccv-2013-Image_Guided_Depth_Upsampling_Using_Anisotropic_Total_Generalized_Variation.html">209 iccv-2013-Image Guided Depth Upsampling Using Anisotropic Total Generalized Variation</a></p>
<p>Author: David Ferstl, Christian Reinbacher, Rene Ranftl, Matthias Ruether, Horst Bischof</p><p>Abstract: In this work we present a novel method for the challenging problem of depth image upsampling. Modern depth cameras such as Kinect or Time of Flight cameras deliver dense, high quality depth measurements but are limited in their lateral resolution. To overcome this limitation we formulate a convex optimization problem using higher order regularization for depth image upsampling. In this optimization an anisotropic diffusion tensor, calculated from a high resolution intensity image, is used to guide the upsampling. We derive a numerical algorithm based on a primaldual formulation that is efficiently parallelized and runs at multiple frames per second. We show that this novel upsampling clearly outperforms state of the art approaches in terms of speed and accuracy on the widely used Middlebury 2007 datasets. Furthermore, we introduce novel datasets with highly accurate groundtruth, which, for the first time, enable to benchmark depth upsampling methods using real sensor data.</p><p>6 0.70394117 <a title="432-lda-6" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>7 0.70136392 <a title="432-lda-7" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>8 0.70114803 <a title="432-lda-8" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>9 0.69950849 <a title="432-lda-9" href="./iccv-2013-DCSH_-_Matching_Patches_in_RGBD_Images.html">101 iccv-2013-DCSH - Matching Patches in RGBD Images</a></p>
<p>10 0.69929087 <a title="432-lda-10" href="./iccv-2013-Partial_Enumeration_and_Curvature_Regularization.html">309 iccv-2013-Partial Enumeration and Curvature Regularization</a></p>
<p>11 0.69837224 <a title="432-lda-11" href="./iccv-2013-Fast_Direct_Super-Resolution_by_Simple_Functions.html">156 iccv-2013-Fast Direct Super-Resolution by Simple Functions</a></p>
<p>12 0.69803172 <a title="432-lda-12" href="./iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</a></p>
<p>13 0.69790417 <a title="432-lda-13" href="./iccv-2013-Symbiotic_Segmentation_and_Part_Localization_for_Fine-Grained_Categorization.html">411 iccv-2013-Symbiotic Segmentation and Part Localization for Fine-Grained Categorization</a></p>
<p>14 0.69769067 <a title="432-lda-14" href="./iccv-2013-Temporally_Consistent_Superpixels.html">414 iccv-2013-Temporally Consistent Superpixels</a></p>
<p>15 0.69750291 <a title="432-lda-15" href="./iccv-2013-Data-Driven_3D_Primitives_for_Single_Image_Understanding.html">102 iccv-2013-Data-Driven 3D Primitives for Single Image Understanding</a></p>
<p>16 0.6967237 <a title="432-lda-16" href="./iccv-2013-Modeling_Self-Occlusions_in_Dynamic_Shape_and_Appearance_Tracking.html">270 iccv-2013-Modeling Self-Occlusions in Dynamic Shape and Appearance Tracking</a></p>
<p>17 0.69669974 <a title="432-lda-17" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>18 0.69628412 <a title="432-lda-18" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>19 0.69624066 <a title="432-lda-19" href="./iccv-2013-Exploiting_Reflection_Change_for_Automatic_Reflection_Removal.html">151 iccv-2013-Exploiting Reflection Change for Automatic Reflection Removal</a></p>
<p>20 0.69573927 <a title="432-lda-20" href="./iccv-2013-Shape_Anchors_for_Data-Driven_Multi-view_Reconstruction.html">387 iccv-2013-Shape Anchors for Data-Driven Multi-view Reconstruction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
