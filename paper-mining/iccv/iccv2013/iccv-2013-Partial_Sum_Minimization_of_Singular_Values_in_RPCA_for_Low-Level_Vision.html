<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-310" href="#">iccv2013-310</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</h1>
<br/><p>Source: <a title="iccv-2013-310-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Oh_Partial_Sum_Minimization_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Tae-Hyun Oh, Hyeongwoo Kim, Yu-Wing Tai, Jean-Charles Bazin, In So Kweon</p><p>Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values. The proposed objective function implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that our approach performs better than conventional rank minimization when the number of samples is deficient, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, photometric stereo and image alignment, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.</p><p>Reference: <a title="iccv-2013-310-reference" href="../iccv2013_reference/iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. [sent-2, score-0.461]
</p><p>2 Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. [sent-3, score-0.954]
</p><p>3 This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. [sent-4, score-0.393]
</p><p>4 In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values. [sent-5, score-0.425]
</p><p>5 The proposed objective function implicitly encourages the target rank constraint in rank minimization. [sent-6, score-0.858]
</p><p>6 Our experimental analyses show that our approach performs better than conventional rank minimization when the number of samples is deficient, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. [sent-7, score-0.572]
</p><p>7 high dynamic range imaging, photometric stereo and image alignment, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method. [sent-10, score-0.996]
</p><p>8 Introduction Robust Principal Component Analysis (RPCA) [5, 3] aims to recover a low-rank matrix A ∈ Rm×n, from corrupted oorb esceorvvaetrio ans lo wO- =ran Ak m+a Etri, xw Aher ∈e E R ∈ Rm×n reprerseupnttse errors vwaitthio arbitrary magnitude earned E Ed∈i str Ribution. [sent-12, score-0.099]
</p><p>9 The rank minimization approach [21, 23, 3, 4] assumes E is sparse in its distribution and formulates the problem as:  argAm,Ein ? [sent-13, score-0.463]
</p><p>10 Yet, when the number of samples in O is very limited, we observe that the unique solution of Eq. [sent-39, score-0.096]
</p><p>11 For instance, in the photometric stereo problem [25], the solution of A might have a rank lower  than the theoretical rank of 3. [sent-42, score-1.026]
</p><p>12 For example, in High Dynamic Range (HDR) context, often only 2-4 differently exposed images are captured and photometric stereo requires only 3 input images in theory. [sent-44, score-0.339]
</p><p>13 In this paper, based on the prior knowledge about the rank of A, we propose an alternative objective function which minimizes the partial sum of singular values of A: argAm,Ein  ? [sent-45, score-0.679]
</p><p>14 O = A + E,  (2) where N is the target rank of A which can be derived from problem definition, e. [sent-50, score-0.395]
</p><p>15 N = 1 for background subtraction, N = 3 for photometric stereo. [sent-52, score-0.221]
</p><p>16 (2) minimizes the rank of residual errors of A, instead of the nuclear norm. [sent-54, score-0.474]
</p><p>17 (2) encourages the resulting low-rank matrix to have the rank close to N even with deficient observations. [sent-57, score-0.518]
</p><p>18 HDR imaging, photometric stereo, and image alignment, where the theoretical rank of A is known and the number of observations is limited. [sent-60, score-0.578]
</p><p>19 (2), converges to a solution more robust to outliers than the solution obtained by the conventional objective function in Eq. [sent-62, score-0.314]
</p><p>20 (1) in rank minimization, when the number of observations is limited. [sent-63, score-0.391]
</p><p>21 [23] suggested  145  In short summary, our contributions are as follows: • We present a partial sum objective function and its corresponding ma pianritmiaizla sutiomn o mbjeetchtiovde fo furn RctPiConA a. [sent-70, score-0.187]
</p><p>22 • We empirically study the partial sum objective functWioen amndp rciclaaiml y th stautd iyt outperforms mcon ovbejnectiotinveal ruannckminimization when the number of observed samples is very limited. [sent-71, score-0.224]
</p><p>23 Early works in RPCA tried to reduce the effects of outliers  by random sampling [10], robust M-estimator [5, 6], or alternating minimization [18] to identify outliers or to penalize data with large errors. [sent-79, score-0.284]
</p><p>24 Recent advances in RPCA showed that the heuristic nuclear norm solution [21, 23, 3], which minimizes the rank of the data matrix, converges to a solution which is robust to sparse outliers. [sent-81, score-0.716]
</p><p>25 Among them, the inexact augmented Lagrange multiplier (ALM) [19] has shown to be good in terms of computationally efficiency. [sent-98, score-0.096]
</p><p>26 The robustness and scalability of the rank minimization algorithm for RPCA [3, 19, 24] have inspired many applications in computer vision, such as background subtraction [3], image and video restoration [16], image alignment [20], regular texture analysis [26], and robust photometric stereo [25]. [sent-99, score-0.873]
</p><p>27 As briefly mentioned in the introduction, in some applications, such as background subtraction [3] and photometric stereo [25], the rank of clean data can be determined by the problem definition. [sent-101, score-0.748]
</p><p>28 In practice, rank minimization proposed by Cand e´s et al. [sent-102, score-0.453]
</p><p>29 [3] is general in the sense that it does not require to know a priori the rank of clean data. [sent-103, score-0.384]
</p><p>30 The success of rank minimization based RPCA comes from the blessing of dimensionality [8, 23], implying large amount of observations. [sent-104, score-0.474]
</p><p>31 correct samples might be considered as outliers and vice versa. [sent-107, score-0.104]
</p><p>32 The impetus of this work is to introduce an alternative objective function that can efficiently deal with deficient examples in rank minimization problem. [sent-108, score-0.584]
</p><p>33 Seeing the limitation of rank minimization as an addendum, the proposed alternative objective function can control the lower bound of the rank with a simple and efficient minimizer. [sent-109, score-0.82]
</p><p>34 We demonstrate the effectiveness of our proposed objective function through thoughtful experiments. [sent-110, score-0.104]
</p><p>35 Partial Sum Minimization by Partial Singular Value Thresholding Operator Our partial sum objective function in Eq. [sent-112, score-0.187]
</p><p>36 According to a recent development of alternating direction minimization [19], Eq. [sent-124, score-0.122]
</p><p>37 This is not equivalent to the exact minimization, but in practice the converged solution is very close to the solution of the original problem while still satisfying the constraints. [sent-126, score-0.188]
</p><p>38 (5) can be re-written in the form of the following minimization problem:  argXmin21? [sent-156, score-0.092]
</p><p>39 Notice that the proposed PSVT operator provides the closed-form solution of the sort of Eq. [sent-162, score-0.098]
</p><p>40 (o7) c lisa a lyow PS-VdiTm,e wnshioenna τl projection oopf Ytim kanlo swolnu as nsi on-f gular value projection [15] which enforces the target rank constraint through projection. [sent-168, score-0.43]
</p><p>41 When σi < τ for 1 ≤ i≤ N, conventional SVT [2] projects σi to zero resulting ≤in a more deficient rank of A than the target rank while PSVT does not. [sent-169, score-0.868]
</p><p>42 Hence, PSVT implicitly encourages the resulting matrix A to meet the target rank even when all the σi are small. [sent-170, score-0.481]
</p><p>43 Yet, PSVT monotonically decreases the value −  Algorithm 1 Partial sum of singular values minimization via the ALM method  via  the  ALM  method  Input : O ∈ Rm×n, λ > 0, the constraint rank N. [sent-174, score-0.701]
</p><p>44 a sets in the contexts of HDR, photometric stereo and batch image alignment. [sent-220, score-0.367]
</p><p>45 Synthetic Dataset We compare our method with RPCA on synthetic data for success ratio and convergence behaviors. [sent-224, score-0.168]
</p><p>46 To synthesize a ground-truth low-rank matrix AGT ∈ Rm×n of rank N, we perform a linear combination of N∈ arbitrary orthogonal basis vector. [sent-225, score-0.386]
</p><p>47 the number of observations decreases), the success ratio of RPCA decreases more rapidly than our method. [sent-259, score-0.174]
</p><p>48 Additional results for the other rank cases and the varying column n cases can be found in the supplementary material. [sent-261, score-0.334]
</p><p>49 We notice that, even though we use the same parameter λ in all the experiments varying the matrix size, rank and corruption ratio, our method shows a more broad success range compared to RPCA. [sent-262, score-0.483]
</p><p>50 Comparison with Other Approaches We provide another comparisons with the singular value projection (SVP) as a baseline method and a low-rank matrix approximation  approach by matrix factorization. [sent-263, score-0.262]
</p><p>51 General matrix factorization methods enforce the target rank N constraint of data matrix (M = UV ) by factorizing it into a product ofrank N basis (U) and coefficient (V ) as hard constraint. [sent-264, score-0.534]
</p><p>52 etic matrix with the row size m = 10000, rank 3 and the corruption ratio r = 0. [sent-277, score-0.476]
</p><p>53 While our objective function is also non-convex, it is closer to the original convex function of RPCA with nuclear norm by definition of the partial sum of singular values which allow our method to converge to a better solution comparing to Zheng et al. [sent-279, score-0.657]
</p><p>54 Convergence behavior of RPCA [19] and our method for the rank 2,3 and 4 cases. [sent-297, score-0.334]
</p><p>55 We randomly generated matrices with m = 5000 rows and n = 40 columns for the rank 2, 3, 4 cases, and the average value over the trials is computed. [sent-298, score-0.334]
</p><p>56 Ideally, the observed intensity Ii is linearly related to irradiance R, which means that O is a rank-1 matrix. [sent-313, score-0.105]
</p><p>57 However, in practice, the rank of O is higher than 1due to moving objects, saturation or other artifacts (shown in Fig. [sent-314, score-0.465]
</p><p>58 We model these artifacts and the background scene as a summation of a low-rank matrix (essentially a rank-1 matrix) and sparse outliers, O = A + E. [sent-316, score-0.165]
</p><p>59 To compose an HDR image without ghost artifacts, we first estimate a Low Dynamic Range (LDR) background scene from the low-rank matrix A, then the weighted sum is applied to the LDR images. [sent-317, score-0.14]
</p><p>60 (2) is used as objective function with a target rank N = 1. [sent-319, score-0.455]
</p><p>61 The estimated background as low-rank matrix and sparse outlier results from the RPCA and the proposed  ? [sent-325, score-0.173]
</p><p>62 Illustration of the observed intensity values for (a) saturation region, (b) moving object, and (c) consistent cases. [sent-337, score-0.123]
</p><p>63 Ideally, a decomposed low–rank matrix A = [vec(A1) | · · · |vec(An)] consists of relative intensities of the background scene from which moving objects or saturation artifacts are removed (see Fig. [sent-347, score-0.217]
</p><p>64 [13] show that the intensity matrix lies in a subspace of rank 3, as illustrated in Fig. [sent-463, score-0.42]
</p><p>65 However, this constraint is hardly satisfied in real situations due to shadow from selfocclusion, saturation and some object materials which do not exactly follow the Lambertian diffuse model. [sent-465, score-0.095]
</p><p>66 artifacts mentioned above could be modeled as sparse outliers and we get a low-rank structure as O = E. [sent-474, score-0.146]
</p><p>67 The robust photometric stereo with outlier rejection can  NTL +  be formulated into a RPCA problem as suggested by Wu et al. [sent-475, score-0.436]
</p><p>68 We replace the formulation of the blind method by our partial sum objective function. [sent-478, score-0.187]
</p><p>69 The LS based photometric stereo estimates the normals by minimizing ? [sent-484, score-0.299]
</p><p>70 7-(c)), as the rank of resulting matrix is lower than 3 due to the lack of supports from the observations. [sent-499, score-0.386]
</p><p>71 In contrast, our method provides robust results for both limited observations and sufficient observations. [sent-502, score-0.115]
</p><p>72 Photometric stereo results from 5 (top) and 12 (bottom) images of Bunny dataset with corruption. [sent-515, score-0.112]
</p><p>73 face), the batch image alignment task aims to align them to a fixed canonical template [1, 20]. [sent-523, score-0.123]
</p><p>74 The rank minimization approach has led to impressive results for robust alignment of linearly correlated images [20]. [sent-524, score-0.583]
</p><p>75 [20], we consider the partial sum of singular values. [sent-534, score-0.285]
</p><p>76 For linearly correlated noise-free batch images, the rank must be N = 1, when the transformations for exact image alignment are estimated. [sent-542, score-0.558]
</p><p>77 Discussion and Conclusion In this paper, we revisited the rank minimization method in RPCA for low-level vision problems. [sent-548, score-0.426]
</p><p>78 When the target rank is known, we show that, by modifying the objective function from the nuclear norm to the partial sum of singular values, we can achieve a better control of the target rank of the low-rank solution, even when the number of observations is limited. [sent-549, score-1.391]
</p><p>79 The generality of our approach and the effectiveness are supported through our encouraging experiments on both synthetic examples and several real-world applications which outperform the conventional nuclear norm objective function. [sent-553, score-0.329]
</p><p>80 the necessary and the  sufficient conditions [21] of our partial sum objective function compared to the nuclear norm solution. [sent-556, score-0.416]
</p><p>81 Sufficient number of samples versus minimum number of samples In our experimental analysis, we found that our solution is more robust than the nuclear norm solution when facing a limited number of samples. [sent-558, score-0.419]
</p><p>82 2 images for HDR, 3 images for photometric stereo, our approach requires more than K samples for a robust model estimation and outlier rejection. [sent-561, score-0.302]
</p><p>83 Convergence The proof of convergence of the exact and inexact ALM with an alternating scheme has been established by [19, 9]. [sent-565, score-0.176]
</p><p>84 In contrast, to the best of our knowledge, the convergence property of inexact ALM alternating for nonconvex (solving A∗) and convex (solving E∗) programming has not been answered yet. [sent-566, score-0.176]
</p><p>85 Since the objective function of the partial sum of singular values is a non-convex function, the global optimal solution cannot be guaranteed. [sent-568, score-0.404]
</p><p>86 Nevertheless extensive experiments showed that our solution is  very closed to the nuclear norm solution when the number of observations is more than sufficient and converges to a better solution when the number of observations is limited. [sent-569, score-0.52]
</p><p>87 Target rank While our formulation implicitly encourages a target rank constraint in the resulting matrix, this constraint is not hardly enforced. [sent-572, score-0.833]
</p><p>88 We discuss here two possible scenarios can produce the resulting matrix having a rank different from the target rank. [sent-573, score-0.447]
</p><p>89 In such case, PSVT can produce a deficient rank lower than the target rank when the span of the observed samples is less than the target rank, but this case is a fundamental limitation of under-sampling rather than a conceptual limitation ofour approach. [sent-575, score-0.925]
</p><p>90 Another scenario is due to too much noise (especially for Gaussian noise that does not follow the sparsity property) in the observed samples which results in large singular values in the residual ranks. [sent-576, score-0.195]
</p><p>91 In this case, a solution to satisfy the rank constraint is to increase τ in Eq. [sent-577, score-0.428]
</p><p>92 When τ is equal to infinity, our solution is close to the result using singular value projection [15]. [sent-579, score-0.217]
</p><p>93 However, the projection method enforcing target rank could produce an over-fitting solution due to the mentioned noise effects. [sent-580, score-0.454]
</p><p>94 Photometric stereo under a light source with  [14] [15] [16] [17] [18]  [19]  [20]  [21]  [22]  [23]  [24]  arbitrary motion. [sent-660, score-0.112]
</p><p>95 Robust l1 norm factorization in the presence of outliers and missing data by alternative convex programming. [sent-691, score-0.153]
</p><p>96 The augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrices. [sent-697, score-0.101]
</p><p>97 RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images. [sent-705, score-0.166]
</p><p>98 Necessary and sufficient conditions for success of the nuclear norm heuristic for rank minimization. [sent-712, score-0.611]
</p><p>99 Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization. [sent-723, score-0.11]
</p><p>100 Robust photometric stereo via low-rank matrix completion and recovery. [sent-751, score-0.351]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rpca', 0.6), ('rank', 0.334), ('hdr', 0.24), ('psvt', 0.222), ('photometric', 0.187), ('singular', 0.158), ('nuclear', 0.14), ('stereo', 0.112), ('cand', 0.105), ('alm', 0.101), ('deficient', 0.098), ('uy', 0.094), ('minimization', 0.092), ('ak', 0.081), ('ek', 0.077), ('partial', 0.073), ('inexact', 0.069), ('batch', 0.068), ('wright', 0.067), ('outliers', 0.067), ('agt', 0.067), ('agtgt', 0.067), ('ntl', 0.067), ('vec', 0.066), ('kaist', 0.065), ('rm', 0.063), ('target', 0.061), ('objective', 0.06), ('saturation', 0.06), ('norm', 0.059), ('solution', 0.059), ('observations', 0.057), ('alignment', 0.055), ('sum', 0.054), ('dy', 0.053), ('matrix', 0.052), ('ganesh', 0.051), ('outlier', 0.05), ('convergence', 0.05), ('zheng', 0.05), ('clean', 0.05), ('debevec', 0.049), ('bunny', 0.049), ('corruption', 0.049), ('success', 0.048), ('corrupted', 0.047), ('exposure', 0.045), ('peng', 0.045), ('argamin', 0.044), ('argemin', 0.044), ('svp', 0.044), ('thoughtful', 0.044), ('vyt', 0.044), ('converged', 0.043), ('inn', 0.042), ('artifacts', 0.042), ('ratio', 0.041), ('fig', 0.041), ('conventional', 0.041), ('exposed', 0.04), ('ldr', 0.039), ('hayakawa', 0.039), ('hale', 0.039), ('lagrange', 0.039), ('operator', 0.039), ('sparse', 0.037), ('samples', 0.037), ('linearly', 0.037), ('correlated', 0.037), ('veec', 0.036), ('gallo', 0.036), ('principal', 0.036), ('ls', 0.035), ('constraint', 0.035), ('intensity', 0.034), ('irradiance', 0.034), ('degenerated', 0.034), ('encourages', 0.034), ('background', 0.034), ('im', 0.032), ('formulated', 0.032), ('analyses', 0.031), ('vy', 0.031), ('subtraction', 0.031), ('dynamic', 0.031), ('lagrangian', 0.031), ('wu', 0.03), ('sufficient', 0.03), ('alternating', 0.03), ('moving', 0.029), ('pn', 0.029), ('synthetic', 0.029), ('decreases', 0.028), ('robust', 0.028), ('et', 0.027), ('convex', 0.027), ('augmented', 0.027), ('termination', 0.027), ('rao', 0.027), ('exact', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="310-tfidf-1" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>Author: Tae-Hyun Oh, Hyeongwoo Kim, Yu-Wing Tai, Jean-Charles Bazin, In So Kweon</p><p>Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values. The proposed objective function implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that our approach performs better than conventional rank minimization when the number of samples is deficient, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, photometric stereo and image alignment, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.</p><p>2 0.27739555 <a title="310-tfidf-2" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>Author: Ricardo Cabral, Fernando De_La_Torre, João P. Costeira, Alexandre Bernardino</p><p>Abstract: Low rank models have been widely usedfor the representation of shape, appearance or motion in computer vision problems. Traditional approaches to fit low rank models make use of an explicit bilinear factorization. These approaches benefit from fast numerical methods for optimization and easy kernelization. However, they suffer from serious local minima problems depending on the loss function and the amount/type of missing data. Recently, these lowrank models have alternatively been formulated as convex problems using the nuclear norm regularizer; unlike factorization methods, their numerical solvers are slow and it is unclear how to kernelize them or to impose a rank a priori. This paper proposes a unified approach to bilinear factorization and nuclear norm regularization, that inherits the benefits of both. We analyze the conditions under which these approaches are equivalent. Moreover, based on this analysis, we propose a new optimization algorithm and a “rank continuation ” strategy that outperform state-of-theart approaches for Robust PCA, Structure from Motion and Photometric Stereo with outliers and missing data.</p><p>3 0.17801972 <a title="310-tfidf-3" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>Author: Jia Xu, Vamsi K. Ithapu, Lopamudra Mukherjee, James M. Rehg, Vikas Singh</p><p>Abstract: We study the problem of online subspace learning in the context of sequential observations involving structured perturbations. In online subspace learning, the observations are an unknown mixture of two components presented to the model sequentially the main effect which pertains to the subspace and a residual/error term. If no additional requirement is imposed on the residual, it often corresponds to noise terms in the signal which were unaccounted for by the main effect. To remedy this, one may impose ‘structural’ contiguity, which has the intended effect of leveraging the secondary terms as a covariate that helps the estimation of the subspace itself, instead of merely serving as a noise residual. We show that the corresponding online estimation procedure can be written as an approximate optimization process on a Grassmannian. We propose an efficient numerical solution, GOSUS, Grassmannian Online Subspace Updates with Structured-sparsity, for this problem. GOSUS is expressive enough in modeling both homogeneous perturbations of the subspace and structural contiguities of outliers, and after certain manipulations, solvable — via an alternating direction method of multipliers (ADMM). We evaluate the empirical performance of this algorithm on two problems of interest: online background subtraction and online multiple face tracking, and demonstrate that it achieves competitive performance with the state-of-the-art in near real time.</p><p>4 0.13023302 <a title="310-tfidf-4" href="./iccv-2013-Fibonacci_Exposure_Bracketing_for_High_Dynamic_Range_Imaging.html">164 iccv-2013-Fibonacci Exposure Bracketing for High Dynamic Range Imaging</a></p>
<p>Author: Mohit Gupta, Daisuke Iso, Shree K. Nayar</p><p>Abstract: Exposure bracketing for high dynamic range (HDR) imaging involves capturing several images of the scene at different exposures. If either the camera or the scene moves during capture, the captured images must be registered. Large exposure differences between bracketed images lead to inaccurate registration, resulting in artifacts such as ghosting (multiple copies of scene objects) and blur. We present two techniques, one for image capture (Fibonacci exposure bracketing) and one for image registration (generalized registration), to prevent such motion-related artifacts. Fibonacci bracketing involves capturing a sequence of images such that each exposure time is the sum of the previous N(N > 1) exposures. Generalized registration involves estimating motion between sums of contiguous sets of frames, instead of between individual frames. Together, the two techniques ensure that motion is always estimated betweenframes of the same total exposure time. This results in HDR images and videos which have both a large dynamic range andminimal motion-relatedartifacts. We show, by results for several real-world indoor and outdoor scenes, that theproposed approach significantly outperforms several ex- isting bracketing schemes.</p><p>5 0.12937124 <a title="310-tfidf-5" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>Author: Xudong Cao, David Wipf, Fang Wen, Genquan Duan, Jian Sun</p><p>Abstract: Face verification involves determining whether a pair of facial images belongs to the same or different subjects. This problem can prove to be quite challenging in many important applications where labeled training data is scarce, e.g., family album photo organization software. Herein we propose a principled transfer learning approach for merging plentiful source-domain data with limited samples from some target domain of interest to create a classifier that ideally performs nearly as well as if rich target-domain data were present. Based upon a surprisingly simple generative Bayesian model, our approach combines a KL-divergencebased regularizer/prior with a robust likelihood function leading to a scalable implementation via the EM algorithm. As justification for our design choices, we later use principles from convex analysis to recast our algorithm as an equivalent structured rank minimization problem leading to a number of interesting insights related to solution structure and feature-transform invariance. These insights help to both explain the effectiveness of our algorithm as well as elucidate a wide variety of related Bayesian approaches. Experimental testing with challenging datasets validate the utility of the proposed algorithm.</p><p>6 0.11486274 <a title="310-tfidf-6" href="./iccv-2013-Multiview_Photometric_Stereo_Using_Planar_Mesh_Parameterization.html">284 iccv-2013-Multiview Photometric Stereo Using Planar Mesh Parameterization</a></p>
<p>7 0.10293306 <a title="310-tfidf-7" href="./iccv-2013-High_Quality_Shape_from_a_Single_RGB-D_Image_under_Uncalibrated_Natural_Illumination.html">199 iccv-2013-High Quality Shape from a Single RGB-D Image under Uncalibrated Natural Illumination</a></p>
<p>8 0.10107736 <a title="310-tfidf-8" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>9 0.092973173 <a title="310-tfidf-9" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>10 0.084332518 <a title="310-tfidf-10" href="./iccv-2013-Rank_Minimization_across_Appearance_and_Shape_for_AAM_Ensemble_Fitting.html">339 iccv-2013-Rank Minimization across Appearance and Shape for AAM Ensemble Fitting</a></p>
<p>11 0.082319789 <a title="310-tfidf-11" href="./iccv-2013-Multi-view_Normal_Field_Integration_for_3D_Reconstruction_of_Mirroring_Objects.html">281 iccv-2013-Multi-view Normal Field Integration for 3D Reconstruction of Mirroring Objects</a></p>
<p>12 0.076649494 <a title="310-tfidf-12" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>13 0.075285167 <a title="310-tfidf-13" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>14 0.074814171 <a title="310-tfidf-14" href="./iccv-2013-Internet_Based_Morphable_Model.html">219 iccv-2013-Internet Based Morphable Model</a></p>
<p>15 0.074369662 <a title="310-tfidf-15" href="./iccv-2013-Coupling_Alignments_with_Recognition_for_Still-to-Video_Face_Recognition.html">97 iccv-2013-Coupling Alignments with Recognition for Still-to-Video Face Recognition</a></p>
<p>16 0.074295528 <a title="310-tfidf-16" href="./iccv-2013-Finding_Causal_Interactions_in_Video_Sequences.html">167 iccv-2013-Finding Causal Interactions in Video Sequences</a></p>
<p>17 0.072725154 <a title="310-tfidf-17" href="./iccv-2013-Toward_Guaranteed_Illumination_Models_for_Non-convex_Objects.html">422 iccv-2013-Toward Guaranteed Illumination Models for Non-convex Objects</a></p>
<p>18 0.072038084 <a title="310-tfidf-18" href="./iccv-2013-Correntropy_Induced_L2_Graph_for_Robust_Subspace_Clustering.html">94 iccv-2013-Correntropy Induced L2 Graph for Robust Subspace Clustering</a></p>
<p>19 0.071187384 <a title="310-tfidf-19" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>20 0.069429941 <a title="310-tfidf-20" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.156), (1, -0.062), (2, -0.069), (3, -0.022), (4, -0.105), (5, 0.023), (6, 0.021), (7, -0.0), (8, 0.084), (9, -0.012), (10, -0.007), (11, -0.04), (12, -0.039), (13, 0.007), (14, 0.01), (15, -0.048), (16, -0.021), (17, 0.052), (18, -0.015), (19, 0.037), (20, 0.029), (21, 0.025), (22, -0.123), (23, -0.111), (24, 0.024), (25, 0.037), (26, 0.068), (27, -0.068), (28, 0.02), (29, -0.049), (30, 0.157), (31, -0.026), (32, -0.028), (33, 0.089), (34, 0.132), (35, -0.021), (36, -0.003), (37, 0.115), (38, 0.092), (39, -0.031), (40, -0.07), (41, 0.003), (42, -0.054), (43, 0.167), (44, 0.002), (45, 0.177), (46, -0.122), (47, -0.077), (48, 0.106), (49, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95428616 <a title="310-lsi-1" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>Author: Tae-Hyun Oh, Hyeongwoo Kim, Yu-Wing Tai, Jean-Charles Bazin, In So Kweon</p><p>Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values. The proposed objective function implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that our approach performs better than conventional rank minimization when the number of samples is deficient, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, photometric stereo and image alignment, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.</p><p>2 0.92817348 <a title="310-lsi-2" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>Author: Ricardo Cabral, Fernando De_La_Torre, João P. Costeira, Alexandre Bernardino</p><p>Abstract: Low rank models have been widely usedfor the representation of shape, appearance or motion in computer vision problems. Traditional approaches to fit low rank models make use of an explicit bilinear factorization. These approaches benefit from fast numerical methods for optimization and easy kernelization. However, they suffer from serious local minima problems depending on the loss function and the amount/type of missing data. Recently, these lowrank models have alternatively been formulated as convex problems using the nuclear norm regularizer; unlike factorization methods, their numerical solvers are slow and it is unclear how to kernelize them or to impose a rank a priori. This paper proposes a unified approach to bilinear factorization and nuclear norm regularization, that inherits the benefits of both. We analyze the conditions under which these approaches are equivalent. Moreover, based on this analysis, we propose a new optimization algorithm and a “rank continuation ” strategy that outperform state-of-theart approaches for Robust PCA, Structure from Motion and Photometric Stereo with outliers and missing data.</p><p>3 0.76239187 <a title="310-lsi-3" href="./iccv-2013-Robust_Matrix_Factorization_with_Unknown_Noise.html">357 iccv-2013-Robust Matrix Factorization with Unknown Noise</a></p>
<p>Author: Deyu Meng, Fernando De_La_Torre</p><p>Abstract: Many problems in computer vision can be posed as recovering a low-dimensional subspace from highdimensional visual data. Factorization approaches to lowrank subspace estimation minimize a loss function between an observed measurement matrix and a bilinear factorization. Most popular loss functions include the L2 and L1 losses. L2 is optimal for Gaussian noise, while L1 is for Laplacian distributed noise. However, real data is often corrupted by an unknown noise distribution, which is unlikely to be purely Gaussian or Laplacian. To address this problem, this paper proposes a low-rank matrix factorization problem with a Mixture of Gaussians (MoG) noise model. The MoG model is a universal approximator for any continuous distribution, and hence is able to model a wider range of noise distributions. The parameters of the MoG model can be estimated with a maximum likelihood method, while the subspace is computed with standard approaches. We illustrate the benefits of our approach in extensive syn- thetic and real-world experiments including structure from motion, face modeling and background subtraction.</p><p>4 0.73509425 <a title="310-lsi-4" href="./iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</a></p>
<p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><p>5 0.62213498 <a title="310-lsi-5" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>Author: Mithun Das Gupta, Sanjeev Kumar</p><p>Abstract: In this paper, we investigate the properties of Lp norm (p ≤ 1) within a projection framework. We start with the (KpK T≤ equations of the neoctni-olnin efraarm optimization problem a thnde then use its key properties to arrive at an algorithm for Lp norm projection on the non-negative simplex. We compare with L1projection which needs prior knowledge of the true norm, as well as hard thresholding based sparsificationproposed in recent compressed sensing literature. We show performance improvements compared to these techniques across different vision applications.</p><p>6 0.60093808 <a title="310-lsi-6" href="./iccv-2013-Finding_Causal_Interactions_in_Video_Sequences.html">167 iccv-2013-Finding Causal Interactions in Video Sequences</a></p>
<p>7 0.56153423 <a title="310-lsi-7" href="./iccv-2013-SGTD%3A_Structure_Gradient_and_Texture_Decorrelating_Regularization_for_Image_Decomposition.html">364 iccv-2013-SGTD: Structure Gradient and Texture Decorrelating Regularization for Image Decomposition</a></p>
<p>8 0.5571596 <a title="310-lsi-8" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>9 0.55514604 <a title="310-lsi-9" href="./iccv-2013-Automatic_Kronecker_Product_Model_Based_Detection_of_Repeated_Patterns_in_2D_Urban_Images.html">55 iccv-2013-Automatic Kronecker Product Model Based Detection of Repeated Patterns in 2D Urban Images</a></p>
<p>10 0.54176718 <a title="310-lsi-10" href="./iccv-2013-The_Way_They_Move%3A_Tracking_Multiple_Targets_with_Similar_Appearance.html">418 iccv-2013-The Way They Move: Tracking Multiple Targets with Similar Appearance</a></p>
<p>11 0.49723151 <a title="310-lsi-11" href="./iccv-2013-GOSUS%3A_Grassmannian_Online_Subspace_Updates_with_Structured-Sparsity.html">182 iccv-2013-GOSUS: Grassmannian Online Subspace Updates with Structured-Sparsity</a></p>
<p>12 0.4944756 <a title="310-lsi-12" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>13 0.48818791 <a title="310-lsi-13" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>14 0.47095659 <a title="310-lsi-14" href="./iccv-2013-Toward_Guaranteed_Illumination_Models_for_Non-convex_Objects.html">422 iccv-2013-Toward Guaranteed Illumination Models for Non-convex Objects</a></p>
<p>15 0.46794462 <a title="310-lsi-15" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>16 0.45791671 <a title="310-lsi-16" href="./iccv-2013-Learning_to_Rank_Using_Privileged_Information.html">248 iccv-2013-Learning to Rank Using Privileged Information</a></p>
<p>17 0.4377524 <a title="310-lsi-17" href="./iccv-2013-Super-resolution_via_Transform-Invariant_Group-Sparse_Regularization.html">408 iccv-2013-Super-resolution via Transform-Invariant Group-Sparse Regularization</a></p>
<p>18 0.43395665 <a title="310-lsi-18" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>19 0.42095354 <a title="310-lsi-19" href="./iccv-2013-A_Generalized_Low-Rank_Appearance_Model_for_Spatio-temporally_Correlated_Rain_Streaks.html">15 iccv-2013-A Generalized Low-Rank Appearance Model for Spatio-temporally Correlated Rain Streaks</a></p>
<p>20 0.41800737 <a title="310-lsi-20" href="./iccv-2013-Cross-Field_Joint_Image_Restoration_via_Scale_Map.html">98 iccv-2013-Cross-Field Joint Image Restoration via Scale Map</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.039), (7, 0.014), (26, 0.061), (27, 0.273), (31, 0.052), (40, 0.011), (42, 0.154), (48, 0.014), (64, 0.025), (73, 0.048), (89, 0.182), (98, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87537384 <a title="310-lda-1" href="./iccv-2013-Non-convex_P-Norm_Projection_for_Robust_Sparsity.html">292 iccv-2013-Non-convex P-Norm Projection for Robust Sparsity</a></p>
<p>Author: Mithun Das Gupta, Sanjeev Kumar</p><p>Abstract: In this paper, we investigate the properties of Lp norm (p ≤ 1) within a projection framework. We start with the (KpK T≤ equations of the neoctni-olnin efraarm optimization problem a thnde then use its key properties to arrive at an algorithm for Lp norm projection on the non-negative simplex. We compare with L1projection which needs prior knowledge of the true norm, as well as hard thresholding based sparsificationproposed in recent compressed sensing literature. We show performance improvements compared to these techniques across different vision applications.</p><p>2 0.87063861 <a title="310-lda-2" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>same-paper 3 0.82089013 <a title="310-lda-3" href="./iccv-2013-Partial_Sum_Minimization_of_Singular_Values_in_RPCA_for_Low-Level_Vision.html">310 iccv-2013-Partial Sum Minimization of Singular Values in RPCA for Low-Level Vision</a></p>
<p>Author: Tae-Hyun Oh, Hyeongwoo Kim, Yu-Wing Tai, Jean-Charles Bazin, In So Kweon</p><p>Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values. The proposed objective function implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that our approach performs better than conventional rank minimization when the number of samples is deficient, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, photometric stereo and image alignment, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.</p><p>4 0.781367 <a title="310-lda-4" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>Author: Zhenyu Guo, Z. Jane Wang</p><p>Abstract: Digital images nowadays show large appearance variabilities on picture styles, in terms of color tone, contrast, vignetting, and etc. These ‘picture styles’ are directly related to the scene radiance, image pipeline of the camera, and post processing functions (e.g., photography effect filters). Due to the complexity and nonlinearity of these factors, popular gradient-based image descriptors generally are not invariant to different picture styles, which could degrade the performance for object recognition. Given that images shared online or created by individual users are taken with a wide range of devices and may be processed by various post processing functions, to find a robust object recognition system is useful and challenging. In this paper, we investigate the influence of picture styles on object recognition by making a connection between image descriptors and a pixel mapping function g, and accordingly propose an adaptive approach based on a g-incorporated kernel descriptor and multiple kernel learning, without estimating or specifying the image styles used in training and testing. We conduct experiments on the Domain Adaptation data set, the Oxford Flower data set, and several variants of the Flower data set by introducing popular photography effects through post-processing. The results demonstrate that theproposedmethod consistently yields recognition improvements over standard descriptors in all studied cases.</p><p>5 0.77290773 <a title="310-lda-5" href="./iccv-2013-Semantic-Aware_Co-indexing_for_Image_Retrieval.html">378 iccv-2013-Semantic-Aware Co-indexing for Image Retrieval</a></p>
<p>Author: Shiliang Zhang, Ming Yang, Xiaoyu Wang, Yuanqing Lin, Qi Tian</p><p>Abstract: Inverted indexes in image retrieval not only allow fast access to database images but also summarize all knowledge about the database, so that their discriminative capacity largely determines the retrieval performance. In this paper, for vocabulary tree based image retrieval, we propose a semantic-aware co-indexing algorithm to jointly San Antonio, TX 78249 . j dl@gmai l com qit ian@cs .ut sa . edu . The query embed two strong cues into the inverted indexes: 1) local invariant features that are robust to delineate low-level image contents, and 2) semantic attributes from large-scale object recognition that may reveal image semantic meanings. For an initial set of inverted indexes of local features, we utilize 1000 semantic attributes to filter out isolated images and insert semantically similar images to the initial set. Encoding these two distinct cues together effectively enhances the discriminative capability of inverted indexes. Such co-indexing operations are totally off-line and introduce small computation overhead to online query cause only local features but no semantic attributes are used for query. Experiments and comparisons with recent retrieval methods on 3 datasets, i.e., UKbench, Holidays, Oxford5K, and 1.3 million images from Flickr as distractors, manifest the competitive performance of our method 1.</p><p>6 0.77250099 <a title="310-lda-6" href="./iccv-2013-Transfer_Feature_Learning_with_Joint_Distribution_Adaptation.html">427 iccv-2013-Transfer Feature Learning with Joint Distribution Adaptation</a></p>
<p>7 0.70396477 <a title="310-lda-7" href="./iccv-2013-Robust_Tucker_Tensor_Decomposition_for_Effective_Image_Representation.html">362 iccv-2013-Robust Tucker Tensor Decomposition for Effective Image Representation</a></p>
<p>8 0.69918412 <a title="310-lda-8" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>9 0.69832391 <a title="310-lda-9" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>10 0.69633448 <a title="310-lda-10" href="./iccv-2013-Exemplar-Based_Graph_Matching_for_Robust_Facial_Landmark_Localization.html">149 iccv-2013-Exemplar-Based Graph Matching for Robust Facial Landmark Localization</a></p>
<p>11 0.69543964 <a title="310-lda-11" href="./iccv-2013-A_Generalized_Iterated_Shrinkage_Algorithm_for_Non-convex_Sparse_Coding.html">14 iccv-2013-A Generalized Iterated Shrinkage Algorithm for Non-convex Sparse Coding</a></p>
<p>12 0.69399774 <a title="310-lda-12" href="./iccv-2013-Latent_Space_Sparse_Subspace_Clustering.html">232 iccv-2013-Latent Space Sparse Subspace Clustering</a></p>
<p>13 0.69165945 <a title="310-lda-13" href="./iccv-2013-Potts_Model%2C_Parametric_Maxflow_and_K-Submodular_Functions.html">324 iccv-2013-Potts Model, Parametric Maxflow and K-Submodular Functions</a></p>
<p>14 0.69102705 <a title="310-lda-14" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>15 0.69005835 <a title="310-lda-15" href="./iccv-2013-Multi-channel_Correlation_Filters.html">277 iccv-2013-Multi-channel Correlation Filters</a></p>
<p>16 0.68755209 <a title="310-lda-16" href="./iccv-2013-Unifying_Nuclear_Norm_and_Bilinear_Factorization_Approaches_for_Low-Rank_Matrix_Decomposition.html">434 iccv-2013-Unifying Nuclear Norm and Bilinear Factorization Approaches for Low-Rank Matrix Decomposition</a></p>
<p>17 0.68731248 <a title="310-lda-17" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>18 0.68704784 <a title="310-lda-18" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>19 0.68437129 <a title="310-lda-19" href="./iccv-2013-Fast_Sparsity-Based_Orthogonal_Dictionary_Learning_for_Image_Restoration.html">161 iccv-2013-Fast Sparsity-Based Orthogonal Dictionary Learning for Image Restoration</a></p>
<p>20 0.68417174 <a title="310-lda-20" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
