<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-227" href="#">iccv2013-227</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</h1>
<br/><p>Source: <a title="iccv-2013-227-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Feng_Large-Scale_Image_Annotation_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Zheyun Feng, Rong Jin, Anil Jain</p><p>Abstract: One of the key challenges in search-based image annotation models is to define an appropriate similarity measure between images. Many kernel distance metric learning (KML) algorithms have been developed in order to capture the nonlinear relationships between visual features and semantics ofthe images. Onefundamental limitation in applying KML to image annotation is that it requires converting image annotations into binary constraints, leading to a significant information loss. In addition, most KML algorithms suffer from high computational cost due to the requirement that the learned matrix has to be positive semi-definitive (PSD). In this paper, we propose a robust kernel metric learning (RKML) algorithm based on the regression technique that is able to directly utilize image annotations. The proposed method is also computationally more efficient because PSD property is automatically ensured by regression. We provide the theoretical guarantee for the proposed algorithm, and verify its efficiency and effectiveness for image annotation by comparing it to state-of-the-art approaches for both distance metric learning and image annotation. ,</p><p>Reference: <a title="iccv-2013-227-reference" href="../iccv2013_reference/iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Many kernel distance metric learning (KML) algorithms have been developed in order to capture the nonlinear relationships between visual features and semantics ofthe images. [sent-2, score-0.48]
</p><p>2 Onefundamental limitation in applying KML to image annotation is that it requires converting image annotations into binary constraints, leading to a significant information loss. [sent-3, score-0.274]
</p><p>3 In this paper, we propose a robust kernel metric learning (RKML) algorithm based on the regression technique that is able to directly utilize image annotations. [sent-5, score-0.354]
</p><p>4 We provide the theoretical guarantee for the proposed algorithm, and verify its efficiency and effectiveness for image annotation by comparing it to state-of-the-art approaches for both distance metric learning and image annotation. [sent-7, score-0.495]
</p><p>5 Introduction The objective of image annotation is to automatically annotate an image with appropriate keywords, often referred to as tags, which reflect its visual content. [sent-9, score-0.209]
</p><p>6 Their key idea is to annotate a test image I the common tags shared by the subset of trainwith ing images tthh atht are visually gsism sihlaarr etod b Iy. [sent-11, score-0.146]
</p><p>7 Distance metric learning (DML) tackles this problem by learning a metric that pulls semantically similar images close and pushes semantically dissimilar images far apart. [sent-14, score-0.358]
</p><p>8 Many studies on DML are restricted to learning a linear Mahalanobis distance metric, failing to capture the nonlinear relationj ain} @ c s e . [sent-15, score-0.227]
</p><p>9 Several nonlinear DML algorithms have been proposed to overcome this limitation. [sent-18, score-0.087]
</p><p>10 In the case of image annotation, it could be difficult to construct these binary constraints as two images with different annotations may still share several common keywords. [sent-24, score-0.099]
</p><p>11 In particular, to ensure the learned metric to be Positive SemiDefinite (PSD), the existing methods need to project the learned matrix into a PSD cone whose computational cost is O(d3). [sent-29, score-0.21]
</p><p>12 Finally, the high dimensionality of KML may lead to the overfitting of training data [18]. [sent-30, score-0.138]
</p><p>13 In this paper, we propose a regression based approach for KML, termed Regression based Kernel Metric Learning (RKML), that explicitly addresses the challenges arising from high dimensionality and limitations of binary constraints. [sent-32, score-0.117]
</p><p>14 RKML directly utilizes image tags to compute a  real-valued semantic similarity, and therefore do not need to construct the binary constraints. [sent-33, score-0.189]
</p><p>15 The projection step is avoided by exploiting the special property of regression, and the overfitting risk is alleviated by appropriately reg11660099  ularizing the rank of the learned kernel metric. [sent-34, score-0.32]
</p><p>16 We demonstrate the robustness of the proposed RKML algorithm to high dimensionality by proving the theoretical guarantee of the learned kernel metric. [sent-35, score-0.242]
</p><p>17 We also verify the efficiency and effectiveness of RKML for search-based image annotation by comparing it to the state-of-the-art approaches for both DML and image annotation on several benchmark datasets. [sent-36, score-0.414]
</p><p>18 Related Work In this section we review the related work on image annotation and distance metric learning. [sent-38, score-0.368]
</p><p>19 Recent studies on image annotation show that search based approaches are more effective than both generative and discriminative models. [sent-41, score-0.212]
</p><p>20 Distance Metric Learning Many algorithms have been developed to learn a linear DML from pairwise constraints [35], and some of them are designed exclusively for image annotation [17, 32, 34]. [sent-47, score-0.261]
</p><p>21 Recently, a number of nonlinear DML approaches have been developed to handle nonlinear and multimodal patterns. [sent-48, score-0.222]
</p><p>22 They are usually classified into two categories, boosting based approaches [14, 15, 26] and kernel based approaches, depending on how the nonlinear mapping is constructed. [sent-49, score-0.263]
</p><p>23 Many KML algorithms, such as Kernel DCA [16], KLMCA [28] and Kernel ITML [7], directly extend their linear counterparts to KML using the kernel trick. [sent-50, score-0.159]
</p><p>24 To handle the high dimensionality challenge in KML, a common approach is to apply dimensionality reduction before learning the metric [5, 28]. [sent-51, score-0.263]
</p><p>25 Although these studies show dimensionality reduction helps alleviate the overfitting risk in KML, no theoretical support is provided. [sent-52, score-0.183]
</p><p>26 ) : Rd Rd → R be a kernel function, and Hκ be the corresponding Reproducing K keerrnneell fHuinlbcetirotn Space. [sent-66, score-0.138]
</p><p>27 Without a metric, the similarity between two instances xa and xb could be assessed by the kernel function as ? [sent-67, score-0.381]
</p><p>28 HThe objective of KML is to learn a PSD linear operator T that is consistent with the class assignments of training examples. [sent-74, score-0.084]
</p><p>29 Note that this is different from similarity learning [4] because we require T to be PSD. [sent-75, score-0.082]
</p><p>30 Regression based Kernel Metric Learning The proposed RKML is a kernel metric learning algorithm based on the regression technique. [sent-79, score-0.354]
</p><p>31 Let si,j ∈ R be the similarity measure between two images xi and xj b Ras ebde  on their annotations yi and yj . [sent-80, score-0.161]
</p><p>32 We adopt a regression model to learn a kernel distance metric consistent with the similarity measure si,j by solving the optimization problem:  T? [sent-85, score-0.402]
</p><p>33 Following the representer theorem of kernel learning [24], it is sufficient to assume that T? [sent-91, score-0.179]
</p><p>34 |2F,  (2)  where K = [κ(xi , xj)]n×n is the kernel matrix and S = [si,j]n×n includes all the pairwise se kmerannetlic m saitmriixla arintides S Sb e=-  tween any two training images. [sent-107, score-0.159]
</p><p>35 Note that when the semantic similarity matrix S is PSD, A will also be PSD, thus no additional projectSion is i Ps SnDe,ed Aed w tiol len alfsoorc bee t PheS Dlin,e tahru operator Tt? [sent-109, score-0.115]
</p><p>36 e best rank r approximation of K, and express A as A = Kr−1SK−r1. [sent-112, score-0.092]
</p><p>37 (3) Evidently, the rank r makes the tradeoff between bias and variance in estimating A: the larger the rank r, the lower the bias and higher the variance. [sent-113, score-0.12]
</p><p>38 , the similarity between any two data instances xa and x? [sent-116, score-0.161]
</p><p>39 Theoretical Guarantee of RKML We will show that the linear operator learned by the proposed algorithm is stochastically consistent, i. [sent-133, score-0.089]
</p><p>40 , the lin-  ear operator learned from finite samples provides a good approximation to the optimal one learned from an infinite number of samples. [sent-135, score-0.146]
</p><p>41 To simplify our analysis, we assume that the semantic similarity measure si,j = yi? [sent-136, score-0.073]
</p><p>42 aLtievte gk ( s·m) a blle, wtheh prediction function for the k-th ? [sent-161, score-0.098]
</p><p>43 e W pree dmicatkioe nth feu following assumption fsosr, gk (·) in our analysis: A1 : gk(·) ∈ Hκ, k = 1, . [sent-165, score-0.073]
</p><p>44 Assumption A1 essentially assumes that it is possible to accurately learn the prediction function gk (·) given sufficiently large number of training examples. [sent-169, score-0.119]
</p><p>45 W) gei vaelsno unofftiethat assumption A1 holds if gk (·) is a smooth function and κ(·, ·) is a universal kernel [23(]·). [sent-170, score-0.23]
</p><p>46 ,  (6)  where Krs is the best rank r approximation of Ks = [κ( x? [sent-193, score-0.092]
</p><p>47 2 ≤ O(1/√ns), that K˜r is an accurate approximation  implying of Kr provided the number of samples ns is sufficiently large. [sent-200, score-0.087]
</p><p>48 , kernel matrix K can be well approximated by the Nytr o¨m method when ns  is a few thousands. [sent-203, score-0.193]
</p><p>49 According to our implementation, we observe that further approximating Kb in (6) to rank r usually yields more accurate prediction for tags. [sent-204, score-0.112]
</p><p>50 Three benchmark datasets for image annotation are used in our study and their statistics are summarized in Table 1. [sent-217, score-0.182]
</p><p>51 Given a test image, we first identify the k most visually similar images from the training set using the learned distance metric, and then rank the tags by a majority vote over the k nearest neighbors, where k is chosen by cross-validation. [sent-227, score-0.274]
</p><p>52 An RBF kernel is used in our study for all KML algorithms. [sent-228, score-0.138]
</p><p>53 38m based on our experience, and determine the kernel width and rank r by cross-validation. [sent-231, score-0.198]
</p><p>54 Besides, annotation based on the Euclidean distance, denoted by Euclid, is used as a reference in our comparison. [sent-233, score-0.182]
</p><p>55 Since most DMLs are developed against mustlinks and cannot-links, we apply the procedure described in [32] to generate the binary constraints by performing a probabilistic clustering over the images based on their tags. [sent-234, score-0.096]
</p><p>56 We evaluate the annotation accuracy by the average precision for the top ranked image tags. [sent-236, score-0.211]
</p><p>57 Following [33, 34], we first compute the precision for each test image by comparing the top 10 annotated tags with the ground truth, and then take the average over the test set. [sent-237, score-0.177]
</p><p>58 Comparison with State-of-the-art Distance Metric Learning Algorithms Comparison to nonlinear DML algorithms. [sent-243, score-0.087]
</p><p>59 , Distance Boost (DBoost) [14], Kernel Boost (KBoost) [15], and metric learning with boosting (BoostM) [26], for comparison. [sent-247, score-0.217]
</p><p>60 11661122  Figure 1 shows the average precision for the top t annotated tags obtained by nonlinear DML baselines and the proposed RKML. [sent-252, score-0.264]
</p><p>61 Surprisingly, we observe that most of the nonlinear DML algorithms are only able to yield performance similar to that based on the Euclidean distance, and more disturbingly, some of the nonlinear DML algorithms  even perform significantly worse than the Euclidean distance. [sent-253, score-0.201]
</p><p>62 As described before, all DML algorithms require converting image annotations into binary constraints, which does not make full use of the annotation information. [sent-257, score-0.274]
</p><p>63 To verify this point, we run RKML with similarity measure si,j computed from the binary constraints that are generated for the baseline DML algorithms, and denote this method by RKMLH. [sent-258, score-0.134]
</p><p>64 Comparison of various extensions of RKML for the top t annotated tags on the IAPR TC12. [sent-268, score-0.148]
</p><p>65 Figure 3 shows the average annotation precision for the linear DML baselines. [sent-272, score-0.232]
</p><p>66 Similar to KML, we observe that even the best linear DML algorithm is only slightly better than the Euclidean distance, while RKML significantly outperforms all linear DML baselines. [sent-273, score-0.069]
</p><p>67 Again, we believe that the failure of linear DML is likely due to the binary constraints generated from image annotations. [sent-274, score-0.089]
</p><p>68 Since none of the baseline algorithms, neither linear nor nonlinear DML, is able to significantly outperform the Euclidean distance, it remains unclear if kernel DML is advantageous to a linear DML. [sent-275, score-0.267]
</p><p>69 It is clear that RKML significantly outperforms its linear counterpart RLML, verifying the advantage of using kernel in DML. [sent-278, score-0.159]
</p><p>70 Average precision for the first tag predicted by RMKL using different values of rank r on IAPR TC12 data. [sent-281, score-0.134]
</p><p>71 To make the overfitting effect clearer, we turn off the Nystr ¨om approximation in this experiment. [sent-282, score-0.107]
</p><p>72 We finally examine the role of rank r in the proposed algorithm by evaluating the prediction accuracy with varied r on the IAPRTC 12 dataset for both training and testing images (Figure 2). [sent-284, score-0.13]
</p><p>73 We observe that while the average accuracy of test images initially improves significantly with increasing rank r, it becomes saturated after certain rank. [sent-286, score-0.087]
</p><p>74 On the other hand, the prediction accuracy of training data increases almost linearly with respect to the rank, and becomes almost 1for very large r, a clear indication of overfitting training data. [sent-287, score-0.142]
</p><p>75 and ns can be found in the supplementary document. [sent-293, score-0.082]
</p><p>76 We include Pop as a comparison reference which simply ranks tags based on their occurring frequency in the training set. [sent-298, score-0.14]
</p><p>77 Average precision for the top t annotated tags using nonlinear distance metrics. [sent-301, score-0.312]
</p><p>78 Average precision for the top t annotated tags using linear distance metrics. [sent-303, score-0.246]
</p><p>79 TIMEDCALMNNITMLLDMLDBoostBoostMKPCAGDAKDCAKLFDAKITMLMLKRRKML  Figure 4 shows the comparison of average precision obtained by different image annotation models. [sent-307, score-0.211]
</p><p>80 It is not surprising to observe that most annotation methods significantly outperform Pop, while the proposed RMKL method outperforms all the state-of-the-art image annotation methods on IAPR TC12 and ESP Game datasets, and only performs slightly worse than TP-D on the Flickr 1M dataset. [sent-308, score-0.391]
</p><p>81 ning time includes the time for both learning a distance metric and predicting image tags. [sent-322, score-0.227]
</p><p>82 We observe that compared to the other annotation methods, the proposed RKML algorithm is particularly efficient for large datasets (i. [sent-323, score-0.209]
</p><p>83 Conclusions and Future Work In this paper, we propose a robust and efficient method for kernel metric learning (KML). [sent-327, score-0.317]
</p><p>84 The proposed method addresses (i) high computational cost by avoiding the projection into PSD cone, (ii) limitation of binary constraints in tags by adopting a real-valued similarity measure, as well as (iii) the overfitting problem by appropriately regularizing the learned kernel metric. [sent-328, score-0.488]
</p><p>85 Experiments with large-scale image annotation demonstrate the effectiveness and efficiency of the proposed algorithm by comparing it to the state-ofthe-art approaches for DML and image annotation. [sent-329, score-0.207]
</p><p>86 In the future, we plan to improve the annotation performance by developing a more robust semantic similarity measure. [sent-330, score-0.255]
</p><p>87 Supervised learning of semantic classes for image annotation and retrieval. [sent-352, score-0.255]
</p><p>88 Large scale online learning of image similarity through ranking. [sent-359, score-0.082]
</p><p>89 On the nystr ¨om method for approximating a gram matrix for improved kernel-based learning. [sent-387, score-0.086]
</p><p>90 Multi-level annotation of natural scenes using dominant image components and semantic concepts. [sent-393, score-0.214]
</p><p>91 TagProp: discriminative metric learning in nearest neighbor models for image auto-annotation. [sent-417, score-0.204]
</p><p>92 Boosting margin  [15]  [16]  [17]  [18] [19] [20]  [21] [22]  [23] [24]  [25]  [26]  based distance functions for clustering. [sent-431, score-0.071]
</p><p>93 Learning a kernel function for classification with small training samples. [sent-438, score-0.159]
</p><p>94 Learning distance metrics with contextual constraints for image retrieval. [sent-445, score-0.078]
</p><p>95 Labeling images by integrating sparse multiple distance learning and semantic context modeling. [sent-452, score-0.121]
</p><p>96 Positive  [27]  [28] [29] [30]  [3 1] [32]  [33] [34]  [35]  semidefinite metric learning with boosting. [sent-510, score-0.201]
</p><p>97 Dimensionality reduction of multimodal labeled data by local fisher discriminant analysis. [sent-515, score-0.08]
</p><p>98 Distance metric learning for large margin nearest neighbor classification. [sent-536, score-0.227]
</p><p>99 Distance metric learning from uncertain side information with application to automated photo tagging. [sent-551, score-0.179]
</p><p>100 Mining social images with distance metric learning for automated image tagging. [sent-567, score-0.227]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dml', 0.545), ('rkml', 0.461), ('kml', 0.39), ('annotation', 0.182), ('kernel', 0.138), ('metric', 0.138), ('iapr', 0.13), ('psd', 0.121), ('tags', 0.119), ('esp', 0.103), ('xa', 0.087), ('nonlinear', 0.087), ('nystr', 0.086), ('rlml', 0.084), ('rmkl', 0.084), ('xb', 0.082), ('overfitting', 0.075), ('gk', 0.073), ('flickr', 0.073), ('hertz', 0.063), ('rank', 0.06), ('kr', 0.057), ('tagprop', 0.056), ('game', 0.055), ('ns', 0.055), ('jin', 0.054), ('distance', 0.048), ('om', 0.047), ('tag', 0.045), ('hoi', 0.044), ('dimensionality', 0.042), ('operator', 0.042), ('dmls', 0.042), ('hillel', 0.042), ('krs', 0.042), ('rkmlh', 0.042), ('rong', 0.042), ('learning', 0.041), ('similarity', 0.041), ('theoretic', 0.039), ('boosting', 0.038), ('binary', 0.038), ('regression', 0.037), ('rca', 0.037), ('keywords', 0.037), ('jmlr', 0.036), ('theoretical', 0.036), ('discriminant', 0.036), ('dca', 0.034), ('instances', 0.033), ('verbeek', 0.032), ('approximation', 0.032), ('semantic', 0.032), ('annotations', 0.031), ('euclidean', 0.031), ('michigan', 0.031), ('constraints', 0.03), ('studies', 0.03), ('itml', 0.03), ('precision', 0.029), ('annotated', 0.029), ('developed', 0.028), ('mensink', 0.028), ('observe', 0.027), ('pop', 0.027), ('annotate', 0.027), ('supplementary', 0.027), ('kb', 0.026), ('learned', 0.026), ('prediction', 0.025), ('multimedia', 0.025), ('yj', 0.025), ('efficiency', 0.025), ('verify', 0.025), ('neighbor', 0.025), ('fisher', 0.024), ('examine', 0.024), ('weinberger', 0.024), ('xj', 0.024), ('margin', 0.023), ('lkopf', 0.023), ('rd', 0.023), ('clearer', 0.023), ('mahalanobis', 0.023), ('guillaumin', 0.023), ('converting', 0.023), ('rbf', 0.022), ('semidefinite', 0.022), ('appropriately', 0.021), ('linear', 0.021), ('xi', 0.021), ('training', 0.021), ('infinite', 0.02), ('website', 0.02), ('multimodal', 0.02), ('cone', 0.02), ('feng', 0.02), ('universal', 0.019), ('yi', 0.019), ('stands', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="227-tfidf-1" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>Author: Zheyun Feng, Rong Jin, Anil Jain</p><p>Abstract: One of the key challenges in search-based image annotation models is to define an appropriate similarity measure between images. Many kernel distance metric learning (KML) algorithms have been developed in order to capture the nonlinear relationships between visual features and semantics ofthe images. Onefundamental limitation in applying KML to image annotation is that it requires converting image annotations into binary constraints, leading to a significant information loss. In addition, most KML algorithms suffer from high computational cost due to the requirement that the learned matrix has to be positive semi-definitive (PSD). In this paper, we propose a robust kernel metric learning (RKML) algorithm based on the regression technique that is able to directly utilize image annotations. The proposed method is also computationally more efficient because PSD property is automatically ensured by regression. We provide the theoretical guarantee for the proposed algorithm, and verify its efficiency and effectiveness for image annotation by comparing it to state-of-the-art approaches for both distance metric learning and image annotation. ,</p><p>2 0.12537494 <a title="227-tfidf-2" href="./iccv-2013-From_Point_to_Set%3A_Extend_the_Learning_of_Distance_Metrics.html">177 iccv-2013-From Point to Set: Extend the Learning of Distance Metrics</a></p>
<p>Author: Pengfei Zhu, Lei Zhang, Wangmeng Zuo, David Zhang</p><p>Abstract: Most of the current metric learning methods are proposed for point-to-point distance (PPD) based classification. In many computer vision tasks, however, we need to measure the point-to-set distance (PSD) and even set-to-set distance (SSD) for classification. In this paper, we extend the PPD based Mahalanobis distance metric learning to PSD and SSD based ones, namely point-to-set distance metric learning (PSDML) and set-to-set distance metric learning (SSDML), and solve them under a unified optimization framework. First, we generate positive and negative sample pairs by computing the PSD and SSD between training samples. Then, we characterize each sample pair by its covariance matrix, and propose a covariance kernel based discriminative function. Finally, we tackle the PSDML and SSDMLproblems by using standard support vector machine solvers, making the metric learning very efficient for multiclass visual classification tasks. Experiments on gender classification, digit recognition, object categorization and face recognition show that the proposed metric learning methods can effectively enhance the performance of PSD and SSD based classification.</p><p>3 0.12380076 <a title="227-tfidf-3" href="./iccv-2013-Handling_Uncertain_Tags_in_Visual_Recognition.html">191 iccv-2013-Handling Uncertain Tags in Visual Recognition</a></p>
<p>Author: Arash Vahdat, Greg Mori</p><p>Abstract: Gathering accurate training data for recognizing a set of attributes or tags on images or videos is a challenge. Obtaining labels via manual effort or from weakly-supervised data typically results in noisy training labels. We develop the FlipSVM, a novel algorithm for handling these noisy, structured labels. The FlipSVM models label noise by “flipping ” labels on training examples. We show empirically that the FlipSVM is effective on images-and-attributes and video tagging datasets.</p><p>4 0.10661036 <a title="227-tfidf-4" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>Author: Stefanos Zafeiriou, Irene Kotsia</p><p>Abstract: Kernels have been a common tool of machine learning and computer vision applications for modeling nonlinearities and/or the design of robust1 similarity measures between objects. Arguably, the class of positive semidefinite (psd) kernels, widely known as Mercer’s Kernels, constitutes one of the most well-studied cases. For every psd kernel there exists an associated feature map to an arbitrary dimensional Hilbert space H, the so-called feature space. Tdihme mnsaiionn reason ebreth sipnadc ep s Hd ,ke threne slos’-c c aplolpedul aferiattyu rise the fact that classification/regression techniques (such as Support Vector Machines (SVMs)) and component analysis algorithms (such as Kernel Principal Component Analysis (KPCA)) can be devised in H, without an explicit defisnisiti (oKnP of t)h)e c feature map, only by using athne xkperlniceitl (dtehfeso-called kernel trick). Recently, due to the development of very efficient solutions for large scale linear SVMs and for incremental linear component analysis, the research to- wards finding feature map approximations for classes of kernels has attracted significant interest. In this paper, we attempt the derivation of explicit feature maps of a recently proposed class of kernels, the so-called one-shot similarity kernels. We show that for this class of kernels either there exists an explicit representation in feature space or the kernel can be expressed in such a form that allows for exact incremental learning. We theoretically explore the properties of these kernels and show how these kernels can be used for the development of robust visual tracking, recognition and deformable fitting algorithms. 1Robustness may refer to either the presence of outliers and noise the robustness to a class of transformations (e.g., translation). or to ∗ Irene Kotsia ,†,? ∗Electronics Laboratory, Department of Physics, University of Patras, Greece ?School of Science and Technology, Middlesex University, London i .kot s i @mdx . ac .uk a</p><p>5 0.10400878 <a title="227-tfidf-5" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>Author: Qiong Cao, Yiming Ying, Peng Li</p><p>Abstract: Recently, there is a considerable amount of efforts devoted to the problem of unconstrained face verification, where the task is to predict whether pairs of images are from the same person or not. This problem is challenging and difficult due to the large variations in face images. In this paper, we develop a novel regularization framework to learn similarity metrics for unconstrained face verification. We formulate its objective function by incorporating the robustness to the large intra-personal variations and the discriminative power of novel similarity metrics. In addition, our formulation is a convex optimization problem which guarantees the existence of its global solution. Experiments show that our proposed method achieves the state-of-the-art results on the challenging Labeled Faces in the Wild (LFW) database [10].</p><p>6 0.090259686 <a title="227-tfidf-6" href="./iccv-2013-A_Framework_for_Shape_Analysis_via_Hilbert_Space_Embedding.html">10 iccv-2013-A Framework for Shape Analysis via Hilbert Space Embedding</a></p>
<p>7 0.074132308 <a title="227-tfidf-7" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>8 0.068713404 <a title="227-tfidf-8" href="./iccv-2013-Image_Set_Classification_Using_Holistic_Multiple_Order_Statistics_Features_and_Localized_Multi-kernel_Metric_Learning.html">212 iccv-2013-Image Set Classification Using Holistic Multiple Order Statistics Features and Localized Multi-kernel Metric Learning</a></p>
<p>9 0.06052715 <a title="227-tfidf-9" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>10 0.058847357 <a title="227-tfidf-10" href="./iccv-2013-Unbiased_Metric_Learning%3A_On_the_Utilization_of_Multiple_Datasets_and_Web_Images_for_Softening_Bias.html">431 iccv-2013-Unbiased Metric Learning: On the Utilization of Multiple Datasets and Web Images for Softening Bias</a></p>
<p>11 0.058613013 <a title="227-tfidf-11" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<p>12 0.05802599 <a title="227-tfidf-12" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>13 0.05728123 <a title="227-tfidf-13" href="./iccv-2013-Joint_Learning_of_Discriminative_Prototypes_and_Large_Margin_Nearest_Neighbor_Classifiers.html">222 iccv-2013-Joint Learning of Discriminative Prototypes and Large Margin Nearest Neighbor Classifiers</a></p>
<p>14 0.053814773 <a title="227-tfidf-14" href="./iccv-2013-Nonparametric_Blind_Super-resolution.html">293 iccv-2013-Nonparametric Blind Super-resolution</a></p>
<p>15 0.053374849 <a title="227-tfidf-15" href="./iccv-2013-A_Practical_Transfer_Learning_Algorithm_for_Face_Verification.html">26 iccv-2013-A Practical Transfer Learning Algorithm for Face Verification</a></p>
<p>16 0.053303819 <a title="227-tfidf-16" href="./iccv-2013-Predicting_an_Object_Location_Using_a_Global_Image_Representation.html">327 iccv-2013-Predicting an Object Location Using a Global Image Representation</a></p>
<p>17 0.052711599 <a title="227-tfidf-17" href="./iccv-2013-Compositional_Models_for_Video_Event_Detection%3A_A_Multiple_Kernel_Learning_Latent_Variable_Approach.html">85 iccv-2013-Compositional Models for Video Event Detection: A Multiple Kernel Learning Latent Variable Approach</a></p>
<p>18 0.051904399 <a title="227-tfidf-18" href="./iccv-2013-Combining_the_Right_Features_for_Complex_Event_Recognition.html">81 iccv-2013-Combining the Right Features for Complex Event Recognition</a></p>
<p>19 0.04782718 <a title="227-tfidf-19" href="./iccv-2013-A_New_Image_Quality_Metric_for_Image_Auto-denoising.html">23 iccv-2013-A New Image Quality Metric for Image Auto-denoising</a></p>
<p>20 0.045728561 <a title="227-tfidf-20" href="./iccv-2013-Accurate_Blur_Models_vs._Image_Priors_in_Single_Image_Super-resolution.html">35 iccv-2013-Accurate Blur Models vs. Image Priors in Single Image Super-resolution</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.121), (1, 0.045), (2, -0.03), (3, -0.049), (4, -0.011), (5, 0.049), (6, 0.01), (7, 0.008), (8, 0.016), (9, -0.042), (10, -0.02), (11, -0.069), (12, -0.032), (13, -0.061), (14, 0.01), (15, -0.011), (16, -0.007), (17, -0.031), (18, -0.029), (19, -0.04), (20, -0.015), (21, 0.01), (22, 0.003), (23, 0.039), (24, 0.027), (25, 0.053), (26, 0.07), (27, 0.059), (28, -0.004), (29, 0.083), (30, -0.001), (31, -0.013), (32, -0.041), (33, -0.023), (34, 0.025), (35, 0.063), (36, 0.044), (37, -0.021), (38, -0.014), (39, -0.022), (40, 0.044), (41, -0.021), (42, -0.026), (43, 0.033), (44, 0.148), (45, -0.02), (46, 0.057), (47, -0.052), (48, -0.047), (49, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93497759 <a title="227-lsi-1" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>Author: Zheyun Feng, Rong Jin, Anil Jain</p><p>Abstract: One of the key challenges in search-based image annotation models is to define an appropriate similarity measure between images. Many kernel distance metric learning (KML) algorithms have been developed in order to capture the nonlinear relationships between visual features and semantics ofthe images. Onefundamental limitation in applying KML to image annotation is that it requires converting image annotations into binary constraints, leading to a significant information loss. In addition, most KML algorithms suffer from high computational cost due to the requirement that the learned matrix has to be positive semi-definitive (PSD). In this paper, we propose a robust kernel metric learning (RKML) algorithm based on the regression technique that is able to directly utilize image annotations. The proposed method is also computationally more efficient because PSD property is automatically ensured by regression. We provide the theoretical guarantee for the proposed algorithm, and verify its efficiency and effectiveness for image annotation by comparing it to state-of-the-art approaches for both distance metric learning and image annotation. ,</p><p>2 0.83211935 <a title="227-lsi-2" href="./iccv-2013-From_Point_to_Set%3A_Extend_the_Learning_of_Distance_Metrics.html">177 iccv-2013-From Point to Set: Extend the Learning of Distance Metrics</a></p>
<p>Author: Pengfei Zhu, Lei Zhang, Wangmeng Zuo, David Zhang</p><p>Abstract: Most of the current metric learning methods are proposed for point-to-point distance (PPD) based classification. In many computer vision tasks, however, we need to measure the point-to-set distance (PSD) and even set-to-set distance (SSD) for classification. In this paper, we extend the PPD based Mahalanobis distance metric learning to PSD and SSD based ones, namely point-to-set distance metric learning (PSDML) and set-to-set distance metric learning (SSDML), and solve them under a unified optimization framework. First, we generate positive and negative sample pairs by computing the PSD and SSD between training samples. Then, we characterize each sample pair by its covariance matrix, and propose a covariance kernel based discriminative function. Finally, we tackle the PSDML and SSDMLproblems by using standard support vector machine solvers, making the metric learning very efficient for multiclass visual classification tasks. Experiments on gender classification, digit recognition, object categorization and face recognition show that the proposed metric learning methods can effectively enhance the performance of PSD and SSD based classification.</p><p>3 0.78902739 <a title="227-lsi-3" href="./iccv-2013-Image_Set_Classification_Using_Holistic_Multiple_Order_Statistics_Features_and_Localized_Multi-kernel_Metric_Learning.html">212 iccv-2013-Image Set Classification Using Holistic Multiple Order Statistics Features and Localized Multi-kernel Metric Learning</a></p>
<p>Author: Jiwen Lu, Gang Wang, Pierre Moulin</p><p>Abstract: This paper presents a new approach for image set classification, where each training and testing example contains a set of image instances of an object captured from varying viewpoints or under varying illuminations. While a number of image set classification methods have been proposed in recent years, most of them model each image set as a single linear subspace or mixture of linear subspaces, which may lose some discriminative information for classification. To address this, we propose exploring multiple order statistics as features of image sets, and develop a localized multikernel metric learning (LMKML) algorithm to effectively combine different order statistics information for classification. Our method achieves the state-of-the-art performance on four widely used databases including the Honda/UCSD, CMU Mobo, and Youtube face datasets, and the ETH-80 object dataset.</p><p>4 0.73906124 <a title="227-lsi-4" href="./iccv-2013-Joint_Learning_of_Discriminative_Prototypes_and_Large_Margin_Nearest_Neighbor_Classifiers.html">222 iccv-2013-Joint Learning of Discriminative Prototypes and Large Margin Nearest Neighbor Classifiers</a></p>
<p>Author: Martin Köstinger, Paul Wohlhart, Peter M. Roth, Horst Bischof</p><p>Abstract: In this paper, we raise important issues concerning the evaluation complexity of existing Mahalanobis metric learning methods. The complexity scales linearly with the size of the dataset. This is especially cumbersome on large scale or for real-time applications with limited time budget. To alleviate this problem we propose to represent the dataset by a fixed number of discriminative prototypes. In particular, we introduce a new method that jointly chooses the positioning of prototypes and also optimizes the Mahalanobis distance metric with respect to these. We show that choosing the positioning of the prototypes and learning the metric in parallel leads to a drastically reduced evaluation effort while maintaining the discriminative essence of the original dataset. Moreover, for most problems our method performing k-nearest prototype (k-NP) classification on the condensed dataset leads to even better generalization compared to k-NN classification using all data. Results on a variety of challenging benchmarks demonstrate the power of our method. These include standard machine learning datasets as well as the challenging Public Fig- ures Face Database. On the competitive machine learning benchmarks we are comparable to the state-of-the-art while being more efficient. On the face benchmark we clearly outperform the state-of-the-art in Mahalanobis metric learning with drastically reduced evaluation effort.</p><p>5 0.7300877 <a title="227-lsi-5" href="./iccv-2013-Quadruplet-Wise_Image_Similarity_Learning.html">332 iccv-2013-Quadruplet-Wise Image Similarity Learning</a></p>
<p>Author: Marc T. Law, Nicolas Thome, Matthieu Cord</p><p>Abstract: This paper introduces a novel similarity learning framework. Working with inequality constraints involving quadruplets of images, our approach aims at efficiently modeling similarity from rich or complex semantic label relationships. From these quadruplet-wise constraints, we propose a similarity learning framework relying on a convex optimization scheme. We then study how our metric learning scheme can exploit specific class relationships, such as class ranking (relative attributes), and class taxonomy. We show that classification using the learned metrics gets improved performance over state-of-the-art methods on several datasets. We also evaluate our approach in a new application to learn similarities between webpage screenshots in a fully unsupervised way.</p><p>6 0.71269011 <a title="227-lsi-6" href="./iccv-2013-On_One-Shot_Similarity_Kernels%3A_Explicit_Feature_Maps_and_Properties.html">295 iccv-2013-On One-Shot Similarity Kernels: Explicit Feature Maps and Properties</a></p>
<p>7 0.70303589 <a title="227-lsi-7" href="./iccv-2013-Dynamic_Label_Propagation_for_Semi-supervised_Multi-class_Multi-label_Classification.html">126 iccv-2013-Dynamic Label Propagation for Semi-supervised Multi-class Multi-label Classification</a></p>
<p>8 0.69685829 <a title="227-lsi-8" href="./iccv-2013-A_Framework_for_Shape_Analysis_via_Hilbert_Space_Embedding.html">10 iccv-2013-A Framework for Shape Analysis via Hilbert Space Embedding</a></p>
<p>9 0.68239385 <a title="227-lsi-9" href="./iccv-2013-Heterogeneous_Image_Features_Integration_via_Multi-modal_Semi-supervised_Learning_Model.html">194 iccv-2013-Heterogeneous Image Features Integration via Multi-modal Semi-supervised Learning Model</a></p>
<p>10 0.67457235 <a title="227-lsi-10" href="./iccv-2013-Unbiased_Metric_Learning%3A_On_the_Utilization_of_Multiple_Datasets_and_Web_Images_for_Softening_Bias.html">431 iccv-2013-Unbiased Metric Learning: On the Utilization of Multiple Datasets and Web Images for Softening Bias</a></p>
<p>11 0.66777813 <a title="227-lsi-11" href="./iccv-2013-A_Novel_Earth_Mover%27s_Distance_Methodology_for_Image_Matching_with_Gaussian_Mixture_Models.html">25 iccv-2013-A Novel Earth Mover's Distance Methodology for Image Matching with Gaussian Mixture Models</a></p>
<p>12 0.62691939 <a title="227-lsi-12" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>13 0.62168384 <a title="227-lsi-13" href="./iccv-2013-Ensemble_Projection_for_Semi-supervised_Image_Classification.html">142 iccv-2013-Ensemble Projection for Semi-supervised Image Classification</a></p>
<p>14 0.60107946 <a title="227-lsi-14" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>15 0.58217126 <a title="227-lsi-15" href="./iccv-2013-Learning_to_Rank_Using_Privileged_Information.html">248 iccv-2013-Learning to Rank Using Privileged Information</a></p>
<p>16 0.57840908 <a title="227-lsi-16" href="./iccv-2013-New_Graph_Structured_Sparsity_Model_for_Multi-label_Image_Annotations.html">290 iccv-2013-New Graph Structured Sparsity Model for Multi-label Image Annotations</a></p>
<p>17 0.5747385 <a title="227-lsi-17" href="./iccv-2013-A_Scalable_Unsupervised_Feature_Merging_Approach_to_Efficient_Dimensionality_Reduction_of_High-Dimensional_Visual_Data.html">29 iccv-2013-A Scalable Unsupervised Feature Merging Approach to Efficient Dimensionality Reduction of High-Dimensional Visual Data</a></p>
<p>18 0.56727928 <a title="227-lsi-18" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>19 0.55546427 <a title="227-lsi-19" href="./iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</a></p>
<p>20 0.55427814 <a title="227-lsi-20" href="./iccv-2013-Recursive_Estimation_of_the_Stein_Center_of_SPD_Matrices_and_Its_Applications.html">347 iccv-2013-Recursive Estimation of the Stein Center of SPD Matrices and Its Applications</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.096), (7, 0.025), (10, 0.012), (26, 0.071), (31, 0.045), (42, 0.101), (64, 0.056), (73, 0.014), (78, 0.013), (89, 0.136), (97, 0.307), (98, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85744274 <a title="227-lda-1" href="./iccv-2013-Saliency_and_Human_Fixations%3A_State-of-the-Art_and_Study_of_Comparison_Metrics.html">373 iccv-2013-Saliency and Human Fixations: State-of-the-Art and Study of Comparison Metrics</a></p>
<p>Author: Nicolas Riche, Matthieu Duvinage, Matei Mancas, Bernard Gosselin, Thierry Dutoit</p><p>Abstract: Visual saliency has been an increasingly active research area in the last ten years with dozens of saliency models recently published. Nowadays, one of the big challenges in the field is to find a way to fairly evaluate all of these models. In this paper, on human eye fixations ,we compare the ranking of 12 state-of-the art saliency models using 12 similarity metrics. The comparison is done on Jian Li ’s database containing several hundreds of natural images. Based on Kendall concordance coefficient, it is shown that some of the metrics are strongly correlated leading to a redundancy in the performance metrics reported in the available benchmarks. On the other hand, other metrics provide a more diverse picture of models ’ overall performance. As a recommendation, three similarity metrics should be used to obtain a complete point of view of saliency model performance.</p><p>2 0.7837612 <a title="227-lda-2" href="./iccv-2013-Recursive_Estimation_of_the_Stein_Center_of_SPD_Matrices_and_Its_Applications.html">347 iccv-2013-Recursive Estimation of the Stein Center of SPD Matrices and Its Applications</a></p>
<p>Author: Hesamoddin Salehian, Guang Cheng, Baba C. Vemuri, Jeffrey Ho</p><p>Abstract: Symmetric positive-definite (SPD) matrices are ubiquitous in Computer Vision, Machine Learning and Medical Image Analysis. Finding the center/average of a population of such matrices is a common theme in many algorithms such as clustering, segmentation, principal geodesic analysis, etc. The center of a population of such matrices can be defined using a variety of distance/divergence measures as the minimizer of the sum of squared distances/divergences from the unknown center to the members of the population. It is well known that the computation of the Karcher mean for the space of SPD matrices which is a negativelycurved Riemannian manifold is computationally expensive. Recently, the LogDet divergence-based center was shown to be a computationally attractive alternative. However, the LogDet-based mean of more than two matrices can not be computed in closed form, which makes it computationally less attractive for large populations. In this paper we present a novel recursive estimator for center based on the Stein distance which is the square root of the LogDet di– vergence that is significantly faster than the batch mode computation of this center. The key theoretical contribution is a closed-form solution for the weighted Stein center of two SPD matrices, which is used in the recursive computation of the Stein center for a population of SPD matrices. Additionally, we show experimental evidence of the convergence of our recursive Stein center estimator to the batch mode Stein center. We present applications of our recursive estimator to K-means clustering and image indexing depicting significant time gains over corresponding algorithms that use the batch mode computations. For the latter application, we develop novel hashing functions using the Stein distance and apply it to publicly available data sets, and experimental results have shown favorable com– ∗This research was funded in part by the NIH grant NS066340 to BCV. †Corresponding author parisons to other competing methods.</p><p>3 0.73997015 <a title="227-lda-3" href="./iccv-2013-Synergistic_Clustering_of_Image_and_Segment_Descriptors_for_Unsupervised_Scene_Understanding.html">412 iccv-2013-Synergistic Clustering of Image and Segment Descriptors for Unsupervised Scene Understanding</a></p>
<p>Author: Daniel M. Steinberg, Oscar Pizarro, Stefan B. Williams</p><p>Abstract: With the advent of cheap, high fidelity, digital imaging systems, the quantity and rate of generation of visual data can dramatically outpace a humans ability to label or annotate it. In these situations there is scope for the use of unsupervised approaches that can model these datasets and automatically summarise their content. To this end, we present a totally unsupervised, and annotation-less, model for scene understanding. This model can simultaneously cluster whole-image and segment descriptors, therebyforming an unsupervised model of scenes and objects. We show that this model outperforms other unsupervised models that can only cluster one source of information (image or segment) at once. We are able to compare unsupervised and supervised techniques using standard measures derived from confusion matrices and contingency tables. This shows that our unsupervised model is competitive with current supervised and weakly-supervised models for scene understanding on standard datasets. We also demonstrate our model operating on a dataset with more than 100,000 images col- lected by an autonomous underwater vehicle.</p><p>same-paper 4 0.72997475 <a title="227-lda-4" href="./iccv-2013-Large-Scale_Image_Annotation_by_Efficient_and_Robust_Kernel_Metric_Learning.html">227 iccv-2013-Large-Scale Image Annotation by Efficient and Robust Kernel Metric Learning</a></p>
<p>Author: Zheyun Feng, Rong Jin, Anil Jain</p><p>Abstract: One of the key challenges in search-based image annotation models is to define an appropriate similarity measure between images. Many kernel distance metric learning (KML) algorithms have been developed in order to capture the nonlinear relationships between visual features and semantics ofthe images. Onefundamental limitation in applying KML to image annotation is that it requires converting image annotations into binary constraints, leading to a significant information loss. In addition, most KML algorithms suffer from high computational cost due to the requirement that the learned matrix has to be positive semi-definitive (PSD). In this paper, we propose a robust kernel metric learning (RKML) algorithm based on the regression technique that is able to directly utilize image annotations. The proposed method is also computationally more efficient because PSD property is automatically ensured by regression. We provide the theoretical guarantee for the proposed algorithm, and verify its efficiency and effectiveness for image annotation by comparing it to state-of-the-art approaches for both distance metric learning and image annotation. ,</p><p>5 0.70520741 <a title="227-lda-5" href="./iccv-2013-A_Max-Margin_Perspective_on_Sparse_Representation-Based_Classification.html">20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</a></p>
<p>Author: Zhaowen Wang, Jianchao Yang, Nasser Nasrabadi, Thomas Huang</p><p>Abstract: Sparse Representation-based Classification (SRC) is a powerful tool in distinguishing signal categories which lie on different subspaces. Despite its wide application to visual recognition tasks, current understanding of SRC is solely based on a reconstructive perspective, which neither offers any guarantee on its classification performance nor provides any insight on how to design a discriminative dictionary for SRC. In this paper, we present a novel perspective towards SRC and interpret it as a margin classifier. The decision boundary and margin of SRC are analyzed in local regions where the support of sparse code is stable. Based on the derived margin, we propose a hinge loss function as the gauge for the classification performance of SRC. A stochastic gradient descent algorithm is implemented to maximize the margin of SRC and obtain more discriminative dictionaries. Experiments validate the effectiveness of the proposed approach in predicting classification performance and improving dictionary quality over reconstructive ones. Classification results competitive with other state-ofthe-art sparse coding methods are reported on several data sets.</p><p>6 0.69254446 <a title="227-lda-6" href="./iccv-2013-Saliency_Detection_via_Dense_and_Sparse_Reconstruction.html">372 iccv-2013-Saliency Detection via Dense and Sparse Reconstruction</a></p>
<p>7 0.6914767 <a title="227-lda-7" href="./iccv-2013-Analysis_of_Scores%2C_Datasets%2C_and_Models_in_Visual_Saliency_Prediction.html">50 iccv-2013-Analysis of Scores, Datasets, and Models in Visual Saliency Prediction</a></p>
<p>8 0.68369353 <a title="227-lda-8" href="./iccv-2013-Tracking_via_Robust_Multi-task_Multi-view_Joint_Sparse_Representation.html">425 iccv-2013-Tracking via Robust Multi-task Multi-view Joint Sparse Representation</a></p>
<p>9 0.6621815 <a title="227-lda-9" href="./iccv-2013-Saliency_Detection%3A_A_Boolean_Map_Approach.html">369 iccv-2013-Saliency Detection: A Boolean Map Approach</a></p>
<p>10 0.64495653 <a title="227-lda-10" href="./iccv-2013-Contextual_Hypergraph_Modeling_for_Salient_Object_Detection.html">91 iccv-2013-Contextual Hypergraph Modeling for Salient Object Detection</a></p>
<p>11 0.63503301 <a title="227-lda-11" href="./iccv-2013-Saliency_Detection_via_Absorbing_Markov_Chain.html">371 iccv-2013-Saliency Detection via Absorbing Markov Chain</a></p>
<p>12 0.63396466 <a title="227-lda-12" href="./iccv-2013-Category-Independent_Object-Level_Saliency_Detection.html">71 iccv-2013-Category-Independent Object-Level Saliency Detection</a></p>
<p>13 0.60628623 <a title="227-lda-13" href="./iccv-2013-Space-Time_Robust_Representation_for_Action_Recognition.html">396 iccv-2013-Space-Time Robust Representation for Action Recognition</a></p>
<p>14 0.60258603 <a title="227-lda-14" href="./iccv-2013-From_Where_and_How_to_What_We_See.html">180 iccv-2013-From Where and How to What We See</a></p>
<p>15 0.59961474 <a title="227-lda-15" href="./iccv-2013-Efficient_Salient_Region_Detection_with_Soft_Image_Abstraction.html">137 iccv-2013-Efficient Salient Region Detection with Soft Image Abstraction</a></p>
<p>16 0.59258956 <a title="227-lda-16" href="./iccv-2013-Robust_Object_Tracking_with_Online_Multi-lifespan_Dictionary_Learning.html">359 iccv-2013-Robust Object Tracking with Online Multi-lifespan Dictionary Learning</a></p>
<p>17 0.588422 <a title="227-lda-17" href="./iccv-2013-Randomized_Ensemble_Tracking.html">338 iccv-2013-Randomized Ensemble Tracking</a></p>
<p>18 0.58084589 <a title="227-lda-18" href="./iccv-2013-Semantically-Based_Human_Scanpath_Estimation_with_HMMs.html">381 iccv-2013-Semantically-Based Human Scanpath Estimation with HMMs</a></p>
<p>19 0.5766536 <a title="227-lda-19" href="./iccv-2013-Log-Euclidean_Kernels_for_Sparse_Representation_and_Dictionary_Learning.html">257 iccv-2013-Log-Euclidean Kernels for Sparse Representation and Dictionary Learning</a></p>
<p>20 0.57581615 <a title="227-lda-20" href="./iccv-2013-Affine-Constrained_Group_Sparse_Coding_and_Its_Application_to_Image-Based_Classifications.html">45 iccv-2013-Affine-Constrained Group Sparse Coding and Its Application to Image-Based Classifications</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
