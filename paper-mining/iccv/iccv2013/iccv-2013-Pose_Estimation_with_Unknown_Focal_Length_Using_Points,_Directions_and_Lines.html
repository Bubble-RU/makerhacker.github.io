<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-323" href="#">iccv2013-323</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</h1>
<br/><p>Source: <a title="iccv-2013-323-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Kuang_Pose_Estimation_with_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>Reference: <a title="iccv-2013-323-reference" href="../iccv2013_reference/iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 s e  Abstract In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. [sent-3, score-0.928]
</p><p>2 We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. [sent-7, score-0.328]
</p><p>3 We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. [sent-8, score-0.769]
</p><p>4 The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. [sent-9, score-1.304]
</p><p>5 We demonstrate in synthetic experiments that our solvers are fast and numerically stable. [sent-11, score-0.635]
</p><p>6 For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions. [sent-12, score-0.52]
</p><p>7 The minimal case of pose estimation using 3 points was studied in [10] and several other formulations are compared and reviewed in [12]. [sent-15, score-0.366]
</p><p>8 For line-to-line correspondences, solutions are derived for minimal of 3 lines in [8, 7]. [sent-16, score-0.317]
</p><p>9 Recently, the minimal cases using combination of points and lines are solved in [27]. [sent-17, score-0.381]
</p><p>10 In [9] a solver is derived for a minimal problem of 2 points and their corresponding tangent directions (equivalently any direction vector through each of the points). [sent-18, score-0.476]
</p><p>11 For camera pose estimation with unknown focal length, the planar case was studied and solved in [1]. [sent-21, score-0.888]
</p><p>12 Efficient and numerically stable solvers are developed in [4]. [sent-23, score-0.579]
</p><p>13 2D-2D and 2D-3D correspondence, [19] investigated several minimal cases for pose estimation with unknown focal length. [sent-44, score-0.867]
</p><p>14 Additionally, for camera with unknown radial distortion and unknown focal length, the 4-point minimal case is solved in [18, 5]. [sent-45, score-0.92]
</p><p>15 Many other works focus on solving the over-constrained problem of estimating camera pose with more than three points [15, 25, 24] or lines [25]. [sent-46, score-0.432]
</p><p>16 Very recently, the approach in [24] was extended to handle unknown focal length [26]. [sent-47, score-0.66]
</p><p>17 Minimal solvers are the key component of the preprocessing steps for such overconstrained solvers to robustly remove outliers. [sent-49, score-0.978]
</p><p>18 To be able to utilize correspondences of geometric primitives like points, directions and lines is of great interest to applications e. [sent-50, score-0.428]
</p><p>19 In typical scenarios of vision-based localization, focal length of the camera is the only unknown that is most difficult to determine accurately (EXIF-tag could provide erroneous estimate) and can render large errors in the pose estimation. [sent-54, score-0.954]
</p><p>20 All previous methods for pose estimation with unknown focal length use point correspondences. [sent-55, score-0.861]
</p><p>21 The contribution of this paper is to enable a wider class of geometric features (combinations of points, lines and n-quivers, Figure 1) for simultaneous pose estimation and focal length  calibration. [sent-56, score-0.887]
</p><p>22 We then develop efficient polynomial solvers for several new minimal cases and a slightly over-determined cases using 4 lines. [sent-60, score-0.893]
</p><p>23 We verify our solvers on both synthetic and real images to demonstrate their efficiency and usability in RANSAC. [sent-61, score-0.639]
</p><p>24 ×  (1) 4 which can be  (2)  The rotation matrix R encodes orientational part of the camera pose specifying in which direction the camera is pointing and t relates to the camera position. [sent-66, score-0.545]
</p><p>25 In this paper, we thereafter assume that the calibration matrix only involves the unknown focal length f. [sent-69, score-0.692]
</p><p>26 The K matrix can be equivalently written as  K =⎣⎡010 10 w00⎦⎤,  (3)  where w = 1/f and f is focal length of the camera. [sent-70, score-0.594]
</p><p>27 We know that the problem of determining camera pose with unknown focal length has in total 7 degrees of freedom (3 in rotation, 3 in translation and 1in f). [sent-71, score-0.943]
</p><p>28 If the 3D line L is represented as a 3D point X and the direction of the line D, one can obtain two equations for the two points in the following form based on (1): lTPX = 0 lTP(X + kD) = 0,  (5)  where k is an arbitrary constant. [sent-83, score-0.494]
</p><p>29 Number of constraints enforced by 2D-3D correspondences of different geometric primitive for camera pose estimation. [sent-93, score-0.436]
</p><p>30 Useful Cases With 2D-3D correspondences of points, lines and nquivers, one can form several novel minimal cases by searching for combination such that 2mp + 2ml + (n +  2)mq = 7, where mp, ml , mq are the number of point, line, n-quiver correspondences, respectively. [sent-96, score-0.421]
</p><p>31 Two Points and One 1-Quiver (P2Q1) : Given three points and one direction passing through one of the points, we can form 6 equations based on (4) and 1equation based on (6). [sent-98, score-0.329]
</p><p>32 One 1-Quiver and One 2-Quiver (Q1Q2) : For two points, where one line passing through one of the point, and two lines passing through the other point are known, we can form 4 point equations (4) and 3 equations with respect to the directions (6). [sent-100, score-0.792]
</p><p>33 Thus, the problem of camera pose with unknown focal length is overdetermined with 4 lines. [sent-103, score-0.881]
</p><p>34 In a similar manner, other minimal cases include the setups: (i) one point, one line and one 1-quiver (ii) one 3quiver and one point (iii) two lines and one 1-quiver which can be solved in similar manner as the presented solvers. [sent-105, score-0.423]
</p><p>35 Once the rotational part is recovered, the focal length can easily be calculated using the ratios between the norms of the third and the first two rows of R. [sent-112, score-0.588]
</p><p>36 [4] formulate the P4P problem with unknown focal length using the invariance of the ratios of distances between the 3D points under rigid transformation. [sent-115, score-0.819]
</p><p>37 To start with, we can use the three points to form 2 independent distance ratio equations involving three unknowns (two relative stretch ratios α1,α2 and f) as in [4]. [sent-120, score-0.408]
</p><p>38 However, the resulting equations consists at least one equation of degree 6 (after substitution and simplification) which makes the resulting −  polynomial system very difficult to solve. [sent-124, score-0.39]
</p><p>39 While the use of geometric invariance might yield polynomial system with fewer solutions for previous problems, it is not straightforward to see that such property is preserved for other primitives like directions with unknown focal length. [sent-125, score-1.055]
</p><p>40 In this paper, we first parameterize the rotation matrix R with quaternion and construct equations directly based on (4), (5) and (6). [sent-126, score-0.34]
</p><p>41 For polynomial systems with small number of unknowns, Gr¨ obner basis methods are generally fast and numerically stable. [sent-153, score-0.347]
</p><p>42 Solving polynomial systems can also be seen as solving polynomial eigenvalue problems [13, 23]. [sent-154, score-0.418]
</p><p>43 Experiments  In this section, we study the performance of our solvers on both synthetic and real data. [sent-169, score-0.603]
</p><p>44 The camera was calibrated except for the focal length. [sent-176, score-0.548]
</p><p>45 1  Stability and Number of Solutions  We evaluate first the solvers on noise-free data to check the numerical stability of the solvers and distribution of number of valid solutions. [sent-179, score-1.111]
</p><p>46 For the simulation results in Figure 3, the focal length of the camera was set to around 1000. [sent-180, score-0.666]
</p><p>47 The numerical errors for all our solvers are fairly low for most of the cases. [sent-181, score-0.672]
</p><p>48 T−15wLog0preal1tivn orsd−5tfcanlsoite10-qrFycnu2150 i ver,1sy2nt3Nuhmb4eriofc5alsx6uptoine7rm8sf  5000 runs on noise-free data with focal length approximately 1000. [sent-185, score-0.586]
</p><p>49 Left: Histogram of relative errors for rotation, translation, focal length; Right: Histogram of number solutions with real and positive focal lengths. [sent-186, score-1.062]
</p><p>50 We can see that for noise-free data, the Gr¨ obner basis solver for (P2Q1) is consistently stable for different focal lengths for both planar and non-planar scenes (Figure 4). [sent-192, score-0.882]
</p><p>51 Similar numerical behaviors are observed for the solver using lines (P4L, Figure 5). [sent-193, score-0.348]
</p><p>52 Given that the performance of other solvers are similar, related figures are not shown individually here. [sent-194, score-0.489]
</p><p>53 Our solvers can also be further optimized for speed using strategies in [22, 21]. [sent-198, score-0.489]
</p><p>54 2  Noise Sensitivity  To study the behaviors of the solvers with noisy measurements, we add noise of different levels both to the image point positions and the angles of the directions. [sent-203, score-0.628]
</p><p>55 In Figure 6, it is shown that the P2Q1 solver gives fairly good estimates for focal lengths with small noise, and is still able to provide (though not as frequently) reasonably good initial solutions when the noise is around 5 pixels. [sent-204, score-0.781]
</p><p>56 We have also noticed that the solvers can be sensitive to errors in the direction measurements. [sent-205, score-0.611]
</p><p>57 We also test the P4L solvers for noisy line measurements by perturbing the intersections between the lines and the x, y axis. [sent-206, score-0.771]
</p><p>58 From Figure 7, we can see that the P4L solver is capable of recovering the focal length accurately for small perturbation and can become unreliable for large perturbation. [sent-207, score-0.676]
</p><p>59 Synthetic experiments of P2Q1 on noise-free data with varying focal lengths. [sent-209, score-0.437]
</p><p>60 Left: Boxplot of relative errors of focal lengths for non-planar points and directions; Right: planar cases. [sent-210, score-0.825]
</p><p>61 Synthetic experiment of P4L on noise-free data with varying focal lengths. [sent-212, score-0.437]
</p><p>62 Left: Boxplot of the relative errors of focal lengths for non-planar line configurations Right: planar cases. [sent-213, score-0.821]
</p><p>63 Left: Relative errors of focal lengths for non-planar lines; Right: planar cases. [sent-230, score-0.717]
</p><p>64 ity, we demonstrate the performance of the solvers on real image measurements in Section 4. [sent-231, score-0.568]
</p><p>65 3  RANSAC Experiments  To test the advantage of the proposed solvers for different geometric primitives, we simulate data with outliers and  Figure 8. [sent-235, score-0.569]
</p><p>66 Distribution ofinlier proportions for 1000 RANSAC runs for different solvers P4P, P2Q1 and Q1Q2. [sent-236, score-0.52]
</p><p>67 For a fixed camera with focal length 1000, we generate randomly 1000 scene points as in the previous section, directions through points are also generated randomly. [sent-238, score-0.923]
</p><p>68 We compare the solvers for two points and one 1-quiver (P2Q1) and one 1-quiver and one 2-quiver (Q1Q2) with the P4P solver in [4]. [sent-241, score-0.691]
</p><p>69 Here we define the inliers as the image points with reprojection errors less than a predefined threshold. [sent-243, score-0.358]
</p><p>70 Real Data We took 16 images of seven cardboards placed in a nonplanar configuration with varying focal lengths (Figure 9), using a standard Canon EOS 50D camera. [sent-248, score-0.564]
</p><p>71 We used these images to verify the applicability of the proposed solvers on real images with point, line and quiver features. [sent-252, score-0.804]
</p><p>72 The resulting construction of the 3D points and the camera poses as well as the focal lengths after bundle adjust-  ment are fairly accurate and thus serves as ground truth. [sent-263, score-0.865]
</p><p>73 Given the reconstruction of the detected lines and intersection points, we use the proposed solvers to estimate both the camera poses and the focal lengths for each of the image. [sent-264, score-1.294]
</p><p>74 We first look at the reprojection errors of the poses and focal lengths estimated using different solvers and investigate whether the solvers adapt to real image noisy measurements. [sent-267, score-1.753]
</p><p>75 To measure the reprojection errors, we run different solvers in a RANSAC manner by choosing random minimal measurements. [sent-268, score-0.726]
</p><p>76 The average reprojection errors of image points for each solver are reported in Table 2. [sent-269, score-0.382]
</p><p>77 We can see from Table 2 that the errors of all our proposed solvers are similar to the P4P solver. [sent-270, score-0.562]
</p><p>78 Average reprojection errors (in pixels) of image points with camera poses and focal lengths of the 16 images estimated with different solvers. [sent-276, score-0.936]
</p><p>79 Statistics of focal length estimation of different solvers, bundle adjustment and exif-tag for the Cardboard dataset. [sent-278, score-0.704]
</p><p>80 For the inlier threshold of 3 pixels, the number of inliers (among in total 621 measurements) and the average reprojection errors for inliers are reported in Table 3. [sent-281, score-0.428]
</p><p>81 The slightly inferior performance of Q1Q2 and P4L solvers might be due to the sensitivity of both solvers to measurement errors in the quiver directions and lines. [sent-283, score-1.353]
</p><p>82 Number of inliers and average reprojection errors (in pixels) ofinliers with 30% synthetic outliers for the cardboard dataset. [sent-289, score-0.45]
</p><p>83 To evaluate the accuracy of the solvers, we compare the best focal length estimated (the one with maximum number of inliers) for each solver against the output from bundle adjustment as well as those extracted from EXIF-tag (conversion from 35mm film equivalent). [sent-290, score-0.78]
</p><p>84 The statistics of the estimated focal lengths are shown in Figure 10. [sent-292, score-0.564]
</p><p>85 It is noted that the focal lengths given by the exif information seems to be very coarse compared to those estimates from image data directly. [sent-293, score-0.564]
</p><p>86 We can also see that all solvers gives fairly similar estimates to the results from bundle adjustment. [sent-294, score-0.598]
</p><p>87 Discussions For the simpler calibrated pose estimation problem, we also see the potential ofcombining the simplicity the quaternion parameterization and the stability of Gr¨ obner basis 534  solvers. [sent-296, score-0.484]
</p><p>88 In [9], the minimal case of equivalently two 1-  quivers (the direction is detected as the tangent to curves instead of arbitrary direction) for pose estimation was studied. [sent-297, score-0.446]
</p><p>89 Conclusions In this paper, we present several novel cases for pose estimation with unknown focal length utilizing combinations of points, lines and quivers. [sent-302, score-1.031]
</p><p>90 We have shown that these solvers are fast and numerically stable. [sent-306, score-0.552]
</p><p>91 The availability of such solvers will serve as an important step towards pose estimation with richer features and also shed light on structure from motion problem with line/direction features which are  common in urban scenes. [sent-308, score-0.644]
</p><p>92 The other key direction is to evaluate the application of new solvers to discriminative feature like SIFT to ease the correspondence problem for edges (direction of a quiver and line). [sent-310, score-0.749]
</p><p>93 In this case, one need to verify whether the solvers are robust against noisy estimation of the gradient directions. [sent-313, score-0.57]
</p><p>94 To improve the speed and numerical stability of the solvers, it is of interest to resolve the intrinsic symmetry in the quaternion parameterization either by algebraic manipulation or by deriving alternative set of constraints using geometric invariances. [sent-314, score-0.449]
</p><p>95 1Codes for the proposed solvers are available for download http://www2. [sent-317, score-0.489]
</p><p>96 A general solution to the p4p problem for camera with unknown focal length. [sent-341, score-0.653]
</p><p>97 New efficient solution to the absolute pose problem for camera with unknown focal length and radial distortion. [sent-349, score-0.913]
</p><p>98 Pose estimation with radial distortion and unknown focal length. [sent-445, score-0.619]
</p><p>99 Numerically stable optimization of polynomial solvers for minimal problems. [sent-465, score-0.84]
</p><p>100 Exhaustive linearization for robust camera pose and focal length estimation. [sent-500, score-0.776]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('solvers', 0.489), ('focal', 0.437), ('polynomial', 0.194), ('quiver', 0.171), ('equations', 0.164), ('lines', 0.13), ('minimal', 0.13), ('lengths', 0.127), ('solver', 0.121), ('quaternion', 0.121), ('length', 0.118), ('camera', 0.111), ('pose', 0.11), ('reprojection', 0.107), ('unknown', 0.105), ('unknowns', 0.103), ('inliers', 0.097), ('directions', 0.095), ('bujnak', 0.094), ('ransac', 0.094), ('obner', 0.09), ('str', 0.086), ('synthetic', 0.083), ('points', 0.081), ('correspondences', 0.081), ('planar', 0.08), ('line', 0.077), ('primitives', 0.075), ('errors', 0.073), ('boxplot', 0.073), ('byr', 0.073), ('quivers', 0.073), ('kukelova', 0.072), ('numerical', 0.071), ('bundle', 0.07), ('numerically', 0.063), ('elimination', 0.063), ('stability', 0.062), ('gr', 0.06), ('constraints', 0.059), ('solutions', 0.057), ('cardboard', 0.057), ('parameterization', 0.056), ('inlier', 0.054), ('josephson', 0.054), ('direction', 0.049), ('measurements', 0.048), ('geometric', 0.047), ('point', 0.046), ('ty', 0.046), ('combinations', 0.046), ('tx', 0.046), ('estimation', 0.045), ('invariance', 0.045), ('monomials', 0.043), ('yubin', 0.043), ('kuang', 0.04), ('percentiles', 0.04), ('mq', 0.04), ('correspondence', 0.04), ('cases', 0.04), ('directional', 0.039), ('equivalently', 0.039), ('fairly', 0.039), ('international', 0.038), ('conference', 0.037), ('verify', 0.036), ('measurement', 0.036), ('passing', 0.035), ('strategic', 0.035), ('positions', 0.034), ('adjustment', 0.034), ('outliers', 0.033), ('ratios', 0.033), ('angles', 0.033), ('algebraic', 0.033), ('degree', 0.032), ('qr', 0.032), ('generator', 0.032), ('pages', 0.032), ('calibration', 0.032), ('radial', 0.032), ('setups', 0.031), ('degrees', 0.031), ('runs', 0.031), ('real', 0.031), ('freedom', 0.031), ('eigenvalue', 0.03), ('perturbed', 0.03), ('rotation', 0.028), ('determination', 0.028), ('perturbations', 0.028), ('primitive', 0.028), ('relative', 0.027), ('stable', 0.027), ('parameterize', 0.027), ('intersections', 0.027), ('icra', 0.027), ('behaviors', 0.026), ('pointing', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="323-tfidf-1" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>2 0.44813818 <a title="323-tfidf-2" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>3 0.31175774 <a title="323-tfidf-3" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>Author: Adrien Bartoli, Daniel Pizarro, Toby Collins</p><p>Abstract: We study the uncalibrated isometric Shape-fromTemplate problem, that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown. Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. This was achieved through two key steps. First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. We use a variational framework, implemented using a smooth function basis and sampled local deformation models. The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy – slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods.</p><p>4 0.22860433 <a title="323-tfidf-4" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>Author: Yinqiang Zheng, Yubin Kuang, Shigeki Sugimoto, Kalle Åström, Masatoshi Okutomi</p><p>Abstract: In this paper, we revisit the classical perspective-n-point (PnP) problem, and propose the first non-iterative O(n) solution that is fast, generally applicable and globally optimal. Our basic idea is to formulate the PnP problem into a functional minimization problem and retrieve all its stationary points by using the Gr¨ obner basis technique. The novelty lies in a non-unit quaternion representation to parameterize the rotation and a simple but elegant formulation of the PnP problem into an unconstrained optimization problem. Interestingly, the polynomial system arising from its first-order optimality condition assumes two-fold symmetry, a nice property that can be utilized to improve speed and numerical stability of a Gr¨ obner basis solver. Experiment results have demonstrated that, in terms of accuracy, our proposed solution is definitely better than the state-ofthe-art O(n) methods, and even comparable with the reprojection error minimization method.</p><p>5 0.19144052 <a title="323-tfidf-5" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>Author: Laurent Kneip, Simon Lynen</p><p>Abstract: This work makes use of a novel, recently proposed epipolar constraint for computing the relative pose between two calibrated images. By enforcing the coplanarity of epipolar plane normal vectors, it constrains the three degrees of freedom of the relative rotation between two camera views directly—independently of the translation. The present paper shows how the approach can be extended to n points, and translated into an efficient eigenvalue minimization over the three rotational degrees of freedom. Each iteration in the non-linear optimization has constant execution time, independently of the number of features. Two global optimization approaches are proposed. The first one consists of an efficient Levenberg-Marquardt scheme with randomized initial value, which already leads to stable and accurate results. The second scheme consists of a globally optimal branch-and-bound algorithm based on a bound on the eigenvalue variation derived from symmetric eigenvalue-perturbation theory. Analysis of the cost function reveals insights into the nature of a specific relative pose problem, and outlines the complexity under different conditions. The algorithm shows state-of-the-art performance w.r.t. essential-matrix based solutions, and a frameto-frame application to a video sequence immediately leads to an alternative, real-time visual odometry solution. Note: All algorithms in this paper are made available in the OpenGV library. Please visit http : / / l aurent kne ip .github . i / opengv o</p><p>6 0.12913498 <a title="323-tfidf-6" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>7 0.12327666 <a title="323-tfidf-7" href="./iccv-2013-Lifting_3D_Manhattan_Lines_from_a_Single_Image.html">250 iccv-2013-Lifting 3D Manhattan Lines from a Single Image</a></p>
<p>8 0.11741505 <a title="323-tfidf-8" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>9 0.1154711 <a title="323-tfidf-9" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>10 0.10816436 <a title="323-tfidf-10" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>11 0.10387892 <a title="323-tfidf-11" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>12 0.10078506 <a title="323-tfidf-12" href="./iccv-2013-Real-World_Normal_Map_Capture_for_Nearly_Flat_Reflective_Surfaces.html">343 iccv-2013-Real-World Normal Map Capture for Nearly Flat Reflective Surfaces</a></p>
<p>13 0.10068001 <a title="323-tfidf-13" href="./iccv-2013-SUN3D%3A_A_Database_of_Big_Spaces_Reconstructed_Using_SfM_and_Object_Labels.html">367 iccv-2013-SUN3D: A Database of Big Spaces Reconstructed Using SfM and Object Labels</a></p>
<p>14 0.097648367 <a title="323-tfidf-14" href="./iccv-2013-Monocular_Image_3D_Human_Pose_Estimation_under_Self-Occlusion.html">273 iccv-2013-Monocular Image 3D Human Pose Estimation under Self-Occlusion</a></p>
<p>15 0.096830331 <a title="323-tfidf-15" href="./iccv-2013-Parsing_IKEA_Objects%3A_Fine_Pose_Estimation.html">308 iccv-2013-Parsing IKEA Objects: Fine Pose Estimation</a></p>
<p>16 0.092571534 <a title="323-tfidf-16" href="./iccv-2013-Street_View_Motion-from-Structure-from-Motion.html">402 iccv-2013-Street View Motion-from-Structure-from-Motion</a></p>
<p>17 0.086489424 <a title="323-tfidf-17" href="./iccv-2013-Data-Driven_3D_Primitives_for_Single_Image_Understanding.html">102 iccv-2013-Data-Driven 3D Primitives for Single Image Understanding</a></p>
<p>18 0.086030126 <a title="323-tfidf-18" href="./iccv-2013-Refractive_Structure-from-Motion_on_Underwater_Images.html">348 iccv-2013-Refractive Structure-from-Motion on Underwater Images</a></p>
<p>19 0.080058955 <a title="323-tfidf-19" href="./iccv-2013-Extrinsic_Camera_Calibration_without_a_Direct_View_Using_Spherical_Mirror.html">152 iccv-2013-Extrinsic Camera Calibration without a Direct View Using Spherical Mirror</a></p>
<p>20 0.079454251 <a title="323-tfidf-20" href="./iccv-2013-Automatic_Registration_of_RGB-D_Scans_via_Salient_Directions.html">56 iccv-2013-Automatic Registration of RGB-D Scans via Salient Directions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, -0.156), (2, -0.067), (3, 0.026), (4, -0.03), (5, 0.032), (6, 0.059), (7, -0.115), (8, 0.055), (9, 0.02), (10, 0.047), (11, -0.036), (12, -0.208), (13, -0.025), (14, 0.06), (15, 0.154), (16, 0.146), (17, 0.14), (18, -0.007), (19, 0.034), (20, 0.11), (21, -0.184), (22, -0.079), (23, -0.034), (24, 0.002), (25, 0.0), (26, 0.106), (27, -0.02), (28, -0.154), (29, -0.051), (30, -0.1), (31, 0.095), (32, -0.096), (33, 0.015), (34, -0.128), (35, -0.119), (36, -0.069), (37, -0.136), (38, -0.018), (39, 0.097), (40, 0.005), (41, -0.041), (42, 0.038), (43, -0.06), (44, -0.05), (45, 0.014), (46, 0.12), (47, -0.053), (48, -0.003), (49, -0.124)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96536064 <a title="323-lsi-1" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>2 0.96018988 <a title="323-lsi-2" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>Author: Zuzana Kukelova, Martin Bujnak, Tomas Pajdla</p><p>Abstract: Theproblem ofdetermining the absoluteposition andorientation of a camera from a set of 2D-to-3D point correspondences is one of the most important problems in computer vision with a broad range of applications. In this paper we present a new solution to the absolute pose problem for camera with unknown radial distortion and unknown focal length from five 2D-to-3D point correspondences. Our new solver is numerically more stable, more accurate, and significantly faster than the existing state-of-the-art minimal fourpoint absolutepose solvers for this problem. Moreover, our solver results in less solutions and can handle larger radial distortions. The new solver is straightforward and uses only simple concepts from linear algebra. Therefore it is simpler than the state-of-the-art Gr¨ obner basis solvers. We compare our new solver with the existing state-of-theart solvers and show its usefulness on synthetic and real datasets. 1</p><p>3 0.86996162 <a title="323-lsi-3" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>Author: Yinqiang Zheng, Yubin Kuang, Shigeki Sugimoto, Kalle Åström, Masatoshi Okutomi</p><p>Abstract: In this paper, we revisit the classical perspective-n-point (PnP) problem, and propose the first non-iterative O(n) solution that is fast, generally applicable and globally optimal. Our basic idea is to formulate the PnP problem into a functional minimization problem and retrieve all its stationary points by using the Gr¨ obner basis technique. The novelty lies in a non-unit quaternion representation to parameterize the rotation and a simple but elegant formulation of the PnP problem into an unconstrained optimization problem. Interestingly, the polynomial system arising from its first-order optimality condition assumes two-fold symmetry, a nice property that can be utilized to improve speed and numerical stability of a Gr¨ obner basis solver. Experiment results have demonstrated that, in terms of accuracy, our proposed solution is definitely better than the state-ofthe-art O(n) methods, and even comparable with the reprojection error minimization method.</p><p>4 0.84295291 <a title="323-lsi-4" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>Author: Adrien Bartoli, Daniel Pizarro, Toby Collins</p><p>Abstract: We study the uncalibrated isometric Shape-fromTemplate problem, that consists in estimating an isometric deformation from a template shape to an input image whose focal length is unknown. Our method is the first that combines the following features: solving for both the 3D deformation and the camera ’s focal length, involving only local analytical solutions (there is no numerical optimization), being robust to mismatches, handling general surfaces and running extremely fast. This was achieved through two key steps. First, an ‘uncalibrated’ 3D deformation is computed thanks to a novel piecewise weak-perspective projection model. Second, the camera’s focal length is estimated and enables upgrading the 3D deformation to metric. We use a variational framework, implemented using a smooth function basis and sampled local deformation models. The only degeneracy which we easily detect– for focal length estimation is a flat and fronto-parallel surface. Experimental results on simulated and real datasets show that our method achieves a 3D shape accuracy – slightly below state of the art methods using a precalibrated or the true focal length, and a focal length accuracy slightly below static calibration methods.</p><p>5 0.78201127 <a title="323-lsi-5" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>Author: R. Melo, M. Antunes, J.P. Barreto, G. Falcão, N. Gonçalves</p><p>Abstract: Estimating the amount and center ofdistortionfrom lines in the scene has been addressed in the literature by the socalled “plumb-line ” approach. In this paper we propose a new geometric method to estimate not only the distortion parameters but the entire camera calibration (up to an “angular” scale factor) using a minimum of 3 lines. We propose a new framework for the unsupervised simultaneous detection of natural image of lines and camera parameters estimation, enabling a robust calibration from a single image. Comparative experiments with existing automatic approaches for the distortion estimation and with ground truth data are presented.</p><p>6 0.74754661 <a title="323-lsi-6" href="./iccv-2013-Extrinsic_Camera_Calibration_without_a_Direct_View_Using_Spherical_Mirror.html">152 iccv-2013-Extrinsic Camera Calibration without a Direct View Using Spherical Mirror</a></p>
<p>7 0.73612374 <a title="323-lsi-7" href="./iccv-2013-Direct_Optimization_of_Frame-to-Frame_Rotation.html">115 iccv-2013-Direct Optimization of Frame-to-Frame Rotation</a></p>
<p>8 0.71877867 <a title="323-lsi-8" href="./iccv-2013-An_Enhanced_Structure-from-Motion_Paradigm_Based_on_the_Absolute_Dual_Quadric_and_Images_of_Circular_Points.html">49 iccv-2013-An Enhanced Structure-from-Motion Paradigm Based on the Absolute Dual Quadric and Images of Circular Points</a></p>
<p>9 0.66295576 <a title="323-lsi-9" href="./iccv-2013-Multi-view_3D_Reconstruction_from_Uncalibrated_Radially-Symmetric_Cameras.html">280 iccv-2013-Multi-view 3D Reconstruction from Uncalibrated Radially-Symmetric Cameras</a></p>
<p>10 0.64717877 <a title="323-lsi-10" href="./iccv-2013-Refractive_Structure-from-Motion_on_Underwater_Images.html">348 iccv-2013-Refractive Structure-from-Motion on Underwater Images</a></p>
<p>11 0.61867988 <a title="323-lsi-11" href="./iccv-2013-A_Global_Linear_Method_for_Camera_Pose_Registration.html">17 iccv-2013-A Global Linear Method for Camera Pose Registration</a></p>
<p>12 0.60177034 <a title="323-lsi-12" href="./iccv-2013-Content-Aware_Rotation.html">90 iccv-2013-Content-Aware Rotation</a></p>
<p>13 0.58364987 <a title="323-lsi-13" href="./iccv-2013-Enhanced_Continuous_Tabu_Search_for_Parameter_Estimation_in_Multiview_Geometry.html">141 iccv-2013-Enhanced Continuous Tabu Search for Parameter Estimation in Multiview Geometry</a></p>
<p>14 0.56189352 <a title="323-lsi-14" href="./iccv-2013-Lifting_3D_Manhattan_Lines_from_a_Single_Image.html">250 iccv-2013-Lifting 3D Manhattan Lines from a Single Image</a></p>
<p>15 0.55588919 <a title="323-lsi-15" href="./iccv-2013-Global_Fusion_of_Relative_Motions_for_Robust%2C_Accurate_and_Scalable_Structure_from_Motion.html">184 iccv-2013-Global Fusion of Relative Motions for Robust, Accurate and Scalable Structure from Motion</a></p>
<p>16 0.54259294 <a title="323-lsi-16" href="./iccv-2013-Rectangling_Stereographic_Projection_for_Wide-Angle_Image_Visualization.html">346 iccv-2013-Rectangling Stereographic Projection for Wide-Angle Image Visualization</a></p>
<p>17 0.51706588 <a title="323-lsi-17" href="./iccv-2013-Efficient_and_Robust_Large-Scale_Rotation_Averaging.html">138 iccv-2013-Efficient and Robust Large-Scale Rotation Averaging</a></p>
<p>18 0.46850875 <a title="323-lsi-18" href="./iccv-2013-Elastic_Net_Constraints_for_Shape_Matching.html">140 iccv-2013-Elastic Net Constraints for Shape Matching</a></p>
<p>19 0.45152092 <a title="323-lsi-19" href="./iccv-2013-Go-ICP%3A_Solving_3D_Registration_Efficiently_and_Globally_Optimally.html">185 iccv-2013-Go-ICP: Solving 3D Registration Efficiently and Globally Optimally</a></p>
<p>20 0.44835976 <a title="323-lsi-20" href="./iccv-2013-Street_View_Motion-from-Structure-from-Motion.html">402 iccv-2013-Street View Motion-from-Structure-from-Motion</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.027), (7, 0.342), (26, 0.06), (27, 0.03), (31, 0.042), (34, 0.012), (42, 0.128), (64, 0.02), (73, 0.039), (89, 0.187), (98, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85753071 <a title="323-lda-1" href="./iccv-2013-From_Semi-supervised_to_Transfer_Counting_of_Crowds.html">178 iccv-2013-From Semi-supervised to Transfer Counting of Crowds</a></p>
<p>Author: Chen Change Loy, Shaogang Gong, Tao Xiang</p><p>Abstract: Regression-based techniques have shown promising results for people counting in crowded scenes. However, most existing techniques require expensive and laborious data annotation for model training. In this study, we propose to address this problem from three perspectives: (1) Instead of exhaustively annotating every single frame, the most informative frames are selected for annotation automatically and actively. (2) Rather than learning from only labelled data, the abundant unlabelled data are exploited. (3) Labelled data from other scenes are employed to further alleviate the burden for data annotation. All three ideas are implemented in a unified active and semi-supervised regression framework with ability to perform transfer learning, by exploiting the underlying geometric structure of crowd patterns via manifold analysis. Extensive experiments validate the effectiveness of our approach.</p><p>same-paper 2 0.84535789 <a title="323-lda-2" href="./iccv-2013-Pose_Estimation_with_Unknown_Focal_Length_Using_Points%2C_Directions_and_Lines.html">323 iccv-2013-Pose Estimation with Unknown Focal Length Using Points, Directions and Lines</a></p>
<p>Author: Yubin Kuang, Kalle Åström</p><p>Abstract: In this paper, we study the geometry problems of estimating camera pose with unknown focal length using combination of geometric primitives. We consider points, lines and also rich features such as quivers, i.e. points with one or more directions. We formulate the problems as polynomial systems where the constraints for different primitives are handled in a unified way. We develop efficient polynomial solvers for each of the derived cases with different combinations of primitives. The availability of these solvers enables robust pose estimation with unknown focal length for wider classes of features. Such rich features allow for fewer feature correspondences and generate larger inlier sets with higher probability. We demonstrate in synthetic experiments that our solvers are fast and numerically stable. For real images, we show that our solvers can be used in RANSAC loops to provide good initial solutions.</p><p>3 0.82756305 <a title="323-lda-3" href="./iccv-2013-Image_Set_Classification_Using_Holistic_Multiple_Order_Statistics_Features_and_Localized_Multi-kernel_Metric_Learning.html">212 iccv-2013-Image Set Classification Using Holistic Multiple Order Statistics Features and Localized Multi-kernel Metric Learning</a></p>
<p>Author: Jiwen Lu, Gang Wang, Pierre Moulin</p><p>Abstract: This paper presents a new approach for image set classification, where each training and testing example contains a set of image instances of an object captured from varying viewpoints or under varying illuminations. While a number of image set classification methods have been proposed in recent years, most of them model each image set as a single linear subspace or mixture of linear subspaces, which may lose some discriminative information for classification. To address this, we propose exploring multiple order statistics as features of image sets, and develop a localized multikernel metric learning (LMKML) algorithm to effectively combine different order statistics information for classification. Our method achieves the state-of-the-art performance on four widely used databases including the Honda/UCSD, CMU Mobo, and Youtube face datasets, and the ETH-80 object dataset.</p><p>4 0.81302655 <a title="323-lda-4" href="./iccv-2013-Text_Localization_in_Natural_Images_Using_Stroke_Feature_Transform_and_Text_Covariance_Descriptors.html">415 iccv-2013-Text Localization in Natural Images Using Stroke Feature Transform and Text Covariance Descriptors</a></p>
<p>Author: Weilin Huang, Zhe Lin, Jianchao Yang, Jue Wang</p><p>Abstract: In this paper, we present a new approach for text localization in natural images, by discriminating text and non-text regions at three levels: pixel, component and textline levels. Firstly, a powerful low-level filter called the Stroke Feature Transform (SFT) is proposed, which extends the widely-used Stroke Width Transform (SWT) by incorporating color cues of text pixels, leading to significantly enhanced performance on inter-component separation and intra-component connection. Secondly, based on the output of SFT, we apply two classifiers, a text component classifier and a text-line classifier, sequentially to extract text regions, eliminating the heuristic procedures that are commonly used in previous approaches. The two classifiers are built upon two novel Text Covariance Descriptors (TCDs) that encode both the heuristic properties and the statistical characteristics of text stokes. Finally, text regions are located by simply thresholding the text-line confident map. Our method was evaluated on two benchmark datasets: ICDAR 2005 and ICDAR 2011, and the corresponding F- , measure values are 0. 72 and 0. 73, respectively, surpassing previous methods in accuracy by a large margin.</p><p>5 0.77389938 <a title="323-lda-5" href="./iccv-2013-No_Matter_Where_You_Are%3A_Flexible_Graph-Guided_Multi-task_Learning_for_Multi-view_Head_Pose_Classification_under_Target_Motion.html">291 iccv-2013-No Matter Where You Are: Flexible Graph-Guided Multi-task Learning for Multi-view Head Pose Classification under Target Motion</a></p>
<p>Author: Yan Yan, Elisa Ricci, Ramanathan Subramanian, Oswald Lanz, Nicu Sebe</p><p>Abstract: We propose a novel Multi-Task Learning framework (FEGA-MTL) for classifying the head pose of a person who moves freely in an environment monitored by multiple, large field-of-view surveillance cameras. As the target (person) moves, distortions in facial appearance owing to camera perspective and scale severely impede performance of traditional head pose classification methods. FEGA-MTL operates on a dense uniform spatial grid and learns appearance relationships across partitions as well as partition-specific appearance variations for a given head pose to build region-specific classifiers. Guided by two graphs which a-priori model appearance similarity among (i) grid partitions based on camera geometry and (ii) head pose classes, the learner efficiently clusters appearancewise related grid partitions to derive the optimal partitioning. For pose classification, upon determining the target’s position using a person tracker, the appropriate regionspecific classifier is invoked. Experiments confirm that FEGA-MTL achieves state-of-the-art classification with few training data.</p><p>6 0.72626466 <a title="323-lda-6" href="./iccv-2013-Supervised_Binary_Hash_Code_Learning_with_Jensen_Shannon_Divergence.html">409 iccv-2013-Supervised Binary Hash Code Learning with Jensen Shannon Divergence</a></p>
<p>7 0.71536732 <a title="323-lda-7" href="./iccv-2013-A_Robust_Analytical_Solution_to_Isometric_Shape-from-Template_with_Focal_Length_Calibration.html">27 iccv-2013-A Robust Analytical Solution to Isometric Shape-from-Template with Focal Length Calibration</a></p>
<p>8 0.68707538 <a title="323-lda-8" href="./iccv-2013-Scene_Text_Localization_and_Recognition_with_Oriented_Stroke_Detection.html">376 iccv-2013-Scene Text Localization and Recognition with Oriented Stroke Detection</a></p>
<p>9 0.6758343 <a title="323-lda-9" href="./iccv-2013-Real-Time_Solution_to_the_Absolute_Pose_Problem_with_Unknown_Radial_Distortion_and_Focal_Length.html">342 iccv-2013-Real-Time Solution to the Absolute Pose Problem with Unknown Radial Distortion and Focal Length</a></p>
<p>10 0.67315096 <a title="323-lda-10" href="./iccv-2013-Revisiting_the_PnP_Problem%3A_A_Fast%2C_General_and_Optimal_Solution.html">353 iccv-2013-Revisiting the PnP Problem: A Fast, General and Optimal Solution</a></p>
<p>11 0.66682184 <a title="323-lda-11" href="./iccv-2013-Lifting_3D_Manhattan_Lines_from_a_Single_Image.html">250 iccv-2013-Lifting 3D Manhattan Lines from a Single Image</a></p>
<p>12 0.66381353 <a title="323-lda-12" href="./iccv-2013-Unsupervised_Intrinsic_Calibration_from_a_Single_Frame_Using_a_%22Plumb-Line%22_Approach.html">436 iccv-2013-Unsupervised Intrinsic Calibration from a Single Frame Using a "Plumb-Line" Approach</a></p>
<p>13 0.66307557 <a title="323-lda-13" href="./iccv-2013-Complex_3D_General_Object_Reconstruction_from_Line_Drawings.html">84 iccv-2013-Complex 3D General Object Reconstruction from Line Drawings</a></p>
<p>14 0.65579224 <a title="323-lda-14" href="./iccv-2013-Recursive_Estimation_of_the_Stein_Center_of_SPD_Matrices_and_Its_Applications.html">347 iccv-2013-Recursive Estimation of the Stein Center of SPD Matrices and Its Applications</a></p>
<p>15 0.64705813 <a title="323-lda-15" href="./iccv-2013-Large-Scale_Video_Hashing_via_Structure_Learning.html">229 iccv-2013-Large-Scale Video Hashing via Structure Learning</a></p>
<p>16 0.64551347 <a title="323-lda-16" href="./iccv-2013-On_the_Mean_Curvature_Flow_on_Graphs_with_Applications_in_Image_and_Manifold_Processing.html">296 iccv-2013-On the Mean Curvature Flow on Graphs with Applications in Image and Manifold Processing</a></p>
<p>17 0.64503878 <a title="323-lda-17" href="./iccv-2013-Similarity_Metric_Learning_for_Face_Recognition.html">392 iccv-2013-Similarity Metric Learning for Face Recognition</a></p>
<p>18 0.63954091 <a title="323-lda-18" href="./iccv-2013-Manifold_Based_Face_Synthesis_from_Sparse_Samples.html">259 iccv-2013-Manifold Based Face Synthesis from Sparse Samples</a></p>
<p>19 0.63543892 <a title="323-lda-19" href="./iccv-2013-Robust_Subspace_Clustering_via_Half-Quadratic_Minimization.html">360 iccv-2013-Robust Subspace Clustering via Half-Quadratic Minimization</a></p>
<p>20 0.63442767 <a title="323-lda-20" href="./iccv-2013-Rectangling_Stereographic_Projection_for_Wide-Angle_Image_Visualization.html">346 iccv-2013-Rectangling Stereographic Projection for Wide-Angle Image Visualization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
