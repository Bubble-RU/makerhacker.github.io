<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>75 jmlr-2010-Mean Field Variational Approximation for Continuous-Time Bayesian Networks</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-75" href="../jmlr2010/jmlr-2010-Mean_Field_Variational_Approximation_for_Continuous-Time_Bayesian_Networks.html">jmlr2010-75</a> <a title="jmlr-2010-75-reference" href="#">jmlr2010-75-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>75 jmlr-2010-Mean Field Variational Approximation for Continuous-Time Bayesian Networks</h1>
<br/><p>Source: <a title="jmlr-2010-75-pdf" href="http://jmlr.org/papers/volume11/cohn10a/cohn10a.pdf">pdf</a></p><p>Author: Ido Cohn, Tal El-Hay, Nir Friedman, Raz Kupferman</p><p>Abstract: Continuous-time Bayesian networks is a natural structured representation language for multicomponent stochastic processes that evolve continuously over time. Despite the compact representation provided by this language, inference in such models is intractable even in relatively simple structured networks. We introduce a mean ﬁeld variational approximation in which we use a product of inhomogeneous Markov processes to approximate a joint distribution over trajectories. This variational approach leads to a globally consistent distribution, which can be efﬁciently queried. Additionally, it provides a lower bound on the probability of observations, thus making it attractive for learning tasks. Here we describe the theoretical foundations for the approximation, an efﬁcient implementation that exploits the wide range of highly optimized ordinary differential equations (ODE) solvers, experimentally explore characterizations of processes for which this approximation is suitable, and show applications to a large-scale real-world inference problem. Keywords: continuous time Markov processes, continuous time Bayesian networks, variational approximations, mean ﬁeld approximation</p><br/>
<h2>reference text</h2><p>C. Archambeau, M. Opper, Y. Shen, D. Cornford, and J. Shawe-Taylor. Variational inference for diffusion processes. In Advances in Neural Information Processing Systems 20. MIT Press, 2007. K. L. Chung. Markov Chains with Stationary Transition Probabilities. Springer Verlag, Berlin, 1960. T. Dean and K. Kanazawa. A model for reasoning about persistence and causation. Comput. Intell., 5(3):142–150, 1989. M. Dewar, V. Kadirkamanathan, M. Opper, and G. Sanguinetti. Parameter estimation and inference for stochastic reaction-diffusion systems: application to morphogenesis in d. melanogaster. BMC Systems Biology, 4(1):21, 2010. T. El-Hay, N. Friedman, D. Koller, and R. Kupferman. Continuous time markov networks. In Proc. Twenty-second Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2006. T. El-Hay, N. Friedman, and R. Kupferman. Gibbs sampling in factorized continuous-time markov processes. In Proc. Twenty-fourth Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2008. T. El-Hay, I. Cohn, N. Friedman, and R. Kupferman. Continuous-time belief propagation. In Proceedings of the 27th International Conference on Machine Learning (ICML), 2010. G. Elidan, I. Mcgraw, and D. Koller. Residual belief propagation: informed scheduling for asynchronous message passing. In Proc. Twenty-second Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2006. Y. Fan and C. R. Shelton. Sampling for approximate inference in continuous time Bayesian networks. In Tenth International Symposium on Artiﬁcial Intelligence and Mathematics, 2008. Y. Fan and C. R. Shelton. Learning continuous-time social network dynamics. In Proc. Twenty-ﬁfth Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2009. J. Felsenstein. Inferring Phylogenies. Sinauer, 2004. C. W. Gardiner. Handbook of Stochastic Methods. Springer-Verlag, New-York, third edition, 2004. I. M. Gelfand and S. V. Fomin. Calculus of Variations. Prentice-Hall, 1963. 2781  C OHN , E L - HAY, F RIEDMAN AND K UPFERMAN  K. Gopalratnam, H. Kautz, and D. S. Weld. Extending continuous time bayesian networks. In Proceedings of the 20th National Conference on Artiﬁcial Intelligence (AAAI), pages 981–986. AAAI Press, 2005. M. I. Jordan, Z. Ghahramani, T. Jaakkola, and L. K. Saul. An introduction to variational approximations methods for graphical models. In M. I. Jordan, editor, Learning in Graphical Models. MIT Press, Cambridge MA, 1999. D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques. MIT Press, Cambridge, MA, 2009. S. Kullback and R. A. Leibler. On information and sufﬁciency. The Annals of Mathematical Statistics, 22(1):79–86, 1951. A. Lipshtat, H. B. Perets, N. Q. Balaban, and O. Biham. Modeling of negative autoregulated genetic networks in single cells. Gene, 347:265, 2005. K. P. Murphy. Dynamic Bayesian Networks: Representation, Inference and Learning. PhD thesis, University of California, Berkeley, 2002. B. Ng, A. Pfeffer, and R. Dearden. Continuous time particle ﬁltering. In Proc. of the Nineteenth International Joint Conference on Artiﬁcial Intelligence (IJCAI), 2005. U. Nodelman, C. R. Shelton, and D. Koller. Continuous time Bayesian networks. In Proc. Eighteenth Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 378–387, 2002. U. Nodelman, C. R. Shelton, and D. Koller. Learning continuous time Bayesian networks. In Proc. Nineteenth Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 451–458, 2003. U. Nodelman, C. R. Shelton, and D. Koller. Expectation maximization and complex duration distributions for continuous time Bayesian networks. In Proc. Twenty-ﬁrst Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 421–430, 2005a. U. Nodelman, C. R. Shelton, and D. Koller. Expectation propagation for continuous time Bayesian networks. In Proc. Twenty-ﬁrst Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 431–440, 2005b. M. Opper and G. Sanguinetti. Variational inference for Markov jump processes. In Advances in Neural Information Processing Systems 20. MIT Press, 2007. M. Opper and G. Sanguinetti. Learning combinatorial transcriptional dynamics from gene expression data. Bioinformatics, 26(13):1623–1629, 2010. W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. Numerical Recipes 3rd Edition: The Art of Scientiﬁc Computing. Cambridge University Press, New York, NY, USA, 3 edition, 2007. S. Rajaram, T. Graepel, and R. Herbrich. Poisson-networks: A model for structured point processes. In Proc. Tenth International Workshop on Artiﬁcial Intelligence and Statistics (AISTATS), January 2005. 2782  M EAN F IELD A PPROXIMATION FOR C ONTINUOUS -T IME BAYESIAN N ETWORKS  A. Ruttor and M. Opper. Approximate parameter inference in a stochastic reaction-diffusion model. In Proc. Thirteenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), volume 9, pages 669–676, 2010. G. Sanguinetti, A. Ruttor, M. Opper, and C. Archambeau. Switching regulatory models of cellular stress response. Bioinformatics, 25(10):1280–1286, 2009. S. Saria, U. Nodelman, and D. Koller. Reasoning at the right time granularity. In Proc. Twenty-third Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2007. A. Simma, M. Goldszmidt, J. MacCormick, P. Barham, R. Black, R. Isaacs, and R. Mortier. Ct-nor: Representing and reasoning about events in continuous time. In Proc. Twenty-fourth Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2008. M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference. Found. Trends Mach. Learn., 1:1–305, 2008. J. Yu and J. L. Thorne. Dependence among sites in RNA evolution. Mol. Biol. Evol., 23:1525–37, 2006.  2783</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
