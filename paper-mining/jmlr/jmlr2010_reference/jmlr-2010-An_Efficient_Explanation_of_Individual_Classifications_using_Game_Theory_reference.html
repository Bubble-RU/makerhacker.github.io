<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>9 jmlr-2010-An Efficient Explanation of Individual Classifications using Game Theory</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-9" href="../jmlr2010/jmlr-2010-An_Efficient_Explanation_of_Individual_Classifications_using_Game_Theory.html">jmlr2010-9</a> <a title="jmlr-2010-9-reference" href="#">jmlr2010-9-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>9 jmlr-2010-An Efficient Explanation of Individual Classifications using Game Theory</h1>
<br/><p>Source: <a title="jmlr-2010-9-pdf" href="http://jmlr.org/papers/volume11/strumbelj10a/strumbelj10a.pdf">pdf</a></p><p>Author: Erik Ĺ trumbelj, Igor Kononenko</p><p>Abstract: We present a general method for explaining individual predictions of classiﬁcation models. The method is based on fundamental concepts from coalitional game theory and predictions are explained with contributions of individual feature values. We overcome the method’s initial exponential time complexity with a sampling-based approximation. In the experimental part of the paper we use the developed method on models generated by several well-known machine learning algorithms on both synthetic and real-world data sets. The results demonstrate that the method is efﬁcient and that the explanations are intuitive and useful. Keywords: data postprocessing, classiﬁcation, explanation, visualization</p><br/>
<h2>reference text</h2><p>Robert Andrews, Joachim Diederich, and Alan B. Tickle. Survey and critique of techniques for extracting rules from trained artiﬁcial neural networks. Knowledge-Based Systems, 8:373–389, 1995. Artur Asuncion and David J. Newman. UCI Machine Learning Repository, http://www.ics.uci. edu/˜mlearn/MLRepository.html, 2009. Barry Becker, Ron Kohavi, and Dan Sommerﬁeld. Visualizing the simple bayesian classier. In KDD Workshop on Issues in the Integration of Data Mining and Data Visualization, 1997. Leo Breiman. Random forests. Machine Learning Journal, 45:5–32, 2001. Javier Castro, Daniel G´ mez, and Juan Tejada. Polynomial calculation of the shapley value based on o sampling. Computers and Operations Research, 2008. (in print, doi: 10.1016/j.cor.2008.04.004). Shay Cohen, Gideon Dror, and Eytan Ruppin. Feature selection via coalitional game theory. Neural Computation, 19(7):1939–1961, 2007. Lutz Hamel. Visualization of support vector machines with unsupervised learning. In Computational Intelligence in Bioinformatics and Computational Biology, pages 1–8. IEEE, 2006. Aleks Jakulin, Martin Moˇ ina, Janez Demˇar, Ivan Bratko, and Blaˇ Zupan. Nomograms for viz s z sualizing support vector machines. In KDD ’05: Proceeding of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pages 108–117, New York, NY, USA, 2005. ACM. ISBN 1-59593-135-X. Alon Keinan, Ben Sandbank, Claus C. Hilgetag, Isaac Meilijson, and Eytan Ruppin. Fair attribution of functional contribution in artiﬁcial and biological networks. Neural Computation, 16(9):1887– 1915, 2004. Ron Kohavi and George H. John. Wrappers for feature subset selection. Artiﬁcial Intelligence journal, 97(1–2):273–324, 1997. Igor Kononenko. Machine learning for medical diagnosis: history, state of the art and perspective. Artiﬁcial Intelligence in Medicine, 23:89–109, 2001. Igor Kononenko and Matjaz Kukar. Machine Learning and Data Mining: Introduction to Principles and Algorithms. Horwood publ., 2007. 17  ˇ S TRUMBELJ AND KONONENKO  Vincent Lemaire, Rapha¨ l Fraud, and Nicolas Voisine. Contact personalization using a score undere standing method. In International Joint Conference on Neural Networks (IJCNN), 2008. David Martens, Bart Baesens, Tony Van Gestel, and Jan Vanthienen. Comprehensible credit scoring models using rule extraction from support vector machines. European Journal of Operational Research, 183(3):1466–1476, 2007. Stefano Moretti and Fioravante Patrone. Transversality of the shapley value. TOP, 16(1):1–41, 2008. Martin Moˇ ina, Janez Demˇar, Michael Kattan, and Blaˇ Zupan. Nomograms for visualization z s z of naive bayesian classiﬁer. In PKDD ’04: Proceedings of the 8th European Conference on Principles and Practice of Knowledge Discovery in Databases, pages 337–348, New York, NY, USA, 2004. Springer-Verlag New York, Inc. ISBN 3-540-23108-0. Richi Nayak. Generating rules with predicates, terms and variables from the pruned neural networks. Neural Networks, 22(4):405–414, 2009. Francois Poulet. Svm and graphical algorithms: A cooperative approach. In Proceedings of Fourth IEEE International Conference on Data Mining, pages 499–502, 2004. ˇ Marko Robnik-Sikonja and Igor Kononenko. Explaining classiﬁcations for individual instances. IEEE Transactions on Knowledge and Data Engineering, 20:589–600, 2008. Lloyd S. Shapley. A Value for n-person Games, volume II of Contributions to the Theory of Games. Princeton University Press, 1953. Duane Szafron, Brett Poulin, Roman Eisner, Paul Lu, Russ Greiner, David Wishart, Alona Fyshe, Brandon Pearcy, Cam Macdonell, and John Anvik. Visual explanation of evidence in additive classiﬁers. In Proceedings of Innovative Applications of Artiﬁcial Intelligence, 2006. Geoffrey Towell and Jude W. Shavlik. Extracting reﬁned rules from knowledge-based neural networks, machine learning. Machine Learning, 13:71–101, 1993. ˇ ˇ Erik Strumbelj, Igor Kononenko, and Marko Robnik Sikonja. Explaining instance classiﬁcations with interactions of subsets of feature values. Data & Knowledge Engineering, 68(10):886–904, 2009.  18</p>
<br/>
<br/><br/><br/></body>
</html>
