<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>30 jmlr-2010-Dimensionality Estimation, Manifold Learning and Function Approximation using Tensor Voting</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-30" href="../jmlr2010/jmlr-2010-Dimensionality_Estimation%2C_Manifold_Learning_and_Function_Approximation_using_Tensor_Voting.html">jmlr2010-30</a> <a title="jmlr-2010-30-reference" href="#">jmlr2010-30-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>30 jmlr-2010-Dimensionality Estimation, Manifold Learning and Function Approximation using Tensor Voting</h1>
<br/><p>Source: <a title="jmlr-2010-30-pdf" href="http://jmlr.org/papers/volume11/mordohai10a/mordohai10a.pdf">pdf</a></p><p>Author: Philippos Mordohai, Gérard Medioni</p><p>Abstract: We address instance-based learning from a perceptual organization standpoint and present methods for dimensionality estimation, manifold learning and function approximation. Under our approach, manifolds in high-dimensional spaces are inferred by estimating geometric relationships among the input instances. Unlike conventional manifold learning, we do not perform dimensionality reduction, but instead perform all operations in the original input space. For this purpose we employ a novel formulation of tensor voting, which allows an N-D implementation. Tensor voting is a perceptual organization framework that has mostly been applied to computer vision problems. Analyzing the estimated local structure at the inputs, we are able to obtain reliable dimensionality estimates at each instance, instead of a global estimate for the entire data set. Moreover, these local dimensionality and structure estimates enable us to measure geodesic distances and perform nonlinear interpolation for data sets with varying density, outliers, perturbation and intersections, that cannot be handled by state-of-the-art methods. Quantitative results on the estimation of local manifold structure using ground truth data are presented. In addition, we compare our approach with several leading methods for manifold learning at the task of measuring geodesic distances. Finally, we show competitive function approximation results on real data. Keywords: dimensionality estimation, manifold learning, geodesic distance, function approximation, high-dimensional processing, tensor voting</p><br/>
<h2>reference text</h2><p>S. Arya, D. M. Mount, N. S. Netanyahu, R. Silverman, and A. Y. Wu. An optimal algorithm for approximate nearest neighbor searching. Journal of the ACM, 45:891–923, 1998. C.G. Atkeson, A.W. Moore, and S. Schaal. Locally weighted learning. Artiﬁcial Intelligence Review, 11(1-5):11–73, 1997. A.R. Barron. Universal approximation bounds for superpositions of a sigmoidal function. IEEE Transactions on Information Theory, 39(3):930–945, 1993. M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6):1373–1396, 2003. 445  M ORDOHAI AND M EDIONI  M. Brand. Nonrigid embeddings for dimensionality reduction. In European Conference on Machine Learning, pages 47–59, 2005. M. Brand. Charting a manifold. In Advances in Neural Information Processing Systems 15, pages 961–968. MIT Press, Cambridge, MA, 2003. L. Breiman. Hinging hyperplanes for regression, classiﬁcation, and function approximation. IEEE Transactions on Information Theory, 39(3):999–1013, 1993. J. Bruske and G. Sommer. Intrinsic dimensionality estimation with optimally topology preserving maps. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(5):572–575, 1998. W. Chu, S.S. Keerthi, and C.J. Ong. Bayesian support vector regression using a uniﬁed loss function. IEEE Transactions on Neural Networks, 15(1):29–44, 2004. R. Collobert and S. Bengio. Svmtorch: Support vector machines for large-scale regression problems. Journal of Machine Learning Research, 1(2):143–160, 2001. J. Costa and A.O. Hero. Geodesic entropic graphs for dimension and entropy estimation in manifold learning. IEEE Transactions on Signal Process, 52(8):2210–2221, 2004. T. Cox and M. Cox. Multidimensional Scaling. Chapman & Hall, London, 1994. L. Csat´ and M. Opper. Sparse on-line gaussian processes. Neural Computation, 14(3):641–668, o 2002. V. de Silva and J.B. Tenenbaum. Global versus local methods in nonlinear dimensionality reduction. In Advances in Neural Information Processing Systems 15, pages 705–712. MIT Press, Cambridge, MA, 2003. P. Doll´ r, V. Rabaud, and S. Belongie. Learning to traverse image manifolds. In Advances in Neural a Information Processing Systems 19, pages 361–368. MIT Press, Cambridge, MA, 2007a. P. Doll´ r, V. Rabaud, and S. Belongie. Non-isometric manifold learning: Analysis and an algorithm. a In International Conference on Machine Learning, 2007b. D. Donoho and C. Grimes. Hessian eigenmaps: new tools for nonlinear dimensionality reduction. In Proceedings of National Academy of Science, pages 5591–5596, 2003. G. Guy and G. Medioni. Inferring global perceptual contours from local features. International Journal of Computer Vision, 20(1/2):113–133, 1996. G. Guy and G. Medioni. Inference of surfaces, 3D curves, and junctions from sparse, noisy, 3D data. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(11):1265–1277, 1997. X. He and P. Niyogi. Locality preserving projections. In Advances in Neural Information Processing Systems 16. MIT Press, Cambridge, MA, 2004. F. Heitger and R. von der Heydt. A computational model of neural contour processing: Figureground segregation and illusory contours. In International Conference on Computer Vision, pages 32–40, 1993. 446  D IMENSIONALITY E STIMATION , M ANIFOLD L EARNING AND F UNCTION A PPROXIMATION  I.T. Jolliffe. Principal Component Analysis. Springer-Verlag, New York, 1986. B. K´ gl. Intrinsic dimension estimation using packing numbers. In Advances in Neural Information e Processing Systems 15, pages 681–688. MIT Press, Cambridge, MA, 2003. K. Koffka. Principles of Gestalt Psychology. Harcourt, Brace, New York, 1935. W. K¨ hler. Physical gestalten. W.D. Ellis (ed), A source book of Gestalt psychology (1950), pages o 17–54, 1920. J.-F. Lalonde, R. Unnikrishnan, N. Vandapel, and M. Hebert. Scale selection for classiﬁcation of point-sampled 3-d surfaces. In International Conference on 3-D Digital Imaging and Modeling, 2005. S. Lawrence, A. C. Tsoi, and A. D. Back. Function approximation with neural networks and local methods: Bias, variance and smoothness. In Australian Conference on Neural Networks, pages 16–21, 1996. E. Levina and P. Bickel. Maximum likelihood estimation of intrinsic dimension. In Advances in Neural Information Processing Systems 17, pages 777–784. MIT Press, Cambridge, MA, 2005. Z. Li. A neural model of contour integration in the primary visual cortex. Neural Computation, 10: 903–940, 1998. G. Medioni, M.S. Lee, and C.K. Tang. A Computational Framework for Segmentation and Grouping. Elsevier, New York, NY, 2000. Facundo M´ moli and Guillermo Sapiro. Distance functions and geodesics on submanifolds of Rd e and point clouds. SIAM Journal of Applied Mathematics, 65(4):1227–1260, 2005. S. Mitaim and B. Kosko. The shape of fuzzy sets in adaptive function approximation. IEEE Transactions on Fuzzy Systems, 9(4):637–656, 2001. T.M. Mitchell. Machine Learning. McGraw-Hill, New York, 1997. N.J. Mitra, A. Nguyen, and L. Guibas. Estimating surface normals in noisy point cloud data. International Journal of Computational Geometry and Applications, 14(4–5):261–276, 2004. P. Mordohai. A Perceptual Organization Approach for Figure Completion, Binocular and MultipleView Stereo and Machine Learning using Tensor Voting. Ph.D. Thesis, University of Southern California, 2005. P. Mordohai and G. Medioni. Unsupervised dimensionality estimation and manifold learning in high-dimensional spaces by tensor voting. International Joint Conference on Artiﬁcial Intelligence, 2005. P. Mordohai and G. Medioni. Stereo using monocular cues within the tensor voting framework. IEEE Transactions on Pattern Analysis and Machine Intelligence, 28(6):968–982, 2006. D.J. Newman, S. Hettich, C.L. Blake, and C.J. Merz. UCI repository of machine learning databases, 1998. URL http://www.ics.uci.edu/˜mlearn/MLRepository.html. 447  M ORDOHAI AND M EDIONI  P. Parent and S.W. Zucker. Trace inference, curvature consistency, and curve detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 11(8):823–839, 1989. T. Poggio and F. Girosi. Networks for approximation and learning. Proc. of IEEE, 78(9):1481–1497, 1990. M. Raginsky and S. Lazebnik. Estimation of intrinsic dimensionality using high-rate vector quantization. In Advances in Neural Information Processing Systems 18, pages 1105–1112. MIT Press, Cambridge, MA, 2006. C.E. Rasmussen, R.M. Neal, G. Hinton, D. van Camp, M. Revow, Z. Ghahramani, R. Kustra, and R. Tibshirani. The DELVE archive, 1996. URL http://www.cs.toronto.edu/˜delve. S.T. Roweis and L.K. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290:2323–2326, 2000. A. Saha, C.L. Wu, and D.S. Tang. Approximation, dimension reduction, and nonconvex optimization using linear superpositions of gaussians. IEEE Transactions on Computers, 42(10): 1222–1233, 1993. T. D. Sanger. A tree-structured algorithm for reducing computation in networks with separable basis functions. Neural Computation, 3(1):67–78, 1991. S. Sarkar and K.L. Boyer. A computational structure for preattentive perceptual organization: Graphical enumeration and voting methods. IEEE Transactions on Systems, Man and Cybernetics, 24:246–267, 1994. L. K. Saul and S. T. Roweis. Think globally, ﬁt locally: unsupervised learning of low dimensional manifolds. Journal of Machine Learning Research, 4:119–155, 2003. E. Saund. Labeling of curvilinear structure across scales by token grouping. In International Conference on Computer Vision and Pattern Recognition, pages 257–263, 1992. S. Schaal and C.G. Atkeson. Constructive incremental learning from only local information. Neural Computation, 10(8):2047–2084, 1998. B. Sch¨ lkopf, A.J. Smola, and K.-R. M¨ ller. Nonlinear component analysis as a kernel eigenvalue o u problem. Neural Computation, 10(5):1299–1319, 1998. A. Schwaighofer and V. Tresp. Transductive and inductive methods for approximate gaussian process regression. In Advances in Neural Information Processing Systems 15, pages 953–960. MIT Press, Cambridge, MA, 2003. F. Sha and L. Saul. Analysis and extension of spectral methods for nonlinear dimensionality reduction. In International Conference on Machine Learning, pages 784–791, 2005. A. Shashua and S. Ullman. Structural saliency: The detection of globally salient structures using a locally connected network. In International Conference on Computer Vision, pages 321–327, 1988. 448  D IMENSIONALITY E STIMATION , M ANIFOLD L EARNING AND F UNCTION A PPROXIMATION  A.J. Smola and P.L. Bartlett. Sparse greedy gaussian process regression. In Advances in Neural Information Processing Systems 13, pages 619–625. MIT Press, Cambridge, MA, 2001. R. Souvenir and R. Pless. Manifold clustering. In International Conf on Computer Vision, pages I: 648–653, 2005. C.K. Tang and G. Medioni. Inference of integrated surface, curve, and junction descriptions from sparse 3d data. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(11):1206– 1223, 1998. C.K. Tang, G. Medioni, and M.S. Lee. N-dimensional tensor voting and application to epipolar geometry estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(8): 829–844, 2001. Y.W. Teh and S. Roweis. Automatic alignment of local representations. In Advances in Neural Information Processing Systems 15, pages 841–848. MIT Press, Cambridge, MA, 2003. J.B. Tenenbaum, V. de Silva, and J.C. Langford. A global geometric framework for nonlinear dimensionality reduction. Science, 290:2319–2323, 2000. J. Ting, A D’Souza, and S. Schaal. bayesian regression with input noise for high dimensional data. In International Conference on Machine Learning, 2006. M.E. Tipping. Sparse bayesian learning and the relevance vector machine. Journal of Machine Learning Research, 1(3):211–244, 2001. V. Tresp. A bayesian committee machine. Neural Computation, 12(11):2719–2741, 2000. V. Vapnik. The Nature of Statistical Learning Theory. Springer, Berlin Heidelberg New York, 1995. S. Vijayakumar and S. Schaal. Locally weighted projection regression: An o(n) algorithm for incremental real time learning in high dimensional space. In International Conference on Machine Learning, pages I:288–293, 2000. J. Wang, Z. Zhang, and H. Zha. Adaptive manifold learning. In Advances in Neural Information Processing Systems 17. MIT Press, Cambridge, MA, 2005. D. Wedge, D. Ingram, D. McLean, C. Mingham, and Z. Bandar. On global-local artiﬁcial neural networks for function approximation. IEEE Transactions on Neural Networks, 17(4):942–952, 2006. K. Q. Weinberger and L. K. Saul. Unsupervised learning of image manifolds by semideﬁnite programming. International Journal of Computer Vision, 70(1):77–90, 2006. K. Q. Weinberger, F. Sha, and L. K. Saul. Learning a kernel matrix for nonlinear dimensionality reduction. In International Conference on Machine Learning, pages 839–846, 2004. K.Q. Weinberger and L.K. Saul. Unsupervised learning of image manifolds by semideﬁnite programming. In International Conference on Computer Vision and Pattern Recognition, pages II: 988–995, 2004. 449  M ORDOHAI AND M EDIONI  M. Wertheimer. Laws of organization in perceptual forms. Psycologische Forschung, Translation by W. Ellis, A source book of Gestalt psychology (1938), 4:301–350, 1923. C.K.I. Williams and C.E. Rasmussen. Gaussian processes for regression. In Advances in Neural Information Processing Systems 8, pages 514–520. MIT Press, Cambridge, MA, 1996. L. Xu, M. I. Jordan, and G. E. Hinton. An alternative model for mixtures of experts. In Advances in Neural Information Processing Systems 7, pages 633–640. MIT Press, Cambridge, MA, 1995. S.C. Yen and L.H. Finkel. Extraction of perceptually salient contours by striate cortical networks. Vision Research, 38(5):719–741, 1998. Z. Zhang and H. Zha. Principal manifolds and nonlinear dimension reduction via local tangent space alignment. SIAM Journal of Scientiﬁc Computing, 26(1):313–338, 2004.  450</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
