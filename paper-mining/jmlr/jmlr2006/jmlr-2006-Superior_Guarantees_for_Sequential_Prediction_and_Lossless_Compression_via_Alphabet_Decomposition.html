<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>90 jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-90" href="#">jmlr2006-90</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>90 jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</h1>
<br/><p>Source: <a title="jmlr-2006-90-pdf" href="http://jmlr.org/papers/volume7/begleiter06a/begleiter06a.pdf">pdf</a></p><p>Author: Ron Begleiter, Ran El-Yaniv</p><p>Abstract: We present worst case bounds for the learning rate of a known prediction method that is based on hierarchical applications of binary context tree weighting (CTW) predictors. A heuristic application of this approach that relies on Huffman’s alphabet decomposition is known to achieve state-ofthe-art performance in prediction and lossless compression benchmarks. We show that our new bound for this heuristic is tighter than the best known performance guarantees for prediction and lossless compression algorithms in various settings. This result substantiates the efﬁciency of this hierarchical method and provides a compelling explanation for its practical success. In addition, we present the results of a few experiments that examine other possibilities for improving the multialphabet prediction performance of CTW-based algorithms. Keywords: sequential prediction, the context tree weighting method, variable order Markov models, error bounds</p><p>Reference: <a title="jmlr-2006-90-reference" href="../jmlr2006_reference/jmlr-2006-Superior_Guarantees_for_Sequential_Prediction_and_Lossless_Compression_via_Alphabet_Decomposition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 IL  Department of Computer Science Technion - Israel Institute of Technology Haifa 32000, Israel  Editor: Dana Ron  Abstract We present worst case bounds for the learning rate of a known prediction method that is based on hierarchical applications of binary context tree weighting (CTW) predictors. [sent-7, score-0.311]
</p><p>2 A heuristic application of this approach that relies on Huffman’s alphabet decomposition is known to achieve state-ofthe-art performance in prediction and lossless compression benchmarks. [sent-8, score-0.483]
</p><p>3 We show that our new bound for this heuristic is tighter than the best known performance guarantees for prediction and lossless compression algorithms in various settings. [sent-9, score-0.323]
</p><p>4 It is well known that this setting is intimately related to lossless compression, where in fact high quality prediction is essentially equivalent to high quality lossless compression. [sent-15, score-0.323]
</p><p>5 Moreover, the algorithm has a ﬁnite sample point-wise redundancy bound (for any particular sequence). [sent-23, score-0.287]
</p><p>6 ” Volf suggested applying the DECO algorithm using Huffman’s tree as the decomposition structure, where the tree construction is based on letter frequencies. [sent-36, score-0.296]
</p><p>7 Our main contribution is a general worst case redundancy bound for algorithm DECO applied with any alphabet decomposition structure. [sent-38, score-0.476]
</p><p>8 A specialization of the bound to the case of Huffman decompositions results in a tight redundancy bound. [sent-40, score-0.328]
</p><p>9 To the best of our knowledge, this new bound is the sharpest available for prediction and lossless compression for sufﬁciently large alphabets and sequences. [sent-41, score-0.363]
</p><p>10 Suppose we are given ˆ a sequence xn = x1 x2 · · · xn . [sent-47, score-0.554]
</p><p>11 Let ALG be a prediction algorithm that assigns a probability estimate PALG (xn ) for any given xn . [sent-52, score-0.33]
</p><p>12 The point1 1 wise redundancy of ALG with respect to the predictor P and the sequence xn is RALG (xn , P) = 1 1 1 log P(xn ) − log PALG (xn ). [sent-53, score-0.822]
</p><p>13 The per-symbol point-wise redundancy is n RALG (xn , P). [sent-54, score-0.258]
</p><p>14 The (zero-order) distribution associated with the leaf s is denoted zs (σ), ∀σ ∈ Σ, where ∑σ zs (σ) = 1 and zs (·) ≥ 0. [sent-78, score-0.673]
</p><p>15 The tree-source induced probability of the sequence xn = 1 x1 x2 · · · xn is, by the chain rule, n  PS (xn ) = ∏ PS (xt |xt−1 ), 1 t−D  (2)  t=1  where PS (xt |xt−1 ) is zs (xt ) = PS (xt |s) and s is the (unique) sufﬁx of xt−1 in S . [sent-111, score-0.764]
</p><p>16 A full k-ary tree is a tree in which each node has exactly zero or k children. [sent-113, score-0.271]
</p><p>17 Let SUBs (xn ) be the ordered non-contiguous sub-sequence of symbols appearing after i−D 1 the context s in xn . [sent-115, score-0.329]
</p><p>18 For every xn = ε we deﬁne zs (xn ) = ∏m zs (yi ) and for the empty i=1 1 1 1 1 sequence zs (ε) = 1. [sent-118, score-0.923]
</p><p>19 A good solution assigns to each s ∈ S a zero-order estimator zs that estimates the true probability distribution zs ˆ associated with s. [sent-129, score-0.469]
</p><p>20 This can be done using standard statistical methods; that is, by considering all occurrences of s in xn and constructing zs via counting and smoothing. [sent-130, score-0.471]
</p><p>21 We currently consider zs as ˆ ˆ 1 a generic estimator and discuss speciﬁc implementations later on. [sent-131, score-0.259]
</p><p>22 In the following description of the CTW algorithm, the output of the algorithm is a probability PCTW (xn ) for the entire sequence xn . [sent-137, score-0.293]
</p><p>23 Let xn be any sequence (in Σn ) and ﬁx a bound D and 1 an initial context x0 . [sent-142, score-0.322]
</p><p>24 The sequential zero-order 1 1 1−D estimation for xn is, by the chain-rule, 1 m  ˆ zs (xn ) = ∏ z(yi |yi−1 ), ˆ 1 1  (5)  i=1  where y0 = ε and z(yi |yi−1 ) is a zero-order probability estimate based on the symbol counts in ˆ 1 1 yi−1 . [sent-144, score-0.591]
</p><p>25 As mentioned above, any lossless compression algorithm can be translated into a sequence prediction algorithm and vice versa (see, e. [sent-149, score-0.326]
</p><p>26 Algorithm 1 The context-tree weighting algorithm /* This code calculates the CTW probability for the (whole) sequence xn , PCTW (xn |x0 ). [sent-160, score-0.34]
</p><p>27 The input argu1 1 1−D  ments include the sequence xn , an initial context x0 (that determines the sufﬁxes for predicting the ﬁrst 1 1−D symbols), a bound D on the order, and an implementation for the sequential zero-order estimators zs (·). [sent-161, score-0.639]
</p><p>28 */ CTW(xn , x0 , D, zs (·)) { ˆ 1 1−D ≤D do for every s ∈ Σ calculate and store zs (xn ) as given in Equation (5). [sent-163, score-0.42]
</p><p>29 ˆ 1 end for return PCTW (xn ) = mix(ε, xn , x0 ). [sent-164, score-0.261]
</p><p>30 */ 1−D mix(s, xn , x0 ) { 1 1−D if |s| = D then return zs (xn ). [sent-167, score-0.471]
</p><p>31 ˆ 1 else return 1 zs (xn ) + 1 ∏σ∈Σ mix(σs, xn , x0 ). [sent-168, score-0.471]
</p><p>32 Then, mix(s, xn , x0 ) = 1 1−D  ∑  2−|TU |  ˆ ∏ zus (xn ). [sent-183, score-0.261]
</p><p>33 Notice that the size |s| = d = D, so k−1 mix(s, xn , x0 ) = zs (xn ). [sent-188, score-0.471]
</p><p>34 We conclude that, ˆ 1 1 1−D 1−1  ˆ 1 mix(s, xn , x0 ) = zs (xn ) = 2−0− k−1 zs (xn ) = ˆ 1 1 1−D  ∑  2−|TU |  U ∈C0  ˆ ∏ zus (xn ). [sent-189, score-0.681]
</p><p>35 384  S UPERIOR G UARANTEES FOR S EQUENTIAL P REDICTION AND L OSSLESS C OMPRESSION  Corollary 4 PCTW (xn ) = mix(ε, xn , x0 ) = 1 1 1−D  ∑  S ∈CD  ˆ 1 2−|TS | ∏ zs (xn ). [sent-200, score-0.471]
</p><p>36 3 Analysis of CTW for Multi-Alphabets The analysis of CTW for multi-alphabets (multi-CTW) relies upon speciﬁc implementations of the sequential zero-order estimators zs (·). [sent-214, score-0.317]
</p><p>37 Deﬁnition 6 Fix any xn and let Nσ be the frequency of σ ∈ Σ in xn . [sent-220, score-0.522]
</p><p>38 The 1 1 following (sequential zero-order) probability to the sequence xn , 1 n−1 zKT (xn ) = zKT (x1 ) ˆ ˆ 1  Nxn + 1/2 , ∑σ∈Σ Nσ + k/2  KT  estimator assigns the  (11)  where zKT (ε) = 1. [sent-221, score-0.342]
</p><p>39 Notice 1 that the per-symbol redundancy of KT diminishes with n at a rate log n . [sent-228, score-0.374]
</p><p>40 For any sequence xn ∈ Σn , 1 k−1 RKT (xn ) = log sup z(xn ) − log zKT (xn ) ≤ ˆ log n + log k. [sent-231, score-0.757]
</p><p>41 R  The upper bound of Theorem 7 on the redundancy of the KT estimator is a key element in the proof of the following theorem, providing a ﬁnite-sample point-wise redundancy bound for the multi-CTW (see, e. [sent-237, score-0.623]
</p><p>42 For any sequence xn ∈ Σn and 1 any D-bounded tree-source with a topology S and distribution PS , the following holds:  RCTW (xn , PS ) ≤ 1  S |−1 n log k + k|k−1 , n < |S |; k|S |−1 (k−1)|S | n log |S | + |S | log k + k−1 , n ≥ |S |. [sent-243, score-0.682]
</p><p>43 2  Proof RCTW (xn , PS ) = log PS (xn ) − log PCTW (xn ) 1 1 1 ˆ 1 PS (xn ) ∏s∈S zs (xn ) 1 + log = log ˆ 1 zs (xn ) PCTW (xn ) ∏s∈S 1 (i)  (ii)  We now bound the term (14)(i) and deﬁne the following auxiliary function:  f (x) =  x log k k−1 2 log x + log k 386  , 0 ≤ x < 1; , x ≥ 1. [sent-244, score-1.261]
</p><p>44 Thus, 1 log  PS (xn ) 1 ˆ 1 ∏s∈S zs (xn )  =  ∑ log  s∈S  ≤  zs (xn ) 1 zs (xn ) ˆ 1  (15)  k−1 log(∑ Nσ (s)) + log k 2 σ  ∑  s∈S , s. [sent-247, score-0.978]
</p><p>45 (1994), who proposed a rudimentary alphabet decomposition approach, he studied a solution to the multi-alphabet prediction problem that is based on a tree hierarchy of binary problems. [sent-277, score-0.417]
</p><p>46 Consider a full binary decomposition tree T with k = |Σ| leaves, where each leaf is uniquely associated with a symbol in Σ. [sent-280, score-0.323]
</p><p>47 Each internal node v of T corresponds to the binary problem of predicting whether the next symbol is a leaf on v’s left subtree or a leaf on v’s right subtree. [sent-281, score-0.282]
</p><p>48 For example, for Σ = {a,b,c,d,r}, Figure 2 depicts a decomposition tree T such that its root corresponds to the problem of predicting whether the next symbol is a or one of the symbols in {b, c, d, r}. [sent-282, score-0.305]
</p><p>49 We denote by CTWv any perfect k-ary tree that provides binary predictions over the binary alphabet {0v , 1v }. [sent-288, score-0.327]
</p><p>50 Observe that zs estimates a binary distribution ˆ that is based on the counts appearing in the table of Figure 2(b). [sent-295, score-0.278]
</p><p>51 (1997) and Volf (2002, Chapter 5) suggested taking T as the Huffman coding tree computed with respect to the frequency counts of the symbols in xn . [sent-319, score-0.47]
</p><p>52 The main result of this section is Theorem 19, providing a pointwise redundancy bound for the DECO algorithm. [sent-336, score-0.287]
</p><p>53 4) simply as a tree and to an ordinary tree source as a multi-source, denoted by M = (S , PS ). [sent-340, score-0.264]
</p><p>54 (28)  Si is the sufﬁx set of the ith (internal) node of the T -equivalent source of T , and ni is the number of times this node is visited when predicting xn . [sent-355, score-0.486]
</p><p>55 In that proof, we applied the bound (18) for the term (14 i) with k = 2, because the zero-order predictors, zs (·) , of CTWv provide binary predictions. [sent-365, score-0.282]
</p><p>56 For a sequence xn , by Theo1 1 rem 19 the per-symbol redundancy is n RDECO (xn , PT ) ≤ 1 ∑k−1 Ri (xn ), which vanishes with n since 1 1 n i=1 ni ≤ n for every internal-node i. [sent-371, score-0.666]
</p><p>57 1−D Recall that Willems provided a point-wise redundancy bound for this case (see Remark 11). [sent-373, score-0.287]
</p><p>58 However, if we replace each |Si | value with its maximal value kD , we are able to show that the bound is optimized when the decomposition tree is the Huffman decoding tree (see, e. [sent-386, score-0.325]
</p><p>59 1 For any decomposition tree T and a sequence xn , let ni be the number of times that the internal 1 node i ∈ T is visited when predicting xn using the DECO algorithm. [sent-390, score-0.945]
</p><p>60 394  S UPERIOR G UARANTEES FOR S EQUENTIAL P REDICTION AND L OSSLESS C OMPRESSION  Lemma 21 Let xn be a sequence and T a decomposition tree constructed using Huffman’s proce1 ˆ dure, which is based on the empirical distribution P(σ) = Nσ /n. [sent-393, score-0.473]
</p><p>61 k−1 k−1 Then, ∑i=1 ni and ∏i=1 ni are both minimal with respect to any other decomposition tree. [sent-395, score-0.294]
</p><p>62 The length of this code for some T , with respect to xn , is 1 n (xn ) = ∑t=1 (xt ), where (xt ) is the codeword length of the symbol xt . [sent-398, score-0.378]
</p><p>63 From Lemma 21 it follows that the tree constructed by Huffman’s algorithm minimizes any linear function of either ∑i ni or ∑i log ni , which proves, using Theorem 19, the following corollary. [sent-439, score-0.462]
</p><p>64 Mind the Gap Here we compare our redundancy (upper) bound for DECO and the known bound for multi-CTW. [sent-444, score-0.316]
</p><p>65 Since the multi-CTW bound is insensitive to alphabet sparsity, this suggests that DECO will outperform the multi-CTW when predicting sequences in which alphabet symbols are sparse. [sent-448, score-0.377]
</p><p>66 In this section we prove that the redundancy bound of DECO is strictly better than the corresponding multi-CTW bound, for any sufﬁciently long sequence. [sent-449, score-0.287]
</p><p>67 Let Σ be an alphabet with |Σ| = k and xn be a sequence over Σ. [sent-451, score-0.418]
</p><p>68 Fix some order D and let S be 1 the topology corresponding to the D-bounded tree-source that maximizes the probability of xn over 1 ¯ CD . [sent-452, score-0.302]
</p><p>69 Denote by RCTW the multi-CTW redundancy bound (see Theorem 9), (k − 1)|S | n k|S | − 1 ¯ RCTW (xn ) = log + |S | log k + . [sent-453, score-0.519]
</p><p>70 1 2 |S | k−1  (36)  ¯ Similarly, let RHUFF denote the redundancy of DECO applied with a Huffman-tree (see Theorem 19), ¯ RHUFF (xn ) = 1  k−1  ∑  i=1  ni kΨ − 1 Ψ log + Ψ + , 2 Ψ k−1  (37)  where Ψ is an upper-bound on the model-sizes |Si | (see Equation 28). [sent-454, score-0.489]
</p><p>71 Let T be the corresponding Huffman decomposition tree 1 k−1 and {ni }i=1 its internal node counters. [sent-458, score-0.276]
</p><p>72 Then, k−1  ∑ log ni < (k − 1) · (log n + log(1 + log k) − log(k − 1))  (38)  i=1  Proof Recall that for every symbol σ ∈ Σ, Nσ denote the number of occurrences of σ in xn and (σ) 1 ˆ denotes the length of the path from the root of T to the leaf σ. [sent-459, score-0.708]
</p><p>73 n n k−1  1  ∑ k − 1 log ni  i=1  k−1  ≤ log  1  ∑ k − 1 log ni  (39)  i=1  k−1  = log  ∑ log ni  i=1  = log  ∑ Nσ  σ∈Σ  − log(k − 1)  (σ) − log(k − 1)  ˆ < log n · (1 + H) − log(k − 1)  ≤ log (n · (1 + log k)) − log(k − 1)  = log n + log(1 + log k) − log(k − 1). [sent-461, score-1.621]
</p><p>74 algorithm has a strictly smaller redun-  Theorem 26 Let Σ be an alphabet with |Σ| = k ≥ 118 and xn be a sequence over Σ generated by 1 ¯ ¯ the (unknown) D-bounded multi-source M = (S , PS ). [sent-476, score-0.418]
</p><p>75 We conclude that the redundancy bound of DECO algorithm converges faster than the bound of the CTW algorithm for alphabet of size k ≥ 118. [sent-487, score-0.441]
</p><p>76 In this case, the DECO redundancy is even smaller than the worst case bound of Corollary 25 and the gap between the two bounds is larger. [sent-495, score-0.287]
</p><p>77 ’ This Corpus serves as a standard benchmark for testing log-loss prediction and lossless compression algorithms (Bell et al. [sent-595, score-0.294]
</p><p>78 The comb tree whose leaves (symbols) are ordered top-down according to their ascending frequencies in xn is 1 referred to as the “Huffman Comb,” and the comb tree whose leaves are reversely ordered is called the “Inverted Huffman Comb. [sent-606, score-0.619]
</p><p>79 7 In this paper, the authors study a hierarchical decomposition where each internal node in the decomposition tree is associated with a (binary) KT estimator (instead of binary-CTW instances in DECO). [sent-816, score-0.425]
</p><p>80 The authors derived a redundancy bound of k − 1 + 1 ∑ni >0 log ni for this algorithm, where the ni terms are the node counters as deﬁned 2 1 in Theorem 19. [sent-818, score-0.743]
</p><p>81 Probably the most famous (and the ﬁrst) universal lossless compression algorithms were proposed by Ziv and Lempel (1977; 1978). [sent-832, score-0.282]
</p><p>82 The point-wise (worst case) redundancy of the prediction game was introduced by Shtarkov (1987). [sent-846, score-0.327]
</p><p>83 Given a comparison class C of target distributions P and some hypothesis class P , from ˆ which the prediction algorithm selects one approximating distribution P, the point-wise redundancy of this game is R∗ (C ) = inf sup max log n n ˆ P∈P P∈C x1  P(xn ) 1 . [sent-847, score-0.443]
</p><p>84 ˆ 1 P(xn )  Shtarkov also presented the ﬁrst asymptotic lower bound on the redundancy for the case where both the hypothesis and comparison classes are the set D-order Markov sources. [sent-848, score-0.287]
</p><p>85 To date, the tightest asymptotic lower bound on the point-wise redundancy for D-gram Markov sources was recently given by Jacquet and Szpankowski (2004, Theorem 3). [sent-849, score-0.329]
</p><p>86 They showed that for large (but unspeciﬁed) D n 1 n, the lower bound is k (k−1) log 2π + log A(D, k) + log(1 + O( n )), where A(D, k) is a constant de2 pending on the order D and the alphabet size k. [sent-850, score-0.386]
</p><p>87 Algorithm  Comparison Class  Source  LZ78  Per Symbol Point-wise Redundancy O(1/ log n)  Markov Sources  CTW  |S |(|Σ|−1) log n 2n  Markov sources  BWT  |S |(|Σ|+1) log n 2n  D-order Markov sources  Savari (1997); Kieffer and Yang (1999); Potapov (2004) Willems et al. [sent-860, score-0.432]
</p><p>88 Note that the stated BWT redundancy matches the average redundancy; hence, it bounds the BWT point-wise redundancy from below. [sent-864, score-0.516]
</p><p>89 Concluding Remarks Our main result is the ﬁrst redundancy bound for the DECO algorithm. [sent-866, score-0.287]
</p><p>90 Our bounding technique can be adapted to DECO-like decomposition schemes using any binary predictor that has a (binary) point-wise redundancy bound with respect to VMMs. [sent-867, score-0.433]
</p><p>91 To the best of our knowledge, our bound for the Huffmann decomposition algorithm (proposed by Volf) is the tightest known for prediction under the log-loss and therefore, for lossless compression. [sent-868, score-0.289]
</p><p>92 Since ﬁnding the best decomposition is an NP-hard problem, a very interesting research question is whether one could optimize the DECO redundancy bound over the possible decompositions. [sent-877, score-0.351]
</p><p>93 But perhaps the most important research target at this time is the development of a lower bound on the redundancy of predictors for ﬁnite (and short) sequences. [sent-888, score-0.287]
</p><p>94 405  B EGLEITER AND E L -YANIV  Lemma 28 Consider the case where Then,  KT  counts all the symbols of the sequence xn (i. [sent-901, score-0.386]
</p><p>95 Recall that this theorem states an upper bound of log n + log k for the worst-case redundancy of zKT (xn ). [sent-907, score-0.519]
</p><p>96 n) n supz∈Z z(x1 k  ¢  Let a = (ai )k ∈ i=1  k  (49)  be a vector of arbitrary symbol counts for some sequence xn . [sent-909, score-0.375]
</p><p>97 It is well known that, given ∏i=1 ∑k a i=1 i the counts a, the distribution that maximizes the probability of xn is z, the maximum likelihood dis1 tribution (see, e. [sent-912, score-0.286]
</p><p>98 1 t  = −1;  y Recall that limx→+∞ (1 + x )x = ey and observe that,  lim f (t) =  t→+∞  lim g(q) =  q→+∞  lim log 1 −  t→+∞  1 2t  + (t − 1) log 1 −  lim − q − 1 +  q→+∞  1 k−2 k−1 log 1 − − log 1 + 2 q 2q  = 1. [sent-952, score-0.464]
</p><p>99 Multi-alphabet universal coding using a binary decomposition context tree weighting algorithm. [sent-1244, score-0.327]
</p><p>100 Efﬁcient universal lossless data compression algorithms based on a greedy sequential grammar transform. [sent-1296, score-0.32]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ctw', 0.426), ('deco', 0.355), ('huffman', 0.276), ('xn', 0.261), ('redundancy', 0.258), ('zs', 0.21), ('lossless', 0.127), ('alphabet', 0.125), ('egleiter', 0.118), ('pctw', 0.118), ('willems', 0.118), ('zkt', 0.118), ('tree', 0.116), ('log', 0.116), ('ni', 0.115), ('ompression', 0.11), ('ossless', 0.11), ('tjalkens', 0.11), ('uarantees', 0.11), ('uperior', 0.11), ('kt', 0.099), ('compression', 0.098), ('volf', 0.094), ('equential', 0.084), ('rediction', 0.084), ('calgary', 0.079), ('ps', 0.073), ('counters', 0.071), ('orlitsky', 0.071), ('rhuff', 0.071), ('prediction', 0.069), ('estimators', 0.069), ('symbols', 0.068), ('decomposition', 0.064), ('comb', 0.063), ('mix', 0.062), ('xt', 0.06), ('internal', 0.057), ('symbol', 0.057), ('universal', 0.057), ('cd', 0.056), ('rctw', 0.055), ('shtarkov', 0.055), ('tdeco', 0.055), ('zgt', 0.055), ('pv', 0.055), ('nv', 0.054), ('estimator', 0.049), ('begleiter', 0.047), ('krichevsky', 0.047), ('nvi', 0.047), ('tro', 0.047), ('weighting', 0.047), ('leaf', 0.043), ('binary', 0.043), ('gt', 0.043), ('sources', 0.042), ('decompositions', 0.041), ('topology', 0.041), ('alphabets', 0.04), ('ctwv', 0.039), ('mov', 0.039), ('sadakane', 0.039), ('subs', 0.039), ('node', 0.039), ('pt', 0.039), ('predictor', 0.039), ('sequential', 0.038), ('si', 0.037), ('trees', 0.036), ('hierarchical', 0.036), ('bwt', 0.033), ('topologies', 0.033), ('sequence', 0.032), ('source', 0.032), ('ascii', 0.032), ('bib', 0.032), ('jacquet', 0.032), ('kieffer', 0.032), ('pdeco', 0.032), ('progc', 0.032), ('progl', 0.032), ('progp', 0.032), ('rdeco', 0.032), ('technion', 0.032), ('tu', 0.031), ('corpus', 0.03), ('sequences', 0.03), ('height', 0.03), ('bound', 0.029), ('decomposed', 0.029), ('ts', 0.028), ('vovk', 0.027), ('turing', 0.027), ('ppm', 0.027), ('compelling', 0.027), ('dz', 0.027), ('counter', 0.026), ('counts', 0.025), ('news', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="90-tfidf-1" href="./jmlr-2006-Superior_Guarantees_for_Sequential_Prediction_and_Lossless_Compression_via_Alphabet_Decomposition.html">90 jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</a></p>
<p>Author: Ron Begleiter, Ran El-Yaniv</p><p>Abstract: We present worst case bounds for the learning rate of a known prediction method that is based on hierarchical applications of binary context tree weighting (CTW) predictors. A heuristic application of this approach that relies on Huffman’s alphabet decomposition is known to achieve state-ofthe-art performance in prediction and lossless compression benchmarks. We show that our new bound for this heuristic is tighter than the best known performance guarantees for prediction and lossless compression algorithms in various settings. This result substantiates the efﬁciency of this hierarchical method and provides a compelling explanation for its practical success. In addition, we present the results of a few experiments that examine other possibilities for improving the multialphabet prediction performance of CTW-based algorithms. Keywords: sequential prediction, the context tree weighting method, variable order Markov models, error bounds</p><p>2 0.081965752 <a title="90-tfidf-2" href="./jmlr-2006-A_Simulation-Based_Algorithm_for_Ergodic_Control_of_Markov_Chains_Conditioned_on_Rare_Events.html">7 jmlr-2006-A Simulation-Based Algorithm for Ergodic Control of Markov Chains Conditioned on Rare Events</a></p>
<p>Author: Shalabh Bhatnagar, Vivek S. Borkar, Madhukar Akarapu</p><p>Abstract: We study the problem of long-run average cost control of Markov chains conditioned on a rare event. In a related recent work, a simulation based algorithm for estimating performance measures associated with a Markov chain conditioned on a rare event has been developed. We extend ideas from this work and develop an adaptive algorithm for obtaining, online, optimal control policies conditioned on a rare event. Our algorithm uses three timescales or step-size schedules. On the slowest timescale, a gradient search algorithm for policy updates that is based on one-simulation simultaneous perturbation stochastic approximation (SPSA) type estimates is used. Deterministic perturbation sequences obtained from appropriate normalized Hadamard matrices are used here. The fast timescale recursions compute the conditional transition probabilities of an associated chain by obtaining solutions to the multiplicative Poisson equation (for a given policy estimate). Further, the risk parameter associated with the value function for a given policy estimate is updated on a timescale that lies in between the two scales above. We brieﬂy sketch the convergence analysis of our algorithm and present a numerical application in the setting of routing multiple ﬂows in communication networks. Keywords: Markov decision processes, optimal control conditioned on a rare event, simulation based algorithms, SPSA with deterministic perturbations, reinforcement learning</p><p>3 0.074955076 <a title="90-tfidf-3" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>Author: Tzu-Kuo Huang, Ruby C. Weng, Chih-Jen Lin</p><p>Abstract: The Bradley-Terry model for obtaining individual skill from paired comparisons has been popular in many areas. In machine learning, this model is related to multi-class probability estimates by coupling all pairwise classiﬁcation results. Error correcting output codes (ECOC) are a general framework to decompose a multi-class problem to several binary problems. To obtain probability estimates under this framework, this paper introduces a generalized Bradley-Terry model in which paired individual comparisons are extended to paired team comparisons. We propose a simple algorithm with convergence proofs to solve the model and obtain individual skill. Experiments on synthetic and real data demonstrate that the algorithm is useful for obtaining multi-class probability estimates. Moreover, we discuss four extensions of the proposed model: 1) weighted individual skill, 2) home-ﬁeld advantage, 3) ties, and 4) comparisons with more than two teams. Keywords: Bradley-Terry model, probability estimates, error correcting output codes, support vector machines</p><p>4 0.06482818 <a title="90-tfidf-4" href="./jmlr-2006-Incremental_Algorithms_for_Hierarchical_Classification.html">37 jmlr-2006-Incremental Algorithms for Hierarchical Classification</a></p>
<p>Author: Nicolò Cesa-Bianchi, Claudio Gentile, Luca Zaniboni</p><p>Abstract: We study the problem of classifying data in a given taxonomy when classiﬁcations associated with multiple and/or partial paths are allowed. We introduce a new algorithm that incrementally learns a linear-threshold classiﬁer for each node of the taxonomy. A hierarchical classiﬁcation is obtained by evaluating the trained node classiﬁers in a top-down fashion. To evaluate classiﬁers in our multipath framework, we deﬁne a new hierarchical loss function, the H-loss, capturing the intuition that whenever a classiﬁcation mistake is made on a node of the taxonomy, then no loss should be charged for any additional mistake occurring in the subtree of that node. Making no assumptions on the mechanism generating the data instances, and assuming a linear noise model for the labels, we bound the H-loss of our on-line algorithm in terms of the H-loss of a reference classiﬁer knowing the true parameters of the label-generating process. We show that, in expectation, the excess cumulative H-loss grows at most logarithmically in the length of the data sequence. Furthermore, our analysis reveals the precise dependence of the rate of convergence on the eigenstructure of the data each node observes. Our theoretical results are complemented by a number of experiments on texual corpora. In these experiments we show that, after only one epoch of training, our algorithm performs much better than Perceptron-based hierarchical classiﬁers, and reasonably close to a hierarchical support vector machine. Keywords: incremental algorithms, online learning, hierarchical classiﬁcation, second order perceptron, support vector machines, regret bound, loss function</p><p>5 0.058228254 <a title="90-tfidf-5" href="./jmlr-2006-Policy_Gradient_in_Continuous_Time.html">75 jmlr-2006-Policy Gradient in Continuous Time</a></p>
<p>Author: Rémi Munos</p><p>Abstract: Policy search is a method for approximately solving an optimal control problem by performing a parametric optimization search in a given class of parameterized policies. In order to process a local optimization technique, such as a gradient method, we wish to evaluate the sensitivity of the performance measure with respect to the policy parameters, the so-called policy gradient. This paper is concerned with the estimation of the policy gradient for continuous-time, deterministic state dynamics, in a reinforcement learning framework, that is, when the decision maker does not have a model of the state dynamics. We show that usual likelihood ratio methods used in discrete-time, fail to proceed the gradient because they are subject to variance explosion when the discretization time-step decreases to 0. We describe an alternative approach based on the approximation of the pathwise derivative, which leads to a policy gradient estimate that converges almost surely to the true gradient when the timestep tends to 0. The underlying idea starts with the derivation of an explicit representation of the policy gradient using pathwise derivation. This derivation makes use of the knowledge of the state dynamics. Then, in order to estimate the gradient from the observable data only, we use a stochastic policy to discretize the continuous deterministic system into a stochastic discrete process, which enables to replace the unknown coefﬁcients by quantities that solely depend on known data. We prove the almost sure convergence of this estimate to the true policy gradient when the discretization time-step goes to zero. The method is illustrated on two target problems, in discrete and continuous control spaces. Keywords: optimal control, reinforcement learning, policy search, sensitivity analysis, parametric optimization, gradient estimate, likelihood ratio method, pathwise derivation 1. Introduction and Statement of the Problem We consider an optimal control problem with continuous state (xt ∈ IRd )t≥0 whose state dynamics is deﬁned according to the controlled differential equation: dxt = f (xt , ut ), dt (1) where the control (ut )t≥0 is a Lebesgue measurable function with values in a control space U. Note that the state-dynamics f may also depend on time, but we omit this dependency in the notation, for simplicity. We intend to maximize a functional J that depends on the trajectory (xt )0≤t≤T over a ﬁnite-time horizon T > 0. For simplicity, in the paper, we illustrate the case of a terminal reward c 2006 Rémi Munos. M UNOS only: J(x; (ut )t≥0 ) := r(xT ), (2) where r : IRd → IR is the reward function. Extension to the case of general functional of the kind J(x; (ut )t≥0 ) = Z T 0 r(t, xt )dt + R(xT ), (3) with r and R being current and terminal reward functions, would easily follow, as indicated in Remark 1. The optimal control problem of ﬁnding a control (ut )t≥0 that maximizes the functional is replaced by a parametric optimization problem for which we search for a good feed-back control law in a given class of parameterized policies {πα : [0, T ] × IRd → U}α , where α ∈ IRm is the parameter. The control ut ∈ U (or action) at time t is ut = πα (t, xt ), and we may write the dynamics of the resulting feed-back system as dxt = fα (xt ), (4) dt where fα (xt ) := f (x, πα (t, x)). In the paper, we will make the assumption that fα is C 2 , with bounded derivatives. Let us deﬁne the performance measure V (α) := J(x; πα (t, xt )t≥0 ), where its dependency with respect to (w.r.t.) the parameter α is emphasized. One may also consider an average performance measure according to some distribution µ for the initial state: V (α) := E[J(x; πα (t, xt )t≥0 )|x ∼ µ]. In order to ﬁnd a local maximum of V (α), one may perform a local search, such as a gradient ascent method α ← α + η∇αV (α), (5) with an adequate step η (see for example (Polyak, 1987; Kushner and Yin, 1997)). The computation of the gradient ∇αV (α) is the object of this paper. A ﬁrst method would be to approximate the gradient by a ﬁnite-difference quotient for each of the m components of the parameter: V (α + εei ) −V (α) , ε for some small value of ε (we use the notation ∂α instead of ∇α to indicate that it is a singledimensional derivative). This ﬁnite-difference method requires the simulation of m + 1 trajectories to compute an approximation of the true gradient. When the number of parameters is large, this may be computationally expensive. However, this simple method may be efﬁcient if the number of parameters is relatively small. In the rest of the paper we will not consider this approach, and will aim at computing the gradient using one trajectory only. ∂αi V (α) ≃ 772 P OLICY G RADIENT IN C ONTINUOUS T IME Pathwise estimation of the gradient. We now illustrate that if the decision-maker has access to a model of the state dynamics, then a pathwise derivation would directly lead to the policy gradient. Indeed, let us deﬁne the gradient of the state with respect to the parameter: zt := ∇α xt (i.e. zt is deﬁned as a d × m-matrix whose (i, j)-component is the derivative of the ith component of xt w.r.t. α j ). Our smoothness assumption on fα allows to differentiate the state dynamics (4) w.r.t. α, which provides the dynamics on (zt ): dzt = ∇α fα (xt ) + ∇x fα (xt )zt , dt (6) where the coefﬁcients ∇α fα and ∇x fα are, respectively, the derivatives of f w.r.t. the parameter (matrix of size d × m) and the state (matrix of size d × d). The initial condition for z is z0 = 0. When the reward function r is smooth (i.e. continuously differentiable), one may apply a pathwise differentiation to derive a gradient formula (see e.g. (Bensoussan, 1988) or (Yang and Kushner, 1991) for an extension to the stochastic case): ∇αV (α) = ∇x r(xT )zT . (7) Remark 1 In the more general setting of a functional (3), the gradient is deduced (by linearity) from the above formula: ∇αV (α) = Z T 0 ∇x r(t, xt )zt dt + ∇x R(xT )zT . What is known from the agent? The decision maker (call it the agent) that intends to design a good controller for the dynamical system may or may not know a model of the state dynamics f . In case the dynamics is known, the state gradient zt = ∇α xt may be computed from (6) along the trajectory and the gradient of the performance measure w.r.t. the parameter α is deduced at time T from (7), which allows to perform the gradient ascent step (5). However, in this paper we consider a Reinforcement Learning (Sutton and Barto, 1998) setting in which the state dynamics is unknown from the agent, but we still assume that the state is fully observable. The agent knows only the response of the system to its control. To be more precise, the available information to the agent at time t is its own control policy πα and the trajectory (xs )0≤s≤t up to time t. At time T , the agent receives the reward r(xT ) and, in this paper, we assume that the gradient ∇r(xT ) is available to the agent. From this point of view, it seems impossible to derive the state gradient zt from (6), since ∇α f and ∇x f are unknown. The term ∇x f (xt ) may be approximated by a least squares method from the observation of past states (xs )s≤t , as this will be explained later on in subsection 3.2. However the term ∇α f (xt ) cannot be calculated analogously. In this paper, we introduce the idea of using stochastic policies to approximate the state (xt ) and the state gradient (zt ) by discrete-time stochastic processes (Xt∆ ) and (Zt∆ ) (with ∆ being some discretization time-step). We show how Zt∆ can be computed without the knowledge of ∇α f , but only from information available to the agent. ∆ ∆ We prove the convergence (with probability one) of the gradient estimate ∇x r(XT )ZT derived from the stochastic processes to ∇αV (α) when ∆ → 0. Here, almost sure convergence is obtained using the concentration of measure phenomenon (Talagrand, 1996; Ledoux, 2001). 773 M UNOS y ∆ XT ∆ X t2 ∆ Xt 0 fα ∆ x Xt 1 Figure 1: A trajectory (Xt∆ )0≤n≤N and the state dynamics vector fα of the continuous process n (xt )0≤t≤T . Likelihood ratio method? It is worth mentioning that this strong convergence result contrasts with the usual likelihood ratio method (also called score method) in discrete time (see e.g. (Reiman and Weiss, 1986; Glynn, 1987) or more recently in the reinforcement learning literature (Williams, 1992; Sutton et al., 2000; Baxter and Bartlett, 2001; Marbach and Tsitsiklis, 2003)) for which the policy gradient estimate is subject to variance explosion when the discretization time-step ∆ tends to 0. The intuitive reason for that problem lies in the fact that the number of decisions before getting the reward grows to inﬁnity when ∆ → 0 (the variance of likelihood ratio estimates being usually linear with the number of decisions). Let us illustrate this problem on a simple 2 dimensional process. Consider the deterministic continuous process (xt )0≤t≤1 deﬁned by the state dynamics: dxt = fα := dt α 1−α , (8) (0 < α < 1) with initial condition x0 = (0 0)′ (where ′ denotes the transpose operator). The performance measure V (α) is the reward at the terminal state at time T = 1, with the reward function being the ﬁrst coordinate of the state r((x y)′ ) := x. Thus V (α) = r(xT =1 ) = α and its derivative is ∇αV (α) = 1. Let (Xt∆ )0≤n≤N ∈ IR2 be a discrete time stochastic process (the discrete times being {tn = n ∆ n∆}n=0...N with the discretization time-step ∆ = 1/N) that starts from initial state X0 = x0 = (0 0)′ and makes N random moves of length ∆ towards the right (action u1 ) or the top (action u2 ) (see Figure 1) according to the stochastic policy (i.e., the probability of choosing the actions in each state x) πα (u1 |x) = α, πα (u2 |x) = 1 − α. The process is thus deﬁned according to the dynamics: Xt∆ = Xt∆ + n n+1 Un 1 −Un ∆, (9) where (Un )0≤n < N and all ∞ N > 0), there exists a constant C that does not depend on N such that dn ≤ C/N. Thus we may take D2 = C2 /N. Now, from the previous paragraph, ||E[XN ] − xN || ≤ e(N), with e(N) → 0 when N → ∞. This means that ||h − E[h]|| + e(N) ≥ ||XN − xN ||, thus P(||h − E[h]|| ≥ ε + e(N)) ≥ P(||XN − xN || ≥ ε), and we deduce from (31) that 2 /(2C 2 ) P(||XN − xN || ≥ ε) ≤ 2e−N(ε+e(N)) . Thus, for all ε > 0, the series ∑N≥0 P(||XN − xN || ≥ ε) converges. Now, from Borel-Cantelli lemma, we deduce that for all ε > 0, there exists Nε such that for all N ≥ Nε , ||XN − xN || < ε, which ∆→0 proves the almost sure convergence of XN to xN as N → ∞ (i.e. XT −→ xT almost surely). Appendix C. Proof of Proposition 8 ′ First, note that Qt = X X ′ − X X is a symmetric, non-negative matrix, since it may be rewritten as 1 nt ∑ (Xs+ − X)(Xs+ − X)′ . s∈S(t) In solving the least squares problem (21), we deduce b = ∆X + AX∆, thus min A,b 1 1 ∑ ∆Xs − b −A(Xs+2 ∆Xs )∆ nt s∈S(t) ≤ 2 = min A 1 ∑ ∆Xs − ∆X − A(Xs+ − X)∆ nt s∈S(t) 1 ∑ ∆Xs− ∆X− ∇x f (X, ut )(Xs+− X)∆ nt s∈S(t) 2 2 . (32) Now, since Xs = X + O(∆) one may obtain like in (19) and (20) (by replacing Xt by X) that: ∆Xs − ∆X − ∇x f (X, ut )(Xs+ − X)∆ = O(∆3 ). (33) We deduce from (32) and (33) that 1 nt ∑ ∇x f (Xt , ut ) − ∇x f (X, ut ) (Xs+ − X)∆ 2 = O(∆6 ). s∈S(t) By developing each component, d ∑ ∇x f (Xt , ut ) − ∇x f (X, ut ) i=1 row i Qt ∇x f (Xt , ut ) − ∇x f (X, ut ) ′ row i = O(∆4 ). Now, from the deﬁnition of ν(∆), for all vector u ∈ IRd , u′ Qt u ≥ ν(∆)||u||2 , thus ν(∆)||∇x f (Xt , ut ) − ∇x f (X, ut )||2 = O(∆4 ). Condition (23) yields ∇x f (Xt , ut ) = ∇x f (X, ut ) + o(1), and since ∇x f (Xt , ut ) = ∇x f (X, ut ) + O(∆), we deduce lim ∇x f (Xt , ut ) = ∇x f (Xt , ut ). ∆→0 789 M UNOS References J. Baxter and P. L. Bartlett. Inﬁnite-horizon gradient-based policy search. Journal of Artiﬁcial Intelligence Research, 15:319–350, 2001. A. Bensoussan. Perturbation methods in optimal control. Wiley/Gauthier-Villars Series in Modern Applied Mathematics. John Wiley & Sons Ltd., Chichester, 1988. Translated from the French by C. Tomson. A. Bogdanov. Optimal control of a double inverted pendulum on a cart. Technical report CSE-04006, CSEE, OGI School of Science and Engineering, OHSU, 2004. P. W. Glynn. Likelihood ratio gradient estimation: an overview. In A. Thesen, H. Grant, and W. D. Kelton, editors, Proceedings of the 1987 Winter Simulation Conference, pages 366–375, 1987. E. Gobet and R. Munos. Sensitivity analysis using Itô-Malliavin calculus and martingales. application to stochastic optimal control. SIAM journal on Control and Optimization, 43(5):1676–1713, 2005. G. H. Golub and C. F. Van Loan. Matrix Computations, 3rd ed. Baltimore, MD: Johns Hopkins, 1996. R. E. Kalman, P. L. Falb, and M. A. Arbib. Topics in Mathematical System Theory. New York: McGraw Hill, 1969. P. E. Kloeden and E. Platen. Numerical Solutions of Stochastic Differential Equations. SpringerVerlag, 1995. H. J. Kushner and G. Yin. Stochastic Approximation Algorithms and Applications. Springer-Verlag, Berlin and New York, 1997. S. M. LaValle. Planning Algorithms. Cambridge University Press, 2006. M. Ledoux. The concentration of measure phenomenon. American Mathematical Society, Providence, RI, 2001. P. Marbach and J. N. Tsitsiklis. Approximate gradient methods in policy-space optimization of Markov reward processes. Journal of Discrete Event Dynamical Systems, 13:111–148, 2003. B. T. Polyak. Introduction to Optimization. Optimization Software Inc., New York, 1987. M. I. Reiman and A. Weiss. Sensitivity analysis via likelihood ratios. In J. Wilson, J. Henriksen, and S. Roberts, editors, Proceedings of the 1986 Winter Simulation Conference, pages 285–289, 1986. R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. Bradford Book, 1998. R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour. Policy gradient methods for reinforcement learning with function approximation. Neural Information Processing Systems. MIT Press, pages 1057–1063, 2000. 790 P OLICY G RADIENT IN C ONTINUOUS T IME M. Talagrand. A new look at independence. Annals of Probability, 24:1–34, 1996. R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, 8:229–256, 1992. J. Yang and H. J. Kushner. A Monte Carlo method for sensitivity analysis and parametric optimization of nonlinear stochastic systems. SIAM J. Control Optim., 29(5):1216–1249, 1991. 791</p><p>6 0.055850964 <a title="90-tfidf-6" href="./jmlr-2006-Lower_Bounds_and_Aggregation_in_Density_Estimation.html">58 jmlr-2006-Lower Bounds and Aggregation in Density Estimation</a></p>
<p>7 0.054985605 <a title="90-tfidf-7" href="./jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">28 jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<p>8 0.052675381 <a title="90-tfidf-8" href="./jmlr-2006-Pattern_Recognition_for__Conditionally_Independent_Data.html">73 jmlr-2006-Pattern Recognition for  Conditionally Independent Data</a></p>
<p>9 0.051298738 <a title="90-tfidf-9" href="./jmlr-2006-Worst-Case_Analysis_of_Selective_Sampling_for_Linear_Classification.html">96 jmlr-2006-Worst-Case Analysis of Selective Sampling for Linear Classification</a></p>
<p>10 0.041139107 <a title="90-tfidf-10" href="./jmlr-2006-Noisy-OR_Component_Analysis_and_its_Application_to_Link_Analysis.html">64 jmlr-2006-Noisy-OR Component Analysis and its Application to Link Analysis</a></p>
<p>11 0.040187288 <a title="90-tfidf-11" href="./jmlr-2006-Toward_Attribute_Efficient_Learning_of_Decision_Lists_and_Parities.html">92 jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</a></p>
<p>12 0.03728557 <a title="90-tfidf-12" href="./jmlr-2006-Online_Passive-Aggressive_Algorithms.html">70 jmlr-2006-Online Passive-Aggressive Algorithms</a></p>
<p>13 0.036672533 <a title="90-tfidf-13" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>14 0.036302645 <a title="90-tfidf-14" href="./jmlr-2006-Bayesian_Network_Learning_with_Parameter_Constraints_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">15 jmlr-2006-Bayesian Network Learning with Parameter Constraints     (Special Topic on Machine Learning and Optimization)</a></p>
<p>15 0.035674255 <a title="90-tfidf-15" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>16 0.034903403 <a title="90-tfidf-16" href="./jmlr-2006-Step_Size_Adaptation_in_Reproducing_Kernel_Hilbert_Space.html">86 jmlr-2006-Step Size Adaptation in Reproducing Kernel Hilbert Space</a></p>
<p>17 0.033912182 <a title="90-tfidf-17" href="./jmlr-2006-Linear_State-Space_Models_for_Blind_Source_Separation.html">57 jmlr-2006-Linear State-Space Models for Blind Source Separation</a></p>
<p>18 0.032404799 <a title="90-tfidf-18" href="./jmlr-2006-Learning_Factor_Graphs_in_Polynomial_Time_and_Sample_Complexity.html">46 jmlr-2006-Learning Factor Graphs in Polynomial Time and Sample Complexity</a></p>
<p>19 0.032353017 <a title="90-tfidf-19" href="./jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>20 0.03106861 <a title="90-tfidf-20" href="./jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">6 jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.174), (1, 0.097), (2, -0.046), (3, -0.034), (4, -0.116), (5, 0.102), (6, -0.034), (7, -0.016), (8, 0.048), (9, 0.017), (10, 0.009), (11, -0.056), (12, 0.037), (13, -0.044), (14, -0.031), (15, 0.03), (16, -0.103), (17, -0.176), (18, 0.097), (19, 0.097), (20, -0.145), (21, 0.232), (22, -0.073), (23, -0.1), (24, -0.062), (25, 0.198), (26, 0.174), (27, -0.106), (28, 0.111), (29, -0.117), (30, 0.106), (31, 0.038), (32, -0.095), (33, -0.156), (34, -0.135), (35, 0.089), (36, -0.038), (37, -0.118), (38, -0.338), (39, 0.144), (40, -0.029), (41, 0.044), (42, 0.095), (43, 0.107), (44, -0.048), (45, -0.041), (46, 0.15), (47, 0.106), (48, 0.05), (49, -0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95651609 <a title="90-lsi-1" href="./jmlr-2006-Superior_Guarantees_for_Sequential_Prediction_and_Lossless_Compression_via_Alphabet_Decomposition.html">90 jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</a></p>
<p>Author: Ron Begleiter, Ran El-Yaniv</p><p>Abstract: We present worst case bounds for the learning rate of a known prediction method that is based on hierarchical applications of binary context tree weighting (CTW) predictors. A heuristic application of this approach that relies on Huffman’s alphabet decomposition is known to achieve state-ofthe-art performance in prediction and lossless compression benchmarks. We show that our new bound for this heuristic is tighter than the best known performance guarantees for prediction and lossless compression algorithms in various settings. This result substantiates the efﬁciency of this hierarchical method and provides a compelling explanation for its practical success. In addition, we present the results of a few experiments that examine other possibilities for improving the multialphabet prediction performance of CTW-based algorithms. Keywords: sequential prediction, the context tree weighting method, variable order Markov models, error bounds</p><p>2 0.49845922 <a title="90-lsi-2" href="./jmlr-2006-A_Simulation-Based_Algorithm_for_Ergodic_Control_of_Markov_Chains_Conditioned_on_Rare_Events.html">7 jmlr-2006-A Simulation-Based Algorithm for Ergodic Control of Markov Chains Conditioned on Rare Events</a></p>
<p>Author: Shalabh Bhatnagar, Vivek S. Borkar, Madhukar Akarapu</p><p>Abstract: We study the problem of long-run average cost control of Markov chains conditioned on a rare event. In a related recent work, a simulation based algorithm for estimating performance measures associated with a Markov chain conditioned on a rare event has been developed. We extend ideas from this work and develop an adaptive algorithm for obtaining, online, optimal control policies conditioned on a rare event. Our algorithm uses three timescales or step-size schedules. On the slowest timescale, a gradient search algorithm for policy updates that is based on one-simulation simultaneous perturbation stochastic approximation (SPSA) type estimates is used. Deterministic perturbation sequences obtained from appropriate normalized Hadamard matrices are used here. The fast timescale recursions compute the conditional transition probabilities of an associated chain by obtaining solutions to the multiplicative Poisson equation (for a given policy estimate). Further, the risk parameter associated with the value function for a given policy estimate is updated on a timescale that lies in between the two scales above. We brieﬂy sketch the convergence analysis of our algorithm and present a numerical application in the setting of routing multiple ﬂows in communication networks. Keywords: Markov decision processes, optimal control conditioned on a rare event, simulation based algorithms, SPSA with deterministic perturbations, reinforcement learning</p><p>3 0.34694356 <a title="90-lsi-3" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>Author: Tzu-Kuo Huang, Ruby C. Weng, Chih-Jen Lin</p><p>Abstract: The Bradley-Terry model for obtaining individual skill from paired comparisons has been popular in many areas. In machine learning, this model is related to multi-class probability estimates by coupling all pairwise classiﬁcation results. Error correcting output codes (ECOC) are a general framework to decompose a multi-class problem to several binary problems. To obtain probability estimates under this framework, this paper introduces a generalized Bradley-Terry model in which paired individual comparisons are extended to paired team comparisons. We propose a simple algorithm with convergence proofs to solve the model and obtain individual skill. Experiments on synthetic and real data demonstrate that the algorithm is useful for obtaining multi-class probability estimates. Moreover, we discuss four extensions of the proposed model: 1) weighted individual skill, 2) home-ﬁeld advantage, 3) ties, and 4) comparisons with more than two teams. Keywords: Bradley-Terry model, probability estimates, error correcting output codes, support vector machines</p><p>4 0.29544151 <a title="90-lsi-4" href="./jmlr-2006-Lower_Bounds_and_Aggregation_in_Density_Estimation.html">58 jmlr-2006-Lower Bounds and Aggregation in Density Estimation</a></p>
<p>Author: Guillaume Lecué</p><p>Abstract: In this paper we prove the optimality of an aggregation procedure. We prove lower bounds for aggregation of model selection type of M density estimators for the Kullback-Leibler divergence (KL), the Hellinger’s distance and the L1 -distance. The lower bound, with respect to the KL distance, can be achieved by the on-line type estimate suggested, among others, by Yang (2000a). Combining these results, we state that log M/n is an optimal rate of aggregation in the sense of Tsybakov (2003), where n is the sample size. Keywords: aggregation, optimal rates, Kullback-Leibler divergence</p><p>5 0.29235929 <a title="90-lsi-5" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>Author: Clayton D. Scott, Robert D. Nowak</p><p>Abstract: Given a probability measure P and a reference measure µ, one is often interested in the minimum µ-measure set with P-measure at least α. Minimum volume sets of this type summarize the regions of greatest probability mass of P, and are useful for detecting anomalies and constructing conﬁdence regions. This paper addresses the problem of estimating minimum volume sets based on independent samples distributed according to P. Other than these samples, no other information is available regarding P, but the reference measure µ is assumed to be known. We introduce rules for estimating minimum volume sets that parallel the empirical risk minimization and structural risk minimization principles in classiﬁcation. As in classiﬁcation, we show that the performances of our estimators are controlled by the rate of uniform convergence of empirical to true probabilities over the class from which the estimator is drawn. Thus we obtain ﬁnite sample size performance bounds in terms of VC dimension and related quantities. We also demonstrate strong universal consistency, an oracle inequality, and rates of convergence. The proposed estimators are illustrated with histogram and decision tree set estimation rules. Keywords: minimum volume sets, anomaly detection, statistical learning theory, uniform deviation bounds, sample complexity, universal consistency</p><p>6 0.27021337 <a title="90-lsi-6" href="./jmlr-2006-Pattern_Recognition_for__Conditionally_Independent_Data.html">73 jmlr-2006-Pattern Recognition for  Conditionally Independent Data</a></p>
<p>7 0.26577044 <a title="90-lsi-7" href="./jmlr-2006-Noisy-OR_Component_Analysis_and_its_Application_to_Link_Analysis.html">64 jmlr-2006-Noisy-OR Component Analysis and its Application to Link Analysis</a></p>
<p>8 0.26017332 <a title="90-lsi-8" href="./jmlr-2006-Learning_Factor_Graphs_in_Polynomial_Time_and_Sample_Complexity.html">46 jmlr-2006-Learning Factor Graphs in Polynomial Time and Sample Complexity</a></p>
<p>9 0.24117444 <a title="90-lsi-9" href="./jmlr-2006-Toward_Attribute_Efficient_Learning_of_Decision_Lists_and_Parities.html">92 jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</a></p>
<p>10 0.23461732 <a title="90-lsi-10" href="./jmlr-2006-Policy_Gradient_in_Continuous_Time.html">75 jmlr-2006-Policy Gradient in Continuous Time</a></p>
<p>11 0.23097685 <a title="90-lsi-11" href="./jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>12 0.22060081 <a title="90-lsi-12" href="./jmlr-2006-Incremental_Algorithms_for_Hierarchical_Classification.html">37 jmlr-2006-Incremental Algorithms for Hierarchical Classification</a></p>
<p>13 0.20521076 <a title="90-lsi-13" href="./jmlr-2006-On_Model_Selection_Consistency_of_Lasso.html">66 jmlr-2006-On Model Selection Consistency of Lasso</a></p>
<p>14 0.19128661 <a title="90-lsi-14" href="./jmlr-2006-Bayesian_Network_Learning_with_Parameter_Constraints_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">15 jmlr-2006-Bayesian Network Learning with Parameter Constraints     (Special Topic on Machine Learning and Optimization)</a></p>
<p>15 0.18805912 <a title="90-lsi-15" href="./jmlr-2006-Learning_a_Hidden_Hypergraph.html">53 jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>16 0.18194292 <a title="90-lsi-16" href="./jmlr-2006-Action_Elimination_and_Stopping_Conditions_for_the_Multi-Armed_Bandit_and_Reinforcement_Learning_Problems.html">10 jmlr-2006-Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems</a></p>
<p>17 0.16445515 <a title="90-lsi-17" href="./jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">28 jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<p>18 0.15983699 <a title="90-lsi-18" href="./jmlr-2006-Worst-Case_Analysis_of_Selective_Sampling_for_Linear_Classification.html">96 jmlr-2006-Worst-Case Analysis of Selective Sampling for Linear Classification</a></p>
<p>19 0.14680272 <a title="90-lsi-19" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>20 0.14421125 <a title="90-lsi-20" href="./jmlr-2006-Parallel_Software_for_Training_Large_Scale_Support_Vector_Machines_on_Multiprocessor_Systems_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">72 jmlr-2006-Parallel Software for Training Large Scale Support Vector Machines on Multiprocessor Systems     (Special Topic on Machine Learning and Optimization)</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.445), (8, 0.011), (36, 0.061), (45, 0.06), (50, 0.034), (61, 0.011), (63, 0.037), (68, 0.017), (76, 0.023), (78, 0.013), (79, 0.021), (81, 0.033), (83, 0.012), (84, 0.021), (90, 0.038), (91, 0.034), (96, 0.046)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73477083 <a title="90-lda-1" href="./jmlr-2006-Superior_Guarantees_for_Sequential_Prediction_and_Lossless_Compression_via_Alphabet_Decomposition.html">90 jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</a></p>
<p>Author: Ron Begleiter, Ran El-Yaniv</p><p>Abstract: We present worst case bounds for the learning rate of a known prediction method that is based on hierarchical applications of binary context tree weighting (CTW) predictors. A heuristic application of this approach that relies on Huffman’s alphabet decomposition is known to achieve state-ofthe-art performance in prediction and lossless compression benchmarks. We show that our new bound for this heuristic is tighter than the best known performance guarantees for prediction and lossless compression algorithms in various settings. This result substantiates the efﬁciency of this hierarchical method and provides a compelling explanation for its practical success. In addition, we present the results of a few experiments that examine other possibilities for improving the multialphabet prediction performance of CTW-based algorithms. Keywords: sequential prediction, the context tree weighting method, variable order Markov models, error bounds</p><p>2 0.28712291 <a title="90-lda-2" href="./jmlr-2006-Learning_Spectral_Clustering%2C_With_Application_To_Speech_Separation.html">52 jmlr-2006-Learning Spectral Clustering, With Application To Speech Separation</a></p>
<p>Author: Francis R. Bach, Michael I. Jordan</p><p>Abstract: Spectral clustering refers to a class of techniques which rely on the eigenstructure of a similarity matrix to partition points into disjoint clusters, with points in the same cluster having high similarity and points in different clusters having low similarity. In this paper, we derive new cost functions for spectral clustering based on measures of error between a given partition and a solution of the spectral relaxation of a minimum normalized cut problem. Minimizing these cost functions with respect to the partition leads to new spectral clustering algorithms. Minimizing with respect to the similarity matrix leads to algorithms for learning the similarity matrix from fully labelled data sets. We apply our learning algorithm to the blind one-microphone speech separation problem, casting the problem as one of segmentation of the spectrogram. Keywords: spectral clustering, blind source separation, computational auditory scene analysis</p><p>3 0.26182917 <a title="90-lda-3" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>Author: Clayton D. Scott, Robert D. Nowak</p><p>Abstract: Given a probability measure P and a reference measure µ, one is often interested in the minimum µ-measure set with P-measure at least α. Minimum volume sets of this type summarize the regions of greatest probability mass of P, and are useful for detecting anomalies and constructing conﬁdence regions. This paper addresses the problem of estimating minimum volume sets based on independent samples distributed according to P. Other than these samples, no other information is available regarding P, but the reference measure µ is assumed to be known. We introduce rules for estimating minimum volume sets that parallel the empirical risk minimization and structural risk minimization principles in classiﬁcation. As in classiﬁcation, we show that the performances of our estimators are controlled by the rate of uniform convergence of empirical to true probabilities over the class from which the estimator is drawn. Thus we obtain ﬁnite sample size performance bounds in terms of VC dimension and related quantities. We also demonstrate strong universal consistency, an oracle inequality, and rates of convergence. The proposed estimators are illustrated with histogram and decision tree set estimation rules. Keywords: minimum volume sets, anomaly detection, statistical learning theory, uniform deviation bounds, sample complexity, universal consistency</p><p>4 0.24528004 <a title="90-lda-4" href="./jmlr-2006-Accurate_Error_Bounds_for_the_Eigenvalues_of_the_Kernel_Matrix.html">9 jmlr-2006-Accurate Error Bounds for the Eigenvalues of the Kernel Matrix</a></p>
<p>Author: Mikio L. Braun</p><p>Abstract: The eigenvalues of the kernel matrix play an important role in a number of kernel methods, in particular, in kernel principal component analysis. It is well known that the eigenvalues of the kernel matrix converge as the number of samples tends to inﬁnity. We derive probabilistic ﬁnite sample size bounds on the approximation error of individual eigenvalues which have the important property that the bounds scale with the eigenvalue under consideration, reﬂecting the actual behavior of the approximation errors as predicted by asymptotic results and observed in numerical simulations. Such scaling bounds have so far only been known for tail sums of eigenvalues. Asymptotically, the bounds presented here have a slower than stochastic rate, but the number of sample points necessary to make this disadvantage noticeable is often unrealistically large. Therefore, under practical conditions, and for all but the largest few eigenvalues, the bounds presented here form a signiﬁcant improvement over existing non-scaling bounds. Keywords: kernel matrix, eigenvalues, relative perturbation bounds</p><p>5 0.2431484 <a title="90-lda-5" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>Author: Juho Rousu, Craig Saunders, Sandor Szedmak, John Shawe-Taylor</p><p>Abstract: We present a kernel-based algorithm for hierarchical text classiﬁcation where the documents are allowed to belong to more than one category at a time. The classiﬁcation model is a variant of the Maximum Margin Markov Network framework, where the classiﬁcation hierarchy is represented as a Markov tree equipped with an exponential family deﬁned on the edges. We present an efﬁcient optimization algorithm based on incremental conditional gradient ascent in single-example subspaces spanned by the marginal dual variables. The optimization is facilitated with a dynamic programming based algorithm that computes best update directions in the feasible set. Experiments show that the algorithm can feasibly optimize training sets of thousands of examples and classiﬁcation hierarchies consisting of hundreds of nodes. Training of the full hierarchical model is as efﬁcient as training independent SVM-light classiﬁers for each node. The algorithm’s predictive accuracy was found to be competitive with other recently introduced hierarchical multicategory or multilabel classiﬁcation learning algorithms. Keywords: kernel methods, hierarchical classiﬁcation, text categorization, convex optimization, structured outputs</p><p>6 0.24201927 <a title="90-lda-6" href="./jmlr-2006-Online_Passive-Aggressive_Algorithms.html">70 jmlr-2006-Online Passive-Aggressive Algorithms</a></p>
<p>7 0.23503411 <a title="90-lda-7" href="./jmlr-2006-A_Simulation-Based_Algorithm_for_Ergodic_Control_of_Markov_Chains_Conditioned_on_Rare_Events.html">7 jmlr-2006-A Simulation-Based Algorithm for Ergodic Control of Markov Chains Conditioned on Rare Events</a></p>
<p>8 0.2339181 <a title="90-lda-8" href="./jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">28 jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<p>9 0.2333886 <a title="90-lda-9" href="./jmlr-2006-Pattern_Recognition_for__Conditionally_Independent_Data.html">73 jmlr-2006-Pattern Recognition for  Conditionally Independent Data</a></p>
<p>10 0.23237322 <a title="90-lda-10" href="./jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>11 0.23225339 <a title="90-lda-11" href="./jmlr-2006-Estimation_of_Gradients_and_Coordinate_Covariation_in_Classification.html">29 jmlr-2006-Estimation of Gradients and Coordinate Covariation in Classification</a></p>
<p>12 0.23173583 <a title="90-lda-12" href="./jmlr-2006-On_Model_Selection_Consistency_of_Lasso.html">66 jmlr-2006-On Model Selection Consistency of Lasso</a></p>
<p>13 0.23107365 <a title="90-lda-13" href="./jmlr-2006-Learning_a_Hidden_Hypergraph.html">53 jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>14 0.22917891 <a title="90-lda-14" href="./jmlr-2006-Bounds_for_the_Loss_in_Probability_of_Correct_Classification_Under_Model_Based_Approximation.html">17 jmlr-2006-Bounds for the Loss in Probability of Correct Classification Under Model Based Approximation</a></p>
<p>15 0.22844031 <a title="90-lda-15" href="./jmlr-2006-Geometric_Variance_Reduction_in_Markov_Chains%3A_Application_to_Value_Function_and_Gradient_Estimation.html">35 jmlr-2006-Geometric Variance Reduction in Markov Chains: Application to Value Function and Gradient Estimation</a></p>
<p>16 0.22737601 <a title="90-lda-16" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>17 0.22731867 <a title="90-lda-17" href="./jmlr-2006-Manifold__Regularization%3A_A_Geometric_Framework_for_Learning_from_Labeled_and_Unlabeled_Examples.html">60 jmlr-2006-Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</a></p>
<p>18 0.22713125 <a title="90-lda-18" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>19 0.22524883 <a title="90-lda-19" href="./jmlr-2006-A_Direct_Method_for_Building_Sparse_Kernel_Learning_Algorithms.html">1 jmlr-2006-A Direct Method for Building Sparse Kernel Learning Algorithms</a></p>
<p>20 0.22442642 <a title="90-lda-20" href="./jmlr-2006-Maximum-Gain_Working_Set_Selection_for_SVMs_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">61 jmlr-2006-Maximum-Gain Working Set Selection for SVMs     (Special Topic on Machine Learning and Optimization)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
