<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>62 jmlr-2006-MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-62" href="#">jmlr2006-62</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>62 jmlr-2006-MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals</h1>
<br/><p>Source: <a title="jmlr-2006-62-pdf" href="http://jmlr.org/papers/volume7/peer06a/peer06a.pdf">pdf</a></p><p>Author: Dana Pe'er, Amos Tanay, Aviv Regev</p><p>Abstract: In recent years, there has been a growing interest in applying Bayesian networks and their extensions to reconstruct regulatory networks from gene expression data. Since the gene expression domain involves a large number of variables and a limited number of samples, it poses both computational and statistical challenges to Bayesian network learning algorithms. Here we deﬁne a constrained family of Bayesian network structures suitable for this domain and devise an efﬁcient search algorithm that utilizes these structural constraints to ﬁnd high scoring networks from data. Interestingly, under reasonable assumptions on the underlying probability distribution, we can provide performance guarantees on our algorithm. Evaluation on real data from yeast and mouse, demonstrates that our method cannot only reconstruct a high quality model of the yeast regulatory network, but is also the ﬁrst method to scale to the complexity of mammalian networks and successfully reconstructs a reasonable model over thousands of variables. Keywords: Bayesian networks, structure learning, gene networks, gene expression, approximation algorithms</p><p>Reference: <a title="jmlr-2006-62-reference" href="../jmlr2006_reference/jmlr-2006-MinReg%3A_A_Scalable_Algorithm_for_Learning_Parsimonious_Regulatory_Networks_in_Yeast_and_Mammals_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('minreg', 0.583), ('reg', 0.47), ('optk', 0.256), ('yeast', 0.21), ('annot', 0.155), ('scor', 0.154), ('minregk', 0.15), ('biolog', 0.144), ('mam', 0.132), ('transcrib', 0.124), ('tanay', 0.115), ('reconstruct', 0.106), ('candid', 0.102), ('fx', 0.097), ('egev', 0.097), ('pax', 0.082), ('cel', 0.082), ('eg', 0.075), ('bayes', 0.07), ('par', 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="62-tfidf-1" href="./jmlr-2006-MinReg%3A_A_Scalable_Algorithm_for_Learning_Parsimonious_Regulatory_Networks_in_Yeast_and_Mammals.html">62 jmlr-2006-MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals</a></p>
<p>Author: Dana Pe'er, Amos Tanay, Aviv Regev</p><p>Abstract: In recent years, there has been a growing interest in applying Bayesian networks and their extensions to reconstruct regulatory networks from gene expression data. Since the gene expression domain involves a large number of variables and a limited number of samples, it poses both computational and statistical challenges to Bayesian network learning algorithms. Here we deﬁne a constrained family of Bayesian network structures suitable for this domain and devise an efﬁcient search algorithm that utilizes these structural constraints to ﬁnd high scoring networks from data. Interestingly, under reasonable assumptions on the underlying probability distribution, we can provide performance guarantees on our algorithm. Evaluation on real data from yeast and mouse, demonstrates that our method cannot only reconstruct a high quality model of the yeast regulatory network, but is also the ﬁrst method to scale to the complexity of mammalian networks and successfully reconstructs a reasonable model over thousands of variables. Keywords: Bayesian networks, structure learning, gene networks, gene expression, approximation algorithms</p><p>2 0.092245966 <a title="62-tfidf-2" href="./jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">6 jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<p>Author: Luis M. de Campos</p><p>Abstract: We propose a new scoring function for learning Bayesian networks from data using score+search algorithms. This is based on the concept of mutual information and exploits some well-known properties of this measure in a novel way. Essentially, a statistical independence test based on the chi-square distribution, associated with the mutual information measure, together with a property of additive decomposition of this measure, are combined in order to measure the degree of interaction between each variable and its parent variables in the network. The result is a non-Bayesian scoring function called MIT (mutual information tests) which belongs to the family of scores based on information theory. The MIT score also represents a penalization of the Kullback-Leibler divergence between the joint probability distributions associated with a candidate network and with the available data set. Detailed results of a complete experimental evaluation of the proposed scoring function and its comparison with the well-known K2, BDeu and BIC/MDL scores are also presented. Keywords: Bayesian networks, scoring functions, learning, mutual information, conditional independence tests</p><p>3 0.053361818 <a title="62-tfidf-3" href="./jmlr-2006-A_Robust_Procedure_For_Gaussian_Graphical_Model_Search_From_Microarray_Data_WithpLarger_Thann.html">5 jmlr-2006-A Robust Procedure For Gaussian Graphical Model Search From Microarray Data WithpLarger Thann</a></p>
<p>Author: Robert Castelo, Alberto Roverato</p><p>Abstract: Learning of large-scale networks of interactions from microarray data is an important and challenging problem in bioinformatics. A widely used approach is to assume that the available data constitute a random sample from a multivariate distribution belonging to a Gaussian graphical model. As a consequence, the prime objects of inference are full-order partial correlations which are partial correlations between two variables given the remaining ones. In the context of microarray data the number of variables exceed the sample size and this precludes the application of traditional structure learning procedures because a sampling version of full-order partial correlations does not exist. In this paper we consider limited-order partial correlations, these are partial correlations computed on marginal distributions of manageable size, and provide a set of rules that allow one to assess the usefulness of these quantities to derive the independence structure of the underlying Gaussian graphical model. Furthermore, we introduce a novel structure learning procedure based on a quantity, obtained from limited-order partial correlations, that we call the non-rejection rate. The applicability and usefulness of the procedure are demonstrated by both simulated and real data. Keywords: Gaussian distribution, gene network, graphical model, microarray data, non-rejection rate, partial correlation, small-sample inference</p><p>4 0.049267102 <a title="62-tfidf-4" href="./jmlr-2006-Bayesian_Network_Learning_with_Parameter_Constraints_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">15 jmlr-2006-Bayesian Network Learning with Parameter Constraints     (Special Topic on Machine Learning and Optimization)</a></p>
<p>Author: Radu Stefan Niculescu, Tom M. Mitchell, R. Bharat Rao</p><p>Abstract: The task of learning models for many real-world problems requires incorporating domain knowledge into learning algorithms, to enable accurate learning from a realistic volume of training data. This paper considers a variety of types of domain knowledge for constraining parameter estimates when learning Bayesian networks. In particular, we consider domain knowledge that constrains the values or relationships among subsets of parameters in a Bayesian network with known structure. We incorporate a wide variety of parameter constraints into learning procedures for Bayesian networks, by formulating this task as a constrained optimization problem. The assumptions made in module networks, dynamic Bayes nets and context speciﬁc independence models can be viewed as particular cases of such parameter constraints. We present closed form solutions or fast iterative algorithms for estimating parameters subject to several speciﬁc classes of parameter constraints, including equalities and inequalities among parameters, constraints on individual parameters, and constraints on sums and ratios of parameters, for discrete and continuous variables. Our methods cover learning from both frequentist and Bayesian points of view, from both complete and incomplete data. We present formal guarantees for our estimators, as well as methods for automatically learning useful parameter constraints from data. To validate our approach, we apply it to the domain of fMRI brain image analysis. Here we demonstrate the ability of our system to ﬁrst learn useful relationships among parameters, and then to use them to constrain the training of the Bayesian network, resulting in improved cross-validated accuracy of the learned model. Experiments on synthetic data are also presented. Keywords: Bayesian networks, constrained optimization, domain knowledge c 2006 Radu Stefan Niculescu, Tom Mitchell and Bharat Rao. N ICULESCU , M ITCHELL AND R AO</p><p>5 0.037883025 <a title="62-tfidf-5" href="./jmlr-2006-A_Hierarchy_of_Support_Vector_Machines_for_Pattern_Detection.html">3 jmlr-2006-A Hierarchy of Support Vector Machines for Pattern Detection</a></p>
<p>Author: Hichem Sahbi, Donald Geman</p><p>Abstract: We introduce a computational design for pattern detection based on a tree-structured network of support vector machines (SVMs). An SVM is associated with each cell in a recursive partitioning of the space of patterns (hypotheses) into increasingly ﬁner subsets. The hierarchy is traversed coarse-to-ﬁne and each chain of positive responses from the root to a leaf constitutes a detection. Our objective is to design and build a network which balances overall error and computation. Initially, SVMs are constructed for each cell with no constraints. This “free network” is then perturbed, cell by cell, into another network, which is “graded” in two ways: ﬁrst, the number of support vectors of each SVM is reduced (by clustering) in order to adjust to a pre-determined, increasing function of cell depth; second, the decision boundaries are shifted to preserve all positive responses from the original set of training data. The limits on the numbers of clusters (virtual support vectors) result from minimizing the mean computational cost of collecting all detections subject to a bound on the expected number of false positives. When applied to detecting faces in cluttered scenes, the patterns correspond to poses and the free network is already faster and more accurate than applying a single pose-speciﬁc SVM many times. The graded network promotes very rapid processing of background regions while maintaining the discriminatory power of the free network. Keywords: statistical learning, hierarchy of classiﬁers, coarse-to-ﬁne computation, support vector machines, face detection</p><p>6 0.037071008 <a title="62-tfidf-6" href="./jmlr-2006-Noisy-OR_Component_Analysis_and_its_Application_to_Link_Analysis.html">64 jmlr-2006-Noisy-OR Component Analysis and its Application to Link Analysis</a></p>
<p>7 0.036811516 <a title="62-tfidf-7" href="./jmlr-2006-Rearrangement_Clustering%3A_Pitfalls%2C_Remedies%2C_and_Applications.html">78 jmlr-2006-Rearrangement Clustering: Pitfalls, Remedies, and Applications</a></p>
<p>8 0.035881914 <a title="62-tfidf-8" href="./jmlr-2006-Stochastic_Complexities_of_Gaussian_Mixtures_in_Variational_Bayesian_Approximation.html">87 jmlr-2006-Stochastic Complexities of Gaussian Mixtures in Variational Bayesian Approximation</a></p>
<p>9 0.034391746 <a title="62-tfidf-9" href="./jmlr-2006-Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets.html">85 jmlr-2006-Statistical Comparisons of Classifiers over Multiple Data Sets</a></p>
<p>10 0.033716381 <a title="62-tfidf-10" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>11 0.032737289 <a title="62-tfidf-11" href="./jmlr-2006-Active_Learning_with_Feedback_on_Features_and_Instances.html">12 jmlr-2006-Active Learning with Feedback on Features and Instances</a></p>
<p>12 0.029004209 <a title="62-tfidf-12" href="./jmlr-2006-Some_Discriminant-Based_PAC_Algorithms.html">81 jmlr-2006-Some Discriminant-Based PAC Algorithms</a></p>
<p>13 0.028295878 <a title="62-tfidf-13" href="./jmlr-2006-The_Interplay_of_Optimization_and_Machine_Learning_Research_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">91 jmlr-2006-The Interplay of Optimization and Machine Learning Research     (Special Topic on Machine Learning and Optimization)</a></p>
<p>14 0.02708208 <a title="62-tfidf-14" href="./jmlr-2006-Structured_Prediction%2C_Dual_Extragradient_and_Bregman_Projections_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">89 jmlr-2006-Structured Prediction, Dual Extragradient and Bregman Projections     (Special Topic on Machine Learning and Optimization)</a></p>
<p>15 0.026054299 <a title="62-tfidf-15" href="./jmlr-2006-Incremental_Support_Vector_Learning%3A_Analysis%2C_Implementation_and_Applications_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">38 jmlr-2006-Incremental Support Vector Learning: Analysis, Implementation and Applications     (Special Topic on Machine Learning and Optimization)</a></p>
<p>16 0.025377432 <a title="62-tfidf-16" href="./jmlr-2006-Bounds_for_the_Loss_in_Probability_of_Correct_Classification_Under_Model_Based_Approximation.html">17 jmlr-2006-Bounds for the Loss in Probability of Correct Classification Under Model Based Approximation</a></p>
<p>17 0.024464738 <a title="62-tfidf-17" href="./jmlr-2006-Learning_the_Structure_of_Linear_Latent_Variable_Models.html">54 jmlr-2006-Learning the Structure of Linear Latent Variable Models</a></p>
<p>18 0.024225952 <a title="62-tfidf-18" href="./jmlr-2006-Evolutionary_Function_Approximation_for_Reinforcement_Learning.html">30 jmlr-2006-Evolutionary Function Approximation for Reinforcement Learning</a></p>
<p>19 0.024115087 <a title="62-tfidf-19" href="./jmlr-2006-Linear_Programming_Relaxations_and_Belief_Propagation_--_An_Empirical_Study_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">55 jmlr-2006-Linear Programming Relaxations and Belief Propagation -- An Empirical Study     (Special Topic on Machine Learning and Optimization)</a></p>
<p>20 0.024060126 <a title="62-tfidf-20" href="./jmlr-2006-Learning_Coordinate_Covariances_via_Gradients.html">45 jmlr-2006-Learning Coordinate Covariances via Gradients</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.127), (1, 0.065), (2, 0.107), (3, -0.021), (4, 0.035), (5, -0.077), (6, -0.027), (7, 0.118), (8, 0.031), (9, 0.124), (10, 0.023), (11, -0.089), (12, 0.084), (13, 0.009), (14, 0.059), (15, -0.13), (16, 0.004), (17, 0.006), (18, -0.035), (19, -0.02), (20, -0.053), (21, -0.174), (22, -0.101), (23, 0.064), (24, 0.007), (25, -0.056), (26, 0.187), (27, 0.045), (28, -0.088), (29, 0.081), (30, -0.089), (31, -0.116), (32, 0.035), (33, 0.084), (34, -0.28), (35, -0.046), (36, 0.131), (37, -0.106), (38, 0.038), (39, 0.269), (40, 0.065), (41, -0.227), (42, 0.197), (43, -0.297), (44, 0.057), (45, -0.257), (46, -0.068), (47, -0.181), (48, 0.074), (49, 0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97550553 <a title="62-lsi-1" href="./jmlr-2006-MinReg%3A_A_Scalable_Algorithm_for_Learning_Parsimonious_Regulatory_Networks_in_Yeast_and_Mammals.html">62 jmlr-2006-MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals</a></p>
<p>Author: Dana Pe'er, Amos Tanay, Aviv Regev</p><p>Abstract: In recent years, there has been a growing interest in applying Bayesian networks and their extensions to reconstruct regulatory networks from gene expression data. Since the gene expression domain involves a large number of variables and a limited number of samples, it poses both computational and statistical challenges to Bayesian network learning algorithms. Here we deﬁne a constrained family of Bayesian network structures suitable for this domain and devise an efﬁcient search algorithm that utilizes these structural constraints to ﬁnd high scoring networks from data. Interestingly, under reasonable assumptions on the underlying probability distribution, we can provide performance guarantees on our algorithm. Evaluation on real data from yeast and mouse, demonstrates that our method cannot only reconstruct a high quality model of the yeast regulatory network, but is also the ﬁrst method to scale to the complexity of mammalian networks and successfully reconstructs a reasonable model over thousands of variables. Keywords: Bayesian networks, structure learning, gene networks, gene expression, approximation algorithms</p><p>2 0.43923157 <a title="62-lsi-2" href="./jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">6 jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<p>Author: Luis M. de Campos</p><p>Abstract: We propose a new scoring function for learning Bayesian networks from data using score+search algorithms. This is based on the concept of mutual information and exploits some well-known properties of this measure in a novel way. Essentially, a statistical independence test based on the chi-square distribution, associated with the mutual information measure, together with a property of additive decomposition of this measure, are combined in order to measure the degree of interaction between each variable and its parent variables in the network. The result is a non-Bayesian scoring function called MIT (mutual information tests) which belongs to the family of scores based on information theory. The MIT score also represents a penalization of the Kullback-Leibler divergence between the joint probability distributions associated with a candidate network and with the available data set. Detailed results of a complete experimental evaluation of the proposed scoring function and its comparison with the well-known K2, BDeu and BIC/MDL scores are also presented. Keywords: Bayesian networks, scoring functions, learning, mutual information, conditional independence tests</p><p>3 0.2349643 <a title="62-lsi-3" href="./jmlr-2006-Rearrangement_Clustering%3A_Pitfalls%2C_Remedies%2C_and_Applications.html">78 jmlr-2006-Rearrangement Clustering: Pitfalls, Remedies, and Applications</a></p>
<p>Author: Sharlee Climer, Weixiong Zhang</p><p>Abstract: Given a matrix of values in which the rows correspond to objects and the columns correspond to features of the objects, rearrangement clustering is the problem of rearranging the rows of the matrix such that the sum of the similarities between adjacent rows is maximized. Referred to by various names and reinvented several times, this clustering technique has been extensively used in many ﬁelds over the last three decades. In this paper, we point out two critical pitfalls that have been previously overlooked. The ﬁrst pitfall is deleterious when rearrangement clustering is applied to objects that form natural clusters. The second concerns a similarity metric that is commonly used. We present an algorithm that overcomes these pitfalls. This algorithm is based on a variation of the Traveling Salesman Problem. It offers an extra beneﬁt as it automatically determines cluster boundaries. Using this algorithm, we optimally solve four benchmark problems and a 2,467-gene expression data clustering problem. As expected, our new algorithm identiﬁes better clusters than those found by previous approaches in all ﬁve cases. Overall, our results demonstrate the beneﬁts of rectifying the pitfalls and exemplify the usefulness of this clustering technique. Our code is available at our websites. Keywords: clustering, visualization of patterns in data, bond energy algorithm, traveling salesman problem, asymmetric clustering</p><p>4 0.2183985 <a title="62-lsi-4" href="./jmlr-2006-Bayesian_Network_Learning_with_Parameter_Constraints_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">15 jmlr-2006-Bayesian Network Learning with Parameter Constraints     (Special Topic on Machine Learning and Optimization)</a></p>
<p>Author: Radu Stefan Niculescu, Tom M. Mitchell, R. Bharat Rao</p><p>Abstract: The task of learning models for many real-world problems requires incorporating domain knowledge into learning algorithms, to enable accurate learning from a realistic volume of training data. This paper considers a variety of types of domain knowledge for constraining parameter estimates when learning Bayesian networks. In particular, we consider domain knowledge that constrains the values or relationships among subsets of parameters in a Bayesian network with known structure. We incorporate a wide variety of parameter constraints into learning procedures for Bayesian networks, by formulating this task as a constrained optimization problem. The assumptions made in module networks, dynamic Bayes nets and context speciﬁc independence models can be viewed as particular cases of such parameter constraints. We present closed form solutions or fast iterative algorithms for estimating parameters subject to several speciﬁc classes of parameter constraints, including equalities and inequalities among parameters, constraints on individual parameters, and constraints on sums and ratios of parameters, for discrete and continuous variables. Our methods cover learning from both frequentist and Bayesian points of view, from both complete and incomplete data. We present formal guarantees for our estimators, as well as methods for automatically learning useful parameter constraints from data. To validate our approach, we apply it to the domain of fMRI brain image analysis. Here we demonstrate the ability of our system to ﬁrst learn useful relationships among parameters, and then to use them to constrain the training of the Bayesian network, resulting in improved cross-validated accuracy of the learned model. Experiments on synthetic data are also presented. Keywords: Bayesian networks, constrained optimization, domain knowledge c 2006 Radu Stefan Niculescu, Tom Mitchell and Bharat Rao. N ICULESCU , M ITCHELL AND R AO</p><p>5 0.20928976 <a title="62-lsi-5" href="./jmlr-2006-Evolutionary_Function_Approximation_for_Reinforcement_Learning.html">30 jmlr-2006-Evolutionary Function Approximation for Reinforcement Learning</a></p>
<p>Author: Shimon Whiteson, Peter Stone</p><p>Abstract: Temporal difference methods are theoretically grounded and empirically effective methods for addressing reinforcement learning problems. In most real-world reinforcement learning tasks, TD methods require a function approximator to represent the value function. However, using function approximators requires manually making crucial representational decisions. This paper investigates evolutionary function approximation, a novel approach to automatically selecting function approximator representations that enable efﬁcient individual learning. This method evolves individuals that are better able to learn. We present a fully implemented instantiation of evolutionary function approximation which combines NEAT, a neuroevolutionary optimization technique, with Q-learning, a popular TD method. The resulting NEAT+Q algorithm automatically discovers effective representations for neural network function approximators. This paper also presents on-line evolutionary computation, which improves the on-line performance of evolutionary computation by borrowing selection mechanisms used in TD methods to choose individual actions and using them in evolutionary computation to select policies for evaluation. We evaluate these contributions with extended empirical studies in two domains: 1) the mountain car task, a standard reinforcement learning benchmark on which neural network function approximators have previously performed poorly and 2) server job scheduling, a large probabilistic domain drawn from the ﬁeld of autonomic computing. The results demonstrate that evolutionary function approximation can signiﬁcantly improve the performance of TD methods and on-line evolutionary computation can signiﬁcantly improve evolutionary methods. This paper also presents additional tests that offer insight into what factors can make neural network function approximation difﬁcult in practice. Keywords: reinforcement learning, temporal difference methods, evolutionary computation, neuroevolution, on-</p><p>6 0.19660175 <a title="62-lsi-6" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>7 0.1958341 <a title="62-lsi-7" href="./jmlr-2006-A_Hierarchy_of_Support_Vector_Machines_for_Pattern_Detection.html">3 jmlr-2006-A Hierarchy of Support Vector Machines for Pattern Detection</a></p>
<p>8 0.19326819 <a title="62-lsi-8" href="./jmlr-2006-Incremental_Support_Vector_Learning%3A_Analysis%2C_Implementation_and_Applications_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">38 jmlr-2006-Incremental Support Vector Learning: Analysis, Implementation and Applications     (Special Topic on Machine Learning and Optimization)</a></p>
<p>9 0.17269734 <a title="62-lsi-9" href="./jmlr-2006-A_Robust_Procedure_For_Gaussian_Graphical_Model_Search_From_Microarray_Data_WithpLarger_Thann.html">5 jmlr-2006-A Robust Procedure For Gaussian Graphical Model Search From Microarray Data WithpLarger Thann</a></p>
<p>10 0.1717708 <a title="62-lsi-10" href="./jmlr-2006-Noisy-OR_Component_Analysis_and_its_Application_to_Link_Analysis.html">64 jmlr-2006-Noisy-OR Component Analysis and its Application to Link Analysis</a></p>
<p>11 0.16036934 <a title="62-lsi-11" href="./jmlr-2006-Maximum-Gain_Working_Set_Selection_for_SVMs_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">61 jmlr-2006-Maximum-Gain Working Set Selection for SVMs     (Special Topic on Machine Learning and Optimization)</a></p>
<p>12 0.15637413 <a title="62-lsi-12" href="./jmlr-2006-Active_Learning_with_Feedback_on_Features_and_Instances.html">12 jmlr-2006-Active Learning with Feedback on Features and Instances</a></p>
<p>13 0.15445563 <a title="62-lsi-13" href="./jmlr-2006-Segmental_Hidden_Markov_Models_with_Random_Effects_for_Waveform_Modeling.html">80 jmlr-2006-Segmental Hidden Markov Models with Random Effects for Waveform Modeling</a></p>
<p>14 0.1543856 <a title="62-lsi-14" href="./jmlr-2006-Distance_Patterns_in_Structural_Similarity.html">25 jmlr-2006-Distance Patterns in Structural Similarity</a></p>
<p>15 0.14998448 <a title="62-lsi-15" href="./jmlr-2006-Structured_Prediction%2C_Dual_Extragradient_and_Bregman_Projections_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">89 jmlr-2006-Structured Prediction, Dual Extragradient and Bregman Projections     (Special Topic on Machine Learning and Optimization)</a></p>
<p>16 0.14652777 <a title="62-lsi-16" href="./jmlr-2006-Some_Discriminant-Based_PAC_Algorithms.html">81 jmlr-2006-Some Discriminant-Based PAC Algorithms</a></p>
<p>17 0.14130183 <a title="62-lsi-17" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>18 0.13449222 <a title="62-lsi-18" href="./jmlr-2006-Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets.html">85 jmlr-2006-Statistical Comparisons of Classifiers over Multiple Data Sets</a></p>
<p>19 0.12544104 <a title="62-lsi-19" href="./jmlr-2006-Linear_Programming_Relaxations_and_Belief_Propagation_--_An_Empirical_Study_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">55 jmlr-2006-Linear Programming Relaxations and Belief Propagation -- An Empirical Study     (Special Topic on Machine Learning and Optimization)</a></p>
<p>20 0.12123721 <a title="62-lsi-20" href="./jmlr-2006-Using_Machine_Learning_to_Guide_Architecture_Simulation.html">94 jmlr-2006-Using Machine Learning to Guide Architecture Simulation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(31, 0.055), (33, 0.024), (48, 0.433), (51, 0.023), (56, 0.014), (63, 0.055), (72, 0.038), (73, 0.063), (77, 0.068), (78, 0.057), (88, 0.029), (99, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72989833 <a title="62-lda-1" href="./jmlr-2006-MinReg%3A_A_Scalable_Algorithm_for_Learning_Parsimonious_Regulatory_Networks_in_Yeast_and_Mammals.html">62 jmlr-2006-MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals</a></p>
<p>Author: Dana Pe'er, Amos Tanay, Aviv Regev</p><p>Abstract: In recent years, there has been a growing interest in applying Bayesian networks and their extensions to reconstruct regulatory networks from gene expression data. Since the gene expression domain involves a large number of variables and a limited number of samples, it poses both computational and statistical challenges to Bayesian network learning algorithms. Here we deﬁne a constrained family of Bayesian network structures suitable for this domain and devise an efﬁcient search algorithm that utilizes these structural constraints to ﬁnd high scoring networks from data. Interestingly, under reasonable assumptions on the underlying probability distribution, we can provide performance guarantees on our algorithm. Evaluation on real data from yeast and mouse, demonstrates that our method cannot only reconstruct a high quality model of the yeast regulatory network, but is also the ﬁrst method to scale to the complexity of mammalian networks and successfully reconstructs a reasonable model over thousands of variables. Keywords: Bayesian networks, structure learning, gene networks, gene expression, approximation algorithms</p><p>2 0.30333623 <a title="62-lda-2" href="./jmlr-2006-Collaborative_Multiagent_Reinforcement_Learning_by_Payoff_Propagation.html">20 jmlr-2006-Collaborative Multiagent Reinforcement Learning by Payoff Propagation</a></p>
<p>Author: Jelle R. Kok, Nikos Vlassis</p><p>Abstract: In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efﬁcient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences. Keywords: collaborative multiagent system, coordination graph, reinforcement learning, Qlearning, belief propagation</p><p>3 0.297885 <a title="62-lda-3" href="./jmlr-2006-A_Graphical_Representation_of_Equivalence_Classes_of_AMP_Chain_Graphs.html">2 jmlr-2006-A Graphical Representation of Equivalence Classes of AMP Chain Graphs</a></p>
<p>Author: Alberto Roverato, Milan Studený</p><p>Abstract: This paper deals with chain graph models under alternative AMP interpretation. A new representative of an AMP Markov equivalence class, called the largest deﬂagged graph, is proposed. The representative is based on revealed internal structure of the AMP Markov equivalence class. More speciﬁcally, the AMP Markov equivalence class decomposes into ﬁner strong equivalence classes and there exists a distinguished strong equivalence class among those forming the AMP Markov equivalence class. The largest deﬂagged graph is the largest chain graph in that distinguished strong equivalence class. A composed graphical procedure to get the largest deﬂagged graph on the basis of any AMP Markov equivalent chain graph is presented. In general, the largest deﬂagged graph differs from the AMP essential graph, which is another representative of the AMP Markov equivalence class. Keywords: chain graph, AMP Markov equivalence, strong equivalence, largest deﬂagged graph, component merging procedure, deﬂagging procedure, essential graph</p><p>4 0.2970632 <a title="62-lda-4" href="./jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>Author: Dmitry M. Malioutov, Jason K. Johnson, Alan S. Willsky</p><p>Abstract: We present a new framework based on walks in a graph for analysis and inference in Gaussian graphical models. The key idea is to decompose the correlation between each pair of variables as a sum over all walks between those variables in the graph. The weight of each walk is given by a product of edgewise partial correlation coefﬁcients. This representation holds for a large class of Gaussian graphical models which we call walk-summable. We give a precise characterization of this class of models, and relate it to other classes including diagonally dominant, attractive, nonfrustrated, and pairwise-normalizable. We provide a walk-sum interpretation of Gaussian belief propagation in trees and of the approximate method of loopy belief propagation in graphs with cycles. The walk-sum perspective leads to a better understanding of Gaussian belief propagation and to stronger results for its convergence in loopy graphs. Keywords: Gaussian graphical models, walk-sum analysis, convergence of loopy belief propagation</p><p>5 0.29621312 <a title="62-lda-5" href="./jmlr-2006-Learning_a_Hidden_Hypergraph.html">53 jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>Author: Dana Angluin, Jiang Chen</p><p>Abstract: We consider the problem of learning a hypergraph using edge-detecting queries. In this model, the learner may query whether a set of vertices induces an edge of the hidden hypergraph or not. We show that an r-uniform hypergraph with m edges and n vertices is learnable with O(2 4r m · poly(r, log n)) queries with high probability. The queries can be made in O(min(2 r (log m + r)2 , (log m + r)3 )) rounds. We also give an algorithm that learns an almost uniform hypergraph of ∆ ∆ dimension r using O(2O((1+ 2 )r) · m1+ 2 · poly(log n)) queries with high probability, where ∆ is the difference between the maximum and the minimum edge sizes. This upper bound matches our ∆ lower bound of Ω(( m∆ )1+ 2 ) for this class of hypergraphs in terms of dependence on m. The 1+ 2 queries can also be made in O((1 + ∆) · min(2r (log m + r)2 , (log m + r)3 )) rounds. Keywords: query learning, hypergraph, multiple round algorithm, sampling, chemical reaction network</p><p>6 0.29259643 <a title="62-lda-6" href="./jmlr-2006-Kernels_on_Prolog_Proof_Trees%3A_Statistical_Learning_in_the_ILP_Setting_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">42 jmlr-2006-Kernels on Prolog Proof Trees: Statistical Learning in the ILP Setting     (Special Topic on Inductive Programming)</a></p>
<p>7 0.29060385 <a title="62-lda-7" href="./jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">6 jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<p>8 0.29012075 <a title="62-lda-8" href="./jmlr-2006-Step_Size_Adaptation_in_Reproducing_Kernel_Hilbert_Space.html">86 jmlr-2006-Step Size Adaptation in Reproducing Kernel Hilbert Space</a></p>
<p>9 0.28947523 <a title="62-lda-9" href="./jmlr-2006-A_Hierarchy_of_Support_Vector_Machines_for_Pattern_Detection.html">3 jmlr-2006-A Hierarchy of Support Vector Machines for Pattern Detection</a></p>
<p>10 0.28815916 <a title="62-lda-10" href="./jmlr-2006-Considering_Cost_Asymmetry_in_Learning_Classifiers.html">22 jmlr-2006-Considering Cost Asymmetry in Learning Classifiers</a></p>
<p>11 0.28568491 <a title="62-lda-11" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>12 0.28473404 <a title="62-lda-12" href="./jmlr-2006-Streamwise_Feature_Selection.html">88 jmlr-2006-Streamwise Feature Selection</a></p>
<p>13 0.2842131 <a title="62-lda-13" href="./jmlr-2006-In_Search_of_Non-Gaussian_Components_of_a_High-Dimensional_Distribution.html">36 jmlr-2006-In Search of Non-Gaussian Components of a High-Dimensional Distribution</a></p>
<p>14 0.28356925 <a title="62-lda-14" href="./jmlr-2006-Learning_Parts-Based_Representations_of_Data.html">49 jmlr-2006-Learning Parts-Based Representations of Data</a></p>
<p>15 0.28348982 <a title="62-lda-15" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>16 0.28213301 <a title="62-lda-16" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>17 0.28169852 <a title="62-lda-17" href="./jmlr-2006-Consistency_and_Convergence_Rates_of_One-Class_SVMs_and_Related_Algorithms.html">23 jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</a></p>
<p>18 0.28147322 <a title="62-lda-18" href="./jmlr-2006-Using_Machine_Learning_to_Guide_Architecture_Simulation.html">94 jmlr-2006-Using Machine Learning to Guide Architecture Simulation</a></p>
<p>19 0.28143522 <a title="62-lda-19" href="./jmlr-2006-Point-Based_Value_Iteration_for_Continuous_POMDPs.html">74 jmlr-2006-Point-Based Value Iteration for Continuous POMDPs</a></p>
<p>20 0.28107834 <a title="62-lda-20" href="./jmlr-2006-Large_Scale_Multiple_Kernel_Learning_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">43 jmlr-2006-Large Scale Multiple Kernel Learning     (Special Topic on Machine Learning and Optimization)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
