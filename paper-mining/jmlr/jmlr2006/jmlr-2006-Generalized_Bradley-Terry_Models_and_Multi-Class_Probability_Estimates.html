<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-34" href="#">jmlr2006-34</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</h1>
<br/><p>Source: <a title="jmlr-2006-34-pdf" href="http://jmlr.org/papers/volume7/huang06a/huang06a.pdf">pdf</a></p><p>Author: Tzu-Kuo Huang, Ruby C. Weng, Chih-Jen Lin</p><p>Abstract: The Bradley-Terry model for obtaining individual skill from paired comparisons has been popular in many areas. In machine learning, this model is related to multi-class probability estimates by coupling all pairwise classiﬁcation results. Error correcting output codes (ECOC) are a general framework to decompose a multi-class problem to several binary problems. To obtain probability estimates under this framework, this paper introduces a generalized Bradley-Terry model in which paired individual comparisons are extended to paired team comparisons. We propose a simple algorithm with convergence proofs to solve the model and obtain individual skill. Experiments on synthetic and real data demonstrate that the algorithm is useful for obtaining multi-class probability estimates. Moreover, we discuss four extensions of the proposed model: 1) weighted individual skill, 2) home-ﬁeld advantage, 3) ties, and 4) comparisons with more than two teams. Keywords: Bradley-Terry model, probability estimates, error correcting output codes, support vector machines</p><p>Reference: <a title="jmlr-2006-34-reference" href="../jmlr2006_reference/jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('qi', 0.596), ('pt', 0.412), ('ps', 0.381), ('ri', 0.358), ('pj', 0.173), ('ii', 0.153), ('weng', 0.103), ('ij', 0.097), ('beat', 0.095), ('huang', 0.085), ('team', 0.084), ('mse', 0.084), ('satim', 0.078), ('ecoc', 0.074), ('pi', 0.073), ('ti', 0.068), ('gam', 0.061), ('rs', 0.056), ('rij', 0.055), ('dna', 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="34-tfidf-1" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>Author: Tzu-Kuo Huang, Ruby C. Weng, Chih-Jen Lin</p><p>Abstract: The Bradley-Terry model for obtaining individual skill from paired comparisons has been popular in many areas. In machine learning, this model is related to multi-class probability estimates by coupling all pairwise classiﬁcation results. Error correcting output codes (ECOC) are a general framework to decompose a multi-class problem to several binary problems. To obtain probability estimates under this framework, this paper introduces a generalized Bradley-Terry model in which paired individual comparisons are extended to paired team comparisons. We propose a simple algorithm with convergence proofs to solve the model and obtain individual skill. Experiments on synthetic and real data demonstrate that the algorithm is useful for obtaining multi-class probability estimates. Moreover, we discuss four extensions of the proposed model: 1) weighted individual skill, 2) home-ﬁeld advantage, 3) ties, and 4) comparisons with more than two teams. Keywords: Bradley-Terry model, probability estimates, error correcting output codes, support vector machines</p><p>2 0.16308732 <a title="34-tfidf-2" href="./jmlr-2006-Consistency_of_Multiclass_Empirical_Risk_Minimization_Methods_Based_on_Convex_Loss.html">24 jmlr-2006-Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss</a></p>
<p>Author: Di-Rong Chen, Tao Sun</p><p>Abstract: The consistency of classiﬁcation algorithm plays a central role in statistical learning theory. A consistent algorithm guarantees us that taking more samples essentially sufﬁces to roughly reconstruct the unknown distribution. We consider the consistency of ERM scheme over classes of combinations of very simple rules (base classiﬁers) in multiclass classiﬁcation. Our approach is, under some mild conditions, to establish a quantitative relationship between classiﬁcation errors and convex risks. In comparison with the related previous work, the feature of our result is that the conditions are mainly expressed in terms of the differences between some values of the convex function. Keywords: multiclass classiﬁcation, classiﬁer, consistency, empirical risk minimization, constrained comparison method, Tsybakov noise condition</p><p>3 0.12062329 <a title="34-tfidf-3" href="./jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">6 jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<p>Author: Luis M. de Campos</p><p>Abstract: We propose a new scoring function for learning Bayesian networks from data using score+search algorithms. This is based on the concept of mutual information and exploits some well-known properties of this measure in a novel way. Essentially, a statistical independence test based on the chi-square distribution, associated with the mutual information measure, together with a property of additive decomposition of this measure, are combined in order to measure the degree of interaction between each variable and its parent variables in the network. The result is a non-Bayesian scoring function called MIT (mutual information tests) which belongs to the family of scores based on information theory. The MIT score also represents a penalization of the Kullback-Leibler divergence between the joint probability distributions associated with a candidate network and with the available data set. Detailed results of a complete experimental evaluation of the proposed scoring function and its comparison with the well-known K2, BDeu and BIC/MDL scores are also presented. Keywords: Bayesian networks, scoring functions, learning, mutual information, conditional independence tests</p><p>4 0.11149155 <a title="34-tfidf-4" href="./jmlr-2006-Worst-Case_Analysis_of_Selective_Sampling_for_Linear_Classification.html">96 jmlr-2006-Worst-Case Analysis of Selective Sampling for Linear Classification</a></p>
<p>Author: Nicolò Cesa-Bianchi, Claudio Gentile, Luca Zaniboni</p><p>Abstract: A selective sampling algorithm is a learning algorithm for classiﬁcation that, based on the past observed data, decides whether to ask the label of each new instance to be classiﬁed. In this paper, we introduce a general technique for turning linear-threshold classiﬁcation algorithms from the general additive family into randomized selective sampling algorithms. For the most popular algorithms in this family we derive mistake bounds that hold for individual sequences of examples. These bounds show that our semi-supervised algorithms can achieve, on average, the same accuracy as that of their fully supervised counterparts, but using fewer labels. Our theoretical results are corroborated by a number of experiments on real-world textual data. The outcome of these experiments is essentially predicted by our theoretical results: Our selective sampling algorithms tend to perform as well as the algorithms receiving the true label after each classiﬁcation, while observing in practice substantially fewer labels. Keywords: selective sampling, semi-supervised learning, on-line learning, kernel algorithms, linear-threshold classiﬁers</p><p>5 0.10490885 <a title="34-tfidf-5" href="./jmlr-2006-Collaborative_Multiagent_Reinforcement_Learning_by_Payoff_Propagation.html">20 jmlr-2006-Collaborative Multiagent Reinforcement Learning by Payoff Propagation</a></p>
<p>Author: Jelle R. Kok, Nikos Vlassis</p><p>Abstract: In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efﬁcient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences. Keywords: collaborative multiagent system, coordination graph, reinforcement learning, Qlearning, belief propagation</p><p>6 0.0930935 <a title="34-tfidf-6" href="./jmlr-2006-A_Robust_Procedure_For_Gaussian_Graphical_Model_Search_From_Microarray_Data_WithpLarger_Thann.html">5 jmlr-2006-A Robust Procedure For Gaussian Graphical Model Search From Microarray Data WithpLarger Thann</a></p>
<p>7 0.08181566 <a title="34-tfidf-7" href="./jmlr-2006-Linear_Programming_Relaxations_and_Belief_Propagation_--_An_Empirical_Study_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">55 jmlr-2006-Linear Programming Relaxations and Belief Propagation -- An Empirical Study     (Special Topic on Machine Learning and Optimization)</a></p>
<p>8 0.073556751 <a title="34-tfidf-8" href="./jmlr-2006-Superior_Guarantees_for_Sequential_Prediction_and_Lossless_Compression_via_Alphabet_Decomposition.html">90 jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</a></p>
<p>9 0.068520777 <a title="34-tfidf-9" href="./jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>10 0.055883702 <a title="34-tfidf-10" href="./jmlr-2006-Segmental_Hidden_Markov_Models_with_Random_Effects_for_Waveform_Modeling.html">80 jmlr-2006-Segmental Hidden Markov Models with Random Effects for Waveform Modeling</a></p>
<p>11 0.049931135 <a title="34-tfidf-11" href="./jmlr-2006-Infinite-%CF%83_Limits_For_Tikhonov_Regularization.html">40 jmlr-2006-Infinite-σ Limits For Tikhonov Regularization</a></p>
<p>12 0.041645888 <a title="34-tfidf-12" href="./jmlr-2006-Toward_Attribute_Efficient_Learning_of_Decision_Lists_and_Parities.html">92 jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</a></p>
<p>13 0.038353451 <a title="34-tfidf-13" href="./jmlr-2006-A_Very_Fast_Learning_Method_for_Neural_Networks_Based_on_Sensitivity_Analysis.html">8 jmlr-2006-A Very Fast Learning Method for Neural Networks Based on Sensitivity Analysis</a></p>
<p>14 0.035654925 <a title="34-tfidf-14" href="./jmlr-2006-Learning_Recursive_Control_Programs_from_Problem_Solving_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">50 jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</a></p>
<p>15 0.033433903 <a title="34-tfidf-15" href="./jmlr-2006-A_Simulation-Based_Algorithm_for_Ergodic_Control_of_Markov_Chains_Conditioned_on_Rare_Events.html">7 jmlr-2006-A Simulation-Based Algorithm for Ergodic Control of Markov Chains Conditioned on Rare Events</a></p>
<p>16 0.033280525 <a title="34-tfidf-16" href="./jmlr-2006-New_Algorithms_for_Efficient_High-Dimensional_Nonparametric_Classification.html">63 jmlr-2006-New Algorithms for Efficient High-Dimensional Nonparametric Classification</a></p>
<p>17 0.032167796 <a title="34-tfidf-17" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>18 0.028364301 <a title="34-tfidf-18" href="./jmlr-2006-QP_Algorithms_with_Guaranteed_Accuracy_and_Run_Time_for_Support_Vector_Machines.html">76 jmlr-2006-QP Algorithms with Guaranteed Accuracy and Run Time for Support Vector Machines</a></p>
<p>19 0.025740806 <a title="34-tfidf-19" href="./jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">28 jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<p>20 0.025246827 <a title="34-tfidf-20" href="./jmlr-2006-Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets.html">85 jmlr-2006-Statistical Comparisons of Classifiers over Multiple Data Sets</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.164), (1, -0.036), (2, 0.15), (3, 0.039), (4, 0.138), (5, 0.127), (6, -0.162), (7, 0.007), (8, -0.068), (9, 0.357), (10, 0.003), (11, 0.276), (12, 0.196), (13, -0.228), (14, -0.008), (15, 0.139), (16, 0.037), (17, -0.058), (18, 0.253), (19, 0.124), (20, 0.096), (21, 0.158), (22, -0.059), (23, 0.089), (24, -0.026), (25, 0.013), (26, 0.05), (27, -0.055), (28, -0.05), (29, -0.011), (30, -0.022), (31, 0.006), (32, 0.022), (33, -0.07), (34, 0.017), (35, -0.068), (36, -0.058), (37, 0.021), (38, -0.021), (39, 0.019), (40, 0.096), (41, 0.041), (42, -0.049), (43, 0.027), (44, 0.079), (45, -0.016), (46, -0.078), (47, -0.072), (48, -0.035), (49, -0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97890306 <a title="34-lsi-1" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>Author: Tzu-Kuo Huang, Ruby C. Weng, Chih-Jen Lin</p><p>Abstract: The Bradley-Terry model for obtaining individual skill from paired comparisons has been popular in many areas. In machine learning, this model is related to multi-class probability estimates by coupling all pairwise classiﬁcation results. Error correcting output codes (ECOC) are a general framework to decompose a multi-class problem to several binary problems. To obtain probability estimates under this framework, this paper introduces a generalized Bradley-Terry model in which paired individual comparisons are extended to paired team comparisons. We propose a simple algorithm with convergence proofs to solve the model and obtain individual skill. Experiments on synthetic and real data demonstrate that the algorithm is useful for obtaining multi-class probability estimates. Moreover, we discuss four extensions of the proposed model: 1) weighted individual skill, 2) home-ﬁeld advantage, 3) ties, and 4) comparisons with more than two teams. Keywords: Bradley-Terry model, probability estimates, error correcting output codes, support vector machines</p><p>2 0.62536687 <a title="34-lsi-2" href="./jmlr-2006-Consistency_of_Multiclass_Empirical_Risk_Minimization_Methods_Based_on_Convex_Loss.html">24 jmlr-2006-Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss</a></p>
<p>Author: Di-Rong Chen, Tao Sun</p><p>Abstract: The consistency of classiﬁcation algorithm plays a central role in statistical learning theory. A consistent algorithm guarantees us that taking more samples essentially sufﬁces to roughly reconstruct the unknown distribution. We consider the consistency of ERM scheme over classes of combinations of very simple rules (base classiﬁers) in multiclass classiﬁcation. Our approach is, under some mild conditions, to establish a quantitative relationship between classiﬁcation errors and convex risks. In comparison with the related previous work, the feature of our result is that the conditions are mainly expressed in terms of the differences between some values of the convex function. Keywords: multiclass classiﬁcation, classiﬁer, consistency, empirical risk minimization, constrained comparison method, Tsybakov noise condition</p><p>3 0.38812554 <a title="34-lsi-3" href="./jmlr-2006-Linear_Programming_Relaxations_and_Belief_Propagation_--_An_Empirical_Study_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">55 jmlr-2006-Linear Programming Relaxations and Belief Propagation -- An Empirical Study     (Special Topic on Machine Learning and Optimization)</a></p>
<p>Author: Chen Yanover, Talya Meltzer, Yair Weiss</p><p>Abstract: The problem of ﬁnding the most probable (MAP) conﬁguration in graphical models comes up in a wide range of applications. In a general graphical model this problem is NP hard, but various approximate algorithms have been developed. Linear programming (LP) relaxations are a standard method in computer science for approximating combinatorial problems and have been used for ﬁnding the most probable assignment in small graphical models. However, applying this powerful method to real-world problems is extremely challenging due to the large numbers of variables and constraints in the linear program. Tree-Reweighted Belief Propagation is a promising recent algorithm for solving LP relaxations, but little is known about its running time on large problems. In this paper we compare tree-reweighted belief propagation (TRBP) and powerful generalpurpose LP solvers (CPLEX) on relaxations of real-world graphical models from the ﬁelds of computer vision and computational biology. We ﬁnd that TRBP almost always ﬁnds the solution signiﬁcantly faster than all the solvers in CPLEX and more importantly, TRBP can be applied to large scale problems for which the solvers in CPLEX cannot be applied. Using TRBP we can ﬁnd the MAP conﬁgurations in a matter of minutes for a large range of real world problems.</p><p>4 0.37355062 <a title="34-lsi-4" href="./jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">6 jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<p>Author: Luis M. de Campos</p><p>Abstract: We propose a new scoring function for learning Bayesian networks from data using score+search algorithms. This is based on the concept of mutual information and exploits some well-known properties of this measure in a novel way. Essentially, a statistical independence test based on the chi-square distribution, associated with the mutual information measure, together with a property of additive decomposition of this measure, are combined in order to measure the degree of interaction between each variable and its parent variables in the network. The result is a non-Bayesian scoring function called MIT (mutual information tests) which belongs to the family of scores based on information theory. The MIT score also represents a penalization of the Kullback-Leibler divergence between the joint probability distributions associated with a candidate network and with the available data set. Detailed results of a complete experimental evaluation of the proposed scoring function and its comparison with the well-known K2, BDeu and BIC/MDL scores are also presented. Keywords: Bayesian networks, scoring functions, learning, mutual information, conditional independence tests</p><p>5 0.29883516 <a title="34-lsi-5" href="./jmlr-2006-Collaborative_Multiagent_Reinforcement_Learning_by_Payoff_Propagation.html">20 jmlr-2006-Collaborative Multiagent Reinforcement Learning by Payoff Propagation</a></p>
<p>Author: Jelle R. Kok, Nikos Vlassis</p><p>Abstract: In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efﬁcient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences. Keywords: collaborative multiagent system, coordination graph, reinforcement learning, Qlearning, belief propagation</p><p>6 0.27069482 <a title="34-lsi-6" href="./jmlr-2006-Superior_Guarantees_for_Sequential_Prediction_and_Lossless_Compression_via_Alphabet_Decomposition.html">90 jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</a></p>
<p>7 0.2556428 <a title="34-lsi-7" href="./jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>8 0.24921726 <a title="34-lsi-8" href="./jmlr-2006-Segmental_Hidden_Markov_Models_with_Random_Effects_for_Waveform_Modeling.html">80 jmlr-2006-Segmental Hidden Markov Models with Random Effects for Waveform Modeling</a></p>
<p>9 0.21117844 <a title="34-lsi-9" href="./jmlr-2006-Infinite-%CF%83_Limits_For_Tikhonov_Regularization.html">40 jmlr-2006-Infinite-σ Limits For Tikhonov Regularization</a></p>
<p>10 0.19314949 <a title="34-lsi-10" href="./jmlr-2006-Worst-Case_Analysis_of_Selective_Sampling_for_Linear_Classification.html">96 jmlr-2006-Worst-Case Analysis of Selective Sampling for Linear Classification</a></p>
<p>11 0.17527418 <a title="34-lsi-11" href="./jmlr-2006-A_Robust_Procedure_For_Gaussian_Graphical_Model_Search_From_Microarray_Data_WithpLarger_Thann.html">5 jmlr-2006-A Robust Procedure For Gaussian Graphical Model Search From Microarray Data WithpLarger Thann</a></p>
<p>12 0.16549133 <a title="34-lsi-12" href="./jmlr-2006-A_Very_Fast_Learning_Method_for_Neural_Networks_Based_on_Sensitivity_Analysis.html">8 jmlr-2006-A Very Fast Learning Method for Neural Networks Based on Sensitivity Analysis</a></p>
<p>13 0.16451581 <a title="34-lsi-13" href="./jmlr-2006-New_Algorithms_for_Efficient_High-Dimensional_Nonparametric_Classification.html">63 jmlr-2006-New Algorithms for Efficient High-Dimensional Nonparametric Classification</a></p>
<p>14 0.15731397 <a title="34-lsi-14" href="./jmlr-2006-Toward_Attribute_Efficient_Learning_of_Decision_Lists_and_Parities.html">92 jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</a></p>
<p>15 0.15119791 <a title="34-lsi-15" href="./jmlr-2006-A_Direct_Method_for_Building_Sparse_Kernel_Learning_Algorithms.html">1 jmlr-2006-A Direct Method for Building Sparse Kernel Learning Algorithms</a></p>
<p>16 0.14619134 <a title="34-lsi-16" href="./jmlr-2006-A_Simulation-Based_Algorithm_for_Ergodic_Control_of_Markov_Chains_Conditioned_on_Rare_Events.html">7 jmlr-2006-A Simulation-Based Algorithm for Ergodic Control of Markov Chains Conditioned on Rare Events</a></p>
<p>17 0.14341389 <a title="34-lsi-17" href="./jmlr-2006-Bounds_for_the_Loss_in_Probability_of_Correct_Classification_Under_Model_Based_Approximation.html">17 jmlr-2006-Bounds for the Loss in Probability of Correct Classification Under Model Based Approximation</a></p>
<p>18 0.1387531 <a title="34-lsi-18" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>19 0.12256586 <a title="34-lsi-19" href="./jmlr-2006-Learning_a_Hidden_Hypergraph.html">53 jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>20 0.1194605 <a title="34-lsi-20" href="./jmlr-2006-Learning_Recursive_Control_Programs_from_Problem_Solving_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">50 jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.494), (31, 0.019), (33, 0.027), (51, 0.017), (56, 0.01), (63, 0.03), (72, 0.051), (73, 0.075), (77, 0.073), (78, 0.032), (88, 0.025), (99, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.77447337 <a title="34-lda-1" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>Author: Tzu-Kuo Huang, Ruby C. Weng, Chih-Jen Lin</p><p>Abstract: The Bradley-Terry model for obtaining individual skill from paired comparisons has been popular in many areas. In machine learning, this model is related to multi-class probability estimates by coupling all pairwise classiﬁcation results. Error correcting output codes (ECOC) are a general framework to decompose a multi-class problem to several binary problems. To obtain probability estimates under this framework, this paper introduces a generalized Bradley-Terry model in which paired individual comparisons are extended to paired team comparisons. We propose a simple algorithm with convergence proofs to solve the model and obtain individual skill. Experiments on synthetic and real data demonstrate that the algorithm is useful for obtaining multi-class probability estimates. Moreover, we discuss four extensions of the proposed model: 1) weighted individual skill, 2) home-ﬁeld advantage, 3) ties, and 4) comparisons with more than two teams. Keywords: Bradley-Terry model, probability estimates, error correcting output codes, support vector machines</p><p>2 0.72076851 <a title="34-lda-2" href="./jmlr-2006-Evolutionary_Function_Approximation_for_Reinforcement_Learning.html">30 jmlr-2006-Evolutionary Function Approximation for Reinforcement Learning</a></p>
<p>Author: Shimon Whiteson, Peter Stone</p><p>Abstract: Temporal difference methods are theoretically grounded and empirically effective methods for addressing reinforcement learning problems. In most real-world reinforcement learning tasks, TD methods require a function approximator to represent the value function. However, using function approximators requires manually making crucial representational decisions. This paper investigates evolutionary function approximation, a novel approach to automatically selecting function approximator representations that enable efﬁcient individual learning. This method evolves individuals that are better able to learn. We present a fully implemented instantiation of evolutionary function approximation which combines NEAT, a neuroevolutionary optimization technique, with Q-learning, a popular TD method. The resulting NEAT+Q algorithm automatically discovers effective representations for neural network function approximators. This paper also presents on-line evolutionary computation, which improves the on-line performance of evolutionary computation by borrowing selection mechanisms used in TD methods to choose individual actions and using them in evolutionary computation to select policies for evaluation. We evaluate these contributions with extended empirical studies in two domains: 1) the mountain car task, a standard reinforcement learning benchmark on which neural network function approximators have previously performed poorly and 2) server job scheduling, a large probabilistic domain drawn from the ﬁeld of autonomic computing. The results demonstrate that evolutionary function approximation can signiﬁcantly improve the performance of TD methods and on-line evolutionary computation can signiﬁcantly improve evolutionary methods. This paper also presents additional tests that offer insight into what factors can make neural network function approximation difﬁcult in practice. Keywords: reinforcement learning, temporal difference methods, evolutionary computation, neuroevolution, on-</p><p>3 0.28279731 <a title="34-lda-3" href="./jmlr-2006-Collaborative_Multiagent_Reinforcement_Learning_by_Payoff_Propagation.html">20 jmlr-2006-Collaborative Multiagent Reinforcement Learning by Payoff Propagation</a></p>
<p>Author: Jelle R. Kok, Nikos Vlassis</p><p>Abstract: In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efﬁcient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences. Keywords: collaborative multiagent system, coordination graph, reinforcement learning, Qlearning, belief propagation</p><p>4 0.27245733 <a title="34-lda-4" href="./jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">6 jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<p>Author: Luis M. de Campos</p><p>Abstract: We propose a new scoring function for learning Bayesian networks from data using score+search algorithms. This is based on the concept of mutual information and exploits some well-known properties of this measure in a novel way. Essentially, a statistical independence test based on the chi-square distribution, associated with the mutual information measure, together with a property of additive decomposition of this measure, are combined in order to measure the degree of interaction between each variable and its parent variables in the network. The result is a non-Bayesian scoring function called MIT (mutual information tests) which belongs to the family of scores based on information theory. The MIT score also represents a penalization of the Kullback-Leibler divergence between the joint probability distributions associated with a candidate network and with the available data set. Detailed results of a complete experimental evaluation of the proposed scoring function and its comparison with the well-known K2, BDeu and BIC/MDL scores are also presented. Keywords: Bayesian networks, scoring functions, learning, mutual information, conditional independence tests</p><p>5 0.25338674 <a title="34-lda-5" href="./jmlr-2006-Consistency_of_Multiclass_Empirical_Risk_Minimization_Methods_Based_on_Convex_Loss.html">24 jmlr-2006-Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss</a></p>
<p>Author: Di-Rong Chen, Tao Sun</p><p>Abstract: The consistency of classiﬁcation algorithm plays a central role in statistical learning theory. A consistent algorithm guarantees us that taking more samples essentially sufﬁces to roughly reconstruct the unknown distribution. We consider the consistency of ERM scheme over classes of combinations of very simple rules (base classiﬁers) in multiclass classiﬁcation. Our approach is, under some mild conditions, to establish a quantitative relationship between classiﬁcation errors and convex risks. In comparison with the related previous work, the feature of our result is that the conditions are mainly expressed in terms of the differences between some values of the convex function. Keywords: multiclass classiﬁcation, classiﬁer, consistency, empirical risk minimization, constrained comparison method, Tsybakov noise condition</p><p>6 0.24850941 <a title="34-lda-6" href="./jmlr-2006-Efficient_Learning_of_Label_Ranking_by_Soft_Projections_onto_Polyhedra_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">26 jmlr-2006-Efficient Learning of Label Ranking by Soft Projections onto Polyhedra     (Special Topic on Machine Learning and Optimization)</a></p>
<p>7 0.24687801 <a title="34-lda-7" href="./jmlr-2006-Step_Size_Adaptation_in_Reproducing_Kernel_Hilbert_Space.html">86 jmlr-2006-Step Size Adaptation in Reproducing Kernel Hilbert Space</a></p>
<p>8 0.24599852 <a title="34-lda-8" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>9 0.24451053 <a title="34-lda-9" href="./jmlr-2006-Considering_Cost_Asymmetry_in_Learning_Classifiers.html">22 jmlr-2006-Considering Cost Asymmetry in Learning Classifiers</a></p>
<p>10 0.24444993 <a title="34-lda-10" href="./jmlr-2006-Building_Support_Vector_Machines_with_Reduced_Classifier_Complexity_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">18 jmlr-2006-Building Support Vector Machines with Reduced Classifier Complexity     (Special Topic on Machine Learning and Optimization)</a></p>
<p>11 0.24424677 <a title="34-lda-11" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>12 0.24337956 <a title="34-lda-12" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>13 0.24318779 <a title="34-lda-13" href="./jmlr-2006-On_Model_Selection_Consistency_of_Lasso.html">66 jmlr-2006-On Model Selection Consistency of Lasso</a></p>
<p>14 0.24307407 <a title="34-lda-14" href="./jmlr-2006-Learning_a_Hidden_Hypergraph.html">53 jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>15 0.24294132 <a title="34-lda-15" href="./jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>16 0.24256945 <a title="34-lda-16" href="./jmlr-2006-Large_Scale_Transductive_SVMs.html">44 jmlr-2006-Large Scale Transductive SVMs</a></p>
<p>17 0.24254258 <a title="34-lda-17" href="./jmlr-2006-A_Hierarchy_of_Support_Vector_Machines_for_Pattern_Detection.html">3 jmlr-2006-A Hierarchy of Support Vector Machines for Pattern Detection</a></p>
<p>18 0.24201518 <a title="34-lda-18" href="./jmlr-2006-Consistency_and_Convergence_Rates_of_One-Class_SVMs_and_Related_Algorithms.html">23 jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</a></p>
<p>19 0.2419809 <a title="34-lda-19" href="./jmlr-2006-Parallel_Software_for_Training_Large_Scale_Support_Vector_Machines_on_Multiprocessor_Systems_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">72 jmlr-2006-Parallel Software for Training Large Scale Support Vector Machines on Multiprocessor Systems     (Special Topic on Machine Learning and Optimization)</a></p>
<p>20 0.2404698 <a title="34-lda-20" href="./jmlr-2006-Pattern_Recognition_for__Conditionally_Independent_Data.html">73 jmlr-2006-Pattern Recognition for  Conditionally Independent Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
