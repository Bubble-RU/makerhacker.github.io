<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-50" href="#">jmlr2006-50</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>50 jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</h1>
<br/><p>Source: <a title="jmlr-2006-50-pdf" href="http://jmlr.org/papers/volume7/langley06a/langley06a.pdf">pdf</a></p><p>Author: Pat Langley, Dongkyu Choi</p><p>Abstract: In this paper, we propose a new representation for physical control – teleoreactive logic programs – along with an interpreter that uses them to achieve goals. In addition, we present a new learning method that acquires recursive forms of these structures from traces of successful problem solving. We report experiments in three different domains that demonstrate the generality of this approach. In closing, we review related work on learning complex skills and discuss directions for future research on this topic. Keywords: teleoreactive control, logic programs, problem solving, skill learning</p><p>Reference: <a title="jmlr-2006-50-reference" href="../jmlr2006_reference/jmlr-2006-Learning_Recursive_Control_Programs_from_Problem_Solving_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In closing, we review related work on learning complex skills and discuss directions for future research on this topic. [sent-7, score-0.411]
</p><p>2 Keywords: teleoreactive control, logic programs, problem solving, skill learning  1. [sent-8, score-0.928]
</p><p>3 Introduction Human skills have a hierarchical character, with complex procedures deﬁned in terms of more basic ones. [sent-9, score-0.459]
</p><p>4 In some domains, these skills are recursive in nature, in that structures are speciﬁed in terms of calls to themselves. [sent-10, score-0.447]
</p><p>5 In this paper we present one response to this problem that relies on a new representation for skills and a new method for acquiring them from experience. [sent-12, score-0.464]
</p><p>6 We represent skills as teleoreactive logic programs, a formalism that incorporates ideas from logic programming, reactive control, and hierarchical task networks. [sent-15, score-1.103]
</p><p>7 We assume that an agent uses hierarchical skills to achieve its goals whenever possible, but also that, upon encountering unfamiliar tasks, it falls back on problem solving. [sent-18, score-0.62]
</p><p>8 The learner begins with primitive skills for the domain, including knowledge of their applicability conditions and their effects, which lets it compose them to form candidate solutions. [sent-19, score-0.563]
</p><p>9 When the system overcomes such an impasse successfully, which may require substantial search, it learns a new skill that it stores in memory for use on future tasks. [sent-20, score-0.65]
</p><p>10 Thus, skill acquisition is incremental and intertwined with problem c 2006 Pat Langley and Dongkyu Choi. [sent-21, score-0.558]
</p><p>11 Moreover, learning is cumulative in that skills acquired early on form the building blocks for those mastered later. [sent-23, score-0.453]
</p><p>12 These concern identifying the hierarchical organization of the learned skills, determining when different skills should have the same name or head, and inferring the conditions under which each skill should be invoked. [sent-26, score-1.017]
</p><p>13 To this end, our approach to constructing teleoreactive logic programs incorporates ideas from previous work on learning and problem solving, but it also introduces some important innovations. [sent-27, score-0.437]
</p><p>14 Teleoreactive Logic Programs As we have noted, our approach revolves around a representational formalism for the execution of complex procedures – teleoreactive logic programs. [sent-33, score-0.473]
</p><p>15 A teleoreactive logic program consists of two interleaved knowledge bases. [sent-37, score-0.37]
</p><p>16 I CARUS distinguishes between primitive conceptual clauses, which refer only to percepts that the agent can observe in the environment, and complex clauses, which refer to other concepts in their bodies. [sent-42, score-0.583]
</p><p>17 Speciﬁc percepts play the same role as ground literals in traditional logic programs, but, because they come from the environment and change over time, we do not consider them part of the program. [sent-43, score-0.469]
</p><p>18 A second knowledge base contains a set of skills that the agent can execute in the world. [sent-46, score-0.55]
</p><p>19 Each skill clause includes a head (a predicate with zero or more arguments) and a body that speciﬁes a set of start conditions and one or more components. [sent-47, score-0.742]
</p><p>20 Primitive clauses have a single start condition (often a nonprimitive concept) and refer to executable actions that alter the environment. [sent-48, score-0.341]
</p><p>21 Table 2 shows the four primitive skills for the Blocks World, which are similar in structure and spirit to S TRIPS operators, but may be executed in a durative manner. [sent-131, score-0.592]
</p><p>22 In contrast, nonprimitive skill clauses specify how to decompose activity into subskills. [sent-132, score-0.759]
</p><p>23 Because a skill may refer to itself, either directly or through a subskill, the formalism supports recursive deﬁnitions. [sent-133, score-0.629]
</p><p>24 For this reason, nonprimitive skills do not specify effects, which can depend on the number of levels of recursion, nor do they state requirements. [sent-134, score-0.475]
</p><p>25 However, the head of each complex skill refers to some concept that the skill aims to achieve, an assumption Reddy and Tadepalli 495  L ANGLEY AND C HOI  ((unstack ? [sent-135, score-1.241]
</p><p>26 to) (hand-empty)))  Table 2: Primitive skills for the Blocks World domain. [sent-190, score-0.411]
</p><p>27 Each skill clause has a head that speciﬁes its name and arguments, a set of typed variables, a single start condition, a set of effects, and a set of executable actions, each marked by an asterisk. [sent-191, score-0.795]
</p><p>28 This connection between skills and concepts constitutes a key difference between the current approach and our earlier work on hierarchical skills in I CARUS (Choi et al. [sent-193, score-0.918]
</p><p>29 Table 3 presents some recursive skills for the Blocks World, including two clauses for achieving the concept clear. [sent-195, score-0.64]
</p><p>30 A)))  Table 3: Some nonprimitive skills for the Blocks World domain that involve recursive calls. [sent-229, score-0.511]
</p><p>31 Each skill clause has a head that speciﬁes the goal it achieves, a set of typed variables, one or more start conditions, and a set of ordered subskills. [sent-230, score-0.808]
</p><p>32 In our framework, skill heads correspond to tasks, skill clauses are equivalent to methods, and concept deﬁnitions play the role of axioms. [sent-233, score-1.357]
</p><p>33 In this mapping, teleoreactive logic programs are a special class of hierarchical task networks in which nonprimitive tasks always map onto declarative goals and in which top-level goals and the preconditions of primitive methods are always single literals. [sent-234, score-0.778]
</p><p>34 For each skill S in a teleoreactive logic program, if S has concept C as its head, then every expansion of S into such a sequence must, if executed successfully, produce a state in which C holds. [sent-237, score-1.013]
</p><p>35 , Iba, 1988); it does not guarantee that, once initiated, the sequence will achieve C, since other events may intervene or the agent may encounter states in which one of the primitive skills does not apply. [sent-240, score-0.702]
</p><p>36 However, if the sequence of primitive skills can be run to completion, then it will achieve the goal literal C. [sent-241, score-0.661]
</p><p>37 Interpreting Teleoreactive Logic Programs As their name suggests, teleoreactive logic programs are designed for reactive execution in a goaldriven manner, within a physical setting that changes over time. [sent-244, score-0.586]
</p><p>38 Unlike inference, the execution process proceeds in a top-down manner, ﬁnding paths through the skill hierarchy that terminate in primitive skills with executable actions. [sent-260, score-1.295]
</p><p>39 We deﬁne a skill path to be a chain of skill instances that starts from the agent’s goal and descends through the hierarchy along subskill links, unifying the arguments of each subskill consistently with those of its parent. [sent-261, score-1.295]
</p><p>40 Furthermore, the execution module only considers skill paths that are applicable. [sent-262, score-0.741]
</p><p>41 This holds if no concept instance that corresponds to a goal along the path is satisﬁed, if the requirements of the terminal (primitive) skill instance are satisﬁed, and if, for each skill instance in the path not executed on the previous cycle, the start condition is satisﬁed. [sent-263, score-1.301]
</p><p>42 This last constraint is necessary because skills may take many cycles to achieve their desired effects, making it important to distinguish between their initiation and their continuation. [sent-264, score-0.411]
</p><p>43 To this end, the module retains the path through the skill hierarchy selected on the previous time step, along with the variable bindings needed to reconstruct it. [sent-265, score-0.674]
</p><p>44 For example, imagine a situation in which the block C is on B, B is on A, and A is on the table, in which the goal is (clear A), and in which the agent knows the primitive skills in Table 2 and the recursive skills in Table 3. [sent-266, score-1.386]
</p><p>45 In this case, the only path through the skill hierarchy is [(clear A) 4], [(unstackable B A) 3], [(clear B) 1], [(unstack C B)]. [sent-268, score-0.585]
</p><p>46 Applying the primitive skill (unstack C B) produces a new situation that leads to new inferences, and in which the only applicable path is [(clear A) 4], [(unstackable B A) 3], [(hand-empty) 2], [(putdown C T)]. [sent-269, score-0.71]
</p><p>47 Second, given a choice between two or more applicable skill paths, it selects the one that shares the most elements from the start of the path executed on the 1. [sent-275, score-0.643]
</p><p>48 498  L EARNING R ECURSIVE C ONTROL P ROGRAMS teleoreactive logic program  problem  reactive control  ? [sent-278, score-0.451]
</p><p>49 primitive skills solution trace yes  problem solving  skill learning  Figure 1: Organization of modules for reactive execution, problem solving, and skill learning, along with their inputs and outputs. [sent-280, score-1.782]
</p><p>50 This bias encourages the agent to keep executing a high-level skill it has started until it achieves the associated goal or becomes inapplicable. [sent-282, score-0.791]
</p><p>51 To summarize, I CARUS’ procedure for interpreting teleoreactive logic programs relies on two interacting processes – conceptual inference and skill execution. [sent-291, score-1.016]
</p><p>52 After this, it starts from the current goal and uses these beliefs to check the conditions on skill instances to determine which paths are applicable, which in turn constrains the actions it executes. [sent-293, score-0.773]
</p><p>53 Solving Problems and Learning Skills Although one can construct teleoreactive logic programs manually, this process is time consuming and prone to error. [sent-297, score-0.437]
</p><p>54 Here we report an approach to learning such programs whenever the agent encounters a problem or subproblem that its current skills do not cover. [sent-298, score-0.617]
</p><p>55 In such cases, the architecture attempts to solve the problem by composing its primitive skills in a way that achieves the goal. [sent-299, score-0.64]
</p><p>56 However, when the effort is successful the agent produces a trace of the solution in terms of component skills that achieved the problem’s goal. [sent-301, score-0.572]
</p><p>57 The system transforms this trace into new skill clauses, which it adds to memory for use on future tasks. [sent-302, score-0.58]
</p><p>58 A key difference is that, in these systems, learning produces search-control knowledge that makes future problem solving more effective, whereas in our framework it generates teleoreactive logic programs that the agent uses in the environment. [sent-306, score-0.576]
</p><p>59 1 Means-Ends Problem Solving As described earlier, the execution module selects skill clauses that should achieve the current goal and that have start conditions which match its current beliefs about the environment. [sent-309, score-1.022]
</p><p>60 This process relies on a goal stack that stores both subgoals and skills that might accomplish them. [sent-312, score-0.707]
</p><p>61 As Table 4 indicates, the problem solver pushes the current goal G onto the goal stack, then checks it on each execution cycle to determine whether it has been achieved. [sent-318, score-0.363]
</p><p>62 If so, then the module pops the stack and focuses on G’s parent goal or, upon achieving the top-level goal, simply halts. [sent-319, score-0.42]
</p><p>63 If the current goal G is not satisﬁed, then the architecture retrieves all nonprimitive skills with heads that unify with G and, if any participate in applicable paths through the skill hierarchy, selects the ﬁrst one found and executes it. [sent-320, score-1.351]
</p><p>64 If the problem solver cannot ﬁnd any complex skills indexed by the goal G, it instead retrieves all primitive skills that produce G as one of their effects. [sent-322, score-1.135]
</p><p>65 The system then generates candidate instances of these skills by inserting known objects as their arguments. [sent-323, score-0.433]
</p><p>66 To select among these skill instances, it expands the instantiated start condition of each skill instance to determine how many of its primitive components are satisﬁed, then selects the one with the fewest literals unsatisﬁed in the current situation. [sent-324, score-1.372]
</p><p>67 500  L EARNING R ECURSIVE C ONTROL P ROGRAMS  Solve(G) Push the goal literal G onto the empty goal stack GS. [sent-328, score-0.388]
</p><p>68 On each cycle, If the top goal G of the goal stack GS is satisfied, Then pop GS. [sent-329, score-0.355]
</p><p>69 Else if the goal stack GS does not exceed the depth limit, Let S be the skill instances whose heads unify with G. [sent-330, score-0.885]
</p><p>70 If any applicable skill paths start from an instance in S, Then select one of these paths and execute it. [sent-331, score-0.644]
</p><p>71 Else let M be the set of primitive skill instances that have not already failed in which G is an effect. [sent-332, score-0.754]
</p><p>72 If the set M is nonempty, Then select a skill instance Q from M. [sent-333, score-0.558]
</p><p>73 Else if G is a complex concept with the unsatisfied subconcepts H and with satisfied subconcepts F, Then if there is a subconcept I in H that has not yet failed, Then push I onto the goal stack GS. [sent-335, score-0.494]
</p><p>74 Table 4: Pseudocode for interleaving means-ends problem solving with skill execution. [sent-340, score-0.585]
</p><p>75 skill instance’s condition is met, the system executes the skill instance in the environment until it achieves the associated goal, which it then pops from the stack. [sent-341, score-1.267]
</p><p>76 However, if the problem solver cannot ﬁnd any skill clause that would achieve the current goal G, it uses G’s concept deﬁnition to decompose the goal into subgoals. [sent-343, score-0.88]
</p><p>77 This leads to chaining off the start condition of additional skills and/or the deﬁnitions of other concepts. [sent-345, score-0.487]
</p><p>78 Upon achieving a subgoal, the architecture pops the stack and, if other subconcepts remain unsatisﬁed, turns its attention to achieving them. [sent-346, score-0.395]
</p><p>79 Of course, the problem-solving module must make decisions about which skills to select during skill chaining and the order in which it should tackle subconcepts during concept chaining. [sent-348, score-1.209]
</p><p>80 Figure 2 shows an example of the problem solver’s behavior on the Blocks World in a situation where block A is on the table, block B is on A, block C is on B, and the hand is empty. [sent-352, score-0.513]
</p><p>81 Upon being given the objective (clear A), the architecture looks for any executable skill with this goal as its head. [sent-353, score-0.754]
</p><p>82 When this fails, it looks for a skill that has the objective as one of its effects. [sent-354, score-0.558]
</p><p>83 invoking the primitive skill instance (unstack B A) would produce the desired result. [sent-356, score-0.71]
</p><p>84 However, this cannot yet be applied because its instantiated start condition, (unstackable B A), does not hold, so the system stores the skill instance with the initial goal and pushes this subgoal onto the stack. [sent-357, score-0.825]
</p><p>85 Next, the problem solver attempts to retrieve skills that would achieve (unstackable B A) but, because it has no such skills in memory, it resorts to chaining off the deﬁnition of unstackable. [sent-358, score-0.917]
</p><p>86 In response, it considers skills that would produce this literal as an effect and retrieves the skill instance (unstack C B), which it stores with the current goal. [sent-360, score-1.082]
</p><p>87 In response, it pops this goal from the stack and reconsiders its parent, (unstackable B A). [sent-362, score-0.352]
</p><p>88 Unfortunately, this has not yet been achieved because executing the skill has caused the third of its component concept instances, (hand-empty), to become false. [sent-363, score-0.642]
</p><p>89 Thus, the system pushes this onto the stack and, upon inspecting memory, retrieves the skill instance (putdown C T), which it can and does execute. [sent-364, score-0.866]
</p><p>90 Thus, the problem solver pops this element from the goal stack and executes the skill instance it had originally selected, (unstack B A), in the new situation. [sent-366, score-0.979]
</p><p>91 Of course, executing a component skill before it has constructed a complete plan can lead the system into difﬁculty, since the agent cannot always backtrack in the physical world and can produce situations from which it cannot recover without starting over on the problem. [sent-373, score-0.754]
</p><p>92 In such cases, the problem solver stores the goal for which the executed skill caused trouble, along with everything below it in the stack. [sent-374, score-0.745]
</p><p>93 The system begins the problem again, this time avoiding the skill and selecting another option. [sent-375, score-0.558]
</p><p>94 If a different execution error occurs this time, the module again stores the problematic skill and its context, then starts over once more. [sent-376, score-0.754]
</p><p>95 2 Goal-Driven Composition of Skills Any method for learning teleoreactive logic programs or similar structures must address three issues. [sent-379, score-0.437]
</p><p>96 This structure follows directly from our assumptions that each primitive skill has one start condition and each goal is cast as a single literal. [sent-388, score-0.81]
</p><p>97 Because the problem solver chains backward off skill and concept deﬁnitions, the result is a hierarchical structure that suggests a new skill clause for each subgoal. [sent-389, score-1.354]
</p><p>98 The answer to the second question is that the head of a learned skill clause is the goal literal that the problem solver achieved for the subproblem that produced it. [sent-392, score-0.859]
</p><p>99 This follows from our assumption that the head of each clause in a teleoreactive logic program speciﬁes some concept that the clause will produce if executed. [sent-393, score-0.657]
</p><p>100 At ﬁrst glance, this appears to confound skills with concepts, but another view is that it indexes skill clauses by the concepts they achieve. [sent-394, score-1.154]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('skill', 0.558), ('skills', 0.411), ('percepts', 0.223), ('teleoreactive', 0.212), ('stack', 0.191), ('block', 0.171), ('unstackable', 0.17), ('logic', 0.158), ('primitive', 0.152), ('agent', 0.139), ('clauses', 0.137), ('unstack', 0.127), ('ypos', 0.117), ('module', 0.089), ('height', 0.089), ('xpos', 0.085), ('clause', 0.081), ('reactive', 0.081), ('architecture', 0.077), ('pops', 0.074), ('head', 0.069), ('execution', 0.068), ('programs', 0.067), ('goal', 0.066), ('angley', 0.064), ('carus', 0.064), ('hoi', 0.064), ('nonprimitive', 0.064), ('ontable', 0.064), ('concept', 0.056), ('ecursive', 0.053), ('executable', 0.053), ('impasse', 0.053), ('putdown', 0.053), ('subconcepts', 0.053), ('subgoal', 0.053), ('actions', 0.053), ('solver', 0.053), ('hierarchical', 0.048), ('heads', 0.048), ('literals', 0.048), ('beliefs', 0.048), ('concepts', 0.048), ('ontrol', 0.045), ('rograms', 0.045), ('chaining', 0.042), ('perceives', 0.042), ('pushes', 0.042), ('retrieves', 0.042), ('blocks', 0.042), ('environment', 0.04), ('stores', 0.039), ('executes', 0.037), ('langley', 0.037), ('choi', 0.036), ('recursive', 0.036), ('clear', 0.036), ('cycle', 0.035), ('formalism', 0.035), ('start', 0.034), ('onto', 0.033), ('holding', 0.033), ('unsatis', 0.032), ('literal', 0.032), ('pickupable', 0.032), ('pop', 0.032), ('putdownable', 0.032), ('soar', 0.032), ('subskill', 0.032), ('world', 0.029), ('executed', 0.029), ('effects', 0.028), ('status', 0.028), ('executing', 0.028), ('acquiring', 0.027), ('interleaving', 0.027), ('interpreter', 0.027), ('hierarchy', 0.027), ('paths', 0.026), ('positives', 0.026), ('response', 0.026), ('prolog', 0.024), ('table', 0.023), ('goals', 0.022), ('failed', 0.022), ('selects', 0.022), ('trace', 0.022), ('instances', 0.022), ('dongkyu', 0.021), ('percept', 0.021), ('perceptions', 0.021), ('reconsiders', 0.021), ('rodigy', 0.021), ('satisfied', 0.021), ('stackable', 0.021), ('subconcept', 0.021), ('subskills', 0.021), ('trips', 0.021), ('ungrasp', 0.021), ('conceptual', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="50-tfidf-1" href="./jmlr-2006-Learning_Recursive_Control_Programs_from_Problem_Solving_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">50 jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</a></p>
<p>Author: Pat Langley, Dongkyu Choi</p><p>Abstract: In this paper, we propose a new representation for physical control – teleoreactive logic programs – along with an interpreter that uses them to achieve goals. In addition, we present a new learning method that acquires recursive forms of these structures from traces of successful problem solving. We report experiments in three different domains that demonstrate the generality of this approach. In closing, we review related work on learning complex skills and discuss directions for future research on this topic. Keywords: teleoreactive control, logic programs, problem solving, skill learning</p><p>2 0.09165775 <a title="50-tfidf-2" href="./jmlr-2006-Kernels_on_Prolog_Proof_Trees%3A_Statistical_Learning_in_the_ILP_Setting_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">42 jmlr-2006-Kernels on Prolog Proof Trees: Statistical Learning in the ILP Setting     (Special Topic on Inductive Programming)</a></p>
<p>Author: Andrea Passerini, Paolo Frasconi, Luc De Raedt</p><p>Abstract: We develop kernels for measuring the similarity between relational instances using background knowledge expressed in ﬁrst-order logic. The method allows us to bridge the gap between traditional inductive logic programming (ILP) representations and statistical approaches to supervised learning. Logic programs are ﬁrst used to generate proofs of given visitor programs that use predicates declared in the available background knowledge. A kernel is then deﬁned over pairs of proof trees. The method can be used for supervised learning tasks and is suitable for classiﬁcation as well as regression. We report positive empirical results on Bongard-like and M-of-N problems that are difﬁcult or impossible to solve with traditional ILP techniques, as well as on real bioinformatics and chemoinformatics data sets. Keywords: kernel methods, inductive logic programming, Prolog, learning from program traces</p><p>3 0.089212149 <a title="50-tfidf-3" href="./jmlr-2006-Collaborative_Multiagent_Reinforcement_Learning_by_Payoff_Propagation.html">20 jmlr-2006-Collaborative Multiagent Reinforcement Learning by Payoff Propagation</a></p>
<p>Author: Jelle R. Kok, Nikos Vlassis</p><p>Abstract: In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efﬁcient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences. Keywords: collaborative multiagent system, coordination graph, reinforcement learning, Qlearning, belief propagation</p><p>4 0.062304083 <a title="50-tfidf-4" href="./jmlr-2006-Inductive_Synthesis_of_Functional_Programs%3A_An_Explanation_Based_Generalization_Approach_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">39 jmlr-2006-Inductive Synthesis of Functional Programs: An Explanation Based Generalization Approach     (Special Topic on Inductive Programming)</a></p>
<p>Author: Emanuel Kitzelmann, Ute Schmid</p><p>Abstract: We describe an approach to the inductive synthesis of recursive equations from input/outputexamples which is based on the classical two-step approach to induction of functional Lisp programs of Summers (1977). In a ﬁrst step, I/O-examples are rewritten to traces which explain the outputs given the respective inputs based on a datatype theory. These traces can be integrated into one conditional expression which represents a non-recursive program. In a second step, this initial program term is generalized into recursive equations by searching for syntactical regularities in the term. Our approach extends the classical work in several aspects. The most important extensions are that we are able to induce a set of recursive equations in one synthesizing step, the equations may contain more than one recursive call, and additionally needed parameters are automatically introduced. Keywords: inductive program synthesis, inductive functional programming, explanation based generalization, recursive program schemes</p><p>5 0.050177526 <a title="50-tfidf-5" href="./jmlr-2006-Using_Machine_Learning_to_Guide_Architecture_Simulation.html">94 jmlr-2006-Using Machine Learning to Guide Architecture Simulation</a></p>
<p>Author: Greg Hamerly, Erez Perelman, Jeremy Lau, Brad Calder, Timothy Sherwood</p><p>Abstract: An essential step in designing a new computer architecture is the careful examination of different design options. It is critical that computer architects have efﬁcient means by which they may estimate the impact of various design options on the overall machine. This task is complicated by the fact that different programs, and even different parts of the same program, may have distinct behaviors that interact with the hardware in different ways. Researchers use very detailed simulators to estimate processor performance, which models every cycle of an executing program. Unfortunately, simulating every cycle of a real program can take weeks or months. To address this problem we have created a tool called SimPoint that uses data clustering algorithms from machine learning to automatically ﬁnd repetitive patterns in a program’s execution. By simulating one representative of each repetitive behavior pattern, simulation time can be reduced to minutes instead of weeks for standard benchmark programs, with very little cost in terms of accuracy. We describe this important problem, the data representation and preprocessing methods used by SimPoint, the clustering algorithm at the core of SimPoint, and we evaluate different options for tuning SimPoint. Keywords: k-means, random projection, Bayesian information criterion, simulation, SimPoint</p><p>6 0.036470063 <a title="50-tfidf-6" href="./jmlr-2006-Point-Based_Value_Iteration_for_Continuous_POMDPs.html">74 jmlr-2006-Point-Based Value Iteration for Continuous POMDPs</a></p>
<p>7 0.0327994 <a title="50-tfidf-7" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>8 0.030527156 <a title="50-tfidf-8" href="./jmlr-2006-Causal_Graph_Based_Decomposition_of_Factored_MDPs.html">19 jmlr-2006-Causal Graph Based Decomposition of Factored MDPs</a></p>
<p>9 0.026976185 <a title="50-tfidf-9" href="./jmlr-2006-Evolutionary_Function_Approximation_for_Reinforcement_Learning.html">30 jmlr-2006-Evolutionary Function Approximation for Reinforcement Learning</a></p>
<p>10 0.025318094 <a title="50-tfidf-10" href="./jmlr-2006-Incremental_Algorithms_for_Hierarchical_Classification.html">37 jmlr-2006-Incremental Algorithms for Hierarchical Classification</a></p>
<p>11 0.025298176 <a title="50-tfidf-11" href="./jmlr-2006-The_Interplay_of_Optimization_and_Machine_Learning_Research_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">91 jmlr-2006-The Interplay of Optimization and Machine Learning Research     (Special Topic on Machine Learning and Optimization)</a></p>
<p>12 0.024023024 <a title="50-tfidf-12" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>13 0.022651503 <a title="50-tfidf-13" href="./jmlr-2006-Policy_Gradient_in_Continuous_Time.html">75 jmlr-2006-Policy Gradient in Continuous Time</a></p>
<p>14 0.021757018 <a title="50-tfidf-14" href="./jmlr-2006-A_Hierarchy_of_Support_Vector_Machines_for_Pattern_Detection.html">3 jmlr-2006-A Hierarchy of Support Vector Machines for Pattern Detection</a></p>
<p>15 0.018518809 <a title="50-tfidf-15" href="./jmlr-2006-Bayesian_Network_Learning_with_Parameter_Constraints_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">15 jmlr-2006-Bayesian Network Learning with Parameter Constraints     (Special Topic on Machine Learning and Optimization)</a></p>
<p>16 0.015969597 <a title="50-tfidf-16" href="./jmlr-2006-Linear_Programming_Relaxations_and_Belief_Propagation_--_An_Empirical_Study_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">55 jmlr-2006-Linear Programming Relaxations and Belief Propagation -- An Empirical Study     (Special Topic on Machine Learning and Optimization)</a></p>
<p>17 0.014797332 <a title="50-tfidf-17" href="./jmlr-2006-On_Representing_and_Generating_Kernels_by_Fuzzy_Equivalence_Relations.html">67 jmlr-2006-On Representing and Generating Kernels by Fuzzy Equivalence Relations</a></p>
<p>18 0.014711171 <a title="50-tfidf-18" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>19 0.014469791 <a title="50-tfidf-19" href="./jmlr-2006-Efficient_Learning_of_Label_Ranking_by_Soft_Projections_onto_Polyhedra_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">26 jmlr-2006-Efficient Learning of Label Ranking by Soft Projections onto Polyhedra     (Special Topic on Machine Learning and Optimization)</a></p>
<p>20 0.014460813 <a title="50-tfidf-20" href="./jmlr-2006-Incremental_Support_Vector_Learning%3A_Analysis%2C_Implementation_and_Applications_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">38 jmlr-2006-Incremental Support Vector Learning: Analysis, Implementation and Applications     (Special Topic on Machine Learning and Optimization)</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.089), (1, 0.028), (2, -0.101), (3, 0.081), (4, 0.095), (5, 0.048), (6, -0.007), (7, -0.116), (8, -0.04), (9, -0.053), (10, 0.134), (11, -0.164), (12, -0.136), (13, 0.24), (14, -0.102), (15, -0.04), (16, 0.031), (17, -0.1), (18, 0.263), (19, -0.082), (20, -0.016), (21, 0.109), (22, 0.07), (23, 0.101), (24, 0.047), (25, -0.195), (26, -0.122), (27, 0.051), (28, -0.0), (29, 0.129), (30, 0.01), (31, -0.183), (32, -0.013), (33, 0.153), (34, -0.109), (35, 0.12), (36, 0.003), (37, -0.008), (38, -0.1), (39, 0.08), (40, -0.178), (41, -0.045), (42, 0.006), (43, 0.119), (44, -0.039), (45, -0.122), (46, -0.113), (47, 0.121), (48, 0.082), (49, 0.202)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98951536 <a title="50-lsi-1" href="./jmlr-2006-Learning_Recursive_Control_Programs_from_Problem_Solving_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">50 jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</a></p>
<p>Author: Pat Langley, Dongkyu Choi</p><p>Abstract: In this paper, we propose a new representation for physical control – teleoreactive logic programs – along with an interpreter that uses them to achieve goals. In addition, we present a new learning method that acquires recursive forms of these structures from traces of successful problem solving. We report experiments in three different domains that demonstrate the generality of this approach. In closing, we review related work on learning complex skills and discuss directions for future research on this topic. Keywords: teleoreactive control, logic programs, problem solving, skill learning</p><p>2 0.49426249 <a title="50-lsi-2" href="./jmlr-2006-Kernels_on_Prolog_Proof_Trees%3A_Statistical_Learning_in_the_ILP_Setting_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">42 jmlr-2006-Kernels on Prolog Proof Trees: Statistical Learning in the ILP Setting     (Special Topic on Inductive Programming)</a></p>
<p>Author: Andrea Passerini, Paolo Frasconi, Luc De Raedt</p><p>Abstract: We develop kernels for measuring the similarity between relational instances using background knowledge expressed in ﬁrst-order logic. The method allows us to bridge the gap between traditional inductive logic programming (ILP) representations and statistical approaches to supervised learning. Logic programs are ﬁrst used to generate proofs of given visitor programs that use predicates declared in the available background knowledge. A kernel is then deﬁned over pairs of proof trees. The method can be used for supervised learning tasks and is suitable for classiﬁcation as well as regression. We report positive empirical results on Bongard-like and M-of-N problems that are difﬁcult or impossible to solve with traditional ILP techniques, as well as on real bioinformatics and chemoinformatics data sets. Keywords: kernel methods, inductive logic programming, Prolog, learning from program traces</p><p>3 0.34888101 <a title="50-lsi-3" href="./jmlr-2006-Collaborative_Multiagent_Reinforcement_Learning_by_Payoff_Propagation.html">20 jmlr-2006-Collaborative Multiagent Reinforcement Learning by Payoff Propagation</a></p>
<p>Author: Jelle R. Kok, Nikos Vlassis</p><p>Abstract: In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efﬁcient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences. Keywords: collaborative multiagent system, coordination graph, reinforcement learning, Qlearning, belief propagation</p><p>4 0.32309824 <a title="50-lsi-4" href="./jmlr-2006-Inductive_Synthesis_of_Functional_Programs%3A_An_Explanation_Based_Generalization_Approach_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">39 jmlr-2006-Inductive Synthesis of Functional Programs: An Explanation Based Generalization Approach     (Special Topic on Inductive Programming)</a></p>
<p>Author: Emanuel Kitzelmann, Ute Schmid</p><p>Abstract: We describe an approach to the inductive synthesis of recursive equations from input/outputexamples which is based on the classical two-step approach to induction of functional Lisp programs of Summers (1977). In a ﬁrst step, I/O-examples are rewritten to traces which explain the outputs given the respective inputs based on a datatype theory. These traces can be integrated into one conditional expression which represents a non-recursive program. In a second step, this initial program term is generalized into recursive equations by searching for syntactical regularities in the term. Our approach extends the classical work in several aspects. The most important extensions are that we are able to induce a set of recursive equations in one synthesizing step, the equations may contain more than one recursive call, and additionally needed parameters are automatically introduced. Keywords: inductive program synthesis, inductive functional programming, explanation based generalization, recursive program schemes</p><p>5 0.26730812 <a title="50-lsi-5" href="./jmlr-2006-Using_Machine_Learning_to_Guide_Architecture_Simulation.html">94 jmlr-2006-Using Machine Learning to Guide Architecture Simulation</a></p>
<p>Author: Greg Hamerly, Erez Perelman, Jeremy Lau, Brad Calder, Timothy Sherwood</p><p>Abstract: An essential step in designing a new computer architecture is the careful examination of different design options. It is critical that computer architects have efﬁcient means by which they may estimate the impact of various design options on the overall machine. This task is complicated by the fact that different programs, and even different parts of the same program, may have distinct behaviors that interact with the hardware in different ways. Researchers use very detailed simulators to estimate processor performance, which models every cycle of an executing program. Unfortunately, simulating every cycle of a real program can take weeks or months. To address this problem we have created a tool called SimPoint that uses data clustering algorithms from machine learning to automatically ﬁnd repetitive patterns in a program’s execution. By simulating one representative of each repetitive behavior pattern, simulation time can be reduced to minutes instead of weeks for standard benchmark programs, with very little cost in terms of accuracy. We describe this important problem, the data representation and preprocessing methods used by SimPoint, the clustering algorithm at the core of SimPoint, and we evaluate different options for tuning SimPoint. Keywords: k-means, random projection, Bayesian information criterion, simulation, SimPoint</p><p>6 0.15766154 <a title="50-lsi-6" href="./jmlr-2006-Causal_Graph_Based_Decomposition_of_Factored_MDPs.html">19 jmlr-2006-Causal Graph Based Decomposition of Factored MDPs</a></p>
<p>7 0.11951403 <a title="50-lsi-7" href="./jmlr-2006-A_Hierarchy_of_Support_Vector_Machines_for_Pattern_Detection.html">3 jmlr-2006-A Hierarchy of Support Vector Machines for Pattern Detection</a></p>
<p>8 0.11278117 <a title="50-lsi-8" href="./jmlr-2006-Bayesian_Network_Learning_with_Parameter_Constraints_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">15 jmlr-2006-Bayesian Network Learning with Parameter Constraints     (Special Topic on Machine Learning and Optimization)</a></p>
<p>9 0.11186171 <a title="50-lsi-9" href="./jmlr-2006-Point-Based_Value_Iteration_for_Continuous_POMDPs.html">74 jmlr-2006-Point-Based Value Iteration for Continuous POMDPs</a></p>
<p>10 0.09834154 <a title="50-lsi-10" href="./jmlr-2006-Learning_Parts-Based_Representations_of_Data.html">49 jmlr-2006-Learning Parts-Based Representations of Data</a></p>
<p>11 0.095973298 <a title="50-lsi-11" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>12 0.095318787 <a title="50-lsi-12" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>13 0.085705824 <a title="50-lsi-13" href="./jmlr-2006-An_Efficient_Implementation_of_an_Active_Set_Method_for_SVMs%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">14 jmlr-2006-An Efficient Implementation of an Active Set Method for SVMs    (Special Topic on Machine Learning and Optimization)</a></p>
<p>14 0.085298799 <a title="50-lsi-14" href="./jmlr-2006-The_Interplay_of_Optimization_and_Machine_Learning_Research_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">91 jmlr-2006-The Interplay of Optimization and Machine Learning Research     (Special Topic on Machine Learning and Optimization)</a></p>
<p>15 0.084747061 <a title="50-lsi-15" href="./jmlr-2006-Segmental_Hidden_Markov_Models_with_Random_Effects_for_Waveform_Modeling.html">80 jmlr-2006-Segmental Hidden Markov Models with Random Effects for Waveform Modeling</a></p>
<p>16 0.081409611 <a title="50-lsi-16" href="./jmlr-2006-Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets.html">85 jmlr-2006-Statistical Comparisons of Classifiers over Multiple Data Sets</a></p>
<p>17 0.077438593 <a title="50-lsi-17" href="./jmlr-2006-Efficient_Learning_of_Label_Ranking_by_Soft_Projections_onto_Polyhedra_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">26 jmlr-2006-Efficient Learning of Label Ranking by Soft Projections onto Polyhedra     (Special Topic on Machine Learning and Optimization)</a></p>
<p>18 0.072675556 <a title="50-lsi-18" href="./jmlr-2006-Linear_State-Space_Models_for_Blind_Source_Separation.html">57 jmlr-2006-Linear State-Space Models for Blind Source Separation</a></p>
<p>19 0.07121639 <a title="50-lsi-19" href="./jmlr-2006-A_Robust_Procedure_For_Gaussian_Graphical_Model_Search_From_Microarray_Data_WithpLarger_Thann.html">5 jmlr-2006-A Robust Procedure For Gaussian Graphical Model Search From Microarray Data WithpLarger Thann</a></p>
<p>20 0.070786983 <a title="50-lsi-20" href="./jmlr-2006-On_Model_Selection_Consistency_of_Lasso.html">66 jmlr-2006-On Model Selection Consistency of Lasso</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(36, 0.706), (50, 0.021), (63, 0.017), (79, 0.024), (81, 0.031), (91, 0.016), (96, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98379934 <a title="50-lda-1" href="./jmlr-2006-Learning_Recursive_Control_Programs_from_Problem_Solving_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">50 jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</a></p>
<p>Author: Pat Langley, Dongkyu Choi</p><p>Abstract: In this paper, we propose a new representation for physical control – teleoreactive logic programs – along with an interpreter that uses them to achieve goals. In addition, we present a new learning method that acquires recursive forms of these structures from traces of successful problem solving. We report experiments in three different domains that demonstrate the generality of this approach. In closing, we review related work on learning complex skills and discuss directions for future research on this topic. Keywords: teleoreactive control, logic programs, problem solving, skill learning</p><p>2 0.98045212 <a title="50-lda-2" href="./jmlr-2006-Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets.html">85 jmlr-2006-Statistical Comparisons of Classifiers over Multiple Data Sets</a></p>
<p>Author: Janez Demšar</p><p>Abstract: While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classiﬁers: the Wilcoxon signed ranks test for comparison of two classiﬁers and the Friedman test with the corresponding post-hoc tests for comparison of more classiﬁers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams. Keywords: comparative studies, statistical methods, Wilcoxon signed ranks test, Friedman test, multiple comparisons tests</p><p>3 0.95119464 <a title="50-lda-3" href="./jmlr-2006-Some_Discriminant-Based_PAC_Algorithms.html">81 jmlr-2006-Some Discriminant-Based PAC Algorithms</a></p>
<p>Author: Paul W. Goldberg</p><p>Abstract: A classical approach in multi-class pattern classiﬁcation is the following. Estimate the probability distributions that generated the observations for each label class, and then label new instances by applying the Bayes classiﬁer to the estimated distributions. That approach provides more useful information than just a class label; it also provides estimates of the conditional distribution of class labels, in situations where there is class overlap. We would like to know whether it is harder to build accurate classiﬁers via this approach, than by techniques that may process all data with distinct labels together. In this paper we make that question precise by considering it in the context of PAC learnability. We propose two restrictions on the PAC learning framework that are intended to correspond with the above approach, and consider their relationship with standard PAC learning. Our main restriction of interest leads to some interesting algorithms that show that the restriction is not stronger (more restrictive) than various other well-known restrictions on PAC learning. An alternative slightly milder restriction turns out to be almost equivalent to unrestricted PAC learning. Keywords: computational learning theory, computational complexity, pattern classiﬁcation</p><p>4 0.61679298 <a title="50-lda-4" href="./jmlr-2006-Bounds_for_the_Loss_in_Probability_of_Correct_Classification_Under_Model_Based_Approximation.html">17 jmlr-2006-Bounds for the Loss in Probability of Correct Classification Under Model Based Approximation</a></p>
<p>Author: Magnus Ekdahl, Timo Koski</p><p>Abstract: In many pattern recognition/classiﬁcation problem the true class conditional model and class probabilities are approximated for reasons of reducing complexity and/or of statistical estimation. The approximated classiﬁer is expected to have worse performance, here measured by the probability of correct classiﬁcation. We present an analysis valid in general, and easily computable formulas for estimating the degradation in probability of correct classiﬁcation when compared to the optimal classiﬁer. An example of an approximation is the Na¨ve Bayes classiﬁer. We show that the perforı mance of the Na¨ve Bayes depends on the degree of functional dependence between the features ı and labels. We provide a sufﬁcient condition for zero loss of performance, too. Keywords: Bayesian networks, na¨ve Bayes, plug-in classiﬁer, Kolmogorov distance of variation, ı variational learning</p><p>5 0.60520846 <a title="50-lda-5" href="./jmlr-2006-New_Algorithms_for_Efficient_High-Dimensional_Nonparametric_Classification.html">63 jmlr-2006-New Algorithms for Efficient High-Dimensional Nonparametric Classification</a></p>
<p>Author: Ting Liu, Andrew W. Moore, Alexander Gray</p><p>Abstract: This paper is about non-approximate acceleration of high-dimensional nonparametric operations such as k nearest neighbor classiﬁers. We attempt to exploit the fact that even if we want exact answers to nonparametric queries, we usually do not need to explicitly ﬁnd the data points close to the query, but merely need to answer questions about the properties of that set of data points. This offers a small amount of computational leeway, and we investigate how much that leeway can be exploited. This is applicable to many algorithms in nonparametric statistics, memory-based learning and kernel-based learning. But for clarity, this paper concentrates on pure k-NN classiﬁcation. We introduce new ball-tree algorithms that on real-world data sets give accelerations from 2-fold to 100-fold compared against highly optimized traditional ball-tree-based k-NN . These results include data sets with up to 106 dimensions and 105 records, and demonstrate non-trivial speed-ups while giving exact answers. keywords: ball-tree, k-NN classiﬁcation</p><p>6 0.5869363 <a title="50-lda-6" href="./jmlr-2006-Computational_and_Theoretical_Analysis_of__Null_Space__and_Orthogonal_Linear_Discriminant_Analysis.html">21 jmlr-2006-Computational and Theoretical Analysis of  Null Space  and Orthogonal Linear Discriminant Analysis</a></p>
<p>7 0.58415127 <a title="50-lda-7" href="./jmlr-2006-Active_Learning_in_Approximately_Linear_Regression_Based_on_Conditional_Expectation_of_Generalization_Error.html">11 jmlr-2006-Active Learning in Approximately Linear Regression Based on Conditional Expectation of Generalization Error</a></p>
<p>8 0.58008689 <a title="50-lda-8" href="./jmlr-2006-Kernels_on_Prolog_Proof_Trees%3A_Statistical_Learning_in_the_ILP_Setting_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">42 jmlr-2006-Kernels on Prolog Proof Trees: Statistical Learning in the ILP Setting     (Special Topic on Inductive Programming)</a></p>
<p>9 0.57247359 <a title="50-lda-9" href="./jmlr-2006-Ensemble_Pruning_Via_Semi-definite_Programming_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">27 jmlr-2006-Ensemble Pruning Via Semi-definite Programming     (Special Topic on Machine Learning and Optimization)</a></p>
<p>10 0.56927073 <a title="50-lda-10" href="./jmlr-2006-Incremental_Algorithms_for_Hierarchical_Classification.html">37 jmlr-2006-Incremental Algorithms for Hierarchical Classification</a></p>
<p>11 0.56852418 <a title="50-lda-11" href="./jmlr-2006-Learning_Image_Components_for_Object_Recognition.html">47 jmlr-2006-Learning Image Components for Object Recognition</a></p>
<p>12 0.55820757 <a title="50-lda-12" href="./jmlr-2006-Toward_Attribute_Efficient_Learning_of_Decision_Lists_and_Parities.html">92 jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</a></p>
<p>13 0.55617213 <a title="50-lda-13" href="./jmlr-2006-Pattern_Recognition_for__Conditionally_Independent_Data.html">73 jmlr-2006-Pattern Recognition for  Conditionally Independent Data</a></p>
<p>14 0.55257636 <a title="50-lda-14" href="./jmlr-2006-Learning_a_Hidden_Hypergraph.html">53 jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>15 0.54635757 <a title="50-lda-15" href="./jmlr-2006-Using_Machine_Learning_to_Guide_Architecture_Simulation.html">94 jmlr-2006-Using Machine Learning to Guide Architecture Simulation</a></p>
<p>16 0.53238142 <a title="50-lda-16" href="./jmlr-2006-Estimation_of_Gradients_and_Coordinate_Covariation_in_Classification.html">29 jmlr-2006-Estimation of Gradients and Coordinate Covariation in Classification</a></p>
<p>17 0.53070599 <a title="50-lda-17" href="./jmlr-2006-Manifold__Regularization%3A_A_Geometric_Framework_for_Learning_from_Labeled_and_Unlabeled_Examples.html">60 jmlr-2006-Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</a></p>
<p>18 0.52911395 <a title="50-lda-18" href="./jmlr-2006-Learning_Parts-Based_Representations_of_Data.html">49 jmlr-2006-Learning Parts-Based Representations of Data</a></p>
<p>19 0.5271638 <a title="50-lda-19" href="./jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">34 jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>20 0.52394783 <a title="50-lda-20" href="./jmlr-2006-MinReg%3A_A_Scalable_Algorithm_for_Learning_Parsimonious_Regulatory_Networks_in_Yeast_and_Mammals.html">62 jmlr-2006-MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
