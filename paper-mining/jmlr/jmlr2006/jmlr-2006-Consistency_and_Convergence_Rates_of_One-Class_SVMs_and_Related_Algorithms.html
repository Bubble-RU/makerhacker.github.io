<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>23 jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-23" href="#">jmlr2006-23</a> knowledge-graph by maker-knowledge-mining</p><h1>23 jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</h1>
<br/><p>Source: <a title="jmlr-2006-23-pdf" href="http://jmlr.org/papers/volume7/vert06a/vert06a.pdf">pdf</a></p><p>Author: Régis Vert, Jean-Philippe Vert</p><p>Abstract: We determine the asymptotic behaviour of the function computed by support vector machines (SVM) and related algorithms that minimize a regularized empirical convex loss function in the reproducing kernel Hilbert space of the Gaussian RBF kernel, in the situation where the number of examples tends to inﬁnity, the bandwidth of the Gaussian kernel tends to 0, and the regularization parameter is held ﬁxed. Non-asymptotic convergence bounds to this limit in the L2 sense are provided, together with upper bounds on the classiﬁcation error that is shown to converge to the Bayes risk, therefore proving the Bayes-consistency of a variety of methods although the regularization term does not vanish. These results are particularly relevant to the one-class SVM, for which the regularization can not vanish by construction, and which is shown for the ﬁrst time to be a consistent density level set estimator. Keywords: regularization, Gaussian kernel RKHS, one-class SVM, convex loss functions, kernel density estimation</p><p>Reference: <a title="jmlr-2006-23-reference" href="../jmlr2006_reference/jmlr-2006-Consistency_and_Convergence_Rates_of_One-Class_SVMs_and_Related_Algorithms_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ert', 0.578), ('rd', 0.345), ('hp', 0.282), ('onsist', 0.221), ('onverg', 0.198), ('rx', 0.191), ('leb', 0.188), ('rkhs', 0.187), ('steinwart', 0.149), ('dx', 0.132), ('ep', 0.131), ('svm', 0.125), ('lgorithm', 0.119), ('lass', 0.102), ('lemm', 0.099), ('convex', 0.089), ('theorem', 0.083), ('deduc', 0.083), ('scovel', 0.081), ('foury', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="23-tfidf-1" href="./jmlr-2006-Consistency_and_Convergence_Rates_of_One-Class_SVMs_and_Related_Algorithms.html">23 jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</a></p>
<p>2 0.17721151 <a title="23-tfidf-2" href="./jmlr-2006-Universal_Kernels.html">93 jmlr-2006-Universal Kernels</a></p>
<p>3 0.11043954 <a title="23-tfidf-3" href="./jmlr-2006-Infinite-%CF%83_Limits_For_Tikhonov_Regularization.html">40 jmlr-2006-Infinite-σ Limits For Tikhonov Regularization</a></p>
<p>4 0.10194934 <a title="23-tfidf-4" href="./jmlr-2006-Lower_Bounds_and_Aggregation_in_Density_Estimation.html">58 jmlr-2006-Lower Bounds and Aggregation in Density Estimation</a></p>
<p>5 0.067618802 <a title="23-tfidf-5" href="./jmlr-2006-Manifold__Regularization%3A_A_Geometric_Framework_for_Learning_from_Labeled_and_Unlabeled_Examples.html">60 jmlr-2006-Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</a></p>
<p>6 0.066177964 <a title="23-tfidf-6" href="./jmlr-2006-QP_Algorithms_with_Guaranteed_Accuracy_and_Run_Time_for_Support_Vector_Machines.html">76 jmlr-2006-QP Algorithms with Guaranteed Accuracy and Run Time for Support Vector Machines</a></p>
<p>7 0.063480124 <a title="23-tfidf-7" href="./jmlr-2006-Estimation_of_Gradients_and_Coordinate_Covariation_in_Classification.html">29 jmlr-2006-Estimation of Gradients and Coordinate Covariation in Classification</a></p>
<p>8 0.058968157 <a title="23-tfidf-8" href="./jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">28 jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<p>9 0.055970926 <a title="23-tfidf-9" href="./jmlr-2006-Incremental_Support_Vector_Learning%3A_Analysis%2C_Implementation_and_Applications_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">38 jmlr-2006-Incremental Support Vector Learning: Analysis, Implementation and Applications     (Special Topic on Machine Learning and Optimization)</a></p>
<p>10 0.052583192 <a title="23-tfidf-10" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>11 0.052185182 <a title="23-tfidf-11" href="./jmlr-2006-Step_Size_Adaptation_in_Reproducing_Kernel_Hilbert_Space.html">86 jmlr-2006-Step Size Adaptation in Reproducing Kernel Hilbert Space</a></p>
<p>12 0.050500885 <a title="23-tfidf-12" href="./jmlr-2006-Accurate_Error_Bounds_for_the_Eigenvalues_of_the_Kernel_Matrix.html">9 jmlr-2006-Accurate Error Bounds for the Eigenvalues of the Kernel Matrix</a></p>
<p>13 0.048169147 <a title="23-tfidf-13" href="./jmlr-2006-Learning_Coordinate_Covariances_via_Gradients.html">45 jmlr-2006-Learning Coordinate Covariances via Gradients</a></p>
<p>14 0.046605647 <a title="23-tfidf-14" href="./jmlr-2006-Incremental_Algorithms_for_Hierarchical_Classification.html">37 jmlr-2006-Incremental Algorithms for Hierarchical Classification</a></p>
<p>15 0.046183556 <a title="23-tfidf-15" href="./jmlr-2006-Nonparametric_Quantile_Estimation.html">65 jmlr-2006-Nonparametric Quantile Estimation</a></p>
<p>16 0.045311339 <a title="23-tfidf-16" href="./jmlr-2006-Building_Support_Vector_Machines_with_Reduced_Classifier_Complexity_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">18 jmlr-2006-Building Support Vector Machines with Reduced Classifier Complexity     (Special Topic on Machine Learning and Optimization)</a></p>
<p>17 0.045116495 <a title="23-tfidf-17" href="./jmlr-2006-Consistency_of_Multiclass_Empirical_Risk_Minimization_Methods_Based_on_Convex_Loss.html">24 jmlr-2006-Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss</a></p>
<p>18 0.044925977 <a title="23-tfidf-18" href="./jmlr-2006-In_Search_of_Non-Gaussian_Components_of_a_High-Dimensional_Distribution.html">36 jmlr-2006-In Search of Non-Gaussian Components of a High-Dimensional Distribution</a></p>
<p>19 0.043729492 <a title="23-tfidf-19" href="./jmlr-2006-Stability_Properties_of_Empirical_Risk_Minimization_over_Donsker_Classes.html">84 jmlr-2006-Stability Properties of Empirical Risk Minimization over Donsker Classes</a></p>
<p>20 0.043038528 <a title="23-tfidf-20" href="./jmlr-2006-Large_Scale_Multiple_Kernel_Learning_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">43 jmlr-2006-Large Scale Multiple Kernel Learning     (Special Topic on Machine Learning and Optimization)</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.23), (1, 0.091), (2, -0.18), (3, 0.158), (4, 0.132), (5, 0.095), (6, 0.065), (7, -0.084), (8, -0.094), (9, 0.005), (10, -0.159), (11, -0.012), (12, -0.083), (13, 0.002), (14, 0.028), (15, 0.098), (16, -0.008), (17, 0.061), (18, -0.143), (19, 0.124), (20, -0.12), (21, -0.096), (22, -0.045), (23, -0.091), (24, -0.067), (25, -0.075), (26, 0.024), (27, -0.214), (28, 0.046), (29, -0.141), (30, -0.164), (31, -0.164), (32, -0.127), (33, -0.05), (34, -0.049), (35, 0.136), (36, 0.025), (37, -0.119), (38, 0.108), (39, -0.122), (40, 0.17), (41, -0.081), (42, 0.017), (43, -0.089), (44, -0.078), (45, -0.076), (46, -0.114), (47, 0.085), (48, 0.013), (49, 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92935538 <a title="23-lsi-1" href="./jmlr-2006-Consistency_and_Convergence_Rates_of_One-Class_SVMs_and_Related_Algorithms.html">23 jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</a></p>
<p>2 0.67198795 <a title="23-lsi-2" href="./jmlr-2006-Universal_Kernels.html">93 jmlr-2006-Universal Kernels</a></p>
<p>3 0.55546695 <a title="23-lsi-3" href="./jmlr-2006-Infinite-%CF%83_Limits_For_Tikhonov_Regularization.html">40 jmlr-2006-Infinite-σ Limits For Tikhonov Regularization</a></p>
<p>4 0.41869959 <a title="23-lsi-4" href="./jmlr-2006-Lower_Bounds_and_Aggregation_in_Density_Estimation.html">58 jmlr-2006-Lower Bounds and Aggregation in Density Estimation</a></p>
<p>5 0.32345536 <a title="23-lsi-5" href="./jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">28 jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<p>6 0.31026018 <a title="23-lsi-6" href="./jmlr-2006-QP_Algorithms_with_Guaranteed_Accuracy_and_Run_Time_for_Support_Vector_Machines.html">76 jmlr-2006-QP Algorithms with Guaranteed Accuracy and Run Time for Support Vector Machines</a></p>
<p>7 0.30371538 <a title="23-lsi-7" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>8 0.29815179 <a title="23-lsi-8" href="./jmlr-2006-Manifold__Regularization%3A_A_Geometric_Framework_for_Learning_from_Labeled_and_Unlabeled_Examples.html">60 jmlr-2006-Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</a></p>
<p>9 0.27722719 <a title="23-lsi-9" href="./jmlr-2006-Accurate_Error_Bounds_for_the_Eigenvalues_of_the_Kernel_Matrix.html">9 jmlr-2006-Accurate Error Bounds for the Eigenvalues of the Kernel Matrix</a></p>
<p>10 0.26642892 <a title="23-lsi-10" href="./jmlr-2006-Exact_1-Norm_Support_Vector_Machines_Via_Unconstrained_Convex_Differentiable_Minimization_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">31 jmlr-2006-Exact 1-Norm Support Vector Machines Via Unconstrained Convex Differentiable Minimization     (Special Topic on Machine Learning and Optimization)</a></p>
<p>11 0.26619637 <a title="23-lsi-11" href="./jmlr-2006-Incremental_Support_Vector_Learning%3A_Analysis%2C_Implementation_and_Applications_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">38 jmlr-2006-Incremental Support Vector Learning: Analysis, Implementation and Applications     (Special Topic on Machine Learning and Optimization)</a></p>
<p>12 0.26116219 <a title="23-lsi-12" href="./jmlr-2006-In_Search_of_Non-Gaussian_Components_of_a_High-Dimensional_Distribution.html">36 jmlr-2006-In Search of Non-Gaussian Components of a High-Dimensional Distribution</a></p>
<p>13 0.25922161 <a title="23-lsi-13" href="./jmlr-2006-A_Direct_Method_for_Building_Sparse_Kernel_Learning_Algorithms.html">1 jmlr-2006-A Direct Method for Building Sparse Kernel Learning Algorithms</a></p>
<p>14 0.25236848 <a title="23-lsi-14" href="./jmlr-2006-Estimation_of_Gradients_and_Coordinate_Covariation_in_Classification.html">29 jmlr-2006-Estimation of Gradients and Coordinate Covariation in Classification</a></p>
<p>15 0.24760002 <a title="23-lsi-15" href="./jmlr-2006-Kernels_on_Prolog_Proof_Trees%3A_Statistical_Learning_in_the_ILP_Setting_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">42 jmlr-2006-Kernels on Prolog Proof Trees: Statistical Learning in the ILP Setting     (Special Topic on Inductive Programming)</a></p>
<p>16 0.24504648 <a title="23-lsi-16" href="./jmlr-2006-Building_Support_Vector_Machines_with_Reduced_Classifier_Complexity_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">18 jmlr-2006-Building Support Vector Machines with Reduced Classifier Complexity     (Special Topic on Machine Learning and Optimization)</a></p>
<p>17 0.24278942 <a title="23-lsi-17" href="./jmlr-2006-Bounds_for_the_Loss_in_Probability_of_Correct_Classification_Under_Model_Based_Approximation.html">17 jmlr-2006-Bounds for the Loss in Probability of Correct Classification Under Model Based Approximation</a></p>
<p>18 0.23099071 <a title="23-lsi-18" href="./jmlr-2006-Consistency_of_Multiclass_Empirical_Risk_Minimization_Methods_Based_on_Convex_Loss.html">24 jmlr-2006-Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss</a></p>
<p>19 0.22511175 <a title="23-lsi-19" href="./jmlr-2006-Large_Scale_Multiple_Kernel_Learning_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">43 jmlr-2006-Large Scale Multiple Kernel Learning     (Special Topic on Machine Learning and Optimization)</a></p>
<p>20 0.2192862 <a title="23-lsi-20" href="./jmlr-2006-Active_Learning_in_Approximately_Linear_Regression_Based_on_Conditional_Expectation_of_Generalization_Error.html">11 jmlr-2006-Active Learning in Approximately Linear Regression Based on Conditional Expectation of Generalization Error</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(15, 0.026), (31, 0.022), (33, 0.053), (51, 0.04), (52, 0.278), (56, 0.011), (63, 0.056), (72, 0.051), (73, 0.165), (77, 0.073), (78, 0.017), (88, 0.032), (99, 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.726946 <a title="23-lda-1" href="./jmlr-2006-Consistency_and_Convergence_Rates_of_One-Class_SVMs_and_Related_Algorithms.html">23 jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</a></p>
<p>2 0.59271568 <a title="23-lda-2" href="./jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">56 jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>3 0.58758777 <a title="23-lda-3" href="./jmlr-2006-Lower_Bounds_and_Aggregation_in_Density_Estimation.html">58 jmlr-2006-Lower Bounds and Aggregation in Density Estimation</a></p>
<p>4 0.58754408 <a title="23-lda-4" href="./jmlr-2006-Some_Theory_for_Generalized_Boosting_Algorithms.html">82 jmlr-2006-Some Theory for Generalized Boosting Algorithms</a></p>
<p>5 0.58093798 <a title="23-lda-5" href="./jmlr-2006-Efficient_Learning_of_Label_Ranking_by_Soft_Projections_onto_Polyhedra_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">26 jmlr-2006-Efficient Learning of Label Ranking by Soft Projections onto Polyhedra     (Special Topic on Machine Learning and Optimization)</a></p>
<p>6 0.57517165 <a title="23-lda-6" href="./jmlr-2006-Maximum-Gain_Working_Set_Selection_for_SVMs_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">61 jmlr-2006-Maximum-Gain Working Set Selection for SVMs     (Special Topic on Machine Learning and Optimization)</a></p>
<p>7 0.57392734 <a title="23-lda-7" href="./jmlr-2006-Parallel_Software_for_Training_Large_Scale_Support_Vector_Machines_on_Multiprocessor_Systems_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">72 jmlr-2006-Parallel Software for Training Large Scale Support Vector Machines on Multiprocessor Systems     (Special Topic on Machine Learning and Optimization)</a></p>
<p>8 0.57293314 <a title="23-lda-8" href="./jmlr-2006-On_Model_Selection_Consistency_of_Lasso.html">66 jmlr-2006-On Model Selection Consistency of Lasso</a></p>
<p>9 0.57101983 <a title="23-lda-9" href="./jmlr-2006-Learning_Minimum_Volume_Sets.html">48 jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>10 0.57041818 <a title="23-lda-10" href="./jmlr-2006-Learning_a_Hidden_Hypergraph.html">53 jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>11 0.56784469 <a title="23-lda-11" href="./jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">41 jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>12 0.56571078 <a title="23-lda-12" href="./jmlr-2006-Structured_Prediction%2C_Dual_Extragradient_and_Bregman_Projections_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">89 jmlr-2006-Structured Prediction, Dual Extragradient and Bregman Projections     (Special Topic on Machine Learning and Optimization)</a></p>
<p>13 0.56044376 <a title="23-lda-13" href="./jmlr-2006-Building_Support_Vector_Machines_with_Reduced_Classifier_Complexity_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">18 jmlr-2006-Building Support Vector Machines with Reduced Classifier Complexity     (Special Topic on Machine Learning and Optimization)</a></p>
<p>14 0.56027752 <a title="23-lda-14" href="./jmlr-2006-Consistency_of_Multiclass_Empirical_Risk_Minimization_Methods_Based_on_Convex_Loss.html">24 jmlr-2006-Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss</a></p>
<p>15 0.55605459 <a title="23-lda-15" href="./jmlr-2006-Streamwise_Feature_Selection.html">88 jmlr-2006-Streamwise Feature Selection</a></p>
<p>16 0.55122149 <a title="23-lda-16" href="./jmlr-2006-Step_Size_Adaptation_in_Reproducing_Kernel_Hilbert_Space.html">86 jmlr-2006-Step Size Adaptation in Reproducing Kernel Hilbert Space</a></p>
<p>17 0.55028814 <a title="23-lda-17" href="./jmlr-2006-Fast_SDP_Relaxations_of_Graph_Cut_Clustering%2C_Transduction%2C_and_Other_Combinatorial_Problems_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">33 jmlr-2006-Fast SDP Relaxations of Graph Cut Clustering, Transduction, and Other Combinatorial Problems     (Special Topic on Machine Learning and Optimization)</a></p>
<p>18 0.5500474 <a title="23-lda-18" href="./jmlr-2006-Stability_Properties_of_Empirical_Risk_Minimization_over_Donsker_Classes.html">84 jmlr-2006-Stability Properties of Empirical Risk Minimization over Donsker Classes</a></p>
<p>19 0.54993469 <a title="23-lda-19" href="./jmlr-2006-An_Efficient_Implementation_of_an_Active_Set_Method_for_SVMs%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">14 jmlr-2006-An Efficient Implementation of an Active Set Method for SVMs    (Special Topic on Machine Learning and Optimization)</a></p>
<p>20 0.54906535 <a title="23-lda-20" href="./jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">28 jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
