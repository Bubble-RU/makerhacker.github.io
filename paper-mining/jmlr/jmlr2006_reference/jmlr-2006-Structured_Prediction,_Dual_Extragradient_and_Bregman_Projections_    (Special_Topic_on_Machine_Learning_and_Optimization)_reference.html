<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>89 jmlr-2006-Structured Prediction, Dual Extragradient and Bregman Projections     (Special Topic on Machine Learning and Optimization)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-89" href="../jmlr2006/jmlr-2006-Structured_Prediction%2C_Dual_Extragradient_and_Bregman_Projections_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr2006-89</a> <a title="jmlr-2006-89-reference" href="#">jmlr2006-89-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>89 jmlr-2006-Structured Prediction, Dual Extragradient and Bregman Projections     (Special Topic on Machine Learning and Optimization)</h1>
<br/><p>Source: <a title="jmlr-2006-89-pdf" href="http://jmlr.org/papers/volume7/taskar06a/taskar06a.pdf">pdf</a></p><p>Author: Ben Taskar, Simon Lacoste-Julien, Michael I. Jordan</p><p>Abstract: We present a simple and scalable algorithm for maximum-margin estimation of structured output models, including an important class of Markov networks and combinatorial models. We formulate the estimation problem as a convex-concave saddle-point problem that allows us to use simple projection methods based on the dual extragradient algorithm (Nesterov, 2003). The projection step can be solved using dynamic programming or combinatorial algorithms for min-cost convex ﬂow, depending on the structure of the problem. We show that this approach provides a memoryefﬁcient alternative to formulations based on reductions to a quadratic program (QP). We analyze the convergence of the method and present experiments on two very different structured prediction tasks: 3D image segmentation and word alignment, illustrating the favorable scaling properties of our algorithm.1 Keywords: Markov networks, large-margin methods, structured prediction, extragradient, Bregman projections</p><br/>
<h2>reference text</h2><p>Yasemin Altun, Ioannis Tsochantaridis, and Thomas Hofmann. Hidden Markov support vector machines. In International Conference on Machine Learning. ACM Press, New York, 2003. Drago Anguelov, Ben Taskar, Vassil Chatalbashev, Daphne Koller, Dinkar Gupta, Geremey Heitz, and Andrew Y. Ng. Discriminative learning of Markov random ﬁelds for segmentation of 3D scan data. In International Conference on Computer Vision and Pattern Recognition. IEEE Computer Society, Washington, DC, 2005. Pierre Baldi, Jianlin Cheng, and Alessandro Vullo. Large-scale prediction of disulphide bond connectivity. In Advances in Neural Information Processing Systems. MIT Press, Cambridge, MA, 2005. Peter L. Bartlett, Michael Collins, Ben Taskar, and David McAllester. Exponentiated gradient algorithms for large-margin structured classiﬁcation. In Advances in Neural Information Processing Systems. MIT Press, Cambridge, MA, 2005. Serge Belongie, Jitendra Malik, and Jan Puzicha. Shape matching and object recognition using shape contexts. IEEE Transactions on Pattern Analysis and Machince Intelligence, 24:509–522, 2002. Dimitri P. Bertsekas. Network Optimization: Continuous and Discrete Models. Athena Scientiﬁc, Belmont, MA, 1998. 1650  S TRUCTURED P REDICTION , D UAL E XTRAGRADIENT AND B REGMAN P ROJECTIONS  Dimitri P. Bertsekas, Lazaros C. Polymenakos, and Paul Tseng. An ε-relaxation method for separable convex cost network ﬂow problems. SIAM Journal on Optimization, 7(3):853–870, 1997. Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, 2004. Chandra Chekuri, Sanjeev Khanna, Joseph Naor, and Leonid Zosin. Approximation algorithms for the metric labeling problem via a new linear programming formulation. In Proceedings of the 12th Annual ACM-SIAM Symposium on Discrete Algorithms, Washington, DC, 2001. Chandra Chekuri, Sanjeev Khanna, Joseph Naor, and Leonid Zosin. A linear programming formulation and approximation algorithms for the metric labeling problem. SIAM Journal on Discrete Mathematics, 18(3):606–635, 2005. Michael Collins. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Philadelphia, PA, 2002. Richard Durbin, Sean Eddy, Anders Krogh, and Graeme Mitchison. Biological Sequence Analysis. Cambridge University Press, UK, 1998. D. M. Greig, B. T. Porteous, and A. H. Seheult. Exact maximum a posteriori estimation for binary images. Journal of the Royal Statistical Society B, 51:271–279, 1989. Francesca Guerriero and Paul Tseng. Implementation and test of auction methods for solving generalized network ﬂow problems with separable convex cost. Journal of Optimization Theory and Applications, 115:113–144, 2002. Trevor Hastie, Saharon Rosset, Robert Tibshirani, and J. Zhu. The entire regularization path for the support vector machine. Journal of Machine Learning Research, 5:1391–1415, 2004. Bingsheng He and Li-Zhi Liao. Improvements of some projection methods for monotone nonlinear variational inequalities. Journal of Optimization Theory and Applications, 112:111–128, 2002. Mark Jerrum and Alistair Sinclair. Polynomial-time approximation algorithms for the Ising model. SIAM Journal on Computing, 22:1087–1116, 1993. Vladimir Kolmogorov and Martin Wainwright. On the optimality of tree-reweighted max-product message passing. In Uncertainty in Artiﬁcial Intelligence: Proceedings of the Twenty-First Conference. Morgan Kaufmann, San Mateo, CA, 2005. Vladimir Kolmogorov and Ramin Zabih. What energy functions can be minimized using graph cuts? IEEE Transactions on Pattern Analysis and Machince Intelligence, 26:147–159, 2004. G. M. Korpelevich. The extragradient method for ﬁnding saddle points and other problems. Ekonomika i Matematicheskie Metody, 12:747–756, 1976. Sanjiv Kumar and Martial Hebert. Discriminative ﬁelds for modeling spatial dependencies in natural images. In Advances in Neural Information Processing Systems. MIT Press, Cambridge, MA, 2004. 1651  TASKAR , L ACOSTE -J ULIEN AND J ORDAN  Simon Lacoste-Julien, Ben Taskar, Dan Klein, and Michael I. Jordan. Word alignment via quadratic assignment. In Human Language Technology–North American Association for Computational Linguistics, New York, NY, 2006. John Lafferty, Andrew McCallum, and Fernando Pereira. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In International Conference on Machine Learning. Morgan Kaufmann, San Mateo, CA, 2001. John Lafferty, Xiaojin Zhu, and Yan Liu. Kernel conditional random ﬁelds: Representation and clique selection. In International Conference on Machine Learning. ACM Press, New York, 2004. Yan LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86:2278–2324, 1998. Christopher Manning and Hinrich Sch¨ tze. Foundations of Statistical Natural Language Processu ing. MIT Press, Cambridge, MA, 1999. Evgeny Matusov, Richard Zens, and Herman Ney. Symmetric word alignments for statistical machine translation. In Proceedings of the Twentieth International Conference on Computational Linguistics, Geneva, Switzerland, 2004. Rada Mihalcea and Ted Pedersen. An evaluation exercise for word alignment. In Human Language Technology–North American Association for Computational Linguistics, Edmonton, Canada, 2003. Yurii Nesterov. Dual extrapolation and its application for solving variational inequalites and related problems. Technical report, CORE, Catholic University of Louvain, 2003. Franz Och and Herman Ney. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–52, 2003. John C. Platt. Fast training of support vector machines using sequential minimal optimization. In B. Schlkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods—Support Vector Learning, pages 185–208. MIT Press, Cambridge, MA, 1999. Saharon Rosset. Tracking curved regularized optimization solution paths. In Advances in Neural Information Processing Systems. MIT Press, Cambridge, MA, 2004. Alexander Schrijver. Combinatorial Optimization: Polyhedra and Efﬁciency. Springer, Berlin, 2003. Ben Taskar. Learning Structured Prediction Models: A Large Margin Approach. PhD thesis, Stanford University, 2004. Ben Taskar, Vassil Chatalbashev, and Daphne Koller. Learning associative Markov networks. In International Conference on Machine Learning. ACM Press, New York, 2004a. Ben Taskar, Carlos Guestrin, and Daphne Koller. Max margin Markov networks. In Advances in Neural Information Processing Systems. MIT Press, Cambridge, MA, 2004b. 1652  S TRUCTURED P REDICTION , D UAL E XTRAGRADIENT AND B REGMAN P ROJECTIONS  Ben Taskar, Vassil Chatalbashev, Daphne Koller, and Carlos Guestrin. Learning structured prediction models: a large margin approach. In International Conference on Machine Learning. ACM Press, New York, 2005a. Ben Taskar, Simon Lacoste-Julien, and Dan Klein. A discriminative matching approach to word alignment. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Vancouver, CA, 2005b. Ben Taskar, Simon Lacoste-Julien, and Michael I. Jordan. Structured prediction via the extragradient method. In Advances in Neural Information Processing Systems. MIT Press, Cambridge, MA, 2006. Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. Support vector machine learning for interdependent and structured output spaces. In International Conference on Machine Learning. ACM Press, New York, 2004. Leslie G. Valiant. The complexity of computing the permanent. Theoretical Computer Science, 8: 189–201, 1979. Martin Wainwright, Tommi Jaakkola, and Alan Willsky. Map estimation via agreement on (hyper)trees: Message-passing and linear programming approaches. In Proceedings of the Allerton Conference on Communication, Control and Computing, Allerton, IL, 2002.  1653</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
