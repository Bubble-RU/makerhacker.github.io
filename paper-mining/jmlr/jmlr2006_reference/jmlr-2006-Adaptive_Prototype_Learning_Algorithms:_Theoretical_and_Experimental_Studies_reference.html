<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>13 jmlr-2006-Adaptive Prototype Learning Algorithms: Theoretical and Experimental Studies</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-13" href="../jmlr2006/jmlr-2006-Adaptive_Prototype_Learning_Algorithms%3A_Theoretical_and_Experimental_Studies.html">jmlr2006-13</a> <a title="jmlr-2006-13-reference" href="#">jmlr2006-13-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>13 jmlr-2006-Adaptive Prototype Learning Algorithms: Theoretical and Experimental Studies</h1>
<br/><p>Source: <a title="jmlr-2006-13-pdf" href="http://jmlr.org/papers/volume7/chang06a/chang06a.pdf">pdf</a></p><p>Author: Fu Chang, Chin-Chin Lin, Chi-Jen Lu</p><p>Abstract: In this paper, we propose a number of adaptive prototype learning (APL) algorithms. They employ the same algorithmic scheme to determine the number and location of prototypes, but differ in the use of samples or the weighted averages of samples as prototypes, and also in the assumption of distance measures. To understand these algorithms from a theoretical viewpoint, we address their convergence properties, as well as their consistency under certain conditions. We also present a soft version of APL, in which a non-zero training error is allowed in order to enhance the generalization power of the resultant classifier. Applying the proposed algorithms to twelve UCI benchmark data sets, we demonstrate that they outperform many instance-based learning algorithms, the k-nearest neighbor rule, and support vector machines in terms of average test accuracy. Keywords: adaptive prototype learning, cluster-based prototypes, consistency, instance-based prototype, pattern classification 1</p><br/>
<h2>reference text</h2><p>P. Bartlett and J. Shaw-Taylor. Generalization performance of support vector machines and other pattern classifiers. In B. Schölkopf, C. Burges, and A. J. Smola, editors, Advances in Kernel Methods: Support Vector Learning. MIT Press, 1999. J. C. Bezdek, Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum, New York, 1981. L. Bottou, C. Cortes, J. Denker, H. Drucker, I. Guyon, L. Jackel, Y. LeCun, U. Muller, E. Sackinger, P. Simard, and V. Vapnik. Comparison of classifier methods: A case study in handwriting digit recognition. In Proc. Int. Conf. Pattern Recognition, pages 77–87, 1994. 2146  ADAPTIVE PROTOTYPE LEARNING ALGORITHMS  H. Brighton and C. Mellish. Advances in instance selection for instance-based learning algorithms. In Data Mining and Knowledge Discovery, 6:153–172, 2002. C. Cortes and V. Vapnik. Support vector machines. In Machine Learning, 20:1-25, 1995. T. Cover and P. Hart. Nearest neighbor pattern classification. In IEEE Trans. Information Theory, 13:21-27, 1967. N. Cristianini and J. Shawe-Taylor. An introduction to Support Vector Machines and other kernel-based learning methods. Cambridge University Press, 2000. F. Devi and M. Murty. An incremental prototype set building technique. In Pattern Recognition, 35:505–513, 2002. L. Devroye and L. Györfi. Nonparametric Density Estimation: The L1 View. John Wiley, New York, 1985. L. Devroye, L. Györfi, A. Krzyżak, and G. Lugosi. On the strong consistency of nearest neighbor regression function estimates. In Annals of Statistics, 22:1371-1385, 1994. L. Devroye, L Györfi, and G. Lugosi. A Probabilistic Theory of Pattern Recognition. Springer, New York, 1996. E. Fix and J. L. Hodges. Discriminatory analysis. Nonparametric discrimination: Consistency properties. Technical Report 4, Project Number 21-49-004, USAF School of Aviation Medicine. Randolph Field, Texas, 1951. E. Fix and J. L. Hodges. Discriminatory analysis: small sample performance. Technical Report 11, Project Number 21-49-004, USAF School of Aviation Medicine. Randolph Field, Texas, 1952. E. Fix and J. L. Hodges. Discriminatory analysis. Nonparametric discrimination: Consistency properties. In B. Dasarathy, editor, Nearest Neighbor Pattern Classification Techniques, pages 32-39, IEEE Computer Society Press, Los Alamitos, 1991. E. Fix and J. L. Hodges. Discriminatory analysis: small sample performance. In B. Dasarathy, editor, Nearest Neighbor Pattern Classification Techniques, pages 40-56, IEEE Computer Society Press, Los Alamitos, 1991. F. Girosi. An equivalence between sparse approximation and support vector machines. In Neural Computation, 10(6):1455-1481, 1998. P. Hart. The condensed nearest neighbor rule. In IEEE Trans. Information Theory, 14:515-516, 1968. F. Höppner, F. Klawonn, R. Kruse, and T. Runkler. In Fuzzy Cluster Analysis: Methods for Classification, Data Analysis and Image Recognition. John Wiley & Sons, New York, 1999. C.-W. Hsu and C.-J. Lin. A comparison of methods for multiclass support vector machines. In IEEE Transactions on Neural Networks, 13(2):415-425, 2002. D.-W. Kim, K.Y. Lee, D. Lee, K. H. Lee. Evaluation of the performance of clustering algorithms in kernel-induced feature space. In Pattern Recognition, 38:607-611, 2005. S. Knerr, L. Personnaz, and G. Dreyfus. Single-layer learning revisited: A stepwise procedure for building and training a neural network. In J. Fogelman, editor, Neurocomputing: Algorithms, Architectures and Applications, Springer-Verlag, New York, 1990. T. Kohonen. Self-Organization and Associated Memory. Springer-Verlag, Berlin, 1988. 2147  CHANG, LIN AND LU  T. Kohonen. Statistical pattern recognition revisited. In R. Eckmiller, editor, Advanced Neural Computers, North-Holland, Amsterdam, pages 137-144, 1990. Y. Linde, A. Buzo, and R. Gray. An algorithm for vector quantizer design. In Pattern Recognition, 19:84-95, 1980. S. Lloyd. Least squares quantization in PCM. In IEEE Trans. Information Theory, 28:129-137, 1982. J. Max. Quantizing for minimum distortion. In IEEE Trans. Information Theory, 6:7-12, 1960. T. Mercer. Functions of positive and negative type and their connection with the theory of integral equations. In Philosophical Transactions of the Royal Society of London, Series A, 209:415-446, 1909. D. J. Newman, S. Hettich, C. L. Blake, and C. J. Merz. UCI Repository of machine learning databases, Irvine, CA: University of California, Department of Information and Computer Science, 1998. [http://www.ics.uci.edu/~mlearn/ MLRepository.html]. J. C. Platt, N. Cristianini, and J. Shawe-Taylor. Large margin DAG’s for multiclass classification. In Advances in Neural Information Processing Systems, 12:547-553, MIT Press, Cambridge, 2000. S. Salzberg. A nearest hyperrectangle learning method. In Machine Learning, 6:251-276, 1991. B. Schölkopf, C. J. C. Burges, and A. J. Smola. In Advances in Kernel Methods — Support Vector Learning. MIT Press, Cambridge, MA, 1999. C. Stone. Consistent nonparametric regression. In Annals of Statistics, 5:595-645, 1977. V. Vapnik and A. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. In Theory of Probability and Its Applications, 16:264-280, 1971. V. Vapnik and A. Chervonenkis. Ordered risk minimization I. In Automation and Remote Control, 35:1226-1235, 1974. V. Vapnik and A. Chervonenkis. Ordered risk minimization II. In Automation and Remote Control, 35:1403-1412, 1974. V. Vapnik. The Nature of Statistical Learning Theory. Springer Verlag, New York, 1995. D. R. Wilson and T. R. Martinez. Reduction techniques with instance-based learning algorithms. In Machine Learning, 38:257–286, 2000. Z.-D. Wu, W.-X. Xie and J.-P. Yu. Fuzzy c-means clustering algorithm based on kernel method. In Fifth Intern. Conf. Computational Intelligence and Multimedia Applications, pages 1–6, 2003. L. Zhao. Exponential bounds of mean error for the nearest neighbor estimates of regression functions. In Journal of Multivariate Analysis, 21:168-178, 1987.  2148</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
