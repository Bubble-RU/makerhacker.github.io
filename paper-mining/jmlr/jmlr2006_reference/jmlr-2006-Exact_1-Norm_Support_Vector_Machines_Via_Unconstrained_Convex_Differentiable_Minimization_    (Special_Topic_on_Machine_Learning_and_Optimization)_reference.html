<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>31 jmlr-2006-Exact 1-Norm Support Vector Machines Via Unconstrained Convex Differentiable Minimization     (Special Topic on Machine Learning and Optimization)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-31" href="../jmlr2006/jmlr-2006-Exact_1-Norm_Support_Vector_Machines_Via_Unconstrained_Convex_Differentiable_Minimization_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr2006-31</a> <a title="jmlr-2006-31-reference" href="#">jmlr2006-31-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>31 jmlr-2006-Exact 1-Norm Support Vector Machines Via Unconstrained Convex Differentiable Minimization     (Special Topic on Machine Learning and Optimization)</h1>
<br/><p>Source: <a title="jmlr-2006-31-pdf" href="http://jmlr.org/papers/volume7/mangasarian06a/mangasarian06a.pdf">pdf</a></p><p>Author: Olvi L. Mangasarian</p><p>Abstract: Support vector machines utilizing the 1-norm, typically set up as linear programs (Mangasarian, 2000; Bradley and Mangasarian, 1998), are formulated here as a completely unconstrained minimization of a convex differentiable piecewise-quadratic objective function in the dual space. The objective function, which has a Lipschitz continuous gradient and contains only one additional ﬁnite parameter, can be minimized by a generalized Newton method and leads to an exact solution of the support vector machine problem. The approach here is based on a formulation of a very general linear program as an unconstrained minimization problem and its application to support vector machine classiﬁcation problems. The present approach which generalizes both (Mangasarian, 2004) and (Fung and Mangasarian, 2004) is also applied to nonlinear approximation where a minimal number of nonlinear kernel functions are utilized to approximate a function from a given number of function values.</p><br/>
<h2>reference text</h2><p>D. P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, Belmont, MA, second edition, 1999. P. S. Bradley and O. L. Mangasarian. Feature selection via concave minimization and support vector machines. In J. Shavlik, editor, Machine Learning Proceedings of the Fifteenth International Conference(ICML ’98), pages 82–90, San Francisco, California, 1998. Morgan Kaufmann. ftp://ftp.cs.wisc.edu/math-prog/tech-reports/98-03.ps. G. B. Dantzig. Linear Programming and Extensions. Princeton University Press, Princeton, New Jersey, 1963. F. Facchinei. Minimization of SC1 functions and the Maratos effect. Operations Research Letters, 17:131–137, 1995. A. V. Fiacco and G. P. McCormick. Nonlinear Programming: Sequential Unconstrained Minimization Techniques. John Wiley & Sons, New York, NY, 1968. M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval Research Logistics Quarterly, 3:95–110, 1956. G. Fung and O. L. Mangasarian. A feature selection Newton method for support vector machine classiﬁcation. Computational Optimization and Applications, 28(2):185–202, July 2004. ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/02-03.ps. G. Fung, O. L. Mangasarian, and J. Shavlik. Knowledge-based support vector machine classiﬁers. In Suzanna Becker, Sebastian Thrun, and Klaus Obermayer, editors, Advances in Neural Information Processing Systems 15, pages 521–528. MIT Press, Cambridge, MA, October 2003. ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/01-09.ps. 1528  SVM-1 AS U NCONSTRAINED M INIMIZATION  J.-B. Hiriart-Urruty, J. J. Strodiot, and V. H. Nguyen. Generalized hessian matrix and second-order optimality conditions for problems with CL1 data. Applied Mathematics and Optimization, 11: 43–56, 1984. ILOG CPLEX 9.0 User’s Manual. http://www.ilog.com/products/cplex/.  ILOG,  Incline  Village,  Nevada,  2003.  Y.-J. Lee and O. L. Mangasarian. RSVM: Reduced support vector machines. In Proceedings of the First SIAM International Conference on Data Mining, Chicago, April 5-7, 2001, CD-ROM, 2001. ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/00-07.ps. S. Lucidi. A new result in the theory and computation of the least-norm solution of a linear program. Journal of Optimization Theory and Applications, 55:103–117, 1987. O. L. Mangasarian. Nonlinear Programming. SIAM, Philadelphia, PA, 1994. O. L. Mangasarian. Parallel gradient distribution in unconstrained optimization. SIAM Journal on Control and Optimization, 33(6):1916–1925, 1995. ftp://ftp.cs.wisc.edu/techreports/reports/1993/tr1145.ps. O. L. Mangasarian. A ﬁnite Newton method for classiﬁcation problems. Technical Report 01-11, Data Mining Institute, Computer Sciences Department, University of Wisconsin, Madison, Wisconsin, December 2001. ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/01-11.ps.Optimization Methods and Software 17, 2002, 913-929. O. L. Mangasarian. A Newton method for linear programming. Journal of Optimization Theory and Applications, 121:1–18, 2004. ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/02-02.ps. O. L. Mangasarian. Knowledge-based linear programming. SIAM Journal on Optimization, 15: 375–382, 2005. ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/03-04.ps. O. L. Mangasarian. Arbitrary-norm separating plane. Operations Research Letters, 24:15–23, 1999. ftp://ftp.cs.wisc.edu/math-prog/tech-reports/97-07r.ps. O. L. Mangasarian. Generalized support vector machines. In A. Smola, P. Bartlett, B. Sch¨ lkopf, o and D. Schuurmans, editors, Advances in Large Margin Classiﬁers, pages 135–146, Cambridge, MA, 2000. MIT Press. ftp://ftp.cs.wisc.edu/math-prog/tech-reports/98-14.ps. O. L. Mangasarian and R. R. Meyer. Nonlinear perturbation of linear programs. SIAM Journal on Control and Optimization, 17(6):745–752, November 1979. O. L. Mangasarian, J. W. Shavlik, and E. W. Wild. Knowledge-based kernel approximation. Journal of Machine Learning Research, 5:1127–1141, 2004. ftp://ftp.cs.wisc.edu/pub/dmi/techreports/03-05.ps. MATLAB. User’s Guide. http://www.mathworks.com. P.  The MathWorks, Inc., Natick, MA 01760, 1994-2001.  M. Murphy and D. W. Aha. UCI www.ics.uci.edu/∼mlearn/MLRepository.html. 1529  machine  learning  repository,  1992.  M ANGASARIAN  S. Odewahn, E. Stockwell, R. Pennington, R. Humphreys, and W. Zumach. Automated star/galaxy discrimination with neural networks. Astronomical Journal, 103(1):318–331, 1992. B. Sch¨ lkopf and A. Smola. Learning with Kernels. MIT Press, Cambridge, MA, 2002. o V. N. Vapnik. The Nature of Statistical Learning Theory. Springer, New York, second edition, 2000. J. Zhu, S. Rosset, T. Hastie, and R. Tibshirani. 1-Norm support vector machines. In Sebastian Thrun, Lawrence K. Saul, and Bernhard Sch¨ lkopf, editors, Advances in Neural Information Processing o Systems 16–NIPS2003. MIT Press, 2004.  1530</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
