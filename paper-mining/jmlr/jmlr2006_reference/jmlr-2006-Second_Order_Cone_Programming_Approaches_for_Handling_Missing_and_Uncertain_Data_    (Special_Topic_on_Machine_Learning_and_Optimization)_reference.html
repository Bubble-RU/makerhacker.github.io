<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>79 jmlr-2006-Second Order Cone Programming Approaches for Handling Missing and Uncertain Data     (Special Topic on Machine Learning and Optimization)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-79" href="../jmlr2006/jmlr-2006-Second_Order_Cone_Programming_Approaches_for_Handling_Missing_and_Uncertain_Data_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr2006-79</a> <a title="jmlr-2006-79-reference" href="#">jmlr2006-79-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>79 jmlr-2006-Second Order Cone Programming Approaches for Handling Missing and Uncertain Data     (Special Topic on Machine Learning and Optimization)</h1>
<br/><p>Source: <a title="jmlr-2006-79-pdf" href="http://jmlr.org/papers/volume7/shivaswamy06a/shivaswamy06a.pdf">pdf</a></p><p>Author: Pannagadatta K. Shivaswamy, Chiranjib Bhattacharyya, Alexander J. Smola</p><p>Abstract: We propose a novel second order cone programming formulation for designing robust classiﬁers which can handle uncertainty in observations. Similar formulations are also derived for designing regression functions which are robust to uncertainties in the regression setting. The proposed formulations are independent of the underlying distribution, requiring only the existence of second order moments. These formulations are then specialized to the case of missing values in observations for both classiﬁcation and regression problems. Experiments show that the proposed formulations outperform imputation.</p><br/>
<h2>reference text</h2><p>A. Ben-Tal and A. Nemirovski. Robust convex optimization. Math. Oper. Res., 23(4):769–805, 1998. A. Ben-Tal and A. Nemirovski. Lectures on Modern Convex Optimization: Analysis, Algorithms, and Engineering Applications. SIAM, 2001. K. P. Bennett and O. L. Mangasarian. Multicategory separation via linear programming. Optimization Methods and Software, 3:27 – 39, 1993. C. Bhattacharyya, L. R. Grate, M. I. Jordan, L. El Ghaoui, and Saira I. Mian. Robust sparse hyperplane classiﬁers: application to uncertain molecular proﬁling data. Journal of Computational Biology, 11(6):1073 – 1089, 2004a. C. Bhattacharyya, K. S. Pannagadatta, and A. J. Smola. A second order cone programming formulation for classifying missing data. In Advances in Neural Information Processing Systems (NIPS 17), 2004b. J. Bi and T. Zhang. Support vector classiﬁcation with input data uncertainty. In Lawrence K. Saul, Yair Weiss, and L´ on Bottou, editors, Advances in Neural Information Processing Systems 17, e 2004. C. M. Bishop. Training with noise is equivalent to Tikhonov regularization. Neural Computation, 7:108 – 116, 1995. C. L. Blake and C. J. Merz. UCI repository of machine learning databases, 1998. http://www.ics.uci.edu/∼mlearn/MLRepository.html.  URL  S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004. G. Calaﬁore and M. C. Campi. The scenario approach to robust control design. Technical report, Universita di Brescia, 2004. submitted. S. Chandrasekaran, G. H. Golub, M. Gu, and A. H. Sayed. Parameter Estimation in the Presence of Bounded Data Uncertainties. SIAM J. Matrix Anal. Appl., 19(1):235–252, 1998. M. Collins. Discriminative training methods for hidden markov models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2002. C. Cortes and V. Vapnik. Support vector networks. Machine Learning, 20:273–297, 1995. 1312  SOCP A PPROACHES FOR M ISSING AND U NCERTAIN DATA  D. Pucci de Farias and B. Van Roy. On constraint sampling in the linear programming approach to approximate dynamic programming. Mathematics of Operations Research, 29(3):462–478, 2004. A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society B, 39(1):1 – 22, 1977. L. El Ghaoui and H. Lebret. Robust solutions to least-squares problems with uncertain data. SIAM J. Matrix Anal. Appl., 18(4):1035–1064, 1997. G. Fung, O. L. Mangasarian, and J. W. Shavlik. Knowledge-based support vector machine classiﬁers. In Advances in Neural Information Processing Systems 15, volume 15. MIT Press, 2002. T. Graepel and R. Herbrich. Invariant pattern recognition by semideﬁnite programming machines. In Sebastian Thrun, Lawrence Saul, and Bernhard Sch¨ lkopf, editors, Advances in Neural Inforo mation Processing Systems 16. MIT Press, 2004. P. J. Huber. Robust statistics. John Wiley, 1982. G. R. G. Lanckriet, L. E. Ghaoui, C. Bhattacharrya, and M. I. Jordan. A robust minimax approach to classiﬁcation. Journal of Machine Learning Research, 3:555–582, 2002. Q. V. Le, T. Sears, and A. J. Smola. Nonparametric quantile regression. Technical report, National ICT Australia, June 2005. Available at http://sml.nicta.com.au/∼quoc.le. M. S. Lobo, L. Vandenberghe, S. Boyd, and H. Lebret. Applications of second-order cone programming. Linear Algebra and its Applications, 284(1 - 3):193 – 228, 1998. A. W. Marshall and I. Olkin. Multivariate chebyshev inequalities. Annals of Mathematical Statistics, 31(4):1001–1014, 1960. J. Mercer. Functions of positive and negative type and their connection with the theory of integral equations. Philosophical Transactions of the Royal Society, London, A 209:415 – 446, 1909. Y. Nesterov and A. Nemirovskii. Interior Point Algorithms in Convex Programming. Number 13 in Studies in Applied Mathematics. SIAM, Philadelphia, 1993. G. R¨ tsch, S. Mika, and A. J. Smola. Adapting codes and embeddings for polychotomies. In Neural a Information Processing Systems, volume 15. MIT Press, 2002. T. Schneider. Analysis of incomplete climate data: Estimation of mean values and covariance matrices and imputation of missing values. Journal of Climate, 14:853 – 871, 2001. B. Sch¨ lkopf and A. Smola. Learning with Kernels. MIT Press, Cambridge, MA, 2002. o J. F. Sturm. Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones. Optimization Methods and Software, 11/12(1 - 4):625 – 653, 1999. B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In Sebastian Thrun, Lawrence Saul, and Bernhard Sch¨ lkopf, editors, Advances in Neural Information Processing Systems 16, o 2003. 1313  S HIVASWAMY, B HATTACHARYYA AND S MOLA  V. Vapnik, S. Golowich, and A. J. Smola. Support vector method for function approximation, regression estimation, and signal processing. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, Advances in Neural Information Processing Systems 9, pages 281 – 287, Cambridge, MA, 1997. MIT Press. C. K. I. Williams. Prediction with Gaussian processes: From linear regression to linear prediction and beyond. In M. I. Jordan, editor, Learning and Inference in Graphical Models, pages 599 – 621. Kluwer Academic, 1998.  1314</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
