<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>60 jmlr-2006-Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-60" href="../jmlr2006/jmlr-2006-Manifold__Regularization%3A_A_Geometric_Framework_for_Learning_from_Labeled_and_Unlabeled_Examples.html">jmlr2006-60</a> <a title="jmlr-2006-60-reference" href="#">jmlr2006-60-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>60 jmlr-2006-Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</h1>
<br/><p>Source: <a title="jmlr-2006-60-pdf" href="http://jmlr.org/papers/volume7/belkin06a/belkin06a.pdf">pdf</a></p><p>Author: Mikhail Belkin, Partha Niyogi, Vikas Sindhwani</p><p>Abstract: We propose a family of learning algorithms based on a new form of regularization that allows us to exploit the geometry of the marginal distribution. We focus on a semi-supervised framework that incorporates labeled and unlabeled data in a general-purpose learner. Some transductive graph learning algorithms and standard methods including support vector machines and regularized least squares can be obtained as special cases. We use properties of reproducing kernel Hilbert spaces to prove new Representer theorems that provide theoretical basis for the algorithms. As a result (in contrast to purely graph-based approaches) we obtain a natural out-of-sample extension to novel examples and so are able to handle both transductive and truly semi-supervised settings. We present experimental evidence suggesting that our semi-supervised algorithms are able to use unlabeled data effectively. Finally we have a brief discussion of unsupervised and fully supervised learning within our general framework. Keywords: semi-supervised learning, graph transduction, regularization, kernel methods, manifold learning, spectral graph theory, unlabeled data, support vector machines</p><br/>
<h2>reference text</h2><p>R.A. Adams. Sobolev spaces. Academic Press New York, 1975. N. Aronszajn. Theory of reproducing kernels. Transactions of the American Mathematical Society, 68(3):337–404, 1950. M. Belkin. Problems of Learning on Manifolds. PhD thesis, The University of Chicago, 2003. M. Belkin, I. Matveeva, and P. Niyogi. Regularization and semi-supervised learning on large graphs. COLT, 2004. 2430  M ANIFOLD R EGULARIZATION  M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6):1373–1396, 2003a. M. Belkin and P. Niyogi. Using manifold structure for partially labeled classiﬁcation. Advances in Neural Information Processing Systems, 15:929–936, 2003b. M. Belkin and P. Niyogi. Towards a theoretical foundation for Laplacian-based manifold methods. Proc. of COLT, 2005. M. Belkin, P. Niyogi, and V. Sindhwani. On manifold regularization. Proceedings of the Tenth International Workshop on Artiﬁcial Intelligence and Statistics (AISTAT 2005), 2005. Y. Bengio, J.F. Paiement, P. Vincent, and O. Delalleau. Out-of-sample extensions for LLE, isomap, MDS, Eigenmaps, and spectral clustering. Advances in Neural Information Processing Systems, 16, 2004. K. Bennett and A. Demiriz. Semi-supervised support vector machines. Advances in Neural Information Processing Systems, 11:368–374, 1999. A. Blum and S. Chawla. Learning from labeled and unlabeled data using graph mincuts. Proc. 18th International Conf. on Machine Learning, pages 19–26, 2001. A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. Proceedings of the eleventh annual conference on Computational learning theory, pages 92–100, 1998. O. Bousquet, O. Chapelle, and M. Hein. Measure based regularization. Advances in Neural Information Processing Systems, 16, 2004. M. Brand. Continuous nonlinear dimensionality reduction by kernel eigenmaps. Int. Joint Conf. Artif. Intel, 2003. O. Chapelle, B. Sch¨ lkopf, and A. Zien, editors. Semi-supervised Learning. MIT Press, 2006. o O. Chapelle, J. Weston, and B. Scholkopf. Cluster kernels for semi-supervised learning. Advances in Neural Information Processing Systems, 15:585–592, 2003. O. Chapelle and A. Zien. Semi-supervised classiﬁcation by low density separation. Proceedings of the Tenth International Workshop on Artiﬁcial Intelligence and Statistics, pages 57–64, 2005. F.R.K. Chung. Spectral Graph Theory. American Mathematical Society, 1997. RR Coifman, S. Lafon, AB Lee, M. Maggioni, B. Nadler, F. Warner, and SW Zucker. Geometric diffusions as a tool for harmonic analysis and structure deﬁnition of data: Diffusion maps. Proceedings of the National Academy of Sciences, 102(21):7426–7431, 2005. A. Corduneanu and T. Jaakkola. On information regularization. Proceedings of the Ninth Annual Conference on Uncertainty in Artiﬁcial Intelligence, 2003. F. Cucker and S. Smale. On the mathematical foundations of learning. American Mathematical Society, 39(1):1–49, 2002. 2431  B ELKIN , N IYOGI AND S INDHWANI  O. Delalleau, Y. Bengio, and N. Le Roux. Efﬁcient non-parametric function induction in semisupervised learning. Proceedings of the Tenth International Workshop on Artiﬁcial Intelligence and Statistics (AISTAT 2005), 2005. M.P. Do Carmo. Riemannian Geometry. Birkhauser, 1992. D.L. Donoho and C. Grimes. Hessian eigenmaps: Locally linear embedding techniques for highdimensional data. Proceedings of the National Academy of Sciences, 100(10):5591–5596, 2003. S. Dumais, J. Platt, D. Heckerman, and M. Sahami. Inductive learning algorithms and representations for text categorization. Proceedings of the Seventh International Conference on Information and Knowledge Management, 11:16, 1998. T. Evgeniou, M. Pontil, and T. Poggio. Regularization networks and support vector machines. Advances in Computational Mathematics, 13(1):1–50, 2000. G. Fung and O.L. Mangasarian. Semi-supervised support vector machines for unlabeled data classiﬁcation. Optimization Methods and Software, 15(1):99–05, 2001. A. Grigor’yan. Heat kernels on weighted manifolds and applications. Cont. Math, 398, 93-191, 2006. J. Ham, D.D. Lee, and L.K. Saul. Semisupervised alignment of manifolds. Proceedings of the Annual Conference on Uncertainty in Artiﬁcial Intelligence, Z. Ghahramani and R. Cowell, Eds, 10:120–127, 2005. M. Hein, J.Y. Audibert, and U. von Luxburg. From graphs to manifolds-weak and strong pointwise consistency of graph Laplacians. Proceedings of the 18th Conference on Learning Theory (COLT), pages 470–485, 2005. T. Joachims. Transductive inference for text classiﬁcation using support vector machines. Proceedings of the Sixteenth International Conference on Machine Learning, pages 200–209, 1999. T. Joachims. Transductive learning via spectral graph partitioning. Proceedings of the International Conference on Machine Learning, pages 290–297, 2003. C. Kemp, T.L. Grifﬁths, S. Stromsten, and J.B. Tenenbaum. Semi-supervised learning with trees. Advances in Neural Information Processing Systems, 16, 2004. R.I. Kondor and J. Lafferty. Diffusion kernels on graphs and other discrete input spaces. Proc. 19th International Conf. on Machine Learning, 2002. S. Lafon. Diffusion Maps and Geometric Harmonics. PhD thesis, Yale University, 2004. K. Nigam, A.K. Mccallum, S. Thrun, and T. Mitchell. Text classiﬁcation from labeled and unlabeled documents using EM. Machine Learning, 39(2):103–134, 2000. R.M. Rifkin. Everything Old Is New Again: A Fresh Look at Historical Approaches in Machine Learning. PhD thesis, Massachusets Institute of Technology, 2002. 2432  M ANIFOLD R EGULARIZATION  S.T. Roweis and L.K. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science, 290(5500):2323, 2000. B. Scholkopf, C. Burges, and V. Vapnik. Extracting support data for a given task. Proceedings, First International Conference on Knowledge Discovery & Data Mining, Menlo Park, 1995. B. Scholkopf and A.J. Smola. Learning with Kernels. MIT Press Cambridge, Mass, 2002. M. Seeger. Learning with labeled and unlabeled data. Inst. for Adaptive and Neural Computation, technical report, Univ. of Edinburgh, 2001. V. Sindhwani. Kernel machines for semi-supervised learning. Master’s thesis, The University of Chicago, 2004. V. Sindhwani, M. Belkin, and P. Niyogi. The geometric basis of semi-supervised learning. In ¨ O. Chapelle, A. Zien, and B. Scholkopf, editors, Semi-supervised Learning, chapter 12, pages 217–235. MIT Press, 2006. V. Sindhwani, P. Niyogi, and M. Belkin. Beyond the point cloud: from transductive to semisupervised learning. In Proceedings, Twenty Second International Conference on Machine Learning, 2005. A. Smola and R. Kondor. Kernels and regularization on graphs. Conference on Learning Theory, COLT/KW, 2003. M. Szummer and T. Jaakkola. Partially labeled classiﬁcation with Markov random walks. Advances in Neural Information Processing Systems, 14:945–952, 2002. J.B. Tenenbaum, V. Silva, and J.C. Langford. A global geometric framework for nonlinear dimensionality reduction. Science, 290(5500):2319, 2000. A.N. Tikhonov. Regularization of incorrectly posed problems. Sov. Math. Dokl, 4:1624–1627, 1963. I. W. Tsang and J. T. Kwok. Very large scale manifold regularization using core vector machines. NIPS 2005 Workshop on Large Scale Kernel Machines, 2005. V.N. Vapnik. Statistical Learning Theory. Wiley-Interscience, 1998. J.P. Vert and Y. Yamanishi. Supervised graph inference. Advances in Neural Information Processing Systems, 17:1433–1440, 2005. U. von Luxburg, M. Belkin, and O. Bousquet. Consistency of spectral clustering. Max Planck Institute for Biological Cybernetics Technical Report TR, 134, 2004. G. Wahba. Spline models for observational data. Society for Industrial and Applied Mathematics Philadelphia, Pa, 1990. D. Zhou, O. Bousquet, T.N. Lal, J. Weston, and B. Scholkopf. Learning with local and global consistency. Advances in Neural Information Processing Systems, 16:321–328, 2004. 2433  B ELKIN , N IYOGI AND S INDHWANI  X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised learning using Gaussian ﬁelds and harmonic functions. In Proceedings of the 20th International Conference on Machine Learning, 2003. X. Zhu, J. Kandola, Z. Ghahramani, and J. Lafferty. Nonparametric transforms of graph kernels for semi-supervised learning. Advances in Neural Information Processing Systems, 17, 2005.  2434</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
