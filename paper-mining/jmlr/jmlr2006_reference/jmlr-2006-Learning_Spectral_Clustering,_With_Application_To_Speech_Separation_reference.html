<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>52 jmlr-2006-Learning Spectral Clustering, With Application To Speech Separation</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-52" href="../jmlr2006/jmlr-2006-Learning_Spectral_Clustering%2C_With_Application_To_Speech_Separation.html">jmlr2006-52</a> <a title="jmlr-2006-52-reference" href="#">jmlr2006-52-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>52 jmlr-2006-Learning Spectral Clustering, With Application To Speech Separation</h1>
<br/><p>Source: <a title="jmlr-2006-52-pdf" href="http://jmlr.org/papers/volume7/bach06b/bach06b.pdf">pdf</a></p><p>Author: Francis R. Bach, Michael I. Jordan</p><p>Abstract: Spectral clustering refers to a class of techniques which rely on the eigenstructure of a similarity matrix to partition points into disjoint clusters, with points in the same cluster having high similarity and points in different clusters having low similarity. In this paper, we derive new cost functions for spectral clustering based on measures of error between a given partition and a solution of the spectral relaxation of a minimum normalized cut problem. Minimizing these cost functions with respect to the partition leads to new spectral clustering algorithms. Minimizing with respect to the similarity matrix leads to algorithms for learning the similarity matrix from fully labelled data sets. We apply our learning algorithm to the blind one-microphone speech separation problem, casting the problem as one of segmentation of the spectrogram. Keywords: spectral clustering, blind source separation, computational auditory scene analysis</p><br/>
<h2>reference text</h2><p>K. Achan, S. Roweis, and B. Frey. Probabilistic inference of speech signals from phaseless spectrograms. In Advances in Neural Information Processing Systems 16. MIT Press, 2003. F. R. Bach and M. I. Jordan. Discriminative training of hidden Markov models for multiple pitch tracking. In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2005. 1998  L EARNING S PECTRAL C LUSTERING , W ITH A PPLICATION T O S PEECH S EPARATION  A. Bar-Hillel, T. Hertz, N. Shental, and D. Weinshall. Learning distance functions using equivalence relations. In International Conference on Machine Learning (ICML), 2003. K.-J. Bathe and E. L. Wilson. Numerical Methods in Finite Element Analysis. Prentice Hall, 1976. D. Bertsimas and J. Tsitsiklis. Introduction to Linear Optimization. Athena Scientiﬁc, 1997. M. Blatt, M. Wiesman, and E. Domany. Data clustering using a model granular magnet. Neural Computation, 9:1805–1842, 1997. A. S. Bregman. Auditory Scene Analysis: The Perceptual Organization of Sound. MIT Press, 1990. G. J. Brown and M. P. Cooke. Computational auditory scene analysis. Computer Speech and Language, 8:297–333, 1994. P. K. Chan, M. D. F. Schlag, and J. Y. Zien. Spectral K-way ratio-cut partitioning and clustering. IEEE Transactions on Computer-Aided Design of Integrated Circuits, 13(9):1088–1096, 1994. F. R. K. Chung. Spectral Graph Theory. American Mathematical Society, 1997. P. Comon and G. H. Golub. Tracking a few extreme singular values and vectors in signal processing. Proceedings of the IEEE, 78(8):1327–1343, 1990. M. Cooke and D. P. W. Ellis. The auditory organization of speech and other sources in listeners and computational models. Speech Communication, 35(3-4):141–177, 2001. T. Cour, N. Gogin, and J. Shi. Learning spectral graph segmentation. In Workshop on Artiﬁcial Intelligence and Statistics (AISTATS), 2005. N. Cristianini, J. Shawe-Taylor, and J. Kandola. Spectral kernel methods for clustering. In Advances in Neural Information Processing Systems, 14. MIT Press, 2002. I. Dhillon, Y. Guan, and B. Kulis. A uniﬁed view of kernel k-means, spectral clustering and and graph cuts. Technical Report #TR-04-25, University of Texas, Computer Science, 2004. C. Ding, X. He, and H. D. Simon. On the equivalence of nonnegative matrix factorization and spectral clustering. In Proceedings of the SIAM International Conference on Data Mining (SDM), 2005. A. Edelman, T. A. Arias, and S. T. Smith. The geometry of algorithms with orthogonality constraints. SIAM Journal on Matrix Analysis and Applications, 20(2):303–353, 1999. ¨ C. Fowlkes, S. Belongie, and J. Malik. Efﬁcient spatiotemporal grouping using the Nystr om method. In IEEE conference on Computer Vision and Pattern Recognition (ECCV), 2001. B. Gold and N. Morgan. Speech and Audio Signal Processing: Processing and Perception of Speech and Music. Wiley Press, 1999. G. H. Golub and C. F. Van Loan. Matrix Computations. Johns Hopkins University Press, 1996. A. G. Gray and A. W. Moore. N-Body problems in statistical learning. In Advances in Neural Information Processing Systems, 13. MIT Press, 2001. 1999  BACH AND J ORDAN  D. W. Grifﬁn and J. S. Lim. Signal estimation from modiﬁed short-time Fourier transform. IEEE Transactions on Acoustics, Speech and Signal Processing, 32(2):236–243, 1984. M. Gu, H. Zha, C. Ding, X. He, and H. Simon. Spectral relaxation models and structure analysis for K-way graph clustering and bi-clustering. Technical report, Penn. State Univ, Computer Science and Engineering, 2001. D. Higham and M. Kibble. A uniﬁed view of spectral clustering. Technical Report 02, University of Strathclyde, Department of Mathematics, 2004. L. J. Hubert and P. Arabie. Comparing partitions. Journal of Classiﬁcation, 2:193–218, 1985. A. Hyv¨ rinen, J. Karhunen, and E. Oja. Independent Component Analysis. John Wiley & Sons, a 2001. G.-J. Jang and T.-W. Lee. A maximum likelihood approach to single-channel source separation. Journal of Machine Learning Research, 4:1365–1392, 2003. A. Jourjine, S. Rickard, and O. Yilmaz. Blind separation of disjoint orthogonal signals: Demixing N sources from 2 mixtures. In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2000. S. D. Kamvar, D. Klein, and C. D. Manning. Spectral learning. In International Joint Conference on Artiﬁcial Intelligence (IJCAI), 2003. D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. In Advances in Neural Information Processing Systems, 12. MIT Press, 2000. J. R. Magnus and H. Neudecker. Matrix differential calculus with applications in statistics and econometrics. John Wiley, 1999. S. Mallat. A Wavelet Tour of Signal Processing. Academic Press, 1998. D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In International Conference on Computer Vision (ICCV), 2001. M. Meila and D. Heckerman. An experimental comparison of several clustering and initialization methods. Machine Learning, 42(1):9–29, 2001. M. Meila and J. Shi. Learning segmentation by random walks. In Advances in Neural Information Processing Systems, 14. MIT Press, 2002. M. Meila and L. Xu. Multiway cuts and spectral clustering. Technical report, University of Washington, Department of Statistics, 2003. A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: analysis and an algorithm. In Advances in Neural Information Processing Systems, 14. MIT Press, 2002. M. L. Overton and R. S. Womersley. Optimality conditions and duality theory for minimizing sums of the largest eigenvalues of symmetric matrics. Mathematical Programming, 62:321–357, 1993. 2000  L EARNING S PECTRAL C LUSTERING , W ITH A PPLICATION T O S PEECH S EPARATION  S. T. Roweis. One microphone source separation. In Advances in Neural Information Processing Systems, 13. MIT Press, 2001. G. L. Scott and H. C. Longuet-Higgins. Feature grouping by relocalisation of eigenvectors of the proximity matrix. In British Machine Vision Conference, 1990. N. Shental, A. Zomet, T. Hertz, and Y. Weiss. Learning and inferring image segmentations using the gbp typical cut algorithm. In International Conference on Computer Vision (ICCV), 2003. J. Shi and J. Malik. Normalized cuts and image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(8):888–905, 2000. M. Szummer and T. Jaakkola. Partially labeled classiﬁcation with Markov random walks. In Advances in Neural Information Processing Systems, 14. MIT Press, 2002. N. Tishby and N. Slonim. Data clustering by Markovian relaxation and the information bottleneck method. In Advances in Neural Information Processing Systems, 13. MIT Press, 2001. U. von Luxburg, O. Bousquet, and M. Belkin. Limits of spectral clustering. In Advances in Neural Information Processing Systems, 17. MIT Press, 2005. ¨ K. Wagstaff, C. Cardie, S. Rogers, and S. Schrodl. Constrained K-means clustering with background knowledge. In International Conference on Machine Learning (ICML), 2001. G. Wahba. Spline Models for Observational Data. SIAM, 1990. Y. Weiss. Segmentation using eigenvectors: a unifying view. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 1999. E. P. Xing and M. I. Jordan. On semideﬁnite relaxation for normalized k-cut and connections to spectral clustering. Technical Report UCB/CSD-03-1265, EECS Department, University of California, Berkeley, 2003. E. P. Xing, A. Y. Ng, M. I. Jordan, and S. Russell. Distance metric learning, with application to clustering with side-information. In Advances in Neural Information Processing Systems, 15. MIT Press, 2003. S. X. Yu and J. Shi. Grouping with bias. In Advances in Neural Information Processing Systems, 14. MIT Press, 2002. S. X. Yu and J. Shi. Multiclass spectral clustering. In International Conference on Computer Vision (ICCV), 2003. H. Zha, C. Ding, M. Gu, X. He, and H. Simon. Spectral relaxation for K-means clustering. In Advances in Neural Information Processing Systems, 14. MIT Press, 2002. M. Zibulevsky, P. Kisilev, Y. Y. Zeevi, and B. A. Pearlmutter. Blind source separation via multinode sparse representation. In Advances in Neural Information Processing Systems, 14. MIT Press, 2002.  2001</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
