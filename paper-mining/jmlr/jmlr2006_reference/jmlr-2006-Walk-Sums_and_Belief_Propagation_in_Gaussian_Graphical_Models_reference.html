<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-95" href="../jmlr2006/jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">jmlr2006-95</a> <a title="jmlr-2006-95-reference" href="#">jmlr2006-95-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>95 jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</h1>
<br/><p>Source: <a title="jmlr-2006-95-pdf" href="http://jmlr.org/papers/volume7/malioutov06a/malioutov06a.pdf">pdf</a></p><p>Author: Dmitry M. Malioutov, Jason K. Johnson, Alan S. Willsky</p><p>Abstract: We present a new framework based on walks in a graph for analysis and inference in Gaussian graphical models. The key idea is to decompose the correlation between each pair of variables as a sum over all walks between those variables in the graph. The weight of each walk is given by a product of edgewise partial correlation coefﬁcients. This representation holds for a large class of Gaussian graphical models which we call walk-summable. We give a precise characterization of this class of models, and relate it to other classes including diagonally dominant, attractive, nonfrustrated, and pairwise-normalizable. We provide a walk-sum interpretation of Gaussian belief propagation in trees and of the approximate method of loopy belief propagation in graphs with cycles. The walk-sum perspective leads to a better understanding of Gaussian belief propagation and to stronger results for its convergence in loopy graphs. Keywords: Gaussian graphical models, walk-sum analysis, convergence of loopy belief propagation</p><br/>
<h2>reference text</h2><p>E. G. Boman, D. Chen, O. Parekh, and S. Toledo. On factor width and symmetric H-matrices. Linear Algebra and its Applications, 405, 2005. D. C. Brydges, J. Frohlich, and A. D. Sokal. The random-walk representation of classical spin systems and correlation inequalities. Communications in mathematical physics, 91, 1983. V. Chandrasekaran, J. Johnson, and A. Willsky. Walk-sum analysis and convergence of embedded subgraph algorithms. In preparation. R. G. Cowell, A. P. Dawid, S. L. Lauritzen, and D. J. Spiegelhalter. Probabilistic Networks and Expert Systems. Springer-Verlag, 1999. M. Fisher. Critical temperatures of anisotropic Ising lattices II, general upper bounds. Physical Review, 1967. R. Godement. Analysis I. Springer-Verlag, 2004. J. Hammersley and P. Clifford. Markov ﬁelds on ﬁnite graphs and lattices. Unpublished manuscript, 1971. L. He, X. Liu, and G. Strang. Laplacian eigenvalues of growing tees. In Conf. on Math. Theory of Networks and Systems, 2000. R. Horn and C. Johnson. Matrix Analysis. Cambridge University Press, 1985. R. Horn and C. Johnson. Topics in Matrix Analysis. Cambridge University Press, 1991. A. T. Ihler, J. W. Fisher III, and A. S. Willsky. Loopy belief propagation: Convergence and effects of message errors. Journal of Machine Learning Research, 6, May 2005. J. Johnson. Walk-summable Gauss-Markov random ﬁelds. Unpublished manuscript, available at http://www.mit.edu/people/jasonj, December 2001. J. Johnson, D. Malioutov, and A. Willsky. Walk-sum interpretation and analysis of Gaussian belief propagation. In Advances in Neural Information Processing Systems, 2006. B. Jones and M. West. Covariance decomposition in undirected Gaussian graphical models. Biometrika, 92(4), 2005. S. Kirkland, J. J. McDonald, and M. Tsatsomeros. Sign patterns that require positive eigenvalues. Linear and Multilinear Algebra, 41, 1996. S. Lauritzen. Graphical Models. Oxford Statistical Science Series. Oxford University Press, 1996. C. Moallemi and B. Van Roy. Consensus propagation. In Advances in Neural Information Processing Systems, 2006a. C. Moallemi and B. Van Roy. Convergence of the min-sum message passing algorithm for quadratic optimization. Technical Report, March 2006b. 2063  M ALIOUTOV, J OHNSON AND W ILLSKY  J. Mooij and H. Kappen. Sufﬁcient conditions for convergence of loopy belief propagation. In Proc. Uncertainty in Artiﬁcial Intelligence, 2005. J. Pearl. Probabilistic inference in intelligent systems. Morgan Kaufmann, 1988. K. Plarre and P. Kumar. Extended message passing algorithm for inference in loopy Gaussian graphical models. In Ad Hoc Networks, 2004. W. Rudin. Principles of Mathematical Analysis. McGraw Hill, 3rd edition, 1976. P. Rusmevichientong and B. Van Roy. An analysis of belief propagation on the turbo decoding graph with Gaussian densities. IEEE Trans. Information Theory, 48(2), 2001. T. Speed and H. Kiiveri. Gaussian Markov distributions over ﬁnite graphs. The Annals of Statistics, 14(1), 1986. E. Sudderth, M. Wainwright, and A. Willsky. Embedded trees: Estimation of Gaussian processes on graphs with cycles. IEEE Trans. Signal Processing, 52(11), November 2004. S. Tatikonda and M. Jordan. Loopy belief propagation and Gibbs measures. In Uncertainty in Artiﬁcial Intelligence, 2002. R. S. Varga. Matrix iterative analysis. Springer-Verlag, 2000. M. Wainwright, T. Jaakkola, and A. Willsky. Tree-based reparameterization framework for analysis of sum-product and related algorithms. IEEE Trans. Information Theory, 49(5), 2003. Y. Weiss and W. Freeman. Correctness of belief propagation in Gaussian graphical models of arbitrary topology. Neural Computation, 13, 2001. J. Yedidia, W. Freeman, and Y. Weiss. Understanding belief propagation and its generalizations. Exploring AI in the new millennium, 2003.  2064</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
