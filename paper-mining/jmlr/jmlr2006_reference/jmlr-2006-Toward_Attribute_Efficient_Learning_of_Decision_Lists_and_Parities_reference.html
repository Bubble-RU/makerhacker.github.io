<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>92 jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-92" href="../jmlr2006/jmlr-2006-Toward_Attribute_Efficient_Learning_of_Decision_Lists_and_Parities.html">jmlr2006-92</a> <a title="jmlr-2006-92-reference" href="#">jmlr2006-92-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>92 jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</h1>
<br/><p>Source: <a title="jmlr-2006-92-pdf" href="http://jmlr.org/papers/volume7/klivans06a/klivans06a.pdf">pdf</a></p><p>Author: Adam R. Klivans, Rocco A. Servedio</p><p>Abstract: We consider two well-studied problems regarding attribute efﬁcient learning: learning decision lists and learning parity functions. First, we give an algorithm for learning decision lists of length ˜ 1/3 ˜ 1/3 k over n variables using 2O(k ) log n examples and time nO(k ) . This is the ﬁrst algorithm for learning decision lists that has both subexponential sample complexity and subexponential running time in the relevant parameters. Our approach establishes a relationship between attribute efﬁcient learning and polynomial threshold functions and is based on a new construction of low degree, low weight polynomial threshold functions for decision lists. For a wide range of parameters our construction matches a lower bound due to Beigel for decision lists and gives an essentially optimal tradeoff between polynomial threshold function degree and weight. Second, we give an algorithm for learning an unknown parity function on k out of n variables using O(n1−1/k ) examples in poly(n) time. For k = o(log n) this yields a polynomial time algorithm with sample complexity o(n); this is the ﬁrst polynomial time algorithm for learning parity on a superconstant number of variables with sublinear sample complexity. We also give a simple algorithm for learning an unknown length-k parity using O(k log n) examples in nk/2 time, which improves on the naive nk time bound of exhaustive search. Keywords: PAC learning, attribute efﬁciency, learning parity, decision lists, Winnow</p><br/>
<h2>reference text</h2><p>D. Angluin. Queries and concept learning. Machine Learning, 2:319–342, 1988. J. Barzdin and R. Freivald. On the prediction of general recursive functions. Soviet Mathematics Doklady, 13:1224–1228, 1972. R. Beigel. Perceptrons, PP, and the Polynomial Hierarchy. Computational Complexity, 4:339–349, 1994. A. Blum. Learning Boolean functions in an inﬁnite attribute space. In Proceedings of the 22nd Annual Symposium on Theory of Computing, pages 64–72, 1990. A. Blum. Rank-r decision trees are a subclass of r-decision lists. Information Processing Letters, 42(4):183–185, 1992. A.  Blum. On-line algorithms in machine learning. http://www.cs.cmu.edu/˜avrim/Papers/pubs.html, 1996.  available  at  A. Blum. Empirical support for Winnow and weighted-majority algorithms: results on a calendar scheduling domain. Machine Learning, 26:5–23, 1997. A. Blum and P. Langley. Selection of relevant features and examples in machine learning. Artiﬁcial Intelligence, 97(1-2):245–271, 1997. A. Blum, L. Hellerstein, and N. Littlestone. Learning in the presence of ﬁnitely or inﬁnitely many irrelevant attributes. Journal of Computer and System Sciences, 50:32–40, 1995. 600  T OWARD ATTRIBUTE E FFICIENT L EARNING  E. Cheney. Introduction to approximation theory. McGraw-Hill, New York, New York, 1966. A. Dhagat and L. Hellerstein. PAC learning with irrelevant attributes. In Proceedings of the 35th Annual Symposium on Foundations of Computer Science, pages 64–74, 1994. A. Ehrenfeucht and D. Haussler. Learning decision trees from random examples. Information and Computation, 82(3):231–246, 1989. A.R. Golding and D. Roth. A Winnow-based approach to spelling correction. Machine Learning, 34:107–130, 1999. M. Goldmann, J. H˚ stad, and A. Razborov. Majority gates vs. general weighted threshold gates. a Computational Complexity, 2:277–300, 1992. D. Haussler. Space efﬁcient learning algorithms. Technical Report UCSC-CRL-88-2, University of California at Santa Cruz, 1988. D. Helmbold, R. Sloan, and M. Warmuth. Learning integer lattices. SIAM Journal on Computing, 21(2):240–266, 1992. M. Kearns and U. Vazirani. An Introduction to Computational Learning Theory. MIT Press, Cambridge, MA, 1994. J. Kivinen, M. Warmuth, and P. Auer. The Perceptron algorithm vs. Winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. Artiﬁcial Intelligence, 97(1-2):325–343, 1997. ˜  A. Klivans and R. Servedio. Learning DNF in time 2O(n 68(2):303–318, 2004.  1/3 )  . Journal of Computer & System Sciences,  A. Klivans, R. O’Donnell, and R. Servedio. Learning intersections and thresholds of halfspaces. Journal of Computer & System Sciences, 68(4):808–840, 2004. M. Krause. On the computational power of Boolean decision lists. In 19th Annual Symposium on Theoretical Aspects of Computer Science, pages 372–383, 2002. M. Krause and P. Pudlak. Computing Boolean functions by polynomials and threshold circuits. Computational Complexity, 7(4):346–370, 1998. N. Littlestone. Learning quickly when irrelevant attributes abound: a new linear-threshold algorithm. Machine Learning, 2:285–318, 1988. N. Littlestone. Mistake bounds and logarithmic linear-threshold learning algorithms. PhD thesis, University of California at Santa Cruz, 1989a. N. Littlestone. From online to batch learning. In Proceedings of the Second Annual Workshop on Computational Learning Theory, pages 269–284, 1989b. T. Mitchell. Generalization as search. Artiﬁcial Intelligence, 18:203–226, 1982. J. Myhill and W. Kautz. On the size of weights required for linear-input switching functions. IRE Trans. on Electronic Computers, EC10(2):288–290, 1961. 601  K LIVANS AND S ERVEDIO  Z. Nevo and R. El-Yaniv. On online learning of decision lists. Journal of Machine Learning Research, 3:271–301, 2002. R. O’Donnell and R. Servedio. New degree bounds for polynomial threshold functions. In Proceedings of the 35th ACM Symposium on Theory of Computing, pages 325–334, 2003. R. Rivest. Learning decision lists. Machine Learning, 2(3):229–246, 1987. R. Servedio. Computational sample complexity and attribute-efﬁcient learning. Journal of Computer and System Sciences, 60(1):161–178, 2000. R. Servedio. Perceptron, Winnow and PAC learning. SIAM Journal on Computing, 31(5):1358– 1369, 2002. D. Spielman. Personal communication, 2003. R. Uehara, K. Tsuchida, and I. Wegener. Identiﬁcation of partial disjunction, parity, and threshold functions. Theoretical Computer Science, 230:131–147, 2000. L. Valiant. Projection learning. Machine Learning, 37(2):115–130, 1999.  602</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
