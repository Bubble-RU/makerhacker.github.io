<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>4 jmlr-2006-A Linear Non-Gaussian Acyclic Model for Causal Discovery</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="../home/jmlr2006_home.html">jmlr2006</a> <a title="jmlr-2006-4" href="../jmlr2006/jmlr-2006-A_Linear_Non-Gaussian_Acyclic_Model_for_Causal_Discovery.html">jmlr2006-4</a> <a title="jmlr-2006-4-reference" href="#">jmlr2006-4-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>4 jmlr-2006-A Linear Non-Gaussian Acyclic Model for Causal Discovery</h1>
<br/><p>Source: <a title="jmlr-2006-4-pdf" href="http://jmlr.org/papers/volume7/shimizu06a/shimizu06a.pdf">pdf</a></p><p>Author: Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvärinen, Antti Kerminen</p><p>Abstract: In recent years, several methods have been proposed for the discovery of causal structure from non-experimental data. Such methods make various assumptions on the data generating process to facilitate its identiﬁcation from purely observational data. Continuing this line of research, we show how to discover the complete causal structure of continuous-valued data, under the assumptions that (a) the data generating process is linear, (b) there are no unobserved confounders, and (c) disturbance variables have non-Gaussian distributions of non-zero variances. The solution relies on the use of the statistical method known as independent component analysis, and does not require any pre-speciﬁed time-ordering of the variables. We provide a complete Matlab package for performing this LiNGAM analysis (short for Linear Non-Gaussian Acyclic Model), and demonstrate the effectiveness of the method using artiﬁcially generated data and real-world data. Keywords: independent component analysis, non-Gaussianity, causal discovery, directed acyclic graph, non-experimental data</p><br/>
<h2>reference text</h2><p>Y. Benjamini and Y. Hochberg. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society: Series B, 57:289–300, 1995. K. A. Bollen. Structural Equations with Latent Variables. John Wiley & Sons, 1989. G. E. P. Box and G. M. Jenkins. Time Series Analysis: forecasting and control. Holden-Day, Oakland, California, USA, revised edition, 1976. P. J. Brockwell and R. A. Davis. Time Series: Theory and Methods. Springer-Verlag, New York, USA, 1987. M. W. Browne. Asymptotically distribution-free methods for the analysis of covariance structures. British Journal of Mathematical and Statistical Psychology, 9:665–672, 1984. R. E. Burkard and E. Cela. Linear assignment problems and extensions. In P. M. Pardalos and D. Z. Du, editors, Handbook of Combinatorial Optimization - Supplement Volume A, pages 75–149. Kluwer, 1999. J.-F. Cardoso and B. H. Laheld. Equivariant adaptive source separation. IEEE Trans. on Signal Processing, 44:3017–3030, 1996. 2028  A L INEAR N ON -G AUSSIAN ACYCLIC M ODEL FOR C AUSAL D ISCOVERY  J.-F. Cardoso and A. Souloumiac. Blind beamforming for non Gaussian signals. IEE Proceedings-F, 140(6):362–370, 1993. P. Comon. Independent component analysis – a new concept? Signal Processing, 36:287–314, 1994. Y. Dodge and V. Rousson. On asymptotic properties of the correlation coefﬁcient in the regression setting. The American Statistician, 55(1):51–54, 2001. B. Efron and R. Tibshirani. An Introduction to the Bootstrap. Chapman & Hall, New York, 1993. D. Geiger and D. Heckerman. Learning gaussian networks. In Proceedings of the 10th Annual Conference on Uncertainty in Artiﬁcial Intelligence (UAI-94), pages 235–243, 1994. V. P. Godambe. Estimating functions. Oxford University Press, New York, 1991. J. Himberg, A. Hyv¨ rinen, and F. Esposito. Validating the independent components of neuroimaging a time-series via clustering and visualization. Neuroimage, 22:1214–1222, 2004. Y. Hochberg. A sharper Bonferroni procedure for multiple tests of signiﬁcance. Biometrika, 4: 800–802, 1988. Y. Hochberg and A. C. Tamhane. Multiple comparison procedures. John Wiley & Sons, New York, 1987. S. Holm. A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6:65–70, 1979. P. O. Hoyer, S. Shimizu, A. Hyv¨ rinen, Y. Kano, and A. J. Kerminen. New permutation algorithms a for causal discovery using ICA. In Proceedings of International Conference on Independent Component Analysis and Blind Signal Separation, Charleston, SC, USA, pages 115–122, 2006a. P. O. Hoyer, S. Shimizu, and A. J. Kerminen. Estimation of linear, non-gaussian causal models in the presence of confounding latent variables. In Proc. the third European Workshop on Probabilistic Graphical Models (PGM2006), 2006b. In press. L. Hu, P. M. Bentler, and Y. Kano. Can test statistics in covariance structure analysis be trusted? Psychological Bulletin, 112:351–362, 1992. R. J. Hyndman. Time series data library, 2005. URL http://www-personal.buseco.monash. edu.au/˜hyndman/TSDL/. [June 2005]. A. Hyv¨ rinen. One-unit contrast functions for independent component analysis: A statistical anala ysis. In Neural Networks for Signal Processing VII (Proceedings of IEEE Workshop on Neural Networks for Signal Processing), pages 388–397, 1997. A. Hyv¨ rinen. Fast and robust ﬁxed-point algorithms for independent component analysis. IEEE a Trans. on Neural Networks, 10(3):626–634, 1999. A. Hyv¨ rinen, J. Karhunen, and E. Oja. Independent Component Analysis. Wiley Interscience, a 2001. 2029  ¨ S HIMIZU , H OYER , H YV ARINEN AND K ERMINEN  M. Kawanabe and K. R. M¨ ller. Estimating functions for blind separation when sources have u variance dependencies. Journal of Machine Learning Research, 6:453–482, 2005. National Statistics, 2005. URL http://www.statistics.gov.uk/. [June 2005]. J. Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press, 2000. D. T. Pham and P. Garrat. Blind separation of mixture of independent sources through a quasimaximum likelihood approach. Signal Processing, 45:1457–1482, 1997. S. Shimizu, A. Hyv¨ rinen, P. O. Hoyer, and Y. Kano. Finding a causal ordering via independent a component analysis. Computational Statistics & Data Analysis, 50(11):3278–3293, 2006a. S. Shimizu, A. Hyv¨ rinen, Y. Kano, and P. O. Hoyer. Discovery of non-gaussian linear causal a models using ICA. In Proc. the 21st Conference on Uncertainty in Artiﬁcial Intelligence (UAI2005), pages 526–533, 2005. S. Shimizu, A. Hyv¨ rinen, Y. Kano, P. O. Hoyer, and A. J. Kerminen. Testing signiﬁcance of mixing a and demixing coefﬁcients in ICA. In Proceedings of International Conference on Independent Component Analysis and Blind Signal Separation, Charleston, SC, USA, pages 901–908, 2006b. S. Shimizu and Y. Kano. Use of non-normality in structural equation modeling: Application to direction of causation. Journal of Statistical Planning and Inference, 2006. In press. R. J. Simes. An improved Bonferroni procedure for multiple tests of signiﬁcance. Biometrika, 73: 751–754, 1986. P. Spirtes, C. Glymour, and R. Scheines. Causation, Prediction, and Search, 2nd ed. MIT Press, 2000. Statistical Software Information, 2005. URL http://www-unix.oit.umass.edu/˜statdata/. [June 2005]. P. Tichavsk´ , Z. Koldovsk´ , and E. Oja. Performance analysis of the FastICA algorithm and y y Cram` r-Rao bounds for linear independent component analysis. IEEE Trans. on Signal Proe cessing, 54(4):1189–1203, 2006. K-H. Yuan and P. M. Bentler. Mean and covariance structure analysis: Theoretical and practical improvements. Journal of the American Statistical Association, 92(438):767–774, 1997.  2030</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
