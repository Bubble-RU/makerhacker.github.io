<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-94" href="../jmlr2008/jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">jmlr2008-94</a> <a title="jmlr-2008-94-reference" href="#">jmlr2008-94-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</h1>
<br/><p>Source: <a title="jmlr-2008-94-pdf" href="http://jmlr.org/papers/volume9/george08a/george08a.pdf">pdf</a></p><p>Author: Abraham George, Warren B. Powell, Sanjeev R. Kulkarni</p><p>Abstract: We consider the problem of estimating the value of a multiattribute resource, where the attributes are categorical or discrete in nature and the number of potential attribute vectors is very large. The problem arises in approximate dynamic programming when we need to estimate the value of a multiattribute resource from estimates based on Monte-Carlo simulation. These problems have been traditionally solved using aggregation, but choosing the right level of aggregation requires resolving the classic tradeoff between aggregation error and sampling error. We propose a method that estimates the value of a resource at different levels of aggregation simultaneously, and then uses a weighted combination of the estimates. Using the optimal weights, which minimizes the variance of the estimate while accounting for correlations between the estimates, is computationally too expensive for practical applications. We have found that a simple inverse variance formula (adjusted for bias), which effectively assumes the estimates are independent, produces near-optimal estimates. We use the setting of two levels of aggregation to explain why this approximation works so well. Keywords: hierarchical statistics, approximate dynamic programming, mixture models, adaptive learning, multiattribute resources</p><br/>
<h2>reference text</h2><p>M. Athans, D. Bertsekas, W. McDermott, J. Tsitsiklis, and B. Van Roy. Intelligent optimal control. Technical report, Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, 1995. J.C. Bean, J.R. Birge, and R.L. Smith. Aggregation in dynamic programming. Operations Research, 35:215–220, 1987. D. Bertsekas and D. Castanon. Adaptive aggregation methods for inﬁnite horizon dynamic programming. IEEE Transactions on Automatic Control, 34(6):589–598, 1989. D.P. Bertsekas and J.N. Tsitsiklis. Neuro-Dynamic Programming. Athena Scientiﬁc, Belmont, MA, 1996. C. Boutilier, T. Dean, and S. Hanks. Decision-theoretic planning: structural assumptions and computational leverage. J. of Artiﬁcial Intelligence, 11:1–94, 1999. C. Boutilier, R. Dearden, and M. Goldszmidt. Stochastic dynamic programming with factored representations. Artiﬁcial Intelligence, 121(1-2):49–107, 2000. URL citeseer.ist.psu.edu/boutilier99stochastic.html. 2109  G EORGE , P OWELL AND K ULKARNI  L. Breiman. Stacked regression. Machine Learning, 24:49–64, 1996. B. Efron and R. Tibshirani. An Introduction to the Bootstrap. Chapman & Hall/CRC, 1993. Z. Feng, E. A. Hansen, and S. Zilberstein. Symbolic generalization for on-line planning. In Christopher Meek and Uffe Kjærulff, editors, UAI, pages 209–216. Morgan Kaufmann, 2003. ISBN 0-127-05664-5. M. Gendreau and J. Y. Potvin. Dynamic vehicle routing and dispatching. In T.G. Crainic and G. Laporte, editors, Fleet Management and Logistics, pages 115–126. Kluwer Academic Publishers, 1998. I. Guttman, S.S. Wilks, and J.S. Hunter. Introductory Engineering Statistics. John Wiley and Sons, Inc., New York, NY, 1965. T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. Springer series in Statistics, New York, NY, 2001. S. Ichoua, M. Gendreau, and J.-Y. Potvin. Exploiting knowledge about future demands for real-time vehicle dispatching. Transportation Science, 40(2):211–225, 2005. K.E. Kim and T. Dean. Solving factored MDP’s using non-homogeneous partitions. Artiﬁcial Intelligence, 147(1-2):225–251, 2003. M. LeBlanc and R. Tibshirani. Combining estimates in regression and classiﬁcation. Journal of the American Statistical Association, 91:1641–1650, 1996. R. Luus. Iterative Dynamic Programming. Chapman & Hall/CRC, New York, 2000. R. Mendelssohn. An iterative aggregation procedure for Markov decision processes. Operations Research, 30(1):62–73, 1982. W. B. Powell. Approximate Dynamic Programming: Solving the curses of dimensionality. John Wiley and Sons, New York, 2007. W. B. Powell and T. A. Carvalho. Dynamic control of logistics queueing networks for large-scale ﬂeet management. Transportation Science, 32(2):90–109, 1998. W. B. Powell, J. A. Shapiro, and H. P. Sim˜ o. An adaptive dynamic programming algorithm for the a heterogeneous resource allocation problem. Transportation Science, 36(2):231–249, 2002. D. Rogers, R. Plante, R. Wong, and J. Evans. Aggregation and disaggregation techniques and methodology in optimization. Operations Research, 39(4):553–582, 1991. N. Secomandi. Comparing neuro-dynamic programming algorithms for the vehicle routing problem with stochastic demands. Computers and Operations Research, 27(11):1201–1225, 2000. N. Secomandi. A rollout policy for the vehicle routing problem with stochastic demands. Operations Research, 49(5):796–802, 2001. 2110  F UNCTION A PPROXIMATION WITH M ULTIPLE AGGREGATION  H. P. Simao, J. Day, A. P. George, T. Gifford, J. Nienow, and W. B. Powell. An approximate dynamic programming algorithm for large-scale ﬂeet management: A case application. Transportation Science, (to appear), 2008. M. Spivey and W. B. Powell. The dynamic assignment problem. Transportation Science, 38(4): 399–419, 2004. R.S. Sutton. Learning to predict by the methods of temporal differences. Machine Learning, 3: 9–44, 1988. R.S. Sutton and A.G. Barto. Reinforcement Learning. The MIT Press, Cambridge, Massachusetts, 1998. J. N. Tsitsiklis and B. Van Roy. Feature-based methods for large scale dynamic programming. Machine Learning, 22:59–94, 1996. X. Wang and T. G. Dietterich. Efﬁcient value function approximation using regression trees. In J. Boyan, W. Buntine, and A. Jagota, editors, Statistical Machine Learning for Large Scale Optimization, Neural Computing Surveys. 2000. C.J.C.H. Watkins. Learning from delayed rewards. Ph.d. thesis, Cambridge University, Cambridge, UK, 1989. W. Whitt. Approximations of dynamic programs I. Mathematics of Operations Research, 3:231– 243, 1978. D. Wolpert. Stacked generalization. Neural Networks, 5:241–259, 1992. Y. Yang. Adaptive regression by mixing. Journal of the American Statistical Association, 96, 2001. Q. Zhang and S. P. Sethi. Near optimization of dynamic systems by decomposition and aggregation. Journal of Optimization Theory and Applications, 99(1):1–22, 1998.  2111</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
