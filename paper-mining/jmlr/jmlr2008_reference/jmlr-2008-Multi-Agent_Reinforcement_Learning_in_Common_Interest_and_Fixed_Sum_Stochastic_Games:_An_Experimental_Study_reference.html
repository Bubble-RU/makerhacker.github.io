<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-65" href="../jmlr2008/jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">jmlr2008-65</a> <a title="jmlr-2008-65-reference" href="#">jmlr2008-65-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</h1>
<br/><p>Source: <a title="jmlr-2008-65-pdf" href="http://jmlr.org/papers/volume9/bab08a/bab08a.pdf">pdf</a></p><p>Author: Avraham Bab, Ronen I. Brafman</p><p>Abstract: Multi Agent Reinforcement Learning (MARL) has received continually growing attention in the past decade. Many algorithms that vary in their approaches to the different subtasks of MARL have been developed. However, the theoretical convergence results for these algorithms do not give a clue as to their practical performance nor supply insights to the dynamics of the learning process itself. This work is a comprehensive empirical study conducted on MGS, a simulation system developed for this purpose. It surveys the important algorithms in the ﬁeld, demonstrates the strengths and weaknesses of the different approaches to MARL through application of FriendQ, OAL, WoLF, FoeQ, Rmax, and other algorithms to a variety of fully cooperative and fully competitive domains in self and heterogeneous play, and supplies an informal analysis of the resulting learning processes. The results can aid in the design of new learning algorithms, in matching existing algorithms to speciﬁc tasks, and may guide further research and formal analysis of the learning processes. Keywords: reinforcement learning, multi-agent reinforcement learning, stochastic games</p><br/>
<h2>reference text</h2><p>A. Bab and R. I. Brafman. An experimental study of different approaches to reinforcement learning in common interest stochastic games. In ECML, pages 75–86, 2004. M. H. Bowling and M. M. Veloso. Multiagent learning using a variable learning rate. Artiﬁcial Intelligence, 136(2):215–250, 2002. R. I. Brafman and M. Tennenholtz. R-max – a general polynomial time algorithm for near-optimal reinforcement learning. JMLR, 3:213–231, 2002. R. I. Brafman and M. Tennenholtz. Learning to coordinate efﬁciently: A model based approach. JAIR, 19:11–23, 2003. R I. Brafman and M. Tennenholtz. Efﬁcient learning equilibrium. Artif. Intell., 159:27–47, 2004. G. W. Brown. Iterative solution of games by ﬁctitious play. In T. C. Koopmans, editor, Activity Analysis of Production and Allocation. Wiley, 1951. G. Chalkiadakis and C. Boutilier. Coordination in multiagent reinforcement learning: A Bayesian approach. In AAMAS’03, 2003. C. Claus and C. Boutilier. The dynamics of reinforcement learning in cooperative multi-agent systems. In Proc. Workshop on Multi-Agent Learning, 1997. 2673  BAB AND B RAFMAN  R. Dearden, N. Friedman, and D. Andre. Model based bayesian exploration. In UAI’99, 1999. R. Dearden, N. Friedman, and S. Russell. Bayesian Q-learning. In AAAI-98, 1998. E. Even-Dar and Y. Mansour. Learning rates for Q-learning. Journal of Machine Learning Research, 5:1–25, 2003. J. Filar and K. Vrieze. Competitive Markov Decision Processes. Springer-Verlag, 1997. J. Hu and M.P. Wellman. Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm. In Proceedings of the Fifteenth International Conference on Machine Learning (ICML-98), pages 1095–1100, 1998. L. P. Kaelbling. Learning in Embedded Systems. The MIT Press: Cambridge, MA, 1993. L. P. Kaelbling, M. L. Littman, and A. W. Moore. Reinforcement learning: A survey. Journal of Artiﬁcial Intelligence Research, 4:237–285, 1996. M. L. Littman. Friend-or-foe Q-learning in general-sum games. In Proc. 18th International Conf. on Machine Learning, 2001. M. L. Littman. Markov games as a framework for multi-agent reinforcement learning. In Proc. 11th International Conference on Machine Learning, 1994. A. W. Moore and C. G. Atkeson. Prioritized sweeping: Reinforcement learning with less data and less time. Machine Learning, 13:103–130, 1993. R. Powers and Y. Shoham. Learning against opponents with bounded memory. In Proc. 19th International Joint Conf. on Artiﬁcial Intelligence, 2005. M. Puterman. Markov Decision Processes. Wiley, New York, 1994. A. Schaerf, Y. Shoham, and M. Tennenholtz. Adaptive load balancing: A study in multi-agent learning. Journal of Artiﬁcial Intelligence Research, 2:475–500, 1995. Y. Shoham, R. Powers, and T. Grenager. If Multi-Agent Learning is the Answer, What is the Question? Artiﬁcial Intelligence, 171(7):365–377, 2007. S. P. Singh and R. S. Sutton. Reinforcement learning with replacing eligibility traces. Machine Learning, 22(1-3):123–158, 1996. M. Sridharan and G. Tesauro. Multi-agent Q-learning and regression trees for automated pricing decisions. In Proc. 17th International Conf. on Machine Learning, pages 927–934. Morgan Kaufmann, San Francisco, CA, 2000. R. S. Sutton and A. G. Barto. Reinforcement Learning: An Introduction. MIT Press, 1998. W. Uther and M. Veloso. Adversarial reinforcement learning. Technical report, Carnegie Mellon University, 2003. J. M. Vidal and E. H. Durfee. Predicting the expected behavior of agents that learn about agents: the clri framework. Autonomous Agents and Multi-Agent Systems, 6(1):77–107, 2003. 2674  M ULTI -AGENT RL IN S TOCHASTIC G AMES  R. V. Vohraa and M. P. Wellman. Foundations of multi-agent learning: Introduction to the special issue. Artiﬁcial Intelligence, 7:363–364, 2007. X. Wang and T. Sandholm. Reinforcement learning to play an optimal nash equilibrium in team markov games. In NIPS’02, 2002. Z. Zheng, M. Shu-gen, C. Bing-gang, Z. Li-ping, and L. Bin. Multiagent reinforcement learning for a planetary exploration multirobot system. In PRIMA, pages 339–350, 2006.  2675</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
