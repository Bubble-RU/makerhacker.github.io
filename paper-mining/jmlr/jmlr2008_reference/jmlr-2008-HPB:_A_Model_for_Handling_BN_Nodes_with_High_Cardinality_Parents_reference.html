<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>42 jmlr-2008-HPB: A Model for Handling BN Nodes with High Cardinality Parents</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-42" href="../jmlr2008/jmlr-2008-HPB%3A_A_Model_for_Handling_BN_Nodes_with_High_Cardinality_Parents.html">jmlr2008-42</a> <a title="jmlr-2008-42-reference" href="#">jmlr2008-42-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>42 jmlr-2008-HPB: A Model for Handling BN Nodes with High Cardinality Parents</h1>
<br/><p>Source: <a title="jmlr-2008-42-pdf" href="http://jmlr.org/papers/volume9/jambeiro08a/jambeiro08a.pdf">pdf</a></p><p>Author: Jorge Jambeiro Filho, Jacques Wainer</p><p>Abstract: We replaced the conditional probability tables of Bayesian network nodes whose parents have high cardinality with a multilevel empirical hierarchical Bayesian model called hierarchical pattern Bayes (HPB).1 The resulting Bayesian networks achieved signiÄ?Ĺš cant performance improvements over Bayesian networks with the same structure and traditional conditional probability tables, over Bayesian networks with simpler structures like naĂ&sbquo;Â¨ve Bayes and tree augmented naĂ&sbquo;Â¨ve Bayes, over Ă&bdquo;Ä&hellip; Ă&bdquo;Ä&hellip; Bayesian networks where traditional conditional probability tables were substituted by noisy-OR gates, default tables, decision trees and decision graphs and over Bayesian networks constructed after a cardinality reduction preprocessing phase using the agglomerative information bottleneck method. Our main tests took place in important fraud detection domains, which are characterized by the presence of high cardinality attributes and by the existence of relevant interactions among them. Other tests, over UCI data sets, show that HPB may have a quite wide applicability. Keywords: probabilistic reasoning, Bayesian networks, smoothing, hierarchical Bayes, empirical Bayes</p><br/>
<h2>reference text</h2><p>Greg M. Allenby, Robert P. Leone, and Lichung Jen. A dynamic model of purchase timing with application to direct marketing. Journal of the American Statistical Association, 94(446):365Ă˘&euro;&ldquo; 374, 1999. Steen Andreassen, Brian Kristensen, Alina Zalounina, Leonard Leibovici, Uwe Frank, and Henrik C. Schonheyder. Hierarchical dirichlet learning - Ä?Ĺš lling in the thin spots in a database. In Michel Dojat, Elpida T. Keravnou, and Pedro Barahona, editors, Proceedings of the 9th Conference on ArtiÄ?Ĺš cial Intelligence in Medicine (AIME), volume 2780 of Lecture Notes in Computer Science, pages 204Ă˘&euro;&ldquo;283. Springer, 2003. Paul N. Bennett. Assessing the calibration of naive bayesĂ˘&euro;&trade; posterior estimates. Technical Report CMU-CS-00-155, School of Computer Science, Carnegie Mellon University, 2000. Marc BoullĂ&sbquo;Â´ . A bayes optimal approach for partitioning the values of categorical attributes. Journal e of Machine Learning Research, 6:1431Ă˘&euro;&ldquo;1452, 2005. Bojan Cestnik. Estimating probabilities: a crucial task in machine learning. In Proceedings of the European Conference on ArtiÄ?Ĺš cial Intelligence, pages 147Ă˘&euro;&ldquo;149, 1990. Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. Smote: Synthetic minority over-sampling technique. Journal of ArtiÄ?Ĺš cial Intelligence and Research, 16: 321Ă˘&euro;&ldquo;357, 2002. David Maxwell Chickering, David Heckerman, and Christopher Meek. A bayesian approach to learning bayesian networks with local structure. In Proceedings of the 13th Conference on Uncertainty in ArtiÄ?Ĺš cial Intelligence (UAI), pages 80Ă˘&euro;&ldquo;89, San Franscisco, CA, 1997. Morgan Kaufman. Pedro Domingos and Michael J. Pazzani. On the optimality of the simple bayesian classiÄ?Ĺš er under zero-one loss. Machine Learning, 29(2-3):103Ă˘&euro;&ldquo;130, 1997. Richard O. Duda and Peter E. Hart. Pattern ClassiÄ?Ĺš cation and Scene Analysis. Wiley, New York, 1973. James P. Egan. Signal Detection Theory and Roc Analysis. Academic Press, New York, 1975. 2168  HPB: A M ODEL FOR H ANDLING BN N ODES WITH H IGH C ARDINALITY PARENTS  Nir Friedman and Moises Goldszmidt. Building classiÄ?Ĺš ers using bayesian networks. In Proceedings of the American Association for ArtiÄ?Ĺš cial Intelligence (AAAI)/Innovative Applications of ArtiÄ?Ĺš cial Intelligence (IAAI), volume 2, pages 1277Ă˘&euro;&ldquo;1284, 1996a. Nir Friedman and Moises Goldszmidt. Learning bayesian networks with local structure. In Proceedings of the Twelfth Conference on Uncertainty in ArtiÄ?Ĺš cial Inteligence (UAI), pages 252Ă˘&euro;&ldquo;262, San Francisco, CA, 1996b. Morgan Kaufmann Publishers. Nir Friedman, Dan Geiger, and Moises Goldszmidt. Bayesian network classiÄ?Ĺš ers. Machine Learning, 29(2-3):131Ă˘&euro;&ldquo;163, 1997. Yu Fujimoto and Noboru Murata. Robust estimation for mixture of probability tables based on beta-likelihood. In Joydeep Ghosh, Diane Lambert, David B. Skillicorn, and Jaideep Srivastava, editors, Proceedings of the Sixth SIAM International Conference on Data Mining. SIAM, 2006. Andrew B. Gelman, John S. Carlin, Hal S. Stern, and Donald B. Rubin. Bayesian Data Analysis. Chapman and Hall, 2. edition, 2003. V. Hamine and P. Helman. Learning optimal augmented bayes networks. Technical Report TR-CS2004-11, Computer Science Department, University of New Mexico, 2004. Jorge Jambeiro Filho and Jacques Wainer. Using a hierarchical bayesian model to handle high cardinality attributes with relevant interactions in a classiÄ?Ĺš cation problem. In Proceedings of the International Joint Conference of ArtiÄ?Ĺš cial Intelligence (IJCAI). AAAI Press, 2007. Eamonn J. Keogh and Michael J. Pazzani. Learning augmented bayesian classiÄ?Ĺš ers: A comparison of distribution-based and classiÄ?Ĺš cation-based approaches. In Proceeeding of the Seventh International Workshop on ArtiÄ?Ĺš cial Intelligence and Statistics, pages 225Ă˘&euro;&ldquo;230, Ft. Lauderdale, FL, 1999. Peter Lenk, Wayne DeSarbo, Paul Green, and Martin Young. Hierarchical bayes conjoint analysis: recovery of part worth heterogeneity from reduced experimental designs. Marketing Science, 15: 173Ă˘&euro;&ldquo;191, 1996. Daniele Micci-Barreca. A preprocessing scheme for high-cardinality categorical attributes in classiÄ?Ĺš cation and prediction problems. SIGKDD Explor. Newsl., 3(1):27Ă˘&euro;&ldquo;32, 2001. Judea Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers Inc., 1988. ISBN 1558604790. Irina Rish, Joseph Hellerstein, and Jayram Thathachar. An analysis of data characteristics that affect naive bayes performance. Technical Report RC21993, Watson Research Center, 2001. Noam Slonim and Naftali Tishby. Agglomerative information bottleneck. In Advances in Neural Information Processing Systems 12 (NIPS), pages 617Ă˘&euro;&ldquo;623, Denver, Colorado, USA, 1999. The MIT Press. ISBN 0-262-19450-3. Benjamin Stewart, Jonathan Ko, Dieter Fox, and Kurt Konolige. The revisiting problem in mobile robot map building: A hierarchical bayesian approach. In Christopher Meek and Uffe KjÄ&sbquo;Ĺ&scaron;rulff, editors, Proceedings of the 19th Conference in Uncertainty in ArtiÄ?Ĺš cial Intelligence (UAI), pages 551Ă˘&euro;&ldquo;558, Acapulco, Mexico, 2003. Morgan Kaufmann. ISBN 0-127-05664-5. 2169  JAMBEIRO AND WAINER  Ian H. Witten and Eibe Frank. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann Publishers Inc., 1999. Bianca Zadrozny. Reducing multiclass to binary by coupling probability estimates. In Proceedings of the Advances in Neural Information Processing Systems 14 (NIPS), Cambridge, MA, 2001. MIT Press. Bianca Zadrozny and Charles Elkan. Transforming classiÄ?Ĺš er scores into accurate multiclass probability estimates. In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 694Ă˘&euro;&ldquo;699. ACM Press, 2002. Bianca Zadrozny and Charles Elkan. Obtaining calibrated probability estimates from decision trees and naive bayesian classiÄ?Ĺš ers. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML), pages 609Ă˘&euro;&ldquo;616, MA, USA, 2001. Morgan Kaufmann. ISBN 1-55860778-1. Harry Zhang and Jiang Su. Naive bayesian classiÄ?Ĺš ers for ranking. Lecture Notes in Computer Science, 3201:501Ă˘&euro;&ldquo;512, 2004. Mu Zhu. Recall, precision and average precision. Technical Report 09, Department of Statistics & Actuarial Science, University of Waterloo, 2004.  2170</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
