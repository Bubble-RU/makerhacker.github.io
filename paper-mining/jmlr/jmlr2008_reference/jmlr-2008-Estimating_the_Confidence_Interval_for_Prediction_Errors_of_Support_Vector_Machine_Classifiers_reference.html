<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-32" href="../jmlr2008/jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">jmlr2008-32</a> <a title="jmlr-2008-32-reference" href="#">jmlr2008-32-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</h1>
<br/><p>Source: <a title="jmlr-2008-32-pdf" href="http://jmlr.org/papers/volume9/jiang08a/jiang08a.pdf">pdf</a></p><p>Author: Bo Jiang, Xuegong Zhang, Tianxi Cai</p><p>Abstract: Support vector machine (SVM) is one of the most popular and promising classiﬁcation algorithms. After a classiﬁcation rule is constructed via the SVM, it is essential to evaluate its prediction accuracy. In this paper, we develop procedures for obtaining both point and interval estimators for the prediction error. Under mild regularity conditions, we derive the consistency and asymptotic normality of the prediction error estimators for SVM with ﬁnite-dimensional kernels. A perturbationresampling procedure is proposed to obtain interval estimates for the prediction error in practice. With numerical studies on simulated data and a benchmark repository, we recommend the use of interval estimates centered at the cross-validated point estimates for the prediction error. Further applications of the proposed procedure in model evaluation and feature selection are illustrated with two examples. Keywords: k-fold cross-validation, model evaluation, perturbation-resampling, prediction errors, support vector machine</p><br/>
<h2>reference text</h2><p>L. Beerenwinkel, B. Schmidt, H. Walter, R. Kaiser, T. Lengauer, D. Hoffmann, K. Korn, and J. Selbig. Diversity and complexity of HIV-1 drug resistance: A bioinformatics approach to predicting phenotype from genotype. Proceedings of the National Academy of Sciences U.S.A., 99:8271– 8276, 2002. Y. Bengio and Y. Grandvalet. No unbiased estimator of the variance of k-fold cross-validation. Journal of Machine Learning Research, 5:1089–1105, 2004. O. Bousquet and A. Elisseeff. Stability and generalization. Journal of Machine Learning Research, 2:499–526, 2002. T. Cai, L. Tian, and L. J. Wei. Semiparametric Box-Cox power transformation models for censored survival observations. Biometrika, 92:619–632, 2005. R. E. Campo, J. N. Moreno, G. Suarez, N. Miller, M. A. Kolber, D. J. Holder, M. Shivaprakash, D. M. DeAngelis, J. L. Wright, W. A. Schleif, E. A. Emini, and J. H. Condra. Efﬁcacy of indinavir-ritonavir-based regimens in HIV-1-infected patients with prior protease inhibitor failures. AIDS, 17:1933–1939, 2003. 537  J IANG , Z HANG AND C AI  C. C. Chang and C. H. Lin. Libsvm—a library for support vector machine. http://www.csie.ntu.edu.tw/cjlin/libsvm/, 2001.  Available at  T. Dietterich. Approximate statistical tests for comparing supervised classiﬁcation learning algorithms. Neural Computation, 10:1895–1923, 1998. R. M. Dudley. Uniform Central Limit Theorems. Cambridge, U.K.: Cambridge University Press, 1999. B. Efron. Bootstrap methods: Another look at the jackknife. The Annals of Statistics, 7:1–26, 1979. B. Efron. How biased is the apparent error rate of a prediction rule. Journal of the American Statistical Association, 81:461–470, 1986. B. Efron. Better bootstrap conﬁdence intervals. Journal of the American Statistical Association, 82: 171–185, 1987. B. Efron and R. Tibshirani. Cross-validation and the bootstrap: Estimating the error rate of a prediction rule. Technical report, Stanford University, 1995. B. Efron and R. Tibshirani. Improvements on cross-validation: The .632+ bootstrap method. Journal of the American Statistical Association, 92:548–560, 1997. W. J. Fu, R. J. Carroll, and S. Wang. Estimating misclassiﬁcation error with small samples via bootstrap cross-validation. Bioinformatics, 21:1979–1986, 2005. P. Hall and Y. Maesono. A weighted bootstrap approach to bootstrap iteration. Journal of the Royal Statistical Society Series B, 62:137–144, 2000. P. Hall and E. Mammen. On general resampling algorithms and their performance in distribution estimation. The Annals of Statistics, 22:2011–2030, 1994. N. L. Hjort and D. Pollard. Asymptotics for minimizers of convex processes. Technical report, Yale University, 1993. M. Kearns and D. Ron. Algorithmic stability and sanity check bounds for leave-one-out crossvalidation. Neural Computation, 11:1427–1453, 1999. R. Y. Liu. Bootstrap procedures under some non-i.i.d. models. The Annals of Statistics, 16:1696– 1708, 1988. S. Mika, G. Ratsch, J. Weston, B. Scholkopf, and K. R. Muller. Fisher discriminant analysis with ¨ ¨ ¨ kernels. In Neural Networks for Signal Processing IX, pages 41–48, 1999. A. Molinaro, R. Simon, and R. Pfeiffer. Prediction error estimation: A comparison of resampling methods. Bioinformatics, 21:3301–3307, 2005. C. Nadeau and Y. Bengio. Inference for the generalization error. Machine Learning, 52:239–281, 2003. 538  E STIMATING THE C ONFIDENCE I NTERVAL FOR P REDICTION E RRORS OF SVM  W. Newey and D. McFadden. Large sample estimation and hypothesis testing. In D. McFadden and R. Engler, editors, Handbook of Econometrics IV, pages 2113–2245. Amsterdam: North Holland, 1994. M. F. Para, D. V. Glidden, R. Coombs, A. Collier, J. Condra, C. Craig, R. Bassett, R. Leavitt, S. Snyder, V. J. McAuliffe, and C. Boucher. Baseline human immunodeﬁciency virus type I phenotype, genotype, and RNA response after switching from long-term hard-capsule saquinavir to indinavir or soft-gel-capsule saquinavir in AIDS clinical trials group protocol 333. Journal of Infectious Diseases, 182:733–743, 2000. Y. Park and L. J. Wei. Estimating subject-speciﬁc survival functions under the accelerated failure time model. Biometrika, 90:717–723, 2003. D. Pollard. Empirical Process: Theory and Applications. Hayward, CA: Institute of Mathematical Statistics, 1990. D. Pollard. Asymptotics for least absolute deviation regression estimators. Econometric Theory, 7: 186–199, 1991. J. Reunanen. Overﬁtting in making comparisons between variable selection methods. Journal of Machine Learning Research, 3:1371–1382, 2003. S. Y. Rhee, M. J. Gonzales, R. Kantor, B. J. Betts, J. Ravela, and R. W. Shafer. Human immunodeﬁciency virus reverse transcriptase and protease sequence database. Nucleic Acids Research, 31: 298–303, 2003. D. Rubin. The bayesian bootstrap. The Annals of Statistics, 9:130–134, 1981. A. J. Saah, D. W. Haas, M. J. DiNubile, J. Chen, D. J. Holder, R. R. Rhodes, M. Shivaprakash, K. K. Bakshi, R. M. Danovich, D. J. Graham, and J. H. Condra. Treatment with indinavir, efavirenz, and adefovir after failure of nelﬁnavir therapy. Journal of Infectious Diseases, 187:1157–1162, 2003. J. Shao. Bootstrap model selection. Journal of the American Statistical Association, 91:655–665, 1996. N. Shulman, A. Zolopa, D. Havlir, A. Hsu, C. Renz, S. Boller, P. Jiang, R. Rode, J. Gallant, E. Race, D. J. Kempf, and E. Sun. Virtual inhibitory quotient predicts response to ritonavir boosting of indinavir-based therapy in human immunodeﬁciency virus-infected patients with ongoing viremia. Antimicrobial Agents and Chemotherapy, 146:3907–3916, 2002. I. Steinwart. Support vector machines are universally consistent. Journal of Complexity, 18:768– 779, 2002. A. W. van der Vaart and J. A. Wellner. Weak Convergence and Empirical Processes. New York: Springer-Verlag Inc., 1996. V. N. Vapnik. The Nature of Statistical Learning Theory. New York: Springer, 1995. V. N. Vapnik. Statistical Learning Theory. New York: John Wiley and Sons Inc., 1998. 539  J IANG , Z HANG AND C AI  S. Varma and R. Simon. Bias in error estimation when using cross-validation for model selection. BMC Bioinformatics, 7:91, 2006. C. F. J. Wu. Jackknife, bootstrap, and other resampling methods in regression analysis (with discussion). The Annals of Statistics, 14:1261–1295, 1986.  540</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
