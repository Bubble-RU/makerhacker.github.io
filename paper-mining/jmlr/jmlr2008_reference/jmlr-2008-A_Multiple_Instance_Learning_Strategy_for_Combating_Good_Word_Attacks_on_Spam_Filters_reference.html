<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>4 jmlr-2008-A Multiple Instance Learning Strategy for Combating Good Word Attacks on Spam Filters</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-4" href="../jmlr2008/jmlr-2008-A_Multiple_Instance_Learning_Strategy_for_Combating_Good_Word_Attacks_on_Spam_Filters.html">jmlr2008-4</a> <a title="jmlr-2008-4-reference" href="#">jmlr2008-4-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>4 jmlr-2008-A Multiple Instance Learning Strategy for Combating Good Word Attacks on Spam Filters</h1>
<br/><p>Source: <a title="jmlr-2008-4-pdf" href="http://jmlr.org/papers/volume9/jorgensen08a/jorgensen08a.pdf">pdf</a></p><p>Author: Zach Jorgensen, Yan Zhou, Meador Inge</p><p>Abstract: Statistical spam ﬁlters are known to be vulnerable to adversarial attacks. One of the more common adversarial attacks, known as the good word attack, thwarts spam ﬁlters by appending to spam messages sets of “good” words, which are words that are common in legitimate email but rare in spam. We present a counterattack strategy that attempts to differentiate spam from legitimate email in the input space by transforming each email into a bag of multiple segments, and subsequently applying multiple instance logistic regression on the bags. We treat each segment in the bag as an instance. An email is classiﬁed as spam if at least one instance in the corresponding bag is spam, and as legitimate if all the instances in it are legitimate. We show that a classiﬁer using our multiple instance counterattack strategy is more robust to good word attacks than its single instance counterpart and other single instance learners commonly used in the spam ﬁltering domain. Keywords: spam ﬁltering, multiple instance learning, good word attack, adversarial learning</p><br/>
<h2>reference text</h2><p>S. Andrews, I. Tsochantaridis, and T. Hofmann. Support vector machines for multiple-instance learning. In NIPS 15, pages 561–568. MIT Press, 2003.  P. Auer. On learning from multi-instance examples: Empirical evaluation of a theoretical approach. In Proceedings of the 14th International Conference on Machine Learning, pages 21–29, San Francisco, CA, 1997. Morgan Kaufmann. 1143  J ORGENSEN , Z HOU AND I NGE  M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar. Can machine learning be secure? In ASIACCS ’06: Proceedings of the 2006 ACM Symposium on Information, computer and communications security, pages 16–25, New York, NY, USA, 2006. ACM Press. ISBN 1-59593-272-0. doi: http://doi.acm.org/10.1145/1128817.1128824. A. Blum and A. Kalai. A note on learning from multiple-instance examples. Machine Learning, 30 (1):23–30, 1998. A.  Bratko. Probabilistic sequence http://ai.ijs.si/andrej/psmslib.html, 2008.  modeling  shared  library.  A. Bratko and B. Filipiˇ . Spam ﬁltering using compression models. Technical Report IJS-DP-9227, c Department of Intelligent Systems, Joˇ ef Stefan Institute, Ljubljana, Slovenia, 2005. z J. Carpinter and R. Hunt. Tightening the net: A review of current and next generation spam ﬁltering tools. Computers and Security, 25(8):566–578, 2006. Y. Chen and J.Z. Wang. Image categorization by learning and reasoning with regions. Journal of Machine Learning Research, 5:913–939, 2004. Y. Chevaleyre and J.D. Zucker. Solving multiple-instance and multiple-part learning problems with decision trees and rule sets. application to the mutagenesis problem. In Proceedings of the 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, pages 204–214, 2001. G. V. Cormack and T. R. Lynam. Spam track guidelines — TREC 2005-2007. http://plg.uwaterloo.ca/ gvcormac/treccorpus06/, 2006. N. Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma. Adversarial classiﬁcation. In Proceedings of the 2004 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 99–108. ACM Press, 2004. T.G. Dietterich, R.H. Lathrop, and T. Lozano-P´ rez. Solving the multiple-instance problem with e axis-parallel rectangles. Artiﬁcial Intelligence Journal, 89(1-2):31–71, 1997. T. Fawcett. An introduction to ROC analysis. Pattern Recognition Letters, 27:861–874, 2006. T. G¨ rtner, P. Flach, A. Kowalczyk, and A. Smola. Multi-instance kernels. In Proceedings of the a 19th International Conference on Machine Learning, pages 179–186, San Francisco, CA, 2002. Morgan Kaufmann. R. Jennings. The global economic impact of spam. Technical report, Ferris Research, 2005. A.M. Kibriya, E. Frank, B. Pfahringer, and G. Holmes. Multinomila naive bayes for text categorization revisited. In Proceedings of the 17th Australian Joint Conference on Artiﬁcial Intelligence, pages 488–499. Springer, 2004. J.Z. Kolter and M.A. Maloof. Using additive expert ensembles to cope with concept drift. In Proceedings of the Twenty-second International Conference on Machine Learning, pages 449– 456, New York, NY, 2005. ACM Press. 1144  C OMBATING G OOD W ORD ATTACKS ON S PAM F ILTERS  H. Lee and A. Ng. Spam deobfuscation using a hidden Markov model. In Proceedings of the Second Conference on Email and Anti-Spam, 2005. P. Long and L. Tan. PAC learning axis-aligned rectangles with respect to product distribution from multiple-instance examples. Machine Learning, 30(1):7–21, 1998. D. Lowd and C. Meek. Adversarial learning. In Proceedings of the 2005 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 641–647. ACM Press, 2005a. D. Lowd and C. Meek. Good word attacks on statistical spam ﬁlters. In Proceedings of the 2nd Conference on Email and Anti-Spam, 2005b. O. Maron and T. Lozano-P´ rez. A framework for multiple-instance learning. Advances in Neural e Information Processing Systems, 10:570–576, 1998. J. Newsome, B. Karp, and D. Song. Paragraph: Thwarting signature learning by training maliciously. In Recent Advances in Intrusion Detection: 9th International Symposium (RAID), pages 81–105, 2006. J. Ramon and L.D. Raedt. Multi instance neural networks. In Proceedings of ICML-2000 workshop on Attribute-Value and Relational Learning, 2000. S. Ray and M. Craven. Supervised versus multiple instance learning: An empirical comparison. In Proceedings of the 22nd International Conference on Machine Learning, pages 697–704, New York, NY, 2005. ACM Press. J. Rocchio Jr. Relevance feedback in information retrieval. In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 68–73. Prentice Hall, 1971. J. Wang and J.D. Zucker. Solving the multiple-instance learning problem: A lazy learning approach. In Proceedings of the 17th International Conference on Machine Learning, pages 1119–1125, San Francisco, CA, 2000. Morgan Kaufmann. S. Webb, S. Chitti, and C. Pu. An experimental evaluation of spam ﬁlter performance and robustness against attack. In The 1st International Conference on Collaborative Computing: Networking, Applications and Worksharing, pages 19–21, 2005. I.H. Witten and E. Frank. Data Mining: Practical Machine Learning Tools with Java Implementations. Morgan Kaufmann, San Francisco, CA, USA, 2000. X. Xu. Statistical learning in multiple instance problems. Master’s thesis, University of Waikato, 2003. X. Xu and E. Frank. Logistic regression and boosting for labeled bags of instances. In Proceedings of the Paciﬁc-Asian Conference on Knowledge discovery and data mining. Springer-Verlag, 2004. W. Yih, J. Goodman, and G. Hulten. Learning at low false positive rates. In Proceedings of the Third Conference on Email and Anti-Spam, 2006. 1145  J ORGENSEN , Z HOU AND I NGE  M.-L. Zhang and Z.-H. Zhou. Multi-label learning by instance differentiation. In The 22nd AAAI Conference on Artiﬁcial Intelligence (AAAI’07), pages 669–674, Vancouver, Canada, 2007. Q. Zhang and S. Goldman. EM-DD: An improved multiple-instance learning technique. In Proceedings of the 2001 Neural Information Processing Systems (NIPS) Conference, pages 1073–1080, Cambridge, MA, 2002. MIT Press. Z.H. Zhou and M.L. Zhang. Ensembles of multi-instance learners. In ECML-03, 15th European Conference on Machine Learning, pages 492–502, 2003.  1146</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
