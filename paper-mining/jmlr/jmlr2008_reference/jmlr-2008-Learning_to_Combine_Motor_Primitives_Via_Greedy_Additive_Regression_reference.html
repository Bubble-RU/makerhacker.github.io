<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-53" href="../jmlr2008/jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">jmlr2008-53</a> <a title="jmlr-2008-53-reference" href="#">jmlr2008-53-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</h1>
<br/><p>Source: <a title="jmlr-2008-53-pdf" href="http://jmlr.org/papers/volume9/chhabra08a/chhabra08a.pdf">pdf</a></p><p>Author: Manu Chhabra, Robert A. Jacobs</p><p>Abstract: The computational complexities arising in motor control can be ameliorated through the use of a library of motor synergies. We present a new model, referred to as the Greedy Additive Regression (GAR) model, for learning a library of torque sequences, and for learning the coefﬁcients of a linear combination of sequences minimizing a cost function. From the perspective of numerical optimization, the GAR model is interesting because it creates a library of “local features”—each sequence in the library is a solution to a single training task—and learns to combine these sequences using a local optimization procedure, namely, additive regression. We speculate that learners with local representational primitives and local optimization procedures will show good performance on nonlinear tasks. The GAR model is also interesting from the perspective of motor control because it outperforms several competing models. Results using a simulated two-joint arm suggest that the GAR model consistently shows excellent performance in the sense that it rapidly learns to perform novel, complex motor tasks. Moreover, its library is overcomplete and sparse, meaning that only a small fraction of the stored torque sequences are used when learning a new movement. The library is also robust in the sense that, after an initial training period, nearly all novel movements can be learned as additive combinations of sequences in the library, and in the sense that it shows good generalization when an arm’s dynamics are altered between training and test conditions, such as when a payload is added to the arm. Lastly, the GAR model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. We conclude that learning techniques using local primitives and optimization procedures are viable and potentially important methods for motor control and possibly other domains, and that these techniques deserve further examination by the artiﬁcial intelligence and cognitive science</p><br/>
<h2>reference text</h2><p>C. G. Atkeson and D. J. Reinkensmeyer. Using associative content-addressable memories to control robots. In W. T. Miller III, R. S. Sutton, and P. J. Werbos, editors,, Neural Networks for Control. MIT Press, 1990. C. G. Atkeson, A. W. Moore, and S. Schaal. Locally weighted learning for control. Artiﬁcial Intelligence Review, 11:75-113, 1997. D. C. Bentivegna. Learning from Observation Using Primitives. Ph.D. dissertation, Georgia Institute of Technology, 2004. N. Bernstein. The Coordination and Regulation of Movements. Pergamon Press, 1967. P. B¨ hlmann. Boosting methods: Why they can be useful for high-dimensional data. In Proceedings u of the 3rd International Workshop on Distributed Statistical Computing (DSC), 2003. M. Chhabra and R. A. Jacobs. Properties of synergies arising from a theory of optimal motor behavior. Neural Computation, 18:2320-2342, 2006. P. Corke. A robotics toolbox for MATLAB. IEEE Robotics and Automation Magazine, 3:24-32, 1996. A. d’Avella, P. Saltiel, and E. Bizzi. Combinations of muscle synergies in the construction of a natural motor behavior. Nature Neuroscience, 6:300-308, 2003. A. Fod, M. J. Matari´ , and O. C. Jenkins. Automated derivation of primitives for movement classic ﬁcation. Autonomous Robots, 12:39-54, 2002. Y. Freund and R. E. Schapire. A decision- theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55:119-139, 1997. J. H. Friedman. Greedy function approximation: A gradient boosting machine. Annals of Statistics, 29:1189-1232, 2001. J. M. Hollerbach and T. Flash. Dynamic interactions between limb segments during planar arm movement. Biological Cybernetics, 44:67-77, 1982. A. Ijspeert, J. Nakanishi, and S. Schaal. Learning attractor landscapes for learning motor primitives. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15. MIT Press, 2003. O. C. Jenkins and M. J. Matari´ . A spatio-temporal extension to Isomap nonlinear dimension rec duction. In Proceedings of the 21st International Conference on Machine Learning, 2004. 1556  L EARNING TO C OMBINE M OTOR P RIMITIVES  M. Kawato, K. Furukawa, and R. Suzuki. Hierarchical neural-network model for control and learning of voluntary movement. Biological Cybernetics, 57:169-185, 1987. M. Lau and J. J. Kuffner. Behavior planning for character animation. In Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, 2005. J. Lee, J. Chai, P. S. A. Reitsma, J. K. Hodgins, and N. S. Pollard. Interactive control of avatars animated with human motion data. ACM Transactions on Graphics (SIGGRAPH), 21:491-500, 2002. M. S. Lewicki and T. J. Sejnowski. Learning overcomplete representations. Neural Computation, 12:337-365, 2000. W. Li and E. Todorov. Iterative linear-quadratic regulator design for nonlinear biological movement systems. In Proceedings of the First International Conference on Informatics in Control, Automation, and Robotics, 2004. S. Mallat and Z. Zhang. Matching pursuit with time-frequency dictionaries. IEEE Transactions on Signal Processing, 41:3397-3415, 1993. T. W. Miller III, F. H. Glanz, and L. G. Kraft. Application of a general learning algorithm to the control of robotic manipulators. International Journal of Robotic Research, 6:84-98, 1987. F. A. Mussa-Ivaldi, S. F. Giszter, and E. Bizzi. Linear combination of primitives in vertebrate motor control. Proceedings of the National Academy of Sciences USA, 91:7534-7538, 1994. S. Perkins, K. Lacker, and J. Theiler. Grafting: Fast, incremental feature selection by gradient descent in function space. Journal of Machine Learning Research, 3:1333-1356, 2003. J. Peters and S. Schaal. Reinforcement learning for parameterized motor primitives. In Proceedings of the International Joint Conference on Neural Networks, 2006. W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. Numerical Recipes in C: The Art of Scientiﬁc Computing. Cambridge University Press, 1992. A. Safanova, J. K. Hodgins, and N. S. Pollard. Synthesizing physically realistic human motion in low-dimensional, behavior-speciﬁc spaces. ACM Transactions on Graphics (SIGGRAPH), 23:514-521, 2004. T. D. Sanger. Optimal unsupervised motor learning for dimensionality reduction of nonlinear control systems. IEEE Transactions on Neural Networks, 5:965-973, 1994. T. D. Sanger. Optimal movement primitives. In G. Tesauro, D. S. Touretzky, and T. K. Leen, editors, Advances in Neural Information Processing Systems 7. MIT Press, 1995. R. E. Schapire. The strength of weak learnability. Machine Learning, 5:197-227, 1990. E. C. Smith and M. S. Lewicki. Efﬁcient auditory coding. Nature, 439:978-982, 2006. M. Stolle and C. G. Atkeson. Policies based on trajectory libraries. In Proceedings of the International Conference on Robotics and Automation (ICRA), 2006. 1557  C HHABRA AND JACOBS  R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour. Policy gradient methods for reinforcement ¨ learning with function approximation. In S. A. Solla, T. K. Leen, and K.-R. M uller, editors, Advances in Neural Information Processing Systems 12. MIT Press, 1999. Y. Tassa, T. Erez, and W. Smart. Receding horizon differential dynamic programming. In J. C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20. MIT Press, 2008. K. A. Thoroughman and R. Shadmehr. Learning of action through adaptive combination of motor primitives. Nature, 407:742-747, 2000. E. Todorov and Z. Ghahramani. Unsupervised learning of sensory-motor primitives. In Proceedings of the 25th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 2003. E. Todorov and Z. Ghahramani. Analysis of the synergies underlying complex hand manipulation. In Proceedings of the 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 2004. P. Viola and M. Jones. Robust real-time face detection. International Journal of Computer Vision, 57:137-154, 2004. R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, 8:229-256, 1992.  1558</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
