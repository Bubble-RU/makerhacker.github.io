<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>82 jmlr-2012-On the Necessity of Irrelevant Variables</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-82" href="#">jmlr2012-82</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>82 jmlr-2012-On the Necessity of Irrelevant Variables</h1>
<br/><p>Source: <a title="jmlr-2012-82-pdf" href="http://jmlr.org/papers/volume13/helmbold12a/helmbold12a.pdf">pdf</a></p><p>Author: David P. Helmbold, Philip M. Long</p><p>Abstract: This work explores the effects of relevant and irrelevant boolean variables on the accuracy of classiﬁers. The analysis uses the assumption that the variables are conditionally independent given the class, and focuses on a natural family of learning algorithms for such sources when the relevant variables have a small advantage over random guessing. The main result is that algorithms relying predominately on irrelevant variables have error probabilities that quickly go to 0 in situations where algorithms that limit the use of irrelevant variables have errors bounded below by a positive constant. We also show that accurate learning is possible even when there are so few examples that one cannot determine with high conﬁdence whether or not any individual variable is relevant. Keywords: feature selection, generalization, learning theory</p><p>Reference: <a title="jmlr-2012-82-reference" href="../jmlr2012_reference/jmlr-2012-On_the_Necessity_of_Irrelevant_Variables_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ln', 0.47), ('irrelev', 0.33), ('elmbold', 0.266), ('prel', 0.266), ('ecess', 0.245), ('pirrel', 0.245), ('rrelev', 0.245), ('relev', 0.188), ('vot', 0.165), ('agr', 0.14), ('mislead', 0.138), ('exp', 0.136), ('edg', 0.13), ('ong', 0.105), ('donoho', 0.102), ('fract', 0.091), ('bound', 0.089), ('label', 0.088), ('goe', 0.078), ('ke', 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="82-tfidf-1" href="./jmlr-2012-On_the_Necessity_of_Irrelevant_Variables.html">82 jmlr-2012-On the Necessity of Irrelevant Variables</a></p>
<p>2 0.18330324 <a title="82-tfidf-2" href="./jmlr-2012-On_Ranking_and_Generalization_Bounds.html">80 jmlr-2012-On Ranking and Generalization Bounds</a></p>
<p>3 0.15457833 <a title="82-tfidf-3" href="./jmlr-2012-Multi-Instance_Learning_with_Any_Hypothesis_Class.html">71 jmlr-2012-Multi-Instance Learning with Any Hypothesis Class</a></p>
<p>4 0.15374474 <a title="82-tfidf-4" href="./jmlr-2012-Regularization_Techniques_for_Learning_with_Matrices.html">97 jmlr-2012-Regularization Techniques for Learning with Matrices</a></p>
<p>5 0.13834864 <a title="82-tfidf-5" href="./jmlr-2012-Active_Learning_via_Perfect_Selective_Classification.html">13 jmlr-2012-Active Learning via Perfect Selective Classification</a></p>
<p>6 0.12043102 <a title="82-tfidf-6" href="./jmlr-2012-Multi-task_Regression_using_Minimal_Penalties.html">73 jmlr-2012-Multi-task Regression using Minimal Penalties</a></p>
<p>7 0.10472525 <a title="82-tfidf-7" href="./jmlr-2012-Noise-Contrastive_Estimation_of_Unnormalized_Statistical_Models%2C_with_Applications_to_Natural_Image_Statistics.html">76 jmlr-2012-Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics</a></p>
<p>8 0.10331069 <a title="82-tfidf-8" href="./jmlr-2012-Fast_Approximation_of_Matrix_Coherence_and_Statistical_Leverage.html">43 jmlr-2012-Fast Approximation of Matrix Coherence and Statistical Leverage</a></p>
<p>9 0.099179812 <a title="82-tfidf-9" href="./jmlr-2012-Activized_Learning%3A_Transforming_Passive_to_Active_with_Improved_Label_Complexity.html">14 jmlr-2012-Activized Learning: Transforming Passive to Active with Improved Label Complexity</a></p>
<p>10 0.093739383 <a title="82-tfidf-10" href="./jmlr-2012-A_Primal-Dual_Convergence_Analysis_of_Boosting.html">8 jmlr-2012-A Primal-Dual Convergence Analysis of Boosting</a></p>
<p>11 0.09240257 <a title="82-tfidf-11" href="./jmlr-2012-PAC-Bayes_Bounds_with_Data_Dependent_Priors.html">87 jmlr-2012-PAC-Bayes Bounds with Data Dependent Priors</a></p>
<p>12 0.091848724 <a title="82-tfidf-12" href="./jmlr-2012-Structured_Sparsity_and_Generalization.html">111 jmlr-2012-Structured Sparsity and Generalization</a></p>
<p>13 0.08170183 <a title="82-tfidf-13" href="./jmlr-2012-Variable_Selection_in_High-dimensional_Varying-coefficient_Models_with_Global_Optimality.html">117 jmlr-2012-Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality</a></p>
<p>14 0.072392493 <a title="82-tfidf-14" href="./jmlr-2012-Coherence_Functions_with_Applications_in_Large-Margin_Classification_Methods.html">26 jmlr-2012-Coherence Functions with Applications in Large-Margin Classification Methods</a></p>
<p>15 0.069922544 <a title="82-tfidf-15" href="./jmlr-2012-Minimax-Optimal_Rates_For_Sparse_Additive_Models_Over_Kernel_Classes_Via_Convex_Programming.html">67 jmlr-2012-Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming</a></p>
<p>16 0.069836862 <a title="82-tfidf-16" href="./jmlr-2012-Bayesian_Mixed-Effects_Inference_on_Classification_Performance_in_Hierarchical_Data_Sets.html">21 jmlr-2012-Bayesian Mixed-Effects Inference on Classification Performance in Hierarchical Data Sets</a></p>
<p>17 0.058095805 <a title="82-tfidf-17" href="./jmlr-2012-Distance_Metric_Learning_with_Eigenvalue_Optimization.html">33 jmlr-2012-Distance Metric Learning with Eigenvalue Optimization</a></p>
<p>18 0.051306706 <a title="82-tfidf-18" href="./jmlr-2012-Mixability_is_Bayes_Risk_Curvature_Relative_to_Log_Loss.html">69 jmlr-2012-Mixability is Bayes Risk Curvature Relative to Log Loss</a></p>
<p>19 0.050484888 <a title="82-tfidf-19" href="./jmlr-2012-High-Dimensional_Gaussian_Graphical_Model_Selection%3A_Walk_Summability_and_Local_Separation_Criterion.html">48 jmlr-2012-High-Dimensional Gaussian Graphical Model Selection: Walk Summability and Local Separation Criterion</a></p>
<p>20 0.046534851 <a title="82-tfidf-20" href="./jmlr-2012-Conditional_Likelihood_Maximisation%3A_A_Unifying_Framework_for_Information_Theoretic_Feature_Selection.html">27 jmlr-2012-Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.282), (1, -0.118), (2, 0.154), (3, -0.116), (4, 0.135), (5, 0.201), (6, 0.075), (7, 0.225), (8, -0.009), (9, 0.075), (10, -0.066), (11, 0.092), (12, 0.131), (13, -0.038), (14, -0.142), (15, 0.226), (16, 0.026), (17, 0.072), (18, 0.138), (19, 0.001), (20, 0.033), (21, 0.016), (22, 0.048), (23, -0.028), (24, 0.075), (25, -0.006), (26, 0.0), (27, 0.031), (28, -0.138), (29, -0.087), (30, -0.112), (31, 0.031), (32, 0.039), (33, 0.012), (34, -0.023), (35, -0.059), (36, 0.066), (37, -0.046), (38, -0.023), (39, -0.077), (40, -0.065), (41, 0.047), (42, -0.013), (43, 0.028), (44, 0.077), (45, 0.067), (46, -0.03), (47, 0.045), (48, -0.053), (49, -0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93077552 <a title="82-lsi-1" href="./jmlr-2012-On_the_Necessity_of_Irrelevant_Variables.html">82 jmlr-2012-On the Necessity of Irrelevant Variables</a></p>
<p>2 0.76043725 <a title="82-lsi-2" href="./jmlr-2012-Multi-Instance_Learning_with_Any_Hypothesis_Class.html">71 jmlr-2012-Multi-Instance Learning with Any Hypothesis Class</a></p>
<p>3 0.63718194 <a title="82-lsi-3" href="./jmlr-2012-On_Ranking_and_Generalization_Bounds.html">80 jmlr-2012-On Ranking and Generalization Bounds</a></p>
<p>4 0.56392306 <a title="82-lsi-4" href="./jmlr-2012-A_Primal-Dual_Convergence_Analysis_of_Boosting.html">8 jmlr-2012-A Primal-Dual Convergence Analysis of Boosting</a></p>
<p>5 0.56096005 <a title="82-lsi-5" href="./jmlr-2012-Regularization_Techniques_for_Learning_with_Matrices.html">97 jmlr-2012-Regularization Techniques for Learning with Matrices</a></p>
<p>6 0.55450159 <a title="82-lsi-6" href="./jmlr-2012-Active_Learning_via_Perfect_Selective_Classification.html">13 jmlr-2012-Active Learning via Perfect Selective Classification</a></p>
<p>7 0.53248596 <a title="82-lsi-7" href="./jmlr-2012-Multi-task_Regression_using_Minimal_Penalties.html">73 jmlr-2012-Multi-task Regression using Minimal Penalties</a></p>
<p>8 0.51334202 <a title="82-lsi-8" href="./jmlr-2012-Activized_Learning%3A_Transforming_Passive_to_Active_with_Improved_Label_Complexity.html">14 jmlr-2012-Activized Learning: Transforming Passive to Active with Improved Label Complexity</a></p>
<p>9 0.4952876 <a title="82-lsi-9" href="./jmlr-2012-PAC-Bayes_Bounds_with_Data_Dependent_Priors.html">87 jmlr-2012-PAC-Bayes Bounds with Data Dependent Priors</a></p>
<p>10 0.4864713 <a title="82-lsi-10" href="./jmlr-2012-Structured_Sparsity_and_Generalization.html">111 jmlr-2012-Structured Sparsity and Generalization</a></p>
<p>11 0.47487944 <a title="82-lsi-11" href="./jmlr-2012-Noise-Contrastive_Estimation_of_Unnormalized_Statistical_Models%2C_with_Applications_to_Natural_Image_Statistics.html">76 jmlr-2012-Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics</a></p>
<p>12 0.424436 <a title="82-lsi-12" href="./jmlr-2012-Fast_Approximation_of_Matrix_Coherence_and_Statistical_Leverage.html">43 jmlr-2012-Fast Approximation of Matrix Coherence and Statistical Leverage</a></p>
<p>13 0.40636659 <a title="82-lsi-13" href="./jmlr-2012-Variable_Selection_in_High-dimensional_Varying-coefficient_Models_with_Global_Optimality.html">117 jmlr-2012-Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality</a></p>
<p>14 0.34312984 <a title="82-lsi-14" href="./jmlr-2012-Bayesian_Mixed-Effects_Inference_on_Classification_Performance_in_Hierarchical_Data_Sets.html">21 jmlr-2012-Bayesian Mixed-Effects Inference on Classification Performance in Hierarchical Data Sets</a></p>
<p>15 0.31223664 <a title="82-lsi-15" href="./jmlr-2012-Minimax-Optimal_Rates_For_Sparse_Additive_Models_Over_Kernel_Classes_Via_Convex_Programming.html">67 jmlr-2012-Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming</a></p>
<p>16 0.30751488 <a title="82-lsi-16" href="./jmlr-2012-Coherence_Functions_with_Applications_in_Large-Margin_Classification_Methods.html">26 jmlr-2012-Coherence Functions with Applications in Large-Margin Classification Methods</a></p>
<p>17 0.30411211 <a title="82-lsi-17" href="./jmlr-2012-Variational_Multinomial_Logit_Gaussian_Process.html">118 jmlr-2012-Variational Multinomial Logit Gaussian Process</a></p>
<p>18 0.28986883 <a title="82-lsi-18" href="./jmlr-2012-Conditional_Likelihood_Maximisation%3A_A_Unifying_Framework_for_Information_Theoretic_Feature_Selection.html">27 jmlr-2012-Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></p>
<p>19 0.28949597 <a title="82-lsi-19" href="./jmlr-2012-Mixability_is_Bayes_Risk_Curvature_Relative_to_Log_Loss.html">69 jmlr-2012-Mixability is Bayes Risk Curvature Relative to Log Loss</a></p>
<p>20 0.27771789 <a title="82-lsi-20" href="./jmlr-2012-Distance_Metric_Learning_with_Eigenvalue_Optimization.html">33 jmlr-2012-Distance Metric Learning with Eigenvalue Optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.013), (28, 0.532), (48, 0.081), (50, 0.023), (67, 0.109), (69, 0.014), (81, 0.041), (82, 0.012), (90, 0.02), (94, 0.014), (95, 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88475704 <a title="82-lda-1" href="./jmlr-2012-On_the_Necessity_of_Irrelevant_Variables.html">82 jmlr-2012-On the Necessity of Irrelevant Variables</a></p>
<p>2 0.71478814 <a title="82-lda-2" href="./jmlr-2012-A_Kernel_Two-Sample_Test.html">4 jmlr-2012-A Kernel Two-Sample Test</a></p>
<p>3 0.49450007 <a title="82-lda-3" href="./jmlr-2012-Active_Learning_via_Perfect_Selective_Classification.html">13 jmlr-2012-Active Learning via Perfect Selective Classification</a></p>
<p>4 0.46082956 <a title="82-lda-4" href="./jmlr-2012-Variational_Multinomial_Logit_Gaussian_Process.html">118 jmlr-2012-Variational Multinomial Logit Gaussian Process</a></p>
<p>5 0.45516431 <a title="82-lda-5" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>6 0.45138934 <a title="82-lda-6" href="./jmlr-2012-Multi-Instance_Learning_with_Any_Hypothesis_Class.html">71 jmlr-2012-Multi-Instance Learning with Any Hypothesis Class</a></p>
<p>7 0.44619504 <a title="82-lda-7" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>8 0.43408507 <a title="82-lda-8" href="./jmlr-2012-On_the_Convergence_Rate_oflp-Norm_Multiple_Kernel_Learning.html">81 jmlr-2012-On the Convergence Rate oflp-Norm Multiple Kernel Learning</a></p>
<p>9 0.43137518 <a title="82-lda-9" href="./jmlr-2012-Feature_Selection_via_Dependence_Maximization.html">44 jmlr-2012-Feature Selection via Dependence Maximization</a></p>
<p>10 0.43115368 <a title="82-lda-10" href="./jmlr-2012-High-Dimensional_Gaussian_Graphical_Model_Selection%3A_Walk_Summability_and_Local_Separation_Criterion.html">48 jmlr-2012-High-Dimensional Gaussian Graphical Model Selection: Walk Summability and Local Separation Criterion</a></p>
<p>11 0.43006459 <a title="82-lda-11" href="./jmlr-2012-Finite-Sample_Analysis_of_Least-Squares_Policy_Iteration.html">46 jmlr-2012-Finite-Sample Analysis of Least-Squares Policy Iteration</a></p>
<p>12 0.42936853 <a title="82-lda-12" href="./jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</a></p>
<p>13 0.42153949 <a title="82-lda-13" href="./jmlr-2012-Stability_of_Density-Based_Clustering.html">109 jmlr-2012-Stability of Density-Based Clustering</a></p>
<p>14 0.41777328 <a title="82-lda-14" href="./jmlr-2012-Activized_Learning%3A_Transforming_Passive_to_Active_with_Improved_Label_Complexity.html">14 jmlr-2012-Activized Learning: Transforming Passive to Active with Improved Label Complexity</a></p>
<p>15 0.41640288 <a title="82-lda-15" href="./jmlr-2012-Online_Submodular_Minimization.html">84 jmlr-2012-Online Submodular Minimization</a></p>
<p>16 0.40864605 <a title="82-lda-16" href="./jmlr-2012-Minimax-Optimal_Rates_For_Sparse_Additive_Models_Over_Kernel_Classes_Via_Convex_Programming.html">67 jmlr-2012-Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming</a></p>
<p>17 0.40268257 <a title="82-lda-17" href="./jmlr-2012-Exact_Covariance_Thresholding_into_Connected_Components_for_Large-Scale_Graphical_Lasso.html">40 jmlr-2012-Exact Covariance Thresholding into Connected Components for Large-Scale Graphical Lasso</a></p>
<p>18 0.40094379 <a title="82-lda-18" href="./jmlr-2012-PAC-Bayes_Bounds_with_Data_Dependent_Priors.html">87 jmlr-2012-PAC-Bayes Bounds with Data Dependent Priors</a></p>
<p>19 0.39456922 <a title="82-lda-19" href="./jmlr-2012-Integrating_a_Partial_Model_into_Model_Free_Reinforcement_Learning.html">51 jmlr-2012-Integrating a Partial Model into Model Free Reinforcement Learning</a></p>
<p>20 0.39167425 <a title="82-lda-20" href="./jmlr-2012-Plug-in_Approach_to_Active_Learning.html">91 jmlr-2012-Plug-in Approach to Active Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
