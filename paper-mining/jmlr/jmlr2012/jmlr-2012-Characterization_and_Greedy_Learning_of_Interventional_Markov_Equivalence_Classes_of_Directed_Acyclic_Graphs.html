<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>25 jmlr-2012-Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-25" href="#">jmlr2012-25</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>25 jmlr-2012-Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs</h1>
<br/><p>Source: <a title="jmlr-2012-25-pdf" href="http://jmlr.org/papers/volume13/hauser12a/hauser12a.pdf">pdf</a></p><p>Author: Alain Hauser, Peter Bühlmann</p><p>Abstract: The investigation of directed acyclic graphs (DAGs) encoding the same Markov property, that is the same conditional independence relations of multivariate observational distributions, has a long tradition; many algorithms exist for model selection and structure learning in Markov equivalence classes. In this paper, we extend the notion of Markov equivalence of DAGs to the case of interventional distributions arising from multiple intervention experiments. We show that under reasonable assumptions on the intervention experiments, interventional Markov equivalence deﬁnes a ﬁner partitioning of DAGs than observational Markov equivalence and hence improves the identiﬁability of causal models. We give a graph theoretic criterion for two DAGs being Markov equivalent under interventions and show that each interventional Markov equivalence class can, analogously to the observational case, be uniquely represented by a chain graph called interventional essential graph (also known as CPDAG in the observational case). These are key insights for deriving a generalization of the Greedy Equivalence Search algorithm aimed at structure learning from interventional data. This new algorithm is evaluated in a simulation study. Keywords: causal inference, interventions, graphical model, Markov equivalence, greedy equivalence search</p><p>Reference: <a title="jmlr-2012-25-reference" href="../jmlr2012_reference/jmlr-2012-Characterization_and_Greedy_Learning_of_Interventional_Markov_Equivalence_Classes_of_Directed_Acyclic_Graphs_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper, we extend the notion of Markov equivalence of DAGs to the case of interventional distributions arising from multiple intervention experiments. [sent-8, score-0.62]
</p><p>2 We show that under reasonable assumptions on the intervention experiments, interventional Markov equivalence deﬁnes a ﬁner partitioning of DAGs than observational Markov equivalence and hence improves the identiﬁability of causal models. [sent-9, score-1.095]
</p><p>3 Introduction Directed acyclic graphs (or DAGs for short) are commonly used to model causal relationships between random variables; in such models, parents of some vertex in the graph are understood as “causes”, and edges have the meaning of “causal inﬂuences”. [sent-14, score-0.538]
</p><p>4 To put it simple, the skeleton of an underlying DAG is completely determined by its Markov property, whereas the direction of the arrows (which is crucial for causal interpretation) is in general not encoded in the Markov property for the observational distribution. [sent-17, score-0.529]
</p><p>5 The ensemble of both the observational and interventional distributions can greatly improve the identiﬁability of the causal structure of the system, the underlying DAG. [sent-20, score-0.716]
</p><p>6 This is of general interest for computation and algorithms dealing with structure (DAG) learning from an ensemble of observational and interventional data such as MCMC. [sent-24, score-0.571]
</p><p>7 We then generalize the concept of essential graphs, a graph theoretic representation of Markov equivalence classes, to the interventional case and characterize the properties of those graphs in Section 3. [sent-27, score-0.703]
</p><p>8 In Section 4, we elaborate a set of algorithmic operations to efﬁciently traverse the search space of interventional essential graphs and ﬁnally present the GIES algorithm. [sent-28, score-0.489]
</p><p>9 Different approaches to incorporate interventional data for learning causal models have been developed in the past. [sent-39, score-0.506]
</p><p>10 Approaches based on active learning (He and Geng, 2008; Tong and Koller, 2001; Eberhardt, 2008) propose an iterative line of action, estimating the essential graph with observational data in a ﬁrst step and using interventional data in a second step to orient beforehand unorientable edges. [sent-43, score-0.784]
</p><p>11 Deﬁnition 4 (Causal model) A causal model is a pair (D, f ), where D is a DAG on the vertex set [p] and f ∈ M(D) is a density obeying the Markov property of D: D is called the causal structure of the model, and f the observational density. [sent-87, score-0.608]
</p><p>12 Using truncated factorization and the assumption of independent intervention variables, this interventional density can be written as f (x | doD (XI = UI )) = ∏ f (xi |xpaD (i) ) ∏ f˜(xi ) . [sent-93, score-0.548]
</p><p>13 (1)  i∈I  i∈I /  / By denoting with I = 0 and using the convention f (x| do(X0 = U0 )) = f (x), we also encompass the / / observational case as an intervention target. [sent-94, score-0.374]
</p><p>14 / For a causal model (D, f ), an interventional density f (·| doD (XI = UI )) obeys the Markov property of D(I) : the Markov property of the observational density is inherited. [sent-98, score-0.762]
</p><p>15 We call such a set an intervention setting, and the corresponding (multi)set of intervention targets I = {I j }J a family j=1 of targets. [sent-101, score-0.43]
</p><p>16 We consider interventional data of sample size n produced by a causal model (D, f ) under an intervention setting S = {(I, f˜I )}I∈I . [sent-103, score-0.67]
</p><p>17 If a family of targets I contains more than one target, interventional data as in Equation (3) are not identically distributed. [sent-132, score-0.463]
</p><p>18 Whereas the distribution of observational data is determined by a single density, we need tuples of densities as in the following deﬁnition to specify the distribution of interventional data. [sent-133, score-0.571]
</p><p>19 / Although the do() operator does not appear in Deﬁnition 7, the elements in MI (D) are exactly the tuples ( f (·| doD (XI = UI )))I∈I that can be realized as interventional densities of some causal model (D, f ). [sent-136, score-0.506]
</p><p>20 These considerations are formalized in the following lemma and motivate Deﬁnition 9 of interventional Markov equivalence in analogy to the observational case. [sent-138, score-0.692]
</p><p>21 (i) Let (D, f ) be a causal model (that is, f ∈ M(D)), S = {(I, f˜I )}I∈I an intervention setting and UI ∼ f˜I intervention variables for I ∈ I. [sent-141, score-0.473]
</p><p>22 We now generalize Theorem 3 for the interventional case in order to get a purely graph theoretic criterion for interventional Markov equivalence of two given DAGs, the main result of this section. [sent-150, score-0.936]
</p><p>23 3 Discussion Throughout this paper, we always assume the observational density f of a causal model to be strictly positive. [sent-154, score-0.378]
</p><p>24 We conjecture that the notion of interventional Markov equivalence (Deﬁnition 9 and Theorem 10) also remains valid for such densities; corresponding proofs would, however, require more caution to avoid the aforementioned problems with (truncated) factorization. [sent-158, score-0.456]
</p><p>25 D1 and D2 can be distinguished if we can measure data from an intervention at one of the vertices in addition to observational data; this / experimental setting corresponds to the (conservative) family of targets I = {0, {1}}. [sent-161, score-0.565]
</p><p>26 This is an explanation for the term “conservative”: a conservative family of targets yields a ﬁner partitioning of DAGs into equivalence classes compared to observational Markov equivalence, but it preserves the “borders” of observational Markov equivalence classes. [sent-171, score-0.752]
</p><p>27 Figure 2 shows three DAGs that are observationally Markov equivalent, but which fall into two different interventional Markov equivalence classes / under the family of targets I = {0, {4}}. [sent-172, score-0.558]
</p><p>28 In this section, we give a characterization of graphs that uniquely represent an interventional Markov equivalence class (Theorem 18). [sent-180, score-0.528]
</p><p>29 Our characterization of these interventional essential graphs is inspired by and similar to the one developed by Andersson et al. [sent-181, score-0.489]
</p><p>30 When the family of targets I in question is clear from the context, we will also use the term interventional essential graph, while “observational essential graph” shall refer to the concept of essential graphs as introduced by Andersson et al. [sent-192, score-0.703]
</p><p>31 Simply speaking of “essential graphs”, we mean interventional or observational essential graphs in the following. [sent-194, score-0.699]
</p><p>32 Due to increased identiﬁability of causal structures, Markov equivalence classes shrink in the interventional case; Equation (4) implies EI (D) ⊂ E{0} (D) for any / conservative family of targets I (see also Figure 8 in Section 5). [sent-205, score-0.743]
</p><p>33 Essential graphs, interventional as well as observational ones, are mainly interesting because of two reasons: • It is important to know which arrow directions of a causal model are identiﬁable and which are not since arrow directions are relevant for the causal interpretation. [sent-206, score-1.205]
</p><p>34 2 Characterization of Interventional Essential Graphs As in the observational setting, we can show that interventional essential graphs are chain graphs / with chordal chain components (see Appendix A. [sent-222, score-0.955]
</p><p>35 As an immediate consequence of Proposition 16, interventional essential graphs are in one-toone correspondence with interventional Markov equivalence classes. [sent-237, score-0.945]
</p><p>36 The algorithm is indeed valid and calculates EI (D), since the graph produced in each iteration is a partial I-essential graph of D (Lemma 21), and the only partial I-essential graph that has only strongly I-protected arrows is EI (D) (Lemma 22). [sent-265, score-0.457]
</p><p>37 To construct EI (D) from some DAG D = ([p], E), we must, in the worst case, execute the iteration of Algorithm 1 for every arrow in the DAG; at each step, we must check every 4-tuple of vertices to see whether some arrow occurs in conﬁguration (d) of Deﬁnition 14. [sent-272, score-0.433]
</p><p>38 If v < s, the interventional essential graph EI (D) is 1  2  . [sent-300, score-0.536]
</p><p>39 In the best case, all edge orientations in the chain can be identiﬁed by a single intervention, while the observational essential graph E{0} (D) that is identiﬁable from observational data alone / contains p representatives. [sent-308, score-0.741]
</p><p>40 p Choosing the central vertex ⌈ 2 ⌉ as intervention target ensures that at least half of the edges become directed in EI (D), independent of the position s of the source. [sent-310, score-0.416]
</p><p>41 It then sequentially steps from one essential graph Gi to a larger one, Gi+1 , for which there are representatives Di ∈ D(Gi ) and Di+1 ∈ D(Gi+1 ) such that Di+1 has exactly one arrow more than Di . [sent-319, score-0.379]
</p><p>42 • In the backward phase, the sequence (Gi )i is continued by gradually stepping from one essential graph Gi to a smaller one, Gi+1 , for which there are representatives Di ∈ D(Gi ) and Di+1 ∈ D(Gi+1 ) such that Di+1 has exactly one arrow less than Di . [sent-320, score-0.424]
</p><p>43 2) that the same is true in the interventional case as long as few interventions are made. [sent-331, score-0.441]
</p><p>44 We denote the score of a DAG D given interventional data (T , X) by S(D; T , X), and we assume that S is score equivalent, that is, it assigns the same score to I-equivalent DAGs; I always stands for a conservative family of targets in this section. [sent-335, score-0.644]
</p><p>45 Such a score function needs only be evaluated at one single representative of some interventional Markov equivalence class. [sent-339, score-0.503]
</p><p>46 Indeed, a key ingredient for the efﬁciency of the observational GES as well as our interventional GIES is an implementation that computes the greedy steps to the next equivalence class in a local fashion without enumerating all corresponding DAG members. [sent-340, score-0.697]
</p><p>47 1 Forward Phase A step in the forward phase of GIES can be formalized as follows: for an I-essential graph Gi , ﬁnd the next one Gi+1 := EI (Di+1 ), where Di+1 := arg max S(D′ ; T , X), and D′ ∈D+ (Gi )  D+ (Gi ) := {D′ a DAG | ∃ an arrow u  v ∈ D′ : D′ − (u, v) ∈ D(Gi )} . [sent-347, score-0.396]
</p><p>48 Proposition 25 has already been proven for the case of observational data (Chickering, 2002b, Theorem 15); it is not obvious, however, to see that this characterization of a forward step is also valid for interventional essential graphs, so we give a new proof in Appendix B. [sent-358, score-0.674]
</p><p>49 In parentheses in Figure (c): arrow conﬁgurations according to Deﬁnition 14; arrows incident to 4 are strongly I-protected by the intervention target {4}. [sent-371, score-0.436]
</p><p>50 The next lemma suggests a novel shortcut to this procedure: it is sufﬁcient to orient the edges of the chain component TG (v) only to get a partial I-essential graph of D′ after adding the arrow u v. [sent-373, score-0.496]
</p><p>51 Let H be the graph that we get by orienting all edges of TG (v) as in D (leaving other chain components unchanged) and inserting the arrow (u, v). [sent-375, score-0.495]
</p><p>52 Let H be the graph that we get by orienting all edges of TG (v) as in D and removing the arrow (u, v). [sent-397, score-0.43]
</p><p>53 Let H be the graph that we get by orienting all edges of TG (v) as in D and turning the arrow (v, u). [sent-430, score-0.511]
</p><p>54 A possible turning step is illustrated in Figure 6, where a non-I-essential arrow (for I = / {0, {4}}) of a representative of the graph G of Figure 3 is turned. [sent-432, score-0.372]
</p><p>55 Chickering (2002a) has already proposed a turning step for essential arrows in the observational case; however, he did not provide necessary and sufﬁcient conditions specifying all possible turning steps as Proposition 34 does. [sent-445, score-0.5]
</p><p>56 Lemma 35 Let G, u, v, C, D and D′ be as in Proposition 34, and let H be the graph that we get by orienting all edges of TG (v) and TG (u) as in D and by turning the edge (v, u). [sent-446, score-0.393]
</p><p>57 Despite the fact that we need to orient the edges of TG (v) and TG (u) to get a partial I-essential graph of D′ , EI (D′ ) is nevertheless determined by the orientation of edges adjacent to v (determined by the clique C) alone. [sent-452, score-0.451]
</p><p>58 4 Discussion Every step in the forward, backward and turning phase of GIES is characterized by a triple (u, v,C), where u and v are different vertices and C is a clique in the neighborhood of v. [sent-458, score-0.372]
</p><p>59 GIES only relies on the notion of interventional Markov equivalence, and on a score function that can be evaluated for a given class of causal models. [sent-497, score-0.553]
</p><p>60 1, we believe that interventional Markov equivalence classes remain unchanged for models that do not have a strictly positive density. [sent-499, score-0.456]
</p><p>61 In this case, not only the observational density f is Gaussian, but also the interventional densities f (x | doD (XI = UI )). [sent-519, score-0.594]
</p><p>62 2 Simulations We simulated interventional data from 4000 randomly generated Gaussian causal models as described in Section 5. [sent-527, score-0.506]
</p><p>63 As a rough summary, GIES markedly beat the conceptually simpler greedy search over the space of DAGs as well as the original GES of Chickering (2002b) ignoring the interventional nature of the simulated data sets. [sent-537, score-0.392]
</p><p>64 With this choice and the aforementioned normalization of Σ, the mean values of the intervention levels lay 2 standard deviations above the mean values of the observational marginal distributions. [sent-587, score-0.374]
</p><p>65 In total, we considered 4000 causal models and simulated 128 observational or interventional data sets from each of them by combining the following simulation parameters: • (p, s) ∈ {(10, 0. [sent-588, score-0.716]
</p><p>66 The ﬁrst one is the original GES of Chickering (2002b) which regards the complete interventional data set as observational (that is, ignores the list T of an interventional data set (T , X) as deﬁned in Equation (2)). [sent-607, score-0.932]
</p><p>67 Two vertices which are adjacent in both G and G, but connected with different edge types (that is, by a directed edge in one graph, by an undirected one in the other; or by directed edges with different orientations in both graphs) constitute a wrongly oriented edge. [sent-621, score-0.621]
</p><p>68 1, the undirected edges in the I-essential graph EI (D) of some causal structure D are the edges with unidentiﬁable orientation. [sent-625, score-0.462]
</p><p>69 This illustrates that interventional data arising from different intervention targets carry more information about the underlying causal model than observational data of the same sample size. [sent-649, score-0.956]
</p><p>70 To sum up, both the price of ignoring interventional Markov equivalence (GDS) and ignoring the interventional nature of the provided data sets (GES) are apparent in Figure 9. [sent-655, score-0.817]
</p><p>71 For example, a data set with n = 1000 and k = 4 consists of 200 observational samples and 200 interventional samples each arising from interventions at four different targets, see Section 5. [sent-658, score-0.651]
</p><p>72 This is not an artifact of GES, but a problem of model-misspeciﬁcation: running DP for an observational model (that is, considering all data as observational as GES does) yields SHD values maximally 14% below that of GES (data not shown). [sent-666, score-0.42]
</p><p>73 It combines both the advantage of GIES- NT, using the space of interventional Markov equivalence classes as search space, and GDS, the turning phase apparently reducing the risk of getting stuck in local maxima of the score function. [sent-670, score-0.642]
</p><p>74 3, the SHD between true and estimated interventional essential graphs can be written as the sum of false positives of the skeleton, false negatives of the skeleton and wrongly oriented edges. [sent-679, score-0.652]
</p><p>75 1 DATA The DREAM4 challenge provides ﬁve data sets with an ensemble of interventional and observational data simulated from ﬁve biologically plausible, possibly cyclic gene regulatory networks with 10 genes (Marbach et al. [sent-707, score-0.571]
</p><p>76 Since our framework can not cope with uncertain interventions (that is, interventions with unknown target), we only used the 50 observational measurements of the second half of the time series. [sent-714, score-0.37]
</p><p>77 Altogether, we have, from each network, a total of 81 data points, 61 observational and 20 interventional ones. [sent-715, score-0.571]
</p><p>78 2 M ETHODS We used each interventional measurement (20 per network) as one test data point and predicted its value from a network estimated with training data consisting either of the 80 remaining data points, or the 61 observational measurements alone. [sent-723, score-0.571]
</p><p>79 GES and PC regard all data as observational and yield an observational essential graph. [sent-729, score-0.476]
</p><p>80 Although all data sets are dominated by observational data (61 observational measurements versus 20 interventional ones), GIES can make use of the additional information carried by interventional data points to rule out its observational competitors. [sent-763, score-1.352]
</p><p>81 On the other hand, the dominance of observational data is probably one of the reasons for the fact that GIES does not outperform the observational methods more clearly but has an overall performance which is comparable with that of its competitors. [sent-764, score-0.42]
</p><p>82 Using those essential graphs as a basis for the algorithmic representation of interventional Markov equivalence classes, we presented a new greedy algorithm (including a new turning phase), GIES, for learning causal structures from data arising from multiple interventions. [sent-780, score-0.841]
</p><p>83 In a simulation study, we showed that the number of non-orientable edges in causal structures drops quickly even with a small number of interventions; our description of interventional essential graphs makes it possible to quantify the gain in identiﬁability. [sent-781, score-0.71]
</p><p>84 For a ﬁxed sample size n, GIES estimates got closer to the true causal structure as the number of intervention vertices grew. [sent-782, score-0.398]
</p><p>85 It clearly beat GDS, a simple greedy search on the space of DAGs, as well as GES which cannot cope with interventional data. [sent-784, score-0.392]
</p><p>86 The skeleton of a graph G is the undirected graph Gu := (V, E u ), E u := {(a, b) ∈ V × V | a b ∈ G}. [sent-816, score-0.386]
</p><p>87 The graph is no chain graph anymore when we replace the arrow 3 4 by a line since this would create a directed cycle: (3, 7, 4, 3). [sent-842, score-0.566]
</p><p>88 2 Perfect Elimination Orderings Perfect elimination orderings play an important role in the characterization of interventional Markov equivalence classes of DAGs as well as in the implementation of the Greedy Interventional Equivalence Search (GIES). [sent-867, score-0.525]
</p><p>89 Figure 17 shows an undirected chordal graph G and a DAG D that has the skeleton G and is oriented according to a LexBFS-ordering σ of G. [sent-892, score-0.382]
</p><p>90 Proposition 44 Let G = (V, E) be a chain graph with chordal chain components that does not contain a b c as an induced subgraph, and let D ⊂ G be a digraph with Du = Gu . [sent-1015, score-0.378]
</p><p>91 By Deﬁnition 9 of interventional Markov equivalence, it follows that M(I) (D1 ) = M(I) (D2 ); (I) (I) hence M(D1 ) = M(D2 ) by Lemma 45. [sent-1083, score-0.386]
</p><p>92 However, in most cases, the generalization from the observational to the interventional case is not obvious and requires adapted techniques presented in this section. [sent-1116, score-0.571]
</p><p>93 A thorough inspection of the proofs given there reveals that they only make use of the fact that two Markov equivalent DAGs have the same skeleton and the same v-structures, which is also true in the interventional case by Theorem 10. [sent-1133, score-0.463]
</p><p>94 (Note that the inverse implication also holds in the observational case, but not in the interventional one; see the discussion after Theorem 10. [sent-1136, score-0.571]
</p><p>95 Then γ is of the form a  b b1  since two or three directed edges would imply the existence of a digraph with a cycle in the equivalence class of D. [sent-1150, score-0.383]
</p><p>96 In a chain graph G, an arrow a b is I-protected if and only if there is some I ∈ I such that |I ∩ {a, b}| = 1, or the arrow a b occurs in at least one subgraph of the form (a), (b), (c) in the notation of Deﬁnition 14, or in a subgraph of the form (d’) (Andersson et al. [sent-1206, score-0.712]
</p><p>97 Let D1 be a digraph that is gained by orienting all chain components of G according to a perfect elimination ordering, where the edges of TG (a) and TG (b) are oriented such that all edges point away from a or b, respectively. [sent-1214, score-0.46]
</p><p>98 ai−1 ai  However, both graphs cannot be an induced subgraph of the chain graph G. [sent-1336, score-0.439]
</p><p>99 Let would be a directed cycle in D 0 k ai ai+1 be the ﬁrst arrow in γ that points away from ak in D. [sent-1419, score-0.436]
</p><p>100 Jointly interventional and observational data: estimation of correu sponding Markov equivalence classes of directed acyclic graphs. [sent-1554, score-0.798]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('interventional', 0.361), ('dag', 0.298), ('gies', 0.293), ('neg', 0.232), ('observational', 0.21), ('tg', 0.207), ('ei', 0.197), ('dags', 0.18), ('arrow', 0.172), ('intervention', 0.164), ('pag', 0.15), ('causal', 0.145), ('graph', 0.119), ('auser', 0.117), ('uhlmann', 0.117), ('arkov', 0.113), ('ges', 0.113), ('nterventional', 0.113), ('quivalence', 0.113), ('andersson', 0.104), ('skeleton', 0.102), ('equivalence', 0.095), ('subgraph', 0.092), ('directed', 0.091), ('vertices', 0.089), ('lexbfs', 0.088), ('lasses', 0.087), ('vertex', 0.085), ('turning', 0.081), ('interventions', 0.08), ('cycle', 0.079), ('gi', 0.077), ('targets', 0.076), ('edges', 0.076), ('clique', 0.075), ('proposition', 0.075), ('graphs', 0.072), ('arrows', 0.072), ('xa', 0.072), ('vmax', 0.071), ('shd', 0.071), ('xpad', 0.067), ('markov', 0.066), ('chain', 0.065), ('adg', 0.063), ('orienting', 0.063), ('oriented', 0.061), ('chickering', 0.059), ('smax', 0.059), ('phase', 0.058), ('ai', 0.058), ('umax', 0.057), ('essential', 0.056), ('edge', 0.054), ('chordal', 0.054), ('gds', 0.05), ('ordering', 0.049), ('score', 0.047), ('forward', 0.047), ('elimination', 0.046), ('undirected', 0.046), ('backward', 0.045), ('gurations', 0.042), ('digraph', 0.042), ('acyclic', 0.041), ('path', 0.041), ('conservative', 0.04), ('foreach', 0.039), ('orient', 0.038), ('dod', 0.036), ('pad', 0.036), ('ak', 0.036), ('orientation', 0.035), ('induced', 0.033), ('iv', 0.033), ('representatives', 0.032), ('adjacent', 0.032), ('greedy', 0.031), ('iii', 0.031), ('perfect', 0.031), ('contradiction', 0.031), ('ui', 0.031), ('dp', 0.029), ('guration', 0.029), ('di', 0.028), ('corollary', 0.028), ('strongly', 0.028), ('orientations', 0.027), ('lemma', 0.026), ('family', 0.026), ('topological', 0.026), ('ii', 0.025), ('vm', 0.025), ('hence', 0.025), ('du', 0.024), ('kalisch', 0.024), ('triple', 0.024), ('density', 0.023), ('orderings', 0.023), ('hauser', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="25-tfidf-1" href="./jmlr-2012-Characterization_and_Greedy_Learning_of_Interventional_Markov_Equivalence_Classes_of_Directed_Acyclic_Graphs.html">25 jmlr-2012-Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs</a></p>
<p>Author: Alain Hauser, Peter Bühlmann</p><p>Abstract: The investigation of directed acyclic graphs (DAGs) encoding the same Markov property, that is the same conditional independence relations of multivariate observational distributions, has a long tradition; many algorithms exist for model selection and structure learning in Markov equivalence classes. In this paper, we extend the notion of Markov equivalence of DAGs to the case of interventional distributions arising from multiple intervention experiments. We show that under reasonable assumptions on the intervention experiments, interventional Markov equivalence deﬁnes a ﬁner partitioning of DAGs than observational Markov equivalence and hence improves the identiﬁability of causal models. We give a graph theoretic criterion for two DAGs being Markov equivalent under interventions and show that each interventional Markov equivalence class can, analogously to the observational case, be uniquely represented by a chain graph called interventional essential graph (also known as CPDAG in the observational case). These are key insights for deriving a generalization of the Greedy Equivalence Search algorithm aimed at structure learning from interventional data. This new algorithm is evaluated in a simulation study. Keywords: causal inference, interventions, graphical model, Markov equivalence, greedy equivalence search</p><p>2 0.1320928 <a title="25-tfidf-2" href="./jmlr-2012-Causal_Bounds_and_Observable_Constraints_for_Non-deterministic_Models.html">24 jmlr-2012-Causal Bounds and Observable Constraints for Non-deterministic Models</a></p>
<p>Author: Roland R. Ramsahai</p><p>Abstract: Conditional independence relations involving latent variables do not necessarily imply observable independences. They may imply inequality constraints on observable parameters and causal bounds, which can be used for falsiﬁcation and identiﬁcation. The literature on computing such constraints often involve a deterministic underlying data generating process in a counterfactual framework. If an analyst is ignorant of the nature of the underlying mechanisms then they may wish to use a model which allows the underlying mechanisms to be probabilistic. A method of computation for a weaker model without any determinism is given here and demonstrated for the instrumental variable model, though applicable to other models. The approach is based on the analysis of mappings with convex polytopes in a decision theoretic framework and can be implemented in readily available polyhedral computation software. Well known constraints and bounds are replicated in a probabilistic model and novel ones are computed for instrumental variable models without non-deterministic versions of the randomization, exclusion restriction and monotonicity assumptions respectively. Keywords: instrumental variables, instrumental inequality, causal bounds, convex polytope, latent variables, directed acyclic graph</p><p>3 0.091178887 <a title="25-tfidf-3" href="./jmlr-2012-Facilitating_Score_and_Causal_Inference_Trees_for_Large_Observational_Studies.html">42 jmlr-2012-Facilitating Score and Causal Inference Trees for Large Observational Studies</a></p>
<p>Author: Xiaogang Su, Joseph Kang, Juanjuan Fan, Richard A. Levine, Xin Yan</p><p>Abstract: Assessing treatment effects in observational studies is a multifaceted problem that not only involves heterogeneous mechanisms of how the treatment or cause is exposed to subjects, known as propensity, but also differential causal effects across sub-populations. We introduce a concept termed the facilitating score to account for both the confounding and interacting impacts of covariates on the treatment effect. Several approaches for estimating the facilitating score are discussed. In particular, we put forward a machine learning method, called causal inference tree (CIT), to provide a piecewise constant approximation of the facilitating score. With interpretable rules, CIT splits data in such a way that both the propensity and the treatment effect become more homogeneous within each resultant partition. Causal inference at different levels can be made on the basis of CIT. Together with an aggregated grouping procedure, CIT stratiﬁes data into strata where causal effects can be conveniently assessed within each. Besides, a feasible way of predicting individual causal effects (ICE) is made available by aggregating ensemble CIT models. Both the stratiﬁed results and the estimated ICE provide an assessment of heterogeneity of causal effects and can be integrated for estimating the average causal effect (ACE). Mean square consistency of CIT is also established. We evaluate the performance of proposed methods with simulations and illustrate their use with the NSW data in Dehejia and Wahba (1999) where the objective is to assess the impact of c 2012 Xiaogang Su, Joseph Kang, Juanjuan Fan, Richard A. Levine and Xin Yan. S U , K ANG , FAN , L EVINE AND YAN a labor training program, the National Supported Work (NSW) demonstration, on post-intervention earnings. Keywords: CART, causal inference, confounding, interaction, observational study, personalized medicine, recursive partitioning</p><p>4 0.086299367 <a title="25-tfidf-4" href="./jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</a></p>
<p>Author: Ioannis Tsamardinos, Sofia Triantafillou, Vincenzo Lagani</p><p>Abstract: We present methods able to predict the presence and strength of conditional and unconditional dependencies (correlations) between two variables Y and Z never jointly measured on the same samples, based on multiple data sets measuring a set of common variables. The algorithms are specializations of prior work on learning causal structures from overlapping variable sets. This problem has also been addressed in the ﬁeld of statistical matching. The proposed methods are applied to a wide range of domains and are shown to accurately predict the presence of thousands of dependencies. Compared against prototypical statistical matching algorithms and within the scope of our experiments, the proposed algorithms make predictions that are better correlated with the sample estimates of the unknown parameters on test data ; this is particularly the case when the number of commonly measured variables is low. The enabling idea behind the methods is to induce one or all causal models that are simultaneously consistent with (ﬁt) all available data sets and prior knowledge and reason with them. This allows constraints stemming from causal assumptions (e.g., Causal Markov Condition, Faithfulness) to propagate. Several methods have been developed based on this idea, for which we propose the unifying name Integrative Causal Analysis (INCA). A contrived example is presented demonstrating the theoretical potential to develop more general methods for co-analyzing heterogeneous data sets. The computational experiments with the novel methods provide evidence that causallyinspired assumptions such as Faithfulness often hold to a good degree of approximation in many real systems and could be exploited for statistical inference. Code, scripts, and data are available at www.mensxmachina.org. Keywords: integrative causal analysis, causal discovery, Bayesian networks, maximal ancestral graphs, structural equation models, causality, statistical matching, data fusion</p><p>5 0.077895932 <a title="25-tfidf-5" href="./jmlr-2012-High-Dimensional_Gaussian_Graphical_Model_Selection%3A_Walk_Summability_and_Local_Separation_Criterion.html">48 jmlr-2012-High-Dimensional Gaussian Graphical Model Selection: Walk Summability and Local Separation Criterion</a></p>
<p>Author: Animashree Anandkumar, Vincent Y.F. Tan, Furong Huang, Alan S. Willsky</p><p>Abstract: We consider the problem of high-dimensional Gaussian graphical model selection. We identify a set of graphs for which an efﬁcient estimation algorithm exists, and this algorithm is based on thresholding of empirical conditional covariances. Under a set of transparent conditions, we establish structural consistency (or sparsistency) for the proposed algorithm, when the number of −2 samples n = Ω(Jmin log p), where p is the number of variables and Jmin is the minimum (absolute) edge potential of the graphical model. The sufﬁcient conditions for sparsistency are based on the notion of walk-summability of the model and the presence of sparse local vertex separators in the underlying graph. We also derive novel non-asymptotic necessary conditions on the number of samples required for sparsistency. Keywords: Gaussian graphical model selection, high-dimensional learning, local-separation property, walk-summability, necessary conditions for model selection</p><p>6 0.075814828 <a title="25-tfidf-6" href="./jmlr-2012-Learning_Linear_Cyclic_Causal_Models_with_Latent_Variables.html">56 jmlr-2012-Learning Linear Cyclic Causal Models with Latent Variables</a></p>
<p>7 0.064605124 <a title="25-tfidf-7" href="./jmlr-2012-Exact_Covariance_Thresholding_into_Connected_Components_for_Large-Scale_Graphical_Lasso.html">40 jmlr-2012-Exact Covariance Thresholding into Connected Components for Large-Scale Graphical Lasso</a></p>
<p>8 0.050808609 <a title="25-tfidf-8" href="./jmlr-2012-Manifold_Identification_in_Dual_Averaging_for_Regularized_Stochastic_Online_Learning.html">64 jmlr-2012-Manifold Identification in Dual Averaging for Regularized Stochastic Online Learning</a></p>
<p>9 0.048358034 <a title="25-tfidf-9" href="./jmlr-2012-A_Geometric_Approach_to_Sample_Compression.html">3 jmlr-2012-A Geometric Approach to Sample Compression</a></p>
<p>10 0.045877397 <a title="25-tfidf-10" href="./jmlr-2012-Query_Strategies_for_Evading_Convex-Inducing_Classifiers.html">94 jmlr-2012-Query Strategies for Evading Convex-Inducing Classifiers</a></p>
<p>11 0.041711342 <a title="25-tfidf-11" href="./jmlr-2012-The_huge_Package_for_High-dimensional_Undirected_Graph_Estimation_in_R.html">113 jmlr-2012-The huge Package for High-dimensional Undirected Graph Estimation in R</a></p>
<p>12 0.037894536 <a title="25-tfidf-12" href="./jmlr-2012-Hope_and_Fear_for_Discriminative_Training_of_Statistical_Translation_Models.html">49 jmlr-2012-Hope and Fear for Discriminative Training of Statistical Translation Models</a></p>
<p>13 0.032505475 <a title="25-tfidf-13" href="./jmlr-2012-An_Active_Learning_Algorithm_for_Ranking_from_Pairwise_Preferences_with_an_Almost_Optimal_Query_Complexity.html">17 jmlr-2012-An Active Learning Algorithm for Ranking from Pairwise Preferences with an Almost Optimal Query Complexity</a></p>
<p>14 0.031369518 <a title="25-tfidf-14" href="./jmlr-2012-Plug-in_Approach_to_Active_Learning.html">91 jmlr-2012-Plug-in Approach to Active Learning</a></p>
<p>15 0.030797178 <a title="25-tfidf-15" href="./jmlr-2012-Finite-Sample_Analysis_of_Least-Squares_Policy_Iteration.html">46 jmlr-2012-Finite-Sample Analysis of Least-Squares Policy Iteration</a></p>
<p>16 0.030748244 <a title="25-tfidf-16" href="./jmlr-2012-A_Unifying_Probabilistic_Perspective_for_Spectral_Dimensionality_Reduction%3A_Insights_and_New_Models.html">11 jmlr-2012-A Unifying Probabilistic Perspective for Spectral Dimensionality Reduction: Insights and New Models</a></p>
<p>17 0.029975304 <a title="25-tfidf-17" href="./jmlr-2012-Metric_and_Kernel_Learning_Using_a_Linear_Transformation.html">66 jmlr-2012-Metric and Kernel Learning Using a Linear Transformation</a></p>
<p>18 0.029671688 <a title="25-tfidf-18" href="./jmlr-2012-Conditional_Likelihood_Maximisation%3A_A_Unifying_Framework_for_Information_Theoretic_Feature_Selection.html">27 jmlr-2012-Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></p>
<p>19 0.027871758 <a title="25-tfidf-19" href="./jmlr-2012-Trading_Regret_for_Efficiency%3A_Online_Convex_Optimization_with_Long_Term_Constraints.html">115 jmlr-2012-Trading Regret for Efficiency: Online Convex Optimization with Long Term Constraints</a></p>
<p>20 0.027718753 <a title="25-tfidf-20" href="./jmlr-2012-Refinement_of_Operator-valued_Reproducing_Kernels.html">96 jmlr-2012-Refinement of Operator-valued Reproducing Kernels</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.145), (1, 0.068), (2, 0.056), (3, -0.155), (4, 0.059), (5, 0.169), (6, -0.078), (7, 0.192), (8, 0.298), (9, 0.016), (10, -0.041), (11, -0.005), (12, -0.102), (13, 0.046), (14, 0.016), (15, -0.092), (16, -0.027), (17, -0.058), (18, -0.019), (19, 0.082), (20, -0.006), (21, 0.031), (22, -0.076), (23, 0.07), (24, -0.024), (25, 0.012), (26, 0.111), (27, -0.183), (28, -0.054), (29, 0.041), (30, 0.021), (31, -0.018), (32, -0.028), (33, -0.012), (34, 0.023), (35, 0.054), (36, -0.013), (37, -0.01), (38, 0.041), (39, 0.039), (40, -0.089), (41, 0.047), (42, 0.012), (43, -0.022), (44, 0.091), (45, -0.048), (46, 0.022), (47, 0.072), (48, 0.051), (49, 0.097)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95149571 <a title="25-lsi-1" href="./jmlr-2012-Characterization_and_Greedy_Learning_of_Interventional_Markov_Equivalence_Classes_of_Directed_Acyclic_Graphs.html">25 jmlr-2012-Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs</a></p>
<p>Author: Alain Hauser, Peter Bühlmann</p><p>Abstract: The investigation of directed acyclic graphs (DAGs) encoding the same Markov property, that is the same conditional independence relations of multivariate observational distributions, has a long tradition; many algorithms exist for model selection and structure learning in Markov equivalence classes. In this paper, we extend the notion of Markov equivalence of DAGs to the case of interventional distributions arising from multiple intervention experiments. We show that under reasonable assumptions on the intervention experiments, interventional Markov equivalence deﬁnes a ﬁner partitioning of DAGs than observational Markov equivalence and hence improves the identiﬁability of causal models. We give a graph theoretic criterion for two DAGs being Markov equivalent under interventions and show that each interventional Markov equivalence class can, analogously to the observational case, be uniquely represented by a chain graph called interventional essential graph (also known as CPDAG in the observational case). These are key insights for deriving a generalization of the Greedy Equivalence Search algorithm aimed at structure learning from interventional data. This new algorithm is evaluated in a simulation study. Keywords: causal inference, interventions, graphical model, Markov equivalence, greedy equivalence search</p><p>2 0.745996 <a title="25-lsi-2" href="./jmlr-2012-Causal_Bounds_and_Observable_Constraints_for_Non-deterministic_Models.html">24 jmlr-2012-Causal Bounds and Observable Constraints for Non-deterministic Models</a></p>
<p>Author: Roland R. Ramsahai</p><p>Abstract: Conditional independence relations involving latent variables do not necessarily imply observable independences. They may imply inequality constraints on observable parameters and causal bounds, which can be used for falsiﬁcation and identiﬁcation. The literature on computing such constraints often involve a deterministic underlying data generating process in a counterfactual framework. If an analyst is ignorant of the nature of the underlying mechanisms then they may wish to use a model which allows the underlying mechanisms to be probabilistic. A method of computation for a weaker model without any determinism is given here and demonstrated for the instrumental variable model, though applicable to other models. The approach is based on the analysis of mappings with convex polytopes in a decision theoretic framework and can be implemented in readily available polyhedral computation software. Well known constraints and bounds are replicated in a probabilistic model and novel ones are computed for instrumental variable models without non-deterministic versions of the randomization, exclusion restriction and monotonicity assumptions respectively. Keywords: instrumental variables, instrumental inequality, causal bounds, convex polytope, latent variables, directed acyclic graph</p><p>3 0.58448702 <a title="25-lsi-3" href="./jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</a></p>
<p>Author: Ioannis Tsamardinos, Sofia Triantafillou, Vincenzo Lagani</p><p>Abstract: We present methods able to predict the presence and strength of conditional and unconditional dependencies (correlations) between two variables Y and Z never jointly measured on the same samples, based on multiple data sets measuring a set of common variables. The algorithms are specializations of prior work on learning causal structures from overlapping variable sets. This problem has also been addressed in the ﬁeld of statistical matching. The proposed methods are applied to a wide range of domains and are shown to accurately predict the presence of thousands of dependencies. Compared against prototypical statistical matching algorithms and within the scope of our experiments, the proposed algorithms make predictions that are better correlated with the sample estimates of the unknown parameters on test data ; this is particularly the case when the number of commonly measured variables is low. The enabling idea behind the methods is to induce one or all causal models that are simultaneously consistent with (ﬁt) all available data sets and prior knowledge and reason with them. This allows constraints stemming from causal assumptions (e.g., Causal Markov Condition, Faithfulness) to propagate. Several methods have been developed based on this idea, for which we propose the unifying name Integrative Causal Analysis (INCA). A contrived example is presented demonstrating the theoretical potential to develop more general methods for co-analyzing heterogeneous data sets. The computational experiments with the novel methods provide evidence that causallyinspired assumptions such as Faithfulness often hold to a good degree of approximation in many real systems and could be exploited for statistical inference. Code, scripts, and data are available at www.mensxmachina.org. Keywords: integrative causal analysis, causal discovery, Bayesian networks, maximal ancestral graphs, structural equation models, causality, statistical matching, data fusion</p><p>4 0.55805403 <a title="25-lsi-4" href="./jmlr-2012-Facilitating_Score_and_Causal_Inference_Trees_for_Large_Observational_Studies.html">42 jmlr-2012-Facilitating Score and Causal Inference Trees for Large Observational Studies</a></p>
<p>Author: Xiaogang Su, Joseph Kang, Juanjuan Fan, Richard A. Levine, Xin Yan</p><p>Abstract: Assessing treatment effects in observational studies is a multifaceted problem that not only involves heterogeneous mechanisms of how the treatment or cause is exposed to subjects, known as propensity, but also differential causal effects across sub-populations. We introduce a concept termed the facilitating score to account for both the confounding and interacting impacts of covariates on the treatment effect. Several approaches for estimating the facilitating score are discussed. In particular, we put forward a machine learning method, called causal inference tree (CIT), to provide a piecewise constant approximation of the facilitating score. With interpretable rules, CIT splits data in such a way that both the propensity and the treatment effect become more homogeneous within each resultant partition. Causal inference at different levels can be made on the basis of CIT. Together with an aggregated grouping procedure, CIT stratiﬁes data into strata where causal effects can be conveniently assessed within each. Besides, a feasible way of predicting individual causal effects (ICE) is made available by aggregating ensemble CIT models. Both the stratiﬁed results and the estimated ICE provide an assessment of heterogeneity of causal effects and can be integrated for estimating the average causal effect (ACE). Mean square consistency of CIT is also established. We evaluate the performance of proposed methods with simulations and illustrate their use with the NSW data in Dehejia and Wahba (1999) where the objective is to assess the impact of c 2012 Xiaogang Su, Joseph Kang, Juanjuan Fan, Richard A. Levine and Xin Yan. S U , K ANG , FAN , L EVINE AND YAN a labor training program, the National Supported Work (NSW) demonstration, on post-intervention earnings. Keywords: CART, causal inference, confounding, interaction, observational study, personalized medicine, recursive partitioning</p><p>5 0.42374152 <a title="25-lsi-5" href="./jmlr-2012-High-Dimensional_Gaussian_Graphical_Model_Selection%3A_Walk_Summability_and_Local_Separation_Criterion.html">48 jmlr-2012-High-Dimensional Gaussian Graphical Model Selection: Walk Summability and Local Separation Criterion</a></p>
<p>Author: Animashree Anandkumar, Vincent Y.F. Tan, Furong Huang, Alan S. Willsky</p><p>Abstract: We consider the problem of high-dimensional Gaussian graphical model selection. We identify a set of graphs for which an efﬁcient estimation algorithm exists, and this algorithm is based on thresholding of empirical conditional covariances. Under a set of transparent conditions, we establish structural consistency (or sparsistency) for the proposed algorithm, when the number of −2 samples n = Ω(Jmin log p), where p is the number of variables and Jmin is the minimum (absolute) edge potential of the graphical model. The sufﬁcient conditions for sparsistency are based on the notion of walk-summability of the model and the presence of sparse local vertex separators in the underlying graph. We also derive novel non-asymptotic necessary conditions on the number of samples required for sparsistency. Keywords: Gaussian graphical model selection, high-dimensional learning, local-separation property, walk-summability, necessary conditions for model selection</p><p>6 0.38433352 <a title="25-lsi-6" href="./jmlr-2012-A_Geometric_Approach_to_Sample_Compression.html">3 jmlr-2012-A Geometric Approach to Sample Compression</a></p>
<p>7 0.38225868 <a title="25-lsi-7" href="./jmlr-2012-Exact_Covariance_Thresholding_into_Connected_Components_for_Large-Scale_Graphical_Lasso.html">40 jmlr-2012-Exact Covariance Thresholding into Connected Components for Large-Scale Graphical Lasso</a></p>
<p>8 0.35054922 <a title="25-lsi-8" href="./jmlr-2012-Learning_Linear_Cyclic_Causal_Models_with_Latent_Variables.html">56 jmlr-2012-Learning Linear Cyclic Causal Models with Latent Variables</a></p>
<p>9 0.26068112 <a title="25-lsi-9" href="./jmlr-2012-The_huge_Package_for_High-dimensional_Undirected_Graph_Estimation_in_R.html">113 jmlr-2012-The huge Package for High-dimensional Undirected Graph Estimation in R</a></p>
<p>10 0.2547965 <a title="25-lsi-10" href="./jmlr-2012-Hope_and_Fear_for_Discriminative_Training_of_Statistical_Translation_Models.html">49 jmlr-2012-Hope and Fear for Discriminative Training of Statistical Translation Models</a></p>
<p>11 0.25086263 <a title="25-lsi-11" href="./jmlr-2012-Finite-Sample_Analysis_of_Least-Squares_Policy_Iteration.html">46 jmlr-2012-Finite-Sample Analysis of Least-Squares Policy Iteration</a></p>
<p>12 0.2443547 <a title="25-lsi-12" href="./jmlr-2012-Manifold_Identification_in_Dual_Averaging_for_Regularized_Stochastic_Online_Learning.html">64 jmlr-2012-Manifold Identification in Dual Averaging for Regularized Stochastic Online Learning</a></p>
<p>13 0.24366158 <a title="25-lsi-13" href="./jmlr-2012-Algebraic_Geometric_Comparison_of_Probability_Distributions.html">15 jmlr-2012-Algebraic Geometric Comparison of Probability Distributions</a></p>
<p>14 0.21859336 <a title="25-lsi-14" href="./jmlr-2012-A_Primal-Dual_Convergence_Analysis_of_Boosting.html">8 jmlr-2012-A Primal-Dual Convergence Analysis of Boosting</a></p>
<p>15 0.21631606 <a title="25-lsi-15" href="./jmlr-2012-A_Unifying_Probabilistic_Perspective_for_Spectral_Dimensionality_Reduction%3A_Insights_and_New_Models.html">11 jmlr-2012-A Unifying Probabilistic Perspective for Spectral Dimensionality Reduction: Insights and New Models</a></p>
<p>16 0.21411328 <a title="25-lsi-16" href="./jmlr-2012-Query_Strategies_for_Evading_Convex-Inducing_Classifiers.html">94 jmlr-2012-Query Strategies for Evading Convex-Inducing Classifiers</a></p>
<p>17 0.20990068 <a title="25-lsi-17" href="./jmlr-2012-DARWIN%3A_A_Framework_for_Machine_Learning_and_Computer_Vision_Research_and_Development.html">30 jmlr-2012-DARWIN: A Framework for Machine Learning and Computer Vision Research and Development</a></p>
<p>18 0.20752817 <a title="25-lsi-18" href="./jmlr-2012-An_Active_Learning_Algorithm_for_Ranking_from_Pairwise_Preferences_with_an_Almost_Optimal_Query_Complexity.html">17 jmlr-2012-An Active Learning Algorithm for Ranking from Pairwise Preferences with an Almost Optimal Query Complexity</a></p>
<p>19 0.19319779 <a title="25-lsi-19" href="./jmlr-2012-Refinement_of_Operator-valued_Reproducing_Kernels.html">96 jmlr-2012-Refinement of Operator-valued Reproducing Kernels</a></p>
<p>20 0.19238037 <a title="25-lsi-20" href="./jmlr-2012-Dynamic_Policy_Programming.html">34 jmlr-2012-Dynamic Policy Programming</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(21, 0.018), (26, 0.021), (29, 0.032), (35, 0.015), (49, 0.013), (57, 0.013), (64, 0.011), (75, 0.039), (79, 0.02), (92, 0.636), (96, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98712176 <a title="25-lda-1" href="./jmlr-2012-Linear_Regression_With_Random_Projections.html">59 jmlr-2012-Linear Regression With Random Projections</a></p>
<p>Author: Odalric-Ambrym Maillard, Rémi Munos</p><p>Abstract: We investigate a method for regression that makes use of a randomly generated subspace GP ⊂ F (of ﬁnite dimension P) of a given large (possibly inﬁnite) dimensional function space F , for example, L2 ([0, 1]d ; R). GP is deﬁned as the span of P random features that are linear combinations of a basis functions of F weighted by random Gaussian i.i.d. coefﬁcients. We show practical motivation for the use of this approach, detail the link that this random projections method share with RKHS and Gaussian objects theory and prove, both in deterministic and random design, approximation error bounds when searching for the best regression function in GP rather than in F , and derive excess risk bounds for a speciﬁc regression algorithm (least squares regression in GP ). This paper stresses the motivation to study such methods, thus the analysis developed is kept simple for explanations purpose and leaves room for future developments. Keywords: regression, random matrices, dimension reduction</p><p>2 0.9826777 <a title="25-lda-2" href="./jmlr-2012-Restricted_Strong_Convexity_and_Weighted_Matrix_Completion%3A_Optimal_Bounds_with_Noise.html">99 jmlr-2012-Restricted Strong Convexity and Weighted Matrix Completion: Optimal Bounds with Noise</a></p>
<p>Author: Sahand Negahban, Martin J. Wainwright</p><p>Abstract: We consider the matrix completion problem under a form of row/column weighted entrywise sampling, including the case of uniform entrywise sampling as a special case. We analyze the associated random observation operator, and prove that with high probability, it satisﬁes a form of restricted strong convexity with respect to weighted Frobenius norm. Using this property, we obtain as corollaries a number of error bounds on matrix completion in the weighted Frobenius norm under noisy sampling and for both exact and near low-rank matrices. Our results are based on measures of the “spikiness” and “low-rankness” of matrices that are less restrictive than the incoherence conditions imposed in previous work. Our technique involves an M-estimator that includes controls on both the rank and spikiness of the solution, and we establish non-asymptotic error bounds in weighted Frobenius norm for recovering matrices lying with ℓq -“balls” of bounded spikiness. Using information-theoretic methods, we show that no algorithm can achieve better estimates (up to a logarithmic factor) over these same sets, showing that our conditions on matrices and associated rates are essentially optimal. Keywords: matrix completion, collaborative ﬁltering, convex optimization</p><p>3 0.97390491 <a title="25-lda-3" href="./jmlr-2012-Integrating_a_Partial_Model_into_Model_Free_Reinforcement_Learning.html">51 jmlr-2012-Integrating a Partial Model into Model Free Reinforcement Learning</a></p>
<p>Author: Aviv Tamar, Dotan Di Castro, Ron Meir</p><p>Abstract: In reinforcement learning an agent uses online feedback from the environment in order to adaptively select an effective policy. Model free approaches address this task by directly mapping environmental states to actions, while model based methods attempt to construct a model of the environment, followed by a selection of optimal actions based on that model. Given the complementary advantages of both approaches, we suggest a novel procedure which augments a model free algorithm with a partial model. The resulting hybrid algorithm switches between a model based and a model free mode, depending on the current state and the agent’s knowledge. Our method relies on a novel deﬁnition for a partially known model, and an estimator that incorporates such knowledge in order to reduce uncertainty in stochastic approximation iterations. We prove that such an approach leads to improved policy evaluation whenever environmental knowledge is available, without compromising performance when such knowledge is absent. Numerical simulations demonstrate the effectiveness of the approach on policy gradient and Q-learning algorithms, and its usefulness in solving a call admission control problem. Keywords: reinforcement learning, temporal difference, stochastic approximation, markov decision processes, hybrid model based model free algorithms</p><p>same-paper 4 0.96994317 <a title="25-lda-4" href="./jmlr-2012-Characterization_and_Greedy_Learning_of_Interventional_Markov_Equivalence_Classes_of_Directed_Acyclic_Graphs.html">25 jmlr-2012-Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs</a></p>
<p>Author: Alain Hauser, Peter Bühlmann</p><p>Abstract: The investigation of directed acyclic graphs (DAGs) encoding the same Markov property, that is the same conditional independence relations of multivariate observational distributions, has a long tradition; many algorithms exist for model selection and structure learning in Markov equivalence classes. In this paper, we extend the notion of Markov equivalence of DAGs to the case of interventional distributions arising from multiple intervention experiments. We show that under reasonable assumptions on the intervention experiments, interventional Markov equivalence deﬁnes a ﬁner partitioning of DAGs than observational Markov equivalence and hence improves the identiﬁability of causal models. We give a graph theoretic criterion for two DAGs being Markov equivalent under interventions and show that each interventional Markov equivalence class can, analogously to the observational case, be uniquely represented by a chain graph called interventional essential graph (also known as CPDAG in the observational case). These are key insights for deriving a generalization of the Greedy Equivalence Search algorithm aimed at structure learning from interventional data. This new algorithm is evaluated in a simulation study. Keywords: causal inference, interventions, graphical model, Markov equivalence, greedy equivalence search</p><p>5 0.89956212 <a title="25-lda-5" href="./jmlr-2012-Finite-Sample_Analysis_of_Least-Squares_Policy_Iteration.html">46 jmlr-2012-Finite-Sample Analysis of Least-Squares Policy Iteration</a></p>
<p>Author: Alessandro Lazaric, Mohammad Ghavamzadeh, Rémi Munos</p><p>Abstract: In this paper, we report a performance bound for the widely used least-squares policy iteration (LSPI) algorithm. We ﬁrst consider the problem of policy evaluation in reinforcement learning, that is, learning the value function of a ﬁxed policy, using the least-squares temporal-difference (LSTD) learning method, and report ﬁnite-sample analysis for this algorithm. To do so, we ﬁrst derive a bound on the performance of the LSTD solution evaluated at the states generated by the Markov chain and used by the algorithm to learn an estimate of the value function. This result is general in the sense that no assumption is made on the existence of a stationary distribution for the Markov chain. We then derive generalization bounds in the case when the Markov chain possesses a stationary distribution and is β-mixing. Finally, we analyze how the error at each policy evaluation step is propagated through the iterations of a policy iteration method, and derive a performance bound for the LSPI algorithm. Keywords: Markov decision processes, reinforcement learning, least-squares temporal-difference, least-squares policy iteration, generalization bounds, ﬁnite-sample analysis</p><p>6 0.86957771 <a title="25-lda-6" href="./jmlr-2012-Minimax-Optimal_Rates_For_Sparse_Additive_Models_Over_Kernel_Classes_Via_Convex_Programming.html">67 jmlr-2012-Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming</a></p>
<p>7 0.84820366 <a title="25-lda-7" href="./jmlr-2012-Dynamic_Policy_Programming.html">34 jmlr-2012-Dynamic Policy Programming</a></p>
<p>8 0.80494648 <a title="25-lda-8" href="./jmlr-2012-Minimax_Manifold_Estimation.html">68 jmlr-2012-Minimax Manifold Estimation</a></p>
<p>9 0.7950722 <a title="25-lda-9" href="./jmlr-2012-Structured_Sparsity_and_Generalization.html">111 jmlr-2012-Structured Sparsity and Generalization</a></p>
<p>10 0.77423292 <a title="25-lda-10" href="./jmlr-2012-Consistent_Model_Selection_Criteria_on_High_Dimensions.html">29 jmlr-2012-Consistent Model Selection Criteria on High Dimensions</a></p>
<p>11 0.7728492 <a title="25-lda-11" href="./jmlr-2012-On_the_Necessity_of_Irrelevant_Variables.html">82 jmlr-2012-On the Necessity of Irrelevant Variables</a></p>
<p>12 0.74729747 <a title="25-lda-12" href="./jmlr-2012-Algebraic_Geometric_Comparison_of_Probability_Distributions.html">15 jmlr-2012-Algebraic Geometric Comparison of Probability Distributions</a></p>
<p>13 0.74293011 <a title="25-lda-13" href="./jmlr-2012-Multi-task_Regression_using_Minimal_Penalties.html">73 jmlr-2012-Multi-task Regression using Minimal Penalties</a></p>
<p>14 0.74142116 <a title="25-lda-14" href="./jmlr-2012-Refinement_of_Operator-valued_Reproducing_Kernels.html">96 jmlr-2012-Refinement of Operator-valued Reproducing Kernels</a></p>
<p>15 0.73423237 <a title="25-lda-15" href="./jmlr-2012-A_Multi-Stage_Framework_for_Dantzig_Selector_and_LASSO.html">7 jmlr-2012-A Multi-Stage Framework for Dantzig Selector and LASSO</a></p>
<p>16 0.73215544 <a title="25-lda-16" href="./jmlr-2012-Active_Learning_via_Perfect_Selective_Classification.html">13 jmlr-2012-Active Learning via Perfect Selective Classification</a></p>
<p>17 0.72712088 <a title="25-lda-17" href="./jmlr-2012-On_Ranking_and_Generalization_Bounds.html">80 jmlr-2012-On Ranking and Generalization Bounds</a></p>
<p>18 0.72222674 <a title="25-lda-18" href="./jmlr-2012-A_Primal-Dual_Convergence_Analysis_of_Boosting.html">8 jmlr-2012-A Primal-Dual Convergence Analysis of Boosting</a></p>
<p>19 0.71883339 <a title="25-lda-19" href="./jmlr-2012-Multi-Instance_Learning_with_Any_Hypothesis_Class.html">71 jmlr-2012-Multi-Instance Learning with Any Hypothesis Class</a></p>
<p>20 0.71241438 <a title="25-lda-20" href="./jmlr-2012-Manifold_Identification_in_Dual_Averaging_for_Regularized_Stochastic_Online_Learning.html">64 jmlr-2012-Manifold Identification in Dual Averaging for Regularized Stochastic Online Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
