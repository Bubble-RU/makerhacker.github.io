<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>106 jmlr-2012-Sign Language Recognition using Sub-Units</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-106" href="#">jmlr2012-106</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>106 jmlr-2012-Sign Language Recognition using Sub-Units</h1>
<br/><p>Source: <a title="jmlr-2012-106-pdf" href="http://jmlr.org/papers/volume13/cooper12a/cooper12a.pdf">pdf</a></p><p>Author: Helen Cooper, Eng-Jon Ong, Nicolas Pugeault, Richard Bowden</p><p>Abstract: This paper discusses sign language recognition using linguistic sub-units. It presents three types of sub-units for consideration; those learnt from appearance data as well as those inferred from both 2D or 3D tracking data. These sub-units are then combined using a sign level classiﬁer; here, two options are presented. The ﬁrst uses Markov Models to encode the temporal changes between sub-units. The second makes use of Sequential Pattern Boosting to apply discriminative feature selection at the same time as encoding temporal information. This approach is more robust to noise and performs well in signer independent tests, improving results from the 54% achieved by the Markov Chains to 76%. Keywords: sign language recognition, sequential pattern boosting, depth cameras, sub-units, signer independence, data set</p><p>Reference: <a title="jmlr-2012-106-reference" href="../jmlr2012_reference/jmlr-2012-Sign_Language_Recognition_using_Sub-Units_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('handshap', 0.545), ('track', 0.178), ('oop', 0.177), ('owd', 0.177), ('ugeault', 0.177), ('angu', 0.151), ('ecognit', 0.151), ('kadir', 0.14), ('mom', 0.139), ('fram', 0.139), ('sp', 0.137), ('sps', 0.136), ('hamnosy', 0.123), ('bp', 0.116), ('lingu', 0.11), ('recognit', 0.106), ('ub', 0.1), ('boost', 0.1), ('langu', 0.099), ('waldron', 0.095)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="106-tfidf-1" href="./jmlr-2012-Sign_Language_Recognition_using_Sub-Units.html">106 jmlr-2012-Sign Language Recognition using Sub-Units</a></p>
<p>Author: Helen Cooper, Eng-Jon Ong, Nicolas Pugeault, Richard Bowden</p><p>Abstract: This paper discusses sign language recognition using linguistic sub-units. It presents three types of sub-units for consideration; those learnt from appearance data as well as those inferred from both 2D or 3D tracking data. These sub-units are then combined using a sign level classiﬁer; here, two options are presented. The ﬁrst uses Markov Models to encode the temporal changes between sub-units. The second makes use of Sequential Pattern Boosting to apply discriminative feature selection at the same time as encoding temporal information. This approach is more robust to noise and performs well in signer independent tests, improving results from the 54% achieved by the Markov Chains to 76%. Keywords: sign language recognition, sequential pattern boosting, depth cameras, sub-units, signer independence, data set</p><p>2 0.13227908 <a title="106-tfidf-2" href="./jmlr-2012-Finding_Recurrent_Patterns_from_Continuous_Sign_Language_Sentences_for_Automated_Extraction_of_Signs.html">45 jmlr-2012-Finding Recurrent Patterns from Continuous Sign Language Sentences for Automated Extraction of Signs</a></p>
<p>Author: Sunita Nayak, Kester Duncan, Sudeep Sarkar, Barbara Loeding</p><p>Abstract: We present a probabilistic framework to automatically learn models of recurring signs from multiple sign language video sequences containing the vocabulary of interest. We extract the parts of the signs that are present in most occurrences of the sign in context and are robust to the variations produced by adjacent signs. Each sentence video is ﬁrst transformed into a multidimensional time series representation, capturing the motion and shape aspects of the sign. Skin color blobs are extracted from frames of color video sequences, and a probabilistic relational distribution is formed for each frame using the contour and edge pixels from the skin blobs. Each sentence is represented as a trajectory in a low dimensional space called the space of relational distributions. Given these time series trajectories, we extract signemes from multiple sentences concurrently using iterated conditional modes (ICM). We show results by learning single signs from a collection of sentences with one common pervading sign, multiple signs from a collection of sentences with more than one common sign, and single signs from a mixed collection of sentences. The extracted signemes demonstrate that our approach is robust to some extent to the variations produced within a sign due to different contexts. We also show results whereby these learned sign models are used for spotting signs in test sequences. Keywords: pattern extraction, sign language recognition, signeme extraction, sign modeling, iterated conditional modes</p><p>3 0.11116628 <a title="106-tfidf-3" href="./jmlr-2012-Human_Gesture_Recognition_on_Product_Manifolds.html">50 jmlr-2012-Human Gesture Recognition on Product Manifolds</a></p>
<p>Author: Yui Man Lui</p><p>Abstract: Action videos are multidimensional data and can be naturally represented as data tensors. While tensor computing is widely used in computer vision, the geometry of tensor space is often ignored. The aim of this paper is to demonstrate the importance of the intrinsic geometry of tensor space which yields a very discriminating structure for action recognition. We characterize data tensors as points on a product manifold and model it statistically using least squares regression. To this aim, we factorize a data tensor relating to each order of the tensor using Higher Order Singular Value Decomposition (HOSVD) and then impose each factorized element on a Grassmann manifold. Furthermore, we account for underlying geometry on manifolds and formulate least squares regression as a composite function. This gives a natural extension from Euclidean space to manifolds. Consequently, classiﬁcation is performed using geodesic distance on a product manifold where each factor manifold is Grassmannian. Our method exploits appearance and motion without explicitly modeling the shapes and dynamics. We assess the proposed method using three gesture databases, namely the Cambridge hand-gesture, the UMD Keck body-gesture, and the CHALEARN gesture challenge data sets. Experimental results reveal that not only does the proposed method perform well on the standard benchmark data sets, but also it generalizes well on the one-shot-learning gesture challenge. Furthermore, it is based on a simple statistical model and the intrinsic geometry of tensor space. Keywords: gesture recognition, action recognition, Grassmann manifolds, product manifolds, one-shot-learning, kinect data</p><p>4 0.075257204 <a title="106-tfidf-4" href="./jmlr-2012-A_Topic_Modeling_Toolbox_Using_Belief_Propagation.html">9 jmlr-2012-A Topic Modeling Toolbox Using Belief Propagation</a></p>
<p>Author: Jia Zeng</p><p>Abstract: Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model for probabilistic topic modeling, which attracts worldwide interests and touches on many important applications in text mining, computer vision and computational biology. This paper introduces a topic modeling toolbox (TMBP) based on the belief propagation (BP) algorithms. TMBP toolbox is implemented by MEX C++/Matlab/Octave for either Windows 7 or Linux. Compared with existing topic modeling packages, the novelty of this toolbox lies in the BP algorithms for learning LDA-based topic models. The current version includes BP algorithms for latent Dirichlet allocation (LDA), authortopic models (ATM), relational topic models (RTM), and labeled LDA (LaLDA). This toolbox is an ongoing project and more BP-based algorithms for various topic models will be added in the near future. Interested users may also extend BP algorithms for learning more complicated topic models. The source codes are freely available under the GNU General Public Licence, Version 1.0 at https://mloss.org/software/view/399/. Keywords: topic models, belief propagation, variational Bayes, Gibbs sampling</p><p>5 0.067557968 <a title="106-tfidf-5" href="./jmlr-2012-Random_Search_for_Hyper-Parameter_Optimization.html">95 jmlr-2012-Random Search for Hyper-Parameter Optimization</a></p>
<p>Author: James Bergstra, Yoshua Bengio</p><p>Abstract: Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efÄ?Ĺš cient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to conÄ?Ĺš gure neural networks and deep belief networks. Compared with neural networks conÄ?Ĺš gured by a pure grid search, we Ä?Ĺš nd that random search over the same domain is able to Ä?Ĺš nd models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search Ä?Ĺš nds better models by effectively searching a larger, less promising conÄ?Ĺš guration space. Compared with deep belief networks conÄ?Ĺš gured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional conÄ?Ĺš guration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for conÄ?Ĺš guring algorithms for new data sets. Our analysis casts some light on why recent Ă˘&euro;&oelig;High ThroughputĂ˘&euro;? methods achieve surprising successĂ˘&euro;&rdquo;they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms. Keyword</p><p>6 0.067555226 <a title="106-tfidf-6" href="./jmlr-2012-Discriminative_Hierarchical_Part-based_Models_for_Human_Parsing_and_Action_Recognition.html">32 jmlr-2012-Discriminative Hierarchical Part-based Models for Human Parsing and Action Recognition</a></p>
<p>7 0.060668726 <a title="106-tfidf-7" href="./jmlr-2012-Trading_Regret_for_Efficiency%3A_Online_Convex_Optimization_with_Long_Term_Constraints.html">115 jmlr-2012-Trading Regret for Efficiency: Online Convex Optimization with Long Term Constraints</a></p>
<p>8 0.060558647 <a title="106-tfidf-8" href="./jmlr-2012-A_Model_of_the_Perception_of_Facial_Expressions_of_Emotion_by_Humans%3A_Research_Overview_and_Perspectives.html">6 jmlr-2012-A Model of the Perception of Facial Expressions of Emotion by Humans: Research Overview and Perspectives</a></p>
<p>9 0.057182856 <a title="106-tfidf-9" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>10 0.05320406 <a title="106-tfidf-10" href="./jmlr-2012-Eliminating_Spammers_and_Ranking_Annotators_for_Crowdsourced_Labeling_Tasks.html">37 jmlr-2012-Eliminating Spammers and Ranking Annotators for Crowdsourced Labeling Tasks</a></p>
<p>11 0.051589161 <a title="106-tfidf-11" href="./jmlr-2012-Online_Submodular_Minimization.html">84 jmlr-2012-Online Submodular Minimization</a></p>
<p>12 0.04484231 <a title="106-tfidf-12" href="./jmlr-2012-Pattern_for_Python.html">90 jmlr-2012-Pattern for Python</a></p>
<p>13 0.043559242 <a title="106-tfidf-13" href="./jmlr-2012-Restricted_Strong_Convexity_and_Weighted_Matrix_Completion%3A_Optimal_Bounds_with_Noise.html">99 jmlr-2012-Restricted Strong Convexity and Weighted Matrix Completion: Optimal Bounds with Noise</a></p>
<p>14 0.042877343 <a title="106-tfidf-14" href="./jmlr-2012-Positive_Semidefinite_Metric_Learning_Using_Boosting-like_Algorithms.html">92 jmlr-2012-Positive Semidefinite Metric Learning Using Boosting-like Algorithms</a></p>
<p>15 0.041445564 <a title="106-tfidf-15" href="./jmlr-2012-Non-Sparse_Multiple_Kernel_Fisher_Discriminant_Analysis.html">77 jmlr-2012-Non-Sparse Multiple Kernel Fisher Discriminant Analysis</a></p>
<p>16 0.040579878 <a title="106-tfidf-16" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>17 0.038282402 <a title="106-tfidf-17" href="./jmlr-2012-Mal-ID%3A_Automatic_Malware_Detection_Using_Common_Segment_Analysis_and_Meta-Features.html">63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</a></p>
<p>18 0.036922984 <a title="106-tfidf-18" href="./jmlr-2012-Bayesian_Mixed-Effects_Inference_on_Classification_Performance_in_Hierarchical_Data_Sets.html">21 jmlr-2012-Bayesian Mixed-Effects Inference on Classification Performance in Hierarchical Data Sets</a></p>
<p>19 0.033485748 <a title="106-tfidf-19" href="./jmlr-2012-On_the_Necessity_of_Irrelevant_Variables.html">82 jmlr-2012-On the Necessity of Irrelevant Variables</a></p>
<p>20 0.033231575 <a title="106-tfidf-20" href="./jmlr-2012-MULTIBOOST%3A_A_Multi-purpose_Boosting_Package.html">62 jmlr-2012-MULTIBOOST: A Multi-purpose Boosting Package</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.164), (1, 0.01), (2, -0.132), (3, 0.184), (4, -0.081), (5, 0.054), (6, 0.125), (7, -0.006), (8, -0.061), (9, -0.016), (10, 0.052), (11, -0.039), (12, -0.169), (13, 0.199), (14, -0.207), (15, 0.165), (16, 0.0), (17, 0.013), (18, -0.003), (19, 0.177), (20, 0.102), (21, -0.06), (22, -0.002), (23, -0.243), (24, 0.012), (25, -0.157), (26, -0.042), (27, -0.012), (28, -0.081), (29, 0.043), (30, 0.039), (31, -0.004), (32, -0.187), (33, -0.103), (34, 0.063), (35, -0.053), (36, 0.044), (37, -0.015), (38, -0.018), (39, 0.03), (40, -0.159), (41, -0.081), (42, -0.029), (43, -0.031), (44, -0.095), (45, 0.083), (46, -0.059), (47, 0.044), (48, 0.165), (49, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92805421 <a title="106-lsi-1" href="./jmlr-2012-Sign_Language_Recognition_using_Sub-Units.html">106 jmlr-2012-Sign Language Recognition using Sub-Units</a></p>
<p>Author: Helen Cooper, Eng-Jon Ong, Nicolas Pugeault, Richard Bowden</p><p>Abstract: This paper discusses sign language recognition using linguistic sub-units. It presents three types of sub-units for consideration; those learnt from appearance data as well as those inferred from both 2D or 3D tracking data. These sub-units are then combined using a sign level classiﬁer; here, two options are presented. The ﬁrst uses Markov Models to encode the temporal changes between sub-units. The second makes use of Sequential Pattern Boosting to apply discriminative feature selection at the same time as encoding temporal information. This approach is more robust to noise and performs well in signer independent tests, improving results from the 54% achieved by the Markov Chains to 76%. Keywords: sign language recognition, sequential pattern boosting, depth cameras, sub-units, signer independence, data set</p><p>2 0.7276786 <a title="106-lsi-2" href="./jmlr-2012-Finding_Recurrent_Patterns_from_Continuous_Sign_Language_Sentences_for_Automated_Extraction_of_Signs.html">45 jmlr-2012-Finding Recurrent Patterns from Continuous Sign Language Sentences for Automated Extraction of Signs</a></p>
<p>Author: Sunita Nayak, Kester Duncan, Sudeep Sarkar, Barbara Loeding</p><p>Abstract: We present a probabilistic framework to automatically learn models of recurring signs from multiple sign language video sequences containing the vocabulary of interest. We extract the parts of the signs that are present in most occurrences of the sign in context and are robust to the variations produced by adjacent signs. Each sentence video is ﬁrst transformed into a multidimensional time series representation, capturing the motion and shape aspects of the sign. Skin color blobs are extracted from frames of color video sequences, and a probabilistic relational distribution is formed for each frame using the contour and edge pixels from the skin blobs. Each sentence is represented as a trajectory in a low dimensional space called the space of relational distributions. Given these time series trajectories, we extract signemes from multiple sentences concurrently using iterated conditional modes (ICM). We show results by learning single signs from a collection of sentences with one common pervading sign, multiple signs from a collection of sentences with more than one common sign, and single signs from a mixed collection of sentences. The extracted signemes demonstrate that our approach is robust to some extent to the variations produced within a sign due to different contexts. We also show results whereby these learned sign models are used for spotting signs in test sequences. Keywords: pattern extraction, sign language recognition, signeme extraction, sign modeling, iterated conditional modes</p><p>3 0.45691174 <a title="106-lsi-3" href="./jmlr-2012-Human_Gesture_Recognition_on_Product_Manifolds.html">50 jmlr-2012-Human Gesture Recognition on Product Manifolds</a></p>
<p>Author: Yui Man Lui</p><p>Abstract: Action videos are multidimensional data and can be naturally represented as data tensors. While tensor computing is widely used in computer vision, the geometry of tensor space is often ignored. The aim of this paper is to demonstrate the importance of the intrinsic geometry of tensor space which yields a very discriminating structure for action recognition. We characterize data tensors as points on a product manifold and model it statistically using least squares regression. To this aim, we factorize a data tensor relating to each order of the tensor using Higher Order Singular Value Decomposition (HOSVD) and then impose each factorized element on a Grassmann manifold. Furthermore, we account for underlying geometry on manifolds and formulate least squares regression as a composite function. This gives a natural extension from Euclidean space to manifolds. Consequently, classiﬁcation is performed using geodesic distance on a product manifold where each factor manifold is Grassmannian. Our method exploits appearance and motion without explicitly modeling the shapes and dynamics. We assess the proposed method using three gesture databases, namely the Cambridge hand-gesture, the UMD Keck body-gesture, and the CHALEARN gesture challenge data sets. Experimental results reveal that not only does the proposed method perform well on the standard benchmark data sets, but also it generalizes well on the one-shot-learning gesture challenge. Furthermore, it is based on a simple statistical model and the intrinsic geometry of tensor space. Keywords: gesture recognition, action recognition, Grassmann manifolds, product manifolds, one-shot-learning, kinect data</p><p>4 0.40694901 <a title="106-lsi-4" href="./jmlr-2012-Discriminative_Hierarchical_Part-based_Models_for_Human_Parsing_and_Action_Recognition.html">32 jmlr-2012-Discriminative Hierarchical Part-based Models for Human Parsing and Action Recognition</a></p>
<p>Author: Yang Wang, Duan Tran, Zicheng Liao, David Forsyth</p><p>Abstract: We consider the problem of parsing human poses and recognizing their actions in static images with part-based models. Most previous work in part-based models only considers rigid parts (e.g., torso, head, half limbs) guided by human anatomy. We argue that this representation of parts is not necessarily appropriate. In this paper, we introduce hierarchical poselets—a new representation for modeling the pose conﬁguration of human bodies. Hierarchical poselets can be rigid parts, but they can also be parts that cover large portions of human bodies (e.g., torso + left arm). In the extreme case, they can be the whole bodies. The hierarchical poselets are organized in a hierarchical way via a structured model. Human parsing can be achieved by inferring the optimal labeling of this hierarchical model. The pose information captured by this hierarchical model can also be used as a intermediate representation for other high-level tasks. We demonstrate it in action recognition from static images. Keywords: human parsing, action recognition, part-based models, hierarchical poselets, maxmargin structured learning</p><p>5 0.38421479 <a title="106-lsi-5" href="./jmlr-2012-A_Model_of_the_Perception_of_Facial_Expressions_of_Emotion_by_Humans%3A_Research_Overview_and_Perspectives.html">6 jmlr-2012-A Model of the Perception of Facial Expressions of Emotion by Humans: Research Overview and Perspectives</a></p>
<p>Author: Aleix Martinez, Shichuan Du</p><p>Abstract: In cognitive science and neuroscience, there have been two leading models describing how humans perceive and classify facial expressions of emotion—the continuous and the categorical model. The continuous model deﬁnes each facial expression of emotion as a feature vector in a face space. This model explains, for example, how expressions of emotion can be seen at different intensities. In contrast, the categorical model consists of C classiﬁers, each tuned to a speciﬁc emotion category. This model explains, among other ﬁndings, why the images in a morphing sequence between a happy and a surprise face are perceived as either happy or surprise but not something in between. While the continuous model has a more difﬁcult time justifying this latter ﬁnding, the categorical model is not as good when it comes to explaining how expressions are recognized at different intensities or modes. Most importantly, both models have problems explaining how one can recognize combinations of emotion categories such as happily surprised versus angrily surprised versus surprise. To resolve these issues, in the past several years, we have worked on a revised model that justiﬁes the results reported in the cognitive science and neuroscience literature. This model consists of C distinct continuous spaces. Multiple (compound) emotion categories can be recognized by linearly combining these C face spaces. The dimensions of these spaces are shown to be mostly conﬁgural. According to this model, the major task for the classiﬁcation of facial expressions of emotion is precise, detailed detection of facial landmarks rather than recognition. We provide an overview of the literature justifying the model, show how the resulting model can be employed to build algorithms for the recognition of facial expression of emotion, and propose research directions in machine learning and computer vision researchers to keep pushing the state of the art in these areas. We also discuss how the model can aid in stu</p><p>6 0.36904389 <a title="106-lsi-6" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>7 0.32847747 <a title="106-lsi-7" href="./jmlr-2012-A_Topic_Modeling_Toolbox_Using_Belief_Propagation.html">9 jmlr-2012-A Topic Modeling Toolbox Using Belief Propagation</a></p>
<p>8 0.30872416 <a title="106-lsi-8" href="./jmlr-2012-Mal-ID%3A_Automatic_Malware_Detection_Using_Common_Segment_Analysis_and_Meta-Features.html">63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</a></p>
<p>9 0.30101341 <a title="106-lsi-9" href="./jmlr-2012-Pattern_for_Python.html">90 jmlr-2012-Pattern for Python</a></p>
<p>10 0.26687959 <a title="106-lsi-10" href="./jmlr-2012-Random_Search_for_Hyper-Parameter_Optimization.html">95 jmlr-2012-Random Search for Hyper-Parameter Optimization</a></p>
<p>11 0.25371593 <a title="106-lsi-11" href="./jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</a></p>
<p>12 0.24554659 <a title="106-lsi-12" href="./jmlr-2012-Nonparametric_Guidance_of_Autoencoder_Representations_using_Label_Information.html">78 jmlr-2012-Nonparametric Guidance of Autoencoder Representations using Label Information</a></p>
<p>13 0.24117592 <a title="106-lsi-13" href="./jmlr-2012-MedLDA%3A_Maximum_Margin_Supervised_Topic_Models.html">65 jmlr-2012-MedLDA: Maximum Margin Supervised Topic Models</a></p>
<p>14 0.23897202 <a title="106-lsi-14" href="./jmlr-2012-Learning_Symbolic_Representations_of_Hybrid_Dynamical_Systems.html">57 jmlr-2012-Learning Symbolic Representations of Hybrid Dynamical Systems</a></p>
<p>15 0.22798201 <a title="106-lsi-15" href="./jmlr-2012-Multi-Target_Regression_with_Rule_Ensembles.html">72 jmlr-2012-Multi-Target Regression with Rule Ensembles</a></p>
<p>16 0.21154025 <a title="106-lsi-16" href="./jmlr-2012-Learning_Algorithms_for_the_Classification_Restricted_Boltzmann_Machine.html">55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</a></p>
<p>17 0.20175463 <a title="106-lsi-17" href="./jmlr-2012-Eliminating_Spammers_and_Ranking_Annotators_for_Crowdsourced_Labeling_Tasks.html">37 jmlr-2012-Eliminating Spammers and Ranking Annotators for Crowdsourced Labeling Tasks</a></p>
<p>18 0.19564201 <a title="106-lsi-18" href="./jmlr-2012-Online_Submodular_Minimization.html">84 jmlr-2012-Online Submodular Minimization</a></p>
<p>19 0.19504888 <a title="106-lsi-19" href="./jmlr-2012-Positive_Semidefinite_Metric_Learning_Using_Boosting-like_Algorithms.html">92 jmlr-2012-Positive Semidefinite Metric Learning Using Boosting-like Algorithms</a></p>
<p>20 0.18896808 <a title="106-lsi-20" href="./jmlr-2012-Conditional_Likelihood_Maximisation%3A_A_Unifying_Framework_for_Information_Theoretic_Feature_Selection.html">27 jmlr-2012-Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.527), (28, 0.019), (38, 0.016), (48, 0.109), (50, 0.036), (67, 0.054), (69, 0.011), (74, 0.011), (81, 0.034), (91, 0.024), (95, 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.77787948 <a title="106-lda-1" href="./jmlr-2012-Robust_Kernel_Density_Estimation.html">100 jmlr-2012-Robust Kernel Density Estimation</a></p>
<p>Author: JooSeuk Kim, Clayton D. Scott</p><p>Abstract: We propose a method for nonparametric density estimation that exhibits robustness to contamination of the training sample. This method achieves robustness by combining a traditional kernel density estimator (KDE) with ideas from classical M-estimation. We interpret the KDE based on a positive semi-deﬁnite kernel as a sample mean in the associated reproducing kernel Hilbert space. Since the sample mean is sensitive to outliers, we estimate it robustly via M-estimation, yielding a robust kernel density estimator (RKDE). An RKDE can be computed efﬁciently via a kernelized iteratively re-weighted least squares (IRWLS) algorithm. Necessary and sufﬁcient conditions are given for kernelized IRWLS to converge to the global minimizer of the M-estimator objective function. The robustness of the RKDE is demonstrated with a representer theorem, the inﬂuence function, and experimental results for density estimation and anomaly detection. Keywords: outlier, reproducing kernel Hilbert space, kernel trick, inﬂuence function, M-estimation</p><p>same-paper 2 0.64907801 <a title="106-lda-2" href="./jmlr-2012-Sign_Language_Recognition_using_Sub-Units.html">106 jmlr-2012-Sign Language Recognition using Sub-Units</a></p>
<p>Author: Helen Cooper, Eng-Jon Ong, Nicolas Pugeault, Richard Bowden</p><p>Abstract: This paper discusses sign language recognition using linguistic sub-units. It presents three types of sub-units for consideration; those learnt from appearance data as well as those inferred from both 2D or 3D tracking data. These sub-units are then combined using a sign level classiﬁer; here, two options are presented. The ﬁrst uses Markov Models to encode the temporal changes between sub-units. The second makes use of Sequential Pattern Boosting to apply discriminative feature selection at the same time as encoding temporal information. This approach is more robust to noise and performs well in signer independent tests, improving results from the 54% achieved by the Markov Chains to 76%. Keywords: sign language recognition, sequential pattern boosting, depth cameras, sub-units, signer independence, data set</p><p>3 0.39392477 <a title="106-lda-3" href="./jmlr-2012-Finding_Recurrent_Patterns_from_Continuous_Sign_Language_Sentences_for_Automated_Extraction_of_Signs.html">45 jmlr-2012-Finding Recurrent Patterns from Continuous Sign Language Sentences for Automated Extraction of Signs</a></p>
<p>Author: Sunita Nayak, Kester Duncan, Sudeep Sarkar, Barbara Loeding</p><p>Abstract: We present a probabilistic framework to automatically learn models of recurring signs from multiple sign language video sequences containing the vocabulary of interest. We extract the parts of the signs that are present in most occurrences of the sign in context and are robust to the variations produced by adjacent signs. Each sentence video is ﬁrst transformed into a multidimensional time series representation, capturing the motion and shape aspects of the sign. Skin color blobs are extracted from frames of color video sequences, and a probabilistic relational distribution is formed for each frame using the contour and edge pixels from the skin blobs. Each sentence is represented as a trajectory in a low dimensional space called the space of relational distributions. Given these time series trajectories, we extract signemes from multiple sentences concurrently using iterated conditional modes (ICM). We show results by learning single signs from a collection of sentences with one common pervading sign, multiple signs from a collection of sentences with more than one common sign, and single signs from a mixed collection of sentences. The extracted signemes demonstrate that our approach is robust to some extent to the variations produced within a sign due to different contexts. We also show results whereby these learned sign models are used for spotting signs in test sequences. Keywords: pattern extraction, sign language recognition, signeme extraction, sign modeling, iterated conditional modes</p><p>4 0.36647695 <a title="106-lda-4" href="./jmlr-2012-Human_Gesture_Recognition_on_Product_Manifolds.html">50 jmlr-2012-Human Gesture Recognition on Product Manifolds</a></p>
<p>Author: Yui Man Lui</p><p>Abstract: Action videos are multidimensional data and can be naturally represented as data tensors. While tensor computing is widely used in computer vision, the geometry of tensor space is often ignored. The aim of this paper is to demonstrate the importance of the intrinsic geometry of tensor space which yields a very discriminating structure for action recognition. We characterize data tensors as points on a product manifold and model it statistically using least squares regression. To this aim, we factorize a data tensor relating to each order of the tensor using Higher Order Singular Value Decomposition (HOSVD) and then impose each factorized element on a Grassmann manifold. Furthermore, we account for underlying geometry on manifolds and formulate least squares regression as a composite function. This gives a natural extension from Euclidean space to manifolds. Consequently, classiﬁcation is performed using geodesic distance on a product manifold where each factor manifold is Grassmannian. Our method exploits appearance and motion without explicitly modeling the shapes and dynamics. We assess the proposed method using three gesture databases, namely the Cambridge hand-gesture, the UMD Keck body-gesture, and the CHALEARN gesture challenge data sets. Experimental results reveal that not only does the proposed method perform well on the standard benchmark data sets, but also it generalizes well on the one-shot-learning gesture challenge. Furthermore, it is based on a simple statistical model and the intrinsic geometry of tensor space. Keywords: gesture recognition, action recognition, Grassmann manifolds, product manifolds, one-shot-learning, kinect data</p><p>5 0.33570486 <a title="106-lda-5" href="./jmlr-2012-Refinement_of_Operator-valued_Reproducing_Kernels.html">96 jmlr-2012-Refinement of Operator-valued Reproducing Kernels</a></p>
<p>Author: Haizhang Zhang, Yuesheng Xu, Qinghui Zhang</p><p>Abstract: This paper studies the construction of a reﬁnement kernel for a given operator-valued reproducing kernel such that the vector-valued reproducing kernel Hilbert space of the reﬁnement kernel contains that of the given kernel as a subspace. The study is motivated from the need of updating the current operator-valued reproducing kernel in multi-task learning when underﬁtting or overﬁtting occurs. Numerical simulations conﬁrm that the established reﬁnement kernel method is able to meet this need. Various characterizations are provided based on feature maps and vector-valued integral representations of operator-valued reproducing kernels. Concrete examples of reﬁning translation invariant and ﬁnite Hilbert-Schmidt operator-valued reproducing kernels are provided. Other examples include reﬁnement of Hessian of scalar-valued translation-invariant kernels and transformation kernels. Existence and properties of operator-valued reproducing kernels preserved during the reﬁnement process are also investigated. Keywords: vector-valued reproducing kernel Hilbert spaces, operator-valued reproducing kernels, reﬁnement, embedding, translation invariant kernels, Hessian of Gaussian kernels, Hilbert-Schmidt kernels, numerical experiments</p><p>6 0.33428285 <a title="106-lda-6" href="./jmlr-2012-Stability_of_Density-Based_Clustering.html">109 jmlr-2012-Stability of Density-Based Clustering</a></p>
<p>7 0.32023701 <a title="106-lda-7" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>8 0.31996515 <a title="106-lda-8" href="./jmlr-2012-A_Model_of_the_Perception_of_Facial_Expressions_of_Emotion_by_Humans%3A_Research_Overview_and_Perspectives.html">6 jmlr-2012-A Model of the Perception of Facial Expressions of Emotion by Humans: Research Overview and Perspectives</a></p>
<p>9 0.30570775 <a title="106-lda-9" href="./jmlr-2012-Efficient_Methods_for_Robust_Classification_Under_Uncertainty_in_Kernel_Matrices.html">36 jmlr-2012-Efficient Methods for Robust Classification Under Uncertainty in Kernel Matrices</a></p>
<p>10 0.29356128 <a title="106-lda-10" href="./jmlr-2012-Transfer_in_Reinforcement_Learning_via_Shared_Features.html">116 jmlr-2012-Transfer in Reinforcement Learning via Shared Features</a></p>
<p>11 0.29296851 <a title="106-lda-11" href="./jmlr-2012-Nonparametric_Guidance_of_Autoencoder_Representations_using_Label_Information.html">78 jmlr-2012-Nonparametric Guidance of Autoencoder Representations using Label Information</a></p>
<p>12 0.28635094 <a title="106-lda-12" href="./jmlr-2012-A_Unifying_Probabilistic_Perspective_for_Spectral_Dimensionality_Reduction%3A_Insights_and_New_Models.html">11 jmlr-2012-A Unifying Probabilistic Perspective for Spectral Dimensionality Reduction: Insights and New Models</a></p>
<p>13 0.28306895 <a title="106-lda-13" href="./jmlr-2012-Structured_Sparsity_via_Alternating_Direction_Methods.html">112 jmlr-2012-Structured Sparsity via Alternating Direction Methods</a></p>
<p>14 0.2815077 <a title="106-lda-14" href="./jmlr-2012-Local_and_Global_Scaling_Reduce_Hubs_in_Space.html">60 jmlr-2012-Local and Global Scaling Reduce Hubs in Space</a></p>
<p>15 0.28107139 <a title="106-lda-15" href="./jmlr-2012-Multi-Assignment_Clustering_for_Boolean_Data.html">70 jmlr-2012-Multi-Assignment Clustering for Boolean Data</a></p>
<p>16 0.28018093 <a title="106-lda-16" href="./jmlr-2012-Entropy_Search_for_Information-Efficient_Global_Optimization.html">38 jmlr-2012-Entropy Search for Information-Efficient Global Optimization</a></p>
<p>17 0.27998859 <a title="106-lda-17" href="./jmlr-2012-Multi-Target_Regression_with_Rule_Ensembles.html">72 jmlr-2012-Multi-Target Regression with Rule Ensembles</a></p>
<p>18 0.27954561 <a title="106-lda-18" href="./jmlr-2012-Selective_Sampling_and_Active_Learning_from_Single_and_Multiple_Teachers.html">105 jmlr-2012-Selective Sampling and Active Learning from Single and Multiple Teachers</a></p>
<p>19 0.27840042 <a title="106-lda-19" href="./jmlr-2012-Plug-in_Approach_to_Active_Learning.html">91 jmlr-2012-Plug-in Approach to Active Learning</a></p>
<p>20 0.27823672 <a title="106-lda-20" href="./jmlr-2012-An_Improved_GLMNET_for_L1-regularized_Logistic_Regression.html">18 jmlr-2012-An Improved GLMNET for L1-regularized Logistic Regression</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
