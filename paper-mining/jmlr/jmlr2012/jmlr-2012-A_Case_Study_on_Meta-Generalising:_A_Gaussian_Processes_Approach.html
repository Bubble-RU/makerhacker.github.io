<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-1" href="#">jmlr2012-1</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</h1>
<br/><p>Source: <a title="jmlr-2012-1-pdf" href="http://jmlr.org/papers/volume13/skolidis12a/skolidis12a.pdf">pdf</a></p><p>Author: Grigorios Skolidis, Guido Sanguinetti</p><p>Abstract: We propose a novel model for meta-generalisation, that is, performing prediction on novel tasks based on information from multiple different but related tasks. The model is based on two coupled Gaussian processes with structured covariance function; one model performs predictions by learning a constrained covariance function encapsulating the relations between the various training tasks, while the second model determines the similarity of new tasks to previously seen tasks. We demonstrate empirically on several real and synthetic data sets both the strengths of the approach and its limitations due to the distributional assumptions underpinning it. Keywords: transfer learning, meta-generalising, multi-task learning, Gaussian processes, mixture of experts</p><p>Reference: <a title="jmlr-2012-1-reference" href="../jmlr2012_reference/jmlr-2012-A_Case_Study_on_Meta-Generalising%3A_A_Gaussian_Processes_Approach_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 On the other hand, in the complex world that we live in we are usually faced with unseen but similar problems, situations which human intelligence handles by adaptively taking decisions on the new tasks using knowledge from similar tasks. [sent-14, score-0.463]
</p><p>2 For example, the situation where labels are available for all tasks is tackled by multi-task learning, which synergistically solves the learning problem in all tasks simultaneously (Caruana, 1997; Bakker and Heskes, 2003; Ando and Zhang, 2005). [sent-19, score-0.808]
</p><p>3 In particular, it is generally assumed that at least the input data for the target task will be available during the learning, so that a measure of similarity between the training and target tasks can be estimated. [sent-33, score-0.694]
</p><p>4 The question that we wish to raise in this work is whether the notion of generalisation can be extended to the level of tasks as a form of meta-generalisation. [sent-34, score-0.415]
</p><p>5 Meta-generalisation is a concept introduced in Baxter (2000), where the author argues whether a transfer learning algorithm can generalise well on totally unseen tasks after seeing sufﬁciently many source (or training) tasks. [sent-35, score-0.622]
</p><p>6 In his work Baxter (2000) derives bounds on the generalisation error of this problem in terms of a generalised VC-dimension parameter, as well as comments that the number of source tasks and examples per task required to ensure good performance on novel tasks has to be sufﬁciently large. [sent-38, score-1.015]
</p><p>7 One way to approach meta-generalising is through domain adaptation, by training a model on the data of the source and the target set of tasks (Ben-David et al. [sent-41, score-0.593]
</p><p>8 This type of approach, as well as the model proposed in Baxter (2000), are essentially trained in a transductive way, as the algorithm is able to make predictions only on the test tasks that is trained on, or needs to be retrained in case a new task arrives. [sent-43, score-0.553]
</p><p>9 The problem of sampling the space of tasks to make predictions on totally unseen tasks in the inductive setting, which is the exact analog of generalising in the level of tasks, to the best of our knowledge has not been speciﬁcally addressed. [sent-47, score-0.975]
</p><p>10 Hence, multi-task learning can be seen as an Inductive TL algorithm since input data and labels are available for all the tasks that we wish to make predictions. [sent-49, score-0.418]
</p><p>11 On this basis, meta-generalising can be considered as a form of Unsupervised TL, since the learning algorithm does not have any exploitable information about the target tasks during training . [sent-52, score-0.503]
</p><p>12 The model uses a multi-class Gaussian process for assigning probabilistically unseen tasks to source tasks (determining task responsibilities), and then uses a multi-task Gaussian process (Bonilla et al. [sent-56, score-1.063]
</p><p>13 In a meta-generalising scenario the learner is provided with a set of source tasks TS = s , . [sent-65, score-0.52]
</p><p>14 , T s } which are used for training the model; testing is then performed on a set of target {T1 M t tasks TT = {T1t , . [sent-68, score-0.503]
</p><p>15 Each of the M source tasks will contain a training set of input/ output pairs (x, y), while data from any of the H target tasks are hidden. [sent-72, score-0.983]
</p><p>16 For later convenience, we will s deﬁne the whole training set across tasks as a set of triples T s = {xis , yst , ysx }N , where xis ∈ Rd is i i i=1 the input feature vector, ysx ∈ {−1, +1} are the class labels, and yst ∈ {1, . [sent-73, score-0.678]
</p><p>17 , M} is the source task i i label indicating to which task the input/ output pair pertains, and N s = ∑M nsj is the total number j=1 of training pairs where nsj is number of data points from the jth source task. [sent-76, score-0.497]
</p><p>18 Moreover, we will ns  ns  j j write X js = {xisj }i=1 to denote the total item set of the jth source task, while ysx = {ysx }i=1 and j ij  ns  j yst = {ystj }i=1 will be used to denote all class and task labels from the jth source task. [sent-77, score-0.521]
</p><p>19 nt  j Each of the H target tasks T jt will consist of a set X tj = {xti j }i=1 of input points, where ntj is number of data points from the jth target task and both types of labels are missing. [sent-79, score-0.758]
</p><p>20 For reasons that will become clear later j=1 on, it is further assumed that for each target task data point xtj there is information that it comes from the jth target task, but there is no knowledge with which of the source tasks is more similar. [sent-81, score-0.777]
</p><p>21 (2010), we will deﬁne the low-error joint prediction between a source and a target task as the error λe between their predictive functions fs and ft respectively, evaluated at the union  693  S KOLIDIS AND S ANGUINETTI  of the source and the target sets X = X s ∪ X t , with N = N s + N t . [sent-88, score-0.472]
</p><p>22 Intuitively, if the error λe is large then there is a disagreement between the labels of the source and target tasks distribution. [sent-90, score-0.579]
</p><p>23 Deﬁnition 1 Given a set of source tasks TS and a set of target tasks TT , meta-generalising is an inductive inference method that aims at making predictions on the set of target tasks by sampling the space of source tasks . [sent-98, score-1.925]
</p><p>24 We further deﬁne two possible scenarios: in the fully observed tasks case, we assume that the similarity of the distribution assumption is perfectly met, so that the data generating distribution of the target task is the same as that of one of the source tasks (but we do not know which one). [sent-99, score-1.113]
</p><p>25 This assumption is relaxed in the partially observed tasks scenario, where we still assume similarity of the distribution but we do not necessarily have identity. [sent-100, score-0.442]
</p><p>26 The data of each task are on the base level and the distribution of the tasks is on the meta level. [sent-102, score-0.51]
</p><p>27 Model the distribution of the data of each task, and the distribution of the source tasks (correlation between tasks). [sent-104, score-0.48]
</p><p>28 In this work, we are interested in the general case where no reliable task descriptor features are available; we will then learn similarities between tasks through a distribution matching pursuit. [sent-114, score-0.51]
</p><p>29 In addition, we employ a classiﬁer over the tasks to learn the task labels (from which task each data point comes from). [sent-127, score-0.658]
</p><p>30 This conﬁguration implies that the matrix Kt models the correlations between the vectors f j , that is, the tasks in the multi-task view, and Kx models the correlations between each element of vectors f j . [sent-161, score-0.496]
</p><p>31 For example, if Kt was ﬁxed to the identity matrix, then all tasks would be independent but they would still share the same hyperparameters of the covariance function. [sent-167, score-0.512]
</p><p>32 The objectives of the model are ﬁrst to model the dependencies between the tasks, and second to assign unseen tasks to source tasks by ﬁnding task similarities. [sent-175, score-1.063]
</p><p>33 In this subsection we use x, yt , and yx to refer to xs , yst , and ysx to keep the notation light, since in the learning phase only source tasks are involved. [sent-178, score-1.016]
</p><p>34 , M} and yx ∈ {−1, +1} as the task and class labels respectively. [sent-184, score-0.449]
</p><p>35 Variables f and g are the two sets of GPs for the multi-task and multi-class classiﬁers respectively, whereas variables hx and ht denote the auxiliary variables of the two classiﬁers; (a) graphical representation of the training phase, (b) graphical representation of Meta-generalising. [sent-187, score-0.352]
</p><p>36 and Chib (1993), we deﬁne two sets of auxiliary variables ht = vec(Ht ), and hx = vec(Hx ), which as shown later on enables the multinomial and the binary probit model respectively. [sent-188, score-0.359]
</p><p>37 The ﬁrst one is responsible for the classiﬁcation over the tasks g|X, θx ∼ GP (0, I ⊗ Kx ), where g = vec(G), G = [g1 , . [sent-193, score-0.39]
</p><p>38 Standard results show that the distributions that maximize the lower bound are given by Q(Θi ) =  exp(EQ(Θ\Θi ) {log p(yt , yx , Θ|X, θt , θx )}) exp(EQ(Θ\Θi ) {log p(yt , yx , Θ|X, θt , θx )})dΘi  where Q(Θ \ Θi ) denotes the factorized distribution with the ith component removed. [sent-223, score-0.602]
</p><p>39 3 Prediction on Novel Tasks While in the previous section we described how to train the model on training data from the source tasks, we now describe how to perform predictions on unseen target tasks. [sent-245, score-0.319]
</p><p>40 In many cases, a target task consists of a batch of input points, and the simple fact that they all come from the same task contains valuable information about the correlations between the associated outputs. [sent-252, score-0.443]
</p><p>41 In many multi-task problems it is a usual phenomenon to observe groups of highly correlated tasks (e. [sent-254, score-0.39]
</p><p>42 b), while other times tasks are correlated but in a more random fashion (e. [sent-257, score-0.39]
</p><p>43 , xt∗ }, in the ﬁrst scenario we treat each data point 2 1 nt from the target task individually to infer its task responsibilities, which we will refer to as Point to Point Gating (P2PGat). [sent-267, score-0.394]
</p><p>44 In the second scenario we wish to combine the information from all nt test points to infer the overall task responsibilities for the target task, which we will refer to as Batch predictions. [sent-269, score-0.358]
</p><p>45 Additionally, kt , kt are used to denote the jth column and the j jth ˜ kj x,x∗ j jj element of Kt respectively, kx ∗ is used to denote the covariance vector between X and x∗ , and Φ is x,x the probit function. [sent-275, score-0.871]
</p><p>46 Equations (12) and (13), indicate that inferring x the tasks responsibilities on a set of points depends not only on the correlations between the test points and the train points but also on the correlations between the test points themselves. [sent-284, score-0.58]
</p><p>47 from the unknown data generating distribution, and approximate it by: ∗  p(yt∗ = k|x∗ , X, yt ) ≈  ∏n p(yt∗ = k|xi∗ , X, yt ) i=1 i , M n∗ ∑m=1 ∏ j=1 p(yt∗ = m|x∗ , X, yt ) j j  (14)  where p(yt∗ = k|xi∗ , X, yt ) are the task responsibilities computed individually for each test point. [sent-298, score-0.652]
</p><p>48 The fully observed tasks case, considered in Section 4. [sent-311, score-0.442]
</p><p>49 In this case all available tasks are used in the training phase, but in the testing phase the model has no information from which of the source task the target task comes from. [sent-313, score-0.833]
</p><p>50 In this case the data generating distribution of the target task does not match the distribution of one of the source tasks, so that the set of source tasks is strictly a subset of the set of all tasks. [sent-316, score-0.761]
</p><p>51 2 gives more insight into the connections between the correlation structure of the tasks and the task prediction mechanism on totally unseen tasks. [sent-319, score-0.615]
</p><p>52 Intuitively, the success of the model depends strongly on whether the model will be able to infer correctly from which of the source tasks the target task actually comes from. [sent-347, score-0.671]
</p><p>53 005  1  (a)  (b)  Figure 2: Toy data set I distribution; (a) scatter plot and density for the ﬁrst cluster of tasks (1-3), (b) scatter plot and density for the second cluster of tasks (4-6). [sent-361, score-0.974]
</p><p>54 Data for the ﬁrst three tasks are generated from a mixture of two partially overlapping Gaussian distributions, and similarly for the remaining three tasks. [sent-367, score-0.417]
</p><p>55 Hence, the six tasks cluster in two groups; for each task 600 data points were generated, which were equally divided between the two classes. [sent-368, score-0.578]
</p><p>56 2 T OY DATA S ET II The second toy data set consists of four tasks which group into two clusters. [sent-395, score-0.484]
</p><p>57 While the densities are peaked in different locations, without class labels the tasks are almost identical, meaning that the multi-class classiﬁer cannot learn to discriminate between the two tasks. [sent-400, score-0.418]
</p><p>58 b shows the Hinton diagram of the task covariance matrix, which indicates a more random structure between the tasks, but ﬁnds that some tasks are more correlated than others, for example ‘a/g’ with ‘a/o’, and ‘i/j’ with ‘f/t’. [sent-485, score-0.617]
</p><p>59 It should be noted though, that in this data set the “low-error joint prediction” assumption is partially violated since there is label disagreement between tasks ‘a/g’ and ‘g/y’, where the ‘g’ letter belongs to class “+1” in task ‘a/g’ and to “-1” in task ‘g/y’. [sent-486, score-0.657]
</p><p>60 Interestingly, the MAP approach is consistently worse than other methods, a situation that will be reversed in the partially observed tasks scenario. [sent-511, score-0.442]
</p><p>61 b, demonstrates that there are correlations between the tasks but in more random way. [sent-513, score-0.443]
</p><p>62 In the fully observed tasks scenario, the space of tasks has been sampled sufﬁciently (by deﬁnition). [sent-525, score-0.832]
</p><p>63 If the model assumptions are met, the correlation structure of the tasks does not have a strong inﬂuence on the predictions, since the Batch mode outperformed the P2PGat gating and MAP estimate in all experiments. [sent-534, score-0.439]
</p><p>64 As we will see, this will be a crucial difference between the fully and partially observed tasks scenario. [sent-535, score-0.469]
</p><p>65 These clusters may be evident from the experimental design of the problem (as in the case of the landmine data set discussed below), or may become evident from the training phase on the source tasks, if the learned task covariance matrix exhibits a strong block structure. [sent-540, score-0.48]
</p><p>66 1 consisting of two clusters of tasks; in this section, training tasks are selected by randomly selecting equal number of tasks from each cluster. [sent-547, score-0.875]
</p><p>67 Experimental results are presented for two and four training tasks in Figures 8. [sent-550, score-0.432]
</p><p>68 65  100  150 DPET  200  100  (a)  150 DPET  200  (b)  Figure 8: Average AP on the unseen tasks of Toy data set I; (a) training on 2 tasks generalising on 4, (b) training on 4 tasks generalising on 2. [sent-567, score-1.421]
</p><p>69 Tasks 1-10 correspond to regions that are relatively highly foliated while tasks 11-19 correspond to regions that are bare earth or desert. [sent-575, score-0.39]
</p><p>70 The experimental setup suggests the presence of two clusters of tasks corresponding to the 700 Landmine (+1) Clutter (−1) 600  Data points  500  400  300  200  100  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 Task  Figure 9: Landmine detection data distribution. [sent-577, score-0.443]
</p><p>71 Thus, in this data set training tasks are set by randomly selecting equal number of tasks from the ﬁrst cluster, tasks 1-10, and from the second cluster, tasks 11-19. [sent-581, score-1.602]
</p><p>72 a shows the mean AP on the 17, 15, and 11 unseen target tasks for each partition respectively. [sent-587, score-0.534]
</p><p>73 15  20  50  100  20  50  100  DPET  DPET  DPET  (a)  (b)  (c)  Figure 10: AP on the 17 unseen tasks of Landmine data set; training on 2 tasks, generalising on 17; (a) AP over 17 tasks, (b) AP over 9 tasks of the ﬁrst cluster, (c) AP over 8 tasks of the second cluster. [sent-626, score-1.332]
</p><p>74 05  100  20  50  100  DPET  DPET  DPET  (a)  (b)  (c)  Figure 11: Average AP on the 15 unseen tasks of Landmine data set; training on 4 tasks, generalising on 15; (a) Overall AP over 15 tasks, (b) Average AP over 8 tasks of the ﬁrst cluster, (c) Average AP over 7 tasks of the second cluster. [sent-653, score-1.332]
</p><p>75 05  20  50  100  DPET  DPET  DPET  (a)  (b)  (c)  Figure 12: Average AP on the 11 unseen tasks of Landmine data set; training on 8 tasks, generalising on 11; (a) Overall AP over 11 tasks, (b) Average AP over 6 tasks of the ﬁrst cluster, (c) Average AP over 5 tasks of the second cluster. [sent-683, score-1.332]
</p><p>76 The results from the fully observed tasks scenario indicate an unclear pattern of correlations between the tasks, as summarised in the task covariance matrix Figure 7. [sent-689, score-0.732]
</p><p>77 This allows us to assume that the classes between the tasks will not be anti-correlated, so that at least the low-error joint prediction assumption should approximately hold. [sent-693, score-0.39]
</p><p>78 Since there are no obvious clusters among tasks, in this set of experiments the training tasks are chosen by randomly selecting some for training and keeping the rest as test tasks. [sent-694, score-0.527]
</p><p>79 Figure 13 presents the results on the unseen tasks that were obtained by training the CMCMT model with 4 and 5 tasks. [sent-695, score-0.505]
</p><p>80 Secondly, we observe that the performance in this set of experiments exhibits some interesting patterns as the number of training tasks increases. [sent-698, score-0.432]
</p><p>81 Speciﬁcally, for four training tasks the performance of all methods does not signiﬁcantly improve as we increase the number of data points per task, and in some cases it even deteriorates, a phenomenon that was also observed for 2 and 3 training tasks but results are omitted for brevity. [sent-699, score-0.889]
</p><p>82 This indicates that if the space of tasks has not been sampled sufﬁciently, the model can not yield good generalisation performance to new tasks, even if the number of training data increases. [sent-700, score-0.457]
</p><p>83 In contrast, for ﬁve training tasks the MAP and P2PGat methods yield a signiﬁcant improvement of performance as the number of data points increases (levelling off after 200 DPETs). [sent-701, score-0.432]
</p><p>84 82  250  DPET  100  150  200  250  DPET  (a)  (b)  Figure 13: Average AP on the unseen tasks of Arrhythmia data set on different number of training tasks; (a) training on 4 tasks, generalising on 3, (b) training on 5 tasks, generalising on 2. [sent-721, score-0.683]
</p><p>85 4 C HARACTER C LASSIFICATION For reasons of completeness, we present an analysis of the character classiﬁcation problem in the partially observed tasks scenario. [sent-730, score-0.477]
</p><p>86 The fully observed tasks analysis of the character classiﬁcation problem did not reveal any clusters of tasks. [sent-732, score-0.53]
</p><p>87 This is borne out by experimental evidence: simulation results with 4, 5, and 6 training tasks, which are omitted for brevity, indicated that increasing the number of tasks and the number of training points per task does not improve the performance in any of the methods. [sent-735, score-0.594]
</p><p>88 5 O BSERVATIONS Meta-generalising in a partially observed tasks scenario is an extremely hard problem; nevertheless, we believe there are some interesting points that can be made from the previous experimental analysis. [sent-739, score-0.482]
</p><p>89 In situations where there are clusters of tasks, even though the model hasn’t seen all tasks, the Batch method can still make accurate predictions that reaches the performance of the fully observed tasks case. [sent-742, score-0.538]
</p><p>90 Pragmatically, one could consider whether the training phase of the model has revealed clusters of tasks when deciding which prediction method to apply. [sent-743, score-0.485]
</p><p>91 While we have not tested our model for very large numbers of training tasks, the results suggest that often a signiﬁcant improvement in performance can be achieved when the number of training tasks crosses a critical number, indicating a sufﬁcient coverage of the task space. [sent-749, score-0.594]
</p><p>92 This phenomenon was observed in the Arrhythmia classiﬁcation problem for 2 and 3 training tasks where the performance of the models remained the same as the number of training samples per task increased. [sent-750, score-0.619]
</p><p>93 In essence more training data lead to stronger biases for metageneralisation in target tasks that are not correlated with any of the training tasks. [sent-751, score-0.545]
</p><p>94 Conclusions In this paper we presented an investigation on the use of Gaussian Processes for meta-generalisation, that is, predicting on unseen learning tasks by leveraging the information of several, related tasks. [sent-756, score-0.463]
</p><p>95 Our model attacks the meta-generalisation problem by coupling two GPs, a multi-class classiﬁer that learns task responsibilities, and a multi-task classiﬁer that learns prediction models on individual tasks as well as learning the global correlation structure between training tasks. [sent-757, score-0.552]
</p><p>96 It is important to remark that our method crucially relies on the ability to learn the covariance matrix of a GP: the fundamental ingredient in this work is the task correlation matrix which captures the correlations between source tasks. [sent-762, score-0.34]
</p><p>97 This not only has a signiﬁcant impact on the prediction results, but can reveal the presence of clusters of tasks within the data, hence guiding the choice of the appropriate prediction method (Batch or P2PGat). [sent-763, score-0.443]
</p><p>98 2 Q(f) Q(f) ∝ exp EQ(hx )  NM  ∑ log p(hx | fi ) + log p(f|X) i  i=1  1 1 1 ∝ exp EQ(hx ) − hxT hx + fT hx − fT f − fT Kt ⊗ Kx 2 2 2 1 T −1 ˜ ∝ exp − f (I + Kt ⊗ Kx )f + fT h + const. [sent-783, score-0.414]
</p><p>99 66  20  50  100  DPET  DPET  DPET  (a)  (b)  (c)  Figure 14: AUC on the Landmine detection problem; (a) AUC over 17 tasks by training on 2 tasks, (b) AUC over 15 tasks by training on 4 tasks, (c) AUC over 11 tasks by training on 8 tasks. [sent-828, score-1.296]
</p><p>100 A framework for learning predictive structures from multiple tasks and unlabeled data. [sent-839, score-0.39]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kx', 0.395), ('tasks', 0.39), ('yx', 0.301), ('ap', 0.262), ('hx', 0.207), ('dpet', 0.189), ('batchmcappr', 0.172), ('kt', 0.14), ('cmtmc', 0.139), ('anguinetti', 0.123), ('eneralising', 0.123), ('kolidis', 0.123), ('task', 0.12), ('yt', 0.112), ('mtl', 0.107), ('tudy', 0.105), ('ht', 0.103), ('landmine', 0.098), ('eta', 0.095), ('pproach', 0.095), ('toy', 0.094), ('source', 0.09), ('pool', 0.089), ('rocesses', 0.087), ('responsibilities', 0.084), ('batch', 0.079), ('covariance', 0.077), ('gp', 0.074), ('unseen', 0.073), ('ase', 0.073), ('target', 0.071), ('arrhythmia', 0.07), ('aussian', 0.069), ('cluster', 0.068), ('ysx', 0.066), ('girolami', 0.063), ('auc', 0.062), ('skolidis', 0.057), ('yst', 0.057), ('gps', 0.057), ('bonilla', 0.056), ('nm', 0.054), ('tl', 0.053), ('correlations', 0.053), ('clusters', 0.053), ('eq', 0.051), ('map', 0.05), ('gating', 0.049), ('probit', 0.049), ('posterior', 0.047), ('generalising', 0.047), ('hyperparameters', 0.045), ('nt', 0.043), ('predictions', 0.043), ('training', 0.042), ('adaptation', 0.042), ('daum', 0.042), ('rogers', 0.042), ('vancouver', 0.042), ('beats', 0.041), ('scenario', 0.04), ('classi', 0.039), ('heart', 0.037), ('transfer', 0.037), ('generalizing', 0.036), ('character', 0.035), ('pooling', 0.035), ('vec', 0.035), ('jth', 0.035), ('experts', 0.034), ('hinton', 0.033), ('arnold', 0.033), ('arrhythmic', 0.033), ('trace', 0.033), ('xue', 0.033), ('totally', 0.032), ('baxter', 0.032), ('canada', 0.031), ('diagram', 0.03), ('ft', 0.03), ('met', 0.029), ('scatter', 0.029), ('processes', 0.029), ('rasmussen', 0.029), ('labels', 0.028), ('beat', 0.028), ('er', 0.027), ('fully', 0.027), ('partially', 0.027), ('average', 0.026), ('variational', 0.026), ('generalisation', 0.025), ('gm', 0.025), ('observed', 0.025), ('dht', 0.025), ('ktj', 0.025), ('nhi', 0.025), ('nht', 0.025), ('pvc', 0.025), ('sanguinetti', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="1-tfidf-1" href="./jmlr-2012-A_Case_Study_on_Meta-Generalising%3A_A_Gaussian_Processes_Approach.html">1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</a></p>
<p>Author: Grigorios Skolidis, Guido Sanguinetti</p><p>Abstract: We propose a novel model for meta-generalisation, that is, performing prediction on novel tasks based on information from multiple different but related tasks. The model is based on two coupled Gaussian processes with structured covariance function; one model performs predictions by learning a constrained covariance function encapsulating the relations between the various training tasks, while the second model determines the similarity of new tasks to previously seen tasks. We demonstrate empirically on several real and synthetic data sets both the strengths of the approach and its limitations due to the distributional assumptions underpinning it. Keywords: transfer learning, meta-generalising, multi-task learning, Gaussian processes, mixture of experts</p><p>2 0.094708525 <a title="1-tfidf-2" href="./jmlr-2012-Variational_Multinomial_Logit_Gaussian_Process.html">118 jmlr-2012-Variational Multinomial Logit Gaussian Process</a></p>
<p>Author: Kian Ming A. Chai</p><p>Abstract: Gaussian process prior with an appropriate likelihood function is a ﬂexible non-parametric model for a variety of learning tasks. One important and standard task is multi-class classiﬁcation, which is the categorization of an item into one of several ﬁxed classes. A usual likelihood function for this is the multinomial logistic likelihood function. However, exact inference with this model has proved to be difﬁcult because high-dimensional integrations are required. In this paper, we propose a variational approximation to this model, and we describe the optimization of the variational parameters. Experiments have shown our approximation to be tight. In addition, we provide dataindependent bounds on the marginal likelihood of the model, one of which is shown to be much tighter than the existing variational mean-ﬁeld bound in the experiments. We also derive a proper lower bound on the predictive likelihood that involves the Kullback-Leibler divergence between the approximating and the true posterior. We combine our approach with a recently proposed sparse approximation to give a variational sparse approximation to the Gaussian process multi-class model. We also derive criteria which can be used to select the inducing set, and we show the effectiveness of these criteria over random selection in an experiment. Keywords: Gaussian process, probabilistic classiﬁcation, multinomial logistic, variational approximation, sparse approximation</p><p>3 0.091963008 <a title="1-tfidf-3" href="./jmlr-2012-Transfer_in_Reinforcement_Learning_via_Shared_Features.html">116 jmlr-2012-Transfer in Reinforcement Learning via Shared Features</a></p>
<p>Author: George Konidaris, Ilya Scheidwasser, Andrew Barto</p><p>Abstract: We present a framework for transfer in reinforcement learning based on the idea that related tasks share some common features, and that transfer can be achieved via those shared features. The framework attempts to capture the notion of tasks that are related but distinct, and provides some insight into when transfer can be usefully applied to a problem sequence and when it cannot. We apply the framework to the knowledge transfer problem, and show that an agent can learn a portable shaping function from experience in a sequence of tasks to signiﬁcantly improve performance in a later related task, even given a very brief training period. We also apply the framework to skill transfer, to show that agents can learn portable skills across a sequence of tasks that signiﬁcantly improve performance on later related tasks, approaching the performance of agents given perfectly learned problem-speciﬁc skills. Keywords: reinforcement learning, transfer, shaping, skills</p><p>4 0.082664102 <a title="1-tfidf-4" href="./jmlr-2012-Entropy_Search_for_Information-Efficient_Global_Optimization.html">38 jmlr-2012-Entropy Search for Information-Efficient Global Optimization</a></p>
<p>Author: Philipp Hennig, Christian J. Schuler</p><p>Abstract: Contemporary global optimization algorithms are based on local measures of utility, rather than a probability measure over location and value of the optimum. They thus attempt to collect low function values, not to learn about the optimum. The reason for the absence of probabilistic global optimizers is that the corresponding inference problem is intractable in several ways. This paper develops desiderata for probabilistic optimization algorithms, then presents a concrete algorithm which addresses each of the computational intractabilities with a sequence of approximations and explicitly addresses the decision problem of maximizing information gain from each evaluation. Keywords: optimization, probability, information, Gaussian processes, expectation propagation</p><p>5 0.068244167 <a title="1-tfidf-5" href="./jmlr-2012-Selective_Sampling_and_Active_Learning_from_Single_and_Multiple_Teachers.html">105 jmlr-2012-Selective Sampling and Active Learning from Single and Multiple Teachers</a></p>
<p>Author: Ofer Dekel, Claudio Gentile, Karthik Sridharan</p><p>Abstract: We present a new online learning algorithm in the selective sampling framework, where labels must be actively queried before they are revealed. We prove bounds on the regret of our algorithm and on the number of labels it queries when faced with an adaptive adversarial strategy of generating the instances. Our bounds both generalize and strictly improve over previous bounds in similar settings. Additionally, our selective sampling algorithm can be converted into an efﬁcient statistical active learning algorithm. We extend our algorithm and analysis to the multiple-teacher setting, where the algorithm can choose which subset of teachers to query for each label. Finally, we demonstrate the effectiveness of our techniques on a real-world Internet search problem. Keywords: online learning, regret, label-efﬁcient, crowdsourcing</p><p>6 0.066843912 <a title="1-tfidf-6" href="./jmlr-2012-Pairwise_Support_Vector_Machines_and_their_Application_to_Large_Scale_Problems.html">89 jmlr-2012-Pairwise Support Vector Machines and their Application to Large Scale Problems</a></p>
<p>7 0.061857205 <a title="1-tfidf-7" href="./jmlr-2012-Integrating_a_Partial_Model_into_Model_Free_Reinforcement_Learning.html">51 jmlr-2012-Integrating a Partial Model into Model Free Reinforcement Learning</a></p>
<p>8 0.056655314 <a title="1-tfidf-8" href="./jmlr-2012-Linear_Regression_With_Random_Projections.html">59 jmlr-2012-Linear Regression With Random Projections</a></p>
<p>9 0.05473939 <a title="1-tfidf-9" href="./jmlr-2012-GPLP%3A_A_Local_and_Parallel_Computation_Toolbox_for_Gaussian_Process_Regression.html">47 jmlr-2012-GPLP: A Local and Parallel Computation Toolbox for Gaussian Process Regression</a></p>
<p>10 0.051686957 <a title="1-tfidf-10" href="./jmlr-2012-Confidence-Weighted_Linear_Classification_for_Text_Categorization.html">28 jmlr-2012-Confidence-Weighted Linear Classification for Text Categorization</a></p>
<p>11 0.049712248 <a title="1-tfidf-11" href="./jmlr-2012-Multi-task_Regression_using_Minimal_Penalties.html">73 jmlr-2012-Multi-task Regression using Minimal Penalties</a></p>
<p>12 0.04876795 <a title="1-tfidf-12" href="./jmlr-2012-Regularization_Techniques_for_Learning_with_Matrices.html">97 jmlr-2012-Regularization Techniques for Learning with Matrices</a></p>
<p>13 0.048766226 <a title="1-tfidf-13" href="./jmlr-2012-Learning_Algorithms_for_the_Classification_Restricted_Boltzmann_Machine.html">55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</a></p>
<p>14 0.048061702 <a title="1-tfidf-14" href="./jmlr-2012-Nonparametric_Guidance_of_Autoencoder_Representations_using_Label_Information.html">78 jmlr-2012-Nonparametric Guidance of Autoencoder Representations using Label Information</a></p>
<p>15 0.047621015 <a title="1-tfidf-15" href="./jmlr-2012-Bayesian_Mixed-Effects_Inference_on_Classification_Performance_in_Hierarchical_Data_Sets.html">21 jmlr-2012-Bayesian Mixed-Effects Inference on Classification Performance in Hierarchical Data Sets</a></p>
<p>16 0.043079648 <a title="1-tfidf-16" href="./jmlr-2012-Trading_Regret_for_Efficiency%3A_Online_Convex_Optimization_with_Long_Term_Constraints.html">115 jmlr-2012-Trading Regret for Efficiency: Online Convex Optimization with Long Term Constraints</a></p>
<p>17 0.037830316 <a title="1-tfidf-17" href="./jmlr-2012-Online_Submodular_Minimization.html">84 jmlr-2012-Online Submodular Minimization</a></p>
<p>18 0.036422726 <a title="1-tfidf-18" href="./jmlr-2012-Multi_Kernel_Learning_with_Online-Batch_Optimization.html">74 jmlr-2012-Multi Kernel Learning with Online-Batch Optimization</a></p>
<p>19 0.03576554 <a title="1-tfidf-19" href="./jmlr-2012-Plug-in_Approach_to_Active_Learning.html">91 jmlr-2012-Plug-in Approach to Active Learning</a></p>
<p>20 0.035727467 <a title="1-tfidf-20" href="./jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.184), (1, -0.022), (2, 0.104), (3, -0.081), (4, 0.109), (5, -0.02), (6, 0.033), (7, 0.086), (8, -0.191), (9, 0.078), (10, -0.093), (11, 0.049), (12, -0.124), (13, 0.025), (14, -0.109), (15, 0.041), (16, -0.064), (17, 0.084), (18, -0.029), (19, 0.028), (20, -0.024), (21, 0.03), (22, 0.031), (23, -0.048), (24, 0.092), (25, 0.07), (26, -0.15), (27, 0.143), (28, 0.053), (29, 0.317), (30, -0.099), (31, -0.05), (32, -0.007), (33, 0.076), (34, 0.04), (35, 0.166), (36, -0.024), (37, -0.223), (38, -0.056), (39, 0.141), (40, 0.015), (41, 0.037), (42, 0.033), (43, 0.045), (44, -0.042), (45, -0.099), (46, -0.011), (47, -0.233), (48, 0.015), (49, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96161717 <a title="1-lsi-1" href="./jmlr-2012-A_Case_Study_on_Meta-Generalising%3A_A_Gaussian_Processes_Approach.html">1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</a></p>
<p>Author: Grigorios Skolidis, Guido Sanguinetti</p><p>Abstract: We propose a novel model for meta-generalisation, that is, performing prediction on novel tasks based on information from multiple different but related tasks. The model is based on two coupled Gaussian processes with structured covariance function; one model performs predictions by learning a constrained covariance function encapsulating the relations between the various training tasks, while the second model determines the similarity of new tasks to previously seen tasks. We demonstrate empirically on several real and synthetic data sets both the strengths of the approach and its limitations due to the distributional assumptions underpinning it. Keywords: transfer learning, meta-generalising, multi-task learning, Gaussian processes, mixture of experts</p><p>2 0.62291342 <a title="1-lsi-2" href="./jmlr-2012-Transfer_in_Reinforcement_Learning_via_Shared_Features.html">116 jmlr-2012-Transfer in Reinforcement Learning via Shared Features</a></p>
<p>Author: George Konidaris, Ilya Scheidwasser, Andrew Barto</p><p>Abstract: We present a framework for transfer in reinforcement learning based on the idea that related tasks share some common features, and that transfer can be achieved via those shared features. The framework attempts to capture the notion of tasks that are related but distinct, and provides some insight into when transfer can be usefully applied to a problem sequence and when it cannot. We apply the framework to the knowledge transfer problem, and show that an agent can learn a portable shaping function from experience in a sequence of tasks to signiﬁcantly improve performance in a later related task, even given a very brief training period. We also apply the framework to skill transfer, to show that agents can learn portable skills across a sequence of tasks that signiﬁcantly improve performance on later related tasks, approaching the performance of agents given perfectly learned problem-speciﬁc skills. Keywords: reinforcement learning, transfer, shaping, skills</p><p>3 0.41404971 <a title="1-lsi-3" href="./jmlr-2012-Pairwise_Support_Vector_Machines_and_their_Application_to_Large_Scale_Problems.html">89 jmlr-2012-Pairwise Support Vector Machines and their Application to Large Scale Problems</a></p>
<p>Author: Carl Brunner, Andreas Fischer, Klaus Luig, Thorsten Thies</p><p>Abstract: Pairwise classiﬁcation is the task to predict whether the examples a, b of a pair (a, b) belong to the same class or to different classes. In particular, interclass generalization problems can be treated in this way. In pairwise classiﬁcation, the order of the two input examples should not affect the classiﬁcation result. To achieve this, particular kernels as well as the use of symmetric training sets in the framework of support vector machines were suggested. The paper discusses both approaches in a general way and establishes a strong connection between them. In addition, an efﬁcient implementation is discussed which allows the training of several millions of pairs. The value of these contributions is conﬁrmed by excellent results on the labeled faces in the wild benchmark. Keywords: pairwise support vector machines, interclass generalization, pairwise kernels, large scale problems</p><p>4 0.38361889 <a title="1-lsi-4" href="./jmlr-2012-Variational_Multinomial_Logit_Gaussian_Process.html">118 jmlr-2012-Variational Multinomial Logit Gaussian Process</a></p>
<p>Author: Kian Ming A. Chai</p><p>Abstract: Gaussian process prior with an appropriate likelihood function is a ﬂexible non-parametric model for a variety of learning tasks. One important and standard task is multi-class classiﬁcation, which is the categorization of an item into one of several ﬁxed classes. A usual likelihood function for this is the multinomial logistic likelihood function. However, exact inference with this model has proved to be difﬁcult because high-dimensional integrations are required. In this paper, we propose a variational approximation to this model, and we describe the optimization of the variational parameters. Experiments have shown our approximation to be tight. In addition, we provide dataindependent bounds on the marginal likelihood of the model, one of which is shown to be much tighter than the existing variational mean-ﬁeld bound in the experiments. We also derive a proper lower bound on the predictive likelihood that involves the Kullback-Leibler divergence between the approximating and the true posterior. We combine our approach with a recently proposed sparse approximation to give a variational sparse approximation to the Gaussian process multi-class model. We also derive criteria which can be used to select the inducing set, and we show the effectiveness of these criteria over random selection in an experiment. Keywords: Gaussian process, probabilistic classiﬁcation, multinomial logistic, variational approximation, sparse approximation</p><p>5 0.37788564 <a title="1-lsi-5" href="./jmlr-2012-Entropy_Search_for_Information-Efficient_Global_Optimization.html">38 jmlr-2012-Entropy Search for Information-Efficient Global Optimization</a></p>
<p>Author: Philipp Hennig, Christian J. Schuler</p><p>Abstract: Contemporary global optimization algorithms are based on local measures of utility, rather than a probability measure over location and value of the optimum. They thus attempt to collect low function values, not to learn about the optimum. The reason for the absence of probabilistic global optimizers is that the corresponding inference problem is intractable in several ways. This paper develops desiderata for probabilistic optimization algorithms, then presents a concrete algorithm which addresses each of the computational intractabilities with a sequence of approximations and explicitly addresses the decision problem of maximizing information gain from each evaluation. Keywords: optimization, probability, information, Gaussian processes, expectation propagation</p><p>6 0.30889338 <a title="1-lsi-6" href="./jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</a></p>
<p>7 0.29390046 <a title="1-lsi-7" href="./jmlr-2012-Learning_Algorithms_for_the_Classification_Restricted_Boltzmann_Machine.html">55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</a></p>
<p>8 0.2712146 <a title="1-lsi-8" href="./jmlr-2012-Selective_Sampling_and_Active_Learning_from_Single_and_Multiple_Teachers.html">105 jmlr-2012-Selective Sampling and Active Learning from Single and Multiple Teachers</a></p>
<p>9 0.26560032 <a title="1-lsi-9" href="./jmlr-2012-Nonparametric_Guidance_of_Autoencoder_Representations_using_Label_Information.html">78 jmlr-2012-Nonparametric Guidance of Autoencoder Representations using Label Information</a></p>
<p>10 0.24515472 <a title="1-lsi-10" href="./jmlr-2012-Mal-ID%3A_Automatic_Malware_Detection_Using_Common_Segment_Analysis_and_Meta-Features.html">63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</a></p>
<p>11 0.24360622 <a title="1-lsi-11" href="./jmlr-2012-Integrating_a_Partial_Model_into_Model_Free_Reinforcement_Learning.html">51 jmlr-2012-Integrating a Partial Model into Model Free Reinforcement Learning</a></p>
<p>12 0.24334282 <a title="1-lsi-12" href="./jmlr-2012-Linear_Regression_With_Random_Projections.html">59 jmlr-2012-Linear Regression With Random Projections</a></p>
<p>13 0.23435123 <a title="1-lsi-13" href="./jmlr-2012-Confidence-Weighted_Linear_Classification_for_Text_Categorization.html">28 jmlr-2012-Confidence-Weighted Linear Classification for Text Categorization</a></p>
<p>14 0.23425174 <a title="1-lsi-14" href="./jmlr-2012-DARWIN%3A_A_Framework_for_Machine_Learning_and_Computer_Vision_Research_and_Development.html">30 jmlr-2012-DARWIN: A Framework for Machine Learning and Computer Vision Research and Development</a></p>
<p>15 0.233127 <a title="1-lsi-15" href="./jmlr-2012-A_Unified_View_of_Performance_Metrics%3A_Translating_Threshold_Choice_into_Expected_Classification_Loss.html">10 jmlr-2012-A Unified View of Performance Metrics: Translating Threshold Choice into Expected Classification Loss</a></p>
<p>16 0.2304143 <a title="1-lsi-16" href="./jmlr-2012-Multi-task_Regression_using_Minimal_Penalties.html">73 jmlr-2012-Multi-task Regression using Minimal Penalties</a></p>
<p>17 0.21869363 <a title="1-lsi-17" href="./jmlr-2012-GPLP%3A_A_Local_and_Parallel_Computation_Toolbox_for_Gaussian_Process_Regression.html">47 jmlr-2012-GPLP: A Local and Parallel Computation Toolbox for Gaussian Process Regression</a></p>
<p>18 0.21696898 <a title="1-lsi-18" href="./jmlr-2012-Multi-Target_Regression_with_Rule_Ensembles.html">72 jmlr-2012-Multi-Target Regression with Rule Ensembles</a></p>
<p>19 0.21179959 <a title="1-lsi-19" href="./jmlr-2012-Multi-Assignment_Clustering_for_Boolean_Data.html">70 jmlr-2012-Multi-Assignment Clustering for Boolean Data</a></p>
<p>20 0.20527388 <a title="1-lsi-20" href="./jmlr-2012-An_Active_Learning_Algorithm_for_Ranking_from_Pairwise_Preferences_with_an_Almost_Optimal_Query_Complexity.html">17 jmlr-2012-An Active Learning Algorithm for Ranking from Pairwise Preferences with an Almost Optimal Query Complexity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.39), (7, 0.016), (21, 0.027), (26, 0.032), (29, 0.042), (35, 0.027), (49, 0.037), (56, 0.012), (57, 0.017), (69, 0.013), (75, 0.076), (77, 0.023), (79, 0.02), (81, 0.019), (92, 0.073), (96, 0.094)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.71320111 <a title="1-lda-1" href="./jmlr-2012-Multi-Target_Regression_with_Rule_Ensembles.html">72 jmlr-2012-Multi-Target Regression with Rule Ensembles</a></p>
<p>Author: Timo Aho, Bernard Ženko, Sašo Džeroski, Tapio Elomaa</p><p>Abstract: Methods for learning decision rules are being successfully applied to many problem domains, in particular when understanding and interpretation of the learned model is necessary. In many real life problems, we would like to predict multiple related (nominal or numeric) target attributes simultaneously. While several methods for learning rules that predict multiple targets at once exist, they are all based on the covering algorithm, which does not work well for regression problems. A better solution for regression is the rule ensemble approach that transcribes an ensemble of decision trees into a large collection of rules. An optimization procedure is then used to select the best (and much smaller) subset of these rules and to determine their respective weights. We introduce the F IRE algorithm for solving multi-target regression problems, which employs the rule ensembles approach. We improve the accuracy of the algorithm by adding simple linear functions to the ensemble. We also extensively evaluate the algorithm with and without linear functions. The results show that the accuracy of multi-target regression rule ensembles is high. They are more accurate than, for instance, multi-target regression trees, but not quite as accurate as multi-target random forests. The rule ensembles are signiﬁcantly more concise than random forests, and it is also possible to create compact rule sets that are smaller than a single regression tree but still comparable in accuracy. Keywords: multi-target prediction, rule learning, rule ensembles, regression ∗. Also in Microtask, Tampere, Finland. †. Also in the Centre of Excellence for Integrated Approaches in Chemistry and Biology of Proteins, Ljubljana, Slovenia. ‡. Also in the Centre of Excellence for Integrated Approaches in Chemistry and Biology of Proteins, Ljubljana, Slovenia and the Joˇ ef Stefan International Postgraduate School, Ljubljana, Slovenia. z ˇ c 2012 Timo Aho, Bernard Zenko, Saˇo Dˇ eroski and Tapio Elomaa. s z ˇ ˇ</p><p>same-paper 2 0.68228632 <a title="1-lda-2" href="./jmlr-2012-A_Case_Study_on_Meta-Generalising%3A_A_Gaussian_Processes_Approach.html">1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</a></p>
<p>Author: Grigorios Skolidis, Guido Sanguinetti</p><p>Abstract: We propose a novel model for meta-generalisation, that is, performing prediction on novel tasks based on information from multiple different but related tasks. The model is based on two coupled Gaussian processes with structured covariance function; one model performs predictions by learning a constrained covariance function encapsulating the relations between the various training tasks, while the second model determines the similarity of new tasks to previously seen tasks. We demonstrate empirically on several real and synthetic data sets both the strengths of the approach and its limitations due to the distributional assumptions underpinning it. Keywords: transfer learning, meta-generalising, multi-task learning, Gaussian processes, mixture of experts</p><p>3 0.36321759 <a title="1-lda-3" href="./jmlr-2012-Selective_Sampling_and_Active_Learning_from_Single_and_Multiple_Teachers.html">105 jmlr-2012-Selective Sampling and Active Learning from Single and Multiple Teachers</a></p>
<p>Author: Ofer Dekel, Claudio Gentile, Karthik Sridharan</p><p>Abstract: We present a new online learning algorithm in the selective sampling framework, where labels must be actively queried before they are revealed. We prove bounds on the regret of our algorithm and on the number of labels it queries when faced with an adaptive adversarial strategy of generating the instances. Our bounds both generalize and strictly improve over previous bounds in similar settings. Additionally, our selective sampling algorithm can be converted into an efﬁcient statistical active learning algorithm. We extend our algorithm and analysis to the multiple-teacher setting, where the algorithm can choose which subset of teachers to query for each label. Finally, we demonstrate the effectiveness of our techniques on a real-world Internet search problem. Keywords: online learning, regret, label-efﬁcient, crowdsourcing</p><p>4 0.35815328 <a title="1-lda-4" href="./jmlr-2012-Optimal_Distributed_Online_Prediction_Using_Mini-Batches.html">85 jmlr-2012-Optimal Distributed Online Prediction Using Mini-Batches</a></p>
<p>Author: Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, Lin Xiao</p><p>Abstract: Online prediction methods are typically presented as serial algorithms running on a single processor. However, in the age of web-scale prediction problems, it is increasingly common to encounter situations where a single processor cannot keep up with the high rate at which inputs arrive. In this work, we present the distributed mini-batch algorithm, a method of converting many serial gradient-based online prediction algorithms into distributed algorithms. We prove a regret bound for this method that is asymptotically optimal for smooth convex loss functions and stochastic inputs. Moreover, our analysis explicitly takes into account communication latencies between nodes in the distributed environment. We show how our method can be used to solve the closely-related distributed stochastic optimization problem, achieving an asymptotically linear speed-up over multiple processors. Finally, we demonstrate the merits of our approach on a web-scale online prediction problem. Keywords: distributed computing, online learning, stochastic optimization, regret bounds, convex optimization</p><p>5 0.35548282 <a title="1-lda-5" href="./jmlr-2012-Non-Sparse_Multiple_Kernel_Fisher_Discriminant_Analysis.html">77 jmlr-2012-Non-Sparse Multiple Kernel Fisher Discriminant Analysis</a></p>
<p>Author: Fei Yan, Josef Kittler, Krystian Mikolajczyk, Atif Tahir</p><p>Abstract: Sparsity-inducing multiple kernel Fisher discriminant analysis (MK-FDA) has been studied in the literature. Building on recent advances in non-sparse multiple kernel learning (MKL), we propose a non-sparse version of MK-FDA, which imposes a general ℓ p norm regularisation on the kernel weights. We formulate the associated optimisation problem as a semi-inﬁnite program (SIP), and adapt an iterative wrapper algorithm to solve it. We then discuss, in light of latest advances in MKL optimisation techniques, several reformulations and optimisation strategies that can potentially lead to signiﬁcant improvements in the efﬁciency and scalability of MK-FDA. We carry out extensive experiments on six datasets from various application areas, and compare closely the performance of ℓ p MK-FDA, ﬁxed norm MK-FDA, and several variants of SVM-based MKL (MK-SVM). Our results demonstrate that ℓ p MK-FDA improves upon sparse MK-FDA in many practical situations. The results also show that on image categorisation problems, ℓ p MK-FDA tends to outperform its SVM counterpart. Finally, we also discuss the connection between (MK-)FDA and (MK-)SVM, under the uniﬁed framework of regularised kernel machines. Keywords: multiple kernel learning, kernel ﬁsher discriminant analysis, regularised least squares, support vector machines</p><p>6 0.35496417 <a title="1-lda-6" href="./jmlr-2012-Trading_Regret_for_Efficiency%3A_Online_Convex_Optimization_with_Long_Term_Constraints.html">115 jmlr-2012-Trading Regret for Efficiency: Online Convex Optimization with Long Term Constraints</a></p>
<p>7 0.35488531 <a title="1-lda-7" href="./jmlr-2012-A_Unifying_Probabilistic_Perspective_for_Spectral_Dimensionality_Reduction%3A_Insights_and_New_Models.html">11 jmlr-2012-A Unifying Probabilistic Perspective for Spectral Dimensionality Reduction: Insights and New Models</a></p>
<p>8 0.35466307 <a title="1-lda-8" href="./jmlr-2012-Manifold_Identification_in_Dual_Averaging_for_Regularized_Stochastic_Online_Learning.html">64 jmlr-2012-Manifold Identification in Dual Averaging for Regularized Stochastic Online Learning</a></p>
<p>9 0.354554 <a title="1-lda-9" href="./jmlr-2012-On_the_Convergence_Rate_oflp-Norm_Multiple_Kernel_Learning.html">81 jmlr-2012-On the Convergence Rate oflp-Norm Multiple Kernel Learning</a></p>
<p>10 0.35329533 <a title="1-lda-10" href="./jmlr-2012-Coherence_Functions_with_Applications_in_Large-Margin_Classification_Methods.html">26 jmlr-2012-Coherence Functions with Applications in Large-Margin Classification Methods</a></p>
<p>11 0.35292977 <a title="1-lda-11" href="./jmlr-2012-A_Primal-Dual_Convergence_Analysis_of_Boosting.html">8 jmlr-2012-A Primal-Dual Convergence Analysis of Boosting</a></p>
<p>12 0.35266834 <a title="1-lda-12" href="./jmlr-2012-Conditional_Likelihood_Maximisation%3A_A_Unifying_Framework_for_Information_Theoretic_Feature_Selection.html">27 jmlr-2012-Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></p>
<p>13 0.34880117 <a title="1-lda-13" href="./jmlr-2012-MedLDA%3A_Maximum_Margin_Supervised_Topic_Models.html">65 jmlr-2012-MedLDA: Maximum Margin Supervised Topic Models</a></p>
<p>14 0.34700608 <a title="1-lda-14" href="./jmlr-2012-Positive_Semidefinite_Metric_Learning_Using_Boosting-like_Algorithms.html">92 jmlr-2012-Positive Semidefinite Metric Learning Using Boosting-like Algorithms</a></p>
<p>15 0.34680507 <a title="1-lda-15" href="./jmlr-2012-Efficient_Methods_for_Robust_Classification_Under_Uncertainty_in_Kernel_Matrices.html">36 jmlr-2012-Efficient Methods for Robust Classification Under Uncertainty in Kernel Matrices</a></p>
<p>16 0.34657598 <a title="1-lda-16" href="./jmlr-2012-Active_Learning_via_Perfect_Selective_Classification.html">13 jmlr-2012-Active Learning via Perfect Selective Classification</a></p>
<p>17 0.34653878 <a title="1-lda-17" href="./jmlr-2012-Optimistic_Bayesian_Sampling_in_Contextual-Bandit_Problems.html">86 jmlr-2012-Optimistic Bayesian Sampling in Contextual-Bandit Problems</a></p>
<p>18 0.34621423 <a title="1-lda-18" href="./jmlr-2012-Algorithms_for_Learning_Kernels_Based_on_Centered_Alignment.html">16 jmlr-2012-Algorithms for Learning Kernels Based on Centered Alignment</a></p>
<p>19 0.34597254 <a title="1-lda-19" href="./jmlr-2012-Multi-Instance_Learning_with_Any_Hypothesis_Class.html">71 jmlr-2012-Multi-Instance Learning with Any Hypothesis Class</a></p>
<p>20 0.34435785 <a title="1-lda-20" href="./jmlr-2012-Security_Analysis_of_Online_Centroid_Anomaly_Detection.html">104 jmlr-2012-Security Analysis of Online Centroid Anomaly Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
