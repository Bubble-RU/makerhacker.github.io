<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2 jmlr-2012-A Comparison of the Lasso and  Marginal Regression</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-2" href="#">jmlr2012-2</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2 jmlr-2012-A Comparison of the Lasso and  Marginal Regression</h1>
<br/><p>Source: <a title="jmlr-2012-2-pdf" href="http://jmlr.org/papers/volume13/genovese12b/genovese12b.pdf">pdf</a></p><p>Author: Christopher R. Genovese, Jiashun Jin, Larry Wasserman, Zhigang Yao</p><p>Abstract: The lasso is an important method for sparse, high-dimensional regression problems, with efﬁcient algorithms available, a long history of practical success, and a large body of theoretical results supporting and explaining its performance. But even with the best available algorithms, ﬁnding the lasso solutions remains a computationally challenging task in cases where the number of covariates vastly exceeds the number of data points. Marginal regression, where each dependent variable is regressed separately on each covariate, offers a promising alternative in this case because the estimates can be computed roughly two orders faster than the lasso solutions. The question that remains is how the statistical performance of the method compares to that of the lasso in these cases. In this paper, we study the relative statistical performance of the lasso and marginal regression for sparse, high-dimensional regression problems. We consider the problem of learning which coefﬁcients are non-zero. Our main results are as follows: (i) we compare the conditions under which the lasso and marginal regression guarantee exact recovery in the ﬁxed design, noise free case; (ii) we establish conditions under which marginal regression provides exact recovery with high probability in the ﬁxed design, noise free, random coefﬁcients case; and (iii) we derive rates of convergence for both procedures, where performance is measured by the number of coefﬁcients with incorrect sign, and characterize the regions in the parameter space recovery is and is not possible under this metric. In light of the computational advantages of marginal regression in very high dimensional problems, our theoretical and simulations results suggest that the procedure merits further study. Keywords: high-dimensional regression, lasso, phase diagram, regularization</p><p>Reference: <a title="jmlr-2012-2-reference" href="../jmlr2012_reference/jmlr-2012-A_Comparison_of_the_Lasso_and__Marginal_Regression_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('css', 0.41), ('lasso', 0.334), ('cns', 0.323), ('xis', 0.268), ('vn', 0.248), ('tn', 0.242), ('dn', 0.174), ('enoves', 0.161), ('yao', 0.153), ('asso', 0.145), ('wasserm', 0.142), ('argin', 0.133), ('ham', 0.131), ('gi', 0.119), ('sgn', 0.118), ('donoho', 0.117), ('incoh', 0.117), ('omparison', 0.106), ('sn', 0.106), ('margin', 0.104)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="2-tfidf-1" href="./jmlr-2012-A_Comparison_of_the_Lasso_and__Marginal_Regression.html">2 jmlr-2012-A Comparison of the Lasso and  Marginal Regression</a></p>
<p>2 0.18643478 <a title="2-tfidf-2" href="./jmlr-2012-Estimation_and_Selection_via_Absolute_Penalized_Convex_Minimization_And_Its_Multistage_Adaptive_Applications.html">39 jmlr-2012-Estimation and Selection via Absolute Penalized Convex Minimization And Its Multistage Adaptive Applications</a></p>
<p>3 0.1209809 <a title="2-tfidf-3" href="./jmlr-2012-A_Multi-Stage_Framework_for_Dantzig_Selector_and_LASSO.html">7 jmlr-2012-A Multi-Stage Framework for Dantzig Selector and LASSO</a></p>
<p>4 0.11366715 <a title="2-tfidf-4" href="./jmlr-2012-Variable_Selection_in_High-dimensional_Varying-coefficient_Models_with_Global_Optimality.html">117 jmlr-2012-Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality</a></p>
<p>5 0.092906423 <a title="2-tfidf-5" href="./jmlr-2012-The_huge_Package_for_High-dimensional_Undirected_Graph_Estimation_in_R.html">113 jmlr-2012-The huge Package for High-dimensional Undirected Graph Estimation in R</a></p>
<p>6 0.085814677 <a title="2-tfidf-6" href="./jmlr-2012-Exact_Covariance_Thresholding_into_Connected_Components_for_Large-Scale_Graphical_Lasso.html">40 jmlr-2012-Exact Covariance Thresholding into Connected Components for Large-Scale Graphical Lasso</a></p>
<p>7 0.08028467 <a title="2-tfidf-7" href="./jmlr-2012-Structured_Sparsity_and_Generalization.html">111 jmlr-2012-Structured Sparsity and Generalization</a></p>
<p>8 0.080271713 <a title="2-tfidf-8" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>9 0.079554021 <a title="2-tfidf-9" href="./jmlr-2012-Minimax_Manifold_Estimation.html">68 jmlr-2012-Minimax Manifold Estimation</a></p>
<p>10 0.077898942 <a title="2-tfidf-10" href="./jmlr-2012-Active_Learning_via_Perfect_Selective_Classification.html">13 jmlr-2012-Active Learning via Perfect Selective Classification</a></p>
<p>11 0.069647141 <a title="2-tfidf-11" href="./jmlr-2012-Noise-Contrastive_Estimation_of_Unnormalized_Statistical_Models%2C_with_Applications_to_Natural_Image_Statistics.html">76 jmlr-2012-Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics</a></p>
<p>12 0.066177003 <a title="2-tfidf-12" href="./jmlr-2012-Restricted_Strong_Convexity_and_Weighted_Matrix_Completion%3A_Optimal_Bounds_with_Noise.html">99 jmlr-2012-Restricted Strong Convexity and Weighted Matrix Completion: Optimal Bounds with Noise</a></p>
<p>13 0.065819278 <a title="2-tfidf-13" href="./jmlr-2012-Coherence_Functions_with_Applications_in_Large-Margin_Classification_Methods.html">26 jmlr-2012-Coherence Functions with Applications in Large-Margin Classification Methods</a></p>
<p>14 0.059254143 <a title="2-tfidf-14" href="./jmlr-2012-Integrating_a_Partial_Model_into_Model_Free_Reinforcement_Learning.html">51 jmlr-2012-Integrating a Partial Model into Model Free Reinforcement Learning</a></p>
<p>15 0.053773984 <a title="2-tfidf-15" href="./jmlr-2012-Minimax-Optimal_Rates_For_Sparse_Additive_Models_Over_Kernel_Classes_Via_Convex_Programming.html">67 jmlr-2012-Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming</a></p>
<p>16 0.050907794 <a title="2-tfidf-16" href="./jmlr-2012-EP-GIG_Priors_and_Applications_in_Bayesian_Sparse_Learning.html">35 jmlr-2012-EP-GIG Priors and Applications in Bayesian Sparse Learning</a></p>
<p>17 0.048781816 <a title="2-tfidf-17" href="./jmlr-2012-Consistent_Model_Selection_Criteria_on_High_Dimensions.html">29 jmlr-2012-Consistent Model Selection Criteria on High Dimensions</a></p>
<p>18 0.046408907 <a title="2-tfidf-18" href="./jmlr-2012-Regularization_Techniques_for_Learning_with_Matrices.html">97 jmlr-2012-Regularization Techniques for Learning with Matrices</a></p>
<p>19 0.045799654 <a title="2-tfidf-19" href="./jmlr-2012-Iterative_Reweighted_Algorithms_for_Matrix_Rank_Minimization.html">52 jmlr-2012-Iterative Reweighted Algorithms for Matrix Rank Minimization</a></p>
<p>20 0.045035575 <a title="2-tfidf-20" href="./jmlr-2012-On_the_Necessity_of_Irrelevant_Variables.html">82 jmlr-2012-On the Necessity of Irrelevant Variables</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.23), (1, -0.155), (2, 0.173), (3, -0.004), (4, 0.057), (5, -0.272), (6, -0.054), (7, -0.128), (8, -0.045), (9, -0.03), (10, 0.051), (11, -0.037), (12, 0.05), (13, 0.093), (14, -0.079), (15, -0.063), (16, 0.061), (17, -0.004), (18, -0.069), (19, 0.013), (20, -0.004), (21, -0.156), (22, 0.06), (23, -0.02), (24, 0.113), (25, -0.009), (26, 0.257), (27, 0.02), (28, -0.007), (29, 0.068), (30, 0.024), (31, -0.082), (32, 0.038), (33, -0.001), (34, 0.039), (35, 0.125), (36, -0.047), (37, 0.003), (38, 0.014), (39, 0.056), (40, -0.049), (41, 0.038), (42, 0.009), (43, 0.122), (44, 0.046), (45, -0.092), (46, 0.002), (47, -0.068), (48, -0.033), (49, -0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91959882 <a title="2-lsi-1" href="./jmlr-2012-A_Comparison_of_the_Lasso_and__Marginal_Regression.html">2 jmlr-2012-A Comparison of the Lasso and  Marginal Regression</a></p>
<p>2 0.73328549 <a title="2-lsi-2" href="./jmlr-2012-Estimation_and_Selection_via_Absolute_Penalized_Convex_Minimization_And_Its_Multistage_Adaptive_Applications.html">39 jmlr-2012-Estimation and Selection via Absolute Penalized Convex Minimization And Its Multistage Adaptive Applications</a></p>
<p>3 0.56930411 <a title="2-lsi-3" href="./jmlr-2012-Variable_Selection_in_High-dimensional_Varying-coefficient_Models_with_Global_Optimality.html">117 jmlr-2012-Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality</a></p>
<p>4 0.52523732 <a title="2-lsi-4" href="./jmlr-2012-A_Multi-Stage_Framework_for_Dantzig_Selector_and_LASSO.html">7 jmlr-2012-A Multi-Stage Framework for Dantzig Selector and LASSO</a></p>
<p>5 0.39648423 <a title="2-lsi-5" href="./jmlr-2012-Structured_Sparsity_and_Generalization.html">111 jmlr-2012-Structured Sparsity and Generalization</a></p>
<p>6 0.36822769 <a title="2-lsi-6" href="./jmlr-2012-The_huge_Package_for_High-dimensional_Undirected_Graph_Estimation_in_R.html">113 jmlr-2012-The huge Package for High-dimensional Undirected Graph Estimation in R</a></p>
<p>7 0.32735404 <a title="2-lsi-7" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>8 0.32576144 <a title="2-lsi-8" href="./jmlr-2012-Exact_Covariance_Thresholding_into_Connected_Components_for_Large-Scale_Graphical_Lasso.html">40 jmlr-2012-Exact Covariance Thresholding into Connected Components for Large-Scale Graphical Lasso</a></p>
<p>9 0.32525432 <a title="2-lsi-9" href="./jmlr-2012-Minimax_Manifold_Estimation.html">68 jmlr-2012-Minimax Manifold Estimation</a></p>
<p>10 0.30997074 <a title="2-lsi-10" href="./jmlr-2012-Structured_Sparsity_via_Alternating_Direction_Methods.html">112 jmlr-2012-Structured Sparsity via Alternating Direction Methods</a></p>
<p>11 0.30341494 <a title="2-lsi-11" href="./jmlr-2012-Restricted_Strong_Convexity_and_Weighted_Matrix_Completion%3A_Optimal_Bounds_with_Noise.html">99 jmlr-2012-Restricted Strong Convexity and Weighted Matrix Completion: Optimal Bounds with Noise</a></p>
<p>12 0.30106473 <a title="2-lsi-12" href="./jmlr-2012-Consistent_Model_Selection_Criteria_on_High_Dimensions.html">29 jmlr-2012-Consistent Model Selection Criteria on High Dimensions</a></p>
<p>13 0.28930432 <a title="2-lsi-13" href="./jmlr-2012-Integrating_a_Partial_Model_into_Model_Free_Reinforcement_Learning.html">51 jmlr-2012-Integrating a Partial Model into Model Free Reinforcement Learning</a></p>
<p>14 0.27609164 <a title="2-lsi-14" href="./jmlr-2012-A_Unified_View_of_Performance_Metrics%3A_Translating_Threshold_Choice_into_Expected_Classification_Loss.html">10 jmlr-2012-A Unified View of Performance Metrics: Translating Threshold Choice into Expected Classification Loss</a></p>
<p>15 0.27155668 <a title="2-lsi-15" href="./jmlr-2012-Large-scale_Linear_Support_Vector_Regression.html">54 jmlr-2012-Large-scale Linear Support Vector Regression</a></p>
<p>16 0.26653695 <a title="2-lsi-16" href="./jmlr-2012-Learning_Linear_Cyclic_Causal_Models_with_Latent_Variables.html">56 jmlr-2012-Learning Linear Cyclic Causal Models with Latent Variables</a></p>
<p>17 0.26580259 <a title="2-lsi-17" href="./jmlr-2012-Stability_of_Density-Based_Clustering.html">109 jmlr-2012-Stability of Density-Based Clustering</a></p>
<p>18 0.26423925 <a title="2-lsi-18" href="./jmlr-2012-Algebraic_Geometric_Comparison_of_Probability_Distributions.html">15 jmlr-2012-Algebraic Geometric Comparison of Probability Distributions</a></p>
<p>19 0.25859889 <a title="2-lsi-19" href="./jmlr-2012-Noise-Contrastive_Estimation_of_Unnormalized_Statistical_Models%2C_with_Applications_to_Natural_Image_Statistics.html">76 jmlr-2012-Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics</a></p>
<p>20 0.25219443 <a title="2-lsi-20" href="./jmlr-2012-Multi-task_Regression_using_Minimal_Penalties.html">73 jmlr-2012-Multi-task Regression using Minimal Penalties</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.011), (28, 0.041), (38, 0.018), (48, 0.081), (50, 0.017), (67, 0.106), (69, 0.021), (79, 0.013), (81, 0.034), (82, 0.015), (90, 0.502), (95, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.7338174 <a title="2-lda-1" href="./jmlr-2012-A_Comparison_of_the_Lasso_and__Marginal_Regression.html">2 jmlr-2012-A Comparison of the Lasso and  Marginal Regression</a></p>
<p>2 0.71247882 <a title="2-lda-2" href="./jmlr-2012-Restricted_Strong_Convexity_and_Weighted_Matrix_Completion%3A_Optimal_Bounds_with_Noise.html">99 jmlr-2012-Restricted Strong Convexity and Weighted Matrix Completion: Optimal Bounds with Noise</a></p>
<p>3 0.45977488 <a title="2-lda-3" href="./jmlr-2012-Consistent_Model_Selection_Criteria_on_High_Dimensions.html">29 jmlr-2012-Consistent Model Selection Criteria on High Dimensions</a></p>
<p>4 0.42102519 <a title="2-lda-4" href="./jmlr-2012-A_Multi-Stage_Framework_for_Dantzig_Selector_and_LASSO.html">7 jmlr-2012-A Multi-Stage Framework for Dantzig Selector and LASSO</a></p>
<p>5 0.3779639 <a title="2-lda-5" href="./jmlr-2012-Linear_Regression_With_Random_Projections.html">59 jmlr-2012-Linear Regression With Random Projections</a></p>
<p>6 0.37630734 <a title="2-lda-6" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>7 0.3746537 <a title="2-lda-7" href="./jmlr-2012-Iterative_Reweighted_Algorithms_for_Matrix_Rank_Minimization.html">52 jmlr-2012-Iterative Reweighted Algorithms for Matrix Rank Minimization</a></p>
<p>8 0.37048039 <a title="2-lda-8" href="./jmlr-2012-Security_Analysis_of_Online_Centroid_Anomaly_Detection.html">104 jmlr-2012-Security Analysis of Online Centroid Anomaly Detection</a></p>
<p>9 0.36971396 <a title="2-lda-9" href="./jmlr-2012-Estimation_and_Selection_via_Absolute_Penalized_Convex_Minimization_And_Its_Multistage_Adaptive_Applications.html">39 jmlr-2012-Estimation and Selection via Absolute Penalized Convex Minimization And Its Multistage Adaptive Applications</a></p>
<p>10 0.36870697 <a title="2-lda-10" href="./jmlr-2012-Minimax-Optimal_Rates_For_Sparse_Additive_Models_Over_Kernel_Classes_Via_Convex_Programming.html">67 jmlr-2012-Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming</a></p>
<p>11 0.36732802 <a title="2-lda-11" href="./jmlr-2012-Multi-Instance_Learning_with_Any_Hypothesis_Class.html">71 jmlr-2012-Multi-Instance Learning with Any Hypothesis Class</a></p>
<p>12 0.36691096 <a title="2-lda-12" href="./jmlr-2012-Active_Learning_via_Perfect_Selective_Classification.html">13 jmlr-2012-Active Learning via Perfect Selective Classification</a></p>
<p>13 0.36188287 <a title="2-lda-13" href="./jmlr-2012-Online_Submodular_Minimization.html">84 jmlr-2012-Online Submodular Minimization</a></p>
<p>14 0.36151141 <a title="2-lda-14" href="./jmlr-2012-Variational_Multinomial_Logit_Gaussian_Process.html">118 jmlr-2012-Variational Multinomial Logit Gaussian Process</a></p>
<p>15 0.35605109 <a title="2-lda-15" href="./jmlr-2012-Variable_Selection_in_High-dimensional_Varying-coefficient_Models_with_Global_Optimality.html">117 jmlr-2012-Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality</a></p>
<p>16 0.35301983 <a title="2-lda-16" href="./jmlr-2012-Plug-in_Approach_to_Active_Learning.html">91 jmlr-2012-Plug-in Approach to Active Learning</a></p>
<p>17 0.35093546 <a title="2-lda-17" href="./jmlr-2012-Trading_Regret_for_Efficiency%3A_Online_Convex_Optimization_with_Long_Term_Constraints.html">115 jmlr-2012-Trading Regret for Efficiency: Online Convex Optimization with Long Term Constraints</a></p>
<p>18 0.3463546 <a title="2-lda-18" href="./jmlr-2012-Finite-Sample_Analysis_of_Least-Squares_Policy_Iteration.html">46 jmlr-2012-Finite-Sample Analysis of Least-Squares Policy Iteration</a></p>
<p>19 0.34612942 <a title="2-lda-19" href="./jmlr-2012-Multi-task_Regression_using_Minimal_Penalties.html">73 jmlr-2012-Multi-task Regression using Minimal Penalties</a></p>
<p>20 0.34487268 <a title="2-lda-20" href="./jmlr-2012-Coherence_Functions_with_Applications_in_Large-Margin_Classification_Methods.html">26 jmlr-2012-Coherence Functions with Applications in Large-Margin Classification Methods</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
