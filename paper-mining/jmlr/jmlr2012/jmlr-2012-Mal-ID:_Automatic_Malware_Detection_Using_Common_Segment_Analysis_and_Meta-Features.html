<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-63" href="#">jmlr2012-63</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</h1>
<br/><p>Source: <a title="jmlr-2012-63-pdf" href="http://jmlr.org/papers/volume13/tahan12a/tahan12a.pdf">pdf</a></p><p>Author: Gil Tahan, Lior Rokach, Yuval Shahar</p><p>Abstract: This paper proposes several novel methods, based on machine learning, to detect malware in executable ﬁles without any need for preprocessing, such as unpacking or disassembling. The basic method (Mal-ID) is a new static (form-based) analysis methodology that uses common segment analysis in order to detect malware ﬁles. By using common segment analysis, Mal-ID is able to discard malware parts that originate from benign code. In addition, Mal-ID uses a new kind of feature, termed meta-feature, to better capture the properties of the analyzed segments. Rather than using the entire ﬁle, as is usually the case with machine learning based techniques, the new approach detects malware on the segment level. This study also introduces two Mal-ID extensions that improve the Mal-ID basic method in various aspects. We rigorously evaluated Mal-ID and its two extensions with more than ten performance measures, and compared them to the highly rated boosted decision tree method under identical settings. The evaluation demonstrated that Mal-ID and the two Mal-ID extensions outperformed the boosted decision tree method in almost all respects. In addition, the results indicated that by extracting meaningful features, it is sufﬁcient to employ one simple detection rule for classifying executable ﬁles. Keywords: computer security, malware detection, common segment analysis, supervised learning</p><p>Reference: <a title="jmlr-2012-63-reference" href="../jmlr2012_reference/jmlr-2012-Mal-ID%3A_Automatic_Malware_Detection_Using_Common_Segment_Analysis_and_Meta-Features_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 653 Beer-Sheva, Israel 84105  Editor: Charles Elkan  Abstract This paper proposes several novel methods, based on machine learning, to detect malware in executable ﬁles without any need for preprocessing, such as unpacking or disassembling. [sent-10, score-0.829]
</p><p>2 The basic method (Mal-ID) is a new static (form-based) analysis methodology that uses common segment analysis in order to detect malware ﬁles. [sent-11, score-0.998]
</p><p>3 By using common segment analysis, Mal-ID is able to discard malware parts that originate from benign code. [sent-12, score-1.148]
</p><p>4 Rather than using the entire ﬁle, as is usually the case with machine learning based techniques, the new approach detects malware on the segment level. [sent-14, score-0.869]
</p><p>5 Keywords: computer security, malware detection, common segment analysis, supervised learning  1. [sent-19, score-0.869]
</p><p>6 The rate of malware attacks and infections is not yet leveling. [sent-28, score-0.696]
</p><p>7 There are many ways to mitigate malware infection and spread. [sent-30, score-0.696]
</p><p>8 Tools such as anti-virus and anti-spyware are able to identify and block or identify malware based on its behavior (Franc and Sonnenburg, 2009) or static features (see Table 1 below). [sent-31, score-0.751]
</p><p>9 A static feature may be a rule or a signature that uniquely identiﬁes a malware or malware group. [sent-32, score-1.469]
</p><p>10 While the tools mitigating malware may vary, at their core there must be some classiﬁcation method to distinguish malware ﬁles from benign ﬁles. [sent-33, score-1.624]
</p><p>11 In addition, in recent years many researchers have been using machine learning (ML) techniques to produce a binary classiﬁer that is able to distinguish malware from benign ﬁles. [sent-41, score-0.928]
</p><p>12 To test the effectiveness of ML techniques, in malware detection, the researchers listed in Table 1 conducted experiments combining various feature extraction methods along with several feature selection and classiﬁcation algorithms. [sent-69, score-0.696]
</p><p>13 (2010) presented a variation of the method, presented above, that uses Hierarchical Associative Classiﬁer (HAC) to detect malware from a large imbalanced list of applications. [sent-80, score-0.729]
</p><p>14 The malware in the imbalanced list were the minority class. [sent-81, score-0.696]
</p><p>15 First, both malware and benign programs are executed inside the virtual machine and the instruction sequences are collected during runtime. [sent-88, score-0.981]
</p><p>16 (2011) presented a simple method to detect malware variants. [sent-96, score-0.729]
</p><p>17 (2011) showed that when the similarity is high, there is a high probability that the suspected ﬁle is a malware variant. [sent-101, score-0.696]
</p><p>18 The experiments deﬁnitely proved that is possible to use ML techniques for malware detection. [sent-102, score-0.696]
</p><p>19 Since most malware are also made of the same common building blocks, we believe it would be reasonable to discard the parts of a malware that are common to all kinds of software, leaving only the parts that are unique to the malware. [sent-111, score-1.418]
</p><p>20 Doing so should increase the difference between malware ﬁles and benign ﬁles and therefore should result in a lower misclassiﬁcation rate. [sent-112, score-0.928]
</p><p>21 As a result, current techniques using short n-gram rely on complex conditions and involve many features for detecting malware ﬁles. [sent-121, score-0.767]
</p><p>22 The goal of this paper is to develop and evaluate a novel methodology and supporting algorithms for detecting malware ﬁles by using common segment analysis. [sent-122, score-0.912]
</p><p>23 In the proposed methodology we initially detect and nullify, by zero patching, benign segments and therefore resolve the deﬁciency of analyzing ﬁles with segments that may not contribute or even hinder classiﬁcation. [sent-123, score-0.547]
</p><p>24 As a result, malware that has been developed with these tools generally resembles benign applications. [sent-179, score-0.928]
</p><p>25 Therefore it may be reasonable to assume that there will be resemblances in various types of malware due to sharing common malware library code or even similar speciﬁc method to perform malicious action. [sent-181, score-1.477]
</p><p>26 Of course such malware commonalities cannot be always guaranteed. [sent-182, score-0.696]
</p><p>27 Since many modern malware ﬁles are in fact much larger than 1 MB, analysis of the newer applications is much more complex than previously when the applications themselves were smaller as well as the malware attacking them. [sent-185, score-1.392]
</p><p>28 As noted above, many applications and malware are developed using the development platforms that include large program language libraries. [sent-187, score-0.722]
</p><p>29 For example, a worm malware that distributes itself via email may contain a benign code for sending emails. [sent-189, score-0.977]
</p><p>30 The TFL contains data structures constructed from malware without segments identiﬁed as benign (i. [sent-199, score-1.069]
</p><p>31 As can be seen in this ﬁgure, our Mal-ID methodology uses two distinct stages to accomplish the malware detection task: setup and detection. [sent-203, score-0.8]
</p><p>32 The detection phase classiﬁes a previously unseen application as either malware or benign. [sent-205, score-0.836]
</p><p>33 1 The Setup Phase The setup phase involves collecting two kinds of ﬁles: benign and malware ﬁles. [sent-209, score-0.964]
</p><p>34 The malware ﬁles can, for example, be downloaded from trusted dedicated Internet sites, or by collaborating with an anti-virus company. [sent-211, score-0.696]
</p><p>35 In this study the malware collection was obtained from trusted sources. [sent-212, score-0.696]
</p><p>36 In particular, Ben-Gurion University Computational Center provided us malware that were detected by them over time. [sent-213, score-0.696]
</p><p>37 The CFL repository is constructed from benign ﬁles and the TFL repository is constructed from malware ﬁles. [sent-215, score-0.928]
</p><p>38 Note that in the proposed algorithm, we are calculating the distribution of 3-grams within each ﬁle and across ﬁles, to make sure that a 3-gram belongs to the examined segment and thus associate the segment to either benign (CFL) or malware (TFL). [sent-218, score-1.306]
</p><p>39 Moreover, 3-grams that seem to appear approximately within the same offset in all malware can be used to characterize the malware. [sent-219, score-0.696]
</p><p>40 Figure 1: The Mal-ID method for detecting new malware applications. [sent-224, score-0.739]
</p><p>41 Each ﬁle from the malware collection is broken into segments. [sent-236, score-0.696]
</p><p>42 It is important to note that the end result is the TFL, a repository made of segments found only in malware and not in benign ﬁles. [sent-241, score-1.069]
</p><p>43 Once the setup phase has constructed the CFL and the TFL, it is possible to classify a ﬁle F as benign or as malware using the algorithm presented in Figure 2. [sent-268, score-0.964]
</p><p>44 The algorithm gets the ThreatThreshold parameter which indicates the minimum occurrences a segment should appear in the TFL in order to be qualiﬁed as malware indicator. [sent-296, score-0.869]
</p><p>45 Obviously a segment that does not appear in any malware cannot be used to indicate that the ﬁle is a malware. [sent-300, score-0.869]
</p><p>46 958  AUTOMATIC M ALWARE D ETECTION  (j) Lines 21-25 (optional stage, aimed to reduce false malware detection). [sent-308, score-0.696]
</p><p>47 A segment that meets all of the above conditions is tested against the malware ﬁle groups that contain all 3-gram segments. [sent-309, score-0.869]
</p><p>48 As a result, only segments that actually reside in the malware are left in the segment collection. [sent-310, score-1.01]
</p><p>49 Second level index aggregation—Count all segments that are found in malware and not in the CFL. [sent-314, score-0.837]
</p><p>50 Classify—If there are at least X segments found in the malware train set (TFL) and not in the CFL then the ﬁle is malware; otherwise consider the ﬁle as benign. [sent-317, score-0.837]
</p><p>51 960  19  AUTOMATIC M ALWARE D ETECTION  Finally, using the model is used to detect the malware among the ﬁles in the test set. [sent-360, score-0.729]
</p><p>52 Next, zero patch each malware in the training set as follows: Iterate over all of the ﬁle segments and perform common segment analysis to detect the segments that appear in the CFL. [sent-366, score-1.215]
</p><p>53 The benign segments (the segments that appear in the CFL) are zero patched in an attempt to reduce the number of n-gram that are clearly not relevant for detecting segments that appear only in malware. [sent-367, score-0.732]
</p><p>54 The patched malware collection and the unchanged benign ﬁle collection are used for training. [sent-371, score-0.962]
</p><p>55 To examine whether the proposed basic methods, could detect malware while keeping the false alarm rate as small as possible. [sent-393, score-0.798]
</p><p>56 An additional 849 malware ﬁles were gathered from the Internet with lengths ranging from 6Kb to 4. [sent-407, score-0.696]
</p><p>57 The malware and benign ﬁle sets were used without any decryption, decompression or any other preprocessing. [sent-415, score-0.928]
</p><p>58 The malware types and frequencies are presented in Figure 3. [sent-416, score-0.696]
</p><p>59 Figure 3: Distribution of malware types in data set. [sent-422, score-0.696]
</p><p>60 Given the low rate of malware versus benign code, accuracy might be a misleading measure. [sent-424, score-0.928]
</p><p>61 Let p(xi ) represents the posterior probability of the instance xi to be associated with the malware class according to the classiﬁer. [sent-433, score-0.696]
</p><p>62 1 R ESULTS  OF  M AL -ID BASIC M ODEL  Table 3 presents the detection performance of the proposed method for 70% of the benign ﬁles and 90% of the malware ﬁles that are used for training. [sent-445, score-1.032]
</p><p>63 The ratio between malware and benign was kept ﬁxed for all cases. [sent-480, score-0.956]
</p><p>64 On the other hand because we also increase the imbalance ratio between benign and malware therefore we should have expected to a decrease in the predictive performance. [sent-536, score-0.956]
</p><p>65 nodes are linear Table 7 reports the mean TPR of Mal-ID basic for small malwares (size<=350K) and large Mal-IDF+RF malware (size>350K) using the largest training set. [sent-597, score-0.851]
</p><p>66 In order to estimate the effect of obfuscation on detection rate, we have divided the tested malware into two groups—obfuscated and non-obfuscated. [sent-603, score-0.823]
</p><p>67 951 in data set content, training size, the benign and malware ratio and possibly other 0. [sent-651, score-0.987]
</p><p>68 893 62%  Compression  Table 8: A comparison of TPR (True Positive Rate) Mal-ID basic for obfuscated and nonobfuscated malware when using maximum training size. [sent-724, score-0.912]
</p><p>69 The comparison suggests that Mal-ID meta-features are useful in contributing to malware detection and probably more meaningful than simple n-gram in capturing a ﬁle’s essence. [sent-742, score-0.8]
</p><p>70 Considering detection performance only when choosing a malware detection method may not be enough; it is important to consider other aspects as well. [sent-746, score-0.904]
</p><p>71 The reason is that each detected segment, that passed the Mal-ID ﬁlter stage as explained in Section 2, can be tracked back to a speciﬁc malware or malware group. [sent-750, score-1.441]
</p><p>72 Disassembly or reverse engineering of the whole malware is no longer required. [sent-752, score-0.696]
</p><p>73 4 Default Signature For Real-time Malware Detection Hardware The end result of applying Mal-ID basic method is a ﬁle segment or segments that appear in malware ﬁles only and thus may be used as a signature for anti-virus tools. [sent-765, score-1.129]
</p><p>74 The detected malware segments can be used, as described by Filiol (2006), to generate signatures resistant against black-box analysis. [sent-766, score-0.837]
</p><p>75 IPSs require the anytime detection trait to act as real-time malware ﬁltering devices and thus promote and provide users with default protection. [sent-768, score-0.823]
</p><p>76 Having both malware detection and signature generation could help shorten the window of vulnerability. [sent-769, score-0.85]
</p><p>77 It is estimated1 that the mean malware size has increased from 150K (in 2005) to 350K (in 2010). [sent-777, score-0.696]
</p><p>78 In this sense, we referred to malware as they are found “in the Wild”. [sent-789, score-0.696]
</p><p>79 For example, malware developers are sharing tools for facilitating the generation of new malwares. [sent-792, score-0.696]
</p><p>80 org/, one can ﬁnd many tools (such as Falckon Encrypter that is used for obfuscation) that can be used by the malware developers but are not used by benign software developers. [sent-795, score-0.928]
</p><p>81 All malware that use the Falckon Encrypter, share the same decryption segment. [sent-796, score-0.696]
</p><p>82 The results of Table 8 agree with the previously-made observation that ML techniques can classify malware that are obfuscated (compressed or encrypted or both). [sent-797, score-0.812]
</p><p>83 006), however it should be noted that this value was obtained when our corpus contained 2,627 benign ﬁles and 849 malware ﬁles (i. [sent-801, score-0.928]
</p><p>84 According to Kolter and Maloof (2006), the success in detecting obfuscated malware relies on learning certain forms of obfuscation such as run-time decompression. [sent-806, score-0.878]
</p><p>85 (2005) noticed that in many cases malware requires ﬁxed sequences to be used in the body of the malware (which must exist before self-decryption or self-decompression) in order to exploit a speciﬁc vulnerability and selfpropagate. [sent-813, score-1.392]
</p><p>86 Theoretically an attacker can speciﬁcally design a malware that will make it hard for MAL ID to detect it. [sent-818, score-0.729]
</p><p>87 In particular, if a malware is designed such that the entropy measure will be high for all segments, it will be undiscovered by the Mal-ID basic method. [sent-819, score-0.804]
</p><p>88 Summary and Future Work In this paper we have described novel methods based on machine learning to detect malware in executable ﬁles without any need for preprocessing the executables. [sent-823, score-0.829]
</p><p>89 The basic method that we presented works on the segment level for detecting new malware instead of using the entire ﬁle as usually done in machine learning based techniques. [sent-824, score-0.981]
</p><p>90 We believe this study has made several contributions to malware detection research, including the introduction of: 1. [sent-829, score-0.8]
</p><p>91 a new and effective method for malware detection based on common segment analysis and supporting algorithms. [sent-830, score-0.973]
</p><p>92 The importance of common segment analysis to the process of malware detection was identiﬁed and demonstrated. [sent-831, score-0.973]
</p><p>93 BCR, BER, PPV, NPV and entropy decrease for measuring the performance of malware detection methods. [sent-838, score-0.839]
</p><p>94 It is our assumption that systematically collecting and choosing common segments will provide a better representation of benign common segments and a more robust and lower FPR. [sent-844, score-0.514]
</p><p>95 A robust and low FPR will enable the use of more sensitive malware detection methods (or parameters that affect malware detection) without increasing the FPR too much. [sent-845, score-1.496]
</p><p>96 In addition, it will be interesting to test the proposed method on live network data and on an institutional network and determine if it detects malware that is not detected by other means. [sent-850, score-0.696]
</p><p>97 Finally, future work may repeat the evaluation Mal-ID on a larger scale with thousands of malware samples and tens of thousands of non-malware samples. [sent-851, score-0.696]
</p><p>98 Auto-sign: an automatic signature generator for high-speed malware ﬁltering devices. [sent-1091, score-0.78]
</p><p>99 Sbmds: an interpretable string based malware detection system using svm ensemble with bagging. [sent-1122, score-0.8]
</p><p>100 Hierarchical associative classiﬁer (hac) for malware detection from the large and imbalanced gray list. [sent-1130, score-0.8]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('malware', 0.696), ('benign', 0.232), ('fpr', 0.187), ('rf', 0.184), ('segment', 0.173), ('tahan', 0.158), ('rokach', 0.144), ('segments', 0.141), ('les', 0.135), ('cfl', 0.13), ('obfuscated', 0.116), ('tfl', 0.116), ('detection', 0.104), ('alware', 0.103), ('hahar', 0.103), ('maloof', 0.103), ('tpr', 0.1), ('kolter', 0.1), ('executable', 0.1), ('le', 0.099), ('bytes', 0.094), ('etection', 0.079), ('basic', 0.069), ('boosted', 0.063), ('malicious', 0.059), ('nn', 0.057), ('elovici', 0.055), ('executables', 0.055), ('malwares', 0.055), ('npv', 0.055), ('ppv', 0.055), ('auc', 0.052), ('signature', 0.05), ('pe', 0.045), ('ber', 0.044), ('detecting', 0.043), ('ye', 0.043), ('ml', 0.043), ('nave', 0.041), ('tree', 0.039), ('strings', 0.039), ('entropy', 0.039), ('phase', 0.036), ('patched', 0.034), ('spread', 0.034), ('automatic', 0.034), ('detect', 0.033), ('examined', 0.032), ('threat', 0.032), ('training', 0.031), ('tp', 0.03), ('security', 0.03), ('hac', 0.029), ('ratio', 0.028), ('gain', 0.028), ('decision', 0.028), ('features', 0.028), ('entropylow', 0.027), ('flooder', 0.027), ('instruction', 0.027), ('maxmalsize', 0.027), ('mfg', 0.027), ('segmentsinmalwareonly', 0.027), ('static', 0.027), ('classi', 0.027), ('platforms', 0.026), ('file', 0.026), ('forest', 0.026), ('programs', 0.026), ('code', 0.026), ('discard', 0.026), ('explained', 0.025), ('api', 0.024), ('continue', 0.024), ('stage', 0.024), ('bcr', 0.023), ('anytime', 0.023), ('newsome', 0.023), ('obfuscation', 0.023), ('virology', 0.023), ('virus', 0.023), ('email', 0.023), ('acc', 0.023), ('sr', 0.023), ('rotation', 0.021), ('internet', 0.021), ('operating', 0.021), ('trees', 0.021), ('installed', 0.021), ('originate', 0.021), ('bgu', 0.021), ('datashort', 0.021), ('disassembly', 0.021), ('henchiri', 0.021), ('mpc', 0.021), ('opcode', 0.021), ('patching', 0.021), ('repositories', 0.021), ('segmentcheck', 0.021), ('segmentcoll', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="63-tfidf-1" href="./jmlr-2012-Mal-ID%3A_Automatic_Malware_Detection_Using_Common_Segment_Analysis_and_Meta-Features.html">63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</a></p>
<p>Author: Gil Tahan, Lior Rokach, Yuval Shahar</p><p>Abstract: This paper proposes several novel methods, based on machine learning, to detect malware in executable ﬁles without any need for preprocessing, such as unpacking or disassembling. The basic method (Mal-ID) is a new static (form-based) analysis methodology that uses common segment analysis in order to detect malware ﬁles. By using common segment analysis, Mal-ID is able to discard malware parts that originate from benign code. In addition, Mal-ID uses a new kind of feature, termed meta-feature, to better capture the properties of the analyzed segments. Rather than using the entire ﬁle, as is usually the case with machine learning based techniques, the new approach detects malware on the segment level. This study also introduces two Mal-ID extensions that improve the Mal-ID basic method in various aspects. We rigorously evaluated Mal-ID and its two extensions with more than ten performance measures, and compared them to the highly rated boosted decision tree method under identical settings. The evaluation demonstrated that Mal-ID and the two Mal-ID extensions outperformed the boosted decision tree method in almost all respects. In addition, the results indicated that by extracting meaningful features, it is sufﬁcient to employ one simple detection rule for classifying executable ﬁles. Keywords: computer security, malware detection, common segment analysis, supervised learning</p><p>2 0.048640385 <a title="63-tfidf-2" href="./jmlr-2012-Security_Analysis_of_Online_Centroid_Anomaly_Detection.html">104 jmlr-2012-Security Analysis of Online Centroid Anomaly Detection</a></p>
<p>Author: Marius Kloft, Pavel Laskov</p><p>Abstract: Security issues are crucial in a number of machine learning applications, especially in scenarios dealing with human activity rather than natural phenomena (e.g., information ranking, spam detection, malware detection, etc.). In such cases, learning algorithms may have to cope with manipulated data aimed at hampering decision making. Although some previous work addressed the issue of handling malicious data in the context of supervised learning, very little is known about the behavior of anomaly detection methods in such scenarios. In this contribution,1 we analyze the performance of a particular method—online centroid anomaly detection—in the presence of adversarial noise. Our analysis addresses the following security-related issues: formalization of learning and attack processes, derivation of an optimal attack, and analysis of attack efﬁciency and limitations. We derive bounds on the effectiveness of a poisoning attack against centroid anomaly detection under different conditions: attacker’s full or limited control over the trafﬁc and bounded false positive rate. Our bounds show that whereas a poisoning attack can be effectively staged in the unconstrained case, it can be made arbitrarily difﬁcult (a strict upper bound on the attacker’s gain) if external constraints are properly used. Our experimental evaluation, carried out on real traces of HTTP and exploit trafﬁc, conﬁrms the tightness of our theoretical bounds and the practicality of our protection mechanisms. Keywords: anomaly detection, adversarial, security analysis, support vector data description, computer security, network intrusion detection</p><p>3 0.048461426 <a title="63-tfidf-3" href="./jmlr-2012-ML-Flex%3A_A_Flexible_Toolbox_for_Performing_Classification_Analyses_In_Parallel.html">61 jmlr-2012-ML-Flex: A Flexible Toolbox for Performing Classification Analyses In Parallel</a></p>
<p>Author: Stephen R. Piccolo, Lewis J. Frey</p><p>Abstract: Motivated by a need to classify high-dimensional, heterogeneous data from the bioinformatics domain, we developed ML-Flex, a machine-learning toolbox that enables users to perform two-class and multi-class classiﬁcation analyses in a systematic yet ﬂexible manner. ML-Flex was written in Java but is capable of interfacing with third-party packages written in other programming languages. It can handle multiple input-data formats and supports a variety of customizations. MLFlex provides implementations of various validation strategies, which can be executed in parallel across multiple computing cores, processors, and nodes. Additionally, ML-Flex supports aggregating evidence across multiple algorithms and data sets via ensemble learning. This open-source software package is freely available from http://mlflex.sourceforge.net. Keywords: toolbox, classiﬁcation, parallel, ensemble, reproducible research</p><p>4 0.04703616 <a title="63-tfidf-4" href="./jmlr-2012-Sally%3A_A_Tool_for_Embedding_Strings_in_Vector_Spaces.html">102 jmlr-2012-Sally: A Tool for Embedding Strings in Vector Spaces</a></p>
<p>Author: Konrad Rieck, Christian Wressnegger, Alexander Bikadorov</p><p>Abstract: Strings and sequences are ubiquitous in many areas of data analysis. However, only few learning methods can be directly applied to this form of data. We present Sally, a tool for embedding strings in vector spaces that allows for applying a wide range of learning methods to string data. Sally implements a generalized form of the bag-of-words model, where strings are mapped to a vector space that is spanned by a set of string features, such as words or n-grams of words. The implementation of Sally builds on efﬁcient string algorithms and enables processing millions of strings and features. The tool supports several data formats and is capable of interfacing with common learning environments, such as Weka, Shogun, Matlab, or Pylab. Sally has been successfully applied for learning with natural language text, DNA sequences and monitored program behavior. Keywords: string embedding, bag-of-words models, learning with sequential data</p><p>5 0.038720466 <a title="63-tfidf-5" href="./jmlr-2012-A_Unified_View_of_Performance_Metrics%3A_Translating_Threshold_Choice_into_Expected_Classification_Loss.html">10 jmlr-2012-A Unified View of Performance Metrics: Translating Threshold Choice into Expected Classification Loss</a></p>
<p>Author: José Hernández-Orallo, Peter Flach, Cèsar Ferri</p><p>Abstract: Many performance metrics have been introduced in the literature for the evaluation of classiﬁcation performance, each of them with different origins and areas of application. These metrics include accuracy, unweighted accuracy, the area under the ROC curve or the ROC convex hull, the mean absolute error and the Brier score or mean squared error (with its decomposition into reﬁnement and calibration). One way of understanding the relations among these metrics is by means of variable operating conditions (in the form of misclassiﬁcation costs and/or class distributions). Thus, a metric may correspond to some expected loss over different operating conditions. One dimension for the analysis has been the distribution for this range of operating conditions, leading to some important connections in the area of proper scoring rules. We demonstrate in this paper that there is an equally important dimension which has so far received much less attention in the analysis of performance metrics. This dimension is given by the decision rule, which is typically implemented as a threshold choice method when using scoring models. In this paper, we explore many old and new threshold choice methods: ﬁxed, score-uniform, score-driven, rate-driven and optimal, among others. By calculating the expected loss obtained with these threshold choice methods for a uniform range of operating conditions we give clear interpretations of the 0-1 loss, the absolute error, the Brier score, the AUC and the reﬁnement loss respectively. Our analysis provides a comprehensive view of performance metrics as well as a systematic approach to loss minimisation which can be summarised as follows: given a model, apply the threshold choice methods that correspond with the available information about the operating condition, and compare their expected losses. In order to assist in this procedure we also derive several connections between the aforementioned performance metrics, and we highlight the role of calibra</p><p>6 0.031784203 <a title="63-tfidf-6" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>7 0.026400086 <a title="63-tfidf-7" href="./jmlr-2012-Variable_Selection_in_High-dimensional_Varying-coefficient_Models_with_Global_Optimality.html">117 jmlr-2012-Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality</a></p>
<p>8 0.026031828 <a title="63-tfidf-8" href="./jmlr-2012-Sign_Language_Recognition_using_Sub-Units.html">106 jmlr-2012-Sign Language Recognition using Sub-Units</a></p>
<p>9 0.025914581 <a title="63-tfidf-9" href="./jmlr-2012-An_Introduction_to_Artificial_Prediction_Markets_for_Classification.html">19 jmlr-2012-An Introduction to Artificial Prediction Markets for Classification</a></p>
<p>10 0.023615265 <a title="63-tfidf-10" href="./jmlr-2012-Bayesian_Mixed-Effects_Inference_on_Classification_Performance_in_Hierarchical_Data_Sets.html">21 jmlr-2012-Bayesian Mixed-Effects Inference on Classification Performance in Hierarchical Data Sets</a></p>
<p>11 0.022609839 <a title="63-tfidf-11" href="./jmlr-2012-Discriminative_Hierarchical_Part-based_Models_for_Human_Parsing_and_Action_Recognition.html">32 jmlr-2012-Discriminative Hierarchical Part-based Models for Human Parsing and Action Recognition</a></p>
<p>12 0.022402655 <a title="63-tfidf-12" href="./jmlr-2012-Pattern_for_Python.html">90 jmlr-2012-Pattern for Python</a></p>
<p>13 0.0220543 <a title="63-tfidf-13" href="./jmlr-2012-Refinement_of_Operator-valued_Reproducing_Kernels.html">96 jmlr-2012-Refinement of Operator-valued Reproducing Kernels</a></p>
<p>14 0.019697582 <a title="63-tfidf-14" href="./jmlr-2012-Facilitating_Score_and_Causal_Inference_Trees_for_Large_Observational_Studies.html">42 jmlr-2012-Facilitating Score and Causal Inference Trees for Large Observational Studies</a></p>
<p>15 0.01947937 <a title="63-tfidf-15" href="./jmlr-2012-Entropy_Search_for_Information-Efficient_Global_Optimization.html">38 jmlr-2012-Entropy Search for Information-Efficient Global Optimization</a></p>
<p>16 0.019288141 <a title="63-tfidf-16" href="./jmlr-2012-Feature_Selection_via_Dependence_Maximization.html">44 jmlr-2012-Feature Selection via Dependence Maximization</a></p>
<p>17 0.018920342 <a title="63-tfidf-17" href="./jmlr-2012-Multi-Target_Regression_with_Rule_Ensembles.html">72 jmlr-2012-Multi-Target Regression with Rule Ensembles</a></p>
<p>18 0.018534627 <a title="63-tfidf-18" href="./jmlr-2012-A_Case_Study_on_Meta-Generalising%3A_A_Gaussian_Processes_Approach.html">1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</a></p>
<p>19 0.018524971 <a title="63-tfidf-19" href="./jmlr-2012-DARWIN%3A_A_Framework_for_Machine_Learning_and_Computer_Vision_Research_and_Development.html">30 jmlr-2012-DARWIN: A Framework for Machine Learning and Computer Vision Research and Development</a></p>
<p>20 0.018495163 <a title="63-tfidf-20" href="./jmlr-2012-On_the_Necessity_of_Irrelevant_Variables.html">82 jmlr-2012-On the Necessity of Irrelevant Variables</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.093), (1, 0.04), (2, 0.096), (3, -0.016), (4, 0.018), (5, 0.018), (6, 0.048), (7, 0.006), (8, 0.018), (9, 0.035), (10, 0.021), (11, -0.037), (12, 0.083), (13, -0.054), (14, -0.04), (15, 0.128), (16, 0.081), (17, -0.049), (18, -0.076), (19, -0.093), (20, 0.024), (21, 0.022), (22, -0.056), (23, -0.065), (24, 0.093), (25, -0.06), (26, -0.064), (27, 0.026), (28, 0.114), (29, -0.106), (30, 0.256), (31, -0.353), (32, 0.119), (33, 0.032), (34, 0.077), (35, 0.13), (36, 0.017), (37, -0.158), (38, -0.077), (39, -0.037), (40, -0.086), (41, 0.055), (42, 0.024), (43, -0.107), (44, -0.165), (45, -0.105), (46, -0.017), (47, -0.021), (48, 0.035), (49, -0.004)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95157522 <a title="63-lsi-1" href="./jmlr-2012-Mal-ID%3A_Automatic_Malware_Detection_Using_Common_Segment_Analysis_and_Meta-Features.html">63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</a></p>
<p>Author: Gil Tahan, Lior Rokach, Yuval Shahar</p><p>Abstract: This paper proposes several novel methods, based on machine learning, to detect malware in executable ﬁles without any need for preprocessing, such as unpacking or disassembling. The basic method (Mal-ID) is a new static (form-based) analysis methodology that uses common segment analysis in order to detect malware ﬁles. By using common segment analysis, Mal-ID is able to discard malware parts that originate from benign code. In addition, Mal-ID uses a new kind of feature, termed meta-feature, to better capture the properties of the analyzed segments. Rather than using the entire ﬁle, as is usually the case with machine learning based techniques, the new approach detects malware on the segment level. This study also introduces two Mal-ID extensions that improve the Mal-ID basic method in various aspects. We rigorously evaluated Mal-ID and its two extensions with more than ten performance measures, and compared them to the highly rated boosted decision tree method under identical settings. The evaluation demonstrated that Mal-ID and the two Mal-ID extensions outperformed the boosted decision tree method in almost all respects. In addition, the results indicated that by extracting meaningful features, it is sufﬁcient to employ one simple detection rule for classifying executable ﬁles. Keywords: computer security, malware detection, common segment analysis, supervised learning</p><p>2 0.64348131 <a title="63-lsi-2" href="./jmlr-2012-Sally%3A_A_Tool_for_Embedding_Strings_in_Vector_Spaces.html">102 jmlr-2012-Sally: A Tool for Embedding Strings in Vector Spaces</a></p>
<p>Author: Konrad Rieck, Christian Wressnegger, Alexander Bikadorov</p><p>Abstract: Strings and sequences are ubiquitous in many areas of data analysis. However, only few learning methods can be directly applied to this form of data. We present Sally, a tool for embedding strings in vector spaces that allows for applying a wide range of learning methods to string data. Sally implements a generalized form of the bag-of-words model, where strings are mapped to a vector space that is spanned by a set of string features, such as words or n-grams of words. The implementation of Sally builds on efﬁcient string algorithms and enables processing millions of strings and features. The tool supports several data formats and is capable of interfacing with common learning environments, such as Weka, Shogun, Matlab, or Pylab. Sally has been successfully applied for learning with natural language text, DNA sequences and monitored program behavior. Keywords: string embedding, bag-of-words models, learning with sequential data</p><p>3 0.54490149 <a title="63-lsi-3" href="./jmlr-2012-Security_Analysis_of_Online_Centroid_Anomaly_Detection.html">104 jmlr-2012-Security Analysis of Online Centroid Anomaly Detection</a></p>
<p>Author: Marius Kloft, Pavel Laskov</p><p>Abstract: Security issues are crucial in a number of machine learning applications, especially in scenarios dealing with human activity rather than natural phenomena (e.g., information ranking, spam detection, malware detection, etc.). In such cases, learning algorithms may have to cope with manipulated data aimed at hampering decision making. Although some previous work addressed the issue of handling malicious data in the context of supervised learning, very little is known about the behavior of anomaly detection methods in such scenarios. In this contribution,1 we analyze the performance of a particular method—online centroid anomaly detection—in the presence of adversarial noise. Our analysis addresses the following security-related issues: formalization of learning and attack processes, derivation of an optimal attack, and analysis of attack efﬁciency and limitations. We derive bounds on the effectiveness of a poisoning attack against centroid anomaly detection under different conditions: attacker’s full or limited control over the trafﬁc and bounded false positive rate. Our bounds show that whereas a poisoning attack can be effectively staged in the unconstrained case, it can be made arbitrarily difﬁcult (a strict upper bound on the attacker’s gain) if external constraints are properly used. Our experimental evaluation, carried out on real traces of HTTP and exploit trafﬁc, conﬁrms the tightness of our theoretical bounds and the practicality of our protection mechanisms. Keywords: anomaly detection, adversarial, security analysis, support vector data description, computer security, network intrusion detection</p><p>4 0.43960705 <a title="63-lsi-4" href="./jmlr-2012-ML-Flex%3A_A_Flexible_Toolbox_for_Performing_Classification_Analyses_In_Parallel.html">61 jmlr-2012-ML-Flex: A Flexible Toolbox for Performing Classification Analyses In Parallel</a></p>
<p>Author: Stephen R. Piccolo, Lewis J. Frey</p><p>Abstract: Motivated by a need to classify high-dimensional, heterogeneous data from the bioinformatics domain, we developed ML-Flex, a machine-learning toolbox that enables users to perform two-class and multi-class classiﬁcation analyses in a systematic yet ﬂexible manner. ML-Flex was written in Java but is capable of interfacing with third-party packages written in other programming languages. It can handle multiple input-data formats and supports a variety of customizations. MLFlex provides implementations of various validation strategies, which can be executed in parallel across multiple computing cores, processors, and nodes. Additionally, ML-Flex supports aggregating evidence across multiple algorithms and data sets via ensemble learning. This open-source software package is freely available from http://mlflex.sourceforge.net. Keywords: toolbox, classiﬁcation, parallel, ensemble, reproducible research</p><p>5 0.294184 <a title="63-lsi-5" href="./jmlr-2012-A_Unified_View_of_Performance_Metrics%3A_Translating_Threshold_Choice_into_Expected_Classification_Loss.html">10 jmlr-2012-A Unified View of Performance Metrics: Translating Threshold Choice into Expected Classification Loss</a></p>
<p>Author: José Hernández-Orallo, Peter Flach, Cèsar Ferri</p><p>Abstract: Many performance metrics have been introduced in the literature for the evaluation of classiﬁcation performance, each of them with different origins and areas of application. These metrics include accuracy, unweighted accuracy, the area under the ROC curve or the ROC convex hull, the mean absolute error and the Brier score or mean squared error (with its decomposition into reﬁnement and calibration). One way of understanding the relations among these metrics is by means of variable operating conditions (in the form of misclassiﬁcation costs and/or class distributions). Thus, a metric may correspond to some expected loss over different operating conditions. One dimension for the analysis has been the distribution for this range of operating conditions, leading to some important connections in the area of proper scoring rules. We demonstrate in this paper that there is an equally important dimension which has so far received much less attention in the analysis of performance metrics. This dimension is given by the decision rule, which is typically implemented as a threshold choice method when using scoring models. In this paper, we explore many old and new threshold choice methods: ﬁxed, score-uniform, score-driven, rate-driven and optimal, among others. By calculating the expected loss obtained with these threshold choice methods for a uniform range of operating conditions we give clear interpretations of the 0-1 loss, the absolute error, the Brier score, the AUC and the reﬁnement loss respectively. Our analysis provides a comprehensive view of performance metrics as well as a systematic approach to loss minimisation which can be summarised as follows: given a model, apply the threshold choice methods that correspond with the available information about the operating condition, and compare their expected losses. In order to assist in this procedure we also derive several connections between the aforementioned performance metrics, and we highlight the role of calibra</p><p>6 0.25008735 <a title="63-lsi-6" href="./jmlr-2012-An_Introduction_to_Artificial_Prediction_Markets_for_Classification.html">19 jmlr-2012-An Introduction to Artificial Prediction Markets for Classification</a></p>
<p>7 0.21436745 <a title="63-lsi-7" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>8 0.20105891 <a title="63-lsi-8" href="./jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</a></p>
<p>9 0.19779587 <a title="63-lsi-9" href="./jmlr-2012-Conditional_Likelihood_Maximisation%3A_A_Unifying_Framework_for_Information_Theoretic_Feature_Selection.html">27 jmlr-2012-Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></p>
<p>10 0.19758163 <a title="63-lsi-10" href="./jmlr-2012-Multi-Target_Regression_with_Rule_Ensembles.html">72 jmlr-2012-Multi-Target Regression with Rule Ensembles</a></p>
<p>11 0.19391365 <a title="63-lsi-11" href="./jmlr-2012-A_Case_Study_on_Meta-Generalising%3A_A_Gaussian_Processes_Approach.html">1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</a></p>
<p>12 0.18390626 <a title="63-lsi-12" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>13 0.17907982 <a title="63-lsi-13" href="./jmlr-2012-Entropy_Search_for_Information-Efficient_Global_Optimization.html">38 jmlr-2012-Entropy Search for Information-Efficient Global Optimization</a></p>
<p>14 0.16633324 <a title="63-lsi-14" href="./jmlr-2012-A_Model_of_the_Perception_of_Facial_Expressions_of_Emotion_by_Humans%3A_Research_Overview_and_Perspectives.html">6 jmlr-2012-A Model of the Perception of Facial Expressions of Emotion by Humans: Research Overview and Perspectives</a></p>
<p>15 0.16191781 <a title="63-lsi-15" href="./jmlr-2012-Discriminative_Hierarchical_Part-based_Models_for_Human_Parsing_and_Action_Recognition.html">32 jmlr-2012-Discriminative Hierarchical Part-based Models for Human Parsing and Action Recognition</a></p>
<p>16 0.16012608 <a title="63-lsi-16" href="./jmlr-2012-Sign_Language_Recognition_using_Sub-Units.html">106 jmlr-2012-Sign Language Recognition using Sub-Units</a></p>
<p>17 0.15562671 <a title="63-lsi-17" href="./jmlr-2012-Variable_Selection_in_High-dimensional_Varying-coefficient_Models_with_Global_Optimality.html">117 jmlr-2012-Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality</a></p>
<p>18 0.15334482 <a title="63-lsi-18" href="./jmlr-2012-Random_Search_for_Hyper-Parameter_Optimization.html">95 jmlr-2012-Random Search for Hyper-Parameter Optimization</a></p>
<p>19 0.14774328 <a title="63-lsi-19" href="./jmlr-2012-Quantum_Set_Intersection_and_its_Application_to_Associative_Memory.html">93 jmlr-2012-Quantum Set Intersection and its Application to Associative Memory</a></p>
<p>20 0.1399639 <a title="63-lsi-20" href="./jmlr-2012-PAC-Bayes_Bounds_with_Data_Dependent_Priors.html">87 jmlr-2012-PAC-Bayes Bounds with Data Dependent Priors</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.016), (21, 0.043), (26, 0.026), (27, 0.025), (29, 0.04), (35, 0.018), (49, 0.014), (56, 0.028), (57, 0.013), (69, 0.022), (75, 0.042), (77, 0.016), (79, 0.015), (81, 0.469), (92, 0.038), (96, 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.766761 <a title="63-lda-1" href="./jmlr-2012-Mal-ID%3A_Automatic_Malware_Detection_Using_Common_Segment_Analysis_and_Meta-Features.html">63 jmlr-2012-Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features</a></p>
<p>Author: Gil Tahan, Lior Rokach, Yuval Shahar</p><p>Abstract: This paper proposes several novel methods, based on machine learning, to detect malware in executable ﬁles without any need for preprocessing, such as unpacking or disassembling. The basic method (Mal-ID) is a new static (form-based) analysis methodology that uses common segment analysis in order to detect malware ﬁles. By using common segment analysis, Mal-ID is able to discard malware parts that originate from benign code. In addition, Mal-ID uses a new kind of feature, termed meta-feature, to better capture the properties of the analyzed segments. Rather than using the entire ﬁle, as is usually the case with machine learning based techniques, the new approach detects malware on the segment level. This study also introduces two Mal-ID extensions that improve the Mal-ID basic method in various aspects. We rigorously evaluated Mal-ID and its two extensions with more than ten performance measures, and compared them to the highly rated boosted decision tree method under identical settings. The evaluation demonstrated that Mal-ID and the two Mal-ID extensions outperformed the boosted decision tree method in almost all respects. In addition, the results indicated that by extracting meaningful features, it is sufﬁcient to employ one simple detection rule for classifying executable ﬁles. Keywords: computer security, malware detection, common segment analysis, supervised learning</p><p>2 0.75827628 <a title="63-lda-2" href="./jmlr-2012-Nonparametric_Guidance_of_Autoencoder_Representations_using_Label_Information.html">78 jmlr-2012-Nonparametric Guidance of Autoencoder Representations using Label Information</a></p>
<p>Author: Jasper Snoek, Ryan P. Adams, Hugo Larochelle</p><p>Abstract: While unsupervised learning has long been useful for density modeling, exploratory data analysis and visualization, it has become increasingly important for discovering features that will later be used for discriminative tasks. Discriminative algorithms often work best with highly-informative features; remarkably, such features can often be learned without the labels. One particularly effective way to perform such unsupervised learning has been to use autoencoder neural networks, which ﬁnd latent representations that are constrained but nevertheless informative for reconstruction. However, pure unsupervised learning with autoencoders can ﬁnd representations that may or may not be useful for the ultimate discriminative task. It is a continuing challenge to guide the training of an autoencoder so that it ﬁnds features which will be useful for predicting labels. Similarly, we often have a priori information regarding what statistical variation will be irrelevant to the ultimate discriminative task, and we would like to be able to use this for guidance as well. Although a typical strategy would be to include a parametric discriminative model as part of the autoencoder training, here we propose a nonparametric approach that uses a Gaussian process to guide the representation. By using a nonparametric model, we can ensure that a useful discriminative function exists for a given set of features, without explicitly instantiating it. We demonstrate the superiority of this guidance mechanism on four data sets, including a real-world application to rehabilitation research. We also show how our proposed approach can learn to explicitly ignore statistically signiﬁcant covariate information that is label-irrelevant, by evaluating on the small NORB image recognition problem in which pose and lighting labels are available. Keywords: autoencoder, gaussian process, gaussian process latent variable model, representation learning, unsupervised learning</p><p>3 0.63986254 <a title="63-lda-3" href="./jmlr-2012-Online_Learning_in_the_Embedded_Manifold_of_Low-rank_Matrices.html">83 jmlr-2012-Online Learning in the Embedded Manifold of Low-rank Matrices</a></p>
<p>Author: Uri Shalit, Daphna Weinshall, Gal Chechik</p><p>Abstract: When learning models that are represented in matrix forms, enforcing a low-rank constraint can dramatically improve the memory and run time complexity, while providing a natural regularization of the model. However, naive approaches to minimizing functions over the set of low-rank matrices are either prohibitively time consuming (repeated singular value decomposition of the matrix) or numerically unstable (optimizing a factored representation of the low-rank matrix). We build on recent advances in optimization over manifolds, and describe an iterative online learning procedure, consisting of a gradient step, followed by a second-order retraction back to the manifold. While the ideal retraction is costly to compute, and so is the projection operator that approximates it, we describe another retraction that can be computed efﬁciently. It has run time and memory complexity of O ((n + m)k) for a rank-k matrix of dimension m × n, when using an online procedure with rank-one gradients. We use this algorithm, L ORETA, to learn a matrix-form similarity measure over pairs of documents represented as high dimensional vectors. L ORETA improves the mean average precision over a passive-aggressive approach in a factorized model, and also improves over a full model trained on pre-selected features using the same memory requirements. We further adapt L ORETA to learn positive semi-deﬁnite low-rank matrices, providing an online algorithm for low-rank metric learning. L ORETA also shows consistent improvement over standard weakly supervised methods in a large (1600 classes and 1 million images, using ImageNet) multi-label image classiﬁcation task. Keywords: low rank, Riemannian manifolds, metric learning, retractions, multitask learning, online learning</p><p>4 0.31821424 <a title="63-lda-4" href="./jmlr-2012-MedLDA%3A_Maximum_Margin_Supervised_Topic_Models.html">65 jmlr-2012-MedLDA: Maximum Margin Supervised Topic Models</a></p>
<p>Author: Jun Zhu, Amr Ahmed, Eric P. Xing</p><p>Abstract: A supervised topic model can use side information such as ratings or labels associated with documents or images to discover more predictive low dimensional topical representations of the data. However, existing supervised topic models predominantly employ likelihood-driven objective functions for learning and inference, leaving the popular and potentially powerful max-margin principle unexploited for seeking predictive representations of data and more discriminative topic bases for the corpus. In this paper, we propose the maximum entropy discrimination latent Dirichlet allocation (MedLDA) model, which integrates the mechanism behind the max-margin prediction models (e.g., SVMs) with the mechanism behind the hierarchical Bayesian topic models (e.g., LDA) under a uniﬁed constrained optimization framework, and yields latent topical representations that are more discriminative and more suitable for prediction tasks such as document classiﬁcation or regression. The principle underlying the MedLDA formalism is quite general and can be applied for jointly max-margin and maximum likelihood learning of directed or undirected topic models when supervising side information is available. Efﬁcient variational methods for posterior inference and parameter estimation are derived and extensive empirical studies on several real data sets are also provided. Our experimental results demonstrate qualitatively and quantitatively that MedLDA could: 1) discover sparse and highly discriminative topical representations; 2) achieve state of the art prediction performance; and 3) be more efﬁcient than existing supervised topic models, especially for classiﬁcation. Keywords: supervised topic models, max-margin learning, maximum entropy discrimination, latent Dirichlet allocation, support vector machines</p><p>5 0.28379059 <a title="63-lda-5" href="./jmlr-2012-Security_Analysis_of_Online_Centroid_Anomaly_Detection.html">104 jmlr-2012-Security Analysis of Online Centroid Anomaly Detection</a></p>
<p>Author: Marius Kloft, Pavel Laskov</p><p>Abstract: Security issues are crucial in a number of machine learning applications, especially in scenarios dealing with human activity rather than natural phenomena (e.g., information ranking, spam detection, malware detection, etc.). In such cases, learning algorithms may have to cope with manipulated data aimed at hampering decision making. Although some previous work addressed the issue of handling malicious data in the context of supervised learning, very little is known about the behavior of anomaly detection methods in such scenarios. In this contribution,1 we analyze the performance of a particular method—online centroid anomaly detection—in the presence of adversarial noise. Our analysis addresses the following security-related issues: formalization of learning and attack processes, derivation of an optimal attack, and analysis of attack efﬁciency and limitations. We derive bounds on the effectiveness of a poisoning attack against centroid anomaly detection under different conditions: attacker’s full or limited control over the trafﬁc and bounded false positive rate. Our bounds show that whereas a poisoning attack can be effectively staged in the unconstrained case, it can be made arbitrarily difﬁcult (a strict upper bound on the attacker’s gain) if external constraints are properly used. Our experimental evaluation, carried out on real traces of HTTP and exploit trafﬁc, conﬁrms the tightness of our theoretical bounds and the practicality of our protection mechanisms. Keywords: anomaly detection, adversarial, security analysis, support vector data description, computer security, network intrusion detection</p><p>6 0.27680993 <a title="63-lda-6" href="./jmlr-2012-Learning_Algorithms_for_the_Classification_Restricted_Boltzmann_Machine.html">55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</a></p>
<p>7 0.25912467 <a title="63-lda-7" href="./jmlr-2012-Sign_Language_Recognition_using_Sub-Units.html">106 jmlr-2012-Sign Language Recognition using Sub-Units</a></p>
<p>8 0.25613463 <a title="63-lda-8" href="./jmlr-2012-Learning_Symbolic_Representations_of_Hybrid_Dynamical_Systems.html">57 jmlr-2012-Learning Symbolic Representations of Hybrid Dynamical Systems</a></p>
<p>9 0.25369599 <a title="63-lda-9" href="./jmlr-2012-Regularized_Bundle_Methods_for_Convex_and_Non-Convex_Risks.html">98 jmlr-2012-Regularized Bundle Methods for Convex and Non-Convex Risks</a></p>
<p>10 0.25022277 <a title="63-lda-10" href="./jmlr-2012-A_Unifying_Probabilistic_Perspective_for_Spectral_Dimensionality_Reduction%3A_Insights_and_New_Models.html">11 jmlr-2012-A Unifying Probabilistic Perspective for Spectral Dimensionality Reduction: Insights and New Models</a></p>
<p>11 0.24582741 <a title="63-lda-11" href="./jmlr-2012-A_Case_Study_on_Meta-Generalising%3A_A_Gaussian_Processes_Approach.html">1 jmlr-2012-A Case Study on Meta-Generalising: A Gaussian Processes Approach</a></p>
<p>12 0.24554493 <a title="63-lda-12" href="./jmlr-2012-Finding_Recurrent_Patterns_from_Continuous_Sign_Language_Sentences_for_Automated_Extraction_of_Signs.html">45 jmlr-2012-Finding Recurrent Patterns from Continuous Sign Language Sentences for Automated Extraction of Signs</a></p>
<p>13 0.24251983 <a title="63-lda-13" href="./jmlr-2012-Selective_Sampling_and_Active_Learning_from_Single_and_Multiple_Teachers.html">105 jmlr-2012-Selective Sampling and Active Learning from Single and Multiple Teachers</a></p>
<p>14 0.2401278 <a title="63-lda-14" href="./jmlr-2012-Robust_Kernel_Density_Estimation.html">100 jmlr-2012-Robust Kernel Density Estimation</a></p>
<p>15 0.23967457 <a title="63-lda-15" href="./jmlr-2012-An_Introduction_to_Artificial_Prediction_Markets_for_Classification.html">19 jmlr-2012-An Introduction to Artificial Prediction Markets for Classification</a></p>
<p>16 0.23174278 <a title="63-lda-16" href="./jmlr-2012-Variational_Multinomial_Logit_Gaussian_Process.html">118 jmlr-2012-Variational Multinomial Logit Gaussian Process</a></p>
<p>17 0.22939353 <a title="63-lda-17" href="./jmlr-2012-Local_and_Global_Scaling_Reduce_Hubs_in_Space.html">60 jmlr-2012-Local and Global Scaling Reduce Hubs in Space</a></p>
<p>18 0.21888706 <a title="63-lda-18" href="./jmlr-2012-Optimal_Distributed_Online_Prediction_Using_Mini-Batches.html">85 jmlr-2012-Optimal Distributed Online Prediction Using Mini-Batches</a></p>
<p>19 0.21759021 <a title="63-lda-19" href="./jmlr-2012-Non-Sparse_Multiple_Kernel_Fisher_Discriminant_Analysis.html">77 jmlr-2012-Non-Sparse Multiple Kernel Fisher Discriminant Analysis</a></p>
<p>20 0.21744579 <a title="63-lda-20" href="./jmlr-2012-Positive_Semidefinite_Metric_Learning_Using_Boosting-like_Algorithms.html">92 jmlr-2012-Positive Semidefinite Metric Learning Using Boosting-like Algorithms</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
