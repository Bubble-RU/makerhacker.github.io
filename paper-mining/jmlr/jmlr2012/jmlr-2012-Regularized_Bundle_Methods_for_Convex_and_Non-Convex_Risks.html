<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>98 jmlr-2012-Regularized Bundle Methods for Convex and Non-Convex Risks</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-98" href="#">jmlr2012-98</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>98 jmlr-2012-Regularized Bundle Methods for Convex and Non-Convex Risks</h1>
<br/><p>Source: <a title="jmlr-2012-98-pdf" href="http://jmlr.org/papers/volume13/do12a/do12a.pdf">pdf</a></p><p>Author: Trinh Minh Tri Do, Thierry Artières</p><p>Abstract: Machine learning is most often cast as an optimization problem. Ideally, one expects a convex objective function to rely on efﬁcient convex optimizers with nice guarantees such as no local optima. Yet, non-convexity is very frequent in practice and it may sometimes be inappropriate to look for convexity at any price. Alternatively one can decide not to limit a priori the modeling expressivity to models whose learning may be solved by convex optimization and rely on non-convex optimization algorithms. The main motivation of this work is to provide efﬁcient and scalable algorithms for non-convex optimization. We focus on regularized unconstrained optimization problems which cover a large number of modern machine learning problems such as logistic regression, conditional random ﬁelds, large margin estimation, etc. We propose a novel algorithm for minimizing a regularized objective that is able to handle convex and non-convex, smooth and non-smooth risks. The algorithm is based on the cutting plane technique and on the idea of exploiting the regularization term in the objective function. It may be thought as a limited memory extension of convex regularized bundle methods for dealing with convex and non convex risks. In case the risk is convex the algorithm is proved to converge to a stationary solution with accuracy ε with a rate O(1/λε) where λ is the regularization parameter of the objective function under the assumption of a Lipschitz empirical risk. In case the risk is not convex getting such a proof is more difﬁcult and requires a stronger and more disputable assumption. Yet we provide experimental results on artiﬁcial test problems, and on ﬁve standard and difﬁcult machine learning problems that are cast as convex and non-convex optimization problems that show how our algorithm compares well in practice with state of the art optimization algorithms. Keywords: optimization, non-convex, non-smooth, cutting plane, bundle method, regularized risk</p><p>Reference: <a title="jmlr-2012-98-reference" href="../jmlr2012_reference/jmlr-2012-Regularized_Bundle_Methods_for_Convex_and_Non-Convex_Risks_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wt', 0.488), ('nbm', 0.345), ('nrbmls', 0.327), ('cut', 0.277), ('nrbm', 0.246), ('bundl', 0.203), ('plan', 0.197), ('gapt', 0.175), ('gt', 0.166), ('bt', 0.164), ('lbfgs', 0.13), ('crbm', 0.122), ('underestim', 0.122), ('onvex', 0.114), ('ct', 0.105), ('cw', 0.103), ('rti', 0.103), ('undl', 0.103), ('jt', 0.095), ('sgd', 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="98-tfidf-1" href="./jmlr-2012-Regularized_Bundle_Methods_for_Convex_and_Non-Convex_Risks.html">98 jmlr-2012-Regularized Bundle Methods for Convex and Non-Convex Risks</a></p>
<p>Author: Trinh Minh Tri Do, Thierry Artières</p><p>Abstract: Machine learning is most often cast as an optimization problem. Ideally, one expects a convex objective function to rely on efﬁcient convex optimizers with nice guarantees such as no local optima. Yet, non-convexity is very frequent in practice and it may sometimes be inappropriate to look for convexity at any price. Alternatively one can decide not to limit a priori the modeling expressivity to models whose learning may be solved by convex optimization and rely on non-convex optimization algorithms. The main motivation of this work is to provide efﬁcient and scalable algorithms for non-convex optimization. We focus on regularized unconstrained optimization problems which cover a large number of modern machine learning problems such as logistic regression, conditional random ﬁelds, large margin estimation, etc. We propose a novel algorithm for minimizing a regularized objective that is able to handle convex and non-convex, smooth and non-smooth risks. The algorithm is based on the cutting plane technique and on the idea of exploiting the regularization term in the objective function. It may be thought as a limited memory extension of convex regularized bundle methods for dealing with convex and non convex risks. In case the risk is convex the algorithm is proved to converge to a stationary solution with accuracy ε with a rate O(1/λε) where λ is the regularization parameter of the objective function under the assumption of a Lipschitz empirical risk. In case the risk is not convex getting such a proof is more difﬁcult and requires a stronger and more disputable assumption. Yet we provide experimental results on artiﬁcial test problems, and on ﬁve standard and difﬁcult machine learning problems that are cast as convex and non-convex optimization problems that show how our algorithm compares well in practice with state of the art optimization algorithms. Keywords: optimization, non-convex, non-smooth, cutting plane, bundle method, regularized risk</p><p>2 0.16319285 <a title="98-tfidf-2" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>Author: Gary B. Huang, Andrew Kae, Carl Doersch, Erik Learned-Miller</p><p>Abstract: We consider a model for which it is important, early in processing, to estimate some variables with high precision, but perhaps at relatively low recall. If some variables can be identiﬁed with near certainty, they can be conditioned upon, allowing further inference to be done efﬁciently. Speciﬁcally, we consider optical character recognition (OCR) systems that can be bootstrapped by identifying a subset of correctly translated document words with very high precision. This “clean set” is subsequently used as document-speciﬁc training data. While OCR systems produce conﬁdence measures for the identity of each letter or word, thresholding these values still produces a signiﬁcant number of errors. We introduce a novel technique for identifying a set of correct words with very high precision. Rather than estimating posterior probabilities, we bound the probability that any given word is incorrect using an approximate worst case analysis. We give empirical results on a data set of difﬁcult historical newspaper scans, demonstrating that our method for identifying correct words makes only two errors in 56 documents. Using document-speciﬁc character models generated from this data, we are able to reduce the error over properly segmented characters by 34.1% from an initial OCR system’s translation.1 Keywords: optical character recognition, probability bounding, document-speciﬁc modeling, computer vision 1. This work is an expanded and revised version of Kae et al. (2010). Supported by NSF Grant IIS-0916555. c 2012 Gary B. Huang, Andrew Kae, Carl Doersch and Erik Learned-Miller. H UANG , K AE , D OERSCH AND L EARNED -M ILLER</p><p>3 0.1575938 <a title="98-tfidf-3" href="./jmlr-2012-Multi_Kernel_Learning_with_Online-Batch_Optimization.html">74 jmlr-2012-Multi Kernel Learning with Online-Batch Optimization</a></p>
<p>Author: Francesco Orabona, Luo Jie, Barbara Caputo</p><p>Abstract: In recent years there has been a lot of interest in designing principled classiﬁcation algorithms over multiple cues, based on the intuitive notion that using more features should lead to better performance. In the domain of kernel methods, a principled way to use multiple features is the Multi Kernel Learning (MKL) approach. Here we present a MKL optimization algorithm based on stochastic gradient descent that has a guaranteed convergence rate. We directly solve the MKL problem in the primal formulation. By having a p-norm formulation of MKL, we introduce a parameter that controls the level of sparsity of the solution, while leading to an easier optimization problem. We prove theoretically and experimentally that 1) our algorithm has a faster convergence rate as the number of kernels grows; 2) the training complexity is linear in the number of training examples; 3) very few iterations are sufﬁcient to reach good solutions. Experiments on standard benchmark databases support our claims. Keywords: multiple kernel learning, learning kernels, online optimization, stochastic subgradient descent, convergence bounds, large scale</p><p>4 0.15572189 <a title="98-tfidf-4" href="./jmlr-2012-Selective_Sampling_and_Active_Learning_from_Single_and_Multiple_Teachers.html">105 jmlr-2012-Selective Sampling and Active Learning from Single and Multiple Teachers</a></p>
<p>Author: Ofer Dekel, Claudio Gentile, Karthik Sridharan</p><p>Abstract: We present a new online learning algorithm in the selective sampling framework, where labels must be actively queried before they are revealed. We prove bounds on the regret of our algorithm and on the number of labels it queries when faced with an adaptive adversarial strategy of generating the instances. Our bounds both generalize and strictly improve over previous bounds in similar settings. Additionally, our selective sampling algorithm can be converted into an efﬁcient statistical active learning algorithm. We extend our algorithm and analysis to the multiple-teacher setting, where the algorithm can choose which subset of teachers to query for each label. Finally, we demonstrate the effectiveness of our techniques on a real-world Internet search problem. Keywords: online learning, regret, label-efﬁcient, crowdsourcing</p><p>5 0.15413234 <a title="98-tfidf-5" href="./jmlr-2012-Manifold_Identification_in_Dual_Averaging_for_Regularized_Stochastic_Online_Learning.html">64 jmlr-2012-Manifold Identification in Dual Averaging for Regularized Stochastic Online Learning</a></p>
<p>Author: Sangkyun Lee, Stephen J. Wright</p><p>Abstract: Iterative methods that calculate their steps from approximate subgradient directions have proved to be useful for stochastic learning problems over large and streaming data sets. When the objective consists of a loss function plus a nonsmooth regularization term, the solution often lies on a lowdimensional manifold of parameter space along which the regularizer is smooth. (When an ℓ1 regularizer is used to induce sparsity in the solution, for example, this manifold is deﬁned by the set of nonzero components of the parameter vector.) This paper shows that a regularized dual averaging algorithm can identify this manifold, with high probability, before reaching the solution. This observation motivates an algorithmic strategy in which, once an iterate is suspected of lying on an optimal or near-optimal manifold, we switch to a “local phase” that searches in this manifold, thus converging rapidly to a near-optimal point. Computational results are presented to verify the identiﬁcation property and to illustrate the effectiveness of this approach. Keywords: regularization, dual averaging, partly smooth manifold, manifold identiﬁcation</p><p>6 0.15318535 <a title="98-tfidf-6" href="./jmlr-2012-Regularization_Techniques_for_Learning_with_Matrices.html">97 jmlr-2012-Regularization Techniques for Learning with Matrices</a></p>
<p>7 0.13974018 <a title="98-tfidf-7" href="./jmlr-2012-Breaking_the_Curse_of_Kernelization%3A_Budgeted_Stochastic_Gradient_Descent_for_Large-Scale_SVM_Training.html">23 jmlr-2012-Breaking the Curse of Kernelization: Budgeted Stochastic Gradient Descent for Large-Scale SVM Training</a></p>
<p>8 0.11438588 <a title="98-tfidf-8" href="./jmlr-2012-A_Local_Spectral_Method_for_Graphs%3A_With_Applications_to_Improving_Graph_Partitions_and_Exploring_Data_Graphs_Locally.html">5 jmlr-2012-A Local Spectral Method for Graphs: With Applications to Improving Graph Partitions and Exploring Data Graphs Locally</a></p>
<p>9 0.08045011 <a title="98-tfidf-9" href="./jmlr-2012-Online_Submodular_Minimization.html">84 jmlr-2012-Online Submodular Minimization</a></p>
<p>10 0.064676762 <a title="98-tfidf-10" href="./jmlr-2012-Query_Strategies_for_Evading_Convex-Inducing_Classifiers.html">94 jmlr-2012-Query Strategies for Evading Convex-Inducing Classifiers</a></p>
<p>11 0.063068405 <a title="98-tfidf-11" href="./jmlr-2012-Online_Learning_in_the_Embedded_Manifold_of_Low-rank_Matrices.html">83 jmlr-2012-Online Learning in the Embedded Manifold of Low-rank Matrices</a></p>
<p>12 0.060472135 <a title="98-tfidf-12" href="./jmlr-2012-Confidence-Weighted_Linear_Classification_for_Text_Categorization.html">28 jmlr-2012-Confidence-Weighted Linear Classification for Text Categorization</a></p>
<p>13 0.050971109 <a title="98-tfidf-13" href="./jmlr-2012-Exploration_in_Relational_Domains_for_Model-based_Reinforcement_Learning.html">41 jmlr-2012-Exploration in Relational Domains for Model-based Reinforcement Learning</a></p>
<p>14 0.045367837 <a title="98-tfidf-14" href="./jmlr-2012-Linear_Fitted-Q_Iteration_with_Multiple_Reward_Functions.html">58 jmlr-2012-Linear Fitted-Q Iteration with Multiple Reward Functions</a></p>
<p>15 0.039943911 <a title="98-tfidf-15" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>16 0.038962401 <a title="98-tfidf-16" href="./jmlr-2012-Non-Sparse_Multiple_Kernel_Fisher_Discriminant_Analysis.html">77 jmlr-2012-Non-Sparse Multiple Kernel Fisher Discriminant Analysis</a></p>
<p>17 0.037047792 <a title="98-tfidf-17" href="./jmlr-2012-Noise-Contrastive_Estimation_of_Unnormalized_Statistical_Models%2C_with_Applications_to_Natural_Image_Statistics.html">76 jmlr-2012-Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics</a></p>
<p>18 0.033706866 <a title="98-tfidf-18" href="./jmlr-2012-Restricted_Strong_Convexity_and_Weighted_Matrix_Completion%3A_Optimal_Bounds_with_Noise.html">99 jmlr-2012-Restricted Strong Convexity and Weighted Matrix Completion: Optimal Bounds with Noise</a></p>
<p>19 0.033334542 <a title="98-tfidf-19" href="./jmlr-2012-Large-scale_Linear_Support_Vector_Regression.html">54 jmlr-2012-Large-scale Linear Support Vector Regression</a></p>
<p>20 0.031229358 <a title="98-tfidf-20" href="./jmlr-2012-On_Ranking_and_Generalization_Bounds.html">80 jmlr-2012-On Ranking and Generalization Bounds</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.199), (1, 0.263), (2, -0.063), (3, -0.055), (4, -0.04), (5, -0.045), (6, 0.299), (7, -0.11), (8, 0.094), (9, 0.23), (10, -0.079), (11, -0.146), (12, 0.281), (13, -0.028), (14, 0.239), (15, -0.112), (16, 0.076), (17, 0.071), (18, 0.031), (19, 0.054), (20, 0.003), (21, 0.085), (22, -0.023), (23, -0.062), (24, 0.115), (25, -0.095), (26, -0.053), (27, -0.067), (28, 0.012), (29, 0.085), (30, 0.022), (31, -0.082), (32, -0.016), (33, -0.005), (34, -0.007), (35, 0.001), (36, -0.126), (37, 0.03), (38, 0.01), (39, -0.008), (40, -0.033), (41, -0.003), (42, 0.016), (43, 0.065), (44, 0.053), (45, -0.007), (46, -0.063), (47, 0.033), (48, 0.039), (49, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95930326 <a title="98-lsi-1" href="./jmlr-2012-Regularized_Bundle_Methods_for_Convex_and_Non-Convex_Risks.html">98 jmlr-2012-Regularized Bundle Methods for Convex and Non-Convex Risks</a></p>
<p>Author: Trinh Minh Tri Do, Thierry Artières</p><p>Abstract: Machine learning is most often cast as an optimization problem. Ideally, one expects a convex objective function to rely on efﬁcient convex optimizers with nice guarantees such as no local optima. Yet, non-convexity is very frequent in practice and it may sometimes be inappropriate to look for convexity at any price. Alternatively one can decide not to limit a priori the modeling expressivity to models whose learning may be solved by convex optimization and rely on non-convex optimization algorithms. The main motivation of this work is to provide efﬁcient and scalable algorithms for non-convex optimization. We focus on regularized unconstrained optimization problems which cover a large number of modern machine learning problems such as logistic regression, conditional random ﬁelds, large margin estimation, etc. We propose a novel algorithm for minimizing a regularized objective that is able to handle convex and non-convex, smooth and non-smooth risks. The algorithm is based on the cutting plane technique and on the idea of exploiting the regularization term in the objective function. It may be thought as a limited memory extension of convex regularized bundle methods for dealing with convex and non convex risks. In case the risk is convex the algorithm is proved to converge to a stationary solution with accuracy ε with a rate O(1/λε) where λ is the regularization parameter of the objective function under the assumption of a Lipschitz empirical risk. In case the risk is not convex getting such a proof is more difﬁcult and requires a stronger and more disputable assumption. Yet we provide experimental results on artiﬁcial test problems, and on ﬁve standard and difﬁcult machine learning problems that are cast as convex and non-convex optimization problems that show how our algorithm compares well in practice with state of the art optimization algorithms. Keywords: optimization, non-convex, non-smooth, cutting plane, bundle method, regularized risk</p><p>2 0.64655584 <a title="98-lsi-2" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>Author: Gary B. Huang, Andrew Kae, Carl Doersch, Erik Learned-Miller</p><p>Abstract: We consider a model for which it is important, early in processing, to estimate some variables with high precision, but perhaps at relatively low recall. If some variables can be identiﬁed with near certainty, they can be conditioned upon, allowing further inference to be done efﬁciently. Speciﬁcally, we consider optical character recognition (OCR) systems that can be bootstrapped by identifying a subset of correctly translated document words with very high precision. This “clean set” is subsequently used as document-speciﬁc training data. While OCR systems produce conﬁdence measures for the identity of each letter or word, thresholding these values still produces a signiﬁcant number of errors. We introduce a novel technique for identifying a set of correct words with very high precision. Rather than estimating posterior probabilities, we bound the probability that any given word is incorrect using an approximate worst case analysis. We give empirical results on a data set of difﬁcult historical newspaper scans, demonstrating that our method for identifying correct words makes only two errors in 56 documents. Using document-speciﬁc character models generated from this data, we are able to reduce the error over properly segmented characters by 34.1% from an initial OCR system’s translation.1 Keywords: optical character recognition, probability bounding, document-speciﬁc modeling, computer vision 1. This work is an expanded and revised version of Kae et al. (2010). Supported by NSF Grant IIS-0916555. c 2012 Gary B. Huang, Andrew Kae, Carl Doersch and Erik Learned-Miller. H UANG , K AE , D OERSCH AND L EARNED -M ILLER</p><p>3 0.55904144 <a title="98-lsi-3" href="./jmlr-2012-Breaking_the_Curse_of_Kernelization%3A_Budgeted_Stochastic_Gradient_Descent_for_Large-Scale_SVM_Training.html">23 jmlr-2012-Breaking the Curse of Kernelization: Budgeted Stochastic Gradient Descent for Large-Scale SVM Training</a></p>
<p>Author: Zhuang Wang, Koby Crammer, Slobodan Vucetic</p><p>Abstract: Online algorithms that process one example at a time are advantageous when dealing with very large data or with data streams. Stochastic Gradient Descent (SGD) is such an algorithm and it is an attractive choice for online Support Vector Machine (SVM) training due to its simplicity and effectiveness. When equipped with kernel functions, similarly to other SVM learning algorithms, SGD is susceptible to the curse of kernelization that causes unbounded linear growth in model size and update time with data size. This may render SGD inapplicable to large data sets. We address this issue by presenting a class of Budgeted SGD (BSGD) algorithms for large-scale kernel SVM training which have constant space and constant time complexity per update. Speciﬁcally, BSGD keeps the number of support vectors bounded during training through several budget maintenance strategies. We treat the budget maintenance as a source of the gradient error, and show that the gap between the BSGD and the optimal SVM solutions depends on the model degradation due to budget maintenance. To minimize the gap, we study greedy budget maintenance methods based on removal, projection, and merging of support vectors. We propose budgeted versions of several popular online SVM algorithms that belong to the SGD family. We further derive BSGD algorithms for multi-class SVM training. Comprehensive empirical results show that BSGD achieves higher accuracy than the state-of-the-art budgeted online algorithms and comparable to non-budget algorithms, while achieving impressive computational efﬁciency both in time and space during training and prediction. Keywords: SVM, large-scale learning, online learning, stochastic gradient descent, kernel methods</p><p>4 0.55442995 <a title="98-lsi-4" href="./jmlr-2012-Manifold_Identification_in_Dual_Averaging_for_Regularized_Stochastic_Online_Learning.html">64 jmlr-2012-Manifold Identification in Dual Averaging for Regularized Stochastic Online Learning</a></p>
<p>Author: Sangkyun Lee, Stephen J. Wright</p><p>Abstract: Iterative methods that calculate their steps from approximate subgradient directions have proved to be useful for stochastic learning problems over large and streaming data sets. When the objective consists of a loss function plus a nonsmooth regularization term, the solution often lies on a lowdimensional manifold of parameter space along which the regularizer is smooth. (When an ℓ1 regularizer is used to induce sparsity in the solution, for example, this manifold is deﬁned by the set of nonzero components of the parameter vector.) This paper shows that a regularized dual averaging algorithm can identify this manifold, with high probability, before reaching the solution. This observation motivates an algorithmic strategy in which, once an iterate is suspected of lying on an optimal or near-optimal manifold, we switch to a “local phase” that searches in this manifold, thus converging rapidly to a near-optimal point. Computational results are presented to verify the identiﬁcation property and to illustrate the effectiveness of this approach. Keywords: regularization, dual averaging, partly smooth manifold, manifold identiﬁcation</p><p>5 0.43452525 <a title="98-lsi-5" href="./jmlr-2012-A_Local_Spectral_Method_for_Graphs%3A_With_Applications_to_Improving_Graph_Partitions_and_Exploring_Data_Graphs_Locally.html">5 jmlr-2012-A Local Spectral Method for Graphs: With Applications to Improving Graph Partitions and Exploring Data Graphs Locally</a></p>
<p>Author: Michael W. Mahoney, Lorenzo Orecchia, Nisheeth K. Vishnoi</p><p>Abstract: The second eigenvalue of the Laplacian matrix and its associated eigenvector are fundamental features of an undirected graph, and as such they have found widespread use in scientiﬁc computing, machine learning, and data analysis. In many applications, however, graphs that arise have several local regions of interest, and the second eigenvector will typically fail to provide information ﬁne-tuned to each local region. In this paper, we introduce a locally-biased analogue of the second eigenvector, and we demonstrate its usefulness at highlighting local properties of data graphs in a semi-supervised manner. To do so, we ﬁrst view the second eigenvector as the solution to a constrained optimization problem, and we incorporate the local information as an additional constraint; we then characterize the optimal solution to this new problem and show that it can be interpreted as a generalization of a Personalized PageRank vector; and ﬁnally, as a consequence, we show that the solution can be computed in nearly-linear time. In addition, we show that this locally-biased vector can be used to compute an approximation to the best partition near an input seed set in a manner analogous to the way in which the second eigenvector of the Laplacian can be used to obtain an approximation to the best partition in the entire input graph. Such a primitive is useful for identifying and reﬁning clusters locally, as it allows us to focus on a local region of interest in a semi-supervised manner. Finally, we provide a detailed empirical evaluation of our method by showing how it can applied to ﬁnding locally-biased sparse cuts around an input vertex seed set in social and information networks. Keywords: spectral graph partitioning, local spectral algorithms, Laplacian matrix, semi-supervised learning, personalized pagerank c 2012 Michael W. Mahoney and Lorenzo Orecchia and Nisheeth K. Vishnoi. M AHONEY, O RECCHIA , AND V ISHNOI</p><p>6 0.42459133 <a title="98-lsi-6" href="./jmlr-2012-Selective_Sampling_and_Active_Learning_from_Single_and_Multiple_Teachers.html">105 jmlr-2012-Selective Sampling and Active Learning from Single and Multiple Teachers</a></p>
<p>7 0.34047532 <a title="98-lsi-7" href="./jmlr-2012-Multi_Kernel_Learning_with_Online-Batch_Optimization.html">74 jmlr-2012-Multi Kernel Learning with Online-Batch Optimization</a></p>
<p>8 0.33013812 <a title="98-lsi-8" href="./jmlr-2012-Regularization_Techniques_for_Learning_with_Matrices.html">97 jmlr-2012-Regularization Techniques for Learning with Matrices</a></p>
<p>9 0.20620945 <a title="98-lsi-9" href="./jmlr-2012-Linear_Fitted-Q_Iteration_with_Multiple_Reward_Functions.html">58 jmlr-2012-Linear Fitted-Q Iteration with Multiple Reward Functions</a></p>
<p>10 0.19665556 <a title="98-lsi-10" href="./jmlr-2012-Query_Strategies_for_Evading_Convex-Inducing_Classifiers.html">94 jmlr-2012-Query Strategies for Evading Convex-Inducing Classifiers</a></p>
<p>11 0.18564507 <a title="98-lsi-11" href="./jmlr-2012-Exploration_in_Relational_Domains_for_Model-based_Reinforcement_Learning.html">41 jmlr-2012-Exploration in Relational Domains for Model-based Reinforcement Learning</a></p>
<p>12 0.17432752 <a title="98-lsi-12" href="./jmlr-2012-Large-scale_Linear_Support_Vector_Regression.html">54 jmlr-2012-Large-scale Linear Support Vector Regression</a></p>
<p>13 0.17117608 <a title="98-lsi-13" href="./jmlr-2012-Online_Learning_in_the_Embedded_Manifold_of_Low-rank_Matrices.html">83 jmlr-2012-Online Learning in the Embedded Manifold of Low-rank Matrices</a></p>
<p>14 0.1602594 <a title="98-lsi-14" href="./jmlr-2012-Confidence-Weighted_Linear_Classification_for_Text_Categorization.html">28 jmlr-2012-Confidence-Weighted Linear Classification for Text Categorization</a></p>
<p>15 0.15593418 <a title="98-lsi-15" href="./jmlr-2012-Structured_Sparsity_via_Alternating_Direction_Methods.html">112 jmlr-2012-Structured Sparsity via Alternating Direction Methods</a></p>
<p>16 0.15298733 <a title="98-lsi-16" href="./jmlr-2012-Analysis_of_a_Random_Forests_Model.html">20 jmlr-2012-Analysis of a Random Forests Model</a></p>
<p>17 0.15120828 <a title="98-lsi-17" href="./jmlr-2012-A_Primal-Dual_Convergence_Analysis_of_Boosting.html">8 jmlr-2012-A Primal-Dual Convergence Analysis of Boosting</a></p>
<p>18 0.13925004 <a title="98-lsi-18" href="./jmlr-2012-Optimal_Distributed_Online_Prediction_Using_Mini-Batches.html">85 jmlr-2012-Optimal Distributed Online Prediction Using Mini-Batches</a></p>
<p>19 0.13888817 <a title="98-lsi-19" href="./jmlr-2012-Learning_Algorithms_for_the_Classification_Restricted_Boltzmann_Machine.html">55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</a></p>
<p>20 0.13764492 <a title="98-lsi-20" href="./jmlr-2012-Pattern_for_Python.html">90 jmlr-2012-Pattern for Python</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(28, 0.014), (38, 0.013), (48, 0.692), (50, 0.023), (58, 0.012), (67, 0.045), (69, 0.012), (81, 0.014), (91, 0.01), (95, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99677604 <a title="98-lda-1" href="./jmlr-2012-PREA%3A_Personalized_Recommendation_Algorithms_Toolkit.html">88 jmlr-2012-PREA: Personalized Recommendation Algorithms Toolkit</a></p>
<p>Author: Joonseok Lee, Mingxuan Sun, Guy Lebanon</p><p>Abstract: Recommendation systems are important business applications with signiﬁcant economic impact. In recent years, a large number of algorithms have been proposed for recommendation systems. In this paper, we describe an open-source toolkit implementing many recommendation algorithms as well as popular evaluation metrics. In contrast to other packages, our toolkit implements recent state-of-the-art algorithms as well as most classic algorithms. Keywords: recommender systems, collaborative ﬁltering, evaluation metrics</p><p>same-paper 2 0.98905724 <a title="98-lda-2" href="./jmlr-2012-Regularized_Bundle_Methods_for_Convex_and_Non-Convex_Risks.html">98 jmlr-2012-Regularized Bundle Methods for Convex and Non-Convex Risks</a></p>
<p>Author: Trinh Minh Tri Do, Thierry Artières</p><p>Abstract: Machine learning is most often cast as an optimization problem. Ideally, one expects a convex objective function to rely on efﬁcient convex optimizers with nice guarantees such as no local optima. Yet, non-convexity is very frequent in practice and it may sometimes be inappropriate to look for convexity at any price. Alternatively one can decide not to limit a priori the modeling expressivity to models whose learning may be solved by convex optimization and rely on non-convex optimization algorithms. The main motivation of this work is to provide efﬁcient and scalable algorithms for non-convex optimization. We focus on regularized unconstrained optimization problems which cover a large number of modern machine learning problems such as logistic regression, conditional random ﬁelds, large margin estimation, etc. We propose a novel algorithm for minimizing a regularized objective that is able to handle convex and non-convex, smooth and non-smooth risks. The algorithm is based on the cutting plane technique and on the idea of exploiting the regularization term in the objective function. It may be thought as a limited memory extension of convex regularized bundle methods for dealing with convex and non convex risks. In case the risk is convex the algorithm is proved to converge to a stationary solution with accuracy ε with a rate O(1/λε) where λ is the regularization parameter of the objective function under the assumption of a Lipschitz empirical risk. In case the risk is not convex getting such a proof is more difﬁcult and requires a stronger and more disputable assumption. Yet we provide experimental results on artiﬁcial test problems, and on ﬁve standard and difﬁcult machine learning problems that are cast as convex and non-convex optimization problems that show how our algorithm compares well in practice with state of the art optimization algorithms. Keywords: optimization, non-convex, non-smooth, cutting plane, bundle method, regularized risk</p><p>3 0.98875356 <a title="98-lda-3" href="./jmlr-2012-Conditional_Likelihood_Maximisation%3A_A_Unifying_Framework_for_Information_Theoretic_Feature_Selection.html">27 jmlr-2012-Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></p>
<p>Author: Gavin Brown, Adam Pocock, Ming-Jie Zhao, Mikel Luján</p><p>Abstract: We present a unifying framework for information theoretic feature selection, bringing almost two decades of research on heuristic ﬁlter criteria under a single theoretical interpretation. This is in response to the question: “what are the implicit statistical assumptions of feature selection criteria based on mutual information?”. To answer this, we adopt a different strategy than is usual in the feature selection literature—instead of trying to deﬁne a criterion, we derive one, directly from a clearly speciﬁed objective function: the conditional likelihood of the training labels. While many hand-designed heuristic criteria try to optimize a deﬁnition of feature ‘relevancy’ and ‘redundancy’, our approach leads to a probabilistic framework which naturally incorporates these concepts. As a result we can unify the numerous criteria published over the last two decades, and show them to be low-order approximations to the exact (but intractable) optimisation problem. The primary contribution is to show that common heuristics for information based feature selection (including Markov Blanket algorithms as a special case) are approximate iterative maximisers of the conditional likelihood. A large empirical study provides strong evidence to favour certain classes of criteria, in particular those that balance the relative size of the relevancy/redundancy terms. Overall we conclude that the JMI criterion (Yang and Moody, 1999; Meyer et al., 2008) provides the best tradeoff in terms of accuracy, stability, and ﬂexibility with small data samples. Keywords: feature selection, mutual information, conditional likelihood</p><p>4 0.97694296 <a title="98-lda-4" href="./jmlr-2012-Confidence-Weighted_Linear_Classification_for_Text_Categorization.html">28 jmlr-2012-Confidence-Weighted Linear Classification for Text Categorization</a></p>
<p>Author: Koby Crammer, Mark Dredze, Fernando Pereira</p><p>Abstract: Conﬁdence-weighted online learning is a generalization of margin-based learning of linear classiﬁers in which the margin constraint is replaced by a probabilistic constraint based on a distribution over classiﬁer weights that is updated online as examples are observed. The distribution captures a notion of conﬁdence on classiﬁer weights, and in some cases it can also be interpreted as replacing a single learning rate by adaptive per-weight rates. Conﬁdence-weighted learning was motivated by the statistical properties of natural-language classiﬁcation tasks, where most of the informative features are relatively rare. We investigate several versions of conﬁdence-weighted learning that use a Gaussian distribution over weight vectors, updated at each observed example to achieve high probability of correct classiﬁcation for the example. Empirical evaluation on a range of textcategorization tasks show that our algorithms improve over other state-of-the-art online and batch methods, learn faster in the online setting, and lead to better classiﬁer combination for a type of distributed training commonly used in cloud computing. Keywords: online learning, conﬁdence prediction, text categorization</p><p>5 0.96852452 <a title="98-lda-5" href="./jmlr-2012-Positive_Semidefinite_Metric_Learning_Using_Boosting-like_Algorithms.html">92 jmlr-2012-Positive Semidefinite Metric Learning Using Boosting-like Algorithms</a></p>
<p>Author: Chunhua Shen, Junae Kim, Lei Wang, Anton van den Hengel</p><p>Abstract: The success of many machine learning and pattern recognition methods relies heavily upon the identiﬁcation of an appropriate distance metric on the input data. It is often beneﬁcial to learn such a metric from the input training data, instead of using a default one such as the Euclidean distance. In this work, we propose a boosting-based technique, termed B OOST M ETRIC, for learning a quadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance metric requires enforcing the constraint that the matrix parameter to the metric remains positive semideﬁnite. Semideﬁnite programming is often used to enforce this constraint, but does not scale well and is not easy to implement. B OOST M ETRIC is instead based on the observation that any positive semideﬁnite matrix can be decomposed into a linear combination of trace-one rank-one matrices. B OOST M ETRIC thus uses rank-one positive semideﬁnite matrices as weak learners within an efﬁcient and scalable boosting-based learning process. The resulting methods are easy to implement, efﬁcient, and can accommodate various types of constraints. We extend traditional boosting algorithms in that its weak learner is a positive semideﬁnite matrix with trace and rank being one rather than a classiﬁer or regressor. Experiments on various data sets demonstrate that the proposed algorithms compare favorably to those state-of-the-art methods in terms of classiﬁcation accuracy and running time. Keywords: Mahalanobis distance, semideﬁnite programming, column generation, boosting, Lagrange duality, large margin nearest neighbor</p><p>6 0.9084115 <a title="98-lda-6" href="./jmlr-2012-Learning_Algorithms_for_the_Classification_Restricted_Boltzmann_Machine.html">55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</a></p>
<p>7 0.90164083 <a title="98-lda-7" href="./jmlr-2012-Multi_Kernel_Learning_with_Online-Batch_Optimization.html">74 jmlr-2012-Multi Kernel Learning with Online-Batch Optimization</a></p>
<p>8 0.89801842 <a title="98-lda-8" href="./jmlr-2012-Large-scale_Linear_Support_Vector_Regression.html">54 jmlr-2012-Large-scale Linear Support Vector Regression</a></p>
<p>9 0.89560294 <a title="98-lda-9" href="./jmlr-2012-Metric_and_Kernel_Learning_Using_a_Linear_Transformation.html">66 jmlr-2012-Metric and Kernel Learning Using a Linear Transformation</a></p>
<p>10 0.89418352 <a title="98-lda-10" href="./jmlr-2012-Local_and_Global_Scaling_Reduce_Hubs_in_Space.html">60 jmlr-2012-Local and Global Scaling Reduce Hubs in Space</a></p>
<p>11 0.893448 <a title="98-lda-11" href="./jmlr-2012-Feature_Selection_via_Dependence_Maximization.html">44 jmlr-2012-Feature Selection via Dependence Maximization</a></p>
<p>12 0.88926226 <a title="98-lda-12" href="./jmlr-2012-An_Introduction_to_Artificial_Prediction_Markets_for_Classification.html">19 jmlr-2012-An Introduction to Artificial Prediction Markets for Classification</a></p>
<p>13 0.88076329 <a title="98-lda-13" href="./jmlr-2012-Multi-Target_Regression_with_Rule_Ensembles.html">72 jmlr-2012-Multi-Target Regression with Rule Ensembles</a></p>
<p>14 0.88052332 <a title="98-lda-14" href="./jmlr-2012-An_Improved_GLMNET_for_L1-regularized_Logistic_Regression.html">18 jmlr-2012-An Improved GLMNET for L1-regularized Logistic Regression</a></p>
<p>15 0.87965 <a title="98-lda-15" href="./jmlr-2012-MULTIBOOST%3A_A_Multi-purpose_Boosting_Package.html">62 jmlr-2012-MULTIBOOST: A Multi-purpose Boosting Package</a></p>
<p>16 0.87883723 <a title="98-lda-16" href="./jmlr-2012-Iterative_Reweighted_Algorithms_for_Matrix_Rank_Minimization.html">52 jmlr-2012-Iterative Reweighted Algorithms for Matrix Rank Minimization</a></p>
<p>17 0.87576884 <a title="98-lda-17" href="./jmlr-2012-Entropy_Search_for_Information-Efficient_Global_Optimization.html">38 jmlr-2012-Entropy Search for Information-Efficient Global Optimization</a></p>
<p>18 0.87020254 <a title="98-lda-18" href="./jmlr-2012-A_Multi-Stage_Framework_for_Dantzig_Selector_and_LASSO.html">7 jmlr-2012-A Multi-Stage Framework for Dantzig Selector and LASSO</a></p>
<p>19 0.86434418 <a title="98-lda-19" href="./jmlr-2012-Bounding_the_Probability_of_Error_for_High_Precision_Optical_Character_Recognition.html">22 jmlr-2012-Bounding the Probability of Error for High Precision Optical Character Recognition</a></p>
<p>20 0.86243266 <a title="98-lda-20" href="./jmlr-2012-Structured_Sparsity_via_Alternating_Direction_Methods.html">112 jmlr-2012-Structured Sparsity via Alternating Direction Methods</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
