<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>29 jmlr-2010-Covariance in Unsupervised Learning of Probabilistic Grammars</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-29" href="#">jmlr2010-29</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>29 jmlr-2010-Covariance in Unsupervised Learning of Probabilistic Grammars</h1>
<br/><p>Source: <a title="jmlr-2010-29-pdf" href="http://jmlr.org/papers/volume11/cohen10a/cohen10a.pdf">pdf</a></p><p>Author: Shay B. Cohen, Noah A. Smith</p><p>Abstract: Probabilistic grammars offer great ﬂexibility in modeling discrete sequential data like natural language text. Their symbolic component is amenable to inspection by humans, while their probabilistic component helps resolve ambiguity. They also permit the use of well-understood, generalpurpose learning algorithms. There has been an increased interest in using probabilistic grammars in the Bayesian setting. To date, most of the literature has focused on using a Dirichlet prior. The Dirichlet prior has several limitations, including that it cannot directly model covariance between the probabilistic grammar’s parameters. Yet, various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties. In this paper, we suggest an alternative to the Dirichlet prior, a family of logistic normal distributions. We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction, demonstrating performance improvements with our priors on a set of six treebanks in different natural languages. Our covariance framework permits soft parameter tying within grammars and across grammars for text in different languages, and we show empirical gains in a novel learning setting using bilingual, non-parallel data. Keywords: dependency grammar induction, variational inference, logistic normal distribution, Bayesian inference</p><p>Reference: <a title="jmlr-2010-29-reference" href="../jmlr2010_reference/jmlr-2010-Covariance_in_Unsupervised_Learning_of_Probabilistic_Grammars_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gramm', 0.726), ('qm', 0.201), ('multinom', 0.175), ('ym', 0.168), ('nk', 0.14), ('langu', 0.127), ('sent', 0.114), ('decod', 0.111), ('dmv', 0.108), ('mith', 0.108), ('nsuperv', 0.108), ('dirichlet', 0.103), ('tag', 0.103), ('ramm', 0.097), ('mbr', 0.097), ('sln', 0.095), ('treebank', 0.094), ('turk', 0.091), ('viterb', 0.086), ('portugues', 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="29-tfidf-1" href="./jmlr-2010-Covariance_in_Unsupervised_Learning_of_Probabilistic_Grammars.html">29 jmlr-2010-Covariance in Unsupervised Learning of Probabilistic Grammars</a></p>
<p>2 0.45953181 <a title="29-tfidf-2" href="./jmlr-2010-Inducing_Tree-Substitution_Grammars.html">53 jmlr-2010-Inducing Tree-Substitution Grammars</a></p>
<p>3 0.2820487 <a title="29-tfidf-3" href="./jmlr-2010-Using_Contextual_Representations_to_Efficiently_Learn_Context-Free_Languages.html">115 jmlr-2010-Using Contextual Representations to Efficiently Learn Context-Free Languages</a></p>
<p>4 0.21384066 <a title="29-tfidf-4" href="./jmlr-2010-Posterior_Regularization_for_Structured_Latent_Variable_Models.html">91 jmlr-2010-Posterior Regularization for Structured Latent Variable Models</a></p>
<p>5 0.20978616 <a title="29-tfidf-5" href="./jmlr-2010-Incremental_Sigmoid_Belief_Networks_for_Grammar_Learning.html">52 jmlr-2010-Incremental Sigmoid Belief Networks for Grammar Learning</a></p>
<p>6 0.14462037 <a title="29-tfidf-6" href="./jmlr-2010-Approximate_Tree_Kernels.html">15 jmlr-2010-Approximate Tree Kernels</a></p>
<p>7 0.10021709 <a title="29-tfidf-7" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>8 0.070297368 <a title="29-tfidf-8" href="./jmlr-2010-Rademacher_Complexities_and_Bounding_the_Excess_Risk_in_Active_Learning.html">95 jmlr-2010-Rademacher Complexities and Bounding the Excess Risk in Active Learning</a></p>
<p>9 0.054276325 <a title="29-tfidf-9" href="./jmlr-2010-Training_and_Testing_Low-degree_Polynomial_Data_Mappings_via_Linear_SVM.html">112 jmlr-2010-Training and Testing Low-degree Polynomial Data Mappings via Linear SVM</a></p>
<p>10 0.053783659 <a title="29-tfidf-10" href="./jmlr-2010-Unsupervised_Supervised_Learning_I%3A_Estimating_Classification_and_Regression_Errors_without_Labels.html">114 jmlr-2010-Unsupervised Supervised Learning I: Estimating Classification and Regression Errors without Labels</a></p>
<p>11 0.052051876 <a title="29-tfidf-11" href="./jmlr-2010-Why_Does_Unsupervised_Pre-training_Help_Deep_Learning%3F.html">117 jmlr-2010-Why Does Unsupervised Pre-training Help Deep Learning?</a></p>
<p>12 0.048836455 <a title="29-tfidf-12" href="./jmlr-2010-Learning_From_Crowds.html">61 jmlr-2010-Learning From Crowds</a></p>
<p>13 0.04258775 <a title="29-tfidf-13" href="./jmlr-2010-Approximate_Riemannian_Conjugate_Gradient_Learning_for_Fixed-Form_Variational_Bayes.html">14 jmlr-2010-Approximate Riemannian Conjugate Gradient Learning for Fixed-Form Variational Bayes</a></p>
<p>14 0.042245042 <a title="29-tfidf-14" href="./jmlr-2010-Learning_Non-Stationary_Dynamic_Bayesian_Networks.html">64 jmlr-2010-Learning Non-Stationary Dynamic Bayesian Networks</a></p>
<p>15 0.039361328 <a title="29-tfidf-15" href="./jmlr-2010-Error-Correcting_Output_Codes_Library.html">35 jmlr-2010-Error-Correcting Output Codes Library</a></p>
<p>16 0.038499855 <a title="29-tfidf-16" href="./jmlr-2010-Hubs_in_Space%3A_Popular_Nearest_Neighbors_in_High-Dimensional_Data.html">49 jmlr-2010-Hubs in Space: Popular Nearest Neighbors in High-Dimensional Data</a></p>
<p>17 0.036729094 <a title="29-tfidf-17" href="./jmlr-2010-Model_Selection%3A_Beyond_the_Bayesian_Frequentist_Divide.html">78 jmlr-2010-Model Selection: Beyond the Bayesian Frequentist Divide</a></p>
<p>18 0.035286553 <a title="29-tfidf-18" href="./jmlr-2010-Classification_with_Incomplete_Data_Using_Dirichlet_Process_Priors.html">23 jmlr-2010-Classification with Incomplete Data Using Dirichlet Process Priors</a></p>
<p>19 0.034114856 <a title="29-tfidf-19" href="./jmlr-2010-PAC-Bayesian_Analysis_of_Co-clustering_and_Beyond.html">89 jmlr-2010-PAC-Bayesian Analysis of Co-clustering and Beyond</a></p>
<p>20 0.034088966 <a title="29-tfidf-20" href="./jmlr-2010-High_Dimensional_Inverse_Covariance_Matrix_Estimation_via_Linear_Programming.html">46 jmlr-2010-High Dimensional Inverse Covariance Matrix Estimation via Linear Programming</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.239), (1, -0.499), (2, -0.355), (3, -0.06), (4, -0.175), (5, -0.273), (6, 0.073), (7, -0.047), (8, -0.039), (9, -0.059), (10, -0.023), (11, 0.03), (12, -0.118), (13, -0.084), (14, 0.088), (15, 0.024), (16, 0.044), (17, -0.035), (18, -0.005), (19, 0.064), (20, -0.059), (21, 0.084), (22, 0.055), (23, -0.023), (24, 0.037), (25, 0.035), (26, 0.048), (27, -0.009), (28, 0.062), (29, -0.012), (30, -0.019), (31, -0.028), (32, 0.001), (33, 0.0), (34, 0.017), (35, -0.014), (36, 0.0), (37, -0.013), (38, 0.03), (39, 0.058), (40, -0.032), (41, 0.026), (42, 0.041), (43, 0.038), (44, 0.035), (45, -0.006), (46, -0.032), (47, 0.023), (48, 0.01), (49, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93196785 <a title="29-lsi-1" href="./jmlr-2010-Covariance_in_Unsupervised_Learning_of_Probabilistic_Grammars.html">29 jmlr-2010-Covariance in Unsupervised Learning of Probabilistic Grammars</a></p>
<p>2 0.88421696 <a title="29-lsi-2" href="./jmlr-2010-Inducing_Tree-Substitution_Grammars.html">53 jmlr-2010-Inducing Tree-Substitution Grammars</a></p>
<p>3 0.79603177 <a title="29-lsi-3" href="./jmlr-2010-Using_Contextual_Representations_to_Efficiently_Learn_Context-Free_Languages.html">115 jmlr-2010-Using Contextual Representations to Efficiently Learn Context-Free Languages</a></p>
<p>4 0.55911666 <a title="29-lsi-4" href="./jmlr-2010-Incremental_Sigmoid_Belief_Networks_for_Grammar_Learning.html">52 jmlr-2010-Incremental Sigmoid Belief Networks for Grammar Learning</a></p>
<p>5 0.44153982 <a title="29-lsi-5" href="./jmlr-2010-Posterior_Regularization_for_Structured_Latent_Variable_Models.html">91 jmlr-2010-Posterior Regularization for Structured Latent Variable Models</a></p>
<p>6 0.3021608 <a title="29-lsi-6" href="./jmlr-2010-Approximate_Tree_Kernels.html">15 jmlr-2010-Approximate Tree Kernels</a></p>
<p>7 0.22492689 <a title="29-lsi-7" href="./jmlr-2010-Approximate_Riemannian_Conjugate_Gradient_Learning_for_Fixed-Form_Variational_Bayes.html">14 jmlr-2010-Approximate Riemannian Conjugate Gradient Learning for Fixed-Form Variational Bayes</a></p>
<p>8 0.19391589 <a title="29-lsi-8" href="./jmlr-2010-Rademacher_Complexities_and_Bounding_the_Excess_Risk_in_Active_Learning.html">95 jmlr-2010-Rademacher Complexities and Bounding the Excess Risk in Active Learning</a></p>
<p>9 0.18859696 <a title="29-lsi-9" href="./jmlr-2010-Stochastic_Composite_Likelihood.html">109 jmlr-2010-Stochastic Composite Likelihood</a></p>
<p>10 0.18564387 <a title="29-lsi-10" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>11 0.16059333 <a title="29-lsi-11" href="./jmlr-2010-Expectation_Truncation_and_the_Benefits_of_Preselection_In_Training_Generative_Models.html">38 jmlr-2010-Expectation Truncation and the Benefits of Preselection In Training Generative Models</a></p>
<p>12 0.15999806 <a title="29-lsi-12" href="./jmlr-2010-Hubs_in_Space%3A_Popular_Nearest_Neighbors_in_High-Dimensional_Data.html">49 jmlr-2010-Hubs in Space: Popular Nearest Neighbors in High-Dimensional Data</a></p>
<p>13 0.14723966 <a title="29-lsi-13" href="./jmlr-2010-Mean_Field_Variational_Approximation_for_Continuous-Time_Bayesian_Networks.html">75 jmlr-2010-Mean Field Variational Approximation for Continuous-Time Bayesian Networks</a></p>
<p>14 0.1460842 <a title="29-lsi-14" href="./jmlr-2010-Error-Correcting_Output_Codes_Library.html">35 jmlr-2010-Error-Correcting Output Codes Library</a></p>
<p>15 0.14543152 <a title="29-lsi-15" href="./jmlr-2010-Model_Selection%3A_Beyond_the_Bayesian_Frequentist_Divide.html">78 jmlr-2010-Model Selection: Beyond the Bayesian Frequentist Divide</a></p>
<p>16 0.14426333 <a title="29-lsi-16" href="./jmlr-2010-Learning_From_Crowds.html">61 jmlr-2010-Learning From Crowds</a></p>
<p>17 0.14292029 <a title="29-lsi-17" href="./jmlr-2010-Learning_Non-Stationary_Dynamic_Bayesian_Networks.html">64 jmlr-2010-Learning Non-Stationary Dynamic Bayesian Networks</a></p>
<p>18 0.14239424 <a title="29-lsi-18" href="./jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">97 jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>19 0.14017653 <a title="29-lsi-19" href="./jmlr-2010-Why_Does_Unsupervised_Pre-training_Help_Deep_Learning%3F.html">117 jmlr-2010-Why Does Unsupervised Pre-training Help Deep Learning?</a></p>
<p>20 0.12990095 <a title="29-lsi-20" href="./jmlr-2010-Learning_Instance-Specific_Predictive_Models.html">63 jmlr-2010-Learning Instance-Specific Predictive Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.126), (13, 0.053), (22, 0.015), (28, 0.022), (33, 0.379), (57, 0.015), (62, 0.012), (65, 0.061), (67, 0.018), (68, 0.011), (71, 0.169)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.67473567 <a title="29-lda-1" href="./jmlr-2010-Covariance_in_Unsupervised_Learning_of_Probabilistic_Grammars.html">29 jmlr-2010-Covariance in Unsupervised Learning of Probabilistic Grammars</a></p>
<p>2 0.50694358 <a title="29-lda-2" href="./jmlr-2010-Approximate_Inference_on_Planar_Graphs_using_Loop_Calculus_and_Belief_Propagation.html">13 jmlr-2010-Approximate Inference on Planar Graphs using Loop Calculus and Belief Propagation</a></p>
<p>3 0.50385207 <a title="29-lda-3" href="./jmlr-2010-Posterior_Regularization_for_Structured_Latent_Variable_Models.html">91 jmlr-2010-Posterior Regularization for Structured Latent Variable Models</a></p>
<p>4 0.49736702 <a title="29-lda-4" href="./jmlr-2010-On_Spectral_Learning.html">84 jmlr-2010-On Spectral Learning</a></p>
<p>5 0.49245775 <a title="29-lda-5" href="./jmlr-2010-Hilbert_Space_Embeddings_and_Metrics_on_Probability_Measures.html">47 jmlr-2010-Hilbert Space Embeddings and Metrics on Probability Measures</a></p>
<p>6 0.49009538 <a title="29-lda-6" href="./jmlr-2010-On_Finding_Predictors_for_Arbitrary_Families_of_Processes.html">81 jmlr-2010-On Finding Predictors for Arbitrary Families of Processes</a></p>
<p>7 0.48842037 <a title="29-lda-7" href="./jmlr-2010-On_Learning_with_Integral_Operators.html">82 jmlr-2010-On Learning with Integral Operators</a></p>
<p>8 0.47951993 <a title="29-lda-8" href="./jmlr-2010-Learning_Translation_Invariant_Kernels_for_Classification.html">65 jmlr-2010-Learning Translation Invariant Kernels for Classification</a></p>
<p>9 0.47854012 <a title="29-lda-9" href="./jmlr-2010-Lp-Nested_Symmetric_Distributions.html">69 jmlr-2010-Lp-Nested Symmetric Distributions</a></p>
<p>10 0.47660473 <a title="29-lda-10" href="./jmlr-2010-Inducing_Tree-Substitution_Grammars.html">53 jmlr-2010-Inducing Tree-Substitution Grammars</a></p>
<p>11 0.4656893 <a title="29-lda-11" href="./jmlr-2010-Learnability%2C_Stability_and_Uniform_Convergence.html">60 jmlr-2010-Learnability, Stability and Uniform Convergence</a></p>
<p>12 0.4605791 <a title="29-lda-12" href="./jmlr-2010-Linear_Algorithms_for_Online_Multitask_Classification.html">66 jmlr-2010-Linear Algorithms for Online Multitask Classification</a></p>
<p>13 0.45768231 <a title="29-lda-13" href="./jmlr-2010-Using_Contextual_Representations_to_Efficiently_Learn_Context-Free_Languages.html">115 jmlr-2010-Using Contextual Representations to Efficiently Learn Context-Free Languages</a></p>
<p>14 0.45680994 <a title="29-lda-14" href="./jmlr-2010-Graph_Kernels.html">44 jmlr-2010-Graph Kernels</a></p>
<p>15 0.45599511 <a title="29-lda-15" href="./jmlr-2010-Approximate_Tree_Kernels.html">15 jmlr-2010-Approximate Tree Kernels</a></p>
<p>16 0.45389664 <a title="29-lda-16" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>17 0.45328194 <a title="29-lda-17" href="./jmlr-2010-Spectral_Regularization_Algorithms_for_Learning_Large_Incomplete_Matrices.html">105 jmlr-2010-Spectral Regularization Algorithms for Learning Large Incomplete Matrices</a></p>
<p>18 0.45327955 <a title="29-lda-18" href="./jmlr-2010-On_the_Foundations_of_Noise-free_Selective_Classification.html">85 jmlr-2010-On the Foundations of Noise-free Selective Classification</a></p>
<p>19 0.45194149 <a title="29-lda-19" href="./jmlr-2010-PAC-Bayesian_Analysis_of_Co-clustering_and_Beyond.html">89 jmlr-2010-PAC-Bayesian Analysis of Co-clustering and Beyond</a></p>
<p>20 0.4517912 <a title="29-lda-20" href="./jmlr-2010-Chromatic_PAC-Bayes_Bounds_for_Non-IID_Data%3A_Applications_to_Ranking_and_Stationary_%CE%B2-Mixing_Processes.html">20 jmlr-2010-Chromatic PAC-Bayes Bounds for Non-IID Data: Applications to Ranking and Stationary β-Mixing Processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
