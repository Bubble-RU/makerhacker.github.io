<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>90 jmlr-2010-Permutation Tests for Studying Classifier Performance</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-90" href="#">jmlr2010-90</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>90 jmlr-2010-Permutation Tests for Studying Classifier Performance</h1>
<br/><p>Source: <a title="jmlr-2010-90-pdf" href="http://jmlr.org/papers/volume11/ojala10a/ojala10a.pdf">pdf</a></p><p>Author: Markus Ojala, Gemma C. Garriga</p><p>Abstract: We explore the framework of permutation-based p-values for assessing the performance of classiﬁers. In this paper we study two simple permutation tests. The ﬁrst test assess whether the classiﬁer has found a real class structure in the data; the corresponding null distribution is estimated by permuting the labels in the data. This test has been used extensively in classiﬁcation problems in computational biology. The second test studies whether the classiﬁer is exploiting the dependency between the features in classiﬁcation; the corresponding null distribution is estimated by permuting the features within classes, inspired by restricted randomization techniques traditionally used in statistics. This new test can serve to identify descriptive features which can be valuable information in improving the classiﬁer performance. We study the properties of these tests and present an extensive empirical evaluation on real and synthetic data. Our analysis shows that studying the classiﬁer performance via permutation tests is effective. In particular, the restricted permutation test clearly reveals whether the classiﬁer exploits the interdependency between the features in the data. Keywords: classiﬁcation, labeled data, permutation tests, restricted randomization, signiﬁcance testing</p><p>Reference: <a title="jmlr-2010-90-reference" href="../jmlr2010_reference/jmlr-2010-Permutation_Tests_for_Studying_Classifier_Performance_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nul', 0.316), ('permut', 0.31), ('arrig', 0.239), ('jal', 0.239), ('tudy', 0.239), ('test', 0.186), ('ermut', 0.184), ('hypothes', 0.18), ('nonsign', 0.159), ('erform', 0.158), ('golland', 0.136), ('std', 0.12), ('nomin', 0.119), ('correl', 0.118), ('naiv', 0.114), ('pow', 0.111), ('reject', 0.109), ('lass', 0.1), ('frank', 0.099), ('feat', 0.097)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="90-tfidf-1" href="./jmlr-2010-Permutation_Tests_for_Studying_Classifier_Performance.html">90 jmlr-2010-Permutation Tests for Studying Classifier Performance</a></p>
<p>Author: Markus Ojala, Gemma C. Garriga</p><p>Abstract: We explore the framework of permutation-based p-values for assessing the performance of classiﬁers. In this paper we study two simple permutation tests. The ﬁrst test assess whether the classiﬁer has found a real class structure in the data; the corresponding null distribution is estimated by permuting the labels in the data. This test has been used extensively in classiﬁcation problems in computational biology. The second test studies whether the classiﬁer is exploiting the dependency between the features in classiﬁcation; the corresponding null distribution is estimated by permuting the features within classes, inspired by restricted randomization techniques traditionally used in statistics. This new test can serve to identify descriptive features which can be valuable information in improving the classiﬁer performance. We study the properties of these tests and present an extensive empirical evaluation on real and synthetic data. Our analysis shows that studying the classiﬁer performance via permutation tests is effective. In particular, the restricted permutation test clearly reveals whether the classiﬁer exploits the interdependency between the features in the data. Keywords: classiﬁcation, labeled data, permutation tests, restricted randomization, signiﬁcance testing</p><p>2 0.10538056 <a title="90-tfidf-2" href="./jmlr-2010-Semi-Supervised_Novelty_Detection.html">102 jmlr-2010-Semi-Supervised Novelty Detection</a></p>
<p>Author: Gilles Blanchard, Gyemin Lee, Clayton Scott</p><p>Abstract: A common setting for novelty detection assumes that labeled examples from the nominal class are available, but that labeled examples of novelties are unavailable. The standard (inductive) approach is to declare novelties where the nominal density is low, which reduces the problem to density level set estimation. In this paper, we consider the setting where an unlabeled and possibly contaminated sample is also available at learning time. We argue that novelty detection in this semi-supervised setting is naturally solved by a general reduction to a binary classiﬁcation problem. In particular, a detector with a desired false positive rate can be achieved through a reduction to Neyman-Pearson classiﬁcation. Unlike the inductive approach, semi-supervised novelty detection (SSND) yields detectors that are optimal (e.g., statistically consistent) regardless of the distribution on novelties. Therefore, in novelty detection, unlabeled data have a substantial impact on the theoretical properties of the decision rule. We validate the practical utility of SSND with an extensive experimental study. We also show that SSND provides distribution-free, learning-theoretic solutions to two well known problems in hypothesis testing. First, our results provide a general solution to the general two-sample problem, that is, the problem of determining whether two random samples arise from the same distribution. Second, a specialization of SSND coincides with the standard p-value approach to multiple testing under the so-called random effects model. Unlike standard rejection regions based on thresholded p-values, the general SSND framework allows for adaptation to arbitrary alternative distributions in multiple dimensions. Keywords: semi-supervised learning, novelty detection, Neyman-Pearson classiﬁcation, learning reduction, two-sample problem, multiple testing</p><p>3 0.096293233 <a title="90-tfidf-3" href="./jmlr-2010-An_Efficient_Explanation_of_Individual_Classifications_using_Game_Theory.html">9 jmlr-2010-An Efficient Explanation of Individual Classifications using Game Theory</a></p>
<p>Author: Erik Ĺ trumbelj, Igor Kononenko</p><p>Abstract: We present a general method for explaining individual predictions of classiﬁcation models. The method is based on fundamental concepts from coalitional game theory and predictions are explained with contributions of individual feature values. We overcome the method’s initial exponential time complexity with a sampling-based approximation. In the experimental part of the paper we use the developed method on models generated by several well-known machine learning algorithms on both synthetic and real-world data sets. The results demonstrate that the method is efﬁcient and that the explanations are intuitive and useful. Keywords: data postprocessing, classiﬁcation, explanation, visualization</p><p>4 0.090830825 <a title="90-tfidf-4" href="./jmlr-2010-An_Exponential_Model_for_Infinite_Rankings.html">10 jmlr-2010-An Exponential Model for Infinite Rankings</a></p>
<p>Author: Marina Meilă, Le Bao</p><p>Abstract: This paper presents a statistical model for expressing preferences through rankings, when the number of alternatives (items to rank) is large. A human ranker will then typically rank only the most preferred items, and may not even examine the whole set of items, or know how many they are. Similarly, a user presented with the ranked output of a search engine, will only consider the highest ranked items. We model such situations by introducing a stagewise ranking model that operates with ﬁnite ordered lists called top-t orderings over an inﬁnite space of items. We give algorithms to estimate this model from data, and demonstrate that it has sufﬁcient statistics, being thus an exponential family model with continuous and discrete parameters. We describe its conjugate prior and other statistical properties. Then, we extend the estimation problem to multimodal data by introducing an Exponential-Blurring-Mean-Shift nonparametric clustering algorithm. The experiments highlight the properties of our model and demonstrate that inﬁnite models over permutations can be simple, elegant and practical. Keywords: permutations, partial orderings, Mallows model, distance based ranking model, exponential family, non-parametric clustering, branch-and-bound</p><p>5 0.085181125 <a title="90-tfidf-5" href="./jmlr-2010-On_the_Foundations_of_Noise-free_Selective_Classification.html">85 jmlr-2010-On the Foundations of Noise-free Selective Classification</a></p>
<p>Author: Ran El-Yaniv, Yair Wiener</p><p>Abstract: We consider selective classiﬁcation, a term we adopt here to refer to ‘classiﬁcation with a reject option.’ The essence in selective classiﬁcation is to trade-off classiﬁer coverage for higher accuracy. We term this trade-off the risk-coverage (RC) trade-off. Our main objective is to characterize this trade-off and to construct algorithms that can optimally or near optimally achieve the best possible trade-offs in a controlled manner. For noise-free models we present in this paper a thorough analysis of selective classiﬁcation including characterizations of RC trade-offs in various interesting settings. Keywords: classiﬁcation with a reject option, selective classiﬁcation, perfect learning, high performance classiﬁcation, risk-coverage trade-off</p><p>6 0.083491147 <a title="90-tfidf-6" href="./jmlr-2010-On_Over-fitting_in_Model_Selection_and_Subsequent_Selection_Bias_in_Performance_Evaluation.html">83 jmlr-2010-On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation</a></p>
<p>7 0.075639971 <a title="90-tfidf-7" href="./jmlr-2010-Classification_Using_Geometric_Level_Sets.html">22 jmlr-2010-Classification Using Geometric Level Sets</a></p>
<p>8 0.074946411 <a title="90-tfidf-8" href="./jmlr-2010-Consistent_Nonparametric_Tests_of_Independence.html">27 jmlr-2010-Consistent Nonparametric Tests of Independence</a></p>
<p>9 0.072349168 <a title="90-tfidf-9" href="./jmlr-2010-A_Rotation_Test_to_Verify_Latent_Structure.html">6 jmlr-2010-A Rotation Test to Verify Latent Structure</a></p>
<p>10 0.071122132 <a title="90-tfidf-10" href="./jmlr-2010-WEKA%E2%88%92Experiences_with_a_Java_Open-Source_Project.html">116 jmlr-2010-WEKA−Experiences with a Java Open-Source Project</a></p>
<p>11 0.067338325 <a title="90-tfidf-11" href="./jmlr-2010-Dimensionality_Estimation%2C_Manifold_Learning_and_Function_Approximation_using_Tensor_Voting.html">30 jmlr-2010-Dimensionality Estimation, Manifold Learning and Function Approximation using Tensor Voting</a></p>
<p>12 0.065415867 <a title="90-tfidf-12" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>13 0.064145029 <a title="90-tfidf-13" href="./jmlr-2010-Kronecker_Graphs%3A_An_Approach_to_Modeling_Networks.html">58 jmlr-2010-Kronecker Graphs: An Approach to Modeling Networks</a></p>
<p>14 0.0629384 <a title="90-tfidf-14" href="./jmlr-2010-Efficient_Heuristics_for_Discriminative_Structure_Learning_of_Bayesian_Network_Classifiers.html">33 jmlr-2010-Efficient Heuristics for Discriminative Structure Learning of Bayesian Network Classifiers</a></p>
<p>15 0.062552787 <a title="90-tfidf-15" href="./jmlr-2010-Local_Causal_and_Markov_Blanket_Induction_for_Causal_Discovery_and_Feature_Selection_for_Classification_Part_II%3A_Analysis_and_Extensions.html">68 jmlr-2010-Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part II: Analysis and Extensions</a></p>
<p>16 0.06115127 <a title="90-tfidf-16" href="./jmlr-2010-How_to_Explain_Individual_Classification_Decisions.html">48 jmlr-2010-How to Explain Individual Classification Decisions</a></p>
<p>17 0.058160726 <a title="90-tfidf-17" href="./jmlr-2010-Learning_From_Crowds.html">61 jmlr-2010-Learning From Crowds</a></p>
<p>18 0.055974469 <a title="90-tfidf-18" href="./jmlr-2010-Classification_Methods_with_Reject_Option_Based_on_Convex_Risk_Minimization.html">21 jmlr-2010-Classification Methods with Reject Option Based on Convex Risk Minimization</a></p>
<p>19 0.052662298 <a title="90-tfidf-19" href="./jmlr-2010-Posterior_Regularization_for_Structured_Latent_Variable_Models.html">91 jmlr-2010-Posterior Regularization for Structured Latent Variable Models</a></p>
<p>20 0.047467928 <a title="90-tfidf-20" href="./jmlr-2010-Approximate_Tree_Kernels.html">15 jmlr-2010-Approximate Tree Kernels</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.225), (1, -0.051), (2, 0.083), (3, 0.12), (4, 0.081), (5, 0.097), (6, 0.069), (7, -0.091), (8, 0.018), (9, 0.035), (10, 0.037), (11, -0.003), (12, 0.061), (13, -0.105), (14, 0.099), (15, -0.067), (16, -0.069), (17, -0.192), (18, -0.197), (19, -0.122), (20, -0.248), (21, -0.048), (22, 0.093), (23, 0.164), (24, -0.001), (25, -0.065), (26, -0.037), (27, -0.023), (28, -0.117), (29, -0.031), (30, 0.048), (31, -0.032), (32, 0.217), (33, 0.231), (34, -0.096), (35, -0.151), (36, 0.091), (37, 0.029), (38, -0.053), (39, 0.023), (40, 0.005), (41, -0.003), (42, -0.003), (43, 0.053), (44, 0.034), (45, -0.099), (46, -0.038), (47, -0.054), (48, -0.06), (49, 0.058)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94973987 <a title="90-lsi-1" href="./jmlr-2010-Permutation_Tests_for_Studying_Classifier_Performance.html">90 jmlr-2010-Permutation Tests for Studying Classifier Performance</a></p>
<p>Author: Markus Ojala, Gemma C. Garriga</p><p>Abstract: We explore the framework of permutation-based p-values for assessing the performance of classiﬁers. In this paper we study two simple permutation tests. The ﬁrst test assess whether the classiﬁer has found a real class structure in the data; the corresponding null distribution is estimated by permuting the labels in the data. This test has been used extensively in classiﬁcation problems in computational biology. The second test studies whether the classiﬁer is exploiting the dependency between the features in classiﬁcation; the corresponding null distribution is estimated by permuting the features within classes, inspired by restricted randomization techniques traditionally used in statistics. This new test can serve to identify descriptive features which can be valuable information in improving the classiﬁer performance. We study the properties of these tests and present an extensive empirical evaluation on real and synthetic data. Our analysis shows that studying the classiﬁer performance via permutation tests is effective. In particular, the restricted permutation test clearly reveals whether the classiﬁer exploits the interdependency between the features in the data. Keywords: classiﬁcation, labeled data, permutation tests, restricted randomization, signiﬁcance testing</p><p>2 0.67357552 <a title="90-lsi-2" href="./jmlr-2010-Semi-Supervised_Novelty_Detection.html">102 jmlr-2010-Semi-Supervised Novelty Detection</a></p>
<p>Author: Gilles Blanchard, Gyemin Lee, Clayton Scott</p><p>Abstract: A common setting for novelty detection assumes that labeled examples from the nominal class are available, but that labeled examples of novelties are unavailable. The standard (inductive) approach is to declare novelties where the nominal density is low, which reduces the problem to density level set estimation. In this paper, we consider the setting where an unlabeled and possibly contaminated sample is also available at learning time. We argue that novelty detection in this semi-supervised setting is naturally solved by a general reduction to a binary classiﬁcation problem. In particular, a detector with a desired false positive rate can be achieved through a reduction to Neyman-Pearson classiﬁcation. Unlike the inductive approach, semi-supervised novelty detection (SSND) yields detectors that are optimal (e.g., statistically consistent) regardless of the distribution on novelties. Therefore, in novelty detection, unlabeled data have a substantial impact on the theoretical properties of the decision rule. We validate the practical utility of SSND with an extensive experimental study. We also show that SSND provides distribution-free, learning-theoretic solutions to two well known problems in hypothesis testing. First, our results provide a general solution to the general two-sample problem, that is, the problem of determining whether two random samples arise from the same distribution. Second, a specialization of SSND coincides with the standard p-value approach to multiple testing under the so-called random effects model. Unlike standard rejection regions based on thresholded p-values, the general SSND framework allows for adaptation to arbitrary alternative distributions in multiple dimensions. Keywords: semi-supervised learning, novelty detection, Neyman-Pearson classiﬁcation, learning reduction, two-sample problem, multiple testing</p><p>3 0.55438542 <a title="90-lsi-3" href="./jmlr-2010-A_Rotation_Test_to_Verify_Latent_Structure.html">6 jmlr-2010-A Rotation Test to Verify Latent Structure</a></p>
<p>Author: Patrick O. Perry, Art B. Owen</p><p>Abstract: In multivariate regression models we have the opportunity to look for hidden structure unrelated to the observed predictors. However, when one ﬁts a model involving such latent variables it is important to be able to tell if the structure is real, or just an artifact of correlation in the regression errors. We develop a new statistical test based on random rotations for verifying the existence of latent variables. The rotations are carefully constructed to rotate orthogonally to the column space of the regression model. We ﬁnd that only non-Gaussian latent variables are detectable, a ﬁnding that parallels a well known phenomenon in independent components analysis. We base our test on a measure of non-Gaussianity in the histogram of the principal eigenvector components instead of on the eigenvalue. The method ﬁnds and veriﬁes some latent dichotomies in the microarray data from the AGEMAP consortium. Keywords: independent components analysis, Kronecker covariance, latent variables, projection pursuit, transposable data</p><p>4 0.53409952 <a title="90-lsi-4" href="./jmlr-2010-On_the_Foundations_of_Noise-free_Selective_Classification.html">85 jmlr-2010-On the Foundations of Noise-free Selective Classification</a></p>
<p>Author: Ran El-Yaniv, Yair Wiener</p><p>Abstract: We consider selective classiﬁcation, a term we adopt here to refer to ‘classiﬁcation with a reject option.’ The essence in selective classiﬁcation is to trade-off classiﬁer coverage for higher accuracy. We term this trade-off the risk-coverage (RC) trade-off. Our main objective is to characterize this trade-off and to construct algorithms that can optimally or near optimally achieve the best possible trade-offs in a controlled manner. For noise-free models we present in this paper a thorough analysis of selective classiﬁcation including characterizations of RC trade-offs in various interesting settings. Keywords: classiﬁcation with a reject option, selective classiﬁcation, perfect learning, high performance classiﬁcation, risk-coverage trade-off</p><p>5 0.52169091 <a title="90-lsi-5" href="./jmlr-2010-An_Efficient_Explanation_of_Individual_Classifications_using_Game_Theory.html">9 jmlr-2010-An Efficient Explanation of Individual Classifications using Game Theory</a></p>
<p>Author: Erik Ĺ trumbelj, Igor Kononenko</p><p>Abstract: We present a general method for explaining individual predictions of classiﬁcation models. The method is based on fundamental concepts from coalitional game theory and predictions are explained with contributions of individual feature values. We overcome the method’s initial exponential time complexity with a sampling-based approximation. In the experimental part of the paper we use the developed method on models generated by several well-known machine learning algorithms on both synthetic and real-world data sets. The results demonstrate that the method is efﬁcient and that the explanations are intuitive and useful. Keywords: data postprocessing, classiﬁcation, explanation, visualization</p><p>6 0.46251315 <a title="90-lsi-6" href="./jmlr-2010-Classification_Using_Geometric_Level_Sets.html">22 jmlr-2010-Classification Using Geometric Level Sets</a></p>
<p>7 0.44658718 <a title="90-lsi-7" href="./jmlr-2010-An_Exponential_Model_for_Infinite_Rankings.html">10 jmlr-2010-An Exponential Model for Infinite Rankings</a></p>
<p>8 0.44610903 <a title="90-lsi-8" href="./jmlr-2010-How_to_Explain_Individual_Classification_Decisions.html">48 jmlr-2010-How to Explain Individual Classification Decisions</a></p>
<p>9 0.43527839 <a title="90-lsi-9" href="./jmlr-2010-Matched_Gene_Selection_and_Committee_Classifier_for_Molecular_Classification_of_Heterogeneous_Diseases.html">71 jmlr-2010-Matched Gene Selection and Committee Classifier for Molecular Classification of Heterogeneous Diseases</a></p>
<p>10 0.43177024 <a title="90-lsi-10" href="./jmlr-2010-Learning_From_Crowds.html">61 jmlr-2010-Learning From Crowds</a></p>
<p>11 0.41921023 <a title="90-lsi-11" href="./jmlr-2010-On_Over-fitting_in_Model_Selection_and_Subsequent_Selection_Bias_in_Performance_Evaluation.html">83 jmlr-2010-On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation</a></p>
<p>12 0.41845962 <a title="90-lsi-12" href="./jmlr-2010-Consistent_Nonparametric_Tests_of_Independence.html">27 jmlr-2010-Consistent Nonparametric Tests of Independence</a></p>
<p>13 0.41701508 <a title="90-lsi-13" href="./jmlr-2010-Efficient_Heuristics_for_Discriminative_Structure_Learning_of_Bayesian_Network_Classifiers.html">33 jmlr-2010-Efficient Heuristics for Discriminative Structure Learning of Bayesian Network Classifiers</a></p>
<p>14 0.38119066 <a title="90-lsi-14" href="./jmlr-2010-WEKA%E2%88%92Experiences_with_a_Java_Open-Source_Project.html">116 jmlr-2010-WEKA−Experiences with a Java Open-Source Project</a></p>
<p>15 0.37699011 <a title="90-lsi-15" href="./jmlr-2010-Learning_Instance-Specific_Predictive_Models.html">63 jmlr-2010-Learning Instance-Specific Predictive Models</a></p>
<p>16 0.36257356 <a title="90-lsi-16" href="./jmlr-2010-Local_Causal_and_Markov_Blanket_Induction_for_Causal_Discovery_and_Feature_Selection_for_Classification_Part_II%3A_Analysis_and_Extensions.html">68 jmlr-2010-Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part II: Analysis and Extensions</a></p>
<p>17 0.33955261 <a title="90-lsi-17" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>18 0.33431175 <a title="90-lsi-18" href="./jmlr-2010-Unsupervised_Supervised_Learning_I%3A_Estimating_Classification_and_Regression_Errors_without_Labels.html">114 jmlr-2010-Unsupervised Supervised Learning I: Estimating Classification and Regression Errors without Labels</a></p>
<p>19 0.33010545 <a title="90-lsi-19" href="./jmlr-2010-Tree_Decomposition_for_Large-Scale_SVM_Problems.html">113 jmlr-2010-Tree Decomposition for Large-Scale SVM Problems</a></p>
<p>20 0.31873599 <a title="90-lsi-20" href="./jmlr-2010-A_Streaming_Parallel_Decision_Tree_Algorithm.html">7 jmlr-2010-A Streaming Parallel Decision Tree Algorithm</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.211), (13, 0.114), (22, 0.035), (46, 0.012), (49, 0.014), (54, 0.405), (62, 0.012), (65, 0.052), (71, 0.055), (82, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.63483304 <a title="90-lda-1" href="./jmlr-2010-Permutation_Tests_for_Studying_Classifier_Performance.html">90 jmlr-2010-Permutation Tests for Studying Classifier Performance</a></p>
<p>Author: Markus Ojala, Gemma C. Garriga</p><p>Abstract: We explore the framework of permutation-based p-values for assessing the performance of classiﬁers. In this paper we study two simple permutation tests. The ﬁrst test assess whether the classiﬁer has found a real class structure in the data; the corresponding null distribution is estimated by permuting the labels in the data. This test has been used extensively in classiﬁcation problems in computational biology. The second test studies whether the classiﬁer is exploiting the dependency between the features in classiﬁcation; the corresponding null distribution is estimated by permuting the features within classes, inspired by restricted randomization techniques traditionally used in statistics. This new test can serve to identify descriptive features which can be valuable information in improving the classiﬁer performance. We study the properties of these tests and present an extensive empirical evaluation on real and synthetic data. Our analysis shows that studying the classiﬁer performance via permutation tests is effective. In particular, the restricted permutation test clearly reveals whether the classiﬁer exploits the interdependency between the features in the data. Keywords: classiﬁcation, labeled data, permutation tests, restricted randomization, signiﬁcance testing</p><p>2 0.52280992 <a title="90-lda-2" href="./jmlr-2010-Unsupervised_Supervised_Learning_I%3A_Estimating_Classification_and_Regression_Errors_without_Labels.html">114 jmlr-2010-Unsupervised Supervised Learning I: Estimating Classification and Regression Errors without Labels</a></p>
<p>Author: Pinar Donmez, Guy Lebanon, Krishnakumar Balasubramanian</p><p>Abstract: Estimating the error rates of classiﬁers or regression models is a fundamental task in machine learning which has thus far been studied exclusively using supervised learning techniques. We propose a novel unsupervised framework for estimating these error rates using only unlabeled data and mild assumptions. We prove consistency results for the framework and demonstrate its practical applicability on both synthetic and real world data. Keywords: classiﬁcation and regression, maximum likelihood, latent variable models</p><p>3 0.5208149 <a title="90-lda-3" href="./jmlr-2010-Learning_Instance-Specific_Predictive_Models.html">63 jmlr-2010-Learning Instance-Specific Predictive Models</a></p>
<p>Author: Shyam Visweswaran, Gregory F. Cooper</p><p>Abstract: This paper introduces a Bayesian algorithm for constructing predictive models from data that are optimized to predict a target variable well for a particular instance. This algorithm learns Markov blanket models, carries out Bayesian model averaging over a set of models to predict a target variable of the instance at hand, and employs an instance-speciﬁc heuristic to locate a set of suitable models to average over. We call this method the instance-speciﬁc Markov blanket (ISMB) algorithm. The ISMB algorithm was evaluated on 21 UCI data sets using ﬁve different performance measures and its performance was compared to that of several commonly used predictive algorithms, including nave Bayes, C4.5 decision tree, logistic regression, neural networks, k-Nearest Neighbor, Lazy Bayesian Rules, and AdaBoost. Over all the data sets, the ISMB algorithm performed better on average on all performance measures against all the comparison algorithms. Keywords: instance-speciﬁc, Bayesian network, Markov blanket, Bayesian model averaging</p><p>4 0.52070236 <a title="90-lda-4" href="./jmlr-2010-Fast_and_Scalable_Local_Kernel_Machines.html">40 jmlr-2010-Fast and Scalable Local Kernel Machines</a></p>
<p>Author: Nicola Segata, Enrico Blanzieri</p><p>Abstract: A computationally efﬁcient approach to local learning with kernel methods is presented. The Fast Local Kernel Support Vector Machine (FaLK-SVM) trains a set of local SVMs on redundant neighbourhoods in the training set and an appropriate model for each query point is selected at testing time according to a proximity strategy. Supported by a recent result by Zakai and Ritov (2009) relating consistency and localizability, our approach achieves high classiﬁcation accuracies by dividing the separation function in local optimisation problems that can be handled very efﬁciently from the computational viewpoint. The introduction of a fast local model selection further speeds-up the learning process. Learning and complexity bounds are derived for FaLK-SVM, and the empirical evaluation of the approach (with data sets up to 3 million points) showed that it is much faster and more accurate and scalable than state-of-the-art accurate and approximated SVM solvers at least for non high-dimensional data sets. More generally, we show that locality can be an important factor to sensibly speed-up learning approaches and kernel methods, differently from other recent techniques that tend to dismiss local information in order to improve scalability. Keywords: locality, kernel methods, local learning algorithms, support vector machines, instancebased learning</p><p>5 0.51936543 <a title="90-lda-5" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>Author: Gideon S. Mann, Andrew McCallum</p><p>Abstract: In this paper, we present an overview of generalized expectation criteria (GE), a simple, robust, scalable method for semi-supervised training using weakly-labeled data. GE ﬁts model parameters by favoring models that match certain expectation constraints, such as marginal label distributions, on the unlabeled data. This paper shows how to apply generalized expectation criteria to two classes of parametric models: maximum entropy models and conditional random ﬁelds. Experimental results demonstrate accuracy improvements over supervised training and a number of other stateof-the-art semi-supervised learning methods for these models. Keywords: generalized expectation criteria, semi-supervised learning, logistic regression, conditional random ﬁelds</p><p>6 0.51616222 <a title="90-lda-6" href="./jmlr-2010-How_to_Explain_Individual_Classification_Decisions.html">48 jmlr-2010-How to Explain Individual Classification Decisions</a></p>
<p>7 0.51555651 <a title="90-lda-7" href="./jmlr-2010-Learning_Non-Stationary_Dynamic_Bayesian_Networks.html">64 jmlr-2010-Learning Non-Stationary Dynamic Bayesian Networks</a></p>
<p>8 0.51440054 <a title="90-lda-8" href="./jmlr-2010-Maximum_Likelihood_in_Cost-Sensitive_Learning%3A_Model_Specification%2C_Approximations%2C_and_Upper_Bounds.html">73 jmlr-2010-Maximum Likelihood in Cost-Sensitive Learning: Model Specification, Approximations, and Upper Bounds</a></p>
<p>9 0.51424587 <a title="90-lda-9" href="./jmlr-2010-An_Exponential_Model_for_Infinite_Rankings.html">10 jmlr-2010-An Exponential Model for Infinite Rankings</a></p>
<p>10 0.51248318 <a title="90-lda-10" href="./jmlr-2010-Classification_with_Incomplete_Data_Using_Dirichlet_Process_Priors.html">23 jmlr-2010-Classification with Incomplete Data Using Dirichlet Process Priors</a></p>
<p>11 0.51241434 <a title="90-lda-11" href="./jmlr-2010-An_Efficient_Explanation_of_Individual_Classifications_using_Game_Theory.html">9 jmlr-2010-An Efficient Explanation of Individual Classifications using Game Theory</a></p>
<p>12 0.51198286 <a title="90-lda-12" href="./jmlr-2010-Bayesian_Learning_in_Sparse_Graphical_Factor_Models_via_Variational_Mean-Field_Annealing.html">17 jmlr-2010-Bayesian Learning in Sparse Graphical Factor Models via Variational Mean-Field Annealing</a></p>
<p>13 0.51187599 <a title="90-lda-13" href="./jmlr-2010-Practical_Approaches_to_Principal_Component_Analysis_in_the_Presence_of_Missing_Values.html">92 jmlr-2010-Practical Approaches to Principal Component Analysis in the Presence of Missing Values</a></p>
<p>14 0.51148272 <a title="90-lda-14" href="./jmlr-2010-Stochastic_Composite_Likelihood.html">109 jmlr-2010-Stochastic Composite Likelihood</a></p>
<p>15 0.51090872 <a title="90-lda-15" href="./jmlr-2010-Tree_Decomposition_for_Large-Scale_SVM_Problems.html">113 jmlr-2010-Tree Decomposition for Large-Scale SVM Problems</a></p>
<p>16 0.51054668 <a title="90-lda-16" href="./jmlr-2010-Matched_Gene_Selection_and_Committee_Classifier_for_Molecular_Classification_of_Heterogeneous_Diseases.html">71 jmlr-2010-Matched Gene Selection and Committee Classifier for Molecular Classification of Heterogeneous Diseases</a></p>
<p>17 0.51040858 <a title="90-lda-17" href="./jmlr-2010-Approximate_Tree_Kernels.html">15 jmlr-2010-Approximate Tree Kernels</a></p>
<p>18 0.51015794 <a title="90-lda-18" href="./jmlr-2010-Generalized_Power_Method_for_Sparse_Principal_Component_Analysis.html">43 jmlr-2010-Generalized Power Method for Sparse Principal Component Analysis</a></p>
<p>19 0.51005256 <a title="90-lda-19" href="./jmlr-2010-Semi-Supervised_Novelty_Detection.html">102 jmlr-2010-Semi-Supervised Novelty Detection</a></p>
<p>20 0.50929677 <a title="90-lda-20" href="./jmlr-2010-Local_Causal_and_Markov_Blanket_Induction_for_Causal_Discovery_and_Feature_Selection_for_Classification_Part_II%3A_Analysis_and_Extensions.html">68 jmlr-2010-Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part II: Analysis and Extensions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
