<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>107 jmlr-2010-Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-107" href="#">jmlr2010-107</a> knowledge-graph by maker-knowledge-mining</p><h1>107 jmlr-2010-Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</h1>
<br/><p>Source: <a title="jmlr-2010-107-pdf" href="http://jmlr.org/papers/volume11/vincent10a/vincent10a.pdf">pdf</a></p><p>Author: Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine Manzagol</p><p>Abstract: We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classiﬁcation problems to yield signiﬁcantly lower classiﬁcation error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classiﬁers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations. Keywords: deep learning, unsupervised feature learning, deep belief networks, autoencoders, denoising</p><p>Reference: <a title="jmlr-2010-107-reference" href="../jmlr2010_reference/jmlr-2010-Stacked_Denoising_Autoencoders%3A_Learning_Useful_Representations_in_a_Deep_Network_with_a_Local_Denoising_Criterion_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('autoencod', 0.653), ('deno', 0.4), ('corrupt', 0.245), ('pretrain', 0.211), ('sda', 0.211), ('lay', 0.163), ('deep', 0.137), ('sae', 0.135), ('stack', 0.116), ('learnt', 0.113), ('ajoy', 0.112), ('arochel', 0.112), ('anzagol', 0.095), ('tack', 0.09), ('nois', 0.087), ('engio', 0.086), ('eno', 0.081), ('larochel', 0.075), ('dbn', 0.07), ('reconstruct', 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="107-tfidf-1" href="./jmlr-2010-Stacked_Denoising_Autoencoders%3A_Learning_Useful_Representations_in_a_Deep_Network_with_a_Local_Denoising_Criterion.html">107 jmlr-2010-Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</a></p>
<p>2 0.36146757 <a title="107-tfidf-2" href="./jmlr-2010-Why_Does_Unsupervised_Pre-training_Help_Deep_Learning%3F.html">117 jmlr-2010-Why Does Unsupervised Pre-training Help Deep Learning?</a></p>
<p>3 0.13446075 <a title="107-tfidf-3" href="./jmlr-2010-Image_Denoising_with_Kernels_Based_on_Natural_Image_Relations.html">50 jmlr-2010-Image Denoising with Kernels Based on Natural Image Relations</a></p>
<p>4 0.043902997 <a title="107-tfidf-4" href="./jmlr-2010-Training_and_Testing_Low-degree_Polynomial_Data_Mappings_via_Linear_SVM.html">112 jmlr-2010-Training and Testing Low-degree Polynomial Data Mappings via Linear SVM</a></p>
<p>5 0.041796375 <a title="107-tfidf-5" href="./jmlr-2010-Model_Selection%3A_Beyond_the_Bayesian_Frequentist_Divide.html">78 jmlr-2010-Model Selection: Beyond the Bayesian Frequentist Divide</a></p>
<p>6 0.041164152 <a title="107-tfidf-6" href="./jmlr-2010-Incremental_Sigmoid_Belief_Networks_for_Grammar_Learning.html">52 jmlr-2010-Incremental Sigmoid Belief Networks for Grammar Learning</a></p>
<p>7 0.040864222 <a title="107-tfidf-7" href="./jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">87 jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>8 0.039146792 <a title="107-tfidf-8" href="./jmlr-2010-PyBrain.html">93 jmlr-2010-PyBrain</a></p>
<p>9 0.034588858 <a title="107-tfidf-9" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>10 0.034260951 <a title="107-tfidf-10" href="./jmlr-2010-Learning_Non-Stationary_Dynamic_Bayesian_Networks.html">64 jmlr-2010-Learning Non-Stationary Dynamic Bayesian Networks</a></p>
<p>11 0.032105207 <a title="107-tfidf-11" href="./jmlr-2010-Expectation_Truncation_and_the_Benefits_of_Preselection_In_Training_Generative_Models.html">38 jmlr-2010-Expectation Truncation and the Benefits of Preselection In Training Generative Models</a></p>
<p>12 0.030352924 <a title="107-tfidf-12" href="./jmlr-2010-Approximate_Tree_Kernels.html">15 jmlr-2010-Approximate Tree Kernels</a></p>
<p>13 0.03033481 <a title="107-tfidf-13" href="./jmlr-2010-Classification_Using_Geometric_Level_Sets.html">22 jmlr-2010-Classification Using Geometric Level Sets</a></p>
<p>14 0.027906269 <a title="107-tfidf-14" href="./jmlr-2010-Posterior_Regularization_for_Structured_Latent_Variable_Models.html">91 jmlr-2010-Posterior Regularization for Structured Latent Variable Models</a></p>
<p>15 0.027197791 <a title="107-tfidf-15" href="./jmlr-2010-Fast_and_Scalable_Local_Kernel_Machines.html">40 jmlr-2010-Fast and Scalable Local Kernel Machines</a></p>
<p>16 0.026830154 <a title="107-tfidf-16" href="./jmlr-2010-On_Over-fitting_in_Model_Selection_and_Subsequent_Selection_Bias_in_Performance_Evaluation.html">83 jmlr-2010-On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation</a></p>
<p>17 0.025373289 <a title="107-tfidf-17" href="./jmlr-2010-Learning_Translation_Invariant_Kernels_for_Classification.html">65 jmlr-2010-Learning Translation Invariant Kernels for Classification</a></p>
<p>18 0.024594102 <a title="107-tfidf-18" href="./jmlr-2010-Error-Correcting_Output_Codes_Library.html">35 jmlr-2010-Error-Correcting Output Codes Library</a></p>
<p>19 0.024412369 <a title="107-tfidf-19" href="./jmlr-2010-Consensus-Based_Distributed_Support_Vector_Machines.html">26 jmlr-2010-Consensus-Based Distributed Support Vector Machines</a></p>
<p>20 0.02437011 <a title="107-tfidf-20" href="./jmlr-2010-Dimensionality_Estimation%2C_Manifold_Learning_and_Function_Approximation_using_Tensor_Voting.html">30 jmlr-2010-Dimensionality Estimation, Manifold Learning and Function Approximation using Tensor Voting</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.142), (1, -0.076), (2, 0.015), (3, 0.009), (4, 0.077), (5, 0.194), (6, 0.095), (7, 0.196), (8, -0.149), (9, 0.443), (10, -0.18), (11, -0.227), (12, -0.305), (13, -0.048), (14, 0.132), (15, -0.096), (16, 0.102), (17, 0.148), (18, 0.169), (19, -0.074), (20, 0.028), (21, 0.112), (22, 0.029), (23, 0.075), (24, -0.001), (25, -0.016), (26, -0.118), (27, -0.064), (28, -0.003), (29, 0.066), (30, -0.035), (31, -0.037), (32, -0.011), (33, 0.046), (34, -0.013), (35, -0.023), (36, -0.013), (37, -0.021), (38, 0.079), (39, -0.011), (40, 0.001), (41, -0.033), (42, 0.015), (43, 0.018), (44, -0.027), (45, -0.038), (46, 0.032), (47, -0.004), (48, 0.047), (49, -0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92891592 <a title="107-lsi-1" href="./jmlr-2010-Stacked_Denoising_Autoencoders%3A_Learning_Useful_Representations_in_a_Deep_Network_with_a_Local_Denoising_Criterion.html">107 jmlr-2010-Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</a></p>
<p>2 0.83148766 <a title="107-lsi-2" href="./jmlr-2010-Why_Does_Unsupervised_Pre-training_Help_Deep_Learning%3F.html">117 jmlr-2010-Why Does Unsupervised Pre-training Help Deep Learning?</a></p>
<p>3 0.49530688 <a title="107-lsi-3" href="./jmlr-2010-Image_Denoising_with_Kernels_Based_on_Natural_Image_Relations.html">50 jmlr-2010-Image Denoising with Kernels Based on Natural Image Relations</a></p>
<p>4 0.29436252 <a title="107-lsi-4" href="./jmlr-2010-PyBrain.html">93 jmlr-2010-PyBrain</a></p>
<p>5 0.18043074 <a title="107-lsi-5" href="./jmlr-2010-Model_Selection%3A_Beyond_the_Bayesian_Frequentist_Divide.html">78 jmlr-2010-Model Selection: Beyond the Bayesian Frequentist Divide</a></p>
<p>6 0.17745557 <a title="107-lsi-6" href="./jmlr-2010-Expectation_Truncation_and_the_Benefits_of_Preselection_In_Training_Generative_Models.html">38 jmlr-2010-Expectation Truncation and the Benefits of Preselection In Training Generative Models</a></p>
<p>7 0.16851072 <a title="107-lsi-7" href="./jmlr-2010-Incremental_Sigmoid_Belief_Networks_for_Grammar_Learning.html">52 jmlr-2010-Incremental Sigmoid Belief Networks for Grammar Learning</a></p>
<p>8 0.16763435 <a title="107-lsi-8" href="./jmlr-2010-Evolving_Static_Representations_for_Task_Transfer.html">37 jmlr-2010-Evolving Static Representations for Task Transfer</a></p>
<p>9 0.16427994 <a title="107-lsi-9" href="./jmlr-2010-Unsupervised_Supervised_Learning_I%3A_Estimating_Classification_and_Regression_Errors_without_Labels.html">114 jmlr-2010-Unsupervised Supervised Learning I: Estimating Classification and Regression Errors without Labels</a></p>
<p>10 0.16311795 <a title="107-lsi-10" href="./jmlr-2010-Fast_and_Scalable_Local_Kernel_Machines.html">40 jmlr-2010-Fast and Scalable Local Kernel Machines</a></p>
<p>11 0.16051665 <a title="107-lsi-11" href="./jmlr-2010-Learning_Non-Stationary_Dynamic_Bayesian_Networks.html">64 jmlr-2010-Learning Non-Stationary Dynamic Bayesian Networks</a></p>
<p>12 0.15174441 <a title="107-lsi-12" href="./jmlr-2010-Training_and_Testing_Low-degree_Polynomial_Data_Mappings_via_Linear_SVM.html">112 jmlr-2010-Training and Testing Low-degree Polynomial Data Mappings via Linear SVM</a></p>
<p>13 0.15064362 <a title="107-lsi-13" href="./jmlr-2010-Large_Scale_Online_Learning_of_Image_Similarity_Through_Ranking.html">59 jmlr-2010-Large Scale Online Learning of Image Similarity Through Ranking</a></p>
<p>14 0.14953926 <a title="107-lsi-14" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>15 0.14893401 <a title="107-lsi-15" href="./jmlr-2010-Tree_Decomposition_for_Large-Scale_SVM_Problems.html">113 jmlr-2010-Tree Decomposition for Large-Scale SVM Problems</a></p>
<p>16 0.14276198 <a title="107-lsi-16" href="./jmlr-2010-Consensus-Based_Distributed_Support_Vector_Machines.html">26 jmlr-2010-Consensus-Based Distributed Support Vector Machines</a></p>
<p>17 0.14143671 <a title="107-lsi-17" href="./jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">87 jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>18 0.13835832 <a title="107-lsi-18" href="./jmlr-2010-Classification_Using_Geometric_Level_Sets.html">22 jmlr-2010-Classification Using Geometric Level Sets</a></p>
<p>19 0.1344997 <a title="107-lsi-19" href="./jmlr-2010-How_to_Explain_Individual_Classification_Decisions.html">48 jmlr-2010-How to Explain Individual Classification Decisions</a></p>
<p>20 0.13299292 <a title="107-lsi-20" href="./jmlr-2010-Efficient_Heuristics_for_Discriminative_Structure_Learning_of_Bayesian_Network_Classifiers.html">33 jmlr-2010-Efficient Heuristics for Discriminative Structure Learning of Bayesian Network Classifiers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.175), (13, 0.046), (22, 0.021), (28, 0.014), (46, 0.013), (57, 0.014), (62, 0.011), (65, 0.048), (68, 0.021), (71, 0.077), (87, 0.33), (94, 0.117)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.66991079 <a title="107-lda-1" href="./jmlr-2010-Stacked_Denoising_Autoencoders%3A_Learning_Useful_Representations_in_a_Deep_Network_with_a_Local_Denoising_Criterion.html">107 jmlr-2010-Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</a></p>
<p>2 0.57116026 <a title="107-lda-2" href="./jmlr-2010-Iterative_Scaling_and_Coordinate_Descent_Methods_for_Maximum_Entropy_Models.html">57 jmlr-2010-Iterative Scaling and Coordinate Descent Methods for Maximum Entropy Models</a></p>
<p>3 0.55460674 <a title="107-lda-3" href="./jmlr-2010-Why_Does_Unsupervised_Pre-training_Help_Deep_Learning%3F.html">117 jmlr-2010-Why Does Unsupervised Pre-training Help Deep Learning?</a></p>
<p>4 0.49625307 <a title="107-lda-4" href="./jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">42 jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>5 0.49493253 <a title="107-lda-5" href="./jmlr-2010-Maximum_Relative_Margin_and_Data-Dependent_Regularization.html">74 jmlr-2010-Maximum Relative Margin and Data-Dependent Regularization</a></p>
<p>6 0.49476519 <a title="107-lda-6" href="./jmlr-2010-An_Exponential_Model_for_Infinite_Rankings.html">10 jmlr-2010-An Exponential Model for Infinite Rankings</a></p>
<p>7 0.49425167 <a title="107-lda-7" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>8 0.49334055 <a title="107-lda-8" href="./jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">87 jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>9 0.49323559 <a title="107-lda-9" href="./jmlr-2010-Stochastic_Composite_Likelihood.html">109 jmlr-2010-Stochastic Composite Likelihood</a></p>
<p>10 0.49306381 <a title="107-lda-10" href="./jmlr-2010-Matrix_Completion_from__Noisy_Entries.html">72 jmlr-2010-Matrix Completion from  Noisy Entries</a></p>
<p>11 0.49217305 <a title="107-lda-11" href="./jmlr-2010-Mean_Field_Variational_Approximation_for_Continuous-Time_Bayesian_Networks.html">75 jmlr-2010-Mean Field Variational Approximation for Continuous-Time Bayesian Networks</a></p>
<p>12 0.49169892 <a title="107-lda-12" href="./jmlr-2010-High-dimensional_Variable_Selection_with_Sparse_Random_Projections%3A_Measurement_Sparsity_and_Statistical_Efficiency.html">45 jmlr-2010-High-dimensional Variable Selection with Sparse Random Projections: Measurement Sparsity and Statistical Efficiency</a></p>
<p>13 0.49154752 <a title="107-lda-13" href="./jmlr-2010-Generalized_Power_Method_for_Sparse_Principal_Component_Analysis.html">43 jmlr-2010-Generalized Power Method for Sparse Principal Component Analysis</a></p>
<p>14 0.49077189 <a title="107-lda-14" href="./jmlr-2010-Incremental_Sigmoid_Belief_Networks_for_Grammar_Learning.html">52 jmlr-2010-Incremental Sigmoid Belief Networks for Grammar Learning</a></p>
<p>15 0.49067551 <a title="107-lda-15" href="./jmlr-2010-Bayesian_Learning_in_Sparse_Graphical_Factor_Models_via_Variational_Mean-Field_Annealing.html">17 jmlr-2010-Bayesian Learning in Sparse Graphical Factor Models via Variational Mean-Field Annealing</a></p>
<p>16 0.49037477 <a title="107-lda-16" href="./jmlr-2010-Learning_Non-Stationary_Dynamic_Bayesian_Networks.html">64 jmlr-2010-Learning Non-Stationary Dynamic Bayesian Networks</a></p>
<p>17 0.49019107 <a title="107-lda-17" href="./jmlr-2010-Fast_and_Scalable_Local_Kernel_Machines.html">40 jmlr-2010-Fast and Scalable Local Kernel Machines</a></p>
<p>18 0.48995492 <a title="107-lda-18" href="./jmlr-2010-Graph_Kernels.html">44 jmlr-2010-Graph Kernels</a></p>
<p>19 0.48987225 <a title="107-lda-19" href="./jmlr-2010-Tree_Decomposition_for_Large-Scale_SVM_Problems.html">113 jmlr-2010-Tree Decomposition for Large-Scale SVM Problems</a></p>
<p>20 0.48927823 <a title="107-lda-20" href="./jmlr-2010-An_Efficient_Explanation_of_Individual_Classifications_using_Game_Theory.html">9 jmlr-2010-An Efficient Explanation of Individual Classifications using Game Theory</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
