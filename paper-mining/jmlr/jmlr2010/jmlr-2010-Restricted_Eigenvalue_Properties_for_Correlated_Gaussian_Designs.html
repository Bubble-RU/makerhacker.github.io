<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>99 jmlr-2010-Restricted Eigenvalue Properties for Correlated Gaussian Designs</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-99" href="#">jmlr2010-99</a> knowledge-graph by maker-knowledge-mining</p><h1>99 jmlr-2010-Restricted Eigenvalue Properties for Correlated Gaussian Designs</h1>
<br/><p>Source: <a title="jmlr-2010-99-pdf" href="http://jmlr.org/papers/volume11/raskutti10a/raskutti10a.pdf">pdf</a></p><p>Author: Garvesh Raskutti, Martin J. Wainwright, Bin Yu</p><p>Abstract: Methods based on ℓ1 -relaxation, such as basis pursuit and the Lasso, are very popular for sparse regression in high dimensions. The conditions for success of these methods are now well-understood: (1) exact recovery in the noiseless setting is possible if and only if the design matrix X satisﬁes the restricted nullspace property, and (2) the squared ℓ2 -error of a Lasso estimate decays at the minimax optimal rate k log p , where k is the sparsity of the p-dimensional regression problem with additive n Gaussian noise, whenever the design satisﬁes a restricted eigenvalue condition. The key issue is thus to determine when the design matrix X satisﬁes these desirable properties. Thus far, there have been numerous results showing that the restricted isometry property, which implies both the restricted nullspace and eigenvalue conditions, is satisﬁed when all entries of X are independent and identically distributed (i.i.d.), or the rows are unitary. This paper proves directly that the restricted nullspace and eigenvalue conditions hold with high probability for quite general classes of Gaussian matrices for which the predictors may be highly dependent, and hence restricted isometry conditions can be violated with high probability. In this way, our results extend the attractive theoretical guarantees on ℓ1 -relaxations to a much broader class of problems than the case of completely independent or unitary designs. Keywords: Lasso, basis pursuit, random matrix theory, Gaussian comparison inequality, concentration of measure</p><p>Reference: <a title="jmlr-2010-99-reference" href="../jmlr2010_reference/jmlr-2010-Restricted_Eigenvalue_Properties_for_Correlated_Gaussian_Designs_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nullspac', 0.415), ('geer', 0.248), ('ss', 0.235), ('xv', 0.224), ('estrict', 0.195), ('askutt', 0.187), ('igenvalu', 0.177), ('rip', 0.176), ('eigenvalu', 0.166), ('orrel', 0.159), ('isometry', 0.147), ('roperty', 0.144), ('pursuit', 0.134), ('toeplitz', 0.128), ('esign', 0.124), ('auss', 0.124), ('lasso', 0.123), ('raskutt', 0.118), ('wainwright', 0.113), ('bickel', 0.112)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="99-tfidf-1" href="./jmlr-2010-Restricted_Eigenvalue_Properties_for_Correlated_Gaussian_Designs.html">99 jmlr-2010-Restricted Eigenvalue Properties for Correlated Gaussian Designs</a></p>
<p>2 0.2442942 <a title="99-tfidf-2" href="./jmlr-2010-High-dimensional_Variable_Selection_with_Sparse_Random_Projections%3A_Measurement_Sparsity_and_Statistical_Efficiency.html">45 jmlr-2010-High-dimensional Variable Selection with Sparse Random Projections: Measurement Sparsity and Statistical Efficiency</a></p>
<p>3 0.16972308 <a title="99-tfidf-3" href="./jmlr-2010-High_Dimensional_Inverse_Covariance_Matrix_Estimation_via_Linear_Programming.html">46 jmlr-2010-High Dimensional Inverse Covariance Matrix Estimation via Linear Programming</a></p>
<p>4 0.15095808 <a title="99-tfidf-4" href="./jmlr-2010-Rate_Minimaxity_of_the_Lasso_and_Dantzig_Selector_for_thelqLoss_inlrBalls.html">96 jmlr-2010-Rate Minimaxity of the Lasso and Dantzig Selector for thelqLoss inlrBalls</a></p>
<p>5 0.094134048 <a title="99-tfidf-5" href="./jmlr-2010-Analysis_of_Multi-stage_Convex_Relaxation_for_Sparse_Regularization.html">12 jmlr-2010-Analysis of Multi-stage Convex Relaxation for Sparse Regularization</a></p>
<p>6 0.076941557 <a title="99-tfidf-6" href="./jmlr-2010-Matrix_Completion_from__Noisy_Entries.html">72 jmlr-2010-Matrix Completion from  Noisy Entries</a></p>
<p>7 0.074573576 <a title="99-tfidf-7" href="./jmlr-2010-On_Learning_with_Integral_Operators.html">82 jmlr-2010-On Learning with Integral Operators</a></p>
<p>8 0.065251209 <a title="99-tfidf-8" href="./jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">87 jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>9 0.060358755 <a title="99-tfidf-9" href="./jmlr-2010-Learning_Translation_Invariant_Kernels_for_Classification.html">65 jmlr-2010-Learning Translation Invariant Kernels for Classification</a></p>
<p>10 0.055619374 <a title="99-tfidf-10" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>11 0.054917593 <a title="99-tfidf-11" href="./jmlr-2010-A_Fast_Hybrid_Algorithm_for_Large-Scalel1-Regularized_Logistic_Regression.html">3 jmlr-2010-A Fast Hybrid Algorithm for Large-Scalel1-Regularized Logistic Regression</a></p>
<p>12 0.053215437 <a title="99-tfidf-12" href="./jmlr-2010-On_Spectral_Learning.html">84 jmlr-2010-On Spectral Learning</a></p>
<p>13 0.053165279 <a title="99-tfidf-13" href="./jmlr-2010-Stochastic_Complexity_and_Generalization_Error_of_a_Restricted_Boltzmann_Machine_in_Bayesian_Estimation.html">108 jmlr-2010-Stochastic Complexity and Generalization Error of a Restricted Boltzmann Machine in Bayesian Estimation</a></p>
<p>14 0.052646272 <a title="99-tfidf-14" href="./jmlr-2010-Linear_Algorithms_for_Online_Multitask_Classification.html">66 jmlr-2010-Linear Algorithms for Online Multitask Classification</a></p>
<p>15 0.04340744 <a title="99-tfidf-15" href="./jmlr-2010-Rademacher_Complexities_and_Bounding_the_Excess_Risk_in_Active_Learning.html">95 jmlr-2010-Rademacher Complexities and Bounding the Excess Risk in Active Learning</a></p>
<p>16 0.041726075 <a title="99-tfidf-16" href="./jmlr-2010-Gaussian_Processes_for_Machine_Learning_%28GPML%29_Toolbox.html">41 jmlr-2010-Gaussian Processes for Machine Learning (GPML) Toolbox</a></p>
<p>17 0.040985145 <a title="99-tfidf-17" href="./jmlr-2010-A_Rotation_Test_to_Verify_Latent_Structure.html">6 jmlr-2010-A Rotation Test to Verify Latent Structure</a></p>
<p>18 0.040657114 <a title="99-tfidf-18" href="./jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">97 jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>19 0.040493146 <a title="99-tfidf-19" href="./jmlr-2010-Dual_Averaging_Methods_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">31 jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</a></p>
<p>20 0.040215589 <a title="99-tfidf-20" href="./jmlr-2010-Estimation_of_a_Structural_Vector_Autoregression_Model_Using_Non-Gaussianity.html">36 jmlr-2010-Estimation of a Structural Vector Autoregression Model Using Non-Gaussianity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.212), (1, 0.218), (2, -0.053), (3, 0.016), (4, 0.075), (5, -0.299), (6, -0.02), (7, 0.283), (8, -0.081), (9, -0.077), (10, -0.031), (11, -0.123), (12, 0.063), (13, -0.049), (14, 0.039), (15, -0.055), (16, -0.02), (17, -0.073), (18, 0.035), (19, 0.083), (20, -0.003), (21, -0.02), (22, 0.186), (23, 0.022), (24, 0.101), (25, 0.051), (26, -0.084), (27, -0.036), (28, -0.1), (29, 0.007), (30, -0.032), (31, -0.048), (32, 0.092), (33, -0.032), (34, 0.1), (35, -0.034), (36, -0.033), (37, -0.021), (38, -0.008), (39, 0.066), (40, 0.033), (41, 0.078), (42, 0.008), (43, 0.034), (44, -0.002), (45, -0.025), (46, 0.001), (47, 0.026), (48, 0.053), (49, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92736328 <a title="99-lsi-1" href="./jmlr-2010-Restricted_Eigenvalue_Properties_for_Correlated_Gaussian_Designs.html">99 jmlr-2010-Restricted Eigenvalue Properties for Correlated Gaussian Designs</a></p>
<p>2 0.79102081 <a title="99-lsi-2" href="./jmlr-2010-Rate_Minimaxity_of_the_Lasso_and_Dantzig_Selector_for_thelqLoss_inlrBalls.html">96 jmlr-2010-Rate Minimaxity of the Lasso and Dantzig Selector for thelqLoss inlrBalls</a></p>
<p>3 0.78700775 <a title="99-lsi-3" href="./jmlr-2010-High-dimensional_Variable_Selection_with_Sparse_Random_Projections%3A_Measurement_Sparsity_and_Statistical_Efficiency.html">45 jmlr-2010-High-dimensional Variable Selection with Sparse Random Projections: Measurement Sparsity and Statistical Efficiency</a></p>
<p>4 0.77745521 <a title="99-lsi-4" href="./jmlr-2010-High_Dimensional_Inverse_Covariance_Matrix_Estimation_via_Linear_Programming.html">46 jmlr-2010-High Dimensional Inverse Covariance Matrix Estimation via Linear Programming</a></p>
<p>5 0.4681032 <a title="99-lsi-5" href="./jmlr-2010-Matrix_Completion_from__Noisy_Entries.html">72 jmlr-2010-Matrix Completion from  Noisy Entries</a></p>
<p>6 0.42010275 <a title="99-lsi-6" href="./jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">97 jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>7 0.35650933 <a title="99-lsi-7" href="./jmlr-2010-A_Fast_Hybrid_Algorithm_for_Large-Scalel1-Regularized_Logistic_Regression.html">3 jmlr-2010-A Fast Hybrid Algorithm for Large-Scalel1-Regularized Logistic Regression</a></p>
<p>8 0.35348377 <a title="99-lsi-8" href="./jmlr-2010-Analysis_of_Multi-stage_Convex_Relaxation_for_Sparse_Regularization.html">12 jmlr-2010-Analysis of Multi-stage Convex Relaxation for Sparse Regularization</a></p>
<p>9 0.34402886 <a title="99-lsi-9" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>10 0.32857192 <a title="99-lsi-10" href="./jmlr-2010-Bayesian_Learning_in_Sparse_Graphical_Factor_Models_via_Variational_Mean-Field_Annealing.html">17 jmlr-2010-Bayesian Learning in Sparse Graphical Factor Models via Variational Mean-Field Annealing</a></p>
<p>11 0.32389772 <a title="99-lsi-11" href="./jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">87 jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>12 0.31803 <a title="99-lsi-12" href="./jmlr-2010-Stochastic_Complexity_and_Generalization_Error_of_a_Restricted_Boltzmann_Machine_in_Bayesian_Estimation.html">108 jmlr-2010-Stochastic Complexity and Generalization Error of a Restricted Boltzmann Machine in Bayesian Estimation</a></p>
<p>13 0.30408606 <a title="99-lsi-13" href="./jmlr-2010-On_Learning_with_Integral_Operators.html">82 jmlr-2010-On Learning with Integral Operators</a></p>
<p>14 0.29016703 <a title="99-lsi-14" href="./jmlr-2010-On_Spectral_Learning.html">84 jmlr-2010-On Spectral Learning</a></p>
<p>15 0.28903139 <a title="99-lsi-15" href="./jmlr-2010-Gaussian_Processes_for_Machine_Learning_%28GPML%29_Toolbox.html">41 jmlr-2010-Gaussian Processes for Machine Learning (GPML) Toolbox</a></p>
<p>16 0.28367484 <a title="99-lsi-16" href="./jmlr-2010-A_Rotation_Test_to_Verify_Latent_Structure.html">6 jmlr-2010-A Rotation Test to Verify Latent Structure</a></p>
<p>17 0.26579794 <a title="99-lsi-17" href="./jmlr-2010-Rademacher_Complexities_and_Bounding_the_Excess_Risk_in_Active_Learning.html">95 jmlr-2010-Rademacher Complexities and Bounding the Excess Risk in Active Learning</a></p>
<p>18 0.26017493 <a title="99-lsi-18" href="./jmlr-2010-Generalized_Power_Method_for_Sparse_Principal_Component_Analysis.html">43 jmlr-2010-Generalized Power Method for Sparse Principal Component Analysis</a></p>
<p>19 0.25076282 <a title="99-lsi-19" href="./jmlr-2010-Learning_Translation_Invariant_Kernels_for_Classification.html">65 jmlr-2010-Learning Translation Invariant Kernels for Classification</a></p>
<p>20 0.25044498 <a title="99-lsi-20" href="./jmlr-2010-Message-passing_for_Graph-structured_Linear_Programs%3A_Proximal_Methods_and_Rounding_Schemes.html">76 jmlr-2010-Message-passing for Graph-structured Linear Programs: Proximal Methods and Rounding Schemes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.154), (13, 0.032), (22, 0.015), (46, 0.011), (62, 0.569), (65, 0.058), (71, 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78979087 <a title="99-lda-1" href="./jmlr-2010-Restricted_Eigenvalue_Properties_for_Correlated_Gaussian_Designs.html">99 jmlr-2010-Restricted Eigenvalue Properties for Correlated Gaussian Designs</a></p>
<p>2 0.71538967 <a title="99-lda-2" href="./jmlr-2010-Analysis_of_Multi-stage_Convex_Relaxation_for_Sparse_Regularization.html">12 jmlr-2010-Analysis of Multi-stage Convex Relaxation for Sparse Regularization</a></p>
<p>3 0.48473722 <a title="99-lda-3" href="./jmlr-2010-Rate_Minimaxity_of_the_Lasso_and_Dantzig_Selector_for_thelqLoss_inlrBalls.html">96 jmlr-2010-Rate Minimaxity of the Lasso and Dantzig Selector for thelqLoss inlrBalls</a></p>
<p>4 0.48256999 <a title="99-lda-4" href="./jmlr-2010-High-dimensional_Variable_Selection_with_Sparse_Random_Projections%3A_Measurement_Sparsity_and_Statistical_Efficiency.html">45 jmlr-2010-High-dimensional Variable Selection with Sparse Random Projections: Measurement Sparsity and Statistical Efficiency</a></p>
<p>5 0.42767188 <a title="99-lda-5" href="./jmlr-2010-Classification_Methods_with_Reject_Option_Based_on_Convex_Risk_Minimization.html">21 jmlr-2010-Classification Methods with Reject Option Based on Convex Risk Minimization</a></p>
<p>6 0.41105694 <a title="99-lda-6" href="./jmlr-2010-A_Fast_Hybrid_Algorithm_for_Large-Scalel1-Regularized_Logistic_Regression.html">3 jmlr-2010-A Fast Hybrid Algorithm for Large-Scalel1-Regularized Logistic Regression</a></p>
<p>7 0.39588061 <a title="99-lda-7" href="./jmlr-2010-Generalized_Power_Method_for_Sparse_Principal_Component_Analysis.html">43 jmlr-2010-Generalized Power Method for Sparse Principal Component Analysis</a></p>
<p>8 0.39312273 <a title="99-lda-8" href="./jmlr-2010-Composite_Binary_Losses.html">25 jmlr-2010-Composite Binary Losses</a></p>
<p>9 0.3879776 <a title="99-lda-9" href="./jmlr-2010-Matrix_Completion_from__Noisy_Entries.html">72 jmlr-2010-Matrix Completion from  Noisy Entries</a></p>
<p>10 0.38548726 <a title="99-lda-10" href="./jmlr-2010-Rademacher_Complexities_and_Bounding_the_Excess_Risk_in_Active_Learning.html">95 jmlr-2010-Rademacher Complexities and Bounding the Excess Risk in Active Learning</a></p>
<p>11 0.38058168 <a title="99-lda-11" href="./jmlr-2010-On_the_Rate_of_Convergence_of_the_Bagged_Nearest_Neighbor_Estimate.html">86 jmlr-2010-On the Rate of Convergence of the Bagged Nearest Neighbor Estimate</a></p>
<p>12 0.38041285 <a title="99-lda-12" href="./jmlr-2010-Dual_Averaging_Methods_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">31 jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</a></p>
<p>13 0.37698665 <a title="99-lda-13" href="./jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">97 jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>14 0.37604621 <a title="99-lda-14" href="./jmlr-2010-Linear_Algorithms_for_Online_Multitask_Classification.html">66 jmlr-2010-Linear Algorithms for Online Multitask Classification</a></p>
<p>15 0.37543359 <a title="99-lda-15" href="./jmlr-2010-SFO%3A_A_Toolbox_for_Submodular_Function_Optimization.html">100 jmlr-2010-SFO: A Toolbox for Submodular Function Optimization</a></p>
<p>16 0.37505674 <a title="99-lda-16" href="./jmlr-2010-Learnability%2C_Stability_and_Uniform_Convergence.html">60 jmlr-2010-Learnability, Stability and Uniform Convergence</a></p>
<p>17 0.37472463 <a title="99-lda-17" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>18 0.37390524 <a title="99-lda-18" href="./jmlr-2010-On_Learning_with_Integral_Operators.html">82 jmlr-2010-On Learning with Integral Operators</a></p>
<p>19 0.3732568 <a title="99-lda-19" href="./jmlr-2010-Message-passing_for_Graph-structured_Linear_Programs%3A_Proximal_Methods_and_Rounding_Schemes.html">76 jmlr-2010-Message-passing for Graph-structured Linear Programs: Proximal Methods and Rounding Schemes</a></p>
<p>20 0.37265044 <a title="99-lda-20" href="./jmlr-2010-Learning_Translation_Invariant_Kernels_for_Classification.html">65 jmlr-2010-Learning Translation Invariant Kernels for Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
