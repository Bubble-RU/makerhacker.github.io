<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>31 jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="../home/jmlr2010_home.html">jmlr2010</a> <a title="jmlr-2010-31" href="#">jmlr2010-31</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>31 jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</h1>
<br/><p>Source: <a title="jmlr-2010-31-pdf" href="http://jmlr.org/papers/volume11/xiao10a/xiao10a.pdf">pdf</a></p><p>Author: Lin Xiao</p><p>Abstract: We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as ℓ1 -norm for promoting sparsity. We develop extensions of Nesterov’s dual averaging method, that can exploit the regularization structure in an online setting. At each iteration of these methods, the learning variables are adjusted by solving a simple minimization problem that involves the running average of all past subgradients of the loss function and the whole regularization term, not just its subgradient. In the case of ℓ1 -regularization, our method is particularly effective in obtaining sparse solutions. We show that these methods achieve the optimal convergence rates or regret bounds that are standard in the literature on stochastic and online convex optimization. For stochastic learning problems in which the loss functions have Lipschitz continuous gradients, we also present an accelerated version of the dual averaging method. Keywords: stochastic learning, online optimization, ℓ1 -regularization, structural convex optimization, dual averaging methods, accelerated gradient methods</p><p>Reference: <a title="jmlr-2010-31-reference" href="../jmlr2010_reference/jmlr-2010-Dual_Averaging_Methods_for_Regularized_Stochastic_Learning_and_Online_Optimization_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wt', 0.523), ('rda', 0.486), ('vt', 0.248), ('gt', 0.228), ('tg', 0.213), ('lnt', 0.172), ('regret', 0.169), ('dom', 0.145), ('iao', 0.137), ('rt', 0.136), ('sgd', 0.129), ('fd', 0.126), ('nnzs', 0.124), ('ual', 0.118), ('subgrady', 0.116), ('nesterov', 0.102), ('st', 0.095), ('convex', 0.083), ('qt', 0.083), ('ut', 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999887 <a title="31-tfidf-1" href="./jmlr-2010-Dual_Averaging_Methods_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">31 jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</a></p>
<p>Author: Lin Xiao</p><p>Abstract: We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as ℓ1 -norm for promoting sparsity. We develop extensions of Nesterov’s dual averaging method, that can exploit the regularization structure in an online setting. At each iteration of these methods, the learning variables are adjusted by solving a simple minimization problem that involves the running average of all past subgradients of the loss function and the whole regularization term, not just its subgradient. In the case of ℓ1 -regularization, our method is particularly effective in obtaining sparse solutions. We show that these methods achieve the optimal convergence rates or regret bounds that are standard in the literature on stochastic and online convex optimization. For stochastic learning problems in which the loss functions have Lipschitz continuous gradients, we also present an accelerated version of the dual averaging method. Keywords: stochastic learning, online optimization, ℓ1 -regularization, structural convex optimization, dual averaging methods, accelerated gradient methods</p><p>2 0.33954659 <a title="31-tfidf-2" href="./jmlr-2010-Bundle_Methods_for_Regularized_Risk_Minimization.html">18 jmlr-2010-Bundle Methods for Regularized Risk Minimization</a></p>
<p>Author: Choon Hui Teo, S.V.N. Vishwanthan, Alex J. Smola, Quoc V. Le</p><p>Abstract: A wide variety of machine learning problems can be described as minimizing a regularized risk functional, with different algorithms using different notions of risk and different regularizers. Examples include linear Support Vector Machines (SVMs), Gaussian Processes, Logistic Regression, Conditional Random Fields (CRFs), and Lasso amongst others. This paper describes the theory and implementation of a scalable and modular convex solver which solves all these estimation problems. It can be parallelized on a cluster of workstations, allows for data-locality, and can deal with regularizers such as L1 and L2 penalties. In addition to the uniﬁed framework we present tight convergence bounds, which show that our algorithm converges in O(1/ε) steps to ε precision for general convex problems and in O(log(1/ε)) steps for continuously differentiable problems. We demonstrate the performance of our general purpose solver on a variety of publicly available data sets. Keywords: optimization, subgradient methods, cutting plane method, bundle methods, regularized risk minimization, parallel optimization ∗. Also at Canberra Research Laboratory, NICTA. c 2010 Choon Hui Teo, S.V. N. Vishwanthan, Alex J. Smola and Quoc V. Le. T EO , V ISHWANATHAN , S MOLA AND L E</p><p>3 0.2326037 <a title="31-tfidf-3" href="./jmlr-2010-A_Quasi-Newton_Approach_to_Nonsmooth_Convex_Optimization_Problems_in_Machine_Learning.html">5 jmlr-2010-A Quasi-Newton Approach to Nonsmooth Convex Optimization Problems in Machine Learning</a></p>
<p>Author: Jin Yu, S.V.N. Vishwanathan, Simon Güunter, Nicol N. Schraudolph</p><p>Abstract: We extend the well-known BFGS quasi-Newton method and its memory-limited variant LBFGS to the optimization of nonsmooth convex objectives. This is done in a rigorous fashion by generalizing three components of BFGS to subdifferentials: the local quadratic model, the identiﬁcation of a descent direction, and the Wolfe line search conditions. We prove that under some technical conditions, the resulting subBFGS algorithm is globally convergent in objective function value. We apply its memory-limited variant (subLBFGS) to L2 -regularized risk minimization with the binary hinge loss. To extend our algorithm to the multiclass and multilabel settings, we develop a new, efﬁcient, exact line search algorithm. We prove its worst-case time complexity bounds, and show that our line search can also be used to extend a recently developed bundle method to the multiclass and multilabel settings. We also apply the direction-ﬁnding component of our algorithm to L1 -regularized risk minimization with logistic loss. In all these contexts our methods perform comparable to or better than specialized state-of-the-art solvers on a number of publicly available data sets. An open source implementation of our algorithms is freely available. Keywords: BFGS, variable metric methods, Wolfe conditions, subgradient, risk minimization, hinge loss, multiclass, multilabel, bundle methods, BMRM, OCAS, OWL-QN</p><p>4 0.11585613 <a title="31-tfidf-4" href="./jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">97 jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>Author: Jean-Yves Audibert, Sébastien Bubeck</p><p>Abstract: This work deals with four classical prediction settings, namely full information, bandit, label efﬁcient and bandit label efﬁcient as well as four different notions of regret: pseudo-regret, expected regret, high probability regret and tracking the best expert regret. We introduce a new forecaster, INF (Implicitly Normalized Forecaster) based on an arbitrary function ψ for which we propose a uniﬁed γ analysis of its pseudo-regret in the four games we consider. In particular, for ψ(x) = exp(ηx) + K , INF reduces to the classical exponentially weighted average forecaster and our analysis of the pseudo-regret recovers known results while for the expected regret we slightly tighten the bounds. γ η q On the other hand with ψ(x) = −x + K , which deﬁnes a new forecaster, we are able to remove the extraneous logarithmic factor in the pseudo-regret bounds for bandits games, and thus ﬁll in a long open gap in the characterization of the minimax rate for the pseudo-regret in the bandit game. We also provide high probability bounds depending on the cumulative reward of the optimal action. Finally, we consider the stochastic bandit game, and prove that an appropriate modiﬁcation of the upper conﬁdence bound policy UCB1 (Auer et al., 2002a) achieves the distribution-free optimal rate while still having a distribution-dependent rate logarithmic in the number of plays. Keywords: Bandits (adversarial and stochastic), regret bound, minimax rate, label efﬁcient, upper conﬁdence bound (UCB) policy, online learning, prediction with limited feedback.</p><p>5 0.10785734 <a title="31-tfidf-5" href="./jmlr-2010-Erratum%3A_SGDQN_is_Less_Careful_than_Expected.html">34 jmlr-2010-Erratum: SGDQN is Less Careful than Expected</a></p>
<p>Author: Antoine Bordes, Léon Bottou, Patrick Gallinari, Jonathan Chang, S. Alex Smith</p><p>Abstract: The SGD-QN algorithm described in Bordes et al. (2009) contains a subtle ﬂaw that prevents it from reaching its design goals. Yet the ﬂawed SGD-QN algorithm has worked well enough to be a winner of the ﬁrst Pascal Large Scale Learning Challenge (Sonnenburg et al., 2008). This document clariﬁes the situation, proposes a corrected algorithm, and evaluates its performance. Keywords: stochastic gradient descent, support vector machine, conditional random ﬁelds</p><p>6 0.10122815 <a title="31-tfidf-6" href="./jmlr-2010-On_the_Foundations_of_Noise-free_Selective_Classification.html">85 jmlr-2010-On the Foundations of Noise-free Selective Classification</a></p>
<p>7 0.080721818 <a title="31-tfidf-7" href="./jmlr-2010-Iterative_Scaling_and_Coordinate_Descent_Methods_for_Maximum_Entropy_Models.html">57 jmlr-2010-Iterative Scaling and Coordinate Descent Methods for Maximum Entropy Models</a></p>
<p>8 0.07903666 <a title="31-tfidf-8" href="./jmlr-2010-Near-optimal_Regret_Bounds_for_Reinforcement_Learning.html">79 jmlr-2010-Near-optimal Regret Bounds for Reinforcement Learning</a></p>
<p>9 0.068637088 <a title="31-tfidf-9" href="./jmlr-2010-Practical_Approaches_to_Principal_Component_Analysis_in_the_Presence_of_Missing_Values.html">92 jmlr-2010-Practical Approaches to Principal Component Analysis in the Presence of Missing Values</a></p>
<p>10 0.064542748 <a title="31-tfidf-10" href="./jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">87 jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>11 0.063043013 <a title="31-tfidf-11" href="./jmlr-2010-On-Line_Sequential_Bin_Packing.html">80 jmlr-2010-On-Line Sequential Bin Packing</a></p>
<p>12 0.06097579 <a title="31-tfidf-12" href="./jmlr-2010-On_Spectral_Learning.html">84 jmlr-2010-On Spectral Learning</a></p>
<p>13 0.060761761 <a title="31-tfidf-13" href="./jmlr-2010-Composite_Binary_Losses.html">25 jmlr-2010-Composite Binary Losses</a></p>
<p>14 0.060424633 <a title="31-tfidf-14" href="./jmlr-2010-A_Generalized_Path_Integral_Control_Approach_to_Reinforcement_Learning.html">4 jmlr-2010-A Generalized Path Integral Control Approach to Reinforcement Learning</a></p>
<p>15 0.059923891 <a title="31-tfidf-15" href="./jmlr-2010-Learning_Gradients%3A_Predictive_Models_that_Infer_Geometry_and_Statistical_Dependence.html">62 jmlr-2010-Learning Gradients: Predictive Models that Infer Geometry and Statistical Dependence</a></p>
<p>16 0.059328932 <a title="31-tfidf-16" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>17 0.052534781 <a title="31-tfidf-17" href="./jmlr-2010-A_Comparison_of_Optimization_Methods_and_Software_for_Large-scale_L1-regularized_Linear_Classification.html">1 jmlr-2010-A Comparison of Optimization Methods and Software for Large-scale L1-regularized Linear Classification</a></p>
<p>18 0.052333474 <a title="31-tfidf-18" href="./jmlr-2010-Analysis_of_Multi-stage_Convex_Relaxation_for_Sparse_Regularization.html">12 jmlr-2010-Analysis of Multi-stage Convex Relaxation for Sparse Regularization</a></p>
<p>19 0.051938057 <a title="31-tfidf-19" href="./jmlr-2010-Training_and_Testing_Low-degree_Polynomial_Data_Mappings_via_Linear_SVM.html">112 jmlr-2010-Training and Testing Low-degree Polynomial Data Mappings via Linear SVM</a></p>
<p>20 0.051830482 <a title="31-tfidf-20" href="./jmlr-2010-Message-passing_for_Graph-structured_Linear_Programs%3A_Proximal_Methods_and_Rounding_Schemes.html">76 jmlr-2010-Message-passing for Graph-structured Linear Programs: Proximal Methods and Rounding Schemes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.205), (1, 0.272), (2, -0.145), (3, -0.021), (4, -0.502), (5, 0.223), (6, -0.047), (7, -0.034), (8, -0.001), (9, -0.021), (10, 0.097), (11, -0.082), (12, -0.077), (13, -0.025), (14, -0.003), (15, 0.021), (16, 0.083), (17, -0.077), (18, -0.006), (19, 0.009), (20, -0.022), (21, -0.008), (22, 0.067), (23, 0.004), (24, 0.038), (25, 0.034), (26, 0.018), (27, -0.061), (28, -0.041), (29, 0.041), (30, -0.012), (31, 0.027), (32, -0.002), (33, -0.078), (34, 0.034), (35, -0.007), (36, -0.064), (37, 0.001), (38, -0.039), (39, -0.017), (40, -0.011), (41, 0.002), (42, -0.061), (43, 0.041), (44, 0.018), (45, 0.012), (46, -0.001), (47, 0.009), (48, 0.093), (49, -0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95190746 <a title="31-lsi-1" href="./jmlr-2010-Dual_Averaging_Methods_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">31 jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</a></p>
<p>Author: Lin Xiao</p><p>Abstract: We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as ℓ1 -norm for promoting sparsity. We develop extensions of Nesterov’s dual averaging method, that can exploit the regularization structure in an online setting. At each iteration of these methods, the learning variables are adjusted by solving a simple minimization problem that involves the running average of all past subgradients of the loss function and the whole regularization term, not just its subgradient. In the case of ℓ1 -regularization, our method is particularly effective in obtaining sparse solutions. We show that these methods achieve the optimal convergence rates or regret bounds that are standard in the literature on stochastic and online convex optimization. For stochastic learning problems in which the loss functions have Lipschitz continuous gradients, we also present an accelerated version of the dual averaging method. Keywords: stochastic learning, online optimization, ℓ1 -regularization, structural convex optimization, dual averaging methods, accelerated gradient methods</p><p>2 0.82663667 <a title="31-lsi-2" href="./jmlr-2010-Bundle_Methods_for_Regularized_Risk_Minimization.html">18 jmlr-2010-Bundle Methods for Regularized Risk Minimization</a></p>
<p>Author: Choon Hui Teo, S.V.N. Vishwanthan, Alex J. Smola, Quoc V. Le</p><p>Abstract: A wide variety of machine learning problems can be described as minimizing a regularized risk functional, with different algorithms using different notions of risk and different regularizers. Examples include linear Support Vector Machines (SVMs), Gaussian Processes, Logistic Regression, Conditional Random Fields (CRFs), and Lasso amongst others. This paper describes the theory and implementation of a scalable and modular convex solver which solves all these estimation problems. It can be parallelized on a cluster of workstations, allows for data-locality, and can deal with regularizers such as L1 and L2 penalties. In addition to the uniﬁed framework we present tight convergence bounds, which show that our algorithm converges in O(1/ε) steps to ε precision for general convex problems and in O(log(1/ε)) steps for continuously differentiable problems. We demonstrate the performance of our general purpose solver on a variety of publicly available data sets. Keywords: optimization, subgradient methods, cutting plane method, bundle methods, regularized risk minimization, parallel optimization ∗. Also at Canberra Research Laboratory, NICTA. c 2010 Choon Hui Teo, S.V. N. Vishwanthan, Alex J. Smola and Quoc V. Le. T EO , V ISHWANATHAN , S MOLA AND L E</p><p>3 0.81607717 <a title="31-lsi-3" href="./jmlr-2010-A_Quasi-Newton_Approach_to_Nonsmooth_Convex_Optimization_Problems_in_Machine_Learning.html">5 jmlr-2010-A Quasi-Newton Approach to Nonsmooth Convex Optimization Problems in Machine Learning</a></p>
<p>Author: Jin Yu, S.V.N. Vishwanathan, Simon Güunter, Nicol N. Schraudolph</p><p>Abstract: We extend the well-known BFGS quasi-Newton method and its memory-limited variant LBFGS to the optimization of nonsmooth convex objectives. This is done in a rigorous fashion by generalizing three components of BFGS to subdifferentials: the local quadratic model, the identiﬁcation of a descent direction, and the Wolfe line search conditions. We prove that under some technical conditions, the resulting subBFGS algorithm is globally convergent in objective function value. We apply its memory-limited variant (subLBFGS) to L2 -regularized risk minimization with the binary hinge loss. To extend our algorithm to the multiclass and multilabel settings, we develop a new, efﬁcient, exact line search algorithm. We prove its worst-case time complexity bounds, and show that our line search can also be used to extend a recently developed bundle method to the multiclass and multilabel settings. We also apply the direction-ﬁnding component of our algorithm to L1 -regularized risk minimization with logistic loss. In all these contexts our methods perform comparable to or better than specialized state-of-the-art solvers on a number of publicly available data sets. An open source implementation of our algorithms is freely available. Keywords: BFGS, variable metric methods, Wolfe conditions, subgradient, risk minimization, hinge loss, multiclass, multilabel, bundle methods, BMRM, OCAS, OWL-QN</p><p>4 0.6796037 <a title="31-lsi-4" href="./jmlr-2010-Erratum%3A_SGDQN_is_Less_Careful_than_Expected.html">34 jmlr-2010-Erratum: SGDQN is Less Careful than Expected</a></p>
<p>Author: Antoine Bordes, Léon Bottou, Patrick Gallinari, Jonathan Chang, S. Alex Smith</p><p>Abstract: The SGD-QN algorithm described in Bordes et al. (2009) contains a subtle ﬂaw that prevents it from reaching its design goals. Yet the ﬂawed SGD-QN algorithm has worked well enough to be a winner of the ﬁrst Pascal Large Scale Learning Challenge (Sonnenburg et al., 2008). This document clariﬁes the situation, proposes a corrected algorithm, and evaluates its performance. Keywords: stochastic gradient descent, support vector machine, conditional random ﬁelds</p><p>5 0.36352453 <a title="31-lsi-5" href="./jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">97 jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>Author: Jean-Yves Audibert, Sébastien Bubeck</p><p>Abstract: This work deals with four classical prediction settings, namely full information, bandit, label efﬁcient and bandit label efﬁcient as well as four different notions of regret: pseudo-regret, expected regret, high probability regret and tracking the best expert regret. We introduce a new forecaster, INF (Implicitly Normalized Forecaster) based on an arbitrary function ψ for which we propose a uniﬁed γ analysis of its pseudo-regret in the four games we consider. In particular, for ψ(x) = exp(ηx) + K , INF reduces to the classical exponentially weighted average forecaster and our analysis of the pseudo-regret recovers known results while for the expected regret we slightly tighten the bounds. γ η q On the other hand with ψ(x) = −x + K , which deﬁnes a new forecaster, we are able to remove the extraneous logarithmic factor in the pseudo-regret bounds for bandits games, and thus ﬁll in a long open gap in the characterization of the minimax rate for the pseudo-regret in the bandit game. We also provide high probability bounds depending on the cumulative reward of the optimal action. Finally, we consider the stochastic bandit game, and prove that an appropriate modiﬁcation of the upper conﬁdence bound policy UCB1 (Auer et al., 2002a) achieves the distribution-free optimal rate while still having a distribution-dependent rate logarithmic in the number of plays. Keywords: Bandits (adversarial and stochastic), regret bound, minimax rate, label efﬁcient, upper conﬁdence bound (UCB) policy, online learning, prediction with limited feedback.</p><p>6 0.30206689 <a title="31-lsi-6" href="./jmlr-2010-On_the_Foundations_of_Noise-free_Selective_Classification.html">85 jmlr-2010-On the Foundations of Noise-free Selective Classification</a></p>
<p>7 0.2684508 <a title="31-lsi-7" href="./jmlr-2010-Iterative_Scaling_and_Coordinate_Descent_Methods_for_Maximum_Entropy_Models.html">57 jmlr-2010-Iterative Scaling and Coordinate Descent Methods for Maximum Entropy Models</a></p>
<p>8 0.25398272 <a title="31-lsi-8" href="./jmlr-2010-Practical_Approaches_to_Principal_Component_Analysis_in_the_Presence_of_Missing_Values.html">92 jmlr-2010-Practical Approaches to Principal Component Analysis in the Presence of Missing Values</a></p>
<p>9 0.23223187 <a title="31-lsi-9" href="./jmlr-2010-Near-optimal_Regret_Bounds_for_Reinforcement_Learning.html">79 jmlr-2010-Near-optimal Regret Bounds for Reinforcement Learning</a></p>
<p>10 0.2160698 <a title="31-lsi-10" href="./jmlr-2010-A_Fast_Hybrid_Algorithm_for_Large-Scalel1-Regularized_Logistic_Regression.html">3 jmlr-2010-A Fast Hybrid Algorithm for Large-Scalel1-Regularized Logistic Regression</a></p>
<p>11 0.21435589 <a title="31-lsi-11" href="./jmlr-2010-A_Comparison_of_Optimization_Methods_and_Software_for_Large-scale_L1-regularized_Linear_Classification.html">1 jmlr-2010-A Comparison of Optimization Methods and Software for Large-scale L1-regularized Linear Classification</a></p>
<p>12 0.20980868 <a title="31-lsi-12" href="./jmlr-2010-A_Generalized_Path_Integral_Control_Approach_to_Reinforcement_Learning.html">4 jmlr-2010-A Generalized Path Integral Control Approach to Reinforcement Learning</a></p>
<p>13 0.19695473 <a title="31-lsi-13" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>14 0.19337262 <a title="31-lsi-14" href="./jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">87 jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>15 0.18465963 <a title="31-lsi-15" href="./jmlr-2010-Analysis_of_Multi-stage_Convex_Relaxation_for_Sparse_Regularization.html">12 jmlr-2010-Analysis of Multi-stage Convex Relaxation for Sparse Regularization</a></p>
<p>16 0.1841086 <a title="31-lsi-16" href="./jmlr-2010-On-Line_Sequential_Bin_Packing.html">80 jmlr-2010-On-Line Sequential Bin Packing</a></p>
<p>17 0.18101181 <a title="31-lsi-17" href="./jmlr-2010-Regularized_Discriminant_Analysis%2C_Ridge_Regression_and_Beyond.html">98 jmlr-2010-Regularized Discriminant Analysis, Ridge Regression and Beyond</a></p>
<p>18 0.17849095 <a title="31-lsi-18" href="./jmlr-2010-Generalized_Power_Method_for_Sparse_Principal_Component_Analysis.html">43 jmlr-2010-Generalized Power Method for Sparse Principal Component Analysis</a></p>
<p>19 0.17605719 <a title="31-lsi-19" href="./jmlr-2010-On_Spectral_Learning.html">84 jmlr-2010-On Spectral Learning</a></p>
<p>20 0.16942993 <a title="31-lsi-20" href="./jmlr-2010-Learning_Gradients%3A_Predictive_Models_that_Infer_Geometry_and_Statistical_Dependence.html">62 jmlr-2010-Learning Gradients: Predictive Models that Infer Geometry and Statistical Dependence</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.094), (13, 0.039), (22, 0.028), (49, 0.016), (57, 0.498), (62, 0.046), (65, 0.07), (71, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.74604863 <a title="31-lda-1" href="./jmlr-2010-Stochastic_Complexity_and_Generalization_Error_of_a_Restricted_Boltzmann_Machine_in_Bayesian_Estimation.html">108 jmlr-2010-Stochastic Complexity and Generalization Error of a Restricted Boltzmann Machine in Bayesian Estimation</a></p>
<p>Author: Miki Aoyagi</p><p>Abstract: In this paper, we consider the asymptotic form of the generalization error for the restricted Boltzmann machine in Bayesian estimation. It has been shown that obtaining the maximum pole of zeta functions is related to the asymptotic form of the generalization error for hierarchical learning models (Watanabe, 2001a,b). The zeta function is deﬁned by using a Kullback function. We use two methods to obtain the maximum pole: a new eigenvalue analysis method and a recursive blowing up process. We show that these methods are effective for obtaining the asymptotic form of the generalization error of hierarchical learning models. Keywords: Boltzmann machine, non-regular learning machine, resolution of singularities, zeta function</p><p>2 0.6734131 <a title="31-lda-2" href="./jmlr-2010-Consistent_Nonparametric_Tests_of_Independence.html">27 jmlr-2010-Consistent Nonparametric Tests of Independence</a></p>
<p>Author: Arthur Gretton, László Györfi</p><p>Abstract: Three simple and explicit procedures for testing the independence of two multi-dimensional random variables are described. Two of the associated test statistics (L1 , log-likelihood) are deﬁned when the empirical distribution of the variables is restricted to ﬁnite partitions. A third test statistic is deﬁned as a kernel-based independence measure. Two kinds of tests are provided. Distributionfree strong consistent tests are derived on the basis of large deviation bounds on the test statistics: these tests make almost surely no Type I or Type II error after a random sample size. Asymptotically α-level tests are obtained from the limiting distribution of the test statistics. For the latter tests, the Type I error converges to a ﬁxed non-zero value α, and the Type II error drops to zero, for increasing sample size. All tests reject the null hypothesis of independence if the test statistics become large. The performance of the tests is evaluated experimentally on benchmark data. Keywords: hypothesis test, independence, L1, log-likelihood, kernel methods, distribution-free consistent test</p><p>same-paper 3 0.66006023 <a title="31-lda-3" href="./jmlr-2010-Dual_Averaging_Methods_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">31 jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</a></p>
<p>Author: Lin Xiao</p><p>Abstract: We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as ℓ1 -norm for promoting sparsity. We develop extensions of Nesterov’s dual averaging method, that can exploit the regularization structure in an online setting. At each iteration of these methods, the learning variables are adjusted by solving a simple minimization problem that involves the running average of all past subgradients of the loss function and the whole regularization term, not just its subgradient. In the case of ℓ1 -regularization, our method is particularly effective in obtaining sparse solutions. We show that these methods achieve the optimal convergence rates or regret bounds that are standard in the literature on stochastic and online convex optimization. For stochastic learning problems in which the loss functions have Lipschitz continuous gradients, we also present an accelerated version of the dual averaging method. Keywords: stochastic learning, online optimization, ℓ1 -regularization, structural convex optimization, dual averaging methods, accelerated gradient methods</p><p>4 0.47022066 <a title="31-lda-4" href="./jmlr-2010-PyBrain.html">93 jmlr-2010-PyBrain</a></p>
<p>Author: Tom Schaul, Justin Bayer, Daan Wierstra, Yi Sun, Martin Felder, Frank Sehnke, Thomas Rückstieß, Jürgen Schmidhuber</p><p>Abstract: PyBrain is a versatile machine learning library for Python. Its goal is to provide ﬂexible, easyto-use yet still powerful algorithms for machine learning tasks, including a variety of predeﬁned environments and benchmarks to test and compare algorithms. Implemented algorithms include Long Short-Term Memory (LSTM), policy gradient methods, (multidimensional) recurrent neural networks and deep belief networks. Keywords: Python, neural networks, reinforcement learning, optimization</p><p>5 0.34949163 <a title="31-lda-5" href="./jmlr-2010-On_Learning_with_Integral_Operators.html">82 jmlr-2010-On Learning with Integral Operators</a></p>
<p>Author: Lorenzo Rosasco, Mikhail Belkin, Ernesto De Vito</p><p>Abstract: A large number of learning algorithms, for example, spectral clustering, kernel Principal Components Analysis and many manifold methods are based on estimating eigenvalues and eigenfunctions of operators deﬁned by a similarity function or a kernel, given empirical data. Thus for the analysis of algorithms, it is an important problem to be able to assess the quality of such approximations. The contribution of our paper is two-fold: 1. We use a technique based on a concentration inequality for Hilbert spaces to provide new much simpliﬁed proofs for a number of results in spectral approximation. 2. Using these methods we provide several new results for estimating spectral properties of the graph Laplacian operator extending and strengthening results from von Luxburg et al. (2008). Keywords: spectral convergence, empirical operators, learning integral operators, perturbation methods</p><p>6 0.32734895 <a title="31-lda-6" href="./jmlr-2010-A_Generalized_Path_Integral_Control_Approach_to_Reinforcement_Learning.html">4 jmlr-2010-A Generalized Path Integral Control Approach to Reinforcement Learning</a></p>
<p>7 0.31351197 <a title="31-lda-7" href="./jmlr-2010-Erratum%3A_SGDQN_is_Less_Careful_than_Expected.html">34 jmlr-2010-Erratum: SGDQN is Less Careful than Expected</a></p>
<p>8 0.31298089 <a title="31-lda-8" href="./jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">97 jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>9 0.31015396 <a title="31-lda-9" href="./jmlr-2010-On_Finding_Predictors_for_Arbitrary_Families_of_Processes.html">81 jmlr-2010-On Finding Predictors for Arbitrary Families of Processes</a></p>
<p>10 0.30375534 <a title="31-lda-10" href="./jmlr-2010-Stochastic_Composite_Likelihood.html">109 jmlr-2010-Stochastic Composite Likelihood</a></p>
<p>11 0.30362043 <a title="31-lda-11" href="./jmlr-2010-Bundle_Methods_for_Regularized_Risk_Minimization.html">18 jmlr-2010-Bundle Methods for Regularized Risk Minimization</a></p>
<p>12 0.29886806 <a title="31-lda-12" href="./jmlr-2010-Lp-Nested_Symmetric_Distributions.html">69 jmlr-2010-Lp-Nested Symmetric Distributions</a></p>
<p>13 0.29556465 <a title="31-lda-13" href="./jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">111 jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>14 0.29442009 <a title="31-lda-14" href="./jmlr-2010-On_the_Foundations_of_Noise-free_Selective_Classification.html">85 jmlr-2010-On the Foundations of Noise-free Selective Classification</a></p>
<p>15 0.29321295 <a title="31-lda-15" href="./jmlr-2010-A_Quasi-Newton_Approach_to_Nonsmooth_Convex_Optimization_Problems_in_Machine_Learning.html">5 jmlr-2010-A Quasi-Newton Approach to Nonsmooth Convex Optimization Problems in Machine Learning</a></p>
<p>16 0.29073298 <a title="31-lda-16" href="./jmlr-2010-Information_Retrieval_Perspective_to_Nonlinear_Dimensionality_Reduction_for_Data_Visualization.html">54 jmlr-2010-Information Retrieval Perspective to Nonlinear Dimensionality Reduction for Data Visualization</a></p>
<p>17 0.28933388 <a title="31-lda-17" href="./jmlr-2010-Matrix_Completion_from__Noisy_Entries.html">72 jmlr-2010-Matrix Completion from  Noisy Entries</a></p>
<p>18 0.28869316 <a title="31-lda-18" href="./jmlr-2010-Spectral_Regularization_Algorithms_for_Learning_Large_Incomplete_Matrices.html">105 jmlr-2010-Spectral Regularization Algorithms for Learning Large Incomplete Matrices</a></p>
<p>19 0.2809512 <a title="31-lda-19" href="./jmlr-2010-Asymptotic_Equivalence_of_Bayes_Cross_Validation_and_Widely_Applicable_Information_Criterion_in_Singular_Learning_Theory.html">16 jmlr-2010-Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory</a></p>
<p>20 0.27726781 <a title="31-lda-20" href="./jmlr-2010-libDAI%3A_A_Free_and_Open_Source_C%2B%2B_Library_for_Discrete_Approximate_Inference_in_Graphical_Models.html">118 jmlr-2010-libDAI: A Free and Open Source C++ Library for Discrete Approximate Inference in Graphical Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
