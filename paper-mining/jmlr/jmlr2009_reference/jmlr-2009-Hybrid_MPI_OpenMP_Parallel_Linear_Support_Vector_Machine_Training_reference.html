<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-39" href="../jmlr2009/jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">jmlr2009-39</a> <a title="jmlr-2009-39-reference" href="#">jmlr2009-39-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</h1>
<br/><p>Source: <a title="jmlr-2009-39-pdf" href="http://jmlr.org/papers/volume10/woodsend09a/woodsend09a.pdf">pdf</a></p><p>Author: Kristian Woodsend, Jacek Gondzio</p><p>Abstract: Support vector machines are a powerful machine learning technology, but the training process involves a dense quadratic optimization problem and is computationally challenging. A parallel implementation of linear Support Vector Machine training has been developed, using a combination of MPI and OpenMP. Using an interior point method for the optimization and a reformulation that avoids the dense Hessian matrix, the structure of the augmented system matrix is exploited to partition data and computations amongst parallel processors efﬁciently. The new implementation has been applied to solve problems from the PASCAL Challenge on Large-scale Learning. We show that our approach is competitive, and is able to solve problems in the Challenge many times faster than other parallel approaches. We also demonstrate that the hybrid version performs more efﬁciently than the version using pure MPI. Keywords: linear SVM training, hybrid parallelism, largescale learning, interior point method</p><br/>
<h2>reference text</h2><p>Antoine Bordes, L´ on Bottou, Patrick Gallinari, and Jason Weston. Solving multiclass support e vector machines with LaRank. In Zoubin Ghahramani, editor, Proceedings of the 24th International Machine Learning Conference, pages 89–96, Corvallis, Oregon, 2007. OmniPress. URL http://leon.bottou.org/papers/bordes-2007. Alfredo Buttari, Julien Langou, Jakub Kurzak, and Jack Dongarra. A class of parallel tiled linear algebra algorithms for multicore architectures. Parallel Computing, 35(1):38–53, January 2009. Edward Chang, Kaihua Zhu, Hao Wang, Hongjie Bai, Jian Li, Zhihuan Qiu, and Hang Cui. Parallelizing support vector machines on distributed computers. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 257–264, Cambridge, MA, 2008. MIT Press. Ronan Collobert, Samy Bengio, and Yoshua Bengio. A parallel mixture of SVMs for very large scale problems. Neural Computation, 14(5):1105–1114, 2002. Jian-xiong Dong, Adam Krzyzak, and Ching Suen. A fast parallel optimization for training support vector machine. In P. Perner and A. Rosenfeld, editors, Proceedings of 3rd International Conference on Machine Learning and Data Mining, pages 96–105, Leipzig, Germany, 2003. Springer Lecture Notes in Artiﬁcial Intelligence. Igor Durdanovic, Eric Cosatto, and Hans-Peter Graf. Large scale parallel SVM implementation. In L´ on Bottou, Olivier Chapelle, Dennis DeCoste, and Jason Weston, editors, Large Scale Kernel e Machines, chapter 5, pages 105–38. MIT Press, 2007. Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. LIBLINEAR: A library for large linear classiﬁcation. Journal of Machine Learning Research, 9:1871–1874, 2008. Michael Ferris and Todd Munson. Interior point methods for massive support vector machines. SIAM Journal on Optimization, 13(3):783–804, 2003. Shai Fine and Katya Scheinberg. Efﬁcient SVM training using low-rank kernel representations. Journal of Machine Learning Research, 2:243–264, 2002. Glenn Fung and Olvi L. Mangasarian. Proximal support vector machine classiﬁers. In F. Provost and R. Srikant, editors, Proceedings KDD-2001: Knowledge Discovery and Data Mining, August 26-29, 2001, San Francisco, CA, pages 77–86, New York, 2001. Asscociation for Computing Machinery. Jacek Gondzio and Andreas Grothey. Parallel interior point solver for structured quadratic programs: Application to ﬁnancial planning problems. Annals of Operations Research, 152(1): 319–339, 2007. 1951  W OODSEND AND G ONDZIO  Jacek Gondzio and Robert Sarkissian. Parallel interior point solver for structured linear programs. Mathematical Programming, 96(3):561–584, 2003. Kazushige Goto and Robert A. van de Geijn. Anatomy of high-performance matrix multiplication. ACM Trans. Math. Softw., 34(3):1–25, 2008. Hans Peter Graf, Eric Cosatto, L´ on Bottou, Igor Dourdanovic, and Vladimir Vapnik. Parallel e support vector machines: the Cascade SVM. In Lawrence Saul, Yair Weiss, and L´ on Bottou, e editors, Advances in Neural Information Processing Systems. MIT Press, 2005. volume 17. Jos´ R. Herrero. A Framework for Efﬁcient Execution of Matrix Computations. PhD thesis, Univere sitat Polit` cnica de Catalunya (UPC), July 2006. e Bo K˚ gstr¨ m, Per Ling, and Charles van Loan. GEMM-based level 3 BLAS: high-performance a o model implementations and performance evaluation benchmark. ACM Trans. Math. Softw., 24 (3):268–302, 1998. Glenn R. Luecke, Jae H. Yun, and Philip W. Smith. Performance of parallel cholesky factorization algorithms using blas. The Journal of Supercomputing, 6(3):315–329, December 1992. MPI-Forum. MPI: A Message-Passing Interface Standard. University of Tennessee, Knoxville, Tennessee, 1.1 edition, June 1995. URL http://www.mpi-forum.org. OpenMP Architecture Review Board. OpenMP Application Program Interface, 3.0 edition, May 2008. URL http://www.openmp.org. Edgar Osuna, Robert Freund, and Federico Girosi. An improved training algorithm for support vector machines. In J. Principe, L. Gile, N. Morgan, and E. Wilson, editors, Neural Networks for Signal Processing VII — Proceedings of the 1997 IEEE Workshop, pages 276–285. IEEE, 1997. John Platt. Fast training of support vector machines using sequential minimal optimization. In Bernhard Sch¨ lkopf, Christopher. J. C. Burges, and Alexander. J. Smola, editors, Advances in o Kernel Methods: Support Vector Learning, pages 185–208. MIT Press, 1999. Rolf Rabenseifner and Gerhard Wellein. Comparison of parallel programming models on clusters of SMP nodes. In Hans Georg Bock, Ekaterina Kostina, Hoang Xuan Phu, and Rolf Rannacher, editors, Modelling, Simulation and Optimization of Complex Processes: Proceedings of the International Conference on High Performance Scientiﬁc Computing, March 10-14, 2003, Hanoi, Vietnam, pages 409–426. Springer, 2003. Lorna Smith and Mark Bull. Development of mixed mode MPI / OpenMP applications. Scientiﬁc Programming, 2001. Soeren Sonnenburg, Vojtech Franc, Elad Yom-Tov, and Michele Sebag. PASCAL large scale learning challenge, 2008. URL http://largescale.first.fraunhofer.de/. Amund Tveit and Havard Engum. Parallelization of the incremental proximal support vector machine classiﬁer using a heap-based tree topology. Technical report, IDI, NTNU, Trondheim, 2003. 1952  H YBRID PARALLEL SVM T RAINING  Vladimir Vapnik. Statistical Learning Theory. Wiley, 1998. Kristian Woodsend and Jacek Gondzio. Exploiting separability in large-scale support vector machine training. Technical Report MS-07-002, School of Mathematics, University of Edinburgh, August 2007. Submitted for publication. Available at http://www.maths.ed.ac.uk/ ˜gondzio/reports/wgSVM.html. Stephen J. Wright. Primal-Dual Interior-Point Methods. S.I.A.M., 1997. Gaetano Zanghirati and Luca Zanni. A parallel solver for large quadratic programs in training support vector machines. Parallel Computing, 29(4):535–551, 2003. Luca Zanni, Thomas Seraﬁni, and Gaetano Zanghirati. Parallel software for training large scale support vector machines on multiprocessor systems. Journal of Machine Learning Research, 7: 1467–1492, 2006.  1953</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
