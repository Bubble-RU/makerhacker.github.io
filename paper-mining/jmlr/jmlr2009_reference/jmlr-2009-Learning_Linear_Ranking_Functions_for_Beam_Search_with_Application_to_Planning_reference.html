<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>47 jmlr-2009-Learning Linear Ranking Functions for Beam Search with Application to Planning</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-47" href="../jmlr2009/jmlr-2009-Learning_Linear_Ranking_Functions_for_Beam_Search_with_Application_to_Planning.html">jmlr2009-47</a> <a title="jmlr-2009-47-reference" href="#">jmlr2009-47-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>47 jmlr-2009-Learning Linear Ranking Functions for Beam Search with Application to Planning</h1>
<br/><p>Source: <a title="jmlr-2009-47-pdf" href="http://jmlr.org/papers/volume10/xu09c/xu09c.pdf">pdf</a></p><p>Author: Yuehua Xu, Alan Fern, Sungwook Yoon</p><p>Abstract: Beam search is commonly used to help maintain tractability in large search spaces at the expense of completeness and optimality. Here we study supervised learning of linear ranking functions for controlling beam search. The goal is to learn ranking functions that allow for beam search to perform nearly as well as unconstrained search, and hence gain computational efﬁciency without seriously sacriﬁcing optimality. In this paper, we develop theoretical aspects of this learning problem and investigate the application of this framework to learning in the context of automated planning. We ﬁrst study the computational complexity of the learning problem, showing that even for exponentially large search spaces the general consistency problem is in NP. We also identify tractable and intractable subclasses of the learning problem, giving insight into the problem structure. Next, we analyze the convergence of recently proposed and modiﬁed online learning algorithms, where we introduce several notions of problem margin that imply convergence for the various algorithms. Finally, we present empirical results in automated planning, where ranking functions are learned to guide beam search in a number of benchmark planning domains. The results show that our approach is often able to outperform an existing state-of-the-art planning heuristic as well as a recent approach to learning such heuristics. Keywords: beam search, speedup learning, automated planning, structured classiﬁcation</p><br/>
<h2>reference text</h2><p>Shivani Agarwal and Dan Roth. Learnability of bipartite ranking functions. In Proceedings of the Conference on Learning Theory, 2005. Ricardo Aler, Daniel Borrajo, and Pedro Isasi. Using genetic programming to learn and improve control knowledge. Artiﬁcial Intelligence, 141(1-2):29–56, 2002. Jos´ Luis Ambite, Craig A. Knoblock, and Steven Minton. Learning plan rewriting rules. In e Proceeding of Artiﬁcial Intelligence Planning Systems, pages 3–12, 2000. Blai Bonet and He´ tor Geffner. Planning as heuristic search: New results. In Proceedings of the c European Conference on Planning, pages 360–372, 1999. Michael Collins. Discriminative training methods for hidden markov models: Theory and experiments with the perceptron algorithm. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2002. Hal Daum´ III and Daniel Marcu. Learning as search optimization: Approximate large margin e methods for structured prediction. In Proceedings of the International Conference on Machine Learning, 2005. Tara A. Estlin and Rymond J. Mooney. Multi-strategy learning of search control for partial-order planning. In Proceedings of the Thirteenth National Conference on Artiﬁcial Intelligence, pages 843–848, 1996. Alan Fern, Sungwook Yoon, and Robert Givan. Approximate policy iteration with a policy language bias: Solving relational markov decision processes. Journal of Artiﬁcial Intelligence Research, 25:85–118, 2006. Richard E. Fikes, Peter E. Hart, and Nils J. Nilsson. Learning and executing generalized robot plans. Artiﬁcial Intelligence Journal, 3(1–3):251–288, 1972. Michael R. Garey and David S. Johnson, editors. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman and Company, New York, 1979. Klaus-Uwe Hoffgen, Hans-Ulrich Simon, and Kevin S. Van Horn. Robust trainability of single neurons. Journal of Computer and System Sciences, 50(1):114–125, 1995. Jorg Hoffmann and Bernhard Nebel. The FF planning system: Fast plan generation through heuristic search. Journal of Artiﬁcial Intelligence Research, 14:263–302, 2001. Yi-Cheng Huang, Bart Selman, and Henry Kautz. Learning declarative control rules for constraintbased planning. In Proceedings of Seventeenth International Conference on Machine Learning, pages 415–422, 2000. Rong Jin and Zoubin Ghahramani. Learning with multiple labels. In Proceedings of the Sixteenth Annual Conference on Neural Information Processing Systems, 2002. Leonid G. Khachiyan. A polynomial algorithm in linear programming. Soviet Mathematics Doklady, 20(1):191–194, 1979. 1608  L EARNING L INEAR R ANKING F UNCTIONS FOR B EAM S EARCH WITH A PPLICATION TO P LANNING  Roni Khardon. Learning action strategies for planning domains. Artiﬁcial Intelligence, 113(1-2): 125–148, 1999. Tom´ s La Rosa, Angel Garc´a Olaya, and Daniel Borrajo. Using cases utility for heuristic planning a ı improvement. In Proceedings of the Seventh International Conference on Case Based Reasoning, 2007. John Lafferty, Andrew McCallum, and Fernando Pereira. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning, pages 282–289, 2001. Mario Martin and Hector Geffner. Learning generalized policies in planning domains using concept languages. In Proceedings of Seventh International Conference on Principles of Knowledge Representation and Reasoning, 2000. Drew McDermott. PDDL- the planning domain deﬁnition language. In The 1st International Planning Competition, 1998. Steven Minton. Quantitative results concerning the utility of explanation-based learning. In Proceedings of National Conference on Artiﬁcial Intelligence, 1988. Steven Minton, editor. Machine Learning Methods for Planning. Morgan Kaufmann Publishers, 1993. Steven Minton, Jaime G. Carbonell, Craig A. Knoblock, Daniel Kuokka, Oren Etzioni, and Yolanda Gil. Explanation-based learning: A problem solving perspective. Artiﬁcial Intelligence, 40: 63–118, 1989. Xuanlong Nguyen, Subbarao Kambhampati, and Romeo S. Nigenda. Planning graph as the basis for deriving heuristics for plan synthesis by state space and CSP search. Artiﬁcial Intelligence, 135(1-2):73–123, 2002. Albert B. Novikoff. On convergence proofs on perceptrons. In Symposium on the Mathematical Theory of Automata, pages 615–622, 1962. Frank Rosenblatt. Principles of Neurodynamics. Spartan, New York, 1962. John Slaney and Sylvie Thi´ baux. Blocks world revisited. Artiﬁcial Intelligence, 125:119–153, e 2001. Ben Taskar, Carlos Guestrin, and Daphne Koller. Max-margin markov networks. In Neural Information Processing Systems Conference, 2003. Manuela M. Veloso, M. Alicia P´ rez, and Jamie G. Carbonell. Nonlinear planning with parallel e resource allocation. In Workshop on Innovative Approaches to Planning, Scheduling and Control, pages 207–212, 1991. Yuehua Xu and Alan Fern. On learning linear ranking functions for beam search. In Proceedings of the Twentieth International Conference on Machine Learning, 2007. 1609  X U , F ERN AND YOON  Yuehua Xu, Alan Fern, and Sungwook Yoon. Discriminative learning of beam-search heuristics for planning. In Proceedings of the International Joint Conference on Artiﬁcial Intelligence, 2007. Sungwook Yoon, Alan Fern, and Robert Givan. Inductive policy selection for ﬁrst-order MDPs. In Proceedings of Eighteenth Conference in Uncertainty in Artiﬁcial Intelligence, 2002. Sungwook Yoon, Alan Fern, and Robert Givan. Learning heuristic functions from relaxed plans. In International Conference on Automated Planning and Scheduling (ICAPS), 2006. Sungwook Yoon, Alan Fern, and Robert Givan. Learning control knowledge for forward search planning. Journal of Machine Learning Research, 9:683–718, 2008. Terry Zimmerman and Subbarao Kambhampati. Learning-assisted automated planning: Looking back, taking stock, going forward. AI Magazine, 24(2)(2):73–96, 2003.  1610</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
