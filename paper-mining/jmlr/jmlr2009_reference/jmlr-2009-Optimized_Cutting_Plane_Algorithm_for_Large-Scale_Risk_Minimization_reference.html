<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>69 jmlr-2009-Optimized Cutting Plane Algorithm for Large-Scale Risk Minimization</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-69" href="../jmlr2009/jmlr-2009-Optimized_Cutting_Plane_Algorithm_for_Large-Scale_Risk_Minimization.html">jmlr2009-69</a> <a title="jmlr-2009-69-reference" href="#">jmlr2009-69-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>69 jmlr-2009-Optimized Cutting Plane Algorithm for Large-Scale Risk Minimization</h1>
<br/><p>Source: <a title="jmlr-2009-69-pdf" href="http://jmlr.org/papers/volume10/franc09a/franc09a.pdf">pdf</a></p><p>Author: Vojtěch Franc, Sören Sonnenburg</p><p>Abstract: We have developed an optimized cutting plane algorithm (OCA) for solving large-scale risk minimization problems. We prove that the number of iterations OCA requires to converge to a ε precise solution is approximately linear in the sample size. We also derive OCAS, an OCA-based linear binary Support Vector Machine (SVM) solver, and OCAM, a linear multi-class SVM solver. In an extensive empirical evaluation we show that OCAS outperforms current state-of-the-art SVM solvers like SVMlight , SVMperf and BMRM, achieving speedup factor more than 1,200 over SVMlight on some data sets and speedup factor of 29 over SVMperf , while obtaining the same precise support vector solution. OCAS, even in the early optimization steps, often shows faster convergence than the currently prevailing approximative methods in this domain, SGD and Pegasos. In addition, our proposed linear multi-class SVM solver, OCAM, achieves speedups of factor of up to 10 compared to SVMmulti−class . Finally, we use OCAS and OCAM in two real-world applications, the problem of human acceptor splice site detection and malware detection. Effectively parallelizing OCAS, we achieve state-of-the-art results on an acceptor splice site recognition problem only by being able to learn from all the available 50 million examples in a 12-million-dimensional feature space. Source code, data sets and scripts to reproduce the experiments are available at http://cmp.felk.cvut.cz/˜xfrancv/ocas/html/. Keywords: risk minimization, linear support vector machine, multi-class classiﬁcation, binary classiﬁcation, large-scale learning, parallelization</p><br/>
<h2>reference text</h2><p>A. Bordes, L. Bottou, P. Gallinari, and J. Weston. Solving multiclass support vector machines with LaRank. In Proceedings of International Machine Learning Conference (ICML), pages 89 – 96. OmniPress, 2007. L. Bottou and O. Bousquet. The tradeoffs of large scale learning. In Advances in Neural Information Processing Systems (NIPS), volume 20, pages 161 – 168. MIT Press, 2007. C.C. Chang and C.J. Lin. LIBSVM: a library for support vector machines, 2001. Software available at http://www.csie.ntu.edu.tw/˜cjlin/libsvm. O. Chapelle. Training a Support Vector Machine in the Primal. Neural Computation, 19(5):1155– 1178, 2007. M. Collins, R.E. Schapire, and Y. Singer. Logistic regression AdaBoost and Bregman distance. In Proceedings of Annual Conference on Computational Learning Theory (COLT), pages 158–169. Morgan Kaufman, San Francisco, 2000. C. Cortes and V.N. Vapnik. Support-vector networks. Machine Learning, 20(3):273–297, 1995. K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector machines. Journal of Machine Learning Research, 2:265–292, 2001. N. Cristianini and J. Shawe-Taylor. An Introduction to Support Vector Machines. Cambridge UP, Cambridge, UK, 2000. 2189  F RANC AND S ONNENBURG  S. Degroeve, Y. Saeys, P. De Baets, B. Rouz´ , and Y. Van de Peer. SpliceMachine: predicting splice e sites from high-dimensional local context representations. Bioinformatics, 21(8):1332–8, 2005. R. Fan, K.W. Chang, C.J. Hsieh, X.R. Wang, and C.J. Lin. LIBLINEAR: A library for large linear classiﬁcation. Journal of Machine Learning Research, 9:1871–1874, 2008. R.E. Fan, P.H. Chen, and C.J. Lin. Working set selection using second order information for training SVM. Journal of Machine Learning Research, 6:1889–1918, 2005. T. Fawcett. ROC graphs: Notes and practical considerations for data mining researchers. Technical Report HPL-2003-4, HP Laboratories, Palo Alto, CA, USA, January 2003. V. Franc. Optimization Algorithms for Kernel Methods. PhD thesis, Czech Technical University in Prague, July 2005. Supervised by V. Hlav´ c. aˇ V. Franc and S. Sonnenburg. OCAS optimized cutting plane algorithm for support vector machines. In Proceedings of International Machine Learning Conference (ICML), pages 320–327. ACM Press, 2008a. V. Franc and S. Sonnenburg. LIBOCAS, 2008b. Software available at http://mloss.org/ software/view/85/. V. Franc, P. Laskov, and K.-R. M¨ ller. Stopping conditions for exact computation of leave-one-out u error in support vector machines. In Proceedings of International Machine Learning Conference (ICML), pages 328–335. ACM Press, 2008. T. Joachims. Making large–scale SVM learning practical. In Advances in Kernel Methods — Support Vector Learning, pages 169–184. MIT Press, Cambridge, MA, USA, 1999. T. Joachims. A support vector method for multivariate performance measures. In Proceedings of International Conference on Machine Learning (ICML), pages 377 – 384. ACM New York, NY, USA, 2005. T. Joachims. Training linear SVMs in linear time. In Proceedings of ACM Conference on Knowledge Discovery and Data Mining (KDD), pages 217 – 226. ACM New York, NY, USA, 2006. T. Joachims, T. Finley, and C.N. Yu. Cutting-plane training of structural SVMs. Machine Learning, 76(1), May 2009. C. Leslie, E. Eskin, and W.S. Noble. The spectrum kernel: A string kernel for SVM protein classiﬁcation. In Proceedings of Paciﬁc Biocomputing Symposium (PBS), pages 564–575. River Edge, NJ, World Scientiﬁc, 2002. C.J. Lin, R.C. Weng, and S.S. Keerthi. Trust region Newton methods for large-scale logistic regression. In Proceedings of International Conference on Machine Learning (ICML), pages 561 – 568. ACM Press New York, 2007. G. R¨ tsch and S. Sonnenburg. Accurate splice site detection for Caenorhabditis elegans. In a K. Tsuda B. Sch¨ lkopf and J.-P. Vert, editors, Kernel Methods in Computational Biology. MIT o Press, 2004. 2190  O PTIMIZED C UTTING P LANE S UPPORT V ECTOR M ACHINES  G. R¨ tsch, S. S. Sonnenburg, and B. Sch¨ lkopf. RASE: recognition of alternatively spliced exons a o in C. elegans. Bioinformatics, 21(Suppl. 1):i369–i377, June 2005. K. Rieck, T. Holtz, C. Willems, P. D¨ ssel, and P. Laskov. Learning and classiﬁcation of malware u behaviour. In Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), Fifth International Conference, pages 108–125, July 2008. B. Sch¨ lkopf and A. Smola. Learning with Kernels. The MIT Press, MA, 2002. o B. Sch¨ lkopf, J. Platt, J. Shawe-Taylor, A.J. Smola, and R.C. Williamson. Estimating the support o of a high-dimensional distribution. Technical Report TR 87, Microsoft Research, Redmond, WA, 1999. S.S. Shwartz, Y. Singer, and N. Srebro. Pegasos: Primal Estimated sub-GrAdient SOlver for SVM. In Proceedings of International Conference on Machine Learning (ICML), pages 807 – 814. ACM Press, 2007. V. Sindhwani and S.S. Keerthi. Newton methods for fast solution of semi-supervised linear svms. In L. Bottou, O. Chapelle, D. DeCoste, and J. Weston, editors, Large Scale Kernel Machines. MIT Press, 2007. S. Sonnenburg. New methods for splice site recognition. Master’s thesis, Humboldt University, 2002. supervised by K.-R. M¨ ller H.-D. Burkhard and G.R¨ tsch. u a S. Sonnenburg. Machine Learning for Genomic Sequence Analysis. PhD thesis, Fraunhofer Institute FIRST, 2008. supervised by K.-R. M¨ ller and G.R¨ tsch. u a S. Sonnenburg and G. R¨ tsch. a software/view/2/.  Shogun, 2007.  Software available at http://mloss.org/  S. Sonnenburg, G. R¨ tsch, and K. Rieck. Large scale learning with string kernels. In L. Bottou, O. a Chapelle, D. DeCoste, and J. Weston, editors, Large Scale Kernel Machines. MIT Press, 2007a. S. Sonnenburg, G. Schweikert, P. Philips, J. Behr, and G. R¨ tsch. Accurate Splice Site Prediction. a BMC Bioinformatics, Special Issue from NIPS workshop on New Problems and Methods in Computational Biology Whistler, Canada, 18 December 2006, 8:(Suppl. 10):S7, December 2007b. S. Sonnenburg, V. Franc, E. Yomtov, and M. Sebag. The pascal large scale learning challenge. Journal of Machine Learning Research, 2009. (manuscript in preparation). C.H. Teo, Q. Le, A. Smola, and S.V.N. Vishwanathan. A scalable modular convex solver for regularized risk minimization. In Proceedings of International Conference on Knowledge Discovery and Data Mining (KDD), August 2007. I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6:1453–1484, Sep. 2005. Wikipedia. DDR2 SDRAM — Wikipedia, the free encyclopedia, 2009. URL {http://en. wikipedia.org/wiki/DDR2_SDRAM}. [Online; accessed 5-February-2009]. 2191  F RANC AND S ONNENBURG  C.K.I Williams. Prediction with Gaussian processes: From linear regression to linear prediction and beyond. In Learning and Inference in Graphical Models, pages 599–621. Kluwer Academic, 1998. L. Zanni, T. Seraﬁni, and G. Zanghirati. Parallel software for training. Journal of Machine Learning Research, 7:1467–1492, July 2006.  2192</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
