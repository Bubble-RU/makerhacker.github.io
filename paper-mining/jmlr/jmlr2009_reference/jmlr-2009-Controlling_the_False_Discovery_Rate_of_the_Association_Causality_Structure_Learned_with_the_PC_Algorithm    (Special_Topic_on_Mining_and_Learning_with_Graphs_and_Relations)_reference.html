<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-19" href="../jmlr2009/jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">jmlr2009-19</a> <a title="jmlr-2009-19-reference" href="#">jmlr2009-19-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</h1>
<br/><p>Source: <a title="jmlr-2009-19-pdf" href="http://jmlr.org/papers/volume10/li09a/li09a.pdf">pdf</a></p><p>Author: Junning Li, Z. Jane Wang</p><p>Abstract: In real world applications, graphical statistical models are not only a tool for operations such as classiﬁcation or prediction, but usually the network structures of the models themselves are also of great interest (e.g., in modeling brain connectivity). The false discovery rate (FDR), the expected ratio of falsely claimed connections to all those claimed, is often a reasonable error-rate criterion in these applications. However, current learning algorithms for graphical models have not been adequately adapted to the concerns of the FDR. The traditional practice of controlling the type I error rate and the type II error rate under a conventional level does not necessarily keep the FDR low, especially in the case of sparse networks. In this paper, we propose embedding an FDR-control procedure into the PC algorithm to curb the FDR of the skeleton of the learned graph. We prove that the proposed method can control the FDR under a user-speciﬁed level at the limit of large sample sizes. In the cases of moderate sample size (about several hundred), empirical experiments show that the method is still able to control the FDR under the user-speciﬁed level, and a heuristic modiﬁcation of the method is able to control the FDR more accurately around the user-speciﬁed level. The proposed method is applicable to any models for which statistical tests of conditional independence are available, such as discrete models and Gaussian models. Keywords: Bayesian networks, false discovery rate, PC algorithm, directed acyclic graph, skeleton</p><br/>
<h2>reference text</h2><p>A. Agresti. Categorical Data Analysis (2nd edition). John Wiley & Sons, Inc., 2002. 512  C ONTROLLING THE FALSE D ISCOVERY R ATE WITH THE PC A LGORITHM  T. W. Anderson. An Introduction to Multivariate Statistical Analysis (2nd edition). John Wiley & Sons, Inc., 1984. S. A. Andersson, D. Madigan, and M. D. Perlman. A characterization of Markov equivalence classes for acyclic digraphs. The Annals of Statistics, 25(2):505–541, 1997. Y. Benjamini and D. Yekutieli. The control of the false discovery rate in multiple testing under dependency. The Annals of Statistics, 29(4):1165–1188, 2001. D. M. Chickering. Optimal structure identiﬁcation with greedy search. Journal of Machine Learning Research, 3:507–554, 2002. C. Chow and C. Liu. Approximating discrete probability distributions with dependence trees. Information Theory, IEEE Transactions on, 14(3):462–467, 1968. G. F. Cooper and E. Herskovits. A Bayesian method for the induction of probabilistic networks from data. Machine Learning, 9(4):309–347, 1992. D. Eaton and K. Murphy. Bayesian structure learning using dynamic programming and MCMC. In Proceedings of the Twenty-Third Conference on Uncertainty in Artiﬁcial Intelligence, 2007. R. A. Fisher. Frequency distribution of the values of the correlation coefﬁcients in samples from an indeﬁnitely large population. Biometrika, 10(4):507–521, 1915. R. A. Fisher. The distribution of the partial correlation coefﬁcient. Metron, 3:329–332, 1924. N. Friedman and D. Koller. Being Bayesian about network structure. A Bayesian approach to structure discovery in Bayesian networks. Machine Learning, 50(1):95–125, 2003. D. Heckerman, D. Geiger, and D. M. Chickering. Learning Bayesian networks: The combination of knowledge and statistical data. Machine Learning, 20(3):197–243, 1995. E. H. Herskovits and G. F. Cooper. Kutato: An entropy-driven system for the construction of probabilistic expert systems from databases. In Proceedings of the Sixth Conference on Uncertainty in Artiﬁcial Intelligence, pages 54–62, 1990. M. Kalisch and P. B¨ hlmann. Estimating high-dimensional directed acyclic graphs with the PCu algorithm. Journal of Machine Learning Research, 8:613–636, 2007. T. A. Keller, M. A. Just, and V. A. Stenger. Reading span and the time-course of cortical activation in sentence-picture veriﬁcation. In Annual Convention of the Psychonomic Society, 2001. M. Koivisto and K. Sood. Exact Bayesian structure discovery in Bayesian networks. Journal of Machine Learning Research, 5:549–573, 2004. S. L. Lauritzen. Graphical Models. Clarendon Press, Oxford University Press, Oxford, New York, 1996. J. Li, Z. J. Wang, S. J. Palmer, and M. J. McKeown. Dynamic Bayesian network modelling of fMRI: A comparison of group analysis methods. NeuroImage, 41:398–407, 2008. 513  LI  AND  WANG  D. Madigan, J. York, and D. Allard. Bayesian graphical models for discrete data. International Statistical Review, 63(2):215–232, 1995. T. M. Mitchell, R. Hutchinson, R. S. Niculescu, F. Pereira, X. Wang, M. Just, and S. Newman. Learning to decode cognitive states from brain images. Machine Learning, 57(1):145–175, 2004. J. Neyman and E. S. Pearson. On the use and interpretation of certain test criteria for purposes of statistical inference: Part I. Biometrika, 20A:175–240, 1928. J. Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, 1988. J. Pearl. Causality. Cambridge University Press, 2000. J. Pearl and T. S. Verma. A statistical semantics for causation. Statistics and Computing, 2(2): 91–95, 1992. H. Qian and S. Huang. Comparison of false discovery rate methods in identifying genes with differential expression. Genomics, 86(4):495–503, 2005. R. W. Robinson. Counting labeled acyclic digraphs. In New Directions in the Theory of Graphs, pages 239–273. Academic Press, 1973. J. Sch¨ fer and K. Strimmer. An empirical Bayes approach to inferring large-scale gene association a networks. Bioinformatics, 21(6):754–764, 2005. P. Spirtes and C. Glymour. An algorithm for fast recovery of sparse causal graphs. Social Science Computer Review, 9:62–72, 1991. P. Spirtes, C. Glymour, and R. Scheines. Causation, Prediction, and Search. The MIT Press, 2001. B. Steinsky. Enumeration of labelled chain graphs and labelled essential directed acyclic graphs. Discrete Mathematics, 270(1-3):267–278, 2003. J. D. Storey. A direct approach to false discovery rates. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 64(3):479–498, 2002. J. D. Storey. The positive false discovery rate: A Bayesian interpretation and the q-value. The Annals of Statistics, 31(6):2013–2035, 2003. A. Wald. Tests of statistical hypotheses concerning several parameters when the number of observations is large. Transactions of the American Mathematical Society, 54(3):426–482, 1943.  514</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
