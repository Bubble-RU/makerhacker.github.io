<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-95" href="../jmlr2009/jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">jmlr2009-95</a> <a title="jmlr-2009-95-reference" href="#">jmlr2009-95-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</h1>
<br/><p>Source: <a title="jmlr-2009-95-pdf" href="http://jmlr.org/papers/volume10/rudin09b/rudin09b.pdf">pdf</a></p><p>Author: Cynthia Rudin</p><p>Abstract: We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This “push” near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. Keywords: ranking, RankBoost, generalization bounds, ROC, information retrieval</p><br/>
<h2>reference text</h2><p>Shivani Agarwal, Thore Graepel, Ralf Herbich, Sariel Har-Peled, and Dan Roth. Generalization bounds for the area under the ROC curve. Journal of Machine Learning Research, 6:393–425, 2005. Arthur Asuncion and David J. Newman. UCI machine learning repository, 2007. http://www.ics.uci.edu/∼mlearn/MLRepository.html.  URL  Olivier Bousquet. New approaches to statistical learning theory. Annals of the Institute of Statistical Mathematics, 55(2):371–389, 2003. Ulf Brefeld and Tobias Scheffer. AUC maximizing support vector learning. In Proceedings of the ICML 2005 Workshop on ROC Analysis in Machine Learning, 2005. St´ phan Clemencon and Nicolas Vayatis. Ranking the best instances. Journal of Machine Learning e ¸ Research, 8:2671–2699, Dec 2007. St´ phan Clemencon and Nicolas Vayatis. Empirical performance maximization for linear rank e ¸ statistics. In Advances in Neural Information Processing Systems 22, 2008. St´ phan Clemencon, Gabor Lugosi, and Nicolas Vayatis. Ranking and empirical minimization of e ¸ U-statistics. The Annals of Statistics, 36(2):844–874, 2008. Michael Collins, Robert E. Schapire, and Yoram Singer. Logistic regression, AdaBoost and Bregman distances. Machine Learning, 48(1/2/3), 2002. Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine Learning, 20(3):273–297, September 1995. David Cossock and Tong Zhang. Subset ranking using regression. In Proceedings of the Ninteenth Annual Conference on Learning Theory, 2006. 2269  RUDIN  Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector machines. Journal of Machine Learning Research, 2:265–292, 2001. Felipe Cucker and Steve Smale. On the mathematical foundations of learning. Bull. Amer. Math. Soc. (N.S.), 39(1):1–49, 2002. Ofer Dekel, Christopher Manning, and Yoram Singer. Log-linear models for label ranking. In Advances in Neural Information Processing Systems 16, 2004. Stephen Della Pietra, Vincent Della Pietra, and John Lafferty. Duality and auxiliary functions for Bregman distances. Technical Report CMU-CS-01-109R, School of Computer Science, Carnegie Mellon University, 2002. Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119–139, August 1997. Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An efﬁcient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933–969, 2003. Simon I. Hill, Hugo Zaragoza T, Ralf Herbrich T, and Peter J. W. Rayner. Average precision and the problem of generalisation. In In Proceedings of the ACM SIGIR Workshop on Mathematical and Formal Methods in Information Retrieval, 2002. Kalervo J¨ rvelin and Jaana Kek¨ l¨ inen. IR evaluation methods for retrieving highly relevant docua aa ments. In SIGIR ’00: Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 41–48, New York, NY, USA, 2000. ACM. Heng Ji, Cynthia Rudin, and Ralph Grishman. Re-ranking algorithms for name tagging. In HLT/NAACL workshop on computationally hard problems and joint interference in speech and language processing, 2006. Vladimir Koltchinskii and Dmitry Panchenko. Empirical margin distributions and bounding the generalization error of combined classiﬁers. The Annals of Statistics, 30(1), February 2002. Quoc Le and Alex Smola. Direct optimization of ranking measures. arXiv:0704.3359v1, November 2007. Sofus A. Macskassy, Foster Provost, and Saharon Rosset. Pointwise ROC conﬁdence bounds: An empirical evaluation. In Proceedings of the ICML 2005 Workshop on ROC Analysis in Machine Learning, 2005. Colin McDiarmid. On the method of bounded differences. In Surveys in Combinatorics 1989, pages 148–188. Cambridge University Press, 1989. Michael C. Mozer, Robert Dodier, Michael D. Colagrosso, Csar Guerra-salcedo, and Richard Wolniewicz. Prodding the ROC curve: Constrained optimization of classiﬁer performance. In Advances in Neural Information Processing Systems 14, pages 1409–1415, 2002. 2270  T HE P-N ORM P USH  Alain Rakotomamonjy. Optimizing AUC with support vector machine (SVM). In Proceedings of European Conference on Artiﬁcial Intelligence Workshop on ROC Curve and AI, Valencia, Spain, 2004. Cynthia Rudin. Ranking with a p-norm push. In Proceedings of the Ninteenth Annual Conference on Learning Theory, pages 589–604, 2006. Cynthia Rudin and Robert E. Schapire. Margin-based ranking and an equivalence between AdaBoost and RankBoost. Journal of Machine Learning Research, 10:2193–2232, October 2009. Cynthia Rudin, Corinna Cortes, Mehryar Mohri, and Robert E. Schapire. Margin-based ranking meets boosting in the middle. In Peter Auer and Ron Meir, editors, Proceedings of the Eighteenth Annual Conference on Learning Theory, pages 63–78. Springer, 2005. Cynthia Rudin, Rebecca Passonneau, Axinia Radeva, Haimonti Dutta, Steve Ierome, and Delﬁna Isaac. Predicting manhole events in Manhattan : A case study in extended knowledge discovery. Accepted for publication to Machine Learning, 2009. Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. Boosting the margin: A new explanation for the effectiveness of voting methods. The Annals of Statistics, 26(5):1651–1686, October 1998. Shai Shalev-Shwartz and Yoram Singer. Efﬁcient learning of label ranking by soft projections onto polyhedra. Journal of Machine Learning Research, 7:1567–1599, December 2006. Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, and Yasemin Altun. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6:1453–1484, Sept 2005. Nicolas Usunier, Massih-Reza Amini, and Patrick Gallinari. A data-dependent generalisation error bound for the AUC. In Proceedings of the ICML 2005 Workshop on ROC Analysis in Machine Learning, 2005. Lian Yan, Robert H. Dodier, Michael Mozer, and Richard H. Wolniewicz. Optimizing classiﬁer performance via an approximation to the Wilcoxon-Mann-Whitney statistic. In Proceedings of the Twentieth International Conference on Machine Learning, pages 848–855, 2003. Tong Zhang and Bin Yu. Boosting with early stopping - convergence and consistency. The Annals of Statistics, 33(4):1538–1579, 2005. Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, and Gordon Sun. A general boosting method and its application to learning ranking functions for web search. In Advances in Neural Information Processing Systems 19, 2007.  2271</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
