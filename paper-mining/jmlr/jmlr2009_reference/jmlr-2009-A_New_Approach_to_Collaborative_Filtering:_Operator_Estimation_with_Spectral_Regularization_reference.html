<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-2" href="../jmlr2009/jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">jmlr2009-2</a> <a title="jmlr-2009-2-reference" href="#">jmlr2009-2-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</h1>
<br/><p>Source: <a title="jmlr-2009-2-pdf" href="http://jmlr.org/papers/volume10/abernethy09a/abernethy09a.pdf">pdf</a></p><p>Author: Jacob Abernethy, Francis Bach, Theodoros Evgeniou, Jean-Philippe Vert</p><p>Abstract: We present a general approach for collaborative ﬁltering (CF) using spectral regularization to learn linear operators mapping a set of “users” to a set of possibly desired “objects”. In particular, several recent low-rank type matrix-completion methods for CF are shown to be special cases of our proposed framework. Unlike existing regularization-based CF, our approach can be used to incorporate additional information such as attributes of the users/objects—a feature currently lacking in existing regularization-based CF approaches—using popular and well-known kernel methods. We provide novel representer theorems that we use to develop new estimation methods. We then provide learning algorithms based on low-rank decompositions and test them on a standard CF data set. The experiments indicate the advantages of generalizing the existing regularization-based CF methods to incorporate related information about users and objects. Finally, we show that certain multi-task learning methods can be also seen as special cases of our proposed approach. Keywords: collaborative ﬁltering, matrix completion, kernel methods, spectral regularization</p><br/>
<h2>reference text</h2><p>J. Abernethy, F. Bach, T. Evgeniou, and J.-P. Vert. Low-rank matrix factorization with attributes. Technical Report N24/06/MM, Ecole des Mines de Paris, 2006. Y. Amit, M. Fink, N. Srebro, and S. Ullman. Uncovering shared structures in multiclass classiﬁcation. In Z. Ghahramani, editor, ICML ’07: Proceedings of the 24th International Conference on Machine Learning, pages 17–24, New York, NY, USA, 2007. ACM. A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Mach. Learn., 73(3): 243–272, 2008. N. Aronszajn. Theory of reproducing kernels. Trans. Am. Math. Soc., 68:337 – 404, 1950. F. R. Bach. Consistency of trace norm minimization. J. Mach. Learn. Res., 9:1019–1048, 2008. F. R. Bach and M. I. Jordan. Predictive low-rank decomposition for kernel methods. In ICML ’05: Proceedings of the 22nd International Conference on Machine Learning, pages 33–40, New York, NY, USA, 2005. ACM. F. R. Bach, G. R. G. Lanckriet, and M. I. Jordan. Multiple kernel learning, conic duality, and the SMO algorithm. In ICML ’04: Proceedings of the Twenty-ﬁrst International Conference on Machine Learning, page 6, New York, NY, USA, 2004. ACM. F. R. Bach, R. Thibaux, and M. I. Jordan. Computing regularization paths for learning multiple kernels. In L. K. Saul, Y. Weiss, and L. Bottou, editors, Adv. Neural. Inform. Process Syst. 17, pages 73–80, Cambridge, MA, 2005. MIT Press. A. Berlinet and C. Thomas-Agnan. Reproducing Kernel Hilbert Spaces in Probability and Statistics. Kluwer Academic Publishers, 2003. S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge Univ. Press, 2003. J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative ﬁltering. In 14th Conference on Uncertainty in Artiﬁcial Intelligence, pages 43–52, Madison, W.I., 1998. Morgan Kaufman. H. Brezis. Analyse Fonctionnelle. Masson, 1980. S. A. Burer and C. Choi. Computational enhancements in low-rank semideﬁnite programming. Optimization Methods and Software, 21:493–512, 2006. 825  A BERNETHY, BACH , E VGENIOU AND V ERT  S. A. Burer and R. D. C. Monteiro. Local minima and convergence in low-rank semideﬁnite programming. Mathematical Programming, 103:427–444, 2005. T. Evgeniou, C. Micchelli, and M. Pontil. Learning multiple tasks with kernel methods. J. Mach. Learn. Res., 6:615–637, 2005. M. Fazel, H. Hindi, and S. Boyd. A rank minimization heuristic with application to minimum order system approximation. In Proceedings of the 2001 American Control Conference, volume 6, pages 4734–4739, 2001. S. Fine and K. Scheinberg. Efﬁcient SVM training using low-rank kernel representations. J. Mach. Learn. Res., 2:243–264, 2001. G. H. Golub and C. F. Van Loan. Matrix Computations. Johns Hopkins University Press, 1996. D. Heckerman, D. M. Chickering, C. Meek, R. Rounthwaite, and C. Kadie. Dependency networks for inference, collaborative ﬁltering, and data visualization. J. Mach. Learn. Res., 1:49–75, 2000. L. Jacob and J.-P. Vert. Efﬁcient peptide-MHC-I binding prediction for alleles with few known binders. Bioinformatics, 24(3):358–366, Feb 2008. G. R. G. Lanckriet, N. Cristianini, L. El Ghaoui, P. Bartlett, and M. I. Jordan. Learning the kernel matrix with semideﬁnite programming. J. Mach. Learn. Res., 5:27–72, 2004. A. S. Lewis and H. S. Sendov. Twice differentiable spectral functions. SIAM J. Mat. Anal. App., 23 (2):368–386, 2002. J. D. M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative prediction. In Proceedings of the 22nd International Conference on Machine Learning, pages 713–719, New York, NY, USA, 2005. ACM Press. R. Salakhutdinov, A. Mnih, and G. Hinton. Restricted boltzmann machines for collaborative ﬁltering. In ICML ’07: Proceedings of the 24th International Conference on Machine Learning, pages 791–798, New York, NY, USA, 2007. ACM. B. Sch¨ lkopf, R. Herbrich, and A. J. Smola. A generalized representer theorem. In Proceedings of o the 14th Annual Conference on Computational Learning Theory, volume 2011 of Lecture Notes in Computer Science, pages 416–426, Berlin / Heidelberg, 2001. Springer. J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press, 2004. N. Srebro and T. Jaakkola. Weighted low-rank approximations. In T. Fawcett and N. Mishra, editors, Proceedings of the Twentieth International Conference on Machine Learning, pages 720–727. AAAI Press, 2003. N. Srebro, J. D. M. Rennie, and T. S. Jaakkola. Maximum-margin matrix factorization. In L. K. Saul, Y. Weiss, and L. Bottou, editors, Adv. Neural. Inform. Process Syst. 17, pages 1329–1336, Cambridge, MA, 2005. MIT Press. G. W. Stewart and J. Sun. Matrix Perturbation Theory. Academic Press, 1990. 826</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
