<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-37" href="../jmlr2009/jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">jmlr2009-37</a> <a title="jmlr-2009-37-reference" href="#">jmlr2009-37-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</h1>
<br/><p>Source: <a title="jmlr-2009-37-pdf" href="http://jmlr.org/papers/volume10/agarwal09a/agarwal09a.pdf">pdf</a></p><p>Author: Shivani Agarwal, Partha Niyogi</p><p>Abstract: The problem of ranking, in which the goal is to learn a real-valued ranking function that induces a ranking or ordering over an instance space, has recently gained much attention in machine learning. We study generalization properties of ranking algorithms using the notion of algorithmic stability; in particular, we derive generalization bounds for ranking algorithms that have good stability properties. We show that kernel-based ranking algorithms that perform regularization in a reproducing kernel Hilbert space have such stability properties, and therefore our bounds can be applied to these algorithms; this is in contrast with generalization bounds based on uniform convergence, which in many cases cannot be applied to these algorithms. Our results generalize earlier results that were derived in the special setting of bipartite ranking (Agarwal and Niyogi, 2005) to a more general setting of the ranking problem that arises frequently in applications. Keywords: ranking, generalization bounds, algorithmic stability</p><br/>
<h2>reference text</h2><p>Shivani Agarwal. Ranking on graph data. In Proceedings of the 23rd International Conference on Machine Learning, 2006. Shivani Agarwal and Partha Niyogi. Stability and generalization of bipartite ranking algorithms. In Proceedings of the 18th Annual Conference on Learning Theory, 2005. 471  AGARWAL AND N IYOGI  Shivani Agarwal, Thore Graepel, Ralf Herbrich, Sariel Har-Peled, and Dan Roth. Generalization bounds for the area under the ROC curve. Journal of Machine Learning Research, 6:393–425, 2005. Nir Ailon and Mehryar Mohri. An efﬁcient reduction of ranking to classiﬁcation. In Proceedings of the 21st Annual Conference on Learning Theory, 2008. Kenneth J. Arrow. Social Choice and Individual Values. Yale University Press, Second edition, 1970. Maria-Florina Balcan, Nikhil Bansal, Alina Beygelzimer, Don Coppersmith, John Langford, and Gregory B. Sorkin. Robust reductions from ranking to classiﬁcation. In Proceedings of the 20th Annual Conference on Learning Theory, 2007. Olivier Bousquet. New approaches to statistical learning theory. Annals of the Institute of Statistical Mathematics, 55(2):371–389, 2003. Olivier Bousquet and Andr´ Elisseeff. Stability and generalization. Journal of Machine Learning e Research, 2:499–526, 2002. Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine Learning, 2005. Alpha C. Chiang and Kevin Wainwright. Fundamental Methods of Mathematical Economics. McGraw-Hill Irwin, Fourth edition, 2005. Stephan Clemencon and Nicolas Vayatis. Ranking the best instances. Journal of Machine Learning Research, 8:2671–2699, 2007. Stephan Clemencon, Gabor Lugosi, and Nicolas Vayatis. Ranking and empirical minimization of U-statistics. Annals of Statistics, 36:844–874, 2008. William W. Cohen, Robert E. Schapire, and Yoram Singer. Learning to order things. Journal of Artiﬁcial Intelligence Research, 10:243–270, 1999. Corinna Cortes, Mehryar Mohri, and Ashish Rastogi. Magnitude-preserving ranking algorithms. In Proceedings of 24th International Conference on Machine Learning, 2007. David Cossock and Tong Zhang. Subset ranking using regression. In Proceedings of the 19th Annual Conference on Learning Theory, 2006. Koby Crammer and Yoram Singer. Pranking with ranking. In Advances in Neural Information Processing Systems 14, pages 641–647. MIT Press, 2002. Felipe Cucker and Steve Smale. On the mathematical foundations of learning. Bulletin of the American Mathematical Society, 39:1–49, 2002. Dominique de Caen. An upper bound on the sum of squares of degrees in a graph. Discrete Mathematics, 185:245–248, 1998. 472  S TABILITY AND G ENERALIZATION OF R ANKING A LGORITHMS  Luc Devroye and Terry J. Wagner. Distribution-free performance bounds for potential function rules. IEEE Transactions on Information Theory, 25(5):601–604, 1979. Theodoros Evgeniou, Massimiliano Pontil, and Tomaso Poggio. Regularization networks and support vector machines. Advances in Computational Mathematics, 13(1):1–50, 2000. Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An efﬁcient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933–969, 2003. David Haussler. Convolution kernels on discrete structures. Technical Report UCSC-CRL-99-10, University of California at Santa Cruz, 1999. Ralf Herbrich, Thore Graepel, Peter Bollmann-Sdorra, and Klaus Obermayer. Learning preference relations for information retrieval. In Proceedings of the ICML-1998 Workshop on Text Categorization and Machine Learning, 1998. Ralf Herbrich, Thore Graepel, and Klaus Obermayer. Large margin rank boundaries for ordinal regression. Advances in Large Margin Classiﬁers, pages 115–132, 2000. Thorsten Joachims. Optimizing search engines using clickthrough data. In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining, 2002. Michael Kearns and Dana Ron. Algorithmic stability and sanity-check bounds for leave-one-out cross-validation. Neural Computation, 11:1427–1453, 1999. Vladimir Koltchinskii and Dmitry Panchenko. Empirical margin distributions and bounding the generalization error of combined classiﬁers. The Annals of Statistics, 30(1):1–50, 2002. Samuel Kutin and Partha Niyogi. The interaction of stability and weakness in AdaBoost. Technical Report TR-2001-30, Computer Science Department, University of Chicago, 2001. Samuel Kutin and Partha Niyogi. Almost-everywhere algorithmic stability and generalization error. In Proceedings of the 18th Conference on Uncertainty in Artiﬁcial Intelligence, 2002. Erich L. Lehmann. Nonparametrics: Statistical Methods Based on Ranks. Holden-Day, 1975. Colin McDiarmid. On the method of bounded differences. In Surveys in Combinatorics 1989, pages 148–188. Cambridge University Press, 1989. Tomaso Poggio, Ryan Rifkin, Sayan Mukherjee, and Partha Niyogi. General conditions for predictivity in learning theory. Nature, 428:419–422, 2004. Filip Radlinski and Thorsten Joachims. Query chains: Learning to rank from implicit feedback. In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining, 2005. Alain Rakotomamonjy. Optimizing area under ROC curves with SVMs. In Proceedings of the ECAI-2004 Workshop on ROC Analysis in AI, 2004. William H. Rogers and Terry J. Wagner. A ﬁnite sample distribution-free performance bound for local discrimination rules. Annals of Statistics, 6(3):506–514, 1978. 473  AGARWAL AND N IYOGI  Cynthia Rudin. Ranking with a p-norm push. In Proceedings of the 19th Annual Conference on Learning Theory, 2006. Cynthia Rudin, Corinna Cortes, Mehryar Mohri, and Robert E. Schapire. Margin-based ranking meets boosting in the middle. In Proceedings of the 18th Annual Conference on Learning Theory, 2005. Vladimir N. Vapnik and Alexey Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and its Applications, 16:264–280, 1971.  474</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
