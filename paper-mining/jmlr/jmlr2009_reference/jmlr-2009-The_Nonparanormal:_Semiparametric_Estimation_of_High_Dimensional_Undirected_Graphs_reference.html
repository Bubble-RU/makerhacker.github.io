<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>94 jmlr-2009-The Nonparanormal: Semiparametric Estimation of High Dimensional Undirected Graphs</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-94" href="../jmlr2009/jmlr-2009-The_Nonparanormal%3A_Semiparametric_Estimation_of_High_Dimensional_Undirected_Graphs.html">jmlr2009-94</a> <a title="jmlr-2009-94-reference" href="#">jmlr2009-94-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>94 jmlr-2009-The Nonparanormal: Semiparametric Estimation of High Dimensional Undirected Graphs</h1>
<br/><p>Source: <a title="jmlr-2009-94-pdf" href="http://jmlr.org/papers/volume10/liu09a/liu09a.pdf">pdf</a></p><p>Author: Han Liu, John Lafferty, Larry Wasserman</p><p>Abstract: Recent methods for estimating sparse undirected graphs for real-valued data in high dimensional problems rely heavily on the assumption of normality. We show how to use a semiparametric Gaussian copula—or “nonparanormal”—for high dimensional inference. Just as additive models extend linear models by replacing linear functions with a set of one-dimensional smooth functions, the nonparanormal extends the normal by transforming the variables by smooth functions. We derive a method for estimating the nonparanormal, study the method’s theoretical properties, and show that it works well in many examples. Keywords: graphical models, Gaussian copula, high dimensional inference, sparsity, ℓ1 regularization, graphical lasso, paranormal, occult</p><br/>
<h2>reference text</h2><p>Felix Abramovich, Yoav Benjamini, David L. Donoho, and Iain M. Johnstone. Adapting to unknown sparsity by controlling the false discovery rate. The Annals of Statistics, 34(2):584–653, 2006. Onureena Banerjee, Laurent El Ghaoui, and Alexandre d’Aspremont. Model selection through sparse maximum likelihood estimation. Journal of Machine Learning Research, 9:485–516, March 2008. Tony Cai, Cun-Hui Zhang, and Harrison H. Zhou. Optimal rates of convergence for covariance matrix estimation. Technical report, Wharton School, Statistics Department, University of Pennsylvania, 2008. Mathias Drton and Michael D. Perlman. Multiple testing and error control in Gaussian graphical model selection. Statistical Science, 22(3):430–449, 2007. Mathias Drton and Michael D. Perlman. A SINful approach to Gaussian graphical model selection. Journal of Statistical Planning and Inference, 138(4):1179–1200, 2008. Jerome H. Friedman, Trevor Hastie, and Robert Tibshirani. Sparse inverse covariance estimation with the graphical lasso. Biostatistics, 9(3):432–441, 2007. Trevor Hastie and Robert Tibshirani. Generalized additive models. Chapman & Hall Ltd., 1999. 2327  L IU , L AFFERTY, AND WASSERMAN  Chris A. J. Klaassen and Jon A. Wellner. Efﬁcient estimation in the bivariate normal copula model: Normal margins are least-favorable. Bernoulli, 3(1):55–77, 1997. Colin L. Mallows, editor. The collected works of John W. Tukey. Volume VI: More mathematical, 1938–1984. Wadsworth & Brooks/Cole, 1990. Nicolai Meinshausen and Peter B¨ hlmann. High dimensional graphs and variable selection with the u Lasso. The Annals of Statistics, 34:1436–1462, 2006. Pradeep Ravikumar, Han Liu, John Lafferty, and Larry Wasserman. SpAM: Sparse additive models. In Advances in Neural Information Processing Systems 20, pages 1201–1208. MIT Press, Cambridge, MA, 2008. Pradeep Ravikumar, John Lafferty, Han Liu, and Larry Wasserman. Sparse additive models. Journal of the Royal Statistical Society, Series B, Methodological, 2009a. To appear. Pradeep Ravikumar, Martin Wainwright, Garvesh Raskutti, and Bin Yu. Model selection in Gaussian graphical models: High-dimensional consistency of ℓ1 -regularized MLE. In Advances in Neural Information Processing Systems 22, Cambridge, MA, 2009b. MIT Press. Adam J. Rothman, Peter J. Bickel, Elizaveta Levina, and Ji Zhu. Sparse permutation invariant covariance estimation. Electronic Journal of Statistics, 2:494–515, 2008. ` Abe Sklar. Fonctions de r´ partition a n dimensions et leurs marges. Publications de l’Institut de e Statistique de L’Universit´ de Paris 8, pages 229–231, 1959. e Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B, Methodological, 58:267–288, 1996. Hideatsu Tsukahara. Semiparametric estimation in copula models. Canadian Journal of Statistics, 33:357–375, 2005. Aad W. van der Vaart. Asymptotic Statistics. Cambridge University Press, 1998. Aad W. van der Vaart and Jon A. Wellner. Weak Convergence and Empirical Processes: With Applications to Statistics. Springer-Verlag, 1996. Anja Wille et al. Sparse Gaussian graphical modelling of the isoprenoid gene network in Arabidopsis thaliana. Genome Biology, 5:R92, 2004. Ming Yuan and Yi Lin. Model selection and estimation in the Gaussian graphical model. Biometrika, 94(1):19–35, 2007.  2328</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
