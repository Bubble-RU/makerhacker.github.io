<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>73 jmlr-2009-Prediction With Expert Advice For The Brier Game</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-73" href="#">jmlr2009-73</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>73 jmlr-2009-Prediction With Expert Advice For The Brier Game</h1>
<br/><p>Source: <a title="jmlr-2009-73-pdf" href="http://jmlr.org/papers/volume10/vovk09a/vovk09a.pdf">pdf</a></p><p>Author: Vladimir Vovk, Fedor Zhdanov</p><p>Abstract: We show that the Brier game of prediction is mixable and ﬁnd the optimal learning rate and substitution function for it. The resulting prediction algorithm is applied to predict results of football and tennis matches, with well-known bookmakers playing the role of experts. The theoretical performance guarantee is not excessively loose on the football data set and is rather tight on the tennis data set. Keywords: Brier game, classiﬁcation, on-line prediction, strong aggregating algorithm, weighted average algorithm</p><p>Reference: <a title="jmlr-2009-73-reference" href="../jmlr2009_reference/jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bookmak', 0.399), ('vovk', 0.347), ('wda', 0.335), ('footbal', 0.291), ('ln', 0.273), ('superpredict', 0.27), ('expert', 0.221), ('gam', 0.186), ('hdanov', 0.14), ('overround', 0.14), ('rier', 0.14), ('xpert', 0.14), ('tn', 0.14), ('ha', 0.123), ('dvic', 0.119), ('wka', 0.119), ('khutsishvil', 0.108), ('redict', 0.098), ('gk', 0.085), ('un', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="73-tfidf-1" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>Author: Vladimir Vovk, Fedor Zhdanov</p><p>Abstract: We show that the Brier game of prediction is mixable and ﬁnd the optimal learning rate and substitution function for it. The resulting prediction algorithm is applied to predict results of football and tennis matches, with well-known bookmakers playing the role of experts. The theoretical performance guarantee is not excessively loose on the football data set and is rather tight on the tennis data set. Keywords: Brier game, classiﬁcation, on-line prediction, strong aggregating algorithm, weighted average algorithm</p><p>2 0.12341355 <a title="73-tfidf-2" href="./jmlr-2009-Learning_Permutations_with_Exponential_Weights.html">49 jmlr-2009-Learning Permutations with Exponential Weights</a></p>
<p>Author: David P. Helmbold, Manfred K. Warmuth</p><p>Abstract: We give an algorithm for the on-line learning of permutations. The algorithm maintains its uncertainty about the target permutation as a doubly stochastic weight matrix, and makes predictions using an efﬁcient method for decomposing the weight matrix into a convex combination of permutations. The weight matrix is updated by multiplying the current matrix entries by exponential factors, and an iterative procedure is needed to restore double stochasticity. Even though the result of this procedure does not have a closed form, a new analysis approach allows us to prove an optimal (up to small constant factors) bound on the regret of our algorithm. This regret bound is signiﬁcantly better than that of either Kalai and Vempala’s more efﬁcient Follow the Perturbed Leader algorithm or the computationally expensive method of explicitly representing each permutation as an expert. Keywords: permutation, ranking, on-line learning, Hedge algorithm, doubly stochastic matrix, relative entropy projection, Sinkhorn balancing</p><p>3 0.085828915 <a title="73-tfidf-3" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>Author: Shie Mannor, John N. Tsitsiklis, Jia Yuan Yu</p><p>Abstract: We study online learning where a decision maker interacts with Nature with the objective of maximizing her long-term average reward subject to some sample path average constraints. We deﬁne the reward-in-hindsight as the highest reward the decision maker could have achieved, while satisfying the constraints, had she known Nature’s choices in advance. We show that in general the reward-in-hindsight is not attainable. The convex hull of the reward-in-hindsight function is, however, attainable. For the important case of a single constraint, the convex hull turns out to be the highest attainable function. Using a calibrated forecasting rule, we provide an explicit strategy that attains this convex hull. We also measure the performance of heuristic methods based on non-calibrated forecasters in experiments involving a CPU power management problem. Keywords: online learning, calibration, regret minimization, approachability</p><p>4 0.053332623 <a title="73-tfidf-4" href="./jmlr-2009-Data-driven_Calibration_of_Penalties_for_Least-Squares_Regression.html">21 jmlr-2009-Data-driven Calibration of Penalties for Least-Squares Regression</a></p>
<p>Author: Sylvain Arlot, Pascal Massart</p><p>Abstract: Penalization procedures often suffer from their dependence on multiplying factors, whose optimal values are either unknown or hard to estimate from data. We propose a completely data-driven calibration algorithm for these parameters in the least-squares regression framework, without assuming a particular shape for the penalty. Our algorithm relies on the concept of minimal penalty, recently introduced by Birg´ and Massart (2007) in the context of penalized least squares for Gaussian hoe moscedastic regression. On the positive side, the minimal penalty can be evaluated from the data themselves, leading to a data-driven estimation of an optimal penalty which can be used in practice; on the negative side, their approach heavily relies on the homoscedastic Gaussian nature of their stochastic framework. The purpose of this paper is twofold: stating a more general heuristics for designing a datadriven penalty (the slope heuristics) and proving that it works for penalized least-squares regression with a random design, even for heteroscedastic non-Gaussian data. For technical reasons, some exact mathematical results will be proved only for regressogram bin-width selection. This is at least a ﬁrst step towards further results, since the approach and the method that we use are indeed general. Keywords: data-driven calibration, non-parametric regression, model selection by penalization, heteroscedastic data, regressogram</p><p>5 0.051415734 <a title="73-tfidf-5" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>Author: Cynthia Rudin, Robert E. Schapire</p><p>Abstract: We study boosting algorithms for learning to rank. We give a general margin-based bound for ranking based on covering numbers for the hypothesis space. Our bound suggests that algorithms that maximize the ranking margin will generalize well. We then describe a new algorithm, smooth margin ranking, that precisely converges to a maximum ranking-margin solution. The algorithm is a modiﬁcation of RankBoost, analogous to “approximate coordinate ascent boosting.” Finally, we prove that AdaBoost and RankBoost are equally good for the problems of bipartite ranking and classiﬁcation in terms of their asymptotic behavior on the training set. Under natural conditions, AdaBoost achieves an area under the ROC curve that is equally as good as RankBoost’s; furthermore, RankBoost, when given a speciﬁc intercept, achieves a misclassiﬁcation error that is as good as AdaBoost’s. This may help to explain the empirical observations made by Cortes and Mohri, and Caruana and Niculescu-Mizil, about the excellent performance of AdaBoost as a bipartite ranking algorithm, as measured by the area under the ROC curve. Keywords: ranking, RankBoost, generalization bounds, AdaBoost, area under the ROC curve</p><p>6 0.051326603 <a title="73-tfidf-6" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>7 0.05013632 <a title="73-tfidf-7" href="./jmlr-2009-On_the_Consistency_of_Feature_Selection_using_Greedy_Least_Squares_Regression.html">66 jmlr-2009-On the Consistency of Feature Selection using Greedy Least Squares Regression</a></p>
<p>8 0.049630538 <a title="73-tfidf-8" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>9 0.043278702 <a title="73-tfidf-9" href="./jmlr-2009-On_Uniform_Deviations_of_General_Empirical_Risks_with_Unboundedness%2C_Dependence%2C_and_High_Dimensionality.html">65 jmlr-2009-On Uniform Deviations of General Empirical Risks with Unboundedness, Dependence, and High Dimensionality</a></p>
<p>10 0.041866489 <a title="73-tfidf-10" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>11 0.033717725 <a title="73-tfidf-11" href="./jmlr-2009-Exploiting_Product_Distributions_to_Identify_Relevant_Variables_of_Correlation_Immune_Functions.html">32 jmlr-2009-Exploiting Product Distributions to Identify Relevant Variables of Correlation Immune Functions</a></p>
<p>12 0.031333596 <a title="73-tfidf-12" href="./jmlr-2009-Multi-task_Reinforcement_Learning_in_Partially_Observable_Stochastic_Environments.html">57 jmlr-2009-Multi-task Reinforcement Learning in Partially Observable Stochastic Environments</a></p>
<p>13 0.028726462 <a title="73-tfidf-13" href="./jmlr-2009-Learning_When_Concepts_Abound.html">50 jmlr-2009-Learning When Concepts Abound</a></p>
<p>14 0.028485157 <a title="73-tfidf-14" href="./jmlr-2009-Identification_of_Recurrent_Neural_Networks_by_Bayesian_Interrogation_Techniques.html">40 jmlr-2009-Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques</a></p>
<p>15 0.024218529 <a title="73-tfidf-15" href="./jmlr-2009-Subgroup_Analysis_via_Recursive_Partitioning.html">91 jmlr-2009-Subgroup Analysis via Recursive Partitioning</a></p>
<p>16 0.023017429 <a title="73-tfidf-16" href="./jmlr-2009-Nearest_Neighbor_Clustering%3A_A_Baseline_Method_for_Consistent_Clustering_with_Arbitrary_Objective_Functions.html">59 jmlr-2009-Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions</a></p>
<p>17 0.022780962 <a title="73-tfidf-17" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>18 0.022664066 <a title="73-tfidf-18" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>19 0.021108743 <a title="73-tfidf-19" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>20 0.019773759 <a title="73-tfidf-20" href="./jmlr-2009-RL-Glue%3A_Language-Independent_Software_for_Reinforcement-Learning_Experiments%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">77 jmlr-2009-RL-Glue: Language-Independent Software for Reinforcement-Learning Experiments    (Machine Learning Open Source Software Paper)</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.13), (1, 0.064), (2, 0.048), (3, 0.002), (4, 0.057), (5, -0.108), (6, 0.098), (7, -0.134), (8, 0.047), (9, -0.017), (10, 0.05), (11, -0.146), (12, -0.031), (13, -0.042), (14, -0.114), (15, 0.004), (16, -0.016), (17, 0.24), (18, -0.09), (19, -0.003), (20, -0.431), (21, 0.051), (22, -0.089), (23, -0.174), (24, -0.025), (25, -0.088), (26, 0.007), (27, 0.036), (28, 0.268), (29, 0.041), (30, -0.088), (31, 0.103), (32, -0.188), (33, 0.022), (34, 0.003), (35, -0.093), (36, 0.045), (37, 0.077), (38, -0.031), (39, -0.11), (40, 0.014), (41, 0.043), (42, -0.042), (43, 0.053), (44, 0.021), (45, 0.06), (46, -0.027), (47, 0.091), (48, 0.056), (49, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95752805 <a title="73-lsi-1" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>Author: Vladimir Vovk, Fedor Zhdanov</p><p>Abstract: We show that the Brier game of prediction is mixable and ﬁnd the optimal learning rate and substitution function for it. The resulting prediction algorithm is applied to predict results of football and tennis matches, with well-known bookmakers playing the role of experts. The theoretical performance guarantee is not excessively loose on the football data set and is rather tight on the tennis data set. Keywords: Brier game, classiﬁcation, on-line prediction, strong aggregating algorithm, weighted average algorithm</p><p>2 0.59462994 <a title="73-lsi-2" href="./jmlr-2009-Learning_Permutations_with_Exponential_Weights.html">49 jmlr-2009-Learning Permutations with Exponential Weights</a></p>
<p>Author: David P. Helmbold, Manfred K. Warmuth</p><p>Abstract: We give an algorithm for the on-line learning of permutations. The algorithm maintains its uncertainty about the target permutation as a doubly stochastic weight matrix, and makes predictions using an efﬁcient method for decomposing the weight matrix into a convex combination of permutations. The weight matrix is updated by multiplying the current matrix entries by exponential factors, and an iterative procedure is needed to restore double stochasticity. Even though the result of this procedure does not have a closed form, a new analysis approach allows us to prove an optimal (up to small constant factors) bound on the regret of our algorithm. This regret bound is signiﬁcantly better than that of either Kalai and Vempala’s more efﬁcient Follow the Perturbed Leader algorithm or the computationally expensive method of explicitly representing each permutation as an expert. Keywords: permutation, ranking, on-line learning, Hedge algorithm, doubly stochastic matrix, relative entropy projection, Sinkhorn balancing</p><p>3 0.41160789 <a title="73-lsi-3" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>Author: Shie Mannor, John N. Tsitsiklis, Jia Yuan Yu</p><p>Abstract: We study online learning where a decision maker interacts with Nature with the objective of maximizing her long-term average reward subject to some sample path average constraints. We deﬁne the reward-in-hindsight as the highest reward the decision maker could have achieved, while satisfying the constraints, had she known Nature’s choices in advance. We show that in general the reward-in-hindsight is not attainable. The convex hull of the reward-in-hindsight function is, however, attainable. For the important case of a single constraint, the convex hull turns out to be the highest attainable function. Using a calibrated forecasting rule, we provide an explicit strategy that attains this convex hull. We also measure the performance of heuristic methods based on non-calibrated forecasters in experiments involving a CPU power management problem. Keywords: online learning, calibration, regret minimization, approachability</p><p>4 0.37248713 <a title="73-lsi-4" href="./jmlr-2009-Data-driven_Calibration_of_Penalties_for_Least-Squares_Regression.html">21 jmlr-2009-Data-driven Calibration of Penalties for Least-Squares Regression</a></p>
<p>Author: Sylvain Arlot, Pascal Massart</p><p>Abstract: Penalization procedures often suffer from their dependence on multiplying factors, whose optimal values are either unknown or hard to estimate from data. We propose a completely data-driven calibration algorithm for these parameters in the least-squares regression framework, without assuming a particular shape for the penalty. Our algorithm relies on the concept of minimal penalty, recently introduced by Birg´ and Massart (2007) in the context of penalized least squares for Gaussian hoe moscedastic regression. On the positive side, the minimal penalty can be evaluated from the data themselves, leading to a data-driven estimation of an optimal penalty which can be used in practice; on the negative side, their approach heavily relies on the homoscedastic Gaussian nature of their stochastic framework. The purpose of this paper is twofold: stating a more general heuristics for designing a datadriven penalty (the slope heuristics) and proving that it works for penalized least-squares regression with a random design, even for heteroscedastic non-Gaussian data. For technical reasons, some exact mathematical results will be proved only for regressogram bin-width selection. This is at least a ﬁrst step towards further results, since the approach and the method that we use are indeed general. Keywords: data-driven calibration, non-parametric regression, model selection by penalization, heteroscedastic data, regressogram</p><p>5 0.32246444 <a title="73-lsi-5" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>Author: Halbert White, Karim Chalak</p><p>Abstract: Judea Pearl’s Causal Model is a rich framework that provides deep insight into the nature of causal relations. As yet, however, the Pearl Causal Model (PCM) has had a lesser impact on economics or econometrics than on other disciplines. This may be due in part to the fact that the PCM is not as well suited to analyzing structures that exhibit features of central interest to economists and econometricians: optimization, equilibrium, and learning. We offer the settable systems framework as an extension of the PCM that permits causal discourse in systems embodying optimization, equilibrium, and learning. Because these are common features of physical, natural, or social systems, our framework may prove generally useful for machine learning. Important features distinguishing the settable system framework from the PCM are its countable dimensionality and the use of partitioning and partition-speciﬁc response functions to accommodate the behavior of optimizing and interacting agents and to eliminate the requirement of a unique ﬁxed point for the system. Reﬁnements of the PCM include the settable systems treatment of attributes, the causal role of exogenous variables, and the dual role of variables as causes and responses. A series of closely related machine learning examples and examples from game theory and machine learning with feedback demonstrates some limitations of the PCM and motivates the distinguishing features of settable systems. Keywords: equations causal models, game theory, machine learning, recursive estimation, simultaneous</p><p>6 0.27925625 <a title="73-lsi-6" href="./jmlr-2009-On_the_Consistency_of_Feature_Selection_using_Greedy_Least_Squares_Regression.html">66 jmlr-2009-On the Consistency of Feature Selection using Greedy Least Squares Regression</a></p>
<p>7 0.20113632 <a title="73-lsi-7" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>8 0.19338635 <a title="73-lsi-8" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>9 0.16566837 <a title="73-lsi-9" href="./jmlr-2009-Learning_Nondeterministic_Classifiers.html">48 jmlr-2009-Learning Nondeterministic Classifiers</a></p>
<p>10 0.14738597 <a title="73-lsi-10" href="./jmlr-2009-Multi-task_Reinforcement_Learning_in_Partially_Observable_Stochastic_Environments.html">57 jmlr-2009-Multi-task Reinforcement Learning in Partially Observable Stochastic Environments</a></p>
<p>11 0.14622782 <a title="73-lsi-11" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>12 0.1450818 <a title="73-lsi-12" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>13 0.14302516 <a title="73-lsi-13" href="./jmlr-2009-On_Uniform_Deviations_of_General_Empirical_Risks_with_Unboundedness%2C_Dependence%2C_and_High_Dimensionality.html">65 jmlr-2009-On Uniform Deviations of General Empirical Risks with Unboundedness, Dependence, and High Dimensionality</a></p>
<p>14 0.13640527 <a title="73-lsi-14" href="./jmlr-2009-Classification_with_Gaussians_and_Convex_Loss.html">16 jmlr-2009-Classification with Gaussians and Convex Loss</a></p>
<p>15 0.12357535 <a title="73-lsi-15" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>16 0.11924871 <a title="73-lsi-16" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>17 0.11726086 <a title="73-lsi-17" href="./jmlr-2009-Nearest_Neighbor_Clustering%3A_A_Baseline_Method_for_Consistent_Clustering_with_Arbitrary_Objective_Functions.html">59 jmlr-2009-Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions</a></p>
<p>18 0.10720576 <a title="73-lsi-18" href="./jmlr-2009-Learning_Halfspaces_with_Malicious_Noise.html">46 jmlr-2009-Learning Halfspaces with Malicious Noise</a></p>
<p>19 0.10440937 <a title="73-lsi-19" href="./jmlr-2009-Universal_Kernel-Based_Learning_with_Applications_to_Regular_Languages%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">98 jmlr-2009-Universal Kernel-Based Learning with Applications to Regular Languages    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>20 0.099137239 <a title="73-lsi-20" href="./jmlr-2009-Evolutionary_Model_Type_Selection_for_Global_Surrogate_Modeling.html">31 jmlr-2009-Evolutionary Model Type Selection for Global Surrogate Modeling</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.049), (20, 0.01), (31, 0.012), (40, 0.013), (42, 0.058), (43, 0.07), (62, 0.016), (74, 0.527), (85, 0.03), (87, 0.036), (97, 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.71056747 <a title="73-lda-1" href="./jmlr-2009-A_Survey_of_Accuracy_Evaluation_Metrics_of_Recommendation_Tasks.html">4 jmlr-2009-A Survey of Accuracy Evaluation Metrics of Recommendation Tasks</a></p>
<p>Author: Asela Gunawardana, Guy Shani</p><p>Abstract: Recommender systems are now popular both commercially and in the research community, where many algorithms have been suggested for providing recommendations. These algorithms typically perform differently in various domains and tasks. Therefore, it is important from the research perspective, as well as from a practical view, to be able to decide on an algorithm that matches the domain and the task of interest. The standard way to make such decisions is by comparing a number of algorithms ofﬂine using some evaluation metric. Indeed, many evaluation metrics have been suggested for comparing recommendation algorithms. The decision on the proper evaluation metric is often critical, as each metric may favor a different algorithm. In this paper we review the proper construction of ofﬂine experiments for deciding on the most appropriate algorithm. We discuss three important tasks of recommender systems, and classify a set of appropriate well known evaluation metrics for each task. We demonstrate how using an improper evaluation metric can lead to the selection of an improper algorithm for the task of interest. We also discuss other important considerations when designing ofﬂine experiments. Keywords: recommender systems, collaborative ﬁltering, statistical analysis, comparative studies</p><p>same-paper 2 0.64767706 <a title="73-lda-2" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>Author: Vladimir Vovk, Fedor Zhdanov</p><p>Abstract: We show that the Brier game of prediction is mixable and ﬁnd the optimal learning rate and substitution function for it. The resulting prediction algorithm is applied to predict results of football and tennis matches, with well-known bookmakers playing the role of experts. The theoretical performance guarantee is not excessively loose on the football data set and is rather tight on the tennis data set. Keywords: Brier game, classiﬁcation, on-line prediction, strong aggregating algorithm, weighted average algorithm</p><p>3 0.34157267 <a title="73-lda-3" href="./jmlr-2009-Scalable_Collaborative_Filtering_Approaches_for_Large_Recommender_Systems%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">84 jmlr-2009-Scalable Collaborative Filtering Approaches for Large Recommender Systems    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Gábor Takács, István Pilászy, Bottyán Németh, Domonkos Tikk</p><p>Abstract: The collaborative ﬁltering (CF) using known user ratings of items has proved to be effective for predicting user preferences in item selection. This thriving subﬁeld of machine learning became popular in the late 1990s with the spread of online services that use recommender systems, such as Amazon, Yahoo! Music, and Netﬂix. CF approaches are usually designed to work on very large data sets. Therefore the scalability of the methods is crucial. In this work, we propose various scalable solutions that are validated against the Netﬂix Prize data set, currently the largest publicly available collection. First, we propose various matrix factorization (MF) based techniques. Second, a neighbor correction method for MF is outlined, which alloys the global perspective of MF and the localized property of neighbor based approaches efﬁciently. In the experimentation section, we ﬁrst report on some implementation issues, and we suggest on how parameter optimization can be performed efﬁciently for MFs. We then show that the proposed scalable approaches compare favorably with existing ones in terms of prediction accuracy and/or required training time. Finally, we report on some experiments performed on MovieLens and Jester data sets. Keywords: collaborative ﬁltering, recommender systems, matrix factorization, neighbor based correction, Netﬂix prize ∗. All authors also afﬁliated with Gravity R&D; Ltd., 1092 Budapest, Kinizsi u. 11., Hungary; info@gravityrd.com. c 2009 G´ bor Tak´ cs, Istv´ n Pil´ szy, Botty´ n N´ meth and Domonkos Tikk. a a a a a e ´ ´ ´ TAK ACS , P IL ASZY, N E METH AND T IKK</p><p>4 0.32409197 <a title="73-lda-4" href="./jmlr-2009-An_Anticorrelation_Kernel_for_Subsystem_Training_in_Multiple_Classifier_Systems.html">8 jmlr-2009-An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems</a></p>
<p>Author: Luciana Ferrer, Kemal Sönmez, Elizabeth Shriberg</p><p>Abstract: We present a method for training support vector machine (SVM)-based classiﬁcation systems for combination with other classiﬁcation systems designed for the same task. Ideally, a new system should be designed such that, when combined with existing systems, the resulting performance is optimized. We present a simple model for this problem and use the understanding gained from this analysis to propose a method to achieve better combination performance when training SVM systems. We include a regularization term in the SVM objective function that aims to reduce the average class-conditional covariance between the resulting scores and the scores produced by the existing systems, introducing a trade-off between such covariance and the system’s individual performance. That is, the new system “takes one for the team”, falling somewhat short of its best possible performance in order to increase the diversity of the ensemble. We report results on the NIST 2005 and 2006 speaker recognition evaluations (SREs) for a variety of subsystems. We show a gain of 19% on the equal error rate (EER) of a combination of four systems when applying the proposed method with respect to the performance obtained when the four systems are trained independently of each other. Keywords: system combination, ensemble diversity, multiple classiﬁer systems, support vector machines, speaker recognition, kernel methods ∗. This author performed part of the work presented in this paper while at the Information Systems Laboratory, Department of Electrical Engineering, Stanford University. c 2009 Luciana Ferrer, Kemal S¨ nmez and Elizabeth Shriberg. o ¨ F ERRER , S ONMEZ AND S HRIBERG</p><p>5 0.29983816 <a title="73-lda-5" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>Author: Halbert White, Karim Chalak</p><p>Abstract: Judea Pearl’s Causal Model is a rich framework that provides deep insight into the nature of causal relations. As yet, however, the Pearl Causal Model (PCM) has had a lesser impact on economics or econometrics than on other disciplines. This may be due in part to the fact that the PCM is not as well suited to analyzing structures that exhibit features of central interest to economists and econometricians: optimization, equilibrium, and learning. We offer the settable systems framework as an extension of the PCM that permits causal discourse in systems embodying optimization, equilibrium, and learning. Because these are common features of physical, natural, or social systems, our framework may prove generally useful for machine learning. Important features distinguishing the settable system framework from the PCM are its countable dimensionality and the use of partitioning and partition-speciﬁc response functions to accommodate the behavior of optimizing and interacting agents and to eliminate the requirement of a unique ﬁxed point for the system. Reﬁnements of the PCM include the settable systems treatment of attributes, the causal role of exogenous variables, and the dual role of variables as causes and responses. A series of closely related machine learning examples and examples from game theory and machine learning with feedback demonstrates some limitations of the PCM and motivates the distinguishing features of settable systems. Keywords: equations causal models, game theory, machine learning, recursive estimation, simultaneous</p><p>6 0.2623271 <a title="73-lda-6" href="./jmlr-2009-Using_Local_Dependencies_within_Batches_to_Improve_Large_Margin_Classifiers.html">99 jmlr-2009-Using Local Dependencies within Batches to Improve Large Margin Classifiers</a></p>
<p>7 0.26028341 <a title="73-lda-7" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>8 0.24532746 <a title="73-lda-8" href="./jmlr-2009-Identification_of_Recurrent_Neural_Networks_by_Bayesian_Interrogation_Techniques.html">40 jmlr-2009-Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques</a></p>
<p>9 0.23724541 <a title="73-lda-9" href="./jmlr-2009-Learning_Nondeterministic_Classifiers.html">48 jmlr-2009-Learning Nondeterministic Classifiers</a></p>
<p>10 0.23676977 <a title="73-lda-10" href="./jmlr-2009-Supervised_Descriptive_Rule_Discovery%3A_A_Unifying_Survey_of_Contrast_Set%2C_Emerging_Pattern_and_Subgroup_Mining.html">92 jmlr-2009-Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining</a></p>
<p>11 0.23354547 <a title="73-lda-11" href="./jmlr-2009-Stable_and_Efficient_Gaussian_Process_Calculations.html">88 jmlr-2009-Stable and Efficient Gaussian Process Calculations</a></p>
<p>12 0.22893094 <a title="73-lda-12" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>13 0.22351047 <a title="73-lda-13" href="./jmlr-2009-Feature_Selection_with_Ensembles%2C_Artificial_Variables%2C_and_Redundancy_Elimination%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">35 jmlr-2009-Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination    (Special Topic on Model Selection)</a></p>
<p>14 0.22156985 <a title="73-lda-14" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>15 0.22031572 <a title="73-lda-15" href="./jmlr-2009-Analysis_of_Perceptron-Based_Active_Learning.html">9 jmlr-2009-Analysis of Perceptron-Based Active Learning</a></p>
<p>16 0.22008184 <a title="73-lda-16" href="./jmlr-2009-Fourier_Theoretic_Probabilistic_Inference_over_Permutations.html">36 jmlr-2009-Fourier Theoretic Probabilistic Inference over Permutations</a></p>
<p>17 0.21931605 <a title="73-lda-17" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>18 0.21905893 <a title="73-lda-18" href="./jmlr-2009-Transfer_Learning_for_Reinforcement_Learning_Domains%3A_A_Survey.html">96 jmlr-2009-Transfer Learning for Reinforcement Learning Domains: A Survey</a></p>
<p>19 0.21781647 <a title="73-lda-19" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>20 0.21691771 <a title="73-lda-20" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
