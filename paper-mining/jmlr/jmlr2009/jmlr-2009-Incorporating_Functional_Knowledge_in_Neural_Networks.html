<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-42" href="#">jmlr2009-42</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</h1>
<br/><p>Source: <a title="jmlr-2009-42-pdf" href="http://jmlr.org/papers/volume10/dugas09a/dugas09a.pdf">pdf</a></p><p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz1 functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints. Keywords: neural networks, universal approximation, monotonicity, convexity, call options</p><p>Reference: <a title="jmlr-2009-42-reference" href="../jmlr2009_reference/jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ih', 0.449), ('ph', 0.375), ('cpsd', 0.296), ('umlp', 0.274), ('gridpoint', 0.219), ('softpl', 0.219), ('ik', 0.201), ('architect', 0.17), ('pric', 0.164), ('nadeau', 0.164), ('gh', 0.161), ('lisl', 0.153), ('uga', 0.131), ('quart', 0.125), ('ncorp', 0.12), ('engio', 0.112), ('asset', 0.11), ('sigmoid', 0.109), ('nowledg', 0.102), ('opt', 0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="42-tfidf-1" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz1 functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints. Keywords: neural networks, universal approximation, monotonicity, convexity, call options</p><p>2 0.10370222 <a title="42-tfidf-2" href="./jmlr-2009-Adaptive_False_Discovery_Rate_Control_under_Independence_and_Dependence.html">5 jmlr-2009-Adaptive False Discovery Rate Control under Independence and Dependence</a></p>
<p>Author: Gilles Blanchard,  Étienne Roquain</p><p>Abstract: In the context of multiple hypothesis testing, the proportion π0 of true null hypotheses in the pool of hypotheses to test often plays a crucial role, although it is generally unknown a priori. A testing procedure using an implicit or explicit estimate of this quantity in order to improve its efﬁcency is called adaptive. In this paper, we focus on the issue of false discovery rate (FDR) control and we present new adaptive multiple testing procedures with control of the FDR. In a ﬁrst part, assuming independence of the p-values, we present two new procedures and give a uniﬁed review of other existing adaptive procedures that have provably controlled FDR. We report extensive simulation results comparing these procedures and testing their robustness when the independence assumption is violated. The new proposed procedures appear competitive with existing ones. The overall best, though, is reported to be Storey’s estimator, albeit for a speciﬁc parameter setting that does not appear to have been considered before. In a second part, we propose adaptive versions of step-up procedures that have provably controlled FDR under positive dependence and unspeciﬁed dependence of the p-values, respectively. In the latter case, while simulations only show an improvement over non-adaptive procedures in limited situations, these are to our knowledge among the ﬁrst theoretically founded adaptive multiple testing procedures that control the FDR when the p-values are not independent. Keywords: multiple testing, false discovery rate, adaptive procedure, positive regression dependence, p-values</p><p>3 0.090070546 <a title="42-tfidf-3" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>Author: Cynthia Rudin</p><p>Abstract: We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This “push” near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. Keywords: ranking, RankBoost, generalization bounds, ROC, information retrieval</p><p>4 0.08531706 <a title="42-tfidf-4" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>Author: Hugo Larochelle, Yoshua Bengio, Jérôme Louradour, Pascal Lamblin</p><p>Abstract: Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments conﬁrm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms. Keywords: artiﬁcial neural networks, deep belief networks, restricted Boltzmann machines, autoassociators, unsupervised learning</p><p>5 0.065734856 <a title="42-tfidf-5" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>Author: Cynthia Rudin, Robert E. Schapire</p><p>Abstract: We study boosting algorithms for learning to rank. We give a general margin-based bound for ranking based on covering numbers for the hypothesis space. Our bound suggests that algorithms that maximize the ranking margin will generalize well. We then describe a new algorithm, smooth margin ranking, that precisely converges to a maximum ranking-margin solution. The algorithm is a modiﬁcation of RankBoost, analogous to “approximate coordinate ascent boosting.” Finally, we prove that AdaBoost and RankBoost are equally good for the problems of bipartite ranking and classiﬁcation in terms of their asymptotic behavior on the training set. Under natural conditions, AdaBoost achieves an area under the ROC curve that is equally as good as RankBoost’s; furthermore, RankBoost, when given a speciﬁc intercept, achieves a misclassiﬁcation error that is as good as AdaBoost’s. This may help to explain the empirical observations made by Cortes and Mohri, and Caruana and Niculescu-Mizil, about the excellent performance of AdaBoost as a bipartite ranking algorithm, as measured by the area under the ROC curve. Keywords: ranking, RankBoost, generalization bounds, AdaBoost, area under the ROC curve</p><p>6 0.040905546 <a title="42-tfidf-6" href="./jmlr-2009-Nieme%3A_Large-Scale_Energy-Based_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">60 jmlr-2009-Nieme: Large-Scale Energy-Based Models    (Machine Learning Open Source Software Paper)</a></p>
<p>7 0.035193361 <a title="42-tfidf-7" href="./jmlr-2009-NEUROSVM%3A_An_Architecture_to_Reduce_the_Effect_of_the_Choice_of_Kernel_on_the_Performance_of_SVM.html">58 jmlr-2009-NEUROSVM: An Architecture to Reduce the Effect of the Choice of Kernel on the Performance of SVM</a></p>
<p>8 0.029772962 <a title="42-tfidf-8" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>9 0.028619252 <a title="42-tfidf-9" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>10 0.025499133 <a title="42-tfidf-10" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>11 0.024384692 <a title="42-tfidf-11" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>12 0.02421722 <a title="42-tfidf-12" href="./jmlr-2009-Estimation_of_Sparse_Binary_Pairwise_Markov_Networks_using_Pseudo-likelihoods.html">30 jmlr-2009-Estimation of Sparse Binary Pairwise Markov Networks using Pseudo-likelihoods</a></p>
<p>13 0.023162674 <a title="42-tfidf-13" href="./jmlr-2009-Similarity-based_Classification%3A_Concepts_and_Algorithms.html">86 jmlr-2009-Similarity-based Classification: Concepts and Algorithms</a></p>
<p>14 0.022867216 <a title="42-tfidf-14" href="./jmlr-2009-Strong_Limit_Theorems_for_the_Bayesian_Scoring_Criterion_in_Bayesian_Networks.html">89 jmlr-2009-Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks</a></p>
<p>15 0.022664066 <a title="42-tfidf-15" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>16 0.021061771 <a title="42-tfidf-16" href="./jmlr-2009-Bi-Level_Path_Following_for_Cross_Validated_Solution_of_Kernel_Quantile_Regression.html">12 jmlr-2009-Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression</a></p>
<p>17 0.020433376 <a title="42-tfidf-17" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>18 0.020260945 <a title="42-tfidf-18" href="./jmlr-2009-Reproducing_Kernel_Banach_Spaces_for_Machine_Learning.html">80 jmlr-2009-Reproducing Kernel Banach Spaces for Machine Learning</a></p>
<p>19 0.020179424 <a title="42-tfidf-19" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>20 0.020051328 <a title="42-tfidf-20" href="./jmlr-2009-Learning_Permutations_with_Exponential_Weights.html">49 jmlr-2009-Learning Permutations with Exponential Weights</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.116), (1, 0.06), (2, -0.05), (3, -0.108), (4, 0.007), (5, -0.078), (6, -0.004), (7, -0.185), (8, 0.024), (9, 0.09), (10, -0.022), (11, 0.017), (12, 0.046), (13, 0.03), (14, 0.042), (15, -0.212), (16, 0.173), (17, 0.048), (18, -0.251), (19, 0.28), (20, -0.016), (21, 0.115), (22, 0.01), (23, 0.028), (24, 0.04), (25, 0.095), (26, 0.066), (27, 0.109), (28, -0.054), (29, -0.034), (30, -0.029), (31, 0.117), (32, -0.016), (33, -0.168), (34, -0.063), (35, 0.144), (36, 0.079), (37, -0.005), (38, -0.008), (39, 0.191), (40, 0.001), (41, 0.058), (42, -0.089), (43, 0.128), (44, -0.073), (45, -0.034), (46, 0.074), (47, -0.076), (48, -0.09), (49, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92606205 <a title="42-lsi-1" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz1 functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints. Keywords: neural networks, universal approximation, monotonicity, convexity, call options</p><p>2 0.49902371 <a title="42-lsi-2" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>Author: Hugo Larochelle, Yoshua Bengio, Jérôme Louradour, Pascal Lamblin</p><p>Abstract: Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments conﬁrm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms. Keywords: artiﬁcial neural networks, deep belief networks, restricted Boltzmann machines, autoassociators, unsupervised learning</p><p>3 0.43288457 <a title="42-lsi-3" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>Author: Cynthia Rudin</p><p>Abstract: We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This “push” near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. Keywords: ranking, RankBoost, generalization bounds, ROC, information retrieval</p><p>4 0.34736902 <a title="42-lsi-4" href="./jmlr-2009-Nieme%3A_Large-Scale_Energy-Based_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">60 jmlr-2009-Nieme: Large-Scale Energy-Based Models    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Francis Maes</p><p>Abstract: N IEME,1 In this paper we introduce a machine learning library for large-scale classiﬁcation, regression and ranking. N IEME relies on the framework of energy-based models (LeCun et al., 2006) which uniﬁes several learning algorithms ranging from simple perceptrons to recent models such as the pegasos support vector machine or l1-regularized maximum entropy models. This framework also uniﬁes batch and stochastic learning which are both seen as energy minimization problems. N IEME can hence be used in a wide range of situations, but is particularly interesting for large-scale learning tasks where both the examples and the features are processed incrementally. Being able to deal with new incoming features at any time within the learning process is another original feature of the N IEME toolbox. N IEME is released under the GPL license. It is efﬁciently implemented in C++, it works on Linux, Mac OS X and Windows and provides interfaces for C++, Java and Python. Keywords: large-scale machine learning, classiﬁcation, ranking, regression, energy-based models, machine learning software</p><p>5 0.31456563 <a title="42-lsi-5" href="./jmlr-2009-NEUROSVM%3A_An_Architecture_to_Reduce_the_Effect_of_the_Choice_of_Kernel_on_the_Performance_of_SVM.html">58 jmlr-2009-NEUROSVM: An Architecture to Reduce the Effect of the Choice of Kernel on the Performance of SVM</a></p>
<p>Author: Pradip Ghanty, Samrat Paul, Nikhil R. Pal</p><p>Abstract: In this paper we propose a new multilayer classiﬁer architecture. The proposed hybrid architecture has two cascaded modules: feature extraction module and classiﬁcation module. In the feature extraction module we use the multilayered perceptron (MLP) neural networks, although other tools such as radial basis function (RBF) networks can be used. In the classiﬁcation module we use support vector machines (SVMs)—here also other tool such as MLP or RBF can be used. The feature extraction module has several sub-modules each of which is expected to extract features capturing the discriminating characteristics of different areas of the input space. The classiﬁcation module classiﬁes the data based on the extracted features. The resultant architecture with MLP in feature extraction module and SVM in classiﬁcation module is called NEUROSVM. The NEUROSVM is tested on twelve benchmark data sets and the performance of the NEUROSVM is found to be better than both MLP and SVM. We also compare the performance of proposed architecture with that of two ensemble methods: majority voting and averaging. Here also the NEUROSVM is found to perform better than these two ensemble methods. Further we explore the use of MLP and RBF in the classiﬁcation module of the proposed architecture. The most attractive feature of NEUROSVM is that it practically eliminates the severe dependency of SVM on the choice of kernel. This has been veriﬁed with respect to both linear and non-linear kernels. We have also demonstrated that for the feature extraction module, the full training of MLPs is not needed. Keywords: feature extraction, neural networks (NNs), support vector machines (SVMs), hybrid system, majority voting, averaging c 2009 Pradip Ghanty, Samrat Paul and Nikhil R. Pal. G HANTY, PAUL AND PAL</p><p>6 0.29060021 <a title="42-lsi-6" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>7 0.24888809 <a title="42-lsi-7" href="./jmlr-2009-Adaptive_False_Discovery_Rate_Control_under_Independence_and_Dependence.html">5 jmlr-2009-Adaptive False Discovery Rate Control under Independence and Dependence</a></p>
<p>8 0.19823128 <a title="42-lsi-8" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>9 0.17831953 <a title="42-lsi-9" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>10 0.1752653 <a title="42-lsi-10" href="./jmlr-2009-Bi-Level_Path_Following_for_Cross_Validated_Solution_of_Kernel_Quantile_Regression.html">12 jmlr-2009-Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression</a></p>
<p>11 0.14933901 <a title="42-lsi-11" href="./jmlr-2009-Application_of_Non_Parametric_Empirical_Bayes_Estimation_to_High_Dimensional_Classification.html">10 jmlr-2009-Application of Non Parametric Empirical Bayes Estimation to High Dimensional Classification</a></p>
<p>12 0.14626697 <a title="42-lsi-12" href="./jmlr-2009-Classification_with_Gaussians_and_Convex_Loss.html">16 jmlr-2009-Classification with Gaussians and Convex Loss</a></p>
<p>13 0.1456655 <a title="42-lsi-13" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>14 0.14225364 <a title="42-lsi-14" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>15 0.14042306 <a title="42-lsi-15" href="./jmlr-2009-Estimation_of_Sparse_Binary_Pairwise_Markov_Networks_using_Pseudo-likelihoods.html">30 jmlr-2009-Estimation of Sparse Binary Pairwise Markov Networks using Pseudo-likelihoods</a></p>
<p>16 0.13962138 <a title="42-lsi-16" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>17 0.13678643 <a title="42-lsi-17" href="./jmlr-2009-A_Parameter-Free_Classification_Method_for_Large_Scale_Learning.html">3 jmlr-2009-A Parameter-Free Classification Method for Large Scale Learning</a></p>
<p>18 0.12829795 <a title="42-lsi-18" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>19 0.12511635 <a title="42-lsi-19" href="./jmlr-2009-Properties_of_Monotonic_Effects_on_Directed_Acyclic_Graphs.html">74 jmlr-2009-Properties of Monotonic Effects on Directed Acyclic Graphs</a></p>
<p>20 0.12446479 <a title="42-lsi-20" href="./jmlr-2009-Data-driven_Calibration_of_Penalties_for_Least-Squares_Regression.html">21 jmlr-2009-Data-driven Calibration of Penalties for Least-Squares Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.044), (14, 0.567), (31, 0.013), (40, 0.06), (42, 0.032), (43, 0.064), (74, 0.017), (85, 0.033), (87, 0.018), (97, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.55391276 <a title="42-lda-1" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz1 functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints. Keywords: neural networks, universal approximation, monotonicity, convexity, call options</p><p>2 0.35886022 <a title="42-lda-2" href="./jmlr-2009-Robustness_and_Regularization_of_Support_Vector_Machines.html">82 jmlr-2009-Robustness and Regularization of Support Vector Machines</a></p>
<p>Author: Huan Xu, Constantine Caramanis, Shie Mannor</p><p>Abstract: We consider regularized support vector machines (SVMs) and show that they are precisely equivalent to a new robust optimization formulation. We show that this equivalence of robust optimization and regularization has implications for both algorithms, and analysis. In terms of algorithms, the equivalence suggests more general SVM-like algorithms for classiﬁcation that explicitly build in protection to noise, and at the same time control overﬁtting. On the analysis front, the equivalence of robustness and regularization provides a robust optimization interpretation for the success of regularized SVMs. We use this new robustness interpretation of SVMs to give a new proof of consistency of (kernelized) SVMs, thus establishing robustness as the reason regularized SVMs generalize well. Keywords: robustness, regularization, generalization, kernel, support vector machine</p><p>3 0.1905846 <a title="42-lda-3" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>Author: Hugo Larochelle, Yoshua Bengio, Jérôme Louradour, Pascal Lamblin</p><p>Abstract: Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments conﬁrm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms. Keywords: artiﬁcial neural networks, deep belief networks, restricted Boltzmann machines, autoassociators, unsupervised learning</p><p>4 0.19054139 <a title="42-lda-4" href="./jmlr-2009-Nonlinear_Models_Using_Dirichlet_Process_Mixtures.html">62 jmlr-2009-Nonlinear Models Using Dirichlet Process Mixtures</a></p>
<p>Author: Babak Shahbaba, Radford Neal</p><p>Abstract: We introduce a new nonlinear model for classiﬁcation, in which we model the joint distribution of response variable, y, and covariates, x, non-parametrically using Dirichlet process mixtures. We keep the relationship between y and x linear within each component of the mixture. The overall relationship becomes nonlinear if the mixture contains more than one component, with different regression coefﬁcients. We use simulated data to compare the performance of this new approach to alternative methods such as multinomial logit (MNL) models, decision trees, and support vector machines. We also evaluate our approach on two classiﬁcation problems: identifying the folding class of protein sequences and detecting Parkinson’s disease. Our model can sometimes improve predictive accuracy. Moreover, by grouping observations into sub-populations (i.e., mixture components), our model can sometimes provide insight into hidden structure in the data. Keywords: mixture models, Dirichlet process, classiﬁcation</p><p>5 0.17492393 <a title="42-lda-5" href="./jmlr-2009-An_Anticorrelation_Kernel_for_Subsystem_Training_in_Multiple_Classifier_Systems.html">8 jmlr-2009-An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems</a></p>
<p>Author: Luciana Ferrer, Kemal Sönmez, Elizabeth Shriberg</p><p>Abstract: We present a method for training support vector machine (SVM)-based classiﬁcation systems for combination with other classiﬁcation systems designed for the same task. Ideally, a new system should be designed such that, when combined with existing systems, the resulting performance is optimized. We present a simple model for this problem and use the understanding gained from this analysis to propose a method to achieve better combination performance when training SVM systems. We include a regularization term in the SVM objective function that aims to reduce the average class-conditional covariance between the resulting scores and the scores produced by the existing systems, introducing a trade-off between such covariance and the system’s individual performance. That is, the new system “takes one for the team”, falling somewhat short of its best possible performance in order to increase the diversity of the ensemble. We report results on the NIST 2005 and 2006 speaker recognition evaluations (SREs) for a variety of subsystems. We show a gain of 19% on the equal error rate (EER) of a combination of four systems when applying the proposed method with respect to the performance obtained when the four systems are trained independently of each other. Keywords: system combination, ensemble diversity, multiple classiﬁer systems, support vector machines, speaker recognition, kernel methods ∗. This author performed part of the work presented in this paper while at the Information Systems Laboratory, Department of Electrical Engineering, Stanford University. c 2009 Luciana Ferrer, Kemal S¨ nmez and Elizabeth Shriberg. o ¨ F ERRER , S ONMEZ AND S HRIBERG</p><p>6 0.1733906 <a title="42-lda-6" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>7 0.17322044 <a title="42-lda-7" href="./jmlr-2009-Bayesian_Network_Structure_Learning_by_Recursive_Autonomy_Identification.html">11 jmlr-2009-Bayesian Network Structure Learning by Recursive Autonomy Identification</a></p>
<p>8 0.17300919 <a title="42-lda-8" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>9 0.17246753 <a title="42-lda-9" href="./jmlr-2009-Computing_Maximum_Likelihood_Estimates_in_Recursive_Linear_Models_with_Correlated_Errors.html">17 jmlr-2009-Computing Maximum Likelihood Estimates in Recursive Linear Models with Correlated Errors</a></p>
<p>10 0.17154214 <a title="42-lda-10" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>11 0.17127122 <a title="42-lda-11" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>12 0.17079589 <a title="42-lda-12" href="./jmlr-2009-Feature_Selection_with_Ensembles%2C_Artificial_Variables%2C_and_Redundancy_Elimination%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">35 jmlr-2009-Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination    (Special Topic on Model Selection)</a></p>
<p>13 0.17053755 <a title="42-lda-13" href="./jmlr-2009-Evolutionary_Model_Type_Selection_for_Global_Surrogate_Modeling.html">31 jmlr-2009-Evolutionary Model Type Selection for Global Surrogate Modeling</a></p>
<p>14 0.17032358 <a title="42-lda-14" href="./jmlr-2009-CarpeDiem%3A_Optimizing_the_Viterbi_Algorithm_and_Applications_to_Supervised_Sequential_Learning.html">14 jmlr-2009-CarpeDiem: Optimizing the Viterbi Algorithm and Applications to Supervised Sequential Learning</a></p>
<p>15 0.16962998 <a title="42-lda-15" href="./jmlr-2009-Subgroup_Analysis_via_Recursive_Partitioning.html">91 jmlr-2009-Subgroup Analysis via Recursive Partitioning</a></p>
<p>16 0.16944228 <a title="42-lda-16" href="./jmlr-2009-Distributed_Algorithms_for_Topic_Models.html">25 jmlr-2009-Distributed Algorithms for Topic Models</a></p>
<p>17 0.16924001 <a title="42-lda-17" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>18 0.16911064 <a title="42-lda-18" href="./jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>19 0.16807541 <a title="42-lda-19" href="./jmlr-2009-Ultrahigh_Dimensional_Feature_Selection%3A_Beyond_The_Linear_Model.html">97 jmlr-2009-Ultrahigh Dimensional Feature Selection: Beyond The Linear Model</a></p>
<p>20 0.16803244 <a title="42-lda-20" href="./jmlr-2009-Particle_Swarm_Model_Selection%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">70 jmlr-2009-Particle Swarm Model Selection    (Special Topic on Model Selection)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
