<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-95" href="#">jmlr2009-95</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</h1>
<br/><p>Source: <a title="jmlr-2009-95-pdf" href="http://jmlr.org/papers/volume10/rudin09b/rudin09b.pdf">pdf</a></p><p>Author: Cynthia Rudin</p><p>Abstract: We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This “push” near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. Keywords: ranking, RankBoost, generalization bounds, ROC, information retrieval</p><p>Reference: <a title="jmlr-2009-95-reference" href="../jmlr2009_reference/jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 EDU  MIT Sloan School of Management Cambridge, MA 02142  Editor: Michael Collins  Abstract We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. [sent-2, score-0.224]
</p><p>2 We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. [sent-5, score-0.179]
</p><p>3 We then derive a boosting-style algorithm for the problem of ranking with a push at the top. [sent-7, score-0.351]
</p><p>4 Many of these domains require the construction of a ranked list, yet often, only the top portion of the list is used in practice. [sent-13, score-0.238]
</p><p>5 We expect the user to examine the top portion of the list as a recommendation. [sent-15, score-0.166]
</p><p>6 Thus, we wish to make sure that the top portion of the list is correctly constructed. [sent-17, score-0.166]
</p><p>7 Specifically, we derive a convex objective function that places more emphasis at the top of the list. [sent-20, score-0.187]
</p><p>8 One can concentrate at the very top of the list (a big push, large p), or one can have a moderate emphasis at the top (a little push, low p), or somewhere in between. [sent-24, score-0.189]
</p><p>9 RUDIN  emphasis at the top (no push, p = 1) corresponds to a standard objective for supervised bipartite ranking, namely the exponentiated pairwise misranking error. [sent-28, score-0.197]
</p><p>10 In this case, we want to push the bad movies away from the top of the list where the good movies are desired. [sent-31, score-0.434]
</p><p>11 The accuracy measure for our problem is different; we care mostly about the leftmost portion of the ROC curve, corresponding to the top of the ranked list. [sent-34, score-0.211]
</p><p>12 The bound underscores an important property of algorithms that concentrate on a small portion of the domain, such as algorithms that concentrate on the top of a ranked list: these algorithms require more examples for generalization. [sent-42, score-0.215]
</p><p>13 2234  T HE P-N ORM P USH  There is a large body of literature on information retrieval (IR) that considers other quality measurements for a ranked list, including “discounted cumulative gain,” “average precision” and “winner take all. [sent-67, score-0.147]
</p><p>14 (2005) and Le and Smola (2007) who also minimize a convex upper bound of IR ranking measurements, but with a structured learning approach that requires optimization with exponentially many constraints; those works have suggested useful ways to combat this problem. [sent-72, score-0.158]
</p><p>15 Here is the outline of the work: in Section 2, we present a general form of objective function, allowing us to incorporate a push near the top of the ranked list. [sent-75, score-0.48]
</p><p>16 We will choose g to be a power law, g(r) = r p , so that a higher power p corresponds to a larger push near the top. [sent-77, score-0.268]
</p><p>17 The main contributions of this work are: a generalization bound for a learning problem that is asymmetric by design, a simple user-adjustable, easy-to-implement algorithm for supervised ranking with a “push,” and a proof that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. [sent-95, score-0.204]
</p><p>18 In the case of the movie ranking problem, the xi ’s are the good movies used ˜ for training, the xk ’s are the bad movies, and X is a database of movies. [sent-106, score-0.176]
</p><p>19 We want to concentrate harder on negative examples that have high scores; we want to push these examples down from the top. [sent-115, score-0.301]
</p><p>20 These high scoring negative examples are precisely the examples represented by the leftmost portion of the ROC Curve. [sent-122, score-0.162]
</p><p>21 Minimizing Rg,1 should thus boost performance around high scoring negative examples and increase the leftmost portion of the ROC Curve. [sent-123, score-0.162]
</p><p>22 For the moment, let us assume we care only about the very top of the list, that is, we wish to push the most offending negative example as far down the list as possible. [sent-130, score-0.421]
</p><p>23 Equivalently, we wish to minimize Rmax , the number of positives below the highest scoring negative example: I  Rmax ( f ) := max ∑ 1[ f (xi )≤ f (˜ k )] . [sent-131, score-0.147]
</p><p>24 x k  i=1  2236  T HE P-N ORM P USH  Minimizing this misranking error at the very top is similar to optimizing a “winner take all” loss such as 1[maxi f (xi )≤maxk f (˜ k )] in that both would choose a ranked list where a negative example is not x at the top of the list. [sent-132, score-0.344]
</p><p>25 Thus, Theorem 1 suggests that Rg,ℓ is a reasonable quantity to minimize in order to incorporate a push at the top, for instance, in order to diminish Rmax . [sent-141, score-0.268]
</p><p>26 By allowing the user to choose p, we allow the amount of push to be speciﬁed to match the application. [sent-145, score-0.268]
</p><p>27 Illustrating That It Works In this section, we will give some examples to illustrate how the objective concentrates on the top of the list when p is large, or more generally, when g is steep. [sent-152, score-0.23]
</p><p>28 Swap on the Top For our ﬁrst illustration, we aim simply to show that the objective function we have derived really does care more about the top of the list than the rest. [sent-155, score-0.191]
</p><p>29 Using the power law g(r) = r4 for the price function, we can compute the value of R4,1 ( forig ) for this ranked list: 04 + 14 + 24 + 24 = 33. [sent-162, score-0.159]
</p><p>30 Let us now instead consider a swap near the top of the list, so that the new set of labels is again only one swap away from the original, fswapOnTop (x6 ) = 7, fswapOnTop (x7 ) = 6, and fswapOnTop (xi ) = i for all other i. [sent-167, score-0.217]
</p><p>31 So, in both cases only one swap was made between neighboring examples; however, the swap at the top of the list changed the objective dramatically (from 33 to 98) while the swap at the bottom hardly changed the objective at all (from 33 to 34). [sent-170, score-0.472]
</p><p>32 So, we have now illustrated that the objective function R p,1 ( f ) concentrates at the top of the list. [sent-171, score-0.179]
</p><p>33 The objective functions change much more in reaction to the swap at the top of the list: the values in the third row (swap on the top) are signiﬁcantly higher than those in the second row (swap on the bottom). [sent-182, score-0.203]
</p><p>34 This is an interesting experiment in which there are only 2 choices available for the function f : the ﬁrst concentrates on the top of the ranked list, but performs poorly on the rest, whereas the second performs badly on the top of the ranked list, but performs well over all. [sent-185, score-0.321]
</p><p>35 So, using steeper price functions means that we are more likely to prefer scoring functions that perform well at the top of the list. [sent-196, score-0.2]
</p><p>36 The value of the (i, k)th entry is the contribution of the kth highest scoring negative examp x ple, ∑i¯ e−( f (xi¯)− f (˜ k )) , multiplied by the proportion attributed to the ith highest scoring positive x x example, e−( f (xi )− f (˜ k )) / ∑i¯ e−( f (xi¯)− f (˜ k )) . [sent-268, score-0.201]
</p><p>37 The upper left corner represents the highest (worst) ranked negative and the lowest (worst) ranked positive. [sent-273, score-0.202]
</p><p>38 As before, we suffer some loss whenever ˜ positive example xi is ranked below negative example xk , but now we also suffer loss whenever xi empirical ˜ and xk have scores within θ of each other. [sent-296, score-0.315]
</p><p>39 Theorem 2 (First Generalization Bound) For all ε > 0, p ≥ 1, θ > 0, the probability over random K I choice of training set, S+ ∼ D+ , S− ∼ D− that there exists an f ∈ F such that empirical  Rtrue ( f ) ≥ R p,1,θ p,1 is at most: 2N  F,  εθ 8  exp −2  ε 4  2p  (f)+ε  K + exp −  ε2 I + ln K 8  . [sent-300, score-0.179]
</p><p>40 This is because we are concentrating on a small portion of input space corresponding to the top of the ranked list. [sent-305, score-0.187]
</p><p>41 , K} where index ik corresponds to the ith positive example and the kth negative example. [sent-341, score-0.365]
</p><p>42 This is because e−(Mλ)ik is a convex function of λ, any sum of convex functions is convex, and a composition of an increasing convex function with a convex function is convex. [sent-346, score-0.188]
</p><p>43 Our choice of jt becomes (ignoring constant factors that do not affect the argmax):   I  K  p−1  ∑ dt,ik  ∑  I  ∑ dt,ik Mik, j   ∈  argmax  =  jt  argmax ∑ d˜t,ik Mik, j , where d˜t,ik = dt,ik  j  i=1  k=1  j  i=1  ik  p−1  ∑ dt,i k  . [sent-357, score-0.572]
</p><p>44 dα αt  Ignoring division by constants, this equation becomes: K  0=    p−1  I  ∑  ∑ dt,ik e−α M  k=1  t  I  ∑ Mik, j dt,ik e−α M t  ik, jt  t  i=1  ik, jt  i=1    . [sent-360, score-0.194]
</p><p>45 To avoid having to compute dt+1 directly from λt , we can perform the update by: dt+1,ik =  dt,ik e−αt Mik, jt zt  where zt := ∑ dt,ik e−αt Mik, jt . [sent-364, score-0.194]
</p><p>46 (c) λt+1 = λt + αt e jt , where e jt is 1 in position jt and 0 elsewhere. [sent-399, score-0.291]
</p><p>47 (d) zt = ∑ik dt,ik e−αt Mik, jt (e) dt+1,ik = dt,ik e−αt Mik, jt /zt for i = 1, . [sent-400, score-0.194]
</p><p>48 A trick that comes in handy IK for such situations is to use the closure of the space Q′ := {q′ ∈ R+ |q′ = e−(Mλ)ik for some λ ∈ ik n }. [sent-409, score-0.358]
</p><p>49 With the help of convex analysis, we will be able to show that our objective function yields a unique minimizer in the closure of Q ′ . [sent-411, score-0.166]
</p><p>50 Here is our uniqueness theorem: IK ¯ Theorem 4 Deﬁne Q′ := {q′ ∈ R+ |q′ = e−(Mλ)ik for some λ ∈ R n } and deﬁne Q ′ as the closure ik ′ in R IK . [sent-412, score-0.388]
</p><p>51 Then for p ≥ 1, there is a unique q′∗ ∈ Q ′ where: ¯ of Q p  q = argminq′ ∈Q¯ ′ ∑ ′∗  k  ∑  q′ ik  . [sent-413, score-0.332]
</p><p>52 Our derivation in Section 2 is designed to push the highly ranked negative examples down. [sent-427, score-0.373]
</p><p>53 ” The reverse height of positive example i is the number of negative examples ranked above it. [sent-429, score-0.209]
</p><p>54 The reverse height only considers the relationship of the positives to the negatives, and disregards the relationship of positives to each other. [sent-432, score-0.164]
</p><p>55 =∑ ln (1 + Rank(i)) ¯ x i ln 1 + ∑k 1[ f (xi )≤ f (˜ k )] + ∑i 1[ f (xi )≤ f (xi¯)]  Let us consider the practical implications of minimizing the negation of the DCG. [sent-442, score-0.174]
</p><p>56 It is possible, however, to choose a different discounting factor that allows us to create a convex objective to minimize. [sent-446, score-0.207]
</p><p>57 Let us choose a discounting factor of − ln(1 + z), which is similar to the discounting factors for the AveR and DCG in that it is decreasing and convex. [sent-447, score-0.178]
</p><p>58 Also, one can now write an objective that concentrates on the top and bottom simultaneously such as R p,exp ( f ) + const RBottom ( f ). [sent-463, score-0.2]
</p><p>59 p,exp Crucial Pairs Formulation: The bipartite ranking problem is a speciﬁc case of the pairwise ranking problem. [sent-464, score-0.197]
</p><p>60 For all of these experiments, in agreement with our algorithm’s derivation, a larger push (p large) causes the algorithm to perform better near the top of the ranked list on the training set. [sent-640, score-0.46]
</p><p>61 As discussed, this ability to correct the top of the list is not without sacriﬁce; we do sacriﬁce the ranks of items farther down on the list and we do reduce the value of the AUC, but we have made this choice on purpose in order to perform better near the top of the list. [sent-641, score-0.24]
</p><p>62 The objective for the IR measures needed a concave price function ln(1 + z), in which case the objective convex was made convex by using the exponential loss, in other words. [sent-711, score-0.285]
</p><p>63 Lemma 6 For all ε > 0, PS+ ∼D+ ,S− ∼D− I K  sup L( f ) ≥ ε  f ∈Br  ≤ PS+ ∼D+ ,S− ∼D− L( fr ) ≥ I K  Proof By Lemma 5, for every training set S and for all f ∈ Br , sup L( f ) − L( fr ) ≤ 4Lip(φ) sup || f − fr ||∞ ≤ 4Lip(φ)  f ∈Br  Thus,  f ∈Br  ε . [sent-752, score-0.282]
</p><p>64 Lemma 9 For all ε1 > 0, for all f ∈ F : PS+ ∼D+ ,S− ∼D− L( f ) ≥ ε1 I K  ≤ 2 exp −2K max  ε2 true 1 R p,φ ( f ) 4  2(p−1)  ,  ε1 2  2p  + 2 exp −  ε2 1 I + ln K . [sent-822, score-0.157]
</p><p>65 f ∈Br  f ∈F  First applying the union bound over balls, then applying Lemma 6 we ﬁnd: sup L( f ) ≥ ε  PS+ ∼D I ,S− ∼D K  f ∈F  ℓε  ∑ PS  ≤  r=1  ≤  ∑ PS  + ∼D  I ,S  − ∼D  K  + ∼D  I ,S  − ∼D  K  ℓε  r=1  sup L( f ) ≥ ε  f ∈Br  {L( fr ) ≥ ε/2} . [sent-840, score-0.153]
</p><p>66 The probability that there exists an f ∈ F where empirical  Rtrue ( f ) ≥ R p,φ p,φ  (f)+ε  is at most  N F,  ε 8Lip(φ)  2 exp −2K max  ε ε2 (R p,min )2(p−1) , 16 4 2260  2p  + 2 exp −  ε2 I + ln K 8  ,  T HE P-N ORM P USH  where R p,min = inf f Rtrue ( f ). [sent-843, score-0.179]
</p><p>67 Thus, the probability that there exists an f ∈ F where empirical  Rtrue ( f ) ≥ R p,1,θ p,1  (f)+ε  is at most  N F,  εθ 8  2 exp −2K max  ε ε2 (R p,min )2(p−1) , 16 4  2p  + 2 exp −  ε2 I + ln K 8  . [sent-847, score-0.179]
</p><p>68 A tighter bound is obtained if we bound differently at (9): instead of using Rtrue ( fr ) ≥ inf f ∈F Rtrue ( f ), we could stop at Rtrue ( fr ) ≥ minr Rtrue ( fr ) and then p,1 p,1 p,1 p,1 choose the { fr }r to maximize minr Rtrue ( fr ). [sent-849, score-0.371]
</p><p>69 Entries of p will always be indexed by pik to avoid confusion. [sent-876, score-0.278]
</p><p>70 IK Consider the following function φ : R>0 → [−∞, ∞]: φ(q) := ∑ qik γ(qik , q), where γ(qik , q) := ln ik  qik ∑i′ qi′ k )(p−1)/p  p1/p (  . [sent-924, score-1.409]
</p><p>71 IK We extend the deﬁnition to R+ by the conventions 0 ln 0 = 0 and qik γ(qik , q) = 0 whenever qik = 0 IK for all i. [sent-925, score-1.077]
</p><p>72 The boundary in our case is where qik equals 0 for one or more ik pairs. [sent-927, score-0.827]
</p><p>73 When that happens, qik = 0, and by our convention, qik γ(qik , q) = 0, thus the entire ik term is zero rather than −∞. [sent-934, score-1.322]
</p><p>74 Consider the following calculation for the gradient of φ in int(∆φ ): (∇φ(q))ik =  ∂φ(q) 1 = + ln ∂qik p  qik (p−1)/p  ∑i′ qi′ k )  p1/p (  =  1 + γ(qik , q), p  (11)  since γ(qik , q) → −∞ as qik → 0, φ is essentially smooth. [sent-939, score-1.077]
</p><p>75 Using (11) it can be shown that: p−1 −1  (∇φ) (z)  ik  (zik −1/p)  = pe  ∑e  (zi′ k −1/p)  . [sent-946, score-0.332]
</p><p>76 First, let us compute a term that appears often: ezik −1/p where zik = (∇φ(q) + v)ik =  ezik −1/p = exp  1 + γ(qik , q) + vik can be rewritten: p  1 1 − + γ(qik , q) + vik = evik eγ(qik ,q) . [sent-948, score-0.155]
</p><p>77 p p  Thus from (10), p−1  ∑e  vik γ(qik ,q)  vi′ k γ(qi′ k ,q)  Lφ (q, v)ik = pe e  e  i′  = pevik  qik 1/p ( ′ q ′ )(p−1)/p p ∑i i k (p−1)  vik  = e qik  ∑e  vi′ k  i′  qi′ k 2264  ∑i′ evi′ k qi′ k p1/p (∑i′ qi′ k )(p−1)/p 1 (∑i′ qi′ k )(p−1)  . [sent-949, score-1.08]
</p><p>78 Let us choose q ∈ Q , that is, qik = e−(Mλ)ik ∑i′ e−(Mλ)i′ k using (11) and the deﬁnitions of φ and Bφ : Bφ (0, q) = φ(0) − φ(q) − ∇φ(q), 0 − q = −φ(q) + q · ∇φ(q) 1 = −φ(q) + ∑ qik + φ(q) p ik  = =  1 p∑ k 1 p∑ k  (p−1)  ∑e  ∑e  −(Mλ)i′ k  −(Mλ)ik  i′  i  p  ∑ e−(Mλ)  ik  i  =  1 R p,exp (λ). [sent-955, score-1.654]
</p><p>79 This sequence converges pointwise to qik ¯ ′ , or if q = 0, then the ikth component of the sequence converges to 0. [sent-965, score-0.495]
</p><p>80 p Bφ (p, q0 ) = φ(p) − φ(q0 ) − ∇φ(q0 ), p − q0 1 1 = φ(p) − ∇φ(q0 ), p + I p K = φ(p) − (∇φ(q0 ))ik ∑ pik + I p K p p ik =  ∑ pik ln ik  1 1 pik − (1 − ln p) ∑ pik + I p K. [sent-970, score-1.95]
</p><p>81 p p p1/p (∑i′ pi′ k )(p−1)/p ik 2265  RUDIN  For p = 1 this reduces exactly to the relative entropy case. [sent-971, score-0.332]
</p><p>82 We knew the desired dual problem was precisely our objective R p,exp , thus, we were able to recover the primal problem by convex conjugation. [sent-974, score-0.178]
</p><p>83 Conclusions We have provided a method for constructing a ranked list where correctness at the top of the list is most important. [sent-978, score-0.243]
</p><p>84 Our main contribution is a general set of convex objective functions determined by a loss ℓ and price function g. [sent-979, score-0.191]
</p><p>85 We have demonstrated the effect of a number of different price functions, and it is clear, both theoretically and empirically, that a steeper price function concentrates harder at the top of the list. [sent-981, score-0.229]
</p><p>86 Proof (Of Lemma 11) First, rewrite φ: φ(q) = ∑ k  ∑ qik ln qik i  − (ln p1/p )  ∑ qik i  p−1 p  −  ∑ qik  ln  i  ∑ qik  . [sent-988, score-2.649]
</p><p>87 Deﬁne f : I I R>0 → R as follows, for q ∈ R+ : f (q) :=  ∑ qi ln qi i  Thus, the Hessian is:  +  1− p p  ∑ qi  ln  i  1 1− p 1 ∂ f (q) = δi=ℓ + . [sent-991, score-0.516]
</p><p>88 ∂f ∑ wi wℓ ∂qℓ ∂qi iℓ  ∑  =  i  w2 i  1 ∑i qi  =  2  1 1− p + qi p   ∑ wi i  1  ∑ w2 qi i    1 ∑i qi  ∑ qi  i  2  1 −1 p  +  i  ∑ wi i  Now, consider the Cauchy-Schwarz inequality, used in the following way: 2  ∑ wi  =  i  w √ √ , q q  2  w ≤ √ q  2  √ q  2 2  w2 ∑ qii i  =  2  ∑ qi    . [sent-994, score-0.788]
</p><p>89 i  Substituting back,  iℓ  ≥  1 ∑i qi  =  ∂f  ∑ wi wℓ ∂qℓ ∂qi    1 ∑i qi  1 p    1  ∑ w2 qi i  ∑ qi  i  +  i  1 p  2  ∑ wi i  −  1  ∑ w2 qi i i  ∑ qi i  2  ∑ wi     . [sent-996, score-0.762]
</p><p>90 , let us simplify using (11), where this calculation is valid for p, q ∈ ∆φ × int(∆φ ): Bφ (p, q) = φ(p) − φ(q) − ∇φ(q) · (p − q) 1 = ∑ pik γ(pik , p) − φ(q) − ∑(pik − qik ) − ∑ pik γ(qik , q) + φ(q) p ki ik ik 1 = ∑ pik γ(pik , p) − γ(qik , q) − ∑(pik − qik ). [sent-1008, score-2.488]
</p><p>91 p ik ik 2267  (13)  RUDIN  Now we consider the boundary. [sent-1009, score-0.664]
</p><p>92 If for some ik pair, pik = 0 then let pik (γ(pik , p) − γ(qik , q)) = 0 for all q. [sent-1010, score-0.888]
</p><p>93 If for some ik pair, pik = 0 and additionally qik = 0 we deﬁne Bφ (p, q) = ∞. [sent-1011, score-1.105]
</p><p>94 ∂pik p p  It is true that γ(pik , p) − γ(qik , q) = 0 for pair ik implies that pik = qik . [sent-1016, score-1.105]
</p><p>95 To see this, note that one can determine pik directly from the γ(pik , p) values as follows. [sent-1017, score-0.278]
</p><p>96 If for any ik, pik = 0 and qik = 0 then Bφ (p, q) = ∞ = 0. [sent-1022, score-0.773]
</p><p>97 So, if Bφ (p, q) = 0, then whenever qik = 0 we must have pik = 0. [sent-1023, score-0.773]
</p><p>98 On the other hand, if pik = 0, there will be a contribution to Bφ (p, q) of 1 qik , implying that p qik must be 0 in order for Bφ (p, q) = 0. [sent-1024, score-1.268]
</p><p>99 p ik ik −  p−1  1 ∑i′ qi′ k p−1 (p−1)/p    (∑i′ qi′ k )(p−1)/p    qik   Thus, since Lφ is jointly continuous in q and v, Bφ is jointly continuous in q and v. [sent-1035, score-1.159]
</p><p>100 p∑ ik  ik  (p−1)/p  qik  Since logarithms grow slowly, one can choose a qik large enough so that this sum exceeds any ﬁxed constant c, regardless of the values of the other qik ’s. [sent-1040, score-2.149]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('qik', 0.495), ('rtrue', 0.368), ('ik', 0.332), ('pik', 0.278), ('push', 0.268), ('ir', 0.161), ('rudin', 0.156), ('ush', 0.143), ('rmax', 0.136), ('roc', 0.123), ('qi', 0.114), ('orm', 0.109), ('rg', 0.098), ('jt', 0.097), ('discounting', 0.089), ('ln', 0.087), ('ranking', 0.083), ('ps', 0.083), ('int', 0.08), ('mik', 0.077), ('ranked', 0.072), ('objective', 0.071), ('top', 0.069), ('swap', 0.063), ('height', 0.063), ('fr', 0.063), ('ex', 0.062), ('dcg', 0.06), ('scoring', 0.059), ('lik', 0.057), ('della', 0.057), ('pietra', 0.057), ('auc', 0.056), ('rgir', 0.053), ('rankboost', 0.052), ('list', 0.051), ('price', 0.049), ('convex', 0.047), ('portion', 0.046), ('xi', 0.046), ('br', 0.046), ('aver', 0.045), ('fswaponbot', 0.045), ('magic', 0.045), ('vik', 0.045), ('kg', 0.044), ('curves', 0.043), ('reverse', 0.041), ('concentrates', 0.039), ('forig', 0.038), ('fswapontop', 0.038), ('bregman', 0.037), ('cynthia', 0.037), ('exp', 0.035), ('curve', 0.034), ('clemencon', 0.034), ('negative', 0.033), ('steep', 0.032), ('retrieval', 0.032), ('adaboost', 0.031), ('bipartite', 0.031), ('sup', 0.031), ('positives', 0.03), ('dual', 0.03), ('uniqueness', 0.03), ('zik', 0.03), ('primal', 0.03), ('bound', 0.028), ('mcdiarmid', 0.028), ('wi', 0.026), ('closure', 0.026), ('housing', 0.026), ('ionosphere', 0.026), ('covering', 0.026), ('disks', 0.026), ('linesearch', 0.026), ('misranking', 0.026), ('schapire', 0.025), ('rd', 0.025), ('highest', 0.025), ('leftmost', 0.024), ('loss', 0.024), ('xk', 0.024), ('movies', 0.023), ('argmax', 0.023), ('discounted', 0.023), ('hadron', 0.023), ('rbottom', 0.023), ('steeper', 0.023), ('empirical', 0.022), ('minimizer', 0.022), ('labels', 0.022), ('dramatic', 0.022), ('measurements', 0.022), ('objectives', 0.022), ('quality', 0.021), ('lemma', 0.021), ('rank', 0.021), ('lip', 0.021), ('bottom', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="95-tfidf-1" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>Author: Cynthia Rudin</p><p>Abstract: We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This “push” near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. Keywords: ranking, RankBoost, generalization bounds, ROC, information retrieval</p><p>2 0.28734815 <a title="95-tfidf-2" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>Author: Cynthia Rudin, Robert E. Schapire</p><p>Abstract: We study boosting algorithms for learning to rank. We give a general margin-based bound for ranking based on covering numbers for the hypothesis space. Our bound suggests that algorithms that maximize the ranking margin will generalize well. We then describe a new algorithm, smooth margin ranking, that precisely converges to a maximum ranking-margin solution. The algorithm is a modiﬁcation of RankBoost, analogous to “approximate coordinate ascent boosting.” Finally, we prove that AdaBoost and RankBoost are equally good for the problems of bipartite ranking and classiﬁcation in terms of their asymptotic behavior on the training set. Under natural conditions, AdaBoost achieves an area under the ROC curve that is equally as good as RankBoost’s; furthermore, RankBoost, when given a speciﬁc intercept, achieves a misclassiﬁcation error that is as good as AdaBoost’s. This may help to explain the empirical observations made by Cortes and Mohri, and Caruana and Niculescu-Mizil, about the excellent performance of AdaBoost as a bipartite ranking algorithm, as measured by the area under the ROC curve. Keywords: ranking, RankBoost, generalization bounds, AdaBoost, area under the ROC curve</p><p>3 0.091012262 <a title="95-tfidf-3" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz1 functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints. Keywords: neural networks, universal approximation, monotonicity, convexity, call options</p><p>4 0.088487357 <a title="95-tfidf-4" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>Author: Shivani Agarwal, Partha Niyogi</p><p>Abstract: The problem of ranking, in which the goal is to learn a real-valued ranking function that induces a ranking or ordering over an instance space, has recently gained much attention in machine learning. We study generalization properties of ranking algorithms using the notion of algorithmic stability; in particular, we derive generalization bounds for ranking algorithms that have good stability properties. We show that kernel-based ranking algorithms that perform regularization in a reproducing kernel Hilbert space have such stability properties, and therefore our bounds can be applied to these algorithms; this is in contrast with generalization bounds based on uniform convergence, which in many cases cannot be applied to these algorithms. Our results generalize earlier results that were derived in the special setting of bipartite ranking (Agarwal and Niyogi, 2005) to a more general setting of the ranking problem that arises frequently in applications. Keywords: ranking, generalization bounds, algorithmic stability</p><p>5 0.05859191 <a title="95-tfidf-5" href="./jmlr-2009-Strong_Limit_Theorems_for_the_Bayesian_Scoring_Criterion_in_Bayesian_Networks.html">89 jmlr-2009-Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks</a></p>
<p>Author: Nikolai Slobodianik, Dmitry Zaporozhets, Neal Madras</p><p>Abstract: In the machine learning community, the Bayesian scoring criterion is widely used for model selection problems. One of the fundamental theoretical properties justifying the usage of the Bayesian scoring criterion is its consistency. In this paper we reﬁne this property for the case of binomial Bayesian network models. As a by-product of our derivations we establish strong consistency and obtain the law of iterated logarithm for the Bayesian scoring criterion. Keywords: Bayesian networks, consistency, scoring criterion, model selection, BIC</p><p>6 0.052784577 <a title="95-tfidf-6" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>7 0.051521465 <a title="95-tfidf-7" href="./jmlr-2009-Application_of_Non_Parametric_Empirical_Bayes_Estimation_to_High_Dimensional_Classification.html">10 jmlr-2009-Application of Non Parametric Empirical Bayes Estimation to High Dimensional Classification</a></p>
<p>8 0.047096957 <a title="95-tfidf-8" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>9 0.046843253 <a title="95-tfidf-9" href="./jmlr-2009-Learning_When_Concepts_Abound.html">50 jmlr-2009-Learning When Concepts Abound</a></p>
<p>10 0.04280743 <a title="95-tfidf-10" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>11 0.041637041 <a title="95-tfidf-11" href="./jmlr-2009-Nonextensive_Information_Theoretic_Kernels_on_Measures.html">61 jmlr-2009-Nonextensive Information Theoretic Kernels on Measures</a></p>
<p>12 0.040357329 <a title="95-tfidf-12" href="./jmlr-2009-Learning_Permutations_with_Exponential_Weights.html">49 jmlr-2009-Learning Permutations with Exponential Weights</a></p>
<p>13 0.032051485 <a title="95-tfidf-13" href="./jmlr-2009-Bi-Level_Path_Following_for_Cross_Validated_Solution_of_Kernel_Quantile_Regression.html">12 jmlr-2009-Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression</a></p>
<p>14 0.031179195 <a title="95-tfidf-14" href="./jmlr-2009-A_Survey_of_Accuracy_Evaluation_Metrics_of_Recommendation_Tasks.html">4 jmlr-2009-A Survey of Accuracy Evaluation Metrics of Recommendation Tasks</a></p>
<p>15 0.029803513 <a title="95-tfidf-15" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>16 0.028952824 <a title="95-tfidf-16" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>17 0.028186021 <a title="95-tfidf-17" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>18 0.027808195 <a title="95-tfidf-18" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>19 0.02743049 <a title="95-tfidf-19" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>20 0.027332133 <a title="95-tfidf-20" href="./jmlr-2009-Estimating_Labels_from_Label_Proportions.html">29 jmlr-2009-Estimating Labels from Label Proportions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.188), (1, -0.039), (2, 0.076), (3, -0.028), (4, -0.111), (5, 0.259), (6, -0.151), (7, 0.434), (8, -0.152), (9, -0.081), (10, -0.188), (11, 0.153), (12, 0.024), (13, 0.027), (14, 0.06), (15, 0.043), (16, 0.05), (17, 0.106), (18, 0.012), (19, -0.067), (20, 0.062), (21, -0.08), (22, 0.071), (23, 0.049), (24, -0.028), (25, 0.059), (26, -0.118), (27, -0.096), (28, -0.024), (29, -0.006), (30, 0.047), (31, -0.008), (32, 0.079), (33, -0.079), (34, -0.067), (35, 0.01), (36, -0.015), (37, -0.034), (38, -0.066), (39, -0.035), (40, -0.056), (41, -0.012), (42, -0.045), (43, 0.058), (44, -0.002), (45, -0.032), (46, -0.061), (47, -0.044), (48, 0.002), (49, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94620687 <a title="95-lsi-1" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>Author: Cynthia Rudin</p><p>Abstract: We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This “push” near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. Keywords: ranking, RankBoost, generalization bounds, ROC, information retrieval</p><p>2 0.84721106 <a title="95-lsi-2" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>Author: Cynthia Rudin, Robert E. Schapire</p><p>Abstract: We study boosting algorithms for learning to rank. We give a general margin-based bound for ranking based on covering numbers for the hypothesis space. Our bound suggests that algorithms that maximize the ranking margin will generalize well. We then describe a new algorithm, smooth margin ranking, that precisely converges to a maximum ranking-margin solution. The algorithm is a modiﬁcation of RankBoost, analogous to “approximate coordinate ascent boosting.” Finally, we prove that AdaBoost and RankBoost are equally good for the problems of bipartite ranking and classiﬁcation in terms of their asymptotic behavior on the training set. Under natural conditions, AdaBoost achieves an area under the ROC curve that is equally as good as RankBoost’s; furthermore, RankBoost, when given a speciﬁc intercept, achieves a misclassiﬁcation error that is as good as AdaBoost’s. This may help to explain the empirical observations made by Cortes and Mohri, and Caruana and Niculescu-Mizil, about the excellent performance of AdaBoost as a bipartite ranking algorithm, as measured by the area under the ROC curve. Keywords: ranking, RankBoost, generalization bounds, AdaBoost, area under the ROC curve</p><p>3 0.54776376 <a title="95-lsi-3" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>Author: Shivani Agarwal, Partha Niyogi</p><p>Abstract: The problem of ranking, in which the goal is to learn a real-valued ranking function that induces a ranking or ordering over an instance space, has recently gained much attention in machine learning. We study generalization properties of ranking algorithms using the notion of algorithmic stability; in particular, we derive generalization bounds for ranking algorithms that have good stability properties. We show that kernel-based ranking algorithms that perform regularization in a reproducing kernel Hilbert space have such stability properties, and therefore our bounds can be applied to these algorithms; this is in contrast with generalization bounds based on uniform convergence, which in many cases cannot be applied to these algorithms. Our results generalize earlier results that were derived in the special setting of bipartite ranking (Agarwal and Niyogi, 2005) to a more general setting of the ranking problem that arises frequently in applications. Keywords: ranking, generalization bounds, algorithmic stability</p><p>4 0.53636056 <a title="95-lsi-4" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz1 functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints. Keywords: neural networks, universal approximation, monotonicity, convexity, call options</p><p>5 0.24096312 <a title="95-lsi-5" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>Author: Shie Mannor, John N. Tsitsiklis, Jia Yuan Yu</p><p>Abstract: We study online learning where a decision maker interacts with Nature with the objective of maximizing her long-term average reward subject to some sample path average constraints. We deﬁne the reward-in-hindsight as the highest reward the decision maker could have achieved, while satisfying the constraints, had she known Nature’s choices in advance. We show that in general the reward-in-hindsight is not attainable. The convex hull of the reward-in-hindsight function is, however, attainable. For the important case of a single constraint, the convex hull turns out to be the highest attainable function. Using a calibrated forecasting rule, we provide an explicit strategy that attains this convex hull. We also measure the performance of heuristic methods based on non-calibrated forecasters in experiments involving a CPU power management problem. Keywords: online learning, calibration, regret minimization, approachability</p><p>6 0.23547192 <a title="95-lsi-6" href="./jmlr-2009-Application_of_Non_Parametric_Empirical_Bayes_Estimation_to_High_Dimensional_Classification.html">10 jmlr-2009-Application of Non Parametric Empirical Bayes Estimation to High Dimensional Classification</a></p>
<p>7 0.21276054 <a title="95-lsi-7" href="./jmlr-2009-Strong_Limit_Theorems_for_the_Bayesian_Scoring_Criterion_in_Bayesian_Networks.html">89 jmlr-2009-Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks</a></p>
<p>8 0.20000421 <a title="95-lsi-8" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>9 0.18194662 <a title="95-lsi-9" href="./jmlr-2009-Bi-Level_Path_Following_for_Cross_Validated_Solution_of_Kernel_Quantile_Regression.html">12 jmlr-2009-Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression</a></p>
<p>10 0.17670155 <a title="95-lsi-10" href="./jmlr-2009-Nonextensive_Information_Theoretic_Kernels_on_Measures.html">61 jmlr-2009-Nonextensive Information Theoretic Kernels on Measures</a></p>
<p>11 0.17634723 <a title="95-lsi-11" href="./jmlr-2009-Learning_Permutations_with_Exponential_Weights.html">49 jmlr-2009-Learning Permutations with Exponential Weights</a></p>
<p>12 0.17405504 <a title="95-lsi-12" href="./jmlr-2009-Learning_Halfspaces_with_Malicious_Noise.html">46 jmlr-2009-Learning Halfspaces with Malicious Noise</a></p>
<p>13 0.16775186 <a title="95-lsi-13" href="./jmlr-2009-Learning_When_Concepts_Abound.html">50 jmlr-2009-Learning When Concepts Abound</a></p>
<p>14 0.15869892 <a title="95-lsi-14" href="./jmlr-2009-Exploiting_Product_Distributions_to_Identify_Relevant_Variables_of_Correlation_Immune_Functions.html">32 jmlr-2009-Exploiting Product Distributions to Identify Relevant Variables of Correlation Immune Functions</a></p>
<p>15 0.15741284 <a title="95-lsi-15" href="./jmlr-2009-On_Efficient_Large_Margin_Semisupervised_Learning%3A_Method_and_Theory.html">63 jmlr-2009-On Efficient Large Margin Semisupervised Learning: Method and Theory</a></p>
<p>16 0.15547711 <a title="95-lsi-16" href="./jmlr-2009-Deterministic_Error_Analysis_of_Support_Vector_Regression_and_Related_Regularized_Kernel_Methods.html">22 jmlr-2009-Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods</a></p>
<p>17 0.15178727 <a title="95-lsi-17" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>18 0.14256221 <a title="95-lsi-18" href="./jmlr-2009-An_Anticorrelation_Kernel_for_Subsystem_Training_in_Multiple_Classifier_Systems.html">8 jmlr-2009-An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems</a></p>
<p>19 0.14083356 <a title="95-lsi-19" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>20 0.14066061 <a title="95-lsi-20" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.016), (11, 0.013), (19, 0.015), (38, 0.023), (52, 0.055), (53, 0.036), (55, 0.039), (58, 0.022), (66, 0.098), (68, 0.011), (90, 0.553), (96, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97048312 <a title="95-lda-1" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>Author: Brijnesh J. Jain, Klaus Obermayer</p><p>Abstract: Finite structures such as point patterns, strings, trees, and graphs occur as ”natural” representations of structured data in different application areas of machine learning. We develop the theory of structure spaces and derive geometrical and analytical concepts such as the angle between structures and the derivative of functions on structures. In particular, we show that the gradient of a differentiable structural function is a well-deﬁned structure pointing in the direction of steepest ascent. Exploiting the properties of structure spaces, it will turn out that a number of problems in structural pattern recognition such as central clustering or learning in structured output spaces can be formulated as optimization problems with cost functions that are locally Lipschitz. Hence, methods from nonsmooth analysis are applicable to optimize those cost functions. Keywords: graphs, graph matching, learning in structured domains, nonsmooth optimization</p><p>2 0.95712602 <a title="95-lda-2" href="./jmlr-2009-An_Anticorrelation_Kernel_for_Subsystem_Training_in_Multiple_Classifier_Systems.html">8 jmlr-2009-An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems</a></p>
<p>Author: Luciana Ferrer, Kemal Sönmez, Elizabeth Shriberg</p><p>Abstract: We present a method for training support vector machine (SVM)-based classiﬁcation systems for combination with other classiﬁcation systems designed for the same task. Ideally, a new system should be designed such that, when combined with existing systems, the resulting performance is optimized. We present a simple model for this problem and use the understanding gained from this analysis to propose a method to achieve better combination performance when training SVM systems. We include a regularization term in the SVM objective function that aims to reduce the average class-conditional covariance between the resulting scores and the scores produced by the existing systems, introducing a trade-off between such covariance and the system’s individual performance. That is, the new system “takes one for the team”, falling somewhat short of its best possible performance in order to increase the diversity of the ensemble. We report results on the NIST 2005 and 2006 speaker recognition evaluations (SREs) for a variety of subsystems. We show a gain of 19% on the equal error rate (EER) of a combination of four systems when applying the proposed method with respect to the performance obtained when the four systems are trained independently of each other. Keywords: system combination, ensemble diversity, multiple classiﬁer systems, support vector machines, speaker recognition, kernel methods ∗. This author performed part of the work presented in this paper while at the Information Systems Laboratory, Department of Electrical Engineering, Stanford University. c 2009 Luciana Ferrer, Kemal S¨ nmez and Elizabeth Shriberg. o ¨ F ERRER , S ONMEZ AND S HRIBERG</p><p>same-paper 3 0.93915993 <a title="95-lda-3" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>Author: Cynthia Rudin</p><p>Abstract: We are interested in supervised ranking algorithms that perform especially well near the top of the ranked list, and are only required to perform sufﬁciently well on the rest of the list. In this work, we provide a general form of convex objective that gives high-scoring examples more importance. This “push” near the top of the list can be chosen arbitrarily large or small, based on the preference of the user. We choose ℓ p -norms to provide a speciﬁc type of push; if the user sets p larger, the objective concentrates harder on the top of the list. We derive a generalization bound based on the p-norm objective, working around the natural asymmetry of the problem. We then derive a boosting-style algorithm for the problem of ranking with a push at the top. The usefulness of the algorithm is illustrated through experiments on repository data. We prove that the minimizer of the algorithm’s objective is unique in a speciﬁc sense. Furthermore, we illustrate how our objective is related to quality measurements for information retrieval. Keywords: ranking, RankBoost, generalization bounds, ROC, information retrieval</p><p>4 0.69987226 <a title="95-lda-4" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in its two arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of Lipschitz1 functions with these and other properties. We apply this new class of functions to the task of modelling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints. Keywords: neural networks, universal approximation, monotonicity, convexity, call options</p><p>5 0.6850149 <a title="95-lda-5" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>Author: Cynthia Rudin, Robert E. Schapire</p><p>Abstract: We study boosting algorithms for learning to rank. We give a general margin-based bound for ranking based on covering numbers for the hypothesis space. Our bound suggests that algorithms that maximize the ranking margin will generalize well. We then describe a new algorithm, smooth margin ranking, that precisely converges to a maximum ranking-margin solution. The algorithm is a modiﬁcation of RankBoost, analogous to “approximate coordinate ascent boosting.” Finally, we prove that AdaBoost and RankBoost are equally good for the problems of bipartite ranking and classiﬁcation in terms of their asymptotic behavior on the training set. Under natural conditions, AdaBoost achieves an area under the ROC curve that is equally as good as RankBoost’s; furthermore, RankBoost, when given a speciﬁc intercept, achieves a misclassiﬁcation error that is as good as AdaBoost’s. This may help to explain the empirical observations made by Cortes and Mohri, and Caruana and Niculescu-Mizil, about the excellent performance of AdaBoost as a bipartite ranking algorithm, as measured by the area under the ROC curve. Keywords: ranking, RankBoost, generalization bounds, AdaBoost, area under the ROC curve</p><p>6 0.66877925 <a title="95-lda-6" href="./jmlr-2009-Reproducing_Kernel_Banach_Spaces_for_Machine_Learning.html">80 jmlr-2009-Reproducing Kernel Banach Spaces for Machine Learning</a></p>
<p>7 0.65330416 <a title="95-lda-7" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>8 0.62896788 <a title="95-lda-8" href="./jmlr-2009-Exploiting_Product_Distributions_to_Identify_Relevant_Variables_of_Correlation_Immune_Functions.html">32 jmlr-2009-Exploiting Product Distributions to Identify Relevant Variables of Correlation Immune Functions</a></p>
<p>9 0.61710417 <a title="95-lda-9" href="./jmlr-2009-Using_Local_Dependencies_within_Batches_to_Improve_Large_Margin_Classifiers.html">99 jmlr-2009-Using Local Dependencies within Batches to Improve Large Margin Classifiers</a></p>
<p>10 0.6112445 <a title="95-lda-10" href="./jmlr-2009-Learning_Approximate_Sequential_Patterns_for_Classification.html">45 jmlr-2009-Learning Approximate Sequential Patterns for Classification</a></p>
<p>11 0.61096686 <a title="95-lda-11" href="./jmlr-2009-Particle_Swarm_Model_Selection%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">70 jmlr-2009-Particle Swarm Model Selection    (Special Topic on Model Selection)</a></p>
<p>12 0.60819745 <a title="95-lda-12" href="./jmlr-2009-Nearest_Neighbor_Clustering%3A_A_Baseline_Method_for_Consistent_Clustering_with_Arbitrary_Objective_Functions.html">59 jmlr-2009-Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions</a></p>
<p>13 0.60572314 <a title="95-lda-13" href="./jmlr-2009-Deterministic_Error_Analysis_of_Support_Vector_Regression_and_Related_Regularized_Kernel_Methods.html">22 jmlr-2009-Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods</a></p>
<p>14 0.60090172 <a title="95-lda-14" href="./jmlr-2009-NEUROSVM%3A_An_Architecture_to_Reduce_the_Effect_of_the_Choice_of_Kernel_on_the_Performance_of_SVM.html">58 jmlr-2009-NEUROSVM: An Architecture to Reduce the Effect of the Choice of Kernel on the Performance of SVM</a></p>
<p>15 0.59301877 <a title="95-lda-15" href="./jmlr-2009-Fast_ApproximatekNN_Graph_Construction_for_High_Dimensional_Data_via_Recursive_Lanczos_Bisection.html">34 jmlr-2009-Fast ApproximatekNN Graph Construction for High Dimensional Data via Recursive Lanczos Bisection</a></p>
<p>16 0.59065551 <a title="95-lda-16" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>17 0.57794666 <a title="95-lda-17" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>18 0.57143277 <a title="95-lda-18" href="./jmlr-2009-Refinement_of_Reproducing_Kernels.html">78 jmlr-2009-Refinement of Reproducing Kernels</a></p>
<p>19 0.56908715 <a title="95-lda-19" href="./jmlr-2009-Efficient_Online_and_Batch_Learning_Using_Forward_Backward_Splitting.html">27 jmlr-2009-Efficient Online and Batch Learning Using Forward Backward Splitting</a></p>
<p>20 0.5687241 <a title="95-lda-20" href="./jmlr-2009-Application_of_Non_Parametric_Empirical_Bayes_Estimation_to_High_Dimensional_Classification.html">10 jmlr-2009-Application of Non Parametric Empirical Bayes Estimation to High Dimensional Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
