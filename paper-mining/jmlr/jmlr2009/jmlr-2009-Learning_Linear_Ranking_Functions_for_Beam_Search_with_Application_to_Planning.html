<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>47 jmlr-2009-Learning Linear Ranking Functions for Beam Search with Application to Planning</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-47" href="#">jmlr2009-47</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>47 jmlr-2009-Learning Linear Ranking Functions for Beam Search with Application to Planning</h1>
<br/><p>Source: <a title="jmlr-2009-47-pdf" href="http://jmlr.org/papers/volume10/xu09c/xu09c.pdf">pdf</a></p><p>Author: Yuehua Xu, Alan Fern, Sungwook Yoon</p><p>Abstract: Beam search is commonly used to help maintain tractability in large search spaces at the expense of completeness and optimality. Here we study supervised learning of linear ranking functions for controlling beam search. The goal is to learn ranking functions that allow for beam search to perform nearly as well as unconstrained search, and hence gain computational efﬁciency without seriously sacriﬁcing optimality. In this paper, we develop theoretical aspects of this learning problem and investigate the application of this framework to learning in the context of automated planning. We ﬁrst study the computational complexity of the learning problem, showing that even for exponentially large search spaces the general consistency problem is in NP. We also identify tractable and intractable subclasses of the learning problem, giving insight into the problem structure. Next, we analyze the convergence of recently proposed and modiﬁed online learning algorithms, where we introduce several notions of problem margin that imply convergence for the various algorithms. Finally, we present empirical results in automated planning, where ranking functions are learned to guide beam search in a number of benchmark planning domains. The results show that our approach is often able to outperform an existing state-of-the-art planning heuristic as well as a recent approach to learning such heuristics. Keywords: beam search, speedup learning, automated planning, structured classiﬁcation</p><p>Reference: <a title="jmlr-2009-47-reference" href="../jmlr2009_reference/jmlr-2009-Learning_Linear_Ranking_Functions_for_Beam_Search_with_Application_to_Planning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The goal is to learn ranking functions that allow for beam search to perform nearly as well as unconstrained search, and hence gain computational efﬁciency without seriously sacriﬁcing optimality. [sent-9, score-1.016]
</p><p>2 Finally, we present empirical results in automated planning, where ranking functions are learned to guide beam search in a number of benchmark planning domains. [sent-14, score-1.244]
</p><p>3 One common way to attempt to maintain tractability of heuristic search is through a pruning technique known as beam search. [sent-19, score-1.015]
</p><p>4 At each search step, beam search maintains a “beam” of the heuristically best b nodes, pruning all other nodes from the search queue. [sent-20, score-1.341]
</p><p>5 Due to this pruning, beam search is not guaranteed to be complete nor optimal. [sent-21, score-0.979]
</p><p>6 X U , F ERN AND YOON  The goal of this paper is to study the problem of learning heuristics, or ranking functions, that allow beam search to quickly ﬁnd solutions, without seriously sacriﬁcing optimality compared to unconstrained search. [sent-24, score-1.016]
</p><p>7 Given a training set, our learning objective is to select a weight vector w such that a beam search of a speciﬁed beam width always maintains one of the target paths in the beam until ﬁnally reaching a goal node. [sent-27, score-2.931]
</p><p>8 Such a w effectively represents a ranking function that allows beam search to efﬁciently solve all of the training instances, and ideally new search problems for which the training set is representative. [sent-28, score-1.244]
</p><p>9 Recent work (Daum´ III and Marcu, 2005) has considered the problem of learning beam search e ranking functions in the context of structured classiﬁcation. [sent-29, score-1.078]
</p><p>10 For the case where training data is ambiguous, that is, where many good solutions to a search problem are not included in the target solution set, we also give sufﬁcient conditions on the minimum beam width to guarantee convergence. [sent-54, score-1.185]
</p><p>11 The learned ranking function for a domain can then be used to guide beam search in order to solve new test problems from the same domain. [sent-66, score-1.076]
</p><p>12 Problem Setup In this section, we ﬁrst describe two different beam search paradigms: breadth-ﬁrst beam search and best-ﬁrst beam search. [sent-74, score-2.794]
</p><p>13 A search space is a tuple I, s(·), f (·), < , where I is the initial search node, s is a successor function from search nodes to ﬁnite sets of search nodes, f is a feature function from search nodes to mdimensional real-valued vectors, and < is a total preference ordering on search nodes. [sent-79, score-1.029]
</p><p>14 Given a search space S = I, s(·), f (·), < , a weight vector w, and a beam width b, breadth-ﬁrst beam search simply conducts breadth-ﬁrst search, but at each search depth keeps only the b highest ranked nodes according to r. [sent-84, score-2.436]
</p><p>15 More formally, breadth-ﬁrst beam search generates a unique beam trajectory (B0 , B1 , . [sent-85, score-1.857]
</p><p>16 Best-ﬁrst beam search is almost identical to breadth-ﬁrst beam search except that we replace the function BreadthExpand with BestExpand(B j , s(·)) = B j ∪s(v∗ )−v∗ , where v∗ is the unique highest ranking node in B j . [sent-90, score-2.085]
</p><p>17 Thus, instead of expanding all nodes in the beam at each search step, bestﬁrst search is more conservative and only expands the single best node. [sent-91, score-1.198]
</p><p>18 For breadth-ﬁrst beam search we specify a learning problem by giving a training set and a beam width { Si , Pi }, b . [sent-100, score-1.982]
</p><p>19 The objective is to ﬁnd a weight vector w that generates a beam trajectory containing at least one of the target paths for each training instance. [sent-101, score-1.022]
</p><p>20 A weight vector that demonstrates a “yes” answer is guaranteed to allow a breath-ﬁrst beam search of width b to uncover at least one goal node (i. [sent-109, score-1.254]
</p><p>21 Unlike the case of breadth-ﬁrst beam search, the length of the beam trajectory required by bestﬁrst beam search to reach a goal node can be greater than the depth d of the target paths. [sent-112, score-2.889]
</p><p>22 This is because best-ﬁrst beam search, does not necessarily increase the maximum depth of search nodes in the beam at each search step. [sent-113, score-2.068]
</p><p>23 Thus, in addition to specifying a beam width for the learning problem, we also specify a maximum number of search steps, or horizon, h. [sent-114, score-1.115]
</p><p>24 The objective is to ﬁnd a weight vector that allows a best-ﬁrst beam search to ﬁnd a goal node within h search steps, while always keeping some node from the target paths in the beam. [sent-115, score-1.415]
</p><p>25 Again, a weight vector that demonstrates a “yes” answer is guaranteed to allow a best-ﬁrst beam search of width b to ﬁnd a goal node in h search steps for all training instances. [sent-125, score-1.428]
</p><p>26 2 E XAMPLE FROM S TRUCTURED C LASSIFICATION Daum´ III and Marcu (2005) considered learning ranking functions to control beam search in the e context of structured classiﬁcation. [sent-141, score-1.078]
</p><p>27 Given a ranking function and a beam width, Daum´ III and Marcu (2005) return a predicted output for x by conducting a e beam search until a terminal node becomes the highest ranked node in the beam, and then return the output component of that terminal node. [sent-148, score-2.16]
</p><p>28 Throughout the complexity analysis we will restrict our attention to problem classes where the maximum number of children c and beam width b are polynomial in the problem size, which are necessary conditions to ensure that each beam search step requires only polynomial time and space. [sent-166, score-1.972]
</p><p>29 Observe that given a weight vector w and beam width b, we can easily generate a unique depth d beam trajectory for each training instance. [sent-181, score-1.964]
</p><p>30 The main idea is to observe that for any search space S it is possible to efﬁciently check whether there is a weight vector that starting with a beam B could generate a beam B′ after one step of breadth-ﬁrst beam search. [sent-184, score-2.7]
</p><p>31 Lemma 3 Given a set of search spaces {Si } and a corresponding set of width b beam trajectories {(Bi,0 , . [sent-197, score-1.139]
</p><p>32 Since the beam width b = 1, then the only way that a beam trajec/ tory (Bi,0 , . [sent-210, score-1.808]
</p><p>33 Thus there is exactly one beam trajectory for each training example, equal to the target trajectory, and using Lemma 3 we can check for a solution weight vector for these trajectories in polynomial time. [sent-214, score-1.021]
</p><p>34 With beam width b = k + 1, the beam Bi,1 is guaranteed to contain node q0 , indicating that w is a solution to the consistency problem. [sent-257, score-1.934]
</p><p>35 The next result shows that if we do not bound the number of training instances n, then the problem remains hard even when the target path depth and beam width are equal to one. [sent-275, score-1.097]
</p><p>36 Although ¬uk might appear in other clauses, for example, qi′ j′ = ¬uk , its corresponding node pi′ , j′ can never appear in the beam trajectory because w· fi′ (pi′ , j′ ) = w·(−ek ) = −w·ek = −w· fi (pi, j ) < 0. [sent-294, score-0.992]
</p><p>37 First we will consider using breadth-ﬁrst beam search with a beam width of b = 2. [sent-312, score-1.951]
</p><p>38 The ﬁrst search step gives the beam {D, B} according to the given preference ordering. [sent-318, score-0.979]
</p><p>39 Given the weight vector w = [γ, γ], the resulting beam search with beam width 2 will generate the beam sequence, {A}, {B,C}, {E,C} which is consistent with the target trajectory. [sent-324, score-2.875]
</p><p>40 In particular, the ﬁrst search step gives the beam {D, B} and since B is on the target path, we do not update the weights and generate a new beam {G, H} by expanding the node D. [sent-327, score-1.944]
</p><p>41 For breadth-ﬁrst beam search, a positive level margin for w implies a positive search margin, but not necessarily vice versa, showing that level margin is a strictly stronger notion of separability. [sent-335, score-1.079]
</p><p>42 However, starting with w′ = 0 and running LaSO-BST the ﬁrst search step gives the beam {D, B}. [sent-365, score-0.979]
</p><p>43 Whenever i this condition is satisﬁed we are guaranteed that a beam search of width b > b′ guided by w will solve all of the training problems. [sent-402, score-1.146]
</p><p>44 The following result shows that for a large enough beam width, which is dependent on the beam margin, LaSO-BR will converge to a consistent solution. [sent-405, score-1.672]
</p><p>45 Theorem 16 Given a dead-end free training set, if there exists a weight vector w with beam margin (b′ , δ1 , δ2 ) and w = 1, then for any beam width b > (1 + δ2 /δ1 ) b′ = b∗ , LaSO-BR will converge −2 weight updates. [sent-406, score-1.987]
</p><p>46 , b′ = 0), the mistake bound here reduces to (R/δ1 )2 , which does not depend on the beam width and matches the result for separable data. [sent-420, score-1.005]
</p><p>47 Rather, all of our previous convergence results were independent of the beam width and held even for beam width b = 1. [sent-423, score-1.967]
</p><p>48 Thus, those previous results did not provide any formalization of the intuition that the learning problem will often become easier as the beam width increases, or equivalently as the amount of search increases. [sent-424, score-1.115]
</p><p>49 It is also possible to deﬁne an analog to the beam margin for best ﬁrst beam search. [sent-432, score-1.722]
</p><p>50 Our goal is to learn heuristics, or ranking functions, that can quickly solve problems using beam search with a small beam width. [sent-473, score-1.875]
</p><p>51 These solutions are then used to learn a heuristic that can guide a small width beam search to the same solutions. [sent-477, score-1.151]
</p><p>52 To do this, for each training problem, we selected the shortest plan out of those found by running the planner FF and beam search with various large beam 1. [sent-560, score-1.981]
</p><p>53 01 for beam widths 1, 10, 50, and 100 and we will denote LaSO-BR run with beam width b by LaSO-BRb . [sent-604, score-1.863]
</p><p>54 This typically occurred because LaSO-BST would maintain an early target node in the beam and thus not trigger a weight update, but at the same time would not progress to include deeper nodes on the target trajectories and instead explore paths off the target trajectories. [sent-610, score-1.217]
</p><p>55 Note that Pipesworld was the only domain for which LaSO-BR converged to a consistent weight vector using a learning beam width 100. [sent-621, score-1.041]
</p><p>56 As expected the training times increase with the training beam width across the domains. [sent-624, score-1.034]
</p><p>57 • LEN : beam search using FF’s relaxed plan length heuristic • U : beam search using a heuristic with uniform weights for all features • LR : beam search using the heuristic learned from linear regression following the approach in Yoon et al. [sent-632, score-3.195]
</p><p>58 The rows correspond to the beam width used to generate the results on the testing problems, with the last row corresponding to using full best-ﬁrst search (BFS) with an inﬁnite beam width, which is the native search procedure used by FF. [sent-637, score-2.108]
</p><p>59 The ﬁrst four data columns labeled “Problems solved” give the number of problems solved using the testing beam width corresponding to the row, where a problem is considered solved if a solution is found within 30 minutes. [sent-639, score-1.071]
</p><p>60 8 seconds using a testing beam width of 50, and solved 19 problems with a median solution length of 142 and a median runtime of 20. [sent-643, score-1.268]
</p><p>61 Figure 13 is similar in structure to Figure 12 but compares the performance of heuristics learned using LaSO-BR with a variety of training beam widths and evaluated using a variety of testing beam widths. [sent-645, score-1.811]
</p><p>62 For example, the upper left-most data point gives the number of problems solved using a learning beam width of 1 and a testing beam width of 1, while the ﬁrst entry in the last column gives the median plan length of solved problems when learning with beam width 100 and testing with beam width 1. [sent-647, score-4.227]
</p><p>63 3 P ERFORMANCE ACROSS T ESTING B EAM W IDTHS From Figure 12, in general, for all algorithms (learning and non-learning) we see that as the testing beam width begins to increase the number of solved problems and runtime increase and solution lengths improve. [sent-817, score-1.09]
</p><p>64 However, at some point as the beam width continues to increase the number of solved problems typically decreases. [sent-818, score-1.026]
</p><p>65 This behavior is typical for beam search, since as the testing beam width increases there is a greater chance of not pruning a solution trajectory, but the computational time and memory demands increase. [sent-819, score-1.822]
</p><p>66 The median runtime typically increases as the test beam width increases, because more search nodes need to be evaluated. [sent-821, score-1.297]
</p><p>67 For example, while using LEN in the Depots planning domain, the median runtime of beam width 50 is smaller than that of beam width 10, because the median plan length improves from 195 to 25. [sent-824, score-2.403]
</p><p>68 With large testing beam widths the number of candidates for the next beam increases, making it more likely for the heuristic to get confused by “bad” states. [sent-826, score-1.777]
</p><p>69 4 L A SO-BR10 V ERSUS N O L EARNING From Figure 12, we see that compared to LEN, the heuristic learned by LaSO-BR10 tends to significantly improve the performance of beam search, especially for small beam widths. [sent-830, score-1.725]
</p><p>70 For example, in Blocksworld with beam width 1, LaSO-BR10 solves almost twice as many problems as LEN. [sent-831, score-1.017]
</p><p>71 The median plan length has also been reduced signiﬁcantly for beam width 1. [sent-832, score-1.175]
</p><p>72 As the beam width increases the gap between LaSO-BR10 and LEN decreases but LaSO-BR10 still solves more problems with comparable solution quality. [sent-833, score-1.017]
</p><p>73 In Pipesworld, LaSO-BR10 has the best performance gap with beam width 50, solving 8 more problems than LEN. [sent-834, score-0.995]
</p><p>74 As the beam width increases, again the performance gap decreases, but LaSO-BR10 consistently solves more problems than LEN. [sent-835, score-1.017]
</p><p>75 Note that in practice one could use a validation set of problems in order to select the best combination of training beam width and testing beam width for a given domain. [sent-842, score-2.012]
</p><p>76 For Blocksworld, LR solves fewer problems than LaSO-BR10 with beam widths smaller than 500 but solves more problems than LaSO-BR10 with beam width 500. [sent-851, score-1.953]
</p><p>77 The median plan length tends to favor LR except for the smallest beam width b = 1. [sent-852, score-1.175]
</p><p>78 Even with learning beam width 1, LaSO-BR can often achieve performance on par with larger learning beam widths. [sent-864, score-1.808]
</p><p>79 For example, in Blocksworld, LaSO-BR1 results in the best performance at most testing beam widths except for beam width 500. [sent-865, score-1.877]
</p><p>80 In cases where the features are rich enough to support successful beam search with small width, it is then likely that learning with smaller widths will be better given a ﬁxed number of iterations and examples. [sent-872, score-1.034]
</p><p>81 Finally note that contrary to what we originally expected it is not typically the case that the best performance for a particular testing beam width is achieved when learning with that same beam width. [sent-875, score-1.822]
</p><p>82 Note that for most domains LaSO-BR never converged to a consistent weight vector in our experiments, 1603  X U , F ERN AND YOON  indicating that either the features were not powerful enough for consistency or the learning beam widths and/or number of iterations needed to be increased. [sent-877, score-1.001]
</p><p>83 In such cases, there is no clear technical reason to expect the best testing beam width to match the learning beam width. [sent-878, score-1.822]
</p><p>84 Note that the lack of relationship between learning and test beam width is in contrast to that observed in Daum´ III and Marcu (2005) for structured classiﬁcation, where there e appeared to be a small advantage to training and testing using the same width. [sent-880, score-1.079]
</p><p>85 7 B EST F IRST S EARCH R ESULTS While our heuristic was learned for the purpose of controlling beam search we conducted one more experiment in each domain where we used the heuristics to guide Best First Search (BFS). [sent-883, score-1.074]
</p><p>86 These results indicate that the advantage of error-driven learning over regression is not just restricted to beam search, but appears to extend to other search approaches. [sent-892, score-0.979]
</p><p>87 That is, by learning in the context of beam search it is possible to extract problem solving information that is useful in other contexts. [sent-893, score-0.979]
</p><p>88 However, the plan lengths at small widths are quite suboptimal, which is typical of beam search. [sent-897, score-1.005]
</p><p>89 Thus, despite the long plan lengths, the improved success rate of LaSO-BR at small beam widths could provide a good starting point for a fast plan length optimization. [sent-903, score-1.124]
</p><p>90 Summary and Future Work This paper presented a detailed study of the problem of learning ranking functions for beam search with an application to automated planning. [sent-905, score-1.077]
</p><p>91 It is important to note that the learning objective does not place a constraint on the rank of a goal node in the ﬁnal beam compared to non-goal nodes, but rather only requires that there exists some goal node in the ﬁnal beam. [sent-931, score-1.016]
</p><p>92 This is a natural formulation for automated planning where when solving test problems it is easy to test each beam to determine whether a goal node has been uncovered and to return a solution trajectory if one has. [sent-932, score-1.202]
</p><p>93 Thus, the exact ordering of the goal node in the ﬁnal beam is not important with respect to ﬁnding solutions to planning problems. [sent-933, score-1.095]
</p><p>94 When using beam search for structured classiﬁcation the search is halted whenever a terminal node becomes highest ranked in the beam and the path leading to that terminal node is returned as the solution. [sent-945, score-2.349]
</p><p>95 Thus, successful learning must ensure both that no non-target terminal node ever becomes ranked ﬁrst in any beam and also that eventually a target terminal node does become ranked ﬁrst. [sent-946, score-1.223]
</p><p>96 Below, given the context of a weight vector w, we will denote the highest ranked node relative to w in a beam B by B(1) . [sent-948, score-1.015]
</p><p>97 , Pi,d ), the breadth-ﬁrst structured classiﬁcation problem asks us to decide whether there is a weight vector w such that for each Si , the corresponding beam / trajectory (Bi,0 , . [sent-952, score-0.989]
</p><p>98 , Pi,d ), the best-ﬁrst structured classiﬁcation problem asks us to decide whether there is a weight vector w that produces for each Si a beam trajectory (Bi,0 , . [sent-959, score-0.989]
</p><p>99 , Bi,k ) S (1) of beam width b, such that k ≤ h, each Bi, j for j < k contains at least one node in j Pi, j , Bi,k ∈ Pi,d , (1)  and Bi, j ∈ T for j < k? [sent-962, score-1.062]
</p><p>100 Since for this class the search spaces have depth 1 and the beam width is 1 it is easy to see that for any problem in this class, a weight vector is a solution to the consistency problem if and only if it is a solution to the structured classiﬁcation problem. [sent-971, score-1.296]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('beam', 0.836), ('len', 0.159), ('planning', 0.15), ('search', 0.143), ('width', 0.136), ('yoon', 0.131), ('lr', 0.103), ('plan', 0.1), ('node', 0.09), ('bfs', 0.086), ('ern', 0.082), ('pplication', 0.077), ('blocksworld', 0.077), ('nodes', 0.076), ('eam', 0.073), ('lanning', 0.073), ('median', 0.07), ('earch', 0.066), ('pi', 0.066), ('daum', 0.063), ('pickup', 0.063), ('structured', 0.062), ('automated', 0.061), ('marcu', 0.059), ('unctions', 0.059), ('wk', 0.058), ('widths', 0.055), ('anking', 0.054), ('margin', 0.05), ('weight', 0.049), ('inear', 0.047), ('terminal', 0.044), ('trajectory', 0.042), ('si', 0.041), ('ontable', 0.041), ('pipesworld', 0.041), ('psr', 0.041), ('ranked', 0.04), ('target', 0.039), ('ff', 0.038), ('ranking', 0.037), ('runtime', 0.036), ('depots', 0.036), ('driverlog', 0.036), ('freecell', 0.036), ('heuristic', 0.036), ('consistency', 0.036), ('planner', 0.035), ('depth', 0.034), ('qi', 0.034), ('length', 0.033), ('mistake', 0.033), ('ebl', 0.032), ('philosopher', 0.032), ('solved', 0.031), ('training', 0.031), ('stack', 0.029), ('fern', 0.029), ('plans', 0.029), ('cat', 0.028), ('laso', 0.027), ('actions', 0.027), ('sungwook', 0.027), ('paths', 0.025), ('domains', 0.025), ('action', 0.025), ('fi', 0.024), ('trajectories', 0.024), ('problems', 0.023), ('convergence', 0.023), ('earning', 0.023), ('minton', 0.023), ('noun', 0.023), ('testtrajectories', 0.023), ('solves', 0.022), ('heuristics', 0.022), ('children', 0.021), ('alan', 0.021), ('path', 0.021), ('domain', 0.02), ('ambiguity', 0.019), ('ordering', 0.019), ('depths', 0.019), ('disagreement', 0.019), ('seconds', 0.019), ('blocks', 0.019), ('iii', 0.019), ('verb', 0.018), ('counter', 0.018), ('learned', 0.017), ('taxonomic', 0.015), ('testing', 0.014), ('policies', 0.014), ('yuehua', 0.014), ('planners', 0.014), ('reactive', 0.014), ('lengths', 0.014), ('armempty', 0.014), ('beams', 0.014), ('cate', 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="47-tfidf-1" href="./jmlr-2009-Learning_Linear_Ranking_Functions_for_Beam_Search_with_Application_to_Planning.html">47 jmlr-2009-Learning Linear Ranking Functions for Beam Search with Application to Planning</a></p>
<p>Author: Yuehua Xu, Alan Fern, Sungwook Yoon</p><p>Abstract: Beam search is commonly used to help maintain tractability in large search spaces at the expense of completeness and optimality. Here we study supervised learning of linear ranking functions for controlling beam search. The goal is to learn ranking functions that allow for beam search to perform nearly as well as unconstrained search, and hence gain computational efﬁciency without seriously sacriﬁcing optimality. In this paper, we develop theoretical aspects of this learning problem and investigate the application of this framework to learning in the context of automated planning. We ﬁrst study the computational complexity of the learning problem, showing that even for exponentially large search spaces the general consistency problem is in NP. We also identify tractable and intractable subclasses of the learning problem, giving insight into the problem structure. Next, we analyze the convergence of recently proposed and modiﬁed online learning algorithms, where we introduce several notions of problem margin that imply convergence for the various algorithms. Finally, we present empirical results in automated planning, where ranking functions are learned to guide beam search in a number of benchmark planning domains. The results show that our approach is often able to outperform an existing state-of-the-art planning heuristic as well as a recent approach to learning such heuristics. Keywords: beam search, speedup learning, automated planning, structured classiﬁcation</p><p>2 0.071172357 <a title="47-tfidf-2" href="./jmlr-2009-CarpeDiem%3A_Optimizing_the_Viterbi_Algorithm_and_Applications_to_Supervised_Sequential_Learning.html">14 jmlr-2009-CarpeDiem: Optimizing the Viterbi Algorithm and Applications to Supervised Sequential Learning</a></p>
<p>Author: Roberto Esposito, Daniele P. Radicioni</p><p>Abstract: The growth of information available to learning systems and the increasing complexity of learning tasks determine the need for devising algorithms that scale well with respect to all learning parameters. In the context of supervised sequential learning, the Viterbi algorithm plays a fundamental role, by allowing the evaluation of the best (most probable) sequence of labels with a time complexity linear in the number of time events, and quadratic in the number of labels. In this paper we propose CarpeDiem, a novel algorithm allowing the evaluation of the best possible sequence of labels with a sub-quadratic time complexity.1 We provide theoretical grounding together with solid empirical results supporting two chief facts. CarpeDiem always ﬁnds the optimal solution requiring, in most cases, only a small fraction of the time taken by the Viterbi algorithm; meantime, CarpeDiem is never asymptotically worse than the Viterbi algorithm, thus conﬁrming it as a sound replacement. Keywords: Viterbi algorithm, sequence labeling, conditional models, classiﬁers optimization, exact inference</p><p>3 0.044426031 <a title="47-tfidf-3" href="./jmlr-2009-Learning_When_Concepts_Abound.html">50 jmlr-2009-Learning When Concepts Abound</a></p>
<p>Author: Omid Madani, Michael Connor, Wiley Greiner</p><p>Abstract: Many learning tasks, such as large-scale text categorization and word prediction, can beneﬁt from efﬁcient training and classiﬁcation when the number of classes, in addition to instances and features, is large, that is, in the thousands and beyond. We investigate the learning of sparse class indices to address this challenge. An index is a mapping from features to classes. We compare the index-learning methods against other techniques, including one-versus-rest and top-down classiﬁcation using perceptrons and support vector machines. We ﬁnd that index learning is highly advantageous for space and time efﬁciency, at both training and classiﬁcation times. Moreover, this approach yields similar and at times better accuracies. On problems with hundreds of thousands of instances and thousands of classes, the index is learned in minutes, while other methods can take hours or days. As we explain, the design of the learning update enables conveniently constraining each feature to connect to a small subset of the classes in the index. This constraint is crucial for scalability. Given an instance with l active (positive-valued) features, each feature on average connecting to d classes in the index (in the order of 10s in our experiments), update and classiﬁcation take O(dl log(dl)). Keywords: index learning, many-class learning, multiclass learning, online learning, text categorization</p><p>4 0.037245546 <a title="47-tfidf-4" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>Author: Shivani Agarwal, Partha Niyogi</p><p>Abstract: The problem of ranking, in which the goal is to learn a real-valued ranking function that induces a ranking or ordering over an instance space, has recently gained much attention in machine learning. We study generalization properties of ranking algorithms using the notion of algorithmic stability; in particular, we derive generalization bounds for ranking algorithms that have good stability properties. We show that kernel-based ranking algorithms that perform regularization in a reproducing kernel Hilbert space have such stability properties, and therefore our bounds can be applied to these algorithms; this is in contrast with generalization bounds based on uniform convergence, which in many cases cannot be applied to these algorithms. Our results generalize earlier results that were derived in the special setting of bipartite ranking (Agarwal and Niyogi, 2005) to a more general setting of the ranking problem that arises frequently in applications. Keywords: ranking, generalization bounds, algorithmic stability</p><p>5 0.035512608 <a title="47-tfidf-5" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>Author: Shie Mannor, John N. Tsitsiklis, Jia Yuan Yu</p><p>Abstract: We study online learning where a decision maker interacts with Nature with the objective of maximizing her long-term average reward subject to some sample path average constraints. We deﬁne the reward-in-hindsight as the highest reward the decision maker could have achieved, while satisfying the constraints, had she known Nature’s choices in advance. We show that in general the reward-in-hindsight is not attainable. The convex hull of the reward-in-hindsight function is, however, attainable. For the important case of a single constraint, the convex hull turns out to be the highest attainable function. Using a calibrated forecasting rule, we provide an explicit strategy that attains this convex hull. We also measure the performance of heuristic methods based on non-calibrated forecasters in experiments involving a CPU power management problem. Keywords: online learning, calibration, regret minimization, approachability</p><p>6 0.033502217 <a title="47-tfidf-6" href="./jmlr-2009-Subgroup_Analysis_via_Recursive_Partitioning.html">91 jmlr-2009-Subgroup Analysis via Recursive Partitioning</a></p>
<p>7 0.03301983 <a title="47-tfidf-7" href="./jmlr-2009-Provably_Efficient_Learning_with_Typed_Parametric_Models.html">75 jmlr-2009-Provably Efficient Learning with Typed Parametric Models</a></p>
<p>8 0.032279272 <a title="47-tfidf-8" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>9 0.031633515 <a title="47-tfidf-9" href="./jmlr-2009-Transfer_Learning_for_Reinforcement_Learning_Domains%3A_A_Survey.html">96 jmlr-2009-Transfer Learning for Reinforcement Learning Domains: A Survey</a></p>
<p>10 0.030751606 <a title="47-tfidf-10" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>11 0.027781364 <a title="47-tfidf-11" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>12 0.027240397 <a title="47-tfidf-12" href="./jmlr-2009-Learning_Nondeterministic_Classifiers.html">48 jmlr-2009-Learning Nondeterministic Classifiers</a></p>
<p>13 0.026343893 <a title="47-tfidf-13" href="./jmlr-2009-Cautious_Collective_Classification.html">15 jmlr-2009-Cautious Collective Classification</a></p>
<p>14 0.024728712 <a title="47-tfidf-14" href="./jmlr-2009-Particle_Swarm_Model_Selection%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">70 jmlr-2009-Particle Swarm Model Selection    (Special Topic on Model Selection)</a></p>
<p>15 0.023164971 <a title="47-tfidf-15" href="./jmlr-2009-Strong_Limit_Theorems_for_the_Bayesian_Scoring_Criterion_in_Bayesian_Networks.html">89 jmlr-2009-Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks</a></p>
<p>16 0.022871904 <a title="47-tfidf-16" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>17 0.022772714 <a title="47-tfidf-17" href="./jmlr-2009-Universal_Kernel-Based_Learning_with_Applications_to_Regular_Languages%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">98 jmlr-2009-Universal Kernel-Based Learning with Applications to Regular Languages    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>18 0.02194027 <a title="47-tfidf-18" href="./jmlr-2009-Learning_Approximate_Sequential_Patterns_for_Classification.html">45 jmlr-2009-Learning Approximate Sequential Patterns for Classification</a></p>
<p>19 0.021286111 <a title="47-tfidf-19" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>20 0.021048114 <a title="47-tfidf-20" href="./jmlr-2009-Feature_Selection_with_Ensembles%2C_Artificial_Variables%2C_and_Redundancy_Elimination%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">35 jmlr-2009-Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination    (Special Topic on Model Selection)</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.114), (1, -0.055), (2, -0.001), (3, 0.021), (4, 0.003), (5, -0.027), (6, -0.057), (7, 0.093), (8, 0.04), (9, -0.006), (10, -0.069), (11, -0.057), (12, 0.113), (13, -0.047), (14, -0.084), (15, -0.045), (16, 0.005), (17, 0.078), (18, -0.087), (19, -0.089), (20, -0.179), (21, 0.211), (22, -0.089), (23, 0.178), (24, 0.13), (25, 0.007), (26, 0.307), (27, -0.196), (28, -0.089), (29, -0.177), (30, -0.018), (31, -0.027), (32, -0.024), (33, 0.14), (34, 0.225), (35, 0.143), (36, -0.027), (37, 0.1), (38, -0.07), (39, 0.005), (40, 0.121), (41, -0.196), (42, -0.05), (43, -0.077), (44, -0.141), (45, 0.133), (46, 0.095), (47, -0.026), (48, -0.136), (49, 0.223)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96318078 <a title="47-lsi-1" href="./jmlr-2009-Learning_Linear_Ranking_Functions_for_Beam_Search_with_Application_to_Planning.html">47 jmlr-2009-Learning Linear Ranking Functions for Beam Search with Application to Planning</a></p>
<p>Author: Yuehua Xu, Alan Fern, Sungwook Yoon</p><p>Abstract: Beam search is commonly used to help maintain tractability in large search spaces at the expense of completeness and optimality. Here we study supervised learning of linear ranking functions for controlling beam search. The goal is to learn ranking functions that allow for beam search to perform nearly as well as unconstrained search, and hence gain computational efﬁciency without seriously sacriﬁcing optimality. In this paper, we develop theoretical aspects of this learning problem and investigate the application of this framework to learning in the context of automated planning. We ﬁrst study the computational complexity of the learning problem, showing that even for exponentially large search spaces the general consistency problem is in NP. We also identify tractable and intractable subclasses of the learning problem, giving insight into the problem structure. Next, we analyze the convergence of recently proposed and modiﬁed online learning algorithms, where we introduce several notions of problem margin that imply convergence for the various algorithms. Finally, we present empirical results in automated planning, where ranking functions are learned to guide beam search in a number of benchmark planning domains. The results show that our approach is often able to outperform an existing state-of-the-art planning heuristic as well as a recent approach to learning such heuristics. Keywords: beam search, speedup learning, automated planning, structured classiﬁcation</p><p>2 0.5101707 <a title="47-lsi-2" href="./jmlr-2009-CarpeDiem%3A_Optimizing_the_Viterbi_Algorithm_and_Applications_to_Supervised_Sequential_Learning.html">14 jmlr-2009-CarpeDiem: Optimizing the Viterbi Algorithm and Applications to Supervised Sequential Learning</a></p>
<p>Author: Roberto Esposito, Daniele P. Radicioni</p><p>Abstract: The growth of information available to learning systems and the increasing complexity of learning tasks determine the need for devising algorithms that scale well with respect to all learning parameters. In the context of supervised sequential learning, the Viterbi algorithm plays a fundamental role, by allowing the evaluation of the best (most probable) sequence of labels with a time complexity linear in the number of time events, and quadratic in the number of labels. In this paper we propose CarpeDiem, a novel algorithm allowing the evaluation of the best possible sequence of labels with a sub-quadratic time complexity.1 We provide theoretical grounding together with solid empirical results supporting two chief facts. CarpeDiem always ﬁnds the optimal solution requiring, in most cases, only a small fraction of the time taken by the Viterbi algorithm; meantime, CarpeDiem is never asymptotically worse than the Viterbi algorithm, thus conﬁrming it as a sound replacement. Keywords: Viterbi algorithm, sequence labeling, conditional models, classiﬁers optimization, exact inference</p><p>3 0.23946901 <a title="47-lsi-3" href="./jmlr-2009-Learning_When_Concepts_Abound.html">50 jmlr-2009-Learning When Concepts Abound</a></p>
<p>Author: Omid Madani, Michael Connor, Wiley Greiner</p><p>Abstract: Many learning tasks, such as large-scale text categorization and word prediction, can beneﬁt from efﬁcient training and classiﬁcation when the number of classes, in addition to instances and features, is large, that is, in the thousands and beyond. We investigate the learning of sparse class indices to address this challenge. An index is a mapping from features to classes. We compare the index-learning methods against other techniques, including one-versus-rest and top-down classiﬁcation using perceptrons and support vector machines. We ﬁnd that index learning is highly advantageous for space and time efﬁciency, at both training and classiﬁcation times. Moreover, this approach yields similar and at times better accuracies. On problems with hundreds of thousands of instances and thousands of classes, the index is learned in minutes, while other methods can take hours or days. As we explain, the design of the learning update enables conveniently constraining each feature to connect to a small subset of the classes in the index. This constraint is crucial for scalability. Given an instance with l active (positive-valued) features, each feature on average connecting to d classes in the index (in the order of 10s in our experiments), update and classiﬁcation take O(dl log(dl)). Keywords: index learning, many-class learning, multiclass learning, online learning, text categorization</p><p>4 0.2187385 <a title="47-lsi-4" href="./jmlr-2009-Cautious_Collective_Classification.html">15 jmlr-2009-Cautious Collective Classification</a></p>
<p>Author: Luke K. McDowell, Kalyan Moy Gupta, David W. Aha</p><p>Abstract: Many collective classiﬁcation (CC) algorithms have been shown to increase accuracy when instances are interrelated. However, CC algorithms must be carefully applied because their use of estimated labels can in some cases decrease accuracy. In this article, we show that managing this label uncertainty through cautious algorithmic behavior is essential to achieving maximal, robust performance. First, we describe cautious inference and explain how four well-known families of CC algorithms can be parameterized to use varying degrees of such caution. Second, we introduce cautious learning and show how it can be used to improve the performance of almost any CC algorithm, with or without cautious inference. We then evaluate cautious inference and learning for the four collective inference families, with three local classiﬁers and a range of both synthetic and real-world data. We ﬁnd that cautious learning and cautious inference typically outperform less cautious approaches. In addition, we identify the data characteristics that predict more substantial performance differences. Our results reveal that the degree of caution used usually has a larger impact on performance than the choice of the underlying inference algorithm. Together, these results identify the most appropriate CC algorithms to use for particular task characteristics and explain multiple conﬂicting ﬁndings from prior CC research. Keywords: collective inference, statistical relational learning, approximate probabilistic inference, networked data, cautious inference</p><p>5 0.19264805 <a title="47-lsi-5" href="./jmlr-2009-Learning_Nondeterministic_Classifiers.html">48 jmlr-2009-Learning Nondeterministic Classifiers</a></p>
<p>Author: Juan José del Coz, Jorge Díez, Antonio Bahamonde</p><p>Abstract: Nondeterministic classiﬁers are deﬁned as those allowed to predict more than one class for some entries from an input space. Given that the true class should be included in predictions and the number of classes predicted should be as small as possible, these kind of classiﬁers can be considered as Information Retrieval (IR) procedures. In this paper, we propose a family of IR loss functions to measure the performance of nondeterministic learners. After discussing such measures, we derive an algorithm for learning optimal nondeterministic hypotheses. Given an entry from the input space, the algorithm requires the posterior probabilities to compute the subset of classes with the lowest expected loss. From a general point of view, nondeterministic classiﬁers provide an improvement in the proportion of predictions that include the true class compared to their deterministic counterparts; the price to be paid for this increase is usually a tiny proportion of predictions with more than one class. The paper includes an extensive experimental study using three deterministic learners to estimate posterior probabilities: a multiclass Support Vector Machine (SVM), a Logistic Regression, and a Na¨ve Bayes. The data sets considered comprise both UCI ı multi-class learning tasks and microarray expressions of different kinds of cancer. We successfully compare nondeterministic classiﬁers with other alternative approaches. Additionally, we shall see how the quality of posterior probabilities (measured by the Brier score) determines the goodness of nondeterministic predictions. Keywords: nondeterministic, multiclassiﬁcation, reject option, multi-label classiﬁcation, posterior probabilities</p><p>6 0.18779896 <a title="47-lsi-6" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>7 0.18694063 <a title="47-lsi-7" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>8 0.18423043 <a title="47-lsi-8" href="./jmlr-2009-Deterministic_Error_Analysis_of_Support_Vector_Regression_and_Related_Regularized_Kernel_Methods.html">22 jmlr-2009-Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods</a></p>
<p>9 0.15570174 <a title="47-lsi-9" href="./jmlr-2009-Universal_Kernel-Based_Learning_with_Applications_to_Regular_Languages%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">98 jmlr-2009-Universal Kernel-Based Learning with Applications to Regular Languages    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>10 0.14422175 <a title="47-lsi-10" href="./jmlr-2009-Particle_Swarm_Model_Selection%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">70 jmlr-2009-Particle Swarm Model Selection    (Special Topic on Model Selection)</a></p>
<p>11 0.13659832 <a title="47-lsi-11" href="./jmlr-2009-Transfer_Learning_for_Reinforcement_Learning_Domains%3A_A_Survey.html">96 jmlr-2009-Transfer Learning for Reinforcement Learning Domains: A Survey</a></p>
<p>12 0.13647322 <a title="47-lsi-12" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>13 0.13433178 <a title="47-lsi-13" href="./jmlr-2009-On_Efficient_Large_Margin_Semisupervised_Learning%3A_Method_and_Theory.html">63 jmlr-2009-On Efficient Large Margin Semisupervised Learning: Method and Theory</a></p>
<p>14 0.13103905 <a title="47-lsi-14" href="./jmlr-2009-A_Least-squares_Approach_to_Direct_Importance_Estimation.html">1 jmlr-2009-A Least-squares Approach to Direct Importance Estimation</a></p>
<p>15 0.12519062 <a title="47-lsi-15" href="./jmlr-2009-Subgroup_Analysis_via_Recursive_Partitioning.html">91 jmlr-2009-Subgroup Analysis via Recursive Partitioning</a></p>
<p>16 0.11872856 <a title="47-lsi-16" href="./jmlr-2009-Polynomial-Delay_Enumeration_of_Monotonic_Graph_Classes.html">72 jmlr-2009-Polynomial-Delay Enumeration of Monotonic Graph Classes</a></p>
<p>17 0.11698309 <a title="47-lsi-17" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>18 0.11378825 <a title="47-lsi-18" href="./jmlr-2009-Ultrahigh_Dimensional_Feature_Selection%3A_Beyond_The_Linear_Model.html">97 jmlr-2009-Ultrahigh Dimensional Feature Selection: Beyond The Linear Model</a></p>
<p>19 0.1108562 <a title="47-lsi-19" href="./jmlr-2009-An_Algorithm_for_Reading_Dependencies_from_the_Minimal_Undirected_Independence_Map_of_a_Graphoid_that_Satisfies_Weak_Transitivity.html">6 jmlr-2009-An Algorithm for Reading Dependencies from the Minimal Undirected Independence Map of a Graphoid that Satisfies Weak Transitivity</a></p>
<p>20 0.10824241 <a title="47-lsi-20" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.025), (11, 0.042), (19, 0.022), (21, 0.015), (26, 0.015), (38, 0.021), (40, 0.392), (47, 0.02), (52, 0.053), (55, 0.029), (58, 0.034), (66, 0.115), (68, 0.016), (90, 0.051), (96, 0.041)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70304155 <a title="47-lda-1" href="./jmlr-2009-Learning_Linear_Ranking_Functions_for_Beam_Search_with_Application_to_Planning.html">47 jmlr-2009-Learning Linear Ranking Functions for Beam Search with Application to Planning</a></p>
<p>Author: Yuehua Xu, Alan Fern, Sungwook Yoon</p><p>Abstract: Beam search is commonly used to help maintain tractability in large search spaces at the expense of completeness and optimality. Here we study supervised learning of linear ranking functions for controlling beam search. The goal is to learn ranking functions that allow for beam search to perform nearly as well as unconstrained search, and hence gain computational efﬁciency without seriously sacriﬁcing optimality. In this paper, we develop theoretical aspects of this learning problem and investigate the application of this framework to learning in the context of automated planning. We ﬁrst study the computational complexity of the learning problem, showing that even for exponentially large search spaces the general consistency problem is in NP. We also identify tractable and intractable subclasses of the learning problem, giving insight into the problem structure. Next, we analyze the convergence of recently proposed and modiﬁed online learning algorithms, where we introduce several notions of problem margin that imply convergence for the various algorithms. Finally, we present empirical results in automated planning, where ranking functions are learned to guide beam search in a number of benchmark planning domains. The results show that our approach is often able to outperform an existing state-of-the-art planning heuristic as well as a recent approach to learning such heuristics. Keywords: beam search, speedup learning, automated planning, structured classiﬁcation</p><p>2 0.35547906 <a title="47-lda-2" href="./jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Junning Li, Z. Jane Wang</p><p>Abstract: In real world applications, graphical statistical models are not only a tool for operations such as classiﬁcation or prediction, but usually the network structures of the models themselves are also of great interest (e.g., in modeling brain connectivity). The false discovery rate (FDR), the expected ratio of falsely claimed connections to all those claimed, is often a reasonable error-rate criterion in these applications. However, current learning algorithms for graphical models have not been adequately adapted to the concerns of the FDR. The traditional practice of controlling the type I error rate and the type II error rate under a conventional level does not necessarily keep the FDR low, especially in the case of sparse networks. In this paper, we propose embedding an FDR-control procedure into the PC algorithm to curb the FDR of the skeleton of the learned graph. We prove that the proposed method can control the FDR under a user-speciﬁed level at the limit of large sample sizes. In the cases of moderate sample size (about several hundred), empirical experiments show that the method is still able to control the FDR under the user-speciﬁed level, and a heuristic modiﬁcation of the method is able to control the FDR more accurately around the user-speciﬁed level. The proposed method is applicable to any models for which statistical tests of conditional independence are available, such as discrete models and Gaussian models. Keywords: Bayesian networks, false discovery rate, PC algorithm, directed acyclic graph, skeleton</p><p>3 0.35517925 <a title="47-lda-3" href="./jmlr-2009-Robustness_and_Regularization_of_Support_Vector_Machines.html">82 jmlr-2009-Robustness and Regularization of Support Vector Machines</a></p>
<p>Author: Huan Xu, Constantine Caramanis, Shie Mannor</p><p>Abstract: We consider regularized support vector machines (SVMs) and show that they are precisely equivalent to a new robust optimization formulation. We show that this equivalence of robust optimization and regularization has implications for both algorithms, and analysis. In terms of algorithms, the equivalence suggests more general SVM-like algorithms for classiﬁcation that explicitly build in protection to noise, and at the same time control overﬁtting. On the analysis front, the equivalence of robustness and regularization provides a robust optimization interpretation for the success of regularized SVMs. We use this new robustness interpretation of SVMs to give a new proof of consistency of (kernelized) SVMs, thus establishing robustness as the reason regularized SVMs generalize well. Keywords: robustness, regularization, generalization, kernel, support vector machine</p><p>4 0.35371786 <a title="47-lda-4" href="./jmlr-2009-Bounded_Kernel-Based_Online_Learning.html">13 jmlr-2009-Bounded Kernel-Based Online Learning</a></p>
<p>Author: Francesco Orabona, Joseph Keshet, Barbara Caputo</p><p>Abstract: A common problem of kernel-based online algorithms, such as the kernel-based Perceptron algorithm, is the amount of memory required to store the online hypothesis, which may increase without bound as the algorithm progresses. Furthermore, the computational load of such algorithms grows linearly with the amount of memory used to store the hypothesis. To attack these problems, most previous work has focused on discarding some of the instances, in order to keep the memory bounded. In this paper we present a new algorithm, in which the instances are not discarded, but are instead projected onto the space spanned by the previous online hypothesis. We call this algorithm Projectron. While the memory size of the Projectron solution cannot be predicted before training, we prove that its solution is guaranteed to be bounded. We derive a relative mistake bound for the proposed algorithm, and deduce from it a slightly different algorithm which outperforms the Perceptron. We call this second algorithm Projectron++. We show that this algorithm can be extended to handle the multiclass and the structured output settings, resulting, as far as we know, in the ﬁrst online bounded algorithm that can learn complex classiﬁcation tasks. The method of bounding the hypothesis representation can be applied to any conservative online algorithm and to other online algorithms, as it is demonstrated for ALMA2 . Experimental results on various data sets show the empirical advantage of our technique compared to various bounded online algorithms, both in terms of memory and accuracy. Keywords: online learning, kernel methods, support vector machines, bounded support set</p><p>5 0.35219014 <a title="47-lda-5" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>Author: John Langford, Lihong Li, Tong Zhang</p><p>Abstract: We propose a general method called truncated gradient to induce sparsity in the weights of onlinelearning algorithms with convex loss functions. This method has several essential properties: 1. The degree of sparsity is continuous—a parameter controls the rate of sparsiﬁcation from no sparsiﬁcation to total sparsiﬁcation. 2. The approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular L1 -regularization method in the batch setting. We prove that small rates of sparsiﬁcation result in only small additional regret with respect to typical online-learning guarantees. 3. The approach works well empirically. We apply the approach to several data sets and ﬁnd for data sets with large numbers of features, substantial sparsity is discoverable. Keywords: truncated gradient, stochastic gradient descent, online learning, sparsity, regularization, Lasso</p><p>6 0.34942415 <a title="47-lda-6" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>7 0.34850407 <a title="47-lda-7" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>8 0.3473998 <a title="47-lda-8" href="./jmlr-2009-Provably_Efficient_Learning_with_Typed_Parametric_Models.html">75 jmlr-2009-Provably Efficient Learning with Typed Parametric Models</a></p>
<p>9 0.34419927 <a title="47-lda-9" href="./jmlr-2009-Analysis_of_Perceptron-Based_Active_Learning.html">9 jmlr-2009-Analysis of Perceptron-Based Active Learning</a></p>
<p>10 0.34326947 <a title="47-lda-10" href="./jmlr-2009-Exploiting_Product_Distributions_to_Identify_Relevant_Variables_of_Correlation_Immune_Functions.html">32 jmlr-2009-Exploiting Product Distributions to Identify Relevant Variables of Correlation Immune Functions</a></p>
<p>11 0.34287417 <a title="47-lda-11" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>12 0.34284595 <a title="47-lda-12" href="./jmlr-2009-Efficient_Online_and_Batch_Learning_Using_Forward_Backward_Splitting.html">27 jmlr-2009-Efficient Online and Batch Learning Using Forward Backward Splitting</a></p>
<p>13 0.34280264 <a title="47-lda-13" href="./jmlr-2009-Reproducing_Kernel_Banach_Spaces_for_Machine_Learning.html">80 jmlr-2009-Reproducing Kernel Banach Spaces for Machine Learning</a></p>
<p>14 0.34215784 <a title="47-lda-14" href="./jmlr-2009-The_Nonparanormal%3A_Semiparametric_Estimation_of_High_Dimensional_Undirected_Graphs.html">94 jmlr-2009-The Nonparanormal: Semiparametric Estimation of High Dimensional Undirected Graphs</a></p>
<p>15 0.34193343 <a title="47-lda-15" href="./jmlr-2009-Refinement_of_Reproducing_Kernels.html">78 jmlr-2009-Refinement of Reproducing Kernels</a></p>
<p>16 0.34182325 <a title="47-lda-16" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>17 0.34123433 <a title="47-lda-17" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>18 0.34026158 <a title="47-lda-18" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>19 0.34003699 <a title="47-lda-19" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<p>20 0.34001708 <a title="47-lda-20" href="./jmlr-2009-On_the_Consistency_of_Feature_Selection_using_Greedy_Least_Squares_Regression.html">66 jmlr-2009-On the Consistency of Feature Selection using Greedy Least Squares Regression</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
