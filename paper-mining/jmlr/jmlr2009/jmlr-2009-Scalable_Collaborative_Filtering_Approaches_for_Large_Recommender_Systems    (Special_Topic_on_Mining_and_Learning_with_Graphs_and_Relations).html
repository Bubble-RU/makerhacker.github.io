<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>84 jmlr-2009-Scalable Collaborative Filtering Approaches for Large Recommender Systems    (Special Topic on Mining and Learning with Graphs and Relations)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-84" href="#">jmlr2009-84</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>84 jmlr-2009-Scalable Collaborative Filtering Approaches for Large Recommender Systems    (Special Topic on Mining and Learning with Graphs and Relations)</h1>
<br/><p>Source: <a title="jmlr-2009-84-pdf" href="http://jmlr.org/papers/volume10/takacs09a/takacs09a.pdf">pdf</a></p><p>Author: Gábor Takács, István Pilászy, Bottyán Németh, Domonkos Tikk</p><p>Abstract: The collaborative ﬁltering (CF) using known user ratings of items has proved to be effective for predicting user preferences in item selection. This thriving subﬁeld of machine learning became popular in the late 1990s with the spread of online services that use recommender systems, such as Amazon, Yahoo! Music, and Netﬂix. CF approaches are usually designed to work on very large data sets. Therefore the scalability of the methods is crucial. In this work, we propose various scalable solutions that are validated against the Netﬂix Prize data set, currently the largest publicly available collection. First, we propose various matrix factorization (MF) based techniques. Second, a neighbor correction method for MF is outlined, which alloys the global perspective of MF and the localized property of neighbor based approaches efﬁciently. In the experimentation section, we ﬁrst report on some implementation issues, and we suggest on how parameter optimization can be performed efﬁciently for MFs. We then show that the proposed scalable approaches compare favorably with existing ones in terms of prediction accuracy and/or required training time. Finally, we report on some experiments performed on MovieLens and Jester data sets. Keywords: collaborative ﬁltering, recommender systems, matrix factorization, neighbor based correction, Netﬂix prize ∗. All authors also afﬁliated with Gravity R&D; Ltd., 1092 Budapest, Kinizsi u. 11., Hungary; info@gravityrd.com. c 2009 G´ bor Tak´ cs, Istv´ n Pil´ szy, Botty´ n N´ meth and Domonkos Tikk. a a a a a e ´ ´ ´ TAK ACS , P IL ASZY, N E METH AND T IKK</p><p>Reference: <a title="jmlr-2009-84-reference" href="../jmlr2009_reference/jmlr-2009-Scalable_Collaborative_Filtering_Approaches_for_Large_Recommender_Systems%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 o Budapest, Hungary  Editors: Paolo Frasconi, Kristian Kersting, Hannu Toivonen and Koji Tsuda  Abstract The collaborative ﬁltering (CF) using known user ratings of items has proved to be effective for predicting user preferences in item selection. [sent-17, score-0.689]
</p><p>2 Keywords: collaborative ﬁltering, recommender systems, matrix factorization, neighbor based correction, Netﬂix prize  ∗. [sent-28, score-0.287]
</p><p>3 The task of recommender systems is to recommend items that ﬁt a user’s tastes, in order to help the user in selecting/purchasing items from an overwhelming set of choices. [sent-37, score-0.365]
</p><p>4 The importance of a good recommender system was recognized by Netﬂix, which led to the announcement of the Netﬂix Prize (NP) competition to motivate researchers to improve the accuracy of the recommender system of Netﬂix (see details in Section 5. [sent-45, score-0.237]
</p><p>5 Contentbased approaches proﬁle users and items by identifying their characteristic features, such us demographic data for user proﬁling, and product information/descriptions for item proﬁling. [sent-49, score-0.394]
</p><p>6 The proﬁles are used by algorithms to connect user interests and item descriptions when generating recommendations. [sent-50, score-0.212]
</p><p>7 Therefore, the alternative approach, termed collaborative ﬁltering (CF), which makes use of only past user activities (for example, transaction history or user satisfaction expressed in ratings), is usually more feasible. [sent-52, score-0.275]
</p><p>8 In this framework, the user ﬁrst provides ratings of some items, titles or artifacts, usually on a discrete numerical scale, and the system then recommends other items based on ratings the virtual community has already provided. [sent-56, score-0.633]
</p><p>9 Memorybased approaches operate on the entire database of ratings collected by the vendor or service supplier. [sent-68, score-0.227]
</p><p>10 Vozalis and Margaritis (2007) presented an MF approach that incorporates demographic information and ratings to enhance plain CF algorithms. [sent-78, score-0.227]
</p><p>11 A realization of (U, I, R) denoted by (u, i, r) means that user u rated item i with value r. [sent-148, score-0.279]
</p><p>12 We assume sampling without replacement in the sense that (user ID, item ID) pairs are unique in the sample, which means that users do not rate items more than once. [sent-156, score-0.301]
</p><p>13 The / value of the matrix R at position (u, i) ∈ T , denoted by rui , stores the rating of user u for item i. [sent-160, score-0.417]
</p><p>14 For clarity, we use the term (u, i)-th rating in general for rui , and (u, i)-th training example if rui : (u, i) ∈ T . [sent-161, score-0.367]
</p><p>15 When we predict a given rating rui by rui we refer to the user u as active user and to the item i ˆ as active item. [sent-177, score-0.648]
</p><p>16 The (u, i) pair of active user and active item is termed query. [sent-178, score-0.23]
</p><p>17 We call P the user feature matrix and Q the item feature matrix, and K is the number of features in the given factorization. [sent-193, score-0.274]
</p><p>18 In the case of the given problem, the unknown ratings of R cannot be represented by zero. [sent-198, score-0.227]
</p><p>19 Let puk denote the elements of 628  S CALABLE C OLLABORATIVE F ILTERING A PPROACHES  P ∈ RN×K , and qki the elements of Q ∈ RK×M . [sent-200, score-0.314]
</p><p>20 Then: K  rui = ˆ  ∑ puk qki = pu qi ,  (2)  k=1  eui = rui − rui ˆ 1 e′ = e2 , ui 2 ui SSE =  ∑  (u,i)∈T  e2 ui  for (u, i) ∈ T , (3) =  2  K  ∑  (u,i)∈T  rui − ∑ puk qki  ,  k=1  1 SSE′ = SSE = ∑ e′ , ui 2 (u,i)∈T RMSE = ∗  SSE/|T |,  ∗  (P , Q ) = arg min SSE′ = arg min SSE = arg min RMSE. [sent-202, score-1.497]
</p><p>21 (P,Q)  (P,Q)  (4)  (P,Q)  Here rui denotes how the u-th user would rate the i-th item, according to the model, eui denotes the ˆ training error measured at the (u, i)-th rating, and SSE denotes the sum of squared training errors. [sent-203, score-0.37]
</p><p>22 For the incremental gradient descent method, suppose we are at the (u, i)-th training example, rui , and its approximation rui is given. [sent-212, score-0.347]
</p><p>23 ˆ We compute the gradient of e′ : ui ∂ ′ e = −eui · qki , ∂puk ui  ∂ ′ e = −eui · puk . [sent-213, score-0.424]
</p><p>24 ∂qki ui  We update the weights in the direction opposite to the gradient: p′ = puk + η · eui · qki , uk q′ = qki + η · eui · puk . [sent-214, score-0.855]
</p><p>25 1 RISMF The matrix factorization presented in the previous section can overﬁt for users with few (no more than K) ratings: assuming that the feature vectors of the items rated by the user are linearly independent and Q does not change, there exists a user feature vector with zero training error. [sent-222, score-0.529]
</p><p>26 Similar to the ISMF approach, we compute the gradient of e′ : ui ∂ ′ e = −eui · puk + λ · qki . [sent-232, score-0.379]
</p><p>27 ∂qki ui  ∂ ′ e = −eui · qki + λ · puk , ∂puk ui  (6)  We update the weights in the direction opposite to the gradient: p′ = puk + η · (eui · qki − λ · puk ), uk q′ = qki + η · (eui · puk − λ · qki ). [sent-233, score-1.346]
</p><p>28 We apply a simple thresholding method to ensure the nonnegativeness of features: for the (u, i)th training example in a given epoch, if puk or qki would become negative when applying (7), we reset their value to 0. [sent-288, score-0.338]
</p><p>29 We describe the modiﬁed equations for the case when both user and item features are required to be nonnegative: p′ = max{0, puk + η · eui · qki − λ · puk }, uk q′ = max{0, qki + η · eui · puk − λ · qki }. [sent-289, score-1.362]
</p><p>30 With the modiﬁcation of (7) we get the following equations: puk (t + 1) = puk (t) + ∆puk (t + 1), ∆puk (t + 1) = η · (eui · qki (t) − λ · puk (t)) + σ · ∆puk (t), qki (t + 1) = qki (t) + ∆qki (t + 1), ∆qki (t + 1) = η · (eui · puk (t) − λ · qki (t)) + σ · ∆qki (t). [sent-297, score-1.256]
</p><p>31 Here σ is the momentum factor and puk (t + 1) and puk (t) stands for the new and old k-th feature values of user u, respectively. [sent-298, score-0.466]
</p><p>32 We can evaluate the test ratings of a user immediately after iterating through its ratings in the training set, and before starting to iterate through the next user’s ratings. [sent-311, score-0.571]
</p><p>33 Then we do not apply the whole training procedure, just reset the user feature weights of the active user u and apply the second training procedure for n∗ epochs for u. [sent-321, score-0.316]
</p><p>34 The second training procedure needs to iterate through the entire database—which requires slow (but sequential) disk access operation—only once (not n∗ times), as the ratings of user u can be kept in memory and can be immediately re-used in the next epoch. [sent-322, score-0.344]
</p><p>35 We remark that the presented algorithm cannot handle the addition of new items, and after the addition of many new ratings to the database, Q will be obsolete, thus the ﬁrst training step should be re-run. [sent-323, score-0.251]
</p><p>36 Via the proposed technique, the information 633  ´ ´ ´ TAK ACS , P IL ASZY, N E METH AND T IKK  that a user purchased but did not rate an item can be incorporated in such cases into the prediction model. [sent-336, score-0.212]
</p><p>37 A proper linear combination—not depending on u or i—of the original user feature vector and this new feature vector can yield a third feature vector for the prediction of rui that produces a better predictor than the original one (see Table 7 for the performance gain obtained by transductive MF). [sent-343, score-0.313]
</p><p>38 i  |i′ : (u, i′ ) ∈ V | + 1 i′′ =1  (9)  ′′  i′′ =i  rui = rui + ν · p′ ( j) · qi = pu · qi + ν · p′ ( j) · qi . [sent-345, score-0.362]
</p><p>39 (9) ensures that the more ratings a user has in the training set, the less ˆ the prediction relies on the information the validation set provides, thus rui will differ less from rui . [sent-347, score-0.62]
</p><p>40 ˆ′ In practice, ν need not be determined: we can use rui and p′ ( j) · qi as two predictions for rui , and ˆ′ u apply linear regression to get an improved RMSE. [sent-348, score-0.296]
</p><p>41 Transductive MF is a post-processing method for MF, which can exploit the information provided by the existence of ratings even if the values of the ratings are unknown. [sent-349, score-0.454]
</p><p>42 The idea is that we store user and item features in a two dimensional (2D) grid instead of a one dimensional row vector. [sent-353, score-0.238]
</p><p>43 Accordingly, we replace the puk and qki notation of feature values with pukl and qimn . [sent-354, score-0.362]
</p><p>44 S CALABLE C OLLABORATIVE F ILTERING A PPROACHES  With this function the gradient used for learning pukl and qikl will be: ∂ ∂ ′ eui ′′ = e + 2 ∑ s(k, l, m, n)(pukl − pumn ), ∂pukl ∂pukl ui m=k,n=l ∂ ∂ ′ eui ′′ = e + 2 ∑ s(k, l, m, n)(qikl − qimn ). [sent-360, score-0.302]
</p><p>45 Visual feature maps can also be used to demonstrate to the users why they are provided the current recommendations: showing similar feature map of items formerly ranked high by the user can justify the recommendations. [sent-380, score-0.311]
</p><p>46 The weight between the u-th input and the k-th hidden neuron corresponds to puk , and the weight between the k-th hidden neuron and the i-th output neuron corresponds to qki . [sent-388, score-0.314]
</p><p>47 x1  y1 z1  xu  puk  zk  qki  yi  zK xN  yM  Figure 3: The multilayer perceptron equivalent for the general MF scheme In the learning phase, an incremental learning method is used. [sent-389, score-0.341]
</p><p>48 We can extend this NN to be equivalent to the BRISMF: item biases can be handled by adding a bias (constant 1) input to the output neurons; user biases can be handled by setting q2• weights to 1 and keeping them constant. [sent-396, score-0.212]
</p><p>49 The answer of the predictor is then obtained by combining the ratings of similar users (items) for the active item (user). [sent-408, score-0.442]
</p><p>50 The ﬁrst variant is termed the user neighbor based, and the second is termed the item neighbor based approach. [sent-409, score-0.386]
</p><p>51 MF can identify the major structural patterns in the ratings matrix. [sent-411, score-0.227]
</p><p>52 Assuming the item neighbor based scheme, the corrected answer for query (u, i) is the following: rui = pT qi + γ ˆ u  ∑ j∈Tu \{i} si j pT q j − ru j u , ∑ j∈Tu \{i} si j  where si j is the similarity between qi and q j , and Tu is set of the items rated by user u. [sent-422, score-0.631]
</p><p>53 Memory requirements: for the u-th user, our method requires the storing qu and Q in the memory, that is O(KN), while their approach must store the item-by-item matrix and the ratings of the user, which is O(M 2 + |Tu |). [sent-437, score-0.227]
</p><p>54 Experiments Currently, the largest publicly available ratings data set is provided by Netﬂix, a popular online DVD rental company. [sent-450, score-0.227]
</p><p>55 The data set released for the competition was substantially larger than former benchmark data sets and contained about 100 million ratings from over 480k users on nearly 18k movies (see details in Subsection 5. [sent-452, score-0.386]
</p><p>56 For comparison, the well-known EachMovie data set4 only consists of 2,811,983 ratings of 4. [sent-455, score-0.227]
</p><p>57 (2006) used a 3 millions ratings subset of the GroupLens project, which entirely contains about 13 million ratings from 105k users on 9k movies. [sent-459, score-0.55]
</p><p>58 The evaluation metrics of recommender systems can greatly vary depending on the characteristics of the data set (size, rating density, rating scale), the goal of recommendation, the purpose of evaluation (Herlocker et al. [sent-466, score-0.234]
</p><p>59 In the current CF setting the goal is to evaluate the predictive accuracy, namely, how closely the recommender system can predict the true ratings of the users, measured in terms of root mean squared error. [sent-468, score-0.327]
</p><p>60 1 T HE N ETFLIX P RIZE DATA S ET The data set provided generously by Netﬂix for the NP competition contains (u, i, rui , dui ) rating quadruples, representing that user u rated item i as rui on date dui , where dui ∈ D the ordered set of possible dates. [sent-474, score-0.702]
</p><p>61 The ratings rui are integers from 1 to 5, where 1 is the worst, and 5 is the best. [sent-475, score-0.365]
</p><p>62 The data were collected between October, 1998 and December, 2005 and reﬂect the distribution of all ratings received by Netﬂix during this period (Bennett and Lanning, 2007). [sent-476, score-0.227]
</p><p>63 Netﬂix selected a random subset of users from their entire customer base with at least 20 ratings in the given period. [sent-478, score-0.323]
</p><p>64 A Hold-out set was created from the 9 most recent ratings of the users, consisting of about 4. [sent-479, score-0.227]
</p><p>65 The ratings of the Hold-out set were split randomly with equal probability into three subsets of equal size: Quiz, Test and Probe. [sent-482, score-0.227]
</p><p>66 The ratings of the Quiz and Test sets were withheld as a Qualifying set to evaluate competitors. [sent-484, score-0.227]
</p><p>67 All Data (~100 M user item pairs)  Held-Out Set (last 9 rating for each user: 4. [sent-496, score-0.279]
</p><p>68 2 M pairs)  Training Data  Random 3way split  Training Data  Probe  Known ratings  Quiz Test  Ratings withheld by Netflix for scoring  Figure 4: The train-test split and the naming convention of Netﬂix Prize data set, after Bell et al. [sent-497, score-0.227]
</p><p>69 (2007a)  There are some interesting characteristics of the data and the set-up of the competition that pose a difﬁcult challenge for prediction: • The distribution over the time of the ratings of the Hold-out set is quite different from the Training set. [sent-498, score-0.247]
</p><p>70 To put this into numbers, ten percent of users rated 16 or fewer movies and one quarter rated 36 or fewer. [sent-504, score-0.273]
</p><p>71 640  S CALABLE C OLLABORATIVE F ILTERING A PPROACHES  • The variance of movie ratings is also very different. [sent-513, score-0.227]
</p><p>72 1 million ratings from 6,040 users on 3,900 movies. [sent-546, score-0.323]
</p><p>73 As in the case of NP, ratings are made on a 5 star scale, and the rating records are also quadruples containing the timestamp of the rating. [sent-547, score-0.294]
</p><p>74 Demographic data provided with the ratings are not used in our setting. [sent-548, score-0.227]
</p><p>75 , 2001) contains 4,136,360 ratings from 73,421 users on 100 jokes. [sent-563, score-0.323]
</p><p>76 Two thirds of the users have rated at least 36 jokes, and the remaining ones have rated between 15 and 35 jokes. [sent-566, score-0.23]
</p><p>77 The average number of ratings per user is 46, so it is a particularly dense data set compared to NP and MovieLens. [sent-567, score-0.32]
</p><p>78 We found the following order to be very effective: iterate over users in an arbitrary order, and for each user, take the ratings in an increasing chronological order, that is, starting from the oldest and ending with the newest. [sent-585, score-0.323]
</p><p>79 The reason for this is that in the evaluation data set movies have much more ratings than users. [sent-625, score-0.27]
</p><p>80 Consequently, if we do user-subsampling for example with 100 instead of the original 200 ratings we lose more information than at movie-subsampling when we have for example 10000 ratings instead of 20000. [sent-626, score-0.454]
</p><p>81 The constant method always predicts the average of the ratings in the training set, the item average outputs the average of the training ratings of the active item at querying, while the item neighbor (Tak´ cs et al. [sent-723, score-0.928]
</p><p>82 Model  Epochs  constant item average item neighbor BRISMF#5 BRISMF#10 BRISMF#20 BRISMF#50 BRISMF#100 BRISMF#200 BRISMF#500  – – – 35 27 24 23 24 21 20  RMSE w/o S2 1. [sent-766, score-0.307]
</p><p>83 The improvement of BRISMF#500 with S2 correction over item neighbor is 2. [sent-811, score-0.248]
</p><p>84 Model  Epochs  constant item average item neighbor BRISMF#5 BRISMF#10 BRISMF#20 BRISMF#50 BRISMF#100  – – – 7 8 7 8 7  RMSE w/o S2 5. [sent-839, score-0.307]
</p><p>85 9056, and for a random order— obtained by a random shufﬂe of the ratings of each user—the RMSE is 0. [sent-888, score-0.227]
</p><p>86 This means that the time-complexity of MF is sublinear in the number of ratings (see Section 5. [sent-897, score-0.227]
</p><p>87 We remark that the number of ratings is proportional to the number of users; the ratio of them—which is equal to the average number of ratings per user—is 209 in the training set. [sent-899, score-0.478]
</p><p>88 9 1⋅103  11 10 10 1⋅104 1⋅105 Number of users  1⋅106  Figure 5: Effect of the number of users on Probe10 RMSE and on the optimal number of training epochs. [sent-909, score-0.216]
</p><p>89 6 S EMIPOSITIVE AND P OSITIVE MF We investigated the accuracy of semipositive and positive variants using the following MFs: • SemPosMF#800: this is a semipositive MF, where user features are nonnegative and item features are arbitrary. [sent-912, score-0.392]
</p><p>90 26%  Table 6: Examining the effect of retraining user features We investigated the effect of retraining only P, when BRISMF#250 was learnt on a subset of the database. [sent-977, score-0.231]
</p><p>91 Second, we discarded the last N1 ratings of each user and ran the same retraining procedure. [sent-986, score-0.376]
</p><p>92 Obviously, the removal of ratings increased Probe10 RMSE signiﬁcantly; the highest score was 1. [sent-988, score-0.227]
</p><p>93 Thus, the proposed retraining method can handle the addition of new ratings as well. [sent-991, score-0.283]
</p><p>94 These experiments verify the usability of user feature retraining method for handling new users or ratings. [sent-992, score-0.263]
</p><p>95 (9) to improve predictions we use only the ratings in the Qualify set, not in the Probe10 + Qualify set. [sent-1022, score-0.227]
</p><p>96 These experiments demonstrate that the Probe10 set containing 140,840 ratings is big enough to evalute not only single methods, but also combinations of many methods. [sent-1099, score-0.227]
</p><p>97 9071 can be achieved within 200 seconds (including the time to train with the 100 million available ratings and evaluate on the Probe10)! [sent-1136, score-0.227]
</p><p>98 1 epoch means that the model was trained for one epoch and then the ratings of the ﬁrst 1/10 of users was used for another epoch. [sent-1141, score-0.445]
</p><p>99 5): when we train only for 1 epoch, the features of the ﬁrst trained users will be obsolete at the end of the epoch, since items have nonsense values at the beginning of the training procedure, and item features change signiﬁcantly by the end of the epoch. [sent-1143, score-0.377]
</p><p>100 In the case of the P-step, one needs to run the solver for each user to determine how the features of the items rated by the user should be combined to best predict the ratings. [sent-1160, score-0.365]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mf', 0.486), ('rmse', 0.409), ('brismf', 0.38), ('ratings', 0.227), ('puk', 0.162), ('qki', 0.152), ('tak', 0.147), ('rui', 0.138), ('item', 0.119), ('meth', 0.111), ('recommender', 0.1), ('qb', 0.096), ('users', 0.096), ('quiz', 0.095), ('cf', 0.093), ('user', 0.093), ('eui', 0.091), ('rismf', 0.091), ('items', 0.086), ('acs', 0.086), ('aszy', 0.086), ('ikk', 0.086), ('calable', 0.081), ('koren', 0.081), ('pproaches', 0.081), ('ix', 0.08), ('jester', 0.076), ('bell', 0.074), ('collaborative', 0.071), ('ollaborative', 0.069), ('neighbor', 0.069), ('rated', 0.067), ('rating', 0.067), ('wq', 0.066), ('net', 0.065), ('mae', 0.065), ('epochs', 0.064), ('iltering', 0.062), ('nb', 0.061), ('epoch', 0.061), ('correction', 0.06), ('movielens', 0.06), ('pb', 0.059), ('retraining', 0.056), ('sse', 0.052), ('probe', 0.049), ('prize', 0.047), ('mfs', 0.046), ('paterek', 0.046), ('semposmf', 0.046), ('ui', 0.045), ('movies', 0.043), ('np', 0.042), ('ltering', 0.037), ('semipositive', 0.035), ('il', 0.034), ('factorization', 0.034), ('salakhutdinov', 0.032), ('momentum', 0.031), ('bknb', 0.03), ('funk', 0.03), ('mlmf', 0.03), ('posmf', 0.03), ('pukl', 0.03), ('transductive', 0.028), ('incremental', 0.027), ('features', 0.026), ('pu', 0.026), ('pil', 0.025), ('qikl', 0.025), ('szy', 0.025), ('cup', 0.025), ('training', 0.024), ('pl', 0.023), ('variants', 0.023), ('scalable', 0.022), ('sarwar', 0.022), ('competition', 0.02), ('blended', 0.02), ('cinematch', 0.02), ('dui', 0.02), ('qualifying', 0.02), ('wui', 0.02), ('qi', 0.02), ('gradient', 0.02), ('srebro', 0.019), ('goldberg', 0.019), ('manually', 0.019), ('corrected', 0.019), ('feature', 0.018), ('nonnegative', 0.018), ('termed', 0.018), ('budapest', 0.018), ('accuracy', 0.017), ('kdd', 0.017), ('personalized', 0.017), ('hungary', 0.017), ('tastes', 0.017), ('mxy', 0.017), ('accurate', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000014 <a title="84-tfidf-1" href="./jmlr-2009-Scalable_Collaborative_Filtering_Approaches_for_Large_Recommender_Systems%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">84 jmlr-2009-Scalable Collaborative Filtering Approaches for Large Recommender Systems    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Gábor Takács, István Pilászy, Bottyán Németh, Domonkos Tikk</p><p>Abstract: The collaborative ﬁltering (CF) using known user ratings of items has proved to be effective for predicting user preferences in item selection. This thriving subﬁeld of machine learning became popular in the late 1990s with the spread of online services that use recommender systems, such as Amazon, Yahoo! Music, and Netﬂix. CF approaches are usually designed to work on very large data sets. Therefore the scalability of the methods is crucial. In this work, we propose various scalable solutions that are validated against the Netﬂix Prize data set, currently the largest publicly available collection. First, we propose various matrix factorization (MF) based techniques. Second, a neighbor correction method for MF is outlined, which alloys the global perspective of MF and the localized property of neighbor based approaches efﬁciently. In the experimentation section, we ﬁrst report on some implementation issues, and we suggest on how parameter optimization can be performed efﬁciently for MFs. We then show that the proposed scalable approaches compare favorably with existing ones in terms of prediction accuracy and/or required training time. Finally, we report on some experiments performed on MovieLens and Jester data sets. Keywords: collaborative ﬁltering, recommender systems, matrix factorization, neighbor based correction, Netﬂix prize ∗. All authors also afﬁliated with Gravity R&D; Ltd., 1092 Budapest, Kinizsi u. 11., Hungary; info@gravityrd.com. c 2009 G´ bor Tak´ cs, Istv´ n Pil´ szy, Botty´ n N´ meth and Domonkos Tikk. a a a a a e ´ ´ ´ TAK ACS , P IL ASZY, N E METH AND T IKK</p><p>2 0.26734558 <a title="84-tfidf-2" href="./jmlr-2009-A_Survey_of_Accuracy_Evaluation_Metrics_of_Recommendation_Tasks.html">4 jmlr-2009-A Survey of Accuracy Evaluation Metrics of Recommendation Tasks</a></p>
<p>Author: Asela Gunawardana, Guy Shani</p><p>Abstract: Recommender systems are now popular both commercially and in the research community, where many algorithms have been suggested for providing recommendations. These algorithms typically perform differently in various domains and tasks. Therefore, it is important from the research perspective, as well as from a practical view, to be able to decide on an algorithm that matches the domain and the task of interest. The standard way to make such decisions is by comparing a number of algorithms ofﬂine using some evaluation metric. Indeed, many evaluation metrics have been suggested for comparing recommendation algorithms. The decision on the proper evaluation metric is often critical, as each metric may favor a different algorithm. In this paper we review the proper construction of ofﬂine experiments for deciding on the most appropriate algorithm. We discuss three important tasks of recommender systems, and classify a set of appropriate well known evaluation metrics for each task. We demonstrate how using an improper evaluation metric can lead to the selection of an improper algorithm for the task of interest. We also discuss other important considerations when designing ofﬂine experiments. Keywords: recommender systems, collaborative ﬁltering, statistical analysis, comparative studies</p><p>3 0.13088408 <a title="84-tfidf-3" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>Author: Jacob Abernethy, Francis Bach, Theodoros Evgeniou, Jean-Philippe Vert</p><p>Abstract: We present a general approach for collaborative ﬁltering (CF) using spectral regularization to learn linear operators mapping a set of “users” to a set of possibly desired “objects”. In particular, several recent low-rank type matrix-completion methods for CF are shown to be special cases of our proposed framework. Unlike existing regularization-based CF, our approach can be used to incorporate additional information such as attributes of the users/objects—a feature currently lacking in existing regularization-based CF approaches—using popular and well-known kernel methods. We provide novel representer theorems that we use to develop new estimation methods. We then provide learning algorithms based on low-rank decompositions and test them on a standard CF data set. The experiments indicate the advantages of generalizing the existing regularization-based CF methods to incorporate related information about users and objects. Finally, we show that certain multi-task learning methods can be also seen as special cases of our proposed approach. Keywords: collaborative ﬁltering, matrix completion, kernel methods, spectral regularization</p><p>4 0.034890465 <a title="84-tfidf-4" href="./jmlr-2009-Model_Monitor_%28M2%29%3A_Evaluating%2C_Comparing%2C_and_Monitoring_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">56 jmlr-2009-Model Monitor (M2): Evaluating, Comparing, and Monitoring Models    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Troy Raeder, Nitesh V. Chawla</p><p>Abstract: This paper presents Model Monitor (M 2 ), a Java toolkit for robustly evaluating machine learning algorithms in the presence of changing data distributions. M 2 provides a simple and intuitive framework in which users can evaluate classiﬁers under hypothesized shifts in distribution and therefore determine the best model (or models) for their data under a number of potential scenarios. Additionally, M 2 is fully integrated with the WEKA machine learning environment, so that a variety of commodity classiﬁers can be used if desired. Keywords: machine learning, open-source software, distribution shift, scenario analysis</p><p>5 0.028083153 <a title="84-tfidf-5" href="./jmlr-2009-Learning_When_Concepts_Abound.html">50 jmlr-2009-Learning When Concepts Abound</a></p>
<p>Author: Omid Madani, Michael Connor, Wiley Greiner</p><p>Abstract: Many learning tasks, such as large-scale text categorization and word prediction, can beneﬁt from efﬁcient training and classiﬁcation when the number of classes, in addition to instances and features, is large, that is, in the thousands and beyond. We investigate the learning of sparse class indices to address this challenge. An index is a mapping from features to classes. We compare the index-learning methods against other techniques, including one-versus-rest and top-down classiﬁcation using perceptrons and support vector machines. We ﬁnd that index learning is highly advantageous for space and time efﬁciency, at both training and classiﬁcation times. Moreover, this approach yields similar and at times better accuracies. On problems with hundreds of thousands of instances and thousands of classes, the index is learned in minutes, while other methods can take hours or days. As we explain, the design of the learning update enables conveniently constraining each feature to connect to a small subset of the classes in the index. This constraint is crucial for scalability. Given an instance with l active (positive-valued) features, each feature on average connecting to d classes in the index (in the order of 10s in our experiments), update and classiﬁcation take O(dl log(dl)). Keywords: index learning, many-class learning, multiclass learning, online learning, text categorization</p><p>6 0.024055071 <a title="84-tfidf-6" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>7 0.023058003 <a title="84-tfidf-7" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>8 0.020956999 <a title="84-tfidf-8" href="./jmlr-2009-Similarity-based_Classification%3A_Concepts_and_Algorithms.html">86 jmlr-2009-Similarity-based Classification: Concepts and Algorithms</a></p>
<p>9 0.020461708 <a title="84-tfidf-9" href="./jmlr-2009-Dlib-ml%3A_A_Machine_Learning_Toolkit%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">26 jmlr-2009-Dlib-ml: A Machine Learning Toolkit    (Machine Learning Open Source Software Paper)</a></p>
<p>10 0.020397704 <a title="84-tfidf-10" href="./jmlr-2009-Stable_and_Efficient_Gaussian_Process_Calculations.html">88 jmlr-2009-Stable and Efficient Gaussian Process Calculations</a></p>
<p>11 0.02010702 <a title="84-tfidf-11" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>12 0.019180421 <a title="84-tfidf-12" href="./jmlr-2009-Feature_Selection_with_Ensembles%2C_Artificial_Variables%2C_and_Redundancy_Elimination%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">35 jmlr-2009-Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination    (Special Topic on Model Selection)</a></p>
<p>13 0.019180281 <a title="84-tfidf-13" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>14 0.018438691 <a title="84-tfidf-14" href="./jmlr-2009-Distance_Metric_Learning_for_Large_Margin_Nearest_Neighbor_Classification.html">24 jmlr-2009-Distance Metric Learning for Large Margin Nearest Neighbor Classification</a></p>
<p>15 0.017414724 <a title="84-tfidf-15" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>16 0.016397759 <a title="84-tfidf-16" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>17 0.015917754 <a title="84-tfidf-17" href="./jmlr-2009-A_Parameter-Free_Classification_Method_for_Large_Scale_Learning.html">3 jmlr-2009-A Parameter-Free Classification Method for Large Scale Learning</a></p>
<p>18 0.015185652 <a title="84-tfidf-18" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>19 0.015126025 <a title="84-tfidf-19" href="./jmlr-2009-Robust_Process_Discovery_with_Artificial_Negative_Events%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">81 jmlr-2009-Robust Process Discovery with Artificial Negative Events    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>20 0.015110378 <a title="84-tfidf-20" href="./jmlr-2009-Estimating_Labels_from_Label_Proportions.html">29 jmlr-2009-Estimating Labels from Label Proportions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.112), (1, -0.072), (2, 0.088), (3, -0.093), (4, -0.024), (5, -0.045), (6, 0.195), (7, 0.072), (8, 0.241), (9, -0.533), (10, -0.081), (11, -0.195), (12, -0.247), (13, 0.016), (14, -0.008), (15, 0.024), (16, -0.092), (17, 0.04), (18, 0.02), (19, 0.033), (20, -0.09), (21, -0.107), (22, 0.102), (23, -0.032), (24, -0.012), (25, -0.004), (26, -0.019), (27, 0.017), (28, -0.04), (29, 0.013), (30, -0.017), (31, 0.001), (32, 0.021), (33, -0.053), (34, 0.063), (35, -0.039), (36, -0.072), (37, 0.013), (38, -0.048), (39, 0.045), (40, 0.019), (41, 0.005), (42, -0.046), (43, 0.026), (44, -0.002), (45, 0.031), (46, 0.004), (47, -0.01), (48, -0.023), (49, -0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95826656 <a title="84-lsi-1" href="./jmlr-2009-Scalable_Collaborative_Filtering_Approaches_for_Large_Recommender_Systems%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">84 jmlr-2009-Scalable Collaborative Filtering Approaches for Large Recommender Systems    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Gábor Takács, István Pilászy, Bottyán Németh, Domonkos Tikk</p><p>Abstract: The collaborative ﬁltering (CF) using known user ratings of items has proved to be effective for predicting user preferences in item selection. This thriving subﬁeld of machine learning became popular in the late 1990s with the spread of online services that use recommender systems, such as Amazon, Yahoo! Music, and Netﬂix. CF approaches are usually designed to work on very large data sets. Therefore the scalability of the methods is crucial. In this work, we propose various scalable solutions that are validated against the Netﬂix Prize data set, currently the largest publicly available collection. First, we propose various matrix factorization (MF) based techniques. Second, a neighbor correction method for MF is outlined, which alloys the global perspective of MF and the localized property of neighbor based approaches efﬁciently. In the experimentation section, we ﬁrst report on some implementation issues, and we suggest on how parameter optimization can be performed efﬁciently for MFs. We then show that the proposed scalable approaches compare favorably with existing ones in terms of prediction accuracy and/or required training time. Finally, we report on some experiments performed on MovieLens and Jester data sets. Keywords: collaborative ﬁltering, recommender systems, matrix factorization, neighbor based correction, Netﬂix prize ∗. All authors also afﬁliated with Gravity R&D; Ltd., 1092 Budapest, Kinizsi u. 11., Hungary; info@gravityrd.com. c 2009 G´ bor Tak´ cs, Istv´ n Pil´ szy, Botty´ n N´ meth and Domonkos Tikk. a a a a a e ´ ´ ´ TAK ACS , P IL ASZY, N E METH AND T IKK</p><p>2 0.93265963 <a title="84-lsi-2" href="./jmlr-2009-A_Survey_of_Accuracy_Evaluation_Metrics_of_Recommendation_Tasks.html">4 jmlr-2009-A Survey of Accuracy Evaluation Metrics of Recommendation Tasks</a></p>
<p>Author: Asela Gunawardana, Guy Shani</p><p>Abstract: Recommender systems are now popular both commercially and in the research community, where many algorithms have been suggested for providing recommendations. These algorithms typically perform differently in various domains and tasks. Therefore, it is important from the research perspective, as well as from a practical view, to be able to decide on an algorithm that matches the domain and the task of interest. The standard way to make such decisions is by comparing a number of algorithms ofﬂine using some evaluation metric. Indeed, many evaluation metrics have been suggested for comparing recommendation algorithms. The decision on the proper evaluation metric is often critical, as each metric may favor a different algorithm. In this paper we review the proper construction of ofﬂine experiments for deciding on the most appropriate algorithm. We discuss three important tasks of recommender systems, and classify a set of appropriate well known evaluation metrics for each task. We demonstrate how using an improper evaluation metric can lead to the selection of an improper algorithm for the task of interest. We also discuss other important considerations when designing ofﬂine experiments. Keywords: recommender systems, collaborative ﬁltering, statistical analysis, comparative studies</p><p>3 0.41613948 <a title="84-lsi-3" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>Author: Jacob Abernethy, Francis Bach, Theodoros Evgeniou, Jean-Philippe Vert</p><p>Abstract: We present a general approach for collaborative ﬁltering (CF) using spectral regularization to learn linear operators mapping a set of “users” to a set of possibly desired “objects”. In particular, several recent low-rank type matrix-completion methods for CF are shown to be special cases of our proposed framework. Unlike existing regularization-based CF, our approach can be used to incorporate additional information such as attributes of the users/objects—a feature currently lacking in existing regularization-based CF approaches—using popular and well-known kernel methods. We provide novel representer theorems that we use to develop new estimation methods. We then provide learning algorithms based on low-rank decompositions and test them on a standard CF data set. The experiments indicate the advantages of generalizing the existing regularization-based CF methods to incorporate related information about users and objects. Finally, we show that certain multi-task learning methods can be also seen as special cases of our proposed approach. Keywords: collaborative ﬁltering, matrix completion, kernel methods, spectral regularization</p><p>4 0.16149923 <a title="84-lsi-4" href="./jmlr-2009-Model_Monitor_%28M2%29%3A_Evaluating%2C_Comparing%2C_and_Monitoring_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">56 jmlr-2009-Model Monitor (M2): Evaluating, Comparing, and Monitoring Models    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Troy Raeder, Nitesh V. Chawla</p><p>Abstract: This paper presents Model Monitor (M 2 ), a Java toolkit for robustly evaluating machine learning algorithms in the presence of changing data distributions. M 2 provides a simple and intuitive framework in which users can evaluate classiﬁers under hypothesized shifts in distribution and therefore determine the best model (or models) for their data under a number of potential scenarios. Additionally, M 2 is fully integrated with the WEKA machine learning environment, so that a variety of commodity classiﬁers can be used if desired. Keywords: machine learning, open-source software, distribution shift, scenario analysis</p><p>5 0.11867294 <a title="84-lsi-5" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>Author: Hugo Larochelle, Yoshua Bengio, Jérôme Louradour, Pascal Lamblin</p><p>Abstract: Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments conﬁrm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms. Keywords: artiﬁcial neural networks, deep belief networks, restricted Boltzmann machines, autoassociators, unsupervised learning</p><p>6 0.1079394 <a title="84-lsi-6" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>7 0.097230628 <a title="84-lsi-7" href="./jmlr-2009-An_Anticorrelation_Kernel_for_Subsystem_Training_in_Multiple_Classifier_Systems.html">8 jmlr-2009-An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems</a></p>
<p>8 0.097058982 <a title="84-lsi-8" href="./jmlr-2009-Transfer_Learning_for_Reinforcement_Learning_Domains%3A_A_Survey.html">96 jmlr-2009-Transfer Learning for Reinforcement Learning Domains: A Survey</a></p>
<p>9 0.095444307 <a title="84-lsi-9" href="./jmlr-2009-Learning_When_Concepts_Abound.html">50 jmlr-2009-Learning When Concepts Abound</a></p>
<p>10 0.091307066 <a title="84-lsi-10" href="./jmlr-2009-Evolutionary_Model_Type_Selection_for_Global_Surrogate_Modeling.html">31 jmlr-2009-Evolutionary Model Type Selection for Global Surrogate Modeling</a></p>
<p>11 0.089241862 <a title="84-lsi-11" href="./jmlr-2009-Using_Local_Dependencies_within_Batches_to_Improve_Large_Margin_Classifiers.html">99 jmlr-2009-Using Local Dependencies within Batches to Improve Large Margin Classifiers</a></p>
<p>12 0.088187687 <a title="84-lsi-12" href="./jmlr-2009-Hash_Kernels_for_Structured_Data.html">38 jmlr-2009-Hash Kernels for Structured Data</a></p>
<p>13 0.084874824 <a title="84-lsi-13" href="./jmlr-2009-Dlib-ml%3A_A_Machine_Learning_Toolkit%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">26 jmlr-2009-Dlib-ml: A Machine Learning Toolkit    (Machine Learning Open Source Software Paper)</a></p>
<p>14 0.081808642 <a title="84-lsi-14" href="./jmlr-2009-Feature_Selection_with_Ensembles%2C_Artificial_Variables%2C_and_Redundancy_Elimination%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">35 jmlr-2009-Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination    (Special Topic on Model Selection)</a></p>
<p>15 0.081166506 <a title="84-lsi-15" href="./jmlr-2009-Supervised_Descriptive_Rule_Discovery%3A_A_Unifying_Survey_of_Contrast_Set%2C_Emerging_Pattern_and_Subgroup_Mining.html">92 jmlr-2009-Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining</a></p>
<p>16 0.080858819 <a title="84-lsi-16" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>17 0.078509629 <a title="84-lsi-17" href="./jmlr-2009-On_Efficient_Large_Margin_Semisupervised_Learning%3A_Method_and_Theory.html">63 jmlr-2009-On Efficient Large Margin Semisupervised Learning: Method and Theory</a></p>
<p>18 0.078412287 <a title="84-lsi-18" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>19 0.077445358 <a title="84-lsi-19" href="./jmlr-2009-A_Parameter-Free_Classification_Method_for_Large_Scale_Learning.html">3 jmlr-2009-A Parameter-Free Classification Method for Large Scale Learning</a></p>
<p>20 0.074737385 <a title="84-lsi-20" href="./jmlr-2009-Distance_Metric_Learning_for_Large_Margin_Nearest_Neighbor_Classification.html">24 jmlr-2009-Distance Metric Learning for Large Margin Nearest Neighbor Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.015), (11, 0.019), (19, 0.01), (21, 0.042), (26, 0.019), (38, 0.031), (47, 0.47), (52, 0.035), (55, 0.027), (58, 0.022), (66, 0.061), (68, 0.021), (73, 0.074), (90, 0.039), (96, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81957215 <a title="84-lda-1" href="./jmlr-2009-Entropy_Inference_and_the_James-Stein_Estimator%2C_with_Application_to_Nonlinear_Gene_Association_Networks.html">28 jmlr-2009-Entropy Inference and the James-Stein Estimator, with Application to Nonlinear Gene Association Networks</a></p>
<p>Author: Jean Hausser, Korbinian Strimmer</p><p>Abstract: We present a procedure for effective estimation of entropy and mutual information from smallsample data, and apply it to the problem of inferring high-dimensional gene association networks. SpeciÄ?Ĺš cally, we develop a James-Stein-type shrinkage estimator, resulting in a procedure that is highly efÄ?Ĺš cient statistically as well as computationally. Despite its simplicity, we show that it outperforms eight other entropy estimation procedures across a diverse range of sampling scenarios and data-generating models, even in cases of severe undersampling. We illustrate the approach by analyzing E. coli gene expression data and computing an entropy-based gene-association network from gene expression data. A computer program is available that implements the proposed shrinkage estimator. Keywords: entropy, shrinkage estimation, James-Stein estimator, Ă˘&euro;&oelig;small n, large pĂ˘&euro;? setting, mutual information, gene association network</p><p>2 0.78500783 <a title="84-lda-2" href="./jmlr-2009-Online_Learning_with_Sample_Path_Constraints.html">67 jmlr-2009-Online Learning with Sample Path Constraints</a></p>
<p>Author: Shie Mannor, John N. Tsitsiklis, Jia Yuan Yu</p><p>Abstract: We study online learning where a decision maker interacts with Nature with the objective of maximizing her long-term average reward subject to some sample path average constraints. We deﬁne the reward-in-hindsight as the highest reward the decision maker could have achieved, while satisfying the constraints, had she known Nature’s choices in advance. We show that in general the reward-in-hindsight is not attainable. The convex hull of the reward-in-hindsight function is, however, attainable. For the important case of a single constraint, the convex hull turns out to be the highest attainable function. Using a calibrated forecasting rule, we provide an explicit strategy that attains this convex hull. We also measure the performance of heuristic methods based on non-calibrated forecasters in experiments involving a CPU power management problem. Keywords: online learning, calibration, regret minimization, approachability</p><p>same-paper 3 0.77163577 <a title="84-lda-3" href="./jmlr-2009-Scalable_Collaborative_Filtering_Approaches_for_Large_Recommender_Systems%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">84 jmlr-2009-Scalable Collaborative Filtering Approaches for Large Recommender Systems    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Gábor Takács, István Pilászy, Bottyán Németh, Domonkos Tikk</p><p>Abstract: The collaborative ﬁltering (CF) using known user ratings of items has proved to be effective for predicting user preferences in item selection. This thriving subﬁeld of machine learning became popular in the late 1990s with the spread of online services that use recommender systems, such as Amazon, Yahoo! Music, and Netﬂix. CF approaches are usually designed to work on very large data sets. Therefore the scalability of the methods is crucial. In this work, we propose various scalable solutions that are validated against the Netﬂix Prize data set, currently the largest publicly available collection. First, we propose various matrix factorization (MF) based techniques. Second, a neighbor correction method for MF is outlined, which alloys the global perspective of MF and the localized property of neighbor based approaches efﬁciently. In the experimentation section, we ﬁrst report on some implementation issues, and we suggest on how parameter optimization can be performed efﬁciently for MFs. We then show that the proposed scalable approaches compare favorably with existing ones in terms of prediction accuracy and/or required training time. Finally, we report on some experiments performed on MovieLens and Jester data sets. Keywords: collaborative ﬁltering, recommender systems, matrix factorization, neighbor based correction, Netﬂix prize ∗. All authors also afﬁliated with Gravity R&D; Ltd., 1092 Budapest, Kinizsi u. 11., Hungary; info@gravityrd.com. c 2009 G´ bor Tak´ cs, Istv´ n Pil´ szy, Botty´ n N´ meth and Domonkos Tikk. a a a a a e ´ ´ ´ TAK ACS , P IL ASZY, N E METH AND T IKK</p><p>4 0.33168018 <a title="84-lda-4" href="./jmlr-2009-A_Survey_of_Accuracy_Evaluation_Metrics_of_Recommendation_Tasks.html">4 jmlr-2009-A Survey of Accuracy Evaluation Metrics of Recommendation Tasks</a></p>
<p>Author: Asela Gunawardana, Guy Shani</p><p>Abstract: Recommender systems are now popular both commercially and in the research community, where many algorithms have been suggested for providing recommendations. These algorithms typically perform differently in various domains and tasks. Therefore, it is important from the research perspective, as well as from a practical view, to be able to decide on an algorithm that matches the domain and the task of interest. The standard way to make such decisions is by comparing a number of algorithms ofﬂine using some evaluation metric. Indeed, many evaluation metrics have been suggested for comparing recommendation algorithms. The decision on the proper evaluation metric is often critical, as each metric may favor a different algorithm. In this paper we review the proper construction of ofﬂine experiments for deciding on the most appropriate algorithm. We discuss three important tasks of recommender systems, and classify a set of appropriate well known evaluation metrics for each task. We demonstrate how using an improper evaluation metric can lead to the selection of an improper algorithm for the task of interest. We also discuss other important considerations when designing ofﬂine experiments. Keywords: recommender systems, collaborative ﬁltering, statistical analysis, comparative studies</p><p>5 0.31348458 <a title="84-lda-5" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>Author: Halbert White, Karim Chalak</p><p>Abstract: Judea Pearl’s Causal Model is a rich framework that provides deep insight into the nature of causal relations. As yet, however, the Pearl Causal Model (PCM) has had a lesser impact on economics or econometrics than on other disciplines. This may be due in part to the fact that the PCM is not as well suited to analyzing structures that exhibit features of central interest to economists and econometricians: optimization, equilibrium, and learning. We offer the settable systems framework as an extension of the PCM that permits causal discourse in systems embodying optimization, equilibrium, and learning. Because these are common features of physical, natural, or social systems, our framework may prove generally useful for machine learning. Important features distinguishing the settable system framework from the PCM are its countable dimensionality and the use of partitioning and partition-speciﬁc response functions to accommodate the behavior of optimizing and interacting agents and to eliminate the requirement of a unique ﬁxed point for the system. Reﬁnements of the PCM include the settable systems treatment of attributes, the causal role of exogenous variables, and the dual role of variables as causes and responses. A series of closely related machine learning examples and examples from game theory and machine learning with feedback demonstrates some limitations of the PCM and motivates the distinguishing features of settable systems. Keywords: equations causal models, game theory, machine learning, recursive estimation, simultaneous</p><p>6 0.26389965 <a title="84-lda-6" href="./jmlr-2009-Robustness_and_Regularization_of_Support_Vector_Machines.html">82 jmlr-2009-Robustness and Regularization of Support Vector Machines</a></p>
<p>7 0.25659561 <a title="84-lda-7" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>8 0.24741964 <a title="84-lda-8" href="./jmlr-2009-Multi-task_Reinforcement_Learning_in_Partially_Observable_Stochastic_Environments.html">57 jmlr-2009-Multi-task Reinforcement Learning in Partially Observable Stochastic Environments</a></p>
<p>9 0.24658558 <a title="84-lda-9" href="./jmlr-2009-Prediction_With_Expert_Advice_For_The_Brier_Game.html">73 jmlr-2009-Prediction With Expert Advice For The Brier Game</a></p>
<p>10 0.24397326 <a title="84-lda-10" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>11 0.24163207 <a title="84-lda-11" href="./jmlr-2009-Provably_Efficient_Learning_with_Typed_Parametric_Models.html">75 jmlr-2009-Provably Efficient Learning with Typed Parametric Models</a></p>
<p>12 0.24076647 <a title="84-lda-12" href="./jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>13 0.24044923 <a title="84-lda-13" href="./jmlr-2009-Reinforcement_Learning_in_Finite_MDPs%3A_PAC_Analysis.html">79 jmlr-2009-Reinforcement Learning in Finite MDPs: PAC Analysis</a></p>
<p>14 0.23928037 <a title="84-lda-14" href="./jmlr-2009-Nonextensive_Information_Theoretic_Kernels_on_Measures.html">61 jmlr-2009-Nonextensive Information Theoretic Kernels on Measures</a></p>
<p>15 0.23874557 <a title="84-lda-15" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>16 0.23650706 <a title="84-lda-16" href="./jmlr-2009-Distributed_Algorithms_for_Topic_Models.html">25 jmlr-2009-Distributed Algorithms for Topic Models</a></p>
<p>17 0.23580767 <a title="84-lda-17" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>18 0.23577261 <a title="84-lda-18" href="./jmlr-2009-Efficient_Online_and_Batch_Learning_Using_Forward_Backward_Splitting.html">27 jmlr-2009-Efficient Online and Batch Learning Using Forward Backward Splitting</a></p>
<p>19 0.23560849 <a title="84-lda-19" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>20 0.2347504 <a title="84-lda-20" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
