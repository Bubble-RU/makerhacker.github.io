<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-100" href="#">jmlr2009-100</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</h1>
<br/><p>Source: <a title="jmlr-2009-100-pdf" href="http://jmlr.org/papers/volume10/argyriou09a/argyriou09a.pdf">pdf</a></p><p>Author: Andreas Argyriou, Charles A. Micchelli, Massimiliano Pontil</p><p>Abstract: We consider a general class of regularization methods which learn a vector of parameters on the basis of linear measurements. It is well known that if the regularizer is a nondecreasing function of the L2 norm, then the learned vector is a linear combination of the input data. This result, known as the representer theorem, lies at the basis of kernel-based methods in machine learning. In this paper, we prove the necessity of the above condition, in the case of differentiable regularizers. We further extend our analysis to regularization methods which learn a matrix, a problem which is motivated by the application to multi-task learning. In this context, we study a more general representer theorem, which holds for a larger class of regularizers. We provide a necessary and sufﬁcient condition characterizing this class of matrix regularizers and we highlight some concrete examples of practical importance. Our analysis uses basic principles from matrix theory, especially the useful notion of matrix nondecreasing functions. Keywords: kernel methods, matrix learning, minimal norm interpolation, multi-task learning, regularization</p><p>Reference: <a title="jmlr-2009-100-reference" href="../jmlr2009_reference/jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('interpol', 0.269), ('nondecreas', 0.231), ('icchell', 0.211), ('ontil', 0.211), ('rgyriou', 0.211), ('nm', 0.197), ('regul', 0.189), ('nn', 0.187), ('atrix', 0.179), ('argyriou', 0.175), ('micchell', 0.164), ('xti', 0.161), ('wt', 0.154), ('heorem', 0.148), ('epres', 0.148), ('rd', 0.139), ('singul', 0.138), ('nmt', 0.134), ('nr', 0.125), ('sn', 0.124)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="100-tfidf-1" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>2 0.18846153 <a title="100-tfidf-2" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>3 0.18068767 <a title="100-tfidf-3" href="./jmlr-2009-Reproducing_Kernel_Banach_Spaces_for_Machine_Learning.html">80 jmlr-2009-Reproducing Kernel Banach Spaces for Machine Learning</a></p>
<p>4 0.1504335 <a title="100-tfidf-4" href="./jmlr-2009-Refinement_of_Reproducing_Kernels.html">78 jmlr-2009-Refinement of Reproducing Kernels</a></p>
<p>5 0.12227284 <a title="100-tfidf-5" href="./jmlr-2009-SGD-QN%3A_Careful_Quasi-Newton_Stochastic_Gradient_Descent.html">83 jmlr-2009-SGD-QN: Careful Quasi-Newton Stochastic Gradient Descent</a></p>
<p>6 0.11762277 <a title="100-tfidf-6" href="./jmlr-2009-Efficient_Online_and_Batch_Learning_Using_Forward_Backward_Splitting.html">27 jmlr-2009-Efficient Online and Batch Learning Using Forward Backward Splitting</a></p>
<p>7 0.1112963 <a title="100-tfidf-7" href="./jmlr-2009-Deterministic_Error_Analysis_of_Support_Vector_Regression_and_Related_Regularized_Kernel_Methods.html">22 jmlr-2009-Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods</a></p>
<p>8 0.089081146 <a title="100-tfidf-8" href="./jmlr-2009-Similarity-based_Classification%3A_Concepts_and_Algorithms.html">86 jmlr-2009-Similarity-based Classification: Concepts and Algorithms</a></p>
<p>9 0.086192496 <a title="100-tfidf-9" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>10 0.076910704 <a title="100-tfidf-10" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<p>11 0.07020022 <a title="100-tfidf-11" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>12 0.067514345 <a title="100-tfidf-12" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>13 0.06404078 <a title="100-tfidf-13" href="./jmlr-2009-Universal_Kernel-Based_Learning_with_Applications_to_Regular_Languages%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">98 jmlr-2009-Universal Kernel-Based Learning with Applications to Regular Languages    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>14 0.059131861 <a title="100-tfidf-14" href="./jmlr-2009-Classification_with_Gaussians_and_Convex_Loss.html">16 jmlr-2009-Classification with Gaussians and Convex Loss</a></p>
<p>15 0.055301905 <a title="100-tfidf-15" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>16 0.054115951 <a title="100-tfidf-16" href="./jmlr-2009-On_Uniform_Deviations_of_General_Empirical_Risks_with_Unboundedness%2C_Dependence%2C_and_High_Dimensionality.html">65 jmlr-2009-On Uniform Deviations of General Empirical Risks with Unboundedness, Dependence, and High Dimensionality</a></p>
<p>17 0.053998947 <a title="100-tfidf-17" href="./jmlr-2009-An_Algorithm_for_Reading_Dependencies_from_the_Minimal_Undirected_Independence_Map_of_a_Graphoid_that_Satisfies_Weak_Transitivity.html">6 jmlr-2009-An Algorithm for Reading Dependencies from the Minimal Undirected Independence Map of a Graphoid that Satisfies Weak Transitivity</a></p>
<p>18 0.053947948 <a title="100-tfidf-18" href="./jmlr-2009-Fourier_Theoretic_Probabilistic_Inference_over_Permutations.html">36 jmlr-2009-Fourier Theoretic Probabilistic Inference over Permutations</a></p>
<p>19 0.053489499 <a title="100-tfidf-19" href="./jmlr-2009-Optimized_Cutting_Plane_Algorithm_for_Large-Scale_Risk_Minimization.html">69 jmlr-2009-Optimized Cutting Plane Algorithm for Large-Scale Risk Minimization</a></p>
<p>20 0.053432073 <a title="100-tfidf-20" href="./jmlr-2009-Robustness_and_Regularization_of_Support_Vector_Machines.html">82 jmlr-2009-Robustness and Regularization of Support Vector Machines</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.302), (1, -0.016), (2, -0.161), (3, 0.133), (4, 0.123), (5, -0.271), (6, -0.197), (7, 0.234), (8, -0.023), (9, -0.101), (10, -0.055), (11, 0.11), (12, 0.088), (13, -0.063), (14, 0.034), (15, -0.081), (16, 0.092), (17, -0.002), (18, -0.152), (19, -0.086), (20, 0.005), (21, -0.059), (22, -0.016), (23, 0.046), (24, 0.008), (25, -0.038), (26, -0.008), (27, -0.028), (28, -0.133), (29, 0.065), (30, -0.023), (31, 0.02), (32, -0.078), (33, -0.029), (34, -0.105), (35, 0.001), (36, 0.062), (37, -0.04), (38, -0.002), (39, -0.071), (40, 0.01), (41, -0.038), (42, 0.029), (43, -0.06), (44, -0.1), (45, -0.028), (46, -0.024), (47, 0.064), (48, -0.041), (49, 0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93848944 <a title="100-lsi-1" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>2 0.71649832 <a title="100-lsi-2" href="./jmlr-2009-Reproducing_Kernel_Banach_Spaces_for_Machine_Learning.html">80 jmlr-2009-Reproducing Kernel Banach Spaces for Machine Learning</a></p>
<p>3 0.69788623 <a title="100-lsi-3" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>4 0.59299093 <a title="100-lsi-4" href="./jmlr-2009-Refinement_of_Reproducing_Kernels.html">78 jmlr-2009-Refinement of Reproducing Kernels</a></p>
<p>5 0.55638063 <a title="100-lsi-5" href="./jmlr-2009-Deterministic_Error_Analysis_of_Support_Vector_Regression_and_Related_Regularized_Kernel_Methods.html">22 jmlr-2009-Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods</a></p>
<p>6 0.42819735 <a title="100-lsi-6" href="./jmlr-2009-Efficient_Online_and_Batch_Learning_Using_Forward_Backward_Splitting.html">27 jmlr-2009-Efficient Online and Batch Learning Using Forward Backward Splitting</a></p>
<p>7 0.40911958 <a title="100-lsi-7" href="./jmlr-2009-SGD-QN%3A_Careful_Quasi-Newton_Stochastic_Gradient_Descent.html">83 jmlr-2009-SGD-QN: Careful Quasi-Newton Stochastic Gradient Descent</a></p>
<p>8 0.40111193 <a title="100-lsi-8" href="./jmlr-2009-Similarity-based_Classification%3A_Concepts_and_Algorithms.html">86 jmlr-2009-Similarity-based Classification: Concepts and Algorithms</a></p>
<p>9 0.38692358 <a title="100-lsi-9" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<p>10 0.3724522 <a title="100-lsi-10" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>11 0.36998203 <a title="100-lsi-11" href="./jmlr-2009-Universal_Kernel-Based_Learning_with_Applications_to_Regular_Languages%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">98 jmlr-2009-Universal Kernel-Based Learning with Applications to Regular Languages    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>12 0.35927773 <a title="100-lsi-12" href="./jmlr-2009-Optimized_Cutting_Plane_Algorithm_for_Large-Scale_Risk_Minimization.html">69 jmlr-2009-Optimized Cutting Plane Algorithm for Large-Scale Risk Minimization</a></p>
<p>13 0.33895478 <a title="100-lsi-13" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>14 0.32077479 <a title="100-lsi-14" href="./jmlr-2009-Classification_with_Gaussians_and_Convex_Loss.html">16 jmlr-2009-Classification with Gaussians and Convex Loss</a></p>
<p>15 0.31697395 <a title="100-lsi-15" href="./jmlr-2009-Fourier_Theoretic_Probabilistic_Inference_over_Permutations.html">36 jmlr-2009-Fourier Theoretic Probabilistic Inference over Permutations</a></p>
<p>16 0.31438577 <a title="100-lsi-16" href="./jmlr-2009-Robustness_and_Regularization_of_Support_Vector_Machines.html">82 jmlr-2009-Robustness and Regularization of Support Vector Machines</a></p>
<p>17 0.30035502 <a title="100-lsi-17" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>18 0.29328626 <a title="100-lsi-18" href="./jmlr-2009-Computing_Maximum_Likelihood_Estimates_in_Recursive_Linear_Models_with_Correlated_Errors.html">17 jmlr-2009-Computing Maximum Likelihood Estimates in Recursive Linear Models with Correlated Errors</a></p>
<p>19 0.26544994 <a title="100-lsi-19" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>20 0.26527435 <a title="100-lsi-20" href="./jmlr-2009-An_Anticorrelation_Kernel_for_Subsystem_Training_in_Multiple_Classifier_Systems.html">8 jmlr-2009-An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.09), (17, 0.027), (31, 0.011), (39, 0.419), (40, 0.014), (42, 0.042), (43, 0.155), (62, 0.011), (85, 0.047), (87, 0.039), (97, 0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6057303 <a title="100-lda-1" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>2 0.42834714 <a title="100-lda-2" href="./jmlr-2009-Refinement_of_Reproducing_Kernels.html">78 jmlr-2009-Refinement of Reproducing Kernels</a></p>
<p>3 0.42237079 <a title="100-lda-3" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>4 0.42223424 <a title="100-lda-4" href="./jmlr-2009-Reproducing_Kernel_Banach_Spaces_for_Machine_Learning.html">80 jmlr-2009-Reproducing Kernel Banach Spaces for Machine Learning</a></p>
<p>5 0.41292757 <a title="100-lda-5" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>6 0.41192344 <a title="100-lda-6" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>7 0.41146705 <a title="100-lda-7" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>8 0.41086802 <a title="100-lda-8" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>9 0.4104819 <a title="100-lda-9" href="./jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>10 0.40689749 <a title="100-lda-10" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>11 0.40684682 <a title="100-lda-11" href="./jmlr-2009-Bounded_Kernel-Based_Online_Learning.html">13 jmlr-2009-Bounded Kernel-Based Online Learning</a></p>
<p>12 0.40680578 <a title="100-lda-12" href="./jmlr-2009-Online_Learning_with_Samples_Drawn_from_Non-identical_Distributions.html">68 jmlr-2009-Online Learning with Samples Drawn from Non-identical Distributions</a></p>
<p>13 0.40245074 <a title="100-lda-13" href="./jmlr-2009-Bi-Level_Path_Following_for_Cross_Validated_Solution_of_Kernel_Quantile_Regression.html">12 jmlr-2009-Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression</a></p>
<p>14 0.40232831 <a title="100-lda-14" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>15 0.40193185 <a title="100-lda-15" href="./jmlr-2009-Improving_the_Reliability_of_Causal_Discovery_from_Small_Data_Sets_Using_Argumentation%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">41 jmlr-2009-Improving the Reliability of Causal Discovery from Small Data Sets Using Argumentation    (Special Topic on Causality)</a></p>
<p>16 0.40097451 <a title="100-lda-16" href="./jmlr-2009-Polynomial-Delay_Enumeration_of_Monotonic_Graph_Classes.html">72 jmlr-2009-Polynomial-Delay Enumeration of Monotonic Graph Classes</a></p>
<p>17 0.40095416 <a title="100-lda-17" href="./jmlr-2009-Analysis_of_Perceptron-Based_Active_Learning.html">9 jmlr-2009-Analysis of Perceptron-Based Active Learning</a></p>
<p>18 0.40044555 <a title="100-lda-18" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>19 0.39994228 <a title="100-lda-19" href="./jmlr-2009-Estimation_of_Sparse_Binary_Pairwise_Markov_Networks_using_Pseudo-likelihoods.html">30 jmlr-2009-Estimation of Sparse Binary Pairwise Markov Networks using Pseudo-likelihoods</a></p>
<p>20 0.39917752 <a title="100-lda-20" href="./jmlr-2009-Classification_with_Gaussians_and_Convex_Loss.html">16 jmlr-2009-Classification with Gaussians and Convex Loss</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
