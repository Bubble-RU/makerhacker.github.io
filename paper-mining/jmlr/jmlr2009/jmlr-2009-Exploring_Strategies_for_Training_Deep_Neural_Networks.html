<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-33" href="#">jmlr2009-33</a> knowledge-graph by maker-knowledge-mining</p><h1>33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</h1>
<br/><p>Source: <a title="jmlr-2009-33-pdf" href="http://jmlr.org/papers/volume10/larochelle09a/larochelle09a.pdf">pdf</a></p><p>Author: Hugo Larochelle, Yoshua Bengio, Jérôme Louradour, Pascal Lamblin</p><p>Abstract: Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments conﬁrm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms. Keywords: artiﬁcial neural networks, deep belief networks, restricted Boltzmann machines, autoassociators, unsupervised learning</p><p>Reference: <a title="jmlr-2009-33-reference" href="../jmlr2009_reference/jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lay', 0.462), ('deep', 0.293), ('autoassocy', 0.267), ('srbm', 0.239), ('rbm', 0.232), ('unsuperv', 0.213), ('hid', 0.2), ('hinton', 0.146), ('eep', 0.144), ('amblin', 0.137), ('arochel', 0.137), ('ourado', 0.137), ('xploring', 0.13), ('saa', 0.122), ('engio', 0.116), ('trategy', 0.11), ('rbms', 0.109), ('network', 0.108), ('etwork', 0.107), ('sigm', 0.103)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="33-tfidf-1" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>2 0.091326527 <a title="33-tfidf-2" href="./jmlr-2009-NEUROSVM%3A_An_Architecture_to_Reduce_the_Effect_of_the_Choice_of_Kernel_on_the_Performance_of_SVM.html">58 jmlr-2009-NEUROSVM: An Architecture to Reduce the Effect of the Choice of Kernel on the Performance of SVM</a></p>
<p>3 0.089655317 <a title="33-tfidf-3" href="./jmlr-2009-CarpeDiem%3A_Optimizing_the_Viterbi_Algorithm_and_Applications_to_Supervised_Sequential_Learning.html">14 jmlr-2009-CarpeDiem: Optimizing the Viterbi Algorithm and Applications to Supervised Sequential Learning</a></p>
<p>4 0.08531706 <a title="33-tfidf-4" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>5 0.06887757 <a title="33-tfidf-5" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>6 0.063658684 <a title="33-tfidf-6" href="./jmlr-2009-Identification_of_Recurrent_Neural_Networks_by_Bayesian_Interrogation_Techniques.html">40 jmlr-2009-Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques</a></p>
<p>7 0.060272086 <a title="33-tfidf-7" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>8 0.050573897 <a title="33-tfidf-8" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>9 0.050139382 <a title="33-tfidf-9" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>10 0.046313085 <a title="33-tfidf-10" href="./jmlr-2009-On_Uniform_Deviations_of_General_Empirical_Risks_with_Unboundedness%2C_Dependence%2C_and_High_Dimensionality.html">65 jmlr-2009-On Uniform Deviations of General Empirical Risks with Unboundedness, Dependence, and High Dimensionality</a></p>
<p>11 0.045544486 <a title="33-tfidf-11" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<p>12 0.044122279 <a title="33-tfidf-12" href="./jmlr-2009-SGD-QN%3A_Careful_Quasi-Newton_Stochastic_Gradient_Descent.html">83 jmlr-2009-SGD-QN: Careful Quasi-Newton Stochastic Gradient Descent</a></p>
<p>13 0.037060633 <a title="33-tfidf-13" href="./jmlr-2009-Learning_Acyclic_Probabilistic_Circuits_Using_Test_Paths.html">44 jmlr-2009-Learning Acyclic Probabilistic Circuits Using Test Paths</a></p>
<p>14 0.037024084 <a title="33-tfidf-14" href="./jmlr-2009-On_the_Consistency_of_Feature_Selection_using_Greedy_Least_Squares_Regression.html">66 jmlr-2009-On the Consistency of Feature Selection using Greedy Least Squares Regression</a></p>
<p>15 0.036347445 <a title="33-tfidf-15" href="./jmlr-2009-Distance_Metric_Learning_for_Large_Margin_Nearest_Neighbor_Classification.html">24 jmlr-2009-Distance Metric Learning for Large Margin Nearest Neighbor Classification</a></p>
<p>16 0.034955811 <a title="33-tfidf-16" href="./jmlr-2009-Bounded_Kernel-Based_Online_Learning.html">13 jmlr-2009-Bounded Kernel-Based Online Learning</a></p>
<p>17 0.033176269 <a title="33-tfidf-17" href="./jmlr-2009-Efficient_Online_and_Batch_Learning_Using_Forward_Backward_Splitting.html">27 jmlr-2009-Efficient Online and Batch Learning Using Forward Backward Splitting</a></p>
<p>18 0.032780491 <a title="33-tfidf-18" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>19 0.032536149 <a title="33-tfidf-19" href="./jmlr-2009-Analysis_of_Perceptron-Based_Active_Learning.html">9 jmlr-2009-Analysis of Perceptron-Based Active Learning</a></p>
<p>20 0.031660102 <a title="33-tfidf-20" href="./jmlr-2009-Nieme%3A_Large-Scale_Energy-Based_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">60 jmlr-2009-Nieme: Large-Scale Energy-Based Models    (Machine Learning Open Source Software Paper)</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.183), (1, -0.001), (2, -0.019), (3, -0.016), (4, -0.072), (5, 0.087), (6, 0.067), (7, -0.026), (8, 0.003), (9, 0.057), (10, -0.104), (11, 0.086), (12, -0.091), (13, -0.005), (14, 0.065), (15, -0.327), (16, 0.245), (17, 0.207), (18, -0.151), (19, 0.271), (20, 0.001), (21, 0.033), (22, 0.11), (23, 0.011), (24, 0.067), (25, 0.083), (26, 0.054), (27, 0.04), (28, -0.065), (29, 0.025), (30, 0.032), (31, 0.001), (32, 0.093), (33, 0.144), (34, -0.061), (35, 0.041), (36, 0.035), (37, 0.083), (38, 0.009), (39, 0.022), (40, 0.043), (41, 0.089), (42, 0.058), (43, 0.101), (44, 0.039), (45, -0.093), (46, -0.035), (47, 0.014), (48, 0.099), (49, -0.166)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95006055 <a title="33-lsi-1" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>2 0.56797755 <a title="33-lsi-2" href="./jmlr-2009-NEUROSVM%3A_An_Architecture_to_Reduce_the_Effect_of_the_Choice_of_Kernel_on_the_Performance_of_SVM.html">58 jmlr-2009-NEUROSVM: An Architecture to Reduce the Effect of the Choice of Kernel on the Performance of SVM</a></p>
<p>3 0.54512477 <a title="33-lsi-3" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>4 0.44448477 <a title="33-lsi-4" href="./jmlr-2009-CarpeDiem%3A_Optimizing_the_Viterbi_Algorithm_and_Applications_to_Supervised_Sequential_Learning.html">14 jmlr-2009-CarpeDiem: Optimizing the Viterbi Algorithm and Applications to Supervised Sequential Learning</a></p>
<p>5 0.33681613 <a title="33-lsi-5" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>6 0.25193521 <a title="33-lsi-6" href="./jmlr-2009-Learning_Acyclic_Probabilistic_Circuits_Using_Test_Paths.html">44 jmlr-2009-Learning Acyclic Probabilistic Circuits Using Test Paths</a></p>
<p>7 0.250175 <a title="33-lsi-7" href="./jmlr-2009-Identification_of_Recurrent_Neural_Networks_by_Bayesian_Interrogation_Techniques.html">40 jmlr-2009-Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques</a></p>
<p>8 0.24021176 <a title="33-lsi-8" href="./jmlr-2009-A_Parameter-Free_Classification_Method_for_Large_Scale_Learning.html">3 jmlr-2009-A Parameter-Free Classification Method for Large Scale Learning</a></p>
<p>9 0.23030098 <a title="33-lsi-9" href="./jmlr-2009-Similarity-based_Classification%3A_Concepts_and_Algorithms.html">86 jmlr-2009-Similarity-based Classification: Concepts and Algorithms</a></p>
<p>10 0.22897762 <a title="33-lsi-10" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>11 0.21461192 <a title="33-lsi-11" href="./jmlr-2009-On_the_Consistency_of_Feature_Selection_using_Greedy_Least_Squares_Regression.html">66 jmlr-2009-On the Consistency of Feature Selection using Greedy Least Squares Regression</a></p>
<p>12 0.19589208 <a title="33-lsi-12" href="./jmlr-2009-Nieme%3A_Large-Scale_Energy-Based_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">60 jmlr-2009-Nieme: Large-Scale Energy-Based Models    (Machine Learning Open Source Software Paper)</a></p>
<p>13 0.19120117 <a title="33-lsi-13" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>14 0.18977423 <a title="33-lsi-14" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>15 0.18280995 <a title="33-lsi-15" href="./jmlr-2009-Nonlinear_Models_Using_Dirichlet_Process_Mixtures.html">62 jmlr-2009-Nonlinear Models Using Dirichlet Process Mixtures</a></p>
<p>16 0.18108456 <a title="33-lsi-16" href="./jmlr-2009-Scalable_Collaborative_Filtering_Approaches_for_Large_Recommender_Systems%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">84 jmlr-2009-Scalable Collaborative Filtering Approaches for Large Recommender Systems    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>17 0.18006779 <a title="33-lsi-17" href="./jmlr-2009-Distance_Metric_Learning_for_Large_Margin_Nearest_Neighbor_Classification.html">24 jmlr-2009-Distance Metric Learning for Large Margin Nearest Neighbor Classification</a></p>
<p>18 0.17857118 <a title="33-lsi-18" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>19 0.16829798 <a title="33-lsi-19" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>20 0.16763692 <a title="33-lsi-20" href="./jmlr-2009-Bounded_Kernel-Based_Online_Learning.html">13 jmlr-2009-Bounded Kernel-Based Online Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.032), (2, 0.013), (20, 0.014), (31, 0.016), (40, 0.588), (42, 0.054), (43, 0.054), (62, 0.011), (85, 0.048), (87, 0.014), (97, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83262545 <a title="33-lda-1" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>2 0.8141188 <a title="33-lda-2" href="./jmlr-2009-Nonlinear_Models_Using_Dirichlet_Process_Mixtures.html">62 jmlr-2009-Nonlinear Models Using Dirichlet Process Mixtures</a></p>
<p>3 0.36269251 <a title="33-lda-3" href="./jmlr-2009-Evolutionary_Model_Type_Selection_for_Global_Surrogate_Modeling.html">31 jmlr-2009-Evolutionary Model Type Selection for Global Surrogate Modeling</a></p>
<p>4 0.34630555 <a title="33-lda-4" href="./jmlr-2009-NEUROSVM%3A_An_Architecture_to_Reduce_the_Effect_of_the_Choice_of_Kernel_on_the_Performance_of_SVM.html">58 jmlr-2009-NEUROSVM: An Architecture to Reduce the Effect of the Choice of Kernel on the Performance of SVM</a></p>
<p>5 0.3153348 <a title="33-lda-5" href="./jmlr-2009-Particle_Swarm_Model_Selection%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">70 jmlr-2009-Particle Swarm Model Selection    (Special Topic on Model Selection)</a></p>
<p>6 0.31215951 <a title="33-lda-6" href="./jmlr-2009-Incorporating_Functional_Knowledge_in_Neural_Networks.html">42 jmlr-2009-Incorporating Functional Knowledge in Neural Networks</a></p>
<p>7 0.30956036 <a title="33-lda-7" href="./jmlr-2009-Nieme%3A_Large-Scale_Energy-Based_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">60 jmlr-2009-Nieme: Large-Scale Energy-Based Models    (Machine Learning Open Source Software Paper)</a></p>
<p>8 0.30520946 <a title="33-lda-8" href="./jmlr-2009-Computing_Maximum_Likelihood_Estimates_in_Recursive_Linear_Models_with_Correlated_Errors.html">17 jmlr-2009-Computing Maximum Likelihood Estimates in Recursive Linear Models with Correlated Errors</a></p>
<p>9 0.2941829 <a title="33-lda-9" href="./jmlr-2009-Bayesian_Network_Structure_Learning_by_Recursive_Autonomy_Identification.html">11 jmlr-2009-Bayesian Network Structure Learning by Recursive Autonomy Identification</a></p>
<p>10 0.29312837 <a title="33-lda-10" href="./jmlr-2009-Distributed_Algorithms_for_Topic_Models.html">25 jmlr-2009-Distributed Algorithms for Topic Models</a></p>
<p>11 0.28566679 <a title="33-lda-11" href="./jmlr-2009-Subgroup_Analysis_via_Recursive_Partitioning.html">91 jmlr-2009-Subgroup Analysis via Recursive Partitioning</a></p>
<p>12 0.28457105 <a title="33-lda-12" href="./jmlr-2009-Discriminative_Learning_Under_Covariate_Shift.html">23 jmlr-2009-Discriminative Learning Under Covariate Shift</a></p>
<p>13 0.2828159 <a title="33-lda-13" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>14 0.27974185 <a title="33-lda-14" href="./jmlr-2009-An_Anticorrelation_Kernel_for_Subsystem_Training_in_Multiple_Classifier_Systems.html">8 jmlr-2009-An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems</a></p>
<p>15 0.27801618 <a title="33-lda-15" href="./jmlr-2009-A_Parameter-Free_Classification_Method_for_Large_Scale_Learning.html">3 jmlr-2009-A Parameter-Free Classification Method for Large Scale Learning</a></p>
<p>16 0.27266708 <a title="33-lda-16" href="./jmlr-2009-Ultrahigh_Dimensional_Feature_Selection%3A_Beyond_The_Linear_Model.html">97 jmlr-2009-Ultrahigh Dimensional Feature Selection: Beyond The Linear Model</a></p>
<p>17 0.27018532 <a title="33-lda-17" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>18 0.26981831 <a title="33-lda-18" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>19 0.26965296 <a title="33-lda-19" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>20 0.26957792 <a title="33-lda-20" href="./jmlr-2009-CarpeDiem%3A_Optimizing_the_Viterbi_Algorithm_and_Applications_to_Supervised_Sequential_Learning.html">14 jmlr-2009-CarpeDiem: Optimizing the Viterbi Algorithm and Applications to Supervised Sequential Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
