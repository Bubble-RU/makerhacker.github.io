<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>76 jmlr-2009-Python Environment for Bayesian Learning: Inferring the Structure of Bayesian Networks from Knowledge and Data    (Machine Learning Open Source Software Paper)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-76" href="#">jmlr2009-76</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>76 jmlr-2009-Python Environment for Bayesian Learning: Inferring the Structure of Bayesian Networks from Knowledge and Data    (Machine Learning Open Source Software Paper)</h1>
<br/><p>Source: <a title="jmlr-2009-76-pdf" href="http://jmlr.org/papers/volume10/shah09a/shah09a.pdf">pdf</a></p><p>Author: Abhik Shah, Peter Woolf</p><p>Abstract: In this paper, we introduce PEBL, a Python library and application for learning Bayesian network structure from data and prior knowledge that provides features unmatched by alternative software packages: the ability to use interventional data, ﬂexible speciﬁcation of structural priors, modeling with hidden variables and exploitation of parallel processing. PEBL is released under the MIT open-source license, can be installed from the Python Package Index and is available at http://pebl-project.googlecode.com. Keywords: Bayesian networks, python, open source software</p><p>Reference: <a title="jmlr-2009-76-reference" href="../jmlr2009_reference/jmlr-2009-Python_Environment_for_Bayesian_Learning%3A_Inferring_the_Structure_of_Bayesian_Networks_from_Knowledge_and_Data%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pebl', 0.857), ('python', 0.31), ('ye', 0.139), ('script', 0.125), ('bns', 0.112), ('libr', 0.071), ('platform', 0.068), ('licens', 0.068), ('bayes', 0.067), ('softw', 0.062), ('abhik', 0.059), ('asch', 0.059), ('greedylearn', 0.059), ('hah', 0.059), ('oolf', 0.059), ('sach', 0.059), ('unmatch', 0.059), ('xgridcontroller', 0.059), ('imoto', 0.05), ('shel', 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="76-tfidf-1" href="./jmlr-2009-Python_Environment_for_Bayesian_Learning%3A_Inferring_the_Structure_of_Bayesian_Networks_from_Knowledge_and_Data%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">76 jmlr-2009-Python Environment for Bayesian Learning: Inferring the Structure of Bayesian Networks from Knowledge and Data    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Abhik Shah, Peter Woolf</p><p>Abstract: In this paper, we introduce PEBL, a Python library and application for learning Bayesian network structure from data and prior knowledge that provides features unmatched by alternative software packages: the ability to use interventional data, ﬂexible speciﬁcation of structural priors, modeling with hidden variables and exploitation of parallel processing. PEBL is released under the MIT open-source license, can be installed from the Python Package Index and is available at http://pebl-project.googlecode.com. Keywords: Bayesian networks, python, open source software</p><p>2 0.1015798 <a title="76-tfidf-2" href="./jmlr-2009-Dlib-ml%3A_A_Machine_Learning_Toolkit%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">26 jmlr-2009-Dlib-ml: A Machine Learning Toolkit    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Davis E. King</p><p>Abstract: There are many excellent toolkits which provide support for developing machine learning software in Python, R, Matlab, and similar environments. Dlib-ml is an open source library, targeted at both engineers and research scientists, which aims to provide a similarly rich environment for developing machine learning software in the C++ language. Towards this end, dlib-ml contains an extensible linear algebra toolkit with built in BLAS support. It also houses implementations of algorithms for performing inference in Bayesian networks and kernel-based methods for classiﬁcation, regression, clustering, anomaly detection, and feature ranking. To enable easy use of these tools, the entire library has been developed with contract programming, which provides complete and precise documentation as well as powerful debugging tools. Keywords: kernel-methods, svm, rvm, kernel clustering, C++, Bayesian networks</p><p>3 0.056152504 <a title="76-tfidf-3" href="./jmlr-2009-Java-ML%3A_A_Machine_Learning_Library%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">43 jmlr-2009-Java-ML: A Machine Learning Library    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Thomas Abeel, Yves Van de Peer, Yvan Saeys</p><p>Abstract: Java-ML is a collection of machine learning and data mining algorithms, which aims to be a readily usable and easily extensible API for both software developers and research scientists. The interfaces for each type of algorithm are kept simple and algorithms strictly follow their respective interface. Comparing different classiﬁers or clustering algorithms is therefore straightforward, and implementing new algorithms is also easy. The implementations of the algorithms are clearly written, properly documented and can thus be used as a reference. The library is written in Java and is available from http://java-ml.sourceforge.net/ under the GNU GPL license. Keywords: open source, machine learning, data mining, java library, clustering, feature selection, classiﬁcation</p><p>4 0.053454973 <a title="76-tfidf-4" href="./jmlr-2009-RL-Glue%3A_Language-Independent_Software_for_Reinforcement-Learning_Experiments%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">77 jmlr-2009-RL-Glue: Language-Independent Software for Reinforcement-Learning Experiments    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Brian Tanner, Adam White</p><p>Abstract: RL-Glue is a standard, language-independent software package for reinforcement-learning experiments. The standardization provided by RL-Glue facilitates code sharing and collaboration. Code sharing reduces the need to re-engineer tasks and experimental apparatus, both common barriers to comparatively evaluating new ideas in the context of the literature. Our software features a minimalist interface and works with several languages and computing platforms. RL-Glue compatibility can be extended to any programming language that supports network socket communication. RL-Glue has been used to teach classes, to run international competitions, and is currently used by several other open-source software and hardware projects. Keywords: reinforcement learning, empirical evaluation, standardization, open source 1. Introduction and Motivation Reinforcement learning is an embodied, trial-and-error problem formulation for artiﬁcial intelligence (Sutton and Barto, 1998; Kaelbling et al., 1996; Bertsekas and Tsitsiklis, 1996). At a series of time steps, the agent emits actions in response to observations and rewards generated by the environment. The agent’s objective is to select actions that maximize the future rewards. Reinforcementlearning methods have been successfully applied to many problems including backgammon (Tesauro, 1994), elevator control (Crites and Barto, 1998), and helicopter control (Ng et al., 2004). Reinforcementlearning models and formalisms have inﬂuenced a number of ﬁelds, including operations research, cognitive science, optimal control, psychology, neuroscience, and others. Reinforcement-learning practitioners create their agents and environments using various incompatible software frameworks, making collaboration inconvenient and thus slowing progress in our community. It can be time consuming, difﬁcult, and sometimes even impossible to exactly reproduce the work of others. A conference or journal article is not the appropriate medium to share a sufﬁciently detailed speciﬁcation of the environment, agent and overall experimental apparatus. We need a convenient way to share source code. We believe that a standard programming interface for reinforcement-learning experiments will remove some barriers to collaboration and accelerate the pace of research in our ﬁeld. To encourage widespread adoption, this interface should be easy to adhere to, and it should not force users to abandon their favorite tools or languages. With these goals in mind, we have developed RL-Glue: language independent software for reinforcement-learning experiments. c 2009 Brian Tanner and Adam White. TANNER AND W HITE 2. RL-Glue Reinforcement-learning environments cannot be stored as ﬁxed data-sets, as is common in conventional supervised machine learning. The environment generates observations and rewards in response to actions selected by the agent, making it more natural to think of the environment and agent as interactive programs. Sutton and Barto describe one prevalent view of agent-environment interactions in their introductory text (1998). Their view, shown in Figure 1, clearly separates the agent and environment into different components which interact in a particular way, following a particular sequence. observation ot reward rt Agent action at rt+1 Environment ot+1 Figure 1: Sutton and Barto’s agent-environment interface, with states generalized to observations. White’s RL-Glue Protocol (2006) formalizes Sutton and Barto’s interface for online, singleagent reinforcement learning. The RL-Glue Protocol describes how the different aspects of a reinforcement-learning experiment should be arranged into programs, and the etiquette they should follow when communicating with each other. These programs (Figure 2) are the agent, the environment, the experiment, and RL-Glue. The agent program implements the learning algorithm and action-selection mechanism. The environment program implements the dynamics of the task and generates the observations and rewards. The experiment program directs the experiment’s execution, including the sequence of agent-environment interactions and agent performance evaluation. The RL-Glue program mediates the communication between the agent and environment programs in response to commands from the experiment program. Our RL-Glue software (RL-Glue) implements White’s protocol.1 Experiment Program Agent Program RL-Glue Program Environment Program Figure 2: The four programs speciﬁed by the RL-Glue Protocol. Arrows indicate the direction of the ﬂow of control. RL-Glue can be used either in internal or external mode. In internal mode, the agent, environment and experiment are linked into a single program, and their communication is through function calls. Internal mode is currently an option if the agent, environment, and experiment are written exclusively in Java or C/C++. In external mode, the agent, environment and experiment are linked 1. This can be found at http://glue.rl-community.org/protocol. 2134 RL-G LUE into separate programs. Each program connects to the RL-Glue server program, and all communication is over TCP/IP socket connections. External mode allows these programs to be written in any programming language that supports socket communication. External mode is currently supported for C/C++, Java, Python, Lisp, and Matlab. Each mode has its strengths and weaknesses. Internal mode has less overhead, so it can execute more steps per second. External mode is more ﬂexible and portable. The performance difference between the two modes vanishes as the agent or environment becomes complex enough that computation dominates the socket overhead in terms of time per step. The agent and environment are indifferent and unaware of their execution mode; the difference in modes lies only in how the agent and environment are linked or loaded. 3. RL-Glue in Practice RL-Glue’s provides a common interface for a number of software and hardware projects in the reinforcement-learning community. For example, there is the annual RL-Competition, where teams from around the world compare their agents on a variety of challenging environments. The competition software uses the API, called RL-Viz, that is layered on top of RL-Glue to dynamically load agent and environment programs, modify parameters at runtime and visualize interaction and performance. All of the environments and sample agents created by the competition organizers are added to the RL-Library, a public, community-supported repository of RL-Glue compatible code. The RL-Library is also available as an archive of top competition agents, challenge problems, project code from academic publications, or any other RL-Glue compatible software that members of our community would like to share. The socket architecture of RL-Glue allows diverse software and hardware platforms to be connected as RL-Glue environment programs. There are ongoing projects that connect a mobile robot platform, a keepaway soccer server, a real-time strategy game, and an Atari emulator to RL-Glue. Our socket architecture helps lower the barriers for researchers wishing to work on larger scale environments by providing a simple and familiar interface. RL-Glue has been used for teaching reinforcement learning in several university courses and to create experiments for scientiﬁc articles published in leading conferences. See our RL-Glue in practice web page for an updated list of projects and papers that have used RL-Glue.2 4. Other Reinforcement-Learning Software Projects RL-Glue is not the ﬁrst software project that aims to standardize empirical reinforcement learning or to make agent and environment programs more accessible within our community. However, RLGlue is the only project that offers a standardized language-independent interface, rich actions and observations, and ﬁne-grained control of the experiment. Other projects, most notably: CLSquare,3 PIQLE,4 RL Toolbox,5 JRLF,6 and LibPG,7 offer signiﬁcant value to the reinforcement-learning community by offering agents and environments, 2. 3. 4. 5. 6. 7. This can be found at http://glue.rl-community.org/rl-glue-in-practice. This can be found at http://www.ni.uos.de/index.php?id=70. This can be found at http://piqle.sourceforge.net/. This can be found at http://www.igi.tugraz.at/ril-toolbox/. This can be found at http://mykel.kochenderfer.com/jrlf/. This can be found at http://code.google.com/p/libpgrl/. 2135 TANNER AND W HITE intuitive visualizations, programming tools, etc. Users should not be forced to choose between RL-Glue and these alternative projects. Our design makes it relatively easy to interface existing frameworks with RL-Glue. We are currently offering our assistance in bridging other frameworks to RL-Glue, with the hope of improving access to all of these tools for all members of our community. 5. RL-Glue Open Source Project Website: http://glue.rl-community.org License: Apache 2.0 RL-Glue is more than an interface; it connects a family of community projects, with many levels of possible participation. Members of the community are invited to submit agent, environment and experiment programs to the RL-Library. Developers can also extend the reach of RL-Glue compatibility by writing external-mode or internal-mode interfaces for their favorite programming language. The RL-Glue software project also welcomes submissions and improvements for all parts of the software and documentation. Acknowledgments We would like to thank the users, testers, and developers for their contributions to RL-Glue 3.0. Special thanks to G´ bor Bal´ zs, Jos´ Antonio Martin H., Scott Livingston, Marc Bellemare, Istv´ n a a e a Szita, Marc Lanctot, Anna Koop, Dan Lizotte, Richard Sutton, Monica Dinculescu, Jordan Frank, and Andrew Butcher. Of course, we also owe a great debt to all of the talented people responsible for the historic and ongoing development of RL-Glue.8 References Dimitri P. Bertsekas and John N. Tsitsiklis. Neuro-Dynamic Programming (Optimization and Neural Computation Series, 3). Athena Scientiﬁc, May 1996. ISBN 1886529108. Robert H. Crites and Andrew G. Barto. Elevator group control using multiple reinforcement learning agents. Machine Learning, 33(2-3):235–262, 1998. Leslie Pack Kaelbling, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: a survey. Journal of Artiﬁcial Intelligence Research, 4:237–285, 1996. Andrew Y. Ng, Adam Coates, Mark Diel, Varun Ganapathi, Jamie Schulte, Ben Tse, Eric Berger, and Eric Liang. Autonomous inverted helicopter ﬂight via reinforcement learning. In Proceedings of the International Symposium on Experimental Robotics, pages 363–372, 2004. Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. The MIT Press, Cambridge, Massachusetts, 1998. Gerald Tesauro. TD-gammon, a self-teaching backgammon program achieves master-level play. Neural Computation, 6:215–219, 1994. Adam White. A Standard System for Benchmarking in Reinforcement Learning. Master’s thesis, University of Alberta, Alberta, Canada, 2006. 8. This can be found at http://glue.rl-community.org/contributors-history. 2136</p><p>5 0.053442035 <a title="76-tfidf-5" href="./jmlr-2009-Nieme%3A_Large-Scale_Energy-Based_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">60 jmlr-2009-Nieme: Large-Scale Energy-Based Models    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Francis Maes</p><p>Abstract: N IEME,1 In this paper we introduce a machine learning library for large-scale classiﬁcation, regression and ranking. N IEME relies on the framework of energy-based models (LeCun et al., 2006) which uniﬁes several learning algorithms ranging from simple perceptrons to recent models such as the pegasos support vector machine or l1-regularized maximum entropy models. This framework also uniﬁes batch and stochastic learning which are both seen as energy minimization problems. N IEME can hence be used in a wide range of situations, but is particularly interesting for large-scale learning tasks where both the examples and the features are processed incrementally. Being able to deal with new incoming features at any time within the learning process is another original feature of the N IEME toolbox. N IEME is released under the GPL license. It is efﬁciently implemented in C++, it works on Linux, Mac OS X and Windows and provides interfaces for C++, Java and Python. Keywords: large-scale machine learning, classiﬁcation, ranking, regression, energy-based models, machine learning software</p><p>6 0.034338072 <a title="76-tfidf-6" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>7 0.022885738 <a title="76-tfidf-7" href="./jmlr-2009-Supervised_Descriptive_Rule_Discovery%3A_A_Unifying_Survey_of_Contrast_Set%2C_Emerging_Pattern_and_Subgroup_Mining.html">92 jmlr-2009-Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining</a></p>
<p>8 0.020897046 <a title="76-tfidf-8" href="./jmlr-2009-Strong_Limit_Theorems_for_the_Bayesian_Scoring_Criterion_in_Bayesian_Networks.html">89 jmlr-2009-Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks</a></p>
<p>9 0.020749899 <a title="76-tfidf-9" href="./jmlr-2009-Transfer_Learning_for_Reinforcement_Learning_Domains%3A_A_Survey.html">96 jmlr-2009-Transfer Learning for Reinforcement Learning Domains: A Survey</a></p>
<p>10 0.020402459 <a title="76-tfidf-10" href="./jmlr-2009-DL-Learner%3A_Learning_Concepts_in_Description_Logics.html">20 jmlr-2009-DL-Learner: Learning Concepts in Description Logics</a></p>
<p>11 0.017751075 <a title="76-tfidf-11" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>12 0.017482609 <a title="76-tfidf-12" href="./jmlr-2009-Model_Monitor_%28M2%29%3A_Evaluating%2C_Comparing%2C_and_Monitoring_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">56 jmlr-2009-Model Monitor (M2): Evaluating, Comparing, and Monitoring Models    (Machine Learning Open Source Software Paper)</a></p>
<p>13 0.017058821 <a title="76-tfidf-13" href="./jmlr-2009-Bayesian_Network_Structure_Learning_by_Recursive_Autonomy_Identification.html">11 jmlr-2009-Bayesian Network Structure Learning by Recursive Autonomy Identification</a></p>
<p>14 0.016995236 <a title="76-tfidf-14" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>15 0.014742989 <a title="76-tfidf-15" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>16 0.014635252 <a title="76-tfidf-16" href="./jmlr-2009-Entropy_Inference_and_the_James-Stein_Estimator%2C_with_Application_to_Nonlinear_Gene_Association_Networks.html">28 jmlr-2009-Entropy Inference and the James-Stein Estimator, with Application to Nonlinear Gene Association Networks</a></p>
<p>17 0.013599179 <a title="76-tfidf-17" href="./jmlr-2009-Learning_Approximate_Sequential_Patterns_for_Classification.html">45 jmlr-2009-Learning Approximate Sequential Patterns for Classification</a></p>
<p>18 0.013008269 <a title="76-tfidf-18" href="./jmlr-2009-Nonlinear_Models_Using_Dirichlet_Process_Mixtures.html">62 jmlr-2009-Nonlinear Models Using Dirichlet Process Mixtures</a></p>
<p>19 0.012842889 <a title="76-tfidf-19" href="./jmlr-2009-Robust_Process_Discovery_with_Artificial_Negative_Events%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">81 jmlr-2009-Robust Process Discovery with Artificial Negative Events    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>20 0.012609047 <a title="76-tfidf-20" href="./jmlr-2009-Feature_Selection_with_Ensembles%2C_Artificial_Variables%2C_and_Redundancy_Elimination%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">35 jmlr-2009-Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination    (Special Topic on Model Selection)</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.069), (1, 0.086), (2, -0.005), (3, 0.025), (4, -0.049), (5, 0.143), (6, -0.075), (7, -0.047), (8, -0.145), (9, 0.099), (10, -0.039), (11, -0.099), (12, 0.179), (13, -0.021), (14, -0.042), (15, -0.082), (16, 0.005), (17, 0.088), (18, -0.012), (19, -0.032), (20, 0.068), (21, 0.064), (22, -0.157), (23, -0.05), (24, -0.063), (25, 0.074), (26, 0.16), (27, -0.122), (28, 0.041), (29, -0.093), (30, 0.01), (31, -0.094), (32, -0.029), (33, -0.02), (34, -0.239), (35, -0.131), (36, -0.269), (37, -0.217), (38, 0.069), (39, -0.06), (40, -0.022), (41, 0.179), (42, -0.004), (43, -0.172), (44, -0.094), (45, -0.117), (46, -0.053), (47, -0.009), (48, -0.032), (49, -0.108)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95648688 <a title="76-lsi-1" href="./jmlr-2009-Python_Environment_for_Bayesian_Learning%3A_Inferring_the_Structure_of_Bayesian_Networks_from_Knowledge_and_Data%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">76 jmlr-2009-Python Environment for Bayesian Learning: Inferring the Structure of Bayesian Networks from Knowledge and Data    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Abhik Shah, Peter Woolf</p><p>Abstract: In this paper, we introduce PEBL, a Python library and application for learning Bayesian network structure from data and prior knowledge that provides features unmatched by alternative software packages: the ability to use interventional data, ﬂexible speciﬁcation of structural priors, modeling with hidden variables and exploitation of parallel processing. PEBL is released under the MIT open-source license, can be installed from the Python Package Index and is available at http://pebl-project.googlecode.com. Keywords: Bayesian networks, python, open source software</p><p>2 0.48891231 <a title="76-lsi-2" href="./jmlr-2009-Dlib-ml%3A_A_Machine_Learning_Toolkit%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">26 jmlr-2009-Dlib-ml: A Machine Learning Toolkit    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Davis E. King</p><p>Abstract: There are many excellent toolkits which provide support for developing machine learning software in Python, R, Matlab, and similar environments. Dlib-ml is an open source library, targeted at both engineers and research scientists, which aims to provide a similarly rich environment for developing machine learning software in the C++ language. Towards this end, dlib-ml contains an extensible linear algebra toolkit with built in BLAS support. It also houses implementations of algorithms for performing inference in Bayesian networks and kernel-based methods for classiﬁcation, regression, clustering, anomaly detection, and feature ranking. To enable easy use of these tools, the entire library has been developed with contract programming, which provides complete and precise documentation as well as powerful debugging tools. Keywords: kernel-methods, svm, rvm, kernel clustering, C++, Bayesian networks</p><p>3 0.48562363 <a title="76-lsi-3" href="./jmlr-2009-Nieme%3A_Large-Scale_Energy-Based_Models%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">60 jmlr-2009-Nieme: Large-Scale Energy-Based Models    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Francis Maes</p><p>Abstract: N IEME,1 In this paper we introduce a machine learning library for large-scale classiﬁcation, regression and ranking. N IEME relies on the framework of energy-based models (LeCun et al., 2006) which uniﬁes several learning algorithms ranging from simple perceptrons to recent models such as the pegasos support vector machine or l1-regularized maximum entropy models. This framework also uniﬁes batch and stochastic learning which are both seen as energy minimization problems. N IEME can hence be used in a wide range of situations, but is particularly interesting for large-scale learning tasks where both the examples and the features are processed incrementally. Being able to deal with new incoming features at any time within the learning process is another original feature of the N IEME toolbox. N IEME is released under the GPL license. It is efﬁciently implemented in C++, it works on Linux, Mac OS X and Windows and provides interfaces for C++, Java and Python. Keywords: large-scale machine learning, classiﬁcation, ranking, regression, energy-based models, machine learning software</p><p>4 0.21320197 <a title="76-lsi-4" href="./jmlr-2009-Java-ML%3A_A_Machine_Learning_Library%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">43 jmlr-2009-Java-ML: A Machine Learning Library    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Thomas Abeel, Yves Van de Peer, Yvan Saeys</p><p>Abstract: Java-ML is a collection of machine learning and data mining algorithms, which aims to be a readily usable and easily extensible API for both software developers and research scientists. The interfaces for each type of algorithm are kept simple and algorithms strictly follow their respective interface. Comparing different classiﬁers or clustering algorithms is therefore straightforward, and implementing new algorithms is also easy. The implementations of the algorithms are clearly written, properly documented and can thus be used as a reference. The library is written in Java and is available from http://java-ml.sourceforge.net/ under the GNU GPL license. Keywords: open source, machine learning, data mining, java library, clustering, feature selection, classiﬁcation</p><p>5 0.20432556 <a title="76-lsi-5" href="./jmlr-2009-Strong_Limit_Theorems_for_the_Bayesian_Scoring_Criterion_in_Bayesian_Networks.html">89 jmlr-2009-Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks</a></p>
<p>Author: Nikolai Slobodianik, Dmitry Zaporozhets, Neal Madras</p><p>Abstract: In the machine learning community, the Bayesian scoring criterion is widely used for model selection problems. One of the fundamental theoretical properties justifying the usage of the Bayesian scoring criterion is its consistency. In this paper we reﬁne this property for the case of binomial Bayesian network models. As a by-product of our derivations we establish strong consistency and obtain the law of iterated logarithm for the Bayesian scoring criterion. Keywords: Bayesian networks, consistency, scoring criterion, model selection, BIC</p><p>6 0.16874911 <a title="76-lsi-6" href="./jmlr-2009-Distributed_Algorithms_for_Topic_Models.html">25 jmlr-2009-Distributed Algorithms for Topic Models</a></p>
<p>7 0.15452278 <a title="76-lsi-7" href="./jmlr-2009-RL-Glue%3A_Language-Independent_Software_for_Reinforcement-Learning_Experiments%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">77 jmlr-2009-RL-Glue: Language-Independent Software for Reinforcement-Learning Experiments    (Machine Learning Open Source Software Paper)</a></p>
<p>8 0.14253685 <a title="76-lsi-8" href="./jmlr-2009-Particle_Swarm_Model_Selection%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">70 jmlr-2009-Particle Swarm Model Selection    (Special Topic on Model Selection)</a></p>
<p>9 0.12333137 <a title="76-lsi-9" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>10 0.09723267 <a title="76-lsi-10" href="./jmlr-2009-Bayesian_Network_Structure_Learning_by_Recursive_Autonomy_Identification.html">11 jmlr-2009-Bayesian Network Structure Learning by Recursive Autonomy Identification</a></p>
<p>11 0.094600163 <a title="76-lsi-11" href="./jmlr-2009-An_Algorithm_for_Reading_Dependencies_from_the_Minimal_Undirected_Independence_Map_of_a_Graphoid_that_Satisfies_Weak_Transitivity.html">6 jmlr-2009-An Algorithm for Reading Dependencies from the Minimal Undirected Independence Map of a Graphoid that Satisfies Weak Transitivity</a></p>
<p>12 0.0936746 <a title="76-lsi-12" href="./jmlr-2009-Entropy_Inference_and_the_James-Stein_Estimator%2C_with_Application_to_Nonlinear_Gene_Association_Networks.html">28 jmlr-2009-Entropy Inference and the James-Stein Estimator, with Application to Nonlinear Gene Association Networks</a></p>
<p>13 0.09302596 <a title="76-lsi-13" href="./jmlr-2009-Learning_Nondeterministic_Classifiers.html">48 jmlr-2009-Learning Nondeterministic Classifiers</a></p>
<p>14 0.091190942 <a title="76-lsi-14" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>15 0.090979323 <a title="76-lsi-15" href="./jmlr-2009-Supervised_Descriptive_Rule_Discovery%3A_A_Unifying_Survey_of_Contrast_Set%2C_Emerging_Pattern_and_Subgroup_Mining.html">92 jmlr-2009-Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining</a></p>
<p>16 0.08777985 <a title="76-lsi-16" href="./jmlr-2009-Learning_Approximate_Sequential_Patterns_for_Classification.html">45 jmlr-2009-Learning Approximate Sequential Patterns for Classification</a></p>
<p>17 0.084076971 <a title="76-lsi-17" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>18 0.077172302 <a title="76-lsi-18" href="./jmlr-2009-Hash_Kernels_for_Structured_Data.html">38 jmlr-2009-Hash Kernels for Structured Data</a></p>
<p>19 0.072989628 <a title="76-lsi-19" href="./jmlr-2009-Exploring_Strategies_for_Training_Deep_Neural_Networks.html">33 jmlr-2009-Exploring Strategies for Training Deep Neural Networks</a></p>
<p>20 0.071970209 <a title="76-lsi-20" href="./jmlr-2009-Identification_of_Recurrent_Neural_Networks_by_Bayesian_Interrogation_Techniques.html">40 jmlr-2009-Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.068), (20, 0.023), (40, 0.022), (42, 0.019), (43, 0.618), (62, 0.02), (69, 0.039), (85, 0.02), (97, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99369645 <a title="76-lda-1" href="./jmlr-2009-Deterministic_Error_Analysis_of_Support_Vector_Regression_and_Related_Regularized_Kernel_Methods.html">22 jmlr-2009-Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods</a></p>
<p>Author: Christian Rieger, Barbara Zwicknagl</p><p>Abstract: We introduce a new technique for the analysis of kernel-based regression problems. The basic tools are sampling inequalities which apply to all machine learning problems involving penalty terms induced by kernels related to Sobolev spaces. They lead to explicit deterministic results concerning the worst case behaviour of ε- and ν-SVRs. Using these, we show how to adjust regularization parameters to get best possible approximation orders for regression. The results are illustrated by some numerical examples. Keywords: sampling inequality, radial basis functions, approximation theory, reproducing kernel Hilbert space, Sobolev space</p><p>2 0.98839623 <a title="76-lda-2" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>Author: Shivani Agarwal, Partha Niyogi</p><p>Abstract: The problem of ranking, in which the goal is to learn a real-valued ranking function that induces a ranking or ordering over an instance space, has recently gained much attention in machine learning. We study generalization properties of ranking algorithms using the notion of algorithmic stability; in particular, we derive generalization bounds for ranking algorithms that have good stability properties. We show that kernel-based ranking algorithms that perform regularization in a reproducing kernel Hilbert space have such stability properties, and therefore our bounds can be applied to these algorithms; this is in contrast with generalization bounds based on uniform convergence, which in many cases cannot be applied to these algorithms. Our results generalize earlier results that were derived in the special setting of bipartite ranking (Agarwal and Niyogi, 2005) to a more general setting of the ranking problem that arises frequently in applications. Keywords: ranking, generalization bounds, algorithmic stability</p><p>3 0.98241621 <a title="76-lda-3" href="./jmlr-2009-Adaptive_False_Discovery_Rate_Control_under_Independence_and_Dependence.html">5 jmlr-2009-Adaptive False Discovery Rate Control under Independence and Dependence</a></p>
<p>Author: Gilles Blanchard,  Étienne Roquain</p><p>Abstract: In the context of multiple hypothesis testing, the proportion π0 of true null hypotheses in the pool of hypotheses to test often plays a crucial role, although it is generally unknown a priori. A testing procedure using an implicit or explicit estimate of this quantity in order to improve its efﬁcency is called adaptive. In this paper, we focus on the issue of false discovery rate (FDR) control and we present new adaptive multiple testing procedures with control of the FDR. In a ﬁrst part, assuming independence of the p-values, we present two new procedures and give a uniﬁed review of other existing adaptive procedures that have provably controlled FDR. We report extensive simulation results comparing these procedures and testing their robustness when the independence assumption is violated. The new proposed procedures appear competitive with existing ones. The overall best, though, is reported to be Storey’s estimator, albeit for a speciﬁc parameter setting that does not appear to have been considered before. In a second part, we propose adaptive versions of step-up procedures that have provably controlled FDR under positive dependence and unspeciﬁed dependence of the p-values, respectively. In the latter case, while simulations only show an improvement over non-adaptive procedures in limited situations, these are to our knowledge among the ﬁrst theoretically founded adaptive multiple testing procedures that control the FDR when the p-values are not independent. Keywords: multiple testing, false discovery rate, adaptive procedure, positive regression dependence, p-values</p><p>same-paper 4 0.9777118 <a title="76-lda-4" href="./jmlr-2009-Python_Environment_for_Bayesian_Learning%3A_Inferring_the_Structure_of_Bayesian_Networks_from_Knowledge_and_Data%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">76 jmlr-2009-Python Environment for Bayesian Learning: Inferring the Structure of Bayesian Networks from Knowledge and Data    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Abhik Shah, Peter Woolf</p><p>Abstract: In this paper, we introduce PEBL, a Python library and application for learning Bayesian network structure from data and prior knowledge that provides features unmatched by alternative software packages: the ability to use interventional data, ﬂexible speciﬁcation of structural priors, modeling with hidden variables and exploitation of parallel processing. PEBL is released under the MIT open-source license, can be installed from the Python Package Index and is available at http://pebl-project.googlecode.com. Keywords: Bayesian networks, python, open source software</p><p>5 0.97702765 <a title="76-lda-5" href="./jmlr-2009-Universal_Kernel-Based_Learning_with_Applications_to_Regular_Languages%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">98 jmlr-2009-Universal Kernel-Based Learning with Applications to Regular Languages    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Leonid (Aryeh) Kontorovich, Boaz Nadler</p><p>Abstract: We propose a novel framework for supervised learning of discrete concepts. Since the 1970’s, the standard computational primitive has been to ﬁnd the most consistent hypothesis in a given complexity class. In contrast, in this paper we propose a new basic operation: for each pair of input instances, count how many concepts of bounded complexity contain both of them. Our approach maps instances to a Hilbert space, whose metric is induced by a universal kernel coinciding with our computational primitive, and identiﬁes concepts with half-spaces. We prove that all concepts are linearly separable under this mapping. Hence, given a labeled sample and an oracle for evaluating the universal kernel, we can efﬁciently compute a linear classiﬁer (via SVM, for example) and use margin bounds to control its generalization error. Even though exact evaluation of the universal kernel may be infeasible, in various natural situations it is efﬁciently approximable. Though our approach is general, our main application is to regular languages. Our approach presents a substantial departure from current learning paradigms and in particular yields a novel method for learning this fundamental concept class. Unlike existing techniques, we make no structural assumptions on the corresponding unknown automata, the string distribution or the completeness of the training set. Instead, given a labeled sample our algorithm outputs a classiﬁer with guaranteed distribution-free generalization bounds; to our knowledge, the proposed framework is the only one capable of achieving the latter. Along the way, we touch upon several fundamental questions in complexity, automata, and machine learning. Keywords: grammar induction, regular language, ﬁnite state automaton, maximum margin hyperplane, kernel approximation</p><p>6 0.91826451 <a title="76-lda-6" href="./jmlr-2009-Online_Learning_with_Samples_Drawn_from_Non-identical_Distributions.html">68 jmlr-2009-Online Learning with Samples Drawn from Non-identical Distributions</a></p>
<p>7 0.91637415 <a title="76-lda-7" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>8 0.91369283 <a title="76-lda-8" href="./jmlr-2009-Robustness_and_Regularization_of_Support_Vector_Machines.html">82 jmlr-2009-Robustness and Regularization of Support Vector Machines</a></p>
<p>9 0.9102338 <a title="76-lda-9" href="./jmlr-2009-Classification_with_Gaussians_and_Convex_Loss.html">16 jmlr-2009-Classification with Gaussians and Convex Loss</a></p>
<p>10 0.90494961 <a title="76-lda-10" href="./jmlr-2009-On_The_Power_of_Membership_Queries_in_Agnostic_Learning.html">64 jmlr-2009-On The Power of Membership Queries in Agnostic Learning</a></p>
<p>11 0.89970565 <a title="76-lda-11" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>12 0.89073139 <a title="76-lda-12" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>13 0.88881981 <a title="76-lda-13" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>14 0.87975436 <a title="76-lda-14" href="./jmlr-2009-Refinement_of_Reproducing_Kernels.html">78 jmlr-2009-Refinement of Reproducing Kernels</a></p>
<p>15 0.87783211 <a title="76-lda-15" href="./jmlr-2009-Exploiting_Product_Distributions_to_Identify_Relevant_Variables_of_Correlation_Immune_Functions.html">32 jmlr-2009-Exploiting Product Distributions to Identify Relevant Variables of Correlation Immune Functions</a></p>
<p>16 0.8613264 <a title="76-lda-16" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>17 0.85938317 <a title="76-lda-17" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>18 0.85657871 <a title="76-lda-18" href="./jmlr-2009-Bi-Level_Path_Following_for_Cross_Validated_Solution_of_Kernel_Quantile_Regression.html">12 jmlr-2009-Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression</a></p>
<p>19 0.85271585 <a title="76-lda-19" href="./jmlr-2009-Strong_Limit_Theorems_for_the_Bayesian_Scoring_Criterion_in_Bayesian_Networks.html">89 jmlr-2009-Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks</a></p>
<p>20 0.85235572 <a title="76-lda-20" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
