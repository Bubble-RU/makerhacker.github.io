<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>7 jmlr-2009-An Analysis of Convex Relaxations for MAP Estimation of Discrete MRFs</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2009" href="../home/jmlr2009_home.html">jmlr2009</a> <a title="jmlr-2009-7" href="#">jmlr2009-7</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>7 jmlr-2009-An Analysis of Convex Relaxations for MAP Estimation of Discrete MRFs</h1>
<br/><p>Source: <a title="jmlr-2009-7-pdf" href="http://jmlr.org/papers/volume10/kumar09a/kumar09a.pdf">pdf</a></p><p>Author: M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr</p><p>Abstract: The problem of obtaining the maximum a posteriori estimate of a general discrete Markov random ﬁeld (i.e., a Markov random ﬁeld deﬁned using a discrete set of labels) is known to be NP-hard. However, due to its central importance in many applications, several approximation algorithms have been proposed in the literature. In this paper, we present an analysis of three such algorithms based on convex relaxations: (i) LP - S: the linear programming (LP) relaxation proposed by Schlesinger (1976) for a special case and independently in Chekuri et al. (2001), Koster et al. (1998), and Wainwright et al. (2005) for the general case; (ii) QP - RL: the quadratic programming (QP) relaxation of Ravikumar and Lafferty (2006); and (iii) SOCP - MS: the second order cone programming (SOCP) relaxation ﬁrst proposed by Muramatsu and Suzuki (2003) for two label problems and later extended by Kumar et al. (2006) for a general label set. We show that the SOCP - MS and the QP - RL relaxations are equivalent. Furthermore, we prove that despite the ﬂexibility in the form of the constraints/objective function offered by QP and SOCP, the LP - S relaxation strictly dominates (i.e., provides a better approximation than) QP - RL and SOCP MS . We generalize these results by deﬁning a large class of SOCP (and equivalent QP ) relaxations which is dominated by the LP - S relaxation. Based on these results we propose some novel SOCP relaxations which deﬁne constraints using random variables that form cycles or cliques in the graphical model representation of the random ﬁeld. Using some examples we show that the new SOCP relaxations strictly dominate the previous approaches. Keywords: probabilistic models, MAP estimation, discrete MRF, convex relaxations, linear programming, second-order cone programming, quadratic programming, dominating relaxations ∗. Work done while at the Dept. of Computing, Oxford Brookes University. c 2008 M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr. K UMAR , KOLMOG</p><p>Reference: <a title="jmlr-2009-7-reference" href="../jmlr2009_reference/jmlr-2009-An_Analysis_of_Convex_Relaxations_for_MAP_Estimation_of_Discrete_MRFs_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 (2005) for the general case; (ii) QP - RL: the quadratic programming (QP) relaxation of Ravikumar and Lafferty (2006); and (iii) SOCP - MS: the second order cone programming (SOCP) relaxation ﬁrst proposed by Muramatsu and Suzuki (2003) for two label problems and later extended by Kumar et al. [sent-22, score-0.389]
</p><p>2 Furthermore, we prove that despite the ﬂexibility in the form of the constraints/objective function offered by QP and SOCP, the LP - S relaxation strictly dominates (i. [sent-25, score-0.246]
</p><p>3 (2005); (ii) QP - RL, the quadratic programming (QP) relaxation of Ravikumar and Lafferty (2006); and (iii) SOCP - MS, the second order cone programming (SOCP) relaxation of Kumar et al. [sent-83, score-0.389]
</p><p>4 We say that the variable xa;i belongs to variable va since it deﬁnes whether the variable va takes the label li . [sent-90, score-0.203]
</p><p>5 Clearly the sum of the unary potentials for a labelling speciﬁed by x is given by (1 + xa;i ) ∑ θ1 2 . [sent-93, score-0.204]
</p><p>6 a;i va ,li Similarly the sum of the pairwise potentials for a labelling x is given by  ∑  (a,b)∈E ,li ,l j  θ2 j ab;i  (1 + xa;i + xb; j + Xab;i j ) (1 + xa;i ) (1 + xb; j ) = . [sent-94, score-0.269]
</p><p>7 • Using the rounding scheme of Kleinberg and Tardos (1999), the LP - S provides a multiplicative bound2 of 2 when the pairwise potentials form a Potts model (Chekuri et al. [sent-138, score-0.199]
</p><p>8 Consider a set of optimization problems A and a relaxation scheme deﬁned over this set A . [sent-141, score-0.199]
</p><p>9 In other words, for every optimization problem A ∈ A , the relaxation scheme provides a relaxation B ∈ B of A. [sent-142, score-0.385]
</p><p>10 To this end, it would be convenient to reformulate the objective function of the ˆ1 IP using a vector of unary potentials of length nh (denoted by θ ) and a matrix of pairwise potentials ˆ2 of size nh × nh (denoted by θ ). [sent-156, score-0.545]
</p><p>11 The element of the unary potential vector at index (a · h + i) is deﬁned as ˆ a;i θ1 = θ1 − ∑ ∑ |θ2 |, a;i ac;ik vc ∈v lk ∈l  ˆ2 where va ∈ v and li ∈ l. [sent-157, score-0.238]
</p><p>12 The (a · h + i, b · h + j)th element of the pairwise potential matrix θ is deﬁned such that if a = b, i = j, ∑vc ∈v ∑lk ∈l |θ2 |, ac;ik otherwise, θ2 j ab;i  ˆ ab;i θ2 j =  where va , vb ∈ v and li , l j ∈ l. [sent-158, score-0.222]
</p><p>13 In other words, the potentials are modiﬁed by deﬁning a pairwise ˆ potential θ2 and subtracting the value of that potential from the corresponding unary potential θ 1 . [sent-159, score-0.2]
</p><p>14 |θ2 j |z2 + |θ2 j |z2 j + 2θ2 j za;i zb; j , ab;i a;i ab;i b; ab;i   |θ2 j | za;i + ab;i  θ2 j ab;i |θ2 j | ab;i  2  zb; j    ,  by rounding the optimal solution of its relaxation B. [sent-162, score-0.236]
</p><p>15 The relaxation scheme is said to provide a multiplicative bound of ρ for the set A if, and only if, the following condition is satisﬁed: E(e A ) ≤ ρeA , ∀A ∈ A , where E(·) denotes the ˆ expectation of its argument under the rounding scheme employed. [sent-163, score-0.262]
</p><p>16 It is worth noting ˆ1 ˆ2 that, although θ and θ deﬁne the same energy for a labelling f as the original parameter θ, they are not a valid reparameterization of θ since they contain non-zero pairwise potentials of the form ˆ θ2 . [sent-169, score-0.204]
</p><p>17 Under their rounding scheme, this bound can be shown to be tight 5 using a random ﬁeld deﬁned over two random variables which speciﬁes uniform unary potentials and Ising model pairwise potentials (see Fig. [sent-178, score-0.341]
</p><p>18 4 Semideﬁnite Programming Relaxation The SDP relaxation of the MAP estimation problem replaces the non-convex constraint X = xx by the convex semideﬁnite constraint X − xx 0 (de Klerk et al. [sent-183, score-0.282]
</p><p>19 A relaxation scheme deﬁned over the set of optimization problems A is said to provide an additive bound of σ for A if, and only if, the following holds true: E(eA ) ≤ eA + σ, ∀A ∈ A . [sent-185, score-0.199]
</p><p>20 The multiplicative bound speciﬁed by a relaxation scheme deﬁned over the set of optimization problems A is said to be tight if, and only if, there exists an A ∈ A such that E(eA ) = ρeA . [sent-188, score-0.199]
</p><p>21 Similarly, the additive bound speciﬁed by a ˆ relaxation scheme deﬁned over A is said to be tight if, and only if, there exists an A ∈ A such that E(e A ) = eA + σ. [sent-189, score-0.199]
</p><p>22 2 T HE SOCP-MS R ELAXATION Consider a pair of neighbouring variables va and vb , that is, (a, b) ∈ E , and a pair of labels li and l j . [sent-223, score-0.215]
</p><p>23 For each such pair of variables and labels, the SOCP - MS relaxation speciﬁes two SOC constraints which involve only the above variables (Kumar et al. [sent-225, score-0.221]
</p><p>24 77  K UMAR , KOLMOGOROV AND T ORR  Using the variables va and vb (where (a, b) ∈ E ) and labels li and l j , we deﬁne the submatrices x(a,b,i, j) and X(a,b,i, j) of x and X respectively as: xa;i xb; j  x(a,b,i, j) =  , X(a,b,i, j) =  Xaa;ii Xab;i j Xba; ji Xbb; j j  . [sent-228, score-0.208]
</p><p>25 The SOCP - MS relaxation speciﬁes SOC constraints of the form: (Uk ) x(a,b,i, j) MS  2  ≤ Ck • X(a,b,i, j) , MS  (10)  for all pairs of neighbouring variables (a, b) ∈ E and labels l i , l j ∈ l. [sent-229, score-0.259]
</p><p>26 The SOCP - MS relaxation yields the supremum and inﬁmum for the elements of the matrix X using constraints (11) and (12) respectively, that is, (xa;i + xb; j )2 (xa;i − xb; j )2 − 1 ≤ Xab;i j ≤ 1 − . [sent-239, score-0.221]
</p><p>27 Similar to the LP - S and QP - RL relaxations deﬁned above, the SOCP - MS relaxation can also be solved in polynomial time. [sent-245, score-0.302]
</p><p>28 We say that a relaxation A dominates (Chekuri et al. [sent-250, score-0.232]
</p><p>29 , 2001) the relaxation B (alternatively, B is dominated by A) if and only if min e(x, X; θ) ≥ min e(x, X; θ), ∀θ, (x,X)∈F ( A )  (x,X)∈F ( B )  where F (A) and F (B) are the feasibility regions of the relaxations A and B respectively. [sent-251, score-0.378]
</p><p>30 Thus the optimal value of the dominating relaxation A is always greater than or equal to the optimal value of relaxation B. [sent-255, score-0.372]
</p><p>31 A relaxation A is said to strictly dominate relaxation B if A dominates B but B does not dominate A. [sent-259, score-0.47]
</p><p>32 Note that, by deﬁnition, the optimal value of any relaxation would always be less than or equal to the energy of the optimal (i. [sent-261, score-0.205]
</p><p>33 Hence, the optimal value of a strictly dominating relaxation A is closer to the optimal value of the MAP estimation IP compared to that of relaxation 79  K UMAR , KOLMOGOROV AND T ORR  B . [sent-264, score-0.386]
</p><p>34 In other words, it is possible for a relaxation B which is strictly dominated by a relaxation A to provide a better ﬁnal (integer) solution than A . [sent-267, score-0.402]
</p><p>35 One may also argue that if a dominating relaxation provides worse ﬁnal solutions, then the deﬁciency of the method may be rooted in the rounding technique used. [sent-269, score-0.236]
</p><p>36 Further, let A and B differ in the constraints that they specify such that F (A) ⊆ F (B), that is, the feasibility region of A is a subset of the feasibility region of B. [sent-273, score-0.205]
</p><p>37 In Section 5, we will consider some examples of relaxations which can be related through the concept of domination despite the fact that their feasibility regions are not subsets (or supersets) of each other. [sent-289, score-0.201]
</p><p>38 Theorem 1: The LP - S relaxation strictly dominates the SOCP - MS relaxation. [sent-311, score-0.246]
</p><p>39 2 2 Consider a pair of neighbouring variables va and vb and a pair of labels li and l j . [sent-315, score-0.215]
</p><p>40 Together with inequality (25), this proves that the LP - S relaxation provides smaller supremum and larger inﬁmum of the elements of the matrix X than the SOCP - MS relaxation. [sent-344, score-0.2]
</p><p>41 The resulting LP relaxation would strictly dominate the SOCP - MS relaxation with triangular inequalities. [sent-353, score-0.405]
</p><p>42 Theorem 2: The QP - RL relaxation and the SOCP - MS relaxation are equivalent. [sent-363, score-0.372]
</p><p>43 Proof: Recall that the QP - RL relaxation is deﬁned as follows: QP - RL :  x∗ = arg minx  1+x 2  ˆ1 θ +  1+x 2  ˆ2 θ  1+x 2  ,  ∑li ∈l xa;i = 2 − h, ∀va ∈ v, x ∈ {−1, 1}nh ,  s. [sent-364, score-0.202]
</p><p>44 1  2  ˆ ˆ where the unary potential vector θ and the pairwise potential matrix θ ˆ a;i θ1 = θ 1 − a;i  ∑ ∑ |θ2 |, ac;ik  vc ∈v lk ∈l  83  0 are deﬁned as (28)  K UMAR , KOLMOGOROV AND T ORR  (a)  (b)  (c)  Figure 1: (a) An example MRF deﬁned using two neighbouring random variables. [sent-366, score-0.202]
</p><p>45 For example, θ1 = 10 a;i a;0 (shown next to the lower branch of the trellis on top of va ) and θ1 = 3 (shown next to b;1 the upper branch of the trellis on top of vb ). [sent-374, score-0.222]
</p><p>46 The pairwise potential θ2 j is shown next to ab;i the connection between the ith and jth branches of the trellises on top of va and vb respectively. [sent-375, score-0.229]
</p><p>47 (c) A feasible solution of the SOCP - MS relaxation which does not belong to the feasibility region of LP - S and has an objective function value of 2. [sent-381, score-0.285]
</p><p>48 ab;i  (29)  Here, the terms θ1 and θ2 are the (original) unary potentials and pairwise potentials for the given a;i ac;ik MRF . [sent-387, score-0.291]
</p><p>49 Further, let X be the solution obtained when minimizing the objective function of the SOCP - MS relaxation whilst keeping x ﬁxed. [sent-389, score-0.2]
</p><p>50 We prove that the value of the objective functions for both relaxations at the above feasible solution is the same by equating the coefﬁcient of θ 1 and θ2 j for all va ∈ v, (a, b) ∈ E a;i ab;i  and li , l j ∈ l in both formulations. [sent-390, score-0.249]
</p><p>51 a;i 2 Therefore the coefﬁcients of θ1 in both relaxations are equal for all va ∈ v and li ∈ l. [sent-393, score-0.235]
</p><p>52 (32)  In order to obtain the minimum of the objective function, the SOCP - MS relaxation uses the maximum value that Xab;i j would take given the SOC constraints. [sent-403, score-0.2]
</p><p>53 Theorems 1 and 2 prove that the LP - S relaxation strictly dominates the QP - RL and SOCP - MS relaxations. [sent-406, score-0.246]
</p><p>54 Theorem 3: For the above rounding scheme, LP - S and SOCP - MS provide the same additive bound as the QP - RL relaxation of Ravikumar and Lafferty (2006), that is, S where 4 S = ∑(a,b)∈E ∑li ,l j ∈l |θ2 j | (i. [sent-419, score-0.236]
</p><p>55 The energy of the labelling x, obtained after rounding the solution of the LP - S relaxation, is represented by the term e L , ˆ Using the above notation, we now show that the LP - S relaxation provides an additive bound of S for the above rounding scheme. [sent-432, score-0.354]
</p><p>56 We ﬁrst consider the unary potentials and observe that 4 E θ1 a;i  1 + xa;i ˆ 2  = θ1 a;i  ∗ 1 + xa;i 2  ,  where E(·) denotes the expectation of its argument under the above rounding scheme. [sent-433, score-0.205]
</p><p>57 A N A NALYSIS OF C ONVEX R ELAXATIONS FOR MAP E STIMATION OF D ISCRETE MRF S  Summing the expectation of the unary and pairwise potentials for all v a ∈ v, (a, b) ∈ E and li , l j ∈ l, we get S S e∗ ≤ E(eL ) ≤ eL + ≤ e∗ + , ˆ 4 4 which proves the additive bound for LP - S. [sent-441, score-0.235]
</p><p>58 Note that the unary potentials are uniform while the pairwise potentials form an Ising model. [sent-446, score-0.291]
</p><p>59 Let the unary and pairwise potentials be as deﬁned in Fig. [sent-454, score-0.2]
</p><p>60 2(a), that is, the unary potentials are uniform and the pairwise potentials follow the Ising model. [sent-455, score-0.291]
</p><p>61 , the optimal value of the objective function of the LP - S relaxation is exactly equal to the energy of the MAP estimate). [sent-459, score-0.219]
</p><p>62 , MRF deﬁned over a large number of variables) with uniform unary potentials and Ising model pairwise potentials for which the bound can be shown to be tight. [sent-470, score-0.291]
</p><p>63 We note here that better bounds can be obtained for some special cases of 87  K UMAR , KOLMOGOROV AND T ORR  the MAP estimation problem using the LP - S relaxation together with more clever rounding schemes (such as those described in Chekuri et al. [sent-477, score-0.236]
</p><p>64 Speciﬁcally, we consider the SOCP relaxations which relax the non-convex constraint X = xx using a set of second order cone (SOC) constraints of the form ||(Uk ) x|| ≤ Ck • X, k = 1, · · · , nC  (34)  where Ck = Uk (Uk ) 0, for all k = 1, · · · , nC . [sent-481, score-0.216]
</p><p>65 Let A be a relaxation which contains constraints (36). [sent-488, score-0.221]
</p><p>66 Using A it is possible to obtain another relaxation B by substituting constraints (36) by some other relaxation of the integer constraints. [sent-489, score-0.407]
</p><p>67 (37)  In the case where a given relaxation A does not contain the SOCP - MS constraints, we can deﬁne a new relaxation B. [sent-495, score-0.372]
</p><p>68 This new relaxation B is obtained by adding all the SOCP - MS constraints to A. [sent-496, score-0.221]
</p><p>69 Hence, if B is dominated by the LP - S relaxation then it follows that LP - S would also dominate A . [sent-498, score-0.221]
</p><p>70 Note that each SOCP relaxation belonging to this class would not include the marginalization constraints. [sent-500, score-0.205]
</p><p>71 Hence, it would deﬁne an equivalent QP relaxation (similar to the equivalent QP - RL relaxation deﬁned by the SOCP - MS relaxation). [sent-501, score-0.372]
</p><p>72 Recall that w(a, b) speciﬁes the strength of the pairwise relationship between two neighbouring variables va and vb . [sent-549, score-0.225]
</p><p>73 Note that for a given relaxation SOCP - T , there may be several SOC constraints deﬁned using this tree G (or its subtrees). [sent-567, score-0.221]
</p><p>74 This would prove inequality (40) which in turn 2 2 would show that the LP - S relaxation dominates SOCP - T (and the equivalent QP relaxation which we call QP - T) whose constraints are deﬁned over trees. [sent-610, score-0.467]
</p><p>75 In other words these variables Xab;i j are bounded only by the relaxation of the integer constraint, that is, −1 ≤ Xab;i j ≤ +1. [sent-614, score-0.2]
</p><p>76 Theorem 5: When d(i, j) ≥ 0 for all li , l j ∈ l, the SOCP relaxations which deﬁne constraints only using non-overlapping graphs G which form (arbitrarily large) even cycles with all positive or all negative weights are dominated by the LP - S relaxation. [sent-688, score-0.22]
</p><p>77 It is worth noting that the feasibility region of the above SOCP relaxation (with SOC constraints deﬁned using some special form of cycles) is not a subset of the LP - S relaxation. [sent-709, score-0.306]
</p><p>78 Speciﬁcally, if the feasibility region of relaxation A is a subset of the feasibility region of relaxation B, then B dominates A. [sent-712, score-0.588]
</p><p>79 1 The SOCP-C Relaxation The SOCP - C relaxation (where C denotes cycles) deﬁnes second order cone (SOC) constraints using positive semideﬁnite matrices C such that the graph G (deﬁned in § 5. [sent-723, score-0.238]
</p><p>80 The SOCP - C relaxation speciﬁes the following constraints: • The marginalization constraints, that is,  ∑ Xab;i j = (2 − h)xa;i , ∀(a, b) ∈ E , li ∈ l. [sent-727, score-0.24]
</p><p>81 Since marginalization constraints are included in the SOCP - C relaxation, the value of the objective function obtained by solving this relaxation would at least be equal to the value obtained by the LP - S relaxation (i. [sent-739, score-0.44]
</p><p>82 We deﬁne a frustrated cycle which consists of all 3 variables of this MRF using the unary and pairwise potentials shown in Fig. [sent-760, score-0.257]
</p><p>83 5, that is, the unary potentials are uniform and the pairwise potentials deﬁne only one non-submodular term (between the vertices b and c). [sent-761, score-0.291]
</p><p>84 The value of the objective function obtained by solving the LP - S relaxation is 3 at an optimal solution shown in Fig. [sent-763, score-0.2]
</p><p>85 In fact, the value of the objective function obtained using the SOCP - C relaxation is 3. [sent-783, score-0.2]
</p><p>86 This proves that SOCP - C strictly dominates the LP - S relaxation (and hence, the QP - RL and SOCP - MS relaxations). [sent-789, score-0.246]
</p><p>87 K UMAR , KOLMOGOROV AND T ORR  We believe that the feasibility region deﬁned by cycle inequalities is a strict subset of the feasibility region deﬁned by Equation (49). [sent-791, score-0.215]
</p><p>88 In other words a relaxation deﬁned by adding cycle inequalities to LP - S would strictly dominate SOCP - C . [sent-792, score-0.278]
</p><p>89 To this end, we deﬁne an SOCP relaxation which speciﬁes constraints such that the resulting graph G form a clique. [sent-800, score-0.221]
</p><p>90 The SOCP - Q relaxation contains the marginalization constraint and the cycle inequalities (deﬁned above). [sent-802, score-0.28]
</p><p>91 This implies that C 0, which enables us to obtain the following SOC constraint: 2  ∑ xa ;i  ≤ q + ∑ Xak al ;ik il . [sent-808, score-0.42]
</p><p>92 a a (ak ,al )∈E  (ak ,al )∈E  Again, this choice is motivated by the fact that the variables Xak al ;ik il corresponding to these sets vQ and lQ are assigned trivial values by the LP - S relaxation in the presence of non-submodular pairwise potentials. [sent-810, score-0.248]
</p><p>93 When the clique contains a frustrated cycle, it can be shown that SOCP - Q dominates the LP - S relaxation (similar to SOCP - C). [sent-811, score-0.257]
</p><p>94 Further, using a counter-example, it can proved that the feasibility region given by cycle inequalities is not a subset of the feasibility region deﬁned by constraint (51). [sent-812, score-0.245]
</p><p>95 Example: We present an example to prove that the feasibility region given by cycle inequalities is not a subset of the feasibility region deﬁned by the SOC constraint 2  ∑ xa ;i  k k  k  ≤ q + ∑ Xak al ;ik il ,  (52)  k,l  which is used in SOCP - Q. [sent-814, score-0.665]
</p><p>96 8 does not belong to the feasibility region of the SOCP Q relaxation since it does not satisfy the following SOC constraint: 2  ∑ xa;0  va ∈v  ≤ 4+2  ∑  Xab;00 . [sent-827, score-0.355]
</p><p>97 The surprising result of our work is that despite the ﬂexibility in the form of the objective function/constraints offered by QP and SOCP, the LP - S relaxation dominates a large class of QP and SOCP relaxations. [sent-830, score-0.246]
</p><p>98 It appears that the authors who have previously used SOCP relaxations in the combinatorial optimization literature (Muramatsu and Suzuki, 2003) and those who have reported QP relaxation in the machine learning literature (Ravikumar and Lafferty, 2006) were unaware of this result. [sent-831, score-0.302]
</p><p>99 Second-order cone programming relaxation of nonconvex quadratic optimization problems. [sent-911, score-0.203]
</p><p>100 A new second-order cone programming relaxation for max-cut problems. [sent-967, score-0.203]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('socp', 0.472), ('xb', 0.403), ('xa', 0.403), ('xab', 0.376), ('lp', 0.2), ('relaxation', 0.186), ('mrf', 0.171), ('ms', 0.147), ('ab', 0.125), ('soc', 0.121), ('relaxations', 0.116), ('cab', 0.102), ('qp', 0.097), ('potentials', 0.091), ('va', 0.084), ('nh', 0.08), ('kolmogorov', 0.076), ('caa', 0.07), ('unary', 0.064), ('xt', 0.062), ('feasibility', 0.06), ('vb', 0.058), ('elaxations', 0.057), ('rl', 0.055), ('iscrete', 0.054), ('onvex', 0.054), ('rounding', 0.05), ('orr', 0.049), ('umar', 0.049), ('labelling', 0.049), ('xaa', 0.048), ('dominates', 0.046), ('pairwise', 0.045), ('chekuri', 0.041), ('map', 0.039), ('neighbouring', 0.038), ('lk', 0.036), ('ravikumar', 0.036), ('constraints', 0.035), ('schlesinger', 0.035), ('xba', 0.035), ('li', 0.035), ('stimation', 0.033), ('cycle', 0.032), ('ji', 0.031), ('ik', 0.031), ('nalysis', 0.03), ('constraint', 0.03), ('el', 0.029), ('kumar', 0.029), ('trellises', 0.029), ('ii', 0.029), ('wainwright', 0.026), ('domination', 0.025), ('frustrated', 0.025), ('muramatsu', 0.025), ('region', 0.025), ('ck', 0.025), ('zb', 0.024), ('trellis', 0.022), ('xbb', 0.022), ('za', 0.022), ('lafferty', 0.021), ('semide', 0.02), ('ip', 0.019), ('mum', 0.019), ('vc', 0.019), ('energy', 0.019), ('dominate', 0.019), ('marginalization', 0.019), ('xx', 0.018), ('cycles', 0.018), ('branch', 0.018), ('suzuki', 0.017), ('kleinberg', 0.017), ('al', 0.017), ('cone', 0.017), ('tardos', 0.016), ('dominated', 0.016), ('boykov', 0.016), ('minx', 0.016), ('xak', 0.016), ('ea', 0.016), ('dc', 0.015), ('neighbourhood', 0.015), ('sdp', 0.015), ('inequality', 0.014), ('nc', 0.014), ('objective', 0.014), ('strictly', 0.014), ('uk', 0.014), ('rhs', 0.014), ('fractional', 0.014), ('ising', 0.014), ('torr', 0.014), ('words', 0.014), ('branches', 0.013), ('inequalities', 0.013), ('scheme', 0.013), ('hammer', 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="7-tfidf-1" href="./jmlr-2009-An_Analysis_of_Convex_Relaxations_for_MAP_Estimation_of_Discrete_MRFs.html">7 jmlr-2009-An Analysis of Convex Relaxations for MAP Estimation of Discrete MRFs</a></p>
<p>Author: M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr</p><p>Abstract: The problem of obtaining the maximum a posteriori estimate of a general discrete Markov random ﬁeld (i.e., a Markov random ﬁeld deﬁned using a discrete set of labels) is known to be NP-hard. However, due to its central importance in many applications, several approximation algorithms have been proposed in the literature. In this paper, we present an analysis of three such algorithms based on convex relaxations: (i) LP - S: the linear programming (LP) relaxation proposed by Schlesinger (1976) for a special case and independently in Chekuri et al. (2001), Koster et al. (1998), and Wainwright et al. (2005) for the general case; (ii) QP - RL: the quadratic programming (QP) relaxation of Ravikumar and Lafferty (2006); and (iii) SOCP - MS: the second order cone programming (SOCP) relaxation ﬁrst proposed by Muramatsu and Suzuki (2003) for two label problems and later extended by Kumar et al. (2006) for a general label set. We show that the SOCP - MS and the QP - RL relaxations are equivalent. Furthermore, we prove that despite the ﬂexibility in the form of the constraints/objective function offered by QP and SOCP, the LP - S relaxation strictly dominates (i.e., provides a better approximation than) QP - RL and SOCP MS . We generalize these results by deﬁning a large class of SOCP (and equivalent QP ) relaxations which is dominated by the LP - S relaxation. Based on these results we propose some novel SOCP relaxations which deﬁne constraints using random variables that form cycles or cliques in the graphical model representation of the random ﬁeld. Using some examples we show that the new SOCP relaxations strictly dominate the previous approaches. Keywords: probabilistic models, MAP estimation, discrete MRF, convex relaxations, linear programming, second-order cone programming, quadratic programming, dominating relaxations ∗. Work done while at the Dept. of Computing, Oxford Brookes University. c 2008 M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr. K UMAR , KOLMOG</p><p>2 0.066192567 <a title="7-tfidf-2" href="./jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Junning Li, Z. Jane Wang</p><p>Abstract: In real world applications, graphical statistical models are not only a tool for operations such as classiﬁcation or prediction, but usually the network structures of the models themselves are also of great interest (e.g., in modeling brain connectivity). The false discovery rate (FDR), the expected ratio of falsely claimed connections to all those claimed, is often a reasonable error-rate criterion in these applications. However, current learning algorithms for graphical models have not been adequately adapted to the concerns of the FDR. The traditional practice of controlling the type I error rate and the type II error rate under a conventional level does not necessarily keep the FDR low, especially in the case of sparse networks. In this paper, we propose embedding an FDR-control procedure into the PC algorithm to curb the FDR of the skeleton of the learned graph. We prove that the proposed method can control the FDR under a user-speciﬁed level at the limit of large sample sizes. In the cases of moderate sample size (about several hundred), empirical experiments show that the method is still able to control the FDR under the user-speciﬁed level, and a heuristic modiﬁcation of the method is able to control the FDR more accurately around the user-speciﬁed level. The proposed method is applicable to any models for which statistical tests of conditional independence are available, such as discrete models and Gaussian models. Keywords: Bayesian networks, false discovery rate, PC algorithm, directed acyclic graph, skeleton</p><p>3 0.056781311 <a title="7-tfidf-3" href="./jmlr-2009-Cautious_Collective_Classification.html">15 jmlr-2009-Cautious Collective Classification</a></p>
<p>Author: Luke K. McDowell, Kalyan Moy Gupta, David W. Aha</p><p>Abstract: Many collective classiﬁcation (CC) algorithms have been shown to increase accuracy when instances are interrelated. However, CC algorithms must be carefully applied because their use of estimated labels can in some cases decrease accuracy. In this article, we show that managing this label uncertainty through cautious algorithmic behavior is essential to achieving maximal, robust performance. First, we describe cautious inference and explain how four well-known families of CC algorithms can be parameterized to use varying degrees of such caution. Second, we introduce cautious learning and show how it can be used to improve the performance of almost any CC algorithm, with or without cautious inference. We then evaluate cautious inference and learning for the four collective inference families, with three local classiﬁers and a range of both synthetic and real-world data. We ﬁnd that cautious learning and cautious inference typically outperform less cautious approaches. In addition, we identify the data characteristics that predict more substantial performance differences. Our results reveal that the degree of caution used usually has a larger impact on performance than the choice of the underlying inference algorithm. Together, these results identify the most appropriate CC algorithms to use for particular task characteristics and explain multiple conﬂicting ﬁndings from prior CC research. Keywords: collective inference, statistical relational learning, approximate probabilistic inference, networked data, cautious inference</p><p>4 0.033270076 <a title="7-tfidf-4" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>Author: Brijnesh J. Jain, Klaus Obermayer</p><p>Abstract: Finite structures such as point patterns, strings, trees, and graphs occur as ”natural” representations of structured data in different application areas of machine learning. We develop the theory of structure spaces and derive geometrical and analytical concepts such as the angle between structures and the derivative of functions on structures. In particular, we show that the gradient of a differentiable structural function is a well-deﬁned structure pointing in the direction of steepest ascent. Exploiting the properties of structure spaces, it will turn out that a number of problems in structural pattern recognition such as central clustering or learning in structured output spaces can be formulated as optimization problems with cost functions that are locally Lipschitz. Hence, methods from nonsmooth analysis are applicable to optimize those cost functions. Keywords: graphs, graph matching, learning in structured domains, nonsmooth optimization</p><p>5 0.03281663 <a title="7-tfidf-5" href="./jmlr-2009-Identification_of_Recurrent_Neural_Networks_by_Bayesian_Interrogation_Techniques.html">40 jmlr-2009-Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques</a></p>
<p>Author: Barnabás Póczos, András Lőrincz</p><p>Abstract: We introduce novel online Bayesian methods for the identiﬁcation of a family of noisy recurrent neural networks (RNNs). We present Bayesian active learning techniques for stimulus selection given past experiences. In particular, we consider the unknown parameters as stochastic variables and use A-optimality and D-optimality principles to choose optimal stimuli. We derive myopic cost functions in order to maximize the information gain concerning network parameters at each time step. We also derive the A-optimal and D-optimal estimations of the additive noise that perturbs the dynamical system of the RNN. Here we investigate myopic as well as non-myopic estimations, and study the problem of simultaneous estimation of both the system parameters and the noise. Employing conjugate priors our derivations remain approximation-free and give rise to simple update rules for the online learning of the parameters. The efﬁciency of our method is demonstrated for a number of selected cases, including the task of controlled independent component analysis. Keywords: active learning, system identiﬁcation, online Bayesian learning, A-optimality, Doptimality, infomax control, optimal design</p><p>6 0.032331064 <a title="7-tfidf-6" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<p>7 0.024468658 <a title="7-tfidf-7" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>8 0.022816764 <a title="7-tfidf-8" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>9 0.021979626 <a title="7-tfidf-9" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>10 0.019578507 <a title="7-tfidf-10" href="./jmlr-2009-Analysis_of_Perceptron-Based_Active_Learning.html">9 jmlr-2009-Analysis of Perceptron-Based Active Learning</a></p>
<p>11 0.01901247 <a title="7-tfidf-11" href="./jmlr-2009-Bounded_Kernel-Based_Online_Learning.html">13 jmlr-2009-Bounded Kernel-Based Online Learning</a></p>
<p>12 0.018659702 <a title="7-tfidf-12" href="./jmlr-2009-Ultrahigh_Dimensional_Feature_Selection%3A_Beyond_The_Linear_Model.html">97 jmlr-2009-Ultrahigh Dimensional Feature Selection: Beyond The Linear Model</a></p>
<p>13 0.018599555 <a title="7-tfidf-13" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>14 0.017686855 <a title="7-tfidf-14" href="./jmlr-2009-Estimation_of_Sparse_Binary_Pairwise_Markov_Networks_using_Pseudo-likelihoods.html">30 jmlr-2009-Estimation of Sparse Binary Pairwise Markov Networks using Pseudo-likelihoods</a></p>
<p>15 0.016680416 <a title="7-tfidf-15" href="./jmlr-2009-On_Uniform_Deviations_of_General_Empirical_Risks_with_Unboundedness%2C_Dependence%2C_and_High_Dimensionality.html">65 jmlr-2009-On Uniform Deviations of General Empirical Risks with Unboundedness, Dependence, and High Dimensionality</a></p>
<p>16 0.016611772 <a title="7-tfidf-16" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>17 0.015967796 <a title="7-tfidf-17" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>18 0.014303987 <a title="7-tfidf-18" href="./jmlr-2009-Maximum_Entropy_Discrimination_Markov_Networks.html">55 jmlr-2009-Maximum Entropy Discrimination Markov Networks</a></p>
<p>19 0.014167356 <a title="7-tfidf-19" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>20 0.013449081 <a title="7-tfidf-20" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.082), (1, -0.002), (2, 0.015), (3, 0.083), (4, 0.009), (5, 0.001), (6, 0.011), (7, -0.004), (8, -0.058), (9, -0.049), (10, 0.026), (11, 0.044), (12, 0.01), (13, -0.004), (14, 0.034), (15, 0.093), (16, -0.028), (17, 0.013), (18, 0.031), (19, -0.012), (20, -0.021), (21, 0.29), (22, 0.094), (23, 0.05), (24, -0.048), (25, -0.396), (26, -0.116), (27, -0.115), (28, 0.372), (29, -0.126), (30, 0.058), (31, 0.115), (32, 0.144), (33, -0.113), (34, -0.057), (35, -0.089), (36, -0.107), (37, 0.008), (38, 0.091), (39, 0.083), (40, 0.021), (41, 0.155), (42, -0.176), (43, 0.126), (44, -0.007), (45, -0.018), (46, -0.141), (47, -0.061), (48, 0.087), (49, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9844805 <a title="7-lsi-1" href="./jmlr-2009-An_Analysis_of_Convex_Relaxations_for_MAP_Estimation_of_Discrete_MRFs.html">7 jmlr-2009-An Analysis of Convex Relaxations for MAP Estimation of Discrete MRFs</a></p>
<p>Author: M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr</p><p>Abstract: The problem of obtaining the maximum a posteriori estimate of a general discrete Markov random ﬁeld (i.e., a Markov random ﬁeld deﬁned using a discrete set of labels) is known to be NP-hard. However, due to its central importance in many applications, several approximation algorithms have been proposed in the literature. In this paper, we present an analysis of three such algorithms based on convex relaxations: (i) LP - S: the linear programming (LP) relaxation proposed by Schlesinger (1976) for a special case and independently in Chekuri et al. (2001), Koster et al. (1998), and Wainwright et al. (2005) for the general case; (ii) QP - RL: the quadratic programming (QP) relaxation of Ravikumar and Lafferty (2006); and (iii) SOCP - MS: the second order cone programming (SOCP) relaxation ﬁrst proposed by Muramatsu and Suzuki (2003) for two label problems and later extended by Kumar et al. (2006) for a general label set. We show that the SOCP - MS and the QP - RL relaxations are equivalent. Furthermore, we prove that despite the ﬂexibility in the form of the constraints/objective function offered by QP and SOCP, the LP - S relaxation strictly dominates (i.e., provides a better approximation than) QP - RL and SOCP MS . We generalize these results by deﬁning a large class of SOCP (and equivalent QP ) relaxations which is dominated by the LP - S relaxation. Based on these results we propose some novel SOCP relaxations which deﬁne constraints using random variables that form cycles or cliques in the graphical model representation of the random ﬁeld. Using some examples we show that the new SOCP relaxations strictly dominate the previous approaches. Keywords: probabilistic models, MAP estimation, discrete MRF, convex relaxations, linear programming, second-order cone programming, quadratic programming, dominating relaxations ∗. Work done while at the Dept. of Computing, Oxford Brookes University. c 2008 M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr. K UMAR , KOLMOG</p><p>2 0.59339291 <a title="7-lsi-2" href="./jmlr-2009-Cautious_Collective_Classification.html">15 jmlr-2009-Cautious Collective Classification</a></p>
<p>Author: Luke K. McDowell, Kalyan Moy Gupta, David W. Aha</p><p>Abstract: Many collective classiﬁcation (CC) algorithms have been shown to increase accuracy when instances are interrelated. However, CC algorithms must be carefully applied because their use of estimated labels can in some cases decrease accuracy. In this article, we show that managing this label uncertainty through cautious algorithmic behavior is essential to achieving maximal, robust performance. First, we describe cautious inference and explain how four well-known families of CC algorithms can be parameterized to use varying degrees of such caution. Second, we introduce cautious learning and show how it can be used to improve the performance of almost any CC algorithm, with or without cautious inference. We then evaluate cautious inference and learning for the four collective inference families, with three local classiﬁers and a range of both synthetic and real-world data. We ﬁnd that cautious learning and cautious inference typically outperform less cautious approaches. In addition, we identify the data characteristics that predict more substantial performance differences. Our results reveal that the degree of caution used usually has a larger impact on performance than the choice of the underlying inference algorithm. Together, these results identify the most appropriate CC algorithms to use for particular task characteristics and explain multiple conﬂicting ﬁndings from prior CC research. Keywords: collective inference, statistical relational learning, approximate probabilistic inference, networked data, cautious inference</p><p>3 0.16795753 <a title="7-lsi-3" href="./jmlr-2009-Identification_of_Recurrent_Neural_Networks_by_Bayesian_Interrogation_Techniques.html">40 jmlr-2009-Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques</a></p>
<p>Author: Barnabás Póczos, András Lőrincz</p><p>Abstract: We introduce novel online Bayesian methods for the identiﬁcation of a family of noisy recurrent neural networks (RNNs). We present Bayesian active learning techniques for stimulus selection given past experiences. In particular, we consider the unknown parameters as stochastic variables and use A-optimality and D-optimality principles to choose optimal stimuli. We derive myopic cost functions in order to maximize the information gain concerning network parameters at each time step. We also derive the A-optimal and D-optimal estimations of the additive noise that perturbs the dynamical system of the RNN. Here we investigate myopic as well as non-myopic estimations, and study the problem of simultaneous estimation of both the system parameters and the noise. Employing conjugate priors our derivations remain approximation-free and give rise to simple update rules for the online learning of the parameters. The efﬁciency of our method is demonstrated for a number of selected cases, including the task of controlled independent component analysis. Keywords: active learning, system identiﬁcation, online Bayesian learning, A-optimality, Doptimality, infomax control, optimal design</p><p>4 0.14098655 <a title="7-lsi-4" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>Author: John Langford, Lihong Li, Tong Zhang</p><p>Abstract: We propose a general method called truncated gradient to induce sparsity in the weights of onlinelearning algorithms with convex loss functions. This method has several essential properties: 1. The degree of sparsity is continuous—a parameter controls the rate of sparsiﬁcation from no sparsiﬁcation to total sparsiﬁcation. 2. The approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular L1 -regularization method in the batch setting. We prove that small rates of sparsiﬁcation result in only small additional regret with respect to typical online-learning guarantees. 3. The approach works well empirically. We apply the approach to several data sets and ﬁnd for data sets with large numbers of features, substantial sparsity is discoverable. Keywords: truncated gradient, stochastic gradient descent, online learning, sparsity, regularization, Lasso</p><p>5 0.13894832 <a title="7-lsi-5" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<p>Author: Brian Kulis, Mátyás A. Sustik, Inderjit S. Dhillon</p><p>Abstract: In this paper, we study low-rank matrix nearness problems, with a focus on learning low-rank positive semideﬁnite (kernel) matrices for machine learning applications. We propose efﬁcient algorithms that scale linearly in the number of data points and quadratically in the rank of the input matrix. Existing algorithms for learning kernel matrices often scale poorly, with running times that are cubic in the number of data points. We employ Bregman matrix divergences as the measures of nearness—these divergences are natural for learning low-rank kernels since they preserve rank as well as positive semideﬁniteness. Special cases of our framework yield faster algorithms for various existing learning problems, and experimental results demonstrate that our algorithms can effectively learn both low-rank and full-rank kernel matrices. Keywords: kernel methods, Bregman divergences, convex optimization, kernel learning, matrix nearness</p><p>6 0.12610535 <a title="7-lsi-6" href="./jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>7 0.12009818 <a title="7-lsi-7" href="./jmlr-2009-Bi-Level_Path_Following_for_Cross_Validated_Solution_of_Kernel_Quantile_Regression.html">12 jmlr-2009-Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression</a></p>
<p>8 0.11429559 <a title="7-lsi-8" href="./jmlr-2009-Structure_Spaces.html">90 jmlr-2009-Structure Spaces</a></p>
<p>9 0.10868066 <a title="7-lsi-9" href="./jmlr-2009-Marginal_Likelihood_Integrals_for_Mixtures_of_Independence_Models.html">53 jmlr-2009-Marginal Likelihood Integrals for Mixtures of Independence Models</a></p>
<p>10 0.097551957 <a title="7-lsi-10" href="./jmlr-2009-The_P-Norm_Push%3A_A_Simple_Convex_Ranking_Algorithm_that_Concentrates_at_the_Top_of_the_List.html">95 jmlr-2009-The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List</a></p>
<p>11 0.092875861 <a title="7-lsi-11" href="./jmlr-2009-Perturbation_Corrections_in_Approximate_Inference%3A_Mixture_Modelling_Applications.html">71 jmlr-2009-Perturbation Corrections in Approximate Inference: Mixture Modelling Applications</a></p>
<p>12 0.092870459 <a title="7-lsi-12" href="./jmlr-2009-Bounded_Kernel-Based_Online_Learning.html">13 jmlr-2009-Bounded Kernel-Based Online Learning</a></p>
<p>13 0.088765465 <a title="7-lsi-13" href="./jmlr-2009-Ultrahigh_Dimensional_Feature_Selection%3A_Beyond_The_Linear_Model.html">97 jmlr-2009-Ultrahigh Dimensional Feature Selection: Beyond The Linear Model</a></p>
<p>14 0.081672668 <a title="7-lsi-14" href="./jmlr-2009-On_Efficient_Large_Margin_Semisupervised_Learning%3A_Method_and_Theory.html">63 jmlr-2009-On Efficient Large Margin Semisupervised Learning: Method and Theory</a></p>
<p>15 0.078549415 <a title="7-lsi-15" href="./jmlr-2009-A_New_Approach_to_Collaborative_Filtering%3A_Operator_Estimation_with_Spectral_Regularization.html">2 jmlr-2009-A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization</a></p>
<p>16 0.077963829 <a title="7-lsi-16" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>17 0.077935681 <a title="7-lsi-17" href="./jmlr-2009-Generalization_Bounds_for_Ranking_Algorithms_via_Algorithmic_Stability.html">37 jmlr-2009-Generalization Bounds for Ranking Algorithms via Algorithmic Stability</a></p>
<p>18 0.075577259 <a title="7-lsi-18" href="./jmlr-2009-Similarity-based_Classification%3A_Concepts_and_Algorithms.html">86 jmlr-2009-Similarity-based Classification: Concepts and Algorithms</a></p>
<p>19 0.074888282 <a title="7-lsi-19" href="./jmlr-2009-Hybrid_MPI_OpenMP_Parallel_Linear_Support_Vector_Machine_Training.html">39 jmlr-2009-Hybrid MPI OpenMP Parallel Linear Support Vector Machine Training</a></p>
<p>20 0.073130719 <a title="7-lsi-20" href="./jmlr-2009-Improving_the_Reliability_of_Causal_Discovery_from_Small_Data_Sets_Using_Argumentation%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">41 jmlr-2009-Improving the Reliability of Causal Discovery from Small Data Sets Using Argumentation    (Special Topic on Causality)</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.026), (26, 0.011), (38, 0.017), (47, 0.012), (52, 0.02), (55, 0.033), (58, 0.024), (66, 0.071), (68, 0.022), (90, 0.047), (95, 0.577), (96, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78938454 <a title="7-lda-1" href="./jmlr-2009-An_Analysis_of_Convex_Relaxations_for_MAP_Estimation_of_Discrete_MRFs.html">7 jmlr-2009-An Analysis of Convex Relaxations for MAP Estimation of Discrete MRFs</a></p>
<p>Author: M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr</p><p>Abstract: The problem of obtaining the maximum a posteriori estimate of a general discrete Markov random ﬁeld (i.e., a Markov random ﬁeld deﬁned using a discrete set of labels) is known to be NP-hard. However, due to its central importance in many applications, several approximation algorithms have been proposed in the literature. In this paper, we present an analysis of three such algorithms based on convex relaxations: (i) LP - S: the linear programming (LP) relaxation proposed by Schlesinger (1976) for a special case and independently in Chekuri et al. (2001), Koster et al. (1998), and Wainwright et al. (2005) for the general case; (ii) QP - RL: the quadratic programming (QP) relaxation of Ravikumar and Lafferty (2006); and (iii) SOCP - MS: the second order cone programming (SOCP) relaxation ﬁrst proposed by Muramatsu and Suzuki (2003) for two label problems and later extended by Kumar et al. (2006) for a general label set. We show that the SOCP - MS and the QP - RL relaxations are equivalent. Furthermore, we prove that despite the ﬂexibility in the form of the constraints/objective function offered by QP and SOCP, the LP - S relaxation strictly dominates (i.e., provides a better approximation than) QP - RL and SOCP MS . We generalize these results by deﬁning a large class of SOCP (and equivalent QP ) relaxations which is dominated by the LP - S relaxation. Based on these results we propose some novel SOCP relaxations which deﬁne constraints using random variables that form cycles or cliques in the graphical model representation of the random ﬁeld. Using some examples we show that the new SOCP relaxations strictly dominate the previous approaches. Keywords: probabilistic models, MAP estimation, discrete MRF, convex relaxations, linear programming, second-order cone programming, quadratic programming, dominating relaxations ∗. Work done while at the Dept. of Computing, Oxford Brookes University. c 2008 M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr. K UMAR , KOLMOG</p><p>2 0.16958131 <a title="7-lda-2" href="./jmlr-2009-Efficient_Online_and_Batch_Learning_Using_Forward_Backward_Splitting.html">27 jmlr-2009-Efficient Online and Batch Learning Using Forward Backward Splitting</a></p>
<p>Author: John Duchi, Yoram Singer</p><p>Abstract: We describe, analyze, and experiment with a framework for empirical loss minimization with regularization. Our algorithmic framework alternates between two phases. On each iteration we ﬁrst perform an unconstrained gradient descent step. We then cast and solve an instantaneous optimization problem that trades off minimization of a regularization term while keeping close proximity to the result of the ﬁrst phase. This view yields a simple yet effective algorithm that can be used for batch penalized risk minimization and online learning. Furthermore, the two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity, such as ℓ1 . We derive concrete and very simple algorithms for minimization of loss functions with ℓ1 , ℓ2 , ℓ2 , and ℓ∞ regularization. We also show how to construct ef2 ﬁcient algorithms for mixed-norm ℓ1 /ℓq regularization. We further extend the algorithms and give efﬁcient implementations for very high-dimensional data with sparsity. We demonstrate the potential of the proposed framework in a series of experiments with synthetic and natural data sets. Keywords: subgradient methods, group sparsity, online learning, convex optimization</p><p>3 0.16689166 <a title="7-lda-3" href="./jmlr-2009-Controlling_the_False_Discovery_Rate_of_the_Association_Causality_Structure_Learned_with_the_PC_Algorithm%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Mining_and_Learning_with_Graphs_and_Relations%29.html">19 jmlr-2009-Controlling the False Discovery Rate of the Association Causality Structure Learned with the PC Algorithm    (Special Topic on Mining and Learning with Graphs and Relations)</a></p>
<p>Author: Junning Li, Z. Jane Wang</p><p>Abstract: In real world applications, graphical statistical models are not only a tool for operations such as classiﬁcation or prediction, but usually the network structures of the models themselves are also of great interest (e.g., in modeling brain connectivity). The false discovery rate (FDR), the expected ratio of falsely claimed connections to all those claimed, is often a reasonable error-rate criterion in these applications. However, current learning algorithms for graphical models have not been adequately adapted to the concerns of the FDR. The traditional practice of controlling the type I error rate and the type II error rate under a conventional level does not necessarily keep the FDR low, especially in the case of sparse networks. In this paper, we propose embedding an FDR-control procedure into the PC algorithm to curb the FDR of the skeleton of the learned graph. We prove that the proposed method can control the FDR under a user-speciﬁed level at the limit of large sample sizes. In the cases of moderate sample size (about several hundred), empirical experiments show that the method is still able to control the FDR under the user-speciﬁed level, and a heuristic modiﬁcation of the method is able to control the FDR more accurately around the user-speciﬁed level. The proposed method is applicable to any models for which statistical tests of conditional independence are available, such as discrete models and Gaussian models. Keywords: Bayesian networks, false discovery rate, PC algorithm, directed acyclic graph, skeleton</p><p>4 0.16537102 <a title="7-lda-4" href="./jmlr-2009-Analysis_of_Perceptron-Based_Active_Learning.html">9 jmlr-2009-Analysis of Perceptron-Based Active Learning</a></p>
<p>Author: Sanjoy Dasgupta, Adam Tauman Kalai, Claire Monteleoni</p><p>Abstract: We start by showing that in an active learning setting, the Perceptron algorithm needs Ω( ε12 ) labels to learn linear separators within generalization error ε. We then present a simple active learning algorithm for this problem, which combines a modiﬁcation of the Perceptron update with an adaptive ﬁltering rule for deciding which points to query. For data distributed uniformly over the unit ˜ sphere, we show that our algorithm reaches generalization error ε after asking for just O(d log 1 ) ε labels. This exponential improvement over the usual sample complexity of supervised learning had previously been demonstrated only for the computationally more complex query-by-committee algorithm. Keywords: active learning, perceptron, label complexity bounds, online learning</p><p>5 0.16484758 <a title="7-lda-5" href="./jmlr-2009-Bounded_Kernel-Based_Online_Learning.html">13 jmlr-2009-Bounded Kernel-Based Online Learning</a></p>
<p>Author: Francesco Orabona, Joseph Keshet, Barbara Caputo</p><p>Abstract: A common problem of kernel-based online algorithms, such as the kernel-based Perceptron algorithm, is the amount of memory required to store the online hypothesis, which may increase without bound as the algorithm progresses. Furthermore, the computational load of such algorithms grows linearly with the amount of memory used to store the hypothesis. To attack these problems, most previous work has focused on discarding some of the instances, in order to keep the memory bounded. In this paper we present a new algorithm, in which the instances are not discarded, but are instead projected onto the space spanned by the previous online hypothesis. We call this algorithm Projectron. While the memory size of the Projectron solution cannot be predicted before training, we prove that its solution is guaranteed to be bounded. We derive a relative mistake bound for the proposed algorithm, and deduce from it a slightly different algorithm which outperforms the Perceptron. We call this second algorithm Projectron++. We show that this algorithm can be extended to handle the multiclass and the structured output settings, resulting, as far as we know, in the ﬁrst online bounded algorithm that can learn complex classiﬁcation tasks. The method of bounding the hypothesis representation can be applied to any conservative online algorithm and to other online algorithms, as it is demonstrated for ALMA2 . Experimental results on various data sets show the empirical advantage of our technique compared to various bounded online algorithms, both in terms of memory and accuracy. Keywords: online learning, kernel methods, support vector machines, bounded support set</p><p>6 0.16476811 <a title="7-lda-6" href="./jmlr-2009-When_Is_There_a_Representer_Theorem%3F__Vector_Versus_Matrix_Regularizers.html">100 jmlr-2009-When Is There a Representer Theorem?  Vector Versus Matrix Regularizers</a></p>
<p>7 0.16459493 <a title="7-lda-7" href="./jmlr-2009-Deterministic_Error_Analysis_of_Support_Vector_Regression_and_Related_Regularized_Kernel_Methods.html">22 jmlr-2009-Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods</a></p>
<p>8 0.16450143 <a title="7-lda-8" href="./jmlr-2009-Robustness_and_Regularization_of_Support_Vector_Machines.html">82 jmlr-2009-Robustness and Regularization of Support Vector Machines</a></p>
<p>9 0.1639491 <a title="7-lda-9" href="./jmlr-2009-Margin-based_Ranking_and_an_Equivalence_between_AdaBoost_and_RankBoost.html">52 jmlr-2009-Margin-based Ranking and an Equivalence between AdaBoost and RankBoost</a></p>
<p>10 0.1632134 <a title="7-lda-10" href="./jmlr-2009-Reproducing_Kernel_Banach_Spaces_for_Machine_Learning.html">80 jmlr-2009-Reproducing Kernel Banach Spaces for Machine Learning</a></p>
<p>11 0.16270602 <a title="7-lda-11" href="./jmlr-2009-Provably_Efficient_Learning_with_Typed_Parametric_Models.html">75 jmlr-2009-Provably Efficient Learning with Typed Parametric Models</a></p>
<p>12 0.16206054 <a title="7-lda-12" href="./jmlr-2009-The_Nonparanormal%3A_Semiparametric_Estimation_of_High_Dimensional_Undirected_Graphs.html">94 jmlr-2009-The Nonparanormal: Semiparametric Estimation of High Dimensional Undirected Graphs</a></p>
<p>13 0.16187137 <a title="7-lda-13" href="./jmlr-2009-On_the_Consistency_of_Feature_Selection_using_Greedy_Least_Squares_Regression.html">66 jmlr-2009-On the Consistency of Feature Selection using Greedy Least Squares Regression</a></p>
<p>14 0.16137841 <a title="7-lda-14" href="./jmlr-2009-Consistency_and_Localizability.html">18 jmlr-2009-Consistency and Localizability</a></p>
<p>15 0.16137256 <a title="7-lda-15" href="./jmlr-2009-The_Hidden_Life_of_Latent_Variables%3A_Bayesian_Learning_with_Mixed_Graph_Models.html">93 jmlr-2009-The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models</a></p>
<p>16 0.16124064 <a title="7-lda-16" href="./jmlr-2009-Refinement_of_Reproducing_Kernels.html">78 jmlr-2009-Refinement of Reproducing Kernels</a></p>
<p>17 0.16096033 <a title="7-lda-17" href="./jmlr-2009-Exploiting_Product_Distributions_to_Identify_Relevant_Variables_of_Correlation_Immune_Functions.html">32 jmlr-2009-Exploiting Product Distributions to Identify Relevant Variables of Correlation Immune Functions</a></p>
<p>18 0.16054066 <a title="7-lda-18" href="./jmlr-2009-Settable_Systems%3A_An_Extension_of_Pearl%27s_Causal_Model_with_Optimization%2C_Equilibrium%2C_and_Learning.html">85 jmlr-2009-Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning</a></p>
<p>19 0.16043183 <a title="7-lda-19" href="./jmlr-2009-Sparse_Online_Learning_via_Truncated_Gradient.html">87 jmlr-2009-Sparse Online Learning via Truncated Gradient</a></p>
<p>20 0.16035546 <a title="7-lda-20" href="./jmlr-2009-Low-Rank_Kernel_Learning_with_Bregman_Matrix_Divergences.html">51 jmlr-2009-Low-Rank Kernel Learning with Bregman Matrix Divergences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
