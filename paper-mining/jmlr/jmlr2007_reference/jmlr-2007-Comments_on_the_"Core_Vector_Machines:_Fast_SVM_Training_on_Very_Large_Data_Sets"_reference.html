<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>21 jmlr-2007-Comments on the "Core Vector Machines: Fast SVM Training on Very Large Data Sets"</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2007" href="../home/jmlr2007_home.html">jmlr2007</a> <a title="jmlr-2007-21" href="../jmlr2007/jmlr-2007-Comments_on_the_%22Core_Vector_Machines%3A_Fast_SVM_Training_on_Very_Large_Data_Sets%22.html">jmlr2007-21</a> <a title="jmlr-2007-21-reference" href="#">jmlr2007-21-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>21 jmlr-2007-Comments on the "Core Vector Machines: Fast SVM Training on Very Large Data Sets"</h1>
<br/><p>Source: <a title="jmlr-2007-21-pdf" href="http://jmlr.org/papers/volume8/loosli07a/loosli07a.pdf">pdf</a></p><p>Author: Gaëlle Loosli, Stéphane Canu</p><p>Abstract: In a recently published paper in JMLR, Tsang et al. (2005) present an algorithm for SVM called Core Vector Machines (CVM) and illustrate its performances through comparisons with other SVM solvers. After reading the CVM paper we were surprised by some of the reported results. In order to clarify the matter, we decided to reproduce some of the experiments. It turns out that to some extent, our results contradict those reported. Reasons of these different behaviors are given through the analysis of the stopping criterion. Keywords: SVM, CVM, large scale, KKT gap, stopping condition, stopping criteria</p><br/>
<h2>reference text</h2><p>Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for support vector machines, 2001a. URL http://www.csie.ntu.edu.tw/~cjlin/libsvm. Chih-Chung Chang and Chih-Jen Lin. Training ν-support vector classiﬁers: Theory and algorithms. Neural Computation, (9):2119–2147, 2001b. Pai-Hsuen Chen, Chih-Jen Lin, and Bernhard Schölkopf. A tutorial on v-support vector machines. Applied Stochastic Models in Business and Industry, 21(2):111–136, 2005. Rong-En Fan, Pai-Hsuen Chen, and Chih-Jen Lin. Working set selection using second order information for training support vector machines. Journal of Machine Learning Research, 2005. Gaëlle Loosli. Fast svm toolbox in Matlab based on SimpleSVM algorithm, 2004. http://asi. insa-rouen.fr/~gloosli/simpleSVM.html. John Platt. Fast training of support vector machines using sequential minimal optimization. In B. Scholkopf, C. Burges, and A. Smola, editors, Advanced in Kernel Methods - Support Vector Learning, pages 185–208. MIT Press, 1999. Bernhard Schölkopf and Alexander J. Smola. Learning with Kernels. MIT Press, 2002. Ivor W. Tsang, James T. Kwok, and Pak-Ming Cheung. Core vector machines: Fast SVM training on very large data sets. J. Mach. Learn. Res., 6:363–392, 2005. S. V. N Vishwanathan, Alexander J. Smola, and M. Narasimha Murty. SimpleSVM. Proceedings of the Twentieth International Conference on Machine Learning, 2003.  301</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
