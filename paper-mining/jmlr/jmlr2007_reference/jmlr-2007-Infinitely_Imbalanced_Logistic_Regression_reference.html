<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>42 jmlr-2007-Infinitely Imbalanced Logistic Regression</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2007" href="../home/jmlr2007_home.html">jmlr2007</a> <a title="jmlr-2007-42" href="../jmlr2007/jmlr-2007-Infinitely_Imbalanced_Logistic_Regression.html">jmlr2007-42</a> <a title="jmlr-2007-42-reference" href="#">jmlr2007-42-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>42 jmlr-2007-Infinitely Imbalanced Logistic Regression</h1>
<br/><p>Source: <a title="jmlr-2007-42-pdf" href="http://jmlr.org/papers/volume8/owen07a/owen07a.pdf">pdf</a></p><p>Author: Art B. Owen</p><p>Abstract: In binary classiﬁcation problems it is common for the two classes to be imbalanced: one case is very rare compared to the other. In this paper we consider the inﬁnitely imbalanced case where one class has a ﬁnite sample size and the other class’s sample size grows without bound. For logistic regression, the inﬁnitely imbalanced case often has a useful solution. Under mild conditions, the intercept diverges as expected, but the rest of the coefﬁcient vector approaches a non trivial and useful limit. That limit can be expressed in terms of exponential tilting and is the minimum of a convex objective function. The limiting form of logistic regression suggests a computational shortcut for fraud detection problems. Keywords: classiﬁcation, drug discovery, fraud detection, rare events, unbalanced data</p><br/>
<h2>reference text</h2><p>R. J. Bolton and D. J. Hand. Statistical fraud detection: A review. Statistical Science, 17(3):235– 255, 2002. L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classiﬁcation And Regression Trees. Wadsworth, Belmont, CA, 1984. N.V. Chawla, N. Japkowicz, and A. Kolcz. Proceedings of the ICML’2003 Workshop on Learning from Imbalanced Data Sets. 2003. N.V. Chawla, N. Japkowicz, and A. Kolcz. Editorial: special issue on learning from imbalanced data sets. ACM SIGKDD Explorations Newsletter, 6(1):1–6, 2004. D.A. Cohn, Z. Ghahramani, and M.I. Jordan. Active learning with statistical models. Journal of Artiﬁcial Intelligence Research, 4:129–145, 1996. N. Japkowicz. Learning from Imbalanced Data Sets: Papers from the AAAI Workshop. AAAI, 2000. Technical Report WS-00-05. G. King and L. Zeng. Logistic regression in rare events data. Political Analysis, 9(2):137–163, 2001. M.J. Silvapulle. On the existence of maximum likelihood estimates for the binomial response models. Journal of the Royal Statistical Society, Series B, 43:310–313, 1981. S. Tong. Active learning: Theory and applications. PhD thesis, Stanford University, 2001. URL http://ai.stanford.edu/∼stong/research.html/tong thesis.pdf. M. Zhu, W. Su, and H. A. Chipman. LAGO: A computationally efﬁcient approach for statistical detection. Technometrics, 48:193–205, 2005.  773</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
