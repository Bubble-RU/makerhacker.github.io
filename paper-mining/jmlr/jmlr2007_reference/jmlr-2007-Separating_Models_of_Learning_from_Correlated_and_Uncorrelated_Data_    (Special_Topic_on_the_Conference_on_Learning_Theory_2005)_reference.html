<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>74 jmlr-2007-Separating Models of Learning from Correlated and Uncorrelated Data     (Special Topic on the Conference on Learning Theory 2005)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2007" href="../home/jmlr2007_home.html">jmlr2007</a> <a title="jmlr-2007-74" href="../jmlr2007/jmlr-2007-Separating_Models_of_Learning_from_Correlated_and_Uncorrelated_Data_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_the_Conference_on_Learning_Theory_2005%29.html">jmlr2007-74</a> <a title="jmlr-2007-74-reference" href="#">jmlr2007-74-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>74 jmlr-2007-Separating Models of Learning from Correlated and Uncorrelated Data     (Special Topic on the Conference on Learning Theory 2005)</h1>
<br/><p>Source: <a title="jmlr-2007-74-pdf" href="http://jmlr.org/papers/volume8/elbaz07a/elbaz07a.pdf">pdf</a></p><p>Author: Ariel Elbaz, Homin K. Lee, Rocco A. Servedio, Andrew Wan</p><p>Abstract: We consider a natural framework of learning from correlated data, in which successive examples used for learning are generated according to a random walk over the space of possible examples. A recent paper by Bshouty et al. (2003) shows that the class of polynomial-size DNF formulas is efﬁciently learnable in this random walk model; this result suggests that the Random Walk model is more powerful than comparable standard models of learning from independent examples, in which similarly efﬁcient DNF learning algorithms are not known. We give strong evidence that the Random Walk model is indeed more powerful than the standard model, by showing that if any cryptographic one-way function exists (a universally held belief in cryptography), then there is a class of functions that can be learned efﬁciently in the Random Walk setting but not in the standard setting where all examples are independent. Keywords: random walks, uniform distribution learning, cryptographic hardness, correlated data, PAC learning</p><br/>
<h2>reference text</h2><p>D. Aldous and U. Vazirani. A Markovian extension of Valiant’s learning model. In Proceedings of the Thirty-First Symposium on Foundations of Computer Science, pages 392–396, 1990. ¨ P. Bartlett, P. Fischer, and K.U. Hoffgen. Exploiting random walks for learning. Information and Computation, 176(2):121–135, 2002. A. Blum. Learning a function of r relevant variables (open problem). In Proc. 16th Annual COLT, pages 731–733, 2003. A. Blum, M. Furst, J. Jackson, M. Kearns, Y. Mansour, and S. Rudich. Weakly learning DNF and characterizing statistical query learning using Fourier analysis. In Proceedings of the TwentySixth Annual Symposium on Theory of Computing, pages 253–262, 1994. N. Bshouty and C. Tamon. On the Fourier spectrum of monotone functions. Journal of the ACM, 43(4):747–770, 1996. 289  E LBAZ , L EE , S ERVEDIO AND WAN  N. Bshouty, J. Jackson, and C. Tamon. More efﬁcient PAC learning of DNF with membership queries under the uniform distribution. In Proceedings of the Twelfth Annual Conference on Computational Learning Theory, pages 286–295, 1999. N. Bshouty, E. Mossel, R. O’Donnell, and R. Servedio. Learning DNF from Random Walks. In Proceedings of the 44th IEEE Symposium on Foundations on Computer Science, pages 189–198, 2003. D. Gamarnik. Extension of the PAC framework to ﬁnite and countable Markov chains. In Proceedings of the 12th Annual Conference on Computational Learning Theory, pages 308–317, 1999. O. Goldreich. Foundations of Cryptography: Volume 1, Basic Tools. Cambridge University Press, New York, 2001. O. Goldreich, S. Goldwasser, and S. Micali. How to construct random functions. Journal of the Association for Computing Machinery, 33(4):792–807, 1986. J. H˚ stad, R. Impagliazzo, L. Levin, and M. Luby. A pseudorandom generator from any one-way a function. SIAM Journal on Computing, 28(4):1364–1396, 1999. J. Jackson. An efﬁcient membership-query algorithm for learning DNF with respect to the uniform distribution. Journal of Computer and System Sciences, 55:414–440, 1997. J. Jackson, A. Klivans, and R. Servedio. Learnability beyond AC 0 . In Proceedings of the 34th ACM Symposium on Theory of Computing, pages 776–784, 2002. M. Kharitonov. Cryptographic hardness of distribution-speciﬁc learning. In Proceedings of the Twenty-Fifth Annual Symposium on Theory of Computing, pages 372–381, 1993. N. Linial, Y. Mansour, and N. Nisan. Constant depth circuits, Fourier transform and learnability. Journal of the ACM, 40(3):607–620, 1993. S. Roch. On learning thresholds of parities and unions of rectangles in random walk models. Random Structures and Algorithms, 2006. L. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134–1142, 1984. K. Verbeurgt. Learning DNF under the uniform distribution in quasi-polynomial time. In Proceedings of the Third Annual Workshop on Computational Learning Theory, pages 314–326, 1990.  290</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
