<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>83 jmlr-2007-The On-Line Shortest Path Problem Under Partial Monitoring</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2007" href="../home/jmlr2007_home.html">jmlr2007</a> <a title="jmlr-2007-83" href="../jmlr2007/jmlr-2007-The_On-Line_Shortest_Path_Problem_Under_Partial_Monitoring.html">jmlr2007-83</a> <a title="jmlr-2007-83-reference" href="#">jmlr2007-83-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>83 jmlr-2007-The On-Line Shortest Path Problem Under Partial Monitoring</h1>
<br/><p>Source: <a title="jmlr-2007-83-pdf" href="http://jmlr.org/papers/volume8/gyoergy07a/gyoergy07a.pdf">pdf</a></p><p>Author: András György, Tamás Linder, Gábor Lugosi, György Ottucsák</p><p>Abstract: The on-line shortest path problem is considered under various models of partial monitoring. Given a weighted directed acyclic graph whose edge weights can change in an arbitrary (adversarial) way, a decision maker has to choose in each round of a game a path between two distinguished vertices such that the loss of the chosen path (deﬁned as the sum of the weights of its composing edges) be as small as possible. In a setting generalizing the multi-armed bandit problem, after choosing a path, the decision maker learns only the weights of those edges that belong to the chosen path. For this problem, an algorithm is given whose average cumulative loss in n rounds exceeds that of the best path, matched off-line to the entire sequence of the edge weights, by a quantity that is √ proportional to 1/ n and depends only polynomially on the number of edges of the graph. The algorithm can be implemented with complexity that is linear in the number of rounds n (i.e., the average complexity per round is constant) and in the number of edges. An extension to the so-called label efﬁcient setting is also given, in which the decision maker is informed about the weights of the edges corresponding to the chosen path at a total of m n time instances. Another extension is shown where the decision maker competes against a time-varying path, a generalization of the problem of tracking the best expert. A version of the multi-armed bandit setting for shortest path is also discussed where the decision maker learns only the total weight of the chosen path but not the weights of the individual edges on the path. Applications to routing in packet switched networks along with simulation results are also presented. Keywords: on-line learning, shortest path problem, multi-armed bandit problem c 2007 Andr´ s Gy¨ rgy, Tam´ s Linder, G´ bor Lugosi and Gy¨ rgy Ottucs´ k. a o a a o a ¨ ´ G Y ORGY, L INDER , L UGOSI AND OTTUCS AK</p><br/>
<h2>reference text</h2><p>C. Allenberg, P. Auer, L. Gy¨ rﬁ, and Gy. Ottucs´ k. Hannan consistency in on-line learning in case o a of unbounded losses under partial monitoring. In Proceedings of 17th International Conference on Algorithmic Learning Theory, ALT 2006, Lecture Notes in Computer Science 4264, pages 229–243, Barcelona, Spain, Oct. 2006. P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire. The non-stochastic multi-armed bandit problem. SIAM Journal on Computing, 32(1):48–77, 2002. P. Auer and M. Warmuth. Tracking the best disjunction. Machine Learning, 32(2):127–150, 1998. P. Auer and Gy. Ottucs´ k. Bound on high-probability regret in loss-bandit game. Preprint, 2006. a http://www.szit.bme.hu/˜ ti/green.pdf. o B. Awerbuch, D. Holmer, H. Rubens, and R. Kleinberg. Provably competitive adaptive routing. In Proceedings of IEEE INFOCOM 2005, volume 1, pages 631–641, March 2005. B. Awerbuch and R. D. Kleinberg. Adaptive routing with end-to-end feedback: Distributed learning and geometric approaches. In Proceedings of the 36th Annual ACM Symposium on the Theory of Computing, STOC 2004, pages 45–53, Chicago, IL, USA, Jun. 2004. ACM Press. D. Blackwell. An analog of the minimax theorem for vector payoffs. Paciﬁc Journal of Mathematics, 6:1–8, 1956. O. Bousquet and M. K. Warmuth. Tracking a small set of experts by mixing past posteriors. Journal of Machine Learning Research, 3:363–396, Nov. 2002. 2401  ¨ ´ G Y ORGY, L INDER , L UGOSI AND OTTUCS AK  N. Cesa-Bianchi, Y. Freund, D. P. Helmbold, D. Haussler, R. Schapire, and M. K. Warmuth. How to use expert advice. Journal of the ACM, 44(3):427–485, 1997. N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, Cambridge, 2006. N. Cesa-Bianchi, G. Lugosi, and G. Stoltz. Minimizing regret with label efﬁcient prediction. IEEE Trans. Inform. Theory, IT-51:2152–2162, June 2005. D.A. Freedman. On tail probabilities for martingales. Annals of Probability, 3:100–118, 1975. E. Gelenbe, M. Gellman, R. Lent, P. Liu, and P. Su. Autonomous smart routing for network QoS. In Proceedings of First International Conference on Autonomic Computing, pages 232–239, New York, May 2004. IEEE Computer Society. E. Gelenbe, R. Lent, and Z. Xhu. Measurement and performance of a cognitive packet network. Journal of Computer Networks, 37:691–701, 2001. A. Gy¨ rgy, T. Linder, and G. Lugosi. Efﬁcient algorithms and minimax bounds for zero-delay lossy o source coding. IEEE Transactions on Signal Processing, 52:2337–2347, Aug. 2004a. A. Gy¨ rgy, T. Linder, and G. Lugosi. A ”follow the perturbed leader”-type algorithm for zero-delay o quantization of individual sequences. In Proc. Data Compression Conference, pages 342–351, Snowbird, UT, USA, Mar. 2004b. A. Gy¨ rgy, T. Linder, and G. Lugosi. Tracking the best of many experts. In Proceedings of the 18th o Annual Conference on Learning Theory, COLT 2005, Lecture Notes in Computer Science 3559, pages 204–216, Bertinoro, Italy, Jun. 2005a. Springer. A. Gy¨ rgy, T. Linder, and G. Lugosi. Tracking the best quantizer. In Proceedings of the IEEE o International Symposium on Information Theory, pages 1163–1167, Adelaide, Australia, JuneJuly 2005b. A. Gy¨ rgy and Gy. Ottucs´ k. Adaptive routing using expert advice. The Computer Journal, 49(2): o a 180–189, 2006. J. Hannan. Approximation to Bayes risk in repeated plays. In M. Dresher, A. Tucker, and P. Wolfe, editors, Contributions to the Theory of Games, volume 3, pages 97–139. Princeton University Press, 1957. D.P. Helmbold and S. Panizza. Some label efﬁcient learning results. In Proceedings of the 10th Annual Conference on Computational Learning Theory, pages 218–230. ACM Press, 1997. M. Herbster and M. K. Warmuth. Tracking the best expert. Machine Learning, 32(2):151–178, 1998. M. Herbster and M. K. Warmuth. Tracking the best linear predictor. Journal of Machine Learning Research, 1:281–309, 2001. W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58:13–30, 1963. 2402  T HE O N -L INE S HORTEST PATH P ROBLEM  ¨ A. Kalai and S Vempala. Efﬁcient algorithms for the online decision problem. In B. Sch olkopf and M. Warmuth, editors, Proceedings of the 16th Annual Conference on Learning Theory and the 7th Kernel Workshop, COLT-Kernel 2003, Lecture Notes in Computer Science 2777, pages 26–40, New York, USA, Aug. 2003. Springer. N. Littlestone and M. K. Warmuth. The weighted majority algorithm. Information and Computation, 108:212–261, 1994. H. B. McMahan and A. Blum. Online geometric optimization in the bandit setting against an adaptive adversary. In Proceedings of the 17th Annual Conference on Learning Theory, COLT 2004, Lecture Notes in Computer Science 3120, pages 109–123, Banff, Canada, Jul. 2004. Springer. M. Mohri. General algebraic frameworks and algorithms for shortest distance problems. Technical Report 981219-10TM, AT&T; Labs Research, 1998. R. E. Schapire and D. P. Helmbold. Predicting nearly as well as the best pruning of a decision tree. Machine Learning, 27:51–68, 1997. E. Takimoto and M. K. Warmuth. Path kernels and multiplicative updates. Journal of Machine Learning Research, 4:773–818, 2003. V. Vovk. Aggregating strategies. In Proceedings of the Third Annual Workshop on Computational Learning Theory, pages 372–383, Rochester, NY, Aug. 1990. Morgan Kaufmann. V. Vovk. Derandomizing stochastic prediction strategies. Machine Learning, 35(3):247–282, Jun. 1999.  2403</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
