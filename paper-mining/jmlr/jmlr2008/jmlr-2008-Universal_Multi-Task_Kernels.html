<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>92 jmlr-2008-Universal Multi-Task Kernels</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-92" href="#">jmlr2008-92</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>92 jmlr-2008-Universal Multi-Task Kernels</h1>
<br/><p>Source: <a title="jmlr-2008-92-pdf" href="http://jmlr.org/papers/volume9/caponnetto08a/caponnetto08a.pdf">pdf</a></p><p>Author: Andrea Caponnetto, Charles A. Micchelli, Massimiliano Pontil, Yiming Ying</p><p>Abstract: In this paper we are concerned with reproducing kernel Hilbert spaces HK of functions from an input space into a Hilbert space Y , an environment appropriate for multi-task learning. The reproducing kernel K associated to HK has its values as operators on Y . Our primary goal here is to derive conditions which ensure that the kernel K is universal. This means that on every compact subset of the input space, every continuous function with values in Y can be uniformly approximated by sections of the kernel. We provide various characterizations of universal kernels and highlight them with several concrete examples of some practical importance. Our analysis uses basic principles of functional analysis and especially the useful notion of vector measures which we describe in sufﬁcient detail to clarify our results. Keywords: multi-task learning, multi-task kernels, universal approximation, vector-valued reproducing kernel Hilbert spaces</p><p>Reference: <a title="jmlr-2008-92-reference" href="../jmlr2008_reference/jmlr-2008-Universal_Multi-Task_Kernels_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nm', 0.416), ('kernel', 0.364), ('nn', 0.332), ('micchell', 0.275), ('aponnetto', 0.204), ('icchell', 0.204), ('ontil', 0.204), ('tq', 0.203), ('nivers', 0.191), ('pq', 0.155), ('hilbert', 0.129), ('compact', 0.129), ('tp', 0.109), ('riesz', 0.102), ('borel', 0.097), ('cj', 0.097), ('folland', 0.089), ('uhl', 0.089), ('rkhs', 0.087), ('rn', 0.081)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="92-tfidf-1" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>2 0.20333147 <a title="92-tfidf-2" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>3 0.17408478 <a title="92-tfidf-3" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>4 0.12185615 <a title="92-tfidf-4" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>5 0.10182324 <a title="92-tfidf-5" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>6 0.10181896 <a title="92-tfidf-6" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>7 0.093195148 <a title="92-tfidf-7" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>8 0.078501463 <a title="92-tfidf-8" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>9 0.073680267 <a title="92-tfidf-9" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>10 0.066206038 <a title="92-tfidf-10" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>11 0.058674276 <a title="92-tfidf-11" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>12 0.0537664 <a title="92-tfidf-12" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>13 0.052672885 <a title="92-tfidf-13" href="./jmlr-2008-A_New_Algorithm_for_Estimating_the_Effective_Dimension-Reduction_Subspace.html">5 jmlr-2008-A New Algorithm for Estimating the Effective Dimension-Reduction Subspace</a></p>
<p>14 0.049701866 <a title="92-tfidf-14" href="./jmlr-2008-Closed_Sets_for_Labeled_Data.html">22 jmlr-2008-Closed Sets for Labeled Data</a></p>
<p>15 0.044969723 <a title="92-tfidf-15" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>16 0.042892132 <a title="92-tfidf-16" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>17 0.042455923 <a title="92-tfidf-17" href="./jmlr-2008-Classification_with_a_Reject_Option_using_a_Hinge_Loss.html">21 jmlr-2008-Classification with a Reject Option using a Hinge Loss</a></p>
<p>18 0.040763713 <a title="92-tfidf-18" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>19 0.038299978 <a title="92-tfidf-19" href="./jmlr-2008-A_Moment_Bound_for_Multi-hinge_Classifiers.html">3 jmlr-2008-A Moment Bound for Multi-hinge Classifiers</a></p>
<p>20 0.037659999 <a title="92-tfidf-20" href="./jmlr-2008-Ranking_Individuals_by_Group_Comparisons.html">80 jmlr-2008-Ranking Individuals by Group Comparisons</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.238), (1, 0.165), (2, 0.166), (3, 0.046), (4, 0.251), (5, -0.237), (6, -0.138), (7, -0.037), (8, -0.075), (9, 0.079), (10, -0.016), (11, -0.052), (12, 0.026), (13, -0.049), (14, -0.006), (15, -0.042), (16, 0.004), (17, -0.039), (18, 0.088), (19, -0.059), (20, -0.101), (21, -0.041), (22, -0.037), (23, 0.085), (24, 0.079), (25, -0.019), (26, -0.086), (27, 0.136), (28, -0.219), (29, 0.122), (30, -0.083), (31, 0.118), (32, -0.046), (33, -0.0), (34, 0.061), (35, -0.016), (36, 0.18), (37, -0.028), (38, -0.107), (39, -0.1), (40, -0.006), (41, 0.071), (42, -0.051), (43, 0.065), (44, 0.168), (45, 0.062), (46, 0.057), (47, 0.084), (48, -0.047), (49, -0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9485333 <a title="92-lsi-1" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>2 0.73177606 <a title="92-lsi-2" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>3 0.63161415 <a title="92-lsi-3" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>4 0.62785739 <a title="92-lsi-4" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>5 0.54918867 <a title="92-lsi-5" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>6 0.49850348 <a title="92-lsi-6" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>7 0.44435656 <a title="92-lsi-7" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>8 0.36330453 <a title="92-lsi-8" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>9 0.35665751 <a title="92-lsi-9" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>10 0.33166564 <a title="92-lsi-10" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>11 0.31501886 <a title="92-lsi-11" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>12 0.26428381 <a title="92-lsi-12" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>13 0.24568023 <a title="92-lsi-13" href="./jmlr-2008-Classification_with_a_Reject_Option_using_a_Hinge_Loss.html">21 jmlr-2008-Classification with a Reject Option using a Hinge Loss</a></p>
<p>14 0.24478182 <a title="92-lsi-14" href="./jmlr-2008-Regularization_on_Graphs_with_Function-adapted_Diffusion_Processes.html">81 jmlr-2008-Regularization on Graphs with Function-adapted Diffusion Processes</a></p>
<p>15 0.23835902 <a title="92-lsi-15" href="./jmlr-2008-Model_Selection_in_Kernel_Based_Regression_using_the_Influence_Function%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">64 jmlr-2008-Model Selection in Kernel Based Regression using the Influence Function    (Special Topic on Model Selection)</a></p>
<p>16 0.23530975 <a title="92-lsi-16" href="./jmlr-2008-Closed_Sets_for_Labeled_Data.html">22 jmlr-2008-Closed Sets for Labeled Data</a></p>
<p>17 0.22320509 <a title="92-lsi-17" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>18 0.21757869 <a title="92-lsi-18" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>19 0.20838928 <a title="92-lsi-19" href="./jmlr-2008-Bouligand_Derivatives_and_Robustness_of_Support_Vector_Machines_for_Regression.html">19 jmlr-2008-Bouligand Derivatives and Robustness of Support Vector Machines for Regression</a></p>
<p>20 0.20612313 <a title="92-lsi-20" href="./jmlr-2008-On_the_Size_and_Recovery_of_Submatrices_of_Ones_in_a_Random_Binary_Matrix.html">72 jmlr-2008-On the Size and Recovery of Submatrices of Ones in a Random Binary Matrix</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.028), (4, 0.023), (6, 0.016), (10, 0.021), (11, 0.014), (25, 0.043), (26, 0.066), (32, 0.322), (53, 0.018), (59, 0.014), (66, 0.122), (73, 0.031), (86, 0.022), (89, 0.026), (91, 0.07), (96, 0.066), (99, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6439451 <a title="92-lda-1" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>2 0.46892932 <a title="92-lda-2" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>3 0.46284002 <a title="92-lda-3" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>4 0.45448637 <a title="92-lda-4" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<p>5 0.45425224 <a title="92-lda-5" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>6 0.45193851 <a title="92-lda-6" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>7 0.45089364 <a title="92-lda-7" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>8 0.44986385 <a title="92-lda-8" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>9 0.44979194 <a title="92-lda-9" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>10 0.44963005 <a title="92-lda-10" href="./jmlr-2008-Visualizing_Data_using_t-SNE.html">96 jmlr-2008-Visualizing Data using t-SNE</a></p>
<p>11 0.4491474 <a title="92-lda-11" href="./jmlr-2008-A_Moment_Bound_for_Multi-hinge_Classifiers.html">3 jmlr-2008-A Moment Bound for Multi-hinge Classifiers</a></p>
<p>12 0.44743949 <a title="92-lda-12" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>13 0.44648153 <a title="92-lda-13" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>14 0.44645306 <a title="92-lda-14" href="./jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</a></p>
<p>15 0.44545451 <a title="92-lda-15" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>16 0.44511312 <a title="92-lda-16" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>17 0.44321454 <a title="92-lda-17" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>18 0.44317898 <a title="92-lda-18" href="./jmlr-2008-Coordinate_Descent_Method_for_Large-scale_L2-loss_Linear_Support_Vector_Machines.html">28 jmlr-2008-Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines</a></p>
<p>19 0.44239545 <a title="92-lda-19" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>20 0.44198874 <a title="92-lda-20" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
