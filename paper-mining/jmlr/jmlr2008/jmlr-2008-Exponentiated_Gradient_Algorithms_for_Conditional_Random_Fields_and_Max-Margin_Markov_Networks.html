<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>34 jmlr-2008-Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-34" href="#">jmlr2008-34</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>34 jmlr-2008-Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks</h1>
<br/><p>Source: <a title="jmlr-2008-34-pdf" href="http://jmlr.org/papers/volume9/collins08a/collins08a.pdf">pdf</a></p><p>Author: Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, Peter L. Bartlett</p><p>Abstract: Log-linear and maximum-margin models are two commonly-used methods in supervised machine learning, and are frequently used in structured prediction problems. Efﬁcient learning of parameters in these models is therefore an important problem, and becomes a key factor when learning from very large data sets. This paper describes exponentiated gradient (EG) algorithms for training such models, where EG updates are applied to the convex dual of either the log-linear or maxmargin objective function; the dual in both the log-linear and max-margin cases corresponds to minimizing a convex function with simplex constraints. We study both batch and online variants of the algorithm, and provide rates of convergence for both cases. In the max-margin case, O( 1 ) EG ε updates are required to reach a given accuracy ε in the dual; in contrast, for log-linear models only O(log( 1 )) updates are required. For both the max-margin and log-linear cases, our bounds suggest ε that the online EG algorithm requires a factor of n less computation to reach a desired accuracy than the batch EG algorithm, where n is the number of training examples. Our experiments conﬁrm that the online algorithms are much faster than the batch algorithms in practice. We describe how the EG updates factor in a convenient way for structured prediction problems, allowing the algorithms to be efﬁciently applied to problems such as sequence learning or natural language parsing. We perform extensive evaluation of the algorithms, comparing them to L-BFGS and stochastic gradient descent for log-linear models, and to SVM-Struct for max-margin models. The algorithms are applied to a multi-class problem as well as to a more complex large-scale parsing task. In all these settings, the EG algorithms presented here outperform the other methods. Keywords: exponentiated gradient, log-linear models, maximum-margin models, structured prediction, conditional random ﬁelds ∗. These authors contributed equally. c 2008 Michael Col</p><p>Reference: <a title="jmlr-2008-34-reference" href="../jmlr2008_reference/jmlr-2008-Exponentiated_Gradient_Algorithms_for_Conditional_Random_Fields_and_Max-Margin_Markov_Networks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We study both batch and online variants of the algorithm, and provide rates of convergence for both cases. [sent-15, score-0.274]
</p><p>2 For both the max-margin and log-linear cases, our bounds suggest ε that the online EG algorithm requires a factor of n less computation to reach a desired accuracy than the batch EG algorithm, where n is the number of training examples. [sent-17, score-0.264]
</p><p>3 Our experiments conﬁrm that the online algorithms are much faster than the batch algorithms in practice. [sent-18, score-0.262]
</p><p>4 , un ) , (1) ∀i, ui ∈∆  where n is the number of training examples, each ui is a vector of dual variables for the i’th training example, and Q(u) is a convex function. [sent-43, score-0.393]
</p><p>5 In the batch case, the entire set of ui variables is updated simultaneously at each iteration of the algorithm; in the online case, a single ui variable is updated at each step. [sent-51, score-0.405]
</p><p>6 1776  E XPONENTIATED G RADIENT A LGORITHMS FOR CRF S AND M AX -M ARGIN M ARKOV N ETWORKS  improve the dual objective at each step, and this objective may be calculated after each example without performing a pass over the entire data set. [sent-64, score-0.299]
</p><p>7 Our key results are as follows: • For the max-margin case, we show that O( 1 ) time is required for both the online and batch ε algorithms to converge to within ε of the optimal value of Q(u). [sent-67, score-0.244]
</p><p>8 Our experiments conﬁrm that the online algorithms are much faster than the batch algorithms in practice. [sent-74, score-0.262]
</p><p>9 In this case the number of dual variables is also exponential in size, making algorithms which deal directly with the ui variables intractable. [sent-76, score-0.263]
</p><p>10 Section 3 describes the batch and online EG algorithms; in Section 4, we describe how the algorithms can be efﬁciently applied to structured prediction problems. [sent-92, score-0.276]
</p><p>11 Section 5 then gives convergence proofs for the batch and 1777  C OLLINS , G LOBERSON , KOO , C ARRERAS AND BARTLETT  online cases. [sent-93, score-0.244]
</p><p>12 We prove rates of convergence for a randomized version of the EG online algorithm; previous work on EG algorithms had not given convergence rates for the online case. [sent-104, score-0.415]
</p><p>13 (2007) ε gave O( 1 ) rates for the batch algorithm for log-linear models, and did not give any theoretical rates ε of convergence for the online case. [sent-108, score-0.32]
</p><p>14 This is a convex optimization problem, and has an equivalent convex dual which was derived by Lebanon and Lafferty (2002). [sent-138, score-0.221]
</p><p>15 The duality between P-LL and D-LL implies that the primal and dual solutions satisfy Cw∗ = w(u∗ ). [sent-158, score-0.336]
</p><p>16 3 The Max-Margin Dual When the loss is deﬁned using P-MM :  MM  (w, xi , yi ), the primal optimization problem is as follows:  w∗ = argmin ∑ max e(xi , yi , y) − w · (f(xi , yi ) − f(xi , y)) + w  i  y  C w 2  2  . [sent-160, score-0.251]
</p><p>17 We ﬁrst deﬁne the dual objective 1 QMM (u) = −bT u + uT Au . [sent-164, score-0.23]
</p><p>18 The optimal primal parameters are again related to the optimal dual parameters, through Cw∗ = w(u∗ ). [sent-171, score-0.3]
</p><p>19 Exponentiated Gradient Algorithms In this section we describe batch and online algorithms for minimizing a convex function Q(u) subject to the constraints u ∈ ∆n . [sent-176, score-0.257]
</p><p>20 For the dual function QLL (u) the gradient is 1 ∇i,y = 1 + log ui,y + w(u) · gi,y , C and for QMM (u) the gradient is 1 ∇i,y = −bi,y + w(u) · gi,y . [sent-187, score-0.276]
</p><p>21 C In this paper we will consider both parallel (batch), and sequential (online) applications of the EG updates, deﬁned as follows: • Batch: At every iteration the dual variables ui are simultaneously updated for all i = 1, . [sent-188, score-0.275]
</p><p>22 The dual variables ui for i = k are left unchanged. [sent-196, score-0.244]
</p><p>23 From here on we will refer to the batch and online EG algorithms applied to the log-linear dual as LLEG-Batch, and LLEG-Online respectively. [sent-198, score-0.388]
</p><p>24 The EG online algorithm is essentially performing coordinate descent on the dual objective, and is similar to SVM algorithms such as SMO (Platt, 1998). [sent-204, score-0.31]
</p><p>25 For binary classiﬁcation, the exact minimum of the dual objective with respect to a given coordinate can be found in closed form, 4 and more complicated algorithms such as the exponentiated-gradient method may be unnecessary. [sent-205, score-0.249]
</p><p>26 In Section 5 we give convergence proofs for the batch and online algorithms. [sent-209, score-0.244]
</p><p>27 We use ut to denote the set of parameters after t iterations. [sent-225, score-0.38]
</p><p>28 , n} – For all y, calculate: ∇kt ,y =  ∂Q(ut ) ∂ukt ,y  – For all y, update ut+1 ∝ utkt ,y e−η∇kt ,y kt ,y – For all i = kt , set ut+1 = uti i Output: Final parameters uT +1 . [sent-234, score-0.419]
</p><p>29 The si variables are used to implicitly deﬁne regular dual values ui = p(si ) where p : R|R| → ∆ is deﬁned as exp ∑r∈y sr py (s) = . [sent-273, score-0.304]
</p><p>30 ∑y exp ∑r∈y sr To see how the si variables can be updated, consider again the EG updates on the dual u variables. [sent-274, score-0.225]
</p><p>31 n as a replacement for the dual variables ui in Figure 2. [sent-307, score-0.244]
</p><p>32 Because of this result, all of the EG algorithms that we have presented can be restated in terms of the s variables: instead of maintaining a sequence ut = {ut1 , ut2 , . [sent-308, score-0.415]
</p><p>33 Convergence Results In this section, we provide convergence results for the EG batch and online algorithms presented in Section 3. [sent-330, score-0.263]
</p><p>34 The ﬁrst consequence of the two theorems above is that the batch and randomized online algorithms converge to a u with the optimal value Q(u∗ ). [sent-361, score-0.318]
</p><p>35 The second consequence is that for a given ε > 0 we can ﬁnd the number of iterations needed to reach a u such that |Q(u) − Q(u∗ )| ≤ ε for the batch algorithm or E [|Q(u) − Q(u∗ )|] ≤ ε for the online algorithm. [sent-363, score-0.27]
</p><p>36 Crucially, note that these rates suggest that the online algorithms are signiﬁcantly more efﬁcient than the batch algorithms; speciﬁcally, the bounds suggest that the online algorithms require a factor of n less computation in both the QLL and QMM cases. [sent-366, score-0.371]
</p><p>37 Thus these results suggest that the randomized online algorithm should converge much faster than the batch algorithm. [sent-367, score-0.331]
</p><p>38 This prediction is conﬁrmed in our empirical evaluations, which show that the online algorithm is far more efﬁcient than the batch algorithm. [sent-369, score-0.224]
</p><p>39 3 Dual Improvement and Bregman Divergence In this section we provide a useful lemma that determines when the EG updates in the batch algorithm will result in monotone improvement of Q(u). [sent-393, score-0.237]
</p><p>40 The next lemma states that if Q(u) is τ-upper-bounded, then the change in the objective as a result of an EG update can be related to the KL divergence between consecutive values of the dual variables. [sent-397, score-0.345]
</p><p>41 η  Proof: Given a ut , the EG update is ut+1 = i,y where ∇ti,y =  ∂Q(ut ) , ∂ui,y  1 t −η∇ti,y u e , Zit i,y Zit = ∑ uti,y e−η∇i,y . [sent-399, score-0.401]
</p><p>42 i i i,y i,y  Equivalently, using the notation for KL divergence between multiple distributions: D[ut ut+1 ] + D[ut+1 ut ] = η(ut − ut+1 ) · ∇Q(ut ) . [sent-401, score-0.434]
</p><p>43 The deﬁnition of the Bregman divergence BQ then implies −ηBQ [ut+1 ut ] + D[ut ut+1 ] + D[ut+1 ut ] = η(Q(ut ) − Q(ut+1 )) . [sent-402, score-0.814]
</p><p>44 (8)  Since Q(u) is τ-upper-bounded and η ≤ 1 it follows that D[ut+1 ut ] ≥ ηBQ [ut+1 ut ], and together τ with Eq. [sent-403, score-0.76]
</p><p>45 5 Convergence Results for the Randomized Online Algorithm This section analyzes the rate of convergence of the randomized online algorithm in Figure 2. [sent-451, score-0.245]
</p><p>46 (2006) present an O( 1 ) rate, but where accuracy is measured in the primal or via ε the duality gap, and not in the dual as in our analysis. [sent-526, score-0.358]
</p><p>47 In contrast, stochastic gradient methods directly optimize the primal problem, and at each update use a single example to approximate the gradient (or subgradient) of the primal objective function. [sent-535, score-0.456]
</p><p>48 , 1995), which is a batch gradient descent method, and to stochastic gradient descent. [sent-540, score-0.22]
</p><p>49 We also report experiments comparing the randomized online algorithm to a deterministic online EG algorithm, where samples are drawn in a ﬁxed order (e. [sent-543, score-0.28]
</p><p>50 It is important that when updating a single example using the online algorithms, the improvement (or decrease) in the dual can be easily evaluated, allowing the halving strategy described in the previous paragraph to be implemented efﬁciently. [sent-559, score-0.272]
</p><p>51 If the current dual parameters are u, the i’th coordinate is selected, and the EG updates then map ui to ui , the change in the dual objective is 1 ∑ ui,y log ui,y + 2C w(u) + ∑ ui,y − ui,y gi,y y y  2  − ∑ ui,y log ui,y − y  1 w(u) 2C  2  . [sent-560, score-0.658]
</p><p>52 The primal parameters w(u) are maintained throughout the algorithm (see Figure 3), so that this change in the dual objective can be calculated efﬁciently. [sent-561, score-0.385]
</p><p>53 A similar method can be used to calculate the change in the dual objective in the max-margin case. [sent-562, score-0.23]
</p><p>54 We measure the performance of each training algorithm (the EG algorithms, as well as the batch gradient and stochastic gradient methods) as a function of the amount of computation spent. [sent-563, score-0.235]
</p><p>55 Figure 5 shows plots of the primal and dual objective functions for different values of C. [sent-601, score-0.369]
</p><p>56 Note that EG does not explicitly minimize the primal objective function, so the EG primal will not necessarily decrease at every iteration. [sent-603, score-0.347]
</p><p>57 Figure 6 shows how the duality gap decreases with the amount of computation spent (the duality gap is the difference between the primal and dual values at each iteration). [sent-605, score-0.426]
</p><p>58 Figure 7 shows the primal and dual objectives for both algorithms. [sent-608, score-0.3]
</p><p>59 The rate results presented in this paper are for dual accuracy, but it is straightforward to obtain an O(log( 1 )) for the ε duality gap in the log-linear case. [sent-627, score-0.248]
</p><p>60 We then optimize C using the randomized online algorithm, until the duality gap is less than ε × p, where p is the primal value. [sent-652, score-0.371]
</p><p>61 It is crucial that each time we decrease C, we take our initial dual values to be the ﬁnal dual values resulting from optimization for the previous value of C. [sent-656, score-0.322]
</p><p>62 Iteration  Figure 5: Primal and dual objective values on the MNIST learning task for log-linear models trained using the EG randomized online algorithm. [sent-670, score-0.399]
</p><p>63 The dual values have been negated so that the primal and dual problems have the same optimal value. [sent-671, score-0.461]
</p><p>64 The Y axis shows the value of the primal or dual objective functions. [sent-673, score-0.389]
</p><p>65 In all cases the primal and dual objectives converge to the same value, with faster convergence for larger values of C. [sent-675, score-0.369]
</p><p>66 3 C OMPARISONS TO S TOCHASTIC G RADIENT D ESCENT This section compares performance of the EG algorithms to stochastic gradient descent (SGD) on the primal objective. [sent-693, score-0.221]
</p><p>67 Iteration  Figure 6: Graph showing the duality gap on the MNIST learning task for log-linear models trained using the EG randomized online algorithm. [sent-795, score-0.232]
</p><p>68 can be thought of as an estimate of the gradient of the primal objective function for the entire training set. [sent-798, score-0.27]
</p><p>69 The left ﬁgure shows primal and dual objective values for both algorithms. [sent-830, score-0.369]
</p><p>70 The right ﬁgure shows the normalized value of the duality gap: (primal(t) − dual(t))/opt, where opt is the value of the joint optimum of the primal and dual problems, and t is the iteration number. [sent-831, score-0.367]
</p><p>71 The left ﬁgure shows primal objective values calculated for C = 1; the right ﬁgure shows validation error. [sent-848, score-0.244]
</p><p>72 L-BFGS is a batch algorithm, in the sense that its updates require evaluating the primal objective and gradient, which involves iterating over the entire data-set. [sent-876, score-0.368]
</p><p>73 In this case, the EG line search will be somewhat more costly, since the dual objective requires evaluations of both marginals and partition function, whereas the primal objective only requires the partition function. [sent-893, score-0.474]
</p><p>74 Iteration  Figure 10: Graphs showing primal objective values on the MNIST learning task, comparing the EG randomized algorithm to stochastic gradient descent (SGD). [sent-931, score-0.361]
</p><p>75 01 was the best-performing learning rate after one iteration for both validation error and primal objective, however a post-hoc analysis shows that η0 = 0. [sent-940, score-0.23]
</p><p>76 in fact does not successfully optimize the primal objective for low values of C, and for higher values of C the SGD primal objective is slower to converge. [sent-1114, score-0.416]
</p><p>77 Figure 13 shows results in terms of primal and dual objective and in terms of accuracy. [sent-1168, score-0.369]
</p><p>78 Although the algorithms have both batch and online variants, the online version turns out to be much more effective, both in theory and in practice. [sent-1173, score-0.322]
</p><p>79 1) suggest that the online algorithm requires a factor of n less iterations to achieve a desired accuracy ε in the dual objective. [sent-1175, score-0.34]
</p><p>80 This factor results from the fact that the online algorithm can use a learning rate η that is n times larger than the batch case to obtain updates that decrease the dual objective. [sent-1176, score-0.456]
</p><p>81 The dual objective has a term uT Au which involves all the ui variables and second order interactions between them. [sent-1178, score-0.313]
</p><p>82 It turns out that for batch updates only a relatively small change in the u i is allowed, if one still requires an improvement in the dual objective after the update. [sent-1179, score-0.39]
</p><p>83 It is possible that our bounds for the batch convergence rate are more conservative than those for the online case. [sent-1180, score-0.268]
</p><p>84 Our convergence rates are with respect to accuracy in the dual objective. [sent-1197, score-0.249]
</p><p>85 1810  (9)  E XPONENTIATED G RADIENT A LGORITHMS FOR CRF S AND M AX -M ARGIN M ARKOV N ETWORKS  Proof: By the deﬁnition of Bregman divergence, we have ηQ(ut ) − ηQ(z) = −η∇Q(ut ) · (z − ut ) − ηBQ [z ut ] . [sent-1235, score-0.76]
</p><p>86 (10)  Given that ut+1 is derived from ut using EG updates, ut+1 i,y  =  uti,y e−η∇i,y Zit  where Zit is a normalization constant, and ∇i,y = D[z ut ] − D[z ut+1 ] + D[ut ut+1 ] =  ∂Q(ut ) ∂ui,y . [sent-1236, score-0.76]
</p><p>87 ∑  =  uti,y zi,y zi,y − zi,y log t+1 + uti,y log t+1 uti,y ui,y ui,y  ∑(zi,y − uti,y ) log i,y  =  Simple algebra then shows that:  zi,y log  i,y  ,  ut+1 i,y uti,y  ∑(zi,y − uti,y )(−η∇i,y − log Zit ) i,y  =  ∑(zi,y − uti,y )(−η∇i,y ) i,y  = −η∇Q(ut ) · (z − ut ) . [sent-1237, score-0.515]
</p><p>88 We can now prove Lemma 5: Proof of Lemma 5: Using −ηBQ [z ut ] ≤ 0, Lemma 10 implies that for all t ηQ(ut ) − ηQ(z) ≤ D[z ut ] − D[z ut+1 ] + D[ut ut+1 ] . [sent-1243, score-0.76]
</p><p>89 12 and 13 gives for all t ηQ(ut+1 ) − ηQ(z) ≤ D[z ut ] − D[z ut+1 ] . [sent-1246, score-0.38]
</p><p>90 η Combining this result with Lemma 10 gives ηQ(ut+1 ) − ηQ(z) ≤ D[z ut ] − D[z ut+1 ] − ηBQ [z ut ] . [sent-1256, score-0.76]
</p><p>91 We can now make use of the assumption that Q(u) is (µ, τ)-bounded, and hence ηB Q [z ut ] ≥ ηµD[z ut ], to obtain ηQ(ut+1 ) − ηQ(z) ≤ D[z ut ] − D[z ut+1 ] − ηµD[z ut ] = (1 − ηµ) D[z ut ] − D[z ut+1 ] ≤ (1 − ηµ) D[z ut ] . [sent-1257, score-2.28]
</p><p>92 Otherwise, it must be the case that Q(ut+1 ) − Q(z) ≥ 0 for all t ≤ T , and thus for all t ≤ T D[z ut+1 ] ≤ (1 − ηµ) D[z ut ] . [sent-1259, score-0.38]
</p><p>93 We will use the following deﬁnitions: 0 • We use kt to denote a sequence of indices k1 , k2 , . [sent-1281, score-0.215]
</p><p>94 T • Finally, for any choice of index sequence k1 we will deﬁne a sequence of dual variables using the following iterative deﬁnition: 0 u(k1 ) = u1  u(kt ) = r(u(kt−1 ), kt ) for t ≥ 1 . [sent-1291, score-0.392]
</p><p>95 For any i, we have D[zi ui ] − D[zi ri (u, i)]  ∑  = D[zi ui ] − D[zi ri (u, i)] + = D[zi ui ] − D[zi ri (u, i)] +  ∑  ∑  D[z j u j ] − D[z j u j ] −  D[z j u j ]  (16)  ∑  D[z j r j (u, i)]  (17)  j=1. [sent-1305, score-0.33]
</p><p>96 Note that the timing of the EG experiments includes the time required to convert the dual parameters to the primal representation. [sent-1408, score-0.317]
</p><p>97 Both SGD and EG share the following operations: (a) inner products between the feature vectors and the primal vector, (b) computation of part-wise marginals, and (c) addition of scaled feature vectors to the primal vector. [sent-1411, score-0.278]
</p><p>98 In the EG algorithm, we require two additional loops over R(x i ) in order to update the dual variables and compute the dual entropy term. [sent-1412, score-0.343]
</p><p>99 δ = 2C wt+1 2 − Hit+1 − ( 2C wt 2 − Hit )  Figure 16: Pseudocode for the updates performed in SGD and online EG for structured log-linear models (note that denotes a comment). [sent-1459, score-0.231]
</p><p>100 In EG, we maintain dual vectors sti , marginals µti , entropy values Hit , and a vector wt = w(ut ). [sent-1460, score-0.278]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('eg', 0.586), ('ut', 0.38), ('sgd', 0.31), ('kt', 0.199), ('dual', 0.161), ('qll', 0.16), ('qmm', 0.145), ('primal', 0.139), ('koo', 0.126), ('arreras', 0.124), ('loberson', 0.124), ('ollins', 0.124), ('argin', 0.119), ('xponentiated', 0.119), ('batch', 0.113), ('bq', 0.109), ('lgorithms', 0.101), ('online', 0.095), ('radient', 0.094), ('arkov', 0.09), ('crf', 0.087), ('ui', 0.083), ('randomized', 0.074), ('etworks', 0.072), ('objective', 0.069), ('ax', 0.065), ('nq', 0.062), ('parsing', 0.061), ('bartlett', 0.055), ('bregman', 0.054), ('divergence', 0.054), ('structured', 0.049), ('updates', 0.047), ('zit', 0.047), ('iterations', 0.046), ('mnist', 0.044), ('gradient', 0.044), ('py', 0.043), ('byrd', 0.041), ('sti', 0.041), ('wt', 0.04), ('lemma', 0.04), ('exponentiated', 0.039), ('kivinen', 0.039), ('validation', 0.036), ('duality', 0.036), ('convergence', 0.036), ('marginals', 0.036), ('globerson', 0.032), ('taskar', 0.032), ('iteration', 0.031), ('carreras', 0.031), ('classification', 0.031), ('endfor', 0.031), ('st', 0.03), ('rates', 0.03), ('zi', 0.03), ('convex', 0.03), ('annealed', 0.029), ('yi', 0.029), ('mm', 0.028), ('ri', 0.027), ('gap', 0.027), ('log', 0.027), ('sentences', 0.026), ('xi', 0.025), ('ll', 0.025), ('crfs', 0.025), ('dependency', 0.024), ('rate', 0.024), ('accuracy', 0.022), ('warmuth', 0.022), ('monotone', 0.021), ('bqll', 0.021), ('csail', 0.021), ('duals', 0.021), ('stkt', 0.021), ('yv', 0.021), ('update', 0.021), ('regularized', 0.02), ('axis', 0.02), ('labels', 0.02), ('gure', 0.02), ('kl', 0.02), ('descent', 0.019), ('language', 0.019), ('algorithms', 0.019), ('training', 0.018), ('sha', 0.018), ('hit', 0.018), ('converge', 0.017), ('effective', 0.017), ('cpu', 0.017), ('timing', 0.017), ('linguistics', 0.017), ('si', 0.017), ('algorithm', 0.016), ('strategy', 0.016), ('sequence', 0.016), ('faster', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="34-tfidf-1" href="./jmlr-2008-Exponentiated_Gradient_Algorithms_for_Conditional_Random_Fields_and_Max-Margin_Markov_Networks.html">34 jmlr-2008-Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks</a></p>
<p>Author: Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, Peter L. Bartlett</p><p>Abstract: Log-linear and maximum-margin models are two commonly-used methods in supervised machine learning, and are frequently used in structured prediction problems. Efﬁcient learning of parameters in these models is therefore an important problem, and becomes a key factor when learning from very large data sets. This paper describes exponentiated gradient (EG) algorithms for training such models, where EG updates are applied to the convex dual of either the log-linear or maxmargin objective function; the dual in both the log-linear and max-margin cases corresponds to minimizing a convex function with simplex constraints. We study both batch and online variants of the algorithm, and provide rates of convergence for both cases. In the max-margin case, O( 1 ) EG ε updates are required to reach a given accuracy ε in the dual; in contrast, for log-linear models only O(log( 1 )) updates are required. For both the max-margin and log-linear cases, our bounds suggest ε that the online EG algorithm requires a factor of n less computation to reach a desired accuracy than the batch EG algorithm, where n is the number of training examples. Our experiments conﬁrm that the online algorithms are much faster than the batch algorithms in practice. We describe how the EG updates factor in a convenient way for structured prediction problems, allowing the algorithms to be efﬁciently applied to problems such as sequence learning or natural language parsing. We perform extensive evaluation of the algorithms, comparing them to L-BFGS and stochastic gradient descent for log-linear models, and to SVM-Struct for max-margin models. The algorithms are applied to a multi-class problem as well as to a more complex large-scale parsing task. In all these settings, the EG algorithms presented here outperform the other methods. Keywords: exponentiated gradient, log-linear models, maximum-margin models, structured prediction, conditional random ﬁelds ∗. These authors contributed equally. c 2008 Michael Col</p><p>2 0.1163381 <a title="34-tfidf-2" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>Author: Yonatan Amit, Shai Shalev-Shwartz, Yoram Singer</p><p>Abstract: We describe and analyze an algorithmic framework for online classiﬁcation where each online trial consists of multiple prediction tasks that are tied together. We tackle the problem of updating the online predictor by deﬁning a projection problem in which each prediction task corresponds to a single linear constraint. These constraints are tied together through a single slack parameter. We then introduce a general method for approximately solving the problem by projecting simultaneously and independently on each constraint which corresponds to a prediction sub-problem, and then averaging the individual solutions. We show that this approach constitutes a feasible, albeit not necessarily optimal, solution of the original projection problem. We derive concrete simultaneous projection schemes and analyze them in the mistake bound model. We demonstrate the power of the proposed algorithm in experiments with synthetic data and with multiclass text categorization tasks. Keywords: online learning, parallel computation, mistake bounds, structured prediction</p><p>3 0.078880154 <a title="34-tfidf-3" href="./jmlr-2008-Randomized_Online_PCA_Algorithms_with_Regret_Bounds_that_are_Logarithmic_in_the_Dimension.html">78 jmlr-2008-Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension</a></p>
<p>Author: Manfred K. Warmuth, Dima Kuzmin</p><p>Abstract: We design an online algorithm for Principal Component Analysis. In each trial the current instance is centered and projected into a probabilistically chosen low dimensional subspace. The regret of our online algorithm, that is, the total expected quadratic compression loss of the online algorithm minus the total quadratic compression loss of the batch algorithm, is bounded by a term whose dependence on the dimension of the instances is only logarithmic. We ﬁrst develop our methodology in the expert setting of online learning by giving an algorithm for learning as well as the best subset of experts of a certain size. This algorithm is then lifted to the matrix setting where the subsets of experts correspond to subspaces. The algorithm represents the uncertainty over the best subspace as a density matrix whose eigenvalues are bounded. The running time is O(n2 ) per trial, where n is the dimension of the instances. Keywords: principal component analysis, online learning, density matrix, expert setting, quantum Bayes rule</p><p>4 0.074800909 <a title="34-tfidf-4" href="./jmlr-2008-Algorithms_for_Sparse_Linear_Classifiers_in_the_Massive_Data_Setting.html">12 jmlr-2008-Algorithms for Sparse Linear Classifiers in the Massive Data Setting</a></p>
<p>Author: Suhrid Balakrishnan, David Madigan</p><p>Abstract: Classiﬁers favoring sparse solutions, such as support vector machines, relevance vector machines, LASSO-regression based classiﬁers, etc., provide competitive methods for classiﬁcation problems in high dimensions. However, current algorithms for training sparse classiﬁers typically scale quite unfavorably with respect to the number of training examples. This paper proposes online and multipass algorithms for training sparse linear classiﬁers for high dimensional data. These algorithms have computational complexity and memory requirements that make learning on massive data sets feasible. The central idea that makes this possible is a straightforward quadratic approximation to the likelihood function. Keywords: Laplace approximation, expectation propagation, LASSO</p><p>5 0.069995798 <a title="34-tfidf-5" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>Author: Balázs Csanád Csáji, László Monostori</p><p>Abstract: The paper investigates the possibility of applying value function based reinforcement learning (RL) methods in cases when the environment may change over time. First, theorems are presented which show that the optimal value function of a discounted Markov decision process (MDP) Lipschitz continuously depends on the immediate-cost function and the transition-probability function. Dependence on the discount factor is also analyzed and shown to be non-Lipschitz. Afterwards, the concept of (ε, δ)-MDPs is introduced, which is a generalization of MDPs and ε-MDPs. In this model the environment may change over time, more precisely, the transition function and the cost function may vary from time to time, but the changes must be bounded in the limit. Then, learning algorithms in changing environments are analyzed. A general relaxed convergence theorem for stochastic iterative algorithms is presented. We also demonstrate the results through three classical RL methods: asynchronous value iteration, Q-learning and temporal difference learning. Finally, some numerical experiments concerning changing environments are presented. Keywords: Markov decision processes, reinforcement learning, changing environments, (ε, δ)MDPs, value function bounds, stochastic iterative algorithms</p><p>6 0.062918536 <a title="34-tfidf-6" href="./jmlr-2008-Gradient_Tree_Boosting_for_Training_Conditional_Random_Fields.html">39 jmlr-2008-Gradient Tree Boosting for Training Conditional Random Fields</a></p>
<p>7 0.059210543 <a title="34-tfidf-7" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>8 0.042102832 <a title="34-tfidf-8" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>9 0.041356325 <a title="34-tfidf-9" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>10 0.041239135 <a title="34-tfidf-10" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>11 0.041218121 <a title="34-tfidf-11" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>12 0.039249685 <a title="34-tfidf-12" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>13 0.038904931 <a title="34-tfidf-13" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>14 0.037184525 <a title="34-tfidf-14" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>15 0.036471568 <a title="34-tfidf-15" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>16 0.036420785 <a title="34-tfidf-16" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>17 0.03615943 <a title="34-tfidf-17" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<p>18 0.034373932 <a title="34-tfidf-18" href="./jmlr-2008-Trust_Region_Newton_Method_for_Logistic_Regression.html">91 jmlr-2008-Trust Region Newton Method for Logistic Regression</a></p>
<p>19 0.033067964 <a title="34-tfidf-19" href="./jmlr-2008-Coordinate_Descent_Method_for_Large-scale_L2-loss_Linear_Support_Vector_Machines.html">28 jmlr-2008-Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines</a></p>
<p>20 0.03198481 <a title="34-tfidf-20" href="./jmlr-2008-Nearly_Uniform_Validation_Improves_Compression-Based_Error_Bounds.html">68 jmlr-2008-Nearly Uniform Validation Improves Compression-Based Error Bounds</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.171), (1, -0.059), (2, -0.011), (3, 0.083), (4, -0.076), (5, -0.067), (6, -0.036), (7, 0.048), (8, -0.188), (9, -0.156), (10, -0.084), (11, -0.145), (12, -0.064), (13, 0.002), (14, -0.174), (15, 0.041), (16, -0.165), (17, -0.016), (18, 0.198), (19, 0.03), (20, -0.033), (21, -0.002), (22, -0.034), (23, 0.113), (24, -0.045), (25, -0.106), (26, -0.226), (27, 0.213), (28, 0.039), (29, -0.223), (30, -0.174), (31, 0.013), (32, -0.022), (33, -0.116), (34, 0.037), (35, 0.122), (36, 0.003), (37, 0.098), (38, -0.119), (39, -0.053), (40, 0.025), (41, 0.024), (42, 0.026), (43, 0.05), (44, 0.129), (45, -0.032), (46, -0.05), (47, 0.052), (48, -0.009), (49, -0.247)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9519757 <a title="34-lsi-1" href="./jmlr-2008-Exponentiated_Gradient_Algorithms_for_Conditional_Random_Fields_and_Max-Margin_Markov_Networks.html">34 jmlr-2008-Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks</a></p>
<p>Author: Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, Peter L. Bartlett</p><p>Abstract: Log-linear and maximum-margin models are two commonly-used methods in supervised machine learning, and are frequently used in structured prediction problems. Efﬁcient learning of parameters in these models is therefore an important problem, and becomes a key factor when learning from very large data sets. This paper describes exponentiated gradient (EG) algorithms for training such models, where EG updates are applied to the convex dual of either the log-linear or maxmargin objective function; the dual in both the log-linear and max-margin cases corresponds to minimizing a convex function with simplex constraints. We study both batch and online variants of the algorithm, and provide rates of convergence for both cases. In the max-margin case, O( 1 ) EG ε updates are required to reach a given accuracy ε in the dual; in contrast, for log-linear models only O(log( 1 )) updates are required. For both the max-margin and log-linear cases, our bounds suggest ε that the online EG algorithm requires a factor of n less computation to reach a desired accuracy than the batch EG algorithm, where n is the number of training examples. Our experiments conﬁrm that the online algorithms are much faster than the batch algorithms in practice. We describe how the EG updates factor in a convenient way for structured prediction problems, allowing the algorithms to be efﬁciently applied to problems such as sequence learning or natural language parsing. We perform extensive evaluation of the algorithms, comparing them to L-BFGS and stochastic gradient descent for log-linear models, and to SVM-Struct for max-margin models. The algorithms are applied to a multi-class problem as well as to a more complex large-scale parsing task. In all these settings, the EG algorithms presented here outperform the other methods. Keywords: exponentiated gradient, log-linear models, maximum-margin models, structured prediction, conditional random ﬁelds ∗. These authors contributed equally. c 2008 Michael Col</p><p>2 0.69441348 <a title="34-lsi-2" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>Author: Yonatan Amit, Shai Shalev-Shwartz, Yoram Singer</p><p>Abstract: We describe and analyze an algorithmic framework for online classiﬁcation where each online trial consists of multiple prediction tasks that are tied together. We tackle the problem of updating the online predictor by deﬁning a projection problem in which each prediction task corresponds to a single linear constraint. These constraints are tied together through a single slack parameter. We then introduce a general method for approximately solving the problem by projecting simultaneously and independently on each constraint which corresponds to a prediction sub-problem, and then averaging the individual solutions. We show that this approach constitutes a feasible, albeit not necessarily optimal, solution of the original projection problem. We derive concrete simultaneous projection schemes and analyze them in the mistake bound model. We demonstrate the power of the proposed algorithm in experiments with synthetic data and with multiclass text categorization tasks. Keywords: online learning, parallel computation, mistake bounds, structured prediction</p><p>3 0.3013978 <a title="34-lsi-3" href="./jmlr-2008-Algorithms_for_Sparse_Linear_Classifiers_in_the_Massive_Data_Setting.html">12 jmlr-2008-Algorithms for Sparse Linear Classifiers in the Massive Data Setting</a></p>
<p>Author: Suhrid Balakrishnan, David Madigan</p><p>Abstract: Classiﬁers favoring sparse solutions, such as support vector machines, relevance vector machines, LASSO-regression based classiﬁers, etc., provide competitive methods for classiﬁcation problems in high dimensions. However, current algorithms for training sparse classiﬁers typically scale quite unfavorably with respect to the number of training examples. This paper proposes online and multipass algorithms for training sparse linear classiﬁers for high dimensional data. These algorithms have computational complexity and memory requirements that make learning on massive data sets feasible. The central idea that makes this possible is a straightforward quadratic approximation to the likelihood function. Keywords: Laplace approximation, expectation propagation, LASSO</p><p>4 0.27335826 <a title="34-lsi-4" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Stefan Klanke, Sethu Vijayakumar, Stefan Schaal</p><p>Abstract: In this paper we introduce an improved implementation of locally weighted projection regression (LWPR), a supervised learning algorithm that is capable of handling high-dimensional input data. As the key features, our code supports multi-threading, is available for multiple platforms, and provides wrappers for several programming languages. Keywords: regression, local learning, online learning, C, C++, Matlab, Octave, Python</p><p>5 0.26235333 <a title="34-lsi-5" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>Author: Balázs Csanád Csáji, László Monostori</p><p>Abstract: The paper investigates the possibility of applying value function based reinforcement learning (RL) methods in cases when the environment may change over time. First, theorems are presented which show that the optimal value function of a discounted Markov decision process (MDP) Lipschitz continuously depends on the immediate-cost function and the transition-probability function. Dependence on the discount factor is also analyzed and shown to be non-Lipschitz. Afterwards, the concept of (ε, δ)-MDPs is introduced, which is a generalization of MDPs and ε-MDPs. In this model the environment may change over time, more precisely, the transition function and the cost function may vary from time to time, but the changes must be bounded in the limit. Then, learning algorithms in changing environments are analyzed. A general relaxed convergence theorem for stochastic iterative algorithms is presented. We also demonstrate the results through three classical RL methods: asynchronous value iteration, Q-learning and temporal difference learning. Finally, some numerical experiments concerning changing environments are presented. Keywords: Markov decision processes, reinforcement learning, changing environments, (ε, δ)MDPs, value function bounds, stochastic iterative algorithms</p><p>6 0.2601546 <a title="34-lsi-6" href="./jmlr-2008-Randomized_Online_PCA_Algorithms_with_Regret_Bounds_that_are_Logarithmic_in_the_Dimension.html">78 jmlr-2008-Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension</a></p>
<p>7 0.21292537 <a title="34-lsi-7" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>8 0.20746864 <a title="34-lsi-8" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>9 0.20234959 <a title="34-lsi-9" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>10 0.19666474 <a title="34-lsi-10" href="./jmlr-2008-Gradient_Tree_Boosting_for_Training_Conditional_Random_Fields.html">39 jmlr-2008-Gradient Tree Boosting for Training Conditional Random Fields</a></p>
<p>11 0.18780203 <a title="34-lsi-11" href="./jmlr-2008-Classification_with_a_Reject_Option_using_a_Hinge_Loss.html">21 jmlr-2008-Classification with a Reject Option using a Hinge Loss</a></p>
<p>12 0.17442799 <a title="34-lsi-12" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>13 0.17171565 <a title="34-lsi-13" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>14 0.17144617 <a title="34-lsi-14" href="./jmlr-2008-HPB%3A_A_Model_for_Handling_BN_Nodes_with_High_Cardinality_Parents.html">42 jmlr-2008-HPB: A Model for Handling BN Nodes with High Cardinality Parents</a></p>
<p>15 0.1604079 <a title="34-lsi-15" href="./jmlr-2008-Manifold_Learning%3A_The_Price_of_Normalization.html">57 jmlr-2008-Manifold Learning: The Price of Normalization</a></p>
<p>16 0.15928823 <a title="34-lsi-16" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>17 0.15210252 <a title="34-lsi-17" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>18 0.14437942 <a title="34-lsi-18" href="./jmlr-2008-Optimization_Techniques_for_Semi-Supervised_Support_Vector_Machines.html">76 jmlr-2008-Optimization Techniques for Semi-Supervised Support Vector Machines</a></p>
<p>19 0.14282002 <a title="34-lsi-19" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>20 0.13980711 <a title="34-lsi-20" href="./jmlr-2008-Using_Markov_Blankets_for_Causal_Structure_Learning%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">93 jmlr-2008-Using Markov Blankets for Causal Structure Learning    (Special Topic on Causality)</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.021), (5, 0.024), (31, 0.011), (40, 0.04), (54, 0.084), (58, 0.049), (66, 0.041), (76, 0.026), (87, 0.35), (88, 0.066), (91, 0.015), (92, 0.046), (94, 0.095), (99, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89386213 <a title="34-lda-1" href="./jmlr-2008-Active_Learning_of_Causal_Networks_with_Intervention_Experiments_and_Optimal_Designs%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">10 jmlr-2008-Active Learning of Causal Networks with Intervention Experiments and Optimal Designs    (Special Topic on Causality)</a></p>
<p>Author: Yang-Bo He, Zhi Geng</p><p>Abstract: The causal discovery from data is important for various scientiﬁc investigations. Because we cannot distinguish the different directed acyclic graphs (DAGs) in a Markov equivalence class learned from observational data, we have to collect further information on causal structures from experiments with external interventions. In this paper, we propose an active learning approach for discovering causal structures in which we ﬁrst ﬁnd a Markov equivalence class from observational data, and then we orient undirected edges in every chain component via intervention experiments separately. In the experiments, some variables are manipulated through external interventions. We discuss two kinds of intervention experiments, randomized experiment and quasi-experiment. Furthermore, we give two optimal designs of experiments, a batch-intervention design and a sequential-intervention design, to minimize the number of manipulated variables and the set of candidate structures based on the minimax and the maximum entropy criteria. We show theoretically that structural learning can be done locally in subgraphs of chain components without need of checking illegal v-structures and cycles in the whole network and that a Markov equivalence subclass obtained after each intervention can still be depicted as a chain graph. Keywords: active learning, causal networks, directed acyclic graphs, intervention, Markov equivalence class, optimal design, structural learning</p><p>same-paper 2 0.7424019 <a title="34-lda-2" href="./jmlr-2008-Exponentiated_Gradient_Algorithms_for_Conditional_Random_Fields_and_Max-Margin_Markov_Networks.html">34 jmlr-2008-Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks</a></p>
<p>Author: Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, Peter L. Bartlett</p><p>Abstract: Log-linear and maximum-margin models are two commonly-used methods in supervised machine learning, and are frequently used in structured prediction problems. Efﬁcient learning of parameters in these models is therefore an important problem, and becomes a key factor when learning from very large data sets. This paper describes exponentiated gradient (EG) algorithms for training such models, where EG updates are applied to the convex dual of either the log-linear or maxmargin objective function; the dual in both the log-linear and max-margin cases corresponds to minimizing a convex function with simplex constraints. We study both batch and online variants of the algorithm, and provide rates of convergence for both cases. In the max-margin case, O( 1 ) EG ε updates are required to reach a given accuracy ε in the dual; in contrast, for log-linear models only O(log( 1 )) updates are required. For both the max-margin and log-linear cases, our bounds suggest ε that the online EG algorithm requires a factor of n less computation to reach a desired accuracy than the batch EG algorithm, where n is the number of training examples. Our experiments conﬁrm that the online algorithms are much faster than the batch algorithms in practice. We describe how the EG updates factor in a convenient way for structured prediction problems, allowing the algorithms to be efﬁciently applied to problems such as sequence learning or natural language parsing. We perform extensive evaluation of the algorithms, comparing them to L-BFGS and stochastic gradient descent for log-linear models, and to SVM-Struct for max-margin models. The algorithms are applied to a multi-class problem as well as to a more complex large-scale parsing task. In all these settings, the EG algorithms presented here outperform the other methods. Keywords: exponentiated gradient, log-linear models, maximum-margin models, structured prediction, conditional random ﬁelds ∗. These authors contributed equally. c 2008 Michael Col</p><p>3 0.43263093 <a title="34-lda-3" href="./jmlr-2008-Causal_Reasoning_with_Ancestral_Graphs%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">20 jmlr-2008-Causal Reasoning with Ancestral Graphs    (Special Topic on Causality)</a></p>
<p>Author: Jiji Zhang</p><p>Abstract: Causal reasoning is primarily concerned with what would happen to a system under external interventions. In particular, we are often interested in predicting the probability distribution of some random variables that would result if some other variables were forced to take certain values. One prominent approach to tackling this problem is based on causal Bayesian networks, using directed acyclic graphs as causal diagrams to relate post-intervention probabilities to pre-intervention probabilities that are estimable from observational data. However, such causal diagrams are seldom fully testable given observational data. In consequence, many causal discovery algorithms based on data-mining can only output an equivalence class of causal diagrams (rather than a single one). This paper is concerned with causal reasoning given an equivalence class of causal diagrams, represented by a (partial) ancestral graph. We present two main results. The ﬁrst result extends Pearl (1995)’s celebrated do-calculus to the context of ancestral graphs. In the second result, we focus on a key component of Pearl’s calculus—the property of invariance under interventions, and give stronger graphical conditions for this property than those implied by the ﬁrst result. The second result also improves the earlier, similar results due to Spirtes et al. (1993). Keywords: ancestral graphs, causal Bayesian network, do-calculus, intervention</p><p>4 0.40428329 <a title="34-lda-4" href="./jmlr-2008-Coordinate_Descent_Method_for_Large-scale_L2-loss_Linear_Support_Vector_Machines.html">28 jmlr-2008-Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines</a></p>
<p>Author: Kai-Wei Chang, Cho-Jui Hsieh, Chih-Jen Lin</p><p>Abstract: Linear support vector machines (SVM) are useful for classifying large-scale sparse data. Problems with sparse features are common in applications such as document classiﬁcation and natural language processing. In this paper, we propose a novel coordinate descent algorithm for training linear SVM with the L2-loss function. At each step, the proposed method minimizes a one-variable sub-problem while ﬁxing other variables. The sub-problem is solved by Newton steps with the line search technique. The procedure globally converges at the linear rate. As each sub-problem involves only values of a corresponding feature, the proposed approach is suitable when accessing a feature is more convenient than accessing an instance. Experiments show that our method is more efﬁcient and stable than state of the art methods such as Pegasos and TRON. Keywords: linear support vector machines, document classiﬁcation, coordinate descent</p><p>5 0.40133238 <a title="34-lda-5" href="./jmlr-2008-Learning_Bounded_Treewidth_Bayesian_Networks.html">48 jmlr-2008-Learning Bounded Treewidth Bayesian Networks</a></p>
<p>Author: Gal Elidan, Stephen Gould</p><p>Abstract: With the increased availability of data for complex domains, it is desirable to learn Bayesian network structures that are sufﬁciently expressive for generalization while at the same time allow for tractable inference. While the method of thin junction trees can, in principle, be used for this purpose, its fully greedy nature makes it prone to overﬁtting, particularly when data is scarce. In this work we present a novel method for learning Bayesian networks of bounded treewidth that employs global structure modiﬁcations and that is polynomial both in the size of the graph and the treewidth bound. At the heart of our method is a dynamic triangulation that we update in a way that facilitates the addition of chain structures that increase the bound on the model’s treewidth by at most one. We demonstrate the effectiveness of our “treewidth-friendly” method on several real-life data sets and show that it is superior to the greedy approach as soon as the bound on the treewidth is nontrivial. Importantly, we also show that by making use of global operators, we are able to achieve better generalization even when learning Bayesian networks of unbounded treewidth. Keywords: Bayesian networks, structure learning, model selection, bounded treewidth</p><p>6 0.39994833 <a title="34-lda-6" href="./jmlr-2008-Structural_Learning_of_Chain_Graphs_via_Decomposition.html">88 jmlr-2008-Structural Learning of Chain Graphs via Decomposition</a></p>
<p>7 0.39698878 <a title="34-lda-7" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>8 0.395522 <a title="34-lda-8" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>9 0.39428845 <a title="34-lda-9" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>10 0.39391273 <a title="34-lda-10" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>11 0.39121065 <a title="34-lda-11" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>12 0.39016801 <a title="34-lda-12" href="./jmlr-2008-Gradient_Tree_Boosting_for_Training_Conditional_Random_Fields.html">39 jmlr-2008-Gradient Tree Boosting for Training Conditional Random Fields</a></p>
<p>13 0.38722655 <a title="34-lda-13" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<p>14 0.38194093 <a title="34-lda-14" href="./jmlr-2008-Search_for_Additive_Nonlinear_Time_Series_Causal_Models.html">84 jmlr-2008-Search for Additive Nonlinear Time Series Causal Models</a></p>
<p>15 0.38086954 <a title="34-lda-15" href="./jmlr-2008-Robust_Submodular_Observation_Selection.html">83 jmlr-2008-Robust Submodular Observation Selection</a></p>
<p>16 0.38023326 <a title="34-lda-16" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>17 0.37507141 <a title="34-lda-17" href="./jmlr-2008-Approximations_for_Binary_Gaussian_Process_Classification.html">16 jmlr-2008-Approximations for Binary Gaussian Process Classification</a></p>
<p>18 0.37484407 <a title="34-lda-18" href="./jmlr-2008-Evidence_Contrary_to_the_Statistical_View_of_Boosting.html">33 jmlr-2008-Evidence Contrary to the Statistical View of Boosting</a></p>
<p>19 0.37468481 <a title="34-lda-19" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>20 0.37295765 <a title="34-lda-20" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
