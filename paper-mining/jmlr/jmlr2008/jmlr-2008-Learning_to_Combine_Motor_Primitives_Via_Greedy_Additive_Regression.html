<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-53" href="#">jmlr2008-53</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</h1>
<br/><p>Source: <a title="jmlr-2008-53-pdf" href="http://jmlr.org/papers/volume9/chhabra08a/chhabra08a.pdf">pdf</a></p><p>Author: Manu Chhabra, Robert A. Jacobs</p><p>Abstract: The computational complexities arising in motor control can be ameliorated through the use of a library of motor synergies. We present a new model, referred to as the Greedy Additive Regression (GAR) model, for learning a library of torque sequences, and for learning the coefﬁcients of a linear combination of sequences minimizing a cost function. From the perspective of numerical optimization, the GAR model is interesting because it creates a library of “local features”—each sequence in the library is a solution to a single training task—and learns to combine these sequences using a local optimization procedure, namely, additive regression. We speculate that learners with local representational primitives and local optimization procedures will show good performance on nonlinear tasks. The GAR model is also interesting from the perspective of motor control because it outperforms several competing models. Results using a simulated two-joint arm suggest that the GAR model consistently shows excellent performance in the sense that it rapidly learns to perform novel, complex motor tasks. Moreover, its library is overcomplete and sparse, meaning that only a small fraction of the stored torque sequences are used when learning a new movement. The library is also robust in the sense that, after an initial training period, nearly all novel movements can be learned as additive combinations of sequences in the library, and in the sense that it shows good generalization when an arm’s dynamics are altered between training and test conditions, such as when a payload is added to the arm. Lastly, the GAR model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. We conclude that learning techniques using local primitives and optimization procedures are viable and potentially important methods for motor control and possibly other domains, and that these techniques deserve further examination by the artiﬁcial intelligence and cognitive science</p><p>Reference: <a title="jmlr-2008-53-reference" href="../jmlr2008_reference/jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 EDU  Department of Brain & Cognitive Sciences University of Rochester Rochester, NY 14627, USA  Editor: Peter Dayan  Abstract The computational complexities arising in motor control can be ameliorated through the use of a library of motor synergies. [sent-6, score-1.205]
</p><p>2 We present a new model, referred to as the Greedy Additive Regression (GAR) model, for learning a library of torque sequences, and for learning the coefﬁcients of a linear combination of sequences minimizing a cost function. [sent-7, score-0.676]
</p><p>3 The GAR model is also interesting from the perspective of motor control because it outperforms several competing models. [sent-10, score-0.528]
</p><p>4 Results using a simulated two-joint arm suggest that the GAR model consistently shows excellent performance in the sense that it rapidly learns to perform novel, complex motor tasks. [sent-11, score-0.72]
</p><p>5 Moreover, its library is overcomplete and sparse, meaning that only a small fraction of the stored torque sequences are used when learning a new movement. [sent-12, score-0.67]
</p><p>6 Lastly, the GAR model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. [sent-14, score-0.57]
</p><p>7 We conclude that learning techniques using local primitives and optimization procedures are viable and potentially important methods for motor control and possibly other domains, and that these techniques deserve further examination by the artiﬁcial intelligence and cognitive science communities. [sent-15, score-0.668]
</p><p>8 Keywords: additive regression, motor primitives, sparse representations  1. [sent-16, score-0.572]
</p><p>9 Consider, for example, an agent whose goal is to apply torques to each joint of a two-joint arm so that the endpoint of the arm moves from an initial location to a target location in 100 time steps. [sent-18, score-0.549]
</p><p>10 A motor synergy is a dependency among the dimensions or parameters of a motor system. [sent-25, score-0.946]
</p><p>11 For example, a coupling of the torques applied at the shoulder and elbow joints would be a motor synergy. [sent-26, score-0.63]
</p><p>12 Motor synergies are useful because they reduce the number of parameters that must be independently controlled, thereby making motor control signiﬁcantly easier (Bernstein, 1967). [sent-27, score-0.629]
</p><p>13 For our current purposes, we focus here on frameworks in which an agent with a library of motor synergies quickly learns to perform complex motor tasks by linearly combining its synergies. [sent-29, score-1.402]
</p><p>14 For example, Mussa-Ivaldi, Giszter, and Bizzi (1994) identiﬁed frogs’ motor synergies by stimulating sites in the frogs’ spinal cords. [sent-31, score-0.594]
</p><p>15 The idea of characterizing complex movements as linear combinations of motor synergies has also been inﬂuential in the ﬁelds of artiﬁcial intelligence and cognitive science. [sent-33, score-0.725]
</p><p>16 Other researchers have speculated that motor primitives can be learned using dimensionality-reduction techniques. [sent-38, score-0.575]
</p><p>17 1 The fact that novel motor tasks can often be performed by linearly combining motor synergies is a surprising result. [sent-42, score-1.166]
</p><p>18 To see why this result is unexpected, consider the case in which an agent needs to control a two-joint arm to perform a motor task. [sent-43, score-0.748]
</p><p>19 , desired angles for the shoulder and elbow joints at each time step of a movement), that a cost function is deﬁned as the sum of squared error between the desired and actual joint angles, and that the agent has a library of motor synergies where a synergy is a sequence of torques (i. [sent-46, score-1.19]
</p><p>20 The agent attempts to perform the motor task by ﬁnding a set of coefﬁcients for a linear combination of synergies minimizing the cost function. [sent-49, score-0.701]
</p><p>21 Our review focuses on frameworks in which complex movements are expressed as linear combinations of motor primitives. [sent-51, score-0.588]
</p><p>22 There are, of course, frameworks that use motor primitives in other ways. [sent-52, score-0.575]
</p><p>23 The Motor Basis Optimization Problem motivates the need to think about good ways of constructing a library of synergies, and good ways of learning to linearly combine the synergies to perform novel motor tasks. [sent-60, score-0.846]
</p><p>24 In this paper, we propose a new learning model that learns a sparse and overcomplete representation of the space of potentially useful motor commands, and learns to linearly combine elements of this representation using a “greedy additive regression” procedure. [sent-61, score-0.693]
</p><p>25 This paper introduces a new learning model for motor control referred to as the Greedy Additive Regression (GAR) model. [sent-71, score-0.528]
</p><p>26 The GAR model maintains a library of torque sequences (i. [sent-72, score-0.65]
</p><p>27 The PCA model learns a library of motor primitives using PCA, and ﬁnds coefﬁcients for linearly combining the primitives using gradient descent. [sent-83, score-0.99]
</p><p>28 Moreover, the library is overcomplete and also sparse, meaning that only a small fraction of the stored torque sequences are used when learning a novel movement. [sent-86, score-0.698]
</p><p>29 If, for example, an arm is suddenly required to carry a payload during testing, torque sequences in the library can still be additively combined to rapidly learn new movements with this altered arm. [sent-91, score-1.036]
</p><p>30 We also demonstrate that the model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian 1537  C HHABRA AND JACOBS  space. [sent-92, score-0.57]
</p><p>31 Based on these results, we believe that the GAR model contains several desirable properties, including a library which maintains a sparse and overcomplete representation of the space of potentially useful motor commands, and an additive regression optimization procedure which is fast and robust. [sent-93, score-0.888]
</p><p>32 Section 2 describes the two-joint arm that we simulated, and Section 3 describes the motor tasks that we used. [sent-95, score-0.732]
</p><p>33 Motor Tasks A motor task is to apply torques to the arm so that it follows a desired trajectory deﬁned in joint space. [sent-107, score-0.946]
</p><p>34 Given a desired joint-space trajectory, a motor task is to apply a time-varying torque to the arm so that the arm follows the desired trajectory. [sent-132, score-1.22]
</p><p>35 The cost function corresponding to the motor task is the sum of 1539  C HHABRA AND JACOBS  Figure 2: A schematic description of the Greedy Additive Regression(GAR) model. [sent-134, score-0.523]
</p><p>36 An additive regression algorithm is then used to construct a torque sequence by linearly combining sequences from the library. [sent-136, score-0.607]
</p><p>37 i The motor tasks deﬁned here are more complex than tasks often used in the literature in at least two respects. [sent-141, score-0.581]
</p><p>38 First, the desired Cartesian-space trajectories used here are typically highly curved, as opposed to straight-line reaching movements which are commonly used in experimental and computational studies of motor control. [sent-142, score-0.622]
</p><p>39 This model rapidly learns new motor tasks using a library of torque sequences. [sent-147, score-1.023]
</p><p>40 When a new motor task arrives, the model ﬁrst checks whether a linear combination of sequences from the library achieves good performance on this task. [sent-149, score-0.924]
</p><p>41 Intuitively, the model removes the torque sequence that has been least used during the motor tasks that it has performed. [sent-158, score-0.835]
</p><p>42 Let n be an index over motor tasks, k be an index over sequences in the library, and |ρk (n)| be the absolute value of the linear coefﬁcient ρk (n) assigned to sequence k on task n by the additive regression algorithm. [sent-159, score-0.842]
</p><p>43 To complete the description of the GAR model, we need to describe the additive regression algorithm for ﬁnding potentially good linear combinations of torque sequences from the library for a motor task. [sent-163, score-1.263]
</p><p>44 At iteration t, the algorithm maintains an aggregate torque sequence F (t) to perform a motor task such that: F (t) =  t  ∑ ρj fj  (2)  j=1  where f j is a sequence in the library and ρ j is its corresponding coefﬁcient. [sent-166, score-1.063]
</p><p>45 Each torque sequence in the library is associated with a trajectory of joint angles. [sent-172, score-0.624]
</p><p>46 Our work differs from their work in many details because the domain of motor control forces us to confront the complexities inherent in learning to control a dynamical system (see also Tassa, Erez, and Smart, 2008). [sent-199, score-0.56]
</p><p>47 In addition, the additive regression algorithm can be seen as performing gradient descent where the direction of the gradient at each iteration is projected onto the library sequence whose trajectory is maximally correlated with this gradient. [sent-205, score-0.597]
</p><p>48 The PCA model performs dimensionality-reduction via PCA to learn a library of motor primitives. [sent-212, score-0.7]
</p><p>49 When given a novel motor task, the PCA model learns to perform the 3. [sent-213, score-0.543]
</p><p>50 task using a policy gradient optimization procedure (Sutton, McAllester, Singh, and Mansour, 1999; Williams 1992) to learn a set of coefﬁcients for linearly combining the motor primitives. [sent-219, score-0.64]
</p><p>51 1 GAR versus PCA In the PCA model, the library of motor synergies was created as follows. [sent-222, score-0.82]
</p><p>52 We ﬁrst generated 3000 motor tasks as described in Section 3, and then used feedback error learning to learn a torque sequence for each task. [sent-223, score-0.878]
</p><p>53 To learn to perform a novel motor task from a test set, the PCA model searched for good linear combinations of the PCA sequences. [sent-230, score-0.581]
</p><p>54 Its library of torque sequences was created by running the model on 3000 motor tasks. [sent-236, score-1.142]
</p><p>55 To learn to perform a novel motor task from a test set, the GAR model learned to linearly combine the GAR sequences using the additive regression algorithm described above. [sent-239, score-0.866]
</p><p>56 1  0  GAR AR  PCA PG  PCA AR  GAR PG  Figure 3: Average root mean squared errors of four systems on a test set of 100 novel motor tasks (the error bars show the standard errors of the means). [sent-242, score-0.555]
</p><p>57 The four systems use: (i) GAR sequences with additive regression (GAR model); (ii) PCA sequences with policy gradient (PCA model); (iii) PCA sequences with additive regression; and (iv) GAR sequences with policy gradient. [sent-243, score-1.086]
</p><p>58 The PCA model combines PCA sequences with policy gradient, whereas the GAR model combines GAR sequences with additive regression. [sent-245, score-0.546]
</p><p>59 For the sake of completeness, we also studied the remaining two combinations, namely, the combination of PCA sequences with additive regression and the combination of GAR sequences with policy gradient. [sent-246, score-0.577]
</p><p>60 The vertical axis gives a system’s average root mean squared error (RMSE where the error is between the desired and actual joint angles) on a test set of 100 novel motor tasks. [sent-249, score-0.606]
</p><p>61 Local optimization methods have been shown to be effective in motor control in previous research. [sent-281, score-0.53]
</p><p>62 2 Visualizing Torque Sequences The library of a GAR model is created on the basis of a wide variety of motor tasks. [sent-296, score-0.719]
</p><p>63 The torque sequences in the library should, therefore, be “representative” of the tasks they encode. [sent-297, score-0.684]
</p><p>64 We then ordered the sequences in the library by the percent of the model’s total activation that a sequence accounted for. [sent-300, score-0.521]
</p><p>65 This graph illustrates that, even though the sequences are added to the library in an arbitrary order, the important sequences that remain in the library are representative of the motor tasks. [sent-307, score-1.239]
</p><p>66 If the size, denoted K, is too small, then torque sequences that are often useful for learning novel motor tasks might be removed. [sent-311, score-0.978]
</p><p>67 4  Figure 5: Cartesian-space trajectories generated by the three torque sequences that accounted for the largest percent of a GAR model’s total activation. [sent-326, score-0.53]
</p><p>68 These trajectories were generated by initializing the shoulder and elbow joint angles of the arm to π/4 and π/2 respectively, and then applying the sequences to the arm with coefﬁcients of 1 and -1. [sent-327, score-0.743]
</p><p>69 In Figure 6, the horizontal axis shows the number of motor tasks, and the vertical axis shows the percent of tasks in which a version of the GAR model needed to learn a torque sequence via feedback error learning. [sent-331, score-1.036]
</p><p>70 The motor tasks were divided into 60 blocks of 50 trials each. [sent-333, score-0.527]
</p><p>71 As training progresses, the library has many more useful sequences, and most novel motor tasks can be performed by linearly combining sequences from the library. [sent-337, score-0.955]
</p><p>72 A comparison of the versions with different library sizes shows that the version with a library size of 50 used feedback error learning more often than versions with library sizes of 100 or 200. [sent-339, score-0.684]
</p><p>73 The sequences in a library are ordered according to the percent of a model’s total activation that a sequence accounted for. [sent-342, score-0.521]
</p><p>74 The libraries for the GAR model (with a library of size 100) and the PCA model were created as described above with an arm that did not carry a payload. [sent-368, score-0.519]
</p><p>75 Test trials were conducted as described above; that is, for each test task, a linear combination of torque sequences in a library was found via the additive regression algorithm for the GAR model, and via policy gradient for the PCA model. [sent-370, score-0.88]
</p><p>76 The sequences in a library are ordered according to the percent of a model’s total activation that a sequence accounted for. [sent-375, score-0.521]
</p><p>77 combinations of libraries with optimization algorithms, namely, the GAR sequences with policy gradient, and the PCA sequences with additive regression. [sent-377, score-0.61]
</p><p>78 It clearly demonstrates that the GAR model develops a useful library of torque sequences, and that the additive regression algorithm is a powerful optimization procedure for ﬁnding good linear combinations, even under test conditions that are very different from training conditions. [sent-385, score-0.622]
</p><p>79 If this is the case, then additive regression should work well for tasks with novel payloads, even when using a library of GAR sequences constructed from zeropayload trials. [sent-389, score-0.591]
</p><p>80 We ﬁrst generated a library of 100 GAR sequences using a training set of 3000 tasks where the simulated arm did not contain a payload. [sent-390, score-0.642]
</p><p>81 5 Motor Tasks Speciﬁed in Cartesian Space In this subsection, we consider learning sequences for motor tasks when the desired trajectories are speciﬁed in Cartesian space instead of joint space. [sent-408, score-0.794]
</p><p>82 2  0 0  10  20 30 Number of iterations  40  Figure 9: Results when motor tasks were speciﬁed in Cartesian space. [sent-416, score-0.527]
</p><p>83 The GAR model was trained using 3000 motor tasks with a library of size 100. [sent-419, score-0.754]
</p><p>84 02 was used to determine if a linear combination of torque sequences from the library provided a “good” aggregate sequence for a task (note that this is different from a threshold of ε = 0. [sent-422, score-0.747]
</p><p>85 This outcome indicates that the GAR model has wide applicability in the sense that it is effective regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. [sent-428, score-0.57]
</p><p>86 Using these optimal sequences as data items, we created a library of PCA sequences by extracting the top thirty principal components based on these data items. [sent-464, score-0.578]
</p><p>87 On average, the learner using GAR sequences and additive regression made 49 calls, the learner using PCA sequences and policy gradient made 3879 calls, the learner using PCA sequences and additive regression made 62 calls, and the learner using GAR sequences and policy gradient made 3422 calls. [sent-476, score-1.236]
</p><p>88 The horizontal axis shows the learning system: (i) Optimal: optimal control signals; (ii) GAR+AR: GAR sequences with additive regression; (iii) PCA+PG: PCA sequences with policy gradient; (iv) PCA+AR: PCA sequences with additive regression; and (v) GAR+PG: GAR sequences with policy gradient. [sent-482, score-1.096]
</p><p>89 Conclusions In summary, the computational complexities arising in motor control can be ameliorated through the use of a library of motor synergies. [sent-484, score-1.205]
</p><p>90 We presented a new model, referred to as the Greedy Additive Regression (GAR) model, for learning a library of torque sequences, and for learning the coefﬁcients of a linear combination of library sequences minimizing a cost function. [sent-485, score-0.883]
</p><p>91 Results using a simulated two-joint arm suggest that the GAR model consistently shows excellent performance in the sense that it rapidly learns to perform novel, complex motor tasks. [sent-486, score-0.72]
</p><p>92 Moreover, its library is overcomplete and sparse, meaning that only a small fraction of the stored torque sequences are used when learning a new movement. [sent-487, score-0.67]
</p><p>93 Additionally, we showed that the GAR model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. [sent-489, score-0.57]
</p><p>94 The GAR model uses a library of local features—each sequence in its library is a solution to a single task from the training set—and a local optimization procedure, namely, additive regression. [sent-492, score-0.622]
</p><p>95 In contrast, the PCA model uses a library of global features—each item in its library reﬂects properties of all tasks in the training set—and policy gradient which is a global optimization procedure because it seeks good combinations of all items in its library. [sent-493, score-0.646]
</p><p>96 Future research will need to focus on the implications of the model for our understanding of motor control in biological organisms, the theoretical foundations of the model, and further empirical evaluations. [sent-500, score-0.528]
</p><p>97 In regard to our understanding of biological motor control, it would be interesting to know whether sets of motor synergies used by biological organisms are sparse and overcomplete as suggested by the GAR model, or are full-distributed and non-redundant as suggested by the PCA model. [sent-501, score-1.127]
</p><p>98 In regard to empirical evaluations, future research will need to evaluate the GAR model with larger and more complex motor systems and motor tasks. [sent-506, score-0.966]
</p><p>99 Properties of synergies arising from a theory of optimal motor behavior. [sent-550, score-0.594]
</p><p>100 Combinations of muscle synergies in the construction of a natural motor behavior. [sent-560, score-0.594]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gar', 0.633), ('motor', 0.473), ('torque', 0.247), ('library', 0.207), ('arm', 0.205), ('sequences', 0.176), ('pca', 0.134), ('synergies', 0.121), ('trajectory', 0.106), ('primitives', 0.102), ('additive', 0.099), ('payload', 0.098), ('movements', 0.081), ('torques', 0.081), ('hhabra', 0.069), ('ombine', 0.063), ('otor', 0.063), ('rimitives', 0.063), ('feedback', 0.063), ('jacobs', 0.061), ('policy', 0.055), ('tasks', 0.054), ('libraries', 0.048), ('gradient', 0.047), ('cartesian', 0.045), ('angles', 0.045), ('sequence', 0.041), ('overcomplete', 0.04), ('percent', 0.039), ('trajectories', 0.036), ('pg', 0.036), ('control', 0.035), ('agent', 0.035), ('feedforward', 0.035), ('lacker', 0.035), ('perkins', 0.035), ('rochester', 0.035), ('viola', 0.034), ('combinations', 0.034), ('desired', 0.032), ('accounted', 0.032), ('axis', 0.032), ('ar', 0.03), ('representational', 0.029), ('payloads', 0.029), ('shoulder', 0.029), ('theiler', 0.029), ('todorov', 0.029), ('movement', 0.028), ('controller', 0.028), ('rmse', 0.028), ('aggregate', 0.028), ('novel', 0.028), ('regression', 0.027), ('activation', 0.026), ('task', 0.026), ('kg', 0.026), ('ft', 0.025), ('elbow', 0.024), ('atkeson', 0.024), ('coef', 0.024), ('cost', 0.024), ('descent', 0.023), ('joint', 0.023), ('chhabra', 0.023), ('hodgins', 0.023), ('joints', 0.023), ('matari', 0.023), ('sticks', 0.023), ('optimization', 0.022), ('combination', 0.022), ('altered', 0.022), ('learns', 0.022), ('performances', 0.022), ('earning', 0.021), ('dynamics', 0.021), ('greedy', 0.021), ('cients', 0.021), ('model', 0.02), ('jones', 0.02), ('procedures', 0.02), ('organisms', 0.02), ('velocities', 0.02), ('robotic', 0.02), ('learner', 0.019), ('created', 0.019), ('vertical', 0.018), ('ms', 0.017), ('bar', 0.017), ('ry', 0.017), ('horizontal', 0.017), ('accelerations', 0.017), ('ameliorated', 0.017), ('kgms', 0.017), ('resting', 0.017), ('system', 0.017), ('linearly', 0.017), ('cognitive', 0.016), ('signals', 0.016), ('robotics', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="53-tfidf-1" href="./jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</a></p>
<p>Author: Manu Chhabra, Robert A. Jacobs</p><p>Abstract: The computational complexities arising in motor control can be ameliorated through the use of a library of motor synergies. We present a new model, referred to as the Greedy Additive Regression (GAR) model, for learning a library of torque sequences, and for learning the coefﬁcients of a linear combination of sequences minimizing a cost function. From the perspective of numerical optimization, the GAR model is interesting because it creates a library of “local features”—each sequence in the library is a solution to a single training task—and learns to combine these sequences using a local optimization procedure, namely, additive regression. We speculate that learners with local representational primitives and local optimization procedures will show good performance on nonlinear tasks. The GAR model is also interesting from the perspective of motor control because it outperforms several competing models. Results using a simulated two-joint arm suggest that the GAR model consistently shows excellent performance in the sense that it rapidly learns to perform novel, complex motor tasks. Moreover, its library is overcomplete and sparse, meaning that only a small fraction of the stored torque sequences are used when learning a new movement. The library is also robust in the sense that, after an initial training period, nearly all novel movements can be learned as additive combinations of sequences in the library, and in the sense that it shows good generalization when an arm’s dynamics are altered between training and test conditions, such as when a payload is added to the arm. Lastly, the GAR model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. We conclude that learning techniques using local primitives and optimization procedures are viable and potentially important methods for motor control and possibly other domains, and that these techniques deserve further examination by the artiﬁcial intelligence and cognitive science</p><p>2 0.062178418 <a title="53-tfidf-2" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>Author: Mikio L. Braun, Joachim M. Buhmann, Klaus-Robert Müller</p><p>Abstract: We show that the relevant information of a supervised learning problem is contained up to negligible error in a ﬁnite number of leading kernel PCA components if the kernel matches the underlying learning problem in the sense that it can asymptotically represent the function to be learned and is sufﬁciently smooth. Thus, kernels do not only transform data sets such that good generalization can be achieved using only linear discriminant functions, but this transformation is also performed in a manner which makes economical use of feature space dimensions. In the best case, kernels provide efﬁcient implicit representations of the data for supervised learning problems. Practically, we propose an algorithm which enables us to recover the number of leading kernel PCA components relevant for good classiﬁcation. Our algorithm can therefore be applied (1) to analyze the interplay of data set and kernel in a geometric fashion, (2) to aid in model selection, and (3) to denoise in feature space in order to yield better classiﬁcation results. Keywords: kernel methods, feature space, dimension reduction, effective dimensionality</p><p>3 0.046183687 <a title="53-tfidf-3" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>Author: Konrad Rieck, Pavel Laskov</p><p>Abstract: Efﬁcient and expressive comparison of sequences is an essential procedure for learning with sequential data. In this article we propose a generic framework for computation of similarity measures for sequences, covering various kernel, distance and non-metric similarity functions. The basis for comparison is embedding of sequences using a formal language, such as a set of natural words, k-grams or all contiguous subsequences. As realizations of the framework we provide linear-time algorithms of different complexity and capabilities using sorted arrays, tries and sufﬁx trees as underlying data structures. Experiments on data sets from bioinformatics, text processing and computer security illustrate the efﬁciency of the proposed algorithms—enabling peak performances of up to 106 pairwise comparisons per second. The utility of distances and non-metric similarity measures for sequences as alternatives to string kernels is demonstrated in applications of text categorization, network intrusion detection and transcription site recognition in DNA. Keywords: string kernels, string distances, learning with sequential data</p><p>4 0.043255851 <a title="53-tfidf-4" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>Author: Matthias W. Seeger</p><p>Abstract: We propose a highly efﬁcient framework for penalized likelihood kernel methods applied to multiclass models with a large, structured set of classes. As opposed to many previous approaches which try to decompose the ﬁtting problem into many smaller ones, we focus on a Newton optimization of the complete model, making use of model structure and linear conjugate gradients in order to approximate Newton search directions. Crucially, our learning method is based entirely on matrix-vector multiplication primitives with the kernel matrices and their derivatives, allowing straightforward specialization to new kernels, and focusing code optimization efforts to these primitives only. Kernel parameters are learned automatically, by maximizing the cross-validation log likelihood in a gradient-based way, and predictive probabilities are estimated. We demonstrate our approach on large scale text classiﬁcation tasks with hierarchical structure on thousands of classes, achieving state-of-the-art results in an order of magnitude less time than previous work. Parts of this work appeared in the conference paper Seeger (2007). Keywords: multi-way classiﬁcation, kernel logistic regression, hierarchical classiﬁcation, cross validation optimization, Newton-Raphson optimization</p><p>5 0.04025906 <a title="53-tfidf-5" href="./jmlr-2008-Randomized_Online_PCA_Algorithms_with_Regret_Bounds_that_are_Logarithmic_in_the_Dimension.html">78 jmlr-2008-Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension</a></p>
<p>Author: Manfred K. Warmuth, Dima Kuzmin</p><p>Abstract: We design an online algorithm for Principal Component Analysis. In each trial the current instance is centered and projected into a probabilistically chosen low dimensional subspace. The regret of our online algorithm, that is, the total expected quadratic compression loss of the online algorithm minus the total quadratic compression loss of the batch algorithm, is bounded by a term whose dependence on the dimension of the instances is only logarithmic. We ﬁrst develop our methodology in the expert setting of online learning by giving an algorithm for learning as well as the best subset of experts of a certain size. This algorithm is then lifted to the matrix setting where the subsets of experts correspond to subspaces. The algorithm represents the uncertainty over the best subspace as a density matrix whose eigenvalues are bounded. The running time is O(n2 ) per trial, where n is the dimension of the instances. Keywords: principal component analysis, online learning, density matrix, expert setting, quantum Bayes rule</p><p>6 0.036010809 <a title="53-tfidf-6" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>7 0.03566891 <a title="53-tfidf-7" href="./jmlr-2008-Shark%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">85 jmlr-2008-Shark    (Machine Learning Open Source Software Paper)</a></p>
<p>8 0.035008579 <a title="53-tfidf-8" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>9 0.03234525 <a title="53-tfidf-9" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>10 0.0315619 <a title="53-tfidf-10" href="./jmlr-2008-Accelerated_Neural_Evolution_through_Cooperatively_Coevolved_Synapses.html">8 jmlr-2008-Accelerated Neural Evolution through Cooperatively Coevolved Synapses</a></p>
<p>11 0.029850235 <a title="53-tfidf-11" href="./jmlr-2008-Search_for_Additive_Nonlinear_Time_Series_Causal_Models.html">84 jmlr-2008-Search for Additive Nonlinear Time Series Causal Models</a></p>
<p>12 0.028968874 <a title="53-tfidf-12" href="./jmlr-2008-Learning_Control_Knowledge_for_Forward_Search_Planning.html">49 jmlr-2008-Learning Control Knowledge for Forward Search Planning</a></p>
<p>13 0.028589454 <a title="53-tfidf-13" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>14 0.028499674 <a title="53-tfidf-14" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>15 0.026429251 <a title="53-tfidf-15" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>16 0.024078039 <a title="53-tfidf-16" href="./jmlr-2008-LIBLINEAR%3A_A_Library_for_Large_Linear_Classification%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">46 jmlr-2008-LIBLINEAR: A Library for Large Linear Classification    (Machine Learning Open Source Software Paper)</a></p>
<p>17 0.02306775 <a title="53-tfidf-17" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>18 0.021185938 <a title="53-tfidf-18" href="./jmlr-2008-Visualizing_Data_using_t-SNE.html">96 jmlr-2008-Visualizing Data using t-SNE</a></p>
<p>19 0.020321971 <a title="53-tfidf-19" href="./jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</a></p>
<p>20 0.019739315 <a title="53-tfidf-20" href="./jmlr-2008-An_Error_Bound_Based_on_a_Worst_Likely_Assignment.html">13 jmlr-2008-An Error Bound Based on a Worst Likely Assignment</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.107), (1, -0.038), (2, 0.001), (3, 0.013), (4, -0.061), (5, -0.068), (6, -0.049), (7, 0.054), (8, -0.06), (9, 0.009), (10, -0.084), (11, 0.069), (12, 0.084), (13, -0.015), (14, 0.015), (15, 0.091), (16, 0.043), (17, 0.014), (18, 0.036), (19, -0.187), (20, 0.051), (21, 0.227), (22, -0.205), (23, -0.036), (24, 0.083), (25, 0.197), (26, -0.051), (27, -0.067), (28, -0.09), (29, 0.081), (30, 0.23), (31, -0.003), (32, -0.155), (33, -0.043), (34, 0.132), (35, -0.147), (36, -0.081), (37, -0.107), (38, -0.252), (39, -0.229), (40, -0.253), (41, -0.207), (42, -0.033), (43, -0.171), (44, 0.04), (45, -0.064), (46, 0.192), (47, 0.212), (48, -0.281), (49, 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97201407 <a title="53-lsi-1" href="./jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</a></p>
<p>Author: Manu Chhabra, Robert A. Jacobs</p><p>Abstract: The computational complexities arising in motor control can be ameliorated through the use of a library of motor synergies. We present a new model, referred to as the Greedy Additive Regression (GAR) model, for learning a library of torque sequences, and for learning the coefﬁcients of a linear combination of sequences minimizing a cost function. From the perspective of numerical optimization, the GAR model is interesting because it creates a library of “local features”—each sequence in the library is a solution to a single training task—and learns to combine these sequences using a local optimization procedure, namely, additive regression. We speculate that learners with local representational primitives and local optimization procedures will show good performance on nonlinear tasks. The GAR model is also interesting from the perspective of motor control because it outperforms several competing models. Results using a simulated two-joint arm suggest that the GAR model consistently shows excellent performance in the sense that it rapidly learns to perform novel, complex motor tasks. Moreover, its library is overcomplete and sparse, meaning that only a small fraction of the stored torque sequences are used when learning a new movement. The library is also robust in the sense that, after an initial training period, nearly all novel movements can be learned as additive combinations of sequences in the library, and in the sense that it shows good generalization when an arm’s dynamics are altered between training and test conditions, such as when a payload is added to the arm. Lastly, the GAR model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. We conclude that learning techniques using local primitives and optimization procedures are viable and potentially important methods for motor control and possibly other domains, and that these techniques deserve further examination by the artiﬁcial intelligence and cognitive science</p><p>2 0.20597616 <a title="53-lsi-2" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>Author: Konrad Rieck, Pavel Laskov</p><p>Abstract: Efﬁcient and expressive comparison of sequences is an essential procedure for learning with sequential data. In this article we propose a generic framework for computation of similarity measures for sequences, covering various kernel, distance and non-metric similarity functions. The basis for comparison is embedding of sequences using a formal language, such as a set of natural words, k-grams or all contiguous subsequences. As realizations of the framework we provide linear-time algorithms of different complexity and capabilities using sorted arrays, tries and sufﬁx trees as underlying data structures. Experiments on data sets from bioinformatics, text processing and computer security illustrate the efﬁciency of the proposed algorithms—enabling peak performances of up to 106 pairwise comparisons per second. The utility of distances and non-metric similarity measures for sequences as alternatives to string kernels is demonstrated in applications of text categorization, network intrusion detection and transcription site recognition in DNA. Keywords: string kernels, string distances, learning with sequential data</p><p>3 0.20189779 <a title="53-lsi-3" href="./jmlr-2008-Search_for_Additive_Nonlinear_Time_Series_Causal_Models.html">84 jmlr-2008-Search for Additive Nonlinear Time Series Causal Models</a></p>
<p>Author: Tianjiao Chu, Clark Glymour</p><p>Abstract: Pointwise consistent, feasible procedures for estimating contemporaneous linear causal structure from time series data have been developed using multiple conditional independence tests, but no such procedures are available for non-linear systems. We describe a feasible procedure for learning a class of non-linear time series structures, which we call additive non-linear time series. We show that for data generated from stationary models of this type, two classes of conditional independence relations among time series variables and their lags can be tested efﬁciently and consistently using tests based on additive model regression. Combining results of statistical tests for these two classes of conditional independence relations and the temporal structure of time series data, a new consistent model speciﬁcation procedure is able to extract relatively detailed causal information. We investigate the ﬁnite sample behavior of the procedure through simulation, and illustrate the application of this method through analysis of the possible causal connections among four ocean indices. Several variants of the procedure are also discussed. Keywords: conditional independence test, contemporaneous causation, additive model regression, Granger causality, ocean indices</p><p>4 0.19733736 <a title="53-lsi-4" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>Author: Stefan Klanke, Sethu Vijayakumar, Stefan Schaal</p><p>Abstract: In this paper we introduce an improved implementation of locally weighted projection regression (LWPR), a supervised learning algorithm that is capable of handling high-dimensional input data. As the key features, our code supports multi-threading, is available for multiple platforms, and provides wrappers for several programming languages. Keywords: regression, local learning, online learning, C, C++, Matlab, Octave, Python</p><p>5 0.16568978 <a title="53-lsi-5" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>Author: Mikio L. Braun, Joachim M. Buhmann, Klaus-Robert Müller</p><p>Abstract: We show that the relevant information of a supervised learning problem is contained up to negligible error in a ﬁnite number of leading kernel PCA components if the kernel matches the underlying learning problem in the sense that it can asymptotically represent the function to be learned and is sufﬁciently smooth. Thus, kernels do not only transform data sets such that good generalization can be achieved using only linear discriminant functions, but this transformation is also performed in a manner which makes economical use of feature space dimensions. In the best case, kernels provide efﬁcient implicit representations of the data for supervised learning problems. Practically, we propose an algorithm which enables us to recover the number of leading kernel PCA components relevant for good classiﬁcation. Our algorithm can therefore be applied (1) to analyze the interplay of data set and kernel in a geometric fashion, (2) to aid in model selection, and (3) to denoise in feature space in order to yield better classiﬁcation results. Keywords: kernel methods, feature space, dimension reduction, effective dimensionality</p><p>6 0.15987168 <a title="53-lsi-6" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>7 0.1597582 <a title="53-lsi-7" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>8 0.13208684 <a title="53-lsi-8" href="./jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</a></p>
<p>9 0.12703541 <a title="53-lsi-9" href="./jmlr-2008-Learning_Control_Knowledge_for_Forward_Search_Planning.html">49 jmlr-2008-Learning Control Knowledge for Forward Search Planning</a></p>
<p>10 0.12611437 <a title="53-lsi-10" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>11 0.1255717 <a title="53-lsi-11" href="./jmlr-2008-Shark%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">85 jmlr-2008-Shark    (Machine Learning Open Source Software Paper)</a></p>
<p>12 0.10952801 <a title="53-lsi-12" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>13 0.10844859 <a title="53-lsi-13" href="./jmlr-2008-Randomized_Online_PCA_Algorithms_with_Regret_Bounds_that_are_Logarithmic_in_the_Dimension.html">78 jmlr-2008-Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension</a></p>
<p>14 0.10671616 <a title="53-lsi-14" href="./jmlr-2008-LIBLINEAR%3A_A_Library_for_Large_Linear_Classification%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">46 jmlr-2008-LIBLINEAR: A Library for Large Linear Classification    (Machine Learning Open Source Software Paper)</a></p>
<p>15 0.095282927 <a title="53-lsi-15" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>16 0.092062756 <a title="53-lsi-16" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>17 0.090265073 <a title="53-lsi-17" href="./jmlr-2008-Maximal_Causes_for_Non-linear_Component_Extraction.html">59 jmlr-2008-Maximal Causes for Non-linear Component Extraction</a></p>
<p>18 0.083713993 <a title="53-lsi-18" href="./jmlr-2008-Finding_Optimal_Bayesian_Network_Given_a_Super-Structure.html">35 jmlr-2008-Finding Optimal Bayesian Network Given a Super-Structure</a></p>
<p>19 0.082769096 <a title="53-lsi-19" href="./jmlr-2008-Accelerated_Neural_Evolution_through_Cooperatively_Coevolved_Synapses.html">8 jmlr-2008-Accelerated Neural Evolution through Cooperatively Coevolved Synapses</a></p>
<p>20 0.077793054 <a title="53-lsi-20" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.017), (5, 0.022), (40, 0.039), (54, 0.055), (58, 0.032), (66, 0.031), (76, 0.015), (78, 0.017), (88, 0.109), (92, 0.032), (94, 0.068), (95, 0.392), (99, 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76531976 <a title="53-lda-1" href="./jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</a></p>
<p>Author: Manu Chhabra, Robert A. Jacobs</p><p>Abstract: The computational complexities arising in motor control can be ameliorated through the use of a library of motor synergies. We present a new model, referred to as the Greedy Additive Regression (GAR) model, for learning a library of torque sequences, and for learning the coefﬁcients of a linear combination of sequences minimizing a cost function. From the perspective of numerical optimization, the GAR model is interesting because it creates a library of “local features”—each sequence in the library is a solution to a single training task—and learns to combine these sequences using a local optimization procedure, namely, additive regression. We speculate that learners with local representational primitives and local optimization procedures will show good performance on nonlinear tasks. The GAR model is also interesting from the perspective of motor control because it outperforms several competing models. Results using a simulated two-joint arm suggest that the GAR model consistently shows excellent performance in the sense that it rapidly learns to perform novel, complex motor tasks. Moreover, its library is overcomplete and sparse, meaning that only a small fraction of the stored torque sequences are used when learning a new movement. The library is also robust in the sense that, after an initial training period, nearly all novel movements can be learned as additive combinations of sequences in the library, and in the sense that it shows good generalization when an arm’s dynamics are altered between training and test conditions, such as when a payload is added to the arm. Lastly, the GAR model works well regardless of whether motor tasks are speciﬁed in joint space or Cartesian space. We conclude that learning techniques using local primitives and optimization procedures are viable and potentially important methods for motor control and possibly other domains, and that these techniques deserve further examination by the artiﬁcial intelligence and cognitive science</p><p>2 0.38540843 <a title="53-lda-2" href="./jmlr-2008-Incremental_Identification_of_Qualitative_Models_of_Biological_Systems_using_Inductive_Logic_Programming.html">44 jmlr-2008-Incremental Identification of Qualitative Models of Biological Systems using Inductive Logic Programming</a></p>
<p>Author: Ashwin Srinivasan, Ross D. King</p><p>Abstract: The use of computational models is increasingly expected to play an important role in predicting the behaviour of biological systems. Models are being sought at different scales of biological organisation namely: sub-cellular, cellular, tissue, organ, organism and ecosystem; with a view of identifying how different components are connected together, how they are controlled and how they behave when functioning as a system. Except for very simple biological processes, system identiﬁcation from ﬁrst principles can be extremely difﬁcult. This has brought into focus automated techniques for constructing models using data of system behaviour. Such techniques face three principal issues: (1) The model representation language must be rich enough to capture system behaviour; (2) The system identiﬁcation technique must be powerful enough to identify substantially complex models; and (3) There may not be sufﬁcient data to obtain both the model’s structure and precise estimates of all of its parameters. In this paper, we address these issues in the following ways: (1) Models are represented in an expressive subset of ﬁrst-order logic. Speciﬁcally, they are expressed as logic programs; (2) System identiﬁcation is done using techniques developed in Inductive Logic Programming (ILP). This allows the identiﬁcation of ﬁrst-order logic models from data. Speciﬁcally, we employ an incremental approach in which increasingly complex models are constructed from simpler ones using snapshots of system behaviour; and (3) We restrict ourselves to “qualitative” models. These are non-parametric: thus, usually less data are required than for identifying parametric quantitative models. A further advantage is that the data need not be precise numerical observations (instead, they are abstractions like positive, negative, zero, increasing, decreasing and so on). We describe incremental construction of qualitative models using a simple physical system and demonstrate its application to identiﬁcatio</p><p>3 0.355432 <a title="53-lda-3" href="./jmlr-2008-Visualizing_Data_using_t-SNE.html">96 jmlr-2008-Visualizing Data using t-SNE</a></p>
<p>Author: Laurens van der Maaten, Geoffrey Hinton</p><p>Abstract: We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces signiﬁcantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to inﬂuence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are signiﬁcantly better than those produced by the other techniques on almost all of the data sets. Keywords: visualization, dimensionality reduction, manifold learning, embedding algorithms, multidimensional scaling</p><p>4 0.34396198 <a title="53-lda-4" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>Author: Hsuan-Tien Lin, Ling Li</p><p>Abstract: Ensemble learning algorithms such as boosting can achieve better performance by averaging over the predictions of some base hypotheses. Nevertheless, most existing algorithms are limited to combining only a ﬁnite number of hypotheses, and the generated ensemble is usually sparse. Thus, it is not clear whether we should construct an ensemble classiﬁer with a larger or even an inﬁnite number of hypotheses. In addition, constructing an inﬁnite ensemble itself is a challenging task. In this paper, we formulate an inﬁnite ensemble learning framework based on the support vector machine (SVM). The framework can output an inﬁnite and nonsparse ensemble through embedding inﬁnitely many hypotheses into an SVM kernel. We use the framework to derive two novel kernels, the stump kernel and the perceptron kernel. The stump kernel embodies inﬁnitely many decision stumps, and the perceptron kernel embodies inﬁnitely many perceptrons. We also show that the Laplacian radial basis function kernel embodies inﬁnitely many decision trees, and can thus be explained through inﬁnite ensemble learning. Experimental results show that SVM with these kernels is superior to boosting with the same base hypothesis set. In addition, SVM with the stump kernel or the perceptron kernel performs similarly to SVM with the Gaussian radial basis function kernel, but enjoys the beneﬁt of faster parameter selection. These properties make the novel kernels favorable choices in practice. Keywords: ensemble learning, boosting, support vector machine, kernel</p><p>5 0.3361212 <a title="53-lda-5" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>Author: Matthias W. Seeger</p><p>Abstract: The linear model with sparsity-favouring prior on the coefﬁcients has important applications in many different domains. In machine learning, most methods to date search for maximum a posteriori sparse solutions and neglect to represent posterior uncertainties. In this paper, we address problems of Bayesian optimal design (or experiment planning), for which accurate estimates of uncertainty are essential. To this end, we employ expectation propagation approximate inference for the linear model with Laplace prior, giving new insight into numerical stability properties and proposing a robust algorithm. We also show how to estimate model hyperparameters by empirical Bayesian maximisation of the marginal likelihood, and propose ideas in order to scale up the method to very large underdetermined problems. We demonstrate the versatility of our framework on the application of gene regulatory network identiﬁcation from micro-array expression data, where both the Laplace prior and the active experimental design approach are shown to result in signiﬁcant improvements. We also address the problem of sparse coding of natural images, and show how our framework can be used for compressive sensing tasks. Part of this work appeared in Seeger et al. (2007b). The gene network identiﬁcation application appears in Steinke et al. (2007). Keywords: sparse linear model, Laplace prior, expectation propagation, approximate inference, optimal design, Bayesian statistics, gene network recovery, image coding, compressive sensing</p><p>6 0.33610725 <a title="53-lda-6" href="./jmlr-2008-Active_Learning_by_Spherical_Subdivision.html">9 jmlr-2008-Active Learning by Spherical Subdivision</a></p>
<p>7 0.3341482 <a title="53-lda-7" href="./jmlr-2008-Exponentiated_Gradient_Algorithms_for_Conditional_Random_Fields_and_Max-Margin_Markov_Networks.html">34 jmlr-2008-Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks</a></p>
<p>8 0.33168441 <a title="53-lda-8" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>9 0.3310051 <a title="53-lda-9" href="./jmlr-2008-Manifold_Learning%3A_The_Price_of_Normalization.html">57 jmlr-2008-Manifold Learning: The Price of Normalization</a></p>
<p>10 0.33057806 <a title="53-lda-10" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>11 0.32969052 <a title="53-lda-11" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>12 0.3295126 <a title="53-lda-12" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>13 0.32887286 <a title="53-lda-13" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>14 0.32848179 <a title="53-lda-14" href="./jmlr-2008-Hit_Miss_Networks_with_Applications_to_Instance_Selection.html">43 jmlr-2008-Hit Miss Networks with Applications to Instance Selection</a></p>
<p>15 0.32587904 <a title="53-lda-15" href="./jmlr-2008-Gradient_Tree_Boosting_for_Training_Conditional_Random_Fields.html">39 jmlr-2008-Gradient Tree Boosting for Training Conditional Random Fields</a></p>
<p>16 0.32483515 <a title="53-lda-16" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>17 0.32307392 <a title="53-lda-17" href="./jmlr-2008-Learning_Control_Knowledge_for_Forward_Search_Planning.html">49 jmlr-2008-Learning Control Knowledge for Forward Search Planning</a></p>
<p>18 0.32269931 <a title="53-lda-18" href="./jmlr-2008-Robust_Submodular_Observation_Selection.html">83 jmlr-2008-Robust Submodular Observation Selection</a></p>
<p>19 0.32059661 <a title="53-lda-19" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>20 0.31901422 <a title="53-lda-20" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
