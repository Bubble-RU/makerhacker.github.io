<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-66" href="#">jmlr2008-66</a> knowledge-graph by maker-knowledge-mining</p><h1>66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</h1>
<br/><p>Source: <a title="jmlr-2008-66-pdf" href="http://jmlr.org/papers/volume9/ye08b/ye08b.pdf">pdf</a></p><p>Author: Jieping Ye, Shuiwang Ji, Jianhui Chen</p><p>Abstract: Regularized kernel discriminant analysis (RKDA) performs linear discriminant analysis in the feature space via the kernel trick. Its performance depends on the selection of kernels. In this paper, we consider the problem of multiple kernel learning (MKL) for RKDA, in which the optimal kernel matrix is obtained as a linear combination of pre-speciﬁed kernel matrices. We show that the kernel learning problem in RKDA can be formulated as convex programs. First, we show that this problem can be formulated as a semideﬁnite program (SDP). Based on the equivalence relationship between RKDA and least square problems in the binary-class case, we propose a convex quadratically constrained quadratic programming (QCQP) formulation for kernel learning in RKDA. A semi-inﬁnite linear programming (SILP) formulation is derived to further improve the efﬁciency. We extend these formulations to the multi-class case based on a key result established in this paper. That is, the multi-class RKDA kernel learning problem can be decomposed into a set of binary-class kernel learning problems which are constrained to share a common kernel. Based on this decomposition property, SDP formulations are proposed for the multi-class case. Furthermore, it leads naturally to QCQP and SILP formulations. As the performance of RKDA depends on the regularization parameter, we show that this parameter can also be optimized in a joint framework with the kernel. Extensive experiments have been conducted and analyzed, and connections to other algorithms are discussed. Keywords: model selection, kernel discriminant analysis, semideﬁnite programming, quadratically constrained quadratic programming, semi-inﬁnite linear programming</p><p>Reference: <a title="jmlr-2008-66-reference" href="../jmlr2008_reference/jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('silp', 0.483), ('qcqp', 0.443), ('sdp', 0.388), ('rkda', 0.37), ('kernel', 0.223), ('rkdak', 0.126), ('hen', 0.125), ('lanckriet', 0.124), ('iscrimin', 0.119), ('tsa', 0.103), ('stk', 0.094), ('ernel', 0.091), ('mkl', 0.09), ('ghi', 0.089), ('gi', 0.088), ('pgp', 0.074), ('satim', 0.072), ('footnot', 0.067), ('gab', 0.067), ('svm', 0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999881 <a title="66-tfidf-1" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>2 0.25394505 <a title="66-tfidf-2" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>3 0.14014286 <a title="66-tfidf-3" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>4 0.10182324 <a title="66-tfidf-4" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>5 0.084702261 <a title="66-tfidf-5" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>6 0.083553314 <a title="66-tfidf-6" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>7 0.077863827 <a title="66-tfidf-7" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>8 0.063600972 <a title="66-tfidf-8" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>9 0.055403627 <a title="66-tfidf-9" href="./jmlr-2008-Comments_on_the_Complete_Characterization_of_a_Family_of_Solutions_to_a_GeneralizedFisherCriterion.html">23 jmlr-2008-Comments on the Complete Characterization of a Family of Solutions to a GeneralizedFisherCriterion</a></p>
<p>10 0.04814158 <a title="66-tfidf-10" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>11 0.047263831 <a title="66-tfidf-11" href="./jmlr-2008-Nearly_Uniform_Validation_Improves_Compression-Based_Error_Bounds.html">68 jmlr-2008-Nearly Uniform Validation Improves Compression-Based Error Bounds</a></p>
<p>12 0.045404047 <a title="66-tfidf-12" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>13 0.045178186 <a title="66-tfidf-13" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>14 0.043239057 <a title="66-tfidf-14" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>15 0.040433042 <a title="66-tfidf-15" href="./jmlr-2008-Robust_Submodular_Observation_Selection.html">83 jmlr-2008-Robust Submodular Observation Selection</a></p>
<p>16 0.034551259 <a title="66-tfidf-16" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>17 0.034080185 <a title="66-tfidf-17" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<p>18 0.033312704 <a title="66-tfidf-18" href="./jmlr-2008-Near-Optimal_Sensor_Placements_in_Gaussian_Processes%3A_Theory%2C_Efficient_Algorithms_and_Empirical_Studies.html">67 jmlr-2008-Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies</a></p>
<p>19 0.033291869 <a title="66-tfidf-19" href="./jmlr-2008-Classification_with_a_Reject_Option_using_a_Hinge_Loss.html">21 jmlr-2008-Classification with a Reject Option using a Hinge Loss</a></p>
<p>20 0.032415416 <a title="66-tfidf-20" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.193), (1, 0.149), (2, 0.16), (3, -0.02), (4, 0.232), (5, -0.19), (6, -0.18), (7, -0.017), (8, -0.238), (9, 0.095), (10, 0.04), (11, -0.092), (12, 0.101), (13, 0.111), (14, -0.004), (15, -0.031), (16, 0.246), (17, -0.009), (18, -0.113), (19, 0.127), (20, -0.142), (21, 0.139), (22, 0.054), (23, -0.083), (24, -0.082), (25, 0.106), (26, 0.114), (27, 0.008), (28, 0.208), (29, -0.061), (30, -0.084), (31, 0.012), (32, 0.079), (33, -0.017), (34, 0.068), (35, 0.127), (36, -0.07), (37, -0.023), (38, 0.077), (39, 0.032), (40, 0.148), (41, -0.053), (42, 0.081), (43, -0.047), (44, 0.032), (45, -0.047), (46, -0.018), (47, -0.082), (48, 0.003), (49, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87310797 <a title="66-lsi-1" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>2 0.85563666 <a title="66-lsi-2" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>3 0.37851435 <a title="66-lsi-3" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>4 0.376973 <a title="66-lsi-4" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>5 0.36281914 <a title="66-lsi-5" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>6 0.34017351 <a title="66-lsi-6" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>7 0.24582249 <a title="66-lsi-7" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>8 0.21412461 <a title="66-lsi-8" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>9 0.19676749 <a title="66-lsi-9" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>10 0.18264453 <a title="66-lsi-10" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>11 0.18179208 <a title="66-lsi-11" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>12 0.17068632 <a title="66-lsi-12" href="./jmlr-2008-Optimization_Techniques_for_Semi-Supervised_Support_Vector_Machines.html">76 jmlr-2008-Optimization Techniques for Semi-Supervised Support Vector Machines</a></p>
<p>13 0.16973875 <a title="66-lsi-13" href="./jmlr-2008-Comments_on_the_Complete_Characterization_of_a_Family_of_Solutions_to_a_GeneralizedFisherCriterion.html">23 jmlr-2008-Comments on the Complete Characterization of a Family of Solutions to a GeneralizedFisherCriterion</a></p>
<p>14 0.16814835 <a title="66-lsi-14" href="./jmlr-2008-Shark%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">85 jmlr-2008-Shark    (Machine Learning Open Source Software Paper)</a></p>
<p>15 0.16732749 <a title="66-lsi-15" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<p>16 0.16168073 <a title="66-lsi-16" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>17 0.1580424 <a title="66-lsi-17" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>18 0.15747997 <a title="66-lsi-18" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>19 0.14407988 <a title="66-lsi-19" href="./jmlr-2008-Regularization_on_Graphs_with_Function-adapted_Diffusion_Processes.html">81 jmlr-2008-Regularization on Graphs with Function-adapted Diffusion Processes</a></p>
<p>20 0.14145361 <a title="66-lsi-20" href="./jmlr-2008-Near-Optimal_Sensor_Placements_in_Gaussian_Processes%3A_Theory%2C_Efficient_Algorithms_and_Empirical_Studies.html">67 jmlr-2008-Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.023), (4, 0.017), (6, 0.014), (10, 0.032), (25, 0.026), (26, 0.568), (53, 0.014), (66, 0.089), (69, 0.019), (91, 0.039), (96, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92576623 <a title="66-lda-1" href="./jmlr-2008-Shark%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">85 jmlr-2008-Shark    (Machine Learning Open Source Software Paper)</a></p>
<p>2 0.89037144 <a title="66-lda-2" href="./jmlr-2008-On_the_Suitable_Domain_for_SVM_Training_in_Image_Coding.html">73 jmlr-2008-On the Suitable Domain for SVM Training in Image Coding</a></p>
<p>same-paper 3 0.87525815 <a title="66-lda-3" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>4 0.84949827 <a title="66-lda-4" href="./jmlr-2008-Active_Learning_of_Causal_Networks_with_Intervention_Experiments_and_Optimal_Designs%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">10 jmlr-2008-Active Learning of Causal Networks with Intervention Experiments and Optimal Designs    (Special Topic on Causality)</a></p>
<p>5 0.62850374 <a title="66-lda-5" href="./jmlr-2008-LIBLINEAR%3A_A_Library_for_Large_Linear_Classification%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">46 jmlr-2008-LIBLINEAR: A Library for Large Linear Classification    (Machine Learning Open Source Software Paper)</a></p>
<p>6 0.58801949 <a title="66-lda-6" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>7 0.5345422 <a title="66-lda-7" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>8 0.50444102 <a title="66-lda-8" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>9 0.49602979 <a title="66-lda-9" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>10 0.49290606 <a title="66-lda-10" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>11 0.475793 <a title="66-lda-11" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>12 0.47402388 <a title="66-lda-12" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>13 0.45863408 <a title="66-lda-13" href="./jmlr-2008-Graphical_Methods_for_Efficient_Likelihood_Inference_in_Gaussian_Covariance_Models.html">40 jmlr-2008-Graphical Methods for Efficient Likelihood Inference in Gaussian Covariance Models</a></p>
<p>14 0.45253095 <a title="66-lda-14" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<p>15 0.45238671 <a title="66-lda-15" href="./jmlr-2008-Comments_on_the_Complete_Characterization_of_a_Family_of_Solutions_to_a_GeneralizedFisherCriterion.html">23 jmlr-2008-Comments on the Complete Characterization of a Family of Solutions to a GeneralizedFisherCriterion</a></p>
<p>16 0.44447374 <a title="66-lda-16" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>17 0.43786076 <a title="66-lda-17" href="./jmlr-2008-Near-Optimal_Sensor_Placements_in_Gaussian_Processes%3A_Theory%2C_Efficient_Algorithms_and_Empirical_Studies.html">67 jmlr-2008-Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies</a></p>
<p>18 0.42897543 <a title="66-lda-18" href="./jmlr-2008-Optimization_Techniques_for_Semi-Supervised_Support_Vector_Machines.html">76 jmlr-2008-Optimization Techniques for Semi-Supervised Support Vector Machines</a></p>
<p>19 0.42832327 <a title="66-lda-19" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>20 0.42150182 <a title="66-lda-20" href="./jmlr-2008-Coordinate_Descent_Method_for_Large-scale_L2-loss_Linear_Support_Vector_Machines.html">28 jmlr-2008-Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
