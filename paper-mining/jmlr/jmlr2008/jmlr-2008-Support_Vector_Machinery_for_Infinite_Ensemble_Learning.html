<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-89" href="#">jmlr2008-89</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</h1>
<br/><p>Source: <a title="jmlr-2008-89-pdf" href="http://jmlr.org/papers/volume9/lin08a/lin08a.pdf">pdf</a></p><p>Author: Hsuan-Tien Lin, Ling Li</p><p>Abstract: Ensemble learning algorithms such as boosting can achieve better performance by averaging over the predictions of some base hypotheses. Nevertheless, most existing algorithms are limited to combining only a ﬁnite number of hypotheses, and the generated ensemble is usually sparse. Thus, it is not clear whether we should construct an ensemble classiﬁer with a larger or even an inﬁnite number of hypotheses. In addition, constructing an inﬁnite ensemble itself is a challenging task. In this paper, we formulate an inﬁnite ensemble learning framework based on the support vector machine (SVM). The framework can output an inﬁnite and nonsparse ensemble through embedding inﬁnitely many hypotheses into an SVM kernel. We use the framework to derive two novel kernels, the stump kernel and the perceptron kernel. The stump kernel embodies inﬁnitely many decision stumps, and the perceptron kernel embodies inﬁnitely many perceptrons. We also show that the Laplacian radial basis function kernel embodies inﬁnitely many decision trees, and can thus be explained through inﬁnite ensemble learning. Experimental results show that SVM with these kernels is superior to boosting with the same base hypothesis set. In addition, SVM with the stump kernel or the perceptron kernel performs similarly to SVM with the Gaussian radial basis function kernel, but enjoys the beneﬁt of faster parameter selection. These properties make the novel kernels favorable choices in practice. Keywords: ensemble learning, boosting, support vector machine, kernel</p><p>Reference: <a title="jmlr-2008-89-reference" href="../jmlr2008_reference/jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('stump', 0.561), ('ensembl', 0.476), ('kernel', 0.253), ('perceptron', 0.185), ('lpboost', 0.181), ('adaboost', 0.147), ('ks', 0.143), ('achinery', 0.131), ('nfinit', 0.131), ('nsembl', 0.131), ('kh', 0.13), ('embody', 0.124), ('svm', 0.121), ('kp', 0.121), ('upport', 0.099), ('hypothes', 0.092), ('decid', 0.083), ('ktl', 0.081), ('ld', 0.077), ('boost', 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="89-tfidf-1" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>2 0.34687808 <a title="89-tfidf-2" href="./jmlr-2008-Responses_to_Evidence_Contrary_to_the_Statistical_View_of_Boosting.html">82 jmlr-2008-Responses to Evidence Contrary to the Statistical View of Boosting</a></p>
<p>3 0.22158287 <a title="89-tfidf-3" href="./jmlr-2008-Evidence_Contrary_to_the_Statistical_View_of_Boosting.html">33 jmlr-2008-Evidence Contrary to the Statistical View of Boosting</a></p>
<p>4 0.15158728 <a title="89-tfidf-4" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>5 0.12185615 <a title="89-tfidf-5" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>6 0.10217825 <a title="89-tfidf-6" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>7 0.085022859 <a title="89-tfidf-7" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>8 0.084702261 <a title="89-tfidf-8" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>9 0.080732666 <a title="89-tfidf-9" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>10 0.077039294 <a title="89-tfidf-10" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>11 0.061456177 <a title="89-tfidf-11" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>12 0.056786831 <a title="89-tfidf-12" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>13 0.046942946 <a title="89-tfidf-13" href="./jmlr-2008-Consistency_of_Random_Forests_and_Other_Averaging_Classifiers.html">25 jmlr-2008-Consistency of Random Forests and Other Averaging Classifiers</a></p>
<p>14 0.046833616 <a title="89-tfidf-14" href="./jmlr-2008-Optimization_Techniques_for_Semi-Supervised_Support_Vector_Machines.html">76 jmlr-2008-Optimization Techniques for Semi-Supervised Support Vector Machines</a></p>
<p>15 0.043707859 <a title="89-tfidf-15" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>16 0.04356372 <a title="89-tfidf-16" href="./jmlr-2008-Classification_with_a_Reject_Option_using_a_Hinge_Loss.html">21 jmlr-2008-Classification with a Reject Option using a Hinge Loss</a></p>
<p>17 0.043383192 <a title="89-tfidf-17" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>18 0.040877044 <a title="89-tfidf-18" href="./jmlr-2008-An_Extension_on_%22Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets%22_for_all_Pairwise_Comparisons.html">14 jmlr-2008-An Extension on "Statistical Comparisons of Classifiers over Multiple Data Sets" for all Pairwise Comparisons</a></p>
<p>19 0.038632322 <a title="89-tfidf-19" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>20 0.038543254 <a title="89-tfidf-20" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.227), (1, 0.164), (2, 0.598), (3, 0.155), (4, -0.009), (5, 0.008), (6, 0.213), (7, 0.042), (8, -0.049), (9, 0.084), (10, 0.036), (11, 0.008), (12, 0.013), (13, -0.018), (14, -0.022), (15, 0.017), (16, 0.004), (17, -0.0), (18, -0.022), (19, 0.0), (20, -0.05), (21, -0.037), (22, 0.005), (23, 0.008), (24, 0.057), (25, 0.008), (26, -0.015), (27, 0.004), (28, -0.014), (29, 0.05), (30, 0.003), (31, 0.001), (32, 0.003), (33, 0.005), (34, -0.027), (35, -0.025), (36, 0.077), (37, -0.024), (38, 0.013), (39, -0.024), (40, -0.05), (41, 0.03), (42, -0.035), (43, 0.013), (44, 0.002), (45, 0.01), (46, 0.013), (47, 0.012), (48, -0.017), (49, 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89112556 <a title="89-lsi-1" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>2 0.83280504 <a title="89-lsi-2" href="./jmlr-2008-Responses_to_Evidence_Contrary_to_the_Statistical_View_of_Boosting.html">82 jmlr-2008-Responses to Evidence Contrary to the Statistical View of Boosting</a></p>
<p>3 0.79038256 <a title="89-lsi-3" href="./jmlr-2008-Evidence_Contrary_to_the_Statistical_View_of_Boosting.html">33 jmlr-2008-Evidence Contrary to the Statistical View of Boosting</a></p>
<p>4 0.45697737 <a title="89-lsi-4" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>5 0.45037821 <a title="89-lsi-5" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>6 0.38885051 <a title="89-lsi-6" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>7 0.38661116 <a title="89-lsi-7" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>8 0.3685087 <a title="89-lsi-8" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>9 0.35421273 <a title="89-lsi-9" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>10 0.29888076 <a title="89-lsi-10" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>11 0.26640406 <a title="89-lsi-11" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>12 0.23289976 <a title="89-lsi-12" href="./jmlr-2008-Regularization_on_Graphs_with_Function-adapted_Diffusion_Processes.html">81 jmlr-2008-Regularization on Graphs with Function-adapted Diffusion Processes</a></p>
<p>13 0.22700764 <a title="89-lsi-13" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>14 0.21875486 <a title="89-lsi-14" href="./jmlr-2008-An_Extension_on_%22Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets%22_for_all_Pairwise_Comparisons.html">14 jmlr-2008-An Extension on "Statistical Comparisons of Classifiers over Multiple Data Sets" for all Pairwise Comparisons</a></p>
<p>15 0.19882409 <a title="89-lsi-15" href="./jmlr-2008-Optimization_Techniques_for_Semi-Supervised_Support_Vector_Machines.html">76 jmlr-2008-Optimization Techniques for Semi-Supervised Support Vector Machines</a></p>
<p>16 0.19638024 <a title="89-lsi-16" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>17 0.19356468 <a title="89-lsi-17" href="./jmlr-2008-Shark%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">85 jmlr-2008-Shark    (Machine Learning Open Source Software Paper)</a></p>
<p>18 0.19096251 <a title="89-lsi-18" href="./jmlr-2008-Gradient_Tree_Boosting_for_Training_Conditional_Random_Fields.html">39 jmlr-2008-Gradient Tree Boosting for Training Conditional Random Fields</a></p>
<p>19 0.1805815 <a title="89-lsi-19" href="./jmlr-2008-Classification_with_a_Reject_Option_using_a_Hinge_Loss.html">21 jmlr-2008-Classification with a Reject Option using a Hinge Loss</a></p>
<p>20 0.17944391 <a title="89-lsi-20" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.027), (4, 0.023), (10, 0.026), (25, 0.028), (26, 0.077), (42, 0.013), (53, 0.463), (59, 0.017), (66, 0.095), (86, 0.011), (91, 0.039), (96, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.6544944 <a title="89-lda-1" href="./jmlr-2008-Incremental_Identification_of_Qualitative_Models_of_Biological_Systems_using_Inductive_Logic_Programming.html">44 jmlr-2008-Incremental Identification of Qualitative Models of Biological Systems using Inductive Logic Programming</a></p>
<p>same-paper 2 0.62725037 <a title="89-lda-2" href="./jmlr-2008-Support_Vector_Machinery_for_Infinite_Ensemble_Learning.html">89 jmlr-2008-Support Vector Machinery for Infinite Ensemble Learning</a></p>
<p>3 0.29519802 <a title="89-lda-3" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>4 0.29407549 <a title="89-lda-4" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>5 0.29016027 <a title="89-lda-5" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>6 0.28431123 <a title="89-lda-6" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>7 0.28422511 <a title="89-lda-7" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>8 0.28343159 <a title="89-lda-8" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>9 0.28197408 <a title="89-lda-9" href="./jmlr-2008-LIBLINEAR%3A_A_Library_for_Large_Linear_Classification%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">46 jmlr-2008-LIBLINEAR: A Library for Large Linear Classification    (Machine Learning Open Source Software Paper)</a></p>
<p>10 0.28063884 <a title="89-lda-10" href="./jmlr-2008-Coordinate_Descent_Method_for_Large-scale_L2-loss_Linear_Support_Vector_Machines.html">28 jmlr-2008-Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines</a></p>
<p>11 0.27953607 <a title="89-lda-11" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<p>12 0.27945298 <a title="89-lda-12" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>13 0.27813506 <a title="89-lda-13" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>14 0.27623737 <a title="89-lda-14" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>15 0.27570093 <a title="89-lda-15" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<p>16 0.2750867 <a title="89-lda-16" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>17 0.27338201 <a title="89-lda-17" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>18 0.27304938 <a title="89-lda-18" href="./jmlr-2008-Optimization_Techniques_for_Semi-Supervised_Support_Vector_Machines.html">76 jmlr-2008-Optimization Techniques for Semi-Supervised Support Vector Machines</a></p>
<p>19 0.27298665 <a title="89-lda-19" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>20 0.27253526 <a title="89-lda-20" href="./jmlr-2008-On_the_Suitable_Domain_for_SVM_Training_in_Image_Coding.html">73 jmlr-2008-On the Suitable Domain for SVM Training in Image Coding</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
