<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>27 jmlr-2008-Consistency of the Group Lasso and Multiple Kernel Learning</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-27" href="#">jmlr2008-27</a> knowledge-graph by maker-knowledge-mining</p><h1>27 jmlr-2008-Consistency of the Group Lasso and Multiple Kernel Learning</h1>
<br/><p>Source: <a title="jmlr-2008-27-pdf" href="http://jmlr.org/papers/volume9/bach08b/bach08b.pdf">pdf</a></p><p>Author: Francis R. Bach</p><p>Abstract: We consider the least-square regression problem with regularization by a block 1 -norm, that is, a sum of Euclidean norms over spaces of dimensions larger than one. This problem, referred to as the group Lasso, extends the usual regularization by the 1 -norm where all spaces have dimension one, where it is commonly referred to as the Lasso. In this paper, we study the asymptotic group selection consistency of the group Lasso. We derive necessary and sufﬁcient conditions for the consistency of group Lasso under practical assumptions, such as model misspeciﬁcation. When the linear predictors and Euclidean norms are replaced by functions and reproducing kernel Hilbert norms, the problem is usually referred to as multiple kernel learning and is commonly used for learning from heterogeneous data sources and for non linear variable selection. Using tools from functional analysis, and in particular covariance operators, we extend the consistency results to this inﬁnite dimensional case and also propose an adaptive scheme to obtain a consistent model estimate, even when the necessary condition required for the non adaptive scheme is not satisﬁed. Keywords: sparsity, regularization, consistency, convex optimization, covariance operators</p><p>Reference: <a title="jmlr-2008-27-reference" href="../jmlr2008_reference/jmlr-2008-Consistency_of_the_Group_Lasso_and_Multiple_Kernel_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xj', 0.831), ('wj', 0.356), ('fj', 0.209), ('xx', 0.154), ('lasso', 0.116), ('cxj', 0.1), ('diag', 0.095), ('dj', 0.071), ('bach', 0.07), ('asso', 0.068), ('fi', 0.065), ('xiy', 0.065), ('roup', 0.058), ('di', 0.055), ('group', 0.055), ('xi', 0.053), ('onsist', 0.052), ('cxi', 0.047), ('ernel', 0.046), ('jc', 0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999917 <a title="27-tfidf-1" href="./jmlr-2008-Consistency_of_the_Group_Lasso_and_Multiple_Kernel_Learning.html">27 jmlr-2008-Consistency of the Group Lasso and Multiple Kernel Learning</a></p>
<p>2 0.098599657 <a title="27-tfidf-2" href="./jmlr-2008-Consistency_of_Trace_Norm_Minimization.html">26 jmlr-2008-Consistency of Trace Norm Minimization</a></p>
<p>3 0.067464732 <a title="27-tfidf-3" href="./jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective.html">90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</a></p>
<p>4 0.064691052 <a title="27-tfidf-4" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>5 0.061129298 <a title="27-tfidf-5" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>6 0.046389215 <a title="27-tfidf-6" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>7 0.043891307 <a title="27-tfidf-7" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>8 0.037043557 <a title="27-tfidf-8" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>9 0.03566904 <a title="27-tfidf-9" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>10 0.035452642 <a title="27-tfidf-10" href="./jmlr-2008-Robust_Submodular_Observation_Selection.html">83 jmlr-2008-Robust Submodular Observation Selection</a></p>
<p>11 0.033556294 <a title="27-tfidf-11" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>12 0.033224188 <a title="27-tfidf-12" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>13 0.02992468 <a title="27-tfidf-13" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>14 0.026019126 <a title="27-tfidf-14" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>15 0.024565671 <a title="27-tfidf-15" href="./jmlr-2008-Non-Parametric_Modeling_of_Partially_Ranked_Data.html">69 jmlr-2008-Non-Parametric Modeling of Partially Ranked Data</a></p>
<p>16 0.024258394 <a title="27-tfidf-16" href="./jmlr-2008-A_Moment_Bound_for_Multi-hinge_Classifiers.html">3 jmlr-2008-A Moment Bound for Multi-hinge Classifiers</a></p>
<p>17 0.024208538 <a title="27-tfidf-17" href="./jmlr-2008-Multi-class_Discriminant_Kernel_Learning_via_Convex_Programming%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">66 jmlr-2008-Multi-class Discriminant Kernel Learning via Convex Programming    (Special Topic on Model Selection)</a></p>
<p>18 0.023339113 <a title="27-tfidf-18" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>19 0.021784415 <a title="27-tfidf-19" href="./jmlr-2008-A_New_Algorithm_for_Estimating_the_Effective_Dimension-Reduction_Subspace.html">5 jmlr-2008-A New Algorithm for Estimating the Effective Dimension-Reduction Subspace</a></p>
<p>20 0.021199957 <a title="27-tfidf-20" href="./jmlr-2008-Ranking_Individuals_by_Group_Comparisons.html">80 jmlr-2008-Ranking Individuals by Group Comparisons</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.119), (1, 0.052), (2, -0.041), (3, 0.009), (4, 0.063), (5, -0.047), (6, 0.042), (7, 0.057), (8, -0.085), (9, -0.017), (10, -0.046), (11, -0.13), (12, -0.182), (13, -0.076), (14, 0.008), (15, -0.176), (16, 0.062), (17, 0.044), (18, 0.102), (19, -0.066), (20, 0.142), (21, 0.218), (22, 0.074), (23, 0.086), (24, 0.184), (25, 0.121), (26, 0.163), (27, -0.028), (28, 0.051), (29, 0.115), (30, 0.033), (31, -0.034), (32, -0.037), (33, 0.096), (34, -0.208), (35, 0.142), (36, -0.079), (37, 0.012), (38, -0.101), (39, -0.141), (40, -0.205), (41, -0.277), (42, 0.066), (43, 0.14), (44, -0.264), (45, -0.112), (46, -0.126), (47, 0.249), (48, 0.198), (49, 0.008)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95872992 <a title="27-lsi-1" href="./jmlr-2008-Consistency_of_the_Group_Lasso_and_Multiple_Kernel_Learning.html">27 jmlr-2008-Consistency of the Group Lasso and Multiple Kernel Learning</a></p>
<p>2 0.50360447 <a title="27-lsi-2" href="./jmlr-2008-Consistency_of_Trace_Norm_Minimization.html">26 jmlr-2008-Consistency of Trace Norm Minimization</a></p>
<p>3 0.21216744 <a title="27-lsi-3" href="./jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective.html">90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</a></p>
<p>4 0.17094637 <a title="27-lsi-4" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>5 0.1687112 <a title="27-lsi-5" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>6 0.1432585 <a title="27-lsi-6" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>7 0.14035565 <a title="27-lsi-7" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>8 0.12409723 <a title="27-lsi-8" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>9 0.11416759 <a title="27-lsi-9" href="./jmlr-2008-Model_Selection_in_Kernel_Based_Regression_using_the_Influence_Function%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Model_Selection%29.html">64 jmlr-2008-Model Selection in Kernel Based Regression using the Influence Function    (Special Topic on Model Selection)</a></p>
<p>10 0.1113767 <a title="27-lsi-10" href="./jmlr-2008-A_Moment_Bound_for_Multi-hinge_Classifiers.html">3 jmlr-2008-A Moment Bound for Multi-hinge Classifiers</a></p>
<p>11 0.11078787 <a title="27-lsi-11" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>12 0.10659001 <a title="27-lsi-12" href="./jmlr-2008-Minimal_Nonlinear_Distortion_Principle_for_Nonlinear_Independent_Component_Analysis.html">60 jmlr-2008-Minimal Nonlinear Distortion Principle for Nonlinear Independent Component Analysis</a></p>
<p>13 0.10469852 <a title="27-lsi-13" href="./jmlr-2008-Robust_Submodular_Observation_Selection.html">83 jmlr-2008-Robust Submodular Observation Selection</a></p>
<p>14 0.10274908 <a title="27-lsi-14" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>15 0.090021171 <a title="27-lsi-15" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>16 0.08691787 <a title="27-lsi-16" href="./jmlr-2008-Complete_Identification_Methods_for_the_Causal_Hierarchy%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">24 jmlr-2008-Complete Identification Methods for the Causal Hierarchy    (Special Topic on Causality)</a></p>
<p>17 0.081008516 <a title="27-lsi-17" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>18 0.080372505 <a title="27-lsi-18" href="./jmlr-2008-Consistency_of_Random_Forests_and_Other_Averaging_Classifiers.html">25 jmlr-2008-Consistency of Random Forests and Other Averaging Classifiers</a></p>
<p>19 0.07968156 <a title="27-lsi-19" href="./jmlr-2008-Ranking_Individuals_by_Group_Comparisons.html">80 jmlr-2008-Ranking Individuals by Group Comparisons</a></p>
<p>20 0.078529105 <a title="27-lsi-20" href="./jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.036), (3, 0.032), (4, 0.015), (6, 0.011), (10, 0.033), (11, 0.025), (25, 0.02), (26, 0.053), (66, 0.135), (81, 0.365), (86, 0.014), (91, 0.035), (96, 0.065), (99, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.66546357 <a title="27-lda-1" href="./jmlr-2008-Consistency_of_the_Group_Lasso_and_Multiple_Kernel_Learning.html">27 jmlr-2008-Consistency of the Group Lasso and Multiple Kernel Learning</a></p>
<p>2 0.62092042 <a title="27-lda-2" href="./jmlr-2008-Graphical_Methods_for_Efficient_Likelihood_Inference_in_Gaussian_Covariance_Models.html">40 jmlr-2008-Graphical Methods for Efficient Likelihood Inference in Gaussian Covariance Models</a></p>
<p>3 0.42241931 <a title="27-lda-3" href="./jmlr-2008-Consistency_of_Trace_Norm_Minimization.html">26 jmlr-2008-Consistency of Trace Norm Minimization</a></p>
<p>4 0.41797405 <a title="27-lda-4" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>5 0.4119584 <a title="27-lda-5" href="./jmlr-2008-Manifold_Learning%3A_The_Price_of_Normalization.html">57 jmlr-2008-Manifold Learning: The Price of Normalization</a></p>
<p>6 0.41006905 <a title="27-lda-6" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>7 0.40895399 <a title="27-lda-7" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>8 0.4067297 <a title="27-lda-8" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>9 0.40646699 <a title="27-lda-9" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>10 0.40624556 <a title="27-lda-10" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>11 0.40545252 <a title="27-lda-11" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>12 0.40491724 <a title="27-lda-12" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>13 0.40263945 <a title="27-lda-13" href="./jmlr-2008-Universal_Multi-Task_Kernels.html">92 jmlr-2008-Universal Multi-Task Kernels</a></p>
<p>14 0.40209344 <a title="27-lda-14" href="./jmlr-2008-Coordinate_Descent_Method_for_Large-scale_L2-loss_Linear_Support_Vector_Machines.html">28 jmlr-2008-Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines</a></p>
<p>15 0.40208465 <a title="27-lda-15" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>16 0.40062097 <a title="27-lda-16" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>17 0.40022796 <a title="27-lda-17" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>18 0.39921799 <a title="27-lda-18" href="./jmlr-2008-Visualizing_Data_using_t-SNE.html">96 jmlr-2008-Visualizing Data using t-SNE</a></p>
<p>19 0.39888024 <a title="27-lda-19" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>20 0.39884174 <a title="27-lda-20" href="./jmlr-2008-Discriminative_Learning_of_Max-Sum_Classifiers.html">30 jmlr-2008-Discriminative Learning of Max-Sum Classifiers</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
