<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-90" href="#">jmlr2008-90</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</h1>
<br/><p>Source: <a title="jmlr-2008-90-pdf" href="http://jmlr.org/papers/volume9/panait08a/panait08a.pdf">pdf</a></p><p>Author: Liviu Panait, Karl Tuyls, Sean Luke</p><p>Abstract: This paper presents the dynamics of multiple learning agents from an evolutionary game theoretic perspective. We provide replicator dynamics models for cooperative coevolutionary algorithms and for traditional multiagent Q-learning, and we extend these differential equations to account for lenient learners: agents that forgive possible mismatched teammate actions that resulted in low rewards. We use these extended formal models to study the convergence guarantees for these algorithms, and also to visualize the basins of attraction to optimal and suboptimal solutions in two benchmark coordination problems. The paper demonstrates that lenience provides learners with more accurate information about the beneﬁts of performing their actions, resulting in higher likelihood of convergence to the globally optimal solution. In addition, the analysis indicates that the choice of learning algorithm has an insigniﬁcant impact on the overall performance of multiagent learning algorithms; rather, the performance of these algorithms depends primarily on the level of lenience that the agents exhibit to one another. Finally, the research herein supports the strength and generality of evolutionary game theory as a backbone for multiagent learning. Keywords: multiagent learning, reinforcement learning, cooperative coevolution, evolutionary game theory, formal models, visualization, basins of attraction</p><p>Reference: <a title="jmlr-2008-90-reference" href="../jmlr2008_reference/jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reward', 0.341), ('multy', 0.335), ('egt', 0.281), ('leny', 0.272), ('ag', 0.227), ('pop', 0.215), ('qai', 0.211), ('ai', 0.202), ('coevolv', 0.194), ('payoff', 0.18), ('panait', 0.171), ('yj', 0.144), ('basin', 0.14), ('qa', 0.14), ('collab', 0.137), ('dvant', 0.105), ('eny', 0.105), ('heoret', 0.105), ('uyl', 0.105), ('wiegand', 0.104)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="90-tfidf-1" href="./jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective.html">90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</a></p>
<p>Author: Liviu Panait, Karl Tuyls, Sean Luke</p><p>Abstract: This paper presents the dynamics of multiple learning agents from an evolutionary game theoretic perspective. We provide replicator dynamics models for cooperative coevolutionary algorithms and for traditional multiagent Q-learning, and we extend these differential equations to account for lenient learners: agents that forgive possible mismatched teammate actions that resulted in low rewards. We use these extended formal models to study the convergence guarantees for these algorithms, and also to visualize the basins of attraction to optimal and suboptimal solutions in two benchmark coordination problems. The paper demonstrates that lenience provides learners with more accurate information about the beneﬁts of performing their actions, resulting in higher likelihood of convergence to the globally optimal solution. In addition, the analysis indicates that the choice of learning algorithm has an insigniﬁcant impact on the overall performance of multiagent learning algorithms; rather, the performance of these algorithms depends primarily on the level of lenience that the agents exhibit to one another. Finally, the research herein supports the strength and generality of evolutionary game theory as a backbone for multiagent learning. Keywords: multiagent learning, reinforcement learning, cooperative coevolution, evolutionary game theory, formal models, visualization, basins of attraction</p><p>2 0.17902924 <a title="90-tfidf-2" href="./jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</a></p>
<p>Author: Avraham Bab, Ronen I. Brafman</p><p>Abstract: Multi Agent Reinforcement Learning (MARL) has received continually growing attention in the past decade. Many algorithms that vary in their approaches to the different subtasks of MARL have been developed. However, the theoretical convergence results for these algorithms do not give a clue as to their practical performance nor supply insights to the dynamics of the learning process itself. This work is a comprehensive empirical study conducted on MGS, a simulation system developed for this purpose. It surveys the important algorithms in the ﬁeld, demonstrates the strengths and weaknesses of the different approaches to MARL through application of FriendQ, OAL, WoLF, FoeQ, Rmax, and other algorithms to a variety of fully cooperative and fully competitive domains in self and heterogeneous play, and supplies an informal analysis of the resulting learning processes. The results can aid in the design of new learning algorithms, in matching existing algorithms to speciﬁc tasks, and may guide further research and formal analysis of the learning processes. Keywords: reinforcement learning, multi-agent reinforcement learning, stochastic games</p><p>3 0.15692982 <a title="90-tfidf-3" href="./jmlr-2008-Accelerated_Neural_Evolution_through_Cooperatively_Coevolved_Synapses.html">8 jmlr-2008-Accelerated Neural Evolution through Cooperatively Coevolved Synapses</a></p>
<p>Author: Faustino Gomez, Jürgen Schmidhuber, Risto Miikkulainen</p><p>Abstract: Many complex control problems require sophisticated solutions that are not amenable to traditional controller design. Not only is it difﬁcult to model real world systems, but often it is unclear what kind of behavior is required to solve the task. Reinforcement learning (RL) approaches have made progress by using direct interaction with the task environment, but have so far not scaled well to large state spaces and environments that are not fully observable. In recent years, neuroevolution, the artiﬁcial evolution of neural networks, has had remarkable success in tasks that exhibit these two properties. In this paper, we compare a neuroevolution method called Cooperative Synapse Neuroevolution (CoSyNE), that uses cooperative coevolution at the level of individual synaptic weights, to a broad range of reinforcement learning algorithms on very difﬁcult versions of the pole balancing problem that involve large (continuous) state spaces and hidden state. CoSyNE is shown to be signiﬁcantly more efﬁcient and powerful than the other methods on these tasks. Keywords: coevolution, recurrent neural networks, non-linear control, genetic algorithms, experimental comparison</p><p>4 0.074469991 <a title="90-tfidf-4" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>Author: David C. Hoyle</p><p>Abstract: Bayesian inference from high-dimensional data involves the integration over a large number of model parameters. Accurate evaluation of such high-dimensional integrals raises a unique set of issues. These issues are illustrated using the exemplar of model selection for principal component analysis (PCA). A Bayesian model selection criterion, based on a Laplace approximation to the model evidence for determining the number of signal principal components present in a data set, has previously been show to perform well on various test data sets. Using simulated data we show that for d-dimensional data and small sample sizes, N, the accuracy of this model selection method is strongly affected by increasing values of d. By taking proper account of the contribution to the evidence from the large number of model parameters we show that model selection accuracy is substantially improved. The accuracy of the improved model evidence is studied in the asymptotic limit d → ∞ at ﬁxed ratio α = N/d, with α < 1. In this limit, model selection based upon the improved model evidence agrees with a frequentist hypothesis testing approach. Keywords: PCA, Bayesian model selection, random matrix theory, high dimensional inference</p><p>5 0.070998713 <a title="90-tfidf-5" href="./jmlr-2008-Comments_on_the_Complete_Characterization_of_a_Family_of_Solutions_to_a_GeneralizedFisherCriterion.html">23 jmlr-2008-Comments on the Complete Characterization of a Family of Solutions to a GeneralizedFisherCriterion</a></p>
<p>Author: Jieping Ye</p><p>Abstract: Loog (2007) provided a complete characterization of the family of solutions to a generalized Fisher criterion. We show that this characterization is essentially equivalent to the original characterization proposed in Ye (2005). The computational advantage of the original characterization over the new one is discussed, which justiﬁes its practical use. Keywords: linear discriminant analysis, dimension reduction, linear transformation 1. Generalized Fisher Criterion For a given data set consisting of n data points {ai }n in IRd , a linear transformation G ∈ IRd× i=1 ( < d) maps each ai for 1 ≤ i ≤ n in the d-dimensional space to a vector ai in the -dimensional ˜ space as follows: G : ai ∈ IRd → ai = GT ai ∈ IR . ˜ Assume that there are k classes in the data set. The within-class scatter matrix S w , the betweenclass scatter matrix Sb , and the total scatter matrix St involved in linear discriminant analysis are deﬁned as follows (Fukunaga, 1990): k Sw = ∑ (Ai − ci eT )(Ai − ci eT )T , i=1 k Sb = ∑ ni (ci − c)(ci − c)T , i=1 k St = ∑ (Ai − ceT )(Ai − ceT )T , i=1 where Ai denotes the data matrix of the i-th class, ci = Ai e/ni is the centroid of the i-th class, ni is the sample size of the i-th class, c = Ae/n is the global centroid, and e is the vector of all ones with an appropriate length. It is easy to verify that St = Sb + Sw . In Ye (2005), the optimal transformation G is computed by maximizing a generalized Fisher criterion as follows: + G = arg max trace GT St G GT Sb G , (1) m× G∈IR c 2008 Jieping Ye. YE where M + denotes the pseudo-inverse (Golub and Van Loan, 1996) of M and it is introduced to overcome the singularity problem when dealing with high-dimensional low-sample-size data. 1.1 Equivalent Transformation Two linear transformations G1 and G2 can be considered equivalent if there is a vector v such that GT (ai − v) = GT (ai − v), for i = 1, · · · , n. Indeed, in this case, the difference between the projections 1 2 by G1 and G2 is a mere shift. Deﬁnition 1.1 For a given data set {a1 , · · · , an }, two transformations G1 and G2 are equivalent, if there is a vector v such that GT (ai − v) = GT (ai − v), for i = 1, · · · , n. 1 2 2. Characterization of Solutions to the Generalized Fisher Criterion Let St = UΣU T be the orthogonal eigendecomposition of St (note that St is symmetric and positive semi-deﬁnite), where U ∈ IRd×d is orthogonal and Σ ∈ IRd×d is diagonal with nonnegative diagonal entries sorted in nonincreasing order. Denote Σr as the r-th principal submatrix of Σ, where r = rank(St ). Partition U into two components as U = [U1 ,U2 ], where U1 ∈ IRd×r and U2 ∈ IRd×(d−r) . Note that r ≤ n, and for high-dimensional low-sample-size data, U1 is much smaller than U2 . In Loog (2007), a complete family of solutions S to the maximization problem in Eq. (1) is given as (We correct the error in Loog (2007) by using U instead of U T .) S= U ΛZ Y ∈ IRd× Z ∈ IR × is nonsingular , Y ∈ IR(n−r)× , where Λ ∈ IRr× maximizes the following objective function: F0 (X) = trace −1 X T Σr X T X T (U1 SbU1 )X . ˜ In Ye (2005), a family of solutions S is given as ˜ S= U ΛZ 0 ∈ IRd× Z ∈ IR × is nonsingular . The only difference between these two characterizations of solutions is the matrix Y in S , which is ˜ replaced by the zero matrix in S . We show in the next section the equivalence relationship between these two characterizations. 3. Equivalent Solution Characterizations ˜ Consider the following two transformations G1 and G2 from S and S respectively: G1 = U ΛZ Y ∈ S, G2 = U 518 ΛZ 0 ˜ ∈ S. O N THE C OMPLETE C HARACTERIZATION OF S OLUTIONS TO A G ENERALIZED F ISHER C RITERION Recall that U = [U1 ,U2 ], where the columns of U2 span the null space of St . Hence, n T T T 0 = U2 St U2 = ∑ U2 (ai − c) · (U2 (ai − c))T , i=1 T and U2 (ai − c) = 0, for i = 1, · · · , n, where c is the global centroid. It follows that T T T GT (ai − c) = Z T ΛT U1 (ai − c) +Y T U2 (ai − c) = Z T ΛT U1 (ai − c) = GT (ai − c), 1 2 for i = 1, · · · , n. That is, G1 and G2 are equivalent transformations. Hence, the two solution charac˜ terizations S and S are essentially equivalent. Remark 3.1 The analysis above shows that the additional information contained in S is the null ˜ space, U2 , of St , which leads to an equivalent transformation. In S , the null space U2 is removed, which can be further justiﬁed as follows. Since St = Sb + Sw , we have T T T 0 = U2 St U2 = U2 SbU2 +U2 SwU2 . T It follows that U2 SbU2 = 0, as both Sb and Sw are positive semi-deﬁnite. Thus, the null space U2 does not contain any discriminant information. This explains why the null space of St is removed in most discriminant analysis based algorithms proposed in the past. 4. Efﬁciency Comparison In S , the full matrix U is involved, whose computation may be expensive, especially for high˜ dimensional data. In contrast, only the ﬁrst component U1 ∈ IRd×r of U is involved in S , which can be computed efﬁciently for high-dimensional low-sample-size problem by directly working on the Gram matrix instead of the covariance matrix. ˜ In summary, we show that S and S are equivalent characterizations of the solutions to the generalized Fisher criterion in Eq. (1). However, the latter one is preferred in practice due to its relative efﬁciency for high-dimensional low-sample-size data. References K. Fukunaga. Introduction to Statistical Pattern Classiﬁcation. Academic Press, San Diego, California, USA, 1990. G. H. Golub and C. F. Van Loan. Matrix Computations. The Johns Hopkins University Press, Baltimore, MD, USA, third edition, 1996. M. Loog. A Complete Characterization of a Family of Solutions to a Generalized Fisher Criterion. Journal of Machine Learning Research, 8:2121–2123, 2007. J. Ye. Characterization of a Family of Algorithms for Generalized Discriminant Analysis on Undersampled Problems. Journal of Machine Learning Research, 6:483–502, 2005. 519</p><p>6 0.067464732 <a title="90-tfidf-6" href="./jmlr-2008-Consistency_of_the_Group_Lasso_and_Multiple_Kernel_Learning.html">27 jmlr-2008-Consistency of the Group Lasso and Multiple Kernel Learning</a></p>
<p>7 0.056945428 <a title="90-tfidf-7" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>8 0.047000404 <a title="90-tfidf-8" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>9 0.042171821 <a title="90-tfidf-9" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>10 0.041631944 <a title="90-tfidf-10" href="./jmlr-2008-Ranking_Individuals_by_Group_Comparisons.html">80 jmlr-2008-Ranking Individuals by Group Comparisons</a></p>
<p>11 0.036096424 <a title="90-tfidf-11" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>12 0.035240795 <a title="90-tfidf-12" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<p>13 0.034895688 <a title="90-tfidf-13" href="./jmlr-2008-An_Error_Bound_Based_on_a_Worst_Likely_Assignment.html">13 jmlr-2008-An Error Bound Based on a Worst Likely Assignment</a></p>
<p>14 0.03484033 <a title="90-tfidf-14" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>15 0.034831334 <a title="90-tfidf-15" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>16 0.030609572 <a title="90-tfidf-16" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>17 0.030400585 <a title="90-tfidf-17" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>18 0.030014925 <a title="90-tfidf-18" href="./jmlr-2008-Algorithms_for_Sparse_Linear_Classifiers_in_the_Massive_Data_Setting.html">12 jmlr-2008-Algorithms for Sparse Linear Classifiers in the Massive Data Setting</a></p>
<p>19 0.02939062 <a title="90-tfidf-19" href="./jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</a></p>
<p>20 0.029158495 <a title="90-tfidf-20" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.153), (1, 0.061), (2, -0.121), (3, 0.023), (4, -0.235), (5, -0.204), (6, 0.079), (7, 0.024), (8, -0.004), (9, 0.139), (10, 0.015), (11, 0.018), (12, -0.269), (13, 0.178), (14, -0.101), (15, -0.138), (16, 0.05), (17, -0.045), (18, -0.226), (19, -0.014), (20, 0.226), (21, 0.046), (22, 0.041), (23, 0.319), (24, 0.135), (25, 0.008), (26, 0.187), (27, -0.006), (28, -0.108), (29, 0.023), (30, -0.056), (31, 0.091), (32, 0.146), (33, -0.009), (34, 0.06), (35, 0.073), (36, 0.054), (37, 0.045), (38, 0.037), (39, -0.016), (40, 0.009), (41, -0.046), (42, -0.019), (43, 0.033), (44, 0.028), (45, -0.049), (46, -0.084), (47, -0.045), (48, -0.122), (49, -0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95295388 <a title="90-lsi-1" href="./jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective.html">90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</a></p>
<p>Author: Liviu Panait, Karl Tuyls, Sean Luke</p><p>Abstract: This paper presents the dynamics of multiple learning agents from an evolutionary game theoretic perspective. We provide replicator dynamics models for cooperative coevolutionary algorithms and for traditional multiagent Q-learning, and we extend these differential equations to account for lenient learners: agents that forgive possible mismatched teammate actions that resulted in low rewards. We use these extended formal models to study the convergence guarantees for these algorithms, and also to visualize the basins of attraction to optimal and suboptimal solutions in two benchmark coordination problems. The paper demonstrates that lenience provides learners with more accurate information about the beneﬁts of performing their actions, resulting in higher likelihood of convergence to the globally optimal solution. In addition, the analysis indicates that the choice of learning algorithm has an insigniﬁcant impact on the overall performance of multiagent learning algorithms; rather, the performance of these algorithms depends primarily on the level of lenience that the agents exhibit to one another. Finally, the research herein supports the strength and generality of evolutionary game theory as a backbone for multiagent learning. Keywords: multiagent learning, reinforcement learning, cooperative coevolution, evolutionary game theory, formal models, visualization, basins of attraction</p><p>2 0.70198321 <a title="90-lsi-2" href="./jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</a></p>
<p>Author: Avraham Bab, Ronen I. Brafman</p><p>Abstract: Multi Agent Reinforcement Learning (MARL) has received continually growing attention in the past decade. Many algorithms that vary in their approaches to the different subtasks of MARL have been developed. However, the theoretical convergence results for these algorithms do not give a clue as to their practical performance nor supply insights to the dynamics of the learning process itself. This work is a comprehensive empirical study conducted on MGS, a simulation system developed for this purpose. It surveys the important algorithms in the ﬁeld, demonstrates the strengths and weaknesses of the different approaches to MARL through application of FriendQ, OAL, WoLF, FoeQ, Rmax, and other algorithms to a variety of fully cooperative and fully competitive domains in self and heterogeneous play, and supplies an informal analysis of the resulting learning processes. The results can aid in the design of new learning algorithms, in matching existing algorithms to speciﬁc tasks, and may guide further research and formal analysis of the learning processes. Keywords: reinforcement learning, multi-agent reinforcement learning, stochastic games</p><p>3 0.57499993 <a title="90-lsi-3" href="./jmlr-2008-Accelerated_Neural_Evolution_through_Cooperatively_Coevolved_Synapses.html">8 jmlr-2008-Accelerated Neural Evolution through Cooperatively Coevolved Synapses</a></p>
<p>Author: Faustino Gomez, Jürgen Schmidhuber, Risto Miikkulainen</p><p>Abstract: Many complex control problems require sophisticated solutions that are not amenable to traditional controller design. Not only is it difﬁcult to model real world systems, but often it is unclear what kind of behavior is required to solve the task. Reinforcement learning (RL) approaches have made progress by using direct interaction with the task environment, but have so far not scaled well to large state spaces and environments that are not fully observable. In recent years, neuroevolution, the artiﬁcial evolution of neural networks, has had remarkable success in tasks that exhibit these two properties. In this paper, we compare a neuroevolution method called Cooperative Synapse Neuroevolution (CoSyNE), that uses cooperative coevolution at the level of individual synaptic weights, to a broad range of reinforcement learning algorithms on very difﬁcult versions of the pole balancing problem that involve large (continuous) state spaces and hidden state. CoSyNE is shown to be signiﬁcantly more efﬁcient and powerful than the other methods on these tasks. Keywords: coevolution, recurrent neural networks, non-linear control, genetic algorithms, experimental comparison</p><p>4 0.24653578 <a title="90-lsi-4" href="./jmlr-2008-Comments_on_the_Complete_Characterization_of_a_Family_of_Solutions_to_a_GeneralizedFisherCriterion.html">23 jmlr-2008-Comments on the Complete Characterization of a Family of Solutions to a GeneralizedFisherCriterion</a></p>
<p>Author: Jieping Ye</p><p>Abstract: Loog (2007) provided a complete characterization of the family of solutions to a generalized Fisher criterion. We show that this characterization is essentially equivalent to the original characterization proposed in Ye (2005). The computational advantage of the original characterization over the new one is discussed, which justiﬁes its practical use. Keywords: linear discriminant analysis, dimension reduction, linear transformation 1. Generalized Fisher Criterion For a given data set consisting of n data points {ai }n in IRd , a linear transformation G ∈ IRd× i=1 ( < d) maps each ai for 1 ≤ i ≤ n in the d-dimensional space to a vector ai in the -dimensional ˜ space as follows: G : ai ∈ IRd → ai = GT ai ∈ IR . ˜ Assume that there are k classes in the data set. The within-class scatter matrix S w , the betweenclass scatter matrix Sb , and the total scatter matrix St involved in linear discriminant analysis are deﬁned as follows (Fukunaga, 1990): k Sw = ∑ (Ai − ci eT )(Ai − ci eT )T , i=1 k Sb = ∑ ni (ci − c)(ci − c)T , i=1 k St = ∑ (Ai − ceT )(Ai − ceT )T , i=1 where Ai denotes the data matrix of the i-th class, ci = Ai e/ni is the centroid of the i-th class, ni is the sample size of the i-th class, c = Ae/n is the global centroid, and e is the vector of all ones with an appropriate length. It is easy to verify that St = Sb + Sw . In Ye (2005), the optimal transformation G is computed by maximizing a generalized Fisher criterion as follows: + G = arg max trace GT St G GT Sb G , (1) m× G∈IR c 2008 Jieping Ye. YE where M + denotes the pseudo-inverse (Golub and Van Loan, 1996) of M and it is introduced to overcome the singularity problem when dealing with high-dimensional low-sample-size data. 1.1 Equivalent Transformation Two linear transformations G1 and G2 can be considered equivalent if there is a vector v such that GT (ai − v) = GT (ai − v), for i = 1, · · · , n. Indeed, in this case, the difference between the projections 1 2 by G1 and G2 is a mere shift. Deﬁnition 1.1 For a given data set {a1 , · · · , an }, two transformations G1 and G2 are equivalent, if there is a vector v such that GT (ai − v) = GT (ai − v), for i = 1, · · · , n. 1 2 2. Characterization of Solutions to the Generalized Fisher Criterion Let St = UΣU T be the orthogonal eigendecomposition of St (note that St is symmetric and positive semi-deﬁnite), where U ∈ IRd×d is orthogonal and Σ ∈ IRd×d is diagonal with nonnegative diagonal entries sorted in nonincreasing order. Denote Σr as the r-th principal submatrix of Σ, where r = rank(St ). Partition U into two components as U = [U1 ,U2 ], where U1 ∈ IRd×r and U2 ∈ IRd×(d−r) . Note that r ≤ n, and for high-dimensional low-sample-size data, U1 is much smaller than U2 . In Loog (2007), a complete family of solutions S to the maximization problem in Eq. (1) is given as (We correct the error in Loog (2007) by using U instead of U T .) S= U ΛZ Y ∈ IRd× Z ∈ IR × is nonsingular , Y ∈ IR(n−r)× , where Λ ∈ IRr× maximizes the following objective function: F0 (X) = trace −1 X T Σr X T X T (U1 SbU1 )X . ˜ In Ye (2005), a family of solutions S is given as ˜ S= U ΛZ 0 ∈ IRd× Z ∈ IR × is nonsingular . The only difference between these two characterizations of solutions is the matrix Y in S , which is ˜ replaced by the zero matrix in S . We show in the next section the equivalence relationship between these two characterizations. 3. Equivalent Solution Characterizations ˜ Consider the following two transformations G1 and G2 from S and S respectively: G1 = U ΛZ Y ∈ S, G2 = U 518 ΛZ 0 ˜ ∈ S. O N THE C OMPLETE C HARACTERIZATION OF S OLUTIONS TO A G ENERALIZED F ISHER C RITERION Recall that U = [U1 ,U2 ], where the columns of U2 span the null space of St . Hence, n T T T 0 = U2 St U2 = ∑ U2 (ai − c) · (U2 (ai − c))T , i=1 T and U2 (ai − c) = 0, for i = 1, · · · , n, where c is the global centroid. It follows that T T T GT (ai − c) = Z T ΛT U1 (ai − c) +Y T U2 (ai − c) = Z T ΛT U1 (ai − c) = GT (ai − c), 1 2 for i = 1, · · · , n. That is, G1 and G2 are equivalent transformations. Hence, the two solution charac˜ terizations S and S are essentially equivalent. Remark 3.1 The analysis above shows that the additional information contained in S is the null ˜ space, U2 , of St , which leads to an equivalent transformation. In S , the null space U2 is removed, which can be further justiﬁed as follows. Since St = Sb + Sw , we have T T T 0 = U2 St U2 = U2 SbU2 +U2 SwU2 . T It follows that U2 SbU2 = 0, as both Sb and Sw are positive semi-deﬁnite. Thus, the null space U2 does not contain any discriminant information. This explains why the null space of St is removed in most discriminant analysis based algorithms proposed in the past. 4. Efﬁciency Comparison In S , the full matrix U is involved, whose computation may be expensive, especially for high˜ dimensional data. In contrast, only the ﬁrst component U1 ∈ IRd×r of U is involved in S , which can be computed efﬁciently for high-dimensional low-sample-size problem by directly working on the Gram matrix instead of the covariance matrix. ˜ In summary, we show that S and S are equivalent characterizations of the solutions to the generalized Fisher criterion in Eq. (1). However, the latter one is preferred in practice due to its relative efﬁciency for high-dimensional low-sample-size data. References K. Fukunaga. Introduction to Statistical Pattern Classiﬁcation. Academic Press, San Diego, California, USA, 1990. G. H. Golub and C. F. Van Loan. Matrix Computations. The Johns Hopkins University Press, Baltimore, MD, USA, third edition, 1996. M. Loog. A Complete Characterization of a Family of Solutions to a Generalized Fisher Criterion. Journal of Machine Learning Research, 8:2121–2123, 2007. J. Ye. Characterization of a Family of Algorithms for Generalized Discriminant Analysis on Undersampled Problems. Journal of Machine Learning Research, 6:483–502, 2005. 519</p><p>5 0.23944995 <a title="90-lsi-5" href="./jmlr-2008-Consistency_of_the_Group_Lasso_and_Multiple_Kernel_Learning.html">27 jmlr-2008-Consistency of the Group Lasso and Multiple Kernel Learning</a></p>
<p>Author: Francis R. Bach</p><p>Abstract: We consider the least-square regression problem with regularization by a block 1 -norm, that is, a sum of Euclidean norms over spaces of dimensions larger than one. This problem, referred to as the group Lasso, extends the usual regularization by the 1 -norm where all spaces have dimension one, where it is commonly referred to as the Lasso. In this paper, we study the asymptotic group selection consistency of the group Lasso. We derive necessary and sufﬁcient conditions for the consistency of group Lasso under practical assumptions, such as model misspeciﬁcation. When the linear predictors and Euclidean norms are replaced by functions and reproducing kernel Hilbert norms, the problem is usually referred to as multiple kernel learning and is commonly used for learning from heterogeneous data sources and for non linear variable selection. Using tools from functional analysis, and in particular covariance operators, we extend the consistency results to this inﬁnite dimensional case and also propose an adaptive scheme to obtain a consistent model estimate, even when the necessary condition required for the non adaptive scheme is not satisﬁed. Keywords: sparsity, regularization, consistency, convex optimization, covariance operators</p><p>6 0.2102804 <a title="90-lsi-6" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>7 0.13858445 <a title="90-lsi-7" href="./jmlr-2008-Algorithms_for_Sparse_Linear_Classifiers_in_the_Massive_Data_Setting.html">12 jmlr-2008-Algorithms for Sparse Linear Classifiers in the Massive Data Setting</a></p>
<p>8 0.13792109 <a title="90-lsi-8" href="./jmlr-2008-Exponentiated_Gradient_Algorithms_for_Conditional_Random_Fields_and_Max-Margin_Markov_Networks.html">34 jmlr-2008-Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks</a></p>
<p>9 0.12716202 <a title="90-lsi-9" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>10 0.12332368 <a title="90-lsi-10" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<p>11 0.12175012 <a title="90-lsi-11" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>12 0.11973429 <a title="90-lsi-12" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<p>13 0.11928441 <a title="90-lsi-13" href="./jmlr-2008-Manifold_Learning%3A_The_Price_of_Normalization.html">57 jmlr-2008-Manifold Learning: The Price of Normalization</a></p>
<p>14 0.11377037 <a title="90-lsi-14" href="./jmlr-2008-A_New_Algorithm_for_Estimating_the_Effective_Dimension-Reduction_Subspace.html">5 jmlr-2008-A New Algorithm for Estimating the Effective Dimension-Reduction Subspace</a></p>
<p>15 0.11014717 <a title="90-lsi-15" href="./jmlr-2008-Finding_Optimal_Bayesian_Network_Given_a_Super-Structure.html">35 jmlr-2008-Finding Optimal Bayesian Network Given a Super-Structure</a></p>
<p>16 0.108464 <a title="90-lsi-16" href="./jmlr-2008-Ranking_Individuals_by_Group_Comparisons.html">80 jmlr-2008-Ranking Individuals by Group Comparisons</a></p>
<p>17 0.10659562 <a title="90-lsi-17" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>18 0.10590155 <a title="90-lsi-18" href="./jmlr-2008-A_Bahadur_Representation_of_the_Linear_Support_Vector_Machine.html">1 jmlr-2008-A Bahadur Representation of the Linear Support Vector Machine</a></p>
<p>19 0.1056684 <a title="90-lsi-19" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>20 0.10377899 <a title="90-lsi-20" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.018), (4, 0.016), (25, 0.07), (26, 0.018), (59, 0.022), (66, 0.702), (91, 0.016), (96, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99204445 <a title="90-lda-1" href="./jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective.html">90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</a></p>
<p>Author: Liviu Panait, Karl Tuyls, Sean Luke</p><p>Abstract: This paper presents the dynamics of multiple learning agents from an evolutionary game theoretic perspective. We provide replicator dynamics models for cooperative coevolutionary algorithms and for traditional multiagent Q-learning, and we extend these differential equations to account for lenient learners: agents that forgive possible mismatched teammate actions that resulted in low rewards. We use these extended formal models to study the convergence guarantees for these algorithms, and also to visualize the basins of attraction to optimal and suboptimal solutions in two benchmark coordination problems. The paper demonstrates that lenience provides learners with more accurate information about the beneﬁts of performing their actions, resulting in higher likelihood of convergence to the globally optimal solution. In addition, the analysis indicates that the choice of learning algorithm has an insigniﬁcant impact on the overall performance of multiagent learning algorithms; rather, the performance of these algorithms depends primarily on the level of lenience that the agents exhibit to one another. Finally, the research herein supports the strength and generality of evolutionary game theory as a backbone for multiagent learning. Keywords: multiagent learning, reinforcement learning, cooperative coevolution, evolutionary game theory, formal models, visualization, basins of attraction</p><p>2 0.98565835 <a title="90-lda-2" href="./jmlr-2008-A_Tutorial_on_Conformal_Prediction.html">7 jmlr-2008-A Tutorial on Conformal Prediction</a></p>
<p>Author: Glenn Shafer, Vladimir Vovk</p><p>Abstract: Conformal prediction uses past experience to determine precise levels of conÄ?Ĺš dence in new predictions. Given an error probability ĂŽÄž, together with a method that makes a prediction y of a label Ă&lsaquo;&dagger; y, it produces a set of labels, typically containing y, that also contains y with probability 1 Ă˘&circ;&rsquo; ĂŽÄž. Ă&lsaquo;&dagger; Conformal prediction can be applied to any method for producing y: a nearest-neighbor method, a Ă&lsaquo;&dagger; support-vector machine, ridge regression, etc. Conformal prediction is designed for an on-line setting in which labels are predicted successively, each one being revealed before the next is predicted. The most novel and valuable feature of conformal prediction is that if the successive examples are sampled independently from the same distribution, then the successive predictions will be right 1 Ă˘&circ;&rsquo; ĂŽÄž of the time, even though they are based on an accumulating data set rather than on independent data sets. In addition to the model under which successive examples are sampled independently, other on-line compression models can also use conformal prediction. The widely used Gaussian linear model is one of these. This tutorial presents a self-contained account of the theory of conformal prediction and works through several numerical examples. A more comprehensive treatment of the topic is provided in Algorithmic Learning in a Random World, by Vladimir Vovk, Alex Gammerman, and Glenn Shafer (Springer, 2005). Keywords: conÄ?Ĺš dence, on-line compression modeling, on-line learning, prediction regions</p><p>3 0.98333204 <a title="90-lda-3" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>Author: Onureena Banerjee, Laurent El Ghaoui, Alexandre d'Aspremont</p><p>Abstract: We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added 1 -norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our ﬁrst algorithm uses block coordinate descent, and can be interpreted as recursive 1 -norm penalized regression. Our second algorithm, based on Nesterov’s ﬁrst order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright and Jordan, 2006), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data. Keywords: model selection, maximum likelihood estimation, convex optimization, Gaussian graphical model, binary data</p><p>4 0.97980696 <a title="90-lda-4" href="./jmlr-2008-Stationary_Features_and_Cat_Detection.html">87 jmlr-2008-Stationary Features and Cat Detection</a></p>
<p>Author: FranĂ§ois Fleuret, Donald Geman</p><p>Abstract: Most discriminative techniques for detecting instances from object categories in still images consist of looping over a partition of a pose space with dedicated binary classiÄ?Ĺš ers. The efÄ?Ĺš ciency of this strategy for a complex pose, that is, for Ä?Ĺš ne-grained descriptions, can be assessed by measuring the effect of sample size and pose resolution on accuracy and computation. Two conclusions emerge: (1) fragmenting the training data, which is inevitable in dealing with high in-class variation, severely reduces accuracy; (2) the computational cost at high resolution is prohibitive due to visiting a massive pose partition. To overcome data-fragmentation we propose a novel framework centered on pose-indexed features which assign a response to a pair consisting of an image and a pose, and are designed to be stationary: the probability distribution of the response is always the same if an object is actually present. Such features allow for efÄ?Ĺš cient, one-shot learning of pose-speciÄ?Ĺš c classiÄ?Ĺš ers. To avoid expensive scene processing, we arrange these classiÄ?Ĺš ers in a hierarchy based on nested partitions of the pose; as in previous work on coarse-to-Ä?Ĺš ne search, this allows for efÄ?Ĺš cient processing. The hierarchy is then Ă˘&euro;?foldedĂ˘&euro;? for training: all the classiÄ?Ĺš ers at each level are derived from one base predictor learned from all the data. The hierarchy is Ă˘&euro;?unfoldedĂ˘&euro;? for testing: parsing a scene amounts to examining increasingly Ä?Ĺš ner object descriptions only when there is sufÄ?Ĺš cient evidence for coarser ones. In this way, the detection results are equivalent to an exhaustive search at high resolution. We illustrate these ideas by detecting and localizing cats in highly cluttered greyscale scenes. Keywords: supervised learning, computer vision, image interpretation, cats, stationary features, hierarchical search</p><p>5 0.95644951 <a title="90-lda-5" href="./jmlr-2008-Learning_Bounded_Treewidth_Bayesian_Networks.html">48 jmlr-2008-Learning Bounded Treewidth Bayesian Networks</a></p>
<p>Author: Gal Elidan, Stephen Gould</p><p>Abstract: With the increased availability of data for complex domains, it is desirable to learn Bayesian network structures that are sufﬁciently expressive for generalization while at the same time allow for tractable inference. While the method of thin junction trees can, in principle, be used for this purpose, its fully greedy nature makes it prone to overﬁtting, particularly when data is scarce. In this work we present a novel method for learning Bayesian networks of bounded treewidth that employs global structure modiﬁcations and that is polynomial both in the size of the graph and the treewidth bound. At the heart of our method is a dynamic triangulation that we update in a way that facilitates the addition of chain structures that increase the bound on the model’s treewidth by at most one. We demonstrate the effectiveness of our “treewidth-friendly” method on several real-life data sets and show that it is superior to the greedy approach as soon as the bound on the treewidth is nontrivial. Importantly, we also show that by making use of global operators, we are able to achieve better generalization even when learning Bayesian networks of unbounded treewidth. Keywords: Bayesian networks, structure learning, model selection, bounded treewidth</p><p>6 0.9048425 <a title="90-lda-6" href="./jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</a></p>
<p>7 0.89849615 <a title="90-lda-7" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>8 0.89775985 <a title="90-lda-8" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>9 0.88798201 <a title="90-lda-9" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>10 0.88194603 <a title="90-lda-10" href="./jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</a></p>
<p>11 0.87880564 <a title="90-lda-11" href="./jmlr-2008-Learning_Control_Knowledge_for_Forward_Search_Planning.html">49 jmlr-2008-Learning Control Knowledge for Forward Search Planning</a></p>
<p>12 0.87829828 <a title="90-lda-12" href="./jmlr-2008-Finding_Optimal_Bayesian_Network_Given_a_Super-Structure.html">35 jmlr-2008-Finding Optimal Bayesian Network Given a Super-Structure</a></p>
<p>13 0.87767339 <a title="90-lda-13" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>14 0.87471855 <a title="90-lda-14" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>15 0.87315345 <a title="90-lda-15" href="./jmlr-2008-Non-Parametric_Modeling_of_Partially_Ranked_Data.html">69 jmlr-2008-Non-Parametric Modeling of Partially Ranked Data</a></p>
<p>16 0.86802858 <a title="90-lda-16" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>17 0.86745602 <a title="90-lda-17" href="./jmlr-2008-Forecasting_Web_Page_Views%3A_Methods_and_Observations.html">37 jmlr-2008-Forecasting Web Page Views: Methods and Observations</a></p>
<p>18 0.86701083 <a title="90-lda-18" href="./jmlr-2008-Search_for_Additive_Nonlinear_Time_Series_Causal_Models.html">84 jmlr-2008-Search for Additive Nonlinear Time Series Causal Models</a></p>
<p>19 0.86429203 <a title="90-lda-19" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>20 0.86130285 <a title="90-lda-20" href="./jmlr-2008-Magic_Moments_for_Structured_Output_Prediction.html">56 jmlr-2008-Magic Moments for Structured Output Prediction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
