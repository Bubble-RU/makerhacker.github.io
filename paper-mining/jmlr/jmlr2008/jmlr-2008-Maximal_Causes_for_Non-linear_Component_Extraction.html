<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>59 jmlr-2008-Maximal Causes for Non-linear Component Extraction</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-59" href="#">jmlr2008-59</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>59 jmlr-2008-Maximal Causes for Non-linear Component Extraction</h1>
<br/><p>Source: <a title="jmlr-2008-59-pdf" href="http://jmlr.org/papers/volume9/luecke08a/luecke08a.pdf">pdf</a></p><p>Author: Jörg Lücke,  Maneesh Sahani</p><p>Abstract: We study a generative model in which hidden causes combine competitively to produce observations. Multiple active causes combine to determine the value of an observed variable through a max function, in the place where algorithms such as sparse coding, independent component analysis, or non-negative matrix factorization would use a sum. This max rule can represent a more realistic model of non-linear interaction between basic components in many settings, including acoustic and image data. While exact maximum-likelihood learning of the parameters of this model proves to be intractable, we show that efﬁcient approximations to expectation-maximization (EM) can be found in the case of sparsely active hidden causes. One of these approximations can be formulated as a neural network model with a generalized softmax activation function and Hebbian learning. Thus, we show that learning in recent softmax-like neural networks may be interpreted as approximate maximization of a data likelihood. We use the bars benchmark test to numerically verify our analytical results and to demonstrate the competitiveness of the resulting algorithms. Finally, we show results of learning model parameters to ﬁt acoustic and visual data sets in which max-like component combinations arise naturally. Keywords: component extraction, maximum likelihood, approximate EM, competitive learning, neural networks</p><p>Reference: <a title="jmlr-2008-59-reference" href="../jmlr2008_reference/jmlr-2008-Maximal_Causes_for_Non-linear_Component_Extraction_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bar', 0.427), ('mca', 0.396), ('qn', 0.289), ('cke', 0.25), ('spratling', 0.218), ('yd', 0.199), ('hid', 0.196), ('ahan', 0.153), ('nmf', 0.153), ('uck', 0.153), ('phonem', 0.123), ('axim', 0.123), ('sh', 0.112), ('caus', 0.108), ('cool', 0.105), ('gid', 0.105), ('malsburg', 0.105), ('aus', 0.098), ('mcaex', 0.097), ('poisson', 0.089)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="59-tfidf-1" href="./jmlr-2008-Maximal_Causes_for_Non-linear_Component_Extraction.html">59 jmlr-2008-Maximal Causes for Non-linear Component Extraction</a></p>
<p>2 0.071438104 <a title="59-tfidf-2" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>3 0.059400942 <a title="59-tfidf-3" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>4 0.058980819 <a title="59-tfidf-4" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>5 0.057872809 <a title="59-tfidf-5" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>6 0.055669811 <a title="59-tfidf-6" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>7 0.053787738 <a title="59-tfidf-7" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>8 0.050293468 <a title="59-tfidf-8" href="./jmlr-2008-A_Moment_Bound_for_Multi-hinge_Classifiers.html">3 jmlr-2008-A Moment Bound for Multi-hinge Classifiers</a></p>
<p>9 0.04737043 <a title="59-tfidf-9" href="./jmlr-2008-Using_Markov_Blankets_for_Causal_Structure_Learning%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">93 jmlr-2008-Using Markov Blankets for Causal Structure Learning    (Special Topic on Causality)</a></p>
<p>10 0.046978507 <a title="59-tfidf-10" href="./jmlr-2008-Stationary_Features_and_Cat_Detection.html">87 jmlr-2008-Stationary Features and Cat Detection</a></p>
<p>11 0.045828067 <a title="59-tfidf-11" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>12 0.044406507 <a title="59-tfidf-12" href="./jmlr-2008-Non-Parametric_Modeling_of_Partially_Ranked_Data.html">69 jmlr-2008-Non-Parametric Modeling of Partially Ranked Data</a></p>
<p>13 0.039979827 <a title="59-tfidf-13" href="./jmlr-2008-Gradient_Tree_Boosting_for_Training_Conditional_Random_Fields.html">39 jmlr-2008-Gradient Tree Boosting for Training Conditional Random Fields</a></p>
<p>14 0.039840382 <a title="59-tfidf-14" href="./jmlr-2008-Complete_Identification_Methods_for_the_Causal_Hierarchy%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">24 jmlr-2008-Complete Identification Methods for the Causal Hierarchy    (Special Topic on Causality)</a></p>
<p>15 0.039764829 <a title="59-tfidf-15" href="./jmlr-2008-Minimal_Nonlinear_Distortion_Principle_for_Nonlinear_Independent_Component_Analysis.html">60 jmlr-2008-Minimal Nonlinear Distortion Principle for Nonlinear Independent Component Analysis</a></p>
<p>16 0.039754357 <a title="59-tfidf-16" href="./jmlr-2008-Algorithms_for_Sparse_Linear_Classifiers_in_the_Massive_Data_Setting.html">12 jmlr-2008-Algorithms for Sparse Linear Classifiers in the Massive Data Setting</a></p>
<p>17 0.038956657 <a title="59-tfidf-17" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>18 0.038600378 <a title="59-tfidf-18" href="./jmlr-2008-Search_for_Additive_Nonlinear_Time_Series_Causal_Models.html">84 jmlr-2008-Search for Additive Nonlinear Time Series Causal Models</a></p>
<p>19 0.038322527 <a title="59-tfidf-19" href="./jmlr-2008-Randomized_Online_PCA_Algorithms_with_Regret_Bounds_that_are_Logarithmic_in_the_Dimension.html">78 jmlr-2008-Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension</a></p>
<p>20 0.037408929 <a title="59-tfidf-20" href="./jmlr-2008-Learning_Similarity_with_Operator-valued_Large-margin_Classifiers.html">51 jmlr-2008-Learning Similarity with Operator-valued Large-margin Classifiers</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.18), (1, 0.025), (2, -0.019), (3, -0.011), (4, -0.067), (5, 0.069), (6, -0.085), (7, 0.02), (8, 0.021), (9, -0.08), (10, -0.014), (11, 0.047), (12, -0.01), (13, -0.017), (14, 0.018), (15, 0.052), (16, -0.035), (17, -0.011), (18, -0.213), (19, -0.091), (20, 0.104), (21, 0.084), (22, -0.066), (23, -0.23), (24, 0.166), (25, 0.183), (26, -0.116), (27, 0.187), (28, -0.013), (29, -0.189), (30, 0.032), (31, -0.038), (32, -0.116), (33, 0.088), (34, 0.147), (35, 0.115), (36, -0.013), (37, 0.311), (38, 0.172), (39, 0.036), (40, 0.133), (41, 0.225), (42, 0.045), (43, 0.018), (44, -0.228), (45, -0.114), (46, 0.025), (47, 0.186), (48, -0.047), (49, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93484938 <a title="59-lsi-1" href="./jmlr-2008-Maximal_Causes_for_Non-linear_Component_Extraction.html">59 jmlr-2008-Maximal Causes for Non-linear Component Extraction</a></p>
<p>2 0.36546379 <a title="59-lsi-2" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>3 0.35048026 <a title="59-lsi-3" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>4 0.28687045 <a title="59-lsi-4" href="./jmlr-2008-Minimal_Nonlinear_Distortion_Principle_for_Nonlinear_Independent_Component_Analysis.html">60 jmlr-2008-Minimal Nonlinear Distortion Principle for Nonlinear Independent Component Analysis</a></p>
<p>5 0.25683835 <a title="59-lsi-5" href="./jmlr-2008-Complete_Identification_Methods_for_the_Causal_Hierarchy%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">24 jmlr-2008-Complete Identification Methods for the Causal Hierarchy    (Special Topic on Causality)</a></p>
<p>6 0.25620848 <a title="59-lsi-6" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>7 0.24815366 <a title="59-lsi-7" href="./jmlr-2008-Algorithms_for_Sparse_Linear_Classifiers_in_the_Massive_Data_Setting.html">12 jmlr-2008-Algorithms for Sparse Linear Classifiers in the Massive Data Setting</a></p>
<p>8 0.24460559 <a title="59-lsi-8" href="./jmlr-2008-Regularization_on_Graphs_with_Function-adapted_Diffusion_Processes.html">81 jmlr-2008-Regularization on Graphs with Function-adapted Diffusion Processes</a></p>
<p>9 0.24363282 <a title="59-lsi-9" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>10 0.24056375 <a title="59-lsi-10" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>11 0.22341333 <a title="59-lsi-11" href="./jmlr-2008-Using_Markov_Blankets_for_Causal_Structure_Learning%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">93 jmlr-2008-Using Markov Blankets for Causal Structure Learning    (Special Topic on Causality)</a></p>
<p>12 0.21965939 <a title="59-lsi-12" href="./jmlr-2008-Accelerated_Neural_Evolution_through_Cooperatively_Coevolved_Synapses.html">8 jmlr-2008-Accelerated Neural Evolution through Cooperatively Coevolved Synapses</a></p>
<p>13 0.21727495 <a title="59-lsi-13" href="./jmlr-2008-Search_for_Additive_Nonlinear_Time_Series_Causal_Models.html">84 jmlr-2008-Search for Additive Nonlinear Time Series Causal Models</a></p>
<p>14 0.20178388 <a title="59-lsi-14" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>15 0.20020075 <a title="59-lsi-15" href="./jmlr-2008-Gradient_Tree_Boosting_for_Training_Conditional_Random_Fields.html">39 jmlr-2008-Gradient Tree Boosting for Training Conditional Random Fields</a></p>
<p>16 0.1999515 <a title="59-lsi-16" href="./jmlr-2008-Non-Parametric_Modeling_of_Partially_Ranked_Data.html">69 jmlr-2008-Non-Parametric Modeling of Partially Ranked Data</a></p>
<p>17 0.19033593 <a title="59-lsi-17" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>18 0.1887974 <a title="59-lsi-18" href="./jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</a></p>
<p>19 0.18408485 <a title="59-lsi-19" href="./jmlr-2008-A_Moment_Bound_for_Multi-hinge_Classifiers.html">3 jmlr-2008-A Moment Bound for Multi-hinge Classifiers</a></p>
<p>20 0.16469149 <a title="59-lsi-20" href="./jmlr-2008-Mixed_Membership_Stochastic_Blockmodels.html">61 jmlr-2008-Mixed Membership Stochastic Blockmodels</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.026), (4, 0.021), (25, 0.589), (26, 0.043), (66, 0.126), (86, 0.011), (91, 0.03), (96, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88394314 <a title="59-lda-1" href="./jmlr-2008-Accelerated_Neural_Evolution_through_Cooperatively_Coevolved_Synapses.html">8 jmlr-2008-Accelerated Neural Evolution through Cooperatively Coevolved Synapses</a></p>
<p>same-paper 2 0.82079989 <a title="59-lda-2" href="./jmlr-2008-Maximal_Causes_for_Non-linear_Component_Extraction.html">59 jmlr-2008-Maximal Causes for Non-linear Component Extraction</a></p>
<p>3 0.67606264 <a title="59-lda-3" href="./jmlr-2008-A_New_Algorithm_for_Estimating_the_Effective_Dimension-Reduction_Subspace.html">5 jmlr-2008-A New Algorithm for Estimating the Effective Dimension-Reduction Subspace</a></p>
<p>4 0.46015543 <a title="59-lda-4" href="./jmlr-2008-Complete_Identification_Methods_for_the_Causal_Hierarchy%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">24 jmlr-2008-Complete Identification Methods for the Causal Hierarchy    (Special Topic on Causality)</a></p>
<p>5 0.45254314 <a title="59-lda-5" href="./jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</a></p>
<p>6 0.43328583 <a title="59-lda-6" href="./jmlr-2008-Search_for_Additive_Nonlinear_Time_Series_Causal_Models.html">84 jmlr-2008-Search for Additive Nonlinear Time Series Causal Models</a></p>
<p>7 0.42109799 <a title="59-lda-7" href="./jmlr-2008-Incremental_Identification_of_Qualitative_Models_of_Biological_Systems_using_Inductive_Logic_Programming.html">44 jmlr-2008-Incremental Identification of Qualitative Models of Biological Systems using Inductive Logic Programming</a></p>
<p>8 0.40877983 <a title="59-lda-8" href="./jmlr-2008-Causal_Reasoning_with_Ancestral_Graphs%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Causality%29.html">20 jmlr-2008-Causal Reasoning with Ancestral Graphs    (Special Topic on Causality)</a></p>
<p>9 0.40660471 <a title="59-lda-9" href="./jmlr-2008-Learning_Reliable_Classifiers_From_Small_or_Incomplete_Data_Sets%3A_The_Naive_Credal_Classifier_2.html">50 jmlr-2008-Learning Reliable Classifiers From Small or Incomplete Data Sets: The Naive Credal Classifier 2</a></p>
<p>10 0.3997761 <a title="59-lda-10" href="./jmlr-2008-An_Extension_on_%22Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets%22_for_all_Pairwise_Comparisons.html">14 jmlr-2008-An Extension on "Statistical Comparisons of Classifiers over Multiple Data Sets" for all Pairwise Comparisons</a></p>
<p>11 0.39163452 <a title="59-lda-11" href="./jmlr-2008-Learning_Control_Knowledge_for_Forward_Search_Planning.html">49 jmlr-2008-Learning Control Knowledge for Forward Search Planning</a></p>
<p>12 0.38726884 <a title="59-lda-12" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>13 0.38405854 <a title="59-lda-13" href="./jmlr-2008-Manifold_Learning%3A_The_Price_of_Normalization.html">57 jmlr-2008-Manifold Learning: The Price of Normalization</a></p>
<p>14 0.38118938 <a title="59-lda-14" href="./jmlr-2008-Finding_Optimal_Bayesian_Network_Given_a_Super-Structure.html">35 jmlr-2008-Finding Optimal Bayesian Network Given a Super-Structure</a></p>
<p>15 0.37996972 <a title="59-lda-15" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>16 0.37802613 <a title="59-lda-16" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>17 0.37380922 <a title="59-lda-17" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>18 0.37324259 <a title="59-lda-18" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>19 0.372464 <a title="59-lda-19" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>20 0.37174565 <a title="59-lda-20" href="./jmlr-2008-Hit_Miss_Networks_with_Applications_to_Instance_Selection.html">43 jmlr-2008-Hit Miss Networks with Applications to Instance Selection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
