<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2008" href="../home/jmlr2008_home.html">jmlr2008</a> <a title="jmlr-2008-94" href="#">jmlr2008-94</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</h1>
<br/><p>Source: <a title="jmlr-2008-94-pdf" href="http://jmlr.org/papers/volume9/george08a/george08a.pdf">pdf</a></p><p>Author: Abraham George, Warren B. Powell, Sanjeev R. Kulkarni</p><p>Abstract: We consider the problem of estimating the value of a multiattribute resource, where the attributes are categorical or discrete in nature and the number of potential attribute vectors is very large. The problem arises in approximate dynamic programming when we need to estimate the value of a multiattribute resource from estimates based on Monte-Carlo simulation. These problems have been traditionally solved using aggregation, but choosing the right level of aggregation requires resolving the classic tradeoff between aggregation error and sampling error. We propose a method that estimates the value of a resource at different levels of aggregation simultaneously, and then uses a weighted combination of the estimates. Using the optimal weights, which minimizes the variance of the estimate while accounting for correlations between the estimates, is computationally too expensive for practical applications. We have found that a simple inverse variance formula (adjusted for bias), which effectively assumes the estimates are independent, produces near-optimal estimates. We use the setting of two levels of aggregation to explain why this approximation works so well. Keywords: hierarchical statistics, approximate dynamic programming, mixture models, adaptive learning, multiattribute resources</p><p>Reference: <a title="jmlr-2008-94-reference" href="../jmlr2008_reference/jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('aggreg', 0.507), ('disaggreg', 0.319), ('na', 0.276), ('attribut', 0.274), ('va', 0.227), ('truck', 0.195), ('wind', 0.186), ('resourc', 0.164), ('wopt', 0.15), ('eorg', 0.142), ('owel', 0.142), ('pproximation', 0.142), ('ulkarn', 0.142), ('wa', 0.135), ('dynam', 0.127), ('hom', 0.124), ('eet', 0.097), ('weight', 0.097), ('vn', 0.092), ('multiattribut', 0.089)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="94-tfidf-1" href="./jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</a></p>
<p>Author: Abraham George, Warren B. Powell, Sanjeev R. Kulkarni</p><p>Abstract: We consider the problem of estimating the value of a multiattribute resource, where the attributes are categorical or discrete in nature and the number of potential attribute vectors is very large. The problem arises in approximate dynamic programming when we need to estimate the value of a multiattribute resource from estimates based on Monte-Carlo simulation. These problems have been traditionally solved using aggregation, but choosing the right level of aggregation requires resolving the classic tradeoff between aggregation error and sampling error. We propose a method that estimates the value of a resource at different levels of aggregation simultaneously, and then uses a weighted combination of the estimates. Using the optimal weights, which minimizes the variance of the estimate while accounting for correlations between the estimates, is computationally too expensive for practical applications. We have found that a simple inverse variance formula (adjusted for bias), which effectively assumes the estimates are independent, produces near-optimal estimates. We use the setting of two levels of aggregation to explain why this approximation works so well. Keywords: hierarchical statistics, approximate dynamic programming, mixture models, adaptive learning, multiattribute resources</p><p>2 0.18409801 <a title="94-tfidf-2" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>Author: Sébastien Loustau</p><p>Abstract: This paper investigates statistical performances of Support Vector Machines (SVM) and considers the problem of adaptation to the margin parameter and to complexity. In particular we provide a classiﬁer with no tuning parameter. It is a combination of SVM classiﬁers. Our contribution is two-fold: (1) we propose learning rates for SVM using Sobolev spaces and build a numerically realizable aggregate that converges with same rate; (2) we present practical experiments of this method of aggregation for SVM using both Sobolev spaces and Gaussian kernels. Keywords: classiﬁcation, support vector machines, learning rates, approximation, aggregation of classiﬁers</p><p>3 0.10040376 <a title="94-tfidf-3" href="./jmlr-2008-Probabilistic_Characterization_of_Random_Decision_Trees.html">77 jmlr-2008-Probabilistic Characterization of Random Decision Trees</a></p>
<p>Author: Amit Dhurandhar, Alin Dobra</p><p>Abstract: In this paper we use the methodology introduced by Dhurandhar and Dobra (2009) for analyzing the error of classiﬁers and the model selection measures, to analyze decision tree algorithms. The methodology consists of obtaining parametric expressions for the moments of the generalization error (GE) for the classiﬁcation model of interest, followed by plotting these expressions for interpretability. The major challenge in applying the methodology to decision trees, the main theme of this work, is customizing the generic expressions for the moments of GE to this particular classiﬁcation algorithm. The speciﬁc contributions we make in this paper are: (a) we primarily characterize a subclass of decision trees namely, Random decision trees, (b) we discuss how the analysis extends to other decision tree algorithms and (c) in order to extend the analysis to certain model selection measures, we generalize the relationships between the moments of GE and moments of the model selection measures given in (Dhurandhar and Dobra, 2009) to randomized classiﬁcation algorithms. An empirical comparison of the proposed method with Monte Carlo and distribution free bounds obtained using Breiman’s formula, depicts the advantages of the method in terms of running time and accuracy. It thus showcases the use of the deployed methodology as an exploratory tool to study learning algorithms. Keywords: moments, generalization error, decision trees</p><p>4 0.082209177 <a title="94-tfidf-4" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>Author: Jun Zhu, Zaiqing Nie, Bo Zhang, Ji-Rong Wen</p><p>Abstract: Existing template-independent web data extraction approaches adopt highly ineffective decoupled strategies—attempting to do data record detection and attribute labeling in two separate phases. In this paper, we propose an integrated web data extraction paradigm with hierarchical models. The proposed model is called Dynamic Hierarchical Markov Random Fields (DHMRFs). DHMRFs take structural uncertainty into consideration and deﬁne a joint distribution of both model structure and class labels. The joint distribution is an exponential family distribution. As a conditional model, DHMRFs relax the independence assumption as made in directed models. Since exact inference is intractable, a variational method is developed to learn the model’s parameters and to ﬁnd the MAP model structure and label assignments. We apply DHMRFs to a real-world web data extraction task. Experimental results show that: (1) integrated web data extraction models can achieve signiﬁcant improvements on both record detection and attribute labeling compared to decoupled models; (2) in diverse web data extraction DHMRFs can potentially address the blocky artifact issue which is suffered by ﬁxed-structured hierarchical models. Keywords: conditional random ﬁelds, dynamic hierarchical Markov random ﬁelds, integrated web data extraction, statistical hierarchical modeling, blocky artifact issue</p><p>5 0.080132909 <a title="94-tfidf-5" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>Author: Balázs Csanád Csáji, László Monostori</p><p>Abstract: The paper investigates the possibility of applying value function based reinforcement learning (RL) methods in cases when the environment may change over time. First, theorems are presented which show that the optimal value function of a discounted Markov decision process (MDP) Lipschitz continuously depends on the immediate-cost function and the transition-probability function. Dependence on the discount factor is also analyzed and shown to be non-Lipschitz. Afterwards, the concept of (ε, δ)-MDPs is introduced, which is a generalization of MDPs and ε-MDPs. In this model the environment may change over time, more precisely, the transition function and the cost function may vary from time to time, but the changes must be bounded in the limit. Then, learning algorithms in changing environments are analyzed. A general relaxed convergence theorem for stochastic iterative algorithms is presented. We also demonstrate the results through three classical RL methods: asynchronous value iteration, Q-learning and temporal difference learning. Finally, some numerical experiments concerning changing environments are presented. Keywords: Markov decision processes, reinforcement learning, changing environments, (ε, δ)MDPs, value function bounds, stochastic iterative algorithms</p><p>6 0.061347473 <a title="94-tfidf-6" href="./jmlr-2008-HPB%3A_A_Model_for_Handling_BN_Nodes_with_High_Cardinality_Parents.html">42 jmlr-2008-HPB: A Model for Handling BN Nodes with High Cardinality Parents</a></p>
<p>7 0.054156758 <a title="94-tfidf-7" href="./jmlr-2008-Stationary_Features_and_Cat_Detection.html">87 jmlr-2008-Stationary Features and Cat Detection</a></p>
<p>8 0.043141451 <a title="94-tfidf-8" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>9 0.04303525 <a title="94-tfidf-9" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>10 0.031288054 <a title="94-tfidf-10" href="./jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</a></p>
<p>11 0.03125022 <a title="94-tfidf-11" href="./jmlr-2008-Mixed_Membership_Stochastic_Blockmodels.html">61 jmlr-2008-Mixed Membership Stochastic Blockmodels</a></p>
<p>12 0.02939062 <a title="94-tfidf-12" href="./jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective.html">90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</a></p>
<p>13 0.028826052 <a title="94-tfidf-13" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>14 0.028670149 <a title="94-tfidf-14" href="./jmlr-2008-Learning_Control_Knowledge_for_Forward_Search_Planning.html">49 jmlr-2008-Learning Control Knowledge for Forward Search Planning</a></p>
<p>15 0.026119025 <a title="94-tfidf-15" href="./jmlr-2008-An_Extension_on_%22Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets%22_for_all_Pairwise_Comparisons.html">14 jmlr-2008-An Extension on "Statistical Comparisons of Classifiers over Multiple Data Sets" for all Pairwise Comparisons</a></p>
<p>16 0.025519233 <a title="94-tfidf-16" href="./jmlr-2008-Incremental_Identification_of_Qualitative_Models_of_Biological_Systems_using_Inductive_Logic_Programming.html">44 jmlr-2008-Incremental Identification of Qualitative Models of Biological Systems using Inductive Logic Programming</a></p>
<p>17 0.02547944 <a title="94-tfidf-17" href="./jmlr-2008-Ranking_Individuals_by_Group_Comparisons.html">80 jmlr-2008-Ranking Individuals by Group Comparisons</a></p>
<p>18 0.024317088 <a title="94-tfidf-18" href="./jmlr-2008-SimpleMKL.html">86 jmlr-2008-SimpleMKL</a></p>
<p>19 0.02413189 <a title="94-tfidf-19" href="./jmlr-2008-Accelerated_Neural_Evolution_through_Cooperatively_Coevolved_Synapses.html">8 jmlr-2008-Accelerated Neural Evolution through Cooperatively Coevolved Synapses</a></p>
<p>20 0.024090922 <a title="94-tfidf-20" href="./jmlr-2008-Linear-Time_Computation_of_Similarity_Measures_for_Sequential_Data.html">55 jmlr-2008-Linear-Time Computation of Similarity Measures for Sequential Data</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.137), (1, 0.051), (2, 0.012), (3, 0.012), (4, -0.15), (5, -0.149), (6, -0.109), (7, -0.103), (8, 0.049), (9, 0.015), (10, 0.019), (11, 0.006), (12, 0.027), (13, -0.03), (14, 0.471), (15, -0.192), (16, -0.303), (17, -0.107), (18, 0.087), (19, 0.016), (20, -0.084), (21, -0.023), (22, 0.042), (23, 0.181), (24, 0.098), (25, 0.002), (26, -0.053), (27, -0.072), (28, 0.114), (29, -0.096), (30, -0.049), (31, -0.184), (32, -0.035), (33, -0.031), (34, 0.056), (35, 0.053), (36, -0.05), (37, -0.041), (38, 0.014), (39, 0.05), (40, 0.114), (41, 0.058), (42, 0.063), (43, -0.04), (44, -0.108), (45, 0.085), (46, -0.109), (47, 0.1), (48, -0.045), (49, -0.04)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96446902 <a title="94-lsi-1" href="./jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</a></p>
<p>Author: Abraham George, Warren B. Powell, Sanjeev R. Kulkarni</p><p>Abstract: We consider the problem of estimating the value of a multiattribute resource, where the attributes are categorical or discrete in nature and the number of potential attribute vectors is very large. The problem arises in approximate dynamic programming when we need to estimate the value of a multiattribute resource from estimates based on Monte-Carlo simulation. These problems have been traditionally solved using aggregation, but choosing the right level of aggregation requires resolving the classic tradeoff between aggregation error and sampling error. We propose a method that estimates the value of a resource at different levels of aggregation simultaneously, and then uses a weighted combination of the estimates. Using the optimal weights, which minimizes the variance of the estimate while accounting for correlations between the estimates, is computationally too expensive for practical applications. We have found that a simple inverse variance formula (adjusted for bias), which effectively assumes the estimates are independent, produces near-optimal estimates. We use the setting of two levels of aggregation to explain why this approximation works so well. Keywords: hierarchical statistics, approximate dynamic programming, mixture models, adaptive learning, multiattribute resources</p><p>2 0.55651271 <a title="94-lsi-2" href="./jmlr-2008-Aggregation_of_SVM_Classifiers_Using_Sobolev_Spaces.html">11 jmlr-2008-Aggregation of SVM Classifiers Using Sobolev Spaces</a></p>
<p>Author: Sébastien Loustau</p><p>Abstract: This paper investigates statistical performances of Support Vector Machines (SVM) and considers the problem of adaptation to the margin parameter and to complexity. In particular we provide a classiﬁer with no tuning parameter. It is a combination of SVM classiﬁers. Our contribution is two-fold: (1) we propose learning rates for SVM using Sobolev spaces and build a numerically realizable aggregate that converges with same rate; (2) we present practical experiments of this method of aggregation for SVM using both Sobolev spaces and Gaussian kernels. Keywords: classiﬁcation, support vector machines, learning rates, approximation, aggregation of classiﬁers</p><p>3 0.40625915 <a title="94-lsi-3" href="./jmlr-2008-Probabilistic_Characterization_of_Random_Decision_Trees.html">77 jmlr-2008-Probabilistic Characterization of Random Decision Trees</a></p>
<p>Author: Amit Dhurandhar, Alin Dobra</p><p>Abstract: In this paper we use the methodology introduced by Dhurandhar and Dobra (2009) for analyzing the error of classiﬁers and the model selection measures, to analyze decision tree algorithms. The methodology consists of obtaining parametric expressions for the moments of the generalization error (GE) for the classiﬁcation model of interest, followed by plotting these expressions for interpretability. The major challenge in applying the methodology to decision trees, the main theme of this work, is customizing the generic expressions for the moments of GE to this particular classiﬁcation algorithm. The speciﬁc contributions we make in this paper are: (a) we primarily characterize a subclass of decision trees namely, Random decision trees, (b) we discuss how the analysis extends to other decision tree algorithms and (c) in order to extend the analysis to certain model selection measures, we generalize the relationships between the moments of GE and moments of the model selection measures given in (Dhurandhar and Dobra, 2009) to randomized classiﬁcation algorithms. An empirical comparison of the proposed method with Monte Carlo and distribution free bounds obtained using Breiman’s formula, depicts the advantages of the method in terms of running time and accuracy. It thus showcases the use of the deployed methodology as an exploratory tool to study learning algorithms. Keywords: moments, generalization error, decision trees</p><p>4 0.30852735 <a title="94-lsi-4" href="./jmlr-2008-Dynamic_Hierarchical_Markov_Random_Fields_for_Integrated_Web_Data_Extraction.html">31 jmlr-2008-Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction</a></p>
<p>Author: Jun Zhu, Zaiqing Nie, Bo Zhang, Ji-Rong Wen</p><p>Abstract: Existing template-independent web data extraction approaches adopt highly ineffective decoupled strategies—attempting to do data record detection and attribute labeling in two separate phases. In this paper, we propose an integrated web data extraction paradigm with hierarchical models. The proposed model is called Dynamic Hierarchical Markov Random Fields (DHMRFs). DHMRFs take structural uncertainty into consideration and deﬁne a joint distribution of both model structure and class labels. The joint distribution is an exponential family distribution. As a conditional model, DHMRFs relax the independence assumption as made in directed models. Since exact inference is intractable, a variational method is developed to learn the model’s parameters and to ﬁnd the MAP model structure and label assignments. We apply DHMRFs to a real-world web data extraction task. Experimental results show that: (1) integrated web data extraction models can achieve signiﬁcant improvements on both record detection and attribute labeling compared to decoupled models; (2) in diverse web data extraction DHMRFs can potentially address the blocky artifact issue which is suffered by ﬁxed-structured hierarchical models. Keywords: conditional random ﬁelds, dynamic hierarchical Markov random ﬁelds, integrated web data extraction, statistical hierarchical modeling, blocky artifact issue</p><p>5 0.2879281 <a title="94-lsi-5" href="./jmlr-2008-HPB%3A_A_Model_for_Handling_BN_Nodes_with_High_Cardinality_Parents.html">42 jmlr-2008-HPB: A Model for Handling BN Nodes with High Cardinality Parents</a></p>
<p>Author: Jorge Jambeiro Filho, Jacques Wainer</p><p>Abstract: We replaced the conditional probability tables of Bayesian network nodes whose parents have high cardinality with a multilevel empirical hierarchical Bayesian model called hierarchical pattern Bayes (HPB).1 The resulting Bayesian networks achieved signiÄ?Ĺš cant performance improvements over Bayesian networks with the same structure and traditional conditional probability tables, over Bayesian networks with simpler structures like naĂ&sbquo;Â¨ve Bayes and tree augmented naĂ&sbquo;Â¨ve Bayes, over Ă&bdquo;Ä&hellip; Ă&bdquo;Ä&hellip; Bayesian networks where traditional conditional probability tables were substituted by noisy-OR gates, default tables, decision trees and decision graphs and over Bayesian networks constructed after a cardinality reduction preprocessing phase using the agglomerative information bottleneck method. Our main tests took place in important fraud detection domains, which are characterized by the presence of high cardinality attributes and by the existence of relevant interactions among them. Other tests, over UCI data sets, show that HPB may have a quite wide applicability. Keywords: probabilistic reasoning, Bayesian networks, smoothing, hierarchical Bayes, empirical Bayes</p><p>6 0.24591932 <a title="94-lsi-6" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>7 0.18273346 <a title="94-lsi-7" href="./jmlr-2008-Stationary_Features_and_Cat_Detection.html">87 jmlr-2008-Stationary Features and Cat Detection</a></p>
<p>8 0.16501227 <a title="94-lsi-8" href="./jmlr-2008-Maximal_Causes_for_Non-linear_Component_Extraction.html">59 jmlr-2008-Maximal Causes for Non-linear Component Extraction</a></p>
<p>9 0.15930022 <a title="94-lsi-9" href="./jmlr-2008-Algorithms_for_Sparse_Linear_Classifiers_in_the_Massive_Data_Setting.html">12 jmlr-2008-Algorithms for Sparse Linear Classifiers in the Massive Data Setting</a></p>
<p>10 0.15279904 <a title="94-lsi-10" href="./jmlr-2008-Learning_from_Multiple_Sources.html">52 jmlr-2008-Learning from Multiple Sources</a></p>
<p>11 0.14561553 <a title="94-lsi-11" href="./jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</a></p>
<p>12 0.14429195 <a title="94-lsi-12" href="./jmlr-2008-Regularization_on_Graphs_with_Function-adapted_Diffusion_Processes.html">81 jmlr-2008-Regularization on Graphs with Function-adapted Diffusion Processes</a></p>
<p>13 0.14085604 <a title="94-lsi-13" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>14 0.14023398 <a title="94-lsi-14" href="./jmlr-2008-Learning_Control_Knowledge_for_Forward_Search_Planning.html">49 jmlr-2008-Learning Control Knowledge for Forward Search Planning</a></p>
<p>15 0.13885577 <a title="94-lsi-15" href="./jmlr-2008-Model_Selection_Through_Sparse_Maximum_Likelihood_Estimation_for_Multivariate_Gaussian_or_Binary_Data.html">62 jmlr-2008-Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data</a></p>
<p>16 0.13719888 <a title="94-lsi-16" href="./jmlr-2008-Incremental_Identification_of_Qualitative_Models_of_Biological_Systems_using_Inductive_Logic_Programming.html">44 jmlr-2008-Incremental Identification of Qualitative Models of Biological Systems using Inductive Logic Programming</a></p>
<p>17 0.13070716 <a title="94-lsi-17" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>18 0.12472907 <a title="94-lsi-18" href="./jmlr-2008-A_New_Algorithm_for_Estimating_the_Effective_Dimension-Reduction_Subspace.html">5 jmlr-2008-A New Algorithm for Estimating the Effective Dimension-Reduction Subspace</a></p>
<p>19 0.12029566 <a title="94-lsi-19" href="./jmlr-2008-Hit_Miss_Networks_with_Applications_to_Instance_Selection.html">43 jmlr-2008-Hit Miss Networks with Applications to Instance Selection</a></p>
<p>20 0.1190963 <a title="94-lsi-20" href="./jmlr-2008-Learning_to_Combine_Motor_Primitives_Via_Greedy_Additive_Regression.html">53 jmlr-2008-Learning to Combine Motor Primitives Via Greedy Additive Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.024), (4, 0.021), (25, 0.036), (26, 0.034), (59, 0.05), (66, 0.141), (90, 0.487), (91, 0.025), (96, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.60606796 <a title="94-lda-1" href="./jmlr-2008-Value_Function_Approximation_using_Multiple_Aggregation_for_Multiattribute_Resource_Management.html">94 jmlr-2008-Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management</a></p>
<p>Author: Abraham George, Warren B. Powell, Sanjeev R. Kulkarni</p><p>Abstract: We consider the problem of estimating the value of a multiattribute resource, where the attributes are categorical or discrete in nature and the number of potential attribute vectors is very large. The problem arises in approximate dynamic programming when we need to estimate the value of a multiattribute resource from estimates based on Monte-Carlo simulation. These problems have been traditionally solved using aggregation, but choosing the right level of aggregation requires resolving the classic tradeoff between aggregation error and sampling error. We propose a method that estimates the value of a resource at different levels of aggregation simultaneously, and then uses a weighted combination of the estimates. Using the optimal weights, which minimizes the variance of the estimate while accounting for correlations between the estimates, is computationally too expensive for practical applications. We have found that a simple inverse variance formula (adjusted for bias), which effectively assumes the estimates are independent, produces near-optimal estimates. We use the setting of two levels of aggregation to explain why this approximation works so well. Keywords: hierarchical statistics, approximate dynamic programming, mixture models, adaptive learning, multiattribute resources</p><p>2 0.32175893 <a title="94-lda-2" href="./jmlr-2008-Robust_Submodular_Observation_Selection.html">83 jmlr-2008-Robust Submodular Observation Selection</a></p>
<p>Author: Andreas Krause, H. Brendan McMahan, Carlos Guestrin, Anupam Gupta</p><p>Abstract: In many applications, one has to actively select among a set of expensive observations before making an informed decision. For example, in environmental monitoring, we want to select locations to measure in order to most effectively predict spatial phenomena. Often, we want to select observations which are robust against a number of possible objective functions. Examples include minimizing the maximum posterior variance in Gaussian Process regression, robust experimental design, and sensor placement for outbreak detection. In this paper, we present the Submodular Saturation algorithm, a simple and efﬁcient algorithm with strong theoretical approximation guarantees for cases where the possible objective functions exhibit submodularity, an intuitive diminishing returns property. Moreover, we prove that better approximation algorithms do not exist unless NP-complete problems admit efﬁcient algorithms. We show how our algorithm can be extended to handle complex cost functions (incorporating non-unit observation cost or communication and path costs). We also show how the algorithm can be used to near-optimally trade off expected-case (e.g., the Mean Square Prediction Error in Gaussian Process regression) and worst-case (e.g., maximum predictive variance) performance. We show that many important machine learning problems ﬁt our robust submodular observation selection formalism, and provide extensive empirical evaluation on several real-world problems. For Gaussian Process regression, our algorithm compares favorably with state-of-the-art heuristics described in the geostatistics literature, while being simpler, faster and providing theoretical guarantees. For robust experimental design, our algorithm performs favorably compared to SDP-based algorithms. c 2008 Andreas Krause, H. Brendan McMahan, Carlos Guestrin and Anupam Gupta. K RAUSE , M C M AHAN , G UESTRIN AND G UPTA Keywords: observation selection, experimental design, active learning, submodular functions, Gaussi</p><p>3 0.31671295 <a title="94-lda-3" href="./jmlr-2008-Value_Function_Based_Reinforcement_Learning_in_Changing_Markovian_Environments.html">95 jmlr-2008-Value Function Based Reinforcement Learning in Changing Markovian Environments</a></p>
<p>Author: Balázs Csanád Csáji, László Monostori</p><p>Abstract: The paper investigates the possibility of applying value function based reinforcement learning (RL) methods in cases when the environment may change over time. First, theorems are presented which show that the optimal value function of a discounted Markov decision process (MDP) Lipschitz continuously depends on the immediate-cost function and the transition-probability function. Dependence on the discount factor is also analyzed and shown to be non-Lipschitz. Afterwards, the concept of (ε, δ)-MDPs is introduced, which is a generalization of MDPs and ε-MDPs. In this model the environment may change over time, more precisely, the transition function and the cost function may vary from time to time, but the changes must be bounded in the limit. Then, learning algorithms in changing environments are analyzed. A general relaxed convergence theorem for stochastic iterative algorithms is presented. We also demonstrate the results through three classical RL methods: asynchronous value iteration, Q-learning and temporal difference learning. Finally, some numerical experiments concerning changing environments are presented. Keywords: Markov decision processes, reinforcement learning, changing environments, (ε, δ)MDPs, value function bounds, stochastic iterative algorithms</p><p>4 0.31292221 <a title="94-lda-4" href="./jmlr-2008-Finite-Time_Bounds_for_Fitted_Value_Iteration.html">36 jmlr-2008-Finite-Time Bounds for Fitted Value Iteration</a></p>
<p>Author: Rémi Munos, Csaba Szepesvári</p><p>Abstract: In this paper we develop a theoretical analysis of the performance of sampling-based ﬁtted value iteration (FVI) to solve inﬁnite state-space, discounted-reward Markovian decision processes (MDPs) under the assumption that a generative model of the environment is available. Our main results come in the form of ﬁnite-time bounds on the performance of two versions of sampling-based FVI. The convergence rate results obtained allow us to show that both versions of FVI are well behaving in the sense that by using a sufﬁciently large number of samples for a large class of MDPs, arbitrary good performance can be achieved with high probability. An important feature of our proof technique is that it permits the study of weighted L p -norm performance bounds. As a result, our technique applies to a large class of function-approximation methods (e.g., neural networks, adaptive regression trees, kernel machines, locally weighted learning), and our bounds scale well with the effective horizon of the MDP. The bounds show a dependence on the stochastic stability properties of the MDP: they scale with the discounted-average concentrability of the future-state distributions. They also depend on a new measure of the approximation power of the function space, the inherent Bellman residual, which reﬂects how well the function space is “aligned” with the dynamics and rewards of the MDP. The conditions of the main result, as well as the concepts introduced in the analysis, are extensively discussed and compared to previous theoretical results. Numerical experiments are used to substantiate the theoretical ﬁndings. Keywords: ﬁtted value iteration, discounted Markovian decision processes, generative model, reinforcement learning, supervised learning, regression, Pollard’s inequality, statistical learning theory, optimal control</p><p>5 0.31239197 <a title="94-lda-5" href="./jmlr-2008-Bayesian_Inference_and_Optimal_Design_for_the_Sparse_Linear_Model.html">18 jmlr-2008-Bayesian Inference and Optimal Design for the Sparse Linear Model</a></p>
<p>Author: Matthias W. Seeger</p><p>Abstract: The linear model with sparsity-favouring prior on the coefﬁcients has important applications in many different domains. In machine learning, most methods to date search for maximum a posteriori sparse solutions and neglect to represent posterior uncertainties. In this paper, we address problems of Bayesian optimal design (or experiment planning), for which accurate estimates of uncertainty are essential. To this end, we employ expectation propagation approximate inference for the linear model with Laplace prior, giving new insight into numerical stability properties and proposing a robust algorithm. We also show how to estimate model hyperparameters by empirical Bayesian maximisation of the marginal likelihood, and propose ideas in order to scale up the method to very large underdetermined problems. We demonstrate the versatility of our framework on the application of gene regulatory network identiﬁcation from micro-array expression data, where both the Laplace prior and the active experimental design approach are shown to result in signiﬁcant improvements. We also address the problem of sparse coding of natural images, and show how our framework can be used for compressive sensing tasks. Part of this work appeared in Seeger et al. (2007b). The gene network identiﬁcation application appears in Steinke et al. (2007). Keywords: sparse linear model, Laplace prior, expectation propagation, approximate inference, optimal design, Bayesian statistics, gene network recovery, image coding, compressive sensing</p><p>6 0.31018275 <a title="94-lda-6" href="./jmlr-2008-Optimal_Solutions_for_Sparse_Principal_Component_Analysis.html">75 jmlr-2008-Optimal Solutions for Sparse Principal Component Analysis</a></p>
<p>7 0.30879807 <a title="94-lda-7" href="./jmlr-2008-Learning_Bounded_Treewidth_Bayesian_Networks.html">48 jmlr-2008-Learning Bounded Treewidth Bayesian Networks</a></p>
<p>8 0.30580941 <a title="94-lda-8" href="./jmlr-2008-Automatic_PCA_Dimension_Selection_for_High_Dimensional_Data_and_Small_Sample_Sizes.html">17 jmlr-2008-Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes</a></p>
<p>9 0.30569226 <a title="94-lda-9" href="./jmlr-2008-On_Relevant_Dimensions_in_Kernel_Feature_Spaces.html">70 jmlr-2008-On Relevant Dimensions in Kernel Feature Spaces</a></p>
<p>10 0.30538967 <a title="94-lda-10" href="./jmlr-2008-Max-margin_Classification_of_Data_with_Absent_Features.html">58 jmlr-2008-Max-margin Classification of Data with Absent Features</a></p>
<p>11 0.3052119 <a title="94-lda-11" href="./jmlr-2008-Finding_Optimal_Bayesian_Network_Given_a_Super-Structure.html">35 jmlr-2008-Finding Optimal Bayesian Network Given a Super-Structure</a></p>
<p>12 0.30456105 <a title="94-lda-12" href="./jmlr-2008-Estimating_the_Confidence_Interval_for_Prediction_Errors_of_Support_Vector_Machine_Classifiers.html">32 jmlr-2008-Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers</a></p>
<p>13 0.30452022 <a title="94-lda-13" href="./jmlr-2008-Learning_to_Select_Features_using_their_Properties.html">54 jmlr-2008-Learning to Select Features using their Properties</a></p>
<p>14 0.30338678 <a title="94-lda-14" href="./jmlr-2008-Online_Learning_of_Complex_Prediction_Problems_Using_Simultaneous_Projections.html">74 jmlr-2008-Online Learning of Complex Prediction Problems Using Simultaneous Projections</a></p>
<p>15 0.30300692 <a title="94-lda-15" href="./jmlr-2008-Cross-Validation_Optimization_for_Large_Scale_Structured_Classification_Kernel_Methods.html">29 jmlr-2008-Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods</a></p>
<p>16 0.30280602 <a title="94-lda-16" href="./jmlr-2008-A_New_Algorithm_for_Estimating_the_Effective_Dimension-Reduction_Subspace.html">5 jmlr-2008-A New Algorithm for Estimating the Effective Dimension-Reduction Subspace</a></p>
<p>17 0.301965 <a title="94-lda-17" href="./jmlr-2008-Multi-Agent_Reinforcement_Learning_in_Common_Interest_and_Fixed_Sum_Stochastic_Games%3A_An_Experimental_Study.html">65 jmlr-2008-Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study</a></p>
<p>18 0.30142137 <a title="94-lda-18" href="./jmlr-2008-Stationary_Features_and_Cat_Detection.html">87 jmlr-2008-Stationary Features and Cat Detection</a></p>
<p>19 0.30121517 <a title="94-lda-19" href="./jmlr-2008-Theoretical_Advantages_of_Lenient_Learners%3A__An_Evolutionary_Game_Theoretic_Perspective.html">90 jmlr-2008-Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective</a></p>
<p>20 0.30106905 <a title="94-lda-20" href="./jmlr-2008-A_Library_for_Locally_Weighted_Projection_Regression%C2%A0%C2%A0%C2%A0%C2%A0%28Machine_Learning_Open_Source_Software_Paper%29.html">2 jmlr-2008-A Library for Locally Weighted Projection Regression    (Machine Learning Open Source Software Paper)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
