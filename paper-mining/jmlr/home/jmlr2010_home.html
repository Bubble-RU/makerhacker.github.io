<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>jmlr 2010 knowledge graph</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2010" href="#">jmlr2010</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>jmlr 2010 knowledge graph</h1>
<br/><h3>similar papers computed by tfidf model</h3><br/><h3>similar papers computed by <a title="lsi-model" href="./jmlr2010_lsi.html">lsi model</a></h3><br/><h3>similar papers computed by <a title="lda-model" href="./jmlr2010_lda.html">lda model</a></h3><br/><h2>papers list:</h2><p>1 <a title="jmlr-2010-1" href="../jmlr2010/jmlr-2010-A_Comparison_of_Optimization_Methods_and_Software_for_Large-scale_L1-regularized_Linear_Classification.html">jmlr-2010-A Comparison of Optimization Methods and Software for Large-scale L1-regularized Linear Classification</a></p>
<p>Author: Guo-Xun Yuan, Kai-Wei Chang, Cho-Jui Hsieh, Chih-Jen Lin</p><p>Abstract: Large-scale linear classiﬁcation is widely used in many areas. The L1-regularized form can be applied for feature selection; however, its non-differentiability causes more difﬁculties in training. Although various optimization methods have been proposed in recent years, these have not yet been compared suitably. In this paper, we ﬁrst broadly review existing methods. Then, we discuss state-of-the-art software packages in detail and propose two efﬁcient implementations. Extensive comparisons indicate that carefully implemented coordinate descent methods are very suitable for training large document data. Keywords: L1 regularization, linear classiﬁcation, optimization methods, logistic regression, support vector machines, document classiﬁcation</p><p>2 <a title="jmlr-2010-2" href="../jmlr2010/jmlr-2010-A_Convergent_Online_Single_Time_Scale_Actor_Critic_Algorithm.html">jmlr-2010-A Convergent Online Single Time Scale Actor Critic Algorithm</a></p>
<p>Author: Dotan Di Castro, Ron Meir</p><p>Abstract: Actor-Critic based approaches were among the ﬁrst to address reinforcement learning in a general setting. Recently, these algorithms have gained renewed interest due to their generality, good convergence properties, and possible biological relevance. In this paper, we introduce an online temporal difference based actor-critic algorithm which is proved to converge to a neighborhood of a local maximum of the average reward. Linear function approximation is used by the critic in order estimate the value function, and the temporal difference signal, which is passed from the critic to the actor. The main distinguishing feature of the present convergence proof is that both the actor and the critic operate on a similar time scale, while in most current convergence proofs they are required to have very different time scales in order to converge. Moreover, the same temporal difference signal is used to update the parameters of both the actor and the critic. A limitation of the proposed approach, compared to results available for two time scale convergence, is that convergence is guaranteed only to a neighborhood of an optimal value, rather to an optimal value itself. The single time scale and identical temporal difference signal used by the actor and the critic, may provide a step towards constructing more biologically realistic models of reinforcement learning in the brain. Keywords: actor critic, single time scale convergence, temporal difference</p><p>3 <a title="jmlr-2010-3" href="../jmlr2010/jmlr-2010-A_Fast_Hybrid_Algorithm_for_Large-Scalel1-Regularized_Logistic_Regression.html">jmlr-2010-A Fast Hybrid Algorithm for Large-Scalel1-Regularized Logistic Regression</a></p>
<p>Author: Jianing Shi, Wotao Yin, Stanley Osher, Paul Sajda</p><p>Abstract: ℓ1 -regularized logistic regression, also known as sparse logistic regression, is widely used in machine learning, computer vision, data mining, bioinformatics and neural signal processing. The use of ℓ1 regularization attributes attractive properties to the classiﬁer, such as feature selection, robustness to noise, and as a result, classiﬁer generality in the context of supervised learning. When a sparse logistic regression problem has large-scale data in high dimensions, it is computationally expensive to minimize the non-differentiable ℓ1 -norm in the objective function. Motivated by recent work (Koh et al., 2007; Hale et al., 2008), we propose a novel hybrid algorithm based on combining two types of optimization iterations: one being very fast and memory friendly while the other being slower but more accurate. Called hybrid iterative shrinkage (HIS), the resulting algorithm is comprised of a ﬁxed point continuation phase and an interior point phase. The ﬁrst phase is based completely on memory efﬁcient operations such as matrix-vector multiplications, while the second phase is based on a truncated Newton’s method. Furthermore, we show that various optimization techniques, including line search and continuation, can signiﬁcantly accelerate convergence. The algorithm has global convergence at a geometric rate (a Q-linear rate in optimization terminology). We present a numerical comparison with several existing algorithms, including an analysis using benchmark data from the UCI machine learning repository, and show our algorithm is the most computationally efﬁcient without loss of accuracy. Keywords: logistic regression, ℓ1 regularization, ﬁxed point continuation, supervised learning, large scale c 2010 Jianing Shi, Wotao Yin, Stanley Osher and Paul Sajda. S HI , Y IN , O SHER AND S AJDA</p><p>4 <a title="jmlr-2010-4" href="../jmlr2010/jmlr-2010-A_Generalized_Path_Integral_Control_Approach_to_Reinforcement_Learning.html">jmlr-2010-A Generalized Path Integral Control Approach to Reinforcement Learning</a></p>
<p>Author: Evangelos Theodorou, Jonas Buchli, Stefan Schaal</p><p>Abstract: With the goal to generate more scalable algorithms with higher efﬁciency and fewer open parameters, reinforcement learning (RL) has recently moved towards combining classical techniques from optimal control and dynamic programming with modern learning techniques from statistical estimation theory. In this vein, this paper suggests to use the framework of stochastic optimal control with path integrals to derive a novel approach to RL with parameterized policies. While solidly grounded in value function estimation and optimal control based on the stochastic Hamilton-JacobiBellman (HJB) equations, policy improvements can be transformed into an approximation problem of a path integral which has no open algorithmic parameters other than the exploration noise. The resulting algorithm can be conceived of as model-based, semi-model-based, or even model free, depending on how the learning problem is structured. The update equations have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Our new algorithm demonstrates interesting similarities with previous RL research in the framework of probability matching and provides intuition why the slightly heuristically motivated probability matching approach can actually perform well. Empirical evaluations demonstrate signiﬁcant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a simulated 12 degree-of-freedom robot dog illustrates the functionality of our algorithm in a complex robot learning scenario. We believe that Policy Improvement with Path Integrals (PI2 ) offers currently one of the most efﬁcient, numerically robust, and easy to implement algorithms for RL based on trajectory roll-outs. Keywords: stochastic optimal control, reinforcement learning, parameterized policies</p><p>5 <a title="jmlr-2010-5" href="../jmlr2010/jmlr-2010-A_Quasi-Newton_Approach_to_Nonsmooth_Convex_Optimization_Problems_in_Machine_Learning.html">jmlr-2010-A Quasi-Newton Approach to Nonsmooth Convex Optimization Problems in Machine Learning</a></p>
<p>Author: Jin Yu, S.V.N. Vishwanathan, Simon Güunter, Nicol N. Schraudolph</p><p>Abstract: We extend the well-known BFGS quasi-Newton method and its memory-limited variant LBFGS to the optimization of nonsmooth convex objectives. This is done in a rigorous fashion by generalizing three components of BFGS to subdifferentials: the local quadratic model, the identiﬁcation of a descent direction, and the Wolfe line search conditions. We prove that under some technical conditions, the resulting subBFGS algorithm is globally convergent in objective function value. We apply its memory-limited variant (subLBFGS) to L2 -regularized risk minimization with the binary hinge loss. To extend our algorithm to the multiclass and multilabel settings, we develop a new, efﬁcient, exact line search algorithm. We prove its worst-case time complexity bounds, and show that our line search can also be used to extend a recently developed bundle method to the multiclass and multilabel settings. We also apply the direction-ﬁnding component of our algorithm to L1 -regularized risk minimization with logistic loss. In all these contexts our methods perform comparable to or better than specialized state-of-the-art solvers on a number of publicly available data sets. An open source implementation of our algorithms is freely available. Keywords: BFGS, variable metric methods, Wolfe conditions, subgradient, risk minimization, hinge loss, multiclass, multilabel, bundle methods, BMRM, OCAS, OWL-QN</p><p>6 <a title="jmlr-2010-6" href="../jmlr2010/jmlr-2010-A_Rotation_Test_to_Verify_Latent_Structure.html">jmlr-2010-A Rotation Test to Verify Latent Structure</a></p>
<p>Author: Patrick O. Perry, Art B. Owen</p><p>Abstract: In multivariate regression models we have the opportunity to look for hidden structure unrelated to the observed predictors. However, when one ﬁts a model involving such latent variables it is important to be able to tell if the structure is real, or just an artifact of correlation in the regression errors. We develop a new statistical test based on random rotations for verifying the existence of latent variables. The rotations are carefully constructed to rotate orthogonally to the column space of the regression model. We ﬁnd that only non-Gaussian latent variables are detectable, a ﬁnding that parallels a well known phenomenon in independent components analysis. We base our test on a measure of non-Gaussianity in the histogram of the principal eigenvector components instead of on the eigenvalue. The method ﬁnds and veriﬁes some latent dichotomies in the microarray data from the AGEMAP consortium. Keywords: independent components analysis, Kronecker covariance, latent variables, projection pursuit, transposable data</p><p>7 <a title="jmlr-2010-7" href="../jmlr2010/jmlr-2010-A_Streaming_Parallel_Decision_Tree_Algorithm.html">jmlr-2010-A Streaming Parallel Decision Tree Algorithm</a></p>
<p>Author: Yael Ben-Haim, Elad Tom-Tov</p><p>Abstract: We propose a new algorithm for building decision tree classiﬁers. The algorithm is executed in a distributed environment and is especially designed for classifying large data sets and streaming data. It is empirically shown to be as accurate as a standard decision tree classiﬁer, while being scalable for processing of streaming data on multiple processors. These ﬁndings are supported by a rigorous analysis of the algorithm’s accuracy. The essence of the algorithm is to quickly construct histograms at the processors, which compress the data to a ﬁxed amount of memory. A master processor uses this information to ﬁnd near-optimal split points to terminal tree nodes. Our analysis shows that guarantees on the local accuracy of split points imply guarantees on the overall tree accuracy. Keywords: decision tree classiﬁers, distributed computing, streaming data, scalability</p><p>8 <a title="jmlr-2010-8" href="../jmlr2010/jmlr-2010-A_Surrogate_Modeling_and_Adaptive_Sampling_Toolbox_for_Computer_Based_Design.html">jmlr-2010-A Surrogate Modeling and Adaptive Sampling Toolbox for Computer Based Design</a></p>
<p>Author: Dirk Gorissen, Ivo Couckuyt, Piet Demeester, Tom Dhaene, Karel Crombecq</p><p>Abstract: An exceedingly large number of scientiﬁc and engineering ﬁelds are confronted with the need for computer simulations to study complex, real world phenomena or solve challenging design problems. However, due to the computational cost of these high ﬁdelity simulations, the use of neural networks, kernel methods, and other surrogate modeling techniques have become indispensable. Surrogate models are compact and cheap to evaluate, and have proven very useful for tasks such as optimization, design space exploration, prototyping, and sensitivity analysis. Consequently, in many ﬁelds there is great interest in tools and techniques that facilitate the construction of such regression models, while minimizing the computational cost and maximizing model accuracy. This paper presents a mature, ﬂexible, and adaptive machine learning toolkit for regression modeling and active learning to tackle these issues. The toolkit brings together algorithms for data ﬁtting, model selection, sample selection (active learning), hyperparameter optimization, and distributed computing in order to empower a domain expert to efﬁciently generate an accurate model for the problem or data at hand. Keywords: surrogate modeling, metamodeling, function approximation, model selection, adaptive sampling, active learning, distributed computing 1. Background and Motivation In many science and engineering problems researchers make heavy use of computer simulation codes in order to replace expensive physical experiments and improve the quality and performance of engineered products and devices. Such simulation activities are collectively referred to as computational science/engineering. Unfortunately, while allowing scientists more ﬂexibility to study phenomena under controlled conditions, computer simulations require a substantial investment of c 2010 Dirk Gorissen, Ivo Couckuyt, Piet Demeester, Tom Dhaene and Karel Crombecq. G ORISSEN , C OUCKUYT, D EMEESTER , D HAENE AND C ROMBECQ computation time. One simulation may take many minutes, hours, days or even weeks, quickly rendering parameter studies impractical (Forrester et al., 2008; Simpson et al., 2008). Of the different ways to deal with this problem, this paper is concerned with the construction of simpler approximation models to predict the system performance and develop a relationship between the system inputs and outputs. When properly constructed, these approximation models mimic the behavior of the simulation accurately while being computationally cheap(er) to evaluate. Different approximation methods exist, each with their relative merits. This work concentrates on the use of data-driven, global approximations using compact surrogate models (also known as metamodels, replacement models, or response surface models). Examples include: rational functions, Kriging models, Artiﬁcial Neural Networks (ANN), splines, and Support Vector Machines (SVM). Once such a global approximation is available it is of great use for gaining insight into the behavior of the underlying system. The surrogate may be easily queried, optimized, visualized, and seamlessly integrated into CAD/CAE software packages. The challenge is thus how to generate an approximation model that is as accurate as possible over the complete domain of interest while minimizing the simulation cost. Solving this challenge involves multiple sub-problems that must be addressed: how to interface with the simulation code, how to run simulations (locally, or on a cluster or cloud), which model type to approximate the data with and how to set the model complexity (e.g., topology of a neural network), how to estimate the model quality and ensure the domain expert trusts the model, how to decide which simulations to run (data collection), etc. The data collection aspect is worth emphasizing. Since data is computationally expensive to obtain and the optimal data distribution is not known up front, data points should be selected iteratively, there where the information gain will be the greatest. A sampling function is needed that minimizes the number of sample points selected in each iteration, yet maximizes the information gain of each iteration step. This process is called adaptive sampling but is also known as active learning, or sequential design. There is a complex dependency web between these different options and dealing with these dependencies is non-trivial, particularly for a domain expert for whom the surrogate model is just an intermediate step towards solving a larger, more important problem. Few domain experts will be experts in the intricacies of efﬁcient sampling and modeling strategies. Their primary concern is obtaining an accurate replacement metamodel for their problem as fast as possible and with minimal overhead (Gorissen et al., 2009d). As a result these choices are often made in a pragmatic, sometimes even ad-hoc, manner. This paper discusses an advanced, and integrated software framework that provides a ﬂexible and rigorous means to tackle such problems. This work lies at the intersection of Machine Learning/AI, Modeling and Simulation, and Distributed Computing. The methods developed are applicable to any domain where a cheap, accurate, approximation is needed to replace some expensive reference model. Our experience has been that the availability of such a framework can facilitate the transfer of knowledge from surrogate modeling researchers and lower the barrier of entry for domain experts. 2. SUMO Toolbox The platform in question is the Matlab SUrrogate MOdeling (SUMO) Toolbox, illustrated in Figure 1. Given a simulation engine (Fluent, Cadence, Abaqus, HFSS, etc.) or other data source (data 2052 A S URROGATE M ODELING AND A DAPTIVE S AMPLING TOOLBOX FOR C OMPUTER BASED D ESIGN Figure 1: The SUMO Toolbox is a ﬂexible framework for accurate global surrogate modeling and adaptive sampling (active learning). It features a rich set of plugins, is applicable to a wide range of domains, and can be applied in an autonomous, black-box fashion, or under full manual control. Written in Matlab and Java it is fully cross platform and comes with a large (60+) number of example problems. set, Matlab script, Java class, etc.), the toolbox drives the data source to produce a surrogate model within the time and accuracy constraints set by the user. The SUMO Toolbox adopts a microkernel design philosophy with many different plugins available for each of the different sub-problems:1 model types (rational functions, Kriging, splines, SVM, ANN, etc.), hyperparameter optimization algorithms (Particle Swarm Optimization, Efﬁcient Global Optimization, simulated annealing, Genetic Algorithm, etc.), model selection algorithms (cross validation, AIC, Leave-out set, etc.), sample selection (random, error based, density based, hybrid, etc.), Design of Experiments (Latin hypercube, Box-Bhenken, etc.), and sample evaluation methods (local, on a cluster or grid). The behavior of each software component is conﬁgurable through a central XML ﬁle and components can easily be added, removed or replaced by custom implementations. In addition the toolbox provides ‘meta’ plugins. For example to automatically select the best model type for a given problem (Gorissen et al., 2009d) or to use multiple model selection or sample selection criteria in concert (Gorissen et al., 2010). Furthermore, there is built-in support for high performance computing. On the modeling side, the model generation process can take full advantage of multi-core CPUs and even of a complete cluster or grid. This can result in signiﬁcant speedups for model types where the ﬁtting process can be expensive (e.g., neural networks). Likewise, sample evaluation (simulation) can occur locally (with the option to take advantage of multi-core architectures) or on a separate compute cluster or grid (possibly accessed through a remote head-node). All interfacing with the grid middleware 1. The full list of plugins and features can be found at http://www.sumowiki.intec.ugent.be. 2053 G ORISSEN , C OUCKUYT, D EMEESTER , D HAENE AND C ROMBECQ (submission, job monitoring, rescheduling of failed/lost simulation points, etc.) is handled transparently and automatically (see Gorissen et al., 2009c for more details). Also, the sample evaluation component runs in parallel with the other components (non-blocking) and not sequentially. This allows for an optimal use of computational resources. In addition the SUMO Toolbox contains extensive logging and proﬁling capabilities so that the modeling process can easily be tracked and the modeling decisions understood. Once a ﬁnal model has been generated, a GUI tool is available to visually explore the model (including derivatives and prediction uncertainty), assess its quality, and export it for use in other software tools. 3. Applications The SUMO Toolbox has already been applied successfully to a very wide range of applications, including RF circuit block modeling (Gorissen et al., 2009b), hydrological modeling (Couckuyt et al., 2009), Electronic Packaging (Zhu and Franzon, 2009), aerodynamic modeling (Gorissen et al., 2009a), process engineering (Stephens et al., 2009), and automotive data modeling (Gorissen et al., 2010). Besides global modeling capabilities, the SUMO Toolbox also includes a powerful optimization framework based on the Efﬁcient Global Optimization framework developed by Jones et al. (1998). As of version 6.1, the toolbox also contains an example of how the framework can also be applied to solve classiﬁcation problems. In sum, the goal of the toolbox is to ﬁll the void in machine learning software when it comes to the challenging, costly, real-valued, problems faced in computational engineering. The toolbox is in use successfully at various institutions and we are continuously reﬁning and extending the set of available plugins as the number of applications increase. Usage instructions, design documentation, and stable releases for all major platforms can be found at http://www.sumo.intec.ugent.be. References I. Couckuyt, D. Gorissen, H. Rouhani, E. Laermans, and T. Dhaene. Evolutionary regression modeling with active learning: An application to rainfall runoff modeling. In International Conference on Adaptive and Natural Computing Algorithms, volume LNCS 5495, pages 548–558, Sep. 2009. A. Forrester, A. Sobester, and A. Keane. Engineering Design Via Surrogate Modelling: A Practical Guide. Wiley, 2008. D. Gorissen, K. Crombecq, I. Couckuyt, and T. Dhaene. Foundations of Computational Intelligence, Volume 1: Learning and Approximation: Theoretical Foundations and Applications, volume 201, chapter Automatic approximation of expensive functions with active learning, pages 35–62. Springer Verlag, Series Studies in Computational Intelligence, 2009a. D. Gorissen, L. De Tommasi, K. Crombecq, and T. Dhaene. Sequential modeling of a low noise ampliﬁer with neural networks and active learning. Neural Computing and Applications, 18(5): 485–494, Jun. 2009b. D. Gorissen, T. Dhaene, P. Demeester, and J. Broeckhove. Handbook of Research on Grid Technologies and Utility Computing: Concepts for Managing Large-Scale Applications, chapter Grid enabled surrogate modeling, pages 249–258. IGI Global, May 2009c. 2054 A S URROGATE M ODELING AND A DAPTIVE S AMPLING TOOLBOX FOR C OMPUTER BASED D ESIGN D. Gorissen, T. Dhaene, and F. DeTurck. Evolutionary model type selection for global surrogate modeling. Journal of Machine Learning Research, 10:2039–2078, 2009d. D. Gorissen, I. Couckuyt, E. Laermans, and T. Dhaene. Multiobjective global surrogate modeling,dealing with the 5-percent problem. Engineering with Computers, 26(1):81–89, Jan. 2010. D. R. Jones, M. Schonlau, and W. J. Welch. Efﬁcient global optimization of expensive black-box functions. Journal of Global Optimization, 13(4):455–492, Nov. 1998. ISSN 0925-5001. T. W. Simpson, V. Toropov, V. Balabanov, and F. A. C. Viana. Design and analysis of computer experiments in multidisciplinary design optimization: a review of how far we have come or not. In Proceedings of the 12th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference, 2008 MAO, Victoria, Canada, 2008. D.W. Stephens, D. Gorissen, and T. Dhaene. Surrogate based sensitivity analysis of process equipment. In Proc. of 7th International Conference on CFD in the Minerals and Process Industries, CSIRO, Melbourne, Australia, Dec. 2009. T. Zhu and P. D. Franzon. Application of surrogate modeling to generate compact and PVT-sensitive IBIS models. In Proceedings of the 18th Conference on Electrical Performance of Electronic Packaging and Systems (EPEPS), Oct. 2009. 2055</p><p>9 <a title="jmlr-2010-9" href="../jmlr2010/jmlr-2010-An_Efficient_Explanation_of_Individual_Classifications_using_Game_Theory.html">jmlr-2010-An Efficient Explanation of Individual Classifications using Game Theory</a></p>
<p>Author: Erik Ĺ trumbelj, Igor Kononenko</p><p>Abstract: We present a general method for explaining individual predictions of classiﬁcation models. The method is based on fundamental concepts from coalitional game theory and predictions are explained with contributions of individual feature values. We overcome the method’s initial exponential time complexity with a sampling-based approximation. In the experimental part of the paper we use the developed method on models generated by several well-known machine learning algorithms on both synthetic and real-world data sets. The results demonstrate that the method is efﬁcient and that the explanations are intuitive and useful. Keywords: data postprocessing, classiﬁcation, explanation, visualization</p><p>10 <a title="jmlr-2010-10" href="../jmlr2010/jmlr-2010-An_Exponential_Model_for_Infinite_Rankings.html">jmlr-2010-An Exponential Model for Infinite Rankings</a></p>
<p>Author: Marina Meilă, Le Bao</p><p>Abstract: This paper presents a statistical model for expressing preferences through rankings, when the number of alternatives (items to rank) is large. A human ranker will then typically rank only the most preferred items, and may not even examine the whole set of items, or know how many they are. Similarly, a user presented with the ranked output of a search engine, will only consider the highest ranked items. We model such situations by introducing a stagewise ranking model that operates with ﬁnite ordered lists called top-t orderings over an inﬁnite space of items. We give algorithms to estimate this model from data, and demonstrate that it has sufﬁcient statistics, being thus an exponential family model with continuous and discrete parameters. We describe its conjugate prior and other statistical properties. Then, we extend the estimation problem to multimodal data by introducing an Exponential-Blurring-Mean-Shift nonparametric clustering algorithm. The experiments highlight the properties of our model and demonstrate that inﬁnite models over permutations can be simple, elegant and practical. Keywords: permutations, partial orderings, Mallows model, distance based ranking model, exponential family, non-parametric clustering, branch-and-bound</p><p>11 <a title="jmlr-2010-11" href="../jmlr2010/jmlr-2010-An_Investigation_of_Missing_Data_Methods_for_Classification_Trees_Applied_to_Binary_Response_Data.html">jmlr-2010-An Investigation of Missing Data Methods for Classification Trees Applied to Binary Response Data</a></p>
<p>Author: Yufeng Ding, Jeffrey S. Simonoff</p><p>Abstract: There are many different methods used by classiﬁcation tree algorithms when missing data occur in the predictors, but few studies have been done comparing their appropriateness and performance. This paper provides both analytic and Monte Carlo evidence regarding the effectiveness of six popular missing data methods for classiﬁcation trees applied to binary response data. We show that in the context of classiﬁcation trees, the relationship between the missingness and the dependent variable, as well as the existence or non-existence of missing values in the testing data, are the most helpful criteria to distinguish different missing data methods. In particular, separate class is clearly the best method to use when the testing set has missing values and the missingness is related to the response variable. A real data set related to modeling bankruptcy of a ﬁrm is then analyzed. The paper concludes with discussion of adaptation of these results to logistic regression, and other potential generalizations. Keywords: classiﬁcation tree, missing data, separate class, RPART, C4.5, CART 1. Classiﬁcation Trees and the Problem of Missing Data Classiﬁcation trees are a supervised learning method appropriate for data where the response variable is categorical. The simple methodology behind classiﬁcation trees is to recursively split data based upon the predictors that best distinguish the response variable classes. There are, of course, many subtleties, such as the choice of criterion function used to pick the best split variable, stopping rules, pruning rules, and so on. In this study, we mostly rely on the built-in features of the tree algorithms C 4.5 and RPART to implement tree methods. Details about classiﬁcation trees can be found in various references, for example, Breiman, Friedman, Olshen, and Stone (1998) and Quinlan (1993). Classiﬁcation trees are computationally efﬁcient, can handle mixed variables (continuous and discrete) easily and the rules generated by them are relatively easy to interpret and understand. Classiﬁcation trees are highly ﬂexible, and naturally uncover interaction effects among the independent variables. Classiﬁcation trees are also popular because they can easily be incorporated into learning ensembles or larger learning systems as base learners. c 2010 Yufeng Ding and Jeffrey S. Simonoff. D ING AND S IMONOFF Like most statistics or machine learning methods, “base form” classiﬁcation trees are designed assuming that data are complete. That is, all of the values in the data matrix, with the rows being the observations (instances) and the columns being the variables (attributes), are observed. However, missing data (meaning that some of the values in the data matrix are not observed) is a very common problem, and for this reason classiﬁcation trees have to, and do, have ways of dealing with missing data in the predictors. (In supervised learning, an observation with missing response value has no information about the underlying relationship, and must be omitted. There is, however, research in the ﬁeld of semi-supervised learning methods that tries to handle the situation where the response value is missing, for example, Wang and Shen 2007.) Although there are many different ways of dealing with missing data in classiﬁcation trees, there are relatively few studies in the literature about the appropriateness and performance of these missing data methods. Moreover, most of these studies limited their coverage to the simplest missing data scenario, namely, missing completely at random (MCAR), while our study shows that the missing data generating process is one of the two crucial criteria in determining the best missing data method. The other crucial criterion is whether or not the testing set is complete. The following two subsections describe in more detail these two criteria. 1.1 Different Types of Missing Data Generating Process Data originate according to the data generating process (DGP) under which the data matrix is “generated” according to the probabilistic relationships between the variables. We can think of the missingness itself as a random variable, realized as the matrix of the missingness indicator Im . Im is generated according to the missingness generating process (MGP), which governs the relationship between Im and the variables in the data matrix. Im has the same dimension as the original data matrix, with each entry equal to 0 if the corresponding original data value is observed and 1 if the corresponding original data value is not observed (missing). Note that an Im value not only can be related to its corresponding original data value, but can also be related to other variables of the same observation. Depending on the relationship between Im and the original data, Rubin (1976) and Little and Rubin (2002) categorize the missingness into three different types. If Im is dependent upon the missing values (the unobserved original data values), then the missingness pattern is called “not missing at random” (NMAR). Otherwise, the missingness pattern is called “missing at random” (MAR). As a special case of MAR, when the missingness is also not dependent on the observed values (that is, is independent of all data values), the missingness pattern is called “missing completely at random” (MCAR). The deﬁnition of MCAR is rather restrictive, which makes MCAR unlikely in reality. For example, in the bankruptcy data discussed later in the paper, there is evidence that after the Enron scandal in 2001, when both government and the public became more wary about ﬁnancial reporting misconduct, missingness of values in ﬁnancial statement data was related to the well-being of the company, and thus other values in the data. This makes intuitive sense because when scrutinized, a company is more likely to have trouble reporting their ﬁnancial data if there were problems. Thus, focusing on the MCAR case is a major limitation that will be avoided in this paper. In fact, this paper shows that the categorization of MCAR, MAR and NMAR itself is not appropriate for the missing data problem in classiﬁcation trees, as well as in another supervised learning context (at least with respect to prediction), although it has been shown to be helpful with likelihood-based or Bayesian analysis. 132 A N I NVESTIGATION OF M ISSING DATA M ETHODS FOR C LASSIFICATION T REES 1 2 3 4 5 6 7 8 Missingness is related to Missing Observed Response values Predictors Variable No No No No Yes No Yes No No Yes Yes No No No Yes No Yes Yes Yes No Yes Yes Yes Yes LR MCAR MAR NMAR NMAR MAR MAR NMAR NMAR Three-Letter −−− −X− M−− M X− −−Y −X Y M−Y MXY Table 1: Eight missingness patterns investigated in this study and their correspondence to the categorization MCAR, MAR and NMAR deﬁned by Rubin (1976) and Little and Rubin (2002) (the LR column). The column Three-Letter shows the notation that is used in this paper. In this paper, we investigate eight different missingness patterns, depending on the relationship between the missingness and three types of variables, the observed predictors, the unobserved predictors (the missing values) and the response variable. The relationship is conditional upon other factors, for example, missingness is not dependent upon the missing values means that the missingness is conditionally independent of the missing values given the observed predictors and/or the response variable. Table 1 shows their correspondence with the MCAR/MAR/NMAR categorization as well as the three-letter notation we use in this paper. The three letters indicate if the missingness is conditionally dependent on the missing values (M), on other predictors (X) and on the response variable (Y), respectively. As will be shown, the dependence of the missingness on the response variable (the letter Y) is the one that affects the choice of best missingness data method. Later in the paper, some derived notations are also used. For example, ∗X∗ means the union of −X−, −XY, MX− and MXY, that is, the missingness is dependent upon the observed predictors, and it may or may not be related to the missing values and/or the response variable. 1.2 Scenarios Where the Testing Data May or May Not Be Complete There are essentially two stages of applying classiﬁcation trees, the training phase where the historical data (training set) are used to construct the tree, and the testing phase where the tree is put into use and applied to testing data. Similar to most other studies, this study deals with the scenario where missing data occur in the training set, but the testing set may or may not have missing values. One basic assumption is, of course, that the DGP (as well as MGP if the testing set also contains missing values) is the same for both the training set and the testing set. While it would probably typically be the case that the testing data would also have missing values (generated by the same process that generated them in the training set), it should be noted that in certain circumstances a testing set without missing values could be expected. For example, consider a problem involving prediction of bankruptcy from various ﬁnancial ratios. If the training set comes from a publicly available database, there could be missing values corresponding to information that was not supplied by various companies. If the goal is to use these publicly available data to try 133 D ING AND S IMONOFF to predict bankruptcy from ratios from one’s own company, it would be expected that all of the necessary information for prediction would be available, and thus the test set would be complete. This study shows that when the missingness is dependent upon the response variable and the test set has missing values, separate class is the best missing data method to use. In other situations, the choice is not as clear, but some insights on effective choices are provided. The rest of paper provides detailed theoretical and empirical analysis and is organized as follows. Section 2 gives a brief introduction to the previous research on this topic. This is followed by discussion of the design of this study and ﬁndings in Section 3. The generality of the results are then tested on real data sets in Section 4. A brief extension of the results to logistic regression is presented in Section 5. We conclude with discussion of these results and future work in Section 6. 2. Previous Research There have been several studies of missing data and classiﬁcation trees in the literature. Liu, White, Thompson, and Bramer (1997) gave a general description of the problem, but did not discuss solutions. Saar-Tsechansky and Provost (2007) discussed various missing data methods in classiﬁcation trees and proposed a cost-sensitive approach to the missing data problem for the scenario when missing data occur only at the testing phase, which is different from the problem studied here (where missing values occur in the training phase). Kim and Yates (2003) conducted a simulation study of seven popular missing value methods but did not ﬁnd any dominant method. Feelders (1999) compared the performance of surrogate split and imputation and found the imputation methods to work better. (These methods, and the methods described below, are described more fully in the next section.) Batista and Monard (2003) compared four different missing data methods, and found that 10 nearest neighbor imputation outperformed other methods in most cases. In the context of cost sensitive classiﬁcation trees, Zhang, Qin, Ling, and Sheng (2005) studied four different missing data methods based on their performances on ﬁve data sets with artiﬁcially generated random missing values. They concluded that the internal node method (the decision rules for the observations with the next split variable missing will be made at the (internal) node) is better than the other three methods examined. Fujikawa and Ho (2002) compared several imputation methods based on preliminary clustering algorithms to probabilistic split on simulations based on several real data sets and found comparable performance. A weakness of all of the above studies is that they focused only on the restrictive MCAR situation. Other studies examined both MAR and NMAR missingness. Kalousis and Hilario (2000) used simulations from real data sets to examine the properties of seven algorithms: two rule inducers, a nearest neighbor method, two decision tree inducers, a naive Bayes inducer, and linear discriminant analysis. They found that the naive Bayes method was by far most resilient to missing data, in the sense that its properties changed the least when the missing rate was increased (note that this resilience is related to, but not the same as, its overall predictive performance). They also found that the deleterious effects of missing data are more serious if a given amount of missing values are spread over several variables, rather than concentrated in a few. Twala (2009) used computer simulations based on real data sets to compare the properties of different missing value methods, including using complete cases, single imputation of missing values, likelihood-based multiple imputation (where missing values are imputed several times, and the results of ﬁtting trees to the different generated data sets are combined), probabilistic split, and surrogate split. He studied MAR, MCAR, and NMAR missingness generating processes, although 134 A N I NVESTIGATION OF M ISSING DATA M ETHODS FOR C LASSIFICATION T REES dependence of missingness on the response variable was not examined. Multiple imputation was found to be most effective, with probabilistic split also performing reasonably well, although little difference was found between methods when the proportion of missing values was low. As would be expected, MCAR missingness caused the least problems for methods, while NMAR missingness caused the most, and as was also found by Kalousis and Hilario (2000), missingness spread over several predictors is more serious than if it is concentrated in only one. Twala, Jones, and Hand (2008) proposed a method closely related to creating a separate class for missing values, and found that its performance was competitive with that of likelihood-based multiple imputation. The study described in the next section extends these previous studies in several ways. First, theoretical analyses are provided for simple situations that help explain observed empirical performance. We then extend these analyses to more complex situations and data sets (including large ones) using Monte Carlo simulations based on generated and real data sets. The importance of whether missing is dependent on the response variable, which has been ignored in previous studies on classiﬁcation trees yet turns out to be of crucial importance, is a fundamental aspect of these results. The generality of the conclusions is ﬁnally tested using real data sets and application to logistic regression. 3. The Effectiveness of Missing Data Methods The recursive nature of classiﬁcation trees makes them almost impossible to analyze analytically in the general case beyond 2×2 tables (where there is only one binary predictor and a binary response variable). On the other hand, trees built on 2×2 tables, which can be thought of as “stumps” with a binary split, can be considered as degenerate classiﬁcation trees, with a classiﬁcation tree being built (recursively) as a hierarchy of these degenerate trees. Therefore, analyzing 2×2 tables can result in important insights for more general cases. We then build on the 2×2 analyses using Monte Carlo simulation, where factors that might have impact on performance are incrementally added, in order to see the effect of each factor. The factors include variation in both the data generating process (DGP) and the missing data generating process (MGP), the number and type of predictors in the data, the number of predictors that contain missing values, and the number of observations with missing data. This study examines six different missing data methods: probabilistic split, complete case method, grand mode/mean imputation, separate class, surrogate split, and complete variable method. Probabilistic split is the default method of C 4.5 (Quinlan, 1993). In the training phase, observations with values observed on the split variable are split ﬁrst. The ones with missing values are then put into each of the child nodes with a weight given as the proportion of non-missing instances in the child. In the testing phase, an observation with a missing value on a split variable will be associated with all of the children using probabilities, which are the weights recorded in the training phase. The complete case method deletes all observations that contain missing values in any of the predictors in the training phase. If the testing set also contains missing values, the complete case method is not applicable and thus some other method has to be used. In the simulations, we use C 4.5 to realize the complete case method. In the training phase, we manually delete all of the observations with missing values and then run C 4.5 on the pre-processed remaining complete data. In the testing phase, the default missing data method, probabilistic split, is used. Grand mode imputation imputes the missing value with the grand mode of that variable if it is categorical. Grand mean is used if the variable is continuous. The separate class method treats the missing values as a new class 135 D ING AND S IMONOFF (category) of the predictor. This is trivial to apply when the original variable is categorical, where we can create a new category called “missing”. To apply the separate class method to a numerical variable, we give all of the missing values a single extremely large value that is obviously outside of the original data range. This creates the needed separation between the nonmissing values and the missing values, implying that any split that involves the variable with missing values will put all of the missing observations into the same branch of the tree. Surrogate split is the default method of CART (realized using RPART in this study; Breiman et al. 1998 and Therneau and Atkinson 1997). It ﬁnds and uses a surrogate variable (or several surrogates in order) within a node if the variable for the next split contains missing values. In the testing phase, if a split variable contains missing values, the surrogate variables in the training phase are used instead. The complete variable method simply deletes all variables that contain missing values. Before we start presenting results, we deﬁne a performance measure that is appropriate for measuring the impact of missing data. Accuracy, calculated as the percentage of correctly classiﬁed observations, is often used to measure the performance of classiﬁcation trees. Since it can be affected by both the data structure (some data are intrinsically easier to classify than others) and by the missing data, this is not necessarily a good summary of the impact of missing data. In this study, we deﬁne a measure called relative accuracy (RelAcc), calculated as RelAcc = Accuracy with missing data . Accuracy with original full data This can be thought of as a standardized accuracy, as RelAcc measures the accuracy achievable with missing values relative to that achievable with the original full data. 3.1 Analytical Results In the following consistency theorems, the data are assumed to reﬂect the DGP exactly, and therefore the training set and the testing set are exactly the same. Several of the theorems are for 2×2 tables, and in those cases stopping and pruning rules are not relevant, since the only question is whether or not the one possible split is made. The proofs are thus dependent on the underlying parameters of the DGP and MGP, rather than on data randomly generated from them. It is important to recognize that these results are only designed to be illustrative of the results found in the much more realistic simulation analyses to follow. Proofs of all of the results are given in the appendix. Before presenting the theorems, we deﬁne some terms to avoid possible confusion. First, a partition of the data refers to the grouping of the observations deﬁned by the classiﬁcation tree’s splitting rules. Note that it is possible for two different trees on the same data set to deﬁne the same partition. For example, suppose that there are only two binary explanatory variables, X1 and X2 , and one tree splits on X1 then X2 while another tree splits on X2 then X1 . In this case, these two trees have different structures, but they can lead to the same partition of the data. Secondly, the set of rules deﬁned by a classiﬁcation tree consists of the rules deﬁned by the tree leaves on each of the groups (the partition) of the data. 3.1.1 W HEN THE T EST S ET IS F ULLY O BSERVED W ITH N O M ISSING VALUES We start with Theorems 1 to 3 that apply to the complete case method. Theorems 4 and 5 apply to probabilistic split and mode imputation, respectively. Proofs of the theorems can be found in the appendix. 136 A N I NVESTIGATION OF M ISSING DATA M ETHODS FOR C LASSIFICATION T REES Theorem 1 Complete Case Method: If the MGP is conditionally independent of Y given X, then the tree built on the data containing missing values using the complete case method gives the same set of rules as the tree built on the original full data set. Theorem 2 Complete Case Method: If the partition of the data deﬁned by the tree built on the incomplete data is not changed from the one deﬁned by the tree built on the original full data, the loss in accuracy when the testing set is complete is bounded above by PM , where PM is the missing rate, deﬁned as the percentage of observations that contain missing values. Theorem 3 Complete Case Method: If the partition of the data deﬁned by the tree built on the incomplete data is not changed from the one deﬁned by the tree built on the original full data, the relative accuracy when the testing set is complete is bounded below by RelAccmin = 1 − PM , 1 + PM where PM is the missing rate. Notice that the tree structure itself could change as long as it gives the same ﬁnal partition of the data. There are similar results in regression analyses as in Theorem 1. In regression analyses, when the missingness is independent of the response variable, by using only the complete observations, the parameter estimators are all unbiased (Allison, 2001). This implies that in theory, when the missingness is independent of the response variable, using complete cases only is not a bad approach on average. However, in practice, as will be seen later, deleting observations with missing values can cause severe loss in information, and thus has generally poor performance. Theorem 4 Probabilistic Split: In a 2×2 data table, if the MGP is independent of either Y or X, given the other variable, then the following results hold for probabilistic split. 1. If X is not informative in terms of classiﬁcation, that is, the majority classes of Y for different X values are the same, then probabilistic split will give the same rule as the one that would be obtained from the original full data; 2. If probabilistic split shows that X is informative in terms of classiﬁcation, that is, the majority classes of Y for different X values are different, then it ﬁnds the same rule as the one that would be obtained from the original full data; 3. The absolute accuracy when the testing set is complete is bounded below by 0.5. Since the original full data accuracy is at most 1, the relative accuracy is also bounded below by 0.5. Theorem 5 Mode Imputation: If the MGP is independent of Y , given X, then the same results hold for mode imputation as for probabilistic split under the conditions of Theorem 4. Theorems 1, 2 and 3 (for the complete case method) are true for general data sets. Theorems 4 and 5 are for 2×2 tables only but they imply that probabilistic split and mode imputation have advantages over the complete case method, which can have very poor performance (as will be shown in Figure 1). 137 D ING AND S IMONOFF Moreover, with 2×2 tables, the complete variable method will always have a higher than 0.5 accuracy since by ignoring the only predictor, we will always classify all of the data to the overall majority class and achieve at least 0.5 accuracy, and thus at least 0.5 relative accuracy. Together with Theorems 4 and 5, as well as the evidence to be shown in Figure 1, this is an indication that classiﬁcation trees tend not to be hurt much by missing values, since trees built on 2 × 2 tables can be considered as degenerate classiﬁcation trees and more complex trees are composites of these degenerate trees. The performance of a classiﬁcation tree is the average (weighted by the number of observations at each leaf) over the degenerate trees at the leaf level, and, as will be seen later in the simulations, can often be quite good. Surrogate split is not applicable to 2×2 tables because there are no other predictors. For 2×2 table problems with a complete testing set, separate class is essentially the same as the complete case method, because as long as the data are split according to the predictor (and it is very likely that this will be so), the separate class method builds separate rules for the observations with missing values; when the testing set is complete, the rules that are used in the testing phase are exactly the ones built on the complete observations. When there is more than one predictor, however, the creation of the “separate class” will save the observations with missing values from being deleted and affect the tree building process. It will very likely lead to a change in the tree structure. This, as will be seen, tends to have a favorable impact on the performance accuracy. Figure 1 illustrates the lower bound calculated in Theorem 3. The illustration is achieved by Monte Carlo simulation of 2×2 tables. A 2×2 table with missing values has only eight cells, that is, eight different value combinations of the binary variables X, Y and M, where M is the missingness indicator such that M = 0 if X is observed and M = 1 if X is missing. There is one constraint, that the sum of the eight cell probabilities must equal one. Therefore, this table is determined by seven parameters. In the simulation, for each 2 × 2 table, the following seven parameters (probabilities) are randomly and independently generated from a uniform distribution between (0, 1): (1)P(X = 1), (2)P(Y = 1|X = 0), (3)P(Y = 1|X = 1), (4)P(M = 1|X = 0,Y = 0), (5)P(M = 1|X = 0,Y = 1), (6)P(M = 1|X = 1,Y = 0) and (7)P(M = 1|X = 1,Y = 1). Here we assume the data tables reﬂect the true underlying DGP and MGP without random variation, and thus the expected performance of the classiﬁcation trees can be derived using the parameters. In this simulation, sets of the seven parameters are generated (but no data sets are generated using these parameters) repeatedly, and the relative accuracy of each missing data method on each parameter set is determined. One million sets of parameters are generated for each missingness pattern. In Figure 1, the plot on the left is a scatter plot of relative accuracy versus missing rate for each Monte Carlo replication for the complete case method when the MGP depends on the response variable. The lower bound is clearly shown. We can see that when the missing rate is high, the lower bound can reduce to almost zero (implying that not only relative accuracy, but accuracy itself, can approach zero). This perhaps somewhat counterintuitive result can occur in the following way. Imagine the extreme case where almost all cases are positive and (virtually) all of the positive cases have missing predictor value at the training phase; in this situation the resultant rule will be to classify everything as negative. When this rule is applied to a complete testing set with almost all positive cases, the accuracy will be almost zero. The graph on the right is the quantile version of the scatter plot on the left. The lines shown in the quantile plot are the theoretical lower bound, the 10th, 20th, 30th, 40th and 50th percentile lines from the lowest to the highest. Higher percentile lines are the same as the 50th percentile (median) line, which is already the horizontal line at RelAcc = 1. The percentile lines are constructed by connecting the corresponding percentiles in a moving window 138 A N I NVESTIGATION OF M ISSING DATA M ETHODS FOR C LASSIFICATION T REES Figure 1: Scatter plot and the corresponding quantile plot of the complete testing set RelAcc vs. missing rate of the complete case method when the MGP is dependent on the response variable. Recall that “∗ ∗ Y” means the MGP is conditionally dependent on the response variable but no restriction on the relationship between the MGP and other variables, missing or observed, is assumed. Each point in the scatter plot represents the result on one of the simulated data tables. of data from the left to the right. Due to space limitations, we do not show quantile plots of other missing data methods and/or under different scenarios, but in all of the other plots, the quantile lines are all higher (that is, the quantile plot in Figure 1 shows the worst case scenario). The plots show that the missing data problem, when the missing rate is not too high, may not be as serious as we might have thought. For example, when 40% of the observations contain missing data, 80% of the time the expected relative accuracy is higher than 90%, and 90% of the time the expected relative accuracy is higher than 80%. 3.1.2 W HEN THE T EST S ET H AS M ISSING VALUES Theorem 6 Separate Class: In 2×2 data tables, if missing values occur in both the training set and the testing set, then the separate class method achieves the best possible performance. In the Monte Carlo simulation of the 2 × 2 tables, the head-to-head comparison between the separate class method and other missing data methods conﬁrmed the uniform dominance of the separate class when the test set also contains missing values, regardless whether the MGP is dependent on the response variable or not. However, as shown in Figure 2, when the MGP is independent of the response variable, separate class never performances better than the performance on the original full data, indicated by relative accuracies less than one. This means that separate class is not gaining from the missingness. On the other hand, when the MGP is dependent on the response variable, a fairly large percentage of the time the relative accuracy of the separate class method is larger than one (the quantiles shown are from the 10th to the 90th percentile with increment 10 percent). This means that trees based on the separate class method can improve on predictive performance compared to the situation where there are no missing data. Our simulations show that other methods can also gain from the missingness when the MGP is dependent on the response variable, but not as frequently as the separate class method and the gains are in general not as large. We follow up on this behavior in more detail in the next section, but the simple explanation is that since missingness depends on the response variable, the tree algorithm can use the presence of missing data in an observation to improve prediction of the response for that observation. Duda, Hart, and Stork (2001) and Hand (1997) brieﬂy mentioned this possibility in the classiﬁcation context, but did not give any 139 D ING AND S IMONOFF Figure 2: Scatter plot of the separate class method with incomplete testing set. Each point in the scatter plot represents the result on one of the simulated data tables. supporting evidence. Theorem 6 makes a fairly strong statement in the simple situation, and it will be seen to be strongly indicative of the results in more general cases. 3.2 Monte Carlo Simulations of General Data Sets In this section extensions of the simulations in the last section are summarized. 3.2.1 A N OVERVIEW OF THE S IMULATION The following simulations are carried out. 1. 2×2 tables, missing values occur in the only predictor. 2. Up to seven binary predictors, missing values occur in only one predictor. 3. Eight binary predictors, missing values occur in two of them. 4. Twelve binary predictors, missing values occur in six of them. 5. Eight continuous predictors, missing values occur in two of them. 6. Twelve continuous predictors, missing values occur in six of them. Two different scenarios of each of the last four simulations listed above were performed. In the ﬁrst scenario, the six complete predictors are all independent of the missing ones, while in the second scenario three of the six complete predictors are related to the missing ones. Therefore, ten simulations were done in total. In each of the simulations, 5000 sets of DGPs are simulated in order to cover a wide range of different-structured data sets so that a generalizable inference from the simulation is possible. For 140 A N I NVESTIGATION OF M ISSING DATA M ETHODS FOR C LASSIFICATION T REES Density 0.6 0.7 0.8 0.9 0.0 1.0 2.0 3.0 Out−of−sample accuracy 0.0 1.0 2.0 3.0 Density In−sample accuracy 1.0 0.5 0.6 0.7 0.8 0.9 1.0 4 0 Density 8 Out−of−sample AUC 0 1 2 3 4 Out−of−sample accuracy In−sample AUC Density In−sample accuracy 0.5 0.6 0.7 0.8 0.9 1.0 0.5 In−sample AUC 0.6 0.7 0.8 0.9 Out−of−sample AUC Figure 3: A summary of the tree performance on the simulated original full data. each DGP, eight different MGPs are simulated to cover different types of missingness patterns. For each data set, the variables are generated sequentially in the order of the predictors, the response and the missingness. The probabilities associated with the binary response variable and the binary missingness variable are generated using conditional logit functions. The predictors may or may not be correlated with each other. Details about the simulations implementation can be found in Ding and Simonoff (2008). For each set of DGP/MGP, several different sample sizes are simulated to see any possible learning curve effect, since it was shown by Perlich, Provost, and Simonoff (2003) that sample size is an important factor in the effectiveness of classiﬁcation trees. Figure 3 shows the distribution of the tree performance on the simulated original full data, as measured by accuracy and area under the ROC curve (AUC). As we can see, there is broad coverage of the entire range of strength of the underlying relationship. Also, as expected, the out-of-sample performance (on the test set) is generally worse than the in-sample performance (on the training set). When the in-sample AUC is close to 0.5, a tree is likely to not split and as a result, any missing data method will not actually be applied, resulting in equivalent performance over all of them. To make the comparisons more meaningful, we exclude the cases where the in-sample AUC is below 0.7. Lower thresholds for exclusion (0.55 and 0.6) yield very similar results. Of the six missing data methods covered by this study, ﬁve of them, namely, complete case method, probabilistic split, separate class, imputation and complete variable method, are realized using C 4.5. These methods are always comparable. However, surrogate split is carried out using RPART , which makes it less comparable to the other methods because of differences between RPART and C 4.5 other than the missing data methods. To remedy this problem, we tuned the RPART parameters (primarily the parameter “cp”) so that it gives balanced results compared to C 4.5 when applied to the original full data (i.e., each has a similar probability of outperforming the other), and special attention is given when comparing RPART with other methods. The out-of-sample performances of each pair of missing data methods were compared based on both t-tests and nonparametric tests; each difference discussed in the following sections was strongly statistically signiﬁcant. 141 D ING AND S IMONOFF 100 P M D S T C D M C T S 500 2000 0 20 40 60 80 P P C D T S M − − Y Winning pct of each method 0 20 40 60 80 Winning pct of each method − − − 10000 P P P D C T S M 100 D C T M S 500 D M S T C 2000 M D S T C 500 2000 0 20 40 60 80 D C M T S P D C T S M P Winning pct of each method 0 20 40 60 80 − X Y P 100 10000 P P P D C T D 100 D M C S T C T M S M S 500 2000 D C T M S M D S T C 500 2000 0 20 40 60 80 P P Winning pct of each method 0 20 40 60 80 M − Y P D C T S M 10000 P P P D C T D 100 D C T M S M S 500 C S T M 2000 P P P D C T S M D C M T S 500 M D S T C 2000 10000 0 20 40 60 80 M X Y Winning pct of each method 0 20 40 60 80 10000 Sample size M X − Winning pct of each method Sample size 100 10000 Sample size M − − Winning pct of each method Sample size 100 10000 Sample size − X − Winning pct of each method Sample size P P P D C T 100 Sample size D C T S M M S 500 D C S M T 2000 10000 Sample size Figure 4: A summary of the order of six missing data methods when tested on a new complete testing set. The Y axis is the percentage of times each method is the best (including being tied with other methods; therefore the percentages do not sum up to one). 3.2.2 T HE T WO FACTORS THAT D ETERMINE DATA M ETHODS THE P ERFORMANCE OF D IFFERENT M ISSING The simulations make clear that the dependence relationship between the missingness and the response variable is the most informative factor in differentiating different missing data methods, and thus is most helpful in determining the appropriateness of the methods. This can be clearly seen in Figures 4 and 5 (these ﬁgures refer to the case with twelve continuous predictors, six of which are subject to missing values, but results for other situations were broadly similar). The left column in 142 A N I NVESTIGATION OF M ISSING DATA M ETHODS FOR C LASSIFICATION T REES 100 P M D T S C D T M C S 500 2000 0 20 40 60 80 P C P D T S M − − Y Winning pct of each method 0 20 40 60 80 Winning pct of each method − − − 10000 S S P D T C M S C P D T M 100 500 P M D T C 2000 P D T C M S 500 M D T S C 2000 0 20 40 60 80 P Winning pct of each method 0 20 40 60 80 − X Y P D C T S M 100 10000 S S S P D T C M C D P T M 100 500 P M D T C 2000 500 P M D S T C 2000 0 20 40 60 80 P D T C M S Winning pct of each method 0 20 40 60 80 M − Y P D C T S M 10000 S S S C P D T M 100 P D T C M 500 P T D M C 2000 P D T M C S D P C T S M 500 P M S D T C 2000 10000 0 20 40 60 80 M X Y Winning pct of each method 0 20 40 60 80 10000 Sample size M X − Winning pct of each method Sample size 100 10000 Sample size M − − Winning pct of each method Sample size 100 10000 Sample size − X − Winning pct of each method Sample size S S S C P D T M 100 Sample size P D T C M 500 P T D M C 2000 10000 Sample size Figure 5: A summary of the order of six missing data methods when tested on a new incomplete testing set. The Y axis is the percentage of times each method is the best (including being tied with other methods). the pictures shows the results when the missingness is independent of the response variable and the right column shows the results when the missingness is dependent on the response variable. We can see that there are clear differences between the two columns, but within each column there is essentially no difference. This also says the categorization of MCAR/MAR/NMAR (which is based upon the dependence relationship between the missingness and missing values, and does not distinguish the dependence of the missingness on other Xs and on Y ) is not helpful in this context. 143 D ING AND S IMONOFF Figure 6: Plot of the case-wise missing rate MR2 versus the value-wise missing rate MR1 in the simulations using the 36 real data sets. Comparison of the right columns of Figures 4 and 5 shows that whether or not there are missing values in the testing set is the second important criterion in differentiating between the methods. The separate class method is strongly dominant when the testing set contains missing values and the missingness is related to the response variable. The reason for this is that when missing data exist in both the training phase and the testing phase, they become part of the data and the MGP becomes an essential part of the DGP. This, of course, requires the assumption that the MGP (as well as the DGP) is the same in both the training phase and the testing phase. Under this scenario, if the missingness is related to the response variable, then there is information about the response variable in the missingness, which should be helpful when making predictions. Separate class, by taking the missingness directly as an “observed” variable, uses the information in the missingness about the response variable most effectively and thus is the best method to use. As a matter of fact, as can be seen in the bottom rows of Figures 7 and 8 (which give average relative accuracies separated by missing rate), the average relative accuracy of separate class under this situation is larger than one, indicating, on average, a better performance than with the original full data. On the other hand, when the missing data only occur in the training phase and the testing set does not have missing values, or when the missingness is not related to and carries no information about the response variable, the existence of missing values is a nuisance. Its only effect is to obscure the underlying DGP and thus would most likely reduce a tree’s performance. In this case, simulations show probabilistic split to be the dominantly best method. However, we don’t see this dominance later in results based on real data sets. More discussion of this point will follow in Section 4. 3.2.3 M ISSING R ATE E FFECT There are two ways of deﬁning the missing rate: the percentage of predictor values that are missing from the data set (the value-wise missing rate, termed here MR1 ), and the percentage of observations that contain missing values (the case-wise missing rate, termed here MR2 ). If there is only one predictor, as is the case with 2×2 tables, then the two deﬁnitions are the same. We have seen earlier in the theoretical analyses that the missing rate has a clear impact on the performance of the missing data methods. In the simulations, there is also evidence of a relationship between relative performance and missing rate, whichever deﬁnition is used to deﬁne the missing rate. 144 A N I NVESTIGATION OF M ISSING DATA M ETHODS FOR C LASSIFICATION T REES 100 500 2000 10000 100 500 2000 80 100 P T D M C 60 40 20 80 60 40 P D C T M 0 P D M C T Winning Pct of each method P D C T M C P D T M S S S P T C M D P T D C M 0 D C P T M S S S 20 60 40 20 S Winning pct of each method 80 S S 0 Winning pct of each method Winning pct / MGP: MXY / MR1>0.35 100 Winning Pct / MGP: MXY / 0.2 <0.3 100 Winning Pct / MGP: MXY / MR1<0.15 10000 100 500 T D P C M 2000 10000 Mean RelAcc / MGP: MXY / MR1<0.15 Mean RelAcc / MGP: MXY / 0.2</p><p>12 <a title="jmlr-2010-12" href="../jmlr2010/jmlr-2010-Analysis_of_Multi-stage_Convex_Relaxation_for_Sparse_Regularization.html">jmlr-2010-Analysis of Multi-stage Convex Relaxation for Sparse Regularization</a></p>
<p>Author: Tong Zhang</p><p>Abstract: We consider learning formulations with non-convex objective functions that often occur in practical applications. There are two approaches to this problem: • Heuristic methods such as gradient descent that only ﬁnd a local minimum. A drawback of this approach is the lack of theoretical guarantee showing that the local minimum gives a good solution. • Convex relaxation such as L1 -regularization that solves the problem under some conditions. However it often leads to a sub-optimal solution in reality. This paper tries to remedy the above gap between theory and practice. In particular, we present a multi-stage convex relaxation scheme for solving problems with non-convex objective functions. For learning formulations with sparse regularization, we analyze the behavior of a speciﬁc multistage relaxation scheme. Under appropriate conditions, we show that the local solution obtained by this procedure is superior to the global solution of the standard L1 convex relaxation for learning sparse targets. Keywords: sparsity, non-convex optimization, convex relaxation, multi-stage convex relaxation</p><p>13 <a title="jmlr-2010-13" href="../jmlr2010/jmlr-2010-Approximate_Inference_on_Planar_Graphs_using_Loop_Calculus_and_Belief_Propagation.html">jmlr-2010-Approximate Inference on Planar Graphs using Loop Calculus and Belief Propagation</a></p>
<p>Author: Vicenç Gómez, Hilbert J. Kappen, Michael Chertkov</p><p>Abstract: We introduce novel results for approximate inference on planar graphical models using the loop calculus framework. The loop calculus (Chertkov and Chernyak, 2006a) allows to express the exact partition function of a graphical model as a ﬁnite sum of terms that can be evaluated once the belief propagation (BP) solution is known. In general, full summation over all correction terms is intractable. We develop an algorithm for the approach presented in Chertkov et al. (2008) which represents an efﬁcient truncation scheme on planar graphs and a new representation of the series in terms of Pfafﬁans of matrices. We analyze the performance of the algorithm for models with binary variables and pairwise interactions on grids and other planar graphs. We study in detail both the loop series and the equivalent Pfafﬁan series and show that the ﬁrst term of the Pfafﬁan series for the general, intractable planar model, can provide very accurate approximations. The algorithm outperforms previous truncation schemes of the loop series and is competitive with other state of the art methods for approximate inference. Keywords: belief propagation, loop calculus, approximate inference, partition function, planar graphs, Ising model</p><p>14 <a title="jmlr-2010-14" href="../jmlr2010/jmlr-2010-Approximate_Riemannian_Conjugate_Gradient_Learning_for_Fixed-Form_Variational_Bayes.html">jmlr-2010-Approximate Riemannian Conjugate Gradient Learning for Fixed-Form Variational Bayes</a></p>
<p>Author: Antti Honkela, Tapani Raiko, Mikael Kuusela, Matti Tornio, Juha Karhunen</p><p>Abstract: Variational Bayesian (VB) methods are typically only applied to models in the conjugate-exponential family using the variational Bayesian expectation maximisation (VB EM) algorithm or one of its variants. In this paper we present an efﬁcient algorithm for applying VB to more general models. The method is based on specifying the functional form of the approximation, such as multivariate Gaussian. The parameters of the approximation are optimised using a conjugate gradient algorithm that utilises the Riemannian geometry of the space of the approximations. This leads to a very efﬁcient algorithm for suitably structured approximations. It is shown empirically that the proposed method is comparable or superior in efﬁciency to the VB EM in a case where both are applicable. We also apply the algorithm to learning a nonlinear state-space model and a nonlinear factor analysis model for which the VB EM is not applicable. For these models, the proposed algorithm outperforms alternative gradient-based methods by a signiﬁcant margin. Keywords: variational inference, approximate Riemannian conjugate gradient, ﬁxed-form approximation, Gaussian approximation</p><p>15 <a title="jmlr-2010-15" href="../jmlr2010/jmlr-2010-Approximate_Tree_Kernels.html">jmlr-2010-Approximate Tree Kernels</a></p>
<p>Author: Konrad Rieck, Tammo Krueger, Ulf Brefeld, Klaus-Robert Müller</p><p>Abstract: Convolution kernels for trees provide simple means for learning with tree-structured data. The computation time of tree kernels is quadratic in the size of the trees, since all pairs of nodes need to be compared. Thus, large parse trees, obtained from HTML documents or structured network data, render convolution kernels inapplicable. In this article, we propose an effective approximation technique for parse tree kernels. The approximate tree kernels (ATKs) limit kernel computation to a sparse subset of relevant subtrees and discard redundant structures, such that training and testing of kernel-based learning methods are signiﬁcantly accelerated. We devise linear programming approaches for identifying such subsets for supervised and unsupervised learning tasks, respectively. Empirically, the approximate tree kernels attain run-time improvements up to three orders of magnitude while preserving the predictive accuracy of regular tree kernels. For unsupervised tasks, the approximate tree kernels even lead to more accurate predictions by identifying relevant dimensions in feature space. Keywords: tree kernels, approximation, kernel methods, convolution kernels</p><p>16 <a title="jmlr-2010-16" href="../jmlr2010/jmlr-2010-Asymptotic_Equivalence_of_Bayes_Cross_Validation_and_Widely_Applicable_Information_Criterion_in_Singular_Learning_Theory.html">jmlr-2010-Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory</a></p>
<p>Author: Sumio Watanabe</p><p>Abstract: In regular statistical models, the leave-one-out cross-validation is asymptotically equivalent to the Akaike information criterion. However, since many learning machines are singular statistical models, the asymptotic behavior of the cross-validation remains unknown. In previous studies, we established the singular learning theory and proposed a widely applicable information criterion, the expectation value of which is asymptotically equal to the average Bayes generalization loss. In the present paper, we theoretically compare the Bayes cross-validation loss and the widely applicable information criterion and prove two theorems. First, the Bayes cross-validation loss is asymptotically equivalent to the widely applicable information criterion as a random variable. Therefore, model selection and hyperparameter optimization using these two values are asymptotically equivalent. Second, the sum of the Bayes generalization error and the Bayes cross-validation error is asymptotically equal to 2λ/n, where λ is the real log canonical threshold and n is the number of training samples. Therefore the relation between the cross-validation error and the generalization error is determined by the algebraic geometrical structure of a learning machine. We also clarify that the deviance information criteria are different from the Bayes cross-validation and the widely applicable information criterion. Keywords: cross-validation, information criterion, singular learning machine, birational invariant</p><p>17 <a title="jmlr-2010-17" href="../jmlr2010/jmlr-2010-Bayesian_Learning_in_Sparse_Graphical_Factor_Models_via_Variational_Mean-Field_Annealing.html">jmlr-2010-Bayesian Learning in Sparse Graphical Factor Models via Variational Mean-Field Annealing</a></p>
<p>Author: Ryo Yoshida, Mike West</p><p>Abstract: We describe a class of sparse latent factor models, called graphical factor models (GFMs), and relevant sparse learning algorithms for posterior mode estimation. Linear, Gaussian GFMs have sparse, orthogonal factor loadings matrices, that, in addition to sparsity of the implied covariance matrices, also induce conditional independence structures via zeros in the implied precision matrices. We describe the models and their use for robust estimation of sparse latent factor structure and data/signal reconstruction. We develop computational algorithms for model exploration and posterior mode search, addressing the hard combinatorial optimization involved in the search over a huge space of potential sparse conﬁgurations. A mean-ﬁeld variational technique coupled with annealing is developed to successively generate “artiﬁcial” posterior distributions that, at the limiting temperature in the annealing schedule, deﬁne required posterior modes in the GFM parameter space. Several detailed empirical studies and comparisons to related approaches are discussed, including analyses of handwritten digit image and cancer gene expression data. Keywords: annealing, graphical factor models, variational mean-ﬁeld method, MAP estimation, sparse factor analysis, gene expression proﬁling</p><p>18 <a title="jmlr-2010-18" href="../jmlr2010/jmlr-2010-Bundle_Methods_for_Regularized_Risk_Minimization.html">jmlr-2010-Bundle Methods for Regularized Risk Minimization</a></p>
<p>Author: Choon Hui Teo, S.V.N. Vishwanthan, Alex J. Smola, Quoc V. Le</p><p>Abstract: A wide variety of machine learning problems can be described as minimizing a regularized risk functional, with different algorithms using different notions of risk and different regularizers. Examples include linear Support Vector Machines (SVMs), Gaussian Processes, Logistic Regression, Conditional Random Fields (CRFs), and Lasso amongst others. This paper describes the theory and implementation of a scalable and modular convex solver which solves all these estimation problems. It can be parallelized on a cluster of workstations, allows for data-locality, and can deal with regularizers such as L1 and L2 penalties. In addition to the uniﬁed framework we present tight convergence bounds, which show that our algorithm converges in O(1/ε) steps to ε precision for general convex problems and in O(log(1/ε)) steps for continuously differentiable problems. We demonstrate the performance of our general purpose solver on a variety of publicly available data sets. Keywords: optimization, subgradient methods, cutting plane method, bundle methods, regularized risk minimization, parallel optimization ∗. Also at Canberra Research Laboratory, NICTA. c 2010 Choon Hui Teo, S.V. N. Vishwanthan, Alex J. Smola and Quoc V. Le. T EO , V ISHWANATHAN , S MOLA AND L E</p><p>19 <a title="jmlr-2010-19" href="../jmlr2010/jmlr-2010-Characterization%2C_Stability_and_Convergence_of_Hierarchical_Clustering_Methods.html">jmlr-2010-Characterization, Stability and Convergence of Hierarchical Clustering Methods</a></p>
<p>Author: Gunnar Carlsson, Facundo Mémoli</p><p>Abstract: We study hierarchical clustering schemes under an axiomatic view. We show that within this framework, one can prove a theorem analogous to one of Kleinberg (2002), in which one obtains an existence and uniqueness theorem instead of a non-existence result. We explore further properties of this unique scheme: stability and convergence are established. We represent dendrograms as ultrametric spaces and use tools from metric geometry, namely the Gromov-Hausdorff distance, to quantify the degree to which perturbations in the input metric space affect the result of hierarchical methods. Keywords: clustering, hierarchical clustering, stability of clustering, Gromov-Hausdorff distance</p><p>20 <a title="jmlr-2010-20" href="../jmlr2010/jmlr-2010-Chromatic_PAC-Bayes_Bounds_for_Non-IID_Data%3A_Applications_to_Ranking_and_Stationary_%CE%B2-Mixing_Processes.html">jmlr-2010-Chromatic PAC-Bayes Bounds for Non-IID Data: Applications to Ranking and Stationary β-Mixing Processes</a></p>
<p>Author: Liva Ralaivola, Marie Szafranski, Guillaume Stempfel</p><p>Abstract: PAC-Bayes bounds are among the most accurate generalization bounds for classiﬁers learned from independently and identically distributed (IID) data, and it is particularly so for margin classiﬁers: there have been recent contributions showing how practical these bounds can be either to perform model selection (Ambroladze et al., 2007) or even to directly guide the learning of linear classiﬁers (Germain et al., 2009). However, there are many practical situations where the training data show some dependencies and where the traditional IID assumption does not hold. Stating generalization bounds for such frameworks is therefore of the utmost interest, both from theoretical and practical standpoints. In this work, we propose the ﬁrst—to the best of our knowledge—PAC-Bayes generalization bounds for classiﬁers trained on data exhibiting interdependencies. The approach undertaken to establish our results is based on the decomposition of a so-called dependency graph that encodes the dependencies within the data, in sets of independent data, thanks to graph fractional covers. Our bounds are very general, since being able to ﬁnd an upper bound on the fractional chromatic number of the dependency graph is sufﬁcient to get new PAC-Bayes bounds for speciﬁc settings. We show how our results can be used to derive bounds for ranking statistics (such as AUC) and classiﬁers trained on data distributed according to a stationary β-mixing process. In the way, we show how our approach seamlessly allows us to deal with U-processes. As a side note, we also provide a PAC-Bayes generalization bound for classiﬁers learned on data from stationary ϕ-mixing distributions. Keywords: PAC-Bayes bounds, non IID data, ranking, U-statistics, mixing processes c 2010 Liva Ralaivola, Marie Szafranski and Guillaume Stempfel. R ALAIVOLA , S ZAFRANSKI AND S TEMPFEL</p><p>21 <a title="jmlr-2010-21" href="../jmlr2010/jmlr-2010-Classification_Methods_with_Reject_Option_Based_on_Convex_Risk_Minimization.html">jmlr-2010-Classification Methods with Reject Option Based on Convex Risk Minimization</a></p>
<p>22 <a title="jmlr-2010-22" href="../jmlr2010/jmlr-2010-Classification_Using_Geometric_Level_Sets.html">jmlr-2010-Classification Using Geometric Level Sets</a></p>
<p>23 <a title="jmlr-2010-23" href="../jmlr2010/jmlr-2010-Classification_with_Incomplete_Data_Using_Dirichlet_Process_Priors.html">jmlr-2010-Classification with Incomplete Data Using Dirichlet Process Priors</a></p>
<p>24 <a title="jmlr-2010-24" href="../jmlr2010/jmlr-2010-Collective_Inference_for__Extraction_MRFs_Coupled_with_Symmetric_Clique_Potentials.html">jmlr-2010-Collective Inference for  Extraction MRFs Coupled with Symmetric Clique Potentials</a></p>
<p>25 <a title="jmlr-2010-25" href="../jmlr2010/jmlr-2010-Composite_Binary_Losses.html">jmlr-2010-Composite Binary Losses</a></p>
<p>26 <a title="jmlr-2010-26" href="../jmlr2010/jmlr-2010-Consensus-Based_Distributed_Support_Vector_Machines.html">jmlr-2010-Consensus-Based Distributed Support Vector Machines</a></p>
<p>27 <a title="jmlr-2010-27" href="../jmlr2010/jmlr-2010-Consistent_Nonparametric_Tests_of_Independence.html">jmlr-2010-Consistent Nonparametric Tests of Independence</a></p>
<p>28 <a title="jmlr-2010-28" href="../jmlr2010/jmlr-2010-Continuous_Time_Bayesian_Network_Reasoning_and_Learning_Engine.html">jmlr-2010-Continuous Time Bayesian Network Reasoning and Learning Engine</a></p>
<p>29 <a title="jmlr-2010-29" href="../jmlr2010/jmlr-2010-Covariance_in_Unsupervised_Learning_of_Probabilistic_Grammars.html">jmlr-2010-Covariance in Unsupervised Learning of Probabilistic Grammars</a></p>
<p>30 <a title="jmlr-2010-30" href="../jmlr2010/jmlr-2010-Dimensionality_Estimation%2C_Manifold_Learning_and_Function_Approximation_using_Tensor_Voting.html">jmlr-2010-Dimensionality Estimation, Manifold Learning and Function Approximation using Tensor Voting</a></p>
<p>31 <a title="jmlr-2010-31" href="../jmlr2010/jmlr-2010-Dual_Averaging_Methods_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">jmlr-2010-Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</a></p>
<p>32 <a title="jmlr-2010-32" href="../jmlr2010/jmlr-2010-Efficient_Algorithms_for_Conditional_Independence_Inference.html">jmlr-2010-Efficient Algorithms for Conditional Independence Inference</a></p>
<p>33 <a title="jmlr-2010-33" href="../jmlr2010/jmlr-2010-Efficient_Heuristics_for_Discriminative_Structure_Learning_of_Bayesian_Network_Classifiers.html">jmlr-2010-Efficient Heuristics for Discriminative Structure Learning of Bayesian Network Classifiers</a></p>
<p>34 <a title="jmlr-2010-34" href="../jmlr2010/jmlr-2010-Erratum%3A_SGDQN_is_Less_Careful_than_Expected.html">jmlr-2010-Erratum: SGDQN is Less Careful than Expected</a></p>
<p>35 <a title="jmlr-2010-35" href="../jmlr2010/jmlr-2010-Error-Correcting_Output_Codes_Library.html">jmlr-2010-Error-Correcting Output Codes Library</a></p>
<p>36 <a title="jmlr-2010-36" href="../jmlr2010/jmlr-2010-Estimation_of_a_Structural_Vector_Autoregression_Model_Using_Non-Gaussianity.html">jmlr-2010-Estimation of a Structural Vector Autoregression Model Using Non-Gaussianity</a></p>
<p>37 <a title="jmlr-2010-37" href="../jmlr2010/jmlr-2010-Evolving_Static_Representations_for_Task_Transfer.html">jmlr-2010-Evolving Static Representations for Task Transfer</a></p>
<p>38 <a title="jmlr-2010-38" href="../jmlr2010/jmlr-2010-Expectation_Truncation_and_the_Benefits_of_Preselection_In_Training_Generative_Models.html">jmlr-2010-Expectation Truncation and the Benefits of Preselection In Training Generative Models</a></p>
<p>39 <a title="jmlr-2010-39" href="../jmlr2010/jmlr-2010-FastInf%3A_An_Efficient_Approximate_Inference_Library.html">jmlr-2010-FastInf: An Efficient Approximate Inference Library</a></p>
<p>40 <a title="jmlr-2010-40" href="../jmlr2010/jmlr-2010-Fast_and_Scalable_Local_Kernel_Machines.html">jmlr-2010-Fast and Scalable Local Kernel Machines</a></p>
<p>41 <a title="jmlr-2010-41" href="../jmlr2010/jmlr-2010-Gaussian_Processes_for_Machine_Learning_%28GPML%29_Toolbox.html">jmlr-2010-Gaussian Processes for Machine Learning (GPML) Toolbox</a></p>
<p>42 <a title="jmlr-2010-42" href="../jmlr2010/jmlr-2010-Generalized_Expectation_Criteria_for_Semi-Supervised_Learning_with_Weakly_Labeled_Data.html">jmlr-2010-Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</a></p>
<p>43 <a title="jmlr-2010-43" href="../jmlr2010/jmlr-2010-Generalized_Power_Method_for_Sparse_Principal_Component_Analysis.html">jmlr-2010-Generalized Power Method for Sparse Principal Component Analysis</a></p>
<p>44 <a title="jmlr-2010-44" href="../jmlr2010/jmlr-2010-Graph_Kernels.html">jmlr-2010-Graph Kernels</a></p>
<p>45 <a title="jmlr-2010-45" href="../jmlr2010/jmlr-2010-High-dimensional_Variable_Selection_with_Sparse_Random_Projections%3A_Measurement_Sparsity_and_Statistical_Efficiency.html">jmlr-2010-High-dimensional Variable Selection with Sparse Random Projections: Measurement Sparsity and Statistical Efficiency</a></p>
<p>46 <a title="jmlr-2010-46" href="../jmlr2010/jmlr-2010-High_Dimensional_Inverse_Covariance_Matrix_Estimation_via_Linear_Programming.html">jmlr-2010-High Dimensional Inverse Covariance Matrix Estimation via Linear Programming</a></p>
<p>47 <a title="jmlr-2010-47" href="../jmlr2010/jmlr-2010-Hilbert_Space_Embeddings_and_Metrics_on_Probability_Measures.html">jmlr-2010-Hilbert Space Embeddings and Metrics on Probability Measures</a></p>
<p>48 <a title="jmlr-2010-48" href="../jmlr2010/jmlr-2010-How_to_Explain_Individual_Classification_Decisions.html">jmlr-2010-How to Explain Individual Classification Decisions</a></p>
<p>49 <a title="jmlr-2010-49" href="../jmlr2010/jmlr-2010-Hubs_in_Space%3A_Popular_Nearest_Neighbors_in_High-Dimensional_Data.html">jmlr-2010-Hubs in Space: Popular Nearest Neighbors in High-Dimensional Data</a></p>
<p>50 <a title="jmlr-2010-50" href="../jmlr2010/jmlr-2010-Image_Denoising_with_Kernels_Based_on_Natural_Image_Relations.html">jmlr-2010-Image Denoising with Kernels Based on Natural Image Relations</a></p>
<p>51 <a title="jmlr-2010-51" href="../jmlr2010/jmlr-2010-Importance_Sampling_for_Continuous_Time_Bayesian_Networks.html">jmlr-2010-Importance Sampling for Continuous Time Bayesian Networks</a></p>
<p>52 <a title="jmlr-2010-52" href="../jmlr2010/jmlr-2010-Incremental_Sigmoid_Belief_Networks_for_Grammar_Learning.html">jmlr-2010-Incremental Sigmoid Belief Networks for Grammar Learning</a></p>
<p>53 <a title="jmlr-2010-53" href="../jmlr2010/jmlr-2010-Inducing_Tree-Substitution_Grammars.html">jmlr-2010-Inducing Tree-Substitution Grammars</a></p>
<p>54 <a title="jmlr-2010-54" href="../jmlr2010/jmlr-2010-Information_Retrieval_Perspective_to_Nonlinear_Dimensionality_Reduction_for_Data_Visualization.html">jmlr-2010-Information Retrieval Perspective to Nonlinear Dimensionality Reduction for Data Visualization</a></p>
<p>55 <a title="jmlr-2010-55" href="../jmlr2010/jmlr-2010-Information_Theoretic_Measures_for_Clusterings_Comparison%3A_Variants%2C_Properties%2C_Normalization_and_Correction_for_Chance.html">jmlr-2010-Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance</a></p>
<p>56 <a title="jmlr-2010-56" href="../jmlr2010/jmlr-2010-Introduction_to_Causal_Inference.html">jmlr-2010-Introduction to Causal Inference</a></p>
<p>57 <a title="jmlr-2010-57" href="../jmlr2010/jmlr-2010-Iterative_Scaling_and_Coordinate_Descent_Methods_for_Maximum_Entropy_Models.html">jmlr-2010-Iterative Scaling and Coordinate Descent Methods for Maximum Entropy Models</a></p>
<p>58 <a title="jmlr-2010-58" href="../jmlr2010/jmlr-2010-Kronecker_Graphs%3A_An_Approach_to_Modeling_Networks.html">jmlr-2010-Kronecker Graphs: An Approach to Modeling Networks</a></p>
<p>59 <a title="jmlr-2010-59" href="../jmlr2010/jmlr-2010-Large_Scale_Online_Learning_of_Image_Similarity_Through_Ranking.html">jmlr-2010-Large Scale Online Learning of Image Similarity Through Ranking</a></p>
<p>60 <a title="jmlr-2010-60" href="../jmlr2010/jmlr-2010-Learnability%2C_Stability_and_Uniform_Convergence.html">jmlr-2010-Learnability, Stability and Uniform Convergence</a></p>
<p>61 <a title="jmlr-2010-61" href="../jmlr2010/jmlr-2010-Learning_From_Crowds.html">jmlr-2010-Learning From Crowds</a></p>
<p>62 <a title="jmlr-2010-62" href="../jmlr2010/jmlr-2010-Learning_Gradients%3A_Predictive_Models_that_Infer_Geometry_and_Statistical_Dependence.html">jmlr-2010-Learning Gradients: Predictive Models that Infer Geometry and Statistical Dependence</a></p>
<p>63 <a title="jmlr-2010-63" href="../jmlr2010/jmlr-2010-Learning_Instance-Specific_Predictive_Models.html">jmlr-2010-Learning Instance-Specific Predictive Models</a></p>
<p>64 <a title="jmlr-2010-64" href="../jmlr2010/jmlr-2010-Learning_Non-Stationary_Dynamic_Bayesian_Networks.html">jmlr-2010-Learning Non-Stationary Dynamic Bayesian Networks</a></p>
<p>65 <a title="jmlr-2010-65" href="../jmlr2010/jmlr-2010-Learning_Translation_Invariant_Kernels_for_Classification.html">jmlr-2010-Learning Translation Invariant Kernels for Classification</a></p>
<p>66 <a title="jmlr-2010-66" href="../jmlr2010/jmlr-2010-Linear_Algorithms_for_Online_Multitask_Classification.html">jmlr-2010-Linear Algorithms for Online Multitask Classification</a></p>
<p>67 <a title="jmlr-2010-67" href="../jmlr2010/jmlr-2010-Local_Causal_and_Markov_Blanket_Induction_for_Causal_Discovery_and_Feature_Selection_for_Classification_Part_I%3A_Algorithms_and_Empirical_Evaluation.html">jmlr-2010-Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part I: Algorithms and Empirical Evaluation</a></p>
<p>68 <a title="jmlr-2010-68" href="../jmlr2010/jmlr-2010-Local_Causal_and_Markov_Blanket_Induction_for_Causal_Discovery_and_Feature_Selection_for_Classification_Part_II%3A_Analysis_and_Extensions.html">jmlr-2010-Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part II: Analysis and Extensions</a></p>
<p>69 <a title="jmlr-2010-69" href="../jmlr2010/jmlr-2010-Lp-Nested_Symmetric_Distributions.html">jmlr-2010-Lp-Nested Symmetric Distributions</a></p>
<p>70 <a title="jmlr-2010-70" href="../jmlr2010/jmlr-2010-MOA%3A_Massive_Online_Analysis.html">jmlr-2010-MOA: Massive Online Analysis</a></p>
<p>71 <a title="jmlr-2010-71" href="../jmlr2010/jmlr-2010-Matched_Gene_Selection_and_Committee_Classifier_for_Molecular_Classification_of_Heterogeneous_Diseases.html">jmlr-2010-Matched Gene Selection and Committee Classifier for Molecular Classification of Heterogeneous Diseases</a></p>
<p>72 <a title="jmlr-2010-72" href="../jmlr2010/jmlr-2010-Matrix_Completion_from__Noisy_Entries.html">jmlr-2010-Matrix Completion from  Noisy Entries</a></p>
<p>73 <a title="jmlr-2010-73" href="../jmlr2010/jmlr-2010-Maximum_Likelihood_in_Cost-Sensitive_Learning%3A_Model_Specification%2C_Approximations%2C_and_Upper_Bounds.html">jmlr-2010-Maximum Likelihood in Cost-Sensitive Learning: Model Specification, Approximations, and Upper Bounds</a></p>
<p>74 <a title="jmlr-2010-74" href="../jmlr2010/jmlr-2010-Maximum_Relative_Margin_and_Data-Dependent_Regularization.html">jmlr-2010-Maximum Relative Margin and Data-Dependent Regularization</a></p>
<p>75 <a title="jmlr-2010-75" href="../jmlr2010/jmlr-2010-Mean_Field_Variational_Approximation_for_Continuous-Time_Bayesian_Networks.html">jmlr-2010-Mean Field Variational Approximation for Continuous-Time Bayesian Networks</a></p>
<p>76 <a title="jmlr-2010-76" href="../jmlr2010/jmlr-2010-Message-passing_for_Graph-structured_Linear_Programs%3A_Proximal_Methods_and_Rounding_Schemes.html">jmlr-2010-Message-passing for Graph-structured Linear Programs: Proximal Methods and Rounding Schemes</a></p>
<p>77 <a title="jmlr-2010-77" href="../jmlr2010/jmlr-2010-Model-based_Boosting_2.0.html">jmlr-2010-Model-based Boosting 2.0</a></p>
<p>78 <a title="jmlr-2010-78" href="../jmlr2010/jmlr-2010-Model_Selection%3A_Beyond_the_Bayesian_Frequentist_Divide.html">jmlr-2010-Model Selection: Beyond the Bayesian Frequentist Divide</a></p>
<p>79 <a title="jmlr-2010-79" href="../jmlr2010/jmlr-2010-Near-optimal_Regret_Bounds_for_Reinforcement_Learning.html">jmlr-2010-Near-optimal Regret Bounds for Reinforcement Learning</a></p>
<p>80 <a title="jmlr-2010-80" href="../jmlr2010/jmlr-2010-On-Line_Sequential_Bin_Packing.html">jmlr-2010-On-Line Sequential Bin Packing</a></p>
<p>81 <a title="jmlr-2010-81" href="../jmlr2010/jmlr-2010-On_Finding_Predictors_for_Arbitrary_Families_of_Processes.html">jmlr-2010-On Finding Predictors for Arbitrary Families of Processes</a></p>
<p>82 <a title="jmlr-2010-82" href="../jmlr2010/jmlr-2010-On_Learning_with_Integral_Operators.html">jmlr-2010-On Learning with Integral Operators</a></p>
<p>83 <a title="jmlr-2010-83" href="../jmlr2010/jmlr-2010-On_Over-fitting_in_Model_Selection_and_Subsequent_Selection_Bias_in_Performance_Evaluation.html">jmlr-2010-On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation</a></p>
<p>84 <a title="jmlr-2010-84" href="../jmlr2010/jmlr-2010-On_Spectral_Learning.html">jmlr-2010-On Spectral Learning</a></p>
<p>85 <a title="jmlr-2010-85" href="../jmlr2010/jmlr-2010-On_the_Foundations_of_Noise-free_Selective_Classification.html">jmlr-2010-On the Foundations of Noise-free Selective Classification</a></p>
<p>86 <a title="jmlr-2010-86" href="../jmlr2010/jmlr-2010-On_the_Rate_of_Convergence_of_the_Bagged_Nearest_Neighbor_Estimate.html">jmlr-2010-On the Rate of Convergence of the Bagged Nearest Neighbor Estimate</a></p>
<p>87 <a title="jmlr-2010-87" href="../jmlr2010/jmlr-2010-Online_Learning_for_Matrix_Factorization_and_Sparse_Coding.html">jmlr-2010-Online Learning for Matrix Factorization and Sparse Coding</a></p>
<p>88 <a title="jmlr-2010-88" href="../jmlr2010/jmlr-2010-Optimal_Search_on_Clustered_Structural_Constraint_for_Learning_Bayesian_Network_Structure.html">jmlr-2010-Optimal Search on Clustered Structural Constraint for Learning Bayesian Network Structure</a></p>
<p>89 <a title="jmlr-2010-89" href="../jmlr2010/jmlr-2010-PAC-Bayesian_Analysis_of_Co-clustering_and_Beyond.html">jmlr-2010-PAC-Bayesian Analysis of Co-clustering and Beyond</a></p>
<p>90 <a title="jmlr-2010-90" href="../jmlr2010/jmlr-2010-Permutation_Tests_for_Studying_Classifier_Performance.html">jmlr-2010-Permutation Tests for Studying Classifier Performance</a></p>
<p>91 <a title="jmlr-2010-91" href="../jmlr2010/jmlr-2010-Posterior_Regularization_for_Structured_Latent_Variable_Models.html">jmlr-2010-Posterior Regularization for Structured Latent Variable Models</a></p>
<p>92 <a title="jmlr-2010-92" href="../jmlr2010/jmlr-2010-Practical_Approaches_to_Principal_Component_Analysis_in_the_Presence_of_Missing_Values.html">jmlr-2010-Practical Approaches to Principal Component Analysis in the Presence of Missing Values</a></p>
<p>93 <a title="jmlr-2010-93" href="../jmlr2010/jmlr-2010-PyBrain.html">jmlr-2010-PyBrain</a></p>
<p>94 <a title="jmlr-2010-94" href="../jmlr2010/jmlr-2010-Quadratic_Programming_Feature_Selection.html">jmlr-2010-Quadratic Programming Feature Selection</a></p>
<p>95 <a title="jmlr-2010-95" href="../jmlr2010/jmlr-2010-Rademacher_Complexities_and_Bounding_the_Excess_Risk_in_Active_Learning.html">jmlr-2010-Rademacher Complexities and Bounding the Excess Risk in Active Learning</a></p>
<p>96 <a title="jmlr-2010-96" href="../jmlr2010/jmlr-2010-Rate_Minimaxity_of_the_Lasso_and_Dantzig_Selector_for_thelqLoss_inlrBalls.html">jmlr-2010-Rate Minimaxity of the Lasso and Dantzig Selector for thelqLoss inlrBalls</a></p>
<p>97 <a title="jmlr-2010-97" href="../jmlr2010/jmlr-2010-Regret_Bounds_and_Minimax_Policies_under_Partial_Monitoring.html">jmlr-2010-Regret Bounds and Minimax Policies under Partial Monitoring</a></p>
<p>98 <a title="jmlr-2010-98" href="../jmlr2010/jmlr-2010-Regularized_Discriminant_Analysis%2C_Ridge_Regression_and_Beyond.html">jmlr-2010-Regularized Discriminant Analysis, Ridge Regression and Beyond</a></p>
<p>99 <a title="jmlr-2010-99" href="../jmlr2010/jmlr-2010-Restricted_Eigenvalue_Properties_for_Correlated_Gaussian_Designs.html">jmlr-2010-Restricted Eigenvalue Properties for Correlated Gaussian Designs</a></p>
<p>100 <a title="jmlr-2010-100" href="../jmlr2010/jmlr-2010-SFO%3A_A_Toolbox_for_Submodular_Function_Optimization.html">jmlr-2010-SFO: A Toolbox for Submodular Function Optimization</a></p>
<p>101 <a title="jmlr-2010-101" href="../jmlr2010/jmlr-2010-Second-Order_Bilinear_Discriminant_Analysis.html">jmlr-2010-Second-Order Bilinear Discriminant Analysis</a></p>
<p>102 <a title="jmlr-2010-102" href="../jmlr2010/jmlr-2010-Semi-Supervised_Novelty_Detection.html">jmlr-2010-Semi-Supervised Novelty Detection</a></p>
<p>103 <a title="jmlr-2010-103" href="../jmlr2010/jmlr-2010-Sparse_Semi-supervised_Learning_Using_Conjugate_Functions.html">jmlr-2010-Sparse Semi-supervised Learning Using Conjugate Functions</a></p>
<p>104 <a title="jmlr-2010-104" href="../jmlr2010/jmlr-2010-Sparse_Spectrum_Gaussian_Process_Regression.html">jmlr-2010-Sparse Spectrum Gaussian Process Regression</a></p>
<p>105 <a title="jmlr-2010-105" href="../jmlr2010/jmlr-2010-Spectral_Regularization_Algorithms_for_Learning_Large_Incomplete_Matrices.html">jmlr-2010-Spectral Regularization Algorithms for Learning Large Incomplete Matrices</a></p>
<p>106 <a title="jmlr-2010-106" href="../jmlr2010/jmlr-2010-Stability_Bounds_for_Stationary_%CF%86-mixing_and_%CE%B2-mixing_Processes.html">jmlr-2010-Stability Bounds for Stationary φ-mixing and β-mixing Processes</a></p>
<p>107 <a title="jmlr-2010-107" href="../jmlr2010/jmlr-2010-Stacked_Denoising_Autoencoders%3A_Learning_Useful_Representations_in_a_Deep_Network_with_a_Local_Denoising_Criterion.html">jmlr-2010-Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</a></p>
<p>108 <a title="jmlr-2010-108" href="../jmlr2010/jmlr-2010-Stochastic_Complexity_and_Generalization_Error_of_a_Restricted_Boltzmann_Machine_in_Bayesian_Estimation.html">jmlr-2010-Stochastic Complexity and Generalization Error of a Restricted Boltzmann Machine in Bayesian Estimation</a></p>
<p>109 <a title="jmlr-2010-109" href="../jmlr2010/jmlr-2010-Stochastic_Composite_Likelihood.html">jmlr-2010-Stochastic Composite Likelihood</a></p>
<p>110 <a title="jmlr-2010-110" href="../jmlr2010/jmlr-2010-The_SHOGUN_Machine_Learning_Toolbox.html">jmlr-2010-The SHOGUN Machine Learning Toolbox</a></p>
<p>111 <a title="jmlr-2010-111" href="../jmlr2010/jmlr-2010-Topology_Selection_in_Graphical_Models_of_Autoregressive_Processes.html">jmlr-2010-Topology Selection in Graphical Models of Autoregressive Processes</a></p>
<p>112 <a title="jmlr-2010-112" href="../jmlr2010/jmlr-2010-Training_and_Testing_Low-degree_Polynomial_Data_Mappings_via_Linear_SVM.html">jmlr-2010-Training and Testing Low-degree Polynomial Data Mappings via Linear SVM</a></p>
<p>113 <a title="jmlr-2010-113" href="../jmlr2010/jmlr-2010-Tree_Decomposition_for_Large-Scale_SVM_Problems.html">jmlr-2010-Tree Decomposition for Large-Scale SVM Problems</a></p>
<p>114 <a title="jmlr-2010-114" href="../jmlr2010/jmlr-2010-Unsupervised_Supervised_Learning_I%3A_Estimating_Classification_and_Regression_Errors_without_Labels.html">jmlr-2010-Unsupervised Supervised Learning I: Estimating Classification and Regression Errors without Labels</a></p>
<p>115 <a title="jmlr-2010-115" href="../jmlr2010/jmlr-2010-Using_Contextual_Representations_to_Efficiently_Learn_Context-Free_Languages.html">jmlr-2010-Using Contextual Representations to Efficiently Learn Context-Free Languages</a></p>
<p>116 <a title="jmlr-2010-116" href="../jmlr2010/jmlr-2010-WEKA%E2%88%92Experiences_with_a_Java_Open-Source_Project.html">jmlr-2010-WEKA−Experiences with a Java Open-Source Project</a></p>
<p>117 <a title="jmlr-2010-117" href="../jmlr2010/jmlr-2010-Why_Does_Unsupervised_Pre-training_Help_Deep_Learning%3F.html">jmlr-2010-Why Does Unsupervised Pre-training Help Deep Learning?</a></p>
<p>118 <a title="jmlr-2010-118" href="../jmlr2010/jmlr-2010-libDAI%3A_A_Free_and_Open_Source_C%2B%2B_Library_for_Discrete_Approximate_Inference_in_Graphical_Models.html">jmlr-2010-libDAI: A Free and Open Source C++ Library for Discrete Approximate Inference in Graphical Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
