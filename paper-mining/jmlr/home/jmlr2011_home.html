<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>jmlr 2011 knowledge graph</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="#">jmlr2011</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>jmlr 2011 knowledge graph</h1>
<br/><h3>similar papers computed by tfidf model</h3><br/><h3>similar papers computed by <a title="lsi-model" href="./jmlr2011_lsi.html">lsi model</a></h3><br/><h3>similar papers computed by <a title="lda-model" href="./jmlr2011_lda.html">lda model</a></h3><br/><h2>papers list:</h2><p>1 <a title="jmlr-2011-1" href="../jmlr2011/jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>Author: Stéphane Ross, Joelle Pineau, Brahim Chaib-draa, Pierre Kreitmann</p><p>Abstract: Bayesian learning methods have recently been shown to provide an elegant solution to the explorationexploitation trade-off in reinforcement learning. However most investigations of Bayesian reinforcement learning to date focus on the standard Markov Decision Processes (MDPs). The primary focus of this paper is to extend these ideas to the case of partially observable domains, by introducing the Bayes-Adaptive Partially Observable Markov Decision Processes. This new framework can be used to simultaneously (1) learn a model of the POMDP domain through interaction with the environment, (2) track the state of the system under partial observability, and (3) plan (near-)optimal sequences of actions. An important contribution of this paper is to provide theoretical results showing how the model can be ﬁnitely approximated while preserving good learning performance. We present approximate algorithms for belief tracking and planning in this model, as well as empirical results that illustrate how the model estimate and agent’s return improve as a function of experience. Keywords: processes reinforcement learning, Bayesian inference, partially observable Markov decision</p><p>2 <a title="jmlr-2011-2" href="../jmlr2011/jmlr-2011-A_Bayesian_Approximation_Method_for_Online_Ranking.html">jmlr-2011-A Bayesian Approximation Method for Online Ranking</a></p>
<p>Author: Ruby C. Weng, Chih-Jen Lin</p><p>Abstract: This paper describes a Bayesian approximation method to obtain online ranking algorithms for games with multiple teams and multiple players. Recently for Internet games large online ranking systems are much needed. We consider game models in which a k-team game is treated as several two-team games. By approximating the expectation of teams’ (or players’) performances, we derive simple analytic update rules. These update rules, without numerical integrations, are very easy to interpret and implement. Experiments on game data show that the accuracy of our approach is competitive with state of the art systems such as TrueSkill, but the running time as well as the code is much shorter. Keywords: Bayesian inference, rating system, Bradley-Terry model, Thurstone-Mosteller model, Plackett-Luce model</p><p>3 <a title="jmlr-2011-3" href="../jmlr2011/jmlr-2011-A_Cure_for_Variance_Inflation_in_High_Dimensional_Kernel_Principal_Component_Analysis.html">jmlr-2011-A Cure for Variance Inflation in High Dimensional Kernel Principal Component Analysis</a></p>
<p>Author: Trine Julie Abrahamsen, Lars Kai Hansen</p><p>Abstract: Small sample high-dimensional principal component analysis (PCA) suffers from variance inﬂation and lack of generalizability. It has earlier been pointed out that a simple leave-one-out variance renormalization scheme can cure the problem. In this paper we generalize the cure in two directions: First, we propose a computationally less intensive approximate leave-one-out estimator, secondly, we show that variance inﬂation is also present in kernel principal component analysis (kPCA) and we provide a non-parametric renormalization scheme which can quite efﬁciently restore generalizability in kPCA. As for PCA our analysis also suggests a simpliﬁed approximate expression. Keywords: PCA, kernel PCA, generalizability, variance renormalization</p><p>4 <a title="jmlr-2011-4" href="../jmlr2011/jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<p>Author: Jinfeng Zhuang, Ivor W. Tsang, Steven C.H. Hoi</p><p>Abstract: Previous studies of Non-Parametric Kernel Learning (NPKL) usually formulate the learning task as a Semi-Deﬁnite Programming (SDP) problem that is often solved by some general purpose SDP solvers. However, for N data examples, the time complexity of NPKL using a standard interiorpoint SDP solver could be as high as O(N 6.5 ), which prohibits NPKL methods applicable to real applications, even for data sets of moderate size. In this paper, we present a family of efﬁcient NPKL algorithms, termed “SimpleNPKL”, which can learn non-parametric kernels from a large set of pairwise constraints efﬁciently. In particular, we propose two efﬁcient SimpleNPKL algorithms. One is SimpleNPKL algorithm with linear loss, which enjoys a closed-form solution that can be efﬁciently computed by the Lanczos sparse eigen decomposition technique. Another one is SimpleNPKL algorithm with other loss functions (including square hinge loss, hinge loss, square loss) that can be re-formulated as a saddle-point optimization problem, which can be further resolved by a fast iterative algorithm. In contrast to the previous NPKL approaches, our empirical results show that the proposed new technique, maintaining the same accuracy, is signiﬁcantly more efﬁcient and scalable. Finally, we also demonstrate that the proposed new technique is also applicable to speed up many kernel learning tasks, including colored maximum variance unfolding, minimum volume embedding, and structure preserving embedding. Keywords: non-parametric kernel learning, semi-deﬁnite programming, semi-supervised learning, side information, pairwise constraints</p><p>5 <a title="jmlr-2011-5" href="../jmlr2011/jmlr-2011-A_Refined_Margin_Analysis_for_Boosting_Algorithms_via_Equilibrium_Margin.html">jmlr-2011-A Refined Margin Analysis for Boosting Algorithms via Equilibrium Margin</a></p>
<p>Author: Liwei Wang, Masashi Sugiyama, Zhaoxiang Jing, Cheng Yang, Zhi-Hua Zhou, Jufu Feng</p><p>Abstract: Much attention has been paid to the theoretical explanation of the empirical success of AdaBoost. The most inﬂuential work is the margin theory, which is essentially an upper bound for the generalization error of any voting classiﬁer in terms of the margin distribution over the training data. However, important questions were raised about the margin explanation. Breiman (1999) proved a bound in terms of the minimum margin, which is sharper than the margin distribution bound. He argued that the minimum margin would be better in predicting the generalization error. Grove and Schuurmans (1998) developed an algorithm called LP-AdaBoost which maximizes the minimum margin while keeping all other factors the same as AdaBoost. In experiments however, LP-AdaBoost usually performs worse than AdaBoost, putting the margin explanation into serious doubt. In this paper, we make a reﬁned analysis of the margin theory. We prove a bound in terms of a new margin measure called the Equilibrium margin (Emargin). The Emargin bound is uniformly ©2011 Liwei Wang, Masashi Sugiyama, Zhaoxiang Jing, Cheng Yang, Zhi-Hua Zhou and Jufu Feng. WANG , S UGIYAMA , J ING , YANG , Z HOU AND F ENG sharper than Breiman’s minimum margin bound. Thus our result suggests that the minimum margin may be not crucial for the generalization error. We also show that a large Emargin and a small empirical error at Emargin imply a smaller bound of the generalization error. Experimental results on benchmark data sets demonstrate that AdaBoost usually has a larger Emargin and a smaller test error than LP-AdaBoost, which agrees well with our theory. Keywords: boosting, margin bounds, voting classiﬁer</p><p>6 <a title="jmlr-2011-6" href="../jmlr2011/jmlr-2011-A_Simpler_Approach_to_Matrix_Completion.html">jmlr-2011-A Simpler Approach to Matrix Completion</a></p>
<p>Author: Benjamin Recht   </p><p>Abstract: This paper provides the best bounds to date on the number of randomly sampled entries required to reconstruct an unknown low-rank matrix. These results improve on prior work by Cand` s and e Recht (2009), Cand` s and Tao (2009), and Keshavan et al. (2009). The reconstruction is accome plished by minimizing the nuclear norm, or sum of the singular values, of the hidden matrix subject to agreement with the provided entries. If the underlying matrix satisﬁes a certain incoherence condition, then the number of entries required is equal to a quadratic logarithmic factor times the number of parameters in the singular value decomposition. The proof of this assertion is short, self contained, and uses very elementary analysis. The novel techniques herein are based on recent work in quantum information theory. Keywords: matrix completion, low-rank matrices, convex optimization, nuclear norm minimization, random matrices, operator Chernoff bound, compressed sensing</p><p>7 <a title="jmlr-2011-7" href="../jmlr2011/jmlr-2011-Adaptive_Exact_Inference_in_Graphical_Models.html">jmlr-2011-Adaptive Exact Inference in Graphical Models</a></p>
<p>Author: Özgür Sümer, Umut A. Acar, Alexander T. Ihler, Ramgopal R. Mettu</p><p>Abstract: Many algorithms and applications involve repeatedly solving variations of the same inference problem, for example to introduce new evidence to the model or to change conditional dependencies. As the model is updated, the goal of adaptive inference is to take advantage of previously computed quantities to perform inference more rapidly than from scratch. In this paper, we present algorithms for adaptive exact inference on general graphs that can be used to efﬁciently compute marginals and update MAP conﬁgurations under arbitrary changes to the input factor graph and its associated elimination tree. After a linear time preprocessing step, our approach enables updates to the model and the computation of any marginal in time that is logarithmic in the size of the input model. Moreover, in contrast to max-product our approach can also be used to update MAP conﬁgurations in time that is roughly proportional to the number of updated entries, rather than the size of the input model. To evaluate the practical effectiveness of our algorithms, we implement and test them using synthetic data as well as for two real-world computational biology applications. Our experiments show that adaptive inference can achieve substantial speedups over performing complete inference as the model undergoes small changes over time. Keywords: exact inference, factor graphs, factor elimination, marginalization, dynamic programming, MAP computation, model updates, parallel tree contraction ¨ u u c 2011 Ozg¨ r S¨ mer, Umut A. Acar, Alexander T. Ihler and Ramgopal R. Mettu. ¨ S UMER , ACAR , I HLER AND M ETTU</p><p>8 <a title="jmlr-2011-8" href="../jmlr2011/jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>Author: John Duchi, Elad Hazan, Yoram Singer</p><p>Abstract: We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms. Keywords: subgradient methods, adaptivity, online learning, stochastic convex optimization</p><p>9 <a title="jmlr-2011-9" href="../jmlr2011/jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>Author: Piotr Zwiernik</p><p>Abstract: The standard Bayesian Information Criterion (BIC) is derived under regularity conditions which are not always satisÄ?Ĺš ed in the case of graphical models with hidden variables. In this paper we derive the BIC for the binary graphical tree models where all the inner nodes of a tree represent binary hidden variables. This provides an extension of a similar formula given by Rusakov and Geiger for naive Bayes models. The main tool used in this paper is the connection between the growth behavior of marginal likelihood integrals and the real log-canonical threshold. Keywords: BIC, marginal likelihood, singular models, tree models, Bayesian networks, real logcanonical threshold</p><p>10 <a title="jmlr-2011-10" href="../jmlr2011/jmlr-2011-Anechoic_Blind_Source_Separation_Using_Wigner_Marginals.html">jmlr-2011-Anechoic Blind Source Separation Using Wigner Marginals</a></p>
<p>Author: Lars Omlor, Martin A. Giese</p><p>Abstract: Blind source separation problems emerge in many applications, where signals can be modeled as superpositions of multiple sources. Many popular applications of blind source separation are based on linear instantaneous mixture models. If speciﬁc invariance properties are known about the sources, for example, translation or rotation invariance, the simple linear model can be extended by inclusion of the corresponding transformations. When the sources are invariant against translations (spatial displacements or time shifts) the resulting model is called an anechoic mixing model. We present a new algorithmic framework for the solution of anechoic problems in arbitrary dimensions. This framework is derived from stochastic time-frequency analysis in general, and the marginal properties of the Wigner-Ville spectrum in particular. The method reduces the general anechoic problem to a set of anechoic problems with non-negativity constraints and a phase retrieval problem. The ﬁrst type of subproblem can be solved by existing algorithms, for example by an appropriate modiﬁcation of non-negative matrix factorization (NMF). The second subproblem is solved by established phase retrieval methods. We discuss and compare implementations of this new algorithmic framework for several example problems with synthetic and real-world data, including music streams, natural 2D images, human motion trajectories and two-dimensional shapes. Keywords: blind source separation, anechoic mixtures, time-frequency transformations, linear canonical transform, Wigner-Ville spectrum</p><p>11 <a title="jmlr-2011-11" href="../jmlr2011/jmlr-2011-Approximate_Marginals_in_Latent_Gaussian_Models.html">jmlr-2011-Approximate Marginals in Latent Gaussian Models</a></p>
<p>Author: Botond Cseke, Tom Heskes</p><p>Abstract: We consider the problem of improving the Gaussian approximate posterior marginals computed by expectation propagation and the Laplace method in latent Gaussian models and propose methods that are similar in spirit to the Laplace approximation of Tierney and Kadane (1986). We show that in the case of sparse Gaussian models, the computational complexity of expectation propagation can be made comparable to that of the Laplace method by using a parallel updating scheme. In some cases, expectation propagation gives excellent estimates where the Laplace approximation fails. Inspired by bounds on the correct marginals, we arrive at factorized approximations, which can be applied on top of both expectation propagation and the Laplace method. The factorized approximations can give nearly indistinguishable results from the non-factorized approximations and their computational complexity scales linearly with the number of variables. We experienced that the expectation propagation based marginal approximations we introduce are typically more accurate than the methods of similar complexity proposed by Rue et al. (2009). Keywords: approximate marginals, Gaussian Markov random ﬁelds, Laplace approximation, variational inference, expectation propagation</p><p>12 <a title="jmlr-2011-12" href="../jmlr2011/jmlr-2011-Bayesian_Co-Training.html">jmlr-2011-Bayesian Co-Training</a></p>
<p>Author: Shipeng Yu, Balaji Krishnapuram, Rómer Rosales, R. Bharat Rao</p><p>Abstract: Co-training (or more generally, co-regularization) has been a popular algorithm for semi-supervised learning in data with two feature representations (or views), but the fundamental assumptions underlying this type of models are still unclear. In this paper we propose a Bayesian undirected graphical model for co-training, or more generally for semi-supervised multi-view learning. This makes explicit the previously unstated assumptions of a large class of co-training type algorithms, and also clariﬁes the circumstances under which these assumptions fail. Building upon new insights from this model, we propose an improved method for co-training, which is a novel co-training kernel for Gaussian process classiﬁers. The resulting approach is convex and avoids local-maxima problems, and it can also automatically estimate how much each view should be trusted to accommodate noisy or unreliable views. The Bayesian co-training approach can also elegantly handle data samples with missing views, that is, some of the views are not available for some data points at learning time. This is further extended to an active sensing framework, in which the missing (sample, view) pairs are actively acquired to improve learning performance. The strength of active sensing model is that one actively sensed (sample, view) pair would improve the joint multi-view classiﬁcation on all the samples. Experiments on toy data and several real world data sets illustrate the beneﬁts of this approach. Keywords: co-training, multi-view learning, semi-supervised learning, Gaussian processes, undirected graphical models, active sensing</p><p>13 <a title="jmlr-2011-13" href="../jmlr2011/jmlr-2011-Bayesian_Generalized_Kernel_Mixed_Models.html">jmlr-2011-Bayesian Generalized Kernel Mixed Models</a></p>
<p>Author: Zhihua Zhang, Guang Dai, Michael I. Jordan</p><p>Abstract: We propose a fully Bayesian methodology for generalized kernel mixed models (GKMMs), which are extensions of generalized linear mixed models in the feature space induced by a reproducing kernel. We place a mixture of a point-mass distribution and Silverman’s g-prior on the regression vector of a generalized kernel model (GKM). This mixture prior allows a fraction of the components of the regression vector to be zero. Thus, it serves for sparse modeling and is useful for Bayesian computation. In particular, we exploit data augmentation methodology to develop a Markov chain Monte Carlo (MCMC) algorithm in which the reversible jump method is used for model selection and a Bayesian model averaging method is used for posterior prediction. When the feature basis expansion in the reproducing kernel Hilbert space is treated as a stochastic process, this approach can be related to the Karhunen-Lo` ve expansion of a Gaussian process (GP). Thus, our sparse e modeling framework leads to a ﬂexible approximation method for GPs. Keywords: reproducing kernel Hilbert spaces, generalized kernel models, Silverman’s g-prior, Bayesian model averaging, Gaussian processes</p><p>14 <a title="jmlr-2011-14" href="../jmlr2011/jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: The online multi-armed bandit problem and its generalizations are repeated decision making problems, where the goal is to select one of several possible decisions in every round, and incur a cost associated with the decision, in such a way that the total cost incurred over all iterations is close to the cost of the best ﬁxed decision in hindsight. The difference in these costs is known as the regret of the algorithm. The term bandit refers to the setting where one only obtains the cost of the decision used in a given iteration and no other information. A very general form of this problem is the non-stochastic bandit linear optimization problem, where the set of decisions is a convex set in some√ Euclidean space, and the cost functions are linear. ˜ Only recently an efﬁcient algorithm attaining O( T ) regret was discovered in this setting. In this paper we propose a new algorithm for the bandit linear optimization problem which √ ˜ obtains a tighter regret bound of O( Q), where Q is the total variation in the cost functions. This regret bound, previously conjectured to hold in the full information case, shows that it is possible to incur much less regret in a slowly changing environment even in the bandit setting. Our algorithm is efﬁcient and applies several new ideas to bandit optimization such as reservoir sampling. Keywords: multi-armed bandit, regret minimization, online learning</p><p>15 <a title="jmlr-2011-15" href="../jmlr2011/jmlr-2011-CARP%3A_Software_for_Fishing_Out_Good_Clustering_Algorithms.html">jmlr-2011-CARP: Software for Fishing Out Good Clustering Algorithms</a></p>
<p>Author: Volodymyr Melnykov, Ranjan Maitra</p><p>Abstract: This paper presents the C LUSTERING A LGORITHMS ’ R EFEREE PACKAGE or CARP, an open source GNU GPL-licensed C package for evaluating clustering algorithms. Calibrating performance of such algorithms is important and CARP addresses this need by generating datasets of different clustering complexity and by assessing the performance of the concerned algorithm in terms of its ability to classify each dataset relative to the true grouping. This paper brieﬂy describes the software and its capabilities. Keywords: CARP, M IX S IM, clustering algorithm, Gaussian mixture, overlap</p><p>16 <a title="jmlr-2011-16" href="../jmlr2011/jmlr-2011-Clustering_Algorithms_for_Chains.html">jmlr-2011-Clustering Algorithms for Chains</a></p>
<p>Author: Antti Ukkonen</p><p>Abstract: We consider the problem of clustering a set of chains to k clusters. A chain is a totally ordered subset of a ﬁnite set of items. Chains are an intuitive way to express preferences over a set of alternatives, as well as a useful representation of ratings in situations where the item-speciﬁc scores are either difﬁcult to obtain, too noisy due to measurement error, or simply not as relevant as the order that they induce over the items. First we adapt the classical k-means for chains by proposing a suitable distance function and a centroid structure. We also present two different approaches for mapping chains to a vector space. The ﬁrst one is related to the planted partition model, while the second one has an intuitive geometrical interpretation. Finally we discuss a randomization test for assessing the signiﬁcance of a clustering. To this end we present an MCMC algorithm for sampling random sets of chains that share certain properties with the original data. The methods are studied in a series of experiments using real and artiﬁcial data. Results indicate that the methods produce interesting clusterings, and for certain types of inputs improve upon previous work on clustering algorithms for orders. Keywords: Lloyd’s algorithm, orders, preference statements, planted partition model, randomization testing</p><p>17 <a title="jmlr-2011-17" href="../jmlr2011/jmlr-2011-Computationally_Efficient_Convolved_Multiple_Output_Gaussian_Processes.html">jmlr-2011-Computationally Efficient Convolved Multiple Output Gaussian Processes</a></p>
<p>Author: Mauricio A. Álvarez, Neil D. Lawrence</p><p>Abstract: Recently there has been an increasing interest in regression methods that deal with multiple outputs. This has been motivated partly by frameworks like multitask learning, multisensor networks or structured output data. From a Gaussian processes perspective, the problem reduces to specifying an appropriate covariance function that, whilst being positive semi-deﬁnite, captures the dependencies between all the data points and across all the outputs. One approach to account for non-trivial correlations between outputs employs convolution processes. Under a latent function interpretation of the convolution transform we establish dependencies between output variables. The main drawbacks of this approach are the associated computational and storage demands. In this paper we address these issues. We present different efﬁcient approximations for dependent output Gaussian processes constructed through the convolution formalism. We exploit the conditional independencies present naturally in the model. This leads to a form of the covariance similar in spirit to the so called PITC and FITC approximations for a single output. We show experimental results with synthetic and real data, in particular, we show results in school exams score prediction, pollution prediction and gene expression data. Keywords: Gaussian processes, convolution processes, efﬁcient approximations, multitask learning, structured outputs, multivariate processes</p><p>18 <a title="jmlr-2011-18" href="../jmlr2011/jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>Author: Adam D. Bull</p><p>Abstract: In the efﬁcient global optimization problem, we minimize an unknown function f , using as few observations f (x) as possible. It can be considered a continuum-armed-bandit problem, with noiseless data, and simple regret. Expected-improvement algorithms are perhaps the most popular methods for solving the problem; in this paper, we provide theoretical results on their asymptotic behaviour. Implementing these algorithms requires a choice of Gaussian-process prior, which determines an associated space of functions, its reproducing-kernel Hilbert space (RKHS). When the prior is ﬁxed, expected improvement is known to converge on the minimum of any function in its RKHS. We provide convergence rates for this procedure, optimal for functions of low smoothness, and describe a modiﬁed algorithm attaining optimal rates for smoother functions. In practice, however, priors are typically estimated sequentially from the data. For standard estimators, we show this procedure may never ﬁnd the minimum of f . We then propose alternative estimators, chosen to minimize the constants in the rate of convergence, and show these estimators retain the convergence rates of a ﬁxed prior. Keywords: convergence rates, efﬁcient global optimization, expected improvement, continuumarmed bandit, Bayesian optimization</p><p>19 <a title="jmlr-2011-19" href="../jmlr2011/jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>Author: Benoît Patra</p><p>Abstract: Motivated by the problem of effectively executing clustering algorithms on very large data sets, we address a model for large scale distributed clustering methods. To this end, we brieﬂy recall some standards on the quantization problem and some results on the almost sure convergence of the competitive learning vector quantization (CLVQ) procedure. A general model for linear distributed asynchronous algorithms well adapted to several parallel computing architectures is also discussed. Our approach brings together this scalable model and the CLVQ algorithm, and we call the resulting technique the distributed asynchronous learning vector quantization algorithm (DALVQ). An indepth analysis of the almost sure convergence of the DALVQ algorithm is performed. A striking result is that we prove that the multiple versions of the quantizers distributed among the processors in the parallel architecture asymptotically reach a consensus almost surely. Furthermore, we also show that these versions converge almost surely towards the same nearly optimal value for the quantization criterion. Keywords: k-means, vector quantization, distributed, asynchronous, stochastic optimization, scalability, distributed consensus</p><p>20 <a title="jmlr-2011-20" href="../jmlr2011/jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>Author: Julien Mairal, Rodolphe Jenatton, Guillaume Obozinski, Francis Bach</p><p>Abstract: We consider a class of learning problems regularized by a structured sparsity-inducing norm deﬁned as the sum of ℓ2 - or ℓ∞ -norms over groups of variables. Whereas much effort has been put in developing fast optimization techniques when the groups are disjoint or embedded in a hierarchy, we address here the case of general overlapping groups. To this end, we present two different strategies: On the one hand, we show that the proximal operator associated with a sum of ℓ∞ norms can be computed exactly in polynomial time by solving a quadratic min-cost ﬂow problem, allowing the use of accelerated proximal gradient methods. On the other hand, we use proximal splitting techniques, and address an equivalent formulation with non-overlapping groups, but in higher dimension and with additional constraints. We propose efﬁcient and scalable algorithms exploiting these two strategies, which are signiﬁcantly faster than alternative approaches. We illustrate these methods with several problems such as CUR matrix factorization, multi-task learning of tree-structured dictionaries, background subtraction in video sequences, image denoising with wavelets, and topographic dictionary learning of natural image patches. Keywords: convex optimization, proximal methods, sparse coding, structured sparsity, matrix factorization, network ﬂow optimization, alternating direction method of multipliers</p><p>21 <a title="jmlr-2011-21" href="../jmlr2011/jmlr-2011-Cumulative_Distribution_Networks_and_the_Derivative-sum-product_Algorithm%3A_Models_and_Inference_for_Cumulative_Distribution_Functions_on_Graphs.html">jmlr-2011-Cumulative Distribution Networks and the Derivative-sum-product Algorithm: Models and Inference for Cumulative Distribution Functions on Graphs</a></p>
<p>22 <a title="jmlr-2011-22" href="../jmlr2011/jmlr-2011-Differentially_Private_Empirical_Risk_Minimization.html">jmlr-2011-Differentially Private Empirical Risk Minimization</a></p>
<p>23 <a title="jmlr-2011-23" href="../jmlr2011/jmlr-2011-DirectLiNGAM%3A_A_Direct_Method_for_Learning_a_Linear_Non-Gaussian_Structural_Equation_Model.html">jmlr-2011-DirectLiNGAM: A Direct Method for Learning a Linear Non-Gaussian Structural Equation Model</a></p>
<p>24 <a title="jmlr-2011-24" href="../jmlr2011/jmlr-2011-Dirichlet_Process_Mixtures_of_Generalized_Linear_Models.html">jmlr-2011-Dirichlet Process Mixtures of Generalized Linear Models</a></p>
<p>25 <a title="jmlr-2011-25" href="../jmlr2011/jmlr-2011-Discriminative_Learning_of_Bayesian_Networks_via_Factorized_Conditional_Log-Likelihood.html">jmlr-2011-Discriminative Learning of Bayesian Networks via Factorized Conditional Log-Likelihood</a></p>
<p>26 <a title="jmlr-2011-26" href="../jmlr2011/jmlr-2011-Distance_Dependent_Chinese_Restaurant_Processes.html">jmlr-2011-Distance Dependent Chinese Restaurant Processes</a></p>
<p>27 <a title="jmlr-2011-27" href="../jmlr2011/jmlr-2011-Domain_Decomposition_Approach_for_Fast_Gaussian_Process_Regression_of_Large_Spatial_Data_Sets.html">jmlr-2011-Domain Decomposition Approach for Fast Gaussian Process Regression of Large Spatial Data Sets</a></p>
<p>28 <a title="jmlr-2011-28" href="../jmlr2011/jmlr-2011-Double_Updating_Online_Learning.html">jmlr-2011-Double Updating Online Learning</a></p>
<p>29 <a title="jmlr-2011-29" href="../jmlr2011/jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>30 <a title="jmlr-2011-30" href="../jmlr2011/jmlr-2011-Efficient_Structure_Learning_of_Bayesian_Networks_using_Constraints.html">jmlr-2011-Efficient Structure Learning of Bayesian Networks using Constraints</a></p>
<p>31 <a title="jmlr-2011-31" href="../jmlr2011/jmlr-2011-Efficient_and_Effective_Visual_Codebook_Generation_Using_Additive_Kernels.html">jmlr-2011-Efficient and Effective Visual Codebook Generation Using Additive Kernels</a></p>
<p>32 <a title="jmlr-2011-32" href="../jmlr2011/jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>33 <a title="jmlr-2011-33" href="../jmlr2011/jmlr-2011-Exploiting_Best-Match_Equations_for_Efficient_Reinforcement_Learning.html">jmlr-2011-Exploiting Best-Match Equations for Efficient Reinforcement Learning</a></p>
<p>34 <a title="jmlr-2011-34" href="../jmlr2011/jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>35 <a title="jmlr-2011-35" href="../jmlr2011/jmlr-2011-Forest_Density_Estimation.html">jmlr-2011-Forest Density Estimation</a></p>
<p>36 <a title="jmlr-2011-36" href="../jmlr2011/jmlr-2011-Generalized_TD_Learning.html">jmlr-2011-Generalized TD Learning</a></p>
<p>37 <a title="jmlr-2011-37" href="../jmlr2011/jmlr-2011-Group_Lasso_Estimation_of_High-dimensional_Covariance_Matrices.html">jmlr-2011-Group Lasso Estimation of High-dimensional Covariance Matrices</a></p>
<p>38 <a title="jmlr-2011-38" href="../jmlr2011/jmlr-2011-Hierarchical_Knowledge_Gradient_for_Sequential_Sampling.html">jmlr-2011-Hierarchical Knowledge Gradient for Sequential Sampling</a></p>
<p>39 <a title="jmlr-2011-39" href="../jmlr2011/jmlr-2011-High-dimensional_Covariance_Estimation_Based_On_Gaussian_Graphical_Models.html">jmlr-2011-High-dimensional Covariance Estimation Based On Gaussian Graphical Models</a></p>
<p>40 <a title="jmlr-2011-40" href="../jmlr2011/jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>41 <a title="jmlr-2011-41" href="../jmlr2011/jmlr-2011-Improved_Moves_for_Truncated_Convex_Models.html">jmlr-2011-Improved Moves for Truncated Convex Models</a></p>
<p>42 <a title="jmlr-2011-42" href="../jmlr2011/jmlr-2011-In_All_Likelihood%2C_Deep_Belief_Is_Not_Enough.html">jmlr-2011-In All Likelihood, Deep Belief Is Not Enough</a></p>
<p>43 <a title="jmlr-2011-43" href="../jmlr2011/jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>44 <a title="jmlr-2011-44" href="../jmlr2011/jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>45 <a title="jmlr-2011-45" href="../jmlr2011/jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>46 <a title="jmlr-2011-46" href="../jmlr2011/jmlr-2011-Introduction_to_the_Special_Topic_on_Grammar_Induction%2C_Representation_of_Language_and_Language_Learning.html">jmlr-2011-Introduction to the Special Topic on Grammar Induction, Representation of Language and Language Learning</a></p>
<p>47 <a title="jmlr-2011-47" href="../jmlr2011/jmlr-2011-Inverse_Reinforcement_Learning_in_Partially_Observable_Environments.html">jmlr-2011-Inverse Reinforcement Learning in Partially Observable Environments</a></p>
<p>48 <a title="jmlr-2011-48" href="../jmlr2011/jmlr-2011-Kernel_Analysis_of_Deep_Networks.html">jmlr-2011-Kernel Analysis of Deep Networks</a></p>
<p>49 <a title="jmlr-2011-49" href="../jmlr2011/jmlr-2011-Kernel_Regression_in_the_Presence_of_Correlated_Errors.html">jmlr-2011-Kernel Regression in the Presence of Correlated Errors</a></p>
<p>50 <a title="jmlr-2011-50" href="../jmlr2011/jmlr-2011-LPmade%3A_Link_Prediction_Made_Easy.html">jmlr-2011-LPmade: Link Prediction Made Easy</a></p>
<p>51 <a title="jmlr-2011-51" href="../jmlr2011/jmlr-2011-Laplacian_Support_Vector_Machines__Trained_in_the_Primal.html">jmlr-2011-Laplacian Support Vector Machines  Trained in the Primal</a></p>
<p>52 <a title="jmlr-2011-52" href="../jmlr2011/jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>53 <a title="jmlr-2011-53" href="../jmlr2011/jmlr-2011-Learning_High-Dimensional_Markov_Forest_Distributions%3A_Analysis_of_Error_Rates.html">jmlr-2011-Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates</a></p>
<p>54 <a title="jmlr-2011-54" href="../jmlr2011/jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<p>55 <a title="jmlr-2011-55" href="../jmlr2011/jmlr-2011-Learning_Multi-modal_Similarity.html">jmlr-2011-Learning Multi-modal Similarity</a></p>
<p>56 <a title="jmlr-2011-56" href="../jmlr2011/jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>57 <a title="jmlr-2011-57" href="../jmlr2011/jmlr-2011-Learning_a_Robust_Relevance_Model_for_Search_Using_Kernel_Methods.html">jmlr-2011-Learning a Robust Relevance Model for Search Using Kernel Methods</a></p>
<p>58 <a title="jmlr-2011-58" href="../jmlr2011/jmlr-2011-Learning_from_Partial_Labels.html">jmlr-2011-Learning from Partial Labels</a></p>
<p>59 <a title="jmlr-2011-59" href="../jmlr2011/jmlr-2011-Learning_with_Structured_Sparsity.html">jmlr-2011-Learning with Structured Sparsity</a></p>
<p>60 <a title="jmlr-2011-60" href="../jmlr2011/jmlr-2011-Locally_Defined_Principal_Curves_and_Surfaces.html">jmlr-2011-Locally Defined Principal Curves and Surfaces</a></p>
<p>61 <a title="jmlr-2011-61" href="../jmlr2011/jmlr-2011-Logistic_Stick-Breaking_Process.html">jmlr-2011-Logistic Stick-Breaking Process</a></p>
<p>62 <a title="jmlr-2011-62" href="../jmlr2011/jmlr-2011-MSVMpack%3A_A_Multi-Class_Support_Vector_Machine_Package.html">jmlr-2011-MSVMpack: A Multi-Class Support Vector Machine Package</a></p>
<p>63 <a title="jmlr-2011-63" href="../jmlr2011/jmlr-2011-MULAN%3A_A_Java_Library_for_Multi-Label_Learning.html">jmlr-2011-MULAN: A Java Library for Multi-Label Learning</a></p>
<p>64 <a title="jmlr-2011-64" href="../jmlr2011/jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>65 <a title="jmlr-2011-65" href="../jmlr2011/jmlr-2011-Models_of_Cooperative_Teaching_and_Learning.html">jmlr-2011-Models of Cooperative Teaching and Learning</a></p>
<p>66 <a title="jmlr-2011-66" href="../jmlr2011/jmlr-2011-Multiple_Kernel_Learning_Algorithms.html">jmlr-2011-Multiple Kernel Learning Algorithms</a></p>
<p>67 <a title="jmlr-2011-67" href="../jmlr2011/jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>68 <a title="jmlr-2011-68" href="../jmlr2011/jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>69 <a title="jmlr-2011-69" href="../jmlr2011/jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>70 <a title="jmlr-2011-70" href="../jmlr2011/jmlr-2011-Non-Parametric_Estimation_of_Topic_Hierarchies_from_Texts_with_Hierarchical_Dirichlet_Processes.html">jmlr-2011-Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes</a></p>
<p>71 <a title="jmlr-2011-71" href="../jmlr2011/jmlr-2011-On_Equivalence_Relationships_Between_Classification_and_Ranking_Algorithms.html">jmlr-2011-On Equivalence Relationships Between Classification and Ranking Algorithms</a></p>
<p>72 <a title="jmlr-2011-72" href="../jmlr2011/jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>73 <a title="jmlr-2011-73" href="../jmlr2011/jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>74 <a title="jmlr-2011-74" href="../jmlr2011/jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>75 <a title="jmlr-2011-75" href="../jmlr2011/jmlr-2011-Parallel_Algorithm_for_Learning_Optimal_Bayesian_Network_Structure.html">jmlr-2011-Parallel Algorithm for Learning Optimal Bayesian Network Structure</a></p>
<p>76 <a title="jmlr-2011-76" href="../jmlr2011/jmlr-2011-Parameter_Screening_and_Optimisation_for_ILP_using_Designed_Experiments.html">jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</a></p>
<p>77 <a title="jmlr-2011-77" href="../jmlr2011/jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>78 <a title="jmlr-2011-78" href="../jmlr2011/jmlr-2011-Producing_Power-Law_Distributions_and_Damping_Word_Frequencies_with_Two-Stage_Language_Models.html">jmlr-2011-Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models</a></p>
<p>79 <a title="jmlr-2011-79" href="../jmlr2011/jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>80 <a title="jmlr-2011-80" href="../jmlr2011/jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>81 <a title="jmlr-2011-81" href="../jmlr2011/jmlr-2011-Robust_Approximate_Bilinear_Programming_for_Value_Function_Approximation.html">jmlr-2011-Robust Approximate Bilinear Programming for Value Function Approximation</a></p>
<p>82 <a title="jmlr-2011-82" href="../jmlr2011/jmlr-2011-Robust_Gaussian_Process_Regression_with_a_Student-tLikelihood.html">jmlr-2011-Robust Gaussian Process Regression with a Student-tLikelihood</a></p>
<p>83 <a title="jmlr-2011-83" href="../jmlr2011/jmlr-2011-Scikit-learn%3A_Machine_Learning_in_Python.html">jmlr-2011-Scikit-learn: Machine Learning in Python</a></p>
<p>84 <a title="jmlr-2011-84" href="../jmlr2011/jmlr-2011-Semi-Supervised_Learning_with_Measure_Propagation.html">jmlr-2011-Semi-Supervised Learning with Measure Propagation</a></p>
<p>85 <a title="jmlr-2011-85" href="../jmlr2011/jmlr-2011-Smoothness%2C_Disagreement_Coefficient%2C_and_the_Label_Complexity_of_Agnostic_Active_Learning.html">jmlr-2011-Smoothness, Disagreement Coefficient, and the Label Complexity of Agnostic Active Learning</a></p>
<p>86 <a title="jmlr-2011-86" href="../jmlr2011/jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>87 <a title="jmlr-2011-87" href="../jmlr2011/jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>88 <a title="jmlr-2011-88" href="../jmlr2011/jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>89 <a title="jmlr-2011-89" href="../jmlr2011/jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>90 <a title="jmlr-2011-90" href="../jmlr2011/jmlr-2011-The_Indian_Buffet_Process%3A_An_Introduction_and_Review.html">jmlr-2011-The Indian Buffet Process: An Introduction and Review</a></p>
<p>91 <a title="jmlr-2011-91" href="../jmlr2011/jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>92 <a title="jmlr-2011-92" href="../jmlr2011/jmlr-2011-The_Stationary_Subspace_Analysis_Toolbox.html">jmlr-2011-The Stationary Subspace Analysis Toolbox</a></p>
<p>93 <a title="jmlr-2011-93" href="../jmlr2011/jmlr-2011-The_arules_R-Package_Ecosystem%3A_Analyzing_Interesting_Patterns_from_Large_Transaction_Data_Sets.html">jmlr-2011-The arules R-Package Ecosystem: Analyzing Interesting Patterns from Large Transaction Data Sets</a></p>
<p>94 <a title="jmlr-2011-94" href="../jmlr2011/jmlr-2011-Theoretical_Analysis_of_Bayesian_Matrix_Factorization.html">jmlr-2011-Theoretical Analysis of Bayesian Matrix Factorization</a></p>
<p>95 <a title="jmlr-2011-95" href="../jmlr2011/jmlr-2011-Training_SVMs_Without_Offset.html">jmlr-2011-Training SVMs Without Offset</a></p>
<p>96 <a title="jmlr-2011-96" href="../jmlr2011/jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>97 <a title="jmlr-2011-97" href="../jmlr2011/jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>98 <a title="jmlr-2011-98" href="../jmlr2011/jmlr-2011-Universality%2C_Characteristic_Kernels_and_RKHS_Embedding_of_Measures.html">jmlr-2011-Universality, Characteristic Kernels and RKHS Embedding of Measures</a></p>
<p>99 <a title="jmlr-2011-99" href="../jmlr2011/jmlr-2011-Unsupervised_Similarity-Based_Risk_Stratification_for_Cardiovascular_Events_Using_Long-Term_Time-Series_Data.html">jmlr-2011-Unsupervised Similarity-Based Risk Stratification for Cardiovascular Events Using Long-Term Time-Series Data</a></p>
<p>100 <a title="jmlr-2011-100" href="../jmlr2011/jmlr-2011-Unsupervised_Supervised_Learning_II%3A_Margin-Based_Classification_Without_Labels.html">jmlr-2011-Unsupervised Supervised Learning II: Margin-Based Classification Without Labels</a></p>
<p>101 <a title="jmlr-2011-101" href="../jmlr2011/jmlr-2011-Variable_Sparsity_Kernel_Learning.html">jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>102 <a title="jmlr-2011-102" href="../jmlr2011/jmlr-2011-Waffles%3A_A_Machine_Learning_Toolkit.html">jmlr-2011-Waffles: A Machine Learning Toolkit</a></p>
<p>103 <a title="jmlr-2011-103" href="../jmlr2011/jmlr-2011-Weisfeiler-Lehman_Graph_Kernels.html">jmlr-2011-Weisfeiler-Lehman Graph Kernels</a></p>
<p>104 <a title="jmlr-2011-104" href="../jmlr2011/jmlr-2011-X-Armed_Bandits.html">jmlr-2011-X-Armed Bandits</a></p>
<p>105 <a title="jmlr-2011-105" href="../jmlr2011/jmlr-2011-lp-Norm_Multiple_Kernel_Learning.html">jmlr-2011-lp-Norm Multiple Kernel Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
