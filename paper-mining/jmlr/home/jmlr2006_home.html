<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>jmlr 2006 knowledge graph</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2006" href="#">jmlr2006</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>jmlr 2006 knowledge graph</h1>
<br/><h3>similar papers computed by tfidf model</h3><br/><h3>similar papers computed by <a title="lsi-model" href="./jmlr2006_lsi.html">lsi model</a></h3><br/><h3>similar papers computed by <a title="lda-model" href="./jmlr2006_lda.html">lda model</a></h3><br/><h2>papers list:</h2><p>1 <a title="jmlr-2006-1" href="../jmlr2006/jmlr-2006-A_Direct_Method_for_Building_Sparse_Kernel_Learning_Algorithms.html">jmlr-2006-A Direct Method for Building Sparse Kernel Learning Algorithms</a></p>
<p>Author: Mingrui Wu, Bernhard Schölkopf, Gökhan Bakır</p><p>Abstract: Many kernel learning algorithms, including support vector machines, result in a kernel machine, such as a kernel classiﬁer, whose key component is a weight vector in a feature space implicitly introduced by a positive deﬁnite kernel function. This weight vector is usually obtained by solving a convex optimization problem. Based on this fact we present a direct method to build sparse kernel learning algorithms by adding one more constraint to the original convex optimization problem, such that the sparseness of the resulting kernel machine is explicitly controlled while at the same time performance is kept as high as possible. A gradient based approach is provided to solve this modiﬁed optimization problem. Applying this method to the support vectom machine results in a concrete algorithm for building sparse large margin classiﬁers. These classiﬁers essentially ﬁnd a discriminating subspace that can be spanned by a small number of vectors, and in this subspace, the diﬀerent classes of data are linearly well separated. Experimental results over several classiﬁcation benchmarks demonstrate the eﬀectiveness of our approach. Keywords: sparse learning, sparse large margin classiﬁers, kernel learning algorithms, support vector machine, kernel Fisher discriminant</p><p>2 <a title="jmlr-2006-2" href="../jmlr2006/jmlr-2006-A_Graphical_Representation_of_Equivalence_Classes_of_AMP_Chain_Graphs.html">jmlr-2006-A Graphical Representation of Equivalence Classes of AMP Chain Graphs</a></p>
<p>Author: Alberto Roverato, Milan Studený</p><p>Abstract: This paper deals with chain graph models under alternative AMP interpretation. A new representative of an AMP Markov equivalence class, called the largest deﬂagged graph, is proposed. The representative is based on revealed internal structure of the AMP Markov equivalence class. More speciﬁcally, the AMP Markov equivalence class decomposes into ﬁner strong equivalence classes and there exists a distinguished strong equivalence class among those forming the AMP Markov equivalence class. The largest deﬂagged graph is the largest chain graph in that distinguished strong equivalence class. A composed graphical procedure to get the largest deﬂagged graph on the basis of any AMP Markov equivalent chain graph is presented. In general, the largest deﬂagged graph differs from the AMP essential graph, which is another representative of the AMP Markov equivalence class. Keywords: chain graph, AMP Markov equivalence, strong equivalence, largest deﬂagged graph, component merging procedure, deﬂagging procedure, essential graph</p><p>3 <a title="jmlr-2006-3" href="../jmlr2006/jmlr-2006-A_Hierarchy_of_Support_Vector_Machines_for_Pattern_Detection.html">jmlr-2006-A Hierarchy of Support Vector Machines for Pattern Detection</a></p>
<p>Author: Hichem Sahbi, Donald Geman</p><p>Abstract: We introduce a computational design for pattern detection based on a tree-structured network of support vector machines (SVMs). An SVM is associated with each cell in a recursive partitioning of the space of patterns (hypotheses) into increasingly ﬁner subsets. The hierarchy is traversed coarse-to-ﬁne and each chain of positive responses from the root to a leaf constitutes a detection. Our objective is to design and build a network which balances overall error and computation. Initially, SVMs are constructed for each cell with no constraints. This “free network” is then perturbed, cell by cell, into another network, which is “graded” in two ways: ﬁrst, the number of support vectors of each SVM is reduced (by clustering) in order to adjust to a pre-determined, increasing function of cell depth; second, the decision boundaries are shifted to preserve all positive responses from the original set of training data. The limits on the numbers of clusters (virtual support vectors) result from minimizing the mean computational cost of collecting all detections subject to a bound on the expected number of false positives. When applied to detecting faces in cluttered scenes, the patterns correspond to poses and the free network is already faster and more accurate than applying a single pose-speciﬁc SVM many times. The graded network promotes very rapid processing of background regions while maintaining the discriminatory power of the free network. Keywords: statistical learning, hierarchy of classiﬁers, coarse-to-ﬁne computation, support vector machines, face detection</p><p>4 <a title="jmlr-2006-4" href="../jmlr2006/jmlr-2006-A_Linear_Non-Gaussian_Acyclic_Model_for_Causal_Discovery.html">jmlr-2006-A Linear Non-Gaussian Acyclic Model for Causal Discovery</a></p>
<p>Author: Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvärinen, Antti Kerminen</p><p>Abstract: In recent years, several methods have been proposed for the discovery of causal structure from non-experimental data. Such methods make various assumptions on the data generating process to facilitate its identiﬁcation from purely observational data. Continuing this line of research, we show how to discover the complete causal structure of continuous-valued data, under the assumptions that (a) the data generating process is linear, (b) there are no unobserved confounders, and (c) disturbance variables have non-Gaussian distributions of non-zero variances. The solution relies on the use of the statistical method known as independent component analysis, and does not require any pre-speciﬁed time-ordering of the variables. We provide a complete Matlab package for performing this LiNGAM analysis (short for Linear Non-Gaussian Acyclic Model), and demonstrate the effectiveness of the method using artiﬁcially generated data and real-world data. Keywords: independent component analysis, non-Gaussianity, causal discovery, directed acyclic graph, non-experimental data</p><p>5 <a title="jmlr-2006-5" href="../jmlr2006/jmlr-2006-A_Robust_Procedure_For_Gaussian_Graphical_Model_Search_From_Microarray_Data_WithpLarger_Thann.html">jmlr-2006-A Robust Procedure For Gaussian Graphical Model Search From Microarray Data WithpLarger Thann</a></p>
<p>Author: Robert Castelo, Alberto Roverato</p><p>Abstract: Learning of large-scale networks of interactions from microarray data is an important and challenging problem in bioinformatics. A widely used approach is to assume that the available data constitute a random sample from a multivariate distribution belonging to a Gaussian graphical model. As a consequence, the prime objects of inference are full-order partial correlations which are partial correlations between two variables given the remaining ones. In the context of microarray data the number of variables exceed the sample size and this precludes the application of traditional structure learning procedures because a sampling version of full-order partial correlations does not exist. In this paper we consider limited-order partial correlations, these are partial correlations computed on marginal distributions of manageable size, and provide a set of rules that allow one to assess the usefulness of these quantities to derive the independence structure of the underlying Gaussian graphical model. Furthermore, we introduce a novel structure learning procedure based on a quantity, obtained from limited-order partial correlations, that we call the non-rejection rate. The applicability and usefulness of the procedure are demonstrated by both simulated and real data. Keywords: Gaussian distribution, gene network, graphical model, microarray data, non-rejection rate, partial correlation, small-sample inference</p><p>6 <a title="jmlr-2006-6" href="../jmlr2006/jmlr-2006-A_Scoring_Function_for_Learning_Bayesian_Networks_based_on_Mutual_Information_and_Conditional_Independence_Tests.html">jmlr-2006-A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests</a></p>
<p>Author: Luis M. de Campos</p><p>Abstract: We propose a new scoring function for learning Bayesian networks from data using score+search algorithms. This is based on the concept of mutual information and exploits some well-known properties of this measure in a novel way. Essentially, a statistical independence test based on the chi-square distribution, associated with the mutual information measure, together with a property of additive decomposition of this measure, are combined in order to measure the degree of interaction between each variable and its parent variables in the network. The result is a non-Bayesian scoring function called MIT (mutual information tests) which belongs to the family of scores based on information theory. The MIT score also represents a penalization of the Kullback-Leibler divergence between the joint probability distributions associated with a candidate network and with the available data set. Detailed results of a complete experimental evaluation of the proposed scoring function and its comparison with the well-known K2, BDeu and BIC/MDL scores are also presented. Keywords: Bayesian networks, scoring functions, learning, mutual information, conditional independence tests</p><p>7 <a title="jmlr-2006-7" href="../jmlr2006/jmlr-2006-A_Simulation-Based_Algorithm_for_Ergodic_Control_of_Markov_Chains_Conditioned_on_Rare_Events.html">jmlr-2006-A Simulation-Based Algorithm for Ergodic Control of Markov Chains Conditioned on Rare Events</a></p>
<p>Author: Shalabh Bhatnagar, Vivek S. Borkar, Madhukar Akarapu</p><p>Abstract: We study the problem of long-run average cost control of Markov chains conditioned on a rare event. In a related recent work, a simulation based algorithm for estimating performance measures associated with a Markov chain conditioned on a rare event has been developed. We extend ideas from this work and develop an adaptive algorithm for obtaining, online, optimal control policies conditioned on a rare event. Our algorithm uses three timescales or step-size schedules. On the slowest timescale, a gradient search algorithm for policy updates that is based on one-simulation simultaneous perturbation stochastic approximation (SPSA) type estimates is used. Deterministic perturbation sequences obtained from appropriate normalized Hadamard matrices are used here. The fast timescale recursions compute the conditional transition probabilities of an associated chain by obtaining solutions to the multiplicative Poisson equation (for a given policy estimate). Further, the risk parameter associated with the value function for a given policy estimate is updated on a timescale that lies in between the two scales above. We brieﬂy sketch the convergence analysis of our algorithm and present a numerical application in the setting of routing multiple ﬂows in communication networks. Keywords: Markov decision processes, optimal control conditioned on a rare event, simulation based algorithms, SPSA with deterministic perturbations, reinforcement learning</p><p>8 <a title="jmlr-2006-8" href="../jmlr2006/jmlr-2006-A_Very_Fast_Learning_Method_for_Neural_Networks_Based_on_Sensitivity_Analysis.html">jmlr-2006-A Very Fast Learning Method for Neural Networks Based on Sensitivity Analysis</a></p>
<p>Author: Enrique Castillo, Bertha Guijarro-Berdiñas, Oscar Fontenla-Romero, Amparo Alonso-Betanzos</p><p>Abstract: This paper introduces a learning method for two-layer feedforward neural networks based on sensitivity analysis, which uses a linear training algorithm for each of the two layers. First, random values are assigned to the outputs of the ﬁrst layer; later, these initial values are updated based on sensitivity formulas, which use the weights in each of the layers; the process is repeated until convergence. Since these weights are learnt solving a linear system of equations, there is an important saving in computational time. The method also gives the local sensitivities of the least square errors with respect to input and output data, with no extra computational cost, because the necessary information becomes available without extra calculations. This method, called the Sensitivity-Based Linear Learning Method, can also be used to provide an initial set of weights, which signiﬁcantly improves the behavior of other learning algorithms. The theoretical basis for the method is given and its performance is illustrated by its application to several examples in which it is compared with several learning algorithms and well known data sets. The results have shown a learning speed generally faster than other existing methods. In addition, it can be used as an initialization tool for other well known methods with signiﬁcant improvements. Keywords: supervised learning, neural networks, linear optimization, least-squares, initialization method, sensitivity analysis</p><p>9 <a title="jmlr-2006-9" href="../jmlr2006/jmlr-2006-Accurate_Error_Bounds_for_the_Eigenvalues_of_the_Kernel_Matrix.html">jmlr-2006-Accurate Error Bounds for the Eigenvalues of the Kernel Matrix</a></p>
<p>Author: Mikio L. Braun</p><p>Abstract: The eigenvalues of the kernel matrix play an important role in a number of kernel methods, in particular, in kernel principal component analysis. It is well known that the eigenvalues of the kernel matrix converge as the number of samples tends to inﬁnity. We derive probabilistic ﬁnite sample size bounds on the approximation error of individual eigenvalues which have the important property that the bounds scale with the eigenvalue under consideration, reﬂecting the actual behavior of the approximation errors as predicted by asymptotic results and observed in numerical simulations. Such scaling bounds have so far only been known for tail sums of eigenvalues. Asymptotically, the bounds presented here have a slower than stochastic rate, but the number of sample points necessary to make this disadvantage noticeable is often unrealistically large. Therefore, under practical conditions, and for all but the largest few eigenvalues, the bounds presented here form a signiﬁcant improvement over existing non-scaling bounds. Keywords: kernel matrix, eigenvalues, relative perturbation bounds</p><p>10 <a title="jmlr-2006-10" href="../jmlr2006/jmlr-2006-Action_Elimination_and_Stopping_Conditions_for_the_Multi-Armed_Bandit_and_Reinforcement_Learning_Problems.html">jmlr-2006-Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems</a></p>
<p>Author: Eyal Even-Dar, Shie Mannor, Yishay Mansour</p><p>Abstract: We incorporate statistical conﬁdence intervals in both the multi-armed bandit and the reinforcement learning problems. In the bandit problem we show that given n arms, it sufﬁces to pull the arms a total of O (n/ε2 ) log(1/δ) times to ﬁnd an ε-optimal arm with probability of at least 1 − δ. This bound matches the lower bound of Mannor and Tsitsiklis (2004) up to constants. We also devise action elimination procedures in reinforcement learning algorithms. We describe a framework that is based on learning the conﬁdence interval around the value function or the Q-function and eliminating actions that are not optimal (with high probability). We provide a model-based and a model-free variants of the elimination method. We further derive stopping conditions guaranteeing that the learned policy is approximately optimal with high probability. Simulations demonstrate a considerable speedup and added robustness over ε-greedy Q-learning.</p><p>11 <a title="jmlr-2006-11" href="../jmlr2006/jmlr-2006-Active_Learning_in_Approximately_Linear_Regression_Based_on_Conditional_Expectation_of_Generalization_Error.html">jmlr-2006-Active Learning in Approximately Linear Regression Based on Conditional Expectation of Generalization Error</a></p>
<p>Author: Masashi Sugiyama</p><p>Abstract: The goal of active learning is to determine the locations of training input points so that the generalization error is minimized. We discuss the problem of active learning in linear regression scenarios. Traditional active learning methods using least-squares learning often assume that the model used for learning is correctly speciﬁed. In many practical situations, however, this assumption may not be fulﬁlled. Recently, active learning methods using “importance”-weighted least-squares learning have been proposed, which are shown to be robust against misspeciﬁcation of models. In this paper, we propose a new active learning method also using the weighted least-squares learning, which we call ALICE (Active Learning using the Importance-weighted least-squares learning based on Conditional Expectation of the generalization error). An important difference from existing methods is that we predict the conditional expectation of the generalization error given training input points, while existing methods predict the full expectation of the generalization error. Due to this difference, the training input design can be ﬁne-tuned depending on the realization of training input points. Theoretically, we prove that the proposed active learning criterion is a more accurate predictor of the single-trial generalization error than the existing criterion. Numerical studies with toy and benchmark data sets show that the proposed method compares favorably to existing methods. Keywords: Active Learning, Conditional Expectation of Generalization Error, Misspeciﬁcation of Models, Importance-Weighted Least-Squares Learning, Covariate Shift.</p><p>12 <a title="jmlr-2006-12" href="../jmlr2006/jmlr-2006-Active_Learning_with_Feedback_on_Features_and_Instances.html">jmlr-2006-Active Learning with Feedback on Features and Instances</a></p>
<p>Author: Hema Raghavan, Omid Madani, Rosie Jones</p><p>Abstract: We extend the traditional active learning framework to include feedback on features in addition to labeling instances, and we execute a careful study of the effects of feature selection and human feedback on features in the setting of text categorization. Our experiments on a variety of categorization tasks indicate that there is signiﬁcant potential in improving classiﬁer performance by feature re-weighting, beyond that achieved via membership queries alone (traditional active learning) if we have access to an oracle that can point to the important (most predictive) features. Our experiments on human subjects indicate that human feedback on feature relevance can identify a sufﬁcient proportion of the most relevant features (over 50% in our experiments). We ﬁnd that on average, labeling a feature takes much less time than labeling a document. We devise an algorithm that interleaves labeling features and documents which signiﬁcantly accelerates standard active learning in our simulation experiments. Feature feedback can complement traditional active learning in applications such as news ﬁltering, e-mail classiﬁcation, and personalization, where the human teacher can have signiﬁcant knowledge on the relevance of features. Keywords: active learning, feature selection, relevance feedback, term feedback, text classiﬁcation</p><p>13 <a title="jmlr-2006-13" href="../jmlr2006/jmlr-2006-Adaptive_Prototype_Learning_Algorithms%3A_Theoretical_and_Experimental_Studies.html">jmlr-2006-Adaptive Prototype Learning Algorithms: Theoretical and Experimental Studies</a></p>
<p>Author: Fu Chang, Chin-Chin Lin, Chi-Jen Lu</p><p>Abstract: In this paper, we propose a number of adaptive prototype learning (APL) algorithms. They employ the same algorithmic scheme to determine the number and location of prototypes, but differ in the use of samples or the weighted averages of samples as prototypes, and also in the assumption of distance measures. To understand these algorithms from a theoretical viewpoint, we address their convergence properties, as well as their consistency under certain conditions. We also present a soft version of APL, in which a non-zero training error is allowed in order to enhance the generalization power of the resultant classifier. Applying the proposed algorithms to twelve UCI benchmark data sets, we demonstrate that they outperform many instance-based learning algorithms, the k-nearest neighbor rule, and support vector machines in terms of average test accuracy. Keywords: adaptive prototype learning, cluster-based prototypes, consistency, instance-based prototype, pattern classification 1</p><p>14 <a title="jmlr-2006-14" href="../jmlr2006/jmlr-2006-An_Efficient_Implementation_of_an_Active_Set_Method_for_SVMs%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-An Efficient Implementation of an Active Set Method for SVMs    (Special Topic on Machine Learning and Optimization)</a></p>
<p>Author: Katya Scheinberg</p><p>Abstract: We propose an active set algorithm to solve the convex quadratic programming (QP) problem which is the core of the support vector machine (SVM) training. The underlying method is not new and is based on the extensive practice of the Simplex method and its variants for convex quadratic problems. However, its application to large-scale SVM problems is new. Until recently the traditional active set methods were considered impractical for large SVM problems. By adapting the methods to the special structure of SVM problems we were able to produce an efﬁcient implementation. We conduct an extensive study of the behavior of our method and its variations on SVM problems. We present computational results comparing our method with Joachims’ SVM light (see Joachims, 1999). The results show that our method has overall better performance on many SVM problems. It seems to have a particularly strong advantage on more difﬁcult problems. In addition this algorithm has better theoretical properties and it naturally extends to the incremental mode. Since the proposed method solves the standard SVM formulation, as does SVMlight , the generalization properties of these two approaches are identical and we do not discuss them in the paper. Keywords: active set methods, support vector machines, quadratic programming</p><p>15 <a title="jmlr-2006-15" href="../jmlr2006/jmlr-2006-Bayesian_Network_Learning_with_Parameter_Constraints_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Bayesian Network Learning with Parameter Constraints     (Special Topic on Machine Learning and Optimization)</a></p>
<p>Author: Radu Stefan Niculescu, Tom M. Mitchell, R. Bharat Rao</p><p>Abstract: The task of learning models for many real-world problems requires incorporating domain knowledge into learning algorithms, to enable accurate learning from a realistic volume of training data. This paper considers a variety of types of domain knowledge for constraining parameter estimates when learning Bayesian networks. In particular, we consider domain knowledge that constrains the values or relationships among subsets of parameters in a Bayesian network with known structure. We incorporate a wide variety of parameter constraints into learning procedures for Bayesian networks, by formulating this task as a constrained optimization problem. The assumptions made in module networks, dynamic Bayes nets and context speciﬁc independence models can be viewed as particular cases of such parameter constraints. We present closed form solutions or fast iterative algorithms for estimating parameters subject to several speciﬁc classes of parameter constraints, including equalities and inequalities among parameters, constraints on individual parameters, and constraints on sums and ratios of parameters, for discrete and continuous variables. Our methods cover learning from both frequentist and Bayesian points of view, from both complete and incomplete data. We present formal guarantees for our estimators, as well as methods for automatically learning useful parameter constraints from data. To validate our approach, we apply it to the domain of fMRI brain image analysis. Here we demonstrate the ability of our system to ﬁrst learn useful relationships among parameters, and then to use them to constrain the training of the Bayesian network, resulting in improved cross-validated accuracy of the learned model. Experiments on synthetic data are also presented. Keywords: Bayesian networks, constrained optimization, domain knowledge c 2006 Radu Stefan Niculescu, Tom Mitchell and Bharat Rao. N ICULESCU , M ITCHELL AND R AO</p><p>16 <a title="jmlr-2006-16" href="../jmlr2006/jmlr-2006-Bounds_for_Linear_Multi-Task_Learning.html">jmlr-2006-Bounds for Linear Multi-Task Learning</a></p>
<p>Author: Andreas Maurer</p><p>Abstract: We give dimension-free and data-dependent bounds for linear multi-task learning where a common linear operator is chosen to preprocess data for a vector of task speciﬁc linear-thresholding classiﬁers. The complexity penalty of multi-task learning is bounded by a simple expression involving the margins of the task-speciﬁc classiﬁers, the Hilbert-Schmidt norm of the selected preprocessor and the Hilbert-Schmidt norm of the covariance operator for the total mixture of all task distributions, or, alternatively, the Frobenius norm of the total Gramian matrix for the data-dependent version. The results can be compared to state-of-the-art results on linear single-task learning. Keywords: learning to learn, transfer learning, multi-task learning</p><p>17 <a title="jmlr-2006-17" href="../jmlr2006/jmlr-2006-Bounds_for_the_Loss_in_Probability_of_Correct_Classification_Under_Model_Based_Approximation.html">jmlr-2006-Bounds for the Loss in Probability of Correct Classification Under Model Based Approximation</a></p>
<p>Author: Magnus Ekdahl, Timo Koski</p><p>Abstract: In many pattern recognition/classiﬁcation problem the true class conditional model and class probabilities are approximated for reasons of reducing complexity and/or of statistical estimation. The approximated classiﬁer is expected to have worse performance, here measured by the probability of correct classiﬁcation. We present an analysis valid in general, and easily computable formulas for estimating the degradation in probability of correct classiﬁcation when compared to the optimal classiﬁer. An example of an approximation is the Na¨ve Bayes classiﬁer. We show that the perforı mance of the Na¨ve Bayes depends on the degree of functional dependence between the features ı and labels. We provide a sufﬁcient condition for zero loss of performance, too. Keywords: Bayesian networks, na¨ve Bayes, plug-in classiﬁer, Kolmogorov distance of variation, ı variational learning</p><p>18 <a title="jmlr-2006-18" href="../jmlr2006/jmlr-2006-Building_Support_Vector_Machines_with_Reduced_Classifier_Complexity_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Building Support Vector Machines with Reduced Classifier Complexity     (Special Topic on Machine Learning and Optimization)</a></p>
<p>Author: S. Sathiya Keerthi, Olivier Chapelle, Dennis DeCoste</p><p>Abstract: Support vector machines (SVMs), though accurate, are not preferred in applications requiring great classiﬁcation speed, due to the number of support vectors being large. To overcome this problem we devise a primal method with the following properties: (1) it decouples the idea of basis functions from the concept of support vectors; (2) it greedily ﬁnds a set of kernel basis functions of a speciﬁed maximum size (dmax ) to approximate the SVM primal cost function well; (3) it is 2 efﬁcient and roughly scales as O(ndmax ) where n is the number of training examples; and, (4) the number of basis functions it requires to achieve an accuracy close to the SVM accuracy is usually far less than the number of SVM support vectors. Keywords: SVMs, classiﬁcation, sparse design</p><p>19 <a title="jmlr-2006-19" href="../jmlr2006/jmlr-2006-Causal_Graph_Based_Decomposition_of_Factored_MDPs.html">jmlr-2006-Causal Graph Based Decomposition of Factored MDPs</a></p>
<p>Author: Anders Jonsson, Andrew Barto</p><p>Abstract: We present Variable Inﬂuence Structure Analysis, or VISA, an algorithm that performs hierarchical decomposition of factored Markov decision processes. VISA uses a dynamic Bayesian network model of actions, and constructs a causal graph that captures relationships between state variables. In tasks with sparse causal graphs VISA exploits structure by introducing activities that cause the values of state variables to change. The result is a hierarchy of activities that together represent a solution to the original task. VISA performs state abstraction for each activity by ignoring irrelevant state variables and lower-level activities. In addition, we describe an algorithm for constructing compact models of the activities introduced. State abstraction and compact activity models enable VISA to apply efﬁcient algorithms to solve the stand-alone subtask associated with each activity. Experimental results show that the decomposition introduced by VISA can signiﬁcantly accelerate construction of an optimal, or near-optimal, policy. Keywords: Markov decision processes, hierarchical decomposition, state abstraction</p><p>20 <a title="jmlr-2006-20" href="../jmlr2006/jmlr-2006-Collaborative_Multiagent_Reinforcement_Learning_by_Payoff_Propagation.html">jmlr-2006-Collaborative Multiagent Reinforcement Learning by Payoff Propagation</a></p>
<p>Author: Jelle R. Kok, Nikos Vlassis</p><p>Abstract: In this article we describe a set of scalable techniques for learning the behavior of a group of agents in a collaborative multiagent setting. As a basis we use the framework of coordination graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between agents to decompose the global payoff function into a sum of local terms. First, we deal with the single-state case and describe a payoff propagation algorithm that computes the individual actions that approximately maximize the global payoff function. The method can be viewed as the decision-making analogue of belief propagation in Bayesian networks. Second, we focus on learning the behavior of the agents in sequential decision-making tasks. We introduce different model-free reinforcementlearning techniques, unitedly called Sparse Cooperative Q-learning, which approximate the global action-value function based on the topology of a coordination graph, and perform updates using the contribution of the individual agents to the maximal global action value. The combined use of an edge-based decomposition of the action-value function and the payoff propagation algorithm for efﬁcient action selection, result in an approach that scales only linearly in the problem size. We provide experimental evidence that our method outperforms related multiagent reinforcement-learning methods based on temporal differences. Keywords: collaborative multiagent system, coordination graph, reinforcement learning, Qlearning, belief propagation</p><p>21 <a title="jmlr-2006-21" href="../jmlr2006/jmlr-2006-Computational_and_Theoretical_Analysis_of__Null_Space__and_Orthogonal_Linear_Discriminant_Analysis.html">jmlr-2006-Computational and Theoretical Analysis of  Null Space  and Orthogonal Linear Discriminant Analysis</a></p>
<p>22 <a title="jmlr-2006-22" href="../jmlr2006/jmlr-2006-Considering_Cost_Asymmetry_in_Learning_Classifiers.html">jmlr-2006-Considering Cost Asymmetry in Learning Classifiers</a></p>
<p>23 <a title="jmlr-2006-23" href="../jmlr2006/jmlr-2006-Consistency_and_Convergence_Rates_of_One-Class_SVMs_and_Related_Algorithms.html">jmlr-2006-Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</a></p>
<p>24 <a title="jmlr-2006-24" href="../jmlr2006/jmlr-2006-Consistency_of_Multiclass_Empirical_Risk_Minimization_Methods_Based_on_Convex_Loss.html">jmlr-2006-Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss</a></p>
<p>25 <a title="jmlr-2006-25" href="../jmlr2006/jmlr-2006-Distance_Patterns_in_Structural_Similarity.html">jmlr-2006-Distance Patterns in Structural Similarity</a></p>
<p>26 <a title="jmlr-2006-26" href="../jmlr2006/jmlr-2006-Efficient_Learning_of_Label_Ranking_by_Soft_Projections_onto_Polyhedra_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Efficient Learning of Label Ranking by Soft Projections onto Polyhedra     (Special Topic on Machine Learning and Optimization)</a></p>
<p>27 <a title="jmlr-2006-27" href="../jmlr2006/jmlr-2006-Ensemble_Pruning_Via_Semi-definite_Programming_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Ensemble Pruning Via Semi-definite Programming     (Special Topic on Machine Learning and Optimization)</a></p>
<p>28 <a title="jmlr-2006-28" href="../jmlr2006/jmlr-2006-Estimating_the_%22Wrong%22_Graphical_Model%3A_Benefits_in_the_Computation-Limited_Setting.html">jmlr-2006-Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting</a></p>
<p>29 <a title="jmlr-2006-29" href="../jmlr2006/jmlr-2006-Estimation_of_Gradients_and_Coordinate_Covariation_in_Classification.html">jmlr-2006-Estimation of Gradients and Coordinate Covariation in Classification</a></p>
<p>30 <a title="jmlr-2006-30" href="../jmlr2006/jmlr-2006-Evolutionary_Function_Approximation_for_Reinforcement_Learning.html">jmlr-2006-Evolutionary Function Approximation for Reinforcement Learning</a></p>
<p>31 <a title="jmlr-2006-31" href="../jmlr2006/jmlr-2006-Exact_1-Norm_Support_Vector_Machines_Via_Unconstrained_Convex_Differentiable_Minimization_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Exact 1-Norm Support Vector Machines Via Unconstrained Convex Differentiable Minimization     (Special Topic on Machine Learning and Optimization)</a></p>
<p>32 <a title="jmlr-2006-32" href="../jmlr2006/jmlr-2006-Expectation_Correction_for_Smoothed_Inference_in_Switching_Linear_Dynamical_Systems.html">jmlr-2006-Expectation Correction for Smoothed Inference in Switching Linear Dynamical Systems</a></p>
<p>33 <a title="jmlr-2006-33" href="../jmlr2006/jmlr-2006-Fast_SDP_Relaxations_of_Graph_Cut_Clustering%2C_Transduction%2C_and_Other_Combinatorial_Problems_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Fast SDP Relaxations of Graph Cut Clustering, Transduction, and Other Combinatorial Problems     (Special Topic on Machine Learning and Optimization)</a></p>
<p>34 <a title="jmlr-2006-34" href="../jmlr2006/jmlr-2006-Generalized_Bradley-Terry_Models_and_Multi-Class_Probability_Estimates.html">jmlr-2006-Generalized Bradley-Terry Models and Multi-Class Probability Estimates</a></p>
<p>35 <a title="jmlr-2006-35" href="../jmlr2006/jmlr-2006-Geometric_Variance_Reduction_in_Markov_Chains%3A_Application_to_Value_Function_and_Gradient_Estimation.html">jmlr-2006-Geometric Variance Reduction in Markov Chains: Application to Value Function and Gradient Estimation</a></p>
<p>36 <a title="jmlr-2006-36" href="../jmlr2006/jmlr-2006-In_Search_of_Non-Gaussian_Components_of_a_High-Dimensional_Distribution.html">jmlr-2006-In Search of Non-Gaussian Components of a High-Dimensional Distribution</a></p>
<p>37 <a title="jmlr-2006-37" href="../jmlr2006/jmlr-2006-Incremental_Algorithms_for_Hierarchical_Classification.html">jmlr-2006-Incremental Algorithms for Hierarchical Classification</a></p>
<p>38 <a title="jmlr-2006-38" href="../jmlr2006/jmlr-2006-Incremental_Support_Vector_Learning%3A_Analysis%2C_Implementation_and_Applications_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Incremental Support Vector Learning: Analysis, Implementation and Applications     (Special Topic on Machine Learning and Optimization)</a></p>
<p>39 <a title="jmlr-2006-39" href="../jmlr2006/jmlr-2006-Inductive_Synthesis_of_Functional_Programs%3A_An_Explanation_Based_Generalization_Approach_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">jmlr-2006-Inductive Synthesis of Functional Programs: An Explanation Based Generalization Approach     (Special Topic on Inductive Programming)</a></p>
<p>40 <a title="jmlr-2006-40" href="../jmlr2006/jmlr-2006-Infinite-%CF%83_Limits_For_Tikhonov_Regularization.html">jmlr-2006-Infinite-σ Limits For Tikhonov Regularization</a></p>
<p>41 <a title="jmlr-2006-41" href="../jmlr2006/jmlr-2006-Kernel-Based_Learning_of_Hierarchical_Multilabel_Classification_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Kernel-Based Learning of Hierarchical Multilabel Classification Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>42 <a title="jmlr-2006-42" href="../jmlr2006/jmlr-2006-Kernels_on_Prolog_Proof_Trees%3A_Statistical_Learning_in_the_ILP_Setting_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">jmlr-2006-Kernels on Prolog Proof Trees: Statistical Learning in the ILP Setting     (Special Topic on Inductive Programming)</a></p>
<p>43 <a title="jmlr-2006-43" href="../jmlr2006/jmlr-2006-Large_Scale_Multiple_Kernel_Learning_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Large Scale Multiple Kernel Learning     (Special Topic on Machine Learning and Optimization)</a></p>
<p>44 <a title="jmlr-2006-44" href="../jmlr2006/jmlr-2006-Large_Scale_Transductive_SVMs.html">jmlr-2006-Large Scale Transductive SVMs</a></p>
<p>45 <a title="jmlr-2006-45" href="../jmlr2006/jmlr-2006-Learning_Coordinate_Covariances_via_Gradients.html">jmlr-2006-Learning Coordinate Covariances via Gradients</a></p>
<p>46 <a title="jmlr-2006-46" href="../jmlr2006/jmlr-2006-Learning_Factor_Graphs_in_Polynomial_Time_and_Sample_Complexity.html">jmlr-2006-Learning Factor Graphs in Polynomial Time and Sample Complexity</a></p>
<p>47 <a title="jmlr-2006-47" href="../jmlr2006/jmlr-2006-Learning_Image_Components_for_Object_Recognition.html">jmlr-2006-Learning Image Components for Object Recognition</a></p>
<p>48 <a title="jmlr-2006-48" href="../jmlr2006/jmlr-2006-Learning_Minimum_Volume_Sets.html">jmlr-2006-Learning Minimum Volume Sets</a></p>
<p>49 <a title="jmlr-2006-49" href="../jmlr2006/jmlr-2006-Learning_Parts-Based_Representations_of_Data.html">jmlr-2006-Learning Parts-Based Representations of Data</a></p>
<p>50 <a title="jmlr-2006-50" href="../jmlr2006/jmlr-2006-Learning_Recursive_Control_Programs_from_Problem_Solving_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Inductive_Programming%29.html">jmlr-2006-Learning Recursive Control Programs from Problem Solving     (Special Topic on Inductive Programming)</a></p>
<p>51 <a title="jmlr-2006-51" href="../jmlr2006/jmlr-2006-Learning_Sparse_Representations_by_Non-Negative_Matrix_Factorization_and_Sequential_Cone_Programming_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Learning Sparse Representations by Non-Negative Matrix Factorization and Sequential Cone Programming     (Special Topic on Machine Learning and Optimization)</a></p>
<p>52 <a title="jmlr-2006-52" href="../jmlr2006/jmlr-2006-Learning_Spectral_Clustering%2C_With_Application_To_Speech_Separation.html">jmlr-2006-Learning Spectral Clustering, With Application To Speech Separation</a></p>
<p>53 <a title="jmlr-2006-53" href="../jmlr2006/jmlr-2006-Learning_a_Hidden_Hypergraph.html">jmlr-2006-Learning a Hidden Hypergraph</a></p>
<p>54 <a title="jmlr-2006-54" href="../jmlr2006/jmlr-2006-Learning_the_Structure_of_Linear_Latent_Variable_Models.html">jmlr-2006-Learning the Structure of Linear Latent Variable Models</a></p>
<p>55 <a title="jmlr-2006-55" href="../jmlr2006/jmlr-2006-Linear_Programming_Relaxations_and_Belief_Propagation_--_An_Empirical_Study_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Linear Programming Relaxations and Belief Propagation -- An Empirical Study     (Special Topic on Machine Learning and Optimization)</a></p>
<p>56 <a title="jmlr-2006-56" href="../jmlr2006/jmlr-2006-Linear_Programs_for_Hypotheses_Selection_in_Probabilistic_Inference_Models_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Linear Programs for Hypotheses Selection in Probabilistic Inference Models     (Special Topic on Machine Learning and Optimization)</a></p>
<p>57 <a title="jmlr-2006-57" href="../jmlr2006/jmlr-2006-Linear_State-Space_Models_for_Blind_Source_Separation.html">jmlr-2006-Linear State-Space Models for Blind Source Separation</a></p>
<p>58 <a title="jmlr-2006-58" href="../jmlr2006/jmlr-2006-Lower_Bounds_and_Aggregation_in_Density_Estimation.html">jmlr-2006-Lower Bounds and Aggregation in Density Estimation</a></p>
<p>59 <a title="jmlr-2006-59" href="../jmlr2006/jmlr-2006-Machine_Learning_for_Computer_Security%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_for_Computer_Security%29.html">jmlr-2006-Machine Learning for Computer Security    (Special Topic on Machine Learning for Computer Security)</a></p>
<p>60 <a title="jmlr-2006-60" href="../jmlr2006/jmlr-2006-Manifold__Regularization%3A_A_Geometric_Framework_for_Learning_from_Labeled_and_Unlabeled_Examples.html">jmlr-2006-Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</a></p>
<p>61 <a title="jmlr-2006-61" href="../jmlr2006/jmlr-2006-Maximum-Gain_Working_Set_Selection_for_SVMs_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Maximum-Gain Working Set Selection for SVMs     (Special Topic on Machine Learning and Optimization)</a></p>
<p>62 <a title="jmlr-2006-62" href="../jmlr2006/jmlr-2006-MinReg%3A_A_Scalable_Algorithm_for_Learning_Parsimonious_Regulatory_Networks_in_Yeast_and_Mammals.html">jmlr-2006-MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals</a></p>
<p>63 <a title="jmlr-2006-63" href="../jmlr2006/jmlr-2006-New_Algorithms_for_Efficient_High-Dimensional_Nonparametric_Classification.html">jmlr-2006-New Algorithms for Efficient High-Dimensional Nonparametric Classification</a></p>
<p>64 <a title="jmlr-2006-64" href="../jmlr2006/jmlr-2006-Noisy-OR_Component_Analysis_and_its_Application_to_Link_Analysis.html">jmlr-2006-Noisy-OR Component Analysis and its Application to Link Analysis</a></p>
<p>65 <a title="jmlr-2006-65" href="../jmlr2006/jmlr-2006-Nonparametric_Quantile_Estimation.html">jmlr-2006-Nonparametric Quantile Estimation</a></p>
<p>66 <a title="jmlr-2006-66" href="../jmlr2006/jmlr-2006-On_Model_Selection_Consistency_of_Lasso.html">jmlr-2006-On Model Selection Consistency of Lasso</a></p>
<p>67 <a title="jmlr-2006-67" href="../jmlr2006/jmlr-2006-On_Representing_and_Generating_Kernels_by_Fuzzy_Equivalence_Relations.html">jmlr-2006-On Representing and Generating Kernels by Fuzzy Equivalence Relations</a></p>
<p>68 <a title="jmlr-2006-68" href="../jmlr2006/jmlr-2006-On_the_Complexity_of_Learning_Lexicographic_Strategies.html">jmlr-2006-On the Complexity of Learning Lexicographic Strategies</a></p>
<p>69 <a title="jmlr-2006-69" href="../jmlr2006/jmlr-2006-One-Class_Novelty_Detection_for_Seizure_Analysis_from_Intracranial_EEG.html">jmlr-2006-One-Class Novelty Detection for Seizure Analysis from Intracranial EEG</a></p>
<p>70 <a title="jmlr-2006-70" href="../jmlr2006/jmlr-2006-Online_Passive-Aggressive_Algorithms.html">jmlr-2006-Online Passive-Aggressive Algorithms</a></p>
<p>71 <a title="jmlr-2006-71" href="../jmlr2006/jmlr-2006-Optimising_Kernel_Parameters_and_Regularisation_Coefficients_for_Non-linear_Discriminant_Analysis.html">jmlr-2006-Optimising Kernel Parameters and Regularisation Coefficients for Non-linear Discriminant Analysis</a></p>
<p>72 <a title="jmlr-2006-72" href="../jmlr2006/jmlr-2006-Parallel_Software_for_Training_Large_Scale_Support_Vector_Machines_on_Multiprocessor_Systems_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Parallel Software for Training Large Scale Support Vector Machines on Multiprocessor Systems     (Special Topic on Machine Learning and Optimization)</a></p>
<p>73 <a title="jmlr-2006-73" href="../jmlr2006/jmlr-2006-Pattern_Recognition_for__Conditionally_Independent_Data.html">jmlr-2006-Pattern Recognition for  Conditionally Independent Data</a></p>
<p>74 <a title="jmlr-2006-74" href="../jmlr2006/jmlr-2006-Point-Based_Value_Iteration_for_Continuous_POMDPs.html">jmlr-2006-Point-Based Value Iteration for Continuous POMDPs</a></p>
<p>75 <a title="jmlr-2006-75" href="../jmlr2006/jmlr-2006-Policy_Gradient_in_Continuous_Time.html">jmlr-2006-Policy Gradient in Continuous Time</a></p>
<p>76 <a title="jmlr-2006-76" href="../jmlr2006/jmlr-2006-QP_Algorithms_with_Guaranteed_Accuracy_and_Run_Time_for_Support_Vector_Machines.html">jmlr-2006-QP Algorithms with Guaranteed Accuracy and Run Time for Support Vector Machines</a></p>
<p>77 <a title="jmlr-2006-77" href="../jmlr2006/jmlr-2006-Quantile_Regression_Forests.html">jmlr-2006-Quantile Regression Forests</a></p>
<p>78 <a title="jmlr-2006-78" href="../jmlr2006/jmlr-2006-Rearrangement_Clustering%3A_Pitfalls%2C_Remedies%2C_and_Applications.html">jmlr-2006-Rearrangement Clustering: Pitfalls, Remedies, and Applications</a></p>
<p>79 <a title="jmlr-2006-79" href="../jmlr2006/jmlr-2006-Second_Order_Cone_Programming_Approaches_for_Handling_Missing_and_Uncertain_Data_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Second Order Cone Programming Approaches for Handling Missing and Uncertain Data     (Special Topic on Machine Learning and Optimization)</a></p>
<p>80 <a title="jmlr-2006-80" href="../jmlr2006/jmlr-2006-Segmental_Hidden_Markov_Models_with_Random_Effects_for_Waveform_Modeling.html">jmlr-2006-Segmental Hidden Markov Models with Random Effects for Waveform Modeling</a></p>
<p>81 <a title="jmlr-2006-81" href="../jmlr2006/jmlr-2006-Some_Discriminant-Based_PAC_Algorithms.html">jmlr-2006-Some Discriminant-Based PAC Algorithms</a></p>
<p>82 <a title="jmlr-2006-82" href="../jmlr2006/jmlr-2006-Some_Theory_for_Generalized_Boosting_Algorithms.html">jmlr-2006-Some Theory for Generalized Boosting Algorithms</a></p>
<p>83 <a title="jmlr-2006-83" href="../jmlr2006/jmlr-2006-Sparse_Boosting.html">jmlr-2006-Sparse Boosting</a></p>
<p>84 <a title="jmlr-2006-84" href="../jmlr2006/jmlr-2006-Stability_Properties_of_Empirical_Risk_Minimization_over_Donsker_Classes.html">jmlr-2006-Stability Properties of Empirical Risk Minimization over Donsker Classes</a></p>
<p>85 <a title="jmlr-2006-85" href="../jmlr2006/jmlr-2006-Statistical_Comparisons_of_Classifiers_over_Multiple_Data_Sets.html">jmlr-2006-Statistical Comparisons of Classifiers over Multiple Data Sets</a></p>
<p>86 <a title="jmlr-2006-86" href="../jmlr2006/jmlr-2006-Step_Size_Adaptation_in_Reproducing_Kernel_Hilbert_Space.html">jmlr-2006-Step Size Adaptation in Reproducing Kernel Hilbert Space</a></p>
<p>87 <a title="jmlr-2006-87" href="../jmlr2006/jmlr-2006-Stochastic_Complexities_of_Gaussian_Mixtures_in_Variational_Bayesian_Approximation.html">jmlr-2006-Stochastic Complexities of Gaussian Mixtures in Variational Bayesian Approximation</a></p>
<p>88 <a title="jmlr-2006-88" href="../jmlr2006/jmlr-2006-Streamwise_Feature_Selection.html">jmlr-2006-Streamwise Feature Selection</a></p>
<p>89 <a title="jmlr-2006-89" href="../jmlr2006/jmlr-2006-Structured_Prediction%2C_Dual_Extragradient_and_Bregman_Projections_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-Structured Prediction, Dual Extragradient and Bregman Projections     (Special Topic on Machine Learning and Optimization)</a></p>
<p>90 <a title="jmlr-2006-90" href="../jmlr2006/jmlr-2006-Superior_Guarantees_for_Sequential_Prediction_and_Lossless_Compression_via_Alphabet_Decomposition.html">jmlr-2006-Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition</a></p>
<p>91 <a title="jmlr-2006-91" href="../jmlr2006/jmlr-2006-The_Interplay_of_Optimization_and_Machine_Learning_Research_%C2%A0%C2%A0%C2%A0%C2%A0%28Special_Topic_on_Machine_Learning_and_Optimization%29.html">jmlr-2006-The Interplay of Optimization and Machine Learning Research     (Special Topic on Machine Learning and Optimization)</a></p>
<p>92 <a title="jmlr-2006-92" href="../jmlr2006/jmlr-2006-Toward_Attribute_Efficient_Learning_of_Decision_Lists_and_Parities.html">jmlr-2006-Toward Attribute Efficient Learning of Decision Lists and Parities</a></p>
<p>93 <a title="jmlr-2006-93" href="../jmlr2006/jmlr-2006-Universal_Kernels.html">jmlr-2006-Universal Kernels</a></p>
<p>94 <a title="jmlr-2006-94" href="../jmlr2006/jmlr-2006-Using_Machine_Learning_to_Guide_Architecture_Simulation.html">jmlr-2006-Using Machine Learning to Guide Architecture Simulation</a></p>
<p>95 <a title="jmlr-2006-95" href="../jmlr2006/jmlr-2006-Walk-Sums_and_Belief_Propagation_in_Gaussian_Graphical_Models.html">jmlr-2006-Walk-Sums and Belief Propagation in Gaussian Graphical Models</a></p>
<p>96 <a title="jmlr-2006-96" href="../jmlr2006/jmlr-2006-Worst-Case_Analysis_of_Selective_Sampling_for_Linear_Classification.html">jmlr-2006-Worst-Case Analysis of Selective Sampling for Linear Classification</a></p>
<p>97 <a title="jmlr-2006-97" href="../jmlr2006/jmlr-2006-%C2%A0%28Special_Topic_on_Machine_Learning_for_Computer_Security%29.html">jmlr-2006- (Special Topic on Machine Learning for Computer Security)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
