<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 jmlr-2013-Learning Trees from Strings: A Strong Learning Algorithm for some Context-Free Grammars</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-63" href="../jmlr2013/jmlr-2013-Learning_Trees_from_Strings%3A_A_Strong_Learning_Algorithm_for_some_Context-Free_Grammars.html">jmlr2013-63</a> <a title="jmlr-2013-63-reference" href="#">jmlr2013-63-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>63 jmlr-2013-Learning Trees from Strings: A Strong Learning Algorithm for some Context-Free Grammars</h1>
<br/><p>Source: <a title="jmlr-2013-63-pdf" href="http://jmlr.org/papers/volume14/clark13a/clark13a.pdf">pdf</a></p><p>Author: Alexander Clark</p><p>Abstract: Standard models of language learning are concerned with weak learning: the learner, receiving as input only information about the strings in the language, must learn to generalise and to generate the correct, potentially inﬁnite, set of strings generated by some target grammar. Here we deﬁne the corresponding notion of strong learning: the learner, again only receiving strings as input, must learn a grammar that generates the correct set of structures or parse trees. We formalise this using a modiﬁcation of Gold’s identiﬁcation in the limit model, requiring convergence to a grammar that is isomorphic to the target grammar. We take as our starting point a simple learning algorithm for substitutable context-free languages, based on principles of distributional learning, and modify it so that it will converge to a canonical grammar for each language. We prove a corresponding strong learning result for a subclass of context-free grammars. Keywords: context-free grammars, grammatical inference, identiﬁcation in the limit, structure learning</p><br/>
<h2>reference text</h2><p>D. Angluin. Inference of reversible languages. Journal of the ACM, 29(3):741–765, 1982. R.C. Berwick, P. Pietroski, B. Yankama, and N. Chomsky. Poverty of the stimulus revisited. Cognitive Science, 35:1207–1242, 2011. L. Blum and M. Blum. Toward a mathematical theory of inductive inference. Information and Control, 28(2):125–155, 1975. J. Case and C. Lynes. Machine inductive inference and language identiﬁcation. Automata, Languages and Programming, pages 107–115, 1982. A. Clark. A language theoretic approach to syntactic structure. In Makoto Kanazawa, Andr´ s a Kornai, Marcus Kracht, and Hiroyuki Seki, editors, The Mathematics of Language, pages 39–56. Springer Berlin Heidelberg, 2011. A. Clark. The syntactic concept lattice: Another algebraic theory of the context-free languages? Journal of Logic and Computation, 2013. doi: 10.1093/logcom/ext037. A. Clark and R. Eyraud. Polynomial identiﬁcation in the limit of substitutable context-free languages. Journal of Machine Learning Research, 8:1725–1745, August 2007. T. Cohn, P. Blunsom, and S. Goldwater. Inducing tree-substitution grammars. Journal of Machine Learning Research, 11:3053–3096, 2010. 3557  C LARK  F. Drewes and J. H¨ gberg. Learning a regular tree language from a teacher. In Zolt´ n Esik and o a ´ Zolt´ n F¨ l¨ p, editors, Developments in Language Theory, pages 279–291. Springer Berlin Heia uo delberg, 2003. H. Enderton. A Mathematical Introduction to Logic. Academic press, 2001. S. Ginsburg. The Mathematical Theory of Context-Free Languages. McGraw-Hill, New York, 1966. E. Mark Gold. Language identiﬁcation in the limit. Information and Control, 10:447–474, 1967. D. Hsu, S. M. Kakade, and P. Liang. Identiﬁability and unmixing of latent parse trees. In Advances in Neural Information Processing Systems (NIPS), pages 1520–1528, 2013. M. Kanazawa and S. Salvati. MIX is not a tree-adjoining language. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 666–674. Association for Computational Linguistics, 2012. D. L´ pez, J.M. Sempere, and P. Garc´a. Inference of reversible tree languages. Systems, Man, and o ı Cybernetics, Part B: Cybernetics, IEEE Transactions on, 34(4):1658–1665, 2004. P.H. Miller. Strong Generative Capacity: The Semantics of Linguistic Formalism. CSLI Publications, Stanford, CA, 1999. D. Osherson, M. Stob, and S. Weinstein. Systems that Learn: An Introduction to Learning Theory for Cognitive and Computer Scientists. MIT Press, ﬁrst edition, 1986. T. Petrie. Probabilistic functions of ﬁnite state Markov chains. The Annals of Mathematical Statistics, 40(1):97–115, 1969. R.C. Read and D.G. Corneil. The graph isomorphism disease. Journal of Graph Theory, 1(4): 339–363, 1977. Y. Sakakibara. Learning context-free grammars from structural data in polynomial time. Theoretical Computer Science, 76(2):223–242, 1990. Y. Sakakibara. Efﬁcient learning of context-free grammars from positive structural examples. Information and Computation, 97(1):23 – 60, 1992. R. E. Schapire. A brief introduction to boosting. In Proceedings of 16th International Joint Conference on Artiﬁcal Intelligence, pages 1401–1406, 1999. H. Seki, T. Matsumura, M. Fujii, and T. Kasami. On multiple context-free grammars. Theoretical Computer Science, 88(2):229, 1991. M. Wakatsuki and E. Tomita. A fast algorithm for checking the inclusion for very simple deterministic pushdown automata. IEICE TRANSACTIONS on Information and Systems, 76(10): 1224–1233, 1993. K. Wexler and P. W. Culicover. Formal Principles of Language Acquisition. MIT Press, Cambridge, MA, 1980. 3558  L EARNING T REES FROM S TRINGS  R. Yoshinaka. Identiﬁcation in the Limit of k-l-Substitutable Context-Free Languages. In Alexander Clark, Francois Coste, and Laurent Miclet, editors, Grammatical Inference: Algorithms and ¸ Applications, pages 266–279. Springer Berlin Heidelberg, 2008. R. Yoshinaka. Efﬁcient learning of multiple context-free languages with multidimensional substitutability from positive data. Theoretical Computer Science, 412(19):1821 – 1831, 2011. R. Yoshinaka. Integration of the dual approaches in the distributional learning of context-free grammars. In Adrian-Horia Dediu and Carlos Mart´n-Vide, editors, Language and Automata Theory ı and Applications, pages 538–550. Springer Berlin Heidelberg, 2012. R. Yoshinaka and M. Kanazawa. Distributional learning of abstract categorial grammars. In Sylvain Pogodalla and Jean-Philippe Prost, editors, Logical Aspects of Computational Linguistics, pages 251–266. Springer Berlin Heidelberg, 2011. V.N. Zemlyachenko, N.M. Korneenko, and R.I. Tyshkevich. Graph isomorphism problem. Journal of Mathematical Sciences, 29(4):1426–1481, 1985.  3559</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
