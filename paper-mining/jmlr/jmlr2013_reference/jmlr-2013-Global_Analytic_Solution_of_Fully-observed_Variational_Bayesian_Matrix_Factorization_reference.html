<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>49 jmlr-2013-Global Analytic Solution of Fully-observed Variational Bayesian Matrix Factorization</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-49" href="../jmlr2013/jmlr-2013-Global_Analytic_Solution_of_Fully-observed_Variational_Bayesian_Matrix_Factorization.html">jmlr2013-49</a> <a title="jmlr-2013-49-reference" href="#">jmlr2013-49-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>49 jmlr-2013-Global Analytic Solution of Fully-observed Variational Bayesian Matrix Factorization</h1>
<br/><p>Source: <a title="jmlr-2013-49-pdf" href="http://jmlr.org/papers/volume14/nakajima13a/nakajima13a.pdf">pdf</a></p><p>Author: Shinichi Nakajima, Masashi Sugiyama, S. Derin Babacan, Ryota Tomioka</p><p>Abstract: The variational Bayesian (VB) approximation is known to be a promising approach to Bayesian estimation, when the rigorous calculation of the Bayes posterior is intractable. The VB approximation has been successfully applied to matrix factorization (MF), offering automatic dimensionality selection for principal component analysis. Generally, ﬁnding the VB solution is a non-convex problem, and most methods rely on a local search algorithm derived through a standard procedure for the VB approximation. In this paper, we show that a better option is available for fully-observed VBMF—the global solution can be analytically computed. More speciﬁcally, the global solution is a reweighted SVD of the observed matrix, and each weight can be obtained by solving a quartic equation with its coefﬁcients being functions of the observed singular value. We further show that the global optimal solution of empirical VBMF (where hyperparameters are also learned from data) can also be analytically computed. We illustrate the usefulness of our results through experiments in multi-variate analysis. Keywords: variational Bayes, matrix factorization, empirical Bayes, model-induced regularization, probabilistic PCA</p><br/>
<h2>reference text</h2><p>T. W. Anderson. An Introduction to Multivariate Statistical Analysis. Wiley, New York, second edition, 1984. A. Asuncion and D.J. Newman. UCI machine learning repository, 2007. http://www.ics.uci.edu/˜mlearn/MLRepository.html.  URL  H. Attias. Inferring parameters and structure of latent variable models by variational Bayes. In Proceedings of the Fifteenth Conference Annual Conference on Uncertainty in Artiﬁcial Intelligence (UAI-99), pages 21–30, San Francisco, CA, 1999. Morgan Kaufmann. S. D. Babacan, M. Luessi, R. Molina, and A. K. Katsaggelos. Sparse Bayesian methods for low-rank matrix estimation. IEEE Trans. on Signal Processing, 60(8):3964–3977, 2012. P. F. Baldi and K. Hornik. Learning in linear neural networks: A survey. IEEE Transactions on Neural Networks, 6(4):837–858, 1995. 34  G LOBAL A NALYTIC S OLUTION OF VARIATIONAL BAYESIAN M ATRIX FACTORIZATION  J. Besag. On the statistical analysis of dirty pictures. Journal of the Royal Statistical Society B, 48: 259–302, 1986. C. M. Bishop. Variational principal components. In Proc. of ICANN, volume 1, pages 514–509, 1999. C. M. Bishop. Pattern Recognition and Machine Learning. Springer, New York, NY, USA, 2006. J. F. Cai, E. J. Candes, and Z. Shen. A singular value thresholding algorithm for matrix completion. SIAM Journal on Optimization, 20(4):1956–1982, 2010. E. J. Candes, X. Li, Y. Ma, and J. Wright. abs/0912.3599, 2009.  Robust principal component analysis?  CoRR,  J. D. Carroll and J. J. Chang. Analysis of individual differences in multidimensional scaling via an N-way generalization of ’Eckart-Young’ decomposition. Psychometrika, 35:283–319, 1970. S. Funk. Try this at home. http://sifter.org/˜simon/journal/20061211.html, 2006. D. R. Hardoon, S. R. Szedmak, and J. R. Shawe-Taylor. Canonical correlation analysis: An overview with application to learning methods. Neural Computation, 16(12):2639–2664, 2004. R. A. Harshman. Foundations of the parafac procedure: Models and conditions for an ”explanatory” multimodal factor analysis. UCLA Working Papers in Phonetics, 16:1–84, 1970. M. Hazewinkel, editor. Encyclopaedia of Mathematics. Springer, 2002. H. Hotelling. Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24:417–441, 1933. H. Hotelling. Relations between two sets of variates. Biometrika, 28(3–4):321–377, 1936. A. Hyv¨ rinen, J. Karhunen, and E. Oja. Independent Component Analysis. Wiley, New York, 2001. a A. Ilin and T. Raiko. Practical approaches to principal component analysis in the presence of missing values. JMLR, 11:1957–2000, 2010. W. James and C. Stein. Estimation with quadratic loss. In Proceedings of the 4th Berkeley Symposium on Mathematical Statistics and Probability, volume 1, pages 361–379, Berkeley, CA., USA, 1961. University of California Press. H. Jeffreys. An invariant form for the prior probability in estimation problems. In Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, volume 186, pages 453–461, 1946. S. Ji and J. Ye. An accelerated gradient method for trace norm minimization. In Proceedings of International Conference on Machine Learning, pages 457–464, 2009. T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM Review, 51(3):455– 500, 2009. 35  NAKAJIMA , S UGIYAMA , BABACAN AND T OMIOKA  J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl. Grouplens: Applying collaborative ﬁltering to Usenet news. Communications of the ACM, 40(3):77–87, 1997. Y. J. Lim and T. W. Teh. Variational Bayesian approach to movie rating prediction. In Proceedings of KDD Cup and Workshop, 2007. D.  J. C. Mackay. Local minima, symmetry-breaking, and pruning in variational free energy minimization. Available http://www.inference.phy.cam.ac.uk/mackay/minima.pdf. 2001.  model from  A. W. Marshall, I. Olkin, and B. C. Arnold. Inequalities: Theory of Majorization and Its Applications, Second Edition. Springer, 2009. R. Mazumder, T. Hastie, and R. Tibshirani. Spectral regularization algorithms for learning large incomplete matrices. Journal of Machine Learning Research, 11:2287–2322, 2010. S. Nakajima. Variational Bayesian algorithm for relational tensor factorization. Under Preparation, 2012. S. Nakajima and M. Sugiyama. Theoretical analysis of Bayesian matrix factorization. Journal of Machine Learning Research, 12:2579–2644, 2011. S. Nakajima, M. Sugiyama, and R. Tomioka. Global analytic solution for variational Bayesian matrix factorization. In Advances in Neural Information Processing Systems 23, pages 1759– 1767, 2010. S. Nakajima, M. Sugiyama, and S. D. Babacan. Global solution of fully-observed variational Bayesian matrix factorization is column-wise independent. In Advances in Neural Information Processing Systems 24, 2011. S. Nakajima, M. Sugiyama, and S. D. Babacan. Sparse additive matrix factorization for robust PCA and its generalization. In Proceedings of Fourth Asian Conference on Machine Learning, 2012a. S. Nakajima, R. Tomioka, M. Sugiyama, and S. D. Babacan. Perfect dimensionality recovery by variational Bayesian PCA. In Advances in Neural Information Processing Systems 25, 2012b. A. Paterek. Improving regularized singular value decomposition for collaborative ﬁltering. In Proceedings of KDD Cup and Workshop, 2007. G. R. Reinsel and R. P. Velu. Multivariate Reduced-Rank Regression: Theory and Applications. Springer, New York, 1998. J. D. M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative prediction. In Proceedings of the 22nd International Conference on Machine learning, pages 713–719, 2005. R. Rosipal and N. Kr¨ mer. Overview and recent advances in partial least squares. In C. Saunders, a M. Grobelnik, S. Gunn, and J. Shawe-Taylor, editors, Subspace, Latent Structure and Feature Selection Techniques, volume 3940 of Lecture Notes in Computer Science, pages 34–51, Berlin, 2006. Springer. 36  G LOBAL A NALYTIC S OLUTION OF VARIATIONAL BAYESIAN M ATRIX FACTORIZATION  A. Ruhe. Perturbation bounds for means of eigenvalues and invariant subspaces. BIT Numerical Mathematics, 10:343–354, 1970. R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In J. C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 1257– 1264, Cambridge, MA, 2008. MIT Press. M. Seeger and G. Bouchard. Fast variational Bayesian inference for non-conjugate matrix factorization models. In Proc. of AISTATS, La Palma, Spain, 2012. N. Srebro, J. Rennie, and T. Jaakkola. Maximum margin matrix factorization. In Advances in Neural Information Processing Systems 17, 2005. G. W. Stewart. On the early history of the singular value decomposition. SIAM Review, 35(4): 551–556, 1993. M. E. Tipping and C. M. Bishop. Probabilistic principal component analysis. Journal of the Royal Statistical Society, 61:611–622, 1999. R. Tomioka, T. Suzuki, M. Sugiyama, and H. Kashima. An efﬁcient and general augmented Lagrangian algorithm for learning low-rank matrices. In Proceedings of International Conference on Machine Learning, 2010. L. R. Tucker. Some mathematical notes on three-mode factor analysis. Psychometrika, 31:279–311, 1996. S. Watanabe. Algebraic Geometry and Statistical Learning. Cambridge University Press, Cambridge, UK, 2009. K. J. Worsley, J-B. Poline, K. J. Friston, and A. C. Evanss. Characterizing the response of PET and fMRI data using multivariate linear models. NeuroImage, 6(4):305–319, 1997.  37</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
