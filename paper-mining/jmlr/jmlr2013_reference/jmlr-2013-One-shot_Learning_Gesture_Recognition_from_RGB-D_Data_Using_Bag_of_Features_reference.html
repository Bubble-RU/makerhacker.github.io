<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>80 jmlr-2013-One-shot Learning Gesture Recognition from RGB-D Data Using Bag of Features</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-80" href="../jmlr2013/jmlr-2013-One-shot_Learning_Gesture_Recognition_from_RGB-D_Data_Using_Bag_of_Features.html">jmlr2013-80</a> <a title="jmlr-2013-80-reference" href="#">jmlr2013-80-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>80 jmlr-2013-One-shot Learning Gesture Recognition from RGB-D Data Using Bag of Features</h1>
<br/><p>Source: <a title="jmlr-2013-80-pdf" href="http://jmlr.org/papers/volume14/wan13a/wan13a.pdf">pdf</a></p><p>Author: Jun Wan, Qiuqi Ruan, Wei Li, Shuang Deng</p><p>Abstract: For one-shot learning gesture recognition, two important challenges are: how to extract distinctive features and how to learn a discriminative model from only one training sample per gesture class. For feature extraction, a new spatio-temporal feature representation called 3D enhanced motion scale-invariant feature transform (3D EMoSIFT) is proposed, which fuses RGB-D data. Compared with other features, the new feature set is invariant to scale and rotation, and has more compact and richer visual representations. For learning a discriminative model, all features extracted from training samples are clustered with the k-means algorithm to learn a visual codebook. Then, unlike the traditional bag of feature (BoF) models using vector quantization (VQ) to map each feature into a certain visual codeword, a sparse coding method named simulation orthogonal matching pursuit (SOMP) is applied and thus each feature can be represented by some linear combination of a small number of codewords. Compared with VQ, SOMP leads to a much lower reconstruction error and achieves better performance. The proposed approach has been evaluated on ChaLearn gesture database and the result has been ranked amongst the top best performing techniques on ChaLearn gesture challenge (round 2). Keywords: gesture recognition, bag of features (BoF) model, one-shot learning, 3D enhanced motion scale invariant feature transform (3D EMoSIFT), Simulation Orthogonal Matching Pursuit (SOMP)</p><br/>
<h2>reference text</h2><p>G. Bradski. The OpenCV Library. Dr. Dobb’s Journal of Software Tools, 2000. 2578  O NE - SHOT L EARNING G ESTURE R ECOGNITION FROM RGB-D DATA U SING BAG OF F EATURES  M. Brand, N. Oliver, and A. Pentland. Coupled hidden markov models for complex action recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 994–999, 1997. C.C. Chang and C.J. Lin. Libsvm: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2(3):27:1–27:27, 2011. F.S. Chen, C.M. Fu, and C.L. Huang. Hand gesture recognition using a real-time tracking method and hidden markov models. Image and Vision Computing, 21:745–758, 2003. M. Chen and A. Hauptmann. Mosift: Recognizing human actions in surveillance videos. Technical Report, 2009. H. Cooper, E.J. Ong, N. Pugeault, and R. Bowden. Sign language recognition using sub-units. Journal of Machine Learning Research, 13:2205–2231, 2012. A. Corradini. Dynamic time warping for off-line recognition of a small gesture vocabulary. In Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems, IEEE ICCV Workshop on, pages 82–89, 2001. N.H. Dardas and N.D. Georganas. Real-time hand gesture detection and recognition using bagof-features and support vector machine techniques. IEEE Transactions on Instrumentation and Measurement, 60(11):3592–3607, 2011. P. Doll´ r, V. Rabaud, G. Cottrell, and S. Belongie. Behavior recognition via sparse spatio-temporal a features. In Proceedings of IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance, pages 65–72, 2005. H.J. Escalante and I. Guyon. Principal motion: Pca-based reconstruction of motion histograms. Technical Memorandum, 2012. L. Fei-Fei and P. Perona. A bayesian hierarchical model for learning natural scene categories. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, volume 2, pages 524–531, 2005. F. Fl´ rez, J.M. Garc´a, J. Garc´a, and A. Hern´ ndez. Hand gesture recognition following the dyo ı ı a namics of a topology-preserving network. In Proceedings of IEEE International Conference on Automatic Face and Gesture Recognition, pages 318–323, 2002. P.-E. Forssen and D.G. Lowe. Shape descriptors for maximally stable extremal regions. In Computer Vision, IEEE 11th International Conference on, pages 1–8, 2007. W.T. Freeman and M. Roth. Orientation histograms for hand gesture recognition. In Proceedings of IEEE International Workshop on Automatic Face and Gesture Recognition, volume 12, pages 296–301, 1995. W. Gao, G. Fang, D. Zhao, and Y. Chen. A chinese sign language recognition system based on sofm/srn/hmm. Pattern Recognition, 37(12):2389–2402, 2004. T. Guha and R.K. Ward. Learning sparse representations for human action recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(8):1576–1588, 2012. 2579  WAN , RUAN , D ENG AND L I  S. Guo, Z. Wang, and Q. Ruan. Enhancing sparsity via ℓ p (0 <1) minimization for robust face recognition. Neurocomputing, 99:592–602, 2013. I. Guyon, V. Athitsos, P. Jangyodsuk, B. Hamner, and H.J. Escalante. Chalearn gesture challenge: Design and ﬁrst results. In Computer Vision and Pattern Recognition Workshops, IEEE Conference on, pages 1–6, 2012. I. Guyon, V. Athitsos, P. Jangyodsuk, H.J. Escalante, and B. Hamner. Results and analysis of the chalearn gesture challenge 2012. Technical Report, 2013. C. Harris and M. Stephens. A combined corner and edge detector. In Proceedings of Alvey Vision Conference, volume 15, page 50, 1988. A. Hern´ ndez-Vela, M. A. Bautista, X. Perez-Sala, V. Ponce, X. Bar´ , O. Pujol, C. Angulo, and a o S. Escalera. Bovdw: Bag-of-visual-and-depth-words for gesture recognition. Pattern Recognition (ICPR), 21st International Conference on, 2012. D. Kim, J. Song, and D. Kim. Simultaneous gesture segmentation and recognition based on forward spotting accumulative hmms. Pattern Recognition, 40(11):3012–3026, 2007. I. Laptev. On space-time interest points. International Journal of Computer Vision, 64(2):107–123, 2005. J.F. Lichtenauer, E.A. Hendriks, and M. J T Reinders. Sign language recognition by combining statistical dtw and independent classiﬁcation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 30(11):2040–2046, 2008. Y. Linde, A. Buzo, and R. Gray. An algorithm for vector quantizer design. Communications, IEEE Transactions on, 28(1):84–95, 1980. D.G. Lowe. Distinctive image features from scale-invariant keypoints. International Journal of Computer Vision, 60(2):91–110, 2004. B.D. Lucas, T. Kanade, et al. An iterative image registration technique with an application to stereo vision. In Proceedings of the 7th International Joint Conference on Artiﬁcial Intelligence, 1981. Yui Man Lui. Human gesture recognition on product manifolds. Journal of Machine Learning Research, 13:3297–3321, 2012. M.R. Malgireddy, I. Inwogu, and V. Govindaraju. A temporal bayesian model for classifying, detecting and localizing activities in video sequences. In Computer Vision and Pattern Recognition Workshops, IEEE Conference on, pages 43–48, 2012. A. Malima, E. Ozgur, and M. Cetin. A fast algorithm for vision-based hand gesture recognition ¸ for robot control. In Proceedings of IEEE Signal Processing and Communications Applications, pages 1–4, 2006. Y. Ming, Q. Ruan, and A.G. Hauptmann. Activity recognition from rgb-d camera with 3d local spatio-temporal features. In Proceedings of IEEE International Conference on Multimedia and Expo, pages 344–349, 2012. 2580  O NE - SHOT L EARNING G ESTURE R ECOGNITION FROM RGB-D DATA U SING BAG OF F EATURES  L.P. Morency, A. Quattoni, and T. Darrell. Latent-dynamic discriminative models for continuous gesture recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 1–8, 2007. B.A. Olshausen, D.J. Field, et al. Sparse coding with an overcomplete basis set: A strategy employed by vi? Vision Research, 37(23):3311–3326, 1997. V.I. Pavlovic, R. Sharma, and T.S. Huang. Visual interpretation of hand gestures for humancomputer interaction: a review. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19:677–695, 1997. A. Rakotomamonjy. Surveying and comparing simultaneous sparse approximation (or group-lasso) algorithms. Signal Processing, 91(7):1505–1526, 2011. S. Reiﬁnger, F. Wallhoff, M. Ablassmeier, T. Poitschke, and G. Rigoll. Static and dynamic handgesture recognition for augmented reality applications. In Proceedings of the 12th International Conference on Human-computer Interaction: Intelligent Multimodal Interaction Environments, pages 728–737, 2007. Y. Ruiduo, S. Sarkar, and B. Loeding. Enhanced level building algorithm for the movement epenthesis problem in sign language recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 1–8, 2007. C. Shan, T. Tan, and Y. Wei. Real-time hand tracking using a mean shift embedded particle ﬁlter. Pattern Recognition, 40(7):1958–1970, 2007. X. Shen, G. Hua, L. Williams, and Y. Wu. Dynamic hand gesture recognition: An exemplar-based approach from motion divergence ﬁelds. Image and Vision Computing, 30(3):227–235, 2012. C. Sminchisescu, A. Kanaujia, Zhiguo Li, and D. Metaxas. Conditional models for contextual human motion recognition. In Computer Vision, Tenth IEEE International Conference on, volume 2, pages 1808–1815, 2005. H.I. Suk, B.K. Sin, and S.W. Lee. Hand gesture recognition based on dynamic bayesian network framework. Pattern Recognition, 43(9):3059–3072, 2010. J. Weaver T. Starner and A. Pentland. Real-time american sign language recognition using desk and wearable computer based video. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20:1371–1375, 1998. J.A. Tropp, A.C. Gilbert, and M.J. Strauss. Algorithms for simultaneous sparse approximation. part i: Greedy pursuit. Signal Processing, 86(3):572–588, 2006. A. Vedaldi and B. Fulkerson. VLFeat: An open and portable library of computer vision algorithms. http://www.vlfeat.org/, 2008. A.J. Viterbi. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. Information Theory, IEEE Transactions on, 13(2):260–269, 1967. 2581  WAN , RUAN , D ENG AND L I  C. P. Vogler. American Sign Language Recognition: Reducing the Complexity of the Task with Phoneme-based Modeling and Parallel Hidden Markov Models. PhD thesis, Doctoral dissertation, University of Pennsylvania, 2003. J. Wan, Q. Ruan, G. An, and W. Li. Gesture recognition based on hidden markov model from sparse representative observations. In Signal Processing (ICSP), IEEE 10th International Conference on, pages 1180–1183, 2012. H. Wang, M.M. Ullah, A. Klaser, I. Laptev, C. Schmid, et al. Evaluation of local spatio-temporal features for action recognition. In Proceedings of British Machine Vision Conference, 2009. J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong. Locality-constrained linear coding for image classiﬁcation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 3360–3367, 2010. S.B. Wang, A. Quattoni, L.P. Morency, D. Demirdjian, and T. Darrell. Hidden conditional random ﬁelds for gesture recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, volume 2, pages 1521–1527, 2006. J. Wright, A.Y. Yang, A. Ganesh, S.S. Sastry, and Yi Ma. Robust face recognition via sparse representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31:210–227, 2009. J. Yamato, Jun Ohya, and K. Ishii. Recognizing human action in time-sequential images using hidden markov model. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 379–385, 1992. J. Yang, K. Yu, Y. Gong, and T. Huang. Linear spatial pyramid matching using sparse coding for image classiﬁcation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 1794–1801, 2009. M.H. Yang, N. Ahuja, and M. Tabb. Extraction of 2d motion trajectories and its application to hand gesture recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24: 1061–1074, 2002. D. Youtian, C. Feng, X. Wenli, and Li. Yongbin. Recognizing interaction activities using dynamic bayesian network. In Pattern Recognition, 18th International Conference on, volume 1, pages 618–621, 2006. Y. Zhu, G. Xu, and D.J. Kriegman. A real-time approach to the spotting, representation, and recognition of hand gestures for human–computer interaction. Computer Vision and Image Understanding, 85(3):189–208, 2002.  2582</p>
<br/>
<br/><br/><br/></body>
</html>
