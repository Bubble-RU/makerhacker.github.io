<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>23 jmlr-2013-Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-23" href="../jmlr2013/jmlr-2013-Cluster_Analysis%3A_Unsupervised_Learning_via_Supervised_Learning_with_a_Non-convex_Penalty.html">jmlr2013-23</a> <a title="jmlr-2013-23-reference" href="#">jmlr2013-23-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>23 jmlr-2013-Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty</h1>
<br/><p>Source: <a title="jmlr-2013-23-pdf" href="http://jmlr.org/papers/volume14/pan13a/pan13a.pdf">pdf</a></p><p>Author: Wei Pan, Xiaotong Shen, Binghui Liu</p><p>Abstract: Clustering analysis is widely used in many ﬁelds. Traditionally clustering is regarded as unsupervised learning for its lack of a class label or a quantitative response variable, which in contrast is present in supervised learning such as classiﬁcation and regression. Here we formulate clustering as penalized regression with grouping pursuit. In addition to the novel use of a non-convex group penalty and its associated unique operating characteristics in the proposed clustering method, a main advantage of this formulation is its allowing borrowing some well established results in classiﬁcation and regression, such as model selection criteria to select the number of clusters, a difﬁcult problem in clustering analysis. In particular, we propose using the generalized cross-validation (GCV) based on generalized degrees of freedom (GDF) to select the number of clusters. We use a few simple numerical examples to compare our proposed method with some existing approaches, demonstrating our method’s promising performance. Keywords: generalized degrees of freedom, grouping, K-means clustering, Lasso, penalized regression, truncated Lasso penalty (TLP)</p><br/>
<h2>reference text</h2><p>L. An and P. Tao. Solving a class of linearly constrained indeﬁnite quadratic problems by D.C. algorithms. J. Global Optimization, 11:253-285, 1997. F.R. Bach and M.I. Jordan. Learning spectral clustering, with application to speech separation. Journal of Machine Learning Research, 7:1963-2001, 2006. J.D. Banﬁeld and A.E. Raftery. Model-based Gaussian and non-Gaussian clustering. Biometrics, 49:803-821, 1993. S. Boyd, N. Parikh, E. Chu, B. Peleato and J. Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning, 3(1):1-122, 2011. A.P. Dempster, N.M. Laird and D.B. Rubin. Maximum likelihood from incomplete data via the EM algorithm (with discussion). JRSS-B, 39:1-38, 1977. J. Fan and R. Li. Variable selection via nonconcave penalized likelihood and it oracle properties. JASA, 96:1348-1360, 2001. C. Fraley and A.E. Raftery. MCLUST Version 3 for R: Normal Mixture Modeling and Model-Based Clustering. Technical Report no. 504, Department of Statistics, University of Washington. 2006. J. Friedman, T. Hastie, H. Hoﬂing and R. Tibshirani. Pathwise coordinate optimization. Ann Appl Statistics, 2:302-332, 2007. G.H. Golub, M. Heath and G. Wahba. Generalized cross-validation as a method for choosing a good ridge parameter. Technometrics, 21:215-223, 1979. M. Grant and S. Boyd. CVX: Matlab software for disciplined convex programming, version 1.21, 2011. http://cvxr.com/cvx T. Hastie, R. Tibshirani and J. Friedman. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer-Verlag, 2001. T. Hocking, A. Joulin, F. Bach and J.-P. Vert. Clusterpath: An Algorithm for Clustering using Convex Fusion Penalties. In L. Getoor and T. Scheffer (Eds.), Proceedings of the 28th International Conference on Machine Learning (ICML’11), p.745-752, 2011. L. Hubert and P. Arabie. Comparing partitions. Journal of Classiﬁcation, 2:193-218, 1985. P. Jaccard. The distribution of ﬂora in the alpine zone. New Phytologist., 11:37-50, 1912. L. Kaufman and P.J. Rousseeuw. Finding Groups in Data: An Introduction to Cluster Analysis. Wiley, New York, 1990. F. Lindsten, H. Ohlsson and L. Ljung, L. Clustering using sum-of-norms regularization: With application to particle ﬁlter output computation. 2011 IEEE Statistical Signal Processing Workshop (SSP), pages 201-204. 2011. 1887  PAN , S HEN AND L IU  G.J. McLachlan and D. Peel. Finite Mixture Model. New York, John Wiley & Sons, Inc. 2002. A. Ng, M. Jordan and Y. Weiss. On spectral clustering: analysis and an algorithm. NIPS, 2002. J. Nocedal and S.J. Wright. Numerical Optimization. Springer, 2000. W. Pan and X. Shen. Penalized model-based clustering with application to variable selection. Journal of Machine Learning Research, 8:1145-1164, 2007. K. Pelckmans, J. De Brabanter, J.A.K. Suykens and B. De Moor. Convex Clustering Shrinkage. Workshop on Statistics and Optimization of Clustering Workshop (PASCAL), London, U.K., Jul. 2005. Available at ftp://ftp.esat.kuleuven.ac.be/pub/SISTA/kpelckma/ccs pelckmans2005.pdf. W.M. Rand. Objective criteria for the evaluation of clustering methods. JASA, 66:846-850, 1971. R.T. Rockafellar and R.J. Wets. Variational Analysis. Springer-Verlag, 2003. X. Shen and J. Ye. Adaptive model selection. JASA, 97:210-221, 2002. X. Shen and H.-C. Huang. Grouping pursuit through a regularization solution surface. JASA, 105:727-739, 2010. X. Shen, W. Pan and Y. Zhu. Likelihood-based selection and sharp parameter estimation. JASA, 107:223-232, 2012. D. Steinley. K-means clustering: a half-century synthesis. British Journal of Mathematical and Statistical Psychology, 59:1-34, 2006. C.A. Sugar and G.M. James. Finding the number of clusters in a data set: An information theoretic approach. Journal of the American Statistical Association, 98:750-763, 2003. A. Thalamuthu, I. Mukhopadhyay, X. Zheng and G.C. Tseng. Evaluation and comparison of gene clustering methods in microarray analysis. Bioinformatics, 22:2405-2412, 2006. R. Tibshirani. Regression shrinkage and selection via the lasso. JRSS-B, 58:267-288, 1996. R. Tibshirani, M. Saunders, S. Rosset, J. Zhu and K. Knight. Sparsity and smoothness via the fused lasso. JRSS-B, 67:91-108, 2005. R. Tibshirani, G. Walther and T. Hastie. Estimating the number of clusters in a data set via the gap statistic. JRSS-B, 63:411-423, 2001. P. Tseng. Convergence of block coordinate descent method for nondifferentiable maximization. J. Opt. Theory Appl., 109:474-494, 2001. J. Wang. Consistent selection of the number of clusters via crossvalidation. Biometrika, 97:893-904, 2010. T.T. Wu and K. Lange. Coordinate descent algorithms for Lasso penalized regression. Ann Appl Statistics, 2:224-244, 2008. 1888  C LUSTER A NALYSIS WITH A N ON - CONVEX P ENALTY  B. Xie, W. Pan and X. Shen. Penalized model-based clustering with cluster-speciﬁc diagonal covariance matrices and grouped variables. Electronic Journal of Statistics, 2:168-212, 2008. R. Xu and D. Wunsch. Survey of clustering algorithms. IEEE Trans Neural Networks, 16:645-678, 2005. J. Ye. On measuring and correcting the effects of data mining and model selection. JASA, 93:120131, 1998. M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. JRSS-B, 68:49-67, 2006. L. Zelnik-Manor and P. Perona. Self-tuning spectral clustering. NIPS, 2004.  1889</p>
<br/>
<br/><br/><br/></body>
</html>
