<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>43 jmlr-2013-Fast MCMC Sampling for Markov Jump Processes and Extensions</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-43" href="../jmlr2013/jmlr-2013-Fast_MCMC_Sampling_for_Markov_Jump_Processes_and_Extensions.html">jmlr2013-43</a> <a title="jmlr-2013-43-reference" href="#">jmlr2013-43-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>43 jmlr-2013-Fast MCMC Sampling for Markov Jump Processes and Extensions</h1>
<br/><p>Source: <a title="jmlr-2013-43-pdf" href="http://jmlr.org/papers/volume14/rao13a/rao13a.pdf">pdf</a></p><p>Author: Vinayak Rao, Yee Whye Teh</p><p>Abstract: Markov jump processes (or continuous-time Markov chains) are a simple and important class of continuous-time dynamical systems. In this paper, we tackle the problem of simulating from the posterior distribution over paths in these models, given partial and noisy observations. Our approach is an auxiliary variable Gibbs sampler, and is based on the idea of uniformization. This sets up a Markov chain over paths by alternately sampling a ﬁnite set of virtual jump times given the current path, and then sampling a new path given the set of extant and virtual jump times. The ﬁrst step involves simulating a piecewise-constant inhomogeneous Poisson process, while for the second, we use a standard hidden Markov model forward ﬁltering-backward sampling algorithm. Our method is exact and does not involve approximations like time-discretization. We demonstrate how our sampler extends naturally to MJP-based models like Markov-modulated Poisson processes and continuous-time Bayesian networks, and show signiﬁcant computational beneﬁts over state-ofthe-art MCMC samplers for these models. Keywords: Markov jump process, MCMC, Gibbs sampler, uniformization, Markov-modulated Poisson process, continuous-time Bayesian network</p><br/>
<h2>reference text</h2><p>G. Bolch, S. Greiner, H. de Meer, and K. S. Trivedi. Queueing Networks and Markov Chains: Modeling and Performance Evaluation with Computer Science Applications. Wiley-Interscience, New York, NY, USA, 1998. ISBN 0-471-19366-6. R. J. Boys, D. J. Wilkinson, and T. B. L. Kirkwood. Bayesian inference for a discretely observed stochastic kinetic model. Statistics and Computing, 18(2):125–135, 2008. 3318  FAST MCMC S AMPLING FOR MJP S AND E XTENSIONS  L. Breuer. From Markov Jump Processes to Spatial Queues. Springer, 2003. ISBN 978-1-40201104-7. T. Burzykowski, J. Szubiakowski, and T. Ryd´ n. Analysis of photon count data from singlee molecule ﬂuorescence experiments. Chemical Physics, 288(2-3):291–307, 2003. C. K. Carter and R. Kohn. Markov chain Monte Carlo in conditionally Gaussian state space models. Biometrika, 83:589–601, 1996. E. Cinlar. Introduction to Stochastic Processes. Prentice Hall, 1975. ¸ I. Cohn, T. El-Hay, N. Friedman, and R. Kupferman. Mean ﬁeld variational approximation for continuous-time Bayesian networks. J. Mach. Learn. Res., 11:2745–2783, December 2010. ISSN 1532-4435. D. J. Daley and D. Vere-Jones. An Introduction to the Theory of Point Processes. Springer, 2008. V. Didelez. Graphical models for marked point processes based on local independence. Journal of the Royal Statistical Society: Series B, 70(1):245–264, 2008. ISSN 1467-9868. T. El-Hay, N. Friedman, and R. Kupferman. Gibbs sampling in factorized continuous-time Markov processes. In Proceedings of the Twenty-fourth Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 169–178, 2008. R. Elliott and C. Osakwe. Option pricing for pure jump processes with Markov switching compensators. Finance and Stochastics, 10:250–275, 2006. Y. Fan and C. R. Shelton. Sampling for approximate inference in continuous time Bayesian networks. In Tenth International Symposium on Artiﬁcial Intelligence and Mathematics, 2008. P. Fearnhead and C. Sherlock. An exact Gibbs sampler for the Markov-modulated Poisson process. Journal Of The Royal Statistical Society Series B, 68(5):767–784, 2006. S. Fr¨ wirth-Schnatter. Data augmentation and dynamic linear models. J. Time Ser. Anal., 15:183– u 202, 1994. D. T. Gillespie. Exact stochastic simulation of coupled chemical reactions. J. Phys. Chem., 81(25): 2340–2361, 1977. ISSN 0022-3654. A. Golightly and D. J. Wilkinson. Bayesian parameter inference for stochastic biochemical network models using particle Markov chain Monte Carlo. Interface Focus, 1(6):807–820, December 2011. A. Hobolth and E. A Stone. Simulation from endpoint-conditioned, continuous-time Markov chains on a ﬁnite state space, with applications to molecular evolution. Ann. Appl. Stat., 3(3):1204, 2009. ISSN 1941-7330. A. Jensen. Markoff chains as an aid in the study of Markoff processes. Skand. Aktuarietiedskr., 36: 87–91, 1953. 3319  R AO AND T EH  O. Kallenberg. Foundations of Modern Probability. Probability and its Applications. SpringerVerlag, New York, Second edition, 2002. ISBN 0-387-95313-2. C. J. Mode and G. T. Pickens. Computational methods for renewal theory and semi-Markov processes with illustrative examples. The American Statistician, 42(2):pp. 143–152, 1988. ISSN 00031305. K. P. Murphy. Dynamic Bayesian Networks: Representation, Inference and Learning. PhD thesis, University of California, Berkeley, 2002. R. M. Neal. Slice sampling. Annals of Statistics, 31:705–767, 2003. R. Nielsen. Mapping mutations on phylogenies. Syst Biol, 51(5):729–739, 2002. U. Nodelman, C.R. Shelton, and D. Koller. Continuous time Bayesian networks. In Proceedings of the Eighteenth Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 378–387, 2002. U. Nodelman, D. Koller, and C.R. Shelton. Expectation propagation for continuous time Bayesian networks. In Proceedings of the Twenty-ﬁrst Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 431–440, July 2005. M. Opper and G. Sanguinetti. Variational inference for Markov jump processes. In Advances in Neural Information Processing Systems 20, 2007. M. Plummer, N. Best, K. Cowles, and K. Vines. CODA: Convergence diagnosis and output analysis for MCMC. R News, 6(1):7–11, March 2006. V. Rao and Y. W. Teh. Fast MCMC sampling for Markov jump processes and continuous time Bayesian networks. In Proceedings of the Twenty-seventh Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2011a. V. Rao and Y. W. Teh. Gaussian process modulated renewal processes. In Advances in Neural Information Processing Systems 23, 2011b. V. Rao and Y. W. Teh. MCMC for continuous-time discrete-state systems. In Advances in Neural Information Processing Systems, 24, 2012. S. L. Scott and P. Smyth. The Markov modulated Poisson process and Markov Poisson cascade with applications to web trafﬁc modeling. Bayesian Statistics, 7:1–10, 2003. C. Shelton, Y. Fan, W. Lam, J. Lee, and J. Xu. Continuous time Bayesian network reasoning and learning engine, 2010. http://mloss.org/software/view/216/. H. C. Tijms. Stochastic Modelling and Analysis: a Computational Approach. Wiley series in probability and mathematical statistics: Applied probability and statistics. Wiley, 1986. ISBN 9780471909118. D. J. Wilkinson. Stochastic modelling for quantitative description of heterogeneous biological systems. Nature Reviews Genetics, 10:122–133, 2009.  3320</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
