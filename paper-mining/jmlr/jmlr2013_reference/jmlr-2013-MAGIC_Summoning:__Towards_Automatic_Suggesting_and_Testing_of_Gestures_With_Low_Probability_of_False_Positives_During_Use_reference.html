<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 jmlr-2013-MAGIC Summoning:  Towards Automatic Suggesting and Testing of Gestures With Low Probability of False Positives During Use</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-66" href="../jmlr2013/jmlr-2013-MAGIC_Summoning%3A__Towards_Automatic_Suggesting_and_Testing_of_Gestures_With_Low_Probability_of_False_Positives_During_Use.html">jmlr2013-66</a> <a title="jmlr-2013-66-reference" href="#">jmlr2013-66-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>66 jmlr-2013-MAGIC Summoning:  Towards Automatic Suggesting and Testing of Gestures With Low Probability of False Positives During Use</h1>
<br/><p>Source: <a title="jmlr-2013-66-pdf" href="http://jmlr.org/papers/volume14/kohlsdorf13a/kohlsdorf13a.pdf">pdf</a></p><p>Author: Daniel Kyu Hwa Kohlsdorf, Thad E. Starner</p><p>Abstract: Gestures for interfaces should be short, pleasing, intuitive, and easily recognized by a computer. However, it is a challenge for interface designers to create gestures easily distinguishable from users’ normal movements. Our tool MAGIC Summoning addresses this problem. Given a speciﬁc platform and task, we gather a large database of unlabeled sensor data captured in the environments in which the system will be used (an “Everyday Gesture Library” or EGL). The EGL is quantized and indexed via multi-dimensional Symbolic Aggregate approXimation (SAX) to enable quick searching. MAGIC exploits the SAX representation of the EGL to suggest gestures with a low likelihood of false triggering. Suggested gestures are ordered according to brevity and simplicity, freeing the interface designer to focus on the user experience. Once a gesture is selected, MAGIC can output synthetic examples of the gesture to train a chosen classiﬁer (for example, with a hidden Markov model). If the interface designer suggests his own gesture and provides several examples, MAGIC estimates how accurately that gesture can be recognized and estimates its false positive rate by comparing it against the natural movements in the EGL. We demonstrate MAGIC’s effectiveness in gesture selection and helpfulness in creating accurate gesture recognizers. Keywords: gesture recognition, gesture spotting, false positives, continuous recognition</p><br/>
<h2>reference text</h2><p>Dan Ashbrook. Enabling Mobile Microinteractions. PhD thesis, Georgia Institute of Technology, Atlanta, Georgia, 2009. 239  KOHLSDORF AND S TARNER  Daniel Ashbrook and Thad Starner. MAGIC: a motion gesture design tool. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pages 2159–2168, New York, New York, 2010. Mohammed Belatar and Francois Coldefy. Sketched menus and iconic gestures, techniques de¸ signed in the context of shareable interfaces. In Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces, pages 143–146, New York, New York, 2010. Xiang Cao and Shumin Zhai. Modeling human performance of pen stroke gestures. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pages 1495–1504, New York, New York, 2007. Chi Tai Dang and Elisabeth Andr´ . Surface-poker: multimodality in tabletop games. In Proceedings e of the ACM International Conference on Interactive Tabletops and Surfaces, pages 251–252, New York, New York, 2010. Roger Dannenberg and Dale Amon. A gesture based user interface prototyping system. In Proceedings of the ACM Symposium on User Interface Software and Technology, pages 127–132, New York, New York, 1989. Anind K. Dey, Raffay Hamid, Chris Beckmann, Ian Li, and Daniel Hsu. a CAPpella: programming by demonstration of context-aware applications. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pages 33–40, New York, New York, 2004. Jerry Fails and Dan Olsen. A design tool for camera-based interaction. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pages 449–456, New York, New York, 2003. Ada Wai-Chee Fu, Eamonn Keogh, Leo Yung Lau, Chotirat Ann Ratanamahatana, and Raymond Chi-Wing Wong. Scaling and time warping in time series querying. The International Journal on Very Large Data Bases, 17(4):899–921, 2008. Francois Guimbreti` re and Terry Winograd. Flowmenu: combining command, text, and data entry. ¸ e In Proceedings of the ACM Symposium on User Interface Software and Technology, pages 213– 216, 2000. Richard Hamming. Error detecting and error correcting codes. Bell Systems Technical Journal, 29: 147–160, 1950. Yuichi Hattori, Sozo Inoue, and Go Hirakawa. A large scale gathering system for activity data with mobile sensors. In Proceedings of the IEEE International Symposium on Wearable Computers, pages 97–100, Washington, District of Columbia, 2011. Edwin L. Hutchins, James D. Hollan, and Donald A. Norman. Direct manipulation interfaces. Human-Computer Interaction, 1(4):311–338, December 1985. ISSN 0737-0024. Daniel Kohlsdorf, Thad Starner, and Daniel Ashbrook. MAGIC 2.0: A web tool for false positive prediction and prevention for gesture recognition systems. In Proceedings of the International Conference on Automatic Face and Gesture Recognition, pages 1–6, Washington, District of Columbia, 2011. 240  MAGIC S UMMONING  Danile Kohlsdorf. Motion gesture: False positive prediction and prevention. Master’s thesis, University of Bremen, Bremen, Germany, 2011. Yang Li. Gesture search: a tool for fast mobile data access. In Proceedings of the ACM Symposium on User Interface Software and Technology, pages 87–96, New York, New York, 2010. Jessica Lin, Li Wei, and Eamonn Keogh. Experiencing sax: A novel symbolic representation of time series. Journal of Data Mining and Knowledge Discovery, 15(2):107–144, 2007. Chris Long. Quill: A Gesture Design Tool for Pen-based User Interfaces. PhD thesis, University of California, Berkeley, California, 2001. Kent Lyons, Helene Brashear, Tracy Westeyn, Jung Soo Kim, and Thad Starner. GART: the gesture and activity recognition toolkit. In Proceedings of the International Conference on HumanComputer Interaction: Intelligent Multimodal Interaction Environments, pages 718–727, Berlin, Germany, 2007. Dan Maynes-Aminzade, Terry Winograd, and Takeo Igarashi. Eyepatch: prototyping camera-based interaction through examples. In Proceedings of the ACM Symposium on User Interface Software and Technology, pages 33–42, New York, New York, 2007. Tom M. Mitchell. Machine Learning. McGraw Hill, New York, New York, 1997. Tom Ouyang and Yang Li. Bootstrapping personal gesture shortcuts with the wisdom of the crowd and handwriting recognition. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pages 2895–2904, 2012. Antti Pirhonen, Stephen Brewster, and Christopher Holguin. Gestural and audio metaphors as a means of control for mobile devices. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pages 291–298, New York, New York, 2002. Jin Shieh and Eamonn Keogh. iSAX: indexing and mining terabyte sized time series. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 623–631, New York, New York, 2008. Jin-Wien Shieh. Time Series Retrievel: Indexing and Mapping Large Datasets. PhD thesis, University California, Riverside, California, 2010. Thad Starner, Joshua Weaver, and Alex Pentland. Real-time American Sign Language recognition using desk and wearable computer-based video. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(12):1371 – 1375, December 1998. Tracy Westeyn, Helene Brashear, Amin Atrash, and Thad Starner. Georgia Tech Gesture Toolkit: supporting experiments in gesture recognition. In Proceedings of the International Conference on Multimodal Interfaces, pages 85–92, New York, New York, 2003. Hendrik Witt. Human-Computer Interfaces for Wearable Computers. PhD thesis, University Bremen, Bremen, Germany, 2007. 241  KOHLSDORF AND S TARNER  Jacob O. Wobbrock, Andrew D. Wilson, and Yang Li. Gestures without libraries, toolkits or training: a $1 recognizer for user interface prototypes. In Proceedings of the ACM Symposium on User Interface Software and Technology, pages 159–168, New York, New York, 2007. Hee-Deok Yang, Stan Sclaroff, and Seong-Whan Lee. Sign language spotting with a threshold model based on conditional random ﬁelds. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(7):1264–1277, 2009.  242</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
