<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-4" href="../jmlr2013/jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">jmlr2013-4</a> <a title="jmlr-2013-4-reference" href="#">jmlr2013-4-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</h1>
<br/><p>Source: <a title="jmlr-2013-4-pdf" href="http://jmlr.org/papers/volume14/cai13b/cai13b.pdf">pdf</a></p><p>Author: Tony Cai, Wen-Xin Zhou</p><p>Abstract: We consider in this paper the problem of noisy 1-bit matrix completion under a general non-uniform sampling distribution using the max-norm as a convex relaxation for the rank. A max-norm constrained maximum likelihood estimate is introduced and studied. The rate of convergence for the estimate is obtained. Information-theoretical methods are used to establish a minimax lower bound under the general sampling model. The minimax upper and lower bounds together yield the optimal rate of convergence for the Frobenius norm loss. Computational algorithms and numerical performance are also discussed. Keywords: 1-bit matrix completion, low-rank matrix, max-norm, trace-norm, constrained optimization, maximum likelihood estimate, optimal rate of convergence</p><br/>
<h2>reference text</h2><p>A. Ai, A. Lapanowski, Y. Plan and R. Vershynin. One-bit compressed sensing with non-Gaussian measurements. Linear Algebra and Its Applications, forthcoming, 2013. P. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: risk bounds and structural results. Journal of Machine Learning Research, 3:463–482, 2002. P. Biswas, T. C. Lian, T. C. Wang and Y. Ye. Semideﬁnite programming based algorithms for sensor network localization. ACM Transactions on Sensor Networks, 2(2):188–220, 2006. P. Boufounos and R. G. Baraniuk. 1-bit compressive sensing. In Proceedings of the 42nd Annual Conference on Information Sciences and Systems, pages 16–21, Princeton, NJ, March 2008. S. Burer and R. D. C. Monteiro. A nonlinear programming algorithm for solving semideﬁnite programs via low-rank factorization. Mathematical Programming, Series B, 95(2):329–357, February 2003. T. T. Cai and W.-X. Zhou Matrix completion via max-norm constrained optimization. arXiv preprint arXiv:1303.0341, 2013. T. M. Cover and J. A. Thomas. Elements of Information Theory. John Wiley and Sons, New York, 1991. M. A. Davenport, Y. Plan, E. van den Berg and M. Wooters. 1-bit matrix completion. arXiv preprint arXiv:1209.3672, 2012. R. Foygel, R. Salakhuidinov, O. Shamir and N. Srebro. Learning with the weighted trace-norm under arbitrary sampling distributions. Advances in Neural Information Processing Systems (NIPS), 24, pages 2133–2141, 2011. R. Foygel and N. Srebro. Concentration-based guarantees for low-rank matrix reconstruction. JMLR: Workshop and Conference Proceedings, 19:315–339, 2011. 3645  C AI AND Z HOU  D. Goldberg, D. Nichols, B. M. Oki and D. Terry. Using collaborative ﬁltering to weave an information tapestry. Communications of the ACM, 35(12):61–70, December 1992. P. E. Green and Y. Wind. Multiattribute Decisions in Marketing: A Measurement Approach. Dryden Press, Hinsdale, IL, 1973. D. Gross and V. Nesme. Note on sampling without replacing from a ﬁnite collection of matrices. arXiv preprint arXiv:1001.2738, 2010. L. Jacques, J. N. Laska, P. T. Boufounos and R. G. Baraniuk. Robust 1-bit compressive sensing via binary stable embeddings of sparse vectors. arXiv preprint arXiv:1104.3160, 2011. M. Jaggi. Revisiting Frank-Wolfe: projection-free sparse convex optimization. JMLR: Workshop and Conference Proceedings, 28(1):427–435, 2013. G. J. O. Jameson. Summing and Nuclear Norms in Banach Space Theory. London Mathematical Society Student Texts, 8. Cambridge University Press, Cambridge, 1987. K. Joag-Dev and F. Proschan. Negative association of random variables with applications. Annals of Statistics, 11(1):286–295, 1983. O. Klopp. Noisy low-rank matrix completion with general sampling distribution. Bernoulli, forthcoming, 2012. V. Koltchinskii, K. Lounici and A. B. Tsybakov. Nuclear norm penalization and optimal rates for noisy low rank matrix completion. Annals of Statistics, 39(5):2302–2329, 2011. J. N. Laska and R. G. Baraniuk. Regime change: bit-depth versus measurement-rate in compressive sensing. IEEE Transactions on Signal Processing, 60(7):3496–3505, 2012. R. Latala. Some estimates of norms of random matrices. Proceedings of the American Mathematical Society, 133(5):1273–1282, 2005. M. Ledoux and M. Talagrand. Probability in Banach Spaces. Isoperimetry and Processes. SpringerVerlag, Berlin, 2011. J. Lee, B. Recht, R. Salakhutdinov, N. Srebro and J. Tropp. Practical large-scale optimization for max-norm regularization. Advances in Neural Information Processing Systems (NIPS), 23, 2010. N. Linial, S. Mendelson, G. Schechtman and A. Shraibman. Complexity measures of sign measures. Combinatorica, 27(4):439–463, 2007. S. Negahban and M. J. Wainwright. Restricted strong convexity and weighted matrix completion: optimal bounds with noise. Journal of Machine Learning Research, 13:1665–1697, 2012. Y. Plan and R. Vershynin. Robust 1-bit compressed sensing and sparse logistic regression: a convex programming approach. IEEE Transactions on Information Theory, 59(1):482–494, January, 2013a. Y. Plan and R. Vershynin. One-bit compressed sensing by linear programming. Communications on Pure and Applied Mathematics, 66(8):1275–1297, August, 2013b. 3646  1-B IT M ATRIX C OMPLETION  R. Salakhutdinov and N. Srebro. Collaborative ﬁltering in a non-uniform world: learning with the weighted trace norm. Advances in Neural Information Processing Systems (NIPS), 23, December, 2010. Y. Seginer. The expected norm of random matrices. Combinatorics, Probability and Computing, 9(2):149–166, March, 2000. I. Spence and D. W. Domoney. Single subject incomplete designs for nonmetric multidimensional scaling. Psychometrika, 39(4):469–490, December, 1974. N. Srebro, J. Rennie and T. Jaakkola. Maximum-margin matrix factorization. Advances in Neural Information Processing Systems (NIPS), 17, pages 1329–1336. MIT Press, 2005. N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. In Learning theory, Proceedings of COLT-2005. Lecture Notes in Computer Science, 3559:545–560, Springer, Berlin, 2005. N. Srebro, K. Sridharan and A. Tewari. Optimistic rates for learning with a smooth loss. arXiv preprint arXiv:1009.3896, 2010. J. A. Tropp. User-friendly tail bounds for sums of random matrices. Foundations of Computational Mathematics, 12(4):389–434, August, 2012. Y. Yang and A. Barron. Information-theoretic determination of minimax rates of convergence. Annals of Statistics, 27(5):1564–1599, 1999. B. Yu. Assouad, Fano and Le Cam. Research Papers in Probability and Statistics: Festschrift for Lucien Le Cam, pages 423–435.  3647</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
