<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>8 jmlr-2013-A Theory of Multiclass Boosting</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-8" href="../jmlr2013/jmlr-2013-A_Theory_of_Multiclass_Boosting.html">jmlr2013-8</a> <a title="jmlr-2013-8-reference" href="#">jmlr2013-8-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>8 jmlr-2013-A Theory of Multiclass Boosting</h1>
<br/><p>Source: <a title="jmlr-2013-8-pdf" href="http://jmlr.org/papers/volume14/mukherjee13a/mukherjee13a.pdf">pdf</a></p><p>Author: Indraneel Mukherjee, Robert E. Schapire</p><p>Abstract: Boosting combines weak classiﬁers to form highly accurate predictors. Although the case of binary classiﬁcation is well understood, in the multiclass setting, the “correct” requirements on the weak classiﬁer, or the notion of the most efﬁcient boosting algorithms are missing. In this paper, we create a broad and general framework, within which we make precise and identify the optimal requirements on the weak-classiﬁer, as well as design the most effective, in a certain sense, boosting algorithms that assume such requirements. Keywords: multiclass, boosting, weak learning condition, drifting games</p><br/>
<h2>reference text</h2><p>Jacob Abernethy, Peter L. Bartlett, Alexander Rakhlin, and Ambuj Tewari. Optimal stragies and minimax lower bounds for online convex games. In COLT, pages 415–424, 2008. Erin L. Allwein, Robert E. Schapire, and Yoram Singer. Reducing multiclass to binary: A unifying approach for margin classiﬁers. Journal of Machine Learning Research, 1:113–141, 2000. Peter L. Bartlett and Mikhail Traskin. AdaBoost is consistent. Journal of Machine Learning Research, 8:2347–2368, 2007. Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classiﬁcation, and risk bounds. Journal of the American Statistical Association, 101(473):138–156, March 2006. Alina Beygelzimer, John Langford, and Pradeep Ravikumar. Error-correcting tournaments. In Algorithmic Learning Theory: 20th International Conference, pages 247–262, 2009. Thomas G. Dietterich and Ghulum Bakiri. Solving multiclass learning problems via error-correcting output codes. Journal of Artiﬁcial Intelligence Research, 2:263–286, January 1995. G¨ nther Eibl and Karl-Peter Pfeiffer. Multiclass boosting for weak classiﬁers. Journal of Machine u Learning Research, 6:189–210, 2005. Yoav Freund. Boosting a weak learning algorithm by majority. Information and Computation, 121 (2):256–285, 1995. Yoav Freund. An adaptive version of the boost by majority algorithm. Machine Learning, 43(3): 293–318, June 2001. Yoav Freund and Manfred Opper. Continuous drifting games. Journal of Computer and System Sciences, pages 113–132, 2002. Yoav Freund and Robert E. Schapire. Experiments with a new boosting algorithm. In Machine Learning: Proceedings of the Thirteenth International Conference, pages 148–156, 1996a. Yoav Freund and Robert E. Schapire. Game theory, on-line prediction and boosting. In Proceedings of the Ninth Annual Conference on Computational Learning Theory, pages 325–332, 1996b. Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119–139, August 1997. Trevor Hastie and Robert Tibshirani. Classiﬁcation by pairwise coupling. Annals of Statistics, 26 (2):451–471, 1998. Vladimir Koltchinskii and Dmitriy Panchenko. Empirical margin distributions and bounding the generalization error of combined classiﬁers. Annals of Statistics, 30(1), February 2002. Ping Li. Robust logitboost and adaptive base class (abc) logitboost. In UAI, pages 302–311, 2010. 496  A T HEORY OF M ULTICLASS B OOSTING  Philip M. Long and Rocco A. Servedio. Random classiﬁcation noise defeats all convex potential boosters. Machine Learning, 78:287–304, 2010. Indraneel Mukherjee and Robert E. Schapire. Learning with continuous experts using drifting games. Theoretical Computer Science, 411(29-30):2670–2683, June 2010. Indraneel Mukherjee, Cynthia Rudin, and Robert E. Schapire. The rate of convergence of AdaBoost. In The 24th Annual Conference on Learning Theory, 2011. Gunnar R¨ tsch and Manfred K. Warmuth. Efﬁcient margin maximizing with boosting. Journal of a Machine Learning Research, 6:2131–2152, 2005. R. Tyrrell Rockafellar. Convex Analysis. Princeton University Press, 1970. Robert E. Schapire. The strength of weak learnability. Machine Learning, 5(2):197–227, 1990. Robert E. Schapire. Drifting games. Machine Learning, 43(3):265–291, June 2001. Robert E. Schapire and Yoav Freund. Boosting: Foundations and Algorithms. MIT Press, 2012. Robert E. Schapire and Yoram Singer. Improved boosting algorithms using conﬁdence-rated predictions. Machine Learning, 37(3):297–336, December 1999. Robert E. Schapire and Yoram Singer. BoosTexter: A boosting-based system for text categorization. Machine Learning, 39(2/3):135–168, May/June 2000. Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. Boosting the margin: A new explanation for the effectiveness of voting methods. Annals of Statistics, 26(5):1651–1686, October 1998. Ambuj Tewari and Peter L. Bartlett. On the Consistency of Multiclass Classiﬁcation Methods. Journal of Machine Learning Research, 8:1007–1025, May 2007. Tong Zhang. Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization. Annals of Statistics, 32(1):56–134, 2004. Ji Zhu, Hui Zou, Saharon Rosset, and Trevor Hastie. Multi-class AdaBoost. Statistics and Its Interface, 2:349360, 2009.  497</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
