<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>19 jmlr-2013-BudgetedSVM: A Toolbox for Scalable SVM Approximations</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-19" href="../jmlr2013/jmlr-2013-BudgetedSVM%3A_A_Toolbox_for_Scalable_SVM_Approximations.html">jmlr2013-19</a> <a title="jmlr-2013-19-reference" href="#">jmlr2013-19-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>19 jmlr-2013-BudgetedSVM: A Toolbox for Scalable SVM Approximations</h1>
<br/><p>Source: <a title="jmlr-2013-19-pdf" href="http://jmlr.org/papers/volume14/djuric13a/djuric13a.pdf">pdf</a></p><p>Author: Nemanja Djuric, Liang Lan, Slobodan Vucetic, Zhuang Wang</p><p>Abstract: We present BudgetedSVM, an open-source C++ toolbox comprising highly-optimized implementations of recently proposed algorithms for scalable training of Support Vector Machine (SVM) approximators: Adaptive Multi-hyperplane Machines, Low-rank Linearization SVM, and Budgeted Stochastic Gradient Descent. BudgetedSVM trains models with accuracy comparable to LibSVM in time comparable to LibLinear, solving non-linear problems with millions of high-dimensional examples within minutes on a regular computer. We provide command-line and Matlab interfaces to BudgetedSVM, an efﬁcient API for handling large-scale, high-dimensional data sets, as well as detailed documentation to help developers use and further extend the toolbox. Keywords: non-linear classiﬁcation, large-scale learning, SVM, machine learning toolbox</p><br/>
<h2>reference text</h2><p>C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27, 2011. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm. K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector machines. Journal of Machine Learning Research, 2:265–292, 2002. C.-J. Hsieh, K.-W. Chang, C.-J. Lin, S. S. Keerthi, and S. Sundararajan. A dual coordinate descent method for large-scale linear SVM. In International Conference on Machine Learning, pages 408–415, 2008. F. Lauer and Y. Guermeur. MSVMpack: A multi-class support vector machine package. Journal of Machine Learning Research, 12:2293–2296, 2011. S. Shalev-Shwartz, Y. Singer, and N. Srebro. Pegasos: Primal estimated sub-gradient solver for SVM. In International Conference on Machine Learning, pages 807–814, 2007. Z. Wang and S. Vucetic. Tighter perceptron with improved dual use of cached data for model representation and validation. In International Joint Conference on Neural Networks, pages 3297– 3302, 2009. Z. Wang and S. Vucetic. Online passive-aggressive algorithms on a budget. In International Conference on Artiﬁcial Intelligence and Statistics, pages 908–915, 2010. Z. Wang, N. Djuric, K. Crammer, and S. Vucetic. Trading representability for scalability: Adaptive multi-hyperplane machine for nonlinear classiﬁcation. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2011. Z. Wang, K. Crammer, and S. Vucetic. Breaking the curse of kernelization: Budgeted stochastic gradient descent for large-scale SVM training. Journal of Machine Learning Research, 13:3103– 3131, 2012. K. Zhang, L. Lan, Z. Wang, and F. Moerchen. Scaling up kernel SVM on limited resources: A lowrank linearization approach. In International Conference on Artiﬁcial Intelligence and Statistics, 2012. Z. A. Zhu, W. Chen, G. Wang, C. Zhu, and Z. Chen. P-packSVM: Parallel primal gradient descent kernel SVM. In IEEE International Conference on Data Mining, 2009.  3817</p>
<br/>
<br/><br/><br/></body>
</html>
