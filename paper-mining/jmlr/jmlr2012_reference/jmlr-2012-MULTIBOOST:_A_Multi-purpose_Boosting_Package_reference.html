<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>62 jmlr-2012-MULTIBOOST: A Multi-purpose Boosting Package</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-62" href="../jmlr2012/jmlr-2012-MULTIBOOST%3A_A_Multi-purpose_Boosting_Package.html">jmlr2012-62</a> <a title="jmlr-2012-62-reference" href="#">jmlr2012-62-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>62 jmlr-2012-MULTIBOOST: A Multi-purpose Boosting Package</h1>
<br/><p>Source: <a title="jmlr-2012-62-pdf" href="http://jmlr.org/papers/volume13/benbouzid12a/benbouzid12a.pdf">pdf</a></p><p>Author: Djalel Benbouzid, Róbert Busa-Fekete, Norman Casagrande, François-David Collin, Balázs Kégl</p><p>Abstract: The M ULTI B OOST package provides a fast C++ implementation of multi-class/multi-label/multitask boosting algorithms. It is based on A DA B OOST.MH but it also implements popular cascade classiﬁers and F ILTER B OOST. The package contains common multi-class base learners (stumps, trees, products, Haar ﬁlters). Further base learners and strong learners following the boosting paradigm can be easily implemented in a ﬂexible framework. Keywords: boosting, A DA B OOST.MH, F ILTER B OOST, cascade classiﬁer</p><br/>
<h2>reference text</h2><p>J. Bergstra, N. Casagrande, D. Erhan, D. Eck, and B. K´ gl. Aggregate features and AdaBoost for e music classiﬁcation. Machine Learning Journal, 65(2/3):473–484, 2006. L. Bourdev and J. Brandt. Robust object detection via soft cascade. In Conference on Computer Vision and Pattern Recognition, volume 2, pages 236–243. IEEE Computer Society, 2005. J.K. Bradley and R.E. Schapire. FilterBoost: Regression and classiﬁcation on large datasets. In Advances in Neural Information Processing Systems, volume 20. The MIT Press, 2008. R. Busa-Fekete and B. K´ gl. Fast boosting using adversarial bandits. In International Conference e on Machine Learning, volume 27, pages 143–150, 2010. R. Busa-Fekete, B. K´ gl, Eltet˝ T., and Gy. Szarvas. Ranking by calibrated AdaBoost. In (JMLR e ´ o W&CP;), volume 14, pages 37–48, 2011. G. Escudero, L. M` rquez, and G. Rigau. Boosting applied to word sense disambiguation. In a Proceedings of the 11th European Conference on Machine Learning, pages 129–141, 2000. Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55:119–139, 1997. B. K´ gl and R. Busa-Fekete. Boosting products of base classiﬁers. In International Conference on e Machine Learning, volume 26, pages 497–504, Montreal, Canada, 2009. R.E. Schapire and Y. Singer. Improved boosting algorithms using conﬁdence-rated predictions. Machine Learning, 37(3):297–336, 1999. P. Viola and M. Jones. Robust real-time face detection. International Journal of Computer Vision, 57:137–154, 2004.  553</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
