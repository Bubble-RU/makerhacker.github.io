<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>19 jmlr-2012-An Introduction to Artificial Prediction Markets for Classification</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-19" href="../jmlr2012/jmlr-2012-An_Introduction_to_Artificial_Prediction_Markets_for_Classification.html">jmlr2012-19</a> <a title="jmlr-2012-19-reference" href="#">jmlr2012-19-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>19 jmlr-2012-An Introduction to Artificial Prediction Markets for Classification</h1>
<br/><p>Source: <a title="jmlr-2012-19-pdf" href="http://jmlr.org/papers/volume13/barbu12a/barbu12a.pdf">pdf</a></p><p>Author: Adrian Barbu, Nathan Lay</p><p>Abstract: Prediction markets are used in real life to predict outcomes of interest such as presidential elections. This paper presents a mathematical theory of artiﬁcial prediction markets for supervised learning of conditional probability estimators. The artiﬁcial prediction market is a novel method for fusing the prediction information of features or trained classiﬁers, where the fusion result is the contract price on the possible outcomes. The market can be trained online by updating the participants’ budgets using training examples. Inspired by the real prediction markets, the equations that govern the market are derived from simple and reasonable assumptions. Efﬁcient numerical algorithms are presented for solving these equations. The obtained artiﬁcial prediction market is shown to be a maximum likelihood estimator. It generalizes linear aggregation, existent in boosting and random forest, as well as logistic regression and some kernel methods. Furthermore, the market mechanism allows the aggregation of specialized classiﬁers that participate only on speciﬁc instances. Experimental comparisons show that the artiﬁcial prediction markets often outperform random forest and implicit online learning on synthetic data and real UCI data sets. Moreover, an extensive evaluation for pelvic and abdominal lymph node detection in CT data shows that the prediction market improves adaboost’s detection rate from 79.6% to 81.2% at 3 false positives/volume. Keywords: online learning, ensemble methods, supervised learning, random forest, implicit online learning</p><br/>
<h2>reference text</h2><p>K. J. Arrow, R. Forsythe, M. Gorham, R. Hahn, R. Hanson, J. O. Ledyard, S. Levmore, R. Litan, P. Milgrom, and F. D. Nelson. The promise of prediction markets. Science, 320(5878):877, 2008. A. Barbu, M. Suehling, X. Xu, D. Liu, S. Zhou, and D. Comaniciu. Automatic detection and segmentation of lymph nodes from ct data. IEEE Trans. on Medical Imaging, 31(2):240–250, 2012. S. Basu. Investment performance of common stocks in relation to their price-earnings ratios: A test of the efﬁcient market hypothesis. The Journal of Finance, 32(3):663–682, 1977. M. Belkin and P. Niyogi. Semi-supervised learning on Riemannian manifolds. Machine Learning, 56(1):209–239, 2004. A.L. Berger, V.J.D. Pietra, and S.A.D. Pietra. A maximum entropy approach to natural language processing. Computational linguistics, 22(1):39–71, 1996. C. Blake and CJ Merz. UCI repository of machine learning databases [http://www. ics. uci. edu/ mlearn/MLRepository. html], Department of Information and Computer Science. University of California, Irvine, CA, 1998. A. Bordes, S. Ertekin, J. Weston, and L. Bottou. Fast kernel classiﬁers with online and active learning. The Journal of Machine Learning Research, 6:1619, 2005. L. Breiman. Random forests. Machine Learning, 45(1):5–32, 2001. G. Cauwenberghs and T. Poggio. Incremental and decremental support vector machine learning. In NIPS, page 409, 2001. Y. Chen and J.W. Vaughan. A new understanding of prediction markets via no-regret learning. In ACM Conf. on Electronic Commerce, pages 189–198, 2010. 2202  A RTIFICIAL P REDICTION M ARKETS  Y. Chen, J. Abernethy, and J.W. Vaughan. An optimization-based framework for automated marketmaking. Proceedings of the EC, 11:5–9, 2011. C. Chow. On optimum recognition error and reject tradeoff. IEEE Trans. on Information Theory, 16(1):41–46, 1970. B. Cowgill, J. Wolfers, and E. Zitzewitz. Using prediction markets to track information ﬂows: Evidence from Google. Dartmouth College, 2008. J. Demˇar. Statistical comparisons of classiﬁers over multiple data sets. The Journal of Machine s Learning Research, 7:30, 2006. A. Elgammal and C.S. Lee. Inferring 3d body pose from silhouettes using activity manifold learning. In CVPR, 2004. E.F. Fama. Efﬁcient capital markets: A review of theory and empirical work. Journal of Finance, pages 383–417, 1970. C. Ferri, P. Flach, and J. Hern´ ndez-Orallo. Delegating classiﬁers. In ICML, 2004. a Y. Freund and R.E. Schapire. Experiments with a new boosting algorithm. In ICML, pages 148–156, 1996. J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic regression: a statistical view of boosting. Annals of Statistics, 28(2):337–407, 2000. J.H. Friedman and B.E. Popescu. Predictive learning via rule ensembles. Ann. Appl. Stat., 2(3): 916–954, 2008. S. Gjerstad and M.C. Hall. Risk aversion, beliefs, and prediction market equilibrium. Economic Science Laboratory, University of Arizona, 2005. J. Kivinen, AJ Smola, and RC Williamson. Online learning with kernels. IEEE Trans. on Signal Processing, 52:2165–2176, 2004. B. Kulis and P.L. Bartlett. Implicit online learning. In ICML, 2010. N. Lay and A. Barbu. Supervised aggregation of classiﬁers using artiﬁcial prediction markets. In ICML, 2010. B.G. Malkiel. The efﬁcient market hypothesis and its critics. The Journal of Economic Perspectives, 17(1):59–82, 2003. W. R. Mann. Mean value methods in iteration. Proc. Amer. Math. Soc., 4:506–510, 1953. C.F. Manski. Interpreting the predictions of prediction markets. Economics Letters, 91(3):425–429, 2006. J. Perols, K. Chari, and M. Agrawal. Information market-based decision fusion. Management Science, 55(5):827–842, 2009. 2203  BARBU AND L AY  C.R. Plott, J. Wit, and W.C. Yang. Parimutuel betting markets as information aggregation devices: Experimental results. Economic Theory, 22(2):311–351, 2003. P.M. Polgreen, F.D. Nelson, and G.R. Neumann. Use of prediction markets to forecast infectious disease activity. Clinical Infectious Diseases, 44(2):272–279, 2006. C. Polk, R. Hanson, J. Ledyard, and T. Ishikida. The policy analysis market: an electronic commerce application of a combinatorial information market. In ACM Conf. on Electronic Commerce, pages 272–273, 2003. A. Ratnaparkhi et al. A maximum entropy model for part-of-speech tagging. In Conf. on Empirical Methods in Natural Language Processing, volume 1, pages 133–142, 1996. L.K. Saul and S.T. Roweis. Think globally, ﬁt locally: Unsupervised learning of low dimensional manifolds. The Journal of Machine Learning Research, 4:119–155, 2003. R.E. Schapire. The boosting approach to machine learning: An overview. Lect. Notes in Statistics, pages 149–172, 2003. A. Storkey. Machine learning markets. AISTATS, 2011. A. Storkey, J. Millin, and K. Geras. Isoelastic agents and wealth updates in machine learning markets. ICML, 2012. F. Tortorella. Reducing the classiﬁcation cost of support vector classiﬁers through an ROC-based reject rule. Pattern Analysis & Applications, 7(2):128–143, 2004. J. Wolfers and E. Zitzewitz. Prediction markets. Journal of Economic Perspectives, pages 107–126, 2004. S.C. Zhu, Y. Wu, and D. Mumford. Filters, random ﬁelds and maximum entropy (FRAME): Towards a uniﬁed theory for texture modeling. International Journal of Computer Vision, 27(2): 107–126, 1998.  2204</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
