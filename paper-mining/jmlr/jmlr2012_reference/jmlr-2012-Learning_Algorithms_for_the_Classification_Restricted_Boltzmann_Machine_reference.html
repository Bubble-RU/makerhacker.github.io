<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-55" href="../jmlr2012/jmlr-2012-Learning_Algorithms_for_the_Classification_Restricted_Boltzmann_Machine.html">jmlr2012-55</a> <a title="jmlr-2012-55-reference" href="#">jmlr2012-55-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>55 jmlr-2012-Learning Algorithms for the Classification Restricted Boltzmann Machine</h1>
<br/><p>Source: <a title="jmlr-2012-55-pdf" href="http://jmlr.org/papers/volume13/larochelle12a/larochelle12a.pdf">pdf</a></p><p>Author: Hugo Larochelle, Michael Mandel, Razvan Pascanu, Yoshua Bengio</p><p>Abstract: Recent developments have demonstrated the capacity of restricted Boltzmann machines (RBM) to be powerful generative models, able to extract useful features from input data or construct deep artiﬁcial neural networks. In such settings, the RBM only yields a preprocessing or an initialization for some other model, instead of acting as a complete supervised model in its own right. In this paper, we argue that RBMs can provide a self-contained framework for developing competitive classiﬁers. We study the Classiﬁcation RBM (ClassRBM), a variant on the RBM adapted to the classiﬁcation setting. We study different strategies for training the ClassRBM and show that competitive classiﬁcation performances can be reached when appropriately combining discriminative and generative training objectives. Since training according to the generative objective requires the computation of a generally intractable gradient, we also compare different approaches to estimating this gradient and address the issue of obtaining such a gradient for problems with very high dimensional inputs. Finally, we describe how to adapt the ClassRBM to two special cases of classiﬁcation problems, namely semi-supervised and multitask learning. Keywords: restricted Boltzmann machine, classiﬁcation, discriminative learning, generative learning</p><br/>
<h2>reference text</h2><p>Arthur Asuncion, Qiang Liu, Alexander Ihler, and Padhraic Smyth. Learning with blocks: Composite likelihood and contrastive divergence. In Proceedings of The Thirteenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS’10), pages 33–40, 2010. Yoshua Bengio, Olivier Delalleau, and Nicolas Le Roux. Label propagation and quadratic criterion. In Olivier Chapelle, Bernhard Sch¨ lkopf, and Alexander Zien, editors, Semi-Supervised o Learning, pages 193–216. MIT Press, 2006a. URL http://www.iro.umontreal.ca/˜lisa/ pointeurs/bengio_ssl.pdf. Yoshua Bengio, Olivier Delalleau, and Nicolas Le Roux. The curse of highly variable functions for local kernel machines. In Y. Weiss, B. Sch¨ lkopf, and J. Platt, editors, Advances in Neuo ral Information Processing Systems 18 (NIPS’05), pages 107–114. MIT Press, Cambridge, MA, 2006b. Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. Greedy layer-wise training of deep networks. In Bernhard Sch¨ lkopf, John Platt, and Thomas Hoffman, editors, Advances o in Neural Information Processing Systems 19 (NIPS’06), pages 153–160. MIT Press, 2007. Julian Besag. Statistical analysis of non-lattice data. The Statistician, 24(3):179–195, 1975. Guillaume Bouchard and Bill Triggs. The tradeoff between generative and discriminative classiﬁers. In IASC International Symposium on Computational Statistics (COMPSTAT), pages 721–728, Prague, August 2004. Rich Caruana. Multitask learning. Machine Learning, 28(1):41–75, 1997. Olivier Chapelle, Bernhard. Sch¨ lkopf, and Alexander Zien. Semi-Supervised Learning. MIT Press, o Cambridge, MA, 2006. Corinna Cortes and Mohri Mohri. Auc optimization vs. error rate minimization. In S. Thrun, L. Saul, and B. Sch¨ lkopf, editors, Advances in Neural Information Processing Systems 16 (NIPS’03), o volume 16, Cambridge, MA, 2004. MIT Press. Gregory Druck, Chris Pal, Andrew Mccallum, and Xiaojin Zhu. Semi-supervised classiﬁcation with hybrid generative/discriminative methods. In Proceedings of the Thirteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’07), pages 280–289, New York, NY, USA, 2007. ACM. Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent, and Samy Bengio. Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research, 11:625–660, February 2010. Peter V. Gehler, Alex D. Holub, and Max Welling. The rate adapting poisson model for information retrieval and object recognition. In William W. Cohen and Andrew Moore, editors, Proceedings of the Twenty-three International Conference on Machine Learning (ICML’06), pages 337–344, New York, NY, USA, 2006. ACM. ISBN 1-59593-383-2. doi: http://doi.acm.org/10. 1145/1143844.1143887. 665  L AROCHELLE , M ANDEL , PASCANU AND B ENGIO  Andrew Gelfand, Yutian Chen, Laurens van der Maaten, and Max Welling. On herding and the perceptron cycling theorem. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23 (NIPS’10), pages 694–702. Curran Associates, 2010. Xavier Glorot, Antoire Bordes, and Yoshua Bengio. Deep sparse rectiﬁer neural networks. In Proceedings of the Fourteenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS’11), April 2011. Geoffrey E. Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14:1771–1800, 2002. Geoffrey E. Hinton. To recognize shapes, ﬁrst learn to generate images. In Paul Cisek, Trevor Drew, and John Kalaska, editors, Computational Neuroscience: Theoretical Insights into Brain Function. Elsevier, 2007. Geoffrey E. Hinton, Simon Osindero, and Yee Whye Teh. A fast learning algorithm for deep belief nets. Neural Computation, 18:1527–1554, 2006. Aapo Hyv¨ rinen. Consistency of Pseudolikelihood Estimation of Fully Visible Boltzmann Maa chines. Neural Computation, 18:2283–2292, 2006. Paul Lamere. Social tagging and music information retrieval. Journal of New Music Research, 37 (2):101–114, 2008. Hugo Larochelle and Yoshua Bengio. Classiﬁcation using discriminative restricted Boltzmann machines. In William W. Cohen, Andrew McCallum, and Sam T. Roweis, editors, Proceedings of the Twenty-ﬁfth International Conference on Machine Learning (ICML’08), pages 536–543. ACM, 2008. Hugo Larochelle, Dumitru Erhan, Aaron Courville, James Bergstra, and Yoshua Bengio. An empirical evaluation of deep architectures on problems with many factors of variation. In Zoubin Ghahramani, editor, Proceedings of the Twenty-fourth International Conference on Machine Learning (ICML’07), pages 473–480. ACM, 2007. Nicolas Le Roux and Yoshua Bengio. Deep belief networks are compact universal approximators. Neural Computation, 22(8):2192–2207, August 2010. ISSN 0899-7667. Honglak Lee, Chaitanya Ekanadham, and Andrew Ng. Sparse deep belief net model for visual area V2. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20 (NIPS’07), pages 873–880. MIT Press, Cambridge, MA, 2008. Percy Liang and Michael I. Jordan. An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators. In William W. Cohen, Andrew McCallum, and Sam T. Roweis, editors, Proceedings of the Twenty-ﬁfth International Conference on Machine Learning (ICML’08), pages 584–591, New York, NY, USA, 2008. ACM. ISBN 978-1-60558-205-4. doi: http: //doi.acm.org/10.1145/1390156.1390230. Bruce G. Lindsay. Composite likelihood methods. Contemporary Mathematics, 80:221–239, 1988. 666  C LASSIFICATION R ESTRICTED B OLTZMANN M ACHINES  J´ rˆ me Louradour and Hugo Larochelle. Classiﬁcation of sets using restricted Boltzmann maeo chines. In Proceedings of the Twenty-seventh Conference on Uncertainty in Artiﬁcial Intelligence (UAI’11) (to appear). AUAI Press, 2011. Michael I. Mandel and Daniel P. W. Ellis. A web-based game for collecting music metadata. Journal of New Music Research, 37(2):151–165, 2008. Michael I. Mandel, Douglas Eck, and Yoshua Bengio. Learning tags that vary within a song. In Proceedings of the Eleventh International Conference on Music Information Retrieval (ISMIR), pages 399–404, August 2010. Michael I. Mandel, Razvan Pascanu, Douglas Eck, Yoshua Bengio, Luca M. Aiello, Rossano Schifanella, and Filippo Menczer. Contextual tag inference. ACM Transactions on Multimedia Computing, Communications and Applications, 7S(1):32:1–32:18, October 2011a. Michael I. Mandel, Razvan Pascanu, Hugo Larochelle, and Yoshua Bengio. Autotagging music with conditional restricted Boltzmann machines. ArXiv e-prints, March 2011b. Andrew McCallum, Chris Pal, Gregory Druck, and Xuerui Wang. Multi-conditional learning: Generative/discriminative training for clustering and classiﬁcation. In Twenty-ﬁrst National Conference on Artiﬁcial Intelligence (AAAI’06). AAAI Press, 2006. Roland Memisevic, Christopher Zach, Geoffrey Hinton, and Marc Pollefeys. Gated softmax classiﬁcation. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23 (NIPS’10), pages 1603–1611. Curran Associates, 2010. Andriy Mnih and Geoffrey E. Hinton. Three new graphical models for statistical language modelling. In Zoubin Ghahramani, editor, Proceedings of the Twenty-fourth International Conference on Machine Learning (ICML’07), pages 641–648. ACM, 2007. Volodymyr Mnih, Hugo Larochelle, and Geoffrey E. Hinton. Conditional restricted boltzmann machines for structured output prediction. In Proceedings of the Twenty-seventh Conference on Uncertainty in Artiﬁcial Intelligence (UAI’11) (to appear). AUAI Press, 2011. Andrew Y. Ng and Michael I. Jordan. On discriminative vs. generative classiﬁers: A comparison of logistic regression and naive bayes. In T.G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14 (NIPS’01), pages 841–848, 2002. Judea Pearl. Probabilistic Reasoning in Intelligent Systems:Networks of Plausible Inference. Morgan Kaufmann, 1988. Marco Pretti. A message-passing algorithm with damping. Journal of Statistical Mechanics: Theory and Experiment, page P11008, 2005. Ruslan Salakhutdinov and Geoffrey E. Hinton. Semantic hashing. In Proceedings of the 2007 Workshop on Information Retrieval and applications of Graphical Models (SIGIR’07), Amsterdam, 2007. Elsevier. 667  L AROCHELLE , M ANDEL , PASCANU AND B ENGIO  Rossano Schifanella, Alain Barrat, Ciro Cattuto, Benjamin Markines, and Filippo Menczer. Folks in folksonomies: Social link prediction from shared metadata. In Proceedings of the Third International Conference on Web Search and Data Mining (WSDM’10), pages 271–280. ACM, Mar 2010. Tanya Schmah, Geoffrey E. Hinton, Richard Zemel, Steven L. Small, and Stephen Strother. Generative versus discriminative training of RBMs for classiﬁcation of fMRI images. In Daphne Koller, Dale Schuurmans, Yoshua Bengio, and Leon Bottou, editors, Advances in Neural Information Processing Systems 21 (NIPS’08), pages 1409–1416. Curran Associates, 2009. Tijmen Tieleman. Training restricted Boltzmann machines using approximations to the likelihood gradient. In William W. Cohen, Andrew McCallum, and Sam T. Roweis, editors, Proceedings of the Twenty-ﬁfth International Conference on Machine Learning (ICML’08), pages 1064–1071. ACM, 2008. Tijmen Tieleman and Geoffrey Hinton. Using fast weights to improve persistent contrastive divergence. In L´ on Bottou and Michael Littman, editors, Proceedings of the Twenty-sixth Intere national Conference on Machine Learning (ICML’09), pages 1033–1040. ACM, 2009. ISBN 978-1-60558-516-1. doi: http://doi.acm.org/10.1145/1553374.1553506. Laurens van der Maaten, Max Welling, and Lawrence K. Saul. Hidden-unit conditional random ﬁelds. In Proceedings of the Fourteenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS’11), volume 15 of JMLR: W&CP;, 2011. Yair Weiss. Comparing the mean ﬁeld method and belief propagation for approximate inference in MRFs. In Advanced Mean Field Methods - Theory and Practice. MIT Press, 2001. Max Welling and Geoffrey E. Hinton. A new learning algorithm for mean ﬁeld Boltzmann machines. In Proceedings of the International Conference on Artiﬁcial Neural Networks (ICANN’02), pages 351–357, London, UK, 2002. Springer-Verlag. ISBN 3-540-44074-7. Max Welling and Charles Sutton. Learning in markov random ﬁelds with contrastive free energies. In In Proceedings of the 10th International Workshop on Artiﬁcial Intelligence and Statistics (AISTATS’05), pages 397–404, 2005. Max Welling, Michal Rosen-Zvi, and Geoffrey E. Hinton. Exponential family harmoniums with an application to information retrieval. In L.K. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17 (NIPS’04), volume 17, Cambridge, MA, 2005. MIT Press. Eric P. Xing, Rong Yan, and Alexander G. Hauptmann. Mining associated text and images with dual-wing harmoniums. In Proceedings of the Twenty-ﬁrst Conference in Uncertainty in Artiﬁcial Intelligence (UAI’05), pages 633–641. AUAI Press, 2005. ISBN 0-9749039-1-4. Jun Yang, Yan Liu, Eric P. Xing, and Alexander G. Hauptmann. Harmonium models for semantic video representation and classiﬁcation. In Proceedings of the Seventh SIAM International Conference on Data Mining (SDM’07). SIAM, 2007. 668  C LASSIFICATION R ESTRICTED B OLTZMANN M ACHINES  Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty. Semi-supervised learning using Gaussian ﬁelds and harmonic functions. In Tom Fawcett and Nina Mishra, editors, Proceedings of the Twenty International Conference on Machine Learning (ICML’03), pages 912–919. AAAI Press, 2003.  669</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
