<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>6 jmlr-2012-A Model of the Perception of Facial Expressions of Emotion by Humans: Research Overview and Perspectives</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-6" href="../jmlr2012/jmlr-2012-A_Model_of_the_Perception_of_Facial_Expressions_of_Emotion_by_Humans%3A_Research_Overview_and_Perspectives.html">jmlr2012-6</a> <a title="jmlr-2012-6-reference" href="#">jmlr2012-6-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>6 jmlr-2012-A Model of the Perception of Facial Expressions of Emotion by Humans: Research Overview and Perspectives</h1>
<br/><p>Source: <a title="jmlr-2012-6-pdf" href="http://jmlr.org/papers/volume13/martinez12a/martinez12a.pdf">pdf</a></p><p>Author: Aleix Martinez, Shichuan Du</p><p>Abstract: In cognitive science and neuroscience, there have been two leading models describing how humans perceive and classify facial expressions of emotion—the continuous and the categorical model. The continuous model deﬁnes each facial expression of emotion as a feature vector in a face space. This model explains, for example, how expressions of emotion can be seen at different intensities. In contrast, the categorical model consists of C classiﬁers, each tuned to a speciﬁc emotion category. This model explains, among other ﬁndings, why the images in a morphing sequence between a happy and a surprise face are perceived as either happy or surprise but not something in between. While the continuous model has a more difﬁcult time justifying this latter ﬁnding, the categorical model is not as good when it comes to explaining how expressions are recognized at different intensities or modes. Most importantly, both models have problems explaining how one can recognize combinations of emotion categories such as happily surprised versus angrily surprised versus surprise. To resolve these issues, in the past several years, we have worked on a revised model that justiﬁes the results reported in the cognitive science and neuroscience literature. This model consists of C distinct continuous spaces. Multiple (compound) emotion categories can be recognized by linearly combining these C face spaces. The dimensions of these spaces are shown to be mostly conﬁgural. According to this model, the major task for the classiﬁcation of facial expressions of emotion is precise, detailed detection of facial landmarks rather than recognition. We provide an overview of the literature justifying the model, show how the resulting model can be employed to build algorithms for the recognition of facial expression of emotion, and propose research directions in machine learning and computer vision researchers to keep pushing the state of the art in these areas. We also discuss how the model can aid in stu</p><br/>
<h2>reference text</h2><p>J. C. Barlett and J. Searcy. Inversion and conﬁguration of faces. Cognitive Psychology, 25(3): 281–316, 1993. J. M. Beale and F. C. Keil. Categorical effects in the perception of faces. Cognition, 57:217–239, 1995. R. Brunelli and T. Poggio. Face recognition: features versus templates. IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(10):1042–1052, 1993. A. J. Calder, A. W. Young, D. Rowland, and D. I. Perrett. Computer-enhanced emotion in facial expressions. Proceedings of the Royal Society of London B, 264:919–925, 1997. A. J. Calder, A. D. Lawrence, and A. W. Young. Neuropsychology of fear and loathing. Nature Review Neuroscience, 2:352–363, 2001. F. Castelli. Understanding emotions from standardized facial expressions in autism and normal development. Autism, 9:428–449, 2005. CDC. Center for Disease Control and Prevention. Prevalence of autism spectrum disorders autism and developmental disabilities monitoring network, 14 sites, united states, 2008. Morbidity and Mortality Weekly Report (MMWR), 61, 2012. T. F. Cootes, G. J. Edwards, and C. J. Taylor. Active appearance models. IEEE Trans. Pattern Analysis and Machine Intelligence, 23(6):681–685, 2001. A. R. Damasio. Descartes’ Error: Emotion, Reason, and the Human Brain. G. P. Putnam’s Sons, New York, 1995. C. Darwin. The Expression of the Emotions in Man and Animal. J. Murray., London, 1872. L. Ding and A. M. Martinez. Features versus context: An approach for precise and detailed detection and delineation of faces and facial features. IEEE Trans. Pattern Analysis and Machine Intelligence, 32:2022–2038, 2010. S. Du and A. M. Martinez. The resolution of facial expressions of emotion. Journal of Vision, 11(13):24, 2011. P. Ekman and W.V. Friesen. Pictures of Facial Affect. Consulting Psychologists Press, Palo Alto, CA, 1976. P. Ekman and E.L. Rosenberg. What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS). Oxford University Press, New York, 2nd edition, 2005. P. F. U. Gotardo and A. M. Martinez. Computing smooth time-trajectories for camera and deformable shape in structure from motion with occlusion. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(10):2051–2065, 2011a. 1605  M ARTINEZ AND D U  P. F. U. Gotardo and A. M. Martinez. Kernel non-rigid structure from motion. In Proceedings of the IEEE International Conference on Computer Vision, 2011b. O. C. Hamsici and A. M. Martinez. Bayes optimality in linear discriminant analysis. IEEE Trans. Pattern Analysis and Machine Intelligence, 30:647–657, 2008. O. C. Hamsici and A. M. Martinez. Rotation invariant kernels and their application to shape analysis. IEEE Trans. Pattern Analysis and Machine Intelligence, 31:1985–1999, 2009a. O. C. Hamsici and A. M. Martinez. Active appearance models with rotation invariant kernels. In IEEE Proc. International Conference on Computer Vision, 2009b. J. A. Hosie, H. D. Ellis, and N. D. Haig. The effect of feature displacement on the perception of well-known faces. Perception, 17(4):461–474, 1988. C. E. Izard. Emotion theory and research: Highlights, unanswered questions, and emerging issues. Annual Review of Psychology, 60:1–25, 2009. B. Jemel, L. Mottron, and M. Dawson. Impaired face processing in autism: Fact or artifact? Journal of Autism and Developmental Disorders, 36:91–106, 2006. T. Kanade. Picture Processing System by Computer Complex and Recognition of Human Faces. PhD thesis, Kyoto University, Japan, 1973. N. Lawrence. Probabilistic non-linear principal component analysis with gaussian process latent variable models. Journal of Machine Learning Research, (6):1783–1816, 2005. J.E. LeDoux. Emotion circuits in the brain. Annual Review of Nueroscience, 23:155–184, 2000. D. Lowe. Three-dimensional object recognition from single two-dimensional images. Artiﬁcial Intelligence, 31(3):355–395, 1983. D. Marr. Early processing of visual information. Philosophical Transactions of the Royal Society of London, 275(942):483–519, 1976. A. M. Martinez. Recognizing imprecisely localized, partially occluded and expression variant faces from a single sample per class. IEEE Trans. Pattern Analysis and Machine Intelligence, 24(6): 748–763, 2002. A. M. Martinez. Matching expression variant faces. Vision Research, 43:1047–1060, 2003. A. M. Martinez. Deciphering the face. In Proc. IEEE Conf. Computer Vision and Pattern Recognition, workshop, 2011. M. Minsky. The Society of Mind. Simon & Schuster, New York, N.Y., 1988. D. Neth and A. M. Martinez. Emotion perception in emotionless face images suggests a norm-based representation. Journal of Vision, 9(1):1–11, 2009. D. Neth and A. M. Martinez. A computational shape-based model of anger and sadness justiﬁes a conﬁgural representation of faces. Vision Research, 50:1693–1711, 2010. 1606  A M ODEL OF THE P ERCEPTION OF FACIAL E XPRESSIONS OF E MOTION  A. Pentland. Looking at people: Sensing for ubiquitous and wearable computing. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(1):107–119, 2000. M. Prior. Is there an increase in the prevalence of autism spectrum disorders? Journal of Paediatrics and Child Health, 39:81–82, 2003. G. Rhodes, S. Brennan, and S. Carey. Identiﬁcation and ratings of caricatures: implications for mental representations of faces. Cognitive Psychology, 19:473–497, 1987. S. Rivera and A. M. Martinez. Learning shape manifolds. Pattern Recognition, 45(4):1792–1801, 2012. E. T. Rolls. A theory of emotion, and its application to understanding the neural basis of emotion. Cognition and Emotion, 4:161–190, 1990. J. A. Russell. A circumplex model of affect. J. Personality Social. Psych., 39:1161–1178, 1980. J. A. Russell. Core affect and the psychological construction of emotion. Psychological Review, 110:145–172, 2003. K.L. Schmidt and J.F. Cohn. Human facial expressions as adaptations: Evolutionary questions in facial expression. Yearbook of Physical Anthropology, 44:3–24, 2001. L. Sirovich and M. Kirby. Low-dimensional procedure for the characterization of human faces. J. Optical Soc. Am. A, 4:519–524, 1987. F.W. Smith and P.G. Schyns. Smile through your fear and sadness: Transmitting and identifying facial expression signals over a range of viewing distances. Psychology Science, 20(10):1202– 1208, 2009. J. Susskind, D. Lee, A. Cusi, R. Feinman, W. Grabski, and A.K. Anderson. Expressing fear enhances sensory acquisition. Nature Neuroscience, 11(7):843–850, 2008. J.M. Susskind, G. Littlewort, M.S. Bartlett, and A.K. Anderson J. Movellanb. Human and computer recognition of facial expressions of emotion. Neuropsychologia, 45:152162, 2007. F. Dela Torre and J. F. Cohn. Facial expression analysis. In Th. B. Moeslund, A. Hilton, V. Kruger, and L. Sigal, editors, Guide to Visual Analysis of Humans: Looking at People, pages 377–410. Springer, 2011. M. Turk and A. Pentland. Eigenfaces for recognition. J. Cognitive Neuroscience, 3:71–86, 1991. T. Valentine. A uniﬁed account of the effects of distinctiveness, inversion, and race in face recognition. Quarterly Journal of Experimental Psychology A: Human Experimental Psychology, 43: 161–204, 1991. V. Vapnik. Statistical Learning Theory. John Wiley and Sons, New York, NY, 1998. D. A. Wilbraham, J. C. Christensen, A. M. Martinez, and J. T. Todd. Can low level image differences account for the ability of human observers to discriminate facial identity? Journal of Vision, 8 (5):1–12, 2008. 1607  M ARTINEZ AND D U  R. B. Wilbur. Nonmanuals, semantic operators, domain marking, and the solution to two outstanding puzzles in asl. In Nonmanuals in Sign Languages. John Benjamins, 2011. M.-H. Yang, D. J. Kriegman, and N. Ahuja. Detecting faces in images: A survey. IEEE Trans. Pattern Analysis and Machine Intelligence, 24(1):34–58, 2002. A. W. Young, D. Hellawell, and D. C. Hay. Conﬁgurational information in face perception. Perception, 16(6):747–759, 1987. L.A. Zebrowitz, M. Kikuchi, and J.M. Fellous. Facial resemblance to emotions: Group differences, impression effects, and race stereotypes. Journal of Personality and Social Psychology, 98(2): 175–189, 2010.  1608</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
