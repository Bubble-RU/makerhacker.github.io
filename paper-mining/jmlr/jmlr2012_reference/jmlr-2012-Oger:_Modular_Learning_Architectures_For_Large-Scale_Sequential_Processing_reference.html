<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>79 jmlr-2012-Oger: Modular Learning Architectures For Large-Scale Sequential Processing</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-79" href="../jmlr2012/jmlr-2012-Oger%3A_Modular_Learning_Architectures_For_Large-Scale_Sequential_Processing.html">jmlr2012-79</a> <a title="jmlr-2012-79-reference" href="#">jmlr2012-79-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>79 jmlr-2012-Oger: Modular Learning Architectures For Large-Scale Sequential Processing</h1>
<br/><p>Source: <a title="jmlr-2012-79-pdf" href="http://jmlr.org/papers/volume13/verstraeten12a/verstraeten12a.pdf">pdf</a></p><p>Author: David Verstraeten, Benjamin Schrauwen, Sander Dieleman, Philemon Brakel, Pieter Buteneers, Dejan Pecevski</p><p>Abstract: Oger (OrGanic Environment for Reservoir computing) is a Python toolbox for building, training and evaluating modular learning architectures on large data sets. It builds on MDP for its modularity, and adds processing of sequential data sets, gradient descent training, several crossvalidation schemes and parallel parameter optimization methods. Additionally, several learning algorithms are implemented, such as different reservoir implementations (both sigmoid and spiking), ridge regression, conditional restricted Boltzmann machine (CRBM) and others, including GPU accelerated versions. Oger is released under the GNU LGPL, and is available from http: //organic.elis.ugent.be/oger. Keywords: Python, modular architectures, sequential processing</p><br/>
<h2>reference text</h2><p>A.P. Davison, D. Br¨ derle, J. Eppler, J. Kremkow, E. Muller, D. Pecevski, L. Perrinet, and P. Yger. u Pynn: A common interface for neuronal network simulators. Frontiers in Neuroinformatics, 2, 2008. N. Hansen. The CMA evolution strategy: A comparing review. In Towards a New Evolutionary Computation, pages 75–102. Springer, 2006. D. Verstraeten, B. Schrauwen, M. D’Haene, and D. Stroobandt. A unifying comparison of reservoir computing methods. Neural Networks, 20:391–403, 2007. T. Zito, N. Wilbert, L. Wiskott, and P. Berkes. Modular toolkit for data processing (mdp): A python data processing framework. Frontiers in Neuroinformatics, 2, 2008.  2998</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
