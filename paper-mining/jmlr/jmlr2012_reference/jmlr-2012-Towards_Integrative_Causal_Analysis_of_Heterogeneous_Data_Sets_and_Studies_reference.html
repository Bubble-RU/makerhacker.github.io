<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-114" href="../jmlr2012/jmlr-2012-Towards_Integrative_Causal_Analysis_of_Heterogeneous_Data_Sets_and_Studies.html">jmlr2012-114</a> <a title="jmlr-2012-114-reference" href="#">jmlr2012-114-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>114 jmlr-2012-Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies</h1>
<br/><p>Source: <a title="jmlr-2012-114-pdf" href="http://jmlr.org/papers/volume13/tsamardinos12a/tsamardinos12a.pdf">pdf</a></p><p>Author: Ioannis Tsamardinos, Sofia Triantafillou, Vincenzo Lagani</p><p>Abstract: We present methods able to predict the presence and strength of conditional and unconditional dependencies (correlations) between two variables Y and Z never jointly measured on the same samples, based on multiple data sets measuring a set of common variables. The algorithms are specializations of prior work on learning causal structures from overlapping variable sets. This problem has also been addressed in the ﬁeld of statistical matching. The proposed methods are applied to a wide range of domains and are shown to accurately predict the presence of thousands of dependencies. Compared against prototypical statistical matching algorithms and within the scope of our experiments, the proposed algorithms make predictions that are better correlated with the sample estimates of the unknown parameters on test data ; this is particularly the case when the number of commonly measured variables is low. The enabling idea behind the methods is to induce one or all causal models that are simultaneously consistent with (ﬁt) all available data sets and prior knowledge and reason with them. This allows constraints stemming from causal assumptions (e.g., Causal Markov Condition, Faithfulness) to propagate. Several methods have been developed based on this idea, for which we propose the unifying name Integrative Causal Analysis (INCA). A contrived example is presented demonstrating the theoretical potential to develop more general methods for co-analyzing heterogeneous data sets. The computational experiments with the novel methods provide evidence that causallyinspired assumptions such as Faithfulness often hold to a good degree of approximation in many real systems and could be exploited for statistical inference. Code, scripts, and data are available at www.mensxmachina.org. Keywords: integrative causal analysis, causal discovery, Bayesian networks, maximal ancestral graphs, structural equation models, causality, statistical matching, data fusion</p><br/>
<h2>reference text</h2><p>B Abramson, J Brown, W Edwards, A Murphy, and RL Winkler. Hailﬁnder: A Bayesian system for forecasting severe weather. International Journal of Forecasting, 12(1):57–71, 1996. J Alcal´ -Fdez, L S´ nchez, S Garc´a, M J Jesus, S Ventura, J M Garrell, J Otero, C Romero, J Baca a ı ardit, V M Rivas, J C Fern´ ndez, and F Herrera. KEEL: a software tool to assess evolutionary a algorithms for data mining problems. Soft Computing, 13(3):307–318, 2009. CF Aliferis, A Statnikov, I Tsamardinos, S Mani, and X Koutsoukos. Local causal and Markov blanket induction for causal discovery and feature selection for classiﬁcation part ii : Analysis and extensions. Journal of Machine Learning Research, 11:235–284, 2010. N Angelopoulos and J Cussens. Bayesian learning of Bayesian networks with informative priors. Annals of Mathematics and Artiﬁcial Intelligence, 54(1-3):53–98, 2008. Y Aphinyanaphongs, AR Statnikov, and CF Aliferis. A comparison of citation metrics to machine learning ﬁlters for the identiﬁcation of high quality MEDLINE documents. JAMIA, 13(4):446– 455, 2006. A Balke and J Pearl. Bounds on treatment effects from studies with imperfect compliance. Journal of the American Statistical Association, 92(439):1172–1176, 1997. IA Beinlich, HJ Suermondt, RM Chavez, and GF Cooper. The ALARM monitoring system: A case study with two probabilistic inference techniques for belief networks. In Second European Conference on Artiﬁcial Intelligence in Medicine, volume 38, pages 247–256. Springer-Verlag, Berlin, 1989. J Binder, D Koller, S Russell, and K Kanazawa. Adaptive probabilistic networks with hidden variables. Machine Learning, 29, 1997. JA Blackard and DJ Dean. Comparative accuracies of artiﬁcial neural networks and discriminant analysis in predicting forest cover types from cartographic variables. Computers and Electronics in Agriculture, 24(3):131–151, 1999. G Borboudakis, S Triantaﬁllou, V Lagani, and I Tsamardinos. A constraint-based approach to incorporate prior knowledge in causal models. In Proceedings of the European Symposium on Artiﬁcial Neural Networks, Computational Intelligence and Machine Learning (ESANN), 2011. M Cannataro, D Talia, and P Trunﬁo. Distributed data mining on the grid. Future Gener. Comput. Syst., 18:1101–1112, October 2002. T Claassen and T Heskes. Causal discovery in multiple models from different experiments. In Advances in Neural Information Processing Systems (NIPS 2010), volume 23, pages 1–9, 2010. TP et al. Conrads. High-resolution serum proteomic features for ovarian cancer detection. Endocrine-Related Cancer, 11(2):163–78, 2004. GF Cooper and Ch Yoo. Causal discovery from a mixture of experimental and observational data. In Proceedings of Uncertainty in Artiﬁcial Intelligence (UAI 1999), volume 10, pages 116–125, 1999. 1153  T SAMARDINOS , T RIANTAFILLOU AND L AGANI  P Cortez, Ao Cerdeira, F Almeida, T Matos, and J Reis. Modeling wine preferences by data mining from physicochemical properties. Decision Support Systems, 47(4):547–553, November 2009. ISSN 01679236. R Cudeck. An estimate of the covariance between variables which are not jointly observed. Psychometrika, 65(4):539–546, 2000. SA Danziger, R Baronio, L Ho, L Hall, K Salmon, GW Hatﬁeld, P Kaiser, and RH Lathrop. Predicting positive p53 cancer rescue regions using most informative positive (MIP) active learning. PLoS Computational Biology, 5(9):12, 2009. M D’Orazio, MD Zio, and M Scanu. Statistical Matching: Theory and Practice. Wiley, 2006. F Eberhardt. A sufﬁcient condition for pooling data. Synthese, 163(3):433–442, February 2008. F Eberhardt, PO Hoyer, and R Scheines. Combining experiments to discover linear cyclic models with latent variables. In Proceedings of Artiﬁcial Intelligence anf Statistics 2010, volume 9, pages 185–192, 2010. C Elkan. Magical thinking in data mining: lessons from CoIL challenge 2000. Proceedings of the seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 426–431, 2001. RA Fisher. On the interpretation of χ2 from contingency tables, and the calculation of p. Journal of the Royal Statistical Society, 85(1):87–94, 1922. A Frank and A Asuncion. UCI machine learning repository, http://archive.ics.uci.edu/ml.  2010.  URL  JH Gennari, ML Neal, BE Carlson, and DL Cook. Integration of multi-scale biosimulation models via light-weight semantics. Paciﬁc Symposium On Biocomputing, 425:414–25, 2008. L Getoor and B Taskar. Introduction to Statistical Relational Learning, volume L. The MIT Press, 2007. HA Guvenir and I Uysal. Bilkent University function approximation repository, 2000. URL http://funapp.cs.bilkent.edu.tr. I Guyon, S Gunn, M Nikravesh, and L Zadeh. Feature Extraction, Foundations and Applications. Springer–Verlag, Berlin, Germany, 2006a. I Guyon, A Saffari, G Dror, and J Buhmann. Performance prediction challenge. The 2006 IEEE International Joint Conference on Neural Network Proceedings, pages 1649–1656, 2006b. A Hyttinen, F Eberhardt, and PO Hoyer. Causal discovery for linear cyclic models with latent variables. In Proccedings of the 5th European Workshop on Probabilistic Graphical Models, 2010. A Hyttinen, F Eberhardt, and PO Hoyer. Noisy-OR models with latent confounding. In Proceedings of the 27th Conference on Uncertainty in Artiﬁcial Intelligence (UAI 2011), 2011. 1154  T OWARDS I NTEGRATIVE C AUSAL A NALYSIS  Th Joachims. Learning to Classify Text Using Support Vector Machines: Methods, Theory and Algorithms. (The Kluwer International Series in Engineering and Computer Science). Springer, 2002. SH Kim. Markovian combination of subgraphs of DAGs. In Proceedings of The 10th IASTED International Conference on Artiﬁcial Intelligence and Applications, pages 90–95, 2010. SH Kim and S Lee. New Developments in Robotics, Automation and Control. In-Tech, Vienna, Austria, 2008. MH Maathuis, M Kalisch, and P B¨ hlmann. Estimating high-dimensional intervention effects from u observational data. Annals of Statistics, 37:3133–3164, 2009. MH Maathuis, D Colombo, M Kalisch, and P B¨ hlmann. Predicting causal effects in large-scale u systems from observational data. Nature Methods, 7(4):247–248, 2010. ISSN 15487105. S Mani and GF Cooper. Causal discovery using a Bayesian local causal discovery algorithm. Medinfo 2004, 11:731–735, 2004. C Meek. Causal inference and causal explanation with background knowledge. In Proceedings of the 11th Conference of Uncertainty in Aritﬁcial Intelligence, pages 403–410, 1995. C Moriarity and F Scheuren. Statistical matching: a paradigm for assessing the uncertainty in the procedure. Journal of Ofﬁcial Statistics, 17:407–422, 2001. RT O’Donnell, AE Nicholson, B. Han, KB Korb, MJ Alam, and LR Hope. Incorporating Expert Elicited Structural Information in the CaMML Causal Discovery Program. Technical report, Clayton School of Information Technology, Monash University, Melbourne, 2006. K O’Rourke. An historical perspective on meta-analysis: dealing quantitatively with varying study results. Journal of the Royal Society of Medicine, 100(12):579–582, 2007. SJ Pan and Q Yang. A Survey on Transfer Learning. IEEE Transactions on Knowledge and Data Engineering, 22(10):1345–1359, 2010. J Pearl. Causality: Models, Reasoning and Inference, volume 113 of Hardcover. Cambridge University Press, 2000. J Pearl. Causal inference in statistics: an overview. Statistics Surveys, 3:96–146, 2009. K Pearson. On a criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can reasonably be supposed to have arisen from random sampling. Philosophical Magazine, 50(50):157–175, 1900. JP Pellet and A Elisseeff. Finding latent causes in causal networks: an efﬁcient approach based on Markov blankets. In Proceedings of the 22nd Annual Conference on Neural Information Processing Systems, 2008. J Ramsey, P Spirtes, and J Zhang. Adjacency faithfulness and conservative causal inference. In Proceedings of Uncertainty in Artiﬁcial Intelligence, 2006. 1155  T SAMARDINOS , T RIANTAFILLOU AND L AGANI  T Richardson and P Spirtes. Ancestral graph markov models. The Annals of Statistics, 30(4): 962–1030, 2002. A Rosenwald et al. The use of molecular proﬁling to predict survival after chemotherapy for diffuse large-b-cell lymphoma. N Engl J Med, 346(25):1937–1947, 2002. DG Rubin. Characterizing the estimation of parameters in incomplete-data problems. Journal of the American Statistical Association, 69:467–474, 1974. G Samsa, G Hu, and M Root. Combining information from multiple data sources to create multivariable risk models: Illustration and preliminary assessment of a new method. Journal of Biomedicine and Biotechnology, 2005(2):113–123, 2005. S Shimizu, PO Hoyer, A Hyv¨ rinen, and A Kerminen. A linear non-Gaussian acyclic model for a causal discovery. Journal of Machine Learning Research, 7(2):2003–2030, 2006. S Shimizu, T Inazumi, Y Sogawa, A Hyvarinen, Y Kawahara, T Washio, PO Hoyer, and K Bollen. DirectLiNGAM: a direct method for learning a linear non-Gaussian structural equation model. Journal of Machine Learning Research, 12:1225–1248, 2011. A Spanos. Revisiting the omitted variables argument: Substantive vs. statistical adequacy. Journal of Economic Methodology, 13(2):179–218, 2006. P Spirtes and TS Richardson. A polynomial time algorithm for determining DAG equivalence in the presence of latent variables and selection bias. In Proceedings of the 6th International Workshop on Artiﬁcial Intelligence and Statistics, pages 489–500, 1996. P Spirtes, C Glymour, and R Scheines. Causation, Prediction, and Search. The MIT Press, second edition, January 2001. J Tian and J Pearl. Causal Discovery from Changes. Proceedings of UAI, pages 512–521, 2001. RE Tillman. Structure learning with independent non-identically distributed data. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 1041–1048. ACM, 2009. RE Tillman and P Spirtes. Learning equivalence classes of acyclic models with latent and selection variables from multiple datasets with overlapping variables. In Proceedings of the 14th International Conference on Artiﬁcial Intelligence and Statistics, volume 15, pages 3–15, 2011. RE Tillman, David Danks, and Clark Glymour. Integrating locally learned causal structures with overlapping variables. In Advances in Neural Information Processing Systems (NIPS, 2008. S Triantaﬁllou, I Tsamardinos, and IG Tollis. Learning causal structure from overlapping variable sets. In Proceedings of Artiﬁcial Intelligence and Statistics, volume 9, 2010. I Tsamardinos and G Borboudakis. Permutation testing improves Bayesian network learning. In ECML PKDD, pages 322–337, 2010. I Tsamardinos and LE Brown. Bounding the false discovery rate in local Bayesian network learning. In Proceedings of the 23rd Conference on Artiﬁcial Intelligence (AAAI), pages 1100–1105, 2008. 1156  T OWARDS I NTEGRATIVE C AUSAL A NALYSIS  I Tsamardinos and S Triantaﬁllou. The possibility of integrative causal analysis: Learning from different datasets and studies. Journal of Engineering Intelligent Systems, 17(2/3):163–175, 2009. I Tsamardinos, LE Brown, and CF Aliferis. The max-min hill-climbing Bayesian network structure learning algorithm. Machine Learning, 65(1):31–78, 2006. G Tsoumakas, I Katakis, and I Vlahavas. Mining multi-label data. Data Mining and Knowledge Discovery Handbook, pages 1–20, 2010. B Vantaggi. Statistical matching of multiple sources: A look through coherence. Int. J. Approx. Reasoning, 49(3):701–711, 2008. Y et al. Wang. Gene-expression proﬁles to predict distant metastasis of lymph-node-negative primary breast cancer. Lancet, 365(9460):671–679, 2005. AV Werhli and D Husmeier. Reconstructing gene regulatory networks with Bayesian networks by combining expression data with multiple sources of prior knowledge. Statistical Applications in Genetics and Molecular Biology, 6(1):Article15, 2007. S Wright. The method of path coefﬁcients. The Annals of Mathematical Statistics, 5(3):161–215, 1934. J Zhang. On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias. Artiﬁcial Intelligence, 172(16-17):1873–1896, 2008. XH Zhou, N Hu, G Hu, and M Root. Synthesis analysis of regression models with a continuous outcome. Statistics in Medicine, 28(11):1620–1635, 2009. DW Zimmerman, BD Zumbo, and RH Williams. Bias in estimation and hypothesis testing of correlation. Psicoliogica, 24:133–158, 2003.  1157</p>
<br/>
<br/><br/><br/></body>
</html>
