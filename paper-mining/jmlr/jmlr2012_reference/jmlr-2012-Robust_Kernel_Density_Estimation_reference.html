<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>100 jmlr-2012-Robust Kernel Density Estimation</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-100" href="../jmlr2012/jmlr-2012-Robust_Kernel_Density_Estimation.html">jmlr2012-100</a> <a title="jmlr-2012-100-reference" href="#">jmlr2012-100-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>100 jmlr-2012-Robust Kernel Density Estimation</h1>
<br/><p>Source: <a title="jmlr-2012-100-pdf" href="http://jmlr.org/papers/volume13/kim12b/kim12b.pdf">pdf</a></p><p>Author: JooSeuk Kim, Clayton D. Scott</p><p>Abstract: We propose a method for nonparametric density estimation that exhibits robustness to contamination of the training sample. This method achieves robustness by combining a traditional kernel density estimator (KDE) with ideas from classical M-estimation. We interpret the KDE based on a positive semi-deﬁnite kernel as a sample mean in the associated reproducing kernel Hilbert space. Since the sample mean is sensitive to outliers, we estimate it robustly via M-estimation, yielding a robust kernel density estimator (RKDE). An RKDE can be computed efﬁciently via a kernelized iteratively re-weighted least squares (IRWLS) algorithm. Necessary and sufﬁcient conditions are given for kernelized IRWLS to converge to the global minimizer of the M-estimator objective function. The robustness of the RKDE is demonstrated with a representer theorem, the inﬂuence function, and experimental results for density estimation and anomaly detection. Keywords: outlier, reproducing kernel Hilbert space, kernel trick, inﬂuence function, M-estimation</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
