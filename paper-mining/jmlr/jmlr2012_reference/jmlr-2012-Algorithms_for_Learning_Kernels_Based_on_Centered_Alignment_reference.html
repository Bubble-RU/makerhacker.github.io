<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>16 jmlr-2012-Algorithms for Learning Kernels Based on Centered Alignment</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-16" href="../jmlr2012/jmlr-2012-Algorithms_for_Learning_Kernels_Based_on_Centered_Alignment.html">jmlr2012-16</a> <a title="jmlr-2012-16-reference" href="#">jmlr2012-16-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>16 jmlr-2012-Algorithms for Learning Kernels Based on Centered Alignment</h1>
<br/><p>Source: <a title="jmlr-2012-16-pdf" href="http://jmlr.org/papers/volume13/cortes12a/cortes12a.pdf">pdf</a></p><p>Author: Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh</p><p>Abstract: This paper presents new and effective algorithms for learning kernels. In particular, as shown by our empirical results, these algorithms consistently outperform the so-called uniform combination solution that has proven to be difﬁcult to improve upon in the past, as well as other algorithms for learning kernels based on convex combinations of base kernels in both classiﬁcation and regression. Our algorithms are based on the notion of centered alignment which is used as a similarity measure between kernels or kernel matrices. We present a number of novel algorithmic, theoretical, and empirical results for learning kernels based on our notion of centered alignment. In particular, we describe efﬁcient algorithms for learning a maximum alignment kernel by showing that the problem can be reduced to a simple QP and discuss a one-stage algorithm for learning both a kernel and a hypothesis based on that kernel using an alignment-based regularization. Our theoretical results include a novel concentration bound for centered alignment between kernel matrices, the proof of the existence of effective predictors for kernels with high alignment, both for classiﬁcation and for regression, and the proof of stability-based generalization bounds for a broad family of algorithms for learning kernels based on centered alignment. We also report the results of experiments with our centered alignment-based algorithms in both classiﬁcation and regression. Keywords: kernel methods, learning kernels, feature selection</p><br/>
<h2>reference text</h2><p>Andreas Argyriou, Charles Micchelli, and Massimiliano Pontil. Learning convex combinations of continuously parameterized basic kernels. In COLT, 2005. Andreas Argyriou, Raphael Hauser, Charles Micchelli, and Massimiliano Pontil. programming algorithm for kernel selection. In ICML, 2006.  A DC-  Francis Bach. Exploring large feature spaces with hierarchical multiple kernel learning. In NIPS, 2008. Maria-Florina Balcan and Avrim Blum. On a theory of learning with similarity functions. In ICML, 2006. John Blitzer, Mark Dredze, and Fernando Pereira. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classiﬁcation. In ACL, 2007. 826  A LGORITHMS FOR L EARNING K ERNELS BASED ON C ENTERED A LIGNMENT  Bernhard Boser, Isabelle Guyon, and Vladimir Vapnik. A training algorithm for optimal margin classiﬁers. In COLT, volume 5, 1992. Olivier Bousquet and Andr´ Elisseeff. Algorithmic stability and generalization performance. In e NIPS, 2000. Olivier Bousquet and Daniel J. L. Herrmann. On the complexity of learning the kernel matrix. In NIPS, 2002. Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, 2004. Olivier Chapelle, Vladimir Vapnik, Olivier Bousquet, and Sayan Mukherjee. Choosing multiple parameters for support vector machines. Machine Learning, 46(1-3), 2002. Corinna Cortes. Invited talk: Can learning kernels help performance? In ICML, 2009. Corinna Cortes and Vladimir Vapnik. Support-Vector Networks. Machine Learning, 20(3), 1995. Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Learning sequence kernels. In MLSP, 2008. Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. L2 -regularization for learning kernels. In UAI, 2009a. Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Learning non-linear combinations of kernels. In NIPS, 2009b. Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Two-stage learning kernel methods. In ICML, 2010a. Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Generalization bounds for learning kernels. In ICML, 2010b. Corinna Cortes, Mehryar Mohri, and Ameet Talwalkar. On the Impact of Kernel Approximation on Learning Accuracy. In AISTATS, 2010c. Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Ensembles of kernel predictors. In UAI, 2011a. Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Tutorial: Learning kernels. In ICML, 2011b. Nello Cristianini, John Shawe-Taylor, Andr´ Elisseeff, and Jaz S. Kandola. On kernel-target aligne ment. In NIPS, 2001. Nello Cristianini, Jaz S. Kandola, Andr´ Elisseeff, and John Shawe-Taylor. On kernel target aligne ment. http://www.support-vector.net/papers/alignment JMLR.ps, unpublished, 2002. Arthur Gretton, Olivier Bousquet, Alexander Smola, and Bernhard Sch¨ lkopf. Measuring statistical o dependence with Hilbert-Schmidt norms. In Algorithmic learning theory, 2005. Tony Jebara. Multi-task feature and kernel selection for SVMs. In ICML, 2004. 827  C ORTES , M OHRI AND ROSTAMIZADEH  Jaz S. Kandola, John Shawe-Taylor, and Nello Cristianini. On the extensions of kernel alignment. technical report 120, Department of Computer Science, Univ. of London, UK, 2002a. Jaz S. Kandola, John Shawe-Taylor, and Nello Cristianini. Optimizing kernel alignment over combinations of kernels. technical report 121, Dept. of CS, Univ. of London, UK, 2002b. Seung-Jean Kim, Alessandro Magnani, and Stephen Boyd. Optimal kernel selection in kernel ﬁsher discriminant analysis. In ICML, 2006. Vladimir Koltchinskii and Ming Yuan. Sparse recovery in large ensembles of kernel machines. In COLT, 2008. Gert Lanckriet, Nello Cristianini, Peter Bartlett, Laurent El Ghaoui, and Michael Jordan. Learning the kernel matrix with semideﬁnite programming. JMLR, 5, 2004. Darrin P. Lewis, Tony Jebara, and William Stafford Noble. Nonstationary kernel combination. In ICML, 2006. Colin McDiarmid. On the method of bounded differences. Surveys in combinatorics, 141, 1989. Marina Meila. Data centering in feature space. In AISTATS, 2003. Charles Micchelli and Massimiliano Pontil. Learning the kernel function via regularization. JMLR, 6, 2005. Cheng Soon Ong, Alexander Smola, and Robert Williamson. Learning the kernel with hyperkernels. JMLR, 6, 2005. Jean-Baptiste Pothin and C´ dric Richard. Optimizing kernel alignment by data translation in feature e space. In ICASSP, 2008. Craig Saunders, A. Gammerman, and Volodya Vovk. Ridge regression learning algorithm in dual variables. In ICML, 1998. S¨ ren Sonnenburg, Gunnar R¨ tsch, Christin Sch¨ fer, and Bernhard Sch¨ lkopf. Large scale multiple o a a o kernel learning. Journal of Machine Learning Research, 7:1531–1565, 2006. Nathan Srebro and Shai Ben-David. Learning bounds for support vector machines with learned kernels. In COLT, 2006. Vladimir N. Vapnik. Statistical Learning Theory. John Wiley & Sons, 1998. Manik Varma and Bodla Rakesh Babu. More generality in efﬁcient multiple kernel learning. In ICML, 2009. Alexander Zien and Cheng Soon Ong. Multiclass multiple kernel learning. In ICML, 2007.  828</p>
<br/>
<br/><br/><br/></body>
</html>
