<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 jmlr-2012-glm-ie: Generalised Linear Models Inference & Estimation Toolbox</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-119" href="../jmlr2012/jmlr-2012-glm-ie%3A_Generalised_Linear_Models_Inference_%26_Estimation_Toolbox.html">jmlr2012-119</a> <a title="jmlr-2012-119-reference" href="#">jmlr2012-119-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>119 jmlr-2012-glm-ie: Generalised Linear Models Inference & Estimation Toolbox</h1>
<br/><p>Source: <a title="jmlr-2012-119-pdf" href="http://jmlr.org/papers/volume13/nickisch12a/nickisch12a.pdf">pdf</a></p><p>Author: Hannes Nickisch</p><p>Abstract: The glm-ie toolbox contains functionality for estimation and inference in generalised linear models over continuous-valued variables. Besides a variety of penalised least squares solvers for estimation, it offers inference based on (convex) variational bounds, on expectation propagation and on factorial mean ﬁeld. Scalable and efﬁcient inference in fully-connected undirected graphical models or Markov random ﬁelds with Gaussian and non-Gaussian potentials is achieved by casting all the computations as matrix vector multiplications. We provide a wide choice of penalty functions for estimation, potential functions for inference and matrix classes with lazy evaluation for convenient modelling. We designed the glm-ie package to be simple, generic and easily expansible. Most of the code is written in Matlab including some MEX ﬁles to be fully compatible to both Matlab 7.x and GNU Octave 3.3.x. Large scale probabilistic classiﬁcation as well as sparse linear modelling can be performed in a common algorithmical framework by the glm-ie toolkit. Keywords: sparse linear models, generalised linear models, Bayesian inference, approximate inference, probabilistic regression and classiﬁcation, penalised least squares estimation, lazy evaluation matrix class</p><br/>
<h2>reference text</h2><p>Jonathan Barzilai and Jonathan M. Borwein. Two-point step size gradient methods. IMA Journal of Numerical Analysis, 8:141–148, 1988. 7. The example is a shortened version of one the detailed application examples, which are part of the documentation of the glm-ie package.  1702  G L M-I E :  G ENERALISED L INEAR M ODELS I NFERENCE & E STIMATION TOOLBOX  Tom Goldstein and Stanley Osher. The split Bregman method for l1 regularized problems. SIAM Journal on Imaging Sciences, 2(2):323–343, 2009. URL ftp://ftp.math.ucla.edu/pub/ camreport/cam08-29.pdf. Michael Lustig, David L. Donoho, and John M. Pauly. Sparse MRI: The application of compressed sensing for rapid MR imaging. Magnetic Resonance in Medicine, 58(6):1182–1195, 2007. Tom Minka. Expectation propagation for approximate Bayesian inference. In UAI, 2001. James Miskin and David J.C. MacKay. Ensemble learning for blind image separation and deconvolution. In Advances in Independent Component Analysis, 2000. Hannes Nickisch and Matthias Seeger. Convex variational Bayesian inference for large scale generalized linear models. In ICML, 2009. Manfred Opper and Ole Winther. Adaptive and selfaveraging Thouless-Anderson-Palmer mean ﬁeld theory for probabilistic modeling. Physical Review E, 64:056131, 2001. George Papandreou and Alan Yuille. Efﬁcient variational inference in large-scale Bayesian compressed sensing. In Proc. IEEE Workshop on Information Theory in Computer Vision and Pattern Recognition (in conjunction with ICCV), 2011. Carl E. Rasmussen. minimize.m, September 2006. URL http://www.kyb.tuebingen.mpg.de/ bs/people/carl/code/minimize/. Matthias W. Seeger and Hannes Nickisch. Large scale variational inference and experimental design for sparse generalized linear models. SIAM Journal on Imaging Sciences, 4(1):166–199, 2011. Matthias W. Seeger, Hannes Nickisch, Rolf Pohmann, and Bernhard Sch¨ lkopf. Bayesian experio mental design of magnetic resonance imaging sequences. In NIPS, 2009. Matthias W. Seeger, Hannes Nickisch, Rolf Pohmann, and Bernhard Sch¨ lkopf. Optimization of ko space trajectories for compressed sensing by bayesian experimental design. Magnetic Resonance in Medicine, 63(1):116–126, 2010. L-BFGS-B. by Ciyou Zhu, Richard Byrd and Jorge Nocedal., 1997. URL http://www.eecs. northwestern.edu/˜nocedal/lbfgsb.html. Marcel van Gerven, Botond Cseke, Floris de Lange, and Tom Heskes. Efﬁcient Bayesian multivariate fMRI analysis using a sparsifying spatio-temporal prior. Neuroimage, 50:150–161, 2010. David Wipf and Srikantan Nagarajan. A new view of automatic relevance determination. In NIPS, 2008.  1703</p>
<br/>
<br/><br/><br/></body>
</html>
