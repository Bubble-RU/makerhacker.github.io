<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>102 jmlr-2012-Sally: A Tool for Embedding Strings in Vector Spaces</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2012" href="../home/jmlr2012_home.html">jmlr2012</a> <a title="jmlr-2012-102" href="../jmlr2012/jmlr-2012-Sally%3A_A_Tool_for_Embedding_Strings_in_Vector_Spaces.html">jmlr2012-102</a> <a title="jmlr-2012-102-reference" href="#">jmlr2012-102-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>102 jmlr-2012-Sally: A Tool for Embedding Strings in Vector Spaces</h1>
<br/><p>Source: <a title="jmlr-2012-102-pdf" href="http://jmlr.org/papers/volume13/rieck12a/rieck12a.pdf">pdf</a></p><p>Author: Konrad Rieck, Christian Wressnegger, Alexander Bikadorov</p><p>Abstract: Strings and sequences are ubiquitous in many areas of data analysis. However, only few learning methods can be directly applied to this form of data. We present Sally, a tool for embedding strings in vector spaces that allows for applying a wide range of learning methods to string data. Sally implements a generalized form of the bag-of-words model, where strings are mapped to a vector space that is spanned by a set of string features, such as words or n-grams of words. The implementation of Sally builds on efﬁcient string algorithms and enables processing millions of strings and features. The tool supports several data formats and is capable of interfacing with common learning environments, such as Weka, Shogun, Matlab, or Pylab. Sally has been successfully applied for learning with natural language text, DNA sequences and monitored program behavior. Keywords: string embedding, bag-of-words models, learning with sequential data</p><br/>
<h2>reference text</h2><p>M. Damashek. Gauging similarity with n-grams: language-independent categorization of text. Science, 267(5199):843–848, 1995. M. Jawurek, M. Johns, and K. Rieck. Smart metering de-pseudonymization. In Proc. of Annual Computer Security Applications Conference (ACSAC), pages 227–236, Dec. 2011. B. Klimt and Y. Yang. The Enron corpus: a new dataset for email classiﬁcation research. In Proc. of Conference on Email and Anti-Spam (CEAS), 2004. C. Leslie, E. Eskin, and W. Noble. The spectrum kernel: a string kernel for SVM protein classiﬁcation. In Proc. of Paciﬁc Symposium on Biocomputing (PSB), pages 564–575, 2002. H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini, and C. Watkins. Text classiﬁcation using string kernels. Journal of Machine Learning Research, 2:419–444, 2002. C. O’Donovan, M. Martin, A. Gattiker, E. Gasteiger, A. Bairoch, and R. Apweiler. High-quality protein knowledge resource: SWISS-PROT and TrEMBL. Brieﬁngs in Bioinformatics, 3(3): 275–284, 2002. K. Rieck and P. Laskov. Linear-time computation of similarity measures for sequential data. Journal of Machine Learning Research, 9(Jan):23–48, Jan. 2008. K. Rieck, P. Trinius, C. Willems, and T. Holz. Automatic analysis of malware behavior using machine learning. Journal of Computer Security (JCS), 19(4):639–668, June 2011. G. Salton, A. Wong, and C. Yang. A vector space model for automatic indexing. Communications of the ACM, 18(11):613–620, 1975. J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press, 2004. Q. Shi, J. Petterson, G. Dror, J. Langford, A. Smola, and S. Vishwanathan. Hash kernels for structured data. Journal of Machine Learning Research, 10(Nov):2615–2637, 2009. S. Sonnenburg, A. Zien, and G. R¨ tsch. ARTS: accurate recognition of transcription starts in human. a Bioinformatics, 22(14):e472–e480, 2006. S. Sonnenburg, G. R¨ tsch, and K. Rieck. Large scale learning with string kernels. In Large Scale a Kernel Machines, pages 73–103. MIT Press, Sept. 2007. S. Wahl, K. Rieck, P. Laskov, P. Domschitz, and K.-R. M¨ ller. Securing IMS against novel threats. u Bell Labs Technical Journal, 14(1):243–257, May 2009.  3251</p>
<br/>
<br/><br/><br/></body>
</html>
