<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>6 jmlr-2005-A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-6" href="../jmlr2005/jmlr-2005-A_Modified_Finite_Newton_Method_for_Fast_Solution_of_Large_Scale_Linear_SVMs.html">jmlr2005-6</a> <a title="jmlr-2005-6-reference" href="#">jmlr2005-6-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>6 jmlr-2005-A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs</h1>
<br/><p>Source: <a title="jmlr-2005-6-pdf" href="http://jmlr.org/papers/volume6/keerthi05a/keerthi05a.pdf">pdf</a></p><p>Author: S. Sathiya Keerthi, Dennis DeCoste</p><p>Abstract: This paper develops a fast method for solving linear SVMs with L2 loss function that is suited for large scale data mining tasks such as text classiﬁcation. This is done by modifying the ﬁnite Newton method of Mangasarian in several ways. Experiments indicate that the method is much faster than decomposition methods such as SVMlight , SMO and BSVM (e.g., 4-100 fold), especially when the number of examples is large. The paper also suggests ways of extending the method to other loss functions such as the modiﬁed Huber’s loss function and the L1 loss function, and also for solving ordinal regression. Keywords: linear SVMs, classiﬁcation, conjugate gradient</p><br/>
<h2>reference text</h2><p>D. P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, Belmont, Massachussetts, 1999. A. Bj¨ rck. Numerical Methods for Least Squares Problems. SIAM, Philadelphia, 1996. o C. L. Blake and C. J. Merz. UCI repository of machine learning databases. Technical report, University of California, Irvine, 1998. www.ics.uci.edu/∼mlearn/MLRepository.html. S. Chakrabarti, S. Roy, and M. V. Soundalgekar. Fast and accurate text classiﬁcation via multiple linear discriminant projections. The VLDB Journal, 12:170–185, 2003. W. Chu and S. S. Keerthi. New approaches to support vector ordinal regression. Technical report, Yahoo! Research Labs, Pasadena, California, USA, 2005. D. DeCoste and K. Wagstaff. Alpha seeding for support vector machines. In Proceedings of the International Conference on Knowledge Discovery and Data Mining, pages 345–359, 2000. A. Frommer and P. Maaß. Fast CG-based methods for Tikhonov-Phillips regularization. SIAM Journal of Scientiﬁc Computing, 20(5):1831–1850, 1999. G. Fung and O. L. Mangasarian. Proximal support vector machine classiﬁers. In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 77–86, 2001. C. W. Hsu and C. J. Lin. A simple decomposition method for support vector machines. Machine Learning, 46:291–314, 2002. T. Joachims. Making large-scale SVM learning practical. In Advances in Kernel Methods - Support Vector Learning. MIT Press, Cambridge, Massachussetts, 1999. W. C. Kao, K.M. Chung, T. Sun, and C. J. Lin. Decomposition methods for linear support vector machines. Neural Computation, 16:1689–1704, 2004. P. Komarek. Logistic regression for data mining and high-dimensional classiﬁcation. Ph.d. thesis, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA, 2004. O. L. Mangasarian. A ﬁnite Newton method for classiﬁcation. Optimization Methods and Software, 17:913–929, 2002. 360  F INITE N EWTON METHOD FOR LINEAR SVM S  A. McCallum. Bow: A toolkit for statistical language modeling, text retrieval, classiﬁcation and clustering. Technical report, University of Massachssetts, Amherst, Massachussetts, USA, 1996. www.cs.cmu.edu/∼mccallum/bow. C. C. Paige and M. A. Saunders. LSQR: An algorithm for sparse linear equations and sparse least squares,. ACM Transactions on Mathematical Software, 8:43–71, 1982. J. Platt. Sequential minimal optimization: A fast algorithm for training support vector machines. In Advances in Kernel Methods - Support Vector Learning. MIT Press, Cambridge, Massachussetts, 1999. J. Suykens and J. Vandewalle. Least squares support vector machine classiﬁers. Neural Processing Letters, 9(3):293–300, 1999. J. Zhang, R. Jin, Y. Yang, and A. Hauptmann. Modiﬁed logistic regression: An approximation to SVM and its applications in large-scale text categorization. In Twentieth International Conference on Machine Learning, pages 472–479, 2003. T. Zhang. Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization. The Annals of Statistics, 32:56–85, 2004.  361</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
