<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>38 jmlr-2005-Generalization Bounds for the Area Under the ROC Curve</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-38" href="../jmlr2005/jmlr-2005-Generalization_Bounds_for_the_Area_Under_the_ROC_Curve.html">jmlr2005-38</a> <a title="jmlr-2005-38-reference" href="#">jmlr2005-38-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>38 jmlr-2005-Generalization Bounds for the Area Under the ROC Curve</h1>
<br/><p>Source: <a title="jmlr-2005-38-pdf" href="http://jmlr.org/papers/volume6/agarwal05a/agarwal05a.pdf">pdf</a></p><p>Author: Shivani Agarwal, Thore Graepel, Ralf Herbrich, Sariel Har-Peled, Dan Roth</p><p>Abstract: We study generalization properties of the area under the ROC curve (AUC), a quantity that has been advocated as an evaluation criterion for the bipartite ranking problem. The AUC is a different term than the error rate used for evaluation in classiﬁcation problems; consequently, existing generalization bounds for the classiﬁcation error rate cannot be used to draw conclusions about the AUC. In this paper, we deﬁne the expected accuracy of a ranking function (analogous to the expected error rate of a classiﬁcation function), and derive distribution-free probabilistic bounds on the deviation of the empirical AUC of a ranking function (observed on a ﬁnite data sequence) from its expected accuracy. We derive both a large deviation bound, which serves to bound the expected accuracy of a ranking function in terms of its empirical AUC on a test sequence, and a uniform convergence bound, which serves to bound the expected accuracy of a learned ranking function in terms of its empirical AUC on a training sequence. Our uniform convergence bound is expressed in terms of a new set of combinatorial parameters that we term the bipartite rank-shatter coefﬁcients; these play the same role in our result as do the standard VC-dimension related shatter coefﬁcients (also known as the growth function) in uniform convergence results for the classiﬁcation error rate. A comparison of our result with a recent uniform convergence result derived by Freund et al. (2003) for a quantity closely related to the AUC shows that the bound provided by our result can be considerably tighter. Keywords: generalization bounds, area under the ROC curve, ranking, large deviations, uniform convergence ∗. Parts of the results contained in this paper were presented at the 18th Annual Conference on Neural Information Processing Systems in December, 2004 (Agarwal et al., 2005a) and at the 10th International Workshop on Artiﬁcial Intelligence and Statistics in January, 2005 (Agarwal et al., 2005b). ©2005 Shivan</p><br/>
<h2>reference text</h2><p>Shivani Agarwal, Thore Graepel, Ralf Herbrich, and Dan Roth. A large deviation bound for the area under the ROC curve. In Advances in Neural Information Processing Systems 17. MIT Press, 2005a. Shivani Agarwal, Sariel Har-Peled, and Dan Roth. A uniform convergence bound for the area under the ROC curve. In Proceedings of the 10th International Workshop on Artiﬁcial Intelligence and Statistics, 2005b. Martin Anthony and Peter Bartlett. Learning in Neural Networks: Theoretical Foundations. Cambridge University Press, 1999. Z. W. Birnbaum and O. M. Klose. Bounds for the variance of the Mann-Whitney statistic. Annals of Mathematical Statistics, 38, 1957. R. C. Buck. Partition of space. American Mathematical Monthly, 50:2541–544, 1943. 423  AGARWAL , G RAEPEL , H ERBRICH , H AR -P ELED AND ROTH  William W. Cohen, Robert E. Schapire, and Yoram Singer. Learning to order things. Journal of Artiﬁcial Intelligence Research, 10:243–270, 1999. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction to Algorithms. MIT Press, second edition, 2001. Corinna Cortes and Mehryar Mohri. AUC optimization vs. error rate minimization. In Sebastian Thrun, Lawrence Saul, and Bernhard Sch¨ lkopf, editors, Advances in Neural Information Proo cessing Systems 16. MIT Press, 2004. Corinna Cortes and Mehryar Mohri. Conﬁdence intervals for the area under the ROC curve. In Advances in Neural Information Processing Systems 17. MIT Press, 2005. Koby Crammer and Yoram Singer. Pranking with ranking. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14, pages 641–647. MIT Press, 2002. D. Van Dantzig. On the consistency and power of Wilcoxon’s two sample test. In Koninklijke Nederlandse Akademie van Weterschappen, Series A, volume 54, 1915. Luc Devroye. Exponential inequalities in nonparametric estimation. In G. Roussas, editor, Nonparametric Functional Estimation and Related Topics, NATO ASI Series, pages 31–44. Kluwer Academic Publishers, 1991. Luc Devroye, L´ szl´ Gy¨ rﬁ, and G´ bor Lugosi. A Probabilistic Theory of Pattern Recognition. a o o a Springer-Verlag, New York, 1996. Bradley Efron and Robert Tibshirani. An Introduction to the Bootstrap. Chapman and Hall, 1993. James P. Egan. Signal Detection Theory and ROC Analysis. Academic Press, 1975. Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An efﬁcient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933–969, 2003. Thore Graepel, Ralf Herbrich, and John Shawe-Taylor. PAC-Bayesian compression bounds on the prediction error of learning algorithms for classiﬁcation. Machine Learning, 2005. To appear. James A. Hanley and Barbara J. McNeil. The meaning and use of the area under a receiver operating characteristic (ROC) curve. Radiology, 143:29–36, 1982. Ralf Herbrich, Thore Graepel, and Klaus Obermayer. Large margin rank boundaries for ordinal regression. Advances in Large Margin Classiﬁers, pages 115–132, 2000. Simon I. Hill, Hugo Zaragoza, Ralf Herbrich, and Peter J. W. Rayner. Average precision and the problem of generalisation. In Proceedings of the ACM SIGIR Workshop on Mathematical and Formal Methods in Information Retrieval, 2002. Erich L. Lehmann. Nonparametrics: Statistical Methods Based on Ranks. Holden-Day, San Francisco, California, 1975. 424  G ENERALIZATION B OUNDS FOR THE A REA U NDER THE ROC C URVE  Nick Littlestone and Manfred Warmuth. Relating data compression and learnability. Technical report, University of California Santa Cruz, 1986. Jiˇ´ Matouˇek. Lectures on Discrete Geometry. Springer-Verlag, New York, 2002. rı s Colin McDiarmid. On the method of bounded differences. In Surveys in Combinatorics 1989, pages 148–188. Cambridge University Press, 1989. Saharon Rosset. Model selection via the AUC. In Proceedings of the 21st International Conference on Machine Learning, 2004. Vladimir N. Vapnik. Estimation of Dependences Based on Empirical Data. Springer-Verlag, New York, 1982.  425</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
