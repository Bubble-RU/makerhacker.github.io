<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>58 jmlr-2005-Multiclass Classification with Multi-Prototype Support Vector Machines</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-58" href="../jmlr2005/jmlr-2005-Multiclass_Classification_with_Multi-Prototype_Support_Vector_Machines.html">jmlr2005-58</a> <a title="jmlr-2005-58-reference" href="#">jmlr2005-58-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>58 jmlr-2005-Multiclass Classification with Multi-Prototype Support Vector Machines</h1>
<br/><p>Source: <a title="jmlr-2005-58-pdf" href="http://jmlr.org/papers/volume6/aiolli05a/aiolli05a.pdf">pdf</a></p><p>Author: Fabio Aiolli, Alessandro Sperduti</p><p>Abstract: Winner-take-all multiclass classiﬁers are built on the top of a set of prototypes each representing one of the available classes. A pattern is then classiﬁed with the label associated to the most ‘similar’ prototype. Recent proposal of SVM extensions to multiclass can be considered instances of the same strategy with one prototype per class. The multi-prototype SVM proposed in this paper extends multiclass SVM to multiple prototypes per class. It allows to combine several vectors in a principled way to obtain large margin decision functions. For this problem, we give a compact constrained quadratic formulation and we propose a greedy optimization algorithm able to ﬁnd locally optimal solutions for the non convex objective function. This algorithm proceeds by reducing the overall problem into a series of simpler convex problems. For the solution of these reduced problems an efﬁcient optimization algorithm is proposed. A number of pattern selection strategies are then discussed to speed-up the optimization process. In addition, given the combinatorial nature of the overall problem, stochastic search strategies are suggested to escape from local minima which are not globally optimal. Finally, we report experiments on a number of datasets. The performance obtained using few simple linear prototypes is comparable to that obtained by state-of-the-art kernel-based methods but with a signiﬁcant reduction (of one or two orders) in response time. Keywords: multiclass classiﬁcation, multi-prototype support vector machines, kernel machines, stochastic search optimization, large margin classiﬁers</p><br/>
<h2>reference text</h2><p>F. Aiolli and A. Sperduti. An efﬁcient SMO-like algortihm for multiclass SVM. In Proceedings of IEEE workshop on Neural Networks for Signal Processing, pages 297–306, 2002a. F. Aiolli and A. Sperduti. A re-weighting strategy for improving margins. Artiﬁcial Intelligence Journal, 137/1-2:197–216, 2002b. F. Aiolli and A. Sperduti. Multi-prototype support vector machine. In Proceedings of International Joint Conference of Artiﬁcial Intelligence (IJCAI), 2003. E. Allwein, R. Schapire, and Y. Singer. Reducing multiclass to binary: A unifying approach for margin classiﬁers. Journal of Machine Learning Research, 2000. K. Crammer and Y. Singer. On the learnability and design of output codes for multiclass problems. In Proceedings of the Thirteenth Annual Conference on Computational Learning Theory, pages 35–46, 2000. K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based machines. Journal of Machine Learning Research, 2(Dec):265–292, 2001. T. G. Dietterich and G. Bakiri. Solving multiclass learning problems via error correcting output codes. Journal of Artiﬁcial Intelligence Research, 2:263–286, 1995. 848  M ULTICLASS C LASSIFICATION WITH M ULTI -P ROTOTYPE S UPPORT V ECTOR M ACHINES  T. Downs, K. E. Gates, and A. Masters. Exact simpliﬁcation of support vector solutions. Journal of Machine Learning Research, 2:293–297, 2001. G. M. Fung, O. L. Mangasarian, and A. J. Smola. Minimal kernel classiﬁers. Journal of Machine Learning Research, 3:303–321, 2002. Y. Guermeur, A. Elisseeff, and H. Paugam-Moisy. A new multi-class SVM based on a uniform convergence result. In Proceedings of the IJCNN, 2000. T. Joachims. Making large-scale SVM learning practical. In Advances in Kernel Methods - Support Vector Learning. B. Schlkopf and C. Burges and A. Smola (ed.), MIT Press, 1999. M. J. Kearns and U. V. Vazirani. An Introduction to Computational Learning Theory. MIT Press, 1994. S. S. Keerthi, S. K. Shevade, C. Bhattacharyya, and K. R. K. Murthy. Improvements to platt’s smo algorithm for SVM classiﬁer design. Technical Report CD-99-14, Control Division, Dept. of Mechanical and Production Engineering, National University of Singapore, 1999. T. Kohonen, J. Hynninen, J. Kangas, J. Laaksonen, and K. Torkkola. Lvq pak: The learning vector quantization program package. Technical Report A30, Helsinki University of Technology, Laboratory of Computer and Information Science, January 1996. http://www.cis.hut.ﬁ/nnrc/nnrcprograms.html. H. R. Lourenco, O. C. Martin, and T. Stutzle. Iterated local search. Handbook of Metaheuristics, Ed. F. Glover and G. Kochenberger, International Series in Operations Research & Management Science(57):321–353, 2002. D. Michie, D. Speigelhalter, and C. Taylor. Machine Learning, Neural and Statistical Classiﬁcation. Ellis Horwood, 1994. T. Mitchell. Machine Learning. McGraw Hill, 1997. J. Platt, N. Cristianini, and J. Shawe Taylor. Large margin DAGs for multiclass classiﬁcation. In S. A. Solla, T. K. Leen, and K. R. Muller, editors, Advances in Neural Information Processing Systems. MIT Press, 2000. J. C. Platt. Fast training of support vector machines using sequential minimal optimization. Advances in Kernel Methods - Support Vector Learning, 1998. J. R. Quinlan. C4.5: Programs for Empirical Learning. Morgan Kaufmann, San Francisco, CA, 1993. D. E. Rumelhart, G. E. Hinton, and R.J Williams. Learning internal representation by error propagation. In Parallel Distributed Processing - Explorations in the Microstructure of cognition, chapter 8, pages 318–362. MIT Press, 1986. B. Sch¨ lkopf, S. Mika, C. J. C. Burges, P. Knirsch, K. R. Muller, G. R¨ tsch, and A. J. Smola. Input o a space versus feature space in kernel-based methods. IEEE Transactions on Neural Networks, 5 (10):1000–1017, 1999. 849  A IOLLI AND S PERDUTI  B. Sch¨ lkopf and C. Burges and V. Vapnik. Extracting support data for a given task. In First o International Conference on Knowledge Discovery & Data Mining, pages 252–257, 1995. D. Sona, A. Sperduti, and A. Starita. Discriminant pattern recognition using transformation invariant neurons. Neural Computation, 12(6), 2000. M. E. Tipping. Sparse Bayesian learning and the relevance vector machine. Journal of Machine Learning Research, 1:211–244, 2001. V. Vapnik. Statistical Learning Theory. Wiley, New York, NY, 1998. J. Weston and C. Watkins. Multiclass support vector machines. In M. Verleysen, editor, Proceedings of ESANN99. D. Facto Press, 1999.  850</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
