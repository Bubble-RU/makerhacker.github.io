<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>73 jmlr-2005-Working Set Selection Using Second Order Information for Training Support Vector Machines</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-73" href="../jmlr2005/jmlr-2005-Working_Set_Selection_Using_Second_Order_Information_for_Training_Support_Vector_Machines.html">jmlr2005-73</a> <a title="jmlr-2005-73-reference" href="#">jmlr2005-73-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>73 jmlr-2005-Working Set Selection Using Second Order Information for Training Support Vector Machines</h1>
<br/><p>Source: <a title="jmlr-2005-73-pdf" href="http://jmlr.org/papers/volume6/fan05a/fan05a.pdf">pdf</a></p><p>Author: Rong-En Fan, Pai-Hsuen Chen, Chih-Jen Lin</p><p>Abstract: Working set selection is an important step in decomposition methods for training support vector machines (SVMs). This paper develops a new technique for working set selection in SMO-type decomposition methods. It uses second order information to achieve fast convergence. Theoretical properties such as linear convergence are established. Experiments demonstrate that the proposed method is faster than existing selection methods using ﬁrst order information. Keywords: support vector machines, decomposition methods, sequential minimal optimization, working set selection</p><br/>
<h2>reference text</h2><p>R. R. Bailey, E. J. Pettit, R. T. Borochoﬀ, M. T. Manry, and X. Jiang. Automatic recognition of usgs land use/cover categories using statistical and neural networks classiﬁers. In SPIE OE/Aerospace and Remote Sensing, Bellingham, WA, 1993. SPIE. C. L. Blake and C. J. Merz. UCI repository of machine learning databases. Technical report, University of California, Department of Information and Computer Science, Irvine, CA, 1998. Available at http://www.ics.uci.edu/~mlearn/MLRepository.html. B. Boser, I. Guyon, and V. Vapnik. A training algorithm for optimal margin classiﬁers. In Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pages 144–152. ACM Press, 1992. 1916  Working Set Selection for Training SVMs  Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for support vector machines, 2001. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm. Pai-Hsuen Chen, Rong-En Fan, and Chih-Jen Lin. A study on SMO-type decomposition methods for support vector machines. IEEE Transactions on Neural Networks, 2006. URL http://www.csie.ntu.edu.tw/~cjlin/papers/generalSMO.pdf. To appear. C. Cortes and V. Vapnik. Support-vector network. Machine Learning, 20:273–297, 1995. Tin Kam Ho and Eugene M. Kleinberg. Building projectable classiﬁers of arbitrary complexity. In Proceedings of the 13th International Conference on Pattern Recognition, pages 880–885, Vienna, Austria, August 1996. Don Hush and Clint Scovel. Polynomial-time decomposition algorithms for support vector machines. Machine Learning, 51:51–71, 2003. URL http://www.c3.lanl.gov/~dhush/machine_learning/svm_decomp.ps. Thorsten Joachims. Making large-scale SVM learning practical. In Bernhard Sch¨lkopf, o Christopher J. C. Burges, and Alexander J. Smola, editors, Advances in Kernel Methods - Support Vector Learning, Cambridge, MA, 1998. MIT Press. S. S. Keerthi, S. K. Shevade, C. Bhattacharyya, and K. R. K. Murthy. Improvements to Platt’s SMO algorithm for SVM classiﬁer design. Neural Computation, 13:637–649, 2001. D. Lai, N. Mani, and M. Palaniswami. Increasing the step of the Newtonian decomposition method for support vector machines. Technical Report MECSE-29-2003, Dept. Electrical and Computer Systems Engineering Monash University, Australia, 2003a. D. Lai, N. Mani, and M. Palaniswami. A new method to select working sets for faster training for support vector machines. Technical Report MESCE-30-2003, Dept. Electrical and Computer Systems Engineering Monash University, Australia, 2003b. Chih-Jen Lin. Linear convergence of a decomposition method for support vector machines. Technical report, Department of Computer Science, National Taiwan University, 2001a. URL http://www.csie.ntu.edu.tw/~cjlin/papers/linearconv.pdf. Chih-Jen Lin. On the convergence of the decomposition method for support vector machines. IEEE Transactions on Neural Networks, 12(6):1288–1298, 2001b. URL http://www.csie.ntu.edu.tw/~cjlin/papers/conv.ps.gz. Chih-Jen Lin. Asymptotic convergence of an SMO algorithm without any assumptions. IEEE Transactions on Neural Networks, 13(1):248–250, 2002. URL http://www.csie.ntu.edu.tw/~cjlin/papers/q2conv.pdf. D. Michie, D. J. Spiegelhalter, and C. C. Taylor. Machine Learning, Neural and Statistical Classiﬁcation. Prentice Hall, Englewood Cliﬀs, N.J., 1994. Data available at http://www.ncc.up.pt/liacc/ML/statlog/datasets.html. E. Osuna, R. Freund, and F. Girosi. Training support vector machines: An application to face detection. In Proceedings of CVPR’97, pages 130–136, New York, NY, 1997. IEEE. 1917  Fan, Chen, and Lin  Laura Palagi and Marco Sciandrone. On the convergence of a modiﬁed version of SVMlight algorithm. Optimization Methods and Software, 20(2-3):315–332, 2005. J. C. Platt. Fast training of support vector machines using sequential minimal optimization. In Bernhard Sch¨lkopf, Christopher J. C. Burges, and Alexander J. Smola, editors, o Advances in Kernel Methods - Support Vector Learning, Cambridge, MA, 1998. MIT Press. Danil Prokhorov. IJCNN 2001 neural network competition. Slide presentation in IJCNN’01, Ford Research Laboratory, 2001. http://www.geocities.com/ijcnn/nnc_ijcnn01.pdf . B. Sch¨lkopf, A. Smola, R. C. Williamson, and P. L. Bartlett. New support vector algoo rithms. Neural Computation, 12:1207–1245, 2000. Hans Ulrich Simon. On the complexity of working set selection. In Proceedings of the 15th International Conference on Algorithmic Learning Theory (ALT 2004), 2004.  1918</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
