<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>69 jmlr-2005-Tutorial on Practical Prediction Theory for Classification</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-69" href="../jmlr2005/jmlr-2005-Tutorial_on_Practical_Prediction_Theory_for_Classification.html">jmlr2005-69</a> <a title="jmlr-2005-69-reference" href="#">jmlr2005-69-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>69 jmlr-2005-Tutorial on Practical Prediction Theory for Classification</h1>
<br/><p>Source: <a title="jmlr-2005-69-pdf" href="http://jmlr.org/papers/volume6/langford05a/langford05a.pdf">pdf</a></p><p>Author: John Langford</p><p>Abstract: We discuss basic prediction theory and its impact on classiﬁcation success evaluation, implications for learning algorithm design, and uses in learning algorithm execution. This tutorial is meant to be a comprehensive compilation of results which are both theoretically rigorous and quantitatively useful. There are two important implications of the results presented here. The ﬁrst is that common practices for reporting results in classiﬁcation should change to use the test set bound. The second is that train set bounds can sometimes be used to directly motivate learning algorithms. Keywords: sample complexity bounds, classiﬁcation, quantitative bounds</p><br/>
<h2>reference text</h2><p>P. L. Bartlett, O. Bousquet, and S. Mendelson. Local Rademacher complexities. Annals of Statistics, 2004. A. Blum, A. Kalai, and J. Langford. Beating the holdout: Bounds for k-fold and progressive crossvalidation. In Computational Learning Theory (COLT), 1999. A. Blumer, A. Ehrenfueucht, D. Haussler, and M. Warmuth. Occam’s razor. Information Processing Letters, 24:377–380, 1987. H. Chernoff. A measure of asymptotic efﬁciency of tests of a hypothesis based upon the sum of the observations. Annals of Mathematical Statistics, 24:493–507, 1952. C. J. Clopper and E. S. Pearson. The use of conﬁdence intervals for ﬁducial limits illustrated in the case of the binomial. Biometrika, 26:404–413, 1934. L. Devroye, L. Gyorﬁ, and G. Lugosi. A Probabilistic Theory of Pattern Recognition. SpringerVerlag, New York, 1996. S. Floyd and M. Warmuth. Sample compression, learnability, and the vapnik-chervonenkis dimension. Machine Learning, 21:269–304, 1995. R. Herbrich and T. Graepel. Large scale bayes point machines. In Advances in Neural Information System Processing 13 (NIPS), pages 528–534, 2001. W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58:13–30, 1963. T. Joachims. program SVMlight. J. Kivinen and M. Warmuth. Additive versus exponentiated gradient updates for linear prediction. Information and Computation, 132(1):1–64, 1997. J. Langford. Program bound. J. Langford. Combining train set and test set bounds. In International Conference on Machine Learning, 2002. J. Langford and A. Blum. Microchoice bounds and self bounding learning algorithms. Machine Learning, 1999. 9. Note that there do exist online to batch conversions, but these conversions always occur under an assumption of i.i.d. samples, essentially changing the setting to the one described here.  305  L ANGFORD  J. Langford and D. McAllester. Computable shell decomposition bounds. In Computational Learning Theory (COLT), 2000. J. Langford and M. Seeger. Bounds for averaging classiﬁers. Technical report, Carnegie Mellon, Department of Computer Science, 2001. J. Langford and J. Shawe-Taylor. PAC-Bayes & margins. In Neural Information Processing Systems (NIPS), 2002. N. Littlestone and M. Warmuth. Relating data compression and learnability. M. Marchand and J. Shawe-Taylor. The set covering machine. In International Conference on Machine Learning (ICML), 2001. D. McAllester. PAC-Bayesian model averaging. In Computational Learning Theory (COLT), 1999. M. Seeger. PAC-Bayesian generalization error bounds for gaussian process classiﬁcation. Journal of Machine Learning Research, 3:233–269, 2002. S. Seung. Unpublished notes. J. Shawe-Taylor, P. Bartlett, R. Williamson, and M. Anthony. Structural risk minimization over data-dependent hierarchies. IEEE Transactions on Information Theory, 44(5):1926–1940, 1998. L.G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134–1142, 1984. V. N. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and its Applications, 16(2):264–280, 1971.  306</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
