<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 jmlr-2005-A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-1" href="../jmlr2005/jmlr-2005-A_Bayes_Optimal_Approach_for_Partitioning_the_Values_of_Categorical_Attributes.html">jmlr2005-1</a> <a title="jmlr-2005-1-reference" href="#">jmlr2005-1-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 jmlr-2005-A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes</h1>
<br/><p>Source: <a title="jmlr-2005-1-pdf" href="http://jmlr.org/papers/volume6/boulle05a/boulle05a.pdf">pdf</a></p><p>Author: Marc Boullé</p><p>Abstract: In supervised machine learning, the partitioning of the values (also called grouping) of a categorical attribute aims at constructing a new synthetic attribute which keeps the information of the initial attribute and reduces the number of its values. In this paper, we propose a new grouping method MODL1 founded on a Bayesian approach. The method relies on a model space of grouping models and on a prior distribution defined on this model space. This results in an evaluation criterion of grouping, which is minimal for the most probable grouping given the data, i.e. the Bayes optimal grouping. We propose new super-linear optimization heuristics that yields near-optimal groupings. Extensive comparative experiments demonstrate that the MODL grouping method builds high quality groupings in terms of predictive quality, robustness and small number of groups. Keywords: data preparation, grouping, Bayesianism, model selection, classification, naïve Bayes 1</p><br/>
<h2>reference text</h2><p>M. Asseraf. Metric on decision trees and optimal partition problem. International Conference on Human System Learning, Proceedings of CAPS’3, Paris, 2000. 1450  A BAYES OPTIMAL GROUPING METHOD  N. C. Berckman. Value grouping for binary decision trees. Technical Report, Computer Science Department – University of Massachusetts, 1995. J. M. Bernardo and A. F. M. Smith. Bayesian Theory. Wiley, New York, 1994. C. L. Blake and C. J. Merz. UCI Repository of machine learning databases Web URL http://www.ics.uci.edu/~mlearn/MLRepository.html. Irvine, CA: University of California, Department of Information and Computer Science, 1998. M. Boullé. Khiops: a Statistical Discretization Method of Continuous Attributes. Machine Learning, 55(1):53-69, 2004a. M. Boullé. A robust method for partitioning the values of categorical attributes. Revue des Nouvelles Technologies de l’Information, Extraction et gestion des connaissances (EGC’2004), RNTI-E-2, volume II: 173-182, 2004b. M. Boullé. A Bayesian Approach for Supervised Discretization. Data Mining V, Eds Zanasi, Ebecken, Brebbia, WIT Press, pp 199-208, 2004c. L. Breiman, J. H. Friedman, R. A. Olshen and C. J. Stone. Classification and Regression Trees. California: Wadsworth International, 1984. B. Cestnik, I. Kononenko and I. Bratko. ASSISTANT 86: A knowledge-elicitation tool for sophisticated users. In Bratko and Lavrac (Eds.), Progress in Machine Learning. Wilmslow, UK: Sigma Press, 1987. P. A. Chou. Optimal Partitioning for Classification and Regression Trees. IEEE Transactions on Pattern Analysis and Machine Intelligence, 13(4):340-354, 1991. T. G. Dietterich. Approximate Statistical Tests for Comparing Supervised Classification Methods. Neural Computation, 10(7), 1998. J. Dougherty, R. Kohavi and M. Sahami. Supervised and Unsupervised Discretization of Continuous Features. Proceedings of the Twelf International Conference on Machine Learning. Los Altos, CA: Morgan Kaufmann, pp 194-202, 1995. T. Fulton, S. Kasif and S. Salzberg. Efficient algorithms for finding multi-way splits for decision trees. In Proc. Thirteenth International Joint Conference on Artificial Intelligence, San Francisco, CA: Morgan Kaufmann, pp 244-255, 1995. D. J. Hand and K. Yu. Idiot Bayes ? not so stupid after all? International Statistical Review, 69:385-398, 2001. C. N. Hsu, H. J. Huang and T. T Wong. Implications of the Dirichlet Assumption for Discretization of Continuous Variables in Naive Bayesian Classifiers. Machine Learning, 53(3):235-263, 2003. G. V. Kass. An exploratory technique for investigating large quantities of categorical data. Applied Statistics, 29(2):119-127, 1980. R. Kass and A. Raftery. Bayes factors. In Journal of the American Statistical Association, 90: 773-795, 1995. R. Kerber. Chimerge discretization of numeric attributes. Proceedings of the 10th International Conference on Artificial Intelligence, pp 123-128, 1991. S. Kullback. Information Theory and Statistics. New York: Wiley, (1959); republished by Dover, 1968.  1451  BOULLE  P. Langley, W. Iba and K. Thompson. An analysis of Bayesian classifiers. In Proceedings of the 10th national conference on Artificial Intelligence, AAAI Press, pp 223-228, 1992. Y. Lechevallier. Recherche d'une partition optimale sous contrainte d'ordre total. Technical report N°1247. INRIA, 1990. D. Pyle. Data Preparation for Data Mining. Morgan Kaufmann, 1999. J. R. Quinlan. Induction of decision trees. Machine Learning, 1:81-106, 1986. J. R. Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann, 1993. G. Ritschard, D. A. Zighed and N. Nicoloyannis. Maximisation de l'association par regroupement de lignes ou de colonnes d'un tableau croisé. Mathématiques et Sciences Humaines, n°154155:81-98, 2001. G. Ritschard. Partition BIC optimale de l'espace des prédicteurs. Revue des Nouvelles Technologies de l'Information, 1:99-110, 2003. G. Schwarz. Estimating the dimension of a model. The Annals of Statistics, 6:461-464, 1978. SPSS Inc. AnswerTree 3.0 User's Guide. Chicago: SPSS Inc, 2001. Y. Yang and G. Webb. On why discretization works for naïve-Bayes classifiers. Proceedings of the 16th Australian Joint Conference on Artificial Intelligence (AI), 2003. D. A. Zighed and R. Rakotomalala. Graphes d’induction. Hermes Science Publications, pp 327359, 2000.  1452</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
