<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>75 jmlr-2011-Parallel Algorithm for Learning Optimal Bayesian Network Structure</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-75" href="../jmlr2011/jmlr-2011-Parallel_Algorithm_for_Learning_Optimal_Bayesian_Network_Structure.html">jmlr2011-75</a> <a title="jmlr-2011-75-reference" href="#">jmlr2011-75-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>75 jmlr-2011-Parallel Algorithm for Learning Optimal Bayesian Network Structure</h1>
<br/><p>Source: <a title="jmlr-2011-75-pdf" href="http://jmlr.org/papers/volume12/tamada11a/tamada11a.pdf">pdf</a></p><p>Author: Yoshinori Tamada, Seiya Imoto, Satoru Miyano</p><p>Abstract: We present a parallel algorithm for the score-based optimal structure search of Bayesian networks. This algorithm is based on a dynamic programming (DP) algorithm having O(n · 2n ) time and space complexity, which is known to be the fastest algorithm for the optimal structure search of networks with n nodes. The bottleneck of the problem is the memory requirement, and therefore, the algorithm is currently applicable for up to a few tens of nodes. While the recently proposed algorithm overcomes this limitation by a space-time trade-off, our proposed algorithm realizes direct parallelization of the original DP algorithm with O(nσ ) time and space overhead calculations, where σ > 0 controls the communication-space trade-off. The overall time and space complexity is O(nσ+1 2n ). This algorithm splits the search space so that the required communication between independent calculations is minimal. Because of this advantage, our algorithm can run on distributed memory supercomputers. Through computational experiments, we conﬁrmed that our algorithm can run in parallel using up to 256 processors with a parallelization efﬁciency of 0.74, compared to the original DP algorithm with a single processor. We also demonstrate optimal structure search for a 32-node network without any constraints, which is the largest network search presented in literature. Keywords: optimal Bayesian network structure, parallel algorithm</p><br/>
<h2>reference text</h2><p>B. P. Buckles and M. Lybanon. Algorithm 515: Generation of a vector from the lexicographical index [G6]. ACM Transductions on Mathematical Software, 3(2):180–182, 1977. D. M. Chickering, D. Geiger, and D. Heckerman. Learning Bayesian networks: Search methods and experimental results. In Proceedings of the Fifth Conference on Artiﬁcial Intelligence and Statistics, pages 112–128, 1995. N. Friedman, M. Linial, I. Nachman, and D. Pe’er. Using Bayesian networks to analyze expression data. J. Computational Biology, 7:601–620, 2000. 2458  PARALLEL A LGORITHM FOR L EARNING O PTIMAL BAYESIAN N ETWORKS  D. Heckerman, D. Geiger, and D. M. Chickering. Learning Bayesian networks: the combination of knowledge and statistical data. Machine Learning, 20:197–243, 1995. S. Imoto, T. Goto, and S. Miyano. Estimation of genetic networks and functional structures between genes by using Bayesian networks and nonparametric regression. Paciﬁc Symposium on Biocomputing, 7:175–186, 2002. M. Koivisto and K. Sood. Exact Bayesian structure discovery in Bayesian networks. Journal of Machine Learning Research, 5:549–573, 2004. S. Ott, S. Imoto, and S. Miyano. Finding optimal models for small gene networks. Paciﬁc Symposium on Biocomputing, 9:557–567, 2004. P. Parviainen and M. Koivisto. Exact structure discovery in Bayesian networks with less space. Proceedings of the 25th Conference on Uncertainty in Artiﬁcial Intelligence (UAI 2009), 2009. J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufman Publishers, San Mateo, CA, 1988. E. Perrier, S. Imoto, and S. Miyano. Finding optimal Bayesian network given a super-structure. J. Machine Learning Research, 9:2251–2286, 2008. T. Silander and P. Myllym¨ ki. A simple approach for ﬁnding the globally optimal Bayesian network a structure. Proceedings of the 22th Conference on Uncertainty in Artiﬁcial Intelligence (UAI 2006), pages 445–452, 2006. Y. Tamada, S. Imoto, and S. Miyano. Conversion between a combination vector and the lexicographical index in linear time with polynomial time preprocessing, 2011. submitted. I. Tsamardinos, L. E. Brown, and C. F. Aliferis. The max-min hill-climbing Bayesian network structure learning algorithm. Machine Learning, 65:31–78, 2006.  2459</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
