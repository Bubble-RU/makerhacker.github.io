<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>26 jmlr-2011-Distance Dependent Chinese Restaurant Processes</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-26" href="../jmlr2011/jmlr-2011-Distance_Dependent_Chinese_Restaurant_Processes.html">jmlr2011-26</a> <a title="jmlr-2011-26-reference" href="#">jmlr2011-26-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>26 jmlr-2011-Distance Dependent Chinese Restaurant Processes</h1>
<br/><p>Source: <a title="jmlr-2011-26-pdf" href="http://jmlr.org/papers/volume12/blei11a/blei11a.pdf">pdf</a></p><p>Author: David M. Blei, Peter I. Frazier</p><p>Abstract: We develop the distance dependent Chinese restaurant process, a ﬂexible class of distributions over partitions that allows for dependencies between the elements. This class can be used to model many kinds of dependencies between data in inﬁnite clustering models, including dependencies arising from time, space, and network connectivity. We examine the properties of the distance dependent CRP, discuss its connections to Bayesian nonparametric mixture models, and derive a Gibbs sampler for both fully observed and latent mixture settings. We study its empirical performance with three text corpora. We show that relaxing the assumption of exchangeability with distance dependent CRPs can provide a better ﬁt to sequential data and network data. We also show that the distance dependent CRP representation of the traditional CRP mixture leads to a faster-mixing Gibbs sampling algorithm than the one based on the original formulation. Keywords: Chinese restaurant processes, Bayesian nonparametrics</p><br/>
<h2>reference text</h2><p>A. Ahmed and E. Xing. Dynamic non-parametric mixture models and the recurrent Chinese restaurant process with applications to evolutionary clustering. In International Conference on Data Mining, 2008. C. Antoniak. Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems. The Annals of Statistics, 2(6):1152–1174, 1974. D. Blackwell. Discreteness of Ferguson selections. The Annals of Statistics, 1(2):356–358, 1973. D. Blei and P. Frazier. Distance dependent Chinese restaurant processes. In International Conference on Machine Learning, 2010. D. Blei and M. Jordan. Variational inference for Dirichlet process mixtures. Journal of Bayesian Analysis, 1(1):121–144, 2005. D. Blei, T. Grifﬁths, and M. Jordan. The nested Chinese restaurant process and Bayesian nonparametric inference of topic hierarchies. Journal of the ACM, 57(2):1–30, 2010. D.B. Dahl. Distance-based probability distribution for set partitions with applications to Bayesian nonparametrics. In JSM Proceedings. Section on Bayesian Statistical Science, American Statistical Association, Alexandria, Va, 2008. H. Daume. Fast search for Dirichlet process mixture models. In Artiﬁcial Intelligence and Statistics, San Juan, Puerto Rico, 2007. URL http://pub.hal3.name/#daume07astar-dp. J. Duan, M. Guindani, and A. Gelfand. Generalized spatial Dirichlet process models. Biometrika, 94:809–825, 2007. 2486  D ISTANCE D EPENDENT C HINESE R ESTAURANT P ROCESSES  D. Dunson. Bayesian dynamic modeling of latent trait distributions. Biostatistics, 2006. D. Dunson, N. Pillai, and J. Park. Bayesian density regression. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 69(2):163–183, 2007. M. Escobar and M. West. Bayesian density estimation and inference using mixtures. Journal of the American Statistical Association, 90:577–588, 1995. T. Ferguson. A Bayesian analysis of some nonparametric problems. The Annals of Statistics, 1: 209–230, 1973. E. Fox, E. Sudderth, M. Jordan, and A. Willsky. Developing a tempered HDP-HMM for systems with state persistence. Technical report, MIT Laboratory for Information and Decision Systems, 2007. C. Geyer and E. Thompson. Constrained Monte Carlo maximum likelihood for dependent data. Journal of the American Statistical Association, 54(657–699), 1992. S. Goldwater, T. Grifﬁths, and M. Johnson. Interpolating between types and tokens by estimating power-law generators. In Neural Information Processing Systems, 2006. J. Grifﬁn and M. Steel. Order-based dependent Dirichlet processes. Journal of the American Statistical Association, 101(473):179–194, 2006. J.A. Hartigan. Partition models. Communications in Statistics-Theory and Methods, 19(8):2745– 2756, 1990. M. Johnson, T. Grifﬁths, and Goldwater S. Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models. In B. Sch¨ lkopf, J. Platt, and T. Hoffman, editors, o Advances in Neural Information Processing Systems 19, pages 641–648, Cambridge, MA, 2007. MIT Press. R. Kass and A. Raftery. Bayes factors. Journal of the American Statistical Association, 90(430): 773–795, 1995. W. Li, D. Blei, and A. McCallum. Nonparametric Bayes pachinko allocation. In The 23rd Conference on Uncertainty in Artiﬁcial Intelligence, 2007. P. Liang, M. Jordan, and B. Taskar. A permutation-augmented sampler for DP mixture models. In International Conference on Machine Learning, 2007. S. MacEachern. Dependent nonparametric processes. In ASA Proceedings of the Section on Bayesian Statistical Science, 1999. A. McCallum, K. Nigam, J. Rennie, and K. Seymore. Automating the construction of internet portals with machine learning. Information Retrieval, 2000. K.T. Miller, T.L. Grifﬁths, and M.I. Jordan. The phylogenetic indian buffet process: A nonexchangeable nonparametric prior for latent features. In David A. McAllester and Petri Myllym¨ ki, editors, UAI, pages 403–410. AUAI Press, 2008. a 2487  B LEI AND F RAZIER  P. Mueller and F. Quintana. Random partition models with regression on covariates. In International Conference on Interdisciplinary Mathematical and Statistical Techniques, 2008. P. Muller, F. Quintana, and G. Rosner. Bayesian clustering with regression. Working paper, 2008. R. Neal. Probabilistic inference using Markov chain Monte Carlo methods. Technical Report CRGTR-93-1, Department of Computer Science, University of Toronto, 1993. R. Neal. Markov chain sampling methods for Dirichlet process mixture models. Journal of Computational and Graphical Statistics, 9(2):249–265, 2000. J. Pitman. Combinatorial Stochastic Processes. Lecture Notes for St. Flour Summer School. Springer-Verlag, New York, NY, 2002. C. Rasmussen and Z. Ghahramani. Inﬁnite mixtures of Gaussian process experts. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14, Cambridge, MA, 2002. MIT Press. C. Ritter and M. Tanner. Facilitating the Gibbs sampler: The Gibbs stopper and the Griddy-Gibbs sampler. Journal of the American Statistical Association, 87(419):861–868, 1992. C. Robert and G. Casella. Monte Carlo Statistical Methods. Springer Texts in Statistics. SpringerVerlag, New York, NY, 2004. E. Sudderth, A. Torralba, W. Freeman, and A. Willsky. Describing visual scenes using transformed Dirichlet processes. In Advances in Neural Information Processing Systems 18, 2005. E.B. Sudderth and M. I. Jordan. Shared segmentation of natural scenes using dependent pitman-yor processes. In Daphne Koller, Dale Schuurmans, Yoshua Bengio, and L´ on Bottou, editors, NIPS, e pages 1585–1592. MIT Press, 2008. Y. Teh. A hierarchical Bayesian language model based on Pitman-Yor processes. In Proceedings of the Association of Computational Linguistics, 2006. Y. Teh, M. Jordan, M. Beal, and D. Blei. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101(476):1566–1581, 2006. E. Xing, M. Jordan, and R. Sharan. Bayesian haplotype inference via the Dirichlet process. Journal of Computational Biology, 14(3):267–284, 2007. Y. Xue, D. Dunson, and L. Carin. The matrix stick-breaking process for ﬂexible multi-task learning. In International Conference on Machine Learning, 2007. X. Zhu, Z. Ghahramani, and J. Lafferty. Time-sensitive Dirichlet process mixture models. Technical Report CMU-CALD-05-104, Carnegie Mellon University, 2005.  2488</p>
<br/>
<br/><br/><br/></body>
</html>
