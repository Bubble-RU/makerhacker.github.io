<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-56" href="../jmlr2011/jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">jmlr2011-56</a> <a title="jmlr-2011-56-reference" href="#">jmlr2011-56-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</h1>
<br/><p>Source: <a title="jmlr-2011-56-pdf" href="http://jmlr.org/papers/volume12/vanbelle11a/vanbelle11a.pdf">pdf</a></p><p>Author: Vanya Van Belle, Kristiaan Pelckmans, Johan A. K. Suykens, Sabine Van Huffel</p><p>Abstract: This paper studies the task of learning transformation models for ranking problems, ordinal regression and survival analysis. The present contribution describes a machine learning approach termed MINLIP . The key insight is to relate ranking criteria as the Area Under the Curve to monotone transformation functions. Consequently, the notion of a Lipschitz smoothness constant is found to be useful for complexity control for learning transformation models, much in a similar vein as the ’margin’ is for Support Vector Machines for classiﬁcation. The use of this model structure in the context of high dimensional data, as well as for estimating non-linear, and additive models based on primal-dual kernel machines, and for sparse models is indicated. Given n observations, the present method solves a quadratic program existing of O (n) constraints and O (n) unknowns, where most existing risk minimization approaches to ranking problems typically result in algorithms with O (n2 ) constraints or unknowns. We specify the MINLIP method for three different cases: the ﬁrst one concerns the preference learning problem. Secondly it is speciﬁed how to adapt the method to ordinal regression with a ﬁnite set of ordered outcomes. Finally, it is shown how the method can be used in the context of survival analysis where one models failure times, typically subject to censoring. The current approach is found to be particularly useful in this context as it can handle, in contrast with the standard statistical model for analyzing survival data, all types of censoring in a straightforward way, and because of the explicit relation with the Proportional Hazard and Accelerated Failure Time models. The advantage of the current method is illustrated on different benchmark data sets, as well as for estimating a model for cancer survival based on different micro-array and clinical data sets. Keywords: support vector machines, preference learning, ranking models, ordinal regression, survival analysis c</p><br/>
<h2>reference text</h2><p>1 T 1 T T T T T T ∗ 2 α Kα + 2 β Kβ − α Kβ − α (Y − B Q) + β (Y − B Q )  0n ≤ α ≤ γ1n    0 ≤ β ≤ γ1 n n 0k−2 ≤ ν    T Q α − Q∗ T β + MT ν = 0 . k−1  N. Ailon and M. Mohri. An efﬁcient reduction of ranking to classiﬁcation. In COLT, pages 87–98. Omnipress, 2008. P.K. Andersen, O. Borgan, R.D. Gill, and N. Leiding. Statistical Models based on Counting Processes. Springer-Verlag, New York, 1993. E. Bair and R. Tibshirani. Semi-supervised methods to predict patient survival from gene expression data. PLoS Biology, 2(4):511–522, April 2004. R. Bair, T. Hastie, P. Debashis, and R. Tibshirani. Prediction by supervised principal components. Journal of the American Statistical Association, 101:119–137, 2006. E. Biganzoli, P. Boracchi, L. Mariani, and E. Marubini. Feedforward neural networks for the analysis of censored survival data: a partial logistic regression approach. Statistics in Medicine, 17 (10):1169–1186, 1998. H.M.M. Bøvelstad, S. Nyg˚ rd, H.L.L. Størvold, M. Aldrin, O. Borgan, A. Frigessi, and O.C.C. a Lingjærde. Predicting survival from microarray data - a comparative study. Bioinformatics, 23 (16):2080–2087, 2007. N. Breslow. Covariance analysis of censored survival data. Biometrics, 30(1):89–99, 1974. S.C. Cheng, L.J. Wei, and Z. Ying. Predicting survival probabilities with semiparametric transformation models. Journal of the American Statistical Association, 92(437):227–235, 1997. W. Chu and Z. Ghahramani. Gaussian processes for ordinal regression. Journal of Machine Learning Research, 6:1019–1041, 2005. W. Chu and S.S. Keerthi. New approaches to support vector ordinal regression. In In ICML 2005: Proceedings of the 22nd international conference on Machine Learning, pages 145–152, 2005. S. Cl´ mencon and N. Vayatis. Ranking the best instances. Journal of Machine Learning Research, e ¸ 8:2671–2699, 2007. S. Cl´ mencon, G. Lugosi, and N. Vayatis. Ranking and scoring using empirical risk minimization. e ¸ In Proceedings of the 18th Annual Conference in Learning Theory (COLT), Bertinoro (Italy), June 2005. D.R. Cox. Regression models and life-tables (with discussion). Journal of the Royal Statistical Society, Series B, 34(2):187–220, 1972. 859  VAN B ELLE , P ELCKMANS , S UYKENS AND VAN H UFFEL  D.M. Dabrowska and K.A. Doksum. Partial likelihood in transformation models with censored data. Scandinavian Journal of Statistics, 15(1):1–23, 1988. P.H. Eilers and B.D. Marx. Flexible smoothing with B-splines and penalties. Statistical Science, 11:89–121, 1996. R.C. Elandt-Johnson and N.L. Johnson. Survival Models and Data Anlysis. John Wiley & Sons, Inc., 1980. D.M. Finkelstein. A proportional hazards model for interval-censored failure time data. Biometrics, 42:845–854, 1986. B. Fisher, M. Bauer, L. Wickerham, C.K. Redmong, and E.R. Fisher. Relation of number of positive axillary nodes to the prognosis of patients with primary breast cancer. An NSABP update. Cancer, 52(9):1551–1557, 1983. Y. Freund, R. Iyer, R.E. Schapire, and Y. Singer. An efﬁcient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4(6):933–969, 2004. J. F¨ rnkranz and E. H¨ llermeier. Pairwise preference learning and ranking. In Proceedings of the u u European Conference on Machine Learning 2003, Cavtat-Dubrovnik, pages 145–156. SpringerVerlag, 2003. F. Harrell. Regression Modeling Strategies. With Applications to Linear Models, Logistic Regression, and Survival Analysis. Springer, 2001. F. Harrell, K. Klee, R. Califf, D. Pryor, and R. Rosati. Regression modeling strategies for improved prognostic prediction. Statistics in Medicine, 3(2):143–152, 1984. T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. Springer-Verlag, 2001. P. Heagerty, T. Lumley, and M. Pepe. Time-dependent ROC curves for censored survival data and a diagnostic marker. Biometrics, 56(2):337–344, 2000. R. Herbrich, T. Graepel, P. Bollmann-Sdorra, and K. Obermayer. Learning preference relations for information retrieval. In Proceedings of the Fifteenth Conference of the American Association for Artiﬁcial Intelligence, pages 1–4, 1998. R. Herbrich, T. Graepel, and K. Obermayer. Large margin rank boundaries for ordinal regression. In Smola, Bartlett, Schoelkopf, and Schuurmans, editors, Advances in Large Margin Classiﬁers, 2000. C.M. Hurvich, J.S. Simonoff, and C.L. Tsai. Smoothing parameter selection in nonparametric regression using an improved akaike information criterion. Journal of the Royal Statistical Society: Series B, 60:371–293, 1998. J.D. Kalbﬂeisch and R.L. Prentice. The Statistical Analysis of Failure Time Data. Wiley series in probability and statistics. 2002. 860  T RANSFORMATION M ODELS FOR R ANKING AND S URVIVAL  M.W. Kattan, H. Ishida, P.T. Scardino, and J.R. Beck. Applying a neural network to prostate cancer survival data. In N. Lavrac, R. Keravnou, and B. Zupan, editors, Intelligent Data Analysis in Medicine and Pharmacology, pages 295–306. Kluwer, Boston, 1997. R. Koenker and O. Geling. Reappraising medﬂy longevity: A quantile regression survival analysis. Journal of the American Statistical Association, 96:458–468, 2001. P.J. Lamy, P. Pujol, S. Thezenas, A. Kramar, P. Rouanet, F. Guilleux, and J. Grenier. Progesterone receptor quantiﬁcation as a strong prognostic determinant in postmenopausal breast cancer women under tamoxifen therapy. Breast cancer reasearch and treatment, 76(1):65–71, 2002. D.J.C. MacKay. A practical Bayesian framework for backpropagation networks. Neural Computing, 4(3):448–472, 1992. H. Martens and T. Næs. Multivariate Calibration. New York: John Wiley & Sons Inc., 1989. R.G. Miller. Survival Anlysis. John Wiley & Sons, 1981. S. Nyg˚ rd, O. Borgan, O. Lingjærde, and H. Størvold. Partial least squares Cox regression for a genome-wide data. Lifetime Data Analysis, 14(2):179–195, 2008. K. Pelckmans, M. Espinoza, J. De Brabanter, J.A.K. Suykens, and B. De Moor. Primal-dual monotone kernel regression. Neural Processing Letters, 22(2):171–182, 2005a. K. Pelckmans, I. Goethals, J. De Brabanter, J.A.K. Suykens, and B. De Moor. Componentwise Least Squares Support Vector Machines, chapter in Support Vector Machines: Theory and Applications, pages 77–98. (L. Wang, ed.), Springer, 2005b. R. Peto. Discussion of paper by D.R. Cox. Journal of the Royal Statistical Society, Series B, 34: 205–207, 1972. M.F. Pichon, C. Pallud, M. Brunet, and E. Milgrom. Relationship of presence of progesterone receptors to prognosis in early breast cancer. Cancer Research, 40:3357–3360, 1980. A. Rosenwald, G. Wright, W.C. Chan, J.M. Connors, E. Campo, R.I. Fisher, R.D. Gascoyne, H.K. Muller-Hermelink, R.B. Smeland, J.M. Giltnane, E.M. Hurt, H. Zhao, L. Averett, and L. Yang. The use of molecular proﬁling to predict survival after chemotherapy for diffuse large-B-cell lymphoma. The New England Journal of Medicine, 346(25):1937–1947, 2002. G.A. Satten. Rank-based inference in the proportional hazards model for interval censored data. Biometrika, 83:355–370, 1996. M. Schumacher, G. Basert, H. Bojar, K. Huebner, M. Olschewski, W. Sauerbrei, C. Schmoor, C. Beyerle, R.L.A. Neumann, and H.F. Rauschecker. Randomized 2 x 2 trial evaluating hormonal treatment and the duration of chemotherapy in node-positive breast cancer patients. Journal of Clinical Oncology, 12, 1994. J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press, 2004. 861  VAN B ELLE , P ELCKMANS , S UYKENS AND VAN H UFFEL  T. Sørlie, R. Tibshirani, J. Parker, T. Hastie, J.S. Marron, A. Nobel, S. Deng, H. Johnsen, R. Pesich, S. Geisler, J. Demeter, C.M. Perou, P.E. Lønning, P.O. Brown, A. Børresen-Dale, and D. Botstein. Repeated observation of breast tumor subtypes in independent gene expression data sets. Proceedings of the National Academy of Sciences of the United States of America, 100(14):8418– 8423, 2003. J.A.K. Suykens, T. Van Gestel, J. De Brabanter, B. De Moor, and J. Vandewalle. Least Squares Support Vector Machines. World Scientiﬁc, Singapore, 2002. T.M. Therneau and P.M. Grambsch. Modeling Survival Data: Extending the Cox Model. Springer, 2 edition, 2000. R. Tibshirani. Regression shrinkage and selection via the Lasso. Journal of the Royal Statistical Society, Series B, 58(1):267–288, 1996. V. Van Belle, K. Pelckmans, J.A.K. Suykens, and S. Van Huffel. Support vector machines for survival analysis. In Proceedings of the Third International Conference on Computational Intelligence in Medicine and Healthcare (CIMED2007), pages 1–8, Plymouth (UK), July 2007. V. Van Belle, K. Pelckmans, J.A.K. Suykens, and S. Van Huffel. Survival SVM: a practical scalable algorithm. In Proceedings of the 16th European Symposium on Artiﬁcial Neural Networks (ESANN2008), pages 89–94, Bruges (Belgium), April 2008. V. Van Belle, K. Pelckmans, J.A.K. Suykens, and S. Van Huffel. MINLIP: Efﬁcient learning of transformation models. In Proceedings of the International Conference on Artiﬁcial Neural Networks (ICANN2009), pages 60–69, Limassol (Cyprus), September 2009. M.J. van de Vijver, L.J. van’t Veer, and H. Dai. A gene-expression signature as a predictor of survival in breast cancer. The New England Journal of Medicine, 347(25):1999–2009, 2002. H.C. van Houwelingen, T. Bruinsma, A.A.M. Hart, L.J. van’t Veer, and L.F.A. Wessels. Crossvalidated cox regression on microarray gene expression data. Statistics in Medicine, 25(18): 3201–3216, 2006. V. Vapnik. Statistical Learning Theory. Wiley and Sons, 1998. C. Verschraegen, C. Vihn-Hung, G. Cserni, R. Gordon, M.E. Royce, G. Vlastos, P. Tai, and G. Storme. Modeling the effect of tumor size in early breast cancer. Annals of Surgery, 241 (2):309–318, 2005.  862</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
