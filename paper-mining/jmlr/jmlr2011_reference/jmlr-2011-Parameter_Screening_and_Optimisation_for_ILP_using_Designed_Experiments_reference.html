<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>76 jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-76" href="../jmlr2011/jmlr-2011-Parameter_Screening_and_Optimisation_for_ILP_using_Designed_Experiments.html">jmlr2011-76</a> <a title="jmlr-2011-76-reference" href="#">jmlr2011-76-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>76 jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</h1>
<br/><p>Source: <a title="jmlr-2011-76-pdf" href="http://jmlr.org/papers/volume12/srinivasan11a/srinivasan11a.pdf">pdf</a></p><p>Author: Ashwin Srinivasan, Ganesh Ramakrishnan</p><p>Abstract: Reports of experiments conducted with an Inductive Logic Programming system rarely describe how speciﬁc values of parameters of the system are arrived at when constructing models. Usually, no attempt is made to identify sensitive parameters, and those that are used are often given “factory-supplied” default values, or values obtained from some non-systematic exploratory analysis. The immediate consequence of this is, of course, that it is not clear if better models could have been obtained if some form of parameter selection and optimisation had been performed. Questions follow inevitably on the experiments themselves: speciﬁcally, are all algorithms being treated fairly, and is the exploratory phase sufﬁciently well-deﬁned to allow the experiments to be replicated? In this paper, we investigate the use of parameter selection and optimisation techniques grouped under the study of experimental design. Screening and response surface methods determine, in turn, sensitive parameters and good values for these parameters. Screening is done here by constructing a stepwise regression model relating the utility of an ILP system’s hypothesis to its input parameters, using systematic combinations of values of input parameters (technically speaking, we use a two-level fractional factorial design of the input parameters). The parameters used by the regression model are taken to be the sensitive parameters for the system for that application. We then seek an assignment of values to these sensitive parameters that maximise the utility of the ILP model. This is done using the technique of constructing a local “response surface”. The parameters are then changed following the path of steepest ascent until a locally optimal value is reached. This combined use of parameter selection and response surface-driven optimisation has a long history of application in industrial engineering, and its role in ILP is demonstrated using well-known benchmarks. The results suggest that computational</p><br/>
<h2>reference text</h2><p>J. Ashby and R.W. Tennant. Deﬁnitive relationships among chemical structure, carcinogenicity and mutagenicity for 301 chemicals tested by the U.S. NTP. Mutation Research, 257:229–306, 1991. M. Baz, B. Hunsaker, J.P. Brooks, and A. Gosavi. Automatic tuning of optimization software parameters. Technical Report 2007-7, University of Pittsburgh, Dept. of Industrial Engineering, 2007. Y. Bengio. Gradient based optimisation of hyperparameters. Neural Computation, 12(8):1889– 1900, 2000. Y. Bengio and Y. Grandvalet. No unbiased estimator of the variance of k-fold cross-validation. Journal of Machine Learning Research, 5:1089–1105, 2004. G.E.P. Box and K.B. Wilson. On the experimental attainment of optimum conditions. Journal of the Royal Statistical Society, Series B (Methodological), 13(1):1–45, 1951. I. Bratko and S.H. Muggleton. Applications of inductive logic programming. Communications of the ACM, 38(11):65–70, 1995. 660  S CREENING AND O PTIMISATION FOR ILP  L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classiﬁcation and Regression Trees. Wadsworth, Belmont, 1984. R. Bronson and G. Naadimuthu, editors. Schaum’s Outline of Theory and Problems of Operations Research. McGraw Hill, New York, 1982. (2nd Edition). A.K. Debnath, R.L Lopez de Compadre, G. Debnath, A.J. Schusterman, and C. Hansch. Structureactivity relationship of mutagenic aromatic and heteroaromatic nitro compounds. Correlation with molecular orbital energies and hydrophobicity. Journal of Medicinal Chemistry, 34(2):786 – 797, 1991. L. DeRaedt and M. Bruynooghe. Interactive concept-learning and constructive induction by analogy. Machine Learning, 8(2):107–150, 1992. S. Dzeroski. Relational data mining applications: An overview. In S. Dzeroski and N. Lavrac, editors, Relational Data Mining, pages 339–360. Springer, Berlin, 2001. M.C. Fu. Optimization via simulation. Annals of Operations Research, 53:199–248, 1994. L. Getoor and B. Taskar, editors. Introduction to Statistical Relational Learning. MIT Press, Cambridge, 2007. D. J. Hand. Construction and Assessment of Classiﬁcation Rules. Wiley, Chichester, 1997. J.C. Helton, J.D. Johnson, C.J. Sallaberry, and C.B. Storlie. Survey of sampling-based methods for uncertainty and sensitivity analysis. Reliability Engineering & System Safety, 91(10–11): 1175–1209, 2006. R. Jain. The Art of Computer Systems Performance Analysis. John Wiley, New York, 1991. Frederik Janssen and Johannes F¨ rnkranz. On the quest for optimal rule learning heuristics. Mach. u Learn., 78:343–379, March 2010. ISSN 0885-6125. S.S. Keerthi, V. Sindhwani, and O. Chapelle. An efﬁcient method for gradient-based adaptation of hyperparameters in svm models. In NIPS, pages 673–680, 2006. R.D. King and A. Srinivasan. Prediction of rodent carcinogenicity bioassays from molecular structure using inductive logic programming. Environmental Health Perspectives, 104(5):1031–1040, 1996. R.D. King, S.H. Muggleton, A. Srinivasan, and M.J.E. Sternberg. Structure-activity relationships derived by machine learning: The use of atoms and their bond connectivities to predict mutagenicity by inductive logic programming. Proc. of the National Academy of Sciences, 93: 438–442, 1996. R. Kohavi and G.H. John. Automatic parameter selection by minimizing estimated error. In A. Prieditis and S. Russell, editors, Proceedings of the Twelfth International Conference on Machine Learning, pages 204–212, San Francisco, CA, 1995. Morgan Kaufmann. N. Landwehr, A. Passerini, L. De Raedt, and P. Frasconi. kfoil: Learning simple relational kernels. In AAAI, pages 389–396, 2006. 661  S RINIVASAN AND R AMAKRISHNAN  D.C. Montgomery. Design and Analysis of Experiments (5th Ed.). John Wiley, New York, 2005. S. Muggleton. Inverse Entailment and Progol. New Gen. Comput., 13:245–286, 1995. S. Muggleton and L. De Raedt. Inductive logic programming: Theory and methods. Journal of Logic Programming, 19,20:629–679, 1994. S.H. Muggleton, J.C. Almeida Santos, and A. Tamaddoni-Nezhad. Toplog: Ilp using a logic program declarative bias. In ICLP, pages 687–692, 2008. H.G. Neddermeijer, G.J. van Oortmarssen, N. Piersma, and R.Dekker. A framework for response surface methodology for simulation optimization. In Winter Simulation Conference, pages 129– 136, 2000. M.H. Saﬁzadeh and R. Signorile. Optimization of simulation via quasi-newton methods. ORSA Journal on Computing, 6(4):388–408, 1994. S. Siegel. Nonparametric Statistics for the Behavioural Sciences. McGraw-Hill, New York, 1956. A. Srinivasan. The aleph manual. 1999. URL http://www.comlab.ox.ac.uk/oucl/research/ areas/machlearn/Aleph/. A. Srinivasan. Four suggestions and a rule concerning the application of ilp. In Nada Lavrac and Saso Dzeroski, editors, Relational Data Mining, pages 365–374. Springer-Verlag, Berlin, 2001a. URL ftp://ftp.comlab.ox.ac.uk/pub/Packages/ILP/Papers/AS/ilpkdd.ps.gz. A. Srinivasan. Extracting context-sensitive models in inductive logic programming. Machine Learning, 44:301–324, 2001b. URL ftp://ftp.comlab.ox.ac.uk/pub/Packages/ILP/Papers/ AS/relev.ps.gz. D.D. Steppan, J. Werner, and R.P. Yeater. Essential Regression and Experimental Design for Chemists and Engineers. 1998. URL http://www.jowerner.homepage.t-online.de/ download.htm. R.E. Walpole and R.H. Myers. Probability and Statistics for Engineers and Scientists. Collier Macmillan, New York, 1978. 2nd Edition. F. Zelezny, A. Srinivasan, and C.D. Page. Lattice-search runtime distributions may be heavytailed. In Proceedings of the Twelfth International Conference on Inductive Logic Programming (ILP2002), LNAI, Berlin, 2002. Springer. URL ftp://ftp.comlab.ox.ac.uk/pub/ Packages/ILP/Papers/AS/rrr.ps.gz.  662</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
