<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-96" href="../jmlr2011/jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">jmlr2011-96</a> <a title="jmlr-2011-96-reference" href="#">jmlr2011-96-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</h1>
<br/><p>Source: <a title="jmlr-2011-96-pdf" href="http://jmlr.org/papers/volume12/taylor11a/taylor11a.pdf">pdf</a></p><p>Author: Graham W. Taylor, Geoffrey E. Hinton, Sam T. Roweis</p><p>Abstract: In this paper we develop a class of nonlinear generative models for high-dimensional time series. We ﬁrst propose a model based on the restricted Boltzmann machine (RBM) that uses an undirected model with binary latent variables and real-valued “visible” variables. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. This “conditional” RBM (CRBM) makes on-line inference efﬁcient and allows us to use a simple approximate learning procedure. We demonstrate the power of our approach by synthesizing various sequences from a model trained on motion capture data and by performing on-line ﬁlling in of data lost during capture. We extend the CRBM in a way that preserves its most important computational properties and introduces multiplicative three-way interactions that allow the effective interaction weight between two variables to be modulated by the dynamic state of a third variable. We introduce a factoring of the implied three-way weight tensor to permit a more compact parameterization. The resulting model can capture diverse styles of motion with a single set of parameters, and the three-way interactions greatly improve its ability to blend motion styles or to transition smoothly among them. Videos and source code can be found at http://www.cs.nyu.edu/˜gwtaylor/publications/ jmlr2011. Keywords: unsupervised learning, restricted Boltzmann machines, time series, generative models, motion capture</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
