<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-72" href="#">jmlr2013-72</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</h1>
<br/><p>Source: <a title="jmlr-2013-72-pdf" href="http://jmlr.org/papers/volume14/gong13a/gong13a.pdf">pdf</a></p><p>Author: Pinghua Gong, Jieping Ye, Changshui Zhang</p><p>Abstract: Multi-task sparse feature learning aims to improve the generalization performance by exploiting the shared features among tasks. It has been successfully applied to many applications including computer vision and biomedical informatics. Most of the existing multi-task sparse feature learning algorithms are formulated as a convex sparse regularization problem, which is usually suboptimal, due to its looseness for approximating an â„“0 -type regularizer. In this paper, we propose a non-convex formulation for multi-task sparse feature learning based on a novel non-convex regularizer. To solve the non-convex optimization problem, we propose a Multi-Stage Multi-Task Feature Learning (MSMTFL) algorithm; we also provide intuitive interpretations, detailed convergence and reproducibility analysis for the proposed algorithm. Moreover, we present a detailed theoretical analysis showing that MSMTFL achieves a better parameter estimation error bound than the convex formulation. Empirical studies on both synthetic and real-world data sets demonstrate the effectiveness of MSMTFL in comparison with the state of the art multi-task sparse feature learning algorithms. Keywords: multi-task learning, multi-stage, non-convex, sparse learning</p><p>Reference: <a title="jmlr-2013-72-reference" href="../jmlr2013_reference/jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ji', 0.509), ('msmtfl', 0.42), ('ult', 0.308), ('dirtymtl', 0.228), ('wii', 0.183), ('wg', 0.179), ('wi', 0.154), ('gi', 0.148), ('tag', 0.139), ('nm', 0.132), ('gic', 0.123), ('jalal', 0.123), ('nmse', 0.12), ('fi', 0.109), ('ams', 0.103), ('ong', 0.1), ('eat', 0.098), ('hang', 0.093), ('zhang', 0.091), ('tsinghu', 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="72-tfidf-1" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>2 0.10634487 <a title="72-tfidf-2" href="./jmlr-2013-Generalized_Spike-and-Slab_Priors_for_Bayesian_Group_Feature_Selection_Using_Expectation_Propagation.html">48 jmlr-2013-Generalized Spike-and-Slab Priors for Bayesian Group Feature Selection Using Expectation Propagation</a></p>
<p>3 0.10240778 <a title="72-tfidf-3" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>4 0.090974338 <a title="72-tfidf-4" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>5 0.071962893 <a title="72-tfidf-5" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>6 0.06704744 <a title="72-tfidf-6" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>7 0.058377445 <a title="72-tfidf-7" href="./jmlr-2013-Message-Passing_Algorithms_for_Quadratic_Minimization.html">71 jmlr-2013-Message-Passing Algorithms for Quadratic Minimization</a></p>
<p>8 0.057660274 <a title="72-tfidf-8" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>9 0.056643791 <a title="72-tfidf-9" href="./jmlr-2013-Distribution-Dependent_Sample_Complexity_of_Large_Margin_Learning.html">35 jmlr-2013-Distribution-Dependent Sample Complexity of Large Margin Learning</a></p>
<p>10 0.050918803 <a title="72-tfidf-10" href="./jmlr-2013-The_Rate_of_Convergence_of_AdaBoost.html">114 jmlr-2013-The Rate of Convergence of AdaBoost</a></p>
<p>11 0.046469681 <a title="72-tfidf-11" href="./jmlr-2013-Parallel_Vector_Field_Embedding.html">86 jmlr-2013-Parallel Vector Field Embedding</a></p>
<p>12 0.044198439 <a title="72-tfidf-12" href="./jmlr-2013-Nested_Expectation_Propagation_for_Gaussian_Process_Classification_with_a_Multinomial_Probit_Likelihood.html">75 jmlr-2013-Nested Expectation Propagation for Gaussian Process Classification with a Multinomial Probit Likelihood</a></p>
<p>13 0.043833204 <a title="72-tfidf-13" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>14 0.042164288 <a title="72-tfidf-14" href="./jmlr-2013-Greedy_Feature_Selection_for_Subspace_Clustering.html">50 jmlr-2013-Greedy Feature Selection for Subspace Clustering</a></p>
<p>15 0.041810311 <a title="72-tfidf-15" href="./jmlr-2013-Consistent_Selection_of_Tuning_Parameters_via_Variable_Selection_Stability.html">27 jmlr-2013-Consistent Selection of Tuning Parameters via Variable Selection Stability</a></p>
<p>16 0.03971947 <a title="72-tfidf-16" href="./jmlr-2013-Algorithms_and_Hardness_Results_for_Parallel_Large_Margin_Learning.html">10 jmlr-2013-Algorithms and Hardness Results for Parallel Large Margin Learning</a></p>
<p>17 0.038579587 <a title="72-tfidf-17" href="./jmlr-2013-On_the_Mutual_Nearest_Neighbors_Estimate_in_Regression.html">79 jmlr-2013-On the Mutual Nearest Neighbors Estimate in Regression</a></p>
<p>18 0.038524978 <a title="72-tfidf-18" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>19 0.037193168 <a title="72-tfidf-19" href="./jmlr-2013-Quasi-Newton_Method%3A_A_New_Direction.html">90 jmlr-2013-Quasi-Newton Method: A New Direction</a></p>
<p>20 0.036798351 <a title="72-tfidf-20" href="./jmlr-2013-Derivative_Estimation_with_Local_Polynomial_Fitting.html">31 jmlr-2013-Derivative Estimation with Local Polynomial Fitting</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.201), (1, 0.041), (2, 0.01), (3, 0.066), (4, -0.084), (5, 0.065), (6, -0.138), (7, -0.074), (8, 0.075), (9, -0.055), (10, -0.013), (11, 0.131), (12, 0.044), (13, -0.049), (14, -0.069), (15, 0.031), (16, -0.074), (17, 0.06), (18, 0.031), (19, 0.129), (20, -0.07), (21, 0.063), (22, 0.142), (23, -0.076), (24, 0.087), (25, 0.001), (26, 0.036), (27, 0.169), (28, 0.138), (29, 0.035), (30, 0.05), (31, -0.139), (32, 0.016), (33, 0.126), (34, 0.066), (35, 0.04), (36, -0.024), (37, 0.072), (38, -0.106), (39, 0.096), (40, -0.054), (41, -0.3), (42, -0.109), (43, 0.01), (44, 0.038), (45, -0.018), (46, 0.141), (47, -0.038), (48, 0.19), (49, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90636146 <a title="72-lsi-1" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>2 0.50671166 <a title="72-lsi-2" href="./jmlr-2013-Generalized_Spike-and-Slab_Priors_for_Bayesian_Group_Feature_Selection_Using_Expectation_Propagation.html">48 jmlr-2013-Generalized Spike-and-Slab Priors for Bayesian Group Feature Selection Using Expectation Propagation</a></p>
<p>3 0.44864726 <a title="72-lsi-3" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>4 0.38962993 <a title="72-lsi-4" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>5 0.38720456 <a title="72-lsi-5" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>6 0.36698824 <a title="72-lsi-6" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>7 0.36251065 <a title="72-lsi-7" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>8 0.361514 <a title="72-lsi-8" href="./jmlr-2013-Message-Passing_Algorithms_for_Quadratic_Minimization.html">71 jmlr-2013-Message-Passing Algorithms for Quadratic Minimization</a></p>
<p>9 0.3502861 <a title="72-lsi-9" href="./jmlr-2013-Bayesian_Canonical_Correlation_Analysis.html">15 jmlr-2013-Bayesian Canonical Correlation Analysis</a></p>
<p>10 0.30911419 <a title="72-lsi-10" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>11 0.30186865 <a title="72-lsi-11" href="./jmlr-2013-Distribution-Dependent_Sample_Complexity_of_Large_Margin_Learning.html">35 jmlr-2013-Distribution-Dependent Sample Complexity of Large Margin Learning</a></p>
<p>12 0.28986731 <a title="72-lsi-12" href="./jmlr-2013-Dimension_Independent_Similarity_Computation.html">33 jmlr-2013-Dimension Independent Similarity Computation</a></p>
<p>13 0.2657533 <a title="72-lsi-13" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>14 0.26574758 <a title="72-lsi-14" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>15 0.25014687 <a title="72-lsi-15" href="./jmlr-2013-On_the_Mutual_Nearest_Neighbors_Estimate_in_Regression.html">79 jmlr-2013-On the Mutual Nearest Neighbors Estimate in Regression</a></p>
<p>16 0.25014684 <a title="72-lsi-16" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>17 0.24710712 <a title="72-lsi-17" href="./jmlr-2013-Parallel_Vector_Field_Embedding.html">86 jmlr-2013-Parallel Vector Field Embedding</a></p>
<p>18 0.24362639 <a title="72-lsi-18" href="./jmlr-2013-Derivative_Estimation_with_Local_Polynomial_Fitting.html">31 jmlr-2013-Derivative Estimation with Local Polynomial Fitting</a></p>
<p>19 0.24266496 <a title="72-lsi-19" href="./jmlr-2013-Machine_Learning_with_Operational_Costs.html">68 jmlr-2013-Machine Learning with Operational Costs</a></p>
<p>20 0.2421205 <a title="72-lsi-20" href="./jmlr-2013-Sparse_Single-Index_Model.html">104 jmlr-2013-Sparse Single-Index Model</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.012), (16, 0.022), (21, 0.049), (34, 0.055), (55, 0.028), (58, 0.037), (61, 0.026), (62, 0.074), (81, 0.046), (84, 0.021), (97, 0.409), (98, 0.108)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.61834025 <a title="72-lda-1" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>2 0.35471183 <a title="72-lda-2" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>3 0.35296738 <a title="72-lda-3" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>4 0.35130259 <a title="72-lda-4" href="./jmlr-2013-Improving_CUR_Matrix_Decomposition_and_the_Nystrom_Approximation_via_Adaptive_Sampling.html">53 jmlr-2013-Improving CUR Matrix Decomposition and the Nystrom Approximation via Adaptive Sampling</a></p>
<p>5 0.35118753 <a title="72-lda-5" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>6 0.35063708 <a title="72-lda-6" href="./jmlr-2013-On_the_Convergence_of_Maximum_Variance_Unfolding.html">77 jmlr-2013-On the Convergence of Maximum Variance Unfolding</a></p>
<p>7 0.34996456 <a title="72-lda-7" href="./jmlr-2013-Nonparametric_Sparsity_and_Regularization.html">76 jmlr-2013-Nonparametric Sparsity and Regularization</a></p>
<p>8 0.34877065 <a title="72-lda-8" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>9 0.346499 <a title="72-lda-9" href="./jmlr-2013-A_Plug-in_Approach_to_Neyman-Pearson_Classification.html">6 jmlr-2013-A Plug-in Approach to Neyman-Pearson Classification</a></p>
<p>10 0.34594285 <a title="72-lda-10" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>11 0.3449361 <a title="72-lda-11" href="./jmlr-2013-CODA%3A_High_Dimensional_Copula_Discriminant_Analysis.html">20 jmlr-2013-CODA: High Dimensional Copula Discriminant Analysis</a></p>
<p>12 0.34493476 <a title="72-lda-12" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>13 0.34371418 <a title="72-lda-13" href="./jmlr-2013-PC_Algorithm_for_Nonparanormal_Graphical_Models.html">84 jmlr-2013-PC Algorithm for Nonparanormal Graphical Models</a></p>
<p>14 0.34337312 <a title="72-lda-14" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>15 0.34179056 <a title="72-lda-15" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>16 0.34139925 <a title="72-lda-16" href="./jmlr-2013-Sparse_Single-Index_Model.html">104 jmlr-2013-Sparse Single-Index Model</a></p>
<p>17 0.3408075 <a title="72-lda-17" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>18 0.34030792 <a title="72-lda-18" href="./jmlr-2013-Similarity-based_Clustering_by_Left-Stochastic_Matrix_Factorization.html">100 jmlr-2013-Similarity-based Clustering by Left-Stochastic Matrix Factorization</a></p>
<p>19 0.33979142 <a title="72-lda-19" href="./jmlr-2013-Classifier_Selection_using_the_Predicate_Depth.html">21 jmlr-2013-Classifier Selection using the Predicate Depth</a></p>
<p>20 0.33971775 <a title="72-lda-20" href="./jmlr-2013-Semi-Supervised_Learning_Using_Greedy_Max-Cut.html">99 jmlr-2013-Semi-Supervised Learning Using Greedy Max-Cut</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
