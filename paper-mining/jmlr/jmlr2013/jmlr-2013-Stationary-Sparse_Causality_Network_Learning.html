<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>106 jmlr-2013-Stationary-Sparse Causality Network Learning</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-106" href="#">jmlr2013-106</a> knowledge-graph by maker-knowledge-mining</p><h1>106 jmlr-2013-Stationary-Sparse Causality Network Learning</h1>
<br/><p>Source: <a title="jmlr-2013-106-pdf" href="http://jmlr.org/papers/volume14/he13a/he13a.pdf">pdf</a></p><p>Author: Yuejia He, Yiyuan She, Dapeng Wu</p><p>Abstract: Recently, researchers have proposed penalized maximum likelihood to identify network topology underlying a dynamical system modeled by multivariate time series. The time series of interest are assumed to be stationary, but this restriction is never taken into consideration by existing estimation methods. Moreover, practical problems of interest may have ultra-high dimensionality and obvious node collinearity. In addition, none of the available algorithms provides a probabilistic measure of the uncertainty for the obtained network topology which is informative in reliable network identiﬁcation. The main purpose of this paper is to tackle these challenging issues. We propose the S2 learning framework, which stands for stationary-sparse network learning. We propose a novel algorithm referred to as the Berhu iterative sparsity pursuit with stationarity (BISPS), where the Berhu regularization can improve the Lasso in detection and estimation. The algorithm is extremely easy to implement, efﬁcient in computation and has a theoretical guarantee to converge to a global optimum. We also incorporate a screening technique into BISPS to tackle ultra-high dimensional problems and enhance computational efﬁciency. Furthermore, a stationary bootstrap technique is applied to provide connection occurring frequency for reliable topology learning. Experiments show that our method can achieve stationary and sparse causality network learning and is scalable for high-dimensional problems. Keywords: stationarity, sparsity, Berhu, screening, bootstrap</p><p>Reference: <a title="jmlr-2013-106-reference" href="../jmlr2013_reference/jmlr-2013-Stationary-Sparse_Causality_Network_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bisp', 0.582), ('berhu', 0.461), ('qti', 0.243), ('ak', 0.172), ('station', 0.167), ('enet', 0.148), ('pml', 0.148), ('screening', 0.133), ('pb', 0.123), ('macroeconom', 0.122), ('aus', 0.112), ('thresholding', 0.111), ('lasso', 0.111), ('penal', 0.106), ('nonst', 0.1), ('etwork', 0.1), ('bootstrap', 0.096), ('forecast', 0.089), ('grang', 0.082), ('collinear', 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="106-tfidf-1" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>2 0.10965132 <a title="106-tfidf-2" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>3 0.082517438 <a title="106-tfidf-3" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>4 0.067166947 <a title="106-tfidf-4" href="./jmlr-2013-Consistent_Selection_of_Tuning_Parameters_via_Variable_Selection_Stability.html">27 jmlr-2013-Consistent Selection of Tuning Parameters via Variable Selection Stability</a></p>
<p>5 0.055148438 <a title="106-tfidf-5" href="./jmlr-2013-Sparse_Robust_Estimation_and_Kalman_Smoothing_with_Nonsmooth_Log-Concave_Densities%3A_Modeling%2C_Computation%2C_and_Theory.html">103 jmlr-2013-Sparse Robust Estimation and Kalman Smoothing with Nonsmooth Log-Concave Densities: Modeling, Computation, and Theory</a></p>
<p>6 0.05230578 <a title="106-tfidf-6" href="./jmlr-2013-Using_Symmetry_and_Evolutionary_Search_to_Minimize_Sorting_Networks.html">118 jmlr-2013-Using Symmetry and Evolutionary Search to Minimize Sorting Networks</a></p>
<p>7 0.050485127 <a title="106-tfidf-7" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>8 0.049121566 <a title="106-tfidf-8" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>9 0.048255935 <a title="106-tfidf-9" href="./jmlr-2013-Optimally_Fuzzy_Temporal_Memory.html">82 jmlr-2013-Optimally Fuzzy Temporal Memory</a></p>
<p>10 0.048002727 <a title="106-tfidf-10" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>11 0.042443171 <a title="106-tfidf-11" href="./jmlr-2013-Variational_Algorithms_for_Marginal_MAP.html">120 jmlr-2013-Variational Algorithms for Marginal MAP</a></p>
<p>12 0.040017694 <a title="106-tfidf-12" href="./jmlr-2013-Nonparametric_Sparsity_and_Regularization.html">76 jmlr-2013-Nonparametric Sparsity and Regularization</a></p>
<p>13 0.036782131 <a title="106-tfidf-13" href="./jmlr-2013-Finding_Optimal_Bayesian_Networks_Using_Precedence_Constraints.html">44 jmlr-2013-Finding Optimal Bayesian Networks Using Precedence Constraints</a></p>
<p>14 0.035767969 <a title="106-tfidf-14" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>15 0.035592232 <a title="106-tfidf-15" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>16 0.035132643 <a title="106-tfidf-16" href="./jmlr-2013-Improving_CUR_Matrix_Decomposition_and_the_Nystrom_Approximation_via_Adaptive_Sampling.html">53 jmlr-2013-Improving CUR Matrix Decomposition and the Nystrom Approximation via Adaptive Sampling</a></p>
<p>17 0.033449572 <a title="106-tfidf-17" href="./jmlr-2013-Experiment_Selection_for_Causal_Discovery.html">41 jmlr-2013-Experiment Selection for Causal Discovery</a></p>
<p>18 0.032713789 <a title="106-tfidf-18" href="./jmlr-2013-Sparse_Single-Index_Model.html">104 jmlr-2013-Sparse Single-Index Model</a></p>
<p>19 0.031079544 <a title="106-tfidf-19" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>20 0.03103574 <a title="106-tfidf-20" href="./jmlr-2013-Distributions_of_Angles_in_Random_Packing_on_Spheres.html">36 jmlr-2013-Distributions of Angles in Random Packing on Spheres</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.167), (1, 0.017), (2, 0.039), (3, 0.042), (4, -0.103), (5, -0.064), (6, -0.1), (7, -0.082), (8, 0.013), (9, -0.128), (10, -0.059), (11, 0.103), (12, 0.074), (13, 0.084), (14, -0.062), (15, 0.163), (16, -0.009), (17, -0.041), (18, 0.113), (19, -0.002), (20, 0.004), (21, -0.19), (22, -0.035), (23, 0.011), (24, -0.008), (25, 0.038), (26, 0.12), (27, -0.037), (28, -0.053), (29, -0.033), (30, 0.076), (31, 0.07), (32, 0.029), (33, 0.006), (34, 0.044), (35, 0.115), (36, 0.14), (37, 0.01), (38, 0.077), (39, 0.091), (40, 0.029), (41, 0.198), (42, 0.114), (43, -0.077), (44, 0.014), (45, 0.14), (46, 0.086), (47, -0.057), (48, -0.175), (49, -0.127)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.8838352 <a title="106-lsi-1" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>2 0.50873023 <a title="106-lsi-2" href="./jmlr-2013-Using_Symmetry_and_Evolutionary_Search_to_Minimize_Sorting_Networks.html">118 jmlr-2013-Using Symmetry and Evolutionary Search to Minimize Sorting Networks</a></p>
<p>3 0.43332839 <a title="106-lsi-3" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>4 0.41966999 <a title="106-lsi-4" href="./jmlr-2013-Consistent_Selection_of_Tuning_Parameters_via_Variable_Selection_Stability.html">27 jmlr-2013-Consistent Selection of Tuning Parameters via Variable Selection Stability</a></p>
<p>5 0.41234252 <a title="106-lsi-5" href="./jmlr-2013-Optimally_Fuzzy_Temporal_Memory.html">82 jmlr-2013-Optimally Fuzzy Temporal Memory</a></p>
<p>6 0.34172419 <a title="106-lsi-6" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>7 0.34128535 <a title="106-lsi-7" href="./jmlr-2013-Sparse_Robust_Estimation_and_Kalman_Smoothing_with_Nonsmooth_Log-Concave_Densities%3A_Modeling%2C_Computation%2C_and_Theory.html">103 jmlr-2013-Sparse Robust Estimation and Kalman Smoothing with Nonsmooth Log-Concave Densities: Modeling, Computation, and Theory</a></p>
<p>8 0.33021352 <a title="106-lsi-8" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>9 0.29113376 <a title="106-lsi-9" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>10 0.28170356 <a title="106-lsi-10" href="./jmlr-2013-Joint_Harmonic_Functions_and_Their_Supervised_Connections.html">55 jmlr-2013-Joint Harmonic Functions and Their Supervised Connections</a></p>
<p>11 0.27970937 <a title="106-lsi-11" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>12 0.27909341 <a title="106-lsi-12" href="./jmlr-2013-Finding_Optimal_Bayesian_Networks_Using_Precedence_Constraints.html">44 jmlr-2013-Finding Optimal Bayesian Networks Using Precedence Constraints</a></p>
<p>13 0.27589646 <a title="106-lsi-13" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>14 0.26780677 <a title="106-lsi-14" href="./jmlr-2013-Training_Energy-Based_Models_for_Time-Series_Imputation.html">115 jmlr-2013-Training Energy-Based Models for Time-Series Imputation</a></p>
<p>15 0.2545754 <a title="106-lsi-15" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>16 0.25435862 <a title="106-lsi-16" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>17 0.2477605 <a title="106-lsi-17" href="./jmlr-2013-Nonparametric_Sparsity_and_Regularization.html">76 jmlr-2013-Nonparametric Sparsity and Regularization</a></p>
<p>18 0.24342923 <a title="106-lsi-18" href="./jmlr-2013-Experiment_Selection_for_Causal_Discovery.html">41 jmlr-2013-Experiment Selection for Causal Discovery</a></p>
<p>19 0.21758169 <a title="106-lsi-19" href="./jmlr-2013-Counterfactual_Reasoning_and_Learning_Systems%3A_The_Example_of_Computational_Advertising.html">30 jmlr-2013-Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</a></p>
<p>20 0.18881039 <a title="106-lsi-20" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.01), (9, 0.017), (16, 0.016), (18, 0.022), (21, 0.029), (26, 0.012), (34, 0.046), (40, 0.012), (55, 0.02), (58, 0.039), (61, 0.023), (62, 0.051), (81, 0.054), (84, 0.495), (98, 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81811863 <a title="106-lda-1" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>same-paper 2 0.73119509 <a title="106-lda-2" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>3 0.30449027 <a title="106-lda-3" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>4 0.30245414 <a title="106-lda-4" href="./jmlr-2013-Optimally_Fuzzy_Temporal_Memory.html">82 jmlr-2013-Optimally Fuzzy Temporal Memory</a></p>
<p>5 0.29752743 <a title="106-lda-5" href="./jmlr-2013-Consistent_Selection_of_Tuning_Parameters_via_Variable_Selection_Stability.html">27 jmlr-2013-Consistent Selection of Tuning Parameters via Variable Selection Stability</a></p>
<p>6 0.29602116 <a title="106-lda-6" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>7 0.29426074 <a title="106-lda-7" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>8 0.29313737 <a title="106-lda-8" href="./jmlr-2013-Improving_CUR_Matrix_Decomposition_and_the_Nystrom_Approximation_via_Adaptive_Sampling.html">53 jmlr-2013-Improving CUR Matrix Decomposition and the Nystrom Approximation via Adaptive Sampling</a></p>
<p>9 0.29031712 <a title="106-lda-9" href="./jmlr-2013-Cluster_Analysis%3A_Unsupervised_Learning_via_Supervised_Learning_with_a_Non-convex_Penalty.html">23 jmlr-2013-Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty</a></p>
<p>10 0.2835122 <a title="106-lda-10" href="./jmlr-2013-Sparse_Robust_Estimation_and_Kalman_Smoothing_with_Nonsmooth_Log-Concave_Densities%3A_Modeling%2C_Computation%2C_and_Theory.html">103 jmlr-2013-Sparse Robust Estimation and Kalman Smoothing with Nonsmooth Log-Concave Densities: Modeling, Computation, and Theory</a></p>
<p>11 0.28211558 <a title="106-lda-11" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>12 0.27982628 <a title="106-lda-12" href="./jmlr-2013-Similarity-based_Clustering_by_Left-Stochastic_Matrix_Factorization.html">100 jmlr-2013-Similarity-based Clustering by Left-Stochastic Matrix Factorization</a></p>
<p>13 0.27790603 <a title="106-lda-13" href="./jmlr-2013-Dynamic_Affine-Invariant_Shape-Appearance_Handshape_Features_and_Classification_in_Sign_Language_Videos.html">38 jmlr-2013-Dynamic Affine-Invariant Shape-Appearance Handshape Features and Classification in Sign Language Videos</a></p>
<p>14 0.27751935 <a title="106-lda-14" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>15 0.27343324 <a title="106-lda-15" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>16 0.27250504 <a title="106-lda-16" href="./jmlr-2013-Fast_MCMC_Sampling_for_Markov_Jump_Processes_and_Extensions.html">43 jmlr-2013-Fast MCMC Sampling for Markov Jump Processes and Extensions</a></p>
<p>17 0.26841655 <a title="106-lda-17" href="./jmlr-2013-Sub-Local_Constraint-Based_Learning_of_Bayesian_Networks_Using_A_Joint_Dependence_Criterion.html">110 jmlr-2013-Sub-Local Constraint-Based Learning of Bayesian Networks Using A Joint Dependence Criterion</a></p>
<p>18 0.26774865 <a title="106-lda-18" href="./jmlr-2013-CODA%3A_High_Dimensional_Copula_Discriminant_Analysis.html">20 jmlr-2013-CODA: High Dimensional Copula Discriminant Analysis</a></p>
<p>19 0.26757923 <a title="106-lda-19" href="./jmlr-2013-Beyond_Fano%27s_Inequality%3A_Bounds_on_the_Optimal_F-Score%2C_BER%2C_and_Cost-Sensitive_Risk_and_Their_Implications.html">18 jmlr-2013-Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</a></p>
<p>20 0.26420355 <a title="106-lda-20" href="./jmlr-2013-Convex_and_Scalable_Weakly_Labeled_SVMs.html">29 jmlr-2013-Convex and Scalable Weakly Labeled SVMs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
