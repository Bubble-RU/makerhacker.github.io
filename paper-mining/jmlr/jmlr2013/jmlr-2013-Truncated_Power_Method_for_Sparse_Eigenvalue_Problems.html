<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-116" href="#">jmlr2013-116</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</h1>
<br/><p>Source: <a title="jmlr-2013-116-pdf" href="http://jmlr.org/papers/volume14/yuan13a/yuan13a.pdf">pdf</a></p><p>Author: Xiao-Tong Yuan, Tong Zhang</p><p>Abstract: This paper considers the sparse eigenvalue problem, which is to extract dominant (largest) sparse eigenvectors with at most k non-zero components. We propose a simple yet effective solution called truncated power method that can approximately solve the underlying nonconvex optimization problem. A strong sparse recovery result is proved for the truncated power method, and this theory is our key motivation for developing the new algorithm. The proposed method is tested on applications such as sparse principal component analysis and the densest k-subgraph problem. Extensive experiments on several synthetic and real-world data sets demonstrate the competitive empirical performance of our method. Keywords: sparse eigenvalue, power method, sparse principal component analysis, densest k-subgraph</p><p>Reference: <a title="jmlr-2013-116-reference" href="../jmlr2013_reference/jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tpow', 0.713), ('densest', 0.314), ('xt', 0.219), ('gpow', 0.209), ('dks', 0.162), ('pathspc', 0.152), ('cardin', 0.128), ('runt', 0.124), ('aspremont', 0.122), ('pca', 0.119), ('spars', 0.11), ('igenvalu', 0.106), ('uan', 0.106), ('trunt', 0.099), ('eigenvect', 0.09), ('pmd', 0.086), ('roblem', 0.077), ('ospc', 0.076), ('spca', 0.076), ('perturb', 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="116-tfidf-1" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>2 0.10756116 <a title="116-tfidf-2" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>3 0.054062873 <a title="116-tfidf-3" href="./jmlr-2013-Lovasz_theta_function%2C_SVMs_and_Finding_Dense_Subgraphs.html">64 jmlr-2013-Lovasz theta function, SVMs and Finding Dense Subgraphs</a></p>
<p>4 0.052484144 <a title="116-tfidf-4" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>5 0.052269258 <a title="116-tfidf-5" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>6 0.050636865 <a title="116-tfidf-6" href="./jmlr-2013-A_Risk_Comparison_of_Ordinary_Least_Squares_vs_Ridge_Regression.html">7 jmlr-2013-A Risk Comparison of Ordinary Least Squares vs Ridge Regression</a></p>
<p>7 0.050502151 <a title="116-tfidf-7" href="./jmlr-2013-Regularization-Free_Principal_Curve_Estimation.html">96 jmlr-2013-Regularization-Free Principal Curve Estimation</a></p>
<p>8 0.049013603 <a title="116-tfidf-8" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>9 0.043635894 <a title="116-tfidf-9" href="./jmlr-2013-Message-Passing_Algorithms_for_Quadratic_Minimization.html">71 jmlr-2013-Message-Passing Algorithms for Quadratic Minimization</a></p>
<p>10 0.041659985 <a title="116-tfidf-10" href="./jmlr-2013-Greedy_Feature_Selection_for_Subspace_Clustering.html">50 jmlr-2013-Greedy Feature Selection for Subspace Clustering</a></p>
<p>11 0.036325194 <a title="116-tfidf-11" href="./jmlr-2013-A_Near-Optimal_Algorithm_for_Differentially-Private_Principal_Components.html">5 jmlr-2013-A Near-Optimal Algorithm for Differentially-Private Principal Components</a></p>
<p>12 0.03610462 <a title="116-tfidf-12" href="./jmlr-2013-Maximum_Volume_Clustering%3A_A_New_Discriminative_Clustering_Approach.html">70 jmlr-2013-Maximum Volume Clustering: A New Discriminative Clustering Approach</a></p>
<p>13 0.035592232 <a title="116-tfidf-13" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>14 0.032690771 <a title="116-tfidf-14" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>15 0.031352498 <a title="116-tfidf-15" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>16 0.030906338 <a title="116-tfidf-16" href="./jmlr-2013-Distributions_of_Angles_in_Random_Packing_on_Spheres.html">36 jmlr-2013-Distributions of Angles in Random Packing on Spheres</a></p>
<p>17 0.030512072 <a title="116-tfidf-17" href="./jmlr-2013-Bayesian_Nonparametric_Hidden_Semi-Markov_Models.html">16 jmlr-2013-Bayesian Nonparametric Hidden Semi-Markov Models</a></p>
<p>18 0.030051703 <a title="116-tfidf-18" href="./jmlr-2013-Random_Walk_Kernels_and_Learning_Curves_for_Gaussian_Process_Regression_on_Random_Graphs.html">93 jmlr-2013-Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs</a></p>
<p>19 0.030029897 <a title="116-tfidf-19" href="./jmlr-2013-Sparse_Single-Index_Model.html">104 jmlr-2013-Sparse Single-Index Model</a></p>
<p>20 0.029930787 <a title="116-tfidf-20" href="./jmlr-2013-Distribution-Dependent_Sample_Complexity_of_Large_Margin_Learning.html">35 jmlr-2013-Distribution-Dependent Sample Complexity of Large Margin Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.158), (1, 0.018), (2, -0.001), (3, 0.004), (4, -0.09), (5, 0.014), (6, -0.068), (7, -0.06), (8, 0.023), (9, -0.025), (10, 0.017), (11, 0.026), (12, 0.139), (13, -0.001), (14, -0.032), (15, -0.04), (16, -0.05), (17, 0.198), (18, -0.021), (19, -0.11), (20, 0.004), (21, -0.08), (22, -0.07), (23, -0.085), (24, -0.044), (25, 0.06), (26, 0.157), (27, -0.08), (28, -0.102), (29, -0.158), (30, 0.064), (31, -0.17), (32, 0.13), (33, 0.114), (34, -0.105), (35, 0.018), (36, -0.214), (37, -0.175), (38, 0.11), (39, 0.108), (40, -0.082), (41, 0.083), (42, 0.105), (43, 0.091), (44, 0.039), (45, -0.024), (46, 0.081), (47, 0.135), (48, -0.13), (49, 0.13)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88780332 <a title="116-lsi-1" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>2 0.59062541 <a title="116-lsi-2" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>3 0.37064615 <a title="116-lsi-3" href="./jmlr-2013-A_Risk_Comparison_of_Ordinary_Least_Squares_vs_Ridge_Regression.html">7 jmlr-2013-A Risk Comparison of Ordinary Least Squares vs Ridge Regression</a></p>
<p>4 0.33773118 <a title="116-lsi-4" href="./jmlr-2013-Bayesian_Nonparametric_Hidden_Semi-Markov_Models.html">16 jmlr-2013-Bayesian Nonparametric Hidden Semi-Markov Models</a></p>
<p>5 0.29422522 <a title="116-lsi-5" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>6 0.28888491 <a title="116-lsi-6" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>7 0.27116743 <a title="116-lsi-7" href="./jmlr-2013-Regularization-Free_Principal_Curve_Estimation.html">96 jmlr-2013-Regularization-Free Principal Curve Estimation</a></p>
<p>8 0.24203789 <a title="116-lsi-8" href="./jmlr-2013-Lovasz_theta_function%2C_SVMs_and_Finding_Dense_Subgraphs.html">64 jmlr-2013-Lovasz theta function, SVMs and Finding Dense Subgraphs</a></p>
<p>9 0.23707533 <a title="116-lsi-9" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>10 0.22489034 <a title="116-lsi-10" href="./jmlr-2013-Dynamic_Affine-Invariant_Shape-Appearance_Handshape_Features_and_Classification_in_Sign_Language_Videos.html">38 jmlr-2013-Dynamic Affine-Invariant Shape-Appearance Handshape Features and Classification in Sign Language Videos</a></p>
<p>11 0.21928072 <a title="116-lsi-11" href="./jmlr-2013-Message-Passing_Algorithms_for_Quadratic_Minimization.html">71 jmlr-2013-Message-Passing Algorithms for Quadratic Minimization</a></p>
<p>12 0.21497941 <a title="116-lsi-12" href="./jmlr-2013-Greedy_Feature_Selection_for_Subspace_Clustering.html">50 jmlr-2013-Greedy Feature Selection for Subspace Clustering</a></p>
<p>13 0.20606932 <a title="116-lsi-13" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>14 0.1900218 <a title="116-lsi-14" href="./jmlr-2013-Efficient_Program_Synthesis_Using_Constraint_Satisfaction_in_Inductive_Logic_Programming.html">40 jmlr-2013-Efficient Program Synthesis Using Constraint Satisfaction in Inductive Logic Programming</a></p>
<p>15 0.18266615 <a title="116-lsi-15" href="./jmlr-2013-Segregating_Event_Streams_and_Noise_with_a_Markov_Renewal_Process_Model.html">98 jmlr-2013-Segregating Event Streams and Noise with a Markov Renewal Process Model</a></p>
<p>16 0.18241891 <a title="116-lsi-16" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>17 0.17939731 <a title="116-lsi-17" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>18 0.1748051 <a title="116-lsi-18" href="./jmlr-2013-CODA%3A_High_Dimensional_Copula_Discriminant_Analysis.html">20 jmlr-2013-CODA: High Dimensional Copula Discriminant Analysis</a></p>
<p>19 0.17456354 <a title="116-lsi-19" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>20 0.17073272 <a title="116-lsi-20" href="./jmlr-2013-Random_Walk_Kernels_and_Learning_Curves_for_Gaussian_Process_Regression_on_Random_Graphs.html">93 jmlr-2013-Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.354), (8, 0.046), (16, 0.02), (18, 0.018), (21, 0.05), (34, 0.036), (55, 0.031), (58, 0.029), (61, 0.041), (62, 0.055), (81, 0.067), (84, 0.028), (98, 0.099)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.60025662 <a title="116-lda-1" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>2 0.39401358 <a title="116-lda-2" href="./jmlr-2013-Sparse_Activity_and_Sparse_Connectivity_in_Supervised_Learning.html">101 jmlr-2013-Sparse Activity and Sparse Connectivity in Supervised Learning</a></p>
<p>3 0.39395425 <a title="116-lda-3" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>4 0.39365587 <a title="116-lda-4" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>5 0.39205134 <a title="116-lda-5" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>6 0.39182597 <a title="116-lda-6" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>7 0.39066094 <a title="116-lda-7" href="./jmlr-2013-Supervised_Feature_Selection_in_Graphs_with_Path_Coding_Penalties_and_Network_Flows.html">111 jmlr-2013-Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows</a></p>
<p>8 0.38980675 <a title="116-lda-8" href="./jmlr-2013-Semi-Supervised_Learning_Using_Greedy_Max-Cut.html">99 jmlr-2013-Semi-Supervised Learning Using Greedy Max-Cut</a></p>
<p>9 0.38900149 <a title="116-lda-9" href="./jmlr-2013-Sparse_Single-Index_Model.html">104 jmlr-2013-Sparse Single-Index Model</a></p>
<p>10 0.38869932 <a title="116-lda-10" href="./jmlr-2013-PC_Algorithm_for_Nonparanormal_Graphical_Models.html">84 jmlr-2013-PC Algorithm for Nonparanormal Graphical Models</a></p>
<p>11 0.38782996 <a title="116-lda-11" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>12 0.38773417 <a title="116-lda-12" href="./jmlr-2013-On_the_Convergence_of_Maximum_Variance_Unfolding.html">77 jmlr-2013-On the Convergence of Maximum Variance Unfolding</a></p>
<p>13 0.38528118 <a title="116-lda-13" href="./jmlr-2013-Improving_CUR_Matrix_Decomposition_and_the_Nystrom_Approximation_via_Adaptive_Sampling.html">53 jmlr-2013-Improving CUR Matrix Decomposition and the Nystrom Approximation via Adaptive Sampling</a></p>
<p>14 0.38464168 <a title="116-lda-14" href="./jmlr-2013-Construction_of_Approximation_Spaces_for_Reinforcement_Learning.html">28 jmlr-2013-Construction of Approximation Spaces for Reinforcement Learning</a></p>
<p>15 0.38402757 <a title="116-lda-15" href="./jmlr-2013-A_Plug-in_Approach_to_Neyman-Pearson_Classification.html">6 jmlr-2013-A Plug-in Approach to Neyman-Pearson Classification</a></p>
<p>16 0.38291901 <a title="116-lda-16" href="./jmlr-2013-CODA%3A_High_Dimensional_Copula_Discriminant_Analysis.html">20 jmlr-2013-CODA: High Dimensional Copula Discriminant Analysis</a></p>
<p>17 0.38257977 <a title="116-lda-17" href="./jmlr-2013-A_Near-Optimal_Algorithm_for_Differentially-Private_Principal_Components.html">5 jmlr-2013-A Near-Optimal Algorithm for Differentially-Private Principal Components</a></p>
<p>18 0.38234571 <a title="116-lda-18" href="./jmlr-2013-Large-scale_SVD_and_Manifold_Learning.html">59 jmlr-2013-Large-scale SVD and Manifold Learning</a></p>
<p>19 0.38207573 <a title="116-lda-19" href="./jmlr-2013-Similarity-based_Clustering_by_Left-Stochastic_Matrix_Factorization.html">100 jmlr-2013-Similarity-based Clustering by Left-Stochastic Matrix Factorization</a></p>
<p>20 0.38022977 <a title="116-lda-20" href="./jmlr-2013-Distance_Preserving_Embeddings_for_General_n-Dimensional_Manifolds.html">34 jmlr-2013-Distance Preserving Embeddings for General n-Dimensional Manifolds</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
