<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>22 jmlr-2013-Classifying With Confidence From Incomplete Information</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-22" href="#">jmlr2013-22</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>22 jmlr-2013-Classifying With Confidence From Incomplete Information</h1>
<br/><p>Source: <a title="jmlr-2013-22-pdf" href="http://jmlr.org/papers/volume14/parrish13a/parrish13a.pdf">pdf</a></p><p>Author: Nathan Parrish, Hyrum S. Anderson, Maya R. Gupta, Dun Yu Hsiao</p><p>Abstract: We consider the problem of classifying a test sample given incomplete information. This problem arises naturally when data about a test sample is collected over time, or when costs must be incurred to compute the classiﬁcation features. For example, in a distributed sensor network only a fraction of the sensors may have reported measurements at a certain time, and additional time, power, and bandwidth is needed to collect the complete data to classify. A practical goal is to assign a class label as soon as enough data is available to make a good decision. We formalize this goal through the notion of reliability—the probability that a label assigned given incomplete data would be the same as the label assigned given the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. Our approach models the complete data as a random variable whose distribution is dependent on the current incomplete data and the (complete) training data. The method differs from standard imputation strategies in that our focus is on determining the reliability of the classiﬁcation decision, rather than just the class label. We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series data sets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met. Keywords: classiﬁcation, sensor networks, signals, reliability</p><p>Reference: <a title="jmlr-2013-22-reference" href="../jmlr2013_reference/jmlr-2013-Classifying_With_Confidence_From_Incomplete_Information_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 EDU  Department of Electrical Engineering University of Washington Seattle, WA 98195-4322, USA  Editor: Kevin Murphy  Abstract We consider the problem of classifying a test sample given incomplete information. [sent-9, score-0.319]
</p><p>2 We formalize this goal through the notion of reliability—the probability that a label assigned given incomplete data would be the same as the label assigned given the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. [sent-13, score-0.903]
</p><p>3 The method differs from standard imputation strategies in that our focus is on determining the reliability of the classiﬁcation decision, rather than just the class label. [sent-15, score-0.362]
</p><p>4 We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series data sets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met. [sent-16, score-0.766]
</p><p>5 Speciﬁcally, we wish to guarantee that a decision made from incomplete test data has a high probability of being the same decision that would be made given the complete test data. [sent-24, score-0.597]
</p><p>6 In this paper, we focus on answering the question “With probability at least equal to τ, will the classiﬁcation decision from incomplete data be the same as that which would be made from the complete data? [sent-25, score-0.357]
</p><p>7 ” Our approach also makes it possible to answer the related question, “If we classify based on the current incomplete data, what is the probability that the class decision will be the same as classifying from the complete data? [sent-26, score-0.512]
</p><p>8 ” First, we propose optimal and practical decision rules for classifying incomplete data. [sent-27, score-0.367]
</p><p>9 In Sections 3, 4, and 5 we provide the details on how to efﬁciently and accurately implement the proposed practical decision rule for classiﬁers that use linear or quadratic discriminants, such as linear support vector machines and linear or quadratic discriminant analysis (LDA and QDA). [sent-28, score-0.37]
</p><p>10 Experiments in Section 7 show that the proposed incomplete decision rule consistently provides enhanced reliability over the state of the art in classifying incomplete data. [sent-30, score-0.938]
</p><p>11 However, suppose that at ˆ test time we do not have x, but instead have some incomplete information given as a vector z. [sent-37, score-0.351]
</p><p>12 To that end, we consider decision rules that answer the question: “Can we classify z and know that we meet some minimum probability threshold of making the same decision that we would make on x? [sent-39, score-0.344]
</p><p>13 ” We use the term reliability to mean the probability that the class label assigned to z matches that assigned to x. [sent-40, score-0.352]
</p><p>14 To estimate reliability, we model the classiﬁcation features derived from the complete data as a random variable X, where X is jointly distributed with the random variable Z modeling the incomplete data. [sent-41, score-0.334]
</p><p>15 Given a desired reliability τ ∈ [0, 1] and a realization of the incomplete information z, an ideal incomplete decision rule is to classify as class g if P(g(X) = g|Z = z) = ˆ  p(x|z) dx x s. [sent-42, score-1.031]
</p><p>16 An alternative check that we ﬁnd easier to approximate is to consider all sets A in the domain of X such that P(X ∈ A|Z = z) ≥ τ, 3562  C LASSIFYING W ITH C ONFIDENCE  Figure 1: In this example, the available information is the incomplete time signal z, shown in green. [sent-48, score-0.315]
</p><p>17 We propose that a more conservative, but computable, incomplete decision rule is to classify as class g if g(x) = g for all x ∈ A for some set A such that P(X ∈ A|Z = z) ≥ τ. [sent-53, score-0.509]
</p><p>18 Deﬁning a Set A that Contains Measure τ of X To implement the incomplete decision rule (2), one must be able to construct a set A that contains at least τ measure of X given z. [sent-63, score-0.385]
</p><p>19 For desired reliability values τ that are smaller than the probability mass of X that falls to the left of the decision boundary, the ideal incomplete decision rule would choose to classify based on the incomplete information z. [sent-71, score-1.111]
</p><p>20 Right: The entire probability mass of X falls on one side of the decision boundary, and thus the ideal incomplete decision rule would choose to classify rather than wait, for every value of τ. [sent-72, score-0.589]
</p><p>21 However, our computable incomplete decision rule constructs a set A that captures a fraction τ of the mass of X and requires that entire set A to lie on one side of the decision boundary. [sent-73, score-0.497]
</p><p>22 For the choice of A shown here in blue, the set A crosses the decision boundary, and thus the computable decision rule would choose to wait for more information before classifying. [sent-74, score-0.296]
</p><p>23 If we assume more about the distribution, we can deﬁne a smaller constraint set A that results in a less conservative decision rule, and therefore earlier classiﬁcation for the same reliability requirement τ. [sent-82, score-0.48]
</p><p>24 xi :yi =g  An optimal method for checking the incomplete decision rule (2) for this discriminant is an open question. [sent-111, score-0.456]
</p><p>25 A conservative reliability decision can be made by treating each sample as its own class in (6). [sent-112, score-0.485]
</p><p>26 Then the proposed incomplete data decision rule (2) is implemented:  if max f (x) ≤ 0  1  x∈A g(z) = ˆ 2 if min f (x) > 0  x∈A  no decision otherwise. [sent-122, score-0.497]
</p><p>27 (7)  Note that the decision rule (7) is dependent on the incomplete data through the dependence of A on z. [sent-123, score-0.385]
</p><p>28 The three different conditions in (7) are shown for a quadratic discriminant (and hence quadratic decision boundary) and a quadratic construction of the set A in Figure 4. [sent-124, score-0.39]
</p><p>29 In the center and rightmost plots, A lies completely on a single side of the decision boundary, so the classiﬁer assigns a label to the incomplete data. [sent-127, score-0.358]
</p><p>30 Coupled with a quadratic set A, such as the Chebyshev or n¨ ive Bayes quadratic sets A given in a Section 3, ﬁnding the maximum and minimum are the linear programs with quadratic constraints:  max f (x) = max βT x + b x∈A  (8)  x  s. [sent-132, score-0.349]
</p><p>31 First consider ﬁnding the maximum and minimum of (12), as required by the incomplete decision rule (7), over a quadratic constraint set A. [sent-158, score-0.509]
</p><p>32 After this change of variables, we can greatly simplify the maximum and minimum computations required by the incomplete decision rule (7) by making the n¨ ive Bayes assumption on the random variable Y = V 1/2 X as opposed to on X. [sent-171, score-0.527]
</p><p>33 ˆ The proposed incomplete data classiﬁcation rule (2) can be written: g(z) = ˆ  c  if min fc (x) − fh (x) ≥ 0 for all h = c  no decision  otherwise. [sent-184, score-0.461]
</p><p>34 x∈A  (15)  That is, classify z as class c if the set A lies completely within the decision region for some class c, and do not decide at the requested reliability if the set A straddles a decision boundary. [sent-185, score-0.678]
</p><p>35 To classify the incomplete data z early as class c, class c must dominate all other classes. [sent-199, score-0.426]
</p><p>36 If yes, classify the incomplete data as the class labelled candidate, if no, output no decision. [sent-210, score-0.426]
</p><p>37 We do this by leveraging the incomplete information about the test signal that is currently available along with the prior knowledge of the structure of the test signal gained from the training data using the standard assumption that the training and test features are IID. [sent-215, score-0.513]
</p><p>38 However, the minimum support parameter is different from our τ parameter in that it does not provide an explicit guarantee on the reliability of the early decision. [sent-246, score-0.372]
</p><p>39 Given such costs, an optimal stopping rule approach would attempt to estimate the probability of each class given the current incomplete information, and determine the expected costs of making a decision or waiting. [sent-275, score-0.448]
</p><p>40 Generally stopping rules are not applicable to the problem we focus on because they assume that all increasing sets of features can be compared, rather than that one only has the incomplete set of features and must make a decision. [sent-280, score-0.357]
</p><p>41 We also use the Synthetic Control data set from this repository, a data set of Gaussian data that has only three hundred test samples, to further illustrate the differences between the constraint sets and estimation methods that we have described for the proposed incomplete decision rule. [sent-313, score-0.427]
</p><p>42 At i=1 time t, the incomplete data for the ith test time-series is zi ∈ Rt , the ﬁrst t samples of xi . [sent-317, score-0.384]
</p><p>43 At each time t we check the proposed incomplete decision rule and classify zi if the reliability condition is met for τ. [sent-318, score-0.866]
</p><p>44 Let ti (τ) be the minimum time at which the ith test signal can be classiﬁed with reliability constraint τ, and let g(zi (τ)) be the class label assigned to zi at this time. [sent-344, score-0.567]
</p><p>45 We measure the test ˆ ˆ ˆ reliability as 1 ∑n I(g(zi (τ)) = g(xi )), where g(xi ) is the label assigned to the complete data and n i=1 ˆ I(·) is one if the argument is true and zero otherwise. [sent-345, score-0.405]
</p><p>46 Ideally, we would like to classify with the smallest average classiﬁcation time while still meeting reliability requirement τ. [sent-347, score-0.483]
</p><p>47 Local QDA learns the mean and covariance for the class g discriminant function for test point x, fg (x), by estimating them using the k nearest class g training points to test point x. [sent-351, score-0.315]
</p><p>48 2 Comparison of Construction of Sets of Measure τ We ﬁrst compare the three set construction methods proposed Section 3, the Chebyshev set (3), the Gaussian n¨ ive Bayes quadratic set (4), and the Gaussian n¨ ive Bayes box set (5). [sent-357, score-0.357]
</p><p>49 a a We vary the reliability parameter between four values τ = [0. [sent-358, score-0.298]
</p><p>50 In all cases, the empirical reliability rate exceeds the reliability requirement τ. [sent-364, score-0.596]
</p><p>51 Additionally, these plots verify that the Chebyshev set is the most conservative, as it waits the longest to classify the test data, and the n¨ ive Bayes quadratic set is the a least conservative. [sent-365, score-0.339]
</p><p>52 This table shows that the n¨ ive Bayes box set is the least computationally complex, a followed by the n¨ ive Bayes quadratic set, and ﬁnally the Chebyshev set. [sent-368, score-0.357]
</p><p>53 3 Comparison of Estimation Methods In this section we compare the performance of reliable incomplete classiﬁcation using jointly Gaussian estimation (16) to that using GMM estimation (17). [sent-370, score-0.368]
</p><p>54 test reliability for the jointly Gaussian and GMM estimation methods using the n¨ ive Bayes quadratic constraint set. [sent-373, score-0.61]
</p><p>55 9  90 116  Chebyshev Naive Bayes Quadratic Naive Bayes Box 118 120 122 124 Average Classification Time  126  Figure 6: Average classiﬁcation time vs test reliability for local QDA (left column) and linear SVM (right column) using jointly Gaussian prediction. [sent-383, score-0.518]
</p><p>56 9  88 114  Joint Gaussian GMM 116 118 120 122 Average Classification Time  124  Figure 7: Average classiﬁcation time vs test reliability for local QDA (left column) and linear SVM (right column) using the n¨ ive Bayes quadratic constraint set with τ varied between a [0. [sent-395, score-0.69]
</p><p>57 4 Dimensionality Reduction Features An advantage of our reliable incomplete classiﬁcation approach is that it can use any features derived from the data for which we can estimate the mean and covariance. [sent-417, score-0.381]
</p><p>58 Thus, if we simply use the time-series samples as the features for classiﬁcation, the optimization problem that the reliable incomplete classiﬁer must solve has d − t free variables. [sent-426, score-0.381]
</p><p>59 The table also compares the testing time required to perform reliable local QDA classiﬁcation with the n¨ ive Bayes quadratic a constraint set with jointly Gaussian estimation at time t = 1 with and without LDG dimensionality reduction. [sent-433, score-0.538]
</p><p>60 The test time shown measures the average time, per test sample, to perform reliable classiﬁcation at time t = 1. [sent-436, score-0.39]
</p><p>61 5 Comparison to Other Methods In this section, we compare the performance of our reliable incomplete data classiﬁer to ECTS (Xing et al. [sent-439, score-0.33]
</p><p>62 For all experiments in this section, we use the n¨ ive Bayes a quadratic constraint set because it proved to be uniformly better than the box constraint set across all experiments in Section 7. [sent-441, score-0.297]
</p><p>63 However, we emphasize that this parameter is not the same as our reliability parameter τ, in that it provides no guarantee on reliability of the early predictions, but is instead a knob that the user can tune to trade off between earliness and reliability. [sent-448, score-0.642]
</p><p>64 ECTS Fixed−time QDA Fixed−time 1−NN  90 85 80 100  110  120 130 140 150 160 Average classification time  90 Rel. [sent-461, score-0.303]
</p><p>65 ECTS Fixed−time QDA Fixed−time 1−NN  80 70 60 0  170  5 10 15 20 Average classification time  Face (All)  Medical Images 100 Test Reliability  Test Reliability  100 95 Rel. [sent-465, score-0.303]
</p><p>66 ECTS Fixed−time QDA Fixed−time 1−NN  90 85 80 100  110 120 130 Average classification time  95 90  80  Non-invasive Fetal ECG 1  90  LDG Rel. [sent-469, score-0.303]
</p><p>67 ECTS Fixed−time QDA Fixed−time 1−NN  85 640  660 680 700 720 Average classification time  Test Reliability  Test Reliability  75 80 85 90 95 Average classification time  100  100  95 LDG Rel. [sent-471, score-0.606]
</p><p>68 ECTS Fixed−time QDA Fixed−time 1−NN  90  85 600  740  Starlight Curves  650 700 Average classification time  750  Swedish Leaf 100 Test Reliability  100 Test Reliability  70  Non-invasive Fetal ECG 2  95  98 96  LDG Rel. [sent-473, score-0.303]
</p><p>69 ECTS Fixed−time QDA Fixed−time 1−NN  85  75 65  140  100  80 620  25  800  850 900 950 1000 Average classification time  1050  95 90 85 80 75 80  Rel. [sent-479, score-0.303]
</p><p>70 ECTS Fixed−time QDA Fixed−time 1−NN 90 100 110 120 Average classification time  130  Figure 8: Average classiﬁcation time vs test reliability for reliable incomplete local QDA classiﬁcation (Rel. [sent-483, score-1.113]
</p><p>71 ), reliable incomplete local QDA classiﬁcation with LDG features (LDG Rel. [sent-485, score-0.415]
</p><p>72 ECTS Fixed−time QDA Fixed−time 1−NN  80  70 100  105 110 115 120 125 Average classification time  95 90  80 75 200  130  U Wave Gesture Library Y  220 240 260 280 300 Average classification time  Rel. [sent-492, score-0.606]
</p><p>73 ECTS Fixed−time QDA Fixed−time 1−NN  80 70  200 250 300 Average classification time  200  220 240 260 280 300 Average classification time  Wafer 100 Test Reliability  Test Reliability  320  Yoga  100  98 Rel. [sent-500, score-0.606]
</p><p>74 ECTS Fixed−time QDA Fixed−time 1−NN  85  40  98 96  92 90 300  60 80 100 120 140 Average classification time  LDG Rel. [sent-508, score-0.303]
</p><p>75 ECTS Fixed−time QDA Fixed−time 1−NN  94  320  340 360 380 400 Average classification time  420  Figure 9: Average classiﬁcation time vs test reliability for reliable incomplete local QDA classiﬁcation (Rel. [sent-510, score-1.113]
</p><p>76 ), reliable incomplete local QDA classiﬁcation with LDG features (LDG Rel. [sent-512, score-0.415]
</p><p>77 The reliability results are shown in Figures 8 and 9. [sent-517, score-0.298]
</p><p>78 Reliable incomplete local QDA classiﬁcation and reliable incomplete local QDA classiﬁcation with LDG features perform well across all experiments. [sent-518, score-0.673]
</p><p>79 ECTS Fixed−time QDA Fixed−time 1−NN 5 10 15 20 25 Average classification time  80 70 60 0  120 140 160 Average classification time  Face (All)  Medical Images 70  70 65 60 55 50 100  Test Accuracy  Test Accuracy  75  Rel. [sent-529, score-0.606]
</p><p>80 ECTS Fixed−time QDA Fixed−time 1−NN 110 120 130 Average classification time  60  140  Non-invasive Fetal ECG 1  LDG Rel. [sent-533, score-0.303]
</p><p>81 ECTS Fixed−time QDA Fixed−time 1−NN 650 700 750 Average classification time  Test Accuracy  Test Accuracy  80 90 Average classification time  100  90  80  60  70  Non-invasive Fetal ECG 2  90  70  Rel. [sent-535, score-0.606]
</p><p>82 ECTS Fixed−time QDA Fixed−time 1−NN 650 700 Average classification time  750  Swedish Leaf Test Accuracy  Test Accuracy  90 90 80 70 750  LDG Rel. [sent-541, score-0.303]
</p><p>83 ECTS Fixed−time QDA Fixed−time 1−NN  80 70 60  800 850 900 950 1000 1050 Average classification time  80  Rel. [sent-543, score-0.303]
</p><p>84 ECTS Fixed−time QDA Fixed−time 1−NN 90 100 110 120 130 Average classification time  Figure 10: Average classiﬁcation time vs test accuracy for reliable incomplete local QDA classiﬁcation (Rel. [sent-547, score-0.837]
</p><p>85 ), reliable incomplete local QDA classiﬁcation with LDG features (LDG Rel. [sent-549, score-0.415]
</p><p>86 ECTS Fixed−time QDA Fixed−time 1−NN 110 120 130 Average classification time  Test Accuracy  Test Accuracy  100  75 70 65 60 200  U Wave Gesture Library Y  Rel. [sent-556, score-0.303]
</p><p>87 ECTS Fixed−time QDA Fixed−time 1−NN 220 240 260 280 300 320 Average classification time  U Wave Gesture Library Z Test Accuracy  Test Accuracy  70 65 Rel. [sent-560, score-0.303]
</p><p>88 ECTS Fixed−time QDA Fixed−time 1−NN  60 55 50 150  200 250 300 Average classification time  70 65 60 55 50  350  200  Wafer  Yoga 84  90  Test Accuracy  Test Accuracy  100  95  Rel. [sent-564, score-0.303]
</p><p>89 ECTS Fixed−time QDA Fixed−time 1−NN 220 240 260 280 300 320 Average classification time  Rel. [sent-568, score-0.303]
</p><p>90 ECTS Fixed−time QDA Fixed−time 1−NN 50 100 Average classification time  150  82 80 78 300  Rel. [sent-572, score-0.303]
</p><p>91 ECTS Fixed−time QDA Fixed−time 1−NN 350 400 Average classification time  Figure 11: Average classiﬁcation time vs test accuracy for reliable incomplete local QDA classiﬁcation (Rel. [sent-576, score-0.837]
</p><p>92 ), reliable incomplete local QDA classiﬁcation with LDG features (LDG Rel. [sent-578, score-0.415]
</p><p>93 Therefore, if someone wanted to set τ by cross-validation on the training data set, the reliable incomplete classiﬁer offers more ﬂexibility than ECTS. [sent-586, score-0.353]
</p><p>94 Discussion and Some Open Questions We have proposed a practical incomplete decision rule that is a conservative approximation of the optimal rule. [sent-595, score-0.428]
</p><p>95 This paper has focused on answering the question “With probability τ, will the classiﬁcation decision from this incomplete data be the same as from the complete data? [sent-600, score-0.357]
</p><p>96 ” The presented tools can also be used to answer the related question: “If we classify based on the current incomplete data, what is the probability that assigned label will match that which would be chosen using the complete data? [sent-601, score-0.359]
</p><p>97 Another related question that can be answered is, “Can we reliably classify as class g with this incomplete data? [sent-603, score-0.348]
</p><p>98 This question can be answered by applying the incomplete decision rule given in (2) only to the class of interest. [sent-607, score-0.417]
</p><p>99 Proof of Proposition 2: First, note that each pairwise check reduces the number of classes labelled candidate by either two classes if the classes tie, or by one class (the loser) if one class dominates. [sent-619, score-0.306]
</p><p>100 Furthermore, for the incomplete data decision rule (7), it is not necessary to ﬁnd the true minimum over A of f (x), but it is instead sufﬁcient to know only whether or not it is less than or equal to zero. [sent-652, score-0.413]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('qda', 0.547), ('ldg', 0.357), ('reliability', 0.298), ('classification', 0.24), ('incomplete', 0.224), ('fixed', 0.221), ('parrish', 0.152), ('ive', 0.114), ('decision', 0.112), ('gmm', 0.111), ('lassifying', 0.106), ('nderson', 0.106), ('onfidence', 0.106), ('saio', 0.106), ('reliable', 0.106), ('chebyshev', 0.1), ('ects', 0.093), ('classify', 0.092), ('upta', 0.091), ('wave', 0.091), ('nn', 0.09), ('classi', 0.078), ('labelled', 0.078), ('ecg', 0.076), ('fetal', 0.076), ('discriminant', 0.071), ('quadratic', 0.069), ('mt', 0.065), ('test', 0.064), ('time', 0.063), ('gesture', 0.06), ('box', 0.06), ('bayes', 0.059), ('missing', 0.052), ('mg', 0.052), ('features', 0.051), ('rule', 0.049), ('medical', 0.048), ('early', 0.046), ('chlorine', 0.046), ('mpl', 0.046), ('conservative', 0.043), ('fc', 0.041), ('raj', 0.039), ('rg', 0.039), ('jointly', 0.038), ('sandia', 0.038), ('sprt', 0.038), ('starlight', 0.038), ('wafer', 0.038), ('classes', 0.037), ('library', 0.036), ('fh', 0.035), ('local', 0.034), ('ith', 0.033), ('discriminants', 0.033), ('imputation', 0.032), ('mq', 0.032), ('er', 0.032), ('class', 0.032), ('stopping', 0.031), ('classifying', 0.031), ('swedish', 0.03), ('yoga', 0.03), ('average', 0.03), ('naive', 0.03), ('ers', 0.029), ('fg', 0.029), ('sdp', 0.029), ('zk', 0.028), ('minimum', 0.028), ('check', 0.028), ('constraint', 0.027), ('svm', 0.027), ('patterns', 0.026), ('images', 0.026), ('candidate', 0.025), ('dimensionality', 0.024), ('final', 0.024), ('italy', 0.024), ('training', 0.023), ('gaussian', 0.023), ('btsrp', 0.023), ('rodriguez', 0.023), ('trsp', 0.023), ('wait', 0.023), ('synthetic', 0.023), ('tied', 0.022), ('label', 0.022), ('dominated', 0.022), ('accuracy', 0.022), ('cation', 0.022), ('cdf', 0.022), ('vs', 0.021), ('complete', 0.021), ('ms', 0.021), ('demand', 0.021), ('speech', 0.021), ('dominates', 0.02), ('gupta', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="22-tfidf-1" href="./jmlr-2013-Classifying_With_Confidence_From_Incomplete_Information.html">22 jmlr-2013-Classifying With Confidence From Incomplete Information</a></p>
<p>Author: Nathan Parrish, Hyrum S. Anderson, Maya R. Gupta, Dun Yu Hsiao</p><p>Abstract: We consider the problem of classifying a test sample given incomplete information. This problem arises naturally when data about a test sample is collected over time, or when costs must be incurred to compute the classiﬁcation features. For example, in a distributed sensor network only a fraction of the sensors may have reported measurements at a certain time, and additional time, power, and bandwidth is needed to collect the complete data to classify. A practical goal is to assign a class label as soon as enough data is available to make a good decision. We formalize this goal through the notion of reliability—the probability that a label assigned given incomplete data would be the same as the label assigned given the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. Our approach models the complete data as a random variable whose distribution is dependent on the current incomplete data and the (complete) training data. The method differs from standard imputation strategies in that our focus is on determining the reliability of the classiﬁcation decision, rather than just the class label. We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series data sets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met. Keywords: classiﬁcation, sensor networks, signals, reliability</p><p>2 0.048588317 <a title="22-tfidf-2" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>Author: Chong Zhang, Yufeng Liu</p><p>Abstract: Hard and soft classiﬁers are two important groups of techniques for classiﬁcation problems. Logistic regression and Support Vector Machines are typical examples of soft and hard classiﬁers respectively. The essential difference between these two groups is whether one needs to estimate the class conditional probability for the classiﬁcation task or not. In particular, soft classiﬁers predict the label based on the obtained class conditional probabilities, while hard classiﬁers bypass the estimation of probabilities and focus on the decision boundary. In practice, for the goal of accurate classiﬁcation, it is unclear which one to use in a given situation. To tackle this problem, the Largemargin Uniﬁed Machine (LUM) was recently proposed as a uniﬁed family to embrace both groups. The LUM family enables one to study the behavior change from soft to hard binary classiﬁers. For multicategory cases, however, the concept of soft and hard classiﬁcation becomes less clear. In that case, class probability estimation becomes more involved as it requires estimation of a probability vector. In this paper, we propose a new Multicategory LUM (MLUM) framework to investigate the behavior of soft versus hard classiﬁcation under multicategory settings. Our theoretical and numerical results help to shed some light on the nature of multicategory classiﬁcation and its transition behavior from soft to hard classiﬁers. The numerical results suggest that the proposed tuned MLUM yields very competitive performance. Keywords: hard classiﬁcation, large-margin, soft classiﬁcation, support vector machine</p><p>3 0.041307107 <a title="22-tfidf-3" href="./jmlr-2013-CODA%3A_High_Dimensional_Copula_Discriminant_Analysis.html">20 jmlr-2013-CODA: High Dimensional Copula Discriminant Analysis</a></p>
<p>Author: Fang Han, Tuo Zhao, Han Liu</p><p>Abstract: We propose a high dimensional classiﬁcation method, named the Copula Discriminant Analysis (CODA). The CODA generalizes the normal-based linear discriminant analysis to the larger Gaussian Copula models (or the nonparanormal) as proposed by Liu et al. (2009). To simultaneously achieve estimation efﬁciency and robustness, the nonparametric rank-based methods including the Spearman’s rho and Kendall’s tau are exploited in estimating the covariance matrix. In high dimensional settings, we prove that the sparsity pattern of the discriminant features can be consistently recovered with the parametric rate, and the expected misclassiﬁcation error is consistent to the Bayes risk. Our theory is backed up by careful numerical experiments, which show that the extra ﬂexibility gained by the CODA method incurs little efﬁciency loss even when the data are truly Gaussian. These results suggest that the CODA method can be an alternative choice besides the normal-based high dimensional linear discriminant analysis. Keywords: high dimensional statistics, sparse nonlinear discriminant analysis, Gaussian copula, nonparanormal distribution, rank-based statistics</p><p>4 0.037767574 <a title="22-tfidf-4" href="./jmlr-2013-One-shot_Learning_Gesture_Recognition_from_RGB-D_Data_Using_Bag_of_Features.html">80 jmlr-2013-One-shot Learning Gesture Recognition from RGB-D Data Using Bag of Features</a></p>
<p>Author: Jun Wan, Qiuqi Ruan, Wei Li, Shuang Deng</p><p>Abstract: For one-shot learning gesture recognition, two important challenges are: how to extract distinctive features and how to learn a discriminative model from only one training sample per gesture class. For feature extraction, a new spatio-temporal feature representation called 3D enhanced motion scale-invariant feature transform (3D EMoSIFT) is proposed, which fuses RGB-D data. Compared with other features, the new feature set is invariant to scale and rotation, and has more compact and richer visual representations. For learning a discriminative model, all features extracted from training samples are clustered with the k-means algorithm to learn a visual codebook. Then, unlike the traditional bag of feature (BoF) models using vector quantization (VQ) to map each feature into a certain visual codeword, a sparse coding method named simulation orthogonal matching pursuit (SOMP) is applied and thus each feature can be represented by some linear combination of a small number of codewords. Compared with VQ, SOMP leads to a much lower reconstruction error and achieves better performance. The proposed approach has been evaluated on ChaLearn gesture database and the result has been ranked amongst the top best performing techniques on ChaLearn gesture challenge (round 2). Keywords: gesture recognition, bag of features (BoF) model, one-shot learning, 3D enhanced motion scale invariant feature transform (3D EMoSIFT), Simulation Orthogonal Matching Pursuit (SOMP)</p><p>5 0.035995461 <a title="22-tfidf-5" href="./jmlr-2013-Keep_It_Simple_And_Sparse%3A_Real-Time_Action_Recognition.html">56 jmlr-2013-Keep It Simple And Sparse: Real-Time Action Recognition</a></p>
<p>Author: Sean Ryan Fanello, Ilaria Gori, Giorgio Metta, Francesca Odone</p><p>Abstract: Sparsity has been showed to be one of the most important properties for visual recognition purposes. In this paper we show that sparse representation plays a fundamental role in achieving one-shot learning and real-time recognition of actions. We start off from RGBD images, combine motion and appearance cues and extract state-of-the-art features in a computationally efﬁcient way. The proposed method relies on descriptors based on 3D Histograms of Scene Flow (3DHOFs) and Global Histograms of Oriented Gradient (GHOGs); adaptive sparse coding is applied to capture high-level patterns from data. We then propose a simultaneous on-line video segmentation and recognition of actions using linear SVMs. The main contribution of the paper is an effective realtime system for one-shot action modeling and recognition; the paper highlights the effectiveness of sparse coding techniques to represent 3D actions. We obtain very good results on three different data sets: a benchmark data set for one-shot action learning (the ChaLearn Gesture Data Set), an in-house data set acquired by a Kinect sensor including complex actions and gestures differing by small details, and a data set created for human-robot interaction purposes. Finally we demonstrate that our system is effective also in a human-robot interaction setting and propose a memory game, “All Gestures You Can”, to be played against a humanoid robot. Keywords: real-time action recognition, sparse representation, one-shot action learning, human robot interaction</p><p>6 0.03549229 <a title="22-tfidf-6" href="./jmlr-2013-Training_Energy-Based_Models_for_Time-Series_Imputation.html">115 jmlr-2013-Training Energy-Based Models for Time-Series Imputation</a></p>
<p>7 0.031814087 <a title="22-tfidf-7" href="./jmlr-2013-MAGIC_Summoning%3A__Towards_Automatic_Suggesting_and_Testing_of_Gestures_With_Low_Probability_of_False_Positives_During_Use.html">66 jmlr-2013-MAGIC Summoning:  Towards Automatic Suggesting and Testing of Gestures With Low Probability of False Positives During Use</a></p>
<p>8 0.030185305 <a title="22-tfidf-8" href="./jmlr-2013-A_Theory_of_Multiclass_Boosting.html">8 jmlr-2013-A Theory of Multiclass Boosting</a></p>
<p>9 0.030119641 <a title="22-tfidf-9" href="./jmlr-2013-Conjugate_Relation_between_Loss_Functions_and_Uncertainty_Sets_in_Classification_Problems.html">26 jmlr-2013-Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems</a></p>
<p>10 0.029869296 <a title="22-tfidf-10" href="./jmlr-2013-Language-Motivated_Approaches_to_Action_Recognition.html">58 jmlr-2013-Language-Motivated Approaches to Action Recognition</a></p>
<p>11 0.029533932 <a title="22-tfidf-11" href="./jmlr-2013-Machine_Learning_with_Operational_Costs.html">68 jmlr-2013-Machine Learning with Operational Costs</a></p>
<p>12 0.028112732 <a title="22-tfidf-12" href="./jmlr-2013-Cluster_Analysis%3A_Unsupervised_Learning_via_Supervised_Learning_with_a_Non-convex_Penalty.html">23 jmlr-2013-Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty</a></p>
<p>13 0.028094444 <a title="22-tfidf-13" href="./jmlr-2013-Convex_and_Scalable_Weakly_Labeled_SVMs.html">29 jmlr-2013-Convex and Scalable Weakly Labeled SVMs</a></p>
<p>14 0.027773913 <a title="22-tfidf-14" href="./jmlr-2013-A_Plug-in_Approach_to_Neyman-Pearson_Classification.html">6 jmlr-2013-A Plug-in Approach to Neyman-Pearson Classification</a></p>
<p>15 0.026777972 <a title="22-tfidf-15" href="./jmlr-2013-Gaussian_Kullback-Leibler_Approximate_Inference.html">47 jmlr-2013-Gaussian Kullback-Leibler Approximate Inference</a></p>
<p>16 0.026333779 <a title="22-tfidf-16" href="./jmlr-2013-JKernelMachines%3A_A_Simple_Framework_for_Kernel_Machines.html">54 jmlr-2013-JKernelMachines: A Simple Framework for Kernel Machines</a></p>
<p>17 0.025855616 <a title="22-tfidf-17" href="./jmlr-2013-BudgetedSVM%3A_A_Toolbox_for_Scalable_SVM_Approximations.html">19 jmlr-2013-BudgetedSVM: A Toolbox for Scalable SVM Approximations</a></p>
<p>18 0.025842357 <a title="22-tfidf-18" href="./jmlr-2013-Dynamic_Affine-Invariant_Shape-Appearance_Handshape_Features_and_Classification_in_Sign_Language_Videos.html">38 jmlr-2013-Dynamic Affine-Invariant Shape-Appearance Handshape Features and Classification in Sign Language Videos</a></p>
<p>19 0.023534654 <a title="22-tfidf-19" href="./jmlr-2013-Alleviating_Naive_Bayes_Attribute_Independence_Assumption_by_Attribute_Weighting.html">12 jmlr-2013-Alleviating Naive Bayes Attribute Independence Assumption by Attribute Weighting</a></p>
<p>20 0.02337745 <a title="22-tfidf-20" href="./jmlr-2013-How_to_Solve_Classification_and_Regression_Problems_on_High-Dimensional_Data_with_a_Supervised_Extension_of_Slow_Feature_Analysis.html">52 jmlr-2013-How to Solve Classification and Regression Problems on High-Dimensional Data with a Supervised Extension of Slow Feature Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.125), (1, 0.009), (2, -0.079), (3, 0.007), (4, 0.031), (5, -0.018), (6, 0.009), (7, 0.0), (8, -0.026), (9, -0.077), (10, 0.037), (11, -0.061), (12, 0.048), (13, -0.1), (14, -0.054), (15, -0.032), (16, 0.013), (17, 0.021), (18, -0.139), (19, 0.003), (20, -0.037), (21, 0.012), (22, -0.008), (23, -0.068), (24, 0.059), (25, -0.05), (26, -0.054), (27, 0.076), (28, -0.198), (29, -0.0), (30, 0.185), (31, -0.066), (32, -0.316), (33, 0.038), (34, 0.022), (35, 0.108), (36, 0.093), (37, -0.132), (38, 0.092), (39, 0.013), (40, -0.029), (41, 0.059), (42, -0.153), (43, -0.001), (44, -0.022), (45, 0.14), (46, -0.015), (47, 0.269), (48, 0.051), (49, 0.259)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94174147 <a title="22-lsi-1" href="./jmlr-2013-Classifying_With_Confidence_From_Incomplete_Information.html">22 jmlr-2013-Classifying With Confidence From Incomplete Information</a></p>
<p>Author: Nathan Parrish, Hyrum S. Anderson, Maya R. Gupta, Dun Yu Hsiao</p><p>Abstract: We consider the problem of classifying a test sample given incomplete information. This problem arises naturally when data about a test sample is collected over time, or when costs must be incurred to compute the classiﬁcation features. For example, in a distributed sensor network only a fraction of the sensors may have reported measurements at a certain time, and additional time, power, and bandwidth is needed to collect the complete data to classify. A practical goal is to assign a class label as soon as enough data is available to make a good decision. We formalize this goal through the notion of reliability—the probability that a label assigned given incomplete data would be the same as the label assigned given the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. Our approach models the complete data as a random variable whose distribution is dependent on the current incomplete data and the (complete) training data. The method differs from standard imputation strategies in that our focus is on determining the reliability of the classiﬁcation decision, rather than just the class label. We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series data sets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met. Keywords: classiﬁcation, sensor networks, signals, reliability</p><p>2 0.6943332 <a title="22-lsi-2" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>Author: Chong Zhang, Yufeng Liu</p><p>Abstract: Hard and soft classiﬁers are two important groups of techniques for classiﬁcation problems. Logistic regression and Support Vector Machines are typical examples of soft and hard classiﬁers respectively. The essential difference between these two groups is whether one needs to estimate the class conditional probability for the classiﬁcation task or not. In particular, soft classiﬁers predict the label based on the obtained class conditional probabilities, while hard classiﬁers bypass the estimation of probabilities and focus on the decision boundary. In practice, for the goal of accurate classiﬁcation, it is unclear which one to use in a given situation. To tackle this problem, the Largemargin Uniﬁed Machine (LUM) was recently proposed as a uniﬁed family to embrace both groups. The LUM family enables one to study the behavior change from soft to hard binary classiﬁers. For multicategory cases, however, the concept of soft and hard classiﬁcation becomes less clear. In that case, class probability estimation becomes more involved as it requires estimation of a probability vector. In this paper, we propose a new Multicategory LUM (MLUM) framework to investigate the behavior of soft versus hard classiﬁcation under multicategory settings. Our theoretical and numerical results help to shed some light on the nature of multicategory classiﬁcation and its transition behavior from soft to hard classiﬁers. The numerical results suggest that the proposed tuned MLUM yields very competitive performance. Keywords: hard classiﬁcation, large-margin, soft classiﬁcation, support vector machine</p><p>3 0.31933403 <a title="22-lsi-3" href="./jmlr-2013-Learning_Theory_Analysis_for_Association_Rules_and_Sequential_Event_Prediction.html">61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</a></p>
<p>Author: Cynthia Rudin, Benjamin Letham, David Madigan</p><p>Abstract: We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called “sequential event prediction.” In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer’s online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the “cold start” problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classiﬁcation, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an “adjusted conﬁdence” measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. Keywords: statistical learning theory, algorithmic stability, association rules, sequence prediction, associative classiﬁcation c 2013 Cynthia Rudin, Benjamin Letham and David Madigan. RUDIN , L E</p><p>4 0.31105092 <a title="22-lsi-4" href="./jmlr-2013-Training_Energy-Based_Models_for_Time-Series_Imputation.html">115 jmlr-2013-Training Energy-Based Models for Time-Series Imputation</a></p>
<p>Author: Philémon Brakel, Dirk Stroobandt, Benjamin Schrauwen</p><p>Abstract: Imputing missing values in high dimensional time-series is a difﬁcult problem. This paper presents a strategy for training energy-based graphical models for imputation directly, bypassing difﬁculties probabilistic approaches would face. The training strategy is inspired by recent work on optimization-based learning (Domke, 2012) and allows complex neural models with convolutional and recurrent structures to be trained for imputation tasks. In this work, we use this training strategy to derive learning rules for three substantially different neural architectures. Inference in these models is done by either truncated gradient descent or variational mean-ﬁeld iterations. In our experiments, we found that the training methods outperform the Contrastive Divergence learning algorithm. Moreover, the training methods can easily handle missing values in the training data itself during learning. We demonstrate the performance of this learning scheme and the three models we introduce on one artiﬁcial and two real-world data sets. Keywords: neural networks, energy-based models, time-series, missing values, optimization</p><p>5 0.28661287 <a title="22-lsi-5" href="./jmlr-2013-CODA%3A_High_Dimensional_Copula_Discriminant_Analysis.html">20 jmlr-2013-CODA: High Dimensional Copula Discriminant Analysis</a></p>
<p>Author: Fang Han, Tuo Zhao, Han Liu</p><p>Abstract: We propose a high dimensional classiﬁcation method, named the Copula Discriminant Analysis (CODA). The CODA generalizes the normal-based linear discriminant analysis to the larger Gaussian Copula models (or the nonparanormal) as proposed by Liu et al. (2009). To simultaneously achieve estimation efﬁciency and robustness, the nonparametric rank-based methods including the Spearman’s rho and Kendall’s tau are exploited in estimating the covariance matrix. In high dimensional settings, we prove that the sparsity pattern of the discriminant features can be consistently recovered with the parametric rate, and the expected misclassiﬁcation error is consistent to the Bayes risk. Our theory is backed up by careful numerical experiments, which show that the extra ﬂexibility gained by the CODA method incurs little efﬁciency loss even when the data are truly Gaussian. These results suggest that the CODA method can be an alternative choice besides the normal-based high dimensional linear discriminant analysis. Keywords: high dimensional statistics, sparse nonlinear discriminant analysis, Gaussian copula, nonparanormal distribution, rank-based statistics</p><p>6 0.24582069 <a title="22-lsi-6" href="./jmlr-2013-Algorithms_for_Discovery_of_Multiple_Markov_Boundaries.html">11 jmlr-2013-Algorithms for Discovery of Multiple Markov Boundaries</a></p>
<p>7 0.23692906 <a title="22-lsi-7" href="./jmlr-2013-BudgetedSVM%3A_A_Toolbox_for_Scalable_SVM_Approximations.html">19 jmlr-2013-BudgetedSVM: A Toolbox for Scalable SVM Approximations</a></p>
<p>8 0.22773559 <a title="22-lsi-8" href="./jmlr-2013-Dynamic_Affine-Invariant_Shape-Appearance_Handshape_Features_and_Classification_in_Sign_Language_Videos.html">38 jmlr-2013-Dynamic Affine-Invariant Shape-Appearance Handshape Features and Classification in Sign Language Videos</a></p>
<p>9 0.22155213 <a title="22-lsi-9" href="./jmlr-2013-Alleviating_Naive_Bayes_Attribute_Independence_Assumption_by_Attribute_Weighting.html">12 jmlr-2013-Alleviating Naive Bayes Attribute Independence Assumption by Attribute Weighting</a></p>
<p>10 0.21819049 <a title="22-lsi-10" href="./jmlr-2013-Kernel_Bayes%27_Rule%3A_Bayesian_Inference_with_Positive_Definite_Kernels.html">57 jmlr-2013-Kernel Bayes' Rule: Bayesian Inference with Positive Definite Kernels</a></p>
<p>11 0.21162769 <a title="22-lsi-11" href="./jmlr-2013-Efficient_Program_Synthesis_Using_Constraint_Satisfaction_in_Inductive_Logic_Programming.html">40 jmlr-2013-Efficient Program Synthesis Using Constraint Satisfaction in Inductive Logic Programming</a></p>
<p>12 0.199826 <a title="22-lsi-12" href="./jmlr-2013-Cluster_Analysis%3A_Unsupervised_Learning_via_Supervised_Learning_with_a_Non-convex_Penalty.html">23 jmlr-2013-Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty</a></p>
<p>13 0.19849712 <a title="22-lsi-13" href="./jmlr-2013-A_Plug-in_Approach_to_Neyman-Pearson_Classification.html">6 jmlr-2013-A Plug-in Approach to Neyman-Pearson Classification</a></p>
<p>14 0.19638008 <a title="22-lsi-14" href="./jmlr-2013-Optimal_Discovery_with_Probabilistic_Expert_Advice%3A_Finite_Time_Analysis_and_Macroscopic_Optimality.html">81 jmlr-2013-Optimal Discovery with Probabilistic Expert Advice: Finite Time Analysis and Macroscopic Optimality</a></p>
<p>15 0.18680401 <a title="22-lsi-15" href="./jmlr-2013-Beyond_Fano%27s_Inequality%3A_Bounds_on_the_Optimal_F-Score%2C_BER%2C_and_Cost-Sensitive_Risk_and_Their_Implications.html">18 jmlr-2013-Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</a></p>
<p>16 0.17543001 <a title="22-lsi-16" href="./jmlr-2013-MAGIC_Summoning%3A__Towards_Automatic_Suggesting_and_Testing_of_Gestures_With_Low_Probability_of_False_Positives_During_Use.html">66 jmlr-2013-MAGIC Summoning:  Towards Automatic Suggesting and Testing of Gestures With Low Probability of False Positives During Use</a></p>
<p>17 0.17498183 <a title="22-lsi-17" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>18 0.17462738 <a title="22-lsi-18" href="./jmlr-2013-One-shot_Learning_Gesture_Recognition_from_RGB-D_Data_Using_Bag_of_Features.html">80 jmlr-2013-One-shot Learning Gesture Recognition from RGB-D Data Using Bag of Features</a></p>
<p>19 0.17403845 <a title="22-lsi-19" href="./jmlr-2013-Stress_Functions_for_Nonlinear_Dimension_Reduction%2C_Proximity_Analysis%2C_and_Graph_Drawing.html">109 jmlr-2013-Stress Functions for Nonlinear Dimension Reduction, Proximity Analysis, and Graph Drawing</a></p>
<p>20 0.17078349 <a title="22-lsi-20" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.035), (5, 0.103), (6, 0.053), (9, 0.012), (10, 0.062), (20, 0.025), (22, 0.393), (23, 0.03), (53, 0.016), (68, 0.022), (70, 0.015), (71, 0.021), (75, 0.055), (85, 0.022), (87, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.68503106 <a title="22-lda-1" href="./jmlr-2013-Classifying_With_Confidence_From_Incomplete_Information.html">22 jmlr-2013-Classifying With Confidence From Incomplete Information</a></p>
<p>Author: Nathan Parrish, Hyrum S. Anderson, Maya R. Gupta, Dun Yu Hsiao</p><p>Abstract: We consider the problem of classifying a test sample given incomplete information. This problem arises naturally when data about a test sample is collected over time, or when costs must be incurred to compute the classiﬁcation features. For example, in a distributed sensor network only a fraction of the sensors may have reported measurements at a certain time, and additional time, power, and bandwidth is needed to collect the complete data to classify. A practical goal is to assign a class label as soon as enough data is available to make a good decision. We formalize this goal through the notion of reliability—the probability that a label assigned given incomplete data would be the same as the label assigned given the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. Our approach models the complete data as a random variable whose distribution is dependent on the current incomplete data and the (complete) training data. The method differs from standard imputation strategies in that our focus is on determining the reliability of the classiﬁcation decision, rather than just the class label. We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series data sets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met. Keywords: classiﬁcation, sensor networks, signals, reliability</p><p>2 0.57663262 <a title="22-lda-2" href="./jmlr-2013-Nested_Expectation_Propagation_for_Gaussian_Process_Classification_with_a_Multinomial_Probit_Likelihood.html">75 jmlr-2013-Nested Expectation Propagation for Gaussian Process Classification with a Multinomial Probit Likelihood</a></p>
<p>Author: Jaakko Riihimäki, Pasi Jylänki, Aki Vehtari</p><p>Abstract: This paper considers probabilistic multinomial probit classiﬁcation using Gaussian process (GP) priors. Challenges with multiclass GP classiﬁcation are the integration over the non-Gaussian posterior distribution, and the increase of the number of unknown latent variables as the number of target classes grows. Expectation propagation (EP) has proven to be a very accurate method for approximate inference but the existing EP approaches for the multinomial probit GP classiﬁcation rely on numerical quadratures, or independence assumptions between the latent values associated with different classes, to facilitate the computations. In this paper we propose a novel nested EP approach which does not require numerical quadratures, and approximates accurately all betweenclass posterior dependencies of the latent values, but still scales linearly in the number of classes. The predictive accuracy of the nested EP approach is compared to Laplace, variational Bayes, and Markov chain Monte Carlo (MCMC) approximations with various benchmark data sets. In the experiments nested EP was the most consistent method compared to MCMC sampling, but in terms of classiﬁcation accuracy the differences between all the methods were small from a practical point of view. Keywords: Gaussian process, multiclass classiﬁcation, multinomial probit, approximate inference, expectation propagation</p><p>3 0.34416047 <a title="22-lda-3" href="./jmlr-2013-How_to_Solve_Classification_and_Regression_Problems_on_High-Dimensional_Data_with_a_Supervised_Extension_of_Slow_Feature_Analysis.html">52 jmlr-2013-How to Solve Classification and Regression Problems on High-Dimensional Data with a Supervised Extension of Slow Feature Analysis</a></p>
<p>Author: Alberto N. Escalante-B., Laurenz Wiskott</p><p>Abstract: Supervised learning from high-dimensional data, for example, multimedia data, is a challenging task. We propose an extension of slow feature analysis (SFA) for supervised dimensionality reduction called graph-based SFA (GSFA). The algorithm extracts a label-predictive low-dimensional set of features that can be post-processed by typical supervised algorithms to generate the ﬁnal label or class estimation. GSFA is trained with a so-called training graph, in which the vertices are the samples and the edges represent similarities of the corresponding labels. A new weighted SFA optimization problem is introduced, generalizing the notion of slowness from sequences of samples to such training graphs. We show that GSFA computes an optimal solution to this problem in the considered function space and propose several types of training graphs. For classiﬁcation, the most straightforward graph yields features equivalent to those of (nonlinear) Fisher discriminant analysis. Emphasis is on regression, where four different graphs were evaluated experimentally with a subproblem of face detection on photographs. The method proposed is promising particularly when linear models are insufﬁcient as well as when feature selection is difﬁcult. Keywords: slow feature analysis, feature extraction, classiﬁcation, regression, pattern recognition, training graphs, nonlinear dimensionality reduction, supervised learning, implicitly supervised, high-dimensional data, image analysis</p><p>4 0.3441292 <a title="22-lda-4" href="./jmlr-2013-Variational_Algorithms_for_Marginal_MAP.html">120 jmlr-2013-Variational Algorithms for Marginal MAP</a></p>
<p>Author: Qiang Liu, Alexander Ihler</p><p>Abstract: The marginal maximum a posteriori probability (MAP) estimation problem, which calculates the mode of the marginal posterior distribution of a subset of variables with the remaining variables marginalized, is an important inference problem in many models, such as those with hidden variables or uncertain parameters. Unfortunately, marginal MAP can be NP-hard even on trees, and has attracted less attention in the literature compared to the joint MAP (maximization) and marginalization problems. We derive a general dual representation for marginal MAP that naturally integrates the marginalization and maximization operations into a joint variational optimization problem, making it possible to easily extend most or all variational-based algorithms to marginal MAP. In particular, we derive a set of “mixed-product” message passing algorithms for marginal MAP, whose form is a hybrid of max-product, sum-product and a novel “argmax-product” message updates. We also derive a class of convergent algorithms based on proximal point methods, including one that transforms the marginal MAP problem into a sequence of standard marginalization problems. Theoretically, we provide guarantees under which our algorithms give globally or locally optimal solutions, and provide novel upper bounds on the optimal objectives. Empirically, we demonstrate that our algorithms signiﬁcantly outperform the existing approaches, including a state-of-the-art algorithm based on local search methods. Keywords: graphical models, message passing, belief propagation, variational methods, maximum a posteriori, marginal-MAP, hidden variable models</p><p>5 0.3428233 <a title="22-lda-5" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>Author: Yuchen Zhang, John C. Duchi, Martin J. Wainwright</p><p>Abstract: We analyze two communication-efﬁcient algorithms for distributed optimization in statistical settings involving large-scale data sets. The ﬁrst algorithm is a standard averaging method that distributes the N data samples evenly to m machines, performs separate minimization on each subset, and then averages the estimates. We provide a sharp analysis of this average mixture algorithm, showing that under a reasonable set of conditions, the combined parameter achieves √ mean-squared error (MSE) that decays as O (N −1 + (N/m)−2 ). Whenever m ≤ N, this guarantee matches the best possible rate achievable by a centralized algorithm having access to all N samples. The second algorithm is a novel method, based on an appropriate form of bootstrap subsampling. Requiring only a single round of communication, it has mean-squared error that decays as O (N −1 + (N/m)−3 ), and so is more robust to the amount of parallelization. In addition, we show that a stochastic gradient-based method attains mean-squared error decaying as O (N −1 + (N/m)−3/2 ), easing computation at the expense of a potentially slower MSE rate. We also provide an experimental evaluation of our methods, investigating their performance both on simulated data and on a large-scale regression problem from the internet search domain. In particular, we show that our methods can be used to efﬁciently solve an advertisement prediction problem from the Chinese SoSo Search Engine, which involves logistic regression with N ≈ 2.4 × 108 samples and d ≈ 740,000 covariates. Keywords: distributed learning, stochastic optimization, averaging, subsampling</p><p>6 0.34276524 <a title="22-lda-6" href="./jmlr-2013-Sub-Local_Constraint-Based_Learning_of_Bayesian_Networks_Using_A_Joint_Dependence_Criterion.html">110 jmlr-2013-Sub-Local Constraint-Based Learning of Bayesian Networks Using A Joint Dependence Criterion</a></p>
<p>7 0.34212101 <a title="22-lda-7" href="./jmlr-2013-Generalized_Spike-and-Slab_Priors_for_Bayesian_Group_Feature_Selection_Using_Expectation_Propagation.html">48 jmlr-2013-Generalized Spike-and-Slab Priors for Bayesian Group Feature Selection Using Expectation Propagation</a></p>
<p>8 0.34201998 <a title="22-lda-8" href="./jmlr-2013-Construction_of_Approximation_Spaces_for_Reinforcement_Learning.html">28 jmlr-2013-Construction of Approximation Spaces for Reinforcement Learning</a></p>
<p>9 0.33954954 <a title="22-lda-9" href="./jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems.html">2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</a></p>
<p>10 0.33939001 <a title="22-lda-10" href="./jmlr-2013-Similarity-based_Clustering_by_Left-Stochastic_Matrix_Factorization.html">100 jmlr-2013-Similarity-based Clustering by Left-Stochastic Matrix Factorization</a></p>
<p>11 0.33873832 <a title="22-lda-11" href="./jmlr-2013-Gaussian_Kullback-Leibler_Approximate_Inference.html">47 jmlr-2013-Gaussian Kullback-Leibler Approximate Inference</a></p>
<p>12 0.33861145 <a title="22-lda-12" href="./jmlr-2013-A_Framework_for_Evaluating_Approximation_Methods_for_Gaussian_Process_Regression.html">3 jmlr-2013-A Framework for Evaluating Approximation Methods for Gaussian Process Regression</a></p>
<p>13 0.3376551 <a title="22-lda-13" href="./jmlr-2013-Belief_Propagation_for_Continuous_State_Spaces%3A_Stochastic_Message-Passing_with_Quantitative_Guarantees.html">17 jmlr-2013-Belief Propagation for Continuous State Spaces: Stochastic Message-Passing with Quantitative Guarantees</a></p>
<p>14 0.33718556 <a title="22-lda-14" href="./jmlr-2013-Semi-Supervised_Learning_Using_Greedy_Max-Cut.html">99 jmlr-2013-Semi-Supervised Learning Using Greedy Max-Cut</a></p>
<p>15 0.33559334 <a title="22-lda-15" href="./jmlr-2013-A_Near-Optimal_Algorithm_for_Differentially-Private_Principal_Components.html">5 jmlr-2013-A Near-Optimal Algorithm for Differentially-Private Principal Components</a></p>
<p>16 0.33555323 <a title="22-lda-16" href="./jmlr-2013-Large-scale_SVD_and_Manifold_Learning.html">59 jmlr-2013-Large-scale SVD and Manifold Learning</a></p>
<p>17 0.33487442 <a title="22-lda-17" href="./jmlr-2013-Random_Walk_Kernels_and_Learning_Curves_for_Gaussian_Process_Regression_on_Random_Graphs.html">93 jmlr-2013-Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs</a></p>
<p>18 0.33478409 <a title="22-lda-18" href="./jmlr-2013-Parallel_Vector_Field_Embedding.html">86 jmlr-2013-Parallel Vector Field Embedding</a></p>
<p>19 0.33440313 <a title="22-lda-19" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>20 0.33407289 <a title="22-lda-20" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
