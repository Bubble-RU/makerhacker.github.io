<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-61" href="#">jmlr2013-61</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</h1>
<br/><p>Source: <a title="jmlr-2013-61-pdf" href="http://jmlr.org/papers/volume14/rudin13a/rudin13a.pdf">pdf</a></p><p>Author: Cynthia Rudin, Benjamin Letham, David Madigan</p><p>Abstract: We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called “sequential event prediction.” In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer’s online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the “cold start” problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classiﬁcation, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an “adjusted conﬁdence” measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. Keywords: statistical learning theory, algorithmic stability, association rules, sequence prediction, associative classiﬁcation c 2013 Cynthia Rudin, Benjamin Letham and David Madigan. RUDIN , L E</p><p>Reference: <a title="jmlr-2013-61-reference" href="../jmlr2013_reference/jmlr-2013-Learning_Theory_Analysis_for_Association_Rules_and_Sequential_Event_Prediction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Introduction Consider the problem of predicting the next event within a current event sequence, given a “sequence database” of past event sequences to learn from. [sent-18, score-0.323]
</p><p>2 We might wish to do this, for instance, using data generated by a customer placing items into the virtual basket of an online grocery store such as NYC’s Fresh Direct, Peapod by Stop & Shop, or Roche Bros. [sent-19, score-0.48]
</p><p>3 Typically in association rule mining, a strict minimum support threshold condition is placed on the support of itemsets within a rule, so that rules falling below the minimum support threshold are simply discarded. [sent-41, score-0.482]
</p><p>4 The large sample bounds are of order O ( 1/m) as in classical analysis of supervised learning, where m denotes the number of event sequences in the database, that is, the number of past baskets ordered by the online grocery store customer. [sent-50, score-0.306]
</p><p>5 At the core of each algorithm is a method for rank-ordering association rules where the list of possible rules is generated using the customer’s past purchase history and subsets of items within the current basket. [sent-56, score-0.453]
</p><p>6 Then the remaining rules are ranked according to the “conﬁdence,” which for rule a → b is the empirical probability that b will be in the basket given that a is in the basket. [sent-66, score-0.488]
</p><p>7 The right-hand sides of rules with the highest adjusted conﬁdence are recommended by the algorithm. [sent-70, score-0.376]
</p><p>8 An algorithm uses B and S to ﬁnd rules a → b, where a is in the basket and b is not in the basket. [sent-115, score-0.405]
</p><p>9 For instance, if salsa and guacamole are in the basket B and also if salsa, guacamole and tortilla chips were often purchased together in S, then the rule (salsa and guacamole) → tortilla chips might be used to recommend tortilla chips. [sent-116, score-0.403]
</p><p>10 The prior for the adjusted conﬁdence tends to bias rules towards the bottom of the ranked list. [sent-130, score-0.323]
</p><p>11 A rule cannot have a high adjusted conﬁdence unless it has a large enough conﬁdence and also a large enough support on the left-hand side. [sent-137, score-0.319]
</p><p>12 Thus, rules attaining high values of adjusted conﬁdence have a lower bound on conﬁdence, and a lower bound on support of both the right and left-hand sides, which means a better estimate of the conditional probability. [sent-140, score-0.396]
</p><p>13 Figure 1 illustrates this by showing the support of rules ordered by adjusted conﬁdence, for two values of K, using a transactional data set “T25I10D10KN200” from the IBM Quest Market-Basket Synthetic Data Generator (Agrawal and Srikant, 1994) which mimics a retail data set. [sent-145, score-0.354]
</p><p>14 1 We use all rules with either one or no items on the left and one item on the right (as produced for instance by GenRules, presented in Algorithm 1). [sent-146, score-0.341]
</p><p>15 The rules are ordered on the x-axis by adjusted conﬁdence, and the support of the rule is indicated on the y-axis. [sent-148, score-0.437]
</p><p>16 As K increases, rules with the highest adjusted conﬁdence are required to achieve a higher support, as can be seen from the gap in the lower left corner of the scatter plot for larger K. [sent-149, score-0.351]
</p><p>17 GenRules (Algorithm 1) is one of the simplest such rule mining algorithms, which in practice should be replaced by a rule mining algorithm that retrieves rules tailored to the application. [sent-152, score-0.372]
</p><p>18 ,m , zi ⊆ X , current basket B ⊂ X , set of items X Output: Set of all rules {a j → b j } j where b j is a single item that is not in the basket B, and where a j is either a subset of items in the basket B, or else it is the empty set. [sent-167, score-1.401]
</p><p>19 For this algorithm, the rules are ranked by conﬁdence, and rules that do not achieve a predetermined ﬁxed minimum support threshold are completely omitted. [sent-172, score-0.317]
</p><p>20 2  Compute adjusted conﬁdence of each rule a j → b j as fS,K (a j , b j ) =  3  Reorder rules by decreasing adjusted conﬁdence. [sent-196, score-0.611]
</p><p>21 A chosen value of K is used to compute the adjusted conﬁdence for each rule, and rules are then ranked according to adjusted conﬁdence. [sent-200, score-0.528]
</p><p>22 The deﬁnition of the adjusted conﬁdence makes an implicit assumption that the order in which items were placed into previous baskets is irrelevant. [sent-201, score-0.471]
</p><p>23 The numerator of the adjusted conﬁdence becomes the number of past orders where a is placed in the basket before b. [sent-203, score-0.527]
</p><p>24 Alternatively, we could create a negation item ¬ice cream indicating that the basket contains no ice cream presently, so sprinkles + ¬ice cream → vanilla could have a high score. [sent-214, score-0.398]
</p><p>25 We can also use negation items on the right, where if there is a rule a → ¬b that receives a higher score (conﬁdence or adjusted conﬁdence) than any other rules recommending b, we can choose not to recommend b. [sent-215, score-0.536]
</p><p>26 The key is to ﬁnd a small but good set of rules, for instance the set of rules containing exhaustively all subsets of 1, 2, or 3 items on the left; or perhaps use the top rules that come out of the Apriori algorithm (Agrawal et al. [sent-218, score-0.366]
</p><p>27 4 Modeling Assumption The general modeling assumption that we make with the two algorithms above can be written as follows, where current basket B is composed of items b1 , . [sent-222, score-0.417]
</p><p>28 bt , and Xi is the random variable governing whether item i will be placed into the basket next: argmax P(Xi = 1|Xb1 = 1, Xb2 = 1, . [sent-225, score-0.436]
</p><p>29 This expression states that the most likely item to be added next into the basket can be identiﬁed using a subset of items in the basket, denoted a. [sent-241, score-0.51]
</p><p>30 Denote z ∼ D to mean that basket z is drawn randomly (iid) according to distribution D over the space of possible items in baskets and permutations over those items, 2X × Π. [sent-265, score-0.553]
</p><p>31 The t th item added to the basket is written z·,t , where the dot is just a placeholder for the generic basket z. [sent-266, score-0.667]
</p><p>32 We deﬁne the number of items in basket z by Tz , that is, Tz := |z|. [sent-268, score-0.417]
</p><p>33 Speciﬁcally, for the way we have deﬁned sequential event prediction, if any item has a higher score than the next item added, the algorithm incurs an error. [sent-325, score-0.359]
</p><p>34 An illustration of this point is that for large K, all adjusted conﬁdence values are ≪ 1, and for small K, the adjusted conﬁdence can be ≈ 1; differences in adjusted conﬁdence for small K cannot be directly compared to those for large K. [sent-334, score-0.615]
</p><p>35 5 provides stability bounds for the large sample asymptotic regime (for both sequential event prediction and classiﬁcation). [sent-371, score-0.303]
</p><p>36 6, starting with stability bounds that formally show that minimum support thresholds can lead to better generalization (for both sequential event prediction and classiﬁcation). [sent-373, score-0.377]
</p><p>37 From there, we present small sample bounds for the adjusted conﬁdence algorithm, for classiﬁcation and (separately) for sequential event prediction. [sent-374, score-0.398]
</p><p>38 We deﬁne a sequential event prediction algorithm producing fS to have strong sequential event prediction stability β (by analogy with B&E; Deﬁnition 15) if the following holds: ∀S ∈ D m , ∀i ∈ {1, . [sent-383, score-0.486]
</p><p>39  0  The empirical error and leave-one-out error deﬁned for this loss are: EmpErrγ ( fS , zi ) :=  1 m ∑ ℓγ ( fS , zi ), m i=1  LooErrγ ( fS , zi ) :=  1 m ∑ ℓγ ( fS/i , zi ). [sent-412, score-0.301]
</p><p>40 m i=1  Lemma 1 A sequential event prediction algorithm producing fS with strong sequential event prediction stability β has uniform stability 2β/γ with respect to the loss function ℓγ . [sent-413, score-0.591]
</p><p>41 3453  RUDIN , L ETHAM AND M ADIGAN  Theorem 2 Let fS be a sequential event prediction algorithm with sequential event stability β. [sent-455, score-0.456]
</p><p>42 This contrasts with sequential event prediction where there is a sequence of labels, one for each item in the basket as it arrives. [sent-463, score-0.583]
</p><p>43 For classiﬁcation, we represent basket x as a binary vector, where entry j is 1 if item j is in the basket. [sent-464, score-0.38]
</p><p>44 Each labeled basket z is chosen randomly (iid) from a ﬁxed (but unknown) probability distribution D over baskets and labels. [sent-466, score-0.423]
</p><p>45 We now deﬁne a class of decision functions that use a valid scoring function g ∈ G to provide a label to a basket x, fg : 2X → {−1, 1}. [sent-473, score-0.363]
</p><p>46 The adjusted conﬁdence algorithm uses the training set S of m iid baskets to compute the adjusted conﬁdences fS,K and ﬁnd a rule that will be used to label the basket. [sent-517, score-0.629]
</p><p>47 We use z = (x, y) to refer to a general labeled basket, and zi = (xi , yi ) to refer speciﬁcally to the ith labeled basket in the training set. [sent-518, score-0.382]
</p><p>48 We deﬁne a highest-scoring-correct rule for x as a rule with the highest adjusted conﬁdence that predicts the correct label y. [sent-519, score-0.399]
</p><p>49 We deﬁne a highest-scoring incorrect rule for x as a rule with the highest adjusted conﬁdence that predicts the incorrect label −y, so the left-hand side obeys: a- ∈ argmax fS,K (a, −y) = argmax SxK a⊆x,a∈A  a⊆x,a∈A  3456  #(a ∪ −y) . [sent-523, score-0.551]
</p><p>50 A misclassiﬁcation error is made for labeled basket z when the highest-scoring-correct rule, a+ → y, has a lower adjusted conﬁdence than the highest-scoring incorrect rule a- → −y. [sent-526, score-0.595]
</p><p>51 For training basket xi , the left-hand side of a highest-scoring-correct rule obeys: a+ i K ∈ argmax fS,K (a, yi ), Sx a⊆xi ,a∈A  and the left-hand side of a highest-scoring-incorrect rule obeys: a- i K ∈ argmax fS,K (a, −yi ). [sent-541, score-0.591]
</p><p>52 Denote z ∼ D to mean that basket z is drawn randomly (iid) according to distribution D over the space of possible items in baskets and permutations over those items, 2X × Π. [sent-553, score-0.553]
</p><p>53 The t th item added to the basket is written z·,t , where the dot is just a placeholder for the generic basket z. [sent-554, score-0.667]
</p><p>54 We deﬁne the number of items in basket z by Tz , that is, Tz := |z|. [sent-556, score-0.417]
</p><p>55 For sequential event prediction, a highest-scoring-correct rule is a highest scoring rule that has the next item z·,t+1 on the right. [sent-557, score-0.485]
</p><p>56 If z·,t+1 has never been purchased, the adjusted conﬁdence for all rules a → z·,t+1 is 0, and we choose the maximizing rule to be ∅ → z·,t+1 . [sent-562, score-0.406]
</p><p>57 Also at time 0 when the basket is empty, the maximizing rule is ∅ → z·,t+1 . [sent-563, score-0.37]
</p><p>58 ,z·,t+1 }  If there is more than one highest-scoring rule, one is chosen at random (with the exception that all incorrect rules are tied at zero adjusted conﬁdence, in which case the left side is taken as ∅ and the right side is chosen randomly). [sent-573, score-0.343]
</p><p>59 Even though we deﬁne an order for the basket for this discussion of prediction, we are still using the undirected adjusted conﬁdence to make recommendations rather than the directed version introduced in Section 2. [sent-577, score-0.515]
</p><p>60 For the speciﬁc training basket zi , the left-hand side a+ itK of a highest-scoring-correct rule at Sz time t obeys : argmax fS,K (a, zi,t+1 ), a+ itK ∈ Sz a⊆{zi,1 ,. [sent-588, score-0.518]
</p><p>61 We can then show: Lemma 5 A rule-based sequential event prediction algorithm with uniform rule stability β has uniform stability 2β/γ with respect to the loss function ℓγ,Kr . [sent-617, score-0.471]
</p><p>62 In the second inequality, we used the deﬁnition of uniform rule stability for both absolute value terms with b∗ being z·,t+1 , and basket z being z·,1 . [sent-656, score-0.45]
</p><p>63 Theorem 6 Let Alg be a sequential event prediction algorithm with uniform rule stability β for sequential event stability. [sent-662, score-0.539]
</p><p>64 3463  RUDIN , L ETHAM AND M ADIGAN  Deﬁne a highest-scoring rule a∗ → b∗ as a rule that achieves the maximum adjusted conSztK SztK ﬁdence, over all of the possible rules. [sent-704, score-0.371]
</p><p>65 3) The adjusted conﬁdence provides a weaker support threshold, allowing important rules to be used, while still being able to generalize. [sent-740, score-0.354]
</p><p>66 Thus each basket is one of the left-hand sides from the allowed set. [sent-776, score-0.312]
</p><p>67 2m  Translating B&E;’s notation to the adjusted conﬁdence setting for sequential event prediction, zi = xi = zi , with zi ∈ 2X × Π. [sent-826, score-0.585]
</p><p>68 The next results bound the difference in the highest adjusted conﬁdence values when the basket zi is removed from S. [sent-836, score-0.61]
</p><p>69 For sequential event prediction, the left-hand side of a highest-scoring-correct rule for a general basket z on S/i obeys: a+/i ztK ∈ S  argmax a⊆{z·,1 ,. [sent-839, score-0.599]
</p><p>70 ,z·,t },a∈A argmax  A highest-scoring-incorrect rule for basket z on S/i obeys: [a- /i ztK , b- /i ztK ] ∈ S S  argmax a⊆{z·,1 ,. [sent-846, score-0.482]
</p><p>71 #/i a + K  In Lemma 16 below, we bound the difference in adjusted conﬁdence of a general basket z when zi is removed from the training set, in the sequential event prediction setting. [sent-859, score-0.785]
</p><p>72 ˆ Lemma 17 (Large Support Implies Stability) |ℓγ,Kr ( fS,K , z) − ℓγ,Kr ( fS/i ,K , z)| ≤  1 1 Tz −1 1 1 ∑ az + K + |Kr − K| az + Kr γ Tz t=0 ˜ ˜ +  1 1 + |Kr − K| az + K ˆ az + Kr ˆ  1 m + m + K az + K ˜  1 m + m + K az + K ˆ  . [sent-875, score-0.474]
</p><p>73 az + Kr ˜ #/i a- /i ztK + K S  Now incorporating Lemma 16 and that term1 ≤ =  #/i (a- /i  ∪b- /i ) S ztK S ztK #/i a- /i +K S ztK  ≤  m−1 m−1+K  ≤  m m+K ,  |Kr − K| m |Kr − K| 1 + 1+ az + K ˜ az + Kr ˜ az + Kr m + K ˜ 1 1 m 1 + |Kr − K| + az + K ˜ az + Kr m + K az + K ˜ ˜  . [sent-879, score-0.553]
</p><p>74 Lemma 18 (Asymptotic Expectation of 1/(#a + K)) For any itemset a ∈ A and any K ≥ 0, ES∼D  1 1 ≤ +O #a + K mpa + K  1 m2  ,  where pa is the probability that a random basket contains a, that is, pa = Pz∼D (a ⊆ z). [sent-882, score-0.341]
</p><p>75 We are interested in the change in adjusted conﬁdence of speciﬁc basket zi when that same basket is removed from the training set, that is on S/i . [sent-885, score-0.848]
</p><p>76 L EARNING T HEORY A NALYSIS FOR A SSOCIATION RULES AND S EQUENTIAL E VENT P REDICTION  The requirement of a minimum support threshold ensures that for any particular item b, the highest argmax scoring rule with b on the right must have support at least θ, that is: f¯S,θ (a, b) a⊆{z·,1 ,. [sent-903, score-0.397]
</p><p>77 The left-hand side of a highest-scoring-correct rule for general basket x on S/i obeys:  a+/i xK ∈ argmax fS/i ,K (a, y) = argmax S a⊆x,a∈A  a⊆x,a∈A  #/i (a ∪ y) . [sent-915, score-0.482]
</p><p>78 #/i a + K  ˆ ˆ ˜ We further deﬁne ax = min(#a- , #/i a- /i xK ) and ax := min(#a+ , #/i a+/i xK ), and axi and axi as the ˜ SxK SxK S S analogous quantities for speciﬁc basket xi . [sent-917, score-0.427]
</p><p>79 Similarly, the adjusted conﬁdence of the highest-scoring-incorrect rule for xi with data set S/i , a- /i x K → −yi , exceeds that of the rule ∅ → −yi , thus: S i  #/i a- /i x K S i  #/i (a- /i x K ∪ −yi ) S i  ≥  #/i a- /i x K + K S  #/i a- /i x K + K S  i  ≥  i  #/i (−yi ) #/i (−yi ) ≥ . [sent-924, score-0.371]
</p><p>80 m+K m+K m+K  The ﬁrst equality uses that basket xi has label yi . [sent-928, score-0.313]
</p><p>81 Proof (Of Theorem 11) From Lemma 17, adapted for classiﬁcation, |ℓclass ( fS,K , zi ) − ℓclass ( fS/i ,K , zi )| γ,Kr γ,Kr ≤  1 1 1 m 1 + |Kr − K| + γ axi + K ˜ axi + Kr m + K axi + K ˜ ˜ 1 1 1 m + |Kr − K| + + axi + K ˆ axi + Kr m + K axi + K ˆ ˆ  . [sent-936, score-0.558]
</p><p>82 It uses the support guarantee for the adjusted conﬁdence algorithm (6) in order to bound the terms of Lemma 17, which holds with the same proof when the loss ℓγ,Kr is changed to the ˜z new loss ℓnew and superscript “- ” is replaced by “∗ ”. [sent-961, score-0.307]
</p><p>83 i  Lemma 20 (Support Thresholds for Adjusted Conﬁdence, Sequential Event Prediction) For speciﬁc basket zi , deﬁne: αKr :=  m + K − #zi,t+1 1 and αK := K(#zi,t+1 − 1) + Kr (m + K − #zi,t+1 ) K  1−  #zi,t+1 − 1 . [sent-964, score-0.356]
</p><p>84 The ﬁrst line above uses the deﬁnition of αK , the second line uses the fact that each basket is chosen independently, the third line uses that zi,t+1 is always contained in zi and also uses the fact that the mean of the binomial distribution Bin(m − 1, pzi,t+1 ) is (m − 1)pzi,t+1 . [sent-990, score-0.356]
</p><p>85 ,m , zi ⊆ X , current basket B ⊂ X , set of items X Output: Set of all rules where a j is an item in the basket B (or the empty set) and b j is not in B. [sent-1009, score-0.984]
</p><p>86 Since these data do not come naturally with a time ordering, items in the basket were randomly permuted to attain an order. [sent-1024, score-0.417]
</p><p>87 At each iteration, rules were formed from one item or the empty item on the left, and one item on the right (See GenRules in Figure 4). [sent-1025, score-0.397]
</p><p>88 Recommendations of one item were made using the following 15 algorithms: highest support, highest conﬁdence, highest adjusted conﬁdence for eight K levels, max conﬁdence, min support algorithm for ﬁve support threshold levels θ. [sent-1026, score-0.473]
</p><p>89 The parameters of the experiment are: number of training baskets (20 in all cases), number of test baskets (100 in all cases), values of K for the adjusted conﬁdence algorithm (0. [sent-1029, score-0.477]
</p><p>90 1 Mining Association Rules Association rule mining has proven successful for many applications, including market basket analysis (cross selling, product placement, afﬁnity promotion, see also Kohavi et al. [sent-1143, score-0.414]
</p><p>91 jority of literature on association rule mining concerns the design of efﬁcient algorithms to address the time-and-memory-consuming task of mining rules within very large databases. [sent-1151, score-0.341]
</p><p>92 In that setting, the adjusted conﬁdence would provide a ranking of rules in terms of their ability to predict, including both “common sense rules” and “nuggets. [sent-1158, score-0.323]
</p><p>93 In other work, we designed a Bayesian framework that estimates K for the adjusted conﬁdence by “borrowing strength” across both users and items (McCormick et al. [sent-1185, score-0.335]
</p><p>94 We are also looking at different approaches to the sequential event prediction problem, where we allow the predictions to alter the sequence in which items are placed into the basket (Letham et al. [sent-1187, score-0.62]
</p><p>95 Let Xi be an indicator variable that is 1 if item i is in the current basket and 0 otherwise. [sent-1234, score-0.38]
</p><p>96 It is incorrect to substitute the current state of the basket directly into the formula above. [sent-1249, score-0.307]
</p><p>97 For instance, if the current basket contains items 1 and 2, so X1 = 1 and X2 = 1, it is incorrect to write P(Xm |X1 = 1, X2 = 1 1) = 1+exp( f ) , where f = λ1 + λ2 + λ0,m . [sent-1250, score-0.437]
</p><p>98 Finally, it is not clear how to incorporate the order in which items are placed into the basket within this type of model, whereas it is trivial to incorporate this into the association rule techniques as discussed in Section 2. [sent-1276, score-0.552]
</p><p>99 If the current basket contains t items, one would use only the models constructed using the ﬁrst t items in each basket to predict the next item to be added. [sent-1283, score-0.797]
</p><p>100 Further, if the current basket is larger than any of the past baskets, the models would be trivial, since none of the past baskets can be used to construct them. [sent-1290, score-0.493]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kr', 0.492), ('ztk', 0.378), ('sztk', 0.331), ('basket', 0.287), ('adjusted', 0.205), ('dence', 0.174), ('baskets', 0.136), ('items', 0.13), ('tz', 0.129), ('rules', 0.118), ('fs', 0.117), ('tzi', 0.117), ('itk', 0.113), ('adigan', 0.101), ('etham', 0.101), ('ssociation', 0.097), ('event', 0.096), ('item', 0.093), ('rudin', 0.091), ('sz', 0.09), ('vent', 0.087), ('con', 0.086), ('rule', 0.083), ('trueerr', 0.082), ('stability', 0.08), ('az', 0.079), ('sequential', 0.077), ('azi', 0.074), ('equential', 0.072), ('rediction', 0.072), ('axi', 0.07), ('zi', 0.069), ('heory', 0.069), ('trueerrclass', 0.062), ('letham', 0.058), ('nalysis', 0.058), ('argmax', 0.056), ('tk', 0.056), ('association', 0.052), ('sx', 0.051), ('fg', 0.051), ('emperr', 0.051), ('genrules', 0.051), ('avgcorrect', 0.047), ('fmaxscore', 0.047), ('sxk', 0.047), ('mining', 0.044), ('customer', 0.044), ('asztk', 0.043), ('pmina', 0.043), ('pmin', 0.039), ('szt', 0.039), ('itemsets', 0.036), ('ezi', 0.035), ('past', 0.035), ('earning', 0.034), ('purchased', 0.033), ('emperrclass', 0.031), ('itemset', 0.031), ('support', 0.031), ('prediction', 0.03), ('alg', 0.03), ('mp', 0.029), ('threshold', 0.029), ('bin', 0.028), ('highest', 0.028), ('recommender', 0.027), ('yi', 0.026), ('classi', 0.025), ('loss', 0.025), ('sides', 0.025), ('scoring', 0.025), ('xm', 0.024), ('obeys', 0.023), ('apples', 0.023), ('mpa', 0.023), ('recommendations', 0.023), ('pointwise', 0.023), ('generalization', 0.022), ('boxplots', 0.022), ('bound', 0.021), ('minimum', 0.021), ('collaborative', 0.021), ('bousquet', 0.021), ('ez', 0.021), ('recommendation', 0.021), ('associative', 0.021), ('pz', 0.02), ('mccormick', 0.02), ('incorrect', 0.02), ('bounds', 0.02), ('chocolate', 0.019), ('grocery', 0.019), ('lettuce', 0.019), ('oranges', 0.019), ('agrawal', 0.019), ('lemma', 0.018), ('benjamin', 0.018), ('cynthia', 0.018), ('vanilla', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999785 <a title="61-tfidf-1" href="./jmlr-2013-Learning_Theory_Analysis_for_Association_Rules_and_Sequential_Event_Prediction.html">61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</a></p>
<p>Author: Cynthia Rudin, Benjamin Letham, David Madigan</p><p>Abstract: We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called “sequential event prediction.” In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer’s online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the “cold start” problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classiﬁcation, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an “adjusted conﬁdence” measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. Keywords: statistical learning theory, algorithmic stability, association rules, sequence prediction, associative classiﬁcation c 2013 Cynthia Rudin, Benjamin Letham and David Madigan. RUDIN , L E</p><p>2 0.068960376 <a title="61-tfidf-2" href="./jmlr-2013-QuantMiner_for_Mining_Quantitative_Association_Rules.html">89 jmlr-2013-QuantMiner for Mining Quantitative Association Rules</a></p>
<p>Author: Ansaf Salleb-Aouissi, Christel Vrain, Cyril Nortet, Xiangrong Kong, Vivek Rathod, Daniel Cassard</p><p>Abstract: In this paper, we propose Q UANT M INER, a mining quantitative association rules system. This system is based on a genetic algorithm that dynamically discovers “good” intervals in association rules by optimizing both the support and the conﬁdence. The experiments on real and artiﬁcial databases have shown the usefulness of Q UANT M INER as an interactive, exploratory data mining tool. Keywords: association rules, numerical and categorical attributes, unsupervised discretization, genetic algorithm, simulated annealing</p><p>3 0.056996867 <a title="61-tfidf-3" href="./jmlr-2013-Optimal_Discovery_with_Probabilistic_Expert_Advice%3A_Finite_Time_Analysis_and_Macroscopic_Optimality.html">81 jmlr-2013-Optimal Discovery with Probabilistic Expert Advice: Finite Time Analysis and Macroscopic Optimality</a></p>
<p>Author: Sébastien Bubeck, Damien Ernst, Aurélien Garivier</p><p>Abstract: We consider an original problem that arises from the issue of security analysis of a power system and that we name optimal discovery with probabilistic expert advice. We address it with an algorithm based on the optimistic paradigm and on the Good-Turing missing mass estimator. We prove two different regret bounds on the performance of this algorithm under weak assumptions on the probabilistic experts. Under more restrictive hypotheses, we also prove a macroscopic optimality result, comparing the algorithm both with an oracle strategy and with uniform sampling. Finally, we provide numerical experiments illustrating these theoretical ﬁndings. Keywords: optimal discovery, probabilistic experts, optimistic algorithm, Good-Turing estimator, UCB</p><p>4 0.051935025 <a title="61-tfidf-4" href="./jmlr-2013-The_Rate_of_Convergence_of_AdaBoost.html">114 jmlr-2013-The Rate of Convergence of AdaBoost</a></p>
<p>Author: Indraneel Mukherjee, Cynthia Rudin, Robert E. Schapire</p><p>Abstract: The AdaBoost algorithm was designed to combine many “weak” hypotheses that perform slightly better than random guessing into a “strong” hypothesis that has very low error. We study the rate at which AdaBoost iteratively converges to the minimum of the “exponential loss.” Unlike previous work, our proofs do not require a weak-learning assumption, nor do they require that minimizers of the exponential loss are ﬁnite. Our ﬁrst result shows that the exponential loss of AdaBoost’s computed parameter vector will be at most ε more than that of any parameter vector of ℓ1 -norm bounded by B in a number of rounds that is at most a polynomial in B and 1/ε. We also provide lower bounds showing that a polynomial dependence is necessary. Our second result is that within C/ε iterations, AdaBoost achieves a value of the exponential loss that is at most ε more than the best possible value, where C depends on the data set. We show that this dependence of the rate on ε is optimal up to constant factors, that is, at least Ω(1/ε) rounds are necessary to achieve within ε of the optimal exponential loss. Keywords: AdaBoost, optimization, coordinate descent, convergence rate</p><p>5 0.044472516 <a title="61-tfidf-5" href="./jmlr-2013-Machine_Learning_with_Operational_Costs.html">68 jmlr-2013-Machine Learning with Operational Costs</a></p>
<p>Author: Theja Tulabandhula, Cynthia Rudin</p><p>Abstract: This work proposes a way to align statistical modeling with decision making. We provide a method that propagates the uncertainty in predictive modeling to the uncertainty in operational cost, where operational cost is the amount spent by the practitioner in solving the problem. The method allows us to explore the range of operational costs associated with the set of reasonable statistical models, so as to provide a useful way for practitioners to understand uncertainty. To do this, the operational cost is cast as a regularization term in a learning algorithm’s objective function, allowing either an optimistic or pessimistic view of possible costs, depending on the regularization parameter. From another perspective, if we have prior knowledge about the operational cost, for instance that it should be low, this knowledge can help to restrict the hypothesis space, and can help with generalization. We provide a theoretical generalization bound for this scenario. We also show that learning with operational costs is related to robust optimization. Keywords: statistical learning theory, optimization, covering numbers, decision theory</p><p>6 0.042558178 <a title="61-tfidf-6" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>7 0.039404396 <a title="61-tfidf-7" href="./jmlr-2013-Counterfactual_Reasoning_and_Learning_Systems%3A_The_Example_of_Computational_Advertising.html">30 jmlr-2013-Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</a></p>
<p>8 0.032857802 <a title="61-tfidf-8" href="./jmlr-2013-Efficient_Active_Learning_of_Halfspaces%3A_An_Aggressive_Approach.html">39 jmlr-2013-Efficient Active Learning of Halfspaces: An Aggressive Approach</a></p>
<p>9 0.031997919 <a title="61-tfidf-9" href="./jmlr-2013-A_Theory_of_Multiclass_Boosting.html">8 jmlr-2013-A Theory of Multiclass Boosting</a></p>
<p>10 0.030089056 <a title="61-tfidf-10" href="./jmlr-2013-Distribution-Dependent_Sample_Complexity_of_Large_Margin_Learning.html">35 jmlr-2013-Distribution-Dependent Sample Complexity of Large Margin Learning</a></p>
<p>11 0.028094728 <a title="61-tfidf-11" href="./jmlr-2013-Lovasz_theta_function%2C_SVMs_and_Finding_Dense_Subgraphs.html">64 jmlr-2013-Lovasz theta function, SVMs and Finding Dense Subgraphs</a></p>
<p>12 0.026247948 <a title="61-tfidf-12" href="./jmlr-2013-Ranked_Bandits_in_Metric_Spaces%3A_Learning_Diverse_Rankings_over_Large_Document_Collections.html">94 jmlr-2013-Ranked Bandits in Metric Spaces: Learning Diverse Rankings over Large Document Collections</a></p>
<p>13 0.024999345 <a title="61-tfidf-13" href="./jmlr-2013-Manifold_Regularization_and_Semi-supervised_Learning%3A_Some_Theoretical_Analyses.html">69 jmlr-2013-Manifold Regularization and Semi-supervised Learning: Some Theoretical Analyses</a></p>
<p>14 0.024830451 <a title="61-tfidf-14" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>15 0.024630196 <a title="61-tfidf-15" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>16 0.024479883 <a title="61-tfidf-16" href="./jmlr-2013-Conjugate_Relation_between_Loss_Functions_and_Uncertainty_Sets_in_Classification_Problems.html">26 jmlr-2013-Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems</a></p>
<p>17 0.023813291 <a title="61-tfidf-17" href="./jmlr-2013-Lower_Bounds_and_Selectivity_of_Weak-Consistent_Policies_in_Stochastic_Multi-Armed_Bandit_Problem.html">65 jmlr-2013-Lower Bounds and Selectivity of Weak-Consistent Policies in Stochastic Multi-Armed Bandit Problem</a></p>
<p>18 0.02338947 <a title="61-tfidf-18" href="./jmlr-2013-A_Plug-in_Approach_to_Neyman-Pearson_Classification.html">6 jmlr-2013-A Plug-in Approach to Neyman-Pearson Classification</a></p>
<p>19 0.022810996 <a title="61-tfidf-19" href="./jmlr-2013-Classifying_With_Confidence_From_Incomplete_Information.html">22 jmlr-2013-Classifying With Confidence From Incomplete Information</a></p>
<p>20 0.021858672 <a title="61-tfidf-20" href="./jmlr-2013-Derivative_Estimation_with_Local_Polynomial_Fitting.html">31 jmlr-2013-Derivative Estimation with Local Polynomial Fitting</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.115), (1, 0.044), (2, 0.01), (3, 0.084), (4, -0.031), (5, -0.01), (6, 0.017), (7, 0.004), (8, -0.036), (9, 0.004), (10, -0.001), (11, -0.12), (12, 0.021), (13, -0.188), (14, 0.05), (15, 0.072), (16, -0.13), (17, 0.072), (18, -0.066), (19, -0.09), (20, -0.056), (21, -0.018), (22, -0.006), (23, -0.03), (24, 0.194), (25, 0.064), (26, 0.063), (27, -0.027), (28, 0.02), (29, -0.178), (30, 0.09), (31, 0.024), (32, 0.06), (33, -0.034), (34, 0.228), (35, 0.124), (36, 0.067), (37, -0.139), (38, -0.094), (39, -0.171), (40, -0.084), (41, 0.087), (42, -0.063), (43, 0.075), (44, -0.337), (45, 0.291), (46, -0.049), (47, -0.006), (48, 0.161), (49, -0.008)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9590764 <a title="61-lsi-1" href="./jmlr-2013-Learning_Theory_Analysis_for_Association_Rules_and_Sequential_Event_Prediction.html">61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</a></p>
<p>Author: Cynthia Rudin, Benjamin Letham, David Madigan</p><p>Abstract: We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called “sequential event prediction.” In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer’s online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the “cold start” problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classiﬁcation, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an “adjusted conﬁdence” measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. Keywords: statistical learning theory, algorithmic stability, association rules, sequence prediction, associative classiﬁcation c 2013 Cynthia Rudin, Benjamin Letham and David Madigan. RUDIN , L E</p><p>2 0.46891683 <a title="61-lsi-2" href="./jmlr-2013-QuantMiner_for_Mining_Quantitative_Association_Rules.html">89 jmlr-2013-QuantMiner for Mining Quantitative Association Rules</a></p>
<p>Author: Ansaf Salleb-Aouissi, Christel Vrain, Cyril Nortet, Xiangrong Kong, Vivek Rathod, Daniel Cassard</p><p>Abstract: In this paper, we propose Q UANT M INER, a mining quantitative association rules system. This system is based on a genetic algorithm that dynamically discovers “good” intervals in association rules by optimizing both the support and the conﬁdence. The experiments on real and artiﬁcial databases have shown the usefulness of Q UANT M INER as an interactive, exploratory data mining tool. Keywords: association rules, numerical and categorical attributes, unsupervised discretization, genetic algorithm, simulated annealing</p><p>3 0.35728317 <a title="61-lsi-3" href="./jmlr-2013-Optimal_Discovery_with_Probabilistic_Expert_Advice%3A_Finite_Time_Analysis_and_Macroscopic_Optimality.html">81 jmlr-2013-Optimal Discovery with Probabilistic Expert Advice: Finite Time Analysis and Macroscopic Optimality</a></p>
<p>Author: Sébastien Bubeck, Damien Ernst, Aurélien Garivier</p><p>Abstract: We consider an original problem that arises from the issue of security analysis of a power system and that we name optimal discovery with probabilistic expert advice. We address it with an algorithm based on the optimistic paradigm and on the Good-Turing missing mass estimator. We prove two different regret bounds on the performance of this algorithm under weak assumptions on the probabilistic experts. Under more restrictive hypotheses, we also prove a macroscopic optimality result, comparing the algorithm both with an oracle strategy and with uniform sampling. Finally, we provide numerical experiments illustrating these theoretical ﬁndings. Keywords: optimal discovery, probabilistic experts, optimistic algorithm, Good-Turing estimator, UCB</p><p>4 0.34746143 <a title="61-lsi-4" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>Author: Stéphan Clémençon, Marine Depecker, Nicolas Vayatis</p><p>Abstract: The present paper examines how the aggregation and feature randomization principles underlying the algorithm R ANDOM F OREST (Breiman, 2001) can be adapted to bipartite ranking. The approach taken here is based on nonparametric scoring and ROC curve optimization in the sense of the AUC criterion. In this problem, aggregation is used to increase the performance of scoring rules produced by ranking trees, as those developed in Cl´ mencon and Vayatis (2009c). The present work e ¸ describes the principles for building median scoring rules based on concepts from rank aggregation. Consistency results are derived for these aggregated scoring rules and an algorithm called R ANK ING F OREST is presented. Furthermore, various strategies for feature randomization are explored through a series of numerical experiments on artiﬁcial data sets. Keywords: bipartite ranking, nonparametric scoring, classiﬁcation data, ROC optimization, AUC criterion, tree-based ranking rules, bootstrap, bagging, rank aggregation, median ranking, feature randomization</p><p>5 0.29156095 <a title="61-lsi-5" href="./jmlr-2013-Classifying_With_Confidence_From_Incomplete_Information.html">22 jmlr-2013-Classifying With Confidence From Incomplete Information</a></p>
<p>Author: Nathan Parrish, Hyrum S. Anderson, Maya R. Gupta, Dun Yu Hsiao</p><p>Abstract: We consider the problem of classifying a test sample given incomplete information. This problem arises naturally when data about a test sample is collected over time, or when costs must be incurred to compute the classiﬁcation features. For example, in a distributed sensor network only a fraction of the sensors may have reported measurements at a certain time, and additional time, power, and bandwidth is needed to collect the complete data to classify. A practical goal is to assign a class label as soon as enough data is available to make a good decision. We formalize this goal through the notion of reliability—the probability that a label assigned given incomplete data would be the same as the label assigned given the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. Our approach models the complete data as a random variable whose distribution is dependent on the current incomplete data and the (complete) training data. The method differs from standard imputation strategies in that our focus is on determining the reliability of the classiﬁcation decision, rather than just the class label. We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series data sets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met. Keywords: classiﬁcation, sensor networks, signals, reliability</p><p>6 0.28627312 <a title="61-lsi-6" href="./jmlr-2013-Counterfactual_Reasoning_and_Learning_Systems%3A_The_Example_of_Computational_Advertising.html">30 jmlr-2013-Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</a></p>
<p>7 0.24818081 <a title="61-lsi-7" href="./jmlr-2013-Machine_Learning_with_Operational_Costs.html">68 jmlr-2013-Machine Learning with Operational Costs</a></p>
<p>8 0.22879723 <a title="61-lsi-8" href="./jmlr-2013-Distribution-Dependent_Sample_Complexity_of_Large_Margin_Learning.html">35 jmlr-2013-Distribution-Dependent Sample Complexity of Large Margin Learning</a></p>
<p>9 0.22161321 <a title="61-lsi-9" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<p>10 0.21651019 <a title="61-lsi-10" href="./jmlr-2013-The_Rate_of_Convergence_of_AdaBoost.html">114 jmlr-2013-The Rate of Convergence of AdaBoost</a></p>
<p>11 0.19529633 <a title="61-lsi-11" href="./jmlr-2013-Lovasz_theta_function%2C_SVMs_and_Finding_Dense_Subgraphs.html">64 jmlr-2013-Lovasz theta function, SVMs and Finding Dense Subgraphs</a></p>
<p>12 0.1935069 <a title="61-lsi-12" href="./jmlr-2013-Variable_Selection_in_High-Dimension_with_Random_Designs_and_Orthogonal_Matching_Pursuit.html">119 jmlr-2013-Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit</a></p>
<p>13 0.18296443 <a title="61-lsi-13" href="./jmlr-2013-Finding_Optimal_Bayesian_Networks_Using_Precedence_Constraints.html">44 jmlr-2013-Finding Optimal Bayesian Networks Using Precedence Constraints</a></p>
<p>14 0.18115787 <a title="61-lsi-14" href="./jmlr-2013-Bayesian_Canonical_Correlation_Analysis.html">15 jmlr-2013-Bayesian Canonical Correlation Analysis</a></p>
<p>15 0.16815986 <a title="61-lsi-15" href="./jmlr-2013-Conjugate_Relation_between_Loss_Functions_and_Uncertainty_Sets_in_Classification_Problems.html">26 jmlr-2013-Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems</a></p>
<p>16 0.16606426 <a title="61-lsi-16" href="./jmlr-2013-Learning_Theory_Approach_to_Minimum_Error_Entropy_Criterion.html">62 jmlr-2013-Learning Theory Approach to Minimum Error Entropy Criterion</a></p>
<p>17 0.16157739 <a title="61-lsi-17" href="./jmlr-2013-Segregating_Event_Streams_and_Noise_with_a_Markov_Renewal_Process_Model.html">98 jmlr-2013-Segregating Event Streams and Noise with a Markov Renewal Process Model</a></p>
<p>18 0.15440097 <a title="61-lsi-18" href="./jmlr-2013-Efficient_Active_Learning_of_Halfspaces%3A_An_Aggressive_Approach.html">39 jmlr-2013-Efficient Active Learning of Halfspaces: An Aggressive Approach</a></p>
<p>19 0.15327018 <a title="61-lsi-19" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>20 0.13410348 <a title="61-lsi-20" href="./jmlr-2013-Optimally_Fuzzy_Temporal_Memory.html">82 jmlr-2013-Optimally Fuzzy Temporal Memory</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.02), (5, 0.114), (6, 0.018), (10, 0.047), (20, 0.047), (23, 0.014), (53, 0.018), (68, 0.018), (70, 0.056), (75, 0.031), (78, 0.441), (85, 0.032), (87, 0.012), (88, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.73599774 <a title="61-lda-1" href="./jmlr-2013-Dimension_Independent_Similarity_Computation.html">33 jmlr-2013-Dimension Independent Similarity Computation</a></p>
<p>Author: Reza Bosagh Zadeh, Ashish Goel</p><p>Abstract: We present a suite of algorithms for Dimension Independent Similarity Computation (DISCO) to compute all pairwise similarities between very high-dimensional sparse vectors. All of our results are provably independent of dimension, meaning that apart from the initial cost of trivially reading in the data, all subsequent operations are independent of the dimension; thus the dimension can be very large. We study Cosine, Dice, Overlap, and the Jaccard similarity measures. For Jaccard similarity we include an improved version of MinHash. Our results are geared toward the MapReduce framework. We empirically validate our theorems with large scale experiments using data from the social networking site Twitter. At time of writing, our algorithms are live in production at twitter.com. Keywords: cosine, Jaccard, overlap, dice, similarity, MapReduce, dimension independent</p><p>same-paper 2 0.69839048 <a title="61-lda-2" href="./jmlr-2013-Learning_Theory_Analysis_for_Association_Rules_and_Sequential_Event_Prediction.html">61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</a></p>
<p>Author: Cynthia Rudin, Benjamin Letham, David Madigan</p><p>Abstract: We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called “sequential event prediction.” In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer’s online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the “cold start” problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classiﬁcation, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an “adjusted conﬁdence” measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. Keywords: statistical learning theory, algorithmic stability, association rules, sequence prediction, associative classiﬁcation c 2013 Cynthia Rudin, Benjamin Letham and David Madigan. RUDIN , L E</p><p>3 0.31335762 <a title="61-lda-3" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>Author: Sohail Bahmani, Bhiksha Raj, Petros T. Boufounos</p><p>Abstract: Sparsity-constrained optimization has wide applicability in machine learning, statistics, and signal processing problems such as feature selection and Compressed Sensing. A vast body of work has studied the sparsity-constrained optimization from theoretical, algorithmic, and application aspects in the context of sparse estimation in linear models where the ﬁdelity of the estimate is measured by the squared error. In contrast, relatively less effort has been made in the study of sparsityconstrained optimization in cases where nonlinear models are involved or the cost function is not quadratic. In this paper we propose a greedy algorithm, Gradient Support Pursuit (GraSP), to approximate sparse minima of cost functions of arbitrary form. Should a cost function have a Stable Restricted Hessian (SRH) or a Stable Restricted Linearization (SRL), both of which are introduced in this paper, our algorithm is guaranteed to produce a sparse vector within a bounded distance from the true sparse optimum. Our approach generalizes known results for quadratic cost functions that arise in sparse linear regression and Compressed Sensing. We also evaluate the performance of GraSP through numerical simulations on synthetic and real data, where the algorithm is employed for sparse logistic regression with and without ℓ2 -regularization. Keywords: sparsity, optimization, compressed sensing, greedy algorithm</p><p>4 0.30618054 <a title="61-lda-4" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>Author: Yuchen Zhang, John C. Duchi, Martin J. Wainwright</p><p>Abstract: We analyze two communication-efﬁcient algorithms for distributed optimization in statistical settings involving large-scale data sets. The ﬁrst algorithm is a standard averaging method that distributes the N data samples evenly to m machines, performs separate minimization on each subset, and then averages the estimates. We provide a sharp analysis of this average mixture algorithm, showing that under a reasonable set of conditions, the combined parameter achieves √ mean-squared error (MSE) that decays as O (N −1 + (N/m)−2 ). Whenever m ≤ N, this guarantee matches the best possible rate achievable by a centralized algorithm having access to all N samples. The second algorithm is a novel method, based on an appropriate form of bootstrap subsampling. Requiring only a single round of communication, it has mean-squared error that decays as O (N −1 + (N/m)−3 ), and so is more robust to the amount of parallelization. In addition, we show that a stochastic gradient-based method attains mean-squared error decaying as O (N −1 + (N/m)−3/2 ), easing computation at the expense of a potentially slower MSE rate. We also provide an experimental evaluation of our methods, investigating their performance both on simulated data and on a large-scale regression problem from the internet search domain. In particular, we show that our methods can be used to efﬁciently solve an advertisement prediction problem from the Chinese SoSo Search Engine, which involves logistic regression with N ≈ 2.4 × 108 samples and d ≈ 740,000 covariates. Keywords: distributed learning, stochastic optimization, averaging, subsampling</p><p>5 0.30489695 <a title="61-lda-5" href="./jmlr-2013-Machine_Learning_with_Operational_Costs.html">68 jmlr-2013-Machine Learning with Operational Costs</a></p>
<p>Author: Theja Tulabandhula, Cynthia Rudin</p><p>Abstract: This work proposes a way to align statistical modeling with decision making. We provide a method that propagates the uncertainty in predictive modeling to the uncertainty in operational cost, where operational cost is the amount spent by the practitioner in solving the problem. The method allows us to explore the range of operational costs associated with the set of reasonable statistical models, so as to provide a useful way for practitioners to understand uncertainty. To do this, the operational cost is cast as a regularization term in a learning algorithm’s objective function, allowing either an optimistic or pessimistic view of possible costs, depending on the regularization parameter. From another perspective, if we have prior knowledge about the operational cost, for instance that it should be low, this knowledge can help to restrict the hypothesis space, and can help with generalization. We provide a theoretical generalization bound for this scenario. We also show that learning with operational costs is related to robust optimization. Keywords: statistical learning theory, optimization, covering numbers, decision theory</p><p>6 0.29938418 <a title="61-lda-6" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>7 0.29917145 <a title="61-lda-7" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>8 0.29539555 <a title="61-lda-8" href="./jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems.html">2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</a></p>
<p>9 0.29517701 <a title="61-lda-9" href="./jmlr-2013-Conjugate_Relation_between_Loss_Functions_and_Uncertainty_Sets_in_Classification_Problems.html">26 jmlr-2013-Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems</a></p>
<p>10 0.2925691 <a title="61-lda-10" href="./jmlr-2013-Learning_Theory_Approach_to_Minimum_Error_Entropy_Criterion.html">62 jmlr-2013-Learning Theory Approach to Minimum Error Entropy Criterion</a></p>
<p>11 0.29211399 <a title="61-lda-11" href="./jmlr-2013-Beyond_Fano%27s_Inequality%3A_Bounds_on_the_Optimal_F-Score%2C_BER%2C_and_Cost-Sensitive_Risk_and_Their_Implications.html">18 jmlr-2013-Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</a></p>
<p>12 0.29188004 <a title="61-lda-12" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>13 0.29109463 <a title="61-lda-13" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>14 0.29078129 <a title="61-lda-14" href="./jmlr-2013-The_Rate_of_Convergence_of_AdaBoost.html">114 jmlr-2013-The Rate of Convergence of AdaBoost</a></p>
<p>15 0.29078075 <a title="61-lda-15" href="./jmlr-2013-Efficient_Active_Learning_of_Halfspaces%3A_An_Aggressive_Approach.html">39 jmlr-2013-Efficient Active Learning of Halfspaces: An Aggressive Approach</a></p>
<p>16 0.29050249 <a title="61-lda-16" href="./jmlr-2013-Belief_Propagation_for_Continuous_State_Spaces%3A_Stochastic_Message-Passing_with_Quantitative_Guarantees.html">17 jmlr-2013-Belief Propagation for Continuous State Spaces: Stochastic Message-Passing with Quantitative Guarantees</a></p>
<p>17 0.29035953 <a title="61-lda-17" href="./jmlr-2013-Algorithms_and_Hardness_Results_for_Parallel_Large_Margin_Learning.html">10 jmlr-2013-Algorithms and Hardness Results for Parallel Large Margin Learning</a></p>
<p>18 0.28989542 <a title="61-lda-18" href="./jmlr-2013-Construction_of_Approximation_Spaces_for_Reinforcement_Learning.html">28 jmlr-2013-Construction of Approximation Spaces for Reinforcement Learning</a></p>
<p>19 0.28966403 <a title="61-lda-19" href="./jmlr-2013-Counterfactual_Reasoning_and_Learning_Systems%3A_The_Example_of_Computational_Advertising.html">30 jmlr-2013-Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</a></p>
<p>20 0.28955808 <a title="61-lda-20" href="./jmlr-2013-Manifold_Regularization_and_Semi-supervised_Learning%3A_Some_Theoretical_Analyses.html">69 jmlr-2013-Manifold Regularization and Semi-supervised Learning: Some Theoretical Analyses</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
