<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-2" href="#">jmlr2013-2</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</h1>
<br/><p>Source: <a title="jmlr-2013-2-pdf" href="http://jmlr.org/papers/volume14/ryabko13a/ryabko13a.pdf">pdf</a></p><p>Author: Daniil Ryabko, Jérémie Mary</p><p>Abstract: A metric between time-series distributions is proposed that can be evaluated using binary classiﬁcation methods, which were originally developed to work on i.i.d. data. It is shown how this metric can be used for solving statistical problems that are seemingly unrelated to classiﬁcation and concern highly dependent time series. Speciﬁcally, the problems of time-series clustering, homogeneity testing and the three-sample problem are addressed. Universal consistency of the resulting algorithms is proven under most general assumptions. The theoretical results are illustrated with experiments on synthetic and real-world data. Keywords: time series, reductions, stationary ergodic, clustering, metrics between probability distributions</p><p>Reference: <a title="jmlr-2013-2-reference" href="../jmlr2013_reference/jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Speciﬁcally, the problems of time-series clustering, homogeneity testing and the three-sample problem are addressed. [sent-10, score-0.192]
</p><p>2 Keywords: time series, reductions, stationary ergodic, clustering, metrics between probability distributions  1. [sent-13, score-0.322]
</p><p>3 To establish the consistency of the suggested methods, for clustering and the three-sample problem the only assumption that we make on the data is that the distributions generating the samples are stationary ergodic; this is one of the weakest assumptions used in statistics. [sent-31, score-0.457]
</p><p>4 For homogeneity testing we have to make some mixing assumptions in order to obtain consistency results (this is indeed unavoidable, as shown by Ryabko, 2010b). [sent-32, score-0.288]
</p><p>5 The proposed approach is based on a new distance between time-series distributions (that is, between probability distributions on the space of inﬁnite sequences), which we call telescope distance. [sent-34, score-0.649]
</p><p>6 This distance can be evaluated using binary classiﬁcation methods, and its ﬁnite-sample estimates are shown to be asymptotically consistent. [sent-35, score-0.198]
</p><p>7 Three main building blocks are used to construct the telescope distance. [sent-36, score-0.287]
</p><p>8 The distance we use for this is the following well-known metric: dH (P, Q) := suph∈H |EP h − EQ h| where P, Q are distributions and H is a set of functions. [sent-38, score-0.244]
</p><p>9 This distance was previously applied to such statistical problems as homogeneity testing and change-point estimation (Kifer et al. [sent-40, score-0.318]
</p><p>10 Thus, the second building block are the recent results of Adams and Nobel (2012), that show that empirical estimates of dH are consistent (under certain conditions on H ) for arbitrary stationary ergodic distributions. [sent-46, score-0.484]
</p><p>11 This, however, is not enough: evaluating dH for (stationary ergodic) time-series distributions means measuring the distance between their ﬁnite-dimensional marginals, and not the distributions themselves. [sent-47, score-0.362]
</p><p>12 The resulting distance can “automatically” select the marginal distribution of the right order: marginals which cannot distinguish between the distributions give distance estimates that converge to zero, while marginals whose orders are too high to have converged have very small weights. [sent-50, score-0.516]
</p><p>13 Thus, the estimate is dominated by the marginals which can distinguish between the time-series distributions, or converges to zero if the distributions are the same. [sent-51, score-0.18]
</p><p>14 Ryabko, 1988; Ryabko, 2011); it is also used in the distributional distance (Gray, 1988), see Section 8 below. [sent-53, score-0.239]
</p><p>15 We show that the resulting distance (telescope distance) indeed can be consistently estimated based on sampling, for arbitrary stationary ergodic distributions. [sent-54, score-0.604]
</p><p>16 Moreover, we analyse some other distances between time-series distributions, the possibility of their use for solving the statistical problems considered, and the relation of these distances to the telescope distance introduced in this work. [sent-58, score-0.52]
</p><p>17 A related approach to address the problems considered here, as well as some related problems about stationary ergodic time series, is based on (consistent) empirical estimates of the distributional distance, see Ryabko and Ryabko (2010), Ryabko (2010a), Khaleghi et al. [sent-62, score-0.588]
</p><p>18 ” This distance is described in some detail in Section 8 below, where we compare it to the telescope distance. [sent-65, score-0.413]
</p><p>19 In Section 3 we introduce and discuss the telescope distance. [sent-70, score-0.287]
</p><p>20 In Section 7, under some mixing conditions, we address the problems of homogeneity testing, clustering with unknown k, and ﬁnite-sample performance guarantees. [sent-73, score-0.338]
</p><p>21 In Section 8 we take a look at other distances between timeseries distributions and their relations to the telescope distance. [sent-74, score-0.488]
</p><p>22 A stationary distribution is called (stationary) ergodic if 1 ∑ IXi. [sent-91, score-0.454]
</p><p>23 A Distance between Time-Series Distributions We start with a distance between distributions on X , and then we extend it to distributions on X N . [sent-102, score-0.362]
</p><p>24 For two probability distributions P and Q on (X , F1 ) and a set H of measurable functions on X , one can deﬁne the distance dH (P, Q) := sup |EP h − EQ h|. [sent-103, score-0.304]
</p><p>25 Lemma 1 dH is a metric on the space of probability distributions over X if and only if H generates F1 . [sent-112, score-0.192]
</p><p>26 For two time-series distributions ρ1 , ρ2 we take the dH between k-dimensional marginal distributions of ρ1 and ρ2 for each k ∈ N, and sum them all up with decreasing weights. [sent-117, score-0.258]
</p><p>27 Deﬁnition 2 (telescope distance DH ) For two time series distributions ρ1 and ρ2 on the space (X N , F ) and a sequence of sets of functions H = (H1 , H2 , . [sent-118, score-0.295]
</p><p>28 ) deﬁne the telescope distance ∞  DH (ρ1 , ρ2 ) :=  ∑ wk sup |Eρ h(X1 , . [sent-121, score-0.561]
</p><p>29 Proof The statement follows from the fact that two process distributions are the same if and only if all their ﬁnite-dimensional marginals coincide. [sent-131, score-0.208]
</p><p>30 ˆ Deﬁnition 4 (empirical telescope distance D) For a pair of samples X1. [sent-132, score-0.451]
</p><p>31 m deﬁne the empirical telescope distance as ˆ DH (X1. [sent-136, score-0.413]
</p><p>32 (3) h∈Hk n − k + 1 i=1 i=1  wk sup  All the methods presented in this work are based on the empirical telescope distance. [sent-145, score-0.435]
</p><p>33 The key fact is that it is an asymptotically consistent estimate of the telescope distance, that is, the latter can be consistently estimated based on sampling. [sent-146, score-0.383]
</p><p>34 Then for every stationary ergodic time series distributions ρX and ρY generating samples X1. [sent-148, score-0.683]
</p><p>35 The condition that the sets Hk are sets of indicator function of ﬁnite VC dimension comes from the results of Adams and Nobel (2012), who show that for any stationary ergodic distribution 1 ρ, under these conditions, suph∈Hk n−k+1 ∑n−k+1 h(Xi. [sent-163, score-0.485]
</p><p>36 i+k−1) + ε m − k + 1 i=1 h∈Hk n − k + 1 i=1  ∑ wk sup k=1  T  ≤  ∑ wk sup k=1  h∈Hk  n−k+1 1 ∑ h(Xi. [sent-199, score-0.296]
</p><p>37 In this case each summand in (2) is the total variation distance between the k-dimensional marginal distributions of ρ1 and ρ2 . [sent-256, score-0.289]
</p><p>38 Both distributions are assumed to be stationary ergodic, but no further assumptions are made about them (no independence, mixing or memory assumptions). [sent-280, score-0.336]
</p><p>39 The three sample-problem for dependent time series has been addressed by Gutman (1989) for Markov processes and by Ryabko and Ryabko (2010) for stationary ergodic time series. [sent-281, score-0.568]
</p><p>40 Indeed, to solve this problem it sufﬁces to have consistent estimates of some distance between time series distributions. [sent-283, score-0.207]
</p><p>41 , Zl ) be generated by stationary ergodic distributions ρX , ρY and ρZ , with ρX = ρY and either (i) ρZ = ρX or (ii) ρZ = ρY . [sent-295, score-0.572]
</p><p>42 It is straightforward to extend this theorem to more than two classes; in other words, instead of X and Y one can have an arbitrary number of samples from different stationary ergodic distributions. [sent-299, score-0.492]
</p><p>43 The target clustering is deﬁned according to whether the samples were generated by the same or different distributions: the samples belong to the same cluster if and only if they were generated by the same distribution. [sent-328, score-0.23]
</p><p>44 A clustering algorithm is called asymptotically consistent if with probability 1 from some n on it outputs the target clustering, where n is the length of the shortest sample n := mini=1. [sent-329, score-0.202]
</p><p>45 Again, to solve this problem it is enough to have a metric between time-series distributions that can be consistently estimated. [sent-332, score-0.189]
</p><p>46 Our approach here is based on the telescope distance, and thus we ˆ use D. [sent-333, score-0.287]
</p><p>47 The clustering problem is relatively simple if the target clustering has what is called the strict separation property (Balcan et al. [sent-334, score-0.289]
</p><p>48 N ni on the target clustering has the strict separation property ˆ with respect to DH . [sent-353, score-0.218]
</p><p>49 The distance between clusters is deﬁned as the average distance between points in these clusters. [sent-357, score-0.295]
</p><p>50 Note that we do not require the samples to be independent; the joint distributions of the samples may be completely arbitrary, as long as the marginal distribution of each sample is stationary ergodic. [sent-372, score-0.364]
</p><p>51 Speed of Convergence The results established so far are asymptotic out of necessity: they are established under the assumption that the distributions involved are stationary ergodic, which is too general to allow for any meaningful ﬁnite-time performance guarantees. [sent-377, score-0.266]
</p><p>52 It turns out that this is possible: for the methods based on D one can establish both the asymptotic performance guarantees for all stationary ergodic distributions and ﬁnite-sample performance guarantees under stronger assumptions, namely the uniform mixing conditions introduced below. [sent-380, score-0.687]
</p><p>53 A stationary distribution on the space of one-way inﬁnite sequences (X N , F ) can be uniquely extended to a stationary distribution on the space of two-way inﬁnite sequences (X Z , FZ ) of the form . [sent-383, score-0.362]
</p><p>54 Since in this section we are after ﬁnite-time bounds, we ﬁx a concrete choice of the weights wk ˆ in the deﬁnition of D (Deﬁnition 2), wk := 2−k . [sent-407, score-0.22]
</p><p>55 m be generated by stationary distributions ρX and ρY whose β-mixing coefﬁcients satisfy β(ρ. [sent-425, score-0.266]
</p><p>56 m generated by distributions ρX and ρY respectively, the problem of homogeneity testing (or the two-sample problem) consists in deciding whether ρX = ρY . [sent-444, score-0.31]
</p><p>57 As mentioned above, in general, for stationary ergodic time series distributions there is no asymptotically consistent test for homogeneity (Ryabko, 2010b) (even for binary-valued time series); thus, stronger assumptions are in order. [sent-446, score-0.924]
</p><p>58 Our contribution to this line of research is to show that this problem can be reduced (via the telescope distance) to binary classiﬁcation, in the case of strongly dependent processes satisfying some mixing conditions. [sent-453, score-0.429]
</p><p>59 It is easy to see that under the mixing conditions of Lemma 10 a consistent test for homogeneity exists, and ﬁnite-sample performance guarantees can be obtained. [sent-454, score-0.263]
</p><p>60 3 Clustering with a Known or Unknown Number of Clusters If the distributions generating the samples satisfy certain mixing conditions, then we can augment Theorems 7 and 8 with ﬁnite-sample performance guarantees. [sent-478, score-0.248]
</p><p>61 Then with probability at least 1 − N(N − 1)∆(δ/12, n′ ) the target clustering of the samples has the strict separation property. [sent-497, score-0.222]
</p><p>62 Proof Note that a sufﬁcient condition for the strict separation property to hold is that for every pair ˆ i, j of samples generated by the same distribution we have DH (X i , X j ) ≤ δ/3, and for every pair i, j ˆ of samples generated by different distributions we have DH (X i , X j ) ≥ 2δ/3. [sent-499, score-0.248]
</p><p>63 As with homogeneity testing, while in the general case of stationary ergodic distributions it is impossible to have a consistent clustering algorithm when the number of clusters k is unknown, the situation changes if the distributions satisfy certain mixing conditions. [sent-502, score-1.101]
</p><p>64 Assign to the same cluster all samples that are at 2847  RYABKO AND M ARY  most εn -far from each other, where the threshold εn is selected the same way as for homogeneity testing: εn → 0 and ∆(εn , n) → 0. [sent-504, score-0.225]
</p><p>65 Theorem 13 Given N samples generated by k different stationary distributions ρi , i = 1. [sent-506, score-0.304]
</p><p>66 In this section we attempt to put the telescope distance into a more general context, and take a broader look at metrics between timeseries distributions. [sent-518, score-0.491]
</p><p>67 1 sum Distances Observe that the telescope distance DH has the form D(µ, ν) =  ∑ wk dk (µk , νk ),  (14)  k∈N  where wk are summable positive real weights. [sent-521, score-0.725]
</p><p>68 Let dk , k ∈ N be a series of distances on the spaces of distributions over X k , such that dk (µk , νk ) ≤ a ∈ R for all µ, ν ∈ C and such that there exists a series dˆk (X1. [sent-524, score-0.348]
</p><p>69 Then the distance D given by (14) can be consistently estimated using the estimate ∑k∈N wk dˆk (X1. [sent-535, score-0.26]
</p><p>70 Clearly, DH is an example of a distance in the form (14), and it satisﬁes the conditions of the proposition with C being the set of all stationary ergodic processes. [sent-541, score-0.58]
</p><p>71 2848  F ROM C LASSIFICATION TO P ROBLEMS ON H IGHLY D EPENDENT T IME S ERIES  Another example of a distance in the form (14) is given by the so-called distributional distance (Gray, 1988; Shields, 1996), whose deﬁnition is given below. [sent-542, score-0.365]
</p><p>72 Empirical estimates of this distance are asymptotically consistent for stationary ergodic time series, and thus can be used (Ryabko and Ryabko, 2010; Ryabko, 2010a; Khaleghi et al. [sent-543, score-0.673]
</p><p>73 Deﬁnition 15 (distributional distance) The distributional distance is deﬁned for a pair of processes ρ1 , ρ2 as follows ∞  Ddd (ρ1 , ρ2 ) :=  ∑  ∑  wm wl  B∈Bm,l  m,l=1  |ρ1 (B) − ρ2 (B)|,  (15)  where wk , k ∈ N is a summable sequence of positive real weights (e. [sent-548, score-0.455]
</p><p>74 Conceptually, one of the advantages of the telescope distance DH is that one can use different sets H—the choice that makes it adaptable to applications. [sent-556, score-0.413]
</p><p>75 2 sup Distances A different way to construct a distance between time-series distributions based on their ﬁnitedimensional marginals is to use the supremum instead of summation in (14): d(µ, ν) = sup dk (µk , νk ). [sent-561, score-0.447]
</p><p>76 Deﬁnition 16 (total variation) For time-series distributions ν, µ the total variation distance between them is deﬁned as Dtv (µ, ν) := supA∈F |µ(A) − ν(A)|. [sent-563, score-0.267]
</p><p>77 However, the total variation distance is not very useful for time-series distributions for the following two reasons. [sent-565, score-0.267]
</p><p>78 First of all, for stationary ergodic distributions it is degenerate: Dtv (µ, ν) = 1 if and only if µ = ν. [sent-566, score-0.572]
</p><p>79 This follows from the fact that any two different stationary ergodic distributions are singular. [sent-567, score-0.572]
</p><p>80 Such a distance could still be useful as a formalization of the problem of homogeneity testing. [sent-568, score-0.289]
</p><p>81 However, the problem of homogeneity testing is impossible to solve based on sampling for stationary ergodic distributions (and even for a smaller family of B processes, see below) (Ryabko, 2010b), so the use of this distance remains limited to more restrictive classes of distributions. [sent-569, score-0.89]
</p><p>82 Considering a growing (with t) number of marginals for the estimate may be a route to take, but this turns out to be difﬁcult to analyse, especially if no rates of convergence can be established for the set of time-series distributions at hand. [sent-573, score-0.18]
</p><p>83 For two time-series distributions µ and ν deﬁne k  1 ¯ d(µ, ν) := sup inf ∑ E p δ(xi , yi ), k∈N k p∈P i=1 where P is the set of all distributions over X k × X k generating a pair of sequences x1. [sent-576, score-0.329]
</p><p>84 ¯ A process is called a B-process (or a Bernoulli process) if it is in the d-closure of the set of all ¯ aperiodic stationary ergodic k-step Markov processes, where k ∈ N. [sent-581, score-0.454]
</p><p>85 The set of B-processes is a strict subset of the set of all stationary ergodic time-series distributions. [sent-583, score-0.484]
</p><p>86 n ) there is a pair of stationary ergodic processes µ and ν such that estimator d(X ˆ ¯ lim supn→∞ |d(X1. [sent-603, score-0.475]
</p><p>87 3 Comparison with the Distributional Distance In this section we show that the telescope distance is stronger than the distributional distance in the topological sense. [sent-609, score-0.697]
</p><p>88 Since in fact both the telescope distance and the distributional distance are families of distances (the telescope distance depends on the sequence H), we will ﬁx a simple natural choice of each of these metrics. [sent-610, score-1.105]
</p><p>89 For the distributional distance (Deﬁnition 15), set Bk,l to be the partition of the set X k into kdimensional cubes with volume hk = (1/l)k . [sent-615, score-0.509]
</p><p>90 Denote D0 the distributional distance Ddd with this l dd set of parameters. [sent-616, score-0.288]
</p><p>91 Note that for the distributional distance, if we use the same sets Bk to generate the sigma algebras X k then the distance deﬁned by (15) is stronger than the distance deﬁned by (16). [sent-619, score-0.41]
</p><p>92 4  RYABKO AND M ARY  0  200  400  600  800  1000  1200  Time of observation  Figure 1: Error of two-class clustering using TSSVM ; 10 time series in each target cluster, averaged over 20 runs. [sent-646, score-0.181]
</p><p>93 The average-linkage clustering is used, with the telescope distance between samples calculated using an SVM, as described in Section 4. [sent-649, score-0.556]
</p><p>94 The parameters wk in the deﬁnition of the telescope distance (Deﬁnition 2) are set to wk := k−2 . [sent-651, score-0.633]
</p><p>95 1 Synthetic Data For the artiﬁcial setting we chose highly-dependent time-series distributions which have the same single-dimensional marginals and which cannot be well approximated by ﬁnite- or countable-state models. [sent-653, score-0.18]
</p><p>96 Variants of this family of distributions are standard examples in ergodic theory and dynamical systems (see, for example, Billingsley, 1965; Gray, 1988; Shields, 1996). [sent-654, score-0.424]
</p><p>97 The latter is of particular interest since the classiﬁcation method we used in the telescope distance is also SVM, but our setting is unsupervised (clustering). [sent-700, score-0.413]
</p><p>98 On this data set the telescope distance demonstrates better performance than the comparison methods, which indicates that it can be useful in real-world scenarios. [sent-701, score-0.413]
</p><p>99 For example, some change-point problems for stationary ergodic time series can be solved using the distributional distance (Ryabko and Ryabko, 2010; Khaleghi and Ryabko, 2012, 2013). [sent-712, score-0.744]
</p><p>100 It remains to see whether the same results can be obtained with the telescope distance and its generalizations. [sent-713, score-0.413]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ryabko', 0.522), ('dh', 0.384), ('ergodic', 0.306), ('telescope', 0.287), ('hk', 0.238), ('homogeneity', 0.163), ('stationary', 0.148), ('ary', 0.137), ('distance', 0.126), ('khaleghi', 0.124), ('distributions', 0.118), ('distributional', 0.113), ('ighly', 0.112), ('rom', 0.112), ('wk', 0.11), ('clustering', 0.105), ('ependent', 0.096), ('eries', 0.086), ('ime', 0.08), ('roblems', 0.074), ('fk', 0.071), ('mixing', 0.07), ('lassification', 0.067), ('dk', 0.065), ('vc', 0.064), ('marginals', 0.062), ('shields', 0.05), ('tssvm', 0.05), ('xnn', 0.05), ('dd', 0.049), ('classi', 0.048), ('metric', 0.047), ('stronger', 0.045), ('summands', 0.044), ('clusters', 0.043), ('supa', 0.043), ('suph', 0.043), ('timeseries', 0.043), ('asymptotically', 0.042), ('distances', 0.04), ('mini', 0.039), ('halfspaces', 0.038), ('samples', 0.038), ('sup', 0.038), ('daniil', 0.037), ('ddd', 0.037), ('dtv', 0.037), ('karandikar', 0.037), ('ornstein', 0.037), ('gray', 0.036), ('balcan', 0.035), ('bci', 0.035), ('metrics', 0.035), ('ni', 0.034), ('adams', 0.033), ('sequences', 0.033), ('cubes', 0.032), ('harchaoui', 0.032), ('indicator', 0.031), ('consistent', 0.03), ('binary', 0.03), ('series', 0.03), ('strict', 0.03), ('testing', 0.029), ('farthest', 0.029), ('linkage', 0.029), ('wl', 0.029), ('wm', 0.029), ('statement', 0.028), ('ak', 0.027), ('generates', 0.027), ('analyse', 0.027), ('nobel', 0.027), ('summable', 0.027), ('consistency', 0.026), ('bk', 0.025), ('foot', 0.025), ('fortet', 0.025), ('kantorovich', 0.025), ('kcpa', 0.025), ('mie', 0.025), ('vidyasagar', 0.025), ('mary', 0.025), ('target', 0.025), ('separation', 0.024), ('qn', 0.024), ('cluster', 0.024), ('consistently', 0.024), ('variation', 0.023), ('generating', 0.022), ('measurable', 0.022), ('concerning', 0.022), ('marginal', 0.022), ('time', 0.021), ('declares', 0.021), ('dhk', 0.021), ('mill', 0.021), ('sakoe', 0.021), ('dependent', 0.021), ('processes', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="2-tfidf-1" href="./jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems.html">2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</a></p>
<p>Author: Daniil Ryabko, Jérémie Mary</p><p>Abstract: A metric between time-series distributions is proposed that can be evaluated using binary classiﬁcation methods, which were originally developed to work on i.i.d. data. It is shown how this metric can be used for solving statistical problems that are seemingly unrelated to classiﬁcation and concern highly dependent time series. Speciﬁcally, the problems of time-series clustering, homogeneity testing and the three-sample problem are addressed. Universal consistency of the resulting algorithms is proven under most general assumptions. The theoretical results are illustrated with experiments on synthetic and real-world data. Keywords: time series, reductions, stationary ergodic, clustering, metrics between probability distributions</p><p>2 0.097813509 <a title="2-tfidf-2" href="./jmlr-2013-Maximum_Volume_Clustering%3A_A_New_Discriminative_Clustering_Approach.html">70 jmlr-2013-Maximum Volume Clustering: A New Discriminative Clustering Approach</a></p>
<p>Author: Gang Niu, Bo Dai, Lin Shang, Masashi Sugiyama</p><p>Abstract: The large volume principle proposed by Vladimir Vapnik, which advocates that hypotheses lying in an equivalence class with a larger volume are more preferable, is a useful alternative to the large margin principle. In this paper, we introduce a new discriminative clustering model based on the large volume principle called maximum volume clustering (MVC), and then propose two approximation schemes to solve this MVC model: A soft-label MVC method using sequential quadratic programming and a hard-label MVC method using semi-deﬁnite programming, respectively. The proposed MVC is theoretically advantageous for three reasons. The optimization involved in hardlabel MVC is convex, and under mild conditions, the optimization involved in soft-label MVC is akin to a convex one in terms of the resulting clusters. Secondly, the soft-label MVC method pos∗. A preliminary and shorter version has appeared in Proceedings of 14th International Conference on Artiﬁcial Intelligence and Statistics (Niu et al., 2011). The preliminary work was done when GN was studying at Department of Computer Science and Technology, Nanjing University, and BD was studying at Institute of Automation, Chinese Academy of Sciences. A Matlab implementation of maximum volume clustering is available from http://sugiyama-www.cs.titech.ac.jp/∼gang/software.html. c 2013 Gang Niu, Bo Dai, Lin Shang and Masashi Sugiyama. N IU , DAI , S HANG AND S UGIYAMA sesses a clustering error bound. Thirdly, MVC includes the optimization problems of a spectral clustering, two relaxed k-means clustering and an information-maximization clustering as special limit cases when its regularization parameter goes to inﬁnity. Experiments on several artiﬁcial and benchmark data sets demonstrate that the proposed MVC compares favorably with state-of-the-art clustering methods. Keywords: discriminative clustering, large volume principle, sequential quadratic programming, semi-deﬁnite programming, ﬁnite sample stability, clustering error</p><p>3 0.040727943 <a title="2-tfidf-3" href="./jmlr-2013-Conjugate_Relation_between_Loss_Functions_and_Uncertainty_Sets_in_Classification_Problems.html">26 jmlr-2013-Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems</a></p>
<p>Author: Takafumi Kanamori, Akiko Takeda, Taiji Suzuki</p><p>Abstract: There are two main approaches to binary classiÄ?Ĺš cation problems: the loss function approach and the uncertainty set approach. The loss function approach is widely used in real-world data analysis. Statistical decision theory has been used to elucidate its properties such as statistical consistency. Conditional probabilities can also be estimated by using the minimum solution of the loss function. In the uncertainty set approach, an uncertainty set is deÄ?Ĺš ned for each binary label from training samples. The best separating hyperplane between the two uncertainty sets is used as the decision function. Although the uncertainty set approach provides an intuitive understanding of learning algorithms, its statistical properties have not been sufÄ?Ĺš ciently studied. In this paper, we show that the uncertainty set is deeply connected with the convex conjugate of a loss function. On the basis of the conjugate relation, we propose a way of revising the uncertainty set approach so that it will have good statistical properties such as statistical consistency. We also introduce statistical models corresponding to uncertainty sets in order to estimate conditional probabilities. Finally, we present numerical experiments, verifying that the learning with revised uncertainty sets improves the prediction accuracy. Keywords: loss function, uncertainty set, convex conjugate, consistency</p><p>4 0.04067741 <a title="2-tfidf-4" href="./jmlr-2013-Construction_of_Approximation_Spaces_for_Reinforcement_Learning.html">28 jmlr-2013-Construction of Approximation Spaces for Reinforcement Learning</a></p>
<p>Author: Wendelin Böhmer, Steffen Grünewälder, Yun Shen, Marek Musial, Klaus Obermayer</p><p>Abstract: Linear reinforcement learning (RL) algorithms like least-squares temporal difference learning (LSTD) require basis functions that span approximation spaces of potential value functions. This article investigates methods to construct these bases from samples. We hypothesize that an ideal approximation spaces should encode diffusion distances and that slow feature analysis (SFA) constructs such spaces. To validate our hypothesis we provide theoretical statements about the LSTD value approximation error and induced metric of approximation spaces constructed by SFA and the state-of-the-art methods Krylov bases and proto-value functions (PVF). In particular, we prove that SFA minimizes the average (over all tasks in the same environment) bound on the above approximation error. Compared to other methods, SFA is very sensitive to sampling and can sometimes fail to encode the whole state space. We derive a novel importance sampling modiﬁcation to compensate for this effect. Finally, the LSTD and least squares policy iteration (LSPI) performance of approximation spaces constructed by Krylov bases, PVF, SFA and PCA is compared in benchmark tasks and a visual robot navigation experiment (both in a realistic simulation and with a robot). The results support our hypothesis and suggest that (i) SFA provides subspace-invariant features for MDPs with self-adjoint transition operators, which allows strong guarantees on the approximation error, (ii) the modiﬁed SFA algorithm is best suited for LSPI in both discrete and continuous state spaces and (iii) approximation spaces encoding diffusion distances facilitate LSPI performance. Keywords: reinforcement learning, diffusion distance, proto value functions, slow feature analysis, least-squares policy iteration, visual robot navigation c 2013 Wendelin B¨ hmer, Steffen Gr¨ new¨ lder, Yun Shen, Marek Musial and Klaus Obermayer. o u a ¨ ¨ ¨ B OHMER , G R UNEW ALDER , S HEN , M USIAL AND O BERMAYER</p><p>5 0.040184595 <a title="2-tfidf-5" href="./jmlr-2013-Distribution-Dependent_Sample_Complexity_of_Large_Margin_Learning.html">35 jmlr-2013-Distribution-Dependent Sample Complexity of Large Margin Learning</a></p>
<p>Author: Sivan Sabato, Nathan Srebro, Naftali Tishby</p><p>Abstract: We obtain a tight distribution-speciﬁc characterization of the sample complexity of large-margin classiﬁcation with L2 regularization: We introduce the margin-adapted dimension, which is a simple function of the second order statistics of the data distribution, and show distribution-speciﬁc upper and lower bounds on the sample complexity, both governed by the margin-adapted dimension of the data distribution. The upper bounds are universal, and the lower bounds hold for the rich family of sub-Gaussian distributions with independent features. We conclude that this new quantity tightly characterizes the true sample complexity of large-margin classiﬁcation. To prove the lower bound, we develop several new tools of independent interest. These include new connections between shattering and hardness of learning, new properties of shattering with linear classiﬁers, and a new lower bound on the smallest eigenvalue of a random Gram matrix generated by sub-Gaussian variables. Our results can be used to quantitatively compare large margin learning to other learning rules, and to improve the effectiveness of methods that use sample complexity bounds, such as active learning. Keywords: supervised learning, sample complexity, linear classiﬁers, distribution-dependence</p><p>6 0.039976884 <a title="2-tfidf-6" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>7 0.039632104 <a title="2-tfidf-7" href="./jmlr-2013-Learning_Theory_Approach_to_Minimum_Error_Entropy_Criterion.html">62 jmlr-2013-Learning Theory Approach to Minimum Error Entropy Criterion</a></p>
<p>8 0.038656235 <a title="2-tfidf-8" href="./jmlr-2013-Lower_Bounds_and_Selectivity_of_Weak-Consistent_Policies_in_Stochastic_Multi-Armed_Bandit_Problem.html">65 jmlr-2013-Lower Bounds and Selectivity of Weak-Consistent Policies in Stochastic Multi-Armed Bandit Problem</a></p>
<p>9 0.033651415 <a title="2-tfidf-9" href="./jmlr-2013-Performance_Bounds_for_%CE%BB_Policy_Iteration_and_Application_to_the_Game_of_Tetris.html">87 jmlr-2013-Performance Bounds for λ Policy Iteration and Application to the Game of Tetris</a></p>
<p>10 0.032113116 <a title="2-tfidf-10" href="./jmlr-2013-A_Plug-in_Approach_to_Neyman-Pearson_Classification.html">6 jmlr-2013-A Plug-in Approach to Neyman-Pearson Classification</a></p>
<p>11 0.031737801 <a title="2-tfidf-11" href="./jmlr-2013-Cluster_Analysis%3A_Unsupervised_Learning_via_Supervised_Learning_with_a_Non-convex_Penalty.html">23 jmlr-2013-Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty</a></p>
<p>12 0.030296095 <a title="2-tfidf-12" href="./jmlr-2013-On_the_Convergence_of_Maximum_Variance_Unfolding.html">77 jmlr-2013-On the Convergence of Maximum Variance Unfolding</a></p>
<p>13 0.029571377 <a title="2-tfidf-13" href="./jmlr-2013-Stress_Functions_for_Nonlinear_Dimension_Reduction%2C_Proximity_Analysis%2C_and_Graph_Drawing.html">109 jmlr-2013-Stress Functions for Nonlinear Dimension Reduction, Proximity Analysis, and Graph Drawing</a></p>
<p>14 0.028597409 <a title="2-tfidf-14" href="./jmlr-2013-Risk_Bounds_of_Learning_Processes_for_L%C3%A9vy_Processes.html">97 jmlr-2013-Risk Bounds of Learning Processes for Lévy Processes</a></p>
<p>15 0.028335273 <a title="2-tfidf-15" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>16 0.027948158 <a title="2-tfidf-16" href="./jmlr-2013-Distributions_of_Angles_in_Random_Packing_on_Spheres.html">36 jmlr-2013-Distributions of Angles in Random Packing on Spheres</a></p>
<p>17 0.025835032 <a title="2-tfidf-17" href="./jmlr-2013-Training_Energy-Based_Models_for_Time-Series_Imputation.html">115 jmlr-2013-Training Energy-Based Models for Time-Series Imputation</a></p>
<p>18 0.025442641 <a title="2-tfidf-18" href="./jmlr-2013-How_to_Solve_Classification_and_Regression_Problems_on_High-Dimensional_Data_with_a_Supervised_Extension_of_Slow_Feature_Analysis.html">52 jmlr-2013-How to Solve Classification and Regression Problems on High-Dimensional Data with a Supervised Extension of Slow Feature Analysis</a></p>
<p>19 0.02498354 <a title="2-tfidf-19" href="./jmlr-2013-Random_Walk_Kernels_and_Learning_Curves_for_Gaussian_Process_Regression_on_Random_Graphs.html">93 jmlr-2013-Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs</a></p>
<p>20 0.024851479 <a title="2-tfidf-20" href="./jmlr-2013-Similarity-based_Clustering_by_Left-Stochastic_Matrix_Factorization.html">100 jmlr-2013-Similarity-based Clustering by Left-Stochastic Matrix Factorization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.144), (1, 0.035), (2, -0.001), (3, 0.028), (4, -0.022), (5, -0.019), (6, -0.058), (7, 0.0), (8, 0.038), (9, -0.088), (10, 0.047), (11, -0.063), (12, 0.047), (13, 0.014), (14, -0.08), (15, 0.071), (16, 0.037), (17, -0.071), (18, -0.19), (19, 0.15), (20, -0.123), (21, 0.221), (22, -0.041), (23, -0.087), (24, -0.1), (25, 0.051), (26, 0.073), (27, -0.09), (28, 0.083), (29, 0.003), (30, -0.057), (31, -0.168), (32, 0.01), (33, 0.095), (34, 0.245), (35, -0.06), (36, 0.008), (37, 0.009), (38, 0.015), (39, 0.125), (40, 0.199), (41, -0.176), (42, 0.085), (43, -0.049), (44, 0.07), (45, -0.092), (46, 0.062), (47, 0.143), (48, -0.124), (49, -0.109)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94310522 <a title="2-lsi-1" href="./jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems.html">2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</a></p>
<p>Author: Daniil Ryabko, Jérémie Mary</p><p>Abstract: A metric between time-series distributions is proposed that can be evaluated using binary classiﬁcation methods, which were originally developed to work on i.i.d. data. It is shown how this metric can be used for solving statistical problems that are seemingly unrelated to classiﬁcation and concern highly dependent time series. Speciﬁcally, the problems of time-series clustering, homogeneity testing and the three-sample problem are addressed. Universal consistency of the resulting algorithms is proven under most general assumptions. The theoretical results are illustrated with experiments on synthetic and real-world data. Keywords: time series, reductions, stationary ergodic, clustering, metrics between probability distributions</p><p>2 0.63367099 <a title="2-lsi-2" href="./jmlr-2013-Maximum_Volume_Clustering%3A_A_New_Discriminative_Clustering_Approach.html">70 jmlr-2013-Maximum Volume Clustering: A New Discriminative Clustering Approach</a></p>
<p>Author: Gang Niu, Bo Dai, Lin Shang, Masashi Sugiyama</p><p>Abstract: The large volume principle proposed by Vladimir Vapnik, which advocates that hypotheses lying in an equivalence class with a larger volume are more preferable, is a useful alternative to the large margin principle. In this paper, we introduce a new discriminative clustering model based on the large volume principle called maximum volume clustering (MVC), and then propose two approximation schemes to solve this MVC model: A soft-label MVC method using sequential quadratic programming and a hard-label MVC method using semi-deﬁnite programming, respectively. The proposed MVC is theoretically advantageous for three reasons. The optimization involved in hardlabel MVC is convex, and under mild conditions, the optimization involved in soft-label MVC is akin to a convex one in terms of the resulting clusters. Secondly, the soft-label MVC method pos∗. A preliminary and shorter version has appeared in Proceedings of 14th International Conference on Artiﬁcial Intelligence and Statistics (Niu et al., 2011). The preliminary work was done when GN was studying at Department of Computer Science and Technology, Nanjing University, and BD was studying at Institute of Automation, Chinese Academy of Sciences. A Matlab implementation of maximum volume clustering is available from http://sugiyama-www.cs.titech.ac.jp/∼gang/software.html. c 2013 Gang Niu, Bo Dai, Lin Shang and Masashi Sugiyama. N IU , DAI , S HANG AND S UGIYAMA sesses a clustering error bound. Thirdly, MVC includes the optimization problems of a spectral clustering, two relaxed k-means clustering and an information-maximization clustering as special limit cases when its regularization parameter goes to inﬁnity. Experiments on several artiﬁcial and benchmark data sets demonstrate that the proposed MVC compares favorably with state-of-the-art clustering methods. Keywords: discriminative clustering, large volume principle, sequential quadratic programming, semi-deﬁnite programming, ﬁnite sample stability, clustering error</p><p>3 0.36566013 <a title="2-lsi-3" href="./jmlr-2013-Similarity-based_Clustering_by_Left-Stochastic_Matrix_Factorization.html">100 jmlr-2013-Similarity-based Clustering by Left-Stochastic Matrix Factorization</a></p>
<p>Author: Raman Arora, Maya R. Gupta, Amol Kapila, Maryam Fazel</p><p>Abstract: For similarity-based clustering, we propose modeling the entries of a given similarity matrix as the inner products of the unknown cluster probabilities. To estimate the cluster probabilities from the given similarity matrix, we introduce a left-stochastic non-negative matrix factorization problem. A rotation-based algorithm is proposed for the matrix factorization. Conditions for unique matrix factorizations and clusterings are given, and an error bound is provided. The algorithm is particularly efﬁcient for the case of two clusters, which motivates a hierarchical variant for cases where the number of desired clusters is large. Experiments show that the proposed left-stochastic decomposition clustering model produces relatively high within-cluster similarity on most data sets and can match given class labels, and that the efﬁcient hierarchical variant performs surprisingly well. Keywords: clustering, non-negative matrix factorization, rotation, indeﬁnite kernel, similarity, completely positive</p><p>4 0.3525207 <a title="2-lsi-4" href="./jmlr-2013-Learning_Theory_Approach_to_Minimum_Error_Entropy_Criterion.html">62 jmlr-2013-Learning Theory Approach to Minimum Error Entropy Criterion</a></p>
<p>Author: Ting Hu, Jun Fan, Qiang Wu, Ding-Xuan Zhou</p><p>Abstract: We consider the minimum error entropy (MEE) criterion and an empirical risk minimization learning algorithm when an approximation of R´ nyi’s entropy (of order 2) by Parzen windowing is e minimized. This learning algorithm involves a Parzen windowing scaling parameter. We present a learning theory approach for this MEE algorithm in a regression setting when the scaling parameter is large. Consistency and explicit convergence rates are provided in terms of the approximation ability and capacity of the involved hypothesis space. Novel analysis is carried out for the generalization error associated with R´ nyi’s entropy and a Parzen windowing function, to overcome e technical difﬁculties arising from the essential differences between the classical least squares problems and the MEE setting. An involved symmetrized least squares error is introduced and analyzed, which is related to some ranking algorithms. Keywords: minimum error entropy, learning theory, R´ nyi’s entropy, empirical risk minimization, e approximation error</p><p>5 0.3016201 <a title="2-lsi-5" href="./jmlr-2013-Stress_Functions_for_Nonlinear_Dimension_Reduction%2C_Proximity_Analysis%2C_and_Graph_Drawing.html">109 jmlr-2013-Stress Functions for Nonlinear Dimension Reduction, Proximity Analysis, and Graph Drawing</a></p>
<p>Author: Lisha Chen, Andreas Buja</p><p>Abstract: Multidimensional scaling (MDS) is the art of reconstructing pointsets (embeddings) from pairwise distance data, and as such it is at the basis of several approaches to nonlinear dimension reduction and manifold learning. At present, MDS lacks a unifying methodology as it consists of a discrete collection of proposals that differ in their optimization criteria, called “stress functions”. To correct this situation we propose (1) to embed many of the extant stress functions in a parametric family of stress functions, and (2) to replace the ad hoc choice among discrete proposals with a principled parameter selection method. This methodology yields the following beneﬁts and problem solutions: (a) It provides guidance in tailoring stress functions to a given data situation, responding to the fact that no single stress function dominates all others across all data situations; (b) the methodology enriches the supply of available stress functions; (c) it helps our understanding of stress functions by replacing the comparison of discrete proposals with a characterization of the effect of parameters on embeddings; (d) it builds a bridge to graph drawing, which is the related but not identical art of constructing embeddings from graphs. Keywords: multidimensional scaling, force-directed layout, cluster analysis, clustering strength, unsupervised learning, Box-Cox transformations</p><p>6 0.27661684 <a title="2-lsi-6" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>7 0.27278262 <a title="2-lsi-7" href="./jmlr-2013-Cluster_Analysis%3A_Unsupervised_Learning_via_Supervised_Learning_with_a_Non-convex_Penalty.html">23 jmlr-2013-Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty</a></p>
<p>8 0.25361997 <a title="2-lsi-8" href="./jmlr-2013-A_Plug-in_Approach_to_Neyman-Pearson_Classification.html">6 jmlr-2013-A Plug-in Approach to Neyman-Pearson Classification</a></p>
<p>9 0.25119901 <a title="2-lsi-9" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>10 0.23975419 <a title="2-lsi-10" href="./jmlr-2013-Training_Energy-Based_Models_for_Time-Series_Imputation.html">115 jmlr-2013-Training Energy-Based Models for Time-Series Imputation</a></p>
<p>11 0.2383956 <a title="2-lsi-11" href="./jmlr-2013-Perturbative_Corrections_for_Approximate_Inference_in_Gaussian_Latent_Variable_Models.html">88 jmlr-2013-Perturbative Corrections for Approximate Inference in Gaussian Latent Variable Models</a></p>
<p>12 0.23702683 <a title="2-lsi-12" href="./jmlr-2013-On_the_Convergence_of_Maximum_Variance_Unfolding.html">77 jmlr-2013-On the Convergence of Maximum Variance Unfolding</a></p>
<p>13 0.22497398 <a title="2-lsi-13" href="./jmlr-2013-Distributions_of_Angles_in_Random_Packing_on_Spheres.html">36 jmlr-2013-Distributions of Angles in Random Packing on Spheres</a></p>
<p>14 0.2185338 <a title="2-lsi-14" href="./jmlr-2013-Distribution-Dependent_Sample_Complexity_of_Large_Margin_Learning.html">35 jmlr-2013-Distribution-Dependent Sample Complexity of Large Margin Learning</a></p>
<p>15 0.19452095 <a title="2-lsi-15" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>16 0.1933859 <a title="2-lsi-16" href="./jmlr-2013-Algorithms_for_Discovery_of_Multiple_Markov_Boundaries.html">11 jmlr-2013-Algorithms for Discovery of Multiple Markov Boundaries</a></p>
<p>17 0.19207686 <a title="2-lsi-17" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>18 0.19122447 <a title="2-lsi-18" href="./jmlr-2013-Risk_Bounds_of_Learning_Processes_for_L%C3%A9vy_Processes.html">97 jmlr-2013-Risk Bounds of Learning Processes for Lévy Processes</a></p>
<p>19 0.18381022 <a title="2-lsi-19" href="./jmlr-2013-Construction_of_Approximation_Spaces_for_Reinforcement_Learning.html">28 jmlr-2013-Construction of Approximation Spaces for Reinforcement Learning</a></p>
<p>20 0.18329021 <a title="2-lsi-20" href="./jmlr-2013-Efficient_Active_Learning_of_Halfspaces%3A_An_Aggressive_Approach.html">39 jmlr-2013-Efficient Active Learning of Halfspaces: An Aggressive Approach</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.02), (5, 0.143), (6, 0.049), (10, 0.078), (20, 0.019), (23, 0.046), (60, 0.344), (68, 0.027), (70, 0.049), (75, 0.051), (85, 0.039), (87, 0.018), (89, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6987468 <a title="2-lda-1" href="./jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems.html">2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</a></p>
<p>Author: Daniil Ryabko, Jérémie Mary</p><p>Abstract: A metric between time-series distributions is proposed that can be evaluated using binary classiﬁcation methods, which were originally developed to work on i.i.d. data. It is shown how this metric can be used for solving statistical problems that are seemingly unrelated to classiﬁcation and concern highly dependent time series. Speciﬁcally, the problems of time-series clustering, homogeneity testing and the three-sample problem are addressed. Universal consistency of the resulting algorithms is proven under most general assumptions. The theoretical results are illustrated with experiments on synthetic and real-world data. Keywords: time series, reductions, stationary ergodic, clustering, metrics between probability distributions</p><p>2 0.48130485 <a title="2-lda-2" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>Author: Yuchen Zhang, John C. Duchi, Martin J. Wainwright</p><p>Abstract: We analyze two communication-efﬁcient algorithms for distributed optimization in statistical settings involving large-scale data sets. The ﬁrst algorithm is a standard averaging method that distributes the N data samples evenly to m machines, performs separate minimization on each subset, and then averages the estimates. We provide a sharp analysis of this average mixture algorithm, showing that under a reasonable set of conditions, the combined parameter achieves √ mean-squared error (MSE) that decays as O (N −1 + (N/m)−2 ). Whenever m ≤ N, this guarantee matches the best possible rate achievable by a centralized algorithm having access to all N samples. The second algorithm is a novel method, based on an appropriate form of bootstrap subsampling. Requiring only a single round of communication, it has mean-squared error that decays as O (N −1 + (N/m)−3 ), and so is more robust to the amount of parallelization. In addition, we show that a stochastic gradient-based method attains mean-squared error decaying as O (N −1 + (N/m)−3/2 ), easing computation at the expense of a potentially slower MSE rate. We also provide an experimental evaluation of our methods, investigating their performance both on simulated data and on a large-scale regression problem from the internet search domain. In particular, we show that our methods can be used to efﬁciently solve an advertisement prediction problem from the Chinese SoSo Search Engine, which involves logistic regression with N ≈ 2.4 × 108 samples and d ≈ 740,000 covariates. Keywords: distributed learning, stochastic optimization, averaging, subsampling</p><p>3 0.47131175 <a title="2-lda-3" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>Author: Tony Cai, Wen-Xin Zhou</p><p>Abstract: We consider in this paper the problem of noisy 1-bit matrix completion under a general non-uniform sampling distribution using the max-norm as a convex relaxation for the rank. A max-norm constrained maximum likelihood estimate is introduced and studied. The rate of convergence for the estimate is obtained. Information-theoretical methods are used to establish a minimax lower bound under the general sampling model. The minimax upper and lower bounds together yield the optimal rate of convergence for the Frobenius norm loss. Computational algorithms and numerical performance are also discussed. Keywords: 1-bit matrix completion, low-rank matrix, max-norm, trace-norm, constrained optimization, maximum likelihood estimate, optimal rate of convergence</p><p>4 0.46970296 <a title="2-lda-4" href="./jmlr-2013-Conjugate_Relation_between_Loss_Functions_and_Uncertainty_Sets_in_Classification_Problems.html">26 jmlr-2013-Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems</a></p>
<p>Author: Takafumi Kanamori, Akiko Takeda, Taiji Suzuki</p><p>Abstract: There are two main approaches to binary classiÄ?Ĺš cation problems: the loss function approach and the uncertainty set approach. The loss function approach is widely used in real-world data analysis. Statistical decision theory has been used to elucidate its properties such as statistical consistency. Conditional probabilities can also be estimated by using the minimum solution of the loss function. In the uncertainty set approach, an uncertainty set is deÄ?Ĺš ned for each binary label from training samples. The best separating hyperplane between the two uncertainty sets is used as the decision function. Although the uncertainty set approach provides an intuitive understanding of learning algorithms, its statistical properties have not been sufÄ?Ĺš ciently studied. In this paper, we show that the uncertainty set is deeply connected with the convex conjugate of a loss function. On the basis of the conjugate relation, we propose a way of revising the uncertainty set approach so that it will have good statistical properties such as statistical consistency. We also introduce statistical models corresponding to uncertainty sets in order to estimate conditional probabilities. Finally, we present numerical experiments, verifying that the learning with revised uncertainty sets improves the prediction accuracy. Keywords: loss function, uncertainty set, convex conjugate, consistency</p><p>5 0.46795961 <a title="2-lda-5" href="./jmlr-2013-Belief_Propagation_for_Continuous_State_Spaces%3A_Stochastic_Message-Passing_with_Quantitative_Guarantees.html">17 jmlr-2013-Belief Propagation for Continuous State Spaces: Stochastic Message-Passing with Quantitative Guarantees</a></p>
<p>Author: Nima Noorshams, Martin J. Wainwright</p><p>Abstract: The sum-product or belief propagation (BP) algorithm is a widely used message-passing technique for computing approximate marginals in graphical models. We introduce a new technique, called stochastic orthogonal series message-passing (SOSMP), for computing the BP ﬁxed point in models with continuous random variables. It is based on a deterministic approximation of the messages via orthogonal series basis expansion, and a stochastic estimation of the basis coefﬁcients via Monte Carlo techniques and damped updates. We prove that the SOSMP iterates converge to a δ-neighborhood of the unique BP ﬁxed point for any tree-structured graph, and for any graphs with cycles in which the BP updates satisfy a contractivity condition. In addition, we demonstrate how to choose the number of basis coefﬁcients as a function of the desired approximation accuracy δ and smoothness of the compatibility functions. We illustrate our theory with both simulated examples and in application to optical ﬂow estimation. Keywords: graphical models, sum-product for continuous state spaces, low-complexity belief propagation, stochastic approximation, Monte Carlo methods, orthogonal basis expansion</p><p>6 0.46793312 <a title="2-lda-6" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>7 0.46746132 <a title="2-lda-7" href="./jmlr-2013-Construction_of_Approximation_Spaces_for_Reinforcement_Learning.html">28 jmlr-2013-Construction of Approximation Spaces for Reinforcement Learning</a></p>
<p>8 0.4673484 <a title="2-lda-8" href="./jmlr-2013-How_to_Solve_Classification_and_Regression_Problems_on_High-Dimensional_Data_with_a_Supervised_Extension_of_Slow_Feature_Analysis.html">52 jmlr-2013-How to Solve Classification and Regression Problems on High-Dimensional Data with a Supervised Extension of Slow Feature Analysis</a></p>
<p>9 0.46588752 <a title="2-lda-9" href="./jmlr-2013-Generalized_Spike-and-Slab_Priors_for_Bayesian_Group_Feature_Selection_Using_Expectation_Propagation.html">48 jmlr-2013-Generalized Spike-and-Slab Priors for Bayesian Group Feature Selection Using Expectation Propagation</a></p>
<p>10 0.46479267 <a title="2-lda-10" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>11 0.46258339 <a title="2-lda-11" href="./jmlr-2013-Sparse_Matrix_Inversion_with_Scaled_Lasso.html">102 jmlr-2013-Sparse Matrix Inversion with Scaled Lasso</a></p>
<p>12 0.46066222 <a title="2-lda-12" href="./jmlr-2013-Machine_Learning_with_Operational_Costs.html">68 jmlr-2013-Machine Learning with Operational Costs</a></p>
<p>13 0.46058142 <a title="2-lda-13" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>14 0.45994976 <a title="2-lda-14" href="./jmlr-2013-Algorithms_and_Hardness_Results_for_Parallel_Large_Margin_Learning.html">10 jmlr-2013-Algorithms and Hardness Results for Parallel Large Margin Learning</a></p>
<p>15 0.45948926 <a title="2-lda-15" href="./jmlr-2013-Efficient_Active_Learning_of_Halfspaces%3A_An_Aggressive_Approach.html">39 jmlr-2013-Efficient Active Learning of Halfspaces: An Aggressive Approach</a></p>
<p>16 0.45800358 <a title="2-lda-16" href="./jmlr-2013-Semi-Supervised_Learning_Using_Greedy_Max-Cut.html">99 jmlr-2013-Semi-Supervised Learning Using Greedy Max-Cut</a></p>
<p>17 0.45732698 <a title="2-lda-17" href="./jmlr-2013-A_Near-Optimal_Algorithm_for_Differentially-Private_Principal_Components.html">5 jmlr-2013-A Near-Optimal Algorithm for Differentially-Private Principal Components</a></p>
<p>18 0.45728123 <a title="2-lda-18" href="./jmlr-2013-A_Widely_Applicable_Bayesian_Information_Criterion.html">9 jmlr-2013-A Widely Applicable Bayesian Information Criterion</a></p>
<p>19 0.45684642 <a title="2-lda-19" href="./jmlr-2013-Asymptotic_Results_on_Adaptive_False_Discovery_Rate_Controlling_Procedures_Based_on_Kernel_Estimators.html">14 jmlr-2013-Asymptotic Results on Adaptive False Discovery Rate Controlling Procedures Based on Kernel Estimators</a></p>
<p>20 0.456801 <a title="2-lda-20" href="./jmlr-2013-Beyond_Fano%27s_Inequality%3A_Bounds_on_the_Optimal_F-Score%2C_BER%2C_and_Cost-Sensitive_Risk_and_Their_Implications.html">18 jmlr-2013-Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
