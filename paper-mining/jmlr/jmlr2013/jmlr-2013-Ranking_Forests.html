<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>95 jmlr-2013-Ranking Forests</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2013" href="../home/jmlr2013_home.html">jmlr2013</a> <a title="jmlr-2013-95" href="#">jmlr2013-95</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>95 jmlr-2013-Ranking Forests</h1>
<br/><p>Source: <a title="jmlr-2013-95-pdf" href="http://jmlr.org/papers/volume14/clemencon13a/clemencon13a.pdf">pdf</a></p><p>Author: Stéphan Clémençon, Marine Depecker, Nicolas Vayatis</p><p>Abstract: The present paper examines how the aggregation and feature randomization principles underlying the algorithm R ANDOM F OREST (Breiman, 2001) can be adapted to bipartite ranking. The approach taken here is based on nonparametric scoring and ROC curve optimization in the sense of the AUC criterion. In this problem, aggregation is used to increase the performance of scoring rules produced by ranking trees, as those developed in Cl´ mencon and Vayatis (2009c). The present work e ¸ describes the principles for building median scoring rules based on concepts from rank aggregation. Consistency results are derived for these aggregated scoring rules and an algorithm called R ANK ING F OREST is presented. Furthermore, various strategies for feature randomization are explored through a series of numerical experiments on artiﬁcial data sets. Keywords: bipartite ranking, nonparametric scoring, classiﬁcation data, ROC optimization, AUC criterion, tree-based ranking rules, bootstrap, bagging, rank aggregation, median ranking, feature randomization</p><p>Reference: <a title="jmlr-2013-95-reference" href="../jmlr2013_reference/jmlr-2013-Ranking_Forests_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Journal of Machine Learning Research 14 (2013) 39-73  Submitted 12/10; Revised 2/12; Published 1/13  Ranking Forests St´ phan Cl´ mencon e e ¸ Marine Depecker  STEPHAN . [sent-1, score-0.303]
</p><p>2 8536 ENS Cachan 61, avenue du Pr´ sident Wilson, Cachan, 94230, France e  Editor: Tong Zhang  Abstract The present paper examines how the aggregation and feature randomization principles underlying the algorithm R ANDOM F OREST (Breiman, 2001) can be adapted to bipartite ranking. [sent-9, score-0.355]
</p><p>3 The approach taken here is based on nonparametric scoring and ROC curve optimization in the sense of the AUC criterion. [sent-10, score-0.708]
</p><p>4 In this problem, aggregation is used to increase the performance of scoring rules produced by ranking trees, as those developed in Cl´ mencon and Vayatis (2009c). [sent-11, score-1.394]
</p><p>5 The present work e ¸ describes the principles for building median scoring rules based on concepts from rank aggregation. [sent-12, score-0.827]
</p><p>6 Consistency results are derived for these aggregated scoring rules and an algorithm called R ANK ING F OREST is presented. [sent-13, score-0.757]
</p><p>7 Keywords: bipartite ranking, nonparametric scoring, classiﬁcation data, ROC optimization, AUC criterion, tree-based ranking rules, bootstrap, bagging, rank aggregation, median ranking, feature randomization  1. [sent-15, score-0.472]
</p><p>8 Introduction Aggregating decision rules or function estimators has now become a folk concept in machine learning and nonparametric statistics. [sent-16, score-0.179]
</p><p>9 Indeed, the idea of combining decision rules with an additional randomization ingredient brings a dramatic improvement of performance in various contexts. [sent-17, score-0.208]
</p><p>10 In the present paper, we propose to take one step beyond in the program of boosting performance by aggregation and randomization for this problem. [sent-20, score-0.272]
</p><p>11 This case is also known as the bipartite ranking problem, see Freund et al. [sent-22, score-0.306]
</p><p>12 The setup of bipartite ranking is useful e ¸ when considering real-life applications such as credit-risk or medical screening, spam ﬁltering, or recommender systems. [sent-26, score-0.332]
</p><p>13 There are two major approaches to bipartite ranking: the preference-based approach (see Cohen et al. [sent-27, score-0.1]
</p><p>14 The idea of combining ranking c 2013 St´ phan Cl´ mencon, Marine Depecker and Nicolas Vayatis. [sent-31, score-0.244]
</p><p>15 e e ¸  ´ C L E MENC ON , D EPECKER AND VAYATIS ¸  rules to learn preferences was introduced in Freund et al. [sent-32, score-0.16]
</p><p>16 (2003) with a boosting algorithm and the consistency for this type of methods was proved in Cl´ mencon et al. [sent-33, score-0.282]
</p><p>17 (2008) by reducing the bipare ¸ tite ranking problem to a classiﬁcation problem over pairs of observations (see also Agarwal et al. [sent-34, score-0.206]
</p><p>18 Here, we will cast bipartite ranking in the context of nonparametric scoring and we will consider the issue of combining randomized scoring rules. [sent-36, score-1.534]
</p><p>19 Scoring rules are real-valued functions mapping the observation space with the real line, thus conveying an order relation between high dimensional observation vectors. [sent-37, score-0.162]
</p><p>20 Nonparametric scoring has received an increasing attention in the machine learning literature as a part of the growing interest which affects ROC analysis. [sent-38, score-0.588]
</p><p>21 The scoring problem can be seen as a learning problem where one observes input observation vectors X in a high dimensional space X and receives only a binary feedback information through an output variable Y ∈ {−1, +1}. [sent-39, score-0.621]
</p><p>22 Whereas classiﬁcation only focuses on predicting the label Y of a new observation X, scoring algorithms aim at recovering an order relation on X in order to predict the ordering over a new sample of observation vectors X ′ 1 , . [sent-40, score-0.606]
</p><p>23 From a statistical perspective, the scoring problem is more difﬁcult than classiﬁcation but easier than regression. [sent-44, score-0.588]
</p><p>24 In previous work, we developed e ¸ a tree-based procedure for nonparametric scoring called T REE R ANK, see Cl´ mencon and Vayatis e ¸ (2009c), Cl´ mencon et al. [sent-46, score-1.153]
</p><p>25 The T REE R ANK algorithm and its variants produce scoring e ¸ rules expressed as partitions of the input space coupled with a permutation over the cells of the partition. [sent-48, score-0.836]
</p><p>26 These scoring rules present the interesting feature that they can be stored in an oriented binary tree structure, called a ranking tree. [sent-49, score-0.955]
</p><p>27 Moreover, their very construction actually implements the optimization of the ROC curve which reﬂects the quality measure of the scoring rule for the end-user. [sent-50, score-0.747]
</p><p>28 The use of resampling in this context was ﬁrst considered in Cl´ mencon et al. [sent-51, score-0.265]
</p><p>29 A more e ¸ thorough analysis is developed throughout this paper and we show how to combine feature randomization and bootstrap aggregation techniques based on the ranking trees produced by the T REE RANK algorithm in order to increase ranking performance in the sense of the ROC curve. [sent-53, score-0.686]
</p><p>30 In the classiﬁcation setup, theoretical evidence has been recently provided for the aggregation of randomized classiﬁers in the spirit of random forests (see Biau et al. [sent-54, score-0.237]
</p><p>31 However, in the context of ROC optimization, combining scoring rules through naive aggregation does not necessarily make sense. [sent-56, score-0.923]
</p><p>32 Our approach builds on the advances in the rank aggregation problem. [sent-57, score-0.238]
</p><p>33 Rank aggregation was originally introduced in social choice theory (see Barth´ l´ my and Montjardet 1981 and the referee ences therein) and recently “rediscovered” in the context of internet applications (see Pennock et al. [sent-58, score-0.243]
</p><p>34 For our needs, we shall focus on metric-based consensus methods (see Hudry 2004 or Fagin et al. [sent-60, score-0.107]
</p><p>35 2006, and the references therein), which provide the key to the aggregation of ranking trees. [sent-61, score-0.397]
</p><p>36 In the paper, we also discuss various aspects of feature randomization which can be incorporated at various levels in ranking trees. [sent-62, score-0.27]
</p><p>37 Also a novel ranking methodology, called R ANKING F OREST, is introduced. [sent-63, score-0.206]
</p><p>38 Section 2 sets out the notations and shortly describes the main notions for the bipartite ranking problem. [sent-65, score-0.306]
</p><p>39 Section 3 describes the elements from the theory of rank aggregation and measures of consensus leading to the aggregation of scoring rules deﬁned over ﬁnite partitions of the input space. [sent-66, score-1.276]
</p><p>40 The next section presents the main theoretical results of the paper 40  R ANKING F ORESTS  which are consistency results for scoring rules based on the aggregation of randomized piecewise constant scoring rules. [sent-67, score-1.624]
</p><p>41 Section 5 presents R ANKING F OREST, a new algorithm for nonparametric scoring which implements the theoretical concepts developed so far. [sent-68, score-0.667]
</p><p>42 Probabilistic Setup for Bipartite Ranking ROC analysis is a popular way of evaluating the capacity of a given scoring rule to discriminate between two populations, see Egan (1975). [sent-73, score-0.683]
</p><p>43 ROC curves and related performance measures such as the AUC have now become of standard use for assessing the quality of ranking methods in a bipartite framework. [sent-74, score-0.324]
</p><p>44 Throughout this section, we recall basic concepts related to bipartite ranking from the angle of ROC analysis. [sent-75, score-0.334]
</p><p>45 An informal way of considering the ranking task under this model is as follows. [sent-85, score-0.222]
</p><p>46 A natural way of deﬁning a total order on the multidimensional space X is to map it with the natural order on the real line by means of a scoring rule, that is, a measurable mapping s : X → R. [sent-90, score-0.588]
</p><p>47 The capacity of a candidate s to discriminate between the positive and negative populations is generally evaluated by means of its ROC curve (standing for “Receiver Operating Characteristic” curve), a widely used functional performance measure which we recall here. [sent-93, score-0.149]
</p><p>48 Deﬁnition 1 (T RUE ROC CURVE ) Let s be a scoring rule. [sent-94, score-0.588]
</p><p>49 The true ROC curve of s is the “probabilityprobability” plot given by: t ∈ R → (P {s(X) > t | Y = −1} , P {s(X) > t | Y = 1}) ∈ [0, 1]2 . [sent-95, score-0.085]
</p><p>50 By convention, when a jump occurs in the plot of the ROC curve, the corresponding extremities of the curve are connected by a line segment, so that the ROC curve of s can be viewed as the graph of a continuous mapping α ∈ [0, 1] → ROC(s, α). [sent-96, score-0.186]
</p><p>51 We refer to Cl´ mencon and Vayatis (2009c) for a list of properties of ROC curves (see the e ¸ Appendix section therein). [sent-97, score-0.265]
</p><p>52 The ROC curve offers a visual tool for assessing ranking performance (see Figure 1): the closer to the left upper corner of the unit square [0, 1]2 the curve ROC(s, . [sent-98, score-0.394]
</p><p>53 Therefore, the ROC curve conveys a partial order on the set of all 1. [sent-100, score-0.123]
</p><p>54 A preorder is a binary relation which is reﬂexive and transitive. [sent-101, score-0.092]
</p><p>55 scoring rules: for all pairs of scoring rules s1 and s2 , we say that s2 is more accurate than s1 when ROC(s1 , α) ≤ ROC(s2 , α) for all α ∈ [0, 1]. [sent-103, score-1.32]
</p><p>56 By a standard Neyman-Pearson argument, one may establish that the most accurate scoring rules are increasing transforms of the regression function which is equal to the conditional probability function η up to an afﬁne transformation. [sent-104, score-0.753]
</p><p>57 Deﬁnition 2 (O PTIMAL SCORING RULES ) We call optimal scoring rules the elements of the set S ∗ of scoring functions s∗ such that ∀(x, x′ ) ∈ X 2 , η(x) < η(x′ ) ⇒ s∗ (x) < s∗ (x′ ). [sent-105, score-1.32]
</p><p>58 The fact that the elements of S ∗ are optimizers of the ROC curve is shown in Cl´ mencon and e ¸ Vayatis (2009c) (see Proposition 4 therein). [sent-106, score-0.35]
</p><p>59 The performance of a candidate scoring rule s is often summarized by a scalar quantity called the Area Under the ROC Curve (AUC) which can be considered as a summary of the ROC curve. [sent-108, score-0.646]
</p><p>60 The AUC is the functional deﬁned as: AUC(s) = P{s(X1 ) < s(X2 ) | (Y1 , Y2 ) = (−1, +1)} 1 + P{s(X1 ) = s(X2 ) | (Y1 ,Y2 ) = (−1, +1)}, 2 where (X1 ,Y1 ) and (X2 ,Y2 ) denote two independent copies of the pair (X,Y ), for any scoring function s. [sent-111, score-0.588]
</p><p>61 This functional provides a total order on the set of scoring rules and, equipped with the convention introduced in Deﬁnition 1, AUC(s) coincides with 01 ROC(s, α) dα (see, for instance, Proposition 1 in Cl´ mencon et al. [sent-112, score-1.048]
</p><p>62 We shall denote the optimal curve and the corresponding (maxie ¸ mum) value for the AUC criterion by ROC∗ = ROC(s∗ , . [sent-114, score-0.127]
</p><p>63 In the paper, we will focus on a particular subclass of scoring rules. [sent-121, score-0.588]
</p><p>64 Deﬁnition 4 (P IECEWISE CONSTANT SCORING RULE ) A scoring rule s is piecewise constant if there exists a ﬁnite partition P of X such that for all C ∈ P , there exists a constant kC ∈ R such that ∀x ∈ C , s(x) = kC . [sent-122, score-0.769]
</p><p>65 The scoring rule conveys an ordering on the cells of the minimal partition. [sent-125, score-0.738]
</p><p>66 Deﬁnition 5 (R ANK OF A CELL ) Let s be a scoring rule and P the associated minimal partition. [sent-126, score-0.646]
</p><p>67 The scoring rule induces a ranking s over the cells of the partition. [sent-127, score-0.906]
</p><p>68 For a given cell C ∈ P , we deﬁne its rank R s (C ) ∈ {1, . [sent-128, score-0.068]
</p><p>69 , |P |} as the rank affected by the ranking s over the elements of the partition. [sent-131, score-0.253]
</p><p>70 The advantage of the class of piecewise constant scoring rules is that they provide ﬁnite rankings on the elements of X and they will be the key for applying the aggregation procedure. [sent-133, score-1.14]
</p><p>71 Aggregation of Scoring Rules In recent years, the issue of summarizing or aggregating various rankings has been a topic of growing interest in the machine-learning community. [sent-135, score-0.145]
</p><p>72 Such problems have led to a variety of results, ranging from the generalization of the mathematical concepts introduced in social choice theory (see Barth´ l´ my ee and Montjardet 1981 and the references therein) for deﬁning relevant notions of consensus between rankings (Fagin et al. [sent-142, score-0.23]
</p><p>73 , 2007) through the study of probabilistic models over sets of rankings (Fligner and Verducci , Eds. [sent-145, score-0.144]
</p><p>74 Here we consider rank aggregation methods in the perspective of extending the bagging approach to ranking trees. [sent-147, score-0.488]
</p><p>75 1 The Case of Piecewise Constant Scoring Rules The ranking rules considered in this paper result from the aggregation of a collection of piecewise constant scoring rules. [sent-149, score-1.262]
</p><p>76 Since each of these scoring rules is related to a possibly different partition, we are lead to consider a collection of partitions of X . [sent-150, score-0.819]
</p><p>77 Hence, the aggregated rule needs to be deﬁned on the least ﬁne subpartition of this collection of partitions. [sent-151, score-0.215]
</p><p>78 Deﬁnition 6 (S UBPARTITION OF A COLLECTION OF PARTITIONS ) Consider a collection of B partitions of X denoted by Pb , b = 1, . [sent-152, score-0.087]
</p><p>79 A subpartition of this collection is a partition PB made 43  ´ C L E MENC ON , D EPECKER AND VAYATIS ¸  of nonempty subsets C ⊂ X which satisfy the following constraint : for all C ∈ PB , there exists (C1 , . [sent-156, score-0.159]
</p><p>80 ∗ One may easily see that PB is a subpartition of any of the Pb ’s, and the largest one in the sense ∗ that any partition P which is a subpartition of Pb for all b ∈ {1, . [sent-161, score-0.217]
</p><p>81 The case where the partitions are obtained from a binary tree structure is of particular interest as we shall consider tree-based piecewise constant scoring rules later on. [sent-165, score-0.937]
</p><p>82 Now consider a collection of piecewise constant scoring rules sb , b = 1, . [sent-168, score-0.888]
</p><p>83 Each scoring rule sb naturally induces a ranking (or a pre∗ ∗2 order) ∗ on the partition PB . [sent-172, score-0.902]
</p><p>84 ∗ The collection of scoring rules leads to a collection of B rankings on PB . [sent-174, score-0.927]
</p><p>85 Whereas the mean, or the median, naturally provides such a summary when considering scalar data, various meanings can be given to this notion for rankings (see Appendix B). [sent-177, score-0.137]
</p><p>86 2 Probabilistic Measures of Scoring Agreement The purpose of this subsection is to extend the concept of measures of agreement for rankings to scoring rules deﬁned over a general space X which is not necessarily ﬁnite. [sent-179, score-0.876]
</p><p>87 In practice, however, we will only consider the case of piecewise constant scoring rules and we shall rely on the deﬁnition of the probabilistic Kendall tau. [sent-180, score-0.893]
</p><p>88 We already introduced the notation s for the preorder relation over the cells of a partition P as induced by a piecewise scoring rule s. [sent-182, score-0.914]
</p><p>89 We shall use the ’curly’ notation for the preorder relation s on X which is described through the following condition: ∀C , C ′ ∈ P , we have x s x′ , ∀x ∈ C , ∀x′ ∈ C ′ , if and only if C s C ′ . [sent-183, score-0.117]
</p><p>90 We now introduce a measure of similarity for preorders on X induced by scoring rules s1 and s2 . [sent-185, score-0.786]
</p><p>91 For any real-valued scoring rule s, we have: 1 1 (1 − τ(s(X),Y )) = 2p(1 − p) (1 − AUC(s)) + P{s(X) = s(X ′ ) , Y = Y ′ } . [sent-192, score-0.646]
</p><p>92 2 2 For given scoring rules s1 and s2 and considering the probabilistic Kendall tau for random variables s1 (X) and s2 (X), we can set: dX (s1 , s2 ) = dτ (s1 (X), s2 (X)). [sent-193, score-0.804]
</p><p>93 The following proposition shows that the deviation between scoring rules in terms of AUC is controlled by a quantity involving the probabilistic agreement based on Kendall tau. [sent-195, score-0.8]
</p><p>94 For any scoring rules s1 and s2 on X , we have: dX (s1 , s2 ) 1 − τX (s1 , s2 ) |AUC(s1 ) − AUC(s2 )| ≤ = . [sent-197, score-0.732]
</p><p>95 Indeed, scoring rules with same AUC may yield to different rankings. [sent-199, score-0.732]
</p><p>96 However, the following result guarantees that a scoring rule with a nearly optimal AUC is close to the optimal scoring rules in the sense of Kendall tau, under the additional assumption that the noise condition introduced in Cl´ mencon et al. [sent-200, score-1.643]
</p><p>97 (1)  Then, we have, for any scoring rule s and any optimal scoring rule s∗ ∈ S ∗ : 1 − τX (s∗ , s) ≤ C · (AUC∗ − AUC(s))a/(1+a) , with C = 3 · c1/(1+a) · (2p(1 − p))a/(1+a) . [sent-203, score-1.292]
</p><p>98 Indeed, it is fulﬁlled for any a ∈ (0, 1) as soon the probability density function of η(X) is bounded (see Corollary 8 in Cl´ mencon et al. [sent-205, score-0.265]
</p><p>99 e ¸ The next result shows the connection between the Kendall tau distance between preorders on X induced by piecewise constant scoring rules s1 and s2 and a speciﬁc notion of distance between the rankings s1 and s2 on P . [sent-207, score-1.052]
</p><p>100 Lemma 12 Let s1 , s2 , two piecewise constant scoring rules. [sent-208, score-0.684]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('scoring', 0.588), ('roc', 0.356), ('mencon', 0.265), ('auc', 0.258), ('ranking', 0.206), ('aggregation', 0.191), ('vayatis', 0.162), ('cl', 0.161), ('pb', 0.161), ('rules', 0.144), ('rankings', 0.121), ('kendall', 0.108), ('bipartite', 0.1), ('anking', 0.097), ('piecewise', 0.096), ('orest', 0.095), ('subpartition', 0.095), ('telecom', 0.095), ('curve', 0.085), ('consensus', 0.065), ('randomization', 0.064), ('ank', 0.058), ('rule', 0.058), ('depecker', 0.057), ('endall', 0.057), ('epecker', 0.057), ('marine', 0.057), ('menc', 0.057), ('orests', 0.057), ('paristech', 0.057), ('preorder', 0.057), ('kc', 0.054), ('cells', 0.054), ('partitions', 0.05), ('tau', 0.049), ('fagin', 0.049), ('cachan', 0.049), ('rank', 0.047), ('cb', 0.045), ('ens', 0.044), ('shall', 0.042), ('barth', 0.038), ('cmla', 0.038), ('conveys', 0.038), ('montjardet', 0.038), ('pennock', 0.038), ('phan', 0.038), ('preorders', 0.038), ('ree', 0.038), ('collection', 0.037), ('nonparametric', 0.035), ('nicolas', 0.034), ('therein', 0.032), ('forests', 0.029), ('convention', 0.028), ('concepts', 0.028), ('meila', 0.027), ('bagging', 0.027), ('populations', 0.027), ('umr', 0.027), ('partition', 0.027), ('setup', 0.026), ('aggregated', 0.025), ('aggregating', 0.024), ('probabilistic', 0.023), ('agreement', 0.023), ('coincides', 0.023), ('dx', 0.023), ('breiman', 0.023), ('sb', 0.023), ('proposition', 0.022), ('discriminate', 0.021), ('fr', 0.021), ('cell', 0.021), ('transforms', 0.021), ('median', 0.02), ('rue', 0.02), ('agarwal', 0.02), ('internet', 0.02), ('bootstrap', 0.019), ('relation', 0.018), ('assessing', 0.018), ('freund', 0.018), ('boosting', 0.017), ('randomized', 0.017), ('perspective', 0.017), ('binary', 0.017), ('implements', 0.016), ('capacity', 0.016), ('feedback', 0.016), ('social', 0.016), ('induced', 0.016), ('informal', 0.016), ('preferences', 0.016), ('clemencon', 0.016), ('exive', 0.016), ('meanings', 0.016), ('extremities', 0.016), ('referee', 0.016), ('france', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="95-tfidf-1" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>Author: Stéphan Clémençon, Marine Depecker, Nicolas Vayatis</p><p>Abstract: The present paper examines how the aggregation and feature randomization principles underlying the algorithm R ANDOM F OREST (Breiman, 2001) can be adapted to bipartite ranking. The approach taken here is based on nonparametric scoring and ROC curve optimization in the sense of the AUC criterion. In this problem, aggregation is used to increase the performance of scoring rules produced by ranking trees, as those developed in Cl´ mencon and Vayatis (2009c). The present work e ¸ describes the principles for building median scoring rules based on concepts from rank aggregation. Consistency results are derived for these aggregated scoring rules and an algorithm called R ANK ING F OREST is presented. Furthermore, various strategies for feature randomization are explored through a series of numerical experiments on artiﬁcial data sets. Keywords: bipartite ranking, nonparametric scoring, classiﬁcation data, ROC optimization, AUC criterion, tree-based ranking rules, bootstrap, bagging, rank aggregation, median ranking, feature randomization</p><p>2 0.051899377 <a title="95-tfidf-2" href="./jmlr-2013-Finding_Optimal_Bayesian_Networks_Using_Precedence_Constraints.html">44 jmlr-2013-Finding Optimal Bayesian Networks Using Precedence Constraints</a></p>
<p>Author: Pekka Parviainen, Mikko Koivisto</p><p>Abstract: We consider the problem of ﬁnding a directed acyclic graph (DAG) that optimizes a decomposable Bayesian network score. While in a favorable case an optimal DAG can be found in polynomial time, in the worst case the fastest known algorithms rely on dynamic programming across the node subsets, taking time and space 2n , to within a factor polynomial in the number of nodes n. In practice, these algorithms are feasible to networks of at most around 30 nodes, mainly due to the large space requirement. Here, we generalize the dynamic programming approach to enhance its feasibility in three dimensions: ﬁrst, the user may trade space against time; second, the proposed algorithms easily and efﬁciently parallelize onto thousands of processors; third, the algorithms can exploit any prior knowledge about the precedence relation on the nodes. Underlying all these results is the key observation that, given a partial order P on the nodes, an optimal DAG compatible with P can be found in time and space roughly proportional to the number of ideals of P , which can be signiﬁcantly less than 2n . Considering sufﬁciently many carefully chosen partial orders guarantees that a globally optimal DAG will be found. Aside from the generic scheme, we present and analyze concrete tradeoff schemes based on parallel bucket orders. Keywords: exact algorithm, parallelization, partial order, space-time tradeoff, structure learning</p><p>3 0.048736587 <a title="95-tfidf-3" href="./jmlr-2013-Algorithms_for_Discovery_of_Multiple_Markov_Boundaries.html">11 jmlr-2013-Algorithms for Discovery of Multiple Markov Boundaries</a></p>
<p>Author: Alexander Statnikov, Nikita I. Lytkin, Jan Lemeire, Constantin F. Aliferis</p><p>Abstract: Algorithms for Markov boundary discovery from data constitute an important recent development in machine learning, primarily because they offer a principled solution to the variable/feature selection problem and give insight on local causal structure. Over the last decade many sound algorithms have been proposed to identify a single Markov boundary of the response variable. Even though faithful distributions and, more broadly, distributions that satisfy the intersection property always have a single Markov boundary, other distributions/data sets may have multiple Markov boundaries of the response variable. The latter distributions/data sets are common in practical data-analytic applications, and there are several reasons why it is important to induce multiple Markov boundaries from such data. However, there are currently no sound and efﬁcient algorithms that can accomplish this task. This paper describes a family of algorithms TIE* that can discover all Markov boundaries in a distribution. The broad applicability as well as efﬁciency of the new algorithmic family is demonstrated in an extensive benchmarking study that involved comparison with 26 state-of-the-art algorithms/variants in 15 data sets from a diversity of application domains. Keywords: Markov boundary discovery, variable/feature selection, information equivalence, violations of faithfulness</p><p>4 0.042558178 <a title="95-tfidf-4" href="./jmlr-2013-Learning_Theory_Analysis_for_Association_Rules_and_Sequential_Event_Prediction.html">61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</a></p>
<p>Author: Cynthia Rudin, Benjamin Letham, David Madigan</p><p>Abstract: We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called “sequential event prediction.” In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer’s online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the “cold start” problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classiﬁcation, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an “adjusted conﬁdence” measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. Keywords: statistical learning theory, algorithmic stability, association rules, sequence prediction, associative classiﬁcation c 2013 Cynthia Rudin, Benjamin Letham and David Madigan. RUDIN , L E</p><p>5 0.038048323 <a title="95-tfidf-5" href="./jmlr-2013-Regularization-Free_Principal_Curve_Estimation.html">96 jmlr-2013-Regularization-Free Principal Curve Estimation</a></p>
<p>Author: Samuel Gerber, Ross Whitaker</p><p>Abstract: Principal curves and manifolds provide a framework to formulate manifold learning within a statistical context. Principal curves deﬁne the notion of a curve passing through the middle of a distribution. While the intuition is clear, the formal deﬁnition leads to some technical and practical difﬁculties. In particular, principal curves are saddle points of the mean-squared projection distance, which poses severe challenges for estimation and model selection. This paper demonstrates that the difﬁculties in model selection associated with the saddle point property of principal curves are intrinsically tied to the minimization of the mean-squared projection distance. We introduce a new objective function, facilitated through a modiﬁcation of the principal curve estimation approach, for which all critical points are principal curves and minima. Thus, the new formulation removes the fundamental issue for model selection in principal curve estimation. A gradient-descent-based estimator demonstrates the effectiveness of the new formulation for controlling model complexity on numerical experiments with synthetic and real data. Keywords: principal curve, manifold estimation, unsupervised learning, model complexity, model selection</p><p>6 0.036322482 <a title="95-tfidf-6" href="./jmlr-2013-Fast_Generalized_Subset_Scan_for_Anomalous_Pattern_Detection.html">42 jmlr-2013-Fast Generalized Subset Scan for Anomalous Pattern Detection</a></p>
<p>7 0.035329118 <a title="95-tfidf-7" href="./jmlr-2013-PC_Algorithm_for_Nonparanormal_Graphical_Models.html">84 jmlr-2013-PC Algorithm for Nonparanormal Graphical Models</a></p>
<p>8 0.035219815 <a title="95-tfidf-8" href="./jmlr-2013-Orange%3A_Data_Mining_Toolbox_in_Python.html">83 jmlr-2013-Orange: Data Mining Toolbox in Python</a></p>
<p>9 0.034244105 <a title="95-tfidf-9" href="./jmlr-2013-QuantMiner_for_Mining_Quantitative_Association_Rules.html">89 jmlr-2013-QuantMiner for Mining Quantitative Association Rules</a></p>
<p>10 0.032035973 <a title="95-tfidf-10" href="./jmlr-2013-CODA%3A_High_Dimensional_Copula_Discriminant_Analysis.html">20 jmlr-2013-CODA: High Dimensional Copula Discriminant Analysis</a></p>
<p>11 0.031645108 <a title="95-tfidf-11" href="./jmlr-2013-Sub-Local_Constraint-Based_Learning_of_Bayesian_Networks_Using_A_Joint_Dependence_Criterion.html">110 jmlr-2013-Sub-Local Constraint-Based Learning of Bayesian Networks Using A Joint Dependence Criterion</a></p>
<p>12 0.030822353 <a title="95-tfidf-12" href="./jmlr-2013-A_Theory_of_Multiclass_Boosting.html">8 jmlr-2013-A Theory of Multiclass Boosting</a></p>
<p>13 0.027956167 <a title="95-tfidf-13" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>14 0.023345841 <a title="95-tfidf-14" href="./jmlr-2013-Counterfactual_Reasoning_and_Learning_Systems%3A_The_Example_of_Computational_Advertising.html">30 jmlr-2013-Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</a></p>
<p>15 0.021304911 <a title="95-tfidf-15" href="./jmlr-2013-Sparse_Single-Index_Model.html">104 jmlr-2013-Sparse Single-Index Model</a></p>
<p>16 0.020709828 <a title="95-tfidf-16" href="./jmlr-2013-Ranked_Bandits_in_Metric_Spaces%3A_Learning_Diverse_Rankings_over_Large_Document_Collections.html">94 jmlr-2013-Ranked Bandits in Metric Spaces: Learning Diverse Rankings over Large Document Collections</a></p>
<p>17 0.019689282 <a title="95-tfidf-17" href="./jmlr-2013-Random_Walk_Kernels_and_Learning_Curves_for_Gaussian_Process_Regression_on_Random_Graphs.html">93 jmlr-2013-Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs</a></p>
<p>18 0.019635001 <a title="95-tfidf-18" href="./jmlr-2013-Derivative_Estimation_with_Local_Polynomial_Fitting.html">31 jmlr-2013-Derivative Estimation with Local Polynomial Fitting</a></p>
<p>19 0.01828973 <a title="95-tfidf-19" href="./jmlr-2013-Beyond_Fano%27s_Inequality%3A_Bounds_on_the_Optimal_F-Score%2C_BER%2C_and_Cost-Sensitive_Risk_and_Their_Implications.html">18 jmlr-2013-Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</a></p>
<p>20 0.018041752 <a title="95-tfidf-20" href="./jmlr-2013-Multivariate_Convex_Regression_with_Adaptive_Partitioning.html">74 jmlr-2013-Multivariate Convex Regression with Adaptive Partitioning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.091), (1, 0.017), (2, 0.001), (3, 0.029), (4, 0.037), (5, 0.049), (6, 0.026), (7, 0.033), (8, -0.044), (9, 0.054), (10, -0.039), (11, -0.127), (12, -0.004), (13, -0.252), (14, -0.049), (15, -0.013), (16, -0.043), (17, -0.042), (18, 0.013), (19, -0.002), (20, -0.019), (21, -0.039), (22, -0.034), (23, -0.106), (24, 0.295), (25, 0.043), (26, 0.108), (27, -0.02), (28, 0.066), (29, -0.029), (30, -0.015), (31, 0.024), (32, 0.165), (33, -0.154), (34, 0.107), (35, 0.055), (36, -0.11), (37, -0.04), (38, -0.044), (39, 0.211), (40, 0.063), (41, 0.081), (42, 0.142), (43, -0.117), (44, 0.129), (45, 0.179), (46, 0.01), (47, 0.263), (48, 0.056), (49, -0.134)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98709226 <a title="95-lsi-1" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>Author: Stéphan Clémençon, Marine Depecker, Nicolas Vayatis</p><p>Abstract: The present paper examines how the aggregation and feature randomization principles underlying the algorithm R ANDOM F OREST (Breiman, 2001) can be adapted to bipartite ranking. The approach taken here is based on nonparametric scoring and ROC curve optimization in the sense of the AUC criterion. In this problem, aggregation is used to increase the performance of scoring rules produced by ranking trees, as those developed in Cl´ mencon and Vayatis (2009c). The present work e ¸ describes the principles for building median scoring rules based on concepts from rank aggregation. Consistency results are derived for these aggregated scoring rules and an algorithm called R ANK ING F OREST is presented. Furthermore, various strategies for feature randomization are explored through a series of numerical experiments on artiﬁcial data sets. Keywords: bipartite ranking, nonparametric scoring, classiﬁcation data, ROC optimization, AUC criterion, tree-based ranking rules, bootstrap, bagging, rank aggregation, median ranking, feature randomization</p><p>2 0.37419596 <a title="95-lsi-2" href="./jmlr-2013-Algorithms_for_Discovery_of_Multiple_Markov_Boundaries.html">11 jmlr-2013-Algorithms for Discovery of Multiple Markov Boundaries</a></p>
<p>Author: Alexander Statnikov, Nikita I. Lytkin, Jan Lemeire, Constantin F. Aliferis</p><p>Abstract: Algorithms for Markov boundary discovery from data constitute an important recent development in machine learning, primarily because they offer a principled solution to the variable/feature selection problem and give insight on local causal structure. Over the last decade many sound algorithms have been proposed to identify a single Markov boundary of the response variable. Even though faithful distributions and, more broadly, distributions that satisfy the intersection property always have a single Markov boundary, other distributions/data sets may have multiple Markov boundaries of the response variable. The latter distributions/data sets are common in practical data-analytic applications, and there are several reasons why it is important to induce multiple Markov boundaries from such data. However, there are currently no sound and efﬁcient algorithms that can accomplish this task. This paper describes a family of algorithms TIE* that can discover all Markov boundaries in a distribution. The broad applicability as well as efﬁciency of the new algorithmic family is demonstrated in an extensive benchmarking study that involved comparison with 26 state-of-the-art algorithms/variants in 15 data sets from a diversity of application domains. Keywords: Markov boundary discovery, variable/feature selection, information equivalence, violations of faithfulness</p><p>3 0.35538915 <a title="95-lsi-3" href="./jmlr-2013-Orange%3A_Data_Mining_Toolbox_in_Python.html">83 jmlr-2013-Orange: Data Mining Toolbox in Python</a></p>
<p>Author: Janez Demšar, Tomaž Curk, Aleš Erjavec, Črt Gorup, Tomaž Hočevar, Mitar Milutinovič, Martin Možina, Matija Polajnar, Marko Toplak, Anže Starič, Miha Štajdohar, Lan Umek, Lan Žagar, Jure Žbontar, Marinka Žitnik, Blaž Zupan</p><p>Abstract: Orange is a machine learning and data mining suite for data analysis through Python scripting and visual programming. Here we report on the scripting part, which features interactive data analysis and component-based assembly of data mining procedures. In the selection and design of components, we focus on the ﬂexibility of their reuse: our principal intention is to let the user write simple and clear scripts in Python, which build upon C++ implementations of computationallyintensive tasks. Orange is intended both for experienced users and programmers, as well as for students of data mining. Keywords: Python, data mining, machine learning, toolbox, scripting</p><p>4 0.33630443 <a title="95-lsi-4" href="./jmlr-2013-Learning_Theory_Analysis_for_Association_Rules_and_Sequential_Event_Prediction.html">61 jmlr-2013-Learning Theory Analysis for Association Rules and Sequential Event Prediction</a></p>
<p>Author: Cynthia Rudin, Benjamin Letham, David Madigan</p><p>Abstract: We present a theoretical analysis for prediction algorithms based on association rules. As part of this analysis, we introduce a problem for which rules are particularly natural, called “sequential event prediction.” In sequential event prediction, events in a sequence are revealed one by one, and the goal is to determine which event will next be revealed. The training set is a collection of past sequences of events. An example application is to predict which item will next be placed into a customer’s online shopping cart, given his/her past purchases. In the context of this problem, algorithms based on association rules have distinct advantages over classical statistical and machine learning methods: they look at correlations based on subsets of co-occurring past events (items a and b imply item c), they can be applied to the sequential event prediction problem in a natural way, they can potentially handle the “cold start” problem where the training set is small, and they yield interpretable predictions. In this work, we present two algorithms that incorporate association rules. These algorithms can be used both for sequential event prediction and for supervised classiﬁcation, and they are simple enough that they can possibly be understood by users, customers, patients, managers, etc. We provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an “adjusted conﬁdence” measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis. Keywords: statistical learning theory, algorithmic stability, association rules, sequence prediction, associative classiﬁcation c 2013 Cynthia Rudin, Benjamin Letham and David Madigan. RUDIN , L E</p><p>5 0.33477825 <a title="95-lsi-5" href="./jmlr-2013-Stationary-Sparse_Causality_Network_Learning.html">106 jmlr-2013-Stationary-Sparse Causality Network Learning</a></p>
<p>Author: Yuejia He, Yiyuan She, Dapeng Wu</p><p>Abstract: Recently, researchers have proposed penalized maximum likelihood to identify network topology underlying a dynamical system modeled by multivariate time series. The time series of interest are assumed to be stationary, but this restriction is never taken into consideration by existing estimation methods. Moreover, practical problems of interest may have ultra-high dimensionality and obvious node collinearity. In addition, none of the available algorithms provides a probabilistic measure of the uncertainty for the obtained network topology which is informative in reliable network identiﬁcation. The main purpose of this paper is to tackle these challenging issues. We propose the S2 learning framework, which stands for stationary-sparse network learning. We propose a novel algorithm referred to as the Berhu iterative sparsity pursuit with stationarity (BISPS), where the Berhu regularization can improve the Lasso in detection and estimation. The algorithm is extremely easy to implement, efﬁcient in computation and has a theoretical guarantee to converge to a global optimum. We also incorporate a screening technique into BISPS to tackle ultra-high dimensional problems and enhance computational efﬁciency. Furthermore, a stationary bootstrap technique is applied to provide connection occurring frequency for reliable topology learning. Experiments show that our method can achieve stationary and sparse causality network learning and is scalable for high-dimensional problems. Keywords: stationarity, sparsity, Berhu, screening, bootstrap</p><p>6 0.29697853 <a title="95-lsi-6" href="./jmlr-2013-QuantMiner_for_Mining_Quantitative_Association_Rules.html">89 jmlr-2013-QuantMiner for Mining Quantitative Association Rules</a></p>
<p>7 0.26358622 <a title="95-lsi-7" href="./jmlr-2013-Finding_Optimal_Bayesian_Networks_Using_Precedence_Constraints.html">44 jmlr-2013-Finding Optimal Bayesian Networks Using Precedence Constraints</a></p>
<p>8 0.25962368 <a title="95-lsi-8" href="./jmlr-2013-Regularization-Free_Principal_Curve_Estimation.html">96 jmlr-2013-Regularization-Free Principal Curve Estimation</a></p>
<p>9 0.22917189 <a title="95-lsi-9" href="./jmlr-2013-Fast_Generalized_Subset_Scan_for_Anomalous_Pattern_Detection.html">42 jmlr-2013-Fast Generalized Subset Scan for Anomalous Pattern Detection</a></p>
<p>10 0.21887602 <a title="95-lsi-10" href="./jmlr-2013-Learning_Bilinear_Model_for_Matching_Queries_and_Documents.html">60 jmlr-2013-Learning Bilinear Model for Matching Queries and Documents</a></p>
<p>11 0.20923828 <a title="95-lsi-11" href="./jmlr-2013-Sub-Local_Constraint-Based_Learning_of_Bayesian_Networks_Using_A_Joint_Dependence_Criterion.html">110 jmlr-2013-Sub-Local Constraint-Based Learning of Bayesian Networks Using A Joint Dependence Criterion</a></p>
<p>12 0.18766335 <a title="95-lsi-12" href="./jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems.html">2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</a></p>
<p>13 0.14565392 <a title="95-lsi-13" href="./jmlr-2013-Truncated_Power_Method_for_Sparse_Eigenvalue_Problems.html">116 jmlr-2013-Truncated Power Method for Sparse Eigenvalue Problems</a></p>
<p>14 0.14550008 <a title="95-lsi-14" href="./jmlr-2013-Beyond_Fano%27s_Inequality%3A_Bounds_on_the_Optimal_F-Score%2C_BER%2C_and_Cost-Sensitive_Risk_and_Their_Implications.html">18 jmlr-2013-Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</a></p>
<p>15 0.13440551 <a title="95-lsi-15" href="./jmlr-2013-PC_Algorithm_for_Nonparanormal_Graphical_Models.html">84 jmlr-2013-PC Algorithm for Nonparanormal Graphical Models</a></p>
<p>16 0.1327381 <a title="95-lsi-16" href="./jmlr-2013-Random_Walk_Kernels_and_Learning_Curves_for_Gaussian_Process_Regression_on_Random_Graphs.html">93 jmlr-2013-Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs</a></p>
<p>17 0.12754299 <a title="95-lsi-17" href="./jmlr-2013-Counterfactual_Reasoning_and_Learning_Systems%3A_The_Example_of_Computational_Advertising.html">30 jmlr-2013-Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</a></p>
<p>18 0.12605165 <a title="95-lsi-18" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>19 0.1193405 <a title="95-lsi-19" href="./jmlr-2013-Derivative_Estimation_with_Local_Polynomial_Fitting.html">31 jmlr-2013-Derivative Estimation with Local Polynomial Fitting</a></p>
<p>20 0.1179579 <a title="95-lsi-20" href="./jmlr-2013-A_Theory_of_Multiclass_Boosting.html">8 jmlr-2013-A Theory of Multiclass Boosting</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.023), (5, 0.096), (6, 0.022), (10, 0.053), (20, 0.028), (23, 0.025), (68, 0.019), (70, 0.03), (75, 0.033), (85, 0.017), (87, 0.011), (95, 0.53)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76283789 <a title="95-lda-1" href="./jmlr-2013-Ranking_Forests.html">95 jmlr-2013-Ranking Forests</a></p>
<p>Author: Stéphan Clémençon, Marine Depecker, Nicolas Vayatis</p><p>Abstract: The present paper examines how the aggregation and feature randomization principles underlying the algorithm R ANDOM F OREST (Breiman, 2001) can be adapted to bipartite ranking. The approach taken here is based on nonparametric scoring and ROC curve optimization in the sense of the AUC criterion. In this problem, aggregation is used to increase the performance of scoring rules produced by ranking trees, as those developed in Cl´ mencon and Vayatis (2009c). The present work e ¸ describes the principles for building median scoring rules based on concepts from rank aggregation. Consistency results are derived for these aggregated scoring rules and an algorithm called R ANK ING F OREST is presented. Furthermore, various strategies for feature randomization are explored through a series of numerical experiments on artiﬁcial data sets. Keywords: bipartite ranking, nonparametric scoring, classiﬁcation data, ROC optimization, AUC criterion, tree-based ranking rules, bootstrap, bagging, rank aggregation, median ranking, feature randomization</p><p>2 0.7090323 <a title="95-lda-2" href="./jmlr-2013-On_the_Mutual_Nearest_Neighbors_Estimate_in_Regression.html">79 jmlr-2013-On the Mutual Nearest Neighbors Estimate in Regression</a></p>
<p>Author: Arnaud Guyader, Nick Hengartner</p><p>Abstract: Motivated by promising experimental results, this paper investigates the theoretical properties of a recently proposed nonparametric estimator, called the Mutual Nearest Neighbors rule, which estimates the regression function m(x) = E[Y |X = x] as follows: ﬁrst identify the k nearest neighbors of x in the sample Dn , then keep only those for which x is itself one of the k nearest neighbors, and ﬁnally take the average over the corresponding response variables. We prove that this estimator is consistent and that its rate of convergence is optimal. Since the estimate with the optimal rate of convergence depends on the unknown distribution of the observations, we also present adaptation results by data-splitting. Keywords: nonparametric estimation, nearest neighbor methods, mathematical statistics</p><p>3 0.22872646 <a title="95-lda-3" href="./jmlr-2013-Communication-Efficient_Algorithms_for_Statistical_Optimization.html">25 jmlr-2013-Communication-Efficient Algorithms for Statistical Optimization</a></p>
<p>Author: Yuchen Zhang, John C. Duchi, Martin J. Wainwright</p><p>Abstract: We analyze two communication-efﬁcient algorithms for distributed optimization in statistical settings involving large-scale data sets. The ﬁrst algorithm is a standard averaging method that distributes the N data samples evenly to m machines, performs separate minimization on each subset, and then averages the estimates. We provide a sharp analysis of this average mixture algorithm, showing that under a reasonable set of conditions, the combined parameter achieves √ mean-squared error (MSE) that decays as O (N −1 + (N/m)−2 ). Whenever m ≤ N, this guarantee matches the best possible rate achievable by a centralized algorithm having access to all N samples. The second algorithm is a novel method, based on an appropriate form of bootstrap subsampling. Requiring only a single round of communication, it has mean-squared error that decays as O (N −1 + (N/m)−3 ), and so is more robust to the amount of parallelization. In addition, we show that a stochastic gradient-based method attains mean-squared error decaying as O (N −1 + (N/m)−3/2 ), easing computation at the expense of a potentially slower MSE rate. We also provide an experimental evaluation of our methods, investigating their performance both on simulated data and on a large-scale regression problem from the internet search domain. In particular, we show that our methods can be used to efﬁciently solve an advertisement prediction problem from the Chinese SoSo Search Engine, which involves logistic regression with N ≈ 2.4 × 108 samples and d ≈ 740,000 covariates. Keywords: distributed learning, stochastic optimization, averaging, subsampling</p><p>4 0.22628808 <a title="95-lda-4" href="./jmlr-2013-Greedy_Sparsity-Constrained_Optimization.html">51 jmlr-2013-Greedy Sparsity-Constrained Optimization</a></p>
<p>Author: Sohail Bahmani, Bhiksha Raj, Petros T. Boufounos</p><p>Abstract: Sparsity-constrained optimization has wide applicability in machine learning, statistics, and signal processing problems such as feature selection and Compressed Sensing. A vast body of work has studied the sparsity-constrained optimization from theoretical, algorithmic, and application aspects in the context of sparse estimation in linear models where the ﬁdelity of the estimate is measured by the squared error. In contrast, relatively less effort has been made in the study of sparsityconstrained optimization in cases where nonlinear models are involved or the cost function is not quadratic. In this paper we propose a greedy algorithm, Gradient Support Pursuit (GraSP), to approximate sparse minima of cost functions of arbitrary form. Should a cost function have a Stable Restricted Hessian (SRH) or a Stable Restricted Linearization (SRL), both of which are introduced in this paper, our algorithm is guaranteed to produce a sparse vector within a bounded distance from the true sparse optimum. Our approach generalizes known results for quadratic cost functions that arise in sparse linear regression and Compressed Sensing. We also evaluate the performance of GraSP through numerical simulations on synthetic and real data, where the algorithm is employed for sparse logistic regression with and without ℓ2 -regularization. Keywords: sparsity, optimization, compressed sensing, greedy algorithm</p><p>5 0.22493805 <a title="95-lda-5" href="./jmlr-2013-A_Binary-Classification-Based_Metric_between_Time-Series_Distributions_and_Its_Use_in_Statistical_and_Learning_Problems.html">2 jmlr-2013-A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems</a></p>
<p>Author: Daniil Ryabko, Jérémie Mary</p><p>Abstract: A metric between time-series distributions is proposed that can be evaluated using binary classiﬁcation methods, which were originally developed to work on i.i.d. data. It is shown how this metric can be used for solving statistical problems that are seemingly unrelated to classiﬁcation and concern highly dependent time series. Speciﬁcally, the problems of time-series clustering, homogeneity testing and the three-sample problem are addressed. Universal consistency of the resulting algorithms is proven under most general assumptions. The theoretical results are illustrated with experiments on synthetic and real-world data. Keywords: time series, reductions, stationary ergodic, clustering, metrics between probability distributions</p><p>6 0.22436212 <a title="95-lda-6" href="./jmlr-2013-Generalized_Spike-and-Slab_Priors_for_Bayesian_Group_Feature_Selection_Using_Expectation_Propagation.html">48 jmlr-2013-Generalized Spike-and-Slab Priors for Bayesian Group Feature Selection Using Expectation Propagation</a></p>
<p>7 0.22392035 <a title="95-lda-7" href="./jmlr-2013-Construction_of_Approximation_Spaces_for_Reinforcement_Learning.html">28 jmlr-2013-Construction of Approximation Spaces for Reinforcement Learning</a></p>
<p>8 0.22343928 <a title="95-lda-8" href="./jmlr-2013-How_to_Solve_Classification_and_Regression_Problems_on_High-Dimensional_Data_with_a_Supervised_Extension_of_Slow_Feature_Analysis.html">52 jmlr-2013-How to Solve Classification and Regression Problems on High-Dimensional Data with a Supervised Extension of Slow Feature Analysis</a></p>
<p>9 0.22318326 <a title="95-lda-9" href="./jmlr-2013-A_Max-Norm_Constrained_Minimization_Approach_to_1-Bit_Matrix_Completion.html">4 jmlr-2013-A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</a></p>
<p>10 0.2226485 <a title="95-lda-10" href="./jmlr-2013-Conjugate_Relation_between_Loss_Functions_and_Uncertainty_Sets_in_Classification_Problems.html">26 jmlr-2013-Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems</a></p>
<p>11 0.2206645 <a title="95-lda-11" href="./jmlr-2013-Belief_Propagation_for_Continuous_State_Spaces%3A_Stochastic_Message-Passing_with_Quantitative_Guarantees.html">17 jmlr-2013-Belief Propagation for Continuous State Spaces: Stochastic Message-Passing with Quantitative Guarantees</a></p>
<p>12 0.22024508 <a title="95-lda-12" href="./jmlr-2013-Multicategory_Large-Margin_Unified_Machines.html">73 jmlr-2013-Multicategory Large-Margin Unified Machines</a></p>
<p>13 0.21995018 <a title="95-lda-13" href="./jmlr-2013-Multi-Stage_Multi-Task_Feature_Learning.html">72 jmlr-2013-Multi-Stage Multi-Task Feature Learning</a></p>
<p>14 0.21985953 <a title="95-lda-14" href="./jmlr-2013-Machine_Learning_with_Operational_Costs.html">68 jmlr-2013-Machine Learning with Operational Costs</a></p>
<p>15 0.21955118 <a title="95-lda-15" href="./jmlr-2013-Semi-Supervised_Learning_Using_Greedy_Max-Cut.html">99 jmlr-2013-Semi-Supervised Learning Using Greedy Max-Cut</a></p>
<p>16 0.21875755 <a title="95-lda-16" href="./jmlr-2013-Sparsity_Regret_Bounds_for_Individual_Sequences_in_Online_Linear_Regression.html">105 jmlr-2013-Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</a></p>
<p>17 0.21843506 <a title="95-lda-17" href="./jmlr-2013-Beyond_Fano%27s_Inequality%3A_Bounds_on_the_Optimal_F-Score%2C_BER%2C_and_Cost-Sensitive_Risk_and_Their_Implications.html">18 jmlr-2013-Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</a></p>
<p>18 0.21829782 <a title="95-lda-18" href="./jmlr-2013-Algorithms_and_Hardness_Results_for_Parallel_Large_Margin_Learning.html">10 jmlr-2013-Algorithms and Hardness Results for Parallel Large Margin Learning</a></p>
<p>19 0.21829465 <a title="95-lda-19" href="./jmlr-2013-Convex_and_Scalable_Weakly_Labeled_SVMs.html">29 jmlr-2013-Convex and Scalable Weakly Labeled SVMs</a></p>
<p>20 0.2180146 <a title="95-lda-20" href="./jmlr-2013-Large-scale_SVD_and_Manifold_Learning.html">59 jmlr-2013-Large-scale SVD and Manifold Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
