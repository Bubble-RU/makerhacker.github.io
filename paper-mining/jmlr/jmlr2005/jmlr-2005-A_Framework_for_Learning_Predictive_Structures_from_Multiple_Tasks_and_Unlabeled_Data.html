<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-4" href="#">jmlr2005-4</a> knowledge-graph by maker-knowledge-mining</p><h1>4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</h1>
<br/><p>Source: <a title="jmlr-2005-4-pdf" href="http://jmlr.org/papers/volume6/ando05a/ando05a.pdf">pdf</a></p><p>Author: Rie Kubota Ando, Tong Zhang</p><p>Abstract: One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don’t have a complete understanding of their eﬀectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Speciﬁcally we consider learning predictive structures on hypothesis spaces (that is, what kind of classiﬁers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the eﬀectiveness of the proposed algorithms in the semi-supervised learning setting.</p><p>Reference: <a title="jmlr-2005-4-reference" href="../jmlr2005_reference/jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('auxy', 0.389), ('unlabel', 0.307), ('structural', 0.28), ('freq', 0.277), ('sem', 0.253), ('ando', 0.232), ('label', 0.18), ('predict', 0.16), ('structures', 0.158), ('superv', 0.157), ('conl', 0.151), ('engl', 0.132), ('zhang', 0.131), ('word', 0.126), ('corp', 0.117), ('chunk', 0.116), ('fs', 0.11), ('shar', 0.103), ('tag', 0.102), ('gazet', 0.101)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="4-tfidf-1" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>2 0.087019242 <a title="4-tfidf-2" href="./jmlr-2005-Active_Learning_to_Recognize_Multiple_Types_of_Plankton.html">9 jmlr-2005-Active Learning to Recognize Multiple Types of Plankton</a></p>
<p>3 0.080282129 <a title="4-tfidf-3" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>4 0.074547321 <a title="4-tfidf-4" href="./jmlr-2005-A_Bayesian_Model_for_Supervised_Clustering_with_the_Dirichlet_Process_Prior.html">2 jmlr-2005-A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior</a></p>
<p>5 0.071535684 <a title="4-tfidf-5" href="./jmlr-2005-Learning_Multiple_Tasks_with_Kernel_Methods.html">45 jmlr-2005-Learning Multiple Tasks with Kernel Methods</a></p>
<p>6 0.068966933 <a title="4-tfidf-6" href="./jmlr-2005-Learning_Module_Networks.html">44 jmlr-2005-Learning Module Networks</a></p>
<p>7 0.066139907 <a title="4-tfidf-7" href="./jmlr-2005-Dimension_Reduction_in_Text_Classification_with_Support_Vector_Machines.html">27 jmlr-2005-Dimension Reduction in Text Classification with Support Vector Machines</a></p>
<p>8 0.063878819 <a title="4-tfidf-8" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>9 0.060163207 <a title="4-tfidf-9" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>10 0.057068206 <a title="4-tfidf-10" href="./jmlr-2005-Generalization_Bounds_for_the_Area_Under_the_ROC_Curve.html">38 jmlr-2005-Generalization Bounds for the Area Under the ROC Curve</a></p>
<p>11 0.056948192 <a title="4-tfidf-11" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>12 0.056049824 <a title="4-tfidf-12" href="./jmlr-2005-Efficient_Computation_of_Gapped_Substring_Kernels_on_Large_Alphabets.html">28 jmlr-2005-Efficient Computation of Gapped Substring Kernels on Large Alphabets</a></p>
<p>13 0.054810677 <a title="4-tfidf-13" href="./jmlr-2005-Assessing_Approximate_Inference_for_Binary_Gaussian_Process_Classification.html">14 jmlr-2005-Assessing Approximate Inference for Binary Gaussian Process Classification</a></p>
<p>14 0.049590617 <a title="4-tfidf-14" href="./jmlr-2005-Asymptotic_Model_Selection_for_Naive_Bayesian_Networks.html">15 jmlr-2005-Asymptotic Model Selection for Naive Bayesian Networks</a></p>
<p>15 0.048710085 <a title="4-tfidf-15" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>16 0.047622565 <a title="4-tfidf-16" href="./jmlr-2005-A_Bayes_Optimal_Approach_for_Partitioning_the_Values_of_Categorical_Attributes.html">1 jmlr-2005-A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes</a></p>
<p>17 0.046818327 <a title="4-tfidf-17" href="./jmlr-2005-Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models.html">62 jmlr-2005-Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models</a></p>
<p>18 0.046780691 <a title="4-tfidf-18" href="./jmlr-2005-Learning_the_Kernel_with_Hyperkernels_%C2%A0%C2%A0%C2%A0%C2%A0%28Kernel_Machines_Section%29.html">49 jmlr-2005-Learning the Kernel with Hyperkernels     (Kernel Machines Section)</a></p>
<p>19 0.046091907 <a title="4-tfidf-19" href="./jmlr-2005-Diffusion_Kernels_on_Statistical_Manifolds.html">26 jmlr-2005-Diffusion Kernels on Statistical Manifolds</a></p>
<p>20 0.045484841 <a title="4-tfidf-20" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth ε-Insensitive Regression by Loss Symmetrization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.272), (1, 0.081), (2, -0.08), (3, -0.025), (4, -0.143), (5, 0.125), (6, 0.116), (7, -0.06), (8, 0.006), (9, -0.023), (10, -0.002), (11, 0.121), (12, -0.043), (13, -0.039), (14, -0.246), (15, -0.037), (16, 0.194), (17, 0.139), (18, 0.182), (19, 0.176), (20, -0.026), (21, -0.095), (22, 0.019), (23, -0.064), (24, 0.025), (25, 0.057), (26, 0.077), (27, -0.059), (28, 0.024), (29, 0.117), (30, -0.048), (31, -0.036), (32, 0.202), (33, -0.037), (34, 0.033), (35, 0.164), (36, -0.052), (37, 0.049), (38, -0.152), (39, 0.06), (40, -0.041), (41, -0.091), (42, -0.227), (43, 0.13), (44, 0.005), (45, -0.035), (46, -0.001), (47, -0.146), (48, -0.139), (49, 0.269)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96197826 <a title="4-lsi-1" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>2 0.44329953 <a title="4-lsi-2" href="./jmlr-2005-Active_Learning_to_Recognize_Multiple_Types_of_Plankton.html">9 jmlr-2005-Active Learning to Recognize Multiple Types of Plankton</a></p>
<p>3 0.35021126 <a title="4-lsi-3" href="./jmlr-2005-Generalization_Bounds_for_the_Area_Under_the_ROC_Curve.html">38 jmlr-2005-Generalization Bounds for the Area Under the ROC Curve</a></p>
<p>4 0.33673185 <a title="4-lsi-4" href="./jmlr-2005-Dimension_Reduction_in_Text_Classification_with_Support_Vector_Machines.html">27 jmlr-2005-Dimension Reduction in Text Classification with Support Vector Machines</a></p>
<p>5 0.30987948 <a title="4-lsi-5" href="./jmlr-2005-A_Classification_Framework_for_Anomaly_Detection.html">3 jmlr-2005-A Classification Framework for Anomaly Detection</a></p>
<p>6 0.30124146 <a title="4-lsi-6" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>7 0.28577814 <a title="4-lsi-7" href="./jmlr-2005-Efficient_Computation_of_Gapped_Substring_Kernels_on_Large_Alphabets.html">28 jmlr-2005-Efficient Computation of Gapped Substring Kernels on Large Alphabets</a></p>
<p>8 0.28279105 <a title="4-lsi-8" href="./jmlr-2005-Learning_Multiple_Tasks_with_Kernel_Methods.html">45 jmlr-2005-Learning Multiple Tasks with Kernel Methods</a></p>
<p>9 0.2511524 <a title="4-lsi-9" href="./jmlr-2005-A_Bayesian_Model_for_Supervised_Clustering_with_the_Dirichlet_Process_Prior.html">2 jmlr-2005-A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior</a></p>
<p>10 0.24590628 <a title="4-lsi-10" href="./jmlr-2005-Learning_Module_Networks.html">44 jmlr-2005-Learning Module Networks</a></p>
<p>11 0.24373393 <a title="4-lsi-11" href="./jmlr-2005-Learning_the_Kernel_with_Hyperkernels_%C2%A0%C2%A0%C2%A0%C2%A0%28Kernel_Machines_Section%29.html">49 jmlr-2005-Learning the Kernel with Hyperkernels     (Kernel Machines Section)</a></p>
<p>12 0.23640971 <a title="4-lsi-12" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>13 0.23511696 <a title="4-lsi-13" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>14 0.22959241 <a title="4-lsi-14" href="./jmlr-2005-Fast_Kernel_Classifiers_with_Online_and_Active_Learning.html">33 jmlr-2005-Fast Kernel Classifiers with Online and Active Learning</a></p>
<p>15 0.22730771 <a title="4-lsi-15" href="./jmlr-2005-An_MDP-Based_Recommender_System.html">12 jmlr-2005-An MDP-Based Recommender System</a></p>
<p>16 0.22648987 <a title="4-lsi-16" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth ε-Insensitive Regression by Loss Symmetrization</a></p>
<p>17 0.22452712 <a title="4-lsi-17" href="./jmlr-2005-Multiclass_Classification_with_Multi-Prototype_Support_Vector_Machines.html">58 jmlr-2005-Multiclass Classification with Multi-Prototype Support Vector Machines</a></p>
<p>18 0.22441274 <a title="4-lsi-18" href="./jmlr-2005-Assessing_Approximate_Inference_for_Binary_Gaussian_Process_Classification.html">14 jmlr-2005-Assessing Approximate Inference for Binary Gaussian Process Classification</a></p>
<p>19 0.22038023 <a title="4-lsi-19" href="./jmlr-2005-Denoising_Source_Separation.html">25 jmlr-2005-Denoising Source Separation</a></p>
<p>20 0.21497932 <a title="4-lsi-20" href="./jmlr-2005-A_Bayes_Optimal_Approach_for_Partitioning_the_Values_of_Categorical_Attributes.html">1 jmlr-2005-A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.51), (35, 0.017), (37, 0.013), (44, 0.037), (62, 0.136), (68, 0.072), (74, 0.017), (78, 0.027), (79, 0.011), (88, 0.033), (97, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87427419 <a title="4-lda-1" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>2 0.77781594 <a title="4-lda-2" href="./jmlr-2005-Learning_a_Mahalanobis_Metric_from_Equivalence_Constraints.html">46 jmlr-2005-Learning a Mahalanobis Metric from Equivalence Constraints</a></p>
<p>3 0.45812824 <a title="4-lda-3" href="./jmlr-2005-Efficient_Margin_Maximizing_with_Boosting.html">29 jmlr-2005-Efficient Margin Maximizing with Boosting</a></p>
<p>4 0.45045832 <a title="4-lda-4" href="./jmlr-2005-A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression.html">7 jmlr-2005-A Unifying View of Sparse Approximate Gaussian Process Regression</a></p>
<p>5 0.43928197 <a title="4-lda-5" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth ε-Insensitive Regression by Loss Symmetrization</a></p>
<p>6 0.42899159 <a title="4-lda-6" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>7 0.42840877 <a title="4-lda-7" href="./jmlr-2005-Quasi-Geodesic_Neural_Learning_Algorithms_Over_the_Orthogonal_Group%3A_A_Tutorial.html">63 jmlr-2005-Quasi-Geodesic Neural Learning Algorithms Over the Orthogonal Group: A Tutorial</a></p>
<p>8 0.42550787 <a title="4-lda-8" href="./jmlr-2005-Kernel_Methods_for_Measuring_Independence.html">41 jmlr-2005-Kernel Methods for Measuring Independence</a></p>
<p>9 0.42497155 <a title="4-lda-9" href="./jmlr-2005-Asymptotic_Model_Selection_for_Naive_Bayesian_Networks.html">15 jmlr-2005-Asymptotic Model Selection for Naive Bayesian Networks</a></p>
<p>10 0.42121604 <a title="4-lda-10" href="./jmlr-2005-Active_Coevolutionary_Learning_of_Deterministic_Finite_Automata.html">8 jmlr-2005-Active Coevolutionary Learning of Deterministic Finite Automata</a></p>
<p>11 0.42079869 <a title="4-lda-11" href="./jmlr-2005-Algorithmic_Stability_and_Meta-Learning.html">11 jmlr-2005-Algorithmic Stability and Meta-Learning</a></p>
<p>12 0.41041121 <a title="4-lda-12" href="./jmlr-2005-Machine_Learning_Methods_for_Predicting_Failures_in_Hard_Drives%3A__A_Multiple-Instance_Application.html">53 jmlr-2005-Machine Learning Methods for Predicting Failures in Hard Drives:  A Multiple-Instance Application</a></p>
<p>13 0.40908182 <a title="4-lda-13" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>14 0.4076876 <a title="4-lda-14" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>15 0.40689546 <a title="4-lda-15" href="./jmlr-2005-Assessing_Approximate_Inference_for_Binary_Gaussian_Process_Classification.html">14 jmlr-2005-Assessing Approximate Inference for Binary Gaussian Process Classification</a></p>
<p>16 0.4035874 <a title="4-lda-16" href="./jmlr-2005-Managing_Diversity_in_Regression_Ensembles.html">54 jmlr-2005-Managing Diversity in Regression Ensembles</a></p>
<p>17 0.40274763 <a title="4-lda-17" href="./jmlr-2005-Stability_of_Randomized_Learning_Algorithms.html">67 jmlr-2005-Stability of Randomized Learning Algorithms</a></p>
<p>18 0.40082806 <a title="4-lda-18" href="./jmlr-2005-Core_Vector_Machines%3A_Fast_SVM_Training_on_Very_Large_Data_Sets.html">24 jmlr-2005-Core Vector Machines: Fast SVM Training on Very Large Data Sets</a></p>
<p>19 0.40033531 <a title="4-lda-19" href="./jmlr-2005-Separating_a_Real-Life_Nonlinear_Image_Mixture.html">65 jmlr-2005-Separating a Real-Life Nonlinear Image Mixture</a></p>
<p>20 0.40033492 <a title="4-lda-20" href="./jmlr-2005-Information_Bottleneck_for_Gaussian_Variables.html">39 jmlr-2005-Information Bottleneck for Gaussian Variables</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
