<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>44 jmlr-2005-Learning Module Networks</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-44" href="#">jmlr2005-44</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>44 jmlr-2005-Learning Module Networks</h1>
<br/><p>Source: <a title="jmlr-2005-44-pdf" href="http://jmlr.org/papers/volume6/segal05a/segal05a.pdf">pdf</a></p><p>Author: Eran Segal, Dana Pe'er, Aviv Regev, Daphne Koller, Nir Friedman</p><p>Abstract: Methods for learning Bayesian networks can discover dependency structure between observed variables. Although these methods are useful in many applications, they run into computational and statistical problems in domains that involve a large number of variables. In this paper,1 we consider a solution that is applicable when many variables have similar behavior. We introduce a new class of models, module networks, that explicitly partition the variables into modules, so that the variables in each module share the same parents in the network and the same conditional probability distribution. We deﬁne the semantics of module networks, and describe an algorithm that learns the modules’ composition and their dependency structure from data. Evaluation on real data in the domains of gene expression and the stock market shows that module networks generalize better than Bayesian networks, and that the learned module network structure reveals regularities that are obscured in learned Bayesian networks. 1. A preliminary version of this paper appeared in the Proceedings of the Nineteenth Conference on Uncertainty in Artiﬁcial Intelligence, 2003 (UAI ’03). c 2005 Eran Segal, Dana Pe’er, Aviv Regev, Daphne Koller and Nir Friedman. S EGAL , P E ’ ER , R EGEV, KOLLER AND F RIEDMAN</p><p>Reference: <a title="jmlr-2005-44-reference" href="../jmlr2005_reference/jmlr-2005-Learning_Module_Networks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We introduce a new class of models, module networks, that explicitly partition the variables into modules, so that the variables in each module share the same parents in the network and the same conditional probability distribution. [sent-16, score-1.841]
</p><p>2 Evaluation on real data in the domains of gene expression and the stock market shows that module networks generalize better than Bayesian networks, and that the learned module network structure reveals regularities that are obscured in learned Bayesian networks. [sent-18, score-2.138]
</p><p>3 By making the modular structure explicit, the module network representation provides insight about the domain that are often be obscured by the intricate details of a large Bayesian network structure. [sent-47, score-1.034]
</p><p>4 A module network can be viewed simply as a Bayesian network in which variables in the same module share parents and parameters. [sent-48, score-1.898]
</p><p>5 (b) A simple module network; the boxes illustrate modules, where stock price variables share CPDs and parameters. [sent-55, score-1.023]
</p><p>6 Note that in a module network, variables in the same module have the same CPDs but may have different descendants. [sent-56, score-1.674]
</p><p>7 Our results show that our learned module network generalizes to unseen test data much better than a Bayesian network. [sent-59, score-0.95]
</p><p>8 They also illustrate the ability of the learned module network to reveal high-level structure that provides important insights. [sent-60, score-0.983]
</p><p>9 To model this type of situation, we might divide stock price variables into groups, which we call modules, and require that variables in the same module have the same probabilistic model; that is, all variables in the module have the same set of parents and the same CPD. [sent-77, score-1.912]
</p><p>10 This notion of a module is the key idea underlying the module network formalism. [sent-81, score-1.731]
</p><p>11 As described above, a module represents a set of variables that share the same set of parents and the same CPD. [sent-88, score-0.923]
</p><p>12 The ﬁrst deﬁnes a template probabilistic model for each module in C ; all of the variables assigned to the module will share this probabilistic model. [sent-97, score-1.782]
</p><p>13 Deﬁnition 1 A module network template T = (S , θ) for C deﬁnes, for each module M j ∈ C : • a set of parents PaM j ⊂ X ; • a conditional probability distribution template P(M j | PaM j ) which speciﬁes a distribution over Val(M j ) for each assignment in Val(PaM j ). [sent-98, score-1.909]
</p><p>14 A module network deﬁnes a probabilistic model by using the formal random variables M j and their associated CPDs as templates that encode the behavior of all of the variables assigned to that module. [sent-111, score-0.968]
</p><p>15 Speciﬁcally, we deﬁne the semantics of a module network by “unrolling” a Bayesian network where all of the variables assigned to module M j share the parents and conditional probability template assigned to M j in T . [sent-112, score-1.969]
</p><p>16 Acyclicity can be guaranteed by the following simple condition on the module network: Deﬁnition 3 Let M be a triple (C , T , A ), where C is a module set, T is a module network template for C , and A is a module assignment function for C . [sent-114, score-3.501]
</p><p>17 M deﬁnes a directed module graph GM as follows: • the nodes in GM correspond to the modules in C ; • GM contains an edge M j → Mk if and only if there is a variable X ∈ X so that A (X) = j and X ∈ PaMk . [sent-115, score-1.179]
</p><p>18 We say that M is a module network if the module graph GM is acyclic. [sent-116, score-1.731]
</p><p>19 For example, for the module network of Figure 1(b), the module graph has the structure M1 → M2 → M3 . [sent-117, score-1.764]
</p><p>20 Returning to our example, the Bayesian network of Figure 1(a) is the ground Bayesian network of the module network of Figure 1(b). [sent-120, score-1.069]
</p><p>21 Using the acyclicity of the module graph, we can now show that the semantics for a module network is well-deﬁned. [sent-121, score-1.761]
</p><p>22 By deﬁnition of the module graph, we must have an edge MA (Xi ) → MA (X j ) in the module graph. [sent-125, score-1.658]
</p><p>23 Recall that a module network is speciﬁed by a set of modules C , an assignment function A of nodes to modules, the parent structure S speciﬁed in T , and the parameters θ for the local probability distributions P(M j | PaM j ). [sent-148, score-1.424]
</p><p>24 Such distinctions can be made within the module network framework through more elaborate prior probability functions that take the module type into account. [sent-154, score-1.731]
</p><p>25 One can consider several learning tasks for module networks, depending on which of the remaining aspects of the module network speciﬁcation are known. [sent-155, score-1.731]
</p><p>26 Our primary goal is to learn a module network structure and assignment function for this distribution. [sent-162, score-1.025]
</p><p>27 As the semantics of a module network is deﬁned via the ground Bayesian network, we have that, in the case of complete data, the likelihood decomposes into a product of local likelihood functions, one for each variable. [sent-171, score-1.002]
</p><p>28 The CPD template of each module is connected to all variables assigned to that module (e. [sent-176, score-1.712]
</p><p>29 The sufﬁcient statistics of each CPD template are the sum of the sufﬁcient statistics of each variable assigned to the module and the module parents. [sent-179, score-1.696]
</p><p>30 In a module network, all of the variables in the same module share the same parameters. [sent-186, score-1.708]
</p><p>31 The second module contains three variables; thus, the sufﬁcient statistics for the module CPD is the sum of the statistics we would collect in the ground Bayesian network of Figure 1(a): ˆ ˆ ˆ ˆ S[M2 , MSFT] = S[AMAT, MSFT] + S[MOT, MSFT] + S[INTL, MSFT]. [sent-198, score-1.752]
</p><p>32 , the module graph induced by the assignment A and structure S is acyclic), and 0 otherwise. [sent-216, score-0.952]
</p><p>33 M M • ρ(S ) satisﬁes structure modularity if ρ(S ) = ∏ ρ j (S j ), j  where S j denotes the choice of parents for module M j and ρ j is a non-negative measure over these choices. [sent-220, score-0.954]
</p><p>34 • κ(A ) satisﬁes assignment modularity if κ(A ) = ∏ κ j (A j ), j  where A j denote is the choice of variables assigned to module M j and κ j is a non-negative measure over these choices. [sent-221, score-0.999]
</p><p>35 Then, the Bayesian score decomposes into local module scores: K  score(S , A : D ) =  ∑ scoreM (PaM , A (X j ) j  j  : D ),  j=1  where scoreM j (U, X : D ) = log  Z  L j (U, X, θM j |U : D )P(θM j | U)dθM j |U  + log ρ j (U) + log κ j (X). [sent-238, score-0.925]
</p><p>36 (4)  Proof Recall that we deﬁned the Bayesian score of a module network as: score(S , A : D ) = log P(D | S , A ) + log P(S , A ). [sent-239, score-0.968]
</p><p>37 Using global modularity, structure modularity and assignment modularity assumptions of Deﬁnition 7, log P(S , A ) decomposes by modules, resulting in the second and third terms Equation (4) that capture the preferences for the parents of module M j and the variables assigned to it. [sent-240, score-1.154]
</p><p>38 (Note that edge reversal is not a well-deﬁned operator for module networks, as an edge from a variable to a module represents a one-to-many relation between the variable and all of the variables in the module. [sent-263, score-1.674]
</p><p>39 ) When an operator causes a parent Xi to be added to the parent set of module M j , we need to verify that the resulting module graph remains acyclic, relative to the current assignment A . [sent-264, score-1.82]
</p><p>40 When updating the dependency structure for a module M j , the module score for another module Mk does not change, nor do the changes in score induced by various operators applied to the dependency structure of Mk . [sent-267, score-2.766]
</p><p>41 Moreover, only the delta score of operators that add or remove a parent from module M j need to be recomputed after a change to the dependency structure of module M j , resulting in additional savings. [sent-269, score-1.844]
</p><p>42 Overall, if the maximum number of parents per module is d, the cost of evaluating each operator applied to the module is, as usual, at most O(Md), for accumulating the necessary sufﬁcient statistics. [sent-271, score-1.702]
</p><p>43 During the structure learning phase, each step to the parent set of module M j requires that we re-evaluate at most n operators (one for each existing or potential parent of M j ), at a total cost of O(nMd). [sent-274, score-0.955]
</p><p>44 This type of step occurs in two places in our algorithm: once at the very beginning of the algorithm, in order to initialize the modules, and once at each iteration, given a module network structure S learned in the previous structure learning step. [sent-277, score-1.016]
</p><p>45 We can therefore view the module assignment task as the task of clustering variables into sets, so that variables in the same set have a similar behavior across all instances. [sent-284, score-0.975]
</p><p>46 Moreover, our setting places certain constraints on the clustering, so that the resulting assignment function will induce a legal (acyclic) module network. [sent-294, score-0.945]
</p><p>47 Our clustering algorithm uses an objective function that evaluates a partition of variables into modules by measuring the extent to which the module model is a good ﬁt to the features (instances) of the module variables. [sent-298, score-2.048]
</p><p>48 We then consider all possible legal module mergers (those corresponding to modules with the same domain), where we change the assignment function to replace two modules j1 and j2 by a new module j1,2 . [sent-308, score-2.474]
</p><p>49 More subtly, the Bayesian score for each module depends non-additively on the sufﬁcient statistics of all the variables assigned to the module. [sent-326, score-0.927]
</p><p>50 ) Thus, we can only compute the delta score for moving a variable from one module to another given a ﬁxed assignment of the other variables to these two modules. [sent-328, score-1.001]
</p><p>51 We start with an initial assignment function A 0 , and in a “round-robin” fashion iterate over all of the variables one at a time, and consider changing their module assignment. [sent-331, score-0.935]
</p><p>52 Our algorithm terminates when it can no longer im570  L EARNING M ODULE N ETWORKS  Input: D // Data set K // Number of modules Output: M // A module network Learn-Module-Network A0 = cluster X into K modules S0 = empty structure Loop t = 1, 2, . [sent-336, score-1.649]
</p><p>53 Greedy-Structure-Search successively applies operators that change the structure as long as each such operator results in a legal structure and improves the module network score  prove the score. [sent-340, score-1.081]
</p><p>54 Once again, the decomposition of the score plays a key role in reducing the complexity of this computation: When reassigning a variable Xi from one module Mold to another Mnew , only the local scores of these modules change. [sent-343, score-1.273]
</p><p>55 The module score of all other modules remains unchanged. [sent-344, score-1.245]
</p><p>56 (c) Initialization of the assignment function for the module network procedure for the data in (a). [sent-428, score-0.992]
</p><p>57 Many of the domains suited for module network models contain continuous valued variables, such as gene expression or price changes in the stock market. [sent-440, score-1.165]
</p><p>58 m Xi ∈X j  ˆ j, S1  =  (5)  m Xi ∈X j  ˆ j, S2  =  m Xi ∈X j  The local module score further decomposes into independent components, one for each leaf . [sent-482, score-0.968]
</p><p>59 When performing structure search for module networks with regression-tree CPDs, in addition to choosing the parents of each module, we must also choose the associated tree structure. [sent-485, score-0.971]
</p><p>60 Experimental Results We evaluated our module network learning procedure on synthetic data and on two real data sets — gene expression data, and stock market data. [sent-498, score-1.127]
</p><p>61 5 0  5  10  15  0  20  5  10  15  20  Algorithm Iterations  Algorithm Iterations  (a)  (b)  Figure 9: (a) Score of the model (normalized by the number of variables/genes) across the iterations of the algorithm for a module network learned with 50 modules on the gene expression data. [sent-538, score-1.394]
</p><p>62 (b) Changes in the assignment of genes to modules for the module network learned in (a) across the iterations of the algorithm. [sent-540, score-1.465]
</p><p>63 We then selected 2355 genes that varied signiﬁcantly in the data and learned a module network over these genes. [sent-558, score-1.025]
</p><p>64 2 0  20  40  60  80  100  Runs (initialized from random clusterings)  Figure 10: Score of 100 module networks (normalized by the number of variables/genes) each learned with 50 modules from a random clustering initialization, where the runs are sorted according to their score. [sent-566, score-1.279]
</p><p>65 The score of a module network learned using the deterministic clustering initialization described in Section 4. [sent-567, score-1.055]
</p><p>66 We generated 100 random assignments of variables to modules, and learned a module network starting from each initialization. [sent-583, score-0.989]
</p><p>67 In Figure 11(a), we show the difference between module networks of different size and the baseline Bayesian network, demonstrating that module networks generalize much better to unseen data for almost all choices of number of modules. [sent-588, score-1.714]
</p><p>68 We evaluated a learned module network with 50 modules, where we selected 50 modules due to the biological plausibility of having, on average, 40–50 genes per module. [sent-594, score-1.393]
</p><p>69 Suppose we ﬁnd l genes with a certain annotation in a module of size N. [sent-599, score-0.935]
</p><p>70 A comparison of the overall enrichments of the modules learned by module networks to the enrichments obtained for clusters using AutoClass is shown in Figure 11(b), indicating that there are many annotations that are much more signiﬁcantly enriched in module networks. [sent-612, score-2.149]
</p><p>71 Another module regulated by the cell cycle module is the nitrogen catabolite repression (NCR) module, a cellular response activated when nitrogen sources are scarce. [sent-616, score-1.672]
</p><p>72 The y-axis denotes the difference in log-likelihood on held out data between the learned module network and the learned Bayesian network, averaged over 10 folds; the error bars show the standard deviation. [sent-620, score-0.998]
</p><p>73 (b) Comparison of the enrichment for annotations of functional annotations between the modules learned using the module network procedure and the clusters learned by the AutoClass clustering algorithm (Cheeseman et al. [sent-621, score-1.496]
</p><p>74 The y-axis denotes the difference in log-likelihood on held out data between the learned module network and the learned Bayesian network, averaged over 10 folds; the error bars show the standard deviation. [sent-637, score-0.998]
</p><p>75 (b) Comparison of the enrichment for annotations of sectors between the modules learned using the module network procedure and the clusters learned by the AutoClass clustering algorithm (Cheeseman et al. [sent-638, score-1.45]
</p><p>76 To test the quality of our modules, we measured the enrichment of the modules in the network with 50 modules for annotations representing various sectors to which each stock belongs (based on sector classiﬁcations from http://finance. [sent-641, score-0.968]
</p><p>77 In 20 of the 21 cases, the enrichment was far more signiﬁcant in the modules learned using module networks compared to the one learned by AutoClass, as can be seen in Figure 12(b). [sent-648, score-1.335]
</p><p>78 Finally, we also looked at the structure of the module network, and found several cases where the structure ﬁt our (limited) understanding of the stock domain. [sent-649, score-1.012]
</p><p>79 One can easily extend module networks with ideas from the hierarchical Bayesian framework, allowing the parameters of different variables in the same module to be correlated but not necessarily equal. [sent-664, score-1.702]
</p><p>80 Each module can be viewed as a class, so that the variables in a single module share the same probabilistic model. [sent-668, score-1.726]
</p><p>81 As the module assignments are not known in advance, module networks correspond most closely to the variant of these frameworks where there is type uncertainty — uncertainty about the class assignment of objects. [sent-669, score-1.799]
</p><p>82 By contrast, in a module network, all of the variables in a module (class) must have the same speciﬁc parents. [sent-672, score-1.674]
</p><p>83 To better relate the PRM approach to module networks, recall the relationship between module networks and clustering, as described in Section 4. [sent-686, score-1.686]
</p><p>84 As we discussed, we can view the module network learning procedure as grouping variables into clusters that share the same probabilistic dependency model. [sent-688, score-1.0]
</p><p>85 From this perspective, the module network framework can be viewed as being closely related to a PRM where the module assignment is a hidden attribute of a row. [sent-695, score-1.821]
</p><p>86 A key difference between the PRM-based approach and our module network framework is that, in the PRM, the regulators cannot themselves participate in the probabilistic model without leading to cycles. [sent-702, score-0.943]
</p><p>87 Overall, the module network framework places strong restrictions on the richness of the set of objects and on the dependency structures that can be represented. [sent-705, score-0.961]
</p><p>88 Discussion and Conclusions We have introduced the framework of module networks, an extension of Bayesian networks that includes an explicit representation of modules — subsets of variables that share a statistical model. [sent-709, score-1.257]
</p><p>89 We have presented a Bayesian learning framework for module networks, which learns both the partitioning of variables into modules and the dependency structure of each module. [sent-710, score-1.258]
</p><p>90 Our results show that our learned module networks have much higher generalization performance than a Bayesian network learned from the same data. [sent-712, score-1.026]
</p><p>91 There are several reasons why a learned module network is a better model than a learned Bayesian network. [sent-713, score-0.998]
</p><p>92 Conversely, in a module network setting, a spurious correlation would have to arise between a possible parent and a large number of other variables before the algorithm would ﬁnd it worthwhile to introduce the dependency. [sent-721, score-0.954]
</p><p>93 In such domains, a module network would force variables into sharing dependency structures and CPDs and may result in poor representations of the underlying domain properties. [sent-725, score-0.976]
</p><p>94 Even in domains where the modularity assumption is warranted, the module network models we presented here may not be ideal. [sent-726, score-0.975]
</p><p>95 , 2004), we presented one possible extension to the module network framework presented in this paper, which allows genes to be assigned to several modules. [sent-733, score-0.993]
</p><p>96 The expression of a gene in a particular array is then modeled as a sum of its expression in each of the modules in which it participates, and each module can potentially have a different set of regulators. [sent-734, score-1.293]
</p><p>97 For instance, in the biological domain, the number of regulatory modules of an organism in an expression data set is obviously not known and thus determining 584  L EARNING M ODULE N ETWORKS  the number of modules should be part of the regulatory module discovery task. [sent-738, score-1.637]
</p><p>98 1 we showed that, at least in synthetic data, where the number of modules is known, we can use the score of the model to select the correct number of modules by choosing the model with the smallest number of modules from among the highest scoring models. [sent-740, score-1.137]
</p><p>99 , 2003b), we use the module network learned from the gene expression data described above to predict gene regulation relationships. [sent-768, score-1.118]
</p><p>100 Thus, we have demonstrated that the module network model is robust enough to learn a good approximation of the dependency structure between 2355 genes using only 173 instances. [sent-773, score-1.04]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('module', 0.829), ('modules', 0.35), ('pam', 0.15), ('stock', 0.117), ('intl', 0.096), ('cpd', 0.092), ('msft', 0.092), ('assignment', 0.09), ('amat', 0.089), ('genes', 0.075), ('gene', 0.074), ('network', 0.073), ('bayesian', 0.071), ('odule', 0.069), ('score', 0.066), ('egal', 0.062), ('egev', 0.062), ('riedman', 0.052), ('koller', 0.051), ('modularity', 0.048), ('learned', 0.048), ('annotations', 0.046), ('mot', 0.046), ('parents', 0.044), ('leaf', 0.043), ('cpds', 0.042), ('dell', 0.039), ('hpq', 0.038), ('val', 0.037), ('etworks', 0.036), ('parent', 0.036), ('segal', 0.036), ('regulatory', 0.035), ('share', 0.034), ('structure', 0.033), ('enrichment', 0.032), ('annotation', 0.031), ('bm', 0.031), ('reassignment', 0.031), ('dependency', 0.03), ('networks', 0.028), ('price', 0.027), ('prms', 0.027), ('trading', 0.027), ('friedman', 0.026), ('relational', 0.026), ('legal', 0.026), ('domains', 0.025), ('clustering', 0.024), ('autoclass', 0.023), ('regulators', 0.023), ('assignments', 0.023), ('heckerman', 0.022), ('template', 0.022), ('earning', 0.021), ('scoring', 0.021), ('intel', 0.021), ('ground', 0.021), ('operators', 0.021), ('stocks', 0.02), ('expression', 0.02), ('tree', 0.02), ('manufacturers', 0.019), ('plate', 0.019), ('chip', 0.019), ('enriched', 0.019), ('oobns', 0.019), ('scorem', 0.019), ('pe', 0.018), ('probabilistic', 0.018), ('biological', 0.018), ('decomposes', 0.017), ('semantics', 0.017), ('search', 0.017), ('instances', 0.017), ('likelihood', 0.016), ('variables', 0.016), ('assigned', 0.016), ('regev', 0.016), ('cheeseman', 0.016), ('gm', 0.016), ('genetics', 0.015), ('pfeffer', 0.015), ('reassigning', 0.015), ('structures', 0.015), ('initialization', 0.015), ('er', 0.015), ('market', 0.014), ('objects', 0.014), ('thousands', 0.014), ('stanford', 0.014), ('cluster', 0.014), ('cell', 0.014), ('local', 0.013), ('priors', 0.013), ('dependencies', 0.013), ('domain', 0.013), ('modular', 0.013), ('acyclicity', 0.013), ('preferences', 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="44-tfidf-1" href="./jmlr-2005-Learning_Module_Networks.html">44 jmlr-2005-Learning Module Networks</a></p>
<p>Author: Eran Segal, Dana Pe'er, Aviv Regev, Daphne Koller, Nir Friedman</p><p>Abstract: Methods for learning Bayesian networks can discover dependency structure between observed variables. Although these methods are useful in many applications, they run into computational and statistical problems in domains that involve a large number of variables. In this paper,1 we consider a solution that is applicable when many variables have similar behavior. We introduce a new class of models, module networks, that explicitly partition the variables into modules, so that the variables in each module share the same parents in the network and the same conditional probability distribution. We deﬁne the semantics of module networks, and describe an algorithm that learns the modules’ composition and their dependency structure from data. Evaluation on real data in the domains of gene expression and the stock market shows that module networks generalize better than Bayesian networks, and that the learned module network structure reveals regularities that are obscured in learned Bayesian networks. 1. A preliminary version of this paper appeared in the Proceedings of the Nineteenth Conference on Uncertainty in Artiﬁcial Intelligence, 2003 (UAI ’03). c 2005 Eran Segal, Dana Pe’er, Aviv Regev, Daphne Koller and Nir Friedman. S EGAL , P E ’ ER , R EGEV, KOLLER AND F RIEDMAN</p><p>2 0.077097543 <a title="44-tfidf-2" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>Author: Gal Elidan, Nir Friedman</p><p>Abstract: A central challenge in learning probabilistic graphical models is dealing with domains that involve hidden variables. The common approach for learning model parameters in such domains is the expectation maximization (EM) algorithm. This algorithm, however, can easily get trapped in suboptimal local maxima. Learning the model structure is even more challenging. The structural EM algorithm can adapt the structure in the presence of hidden variables, but usually performs poorly without prior knowledge about the cardinality and location of the hidden variables. In this work, we present a general approach for learning Bayesian networks with hidden variables that overcomes these problems. The approach builds on the information bottleneck framework of Tishby et al. (1999). We start by proving formal correspondence between the information bottleneck objective and the standard parametric EM functional. We then use this correspondence to construct a learning algorithm that combines an information-theoretic smoothing term with a continuation procedure. Intuitively, the algorithm bypasses local maxima and achieves superior solutions by following a continuous path from a solution of, an easy and smooth, target function, to a solution of the desired likelihood function. As we show, our algorithmic framework allows learning of the parameters as well as the structure of a network. In addition, it also allows us to introduce new hidden variables during model selection and learn their cardinality. We demonstrate the performance of our procedure on several challenging real-life data sets. Keywords: Bayesian networks, hidden variables, information bottleneck, continuation, variational methods</p><p>3 0.039901622 <a title="44-tfidf-3" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>Author: Lior Wolf, Amnon Shashua</p><p>Abstract: The problem of selecting a subset of relevant features in a potentially overwhelming quantity of data is classic and found in many branches of science. Examples in computer vision, text processing and more recently bio-informatics are abundant. In text classiﬁcation tasks, for example, it is not uncommon to have 104 to 107 features of the size of the vocabulary containing word frequency counts, with the expectation that only a small fraction of them are relevant. Typical examples include the automatic sorting of URLs into a web directory and the detection of spam email. In this work we present a deﬁnition of “relevancy” based on spectral properties of the Laplacian of the features’ measurement matrix. The feature selection process is then based on a continuous ranking of the features deﬁned by a least-squares optimization process. A remarkable property of the feature relevance function is that sparse solutions for the ranking values naturally emerge as a result of a “biased non-negativity” of a key matrix in the process. As a result, a simple leastsquares optimization process converges onto a sparse solution, i.e., a selection of a subset of features which form a local maximum over the relevance function. The feature selection algorithm can be embedded in both unsupervised and supervised inference problems and empirical evidence show that the feature selections typically achieve high accuracy even when only a small fraction of the features are relevant.</p><p>4 0.039648399 <a title="44-tfidf-4" href="./jmlr-2005-Inner_Product_Spaces_for_Bayesian_Networks.html">40 jmlr-2005-Inner Product Spaces for Bayesian Networks</a></p>
<p>Author: Atsuyoshi Nakamura, Michael Schmitt, Niels Schmitt, Hans Ulrich Simon</p><p>Abstract: Bayesian networks have become one of the major models used for statistical inference. We study the question whether the decisions computed by a Bayesian network can be represented within a low-dimensional inner product space. We focus on two-label classiﬁcation tasks over the Boolean domain. As main results we establish upper and lower bounds on the dimension of the inner product space for Bayesian networks with an explicitly given (full or reduced) parameter collection. In particular, these bounds are tight up to a factor of 2. For some nontrivial cases of Bayesian networks we even determine the exact values of this dimension. We further consider logistic autoregressive Bayesian networks and show that every sufﬁciently expressive inner product space must have dimension at least Ω(n2 ), where n is the number of network nodes. We also derive the bound 2Ω(n) for an artiﬁcial variant of this network, thereby demonstrating the limits of our approach and raising an interesting open question. As a major technical contribution, this work reveals combinatorial and algebraic structures within Bayesian networks such that known methods for the derivation of lower bounds on the dimension of inner product spaces can be brought into play. Keywords: Bayesian network, inner product space, embedding, linear arrangement, Euclidean dimension</p><p>5 0.034801882 <a title="44-tfidf-5" href="./jmlr-2005-Estimation_of_Non-Normalized_Statistical_Models_by_Score_Matching.html">31 jmlr-2005-Estimation of Non-Normalized Statistical Models by Score Matching</a></p>
<p>Author: Aapo Hyvärinen</p><p>Abstract: One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very diﬃcult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simpliﬁes to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete ﬁlter set for natural image data. Keywords: statistical estimation, non-normalized densities, pseudo-likelihood, Markov chain Monte Carlo, contrastive divergence</p><p>6 0.033030171 <a title="44-tfidf-6" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>7 0.031742387 <a title="44-tfidf-7" href="./jmlr-2005-Asymptotic_Model_Selection_for_Naive_Bayesian_Networks.html">15 jmlr-2005-Asymptotic Model Selection for Naive Bayesian Networks</a></p>
<p>8 0.031596854 <a title="44-tfidf-8" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>9 0.030481117 <a title="44-tfidf-9" href="./jmlr-2005-A_Bayesian_Model_for_Supervised_Clustering_with_the_Dirichlet_Process_Prior.html">2 jmlr-2005-A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior</a></p>
<p>10 0.028650874 <a title="44-tfidf-10" href="./jmlr-2005-Local_Propagation_in_Conditional_Gaussian_Bayesian_Networks.html">51 jmlr-2005-Local Propagation in Conditional Gaussian Bayesian Networks</a></p>
<p>11 0.026345979 <a title="44-tfidf-11" href="./jmlr-2005-Variational_Message_Passing.html">71 jmlr-2005-Variational Message Passing</a></p>
<p>12 0.021622123 <a title="44-tfidf-12" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>13 0.019645514 <a title="44-tfidf-13" href="./jmlr-2005-Tree-Based_Batch_Mode_Reinforcement_Learning.html">68 jmlr-2005-Tree-Based Batch Mode Reinforcement Learning</a></p>
<p>14 0.019080473 <a title="44-tfidf-14" href="./jmlr-2005-What%27s_Strange_About_Recent_Events_%28WSARE%29%3A_An_Algorithm_for_the_Early_Detection_of_Disease_Outbreaks.html">72 jmlr-2005-What's Strange About Recent Events (WSARE): An Algorithm for the Early Detection of Disease Outbreaks</a></p>
<p>15 0.015696676 <a title="44-tfidf-15" href="./jmlr-2005-Machine_Learning_Methods_for_Predicting_Failures_in_Hard_Drives%3A__A_Multiple-Instance_Application.html">53 jmlr-2005-Machine Learning Methods for Predicting Failures in Hard Drives:  A Multiple-Instance Application</a></p>
<p>16 0.01547694 <a title="44-tfidf-16" href="./jmlr-2005-Multiclass_Classification_with_Multi-Prototype_Support_Vector_Machines.html">58 jmlr-2005-Multiclass Classification with Multi-Prototype Support Vector Machines</a></p>
<p>17 0.014808424 <a title="44-tfidf-17" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>18 0.014759164 <a title="44-tfidf-18" href="./jmlr-2005-Learning_Multiple_Tasks_with_Kernel_Methods.html">45 jmlr-2005-Learning Multiple Tasks with Kernel Methods</a></p>
<p>19 0.013635128 <a title="44-tfidf-19" href="./jmlr-2005-Assessing_Approximate_Inference_for_Binary_Gaussian_Process_Classification.html">14 jmlr-2005-Assessing Approximate Inference for Binary Gaussian Process Classification</a></p>
<p>20 0.013433851 <a title="44-tfidf-20" href="./jmlr-2005-Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models.html">62 jmlr-2005-Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.105), (1, -0.028), (2, -0.019), (3, -0.094), (4, 0.052), (5, 0.06), (6, -0.127), (7, -0.089), (8, 0.049), (9, -0.086), (10, 0.148), (11, 0.032), (12, 0.176), (13, 0.013), (14, 0.207), (15, 0.064), (16, 0.022), (17, -0.22), (18, -0.122), (19, 0.026), (20, 0.107), (21, -0.003), (22, 0.29), (23, 0.006), (24, 0.071), (25, -0.052), (26, -0.243), (27, 0.296), (28, 0.128), (29, -0.052), (30, -0.071), (31, 0.146), (32, -0.227), (33, -0.304), (34, 0.148), (35, 0.013), (36, 0.258), (37, -0.188), (38, 0.074), (39, -0.169), (40, -0.135), (41, 0.063), (42, -0.11), (43, -0.188), (44, 0.034), (45, -0.064), (46, 0.123), (47, -0.049), (48, -0.049), (49, -0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96999741 <a title="44-lsi-1" href="./jmlr-2005-Learning_Module_Networks.html">44 jmlr-2005-Learning Module Networks</a></p>
<p>Author: Eran Segal, Dana Pe'er, Aviv Regev, Daphne Koller, Nir Friedman</p><p>Abstract: Methods for learning Bayesian networks can discover dependency structure between observed variables. Although these methods are useful in many applications, they run into computational and statistical problems in domains that involve a large number of variables. In this paper,1 we consider a solution that is applicable when many variables have similar behavior. We introduce a new class of models, module networks, that explicitly partition the variables into modules, so that the variables in each module share the same parents in the network and the same conditional probability distribution. We deﬁne the semantics of module networks, and describe an algorithm that learns the modules’ composition and their dependency structure from data. Evaluation on real data in the domains of gene expression and the stock market shows that module networks generalize better than Bayesian networks, and that the learned module network structure reveals regularities that are obscured in learned Bayesian networks. 1. A preliminary version of this paper appeared in the Proceedings of the Nineteenth Conference on Uncertainty in Artiﬁcial Intelligence, 2003 (UAI ’03). c 2005 Eran Segal, Dana Pe’er, Aviv Regev, Daphne Koller and Nir Friedman. S EGAL , P E ’ ER , R EGEV, KOLLER AND F RIEDMAN</p><p>2 0.23480329 <a title="44-lsi-2" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>Author: Gal Elidan, Nir Friedman</p><p>Abstract: A central challenge in learning probabilistic graphical models is dealing with domains that involve hidden variables. The common approach for learning model parameters in such domains is the expectation maximization (EM) algorithm. This algorithm, however, can easily get trapped in suboptimal local maxima. Learning the model structure is even more challenging. The structural EM algorithm can adapt the structure in the presence of hidden variables, but usually performs poorly without prior knowledge about the cardinality and location of the hidden variables. In this work, we present a general approach for learning Bayesian networks with hidden variables that overcomes these problems. The approach builds on the information bottleneck framework of Tishby et al. (1999). We start by proving formal correspondence between the information bottleneck objective and the standard parametric EM functional. We then use this correspondence to construct a learning algorithm that combines an information-theoretic smoothing term with a continuation procedure. Intuitively, the algorithm bypasses local maxima and achieves superior solutions by following a continuous path from a solution of, an easy and smooth, target function, to a solution of the desired likelihood function. As we show, our algorithmic framework allows learning of the parameters as well as the structure of a network. In addition, it also allows us to introduce new hidden variables during model selection and learn their cardinality. We demonstrate the performance of our procedure on several challenging real-life data sets. Keywords: Bayesian networks, hidden variables, information bottleneck, continuation, variational methods</p><p>3 0.1618109 <a title="44-lsi-3" href="./jmlr-2005-Estimation_of_Non-Normalized_Statistical_Models_by_Score_Matching.html">31 jmlr-2005-Estimation of Non-Normalized Statistical Models by Score Matching</a></p>
<p>Author: Aapo Hyvärinen</p><p>Abstract: One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very diﬃcult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simpliﬁes to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete ﬁlter set for natural image data. Keywords: statistical estimation, non-normalized densities, pseudo-likelihood, Markov chain Monte Carlo, contrastive divergence</p><p>4 0.1466583 <a title="44-lsi-4" href="./jmlr-2005-Local_Propagation_in_Conditional_Gaussian_Bayesian_Networks.html">51 jmlr-2005-Local Propagation in Conditional Gaussian Bayesian Networks</a></p>
<p>Author: Robert G. Cowell</p><p>Abstract: This paper describes a scheme for local computation in conditional Gaussian Bayesian networks that combines the approach of Lauritzen and Jensen (2001) with some elements of Shachter and Kenley (1989). Message passing takes place on an elimination tree structure rather than the more compact (and usual) junction tree of cliques. This yields a local computation scheme in which all calculations involving the continuous variables are performed by manipulating univariate regressions, and hence matrix operations are avoided. Keywords: Bayesian networks, conditional Gaussian distributions, propagation algorithm, elimination tree</p><p>5 0.11371844 <a title="44-lsi-5" href="./jmlr-2005-Asymptotic_Model_Selection_for_Naive_Bayesian_Networks.html">15 jmlr-2005-Asymptotic Model Selection for Naive Bayesian Networks</a></p>
<p>Author: Dmitry Rusakov, Dan Geiger</p><p>Abstract: We develop a closed form asymptotic formula to compute the marginal likelihood of data given a naive Bayesian network model with two hidden states and binary features. This formula deviates from the standard BIC score. Our work provides a concrete example that the BIC score is generally incorrect for statistical models that belong to stratiﬁed exponential families. This claim stands in contrast to linear and curved exponential families, where the BIC score has been proven to provide a correct asymptotic approximation for the marginal likelihood. Keywords: Bayesian networks, asymptotic model selection, Bayesian information criterion (BIC)</p><p>6 0.11276133 <a title="44-lsi-6" href="./jmlr-2005-Inner_Product_Spaces_for_Bayesian_Networks.html">40 jmlr-2005-Inner Product Spaces for Bayesian Networks</a></p>
<p>7 0.10991068 <a title="44-lsi-7" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>8 0.092438094 <a title="44-lsi-8" href="./jmlr-2005-Tree-Based_Batch_Mode_Reinforcement_Learning.html">68 jmlr-2005-Tree-Based Batch Mode Reinforcement Learning</a></p>
<p>9 0.085061289 <a title="44-lsi-9" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>10 0.084327415 <a title="44-lsi-10" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>11 0.075042054 <a title="44-lsi-11" href="./jmlr-2005-Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models.html">62 jmlr-2005-Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models</a></p>
<p>12 0.07254833 <a title="44-lsi-12" href="./jmlr-2005-Tutorial_on_Practical_Prediction_Theory_for_Classification.html">69 jmlr-2005-Tutorial on Practical Prediction Theory for Classification</a></p>
<p>13 0.070685782 <a title="44-lsi-13" href="./jmlr-2005-Core_Vector_Machines%3A_Fast_SVM_Training_on_Very_Large_Data_Sets.html">24 jmlr-2005-Core Vector Machines: Fast SVM Training on Very Large Data Sets</a></p>
<p>14 0.06979949 <a title="44-lsi-14" href="./jmlr-2005-Learning_Multiple_Tasks_with_Kernel_Methods.html">45 jmlr-2005-Learning Multiple Tasks with Kernel Methods</a></p>
<p>15 0.069142073 <a title="44-lsi-15" href="./jmlr-2005-A_Bayesian_Model_for_Supervised_Clustering_with_the_Dirichlet_Process_Prior.html">2 jmlr-2005-A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior</a></p>
<p>16 0.056025691 <a title="44-lsi-16" href="./jmlr-2005-A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression.html">7 jmlr-2005-A Unifying View of Sparse Approximate Gaussian Process Regression</a></p>
<p>17 0.055852644 <a title="44-lsi-17" href="./jmlr-2005-Analysis_of_Variance_of_Cross-Validation_Estimators_of_the_Generalization_Error.html">13 jmlr-2005-Analysis of Variance of Cross-Validation Estimators of the Generalization Error</a></p>
<p>18 0.055252708 <a title="44-lsi-18" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>19 0.049543738 <a title="44-lsi-19" href="./jmlr-2005-Variational_Message_Passing.html">71 jmlr-2005-Variational Message Passing</a></p>
<p>20 0.048007611 <a title="44-lsi-20" href="./jmlr-2005-Matrix_Exponentiated_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">55 jmlr-2005-Matrix Exponentiated Gradient Updates for On-line Learning and Bregman Projection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.014), (17, 0.041), (19, 0.017), (36, 0.048), (37, 0.033), (41, 0.374), (42, 0.016), (43, 0.043), (47, 0.012), (52, 0.078), (59, 0.021), (70, 0.024), (88, 0.136), (90, 0.011), (94, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72189099 <a title="44-lda-1" href="./jmlr-2005-Learning_Module_Networks.html">44 jmlr-2005-Learning Module Networks</a></p>
<p>Author: Eran Segal, Dana Pe'er, Aviv Regev, Daphne Koller, Nir Friedman</p><p>Abstract: Methods for learning Bayesian networks can discover dependency structure between observed variables. Although these methods are useful in many applications, they run into computational and statistical problems in domains that involve a large number of variables. In this paper,1 we consider a solution that is applicable when many variables have similar behavior. We introduce a new class of models, module networks, that explicitly partition the variables into modules, so that the variables in each module share the same parents in the network and the same conditional probability distribution. We deﬁne the semantics of module networks, and describe an algorithm that learns the modules’ composition and their dependency structure from data. Evaluation on real data in the domains of gene expression and the stock market shows that module networks generalize better than Bayesian networks, and that the learned module network structure reveals regularities that are obscured in learned Bayesian networks. 1. A preliminary version of this paper appeared in the Proceedings of the Nineteenth Conference on Uncertainty in Artiﬁcial Intelligence, 2003 (UAI ’03). c 2005 Eran Segal, Dana Pe’er, Aviv Regev, Daphne Koller and Nir Friedman. S EGAL , P E ’ ER , R EGEV, KOLLER AND F RIEDMAN</p><p>2 0.40796757 <a title="44-lda-2" href="./jmlr-2005-Variational_Message_Passing.html">71 jmlr-2005-Variational Message Passing</a></p>
<p>Author: John Winn, Christopher M. Bishop</p><p>Abstract: Bayesian inference is now widely established as one of the principal foundations for machine learning. In practice, exact inference is rarely possible, and so a variety of approximation techniques have been developed, one of the most widely used being a deterministic framework called variational inference. In this paper we introduce Variational Message Passing (VMP), a general purpose algorithm for applying variational inference to Bayesian Networks. Like belief propagation, VMP proceeds by sending messages between nodes in the network and updating posterior beliefs using local operations at each node. Each such update increases a lower bound on the log evidence (unless already at a local maximum). In contrast to belief propagation, VMP can be applied to a very general class of conjugate-exponential models because it uses a factorised variational approximation. Furthermore, by introducing additional variational parameters, VMP can be applied to models containing non-conjugate distributions. The VMP framework also allows the lower bound to be evaluated, and this can be used both for model comparison and for detection of convergence. Variational message passing has been implemented in the form of a general purpose inference engine called VIBES (‘Variational Inference for BayEsian networkS’) which allows models to be speciﬁed graphically and then solved variationally without recourse to coding. Keywords: Bayesian networks, variational inference, message passing</p><p>3 0.40427426 <a title="44-lda-3" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>Author: Gal Elidan, Nir Friedman</p><p>Abstract: A central challenge in learning probabilistic graphical models is dealing with domains that involve hidden variables. The common approach for learning model parameters in such domains is the expectation maximization (EM) algorithm. This algorithm, however, can easily get trapped in suboptimal local maxima. Learning the model structure is even more challenging. The structural EM algorithm can adapt the structure in the presence of hidden variables, but usually performs poorly without prior knowledge about the cardinality and location of the hidden variables. In this work, we present a general approach for learning Bayesian networks with hidden variables that overcomes these problems. The approach builds on the information bottleneck framework of Tishby et al. (1999). We start by proving formal correspondence between the information bottleneck objective and the standard parametric EM functional. We then use this correspondence to construct a learning algorithm that combines an information-theoretic smoothing term with a continuation procedure. Intuitively, the algorithm bypasses local maxima and achieves superior solutions by following a continuous path from a solution of, an easy and smooth, target function, to a solution of the desired likelihood function. As we show, our algorithmic framework allows learning of the parameters as well as the structure of a network. In addition, it also allows us to introduce new hidden variables during model selection and learn their cardinality. We demonstrate the performance of our procedure on several challenging real-life data sets. Keywords: Bayesian networks, hidden variables, information bottleneck, continuation, variational methods</p><p>4 0.40420231 <a title="44-lda-4" href="./jmlr-2005-Learning_the_Kernel_with_Hyperkernels_%C2%A0%C2%A0%C2%A0%C2%A0%28Kernel_Machines_Section%29.html">49 jmlr-2005-Learning the Kernel with Hyperkernels     (Kernel Machines Section)</a></p>
<p>Author: Cheng Soon Ong, Alexander J. Smola, Robert C. Williamson</p><p>Abstract: This paper addresses the problem of choosing a kernel suitable for estimation with a support vector machine, hence further automating machine learning. This goal is achieved by deﬁning a reproducing kernel Hilbert space on the space of kernels itself. Such a formulation leads to a statistical estimation problem similar to the problem of minimizing a regularized risk functional. We state the equivalent representer theorem for the choice of kernels and present a semideﬁnite programming formulation of the resulting optimization problem. Several recipes for constructing hyperkernels are provided, as well as the details of common machine learning problems. Experimental results for classiﬁcation, regression and novelty detection on UCI data show the feasibility of our approach. Keywords: learning the kernel, capacity control, kernel methods, support vector machines, representer theorem, semideﬁnite programming</p><p>5 0.40418461 <a title="44-lda-5" href="./jmlr-2005-Algorithmic_Stability_and_Meta-Learning.html">11 jmlr-2005-Algorithmic Stability and Meta-Learning</a></p>
<p>Author: Andreas Maurer</p><p>Abstract: A mechnism of transfer learning is analysed, where samples drawn from different learning tasks of an environment are used to improve the learners performance on a new task. We give a general method to prove generalisation error bounds for such meta-algorithms. The method can be applied to the bias learning model of J. Baxter and to derive novel generalisation bounds for metaalgorithms searching spaces of uniformly stable algorithms. We also present an application to regularized least squares regression. Keywords: algorithmic stability, meta-learning, learning to learn</p><p>6 0.40411967 <a title="44-lda-6" href="./jmlr-2005-Information_Bottleneck_for_Gaussian_Variables.html">39 jmlr-2005-Information Bottleneck for Gaussian Variables</a></p>
<p>7 0.40252981 <a title="44-lda-7" href="./jmlr-2005-Maximum_Margin_Algorithms_with_Boolean_Kernels.html">56 jmlr-2005-Maximum Margin Algorithms with Boolean Kernels</a></p>
<p>8 0.40234092 <a title="44-lda-8" href="./jmlr-2005-A_Classification_Framework_for_Anomaly_Detection.html">3 jmlr-2005-A Classification Framework for Anomaly Detection</a></p>
<p>9 0.40196517 <a title="44-lda-9" href="./jmlr-2005-On_the_Nystr%C3%B6m_Method_for_Approximating_a_Gram_Matrix_for_Improved_Kernel-Based_Learning.html">60 jmlr-2005-On the Nyström Method for Approximating a Gram Matrix for Improved Kernel-Based Learning</a></p>
<p>10 0.40172222 <a title="44-lda-10" href="./jmlr-2005-Semigroup_Kernels_on_Measures.html">64 jmlr-2005-Semigroup Kernels on Measures</a></p>
<p>11 0.40030929 <a title="44-lda-11" href="./jmlr-2005-Clustering_with_Bregman_Divergences.html">20 jmlr-2005-Clustering with Bregman Divergences</a></p>
<p>12 0.40014172 <a title="44-lda-12" href="./jmlr-2005-Learning_the_Kernel_Function_via_Regularization.html">48 jmlr-2005-Learning the Kernel Function via Regularization</a></p>
<p>13 0.39472765 <a title="44-lda-13" href="./jmlr-2005-Generalization_Bounds_for_the_Area_Under_the_ROC_Curve.html">38 jmlr-2005-Generalization Bounds for the Area Under the ROC Curve</a></p>
<p>14 0.39117858 <a title="44-lda-14" href="./jmlr-2005-Estimation_of_Non-Normalized_Statistical_Models_by_Score_Matching.html">31 jmlr-2005-Estimation of Non-Normalized Statistical Models by Score Matching</a></p>
<p>15 0.38962194 <a title="44-lda-15" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>16 0.38521579 <a title="44-lda-16" href="./jmlr-2005-Loopy_Belief_Propagation%3A_Convergence_and_Effects_of_Message_Errors.html">52 jmlr-2005-Loopy Belief Propagation: Convergence and Effects of Message Errors</a></p>
<p>17 0.38476706 <a title="44-lda-17" href="./jmlr-2005-Learning_a_Mahalanobis_Metric_from_Equivalence_Constraints.html">46 jmlr-2005-Learning a Mahalanobis Metric from Equivalence Constraints</a></p>
<p>18 0.38293198 <a title="44-lda-18" href="./jmlr-2005-Fast_Kernel_Classifiers_with_Online_and_Active_Learning.html">33 jmlr-2005-Fast Kernel Classifiers with Online and Active Learning</a></p>
<p>19 0.38267308 <a title="44-lda-19" href="./jmlr-2005-Frames%2C_Reproducing_Kernels%2C_Regularization_and_Learning.html">35 jmlr-2005-Frames, Reproducing Kernels, Regularization and Learning</a></p>
<p>20 0.38237581 <a title="44-lda-20" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
