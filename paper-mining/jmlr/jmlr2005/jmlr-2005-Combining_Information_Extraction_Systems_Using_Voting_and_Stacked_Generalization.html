<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>21 jmlr-2005-Combining Information Extraction Systems Using Voting and Stacked Generalization</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-21" href="#">jmlr2005-21</a> knowledge-graph by maker-knowledge-mining</p><h1>21 jmlr-2005-Combining Information Extraction Systems Using Voting and Stacked Generalization</h1>
<br/><p>Source: <a title="jmlr-2005-21-pdf" href="http://jmlr.org/papers/volume6/sigletos05a/sigletos05a.pdf">pdf</a></p><p>Author: Georgios Sigletos, Georgios Paliouras, Constantine D. Spyropoulos, Michalis Hatzopoulos</p><p>Abstract: This article investigates the effectiveness of voting and stacked generalization -also known as stacking- in the context of information extraction (IE). A new stacking framework is proposed that accommodates well-known approaches for IE. The key idea is to perform cross-validation on the base-level data set, which consists of text documents annotated with relevant information, in order to create a meta-level data set that consists of feature vectors. A classifier is then trained using the new vectors. Therefore, base-level IE systems are combined with a common classifier at the metalevel. Various voting schemes are presented for comparing against stacking in various IE domains. Well known IE systems are employed at the base-level, together with a variety of classifiers at the meta-level. Results show that both voting and stacking work better when relying on probabilistic estimates by the base-level systems. Voting proved to be effective in most domains in the experiments. Stacking, on the other hand, proved to be consistently effective over all domains, doing comparably or better than voting and always better than the best base-level systems. Particular emphasis is also given to explaining the results obtained by voting and stacking at the meta-level, with respect to the varying degree of similarity in the output of the base-level systems. Keywords: stacking, voting, information extraction, cross-validation 1</p><p>Reference: <a title="jmlr-2005-21-reference" href="../jmlr2005_reference/jmlr-2005-Combining_Information_Extraction_Systems_Using_Voting_and_Stacked_Generalization_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('frag', 0.42), ('stack', 0.413), ('field', 0.369), ('templ', 0.297), ('vot', 0.205), ('laptop', 0.179), ('freit', 0.162), ('ram', 0.142), ('hdcapacity', 0.138), ('multistrategy', 0.138), ('merg', 0.121), ('gb', 0.115), ('opd', 0.11), ('fals', 0.11), ('confid', 0.102), ('procnam', 0.096), ('procspee', 0.096), ('screentype', 0.096), ('sigleto', 0.096), ('text', 0.096)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="21-tfidf-1" href="./jmlr-2005-Combining_Information_Extraction_Systems_Using_Voting_and_Stacked_Generalization.html">21 jmlr-2005-Combining Information Extraction Systems Using Voting and Stacked Generalization</a></p>
<p>2 0.05693157 <a title="21-tfidf-2" href="./jmlr-2005-Learning_Module_Networks.html">44 jmlr-2005-Learning Module Networks</a></p>
<p>3 0.043984633 <a title="21-tfidf-3" href="./jmlr-2005-Machine_Learning_Methods_for_Predicting_Failures_in_Hard_Drives%3A__A_Multiple-Instance_Application.html">53 jmlr-2005-Machine Learning Methods for Predicting Failures in Hard Drives:  A Multiple-Instance Application</a></p>
<p>4 0.043473013 <a title="21-tfidf-4" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth Îµ-Insensitive Regression by Loss Symmetrization</a></p>
<p>5 0.042216826 <a title="21-tfidf-5" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>6 0.04125081 <a title="21-tfidf-6" href="./jmlr-2005-A_Bayes_Optimal_Approach_for_Partitioning_the_Values_of_Categorical_Attributes.html">1 jmlr-2005-A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes</a></p>
<p>7 0.039051361 <a title="21-tfidf-7" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>8 0.032981221 <a title="21-tfidf-8" href="./jmlr-2005-Dimension_Reduction_in_Text_Classification_with_Support_Vector_Machines.html">27 jmlr-2005-Dimension Reduction in Text Classification with Support Vector Machines</a></p>
<p>9 0.031970609 <a title="21-tfidf-9" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>10 0.025918294 <a title="21-tfidf-10" href="./jmlr-2005-Estimation_of_Non-Normalized_Statistical_Models_by_Score_Matching.html">31 jmlr-2005-Estimation of Non-Normalized Statistical Models by Score Matching</a></p>
<p>11 0.024491774 <a title="21-tfidf-11" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>12 0.023830349 <a title="21-tfidf-12" href="./jmlr-2005-Active_Learning_to_Recognize_Multiple_Types_of_Plankton.html">9 jmlr-2005-Active Learning to Recognize Multiple Types of Plankton</a></p>
<p>13 0.019874012 <a title="21-tfidf-13" href="./jmlr-2005-What%27s_Strange_About_Recent_Events_%28WSARE%29%3A_An_Algorithm_for_the_Early_Detection_of_Disease_Outbreaks.html">72 jmlr-2005-What's Strange About Recent Events (WSARE): An Algorithm for the Early Detection of Disease Outbreaks</a></p>
<p>14 0.019320488 <a title="21-tfidf-14" href="./jmlr-2005-Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models.html">62 jmlr-2005-Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models</a></p>
<p>15 0.019204987 <a title="21-tfidf-15" href="./jmlr-2005-A_Bayesian_Model_for_Supervised_Clustering_with_the_Dirichlet_Process_Prior.html">2 jmlr-2005-A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior</a></p>
<p>16 0.018510921 <a title="21-tfidf-16" href="./jmlr-2005-Separating_a_Real-Life_Nonlinear_Image_Mixture.html">65 jmlr-2005-Separating a Real-Life Nonlinear Image Mixture</a></p>
<p>17 0.016613375 <a title="21-tfidf-17" href="./jmlr-2005-Diffusion_Kernels_on_Statistical_Manifolds.html">26 jmlr-2005-Diffusion Kernels on Statistical Manifolds</a></p>
<p>18 0.016483847 <a title="21-tfidf-18" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>19 0.015339644 <a title="21-tfidf-19" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>20 0.015248311 <a title="21-tfidf-20" href="./jmlr-2005-A_Modified_Finite_Newton_Method_for_Fast_Solution_of_Large_Scale_Linear_SVMs.html">6 jmlr-2005-A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.102), (1, 0.066), (2, -0.051), (3, 0.077), (4, -0.06), (5, 0.111), (6, 0.015), (7, -0.047), (8, -0.05), (9, 0.045), (10, 0.024), (11, 0.172), (12, -0.083), (13, 0.024), (14, -0.173), (15, 0.133), (16, 0.213), (17, 0.036), (18, 0.084), (19, 0.049), (20, 0.006), (21, -0.102), (22, 0.097), (23, 0.171), (24, 0.31), (25, -0.077), (26, -0.358), (27, 0.09), (28, -0.148), (29, -0.249), (30, -0.113), (31, -0.24), (32, -0.197), (33, 0.079), (34, 0.212), (35, -0.295), (36, -0.014), (37, -0.032), (38, 0.144), (39, -0.063), (40, -0.077), (41, -0.047), (42, -0.094), (43, 0.035), (44, 0.192), (45, -0.123), (46, -0.018), (47, 0.203), (48, 0.026), (49, -0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97854352 <a title="21-lsi-1" href="./jmlr-2005-Combining_Information_Extraction_Systems_Using_Voting_and_Stacked_Generalization.html">21 jmlr-2005-Combining Information Extraction Systems Using Voting and Stacked Generalization</a></p>
<p>2 0.14795272 <a title="21-lsi-2" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>3 0.13241816 <a title="21-lsi-3" href="./jmlr-2005-Learning_Module_Networks.html">44 jmlr-2005-Learning Module Networks</a></p>
<p>4 0.12222948 <a title="21-lsi-4" href="./jmlr-2005-Dimension_Reduction_in_Text_Classification_with_Support_Vector_Machines.html">27 jmlr-2005-Dimension Reduction in Text Classification with Support Vector Machines</a></p>
<p>5 0.11832544 <a title="21-lsi-5" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>6 0.11622585 <a title="21-lsi-6" href="./jmlr-2005-Machine_Learning_Methods_for_Predicting_Failures_in_Hard_Drives%3A__A_Multiple-Instance_Application.html">53 jmlr-2005-Machine Learning Methods for Predicting Failures in Hard Drives:  A Multiple-Instance Application</a></p>
<p>7 0.10865603 <a title="21-lsi-7" href="./jmlr-2005-An_MDP-Based_Recommender_System.html">12 jmlr-2005-An MDP-Based Recommender System</a></p>
<p>8 0.10602245 <a title="21-lsi-8" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>9 0.091637209 <a title="21-lsi-9" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth Îµ-Insensitive Regression by Loss Symmetrization</a></p>
<p>10 0.090149276 <a title="21-lsi-10" href="./jmlr-2005-A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression.html">7 jmlr-2005-A Unifying View of Sparse Approximate Gaussian Process Regression</a></p>
<p>11 0.081749596 <a title="21-lsi-11" href="./jmlr-2005-Core_Vector_Machines%3A_Fast_SVM_Training_on_Very_Large_Data_Sets.html">24 jmlr-2005-Core Vector Machines: Fast SVM Training on Very Large Data Sets</a></p>
<p>12 0.079767913 <a title="21-lsi-12" href="./jmlr-2005-A_Bayes_Optimal_Approach_for_Partitioning_the_Values_of_Categorical_Attributes.html">1 jmlr-2005-A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes</a></p>
<p>13 0.075580798 <a title="21-lsi-13" href="./jmlr-2005-Active_Learning_to_Recognize_Multiple_Types_of_Plankton.html">9 jmlr-2005-Active Learning to Recognize Multiple Types of Plankton</a></p>
<p>14 0.075206198 <a title="21-lsi-14" href="./jmlr-2005-Estimation_of_Non-Normalized_Statistical_Models_by_Score_Matching.html">31 jmlr-2005-Estimation of Non-Normalized Statistical Models by Score Matching</a></p>
<p>15 0.072577998 <a title="21-lsi-15" href="./jmlr-2005-Expectation_Consistent_Approximate_Inference.html">32 jmlr-2005-Expectation Consistent Approximate Inference</a></p>
<p>16 0.066702798 <a title="21-lsi-16" href="./jmlr-2005-Learning_with_Decision_Lists_of_Data-Dependent_Features.html">50 jmlr-2005-Learning with Decision Lists of Data-Dependent Features</a></p>
<p>17 0.065761529 <a title="21-lsi-17" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>18 0.064400099 <a title="21-lsi-18" href="./jmlr-2005-Diffusion_Kernels_on_Statistical_Manifolds.html">26 jmlr-2005-Diffusion Kernels on Statistical Manifolds</a></p>
<p>19 0.061189719 <a title="21-lsi-19" href="./jmlr-2005-Separating_a_Real-Life_Nonlinear_Image_Mixture.html">65 jmlr-2005-Separating a Real-Life Nonlinear Image Mixture</a></p>
<p>20 0.057172123 <a title="21-lsi-20" href="./jmlr-2005-Algorithmic_Stability_and_Meta-Learning.html">11 jmlr-2005-Algorithmic Stability and Meta-Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.03), (44, 0.688), (62, 0.072), (68, 0.022), (78, 0.014), (88, 0.015), (97, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91693032 <a title="21-lda-1" href="./jmlr-2005-Concentration_Bounds_for_Unigram_Language_Models.html">22 jmlr-2005-Concentration Bounds for Unigram Language Models</a></p>
<p>same-paper 2 0.89849579 <a title="21-lda-2" href="./jmlr-2005-Combining_Information_Extraction_Systems_Using_Voting_and_Stacked_Generalization.html">21 jmlr-2005-Combining Information Extraction Systems Using Voting and Stacked Generalization</a></p>
<p>3 0.85461128 <a title="21-lda-3" href="./jmlr-2005-Estimation_of_Non-Normalized_Statistical_Models_by_Score_Matching.html">31 jmlr-2005-Estimation of Non-Normalized Statistical Models by Score Matching</a></p>
<p>4 0.41624185 <a title="21-lda-4" href="./jmlr-2005-Asymptotic_Model_Selection_for_Naive_Bayesian_Networks.html">15 jmlr-2005-Asymptotic Model Selection for Naive Bayesian Networks</a></p>
<p>5 0.33088955 <a title="21-lda-5" href="./jmlr-2005-Assessing_Approximate_Inference_for_Binary_Gaussian_Process_Classification.html">14 jmlr-2005-Assessing Approximate Inference for Binary Gaussian Process Classification</a></p>
<p>6 0.32017457 <a title="21-lda-6" href="./jmlr-2005-Denoising_Source_Separation.html">25 jmlr-2005-Denoising Source Separation</a></p>
<p>7 0.31781426 <a title="21-lda-7" href="./jmlr-2005-Generalization_Bounds_and_Complexities_Based_on_Sparsity_and_Clustering_for_Convex_Combinations_of_Functions_from_Random_Classes.html">37 jmlr-2005-Generalization Bounds and Complexities Based on Sparsity and Clustering for Convex Combinations of Functions from Random Classes</a></p>
<p>8 0.30520555 <a title="21-lda-8" href="./jmlr-2005-Managing_Diversity_in_Regression_Ensembles.html">54 jmlr-2005-Managing Diversity in Regression Ensembles</a></p>
<p>9 0.29505092 <a title="21-lda-9" href="./jmlr-2005-Kernel_Methods_for_Measuring_Independence.html">41 jmlr-2005-Kernel Methods for Measuring Independence</a></p>
<p>10 0.2933934 <a title="21-lda-10" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth Îµ-Insensitive Regression by Loss Symmetrization</a></p>
<p>11 0.27949899 <a title="21-lda-11" href="./jmlr-2005-Quasi-Geodesic_Neural_Learning_Algorithms_Over_the_Orthogonal_Group%3A_A_Tutorial.html">63 jmlr-2005-Quasi-Geodesic Neural Learning Algorithms Over the Orthogonal Group: A Tutorial</a></p>
<p>12 0.27796048 <a title="21-lda-12" href="./jmlr-2005-Asymptotics_in_Empirical_Risk_Minimization.html">16 jmlr-2005-Asymptotics in Empirical Risk Minimization</a></p>
<p>13 0.27701828 <a title="21-lda-13" href="./jmlr-2005-Efficient_Margin_Maximizing_with_Boosting.html">29 jmlr-2005-Efficient Margin Maximizing with Boosting</a></p>
<p>14 0.27368456 <a title="21-lda-14" href="./jmlr-2005-Convergence_Theorems_for_Generalized_Alternating_Minimization_Procedures.html">23 jmlr-2005-Convergence Theorems for Generalized Alternating Minimization Procedures</a></p>
<p>15 0.26895201 <a title="21-lda-15" href="./jmlr-2005-Information_Bottleneck_for_Gaussian_Variables.html">39 jmlr-2005-Information Bottleneck for Gaussian Variables</a></p>
<p>16 0.26380923 <a title="21-lda-16" href="./jmlr-2005-Algorithmic_Stability_and_Meta-Learning.html">11 jmlr-2005-Algorithmic Stability and Meta-Learning</a></p>
<p>17 0.26305914 <a title="21-lda-17" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>18 0.26096326 <a title="21-lda-18" href="./jmlr-2005-Estimating_Functions_for_Blind_Separation_When_Sources_Have_Variance_Dependencies.html">30 jmlr-2005-Estimating Functions for Blind Separation When Sources Have Variance Dependencies</a></p>
<p>19 0.2569097 <a title="21-lda-19" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>20 0.25684723 <a title="21-lda-20" href="./jmlr-2005-Variational_Message_Passing.html">71 jmlr-2005-Variational Message Passing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
