<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 jmlr-2005-Efficient Computation of Gapped Substring Kernels on Large Alphabets</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-28" href="#">jmlr2005-28</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>28 jmlr-2005-Efficient Computation of Gapped Substring Kernels on Large Alphabets</h1>
<br/><p>Source: <a title="jmlr-2005-28-pdf" href="http://jmlr.org/papers/volume6/rousu05a/rousu05a.pdf">pdf</a></p><p>Author: Juho Rousu, John Shawe-Taylor</p><p>Abstract: We present a sparse dynamic programming algorithm that, given two strings s and t, a gap penalty λ, and an integer p, computes the value of the gap-weighted length-p subsequences kernel. The algorithm works in time O(p|M| log |t|), where M = {(i, j)|si = t j } is the set of matches of characters in the two sequences. The algorithm is easily adapted to handle bounded length subsequences and different gap-penalty schemes, including penalizing by the total length of gaps and the number of gaps as well as incorporating character-speciﬁc match/gap penalties. The new algorithm is empirically evaluated against a full dynamic programming approach and a trie-based algorithm both on synthetic and newswire article data. Based on the experiments, the full dynamic programming approach is the fastest on short strings, and on long strings if the alphabet is small. On large alphabets, the new sparse dynamic programming algorithm is the most efﬁcient. On medium-sized alphabets the trie-based approach is best if the maximum number of allowed gaps is strongly restricted. Keywords: kernel methods, string kernels, text categorization, sparse dynamic programming</p><p>Reference: <a title="jmlr-2005-28-reference" href="../jmlr2005_reference/jmlr-2005-Efficient_Computation_of_Gapped_Substring_Kernels_on_Large_Alphabets_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dog', 0.493), ('gap', 0.441), ('strings', 0.276), ('chas', 0.271), ('fat', 0.227), ('string', 0.162), ('subsequ', 0.152), ('subst', 0.142), ('phrases', 0.136), ('rousu', 0.136), ('gmax', 0.133), ('jq', 0.133), ('alphabet', 0.121), ('occur', 0.118), ('dynam', 0.116), ('syl', 0.114), ('haw', 0.09), ('les', 0.086), ('kernel', 0.082), ('text', 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="28-tfidf-1" href="./jmlr-2005-Efficient_Computation_of_Gapped_Substring_Kernels_on_Large_Alphabets.html">28 jmlr-2005-Efficient Computation of Gapped Substring Kernels on Large Alphabets</a></p>
<p>2 0.07193353 <a title="28-tfidf-2" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>3 0.056049824 <a title="28-tfidf-3" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>4 0.046713293 <a title="28-tfidf-4" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>5 0.045573685 <a title="28-tfidf-5" href="./jmlr-2005-Learning_Multiple_Tasks_with_Kernel_Methods.html">45 jmlr-2005-Learning Multiple Tasks with Kernel Methods</a></p>
<p>6 0.043997157 <a title="28-tfidf-6" href="./jmlr-2005-Semigroup_Kernels_on_Measures.html">64 jmlr-2005-Semigroup Kernels on Measures</a></p>
<p>7 0.036977511 <a title="28-tfidf-7" href="./jmlr-2005-Maximum_Margin_Algorithms_with_Boolean_Kernels.html">56 jmlr-2005-Maximum Margin Algorithms with Boolean Kernels</a></p>
<p>8 0.032099463 <a title="28-tfidf-8" href="./jmlr-2005-A_Bayesian_Model_for_Supervised_Clustering_with_the_Dirichlet_Process_Prior.html">2 jmlr-2005-A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior</a></p>
<p>9 0.031114016 <a title="28-tfidf-9" href="./jmlr-2005-Dimension_Reduction_in_Text_Classification_with_Support_Vector_Machines.html">27 jmlr-2005-Dimension Reduction in Text Classification with Support Vector Machines</a></p>
<p>10 0.030200996 <a title="28-tfidf-10" href="./jmlr-2005-Frames%2C_Reproducing_Kernels%2C_Regularization_and_Learning.html">35 jmlr-2005-Frames, Reproducing Kernels, Regularization and Learning</a></p>
<p>11 0.027903302 <a title="28-tfidf-11" href="./jmlr-2005-Fast_Kernel_Classifiers_with_Online_and_Active_Learning.html">33 jmlr-2005-Fast Kernel Classifiers with Online and Active Learning</a></p>
<p>12 0.027008304 <a title="28-tfidf-12" href="./jmlr-2005-Learning_the_Kernel_with_Hyperkernels_%C2%A0%C2%A0%C2%A0%C2%A0%28Kernel_Machines_Section%29.html">49 jmlr-2005-Learning the Kernel with Hyperkernels     (Kernel Machines Section)</a></p>
<p>13 0.026891356 <a title="28-tfidf-13" href="./jmlr-2005-Learning_with_Decision_Lists_of_Data-Dependent_Features.html">50 jmlr-2005-Learning with Decision Lists of Data-Dependent Features</a></p>
<p>14 0.025817297 <a title="28-tfidf-14" href="./jmlr-2005-Diffusion_Kernels_on_Statistical_Manifolds.html">26 jmlr-2005-Diffusion Kernels on Statistical Manifolds</a></p>
<p>15 0.02569839 <a title="28-tfidf-15" href="./jmlr-2005-Active_Coevolutionary_Learning_of_Deterministic_Finite_Automata.html">8 jmlr-2005-Active Coevolutionary Learning of Deterministic Finite Automata</a></p>
<p>16 0.025409631 <a title="28-tfidf-16" href="./jmlr-2005-Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models.html">62 jmlr-2005-Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models</a></p>
<p>17 0.023630816 <a title="28-tfidf-17" href="./jmlr-2005-Efficient_Margin_Maximizing_with_Boosting.html">29 jmlr-2005-Efficient Margin Maximizing with Boosting</a></p>
<p>18 0.023365773 <a title="28-tfidf-18" href="./jmlr-2005-A_Modified_Finite_Newton_Method_for_Fast_Solution_of_Large_Scale_Linear_SVMs.html">6 jmlr-2005-A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs</a></p>
<p>19 0.019760225 <a title="28-tfidf-19" href="./jmlr-2005-Change_Point_Problems_in_Linear_Dynamical_Systems.html">17 jmlr-2005-Change Point Problems in Linear Dynamical Systems</a></p>
<p>20 0.018554045 <a title="28-tfidf-20" href="./jmlr-2005-Tree-Based_Batch_Mode_Reinforcement_Learning.html">68 jmlr-2005-Tree-Based Batch Mode Reinforcement Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.124), (1, 0.098), (2, -0.083), (3, -0.044), (4, -0.052), (5, 0.016), (6, 0.089), (7, -0.014), (8, -0.078), (9, -0.045), (10, -0.036), (11, 0.052), (12, 0.214), (13, -0.216), (14, -0.147), (15, -0.096), (16, 0.076), (17, 0.024), (18, 0.21), (19, 0.003), (20, -0.014), (21, -0.058), (22, -0.034), (23, 0.268), (24, -0.093), (25, -0.277), (26, 0.041), (27, 0.259), (28, -0.058), (29, 0.186), (30, 0.224), (31, -0.153), (32, 0.007), (33, -0.012), (34, -0.145), (35, 0.154), (36, -0.345), (37, 0.143), (38, -0.019), (39, -0.084), (40, 0.219), (41, -0.083), (42, 0.097), (43, -0.061), (44, 0.13), (45, 0.024), (46, 0.182), (47, -0.003), (48, -0.13), (49, -0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96755373 <a title="28-lsi-1" href="./jmlr-2005-Efficient_Computation_of_Gapped_Substring_Kernels_on_Large_Alphabets.html">28 jmlr-2005-Efficient Computation of Gapped Substring Kernels on Large Alphabets</a></p>
<p>2 0.24835232 <a title="28-lsi-2" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>3 0.21514349 <a title="28-lsi-3" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>4 0.19401 <a title="28-lsi-4" href="./jmlr-2005-Semigroup_Kernels_on_Measures.html">64 jmlr-2005-Semigroup Kernels on Measures</a></p>
<p>5 0.14909807 <a title="28-lsi-5" href="./jmlr-2005-Learning_with_Decision_Lists_of_Data-Dependent_Features.html">50 jmlr-2005-Learning with Decision Lists of Data-Dependent Features</a></p>
<p>6 0.14510973 <a title="28-lsi-6" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>7 0.1328572 <a title="28-lsi-7" href="./jmlr-2005-Maximum_Margin_Algorithms_with_Boolean_Kernels.html">56 jmlr-2005-Maximum Margin Algorithms with Boolean Kernels</a></p>
<p>8 0.11746093 <a title="28-lsi-8" href="./jmlr-2005-Diffusion_Kernels_on_Statistical_Manifolds.html">26 jmlr-2005-Diffusion Kernels on Statistical Manifolds</a></p>
<p>9 0.11626786 <a title="28-lsi-9" href="./jmlr-2005-Tree-Based_Batch_Mode_Reinforcement_Learning.html">68 jmlr-2005-Tree-Based Batch Mode Reinforcement Learning</a></p>
<p>10 0.11562409 <a title="28-lsi-10" href="./jmlr-2005-A_Modified_Finite_Newton_Method_for_Fast_Solution_of_Large_Scale_Linear_SVMs.html">6 jmlr-2005-A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs</a></p>
<p>11 0.11119879 <a title="28-lsi-11" href="./jmlr-2005-Learning_the_Kernel_Function_via_Regularization.html">48 jmlr-2005-Learning the Kernel Function via Regularization</a></p>
<p>12 0.11061604 <a title="28-lsi-12" href="./jmlr-2005-Core_Vector_Machines%3A_Fast_SVM_Training_on_Very_Large_Data_Sets.html">24 jmlr-2005-Core Vector Machines: Fast SVM Training on Very Large Data Sets</a></p>
<p>13 0.10267268 <a title="28-lsi-13" href="./jmlr-2005-Learning_the_Kernel_with_Hyperkernels_%C2%A0%C2%A0%C2%A0%C2%A0%28Kernel_Machines_Section%29.html">49 jmlr-2005-Learning the Kernel with Hyperkernels     (Kernel Machines Section)</a></p>
<p>14 0.097976908 <a title="28-lsi-14" href="./jmlr-2005-Learning_Multiple_Tasks_with_Kernel_Methods.html">45 jmlr-2005-Learning Multiple Tasks with Kernel Methods</a></p>
<p>15 0.096200317 <a title="28-lsi-15" href="./jmlr-2005-Frames%2C_Reproducing_Kernels%2C_Regularization_and_Learning.html">35 jmlr-2005-Frames, Reproducing Kernels, Regularization and Learning</a></p>
<p>16 0.093012296 <a title="28-lsi-16" href="./jmlr-2005-Kernel_Methods_for_Measuring_Independence.html">41 jmlr-2005-Kernel Methods for Measuring Independence</a></p>
<p>17 0.09052901 <a title="28-lsi-17" href="./jmlr-2005-Dimension_Reduction_in_Text_Classification_with_Support_Vector_Machines.html">27 jmlr-2005-Dimension Reduction in Text Classification with Support Vector Machines</a></p>
<p>18 0.088173963 <a title="28-lsi-18" href="./jmlr-2005-Adaptive_Online_Prediction_by_Following_the_Perturbed_Leader.html">10 jmlr-2005-Adaptive Online Prediction by Following the Perturbed Leader</a></p>
<p>19 0.084851518 <a title="28-lsi-19" href="./jmlr-2005-Change_Point_Problems_in_Linear_Dynamical_Systems.html">17 jmlr-2005-Change Point Problems in Linear Dynamical Systems</a></p>
<p>20 0.0732297 <a title="28-lsi-20" href="./jmlr-2005-Efficient_Margin_Maximizing_with_Boosting.html">29 jmlr-2005-Efficient Margin Maximizing with Boosting</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.028), (35, 0.015), (44, 0.025), (47, 0.018), (62, 0.069), (68, 0.042), (74, 0.611), (78, 0.021), (79, 0.011), (88, 0.021), (97, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83037204 <a title="28-lda-1" href="./jmlr-2005-Efficient_Computation_of_Gapped_Substring_Kernels_on_Large_Alphabets.html">28 jmlr-2005-Efficient Computation of Gapped Substring Kernels on Large Alphabets</a></p>
<p>2 0.78341115 <a title="28-lda-2" href="./jmlr-2005-Prioritization_Methods_for_Accelerating_MDP_Solvers.html">61 jmlr-2005-Prioritization Methods for Accelerating MDP Solvers</a></p>
<p>3 0.32014936 <a title="28-lda-3" href="./jmlr-2005-Tree-Based_Batch_Mode_Reinforcement_Learning.html">68 jmlr-2005-Tree-Based Batch Mode Reinforcement Learning</a></p>
<p>4 0.23477477 <a title="28-lda-4" href="./jmlr-2005-Working_Set_Selection_Using_Second_Order_Information_for_Training_Support_Vector_Machines.html">73 jmlr-2005-Working Set Selection Using Second Order Information for Training Support Vector Machines</a></p>
<p>5 0.22911029 <a title="28-lda-5" href="./jmlr-2005-Efficient_Margin_Maximizing_with_Boosting.html">29 jmlr-2005-Efficient Margin Maximizing with Boosting</a></p>
<p>6 0.22160842 <a title="28-lda-6" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>7 0.21187517 <a title="28-lda-7" href="./jmlr-2005-An_MDP-Based_Recommender_System.html">12 jmlr-2005-An MDP-Based Recommender System</a></p>
<p>8 0.21012783 <a title="28-lda-8" href="./jmlr-2005-A_Generalization_Error_for_Q-Learning.html">5 jmlr-2005-A Generalization Error for Q-Learning</a></p>
<p>9 0.2086224 <a title="28-lda-9" href="./jmlr-2005-Active_Coevolutionary_Learning_of_Deterministic_Finite_Automata.html">8 jmlr-2005-Active Coevolutionary Learning of Deterministic Finite Automata</a></p>
<p>10 0.2079283 <a title="28-lda-10" href="./jmlr-2005-Fast_Kernel_Classifiers_with_Online_and_Active_Learning.html">33 jmlr-2005-Fast Kernel Classifiers with Online and Active Learning</a></p>
<p>11 0.20179188 <a title="28-lda-11" href="./jmlr-2005-Quasi-Geodesic_Neural_Learning_Algorithms_Over_the_Orthogonal_Group%3A_A_Tutorial.html">63 jmlr-2005-Quasi-Geodesic Neural Learning Algorithms Over the Orthogonal Group: A Tutorial</a></p>
<p>12 0.20109937 <a title="28-lda-12" href="./jmlr-2005-Information_Bottleneck_for_Gaussian_Variables.html">39 jmlr-2005-Information Bottleneck for Gaussian Variables</a></p>
<p>13 0.19771074 <a title="28-lda-13" href="./jmlr-2005-A_Bayes_Optimal_Approach_for_Partitioning_the_Values_of_Categorical_Attributes.html">1 jmlr-2005-A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes</a></p>
<p>14 0.19609709 <a title="28-lda-14" href="./jmlr-2005-New_Horn_Revision_Algorithms.html">59 jmlr-2005-New Horn Revision Algorithms</a></p>
<p>15 0.19324495 <a title="28-lda-15" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth ε-Insensitive Regression by Loss Symmetrization</a></p>
<p>16 0.19188033 <a title="28-lda-16" href="./jmlr-2005-Change_Point_Problems_in_Linear_Dynamical_Systems.html">17 jmlr-2005-Change Point Problems in Linear Dynamical Systems</a></p>
<p>17 0.19107096 <a title="28-lda-17" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>18 0.19028825 <a title="28-lda-18" href="./jmlr-2005-Loopy_Belief_Propagation%3A_Convergence_and_Effects_of_Message_Errors.html">52 jmlr-2005-Loopy Belief Propagation: Convergence and Effects of Message Errors</a></p>
<p>19 0.1865927 <a title="28-lda-19" href="./jmlr-2005-Semigroup_Kernels_on_Measures.html">64 jmlr-2005-Semigroup Kernels on Measures</a></p>
<p>20 0.18607287 <a title="28-lda-20" href="./jmlr-2005-Maximum_Margin_Algorithms_with_Boolean_Kernels.html">56 jmlr-2005-Maximum Margin Algorithms with Boolean Kernels</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
