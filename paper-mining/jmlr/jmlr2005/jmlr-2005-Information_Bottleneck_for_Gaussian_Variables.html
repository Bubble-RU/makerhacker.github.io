<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>39 jmlr-2005-Information Bottleneck for Gaussian Variables</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2005" href="../home/jmlr2005_home.html">jmlr2005</a> <a title="jmlr-2005-39" href="#">jmlr2005-39</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>39 jmlr-2005-Information Bottleneck for Gaussian Variables</h1>
<br/><p>Source: <a title="jmlr-2005-39-pdf" href="http://jmlr.org/papers/volume6/chechik05a/chechik05a.pdf">pdf</a></p><p>Author: Gal Chechik, Amir Globerson, Naftali Tishby, Yair Weiss</p><p>Abstract: The problem of extracting the relevant aspects of data was previously addressed through the information bottleneck (IB) method, through (soft) clustering one variable while preserving information about another - relevance - variable. The current work extends these ideas to obtain continuous representations that preserve relevant information, rather than discrete clusters, for the special case of multivariate Gaussian variables. While the general continuous IB problem is difﬁcult to solve, we provide an analytic solution for the optimal representation and tradeoff between compression and relevance for the this important case. The obtained optimal representation is a noisy linear projection to eigenvectors of the normalized regression matrix Σx|y Σ−1 , which is also the basis obtained x in canonical correlation analysis. However, in Gaussian IB, the compression tradeoff parameter uniquely determines the dimension, as well as the scale of each eigenvector, through a cascade of structural phase transitions. This introduces a novel interpretation where solutions of different ranks lie on a continuum parametrized by the compression level. Our analysis also provides a complete analytic expression of the preserved information as a function of the compression (the “information-curve”), in terms of the eigenvalue spectrum of the data. As in the discrete case, the information curve is concave and smooth, though it is made of different analytic segments for each optimal dimension. Finally, we show how the algorithmic theory developed in the IB framework provides an iterative algorithm for obtaining the optimal Gaussian projections. Keywords: information bottleneck, Gaussian processes, dimensionality reduction, canonical correlation analysis</p><p>Reference: <a title="jmlr-2005-39-reference" href="../jmlr2005_reference/jmlr-2005-Information_Bottleneck_for_Gaussian_Variables_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tk', 0.52), ('ib', 0.307), ('eigenvect', 0.299), ('gib', 0.198), ('eiss', 0.162), ('hechik', 0.162), ('ishby', 0.162), ('loberson', 0.162), ('cca', 0.146), ('yx', 0.141), ('ytk', 0.135), ('compress', 0.13), ('tishby', 0.127), ('eigenvalu', 0.127), ('ottleneck', 0.125), ('bottleneck', 0.118), ('ak', 0.115), ('nx', 0.11), ('rw', 0.102), ('xy', 0.101)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="39-tfidf-1" href="./jmlr-2005-Information_Bottleneck_for_Gaussian_Variables.html">39 jmlr-2005-Information Bottleneck for Gaussian Variables</a></p>
<p>2 0.13412353 <a title="39-tfidf-2" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>3 0.083292343 <a title="39-tfidf-3" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>4 0.058758788 <a title="39-tfidf-4" href="./jmlr-2005-Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models.html">62 jmlr-2005-Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models</a></p>
<p>5 0.052499302 <a title="39-tfidf-5" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>6 0.050766725 <a title="39-tfidf-6" href="./jmlr-2005-Matrix_Exponentiated_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">55 jmlr-2005-Matrix Exponentiated Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>7 0.04931904 <a title="39-tfidf-7" href="./jmlr-2005-Expectation_Consistent_Approximate_Inference.html">32 jmlr-2005-Expectation Consistent Approximate Inference</a></p>
<p>8 0.044186424 <a title="39-tfidf-8" href="./jmlr-2005-A_Bayesian_Model_for_Supervised_Clustering_with_the_Dirichlet_Process_Prior.html">2 jmlr-2005-A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior</a></p>
<p>9 0.044063784 <a title="39-tfidf-9" href="./jmlr-2005-Learning_with_Decision_Lists_of_Data-Dependent_Features.html">50 jmlr-2005-Learning with Decision Lists of Data-Dependent Features</a></p>
<p>10 0.042485993 <a title="39-tfidf-10" href="./jmlr-2005-Clustering_with_Bregman_Divergences.html">20 jmlr-2005-Clustering with Bregman Divergences</a></p>
<p>11 0.040522691 <a title="39-tfidf-11" href="./jmlr-2005-Denoising_Source_Separation.html">25 jmlr-2005-Denoising Source Separation</a></p>
<p>12 0.039919436 <a title="39-tfidf-12" href="./jmlr-2005-Quasi-Geodesic_Neural_Learning_Algorithms_Over_the_Orthogonal_Group%3A_A_Tutorial.html">63 jmlr-2005-Quasi-Geodesic Neural Learning Algorithms Over the Orthogonal Group: A Tutorial</a></p>
<p>13 0.039540187 <a title="39-tfidf-13" href="./jmlr-2005-Kernel_Methods_for_Measuring_Independence.html">41 jmlr-2005-Kernel Methods for Measuring Independence</a></p>
<p>14 0.038275208 <a title="39-tfidf-14" href="./jmlr-2005-Asymptotic_Model_Selection_for_Naive_Bayesian_Networks.html">15 jmlr-2005-Asymptotic Model Selection for Naive Bayesian Networks</a></p>
<p>15 0.038270324 <a title="39-tfidf-15" href="./jmlr-2005-Assessing_Approximate_Inference_for_Binary_Gaussian_Process_Classification.html">14 jmlr-2005-Assessing Approximate Inference for Binary Gaussian Process Classification</a></p>
<p>16 0.034796011 <a title="39-tfidf-16" href="./jmlr-2005-Variational_Message_Passing.html">71 jmlr-2005-Variational Message Passing</a></p>
<p>17 0.034540001 <a title="39-tfidf-17" href="./jmlr-2005-A_Framework_for_Learning_Predictive_Structures_from_Multiple_Tasks_and_Unlabeled_Data.html">4 jmlr-2005-A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>
<p>18 0.033275899 <a title="39-tfidf-18" href="./jmlr-2005-Tutorial_on_Practical_Prediction_Theory_for_Classification.html">69 jmlr-2005-Tutorial on Practical Prediction Theory for Classification</a></p>
<p>19 0.031970769 <a title="39-tfidf-19" href="./jmlr-2005-Dimension_Reduction_in_Text_Classification_with_Support_Vector_Machines.html">27 jmlr-2005-Dimension Reduction in Text Classification with Support Vector Machines</a></p>
<p>20 0.031762399 <a title="39-tfidf-20" href="./jmlr-2005-Local_Propagation_in_Conditional_Gaussian_Bayesian_Networks.html">51 jmlr-2005-Local Propagation in Conditional Gaussian Bayesian Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.208), (1, 0.037), (2, 0.023), (3, 0.073), (4, -0.113), (5, -0.093), (6, 0.073), (7, 0.061), (8, 0.023), (9, 0.062), (10, 0.093), (11, -0.039), (12, 0.147), (13, -0.147), (14, 0.0), (15, 0.145), (16, 0.025), (17, -0.055), (18, -0.312), (19, 0.286), (20, -0.402), (21, -0.082), (22, -0.028), (23, -0.106), (24, -0.035), (25, 0.008), (26, 0.091), (27, 0.167), (28, -0.141), (29, 0.06), (30, -0.146), (31, 0.009), (32, -0.086), (33, -0.024), (34, -0.12), (35, 0.042), (36, 0.17), (37, -0.222), (38, 0.05), (39, 0.11), (40, 0.104), (41, 0.038), (42, 0.13), (43, 0.075), (44, -0.064), (45, -0.009), (46, -0.053), (47, 0.165), (48, 0.021), (49, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96544003 <a title="39-lsi-1" href="./jmlr-2005-Information_Bottleneck_for_Gaussian_Variables.html">39 jmlr-2005-Information Bottleneck for Gaussian Variables</a></p>
<p>2 0.49331775 <a title="39-lsi-2" href="./jmlr-2005-Feature_Selection_for_Unsupervised_and_Supervised_Inference%3A_The_Emergence_of_Sparsity_in_a_Weight-Based_Approach.html">34 jmlr-2005-Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach</a></p>
<p>3 0.27330825 <a title="39-lsi-3" href="./jmlr-2005-Learning_Hidden_Variable_Networks%3A_The_Information_Bottleneck_Approach.html">43 jmlr-2005-Learning Hidden Variable Networks: The Information Bottleneck Approach</a></p>
<p>4 0.22571699 <a title="39-lsi-4" href="./jmlr-2005-Matrix_Exponentiated_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">55 jmlr-2005-Matrix Exponentiated Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>5 0.21674274 <a title="39-lsi-5" href="./jmlr-2005-Kernel_Methods_for_Measuring_Independence.html">41 jmlr-2005-Kernel Methods for Measuring Independence</a></p>
<p>6 0.17408596 <a title="39-lsi-6" href="./jmlr-2005-Learning_with_Decision_Lists_of_Data-Dependent_Features.html">50 jmlr-2005-Learning with Decision Lists of Data-Dependent Features</a></p>
<p>7 0.16336082 <a title="39-lsi-7" href="./jmlr-2005-A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression.html">7 jmlr-2005-A Unifying View of Sparse Approximate Gaussian Process Regression</a></p>
<p>8 0.16148448 <a title="39-lsi-8" href="./jmlr-2005-Characterization_of_a_Family_of_Algorithms_for_Generalized_Discriminant_Analysis_on_Undersampled_Problems.html">18 jmlr-2005-Characterization of a Family of Algorithms for Generalized Discriminant Analysis on Undersampled Problems</a></p>
<p>9 0.15987509 <a title="39-lsi-9" href="./jmlr-2005-Quasi-Geodesic_Neural_Learning_Algorithms_Over_the_Orthogonal_Group%3A_A_Tutorial.html">63 jmlr-2005-Quasi-Geodesic Neural Learning Algorithms Over the Orthogonal Group: A Tutorial</a></p>
<p>10 0.15798151 <a title="39-lsi-10" href="./jmlr-2005-Expectation_Consistent_Approximate_Inference.html">32 jmlr-2005-Expectation Consistent Approximate Inference</a></p>
<p>11 0.15705654 <a title="39-lsi-11" href="./jmlr-2005-Denoising_Source_Separation.html">25 jmlr-2005-Denoising Source Separation</a></p>
<p>12 0.14801942 <a title="39-lsi-12" href="./jmlr-2005-Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models.html">62 jmlr-2005-Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models</a></p>
<p>13 0.14361133 <a title="39-lsi-13" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>14 0.13545264 <a title="39-lsi-14" href="./jmlr-2005-Prioritization_Methods_for_Accelerating_MDP_Solvers.html">61 jmlr-2005-Prioritization Methods for Accelerating MDP Solvers</a></p>
<p>15 0.13133642 <a title="39-lsi-15" href="./jmlr-2005-Local_Propagation_in_Conditional_Gaussian_Bayesian_Networks.html">51 jmlr-2005-Local Propagation in Conditional Gaussian Bayesian Networks</a></p>
<p>16 0.12626338 <a title="39-lsi-16" href="./jmlr-2005-On_the_Nystr%C3%B6m_Method_for_Approximating_a_Gram_Matrix_for_Improved_Kernel-Based_Learning.html">60 jmlr-2005-On the Nyström Method for Approximating a Gram Matrix for Improved Kernel-Based Learning</a></p>
<p>17 0.11773638 <a title="39-lsi-17" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>18 0.11707111 <a title="39-lsi-18" href="./jmlr-2005-Generalization_Bounds_for_the_Area_Under_the_ROC_Curve.html">38 jmlr-2005-Generalization Bounds for the Area Under the ROC Curve</a></p>
<p>19 0.11399394 <a title="39-lsi-19" href="./jmlr-2005-Asymptotics_in_Empirical_Risk_Minimization.html">16 jmlr-2005-Asymptotics in Empirical Risk Minimization</a></p>
<p>20 0.10862801 <a title="39-lsi-20" href="./jmlr-2005-Estimating_Functions_for_Blind_Separation_When_Sources_Have_Variance_Dependencies.html">30 jmlr-2005-Estimating Functions for Blind Separation When Sources Have Variance Dependencies</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.017), (11, 0.028), (35, 0.017), (37, 0.022), (44, 0.035), (47, 0.016), (62, 0.102), (68, 0.038), (74, 0.015), (75, 0.463), (78, 0.019), (79, 0.021), (88, 0.061), (97, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6809516 <a title="39-lda-1" href="./jmlr-2005-Information_Bottleneck_for_Gaussian_Variables.html">39 jmlr-2005-Information Bottleneck for Gaussian Variables</a></p>
<p>2 0.27903056 <a title="39-lda-2" href="./jmlr-2005-Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables.html">42 jmlr-2005-Large Margin Methods for Structured and Interdependent Output Variables</a></p>
<p>3 0.27437726 <a title="39-lda-3" href="./jmlr-2005-Gaussian_Processes_for_Ordinal_Regression.html">36 jmlr-2005-Gaussian Processes for Ordinal Regression</a></p>
<p>4 0.27364922 <a title="39-lda-4" href="./jmlr-2005-Smooth_%CE%B5-Insensitive_Regression_by_Loss_Symmetrization.html">66 jmlr-2005-Smooth ε-Insensitive Regression by Loss Symmetrization</a></p>
<p>5 0.27293906 <a title="39-lda-5" href="./jmlr-2005-Loopy_Belief_Propagation%3A_Convergence_and_Effects_of_Message_Errors.html">52 jmlr-2005-Loopy Belief Propagation: Convergence and Effects of Message Errors</a></p>
<p>6 0.27152982 <a title="39-lda-6" href="./jmlr-2005-Maximum_Margin_Algorithms_with_Boolean_Kernels.html">56 jmlr-2005-Maximum Margin Algorithms with Boolean Kernels</a></p>
<p>7 0.27099204 <a title="39-lda-7" href="./jmlr-2005-Clustering_on_the_Unit_Hypersphere_using_von_Mises-Fisher__Distributions.html">19 jmlr-2005-Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions</a></p>
<p>8 0.27091417 <a title="39-lda-8" href="./jmlr-2005-Inner_Product_Spaces_for_Bayesian_Networks.html">40 jmlr-2005-Inner Product Spaces for Bayesian Networks</a></p>
<p>9 0.27039737 <a title="39-lda-9" href="./jmlr-2005-Fast_Kernel_Classifiers_with_Online_and_Active_Learning.html">33 jmlr-2005-Fast Kernel Classifiers with Online and Active Learning</a></p>
<p>10 0.27024832 <a title="39-lda-10" href="./jmlr-2005-Asymptotic_Model_Selection_for_Naive_Bayesian_Networks.html">15 jmlr-2005-Asymptotic Model Selection for Naive Bayesian Networks</a></p>
<p>11 0.26910251 <a title="39-lda-11" href="./jmlr-2005-Efficient_Margin_Maximizing_with_Boosting.html">29 jmlr-2005-Efficient Margin Maximizing with Boosting</a></p>
<p>12 0.26755804 <a title="39-lda-12" href="./jmlr-2005-Assessing_Approximate_Inference_for_Binary_Gaussian_Process_Classification.html">14 jmlr-2005-Assessing Approximate Inference for Binary Gaussian Process Classification</a></p>
<p>13 0.26693708 <a title="39-lda-13" href="./jmlr-2005-Learning_a_Mahalanobis_Metric_from_Equivalence_Constraints.html">46 jmlr-2005-Learning a Mahalanobis Metric from Equivalence Constraints</a></p>
<p>14 0.26656735 <a title="39-lda-14" href="./jmlr-2005-Clustering_with_Bregman_Divergences.html">20 jmlr-2005-Clustering with Bregman Divergences</a></p>
<p>15 0.26557875 <a title="39-lda-15" href="./jmlr-2005-Semigroup_Kernels_on_Measures.html">64 jmlr-2005-Semigroup Kernels on Measures</a></p>
<p>16 0.26503858 <a title="39-lda-16" href="./jmlr-2005-Denoising_Source_Separation.html">25 jmlr-2005-Denoising Source Separation</a></p>
<p>17 0.26387832 <a title="39-lda-17" href="./jmlr-2005-Kernel_Methods_for_Measuring_Independence.html">41 jmlr-2005-Kernel Methods for Measuring Independence</a></p>
<p>18 0.26308259 <a title="39-lda-18" href="./jmlr-2005-Characterization_of_a_Family_of_Algorithms_for_Generalized_Discriminant_Analysis_on_Undersampled_Problems.html">18 jmlr-2005-Characterization of a Family of Algorithms for Generalized Discriminant Analysis on Undersampled Problems</a></p>
<p>19 0.26080498 <a title="39-lda-19" href="./jmlr-2005-Multiclass_Classification_with_Multi-Prototype_Support_Vector_Machines.html">58 jmlr-2005-Multiclass Classification with Multi-Prototype Support Vector Machines</a></p>
<p>20 0.26050872 <a title="39-lda-20" href="./jmlr-2005-Variational_Message_Passing.html">71 jmlr-2005-Variational Message Passing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
