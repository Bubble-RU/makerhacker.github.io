<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-79" href="#">jmlr2011-79</a> knowledge-graph by maker-knowledge-mining</p><h1>79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</h1>
<br/><p>Source: <a title="jmlr-2011-79-pdf" href="http://jmlr.org/papers/volume12/jenatton11a/jenatton11a.pdf">pdf</a></p><p>Author: Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski, Francis Bach</p><p>Abstract: Sparse coding consists in representing signals as sparse linear combinations of atoms selected from a dictionary. We consider an extension of this framework where the atoms are further assumed to be embedded in a tree. This is achieved using a recently introduced tree-structured sparse regularization norm, which has proven useful in several applications. This norm leads to regularized problems that are difﬁcult to optimize, and in this paper, we propose efﬁcient algorithms for solving them. More precisely, we show that the proximal operator associated with this norm is computable exactly via a dual approach that can be viewed as the composition of elementary proximal operators. Our procedure has a complexity linear, or close to linear, in the number of atoms, and allows the use of accelerated gradient techniques to solve the tree-structured sparse approximation problem at the same computational cost as traditional ones using the ℓ1 -norm. Our method is efﬁcient and scales gracefully to millions of variables, which we illustrate in two types of applications: ﬁrst, we consider ﬁxed hierarchical dictionaries of wavelets to denoise natural images. Then, we apply our optimization tools in the context of dictionary learning, where learned dictionary elements naturally self-organize in a prespeciﬁed arborescent structure, leading to better performance in reconstruction of natural image patches. When applied to text documents, our method learns hierarchies of topics, thus providing a competitive alternative to probabilistic topic models. Keywords: Proximal methods, dictionary learning, structured sparsity, matrix factorization</p><p>Reference: <a title="jmlr-2011-79-reference" href="../jmlr2011_reference/jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dict', 0.477), ('tg', 0.312), ('proxim', 0.267), ('roxim', 0.208), ('bozinsk', 0.187), ('ierarch', 0.186), ('zg', 0.177), ('mair', 0.174), ('enatton', 0.168), ('wavelet', 0.128), ('nonconvex', 0.128), ('air', 0.116), ('baraniuk', 0.114), ('bach', 0.111), ('jenatton', 0.106), ('patch', 0.104), ('ethod', 0.097), ('sphdl', 0.093), ('dual', 0.089), ('group', 0.088)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="79-tfidf-1" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>2 0.35283777 <a title="79-tfidf-2" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>3 0.32992378 <a title="79-tfidf-3" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>4 0.13739926 <a title="79-tfidf-4" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>5 0.12796172 <a title="79-tfidf-5" href="./jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">40 jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>6 0.11557443 <a title="79-tfidf-6" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>7 0.092630431 <a title="79-tfidf-7" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>8 0.079803653 <a title="79-tfidf-8" href="./jmlr-2011-Group_Lasso_Estimation_of_High-dimensional_Covariance_Matrices.html">37 jmlr-2011-Group Lasso Estimation of High-dimensional Covariance Matrices</a></p>
<p>9 0.070223995 <a title="79-tfidf-9" href="./jmlr-2011-Non-Parametric_Estimation_of_Topic_Hierarchies_from_Texts_with_Hierarchical_Dirichlet_Processes.html">70 jmlr-2011-Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes</a></p>
<p>10 0.069206774 <a title="79-tfidf-10" href="./jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">68 jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>11 0.065802053 <a title="79-tfidf-11" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>12 0.063855454 <a title="79-tfidf-12" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>13 0.059313271 <a title="79-tfidf-13" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>14 0.053253789 <a title="79-tfidf-14" href="./jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">54 jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<p>15 0.051615838 <a title="79-tfidf-15" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>16 0.047922757 <a title="79-tfidf-16" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>17 0.045712072 <a title="79-tfidf-17" href="./jmlr-2011-Adaptive_Exact_Inference_in_Graphical_Models.html">7 jmlr-2011-Adaptive Exact Inference in Graphical Models</a></p>
<p>18 0.043089937 <a title="79-tfidf-18" href="./jmlr-2011-In_All_Likelihood%2C_Deep_Belief_Is_Not_Enough.html">42 jmlr-2011-In All Likelihood, Deep Belief Is Not Enough</a></p>
<p>19 0.042406648 <a title="79-tfidf-19" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>20 0.041974243 <a title="79-tfidf-20" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.288), (1, -0.014), (2, -0.332), (3, -0.465), (4, 0.012), (5, -0.077), (6, -0.082), (7, -0.022), (8, -0.029), (9, -0.169), (10, -0.292), (11, -0.129), (12, -0.13), (13, 0.19), (14, -0.012), (15, -0.028), (16, 0.037), (17, -0.141), (18, 0.006), (19, -0.149), (20, -0.055), (21, 0.051), (22, 0.026), (23, -0.016), (24, 0.006), (25, -0.004), (26, 0.058), (27, 0.025), (28, 0.011), (29, 0.017), (30, -0.006), (31, 0.038), (32, 0.025), (33, -0.026), (34, 0.03), (35, -0.078), (36, -0.064), (37, 0.032), (38, -0.044), (39, 0.025), (40, -0.011), (41, -0.018), (42, -0.011), (43, 0.04), (44, 0.024), (45, 0.002), (46, 0.006), (47, -0.027), (48, -0.015), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92214352 <a title="79-lsi-1" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>2 0.84859675 <a title="79-lsi-2" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>3 0.73329777 <a title="79-lsi-3" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>4 0.43378863 <a title="79-lsi-4" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>5 0.32991728 <a title="79-lsi-5" href="./jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">40 jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>6 0.32110974 <a title="79-lsi-6" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>7 0.25476709 <a title="79-lsi-7" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>8 0.24901596 <a title="79-lsi-8" href="./jmlr-2011-Non-Parametric_Estimation_of_Topic_Hierarchies_from_Texts_with_Hierarchical_Dirichlet_Processes.html">70 jmlr-2011-Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes</a></p>
<p>9 0.24493656 <a title="79-lsi-9" href="./jmlr-2011-Group_Lasso_Estimation_of_High-dimensional_Covariance_Matrices.html">37 jmlr-2011-Group Lasso Estimation of High-dimensional Covariance Matrices</a></p>
<p>10 0.23046766 <a title="79-lsi-10" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>11 0.2217214 <a title="79-lsi-11" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>12 0.21004051 <a title="79-lsi-12" href="./jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">68 jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>13 0.1876017 <a title="79-lsi-13" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>14 0.18759127 <a title="79-lsi-14" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>15 0.18739197 <a title="79-lsi-15" href="./jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">54 jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<p>16 0.18650182 <a title="79-lsi-16" href="./jmlr-2011-Anechoic_Blind_Source_Separation_Using_Wigner_Marginals.html">10 jmlr-2011-Anechoic Blind Source Separation Using Wigner Marginals</a></p>
<p>17 0.17903087 <a title="79-lsi-17" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>18 0.17741726 <a title="79-lsi-18" href="./jmlr-2011-Logistic_Stick-Breaking_Process.html">61 jmlr-2011-Logistic Stick-Breaking Process</a></p>
<p>19 0.17648472 <a title="79-lsi-19" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>20 0.17508668 <a title="79-lsi-20" href="./jmlr-2011-lp-Norm_Multiple_Kernel_Learning.html">105 jmlr-2011-lp-Norm Multiple Kernel Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.035), (11, 0.042), (17, 0.047), (24, 0.04), (37, 0.04), (39, 0.036), (50, 0.462), (67, 0.046), (84, 0.026), (86, 0.13)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.74954677 <a title="79-lda-1" href="./jmlr-2011-Clustering_Algorithms_for_Chains.html">16 jmlr-2011-Clustering Algorithms for Chains</a></p>
<p>same-paper 2 0.73764515 <a title="79-lda-2" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>3 0.52185631 <a title="79-lda-3" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>4 0.42261708 <a title="79-lda-4" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>5 0.41243541 <a title="79-lda-5" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>6 0.40526977 <a title="79-lda-6" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>7 0.40372348 <a title="79-lda-7" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>8 0.39412755 <a title="79-lda-8" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>9 0.38822338 <a title="79-lda-9" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>10 0.38019633 <a title="79-lda-10" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>11 0.3754577 <a title="79-lda-11" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>12 0.3544299 <a title="79-lda-12" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>13 0.35240322 <a title="79-lda-13" href="./jmlr-2011-Double_Updating_Online_Learning.html">28 jmlr-2011-Double Updating Online Learning</a></p>
<p>14 0.34872156 <a title="79-lda-14" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>15 0.3450129 <a title="79-lda-15" href="./jmlr-2011-lp-Norm_Multiple_Kernel_Learning.html">105 jmlr-2011-lp-Norm Multiple Kernel Learning</a></p>
<p>16 0.34490776 <a title="79-lda-16" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>17 0.34301147 <a title="79-lda-17" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>18 0.34121853 <a title="79-lda-18" href="./jmlr-2011-Group_Lasso_Estimation_of_High-dimensional_Covariance_Matrices.html">37 jmlr-2011-Group Lasso Estimation of High-dimensional Covariance Matrices</a></p>
<p>19 0.33476558 <a title="79-lda-19" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>20 0.33433732 <a title="79-lda-20" href="./jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">54 jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<br/><br/><br/></body>
</html>
