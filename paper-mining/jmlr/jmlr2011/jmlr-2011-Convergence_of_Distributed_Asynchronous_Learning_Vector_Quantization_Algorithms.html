<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-19" href="#">jmlr2011-19</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</h1>
<br/><p>Source: <a title="jmlr-2011-19-pdf" href="http://jmlr.org/papers/volume12/patra11a/patra11a.pdf">pdf</a></p><p>Author: Benoît Patra</p><p>Abstract: Motivated by the problem of effectively executing clustering algorithms on very large data sets, we address a model for large scale distributed clustering methods. To this end, we brieﬂy recall some standards on the quantization problem and some results on the almost sure convergence of the competitive learning vector quantization (CLVQ) procedure. A general model for linear distributed asynchronous algorithms well adapted to several parallel computing architectures is also discussed. Our approach brings together this scalable model and the CLVQ algorithm, and we call the resulting technique the distributed asynchronous learning vector quantization algorithm (DALVQ). An indepth analysis of the almost sure convergence of the DALVQ algorithm is performed. A striking result is that we prove that the multiple versions of the quantizers distributed among the processors in the parallel architecture asymptotically reach a consensus almost surely. Furthermore, we also show that these versions converge almost surely towards the same nearly optimal value for the quantization criterion. Keywords: k-means, vector quantization, distributed, asynchronous, stochastic optimization, scalability, distributed consensus</p><p>Reference: <a title="jmlr-2011-19-reference" href="../jmlr2011_reference/jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 To this end, we brieﬂy recall some standards on the quantization problem and some results on the almost sure convergence of the competitive learning vector quantization (CLVQ) procedure. [sent-4, score-0.591]
</p><p>2 A general model for linear distributed asynchronous algorithms well adapted to several parallel computing architectures is also discussed. [sent-5, score-0.385]
</p><p>3 Our approach brings together this scalable model and the CLVQ algorithm, and we call the resulting technique the distributed asynchronous learning vector quantization algorithm (DALVQ). [sent-6, score-0.579]
</p><p>4 A striking result is that we prove that the multiple versions of the quantizers distributed among the processors in the parallel architecture asymptotically reach a consensus almost surely. [sent-8, score-0.445]
</p><p>5 Furthermore, we also show that these versions converge almost surely towards the same nearly optimal value for the quantization criterion. [sent-9, score-0.363]
</p><p>6 Keywords: k-means, vector quantization, distributed, asynchronous, stochastic optimization, scalability, distributed consensus  1. [sent-10, score-0.194]
</p><p>7 Building such large scale algorithms attacks several problems in a distributed framework, such as communication delays in the network or numerous problems caused by the lack of shared memory. [sent-14, score-0.231]
</p><p>8 ı  PATRA  competitive learning vector quantization (CLVQ) algorithm (see Gersho and Gray, 1992) provides a technique for building reliable clusters characterized by their prototypes. [sent-24, score-0.219]
</p><p>9 The CLVQ also belongs to the class of stochastic gradient descent algorithms (for more information on stochastic gradient descent procedures we refer the reader to Benveniste et al. [sent-26, score-0.368]
</p><p>10 In the present paper, we go further by introducing a model that brings together the original CLVQ algorithm and the comprehensive theory of asynchronous parallel linear algorithms developed by Tsitsiklis (1984), Tsitsiklis et al. [sent-31, score-0.322]
</p><p>11 The resulting model will be called distributed asynchronous learning vector quantization (DALVQ for short). [sent-33, score-0.579]
</p><p>12 At a high level, the DALVQ algorithm parallelizes several executions of the CLVQ method concurrently on different processors while the results of these algorithms are broadcast through the distributed framework asynchronously and efﬁciently. [sent-34, score-0.167]
</p><p>13 Here, the term processor refers to any computing instance in a distributed architecture (see Bullo et al. [sent-35, score-0.228]
</p><p>14 (2009), a coverage control problem is formulated as an optimization problem where the functional cost to be minimized is the same of the quantization problem stated in this manuscript. [sent-41, score-0.219]
</p><p>15 The ﬁrst technique computes quantization scheme for d dimensional samples z1 , z2 , . [sent-43, score-0.219]
</p><p>16 Therefore, the DALVQ algorithms are deﬁned by the M iterations {wi (t)}t=0 , called versions, satisfying (with slight simpliﬁcations) wi (t + 1) =  M  i ∑ ai, j (t)w j (τi, j (t)) − εt+1H  i zt+1 , wi (t) ,  j=1  i ∈ {1, . [sent-56, score-0.288]
</p><p>17 j=1 As a striking result, we prove that multiple versions of the quantizers, distributed among the processors in a parallel architecture, asymptotically reach a consensus almost surely. [sent-62, score-0.349]
</p><p>18 Using the materials introduced above, it writes wi (t) − w j (t) − → 0, − t→∞  (i, j) ∈ {1, . [sent-63, score-0.162]
</p><p>19 Furthermore, we also show that these versions converge almost surely towards (the same) nearly optimal value for the quantization criterion. [sent-69, score-0.363]
</p><p>20 These convergence results are similar in spirit to the 3432  C ONVERGENCE OF D ISTRIBUTED A SYNCHRONOUS L EARNING V ECTOR Q UANTIZATION A LGORITHMS  most satisfactory almost sure convergence theorem for the CLVQ algorithm obtained by Pag` s e (1997). [sent-70, score-0.233]
</p><p>21 For a given time span, our parallel DALVQ algorithm is able to process much more data than a single processor execution of the CLVQ procedure. [sent-71, score-0.164]
</p><p>22 This allows some processors to compute faster and execute more iterations than others, and it also allows communication delays to be substantial and unpredictable. [sent-74, score-0.308]
</p><p>23 First, a reduction of the synchronization penalty, which could bring a speed advantage over a synchronous execution. [sent-77, score-0.18]
</p><p>24 In Section 3 we give a brief exposition of the mathematical framework for parallel asynchronous gradient methods introduced by Tsitsiklis (1984), Tsitsiklis et al. [sent-86, score-0.37]
</p><p>25 (2005) on the asymptotic consensus in asynchronous parallel averaging problems are also recalled. [sent-89, score-0.407]
</p><p>26 Quantization and CLVQ Algorithm In this section, we describe the mathematical quantization problem and the CLVQ algorithm. [sent-92, score-0.219]
</p><p>27 The quantization problem consists in ﬁnding a “good approximation” of µ by a set of κ vectors of Rd called quantizer. [sent-96, score-0.219]
</p><p>28 Throughout the document the κ quantization points (or prototypes) will be seen as the components κ of a Rd -dimensional vector w = (w1 , . [sent-97, score-0.219]
</p><p>29 To measure the correctness of a quantization scheme given by w, one introduces a cost function called distortion, deﬁned by Cµ (w) =  1 2  Rd  min z − wℓ  1≤ℓ≤κ  2  dµ(z). [sent-101, score-0.219]
</p><p>30 ∑1 n i=1 {zi ∈A}  Much attention has been devoted to the convergence study of the quantization scheme provided by the empirical minimizers w◦ ∈ argmin Cµn (w). [sent-111, score-0.347]
</p><p>31 n κ w∈(Rd ) The almost sure convergence of Cµ (w◦ ) towards minw∈(Rd )κ Cµ (w) was proved by Pollard (1981, n 1982a) and Abaya and Wise (1984). [sent-112, score-0.183]
</p><p>32 Another celebrated quantization algorithm is the competitive learning vector quantization (CLVQ), also called on-line k-means. [sent-126, score-0.438]
</p><p>33 The CLVQ procedure can be seen as a stochastic gradient descent algorithm. [sent-130, score-0.184]
</p><p>34 In the more general context of gradient descent methods, one cannot hope for the convergence of the procedure towards global minimizers with a non convex objective function (see for instance Benveniste et al. [sent-131, score-0.267]
</p><p>35 In our quantization context, the distortion mapping Cµ is not convex (see for instance Graf and Luschgy 2000). [sent-133, score-0.368]
</p><p>36 Assuming that the distribution µ has a compact support and a bounded density with respect to the Lebesgue measure, Pag` s (1997) states a result regarding the almost sure consistency of the CLVQ e algorithm towards critical points of the distortion Cµ . [sent-135, score-0.287]
</p><p>37 The main difﬁculties in the proof arise from the fact that the gradient of the distortion is singular on κ-tuples having equal components and the distortion function Cµ is not convex. [sent-137, score-0.346]
</p><p>38 ı The next proposition states the differentiability of the distortion C, and provides an explicit formula for the gradient ∇C whenever the distortion is differentiable. [sent-160, score-0.385]
</p><p>39 This leads to the following stochastic gradient descent procedure w(t + 1) = w(t) − εt+1 H (zt+1 , w(t)) ,  t ≥ 0,  (3)  ◦  κ where w(0) ∈ G κ ∩ D∗ and z1 , z2 . [sent-187, score-0.184]
</p><p>40 As outlined by Pag` s in Pag` s (1997), this algorithm belongs e e to the class of stochastic gradient descent methods. [sent-193, score-0.184]
</p><p>41 The following assumption set is standard in a gradient descent context. [sent-196, score-0.185]
</p><p>42 ,  (5)  The next theorem is, as far as we know, the ﬁrst almost sure convergence theorem for the stochastic algorithm CLVQ. [sent-241, score-0.269]
</p><p>43 Recall that without more assumption than w(0) ∈ G κ ∩ D∗ , we have already discussed the fact that the components of w(t) are almost surely parted for all t ≥ 0. [sent-248, score-0.232]
</p><p>44 Thus, it is easily seen that the two following events only differ on a set of zero probability κ lim inf dist w(t), ∁D∗ > 0 t→∞  and κ inf dist w(t), ∁D∗ > 0 . [sent-249, score-0.166]
</p><p>45 General Distributed Asynchronous Algorithm We present in this section some materials and results of the asynchronous parallel linear algorithms theory. [sent-252, score-0.322]
</p><p>46 The aim of this section is to discuss a precise mathematical description of a distributed asynchronous model for the iterations (6). [sent-258, score-0.396]
</p><p>47 Assume that we dispose of a distributed architecture with M computing entities called processors (or agents, see for instance Bullo et al. [sent-262, score-0.217]
</p><p>48 Throughout the paper, we will add the superscript i on the variables possessed by the processor i. [sent-268, score-0.169]
</p><p>49 Thus, for agent i such κ ∞ iterations are represented by the Rd -valued sequence wi (t) t=0 . [sent-270, score-0.239]
</p><p>50 We deﬁne the general distributed asynchronous algorithm by the following iterations wi (t + 1) =  M  ∑ ai, j (t)w j (τi, j (t)) + si(t),  j=1  i ∈ {1, . [sent-287, score-0.522]
</p><p>51 (7)  The model can be interpreted as follows: at time t ≥ 0, processor i receives messages from other processors containing w j (τi, j (t)). [sent-291, score-0.243]
</p><p>52 In Section 4, when we deﬁne the distributed asynchronous learning vector quantization (DALVQ), the deﬁnition of the descent terms will be made more explicit. [sent-302, score-0.669]
</p><p>53 (2005), for a natural simpliﬁcation of the general distributed asynchronous algorithm (7). [sent-305, score-0.36]
</p><p>54 (2005) deﬁne two sets of assumptions that enforce some weak properties on the communication delays and the network topology. [sent-314, score-0.168]
</p><p>55 − t→∞  The agreement algorithm (9) is essentially driven by the communication times τi, j (t) assumed to be deterministic but do not need to be known a priori by the processors. [sent-321, score-0.174]
</p><p>56 The following Assumption 3441  PATRA  Global time reference  Figure 3: Illustration of the time delays introduced in the general distributed asynchronous algorithm. [sent-322, score-0.44]
</p><p>57 3 essentially ensures, in its third statement, that the communication delays t − τi, j (t) are bounded. [sent-326, score-0.168]
</p><p>58 This assumption prevents some processor from taking into account some arbitrarily old values computed by others processors. [sent-327, score-0.186]
</p><p>59 , M} | ai, j (t) = 0  corresponds to the set of agents whose version is taken into account by processor i at time t. [sent-372, score-0.168]
</p><p>60 The communication patterns, sometimes refereed to as the network communication topology, can be expressed in terms of directed graph. [sent-380, score-0.2]
</p><p>61 Deﬁnition 5 (Communication graph) Let us ﬁx t ≥ 0, the communication graph at time t, (V , E(t)), is deﬁned by • the set of vertices V is formed by the set of processors V = {1, . [sent-382, score-0.192]
</p><p>62 The Theorem 6 expresses the fact that, for the agreement algorithm, a consensus is asymptotically reached by the agents. [sent-410, score-0.196]
</p><p>63 3 Asymptotic Consensus This subsection is devoted to the analysis of the general distributed asynchronous algorithm (7). [sent-421, score-0.389]
</p><p>64 The following lemma states that the version possessed by agent i ∈ {1, . [sent-423, score-0.16]
</p><p>65 , M} at time t ≥ 0, namely wi (t), depends linearly on the others initialization vectors w j (0) and the descent t−1 subsequences s j (τ) τ=−1 , where j ∈ {1, . [sent-426, score-0.216]
</p><p>66 , M}2 and t ≥ 0, the real-valued sequences φi, j (t, τ) τ=−1 do not depend on the value taken by the descent terms si (t). [sent-437, score-0.162]
</p><p>67 Distributed Asynchronous Learning Vector Quantization This section is devoted to the distributed asynchronous learning vector quantization techniques. [sent-477, score-0.608]
</p><p>68 3445  PATRA  Global time reference  Figure 4: The agreement vector at time t ′ , w⋆ (t ′ ) corresponds to the common value asymptotically achieved by all processors if computations integrating descent terms have stopped after t ′ , that is, s j (t) = 0 for all t ≥ t ′ . [sent-479, score-0.305]
</p><p>69 (1986) and Bertsekas and Tsitsiklis (1989) studied distributed asynchronous stochastic gradient optimization algorithms. [sent-485, score-0.454]
</p><p>70 In this series of publications, for the κ distributed minimization of a cost function F : Rd −→ R, the authors considered the general distributed asynchronous algorithm deﬁned by Equation (7) with speciﬁc choices for stochastic descent terms si . [sent-486, score-0.596]
</p><p>71 Using the notation of Section 3, the algorithm writes wi (t + 1) =  M  ∑ ai, j (t)w j (τi, j (t)) + si (t),  j=1  i ∈ {1, . [sent-487, score-0.199]
</p><p>72 , M} and t ≥ 0,  with stochastic descent terms si (t) satisfying i E si (t) s j (τ), j ∈ {1, . [sent-490, score-0.21]
</p><p>73 As discussed in Section 2, the CLVQ algorithm is also a stochastic gradient descent procedure. [sent-505, score-0.184]
</p><p>74 to the context of vector quantization and on-line clustering. [sent-509, score-0.219]
</p><p>75 We ﬁrst introduce the distributed asynchronous learning vector quantization (DALVQ) algorithm. [sent-510, score-0.579]
</p><p>76 To prove its almost sure consistency, we will need an asynchronous G-lemma, which is inspired from the G-lemma, Theorem 3, presented in Section 2. [sent-511, score-0.405]
</p><p>77 This theorem may be seen as an easyto-apply tool for the almost sure consistency of a distributed asynchronous system where the average function is not necessary regular. [sent-512, score-0.503]
</p><p>78 Our approach sheds also some new light on the convergence of distributed asynchronous stochastic gradient descent algorithms. [sent-513, score-0.589]
</p><p>79 Similarly to Pag` s (1997), e who assumes that the trajectory of the CLVQ algorithm has almost surely asymptotically parted components (see Theorem 4 in Section 2), we will suppose that the agreement vector sequence has, almost surely, asymptotically parted component trajectories. [sent-518, score-0.439]
</p><p>80 The data sets (or streams of data) are distributed among several queues sending data to the different processors of our distributed framework. [sent-520, score-0.23]
</p><p>81 Thus, the DALVQ procedure is 1 2 deﬁned by Equation (7) with the following choice for the descent term si : si (t) =  i i −εt+1 H zt+1 , wi (t) 0  if t ∈ T i ; otherwise;  ∞  (12)  where εti t=0 are (0, 1)-valued sequences. [sent-543, score-0.29]
</p><p>82 The sets T i contain the time instants where the version wi , kept by processor i, is updated with the descent terms. [sent-544, score-0.39]
</p><p>83 This ﬁne grain description of the algorithm allows some processors to be idle for computing descent terms (when t ∈ T i ). [sent-545, score-0.194]
</p><p>84 This reﬂects / the fact that the computing operations might not take the same time for all processors, which is precisely the core of asynchronous algorithms analysis. [sent-546, score-0.297]
</p><p>85 This assumption is satisﬁed, for example, by taking the current value of εti proportional to 1/nti , where nti is the number of times that processor i as performed an update, that is, the cardinal of the set T i ∩ {0, . [sent-566, score-0.21]
</p><p>86 2 The Asynchronous G-lemma The aim of this subsection is to state a useful theorem similar to Theorem 3, but adapted to our asynchronous distributed context. [sent-579, score-0.395]
</p><p>87 The reader should keep in mind that the vector w⋆ (t) is also the asymptotical consensus if descent terms are zero after time t. [sent-581, score-0.175]
</p><p>88 Nevertheless, the agreement vector w⋆ (t) can be interpreted as a “probabilistic state” of the whole distributed quantization scheme at time t. [sent-583, score-0.368]
</p><p>89 (16)  We are now in a position to state our most useful tool, which is similar in spirit to the G-lemma, but adapted to the context of distributed asynchronous stochastic gradient descent algorithm. [sent-599, score-0.544]
</p><p>90 Thus, Equation (7) takes the form /  i i  wi (t + 1) = wi (t) − εt+1 wi (t) − zt+1  if t ∈ T i ; i i i wi (t + 1) = = 1 − εt+1 wi (t) + εt+1 zt+1   i otherwise. [sent-631, score-0.63]
</p><p>91 The next Lemma 11 provides a deterministic upper bound on the differences between the disκ tributed versions wi and the agreement vector. [sent-636, score-0.212]
</p><p>92 wi (t) − w j (t) − → 0, − t→∞  (18)  This shows that the trajectories of the distributed versions of the quantizers reach asymptotically ∞ a consensus with probability 1. [sent-656, score-0.369]
</p><p>93 In other words, if one of the sequences wi (t) t=0 converges then they all converge towards the same value. [sent-657, score-0.191]
</p><p>94 Its proof is based on the asynchronous G-lemma, Theorem 10. [sent-667, score-0.297]
</p><p>95 We are now in a position to state the main theorem of this paper, which expresses the convergence of the distributed version towards some zero of the gradient of the distortion. [sent-686, score-0.221]
</p><p>96 5 Annex Sketch of the proof of asynchronous G-lemma 10. [sent-711, score-0.297]
</p><p>97 τ=−1 τ ∨ 1  ∑  Consequently, w⋆ (t) − wi (t) κ  ∑  =  ℓ=1  ≤  √  2  wi (t) − w⋆ (t) ℓ ℓ  κM diam(G )AK2  t−1  1 t−τ ρ . [sent-750, score-0.252]
</p><p>98 For any t ≥ tδ ,  αwi (t) + (1 − α)w⋆ (t) − αwi (t) − (1 − α)w⋆ (t) k ℓ k ℓ  = w⋆ (t) − w⋆ (t) + α(wi (t) − w⋆ (t)) + α(w⋆ (t) − wi (t)) k ℓ k ℓ ℓ k  ≥ w⋆ (t) − w⋆ (t) − α wi (t) − w⋆ (t) − α w⋆ (t) − wi (t) k ℓ ℓ k k ℓ δ ≥ δ − 2α 4 ≥ δ/2. [sent-784, score-0.378]
</p><p>99 For √ ∞ all z ∈ G and all t ≥ 0, we have H(z, w⋆ (t)) ≤ κ diam (G ), almost surely, whereas {h(w⋆ (t))}t=0 satisﬁes h(w⋆ (t)) = E {H (z, w⋆ (t)) | Ft } , t ≥ 0, a. [sent-845, score-0.22]
</p><p>100 The distortion of vector quantizers trained on n vectors decreases to the optimum at o p (1/n). [sent-948, score-0.219]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('clvq', 0.318), ('asynchronous', 0.297), ('pag', 0.26), ('asy', 0.24), ('patra', 0.235), ('quantization', 0.219), ('dalvq', 0.212), ('uantization', 0.2), ('synchronous', 0.18), ('diam', 0.173), ('istributed', 0.17), ('tsitsiklis', 0.154), ('distortion', 0.149), ('ector', 0.14), ('processor', 0.139), ('rd', 0.135), ('wi', 0.126), ('mt', 0.114), ('fort', 0.106), ('onvergence', 0.106), ('processors', 0.104), ('zt', 0.098), ('descent', 0.09), ('ft', 0.089), ('communication', 0.088), ('agreement', 0.086), ('consensus', 0.085), ('lgorithms', 0.084), ('dist', 0.083), ('delays', 0.08), ('blondel', 0.08), ('agent', 0.077), ('parted', 0.071), ('lloyd', 0.07), ('quantizers', 0.07), ('surely', 0.067), ('distributed', 0.063), ('ai', 0.063), ('sure', 0.061), ('kohonen', 0.059), ('clock', 0.054), ('minimizers', 0.054), ('lemma', 0.053), ('vorono', 0.05), ('earning', 0.05), ('gradient', 0.048), ('assumption', 0.047), ('almost', 0.047), ('benveniste', 0.047), ('stochastic', 0.046), ('ltration', 0.045), ('convergence', 0.045), ('bertsekas', 0.042), ('linder', 0.041), ('proposition', 0.039), ('si', 0.037), ('iterations', 0.036), ('statement', 0.036), ('writes', 0.036), ('antos', 0.035), ('bullo', 0.035), ('frasca', 0.035), ('inft', 0.035), ('instants', 0.035), ('sabin', 0.035), ('sequences', 0.035), ('theorem', 0.035), ('ru', 0.033), ('quantizer', 0.033), ('wk', 0.033), ('stands', 0.031), ('graf', 0.03), ('possessed', 0.03), ('towards', 0.03), ('agents', 0.029), ('devoted', 0.029), ('bottou', 0.028), ('architecture', 0.026), ('wt', 0.026), ('asymptotically', 0.025), ('parallel', 0.025), ('pollard', 0.025), ('zi', 0.025), ('clustering', 0.024), ('abaya', 0.024), ('asynchronism', 0.024), ('beno', 0.024), ('cardinal', 0.024), ('carli', 0.024), ('chou', 0.024), ('communicates', 0.024), ('dispose', 0.024), ('gossip', 0.024), ('homothety', 0.024), ('inaba', 0.024), ('luschgy', 0.024), ('organizing', 0.024), ('refereed', 0.024), ('tessellation', 0.024), ('martingale', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="19-tfidf-1" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>Author: Benoît Patra</p><p>Abstract: Motivated by the problem of effectively executing clustering algorithms on very large data sets, we address a model for large scale distributed clustering methods. To this end, we brieﬂy recall some standards on the quantization problem and some results on the almost sure convergence of the competitive learning vector quantization (CLVQ) procedure. A general model for linear distributed asynchronous algorithms well adapted to several parallel computing architectures is also discussed. Our approach brings together this scalable model and the CLVQ algorithm, and we call the resulting technique the distributed asynchronous learning vector quantization algorithm (DALVQ). An indepth analysis of the almost sure convergence of the DALVQ algorithm is performed. A striking result is that we prove that the multiple versions of the quantizers distributed among the processors in the parallel architecture asymptotically reach a consensus almost surely. Furthermore, we also show that these versions converge almost surely towards the same nearly optimal value for the quantization criterion. Keywords: k-means, vector quantization, distributed, asynchronous, stochastic optimization, scalability, distributed consensus</p><p>2 0.11001399 <a title="19-tfidf-2" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>Author: Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</p><p>Abstract: Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed. Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation. To solve these problems, we introduce a new framework, semiparametric statistical inference, to model-free policy evaluation. This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a uniﬁed way in terms of estimating functions. Furthermore, based on this framework, we derive an optimal estimating function with the minimum asymptotic variance and propose batch and online learning algorithms which achieve the optimality. Keywords: reinforcement learning, model-free policy evaluation, TD learning, semiparametirc model, estimating function</p><p>3 0.096956827 <a title="19-tfidf-3" href="./jmlr-2011-Parallel_Algorithm_for_Learning_Optimal_Bayesian_Network_Structure.html">75 jmlr-2011-Parallel Algorithm for Learning Optimal Bayesian Network Structure</a></p>
<p>Author: Yoshinori Tamada, Seiya Imoto, Satoru Miyano</p><p>Abstract: We present a parallel algorithm for the score-based optimal structure search of Bayesian networks. This algorithm is based on a dynamic programming (DP) algorithm having O(n · 2n ) time and space complexity, which is known to be the fastest algorithm for the optimal structure search of networks with n nodes. The bottleneck of the problem is the memory requirement, and therefore, the algorithm is currently applicable for up to a few tens of nodes. While the recently proposed algorithm overcomes this limitation by a space-time trade-off, our proposed algorithm realizes direct parallelization of the original DP algorithm with O(nσ ) time and space overhead calculations, where σ > 0 controls the communication-space trade-off. The overall time and space complexity is O(nσ+1 2n ). This algorithm splits the search space so that the required communication between independent calculations is minimal. Because of this advantage, our algorithm can run on distributed memory supercomputers. Through computational experiments, we conﬁrmed that our algorithm can run in parallel using up to 256 processors with a parallelization efﬁciency of 0.74, compared to the original DP algorithm with a single processor. We also demonstrate optimal structure search for a 32-node network without any constraints, which is the largest network search presented in literature. Keywords: optimal Bayesian network structure, parallel algorithm</p><p>4 0.070286557 <a title="19-tfidf-4" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>Author: Adam D. Bull</p><p>Abstract: In the efﬁcient global optimization problem, we minimize an unknown function f , using as few observations f (x) as possible. It can be considered a continuum-armed-bandit problem, with noiseless data, and simple regret. Expected-improvement algorithms are perhaps the most popular methods for solving the problem; in this paper, we provide theoretical results on their asymptotic behaviour. Implementing these algorithms requires a choice of Gaussian-process prior, which determines an associated space of functions, its reproducing-kernel Hilbert space (RKHS). When the prior is ﬁxed, expected improvement is known to converge on the minimum of any function in its RKHS. We provide convergence rates for this procedure, optimal for functions of low smoothness, and describe a modiﬁed algorithm attaining optimal rates for smoother functions. In practice, however, priors are typically estimated sequentially from the data. For standard estimators, we show this procedure may never ﬁnd the minimum of f . We then propose alternative estimators, chosen to minimize the constants in the rate of convergence, and show these estimators retain the convergence rates of a ﬁxed prior. Keywords: convergence rates, efﬁcient global optimization, expected improvement, continuumarmed bandit, Bayesian optimization</p><p>5 0.059048586 <a title="19-tfidf-5" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: The online multi-armed bandit problem and its generalizations are repeated decision making problems, where the goal is to select one of several possible decisions in every round, and incur a cost associated with the decision, in such a way that the total cost incurred over all iterations is close to the cost of the best ﬁxed decision in hindsight. The difference in these costs is known as the regret of the algorithm. The term bandit refers to the setting where one only obtains the cost of the decision used in a given iteration and no other information. A very general form of this problem is the non-stochastic bandit linear optimization problem, where the set of decisions is a convex set in some√ Euclidean space, and the cost functions are linear. ˜ Only recently an efﬁcient algorithm attaining O( T ) regret was discovered in this setting. In this paper we propose a new algorithm for the bandit linear optimization problem which √ ˜ obtains a tighter regret bound of O( Q), where Q is the total variation in the cost functions. This regret bound, previously conjectured to hold in the full information case, shows that it is possible to incur much less regret in a slowly changing environment even in the bandit setting. Our algorithm is efﬁcient and applies several new ideas to bandit optimization such as reservoir sampling. Keywords: multi-armed bandit, regret minimization, online learning</p><p>6 0.05143236 <a title="19-tfidf-6" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>7 0.049079008 <a title="19-tfidf-7" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>8 0.047464404 <a title="19-tfidf-8" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>9 0.044235874 <a title="19-tfidf-9" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>10 0.040891789 <a title="19-tfidf-10" href="./jmlr-2011-Universality%2C_Characteristic_Kernels_and_RKHS_Embedding_of_Measures.html">98 jmlr-2011-Universality, Characteristic Kernels and RKHS Embedding of Measures</a></p>
<p>11 0.036952738 <a title="19-tfidf-11" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>12 0.034483958 <a title="19-tfidf-12" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>13 0.033271533 <a title="19-tfidf-13" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>14 0.032950565 <a title="19-tfidf-14" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>15 0.0328997 <a title="19-tfidf-15" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>16 0.032282244 <a title="19-tfidf-16" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>17 0.031762902 <a title="19-tfidf-17" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>18 0.031714749 <a title="19-tfidf-18" href="./jmlr-2011-Anechoic_Blind_Source_Separation_Using_Wigner_Marginals.html">10 jmlr-2011-Anechoic Blind Source Separation Using Wigner Marginals</a></p>
<p>19 0.031586323 <a title="19-tfidf-19" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>20 0.030788705 <a title="19-tfidf-20" href="./jmlr-2011-Clustering_Algorithms_for_Chains.html">16 jmlr-2011-Clustering Algorithms for Chains</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, 0.133), (2, -0.059), (3, -0.022), (4, -0.009), (5, 0.009), (6, 0.002), (7, 0.016), (8, -0.056), (9, 0.073), (10, -0.013), (11, 0.012), (12, -0.01), (13, 0.08), (14, -0.021), (15, -0.078), (16, 0.107), (17, -0.081), (18, -0.028), (19, 0.011), (20, 0.093), (21, -0.166), (22, -0.061), (23, -0.027), (24, 0.026), (25, -0.39), (26, -0.311), (27, 0.066), (28, 0.094), (29, 0.215), (30, -0.313), (31, 0.047), (32, 0.173), (33, 0.003), (34, -0.046), (35, -0.049), (36, 0.028), (37, -0.01), (38, 0.01), (39, -0.045), (40, 0.04), (41, 0.037), (42, -0.008), (43, -0.006), (44, -0.011), (45, -0.045), (46, 0.018), (47, 0.072), (48, -0.032), (49, -0.083)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94444746 <a title="19-lsi-1" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>Author: Benoît Patra</p><p>Abstract: Motivated by the problem of effectively executing clustering algorithms on very large data sets, we address a model for large scale distributed clustering methods. To this end, we brieﬂy recall some standards on the quantization problem and some results on the almost sure convergence of the competitive learning vector quantization (CLVQ) procedure. A general model for linear distributed asynchronous algorithms well adapted to several parallel computing architectures is also discussed. Our approach brings together this scalable model and the CLVQ algorithm, and we call the resulting technique the distributed asynchronous learning vector quantization algorithm (DALVQ). An indepth analysis of the almost sure convergence of the DALVQ algorithm is performed. A striking result is that we prove that the multiple versions of the quantizers distributed among the processors in the parallel architecture asymptotically reach a consensus almost surely. Furthermore, we also show that these versions converge almost surely towards the same nearly optimal value for the quantization criterion. Keywords: k-means, vector quantization, distributed, asynchronous, stochastic optimization, scalability, distributed consensus</p><p>2 0.61266834 <a title="19-lsi-2" href="./jmlr-2011-Parallel_Algorithm_for_Learning_Optimal_Bayesian_Network_Structure.html">75 jmlr-2011-Parallel Algorithm for Learning Optimal Bayesian Network Structure</a></p>
<p>Author: Yoshinori Tamada, Seiya Imoto, Satoru Miyano</p><p>Abstract: We present a parallel algorithm for the score-based optimal structure search of Bayesian networks. This algorithm is based on a dynamic programming (DP) algorithm having O(n · 2n ) time and space complexity, which is known to be the fastest algorithm for the optimal structure search of networks with n nodes. The bottleneck of the problem is the memory requirement, and therefore, the algorithm is currently applicable for up to a few tens of nodes. While the recently proposed algorithm overcomes this limitation by a space-time trade-off, our proposed algorithm realizes direct parallelization of the original DP algorithm with O(nσ ) time and space overhead calculations, where σ > 0 controls the communication-space trade-off. The overall time and space complexity is O(nσ+1 2n ). This algorithm splits the search space so that the required communication between independent calculations is minimal. Because of this advantage, our algorithm can run on distributed memory supercomputers. Through computational experiments, we conﬁrmed that our algorithm can run in parallel using up to 256 processors with a parallelization efﬁciency of 0.74, compared to the original DP algorithm with a single processor. We also demonstrate optimal structure search for a 32-node network without any constraints, which is the largest network search presented in literature. Keywords: optimal Bayesian network structure, parallel algorithm</p><p>3 0.45525765 <a title="19-lsi-3" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>Author: Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</p><p>Abstract: Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed. Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation. To solve these problems, we introduce a new framework, semiparametric statistical inference, to model-free policy evaluation. This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a uniﬁed way in terms of estimating functions. Furthermore, based on this framework, we derive an optimal estimating function with the minimum asymptotic variance and propose batch and online learning algorithms which achieve the optimality. Keywords: reinforcement learning, model-free policy evaluation, TD learning, semiparametirc model, estimating function</p><p>4 0.28484491 <a title="19-lsi-4" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>Author: Bruno Pelletier, Pierre Pudlo</p><p>Abstract: Following Hartigan (1975), a cluster is deﬁned as a connected component of the t-level set of the underlying density, that is, the set of points for which the density is greater than t. A clustering algorithm which combines a density estimate with spectral clustering techniques is proposed. Our algorithm is composed of two steps. First, a nonparametric density estimate is used to extract the data points for which the estimated density takes a value greater than t. Next, the extracted points are clustered based on the eigenvectors of a graph Laplacian matrix. Under mild assumptions, we prove the almost sure convergence in operator norm of the empirical graph Laplacian operator associated with the algorithm. Furthermore, we give the typical behavior of the representation of the data set into the feature space, which establishes the strong consistency of our proposed algorithm. Keywords: spectral clustering, graph, unsupervised classiﬁcation, level sets, connected components</p><p>5 0.27779055 <a title="19-lsi-5" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>Author: Adam D. Bull</p><p>Abstract: In the efﬁcient global optimization problem, we minimize an unknown function f , using as few observations f (x) as possible. It can be considered a continuum-armed-bandit problem, with noiseless data, and simple regret. Expected-improvement algorithms are perhaps the most popular methods for solving the problem; in this paper, we provide theoretical results on their asymptotic behaviour. Implementing these algorithms requires a choice of Gaussian-process prior, which determines an associated space of functions, its reproducing-kernel Hilbert space (RKHS). When the prior is ﬁxed, expected improvement is known to converge on the minimum of any function in its RKHS. We provide convergence rates for this procedure, optimal for functions of low smoothness, and describe a modiﬁed algorithm attaining optimal rates for smoother functions. In practice, however, priors are typically estimated sequentially from the data. For standard estimators, we show this procedure may never ﬁnd the minimum of f . We then propose alternative estimators, chosen to minimize the constants in the rate of convergence, and show these estimators retain the convergence rates of a ﬁxed prior. Keywords: convergence rates, efﬁcient global optimization, expected improvement, continuumarmed bandit, Bayesian optimization</p><p>6 0.2622529 <a title="19-lsi-6" href="./jmlr-2011-Anechoic_Blind_Source_Separation_Using_Wigner_Marginals.html">10 jmlr-2011-Anechoic Blind Source Separation Using Wigner Marginals</a></p>
<p>7 0.21715991 <a title="19-lsi-7" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>8 0.21382917 <a title="19-lsi-8" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>9 0.19796965 <a title="19-lsi-9" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>10 0.19494405 <a title="19-lsi-10" href="./jmlr-2011-Universality%2C_Characteristic_Kernels_and_RKHS_Embedding_of_Measures.html">98 jmlr-2011-Universality, Characteristic Kernels and RKHS Embedding of Measures</a></p>
<p>11 0.18230243 <a title="19-lsi-11" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>12 0.1710663 <a title="19-lsi-12" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>13 0.15890202 <a title="19-lsi-13" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>14 0.15750821 <a title="19-lsi-14" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>15 0.15592502 <a title="19-lsi-15" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>16 0.15384436 <a title="19-lsi-16" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>17 0.14922409 <a title="19-lsi-17" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>18 0.1480529 <a title="19-lsi-18" href="./jmlr-2011-Clustering_Algorithms_for_Chains.html">16 jmlr-2011-Clustering Algorithms for Chains</a></p>
<p>19 0.14660107 <a title="19-lsi-19" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>20 0.14024191 <a title="19-lsi-20" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.041), (9, 0.026), (10, 0.06), (24, 0.035), (31, 0.079), (32, 0.019), (41, 0.039), (57, 0.41), (60, 0.014), (65, 0.014), (67, 0.012), (71, 0.011), (73, 0.023), (78, 0.094), (90, 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6726864 <a title="19-lda-1" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>Author: Benoît Patra</p><p>Abstract: Motivated by the problem of effectively executing clustering algorithms on very large data sets, we address a model for large scale distributed clustering methods. To this end, we brieﬂy recall some standards on the quantization problem and some results on the almost sure convergence of the competitive learning vector quantization (CLVQ) procedure. A general model for linear distributed asynchronous algorithms well adapted to several parallel computing architectures is also discussed. Our approach brings together this scalable model and the CLVQ algorithm, and we call the resulting technique the distributed asynchronous learning vector quantization algorithm (DALVQ). An indepth analysis of the almost sure convergence of the DALVQ algorithm is performed. A striking result is that we prove that the multiple versions of the quantizers distributed among the processors in the parallel architecture asymptotically reach a consensus almost surely. Furthermore, we also show that these versions converge almost surely towards the same nearly optimal value for the quantization criterion. Keywords: k-means, vector quantization, distributed, asynchronous, stochastic optimization, scalability, distributed consensus</p><p>2 0.33365116 <a title="19-lda-2" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>Author: Nicolò Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</p><p>Abstract: We investigate three variants of budgeted learning, a setting in which the learner is allowed to access a limited number of attributes from training or test examples. In the “local budget” setting, where a constraint is imposed on the number of available attributes per training example, we design and analyze an efﬁcient algorithm for learning linear predictors that actively samples the attributes of each training instance. Our analysis bounds the number of additional examples sufﬁcient to compensate for the lack of full information on the training set. This result is complemented by a general lower bound for the easier “global budget” setting, where it is only the overall number of accessible training attributes that is being constrained. In the third, “prediction on a budget” setting, when the constraint is on the number of available attributes per test example, we show that there are cases in which there exists a linear predictor with zero error but it is statistically impossible to achieve arbitrary accuracy without full information on test examples. Finally, we run simple experiments on a digit recognition problem that reveal that our algorithm has a good performance against both partial information and full information baselines. Keywords: budgeted learning, statistical learning, linear predictors, learning with partial information, learning theory</p><p>3 0.33295417 <a title="19-lda-3" href="./jmlr-2011-Clustering_Algorithms_for_Chains.html">16 jmlr-2011-Clustering Algorithms for Chains</a></p>
<p>Author: Antti Ukkonen</p><p>Abstract: We consider the problem of clustering a set of chains to k clusters. A chain is a totally ordered subset of a ﬁnite set of items. Chains are an intuitive way to express preferences over a set of alternatives, as well as a useful representation of ratings in situations where the item-speciﬁc scores are either difﬁcult to obtain, too noisy due to measurement error, or simply not as relevant as the order that they induce over the items. First we adapt the classical k-means for chains by proposing a suitable distance function and a centroid structure. We also present two different approaches for mapping chains to a vector space. The ﬁrst one is related to the planted partition model, while the second one has an intuitive geometrical interpretation. Finally we discuss a randomization test for assessing the signiﬁcance of a clustering. To this end we present an MCMC algorithm for sampling random sets of chains that share certain properties with the original data. The methods are studied in a series of experiments using real and artiﬁcial data. Results indicate that the methods produce interesting clusterings, and for certain types of inputs improve upon previous work on clustering algorithms for orders. Keywords: Lloyd’s algorithm, orders, preference statements, planted partition model, randomization testing</p><p>4 0.32836318 <a title="19-lda-4" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>Author: Sébastien Bubeck, Rémi Munos, Gilles Stoltz, Csaba Szepesvári</p><p>Abstract: We consider a generalization of stochastic bandits where the set of arms, X , is allowed to be a generic measurable space and the mean-payoff function is “locally Lipschitz” with respect to a dissimilarity function that is known to the decision maker. Under this condition we construct an arm selection policy, called HOO (hierarchical optimistic optimization), with improved regret bounds compared to previous results for a large class of problems. In particular, our results imply that if X is the unit hypercube in a Euclidean space and the mean-payoff function has a ﬁnite number of global maxima around which the behavior of the function is locally continuous with a known √ smoothness degree, then the expected regret of HOO is bounded up to a logarithmic factor by n, that is, the rate of growth of the regret is independent of the dimension of the space. We also prove the minimax optimality of our algorithm when the dissimilarity is a metric. Our basic strategy has quadratic computational complexity as a function of the number of time steps and does not rely on the doubling trick. We also introduce a modiﬁed strategy, which relies on the doubling trick but runs in linearithmic time. Both results are improvements with respect to previous approaches. Keywords: bandits with inﬁnitely many arms, optimistic online optimization, regret bounds, minimax rates</p><p>5 0.32742018 <a title="19-lda-5" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>Author: Bruno Pelletier, Pierre Pudlo</p><p>Abstract: Following Hartigan (1975), a cluster is deﬁned as a connected component of the t-level set of the underlying density, that is, the set of points for which the density is greater than t. A clustering algorithm which combines a density estimate with spectral clustering techniques is proposed. Our algorithm is composed of two steps. First, a nonparametric density estimate is used to extract the data points for which the estimated density takes a value greater than t. Next, the extracted points are clustered based on the eigenvectors of a graph Laplacian matrix. Under mild assumptions, we prove the almost sure convergence in operator norm of the empirical graph Laplacian operator associated with the algorithm. Furthermore, we give the typical behavior of the representation of the data set into the feature space, which establishes the strong consistency of our proposed algorithm. Keywords: spectral clustering, graph, unsupervised classiﬁcation, level sets, connected components</p><p>6 0.32690525 <a title="19-lda-6" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<p>7 0.32556587 <a title="19-lda-7" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>8 0.32472655 <a title="19-lda-8" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>9 0.32368997 <a title="19-lda-9" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>10 0.32276309 <a title="19-lda-10" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>11 0.32255465 <a title="19-lda-11" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>12 0.32087722 <a title="19-lda-12" href="./jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">4 jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<p>13 0.32063392 <a title="19-lda-13" href="./jmlr-2011-Parameter_Screening_and_Optimisation_for_ILP_using_Designed_Experiments.html">76 jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</a></p>
<p>14 0.32025453 <a title="19-lda-14" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>15 0.31992397 <a title="19-lda-15" href="./jmlr-2011-Learning_High-Dimensional_Markov_Forest_Distributions%3A_Analysis_of_Error_Rates.html">53 jmlr-2011-Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates</a></p>
<p>16 0.31971973 <a title="19-lda-16" href="./jmlr-2011-Hierarchical_Knowledge_Gradient_for_Sequential_Sampling.html">38 jmlr-2011-Hierarchical Knowledge Gradient for Sequential Sampling</a></p>
<p>17 0.31966752 <a title="19-lda-17" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>18 0.31965211 <a title="19-lda-18" href="./jmlr-2011-Group_Lasso_Estimation_of_High-dimensional_Covariance_Matrices.html">37 jmlr-2011-Group Lasso Estimation of High-dimensional Covariance Matrices</a></p>
<p>19 0.31905904 <a title="19-lda-19" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>20 0.31889766 <a title="19-lda-20" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
