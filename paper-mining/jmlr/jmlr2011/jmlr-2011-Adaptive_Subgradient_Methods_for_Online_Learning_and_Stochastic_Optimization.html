<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-8" href="#">jmlr2011-8</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</h1>
<br/><p>Source: <a title="jmlr-2011-8-pdf" href="http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">pdf</a></p><p>Author: John Duchi, Elad Hazan, Yoram Singer</p><p>Abstract: We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms. Keywords: subgradient methods, adaptivity, online learning, stochastic convex optimization</p><p>Reference: <a title="jmlr-2011-8-reference" href="../jmlr2011_reference/jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gt', 0.588), ('xt', 0.483), ('rda', 0.236), ('arow', 0.225), ('tr', 0.199), ('ft', 0.183), ('subgrady', 0.142), ('regret', 0.141), ('dag', 0.14), ('ubgrady', 0.122), ('uch', 0.122), ('proxim', 0.096), ('rad', 0.093), ('dapt', 0.09), ('zt', 0.086), ('st', 0.079), ('vi', 0.079), ('az', 0.075), ('ht', 0.069), ('onlin', 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="8-tfidf-1" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>Author: John Duchi, Elad Hazan, Yoram Singer</p><p>Abstract: We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms. Keywords: subgradient methods, adaptivity, online learning, stochastic convex optimization</p><p>2 0.48771754 <a title="8-tfidf-2" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: The online multi-armed bandit problem and its generalizations are repeated decision making problems, where the goal is to select one of several possible decisions in every round, and incur a cost associated with the decision, in such a way that the total cost incurred over all iterations is close to the cost of the best ﬁxed decision in hindsight. The difference in these costs is known as the regret of the algorithm. The term bandit refers to the setting where one only obtains the cost of the decision used in a given iteration and no other information. A very general form of this problem is the non-stochastic bandit linear optimization problem, where the set of decisions is a convex set in some√ Euclidean space, and the cost functions are linear. ˜ Only recently an efﬁcient algorithm attaining O( T ) regret was discovered in this setting. In this paper we propose a new algorithm for the bandit linear optimization problem which √ ˜ obtains a tighter regret bound of O( Q), where Q is the total variation in the cost functions. This regret bound, previously conjectured to hold in the full information case, shows that it is possible to incur much less regret in a slowly changing environment even in the bandit setting. Our algorithm is efﬁcient and applies several new ideas to bandit optimization such as reservoir sampling. Keywords: multi-armed bandit, regret minimization, online learning</p><p>3 0.16161288 <a title="8-tfidf-3" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>Author: Gilles Meyer, Silvère Bonnabel, Rodolphe Sepulchre</p><p>Abstract: The paper addresses the problem of learning a regression model parameterized by a ﬁxed-rank positive semideﬁnite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of ﬁxedrank positive semideﬁnite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semideﬁnite matrix. Good performance is observed on classical benchmarks. Keywords: linear regression, positive semideﬁnite matrices, low-rank approximation, Riemannian geometry, gradient-based learning</p><p>4 0.12919497 <a title="8-tfidf-4" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>Author: Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</p><p>Abstract: Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed. Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation. To solve these problems, we introduce a new framework, semiparametric statistical inference, to model-free policy evaluation. This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a uniﬁed way in terms of estimating functions. Furthermore, based on this framework, we derive an optimal estimating function with the minimum asymptotic variance and propose batch and online learning algorithms which achieve the optimality. Keywords: reinforcement learning, model-free policy evaluation, TD learning, semiparametirc model, estimating function</p><p>5 0.12229119 <a title="8-tfidf-5" href="./jmlr-2011-Double_Updating_Online_Learning.html">28 jmlr-2011-Double Updating Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C.H. Hoi, Rong Jin</p><p>Abstract: In most kernel based online learning algorithms, when an incoming instance is misclassiﬁed, it will be added into the pool of support vectors and assigned with a weight, which often remains unchanged during the rest of the learning process. This is clearly insufﬁcient since when a new support vector is added, we generally expect the weights of the other existing support vectors to be updated in order to reﬂect the inﬂuence of the added support vector. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short, that explicitly addresses this problem. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received at the current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be improved by the proposed online learning method. We conduct an extensive set of empirical evaluations for both binary and multi-class online learning tasks. The experimental results show that the proposed technique is considerably more effective than the state-of-the-art online learning algorithms. The source code is available to public at http://www.cais.ntu.edu.sg/˜chhoi/DUOL/. Keywords: online learning, kernel method, support vector machines, maximum margin learning, classiﬁcation</p><p>6 0.090718366 <a title="8-tfidf-6" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>7 0.085086375 <a title="8-tfidf-7" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>8 0.083743341 <a title="8-tfidf-8" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>9 0.072664827 <a title="8-tfidf-9" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>10 0.066268623 <a title="8-tfidf-10" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>11 0.065802053 <a title="8-tfidf-11" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>12 0.06122572 <a title="8-tfidf-12" href="./jmlr-2011-High-dimensional_Covariance_Estimation_Based_On_Gaussian_Graphical_Models.html">39 jmlr-2011-High-dimensional Covariance Estimation Based On Gaussian Graphical Models</a></p>
<p>13 0.060459379 <a title="8-tfidf-13" href="./jmlr-2011-Adaptive_Exact_Inference_in_Graphical_Models.html">7 jmlr-2011-Adaptive Exact Inference in Graphical Models</a></p>
<p>14 0.059037149 <a title="8-tfidf-14" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>15 0.058687158 <a title="8-tfidf-15" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>16 0.052195575 <a title="8-tfidf-16" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>17 0.050228324 <a title="8-tfidf-17" href="./jmlr-2011-Learning_Multi-modal_Similarity.html">55 jmlr-2011-Learning Multi-modal Similarity</a></p>
<p>18 0.048853543 <a title="8-tfidf-18" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>19 0.048689924 <a title="8-tfidf-19" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>20 0.047850493 <a title="8-tfidf-20" href="./jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">4 jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.263), (1, -0.365), (2, 0.184), (3, 0.096), (4, 0.257), (5, 0.091), (6, -0.433), (7, -0.023), (8, 0.102), (9, -0.135), (10, -0.032), (11, -0.095), (12, -0.115), (13, -0.007), (14, -0.083), (15, -0.005), (16, 0.189), (17, 0.037), (18, 0.085), (19, -0.003), (20, -0.018), (21, 0.182), (22, 0.01), (23, 0.051), (24, -0.08), (25, -0.059), (26, 0.019), (27, -0.049), (28, -0.005), (29, 0.089), (30, -0.009), (31, 0.048), (32, -0.02), (33, -0.017), (34, -0.012), (35, 0.035), (36, 0.015), (37, -0.009), (38, -0.017), (39, -0.017), (40, 0.011), (41, 0.006), (42, -0.026), (43, 0.023), (44, 0.027), (45, 0.021), (46, 0.012), (47, 0.004), (48, 0.01), (49, -0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97892928 <a title="8-lsi-1" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>Author: John Duchi, Elad Hazan, Yoram Singer</p><p>Abstract: We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms. Keywords: subgradient methods, adaptivity, online learning, stochastic convex optimization</p><p>2 0.94571173 <a title="8-lsi-2" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: The online multi-armed bandit problem and its generalizations are repeated decision making problems, where the goal is to select one of several possible decisions in every round, and incur a cost associated with the decision, in such a way that the total cost incurred over all iterations is close to the cost of the best ﬁxed decision in hindsight. The difference in these costs is known as the regret of the algorithm. The term bandit refers to the setting where one only obtains the cost of the decision used in a given iteration and no other information. A very general form of this problem is the non-stochastic bandit linear optimization problem, where the set of decisions is a convex set in some√ Euclidean space, and the cost functions are linear. ˜ Only recently an efﬁcient algorithm attaining O( T ) regret was discovered in this setting. In this paper we propose a new algorithm for the bandit linear optimization problem which √ ˜ obtains a tighter regret bound of O( Q), where Q is the total variation in the cost functions. This regret bound, previously conjectured to hold in the full information case, shows that it is possible to incur much less regret in a slowly changing environment even in the bandit setting. Our algorithm is efﬁcient and applies several new ideas to bandit optimization such as reservoir sampling. Keywords: multi-armed bandit, regret minimization, online learning</p><p>3 0.4863618 <a title="8-lsi-3" href="./jmlr-2011-Double_Updating_Online_Learning.html">28 jmlr-2011-Double Updating Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C.H. Hoi, Rong Jin</p><p>Abstract: In most kernel based online learning algorithms, when an incoming instance is misclassiﬁed, it will be added into the pool of support vectors and assigned with a weight, which often remains unchanged during the rest of the learning process. This is clearly insufﬁcient since when a new support vector is added, we generally expect the weights of the other existing support vectors to be updated in order to reﬂect the inﬂuence of the added support vector. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short, that explicitly addresses this problem. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received at the current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be improved by the proposed online learning method. We conduct an extensive set of empirical evaluations for both binary and multi-class online learning tasks. The experimental results show that the proposed technique is considerably more effective than the state-of-the-art online learning algorithms. The source code is available to public at http://www.cais.ntu.edu.sg/˜chhoi/DUOL/. Keywords: online learning, kernel method, support vector machines, maximum margin learning, classiﬁcation</p><p>4 0.39990991 <a title="8-lsi-4" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>Author: Gilles Meyer, Silvère Bonnabel, Rodolphe Sepulchre</p><p>Abstract: The paper addresses the problem of learning a regression model parameterized by a ﬁxed-rank positive semideﬁnite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of ﬁxedrank positive semideﬁnite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semideﬁnite matrix. Good performance is observed on classical benchmarks. Keywords: linear regression, positive semideﬁnite matrices, low-rank approximation, Riemannian geometry, gradient-based learning</p><p>5 0.35687828 <a title="8-lsi-5" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>Author: Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</p><p>Abstract: Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed. Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation. To solve these problems, we introduce a new framework, semiparametric statistical inference, to model-free policy evaluation. This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a uniﬁed way in terms of estimating functions. Furthermore, based on this framework, we derive an optimal estimating function with the minimum asymptotic variance and propose batch and online learning algorithms which achieve the optimality. Keywords: reinforcement learning, model-free policy evaluation, TD learning, semiparametirc model, estimating function</p><p>6 0.32320139 <a title="8-lsi-6" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>7 0.2976765 <a title="8-lsi-7" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>8 0.28298289 <a title="8-lsi-8" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>9 0.23230375 <a title="8-lsi-9" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>10 0.2044104 <a title="8-lsi-10" href="./jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">4 jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<p>11 0.20129117 <a title="8-lsi-11" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>12 0.20006253 <a title="8-lsi-12" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>13 0.18881713 <a title="8-lsi-13" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>14 0.18479006 <a title="8-lsi-14" href="./jmlr-2011-High-dimensional_Covariance_Estimation_Based_On_Gaussian_Graphical_Models.html">39 jmlr-2011-High-dimensional Covariance Estimation Based On Gaussian Graphical Models</a></p>
<p>15 0.18068135 <a title="8-lsi-15" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>16 0.17439227 <a title="8-lsi-16" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>17 0.17299643 <a title="8-lsi-17" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>18 0.16031767 <a title="8-lsi-18" href="./jmlr-2011-The_Indian_Buffet_Process%3A_An_Introduction_and_Review.html">90 jmlr-2011-The Indian Buffet Process: An Introduction and Review</a></p>
<p>19 0.14908519 <a title="8-lsi-19" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>20 0.14700937 <a title="8-lsi-20" href="./jmlr-2011-Learning_Multi-modal_Similarity.html">55 jmlr-2011-Learning Multi-modal Similarity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.043), (8, 0.013), (11, 0.042), (17, 0.09), (22, 0.026), (24, 0.037), (37, 0.055), (39, 0.031), (50, 0.047), (65, 0.288), (67, 0.03), (84, 0.044), (86, 0.138), (96, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73295367 <a title="8-lda-1" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>Author: John Duchi, Elad Hazan, Yoram Singer</p><p>Abstract: We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms. Keywords: subgradient methods, adaptivity, online learning, stochastic convex optimization</p><p>2 0.5471313 <a title="8-lda-2" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>Author: Julien Mairal, Rodolphe Jenatton, Guillaume Obozinski, Francis Bach</p><p>Abstract: We consider a class of learning problems regularized by a structured sparsity-inducing norm deﬁned as the sum of ℓ2 - or ℓ∞ -norms over groups of variables. Whereas much effort has been put in developing fast optimization techniques when the groups are disjoint or embedded in a hierarchy, we address here the case of general overlapping groups. To this end, we present two different strategies: On the one hand, we show that the proximal operator associated with a sum of ℓ∞ norms can be computed exactly in polynomial time by solving a quadratic min-cost ﬂow problem, allowing the use of accelerated proximal gradient methods. On the other hand, we use proximal splitting techniques, and address an equivalent formulation with non-overlapping groups, but in higher dimension and with additional constraints. We propose efﬁcient and scalable algorithms exploiting these two strategies, which are signiﬁcantly faster than alternative approaches. We illustrate these methods with several problems such as CUR matrix factorization, multi-task learning of tree-structured dictionaries, background subtraction in video sequences, image denoising with wavelets, and topographic dictionary learning of natural image patches. Keywords: convex optimization, proximal methods, sparse coding, structured sparsity, matrix factorization, network ﬂow optimization, alternating direction method of multipliers</p><p>3 0.53640938 <a title="8-lda-3" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>Author: Tony Jebara</p><p>Abstract: A multitask learning framework is developed for discriminative classiﬁcation and regression where multiple large-margin linear classiﬁers are estimated for different prediction problems. These classiﬁers operate in a common input space but are coupled as they recover an unknown shared representation. A maximum entropy discrimination (MED) framework is used to derive the multitask algorithm which involves only convex optimization problems that are straightforward to implement. Three multitask scenarios are described. The ﬁrst multitask method produces multiple support vector machines that learn a shared sparse feature selection over the input space. The second multitask method produces multiple support vector machines that learn a shared conic kernel combination. The third multitask method produces a pooled classiﬁer as well as adaptively specialized individual classiﬁers. Furthermore, extensions to regression, graphical model structure estimation and other sparse methods are discussed. The maximum entropy optimization problems are implemented via a sequential quadratic programming method which leverages recent progress in fast SVM solvers. Fast monotonic convergence bounds are provided by bounding the MED sparsifying cost function with a quadratic function and ensuring only a constant factor runtime increase above standard independent SVM solvers. Results are shown on multitask data sets and favor multitask learning over single-task or tabula rasa methods. Keywords: meta-learning, support vector machines, feature selection, kernel selection, maximum entropy, large margin, Bayesian methods, variational bounds, classiﬁcation, regression, Lasso, graphical model structure estimation, quadratic programming, convex programming</p><p>4 0.53338259 <a title="8-lda-4" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>Author: Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski, Francis Bach</p><p>Abstract: Sparse coding consists in representing signals as sparse linear combinations of atoms selected from a dictionary. We consider an extension of this framework where the atoms are further assumed to be embedded in a tree. This is achieved using a recently introduced tree-structured sparse regularization norm, which has proven useful in several applications. This norm leads to regularized problems that are difﬁcult to optimize, and in this paper, we propose efﬁcient algorithms for solving them. More precisely, we show that the proximal operator associated with this norm is computable exactly via a dual approach that can be viewed as the composition of elementary proximal operators. Our procedure has a complexity linear, or close to linear, in the number of atoms, and allows the use of accelerated gradient techniques to solve the tree-structured sparse approximation problem at the same computational cost as traditional ones using the ℓ1 -norm. Our method is efﬁcient and scales gracefully to millions of variables, which we illustrate in two types of applications: ﬁrst, we consider ﬁxed hierarchical dictionaries of wavelets to denoise natural images. Then, we apply our optimization tools in the context of dictionary learning, where learned dictionary elements naturally self-organize in a prespeciﬁed arborescent structure, leading to better performance in reconstruction of natural image patches. When applied to text documents, our method learns hierarchies of topics, thus providing a competitive alternative to probabilistic topic models. Keywords: Proximal methods, dictionary learning, structured sparsity, matrix factorization</p><p>5 0.5277245 <a title="8-lda-5" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>Author: Junzhou Huang, Tong Zhang, Dimitris Metaxas</p><p>Abstract: This paper investigates a learning formulation called structured sparsity, which is a natural extension of the standard sparsity concept in statistical learning and compressive sensing. By allowing arbitrary structures on the feature set, this concept generalizes the group sparsity idea that has become popular in recent years. A general theory is developed for learning with structured sparsity, based on the notion of coding complexity associated with the structure. It is shown that if the coding complexity of the target signal is small, then one can achieve improved performance by using coding complexity regularization methods, which generalize the standard sparse regularization. Moreover, a structured greedy algorithm is proposed to efﬁciently solve the structured sparsity problem. It is shown that the greedy algorithm approximately solves the coding complexity optimization problem under appropriate conditions. Experiments are included to demonstrate the advantage of structured sparsity over standard sparsity on some real applications. Keywords: structured sparsity, standard sparsity, group sparsity, tree sparsity, graph sparsity, sparse learning, feature selection, compressive sensing</p><p>6 0.51891506 <a title="8-lda-6" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>7 0.51808965 <a title="8-lda-7" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>8 0.51738697 <a title="8-lda-8" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>9 0.51588565 <a title="8-lda-9" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>10 0.50617713 <a title="8-lda-10" href="./jmlr-2011-Double_Updating_Online_Learning.html">28 jmlr-2011-Double Updating Online Learning</a></p>
<p>11 0.50457966 <a title="8-lda-11" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>12 0.50299263 <a title="8-lda-12" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>13 0.50133693 <a title="8-lda-13" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>14 0.49234271 <a title="8-lda-14" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>15 0.49169385 <a title="8-lda-15" href="./jmlr-2011-lp-Norm_Multiple_Kernel_Learning.html">105 jmlr-2011-lp-Norm Multiple Kernel Learning</a></p>
<p>16 0.48689562 <a title="8-lda-16" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>17 0.48155713 <a title="8-lda-17" href="./jmlr-2011-Laplacian_Support_Vector_Machines__Trained_in_the_Primal.html">51 jmlr-2011-Laplacian Support Vector Machines  Trained in the Primal</a></p>
<p>18 0.47767633 <a title="8-lda-18" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>19 0.47531965 <a title="8-lda-19" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<p>20 0.47505277 <a title="8-lda-20" href="./jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">4 jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
