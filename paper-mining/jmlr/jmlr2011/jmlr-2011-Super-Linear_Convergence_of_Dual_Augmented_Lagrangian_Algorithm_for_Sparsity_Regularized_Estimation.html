<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-89" href="#">jmlr2011-89</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</h1>
<br/><p>Source: <a title="jmlr-2011-89-pdf" href="http://jmlr.org/papers/volume12/tomioka11a/tomioka11a.pdf">pdf</a></p><p>Author: Ryota Tomioka, Taiji Suzuki, Masashi Sugiyama</p><p>Abstract: We analyze the convergence behaviour of a recently proposed algorithm for regularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is based on a new interpretation of DAL as a proximal minimization algorithm. We theoretically show under some conditions that DAL converges super-linearly in a non-asymptotic and global sense. Due to a special modelling of sparse estimation problems in the context of machine learning, the assumptions we make are milder and more natural than those made in conventional analysis of augmented Lagrangian algorithms. In addition, the new interpretation enables us to generalize DAL to wide varieties of sparse estimation problems. We experimentally conﬁrm our analysis in a large scale ℓ1 -regularized logistic regression problem and extensively compare the efﬁciency of DAL algorithm to previously proposed algorithms on both synthetic and benchmark data sets. Keywords: dual augmented Lagrangian, proximal minimization, global convergence, sparse estimation, convex optimization</p><p>Reference: <a title="jmlr-2011-89-reference" href="../jmlr2011_reference/jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Our analysis is based on a new interpretation of DAL as a proximal minimization algorithm. [sent-13, score-0.147]
</p><p>2 Due to a special modelling of sparse estimation problems in the context of machine learning, the assumptions we make are milder and more natural than those made in conventional analysis of augmented Lagrangian algorithms. [sent-15, score-0.15]
</p><p>3 Keywords: dual augmented Lagrangian, proximal minimization, global convergence, sparse estimation, convex optimization  1. [sent-18, score-0.294]
</p><p>4 In this paper, we show that a recently proposed dual augmented Lagrangian (DAL) algorithm (Tomioka and Sugiyama, 2009) can be considered as an exact (up to ﬁnite tolerance) version of the iterative approximation process discussed in Wright et al. [sent-59, score-0.175]
</p><p>5 Our formulation is based on the connection between the proximal minimization (Rockafellar, 1976a) and the augmented Lagrangian (AL) algorithm (Hestenes, 1969; Powell, 1969; Rockafellar, 1976b; Bertsekas, 1982). [sent-61, score-0.277]
</p><p>6 The proximal minimization framework also allows us to rigorously study the convergence behaviour of DAL. [sent-62, score-0.167]
</p><p>7 Our analysis improves the classical result on the convergence of augmented Lagrangian algorithms in Rockafellar (1976b) by taking special structures of sparse estimation into account. [sent-65, score-0.17]
</p><p>8 Recently Yang and Zhang (2009) compared primal and dual augmented Lagrangian algorithms for ℓ1 -problems and reported that the dual formulation was more efﬁcient. [sent-100, score-0.198]
</p><p>9 We derive DAL algorithm from the proximal minimization framework in Section 3; special instances of DAL algorithm are discussed in Section 4. [sent-105, score-0.147]
</p><p>10 Next we derive DAL algorithm for ℓ1 -problem as an augmented Lagrangian method in the dual. [sent-114, score-0.13]
</p><p>11 For general information on augmented Lagrangian algorithms (Powell, 1969; Hestenes, 1969; Rockafellar, 1976b), see Bertsekas (1982) and Nocedal and Wright (1999). [sent-144, score-0.13]
</p><p>12 λ Let us consider the augmented Lagrangian (AL) function Lη with respect to the above dual problem (3) Lη (α, v; w) = − fℓ∗ (−α) − δ∞ (v) + w⊤ (v − A⊤ α) − λ  η v − A⊤ α 2 , 2  (6)  where the primal variable w ∈ Rn is interpreted as a Lagrangian multiplier vector in the AL framework. [sent-147, score-0.194]
</p><p>13 At every time step t, given the current primal solution wt , we maximize the AL function Lηt (α, v; wt ) with respect to α and v. [sent-153, score-1.102]
</p><p>14 The maximizer (αt , vt ) is used to update the primal solution (Lagrangian multiplier) wt as follows: wt+1 = wt + ηt (A⊤ αt − vt ). [sent-154, score-1.102]
</p><p>15 Furthermore, substituting the above vt (α) into Equation (6), we can express αt as the minimizer of the function ϕt (α) := −Lηt (α, vt (α); wt ) = fℓ∗ (−α) +  1 proxℓ1 t (wt + ηt A⊤ α) 2 , λη 2ηt  (10)  which we also call an AL function with a slight abuse of terminology. [sent-161, score-0.561]
</p><p>16 2 from the proximal minimization framework (Rockafellar, 1976a), which allows for a new interpretation of the algorithm (see Section 3. [sent-165, score-0.147]
</p><p>17 1 Proximal Minimization Algorithm Let us consider the following iterative algorithm called the proximal minimization algorithm (Rockafellar, 1976a) for the minimization of the objective (1). [sent-168, score-0.243]
</p><p>18 , 2009; Tomioka and Sugiyama, 2009) is satisﬁed: wt+1 = argmin f (w) + w∈Rn  1 w − wt 2ηt  2  ,  (11)  where f (w) is the objective function in Equation (1) and ηt controls the inﬂuence of the additional proximity term. [sent-181, score-0.648]
</p><p>19 The proximity term tries to keep the next solution wt+1 close to the current solution wt . [sent-182, score-0.628]
</p><p>20 Although at this point it is not clear how we are going to carry out the above minimization, 1 by deﬁnition we have f (wt+1 ) + 2ηt wt+1 − wt 2 ≤ f (wt ); that is, provided that the step-size is positive, the function value decreases monotonically at every iteration. [sent-184, score-0.543]
</p><p>21 One way to make the proximal minimization algorithm practical is to linearly approximate (see Wright et al. [sent-188, score-0.147]
</p><p>22 , 2009) the loss term at the current point wt as t fℓ (Aw) ≃ fℓ (Awt ) + ∇ fℓ  ⊤  A w − wt ,  (12)  t where ∇ fℓ is a short hand for ∇ fℓ (Awt ). [sent-189, score-1.107]
</p><p>23 Substituting the above approximation (12) into the iteration (11), we obtain t ∇ fℓ  wt+1 = argmin w∈Rn  ⊤  Aw + φλ (w) +  1 w − wt 2ηt  2  ,  (13)  where constant terms are omitted from the right-hand side. [sent-190, score-0.543]
</p><p>24 The IST iteration can be written as follows: wt+1 := proxφλη  t  t wt − ηt A⊤ ∇ fℓ ,  (14)  where the proximity operator proxφλη is deﬁned as follows: t  proxφλ (y) = argmin x∈Rn  1 y−x 2  2  + φλ (x) . [sent-196, score-0.628]
</p><p>25 (15)  Note that the soft-threshold operation proxℓ1 (9) is the proximity operator corresponding to the ℓ1 λ regularizer φℓ1 (w) = λ w 1 . [sent-197, score-0.139]
</p><p>26 3 DAL Algorithm from the Proximal Minimization Framework The above IST approach can be considered to be constructing a linear lower bound of the loss term in Equation (11) at the current point wt . [sent-201, score-0.564]
</p><p>27 Now we substitute this expression into the iteration (11) as follows: 1 w − wt 2ηt  wt+1 = argmin max −α⊤ Aw − fℓ∗ (−α) + φλ (w) + m w∈Rn  α∈R  2  . [sent-205, score-0.543]
</p><p>28 , convex with respect to w and concave with respect to α Rockafellar, 1970), as follows: minn max −α⊤ Aw − fℓ∗ (−α) + φλ (w) + m  w∈R α∈R  1 w − wt 2ηt  = max − fℓ∗ (−α) + minn −α⊤ Aw + φλ (w) + m α∈R  w∈R  2  1 w − wt 2ηt  2  . [sent-209, score-1.114]
</p><p>29 The minimization with respect to w in Equation (18) gives the following update equation wt+1 = proxφλη  t  wt + ηt A⊤ αt ,  (19)  where αt denotes the maximizer with respect to α in Equation (18). [sent-211, score-0.63]
</p><p>30 Since the function ϕt (α) in Equation (20) generalizes the ALfunction (10), we call it an augmented Lagrangian (AL) function. [sent-220, score-0.13]
</p><p>31 What we need to do at every iteration is to minimize the AL function ϕt (α) and update the Lagrangian multiplier wt as in Equation (19) using the minimizer αt in Equation (20). [sent-221, score-0.583]
</p><p>32 This can be shown by computing the proximity operator (19) and the Moreau envelope (21) for the speciﬁc case of ℓ1 -regularization; see Section 4. [sent-226, score-0.15]
</p><p>33 In fact, using Lemma 10 in Appendix A, the derivative of the AL function can be evaluated as follows: ∇ϕt (α) = −∇ fℓ∗ (−α) + Awt+1 (α),  (22)  where wt+1 (α) := proxφλη wt + ηt A⊤ α . [sent-229, score-0.543]
</p><p>34 IST uses a ﬁxed gradient-based lower-bound which is tightest at the current solution wt , whereas DAL uses a variational lower-bound, which can be adjusted to become tightest at the next solution wt+1 . [sent-235, score-0.575]
</p><p>35 The general connection between the augmented Lagrangian algorithm and the proximal minimization algorithm, and (asymptotic) convergence results can be found in Rockafellar (1976b) and Bertsekas (1982). [sent-236, score-0.297]
</p><p>36 1546  D UAL AUGMENTED -L AGRANGIAN C ONVERGES S UPER -L INEARLY  Algorithm 1 DAL algorithm for ℓ1 -regularization 1: Input: design matrix A, loss function f ℓ , regularization constant λ, sequence of proximity parameters ηt (t = 0, 1, 2, . [sent-243, score-0.136]
</p><p>37 3: repeat 4: Minimize the augmented Lagrangian function ϕt (α) (see Equation 10) with the gradient and Hessian given in Equations (24) and (25), respectively, using Newton’s method. [sent-248, score-0.155]
</p><p>38 2) ∇ϕt (αt ) ≤  γ proxℓ1 t (wt + ηt A⊤ αt ) − wt , λη ηt  where ϕt (α) is the derivative of the inner objective (24) and 1/γ is the Lipschitz constant of ∇ fℓ . [sent-250, score-0.589]
</p><p>39 Therefore, the AL function (10) in Tomioka and Sugiyama (2009) is derived from the proximal minimization framework (see Equation 20) in Section 3. [sent-268, score-0.147]
</p><p>40 Note that Equation (24) equals the general expression (22) from the proximal minimization framework. [sent-274, score-0.147]
</p><p>41 The proximity operator corresponding to the group-lasso regularizer φG is obtained as follows: λ proxG (y) := proxφG (y) = max( yg − λ, 0) λ λ  yg yg  ,  (27)  g∈G  where similarly to Equation (9), (yg )g∈G denotes an n-dimensional vector whose g component is given by yg . [sent-285, score-0.226]
</p><p>42 Moreover, analogous to update Equation (23) (see also Equation 10) in the ℓ1 -case, the update equations can be written as follows: wt+1 = proxG t wt + ηt A⊤ αt , λη where αt is the minimizer of the AL function ϕt (α) = fℓ∗ (−α) +  1 proxG t (wt + ηt A⊤ α) 2 . [sent-286, score-0.561]
</p><p>43 1), which is equivalent to the proximal minimization algorithm (11). [sent-323, score-0.147]
</p><p>44 be the sequence generated by the proximal minimization algorithm (Equation 11). [sent-343, score-0.147]
</p><p>45 Note that DAL algorithm (Equations 19 and 20) with exact inner minimization generates a sequence from the proximal minimization algorithm (Equation 11). [sent-347, score-0.23]
</p><p>46 2  Finally, taking the minimum of the right-hand side with respect to w∗ ∈ W ∗ and using the equivalence of proximal minimization (11) and DAL algorithm (19)-(20) (see Section 3. [sent-363, score-0.147]
</p><p>47 We can convert the above result into convergence in terms of the residual norm wt − w∗ by introducing an assumption that connects the residual function value to the residual norm. [sent-369, score-0.68]
</p><p>48 If the inner minimization is solved exactly, we have the following inequality: wt+1 −W ∗ + σηt wt+1 −W ∗  α−1  ≤ wt −W ∗ . [sent-380, score-0.626]
</p><p>49 Moreover, this implies that wt+1 −W ∗  1+(α−1)σηt 1+σηt  ≤  1 wt −W ∗ . [sent-381, score-0.543]
</p><p>50 1 + σηt  (42)  That is, wt converges to W ∗ super-linearly if α < 2 or α = 2 and ηt is increasing, in a global and non-asymptotic sense. [sent-382, score-0.543]
</p><p>51 (A4) The inner minimization (Equation 20) is solved to the following tolerance: γ wt+1 − wt , ηt  ∇ϕt (αt ) ≤  (44)  where γ is the constant in Equation (43). [sent-394, score-0.626]
</p><p>52 Under assumption (A1) in Theorem 3 and (A2)-(A4) in Lemma 4, we have wt+1 −W ∗  2  + 2σηt wt+1 −W ∗  α  ≤ wt −W ∗ 2 ,  where wt − W ∗ is the minimum distance between wt and W ∗ as in Theorem 3. [sent-409, score-1.629]
</p><p>53 Moreover, this implies that wt+1 −W ∗  1+ασηt 1+2σηt  ≤√  1 wt −W ∗ . [sent-410, score-0.543]
</p><p>54 1 + 2σηt  That is, wt converges to W ∗ super-linearly if α < 2 or α = 2 and ηt is increasing. [sent-411, score-0.543]
</p><p>55 1553  (46)  T OMIOKA , S UZUKI AND S UGIYAMA  ¯ ¯ Proof Let wt be the closest point in W ∗ from wt , that is, wt := argminw∗ ∈W ∗ wt − w∗ . [sent-412, score-2.172]
</p><p>56 Using ¯ Lemma 4 with w = wt and Assumption (A1), we have the ﬁrst part of the theorem as follows: wt −W ∗  2  ¯ = wt − wt  2  ¯ ≥ wt+1 − wt  ≥ wt+1 −W ∗  2  + 2σηt wt+1 −W ∗  2  + 2σηt wt+1 −W ∗  α α  ,  ¯ where we used the minimality of wt+1 − wt+1 in the second line. [sent-413, score-2.732]
</p><p>57 3 A Faster Rate √ The factor 1/ 1 + 2σηt obtained under the approximate minimization (A4) (see inequality (46) in Theorem 5) is larger than that obtained under the exact inner minimization (see inequality (42) in Theorem 3); that is, the statement in Theorem 5 is weaker than that in Theorem 3. [sent-417, score-0.14]
</p><p>58 Here we show that a better rate can also be obtained for approximate minimization if we perform √ the inner minimization to O( wt+1 − wt /ηt ) instead of O( wt+1 − wt / ηt ) in Assumption (A4). [sent-418, score-1.226]
</p><p>59 Under assumption (A1) in Theorem 3 with α = 2, and assumptions (A2) and (A3) in Lemma 4, for any ε < 1 such that δ := (1 − ε)/(σηt ) ≤ 3/4, if we solve the inner minimization to the following precision (A4′ )  ∇ϕt (αt ) ≤  γ(1 − ε)/σ t+1 w − wt , ηt  then we have wt+1 −W ∗ ≤  1 wt −W ∗ . [sent-423, score-1.169]
</p><p>60 In this case, DAL converges rapidly in terms of function value due to Theorem 2; however it does not necessarily converge in terms of the distance wt −W ∗ . [sent-443, score-0.543]
</p><p>61 In fact, they require that as the optimization proceeds, the solution becomes closer to the optimum w∗ in the sense of the distance wt −W ∗ in Kort and Bertsekas (1976) and β in Rockafellar (1976b). [sent-466, score-0.543]
</p><p>62 In the columns, six methods, namely, projected gradient (PG), interior point (IP), iterative reweighted shrinkage (IRS), orthantwise limited-memory quasi Newton (OWLQN), accelerated gradient (AG), and dual augmented Lagrangian (DAL), are categorized into four groups discussed in the text. [sent-529, score-0.225]
</p><p>63 2 Iterative Proximation Yet another approach is to deal with the nondifferentiable regularization through the proximity operation. [sent-543, score-0.148]
</p><p>64 For example, the IST approach (also known as the forward-backward splitting Lions and Mercier, 1979; Combettes and Wajs, 2005; Duchi and Singer, 2009) can be described as follows: yt := wt − ηt A⊤ ∇ fℓ (Awt ),  λt := ληt . [sent-553, score-0.543]
</p><p>65 What we need to do at every iteration is only to compute the gradient at the current point, take a gradient step, and then perform the proximal operation (Equation 49). [sent-554, score-0.165]
</p><p>66 Since the proximal gradient step (13) reduces to an ordinary gradient step when φλ = 0, the basic idea behind IST is to keep the non-smooth term φλ as a part of the proximity step (see Lan, 2010). [sent-557, score-0.225]
</p><p>67 IST approach maintains sparsity of wt throughout the optimization, which results in signiﬁcant reduction of computational cost; this is an advantage of iterative proximation methods compared to interior-point methods (e. [sent-562, score-0.591]
</p><p>68 The conjugate of the loss function can be obtained as follows: m  ∗ fLR (−α) = ∑ ℓ∗ (−αi , yi ), LR i=1  where ℓ∗ (−αi , yi ) = LR  αi yi log(αi yi ) + (1 − αi yi ) log(1 − αi yi ) +∞ 1560  (if 0 ≤ αi yi ≤ 1), (otherwise). [sent-610, score-0.166]
</p><p>69 The inner minimization is terminated by the criterion (44) with γ = 4, because the Hessian of the loss function (50) is uniformly bounded by 1/4 (see Table 1). [sent-643, score-0.137]
</p><p>70 As an augmented Lagrangian algorithm, DAL-B solves the following dual problem: maximize m  ∗ − fLR (−α) − δ∞ (v), λ  subject to  A⊤ α = v,  (53)  1 α = 0. [sent-663, score-0.156]
</p><p>71 The parameter σ in Equation (41) was estimated by taking the minimum of ( f (wt ) − f (w∗ ))/ wt − w∗ 2 along the trajectory obtained by the above minimization and multiplying the minimum value by a safety factor of 0. [sent-757, score-0.6]
</p><p>72 In order to estimate the residual norm wt − w∗ , we use bounds (42) and (46) with α = 2 and the initial residual w0 − w∗ . [sent-759, score-0.621]
</p><p>73 In the top left panel of Figure 2, we can see that the convergence in terms of the norm of the residual vector wt − w∗ happens indeed rapidly as predicted by the theorems in Section 5. [sent-763, score-0.602]
</p><p>74 In Figure 5, plotted are the number of PCG steps for inner minimization and the CPU time spent by DAL algorithm with the conservative setting (η0 = 0. [sent-860, score-0.141]
</p><p>75 01/λ) and aggressive (η0 = 1/λ) choice of proximity ¯ parameter η0 for λ = 0. [sent-885, score-0.135]
</p><p>76 Generalizing the recent result from Beck and Teboulle (2009), we improved the convergence results on super-linear convergence of augmented Lagrangian methods in literature for the case of sparse estimation. [sent-1063, score-0.19]
</p><p>77 Currently, our results does not apply to primal-based augmented Lagrangian method discussed in Goldstein and Osher (2009) for loss functions that are not strongly convex (e. [sent-1071, score-0.179]
</p><p>78 Future work includes the extension of our analysis to the primal-based augmented Lagrangian methods (Yin et al. [sent-1092, score-0.13]
</p><p>79 , 2009), application of approximate augmented Lagrangian methods and operator splitting methods to machine learning problems (see Zhang et al. [sent-1094, score-0.13]
</p><p>80 The proximal operator with respect to f is deﬁned as follows: prox f (z) = argmin f (x) + x∈Rn  1573  1 x−z 2  2  . [sent-1108, score-0.264]
</p><p>81 Similarly we deﬁne the proximal operator with respect to the convex conjugate function f ∗ of f as follows: prox f ∗ (z) = argmin f ∗ (x) + x∈Rn  1 x−z 2  2  . [sent-1110, score-0.318]
</p><p>82 Lemma 8 (Moreau’s decomposition) The proximation of a vector z ∈ Rn with respect to a convex function f and that with respect to its convex conjugate f ∗ is complementary in the following sense: prox f (z) + prox f ∗ (z) = z. [sent-1112, score-0.459]
</p><p>83 2  Proof Let x = prox f (z) and y = prox f ∗ (z) as in the proof of Lemma 8. [sent-1132, score-0.348]
</p><p>84 Lemma 10 (Derivative of Moreau’s envelope) Moreau’s envelope function F in Equation (64) is continuously differentiable (even if f is not differentiable) and the derivative can be written as follows: ∇F(z) = prox f ∗ (z). [sent-1139, score-0.239]
</p><p>85 We ﬁrst show that for all z, z′ ∈ Rn F(z′ ) ≥ F(z) + (z′ − z)⊤ y,  (65)  where y = prox f ∗ (z), which implies that y = prox f ∗ (z) ∈ ∂F(z). [sent-1144, score-0.348]
</p><p>86 Finally omitting the constant term wt 2 /(2ηt ) in the last line and reversing the sign we obtain Equation (20). [sent-1157, score-0.543]
</p><p>87 Let wt be the closest point from wt in W ∗ , namely wt := argminw∗ ∈W ∗ wt − w∗ . [sent-1162, score-2.172]
</p><p>88 ¯ ¯ Note that by setting µ = 1 in (⋆) and wt = wt+1 , we recover Lemma 1. [sent-1166, score-0.543]
</p><p>89 Now using assumption (A1), we obtain the following expression: 2µ − µ2  wt+1 −W ∗  2  + 2µσηt wt+1 −W ∗  α  ≤ wt −W ∗ 2 . [sent-1167, score-0.543]
</p><p>90 Maximizing the left hand side with respect to µ, we have µ = 1 + σηt wt+1 −W ∗ ingly, 1 + σηt wt+1 −W ∗  α−2 2  wt+1 −W ∗  2  α−2  and accord-  ≤ wt −W ∗ 2 . [sent-1168, score-0.543]
</p><p>91 Taking the square-root of both sides we obtain wt+1 −W ∗ + σηt wt+1 −W ∗  α−1  ≤ wt −W ∗ . [sent-1169, score-0.543]
</p><p>92 1 from Rockafellar (1970), we have  wt+1 − wt from Assumption (A4). [sent-1176, score-0.543]
</p><p>93 Combining (A), (B), and (C), we have the following expression: ηt ( f (w) − f (wt+1 )) ≥ wt − wt+1 , w − wt+1 − 1579  ηt t δ 2γ  2  . [sent-1187, score-0.543]
</p><p>94 Using assumption (A4), we obtain ηt ( f (w) − f (wt+1 )) ≥ wt − w + w − wt+1 , w − wt+1 − =  1 w − wt+1 2  2  −  1 w − wt 2  2  1 t w − wt+1 2  2  ,  which completes the proof. [sent-1189, score-1.086]
</p><p>95 2  Multiplying both sides with µ/ wt+1 −W ∗ 2 , we have 1−δ 2 1 − δ wt −W ∗ 2 ≥− µ + 2 wt+1 −W ∗ 2 2  1− 1580  δ δ wt −W ∗ 2 + σηt − 2 2 wt+1 −W ∗ 2  µ. [sent-1195, score-1.086]
</p><p>96 If the sign is negative or zero, we have δ wt −W ∗ 2 δ ≤ 0, 1 − + σηt − 2 2 wt+1 −W ∗ 2 which implies wt+1 −W ∗  2  ≤  δ wt −W ∗ 2 . [sent-1197, score-1.086]
</p><p>97 2 − δ + 2σηt  (71)  Since δ ≤ 3/4, the factor in front of wt −W ∗ 2 in the right-hand side is clearly smaller than one. [sent-1198, score-0.543]
</p><p>98 σηt 1 + εσηt 1 + εσηt 1 + εσηt  Plugging the above upper bound into inequality (71), we have wt+1 −W ∗  2  δ wt −W ∗ 2 1 + 2σηt 1 ≤ wt −W ∗ (1 + εσηt )(1 + 2σηt )  ≤  2  ≤  1 wt −W ∗ 2 , (1 + εσηt )2  which completes the proof for the ﬁrst case. [sent-1201, score-1.629]
</p><p>99 If on the other hand, the term inside the curly brackets is positive in Equation (70), maximizing the right-hand side of Equation (70) with respect to µ gives the following expression: δ δ (1 − δ)rt ≥ 1 − + σηt − rt2 , 2 2 where we deﬁned rt := wt − W ∗ / wt+1 − W ∗ . [sent-1202, score-0.543]
</p><p>100 The augmented lagrange multiplier method for exact recovery of a corrupted low-rank matrices. [sent-1529, score-0.152]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dal', 0.583), ('wt', 0.543), ('prox', 0.174), ('owlqn', 0.142), ('augmented', 0.13), ('sparsa', 0.128), ('omioka', 0.118), ('uper', 0.118), ('uzuki', 0.118), ('agrangian', 0.114), ('inearly', 0.114), ('onverges', 0.114), ('rockafellar', 0.113), ('tomioka', 0.101), ('logreg', 0.1), ('irs', 0.095), ('ugiyama', 0.091), ('proximal', 0.09), ('ist', 0.089), ('fista', 0.087), ('proximity', 0.085), ('ual', 0.08), ('al', 0.069), ('awt', 0.066), ('envelope', 0.065), ('cpu', 0.059), ('figueiredo', 0.058), ('moreau', 0.058), ('minimization', 0.057), ('lagrangian', 0.052), ('kort', 0.052), ('aggressive', 0.05), ('koh', 0.05), ('rdg', 0.048), ('pcg', 0.044), ('wright', 0.044), ('aw', 0.044), ('sugiyama', 0.04), ('residual', 0.039), ('wajs', 0.038), ('minimizers', 0.034), ('beck', 0.034), ('bertsekas', 0.034), ('teboulle', 0.033), ('nondifferentiable', 0.033), ('terminated', 0.033), ('qg', 0.033), ('equation', 0.03), ('conservative', 0.03), ('regularization', 0.03), ('proximation', 0.029), ('wg', 0.029), ('regularizer', 0.029), ('yik', 0.028), ('yg', 0.028), ('convex', 0.028), ('combettes', 0.028), ('spent', 0.028), ('inner', 0.026), ('conjugate', 0.026), ('dual', 0.026), ('rn', 0.026), ('daubechies', 0.025), ('operation', 0.025), ('gradient', 0.025), ('flr', 0.024), ('nondifferentiability', 0.024), ('yic', 0.024), ('convexity', 0.023), ('rm', 0.022), ('subgradient', 0.022), ('multiplier', 0.022), ('gao', 0.022), ('nocedal', 0.022), ('unregularized', 0.022), ('loss', 0.021), ('logistic', 0.021), ('convergence', 0.02), ('newton', 0.02), ('nowak', 0.02), ('tolerance', 0.02), ('sparse', 0.02), ('objective', 0.02), ('iterative', 0.019), ('hessian', 0.019), ('proxc', 0.019), ('violt', 0.019), ('poorly', 0.019), ('stopping', 0.018), ('ip', 0.018), ('proxg', 0.018), ('minimizer', 0.018), ('increased', 0.017), ('theorem', 0.017), ('yi', 0.017), ('tokyo', 0.017), ('primal', 0.016), ('tightest', 0.016), ('osher', 0.016), ('dorothea', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="89-tfidf-1" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>Author: Ryota Tomioka, Taiji Suzuki, Masashi Sugiyama</p><p>Abstract: We analyze the convergence behaviour of a recently proposed algorithm for regularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is based on a new interpretation of DAL as a proximal minimization algorithm. We theoretically show under some conditions that DAL converges super-linearly in a non-asymptotic and global sense. Due to a special modelling of sparse estimation problems in the context of machine learning, the assumptions we make are milder and more natural than those made in conventional analysis of augmented Lagrangian algorithms. In addition, the new interpretation enables us to generalize DAL to wide varieties of sparse estimation problems. We experimentally conﬁrm our analysis in a large scale ℓ1 -regularized logistic regression problem and extensively compare the efﬁciency of DAL algorithm to previously proposed algorithms on both synthetic and benchmark data sets. Keywords: dual augmented Lagrangian, proximal minimization, global convergence, sparse estimation, convex optimization</p><p>2 0.43503231 <a title="89-tfidf-2" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>Author: Shai Shalev-Shwartz, Ambuj Tewari</p><p>Abstract: We describe and analyze two stochastic methods for ℓ1 regularized loss minimization problems, such as the Lasso. The ﬁrst method updates the weight of a single feature at each iteration while the second method updates the entire weight vector but only uses a single training example at each iteration. In both methods, the choice of feature or example is uniformly at random. Our theoretical runtime analysis suggests that the stochastic methods should outperform state-of-the-art deterministic approaches, including their deterministic counterparts, when the size of the problem is large. We demonstrate the advantage of stochastic methods by experimenting with synthetic and natural data sets.1 Keywords: L1 regularization, optimization, coordinate descent, mirror descent, sparsity</p><p>3 0.18159679 <a title="89-tfidf-3" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>Author: Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</p><p>Abstract: Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed. Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation. To solve these problems, we introduce a new framework, semiparametric statistical inference, to model-free policy evaluation. This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a uniﬁed way in terms of estimating functions. Furthermore, based on this framework, we derive an optimal estimating function with the minimum asymptotic variance and propose batch and online learning algorithms which achieve the optimality. Keywords: reinforcement learning, model-free policy evaluation, TD learning, semiparametirc model, estimating function</p><p>4 0.13232724 <a title="89-tfidf-4" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>Author: Gilles Meyer, Silvère Bonnabel, Rodolphe Sepulchre</p><p>Abstract: The paper addresses the problem of learning a regression model parameterized by a ﬁxed-rank positive semideﬁnite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of ﬁxedrank positive semideﬁnite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semideﬁnite matrix. Good performance is observed on classical benchmarks. Keywords: linear regression, positive semideﬁnite matrices, low-rank approximation, Riemannian geometry, gradient-based learning</p><p>5 0.086360477 <a title="89-tfidf-5" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>Author: Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski, Francis Bach</p><p>Abstract: Sparse coding consists in representing signals as sparse linear combinations of atoms selected from a dictionary. We consider an extension of this framework where the atoms are further assumed to be embedded in a tree. This is achieved using a recently introduced tree-structured sparse regularization norm, which has proven useful in several applications. This norm leads to regularized problems that are difﬁcult to optimize, and in this paper, we propose efﬁcient algorithms for solving them. More precisely, we show that the proximal operator associated with this norm is computable exactly via a dual approach that can be viewed as the composition of elementary proximal operators. Our procedure has a complexity linear, or close to linear, in the number of atoms, and allows the use of accelerated gradient techniques to solve the tree-structured sparse approximation problem at the same computational cost as traditional ones using the ℓ1 -norm. Our method is efﬁcient and scales gracefully to millions of variables, which we illustrate in two types of applications: ﬁrst, we consider ﬁxed hierarchical dictionaries of wavelets to denoise natural images. Then, we apply our optimization tools in the context of dictionary learning, where learned dictionary elements naturally self-organize in a prespeciﬁed arborescent structure, leading to better performance in reconstruction of natural image patches. When applied to text documents, our method learns hierarchies of topics, thus providing a competitive alternative to probabilistic topic models. Keywords: Proximal methods, dictionary learning, structured sparsity, matrix factorization</p><p>6 0.083153389 <a title="89-tfidf-6" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>7 0.081103228 <a title="89-tfidf-7" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>8 0.075541474 <a title="89-tfidf-8" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>9 0.055324234 <a title="89-tfidf-9" href="./jmlr-2011-Laplacian_Support_Vector_Machines__Trained_in_the_Primal.html">51 jmlr-2011-Laplacian Support Vector Machines  Trained in the Primal</a></p>
<p>10 0.033726644 <a title="89-tfidf-10" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>11 0.031586323 <a title="89-tfidf-11" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>12 0.028899506 <a title="89-tfidf-12" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>13 0.028790424 <a title="89-tfidf-13" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>14 0.028179182 <a title="89-tfidf-14" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>15 0.026936116 <a title="89-tfidf-15" href="./jmlr-2011-Unsupervised_Supervised_Learning_II%3A_Margin-Based_Classification_Without_Labels.html">100 jmlr-2011-Unsupervised Supervised Learning II: Margin-Based Classification Without Labels</a></p>
<p>16 0.026665175 <a title="89-tfidf-16" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>17 0.024125118 <a title="89-tfidf-17" href="./jmlr-2011-lp-Norm_Multiple_Kernel_Learning.html">105 jmlr-2011-lp-Norm Multiple Kernel Learning</a></p>
<p>18 0.023601785 <a title="89-tfidf-18" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>19 0.023578851 <a title="89-tfidf-19" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>20 0.022110859 <a title="89-tfidf-20" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.188), (1, 0.447), (2, 0.072), (3, -0.078), (4, -0.289), (5, -0.369), (6, -0.222), (7, 0.011), (8, 0.106), (9, 0.097), (10, -0.037), (11, 0.007), (12, -0.035), (13, 0.063), (14, 0.053), (15, -0.025), (16, -0.054), (17, 0.042), (18, -0.003), (19, 0.064), (20, 0.037), (21, -0.002), (22, -0.006), (23, 0.038), (24, -0.035), (25, 0.101), (26, -0.007), (27, 0.027), (28, 0.002), (29, 0.001), (30, 0.055), (31, -0.028), (32, -0.022), (33, 0.05), (34, 0.046), (35, 0.013), (36, -0.045), (37, 0.032), (38, 0.038), (39, 0.016), (40, -0.014), (41, 0.005), (42, 0.02), (43, -0.038), (44, 0.02), (45, 0.035), (46, -0.023), (47, -0.038), (48, -0.029), (49, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97678608 <a title="89-lsi-1" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>Author: Ryota Tomioka, Taiji Suzuki, Masashi Sugiyama</p><p>Abstract: We analyze the convergence behaviour of a recently proposed algorithm for regularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is based on a new interpretation of DAL as a proximal minimization algorithm. We theoretically show under some conditions that DAL converges super-linearly in a non-asymptotic and global sense. Due to a special modelling of sparse estimation problems in the context of machine learning, the assumptions we make are milder and more natural than those made in conventional analysis of augmented Lagrangian algorithms. In addition, the new interpretation enables us to generalize DAL to wide varieties of sparse estimation problems. We experimentally conﬁrm our analysis in a large scale ℓ1 -regularized logistic regression problem and extensively compare the efﬁciency of DAL algorithm to previously proposed algorithms on both synthetic and benchmark data sets. Keywords: dual augmented Lagrangian, proximal minimization, global convergence, sparse estimation, convex optimization</p><p>2 0.95647424 <a title="89-lsi-2" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>Author: Shai Shalev-Shwartz, Ambuj Tewari</p><p>Abstract: We describe and analyze two stochastic methods for ℓ1 regularized loss minimization problems, such as the Lasso. The ﬁrst method updates the weight of a single feature at each iteration while the second method updates the entire weight vector but only uses a single training example at each iteration. In both methods, the choice of feature or example is uniformly at random. Our theoretical runtime analysis suggests that the stochastic methods should outperform state-of-the-art deterministic approaches, including their deterministic counterparts, when the size of the problem is large. We demonstrate the advantage of stochastic methods by experimenting with synthetic and natural data sets.1 Keywords: L1 regularization, optimization, coordinate descent, mirror descent, sparsity</p><p>3 0.67380667 <a title="89-lsi-3" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>Author: Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</p><p>Abstract: Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed. Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation. To solve these problems, we introduce a new framework, semiparametric statistical inference, to model-free policy evaluation. This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a uniﬁed way in terms of estimating functions. Furthermore, based on this framework, we derive an optimal estimating function with the minimum asymptotic variance and propose batch and online learning algorithms which achieve the optimality. Keywords: reinforcement learning, model-free policy evaluation, TD learning, semiparametirc model, estimating function</p><p>4 0.54176956 <a title="89-lsi-4" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>Author: Gilles Meyer, Silvère Bonnabel, Rodolphe Sepulchre</p><p>Abstract: The paper addresses the problem of learning a regression model parameterized by a ﬁxed-rank positive semideﬁnite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of ﬁxedrank positive semideﬁnite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semideﬁnite matrix. Good performance is observed on classical benchmarks. Keywords: linear regression, positive semideﬁnite matrices, low-rank approximation, Riemannian geometry, gradient-based learning</p><p>5 0.3855347 <a title="89-lsi-5" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>Author: Nicolò Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</p><p>Abstract: We investigate three variants of budgeted learning, a setting in which the learner is allowed to access a limited number of attributes from training or test examples. In the “local budget” setting, where a constraint is imposed on the number of available attributes per training example, we design and analyze an efﬁcient algorithm for learning linear predictors that actively samples the attributes of each training instance. Our analysis bounds the number of additional examples sufﬁcient to compensate for the lack of full information on the training set. This result is complemented by a general lower bound for the easier “global budget” setting, where it is only the overall number of accessible training attributes that is being constrained. In the third, “prediction on a budget” setting, when the constraint is on the number of available attributes per test example, we show that there are cases in which there exists a linear predictor with zero error but it is statistically impossible to achieve arbitrary accuracy without full information on test examples. Finally, we run simple experiments on a digit recognition problem that reveal that our algorithm has a good performance against both partial information and full information baselines. Keywords: budgeted learning, statistical learning, linear predictors, learning with partial information, learning theory</p><p>6 0.36472356 <a title="89-lsi-6" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>7 0.26110339 <a title="89-lsi-7" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>8 0.23128515 <a title="89-lsi-8" href="./jmlr-2011-Laplacian_Support_Vector_Machines__Trained_in_the_Primal.html">51 jmlr-2011-Laplacian Support Vector Machines  Trained in the Primal</a></p>
<p>9 0.22970371 <a title="89-lsi-9" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>10 0.1367936 <a title="89-lsi-10" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>11 0.12887102 <a title="89-lsi-11" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>12 0.12832657 <a title="89-lsi-12" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>13 0.12714955 <a title="89-lsi-13" href="./jmlr-2011-Unsupervised_Supervised_Learning_II%3A_Margin-Based_Classification_Without_Labels.html">100 jmlr-2011-Unsupervised Supervised Learning II: Margin-Based Classification Without Labels</a></p>
<p>14 0.11773428 <a title="89-lsi-14" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>15 0.11736624 <a title="89-lsi-15" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>16 0.11440334 <a title="89-lsi-16" href="./jmlr-2011-On_Equivalence_Relationships_Between_Classification_and_Ranking_Algorithms.html">71 jmlr-2011-On Equivalence Relationships Between Classification and Ranking Algorithms</a></p>
<p>17 0.11400702 <a title="89-lsi-17" href="./jmlr-2011-Robust_Approximate_Bilinear_Programming_for_Value_Function_Approximation.html">81 jmlr-2011-Robust Approximate Bilinear Programming for Value Function Approximation</a></p>
<p>18 0.10875487 <a title="89-lsi-18" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>19 0.10551067 <a title="89-lsi-19" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>20 0.10411565 <a title="89-lsi-20" href="./jmlr-2011-Learning_from_Partial_Labels.html">58 jmlr-2011-Learning from Partial Labels</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.033), (9, 0.09), (10, 0.037), (24, 0.024), (27, 0.372), (31, 0.062), (32, 0.027), (41, 0.026), (60, 0.014), (70, 0.015), (71, 0.014), (73, 0.023), (78, 0.134), (90, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70986682 <a title="89-lda-1" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>Author: Ryota Tomioka, Taiji Suzuki, Masashi Sugiyama</p><p>Abstract: We analyze the convergence behaviour of a recently proposed algorithm for regularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is based on a new interpretation of DAL as a proximal minimization algorithm. We theoretically show under some conditions that DAL converges super-linearly in a non-asymptotic and global sense. Due to a special modelling of sparse estimation problems in the context of machine learning, the assumptions we make are milder and more natural than those made in conventional analysis of augmented Lagrangian algorithms. In addition, the new interpretation enables us to generalize DAL to wide varieties of sparse estimation problems. We experimentally conﬁrm our analysis in a large scale ℓ1 -regularized logistic regression problem and extensively compare the efﬁciency of DAL algorithm to previously proposed algorithms on both synthetic and benchmark data sets. Keywords: dual augmented Lagrangian, proximal minimization, global convergence, sparse estimation, convex optimization</p><p>2 0.40524328 <a title="89-lda-2" href="./jmlr-2011-lp-Norm_Multiple_Kernel_Learning.html">105 jmlr-2011-lp-Norm Multiple Kernel Learning</a></p>
<p>Author: Marius Kloft, Ulf Brefeld, Sören Sonnenburg, Alexander Zien</p><p>Abstract: Learning linear combinations of multiple kernels is an appealing strategy when the right choice of features is unknown. Previous approaches to multiple kernel learning (MKL) promote sparse kernel combinations to support interpretability and scalability. Unfortunately, this ℓ1 -norm MKL is rarely observed to outperform trivial baselines in practical applications. To allow for robust kernel mixtures that generalize well, we extend MKL to arbitrary norms. We devise new insights on the connection between several existing MKL formulations and develop two efﬁcient interleaved optimization strategies for arbitrary norms, that is ℓ p -norms with p ≥ 1. This interleaved optimization is much faster than the commonly used wrapper approaches, as demonstrated on several data sets. A theoretical analysis and an experiment on controlled artiﬁcial data shed light on the appropriateness of sparse, non-sparse and ℓ∞ -norm MKL in various scenarios. Importantly, empirical applications of ℓ p -norm MKL to three real-world problems from computational biology show that non-sparse MKL achieves accuracies that surpass the state-of-the-art. Data sets, source code to reproduce the experiments, implementations of the algorithms, and further information are available at http://doc.ml.tu-berlin.de/nonsparse_mkl/. Keywords: multiple kernel learning, learning kernels, non-sparse, support vector machine, convex conjugate, block coordinate descent, large scale optimization, bioinformatics, generalization bounds, Rademacher complexity ∗. Also at Machine Learning Group, Technische Universit¨ t Berlin, 10587 Berlin, Germany. a †. Parts of this work were done while SS was at the Friedrich Miescher Laboratory, Max Planck Society, 72076 T¨ bingen, Germany. u ‡. Most contributions by AZ were done at the Fraunhofer Institute FIRST, 12489 Berlin, Germany. c 2011 Marius Kloft, Ulf Brefeld, S¨ ren Sonnenburg and Alexander Zien. o K LOFT, B REFELD , S ONNENBURG AND Z IEN</p><p>3 0.40481928 <a title="89-lda-3" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>Author: Julien Mairal, Rodolphe Jenatton, Guillaume Obozinski, Francis Bach</p><p>Abstract: We consider a class of learning problems regularized by a structured sparsity-inducing norm deﬁned as the sum of ℓ2 - or ℓ∞ -norms over groups of variables. Whereas much effort has been put in developing fast optimization techniques when the groups are disjoint or embedded in a hierarchy, we address here the case of general overlapping groups. To this end, we present two different strategies: On the one hand, we show that the proximal operator associated with a sum of ℓ∞ norms can be computed exactly in polynomial time by solving a quadratic min-cost ﬂow problem, allowing the use of accelerated proximal gradient methods. On the other hand, we use proximal splitting techniques, and address an equivalent formulation with non-overlapping groups, but in higher dimension and with additional constraints. We propose efﬁcient and scalable algorithms exploiting these two strategies, which are signiﬁcantly faster than alternative approaches. We illustrate these methods with several problems such as CUR matrix factorization, multi-task learning of tree-structured dictionaries, background subtraction in video sequences, image denoising with wavelets, and topographic dictionary learning of natural image patches. Keywords: convex optimization, proximal methods, sparse coding, structured sparsity, matrix factorization, network ﬂow optimization, alternating direction method of multipliers</p><p>4 0.40200433 <a title="89-lda-4" href="./jmlr-2011-Differentially_Private_Empirical_Risk_Minimization.html">22 jmlr-2011-Differentially Private Empirical Risk Minimization</a></p>
<p>Author: Kamalika Chaudhuri, Claire Monteleoni, Anand D. Sarwate</p><p>Abstract: Privacy-preserving machine learning algorithms are crucial for the increasingly common setting in which personal data, such as medical or ﬁnancial records, are analyzed. We provide general techniques to produce privacy-preserving approximations of classiﬁers learned via (regularized) empirical risk minimization (ERM). These algorithms are private under the ε-differential privacy deﬁnition due to Dwork et al. (2006). First we apply the output perturbation ideas of Dwork et al. (2006), to ERM classiﬁcation. Then we propose a new method, objective perturbation, for privacy-preserving machine learning algorithm design. This method entails perturbing the objective function before optimizing over classiﬁers. If the loss and regularizer satisfy certain convexity and differentiability criteria, we prove theoretical results showing that our algorithms preserve privacy, and provide generalization bounds for linear and nonlinear kernels. We further present a privacypreserving technique for tuning the parameters in general machine learning algorithms, thereby providing end-to-end privacy guarantees for the training process. We apply these results to produce privacy-preserving analogues of regularized logistic regression and support vector machines. We obtain encouraging results from evaluating their performance on real demographic and benchmark data sets. Our results show that both theoretically and empirically, objective perturbation is superior to the previous state-of-the-art, output perturbation, in managing the inherent tradeoff between privacy and learning performance. Keywords: privacy, classiﬁcation, optimization, empirical risk minimization, support vector machines, logistic regression</p><p>5 0.39961824 <a title="89-lda-5" href="./jmlr-2011-Group_Lasso_Estimation_of_High-dimensional_Covariance_Matrices.html">37 jmlr-2011-Group Lasso Estimation of High-dimensional Covariance Matrices</a></p>
<p>Author: Jérémie Bigot, Rolando J. Biscay, Jean-Michel Loubes, Lillian Muñiz-Alvarez</p><p>Abstract: In this paper, we consider the Group Lasso estimator of the covariance matrix of a stochastic process corrupted by an additive noise. We propose to estimate the covariance matrix in a highdimensional setting under the assumption that the process has a sparse representation in a large dictionary of basis functions. Using a matrix regression model, we propose a new methodology for high-dimensional covariance matrix estimation based on empirical contrast regularization by a group Lasso penalty. Using such a penalty, the method selects a sparse set of basis functions in the dictionary used to approximate the process, leading to an approximation of the covariance matrix into a low dimensional space. Consistency of the estimator is studied in Frobenius and operator norms and an application to sparse PCA is proposed. Keywords: group Lasso, ℓ1 penalty, high-dimensional covariance estimation, basis expansion, sparsity, oracle inequality, sparse PCA</p><p>6 0.3993926 <a title="89-lda-6" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>7 0.3992348 <a title="89-lda-7" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>8 0.3986659 <a title="89-lda-8" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>9 0.39714763 <a title="89-lda-9" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>10 0.3954905 <a title="89-lda-10" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>11 0.39049071 <a title="89-lda-11" href="./jmlr-2011-On_Equivalence_Relationships_Between_Classification_and_Ranking_Algorithms.html">71 jmlr-2011-On Equivalence Relationships Between Classification and Ranking Algorithms</a></p>
<p>12 0.38921416 <a title="89-lda-12" href="./jmlr-2011-Robust_Approximate_Bilinear_Programming_for_Value_Function_Approximation.html">81 jmlr-2011-Robust Approximate Bilinear Programming for Value Function Approximation</a></p>
<p>13 0.38820764 <a title="89-lda-13" href="./jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">40 jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>14 0.38538903 <a title="89-lda-14" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>15 0.38417992 <a title="89-lda-15" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>16 0.3830747 <a title="89-lda-16" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>17 0.38282526 <a title="89-lda-17" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>18 0.38095248 <a title="89-lda-18" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>19 0.38045681 <a title="89-lda-19" href="./jmlr-2011-High-dimensional_Covariance_Estimation_Based_On_Gaussian_Graphical_Models.html">39 jmlr-2011-High-dimensional Covariance Estimation Based On Gaussian Graphical Models</a></p>
<p>20 0.37889099 <a title="89-lda-20" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
