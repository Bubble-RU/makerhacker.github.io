<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-73" href="#">jmlr2011-73</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</h1>
<br/><p>Source: <a title="jmlr-2011-73-pdf" href="http://jmlr.org/papers/volume12/vyugin11a/vyugin11a.pdf">pdf</a></p><p>Author: Vladimir V. V'yugin</p><p>Abstract: In this paper the sequential prediction problem with expert advice is considered for the case where losses of experts suffered at each step cannot be bounded in advance. We present some modiﬁcation of Kalai and Vempala algorithm of following the perturbed leader where weights depend on past losses of the experts. New notions of a volume and a scaled ﬂuctuation of a game are introduced. We present a probabilistic algorithm protected from unrestrictedly large one-step losses. This algorithm has the optimal performance in the case when the scaled ﬂuctuations of one-step losses of experts of the pool tend to zero. Keywords: prediction with expert advice, follow the perturbed leader, unbounded losses, adaptive learning rate, expected bounds, Hannan consistency, online sequential prediction</p><p>Reference: <a title="jmlr-2011-73-reference" href="../jmlr2011_reference/jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 19 Moscow GSP-4, 127994, Russia  Editor: Manfred Warmuth  Abstract In this paper the sequential prediction problem with expert advice is considered for the case where losses of experts suffered at each step cannot be bounded in advance. [sent-4, score-0.7]
</p><p>2 We present some modiﬁcation of Kalai and Vempala algorithm of following the perturbed leader where weights depend on past losses of the experts. [sent-5, score-0.441]
</p><p>3 This algorithm has the optimal performance in the case when the scaled ﬂuctuations of one-step losses of experts of the pool tend to zero. [sent-8, score-0.514]
</p><p>4 Keywords: prediction with expert advice, follow the perturbed leader, unbounded losses, adaptive learning rate, expected bounds, Hannan consistency, online sequential prediction  1. [sent-9, score-0.279]
</p><p>5 Arbitrary losses are less common, and, as a rule, they are supposed to be bounded in advance (see well known Hedge Algorithm of Freund and Schapire 1997, Normal Hedge of Chaudhuri et al. [sent-14, score-0.277]
</p><p>6 N receive results of their actions in form of their losses sti —arbitrary real numbers. [sent-31, score-0.557]
</p><p>7 i i At the beginning of the step t Learner, observing cumulating losses si 1:t−1 = s1 + . [sent-32, score-0.388]
</p><p>8 At the end of step t Learner receives the same loss sti as Expert i at step t and suffers Learner’s cumulative loss s1:t = s1:t−1 + sti . [sent-39, score-0.619]
</p><p>9 In the traditional framework, we suppose that one-step losses of all experts are bounded, for example, 0 ≤ sti ≤ 1 for all i and t. [sent-40, score-0.746]
</p><p>10 Well known simple example of a game with two experts shows that Learner can perform much worse than each expert: let the current losses of two experts on steps t = 0, 1, . [sent-41, score-0.879]
</p><p>11 When the experts one-step losses are bounded, this problem has been solved using randomization of the experts cumulative losses. [sent-47, score-0.76]
</p><p>12 The FPL algorithm outputs prediction of an expert i which minimizes 1 i si 1:t−1 − ξ , ε where ξi , i = 1, . [sent-51, score-0.255]
</p><p>13 Also, FPL algorithm is usually considered for bounded one-step losses: 0 ≤ sti ≤ 1 for all i and t. [sent-65, score-0.255]
</p><p>14 ,N  Most papers on prediction with expert advice either consider bounded losses or assume the existence of a speciﬁc loss function (see Lugosi and Cesa-Bianchi 2006). [sent-70, score-0.513]
</p><p>15 The setting allowing unbounded one-step losses do not have wide coverage in literature; we can only refer reader to Allenberg et al. [sent-73, score-0.344]
</p><p>16 Poland and Hutter (2005) have studied the games where one-step losses of all experts at each step t are bounded from above by an increasing sequence Bt given in advance. [sent-76, score-0.51]
</p><p>17 (2006) have considered polynomially bounded one-step losses for a modiﬁed version of the Littlestone and Warmuth (1994) algorithm under partial monitoring. [sent-79, score-0.277]
</p><p>18 In full infor√ 1 mation case, their algorithm has the expected regret 2 N ln N(T + 1) 2 (1+a+β) in the case where one-step losses of all experts i = 1, 2, . [sent-80, score-0.657]
</p><p>19 t=1  These bounds were improved using cumulative variances of losses (under distributions used in the Weighted Majority algorithm). [sent-87, score-0.332]
</p><p>20 In this paper we present a sufﬁcient condition for the FPL algorithm to be asymptotically consistent in case where losses are unbounded. [sent-90, score-0.357]
</p><p>21 We present some modiﬁcation of Kalai and Vempala (2003) algorithm of following the perturbed leader (FPL) for the case of unrestrictedly large one-step expert losses sti not bounded in advance: sti ∈ (−∞, +∞). [sent-92, score-1.114]
</p><p>22 This algorithm uses adaptive weights depending on past cumulative losses of the experts. [sent-93, score-0.332]
</p><p>23 A motivating example, where losses of the experts cannot be bounded in advance, is given in Section 5. [sent-94, score-0.491]
</p><p>24 We introduce new notions of the volume of a game t  vt = v0 + ∑ maxi |sij | and the scaled ﬂuctuation of the game ﬂuc(t) = ∆vt /vt , where ∆vt = vt − vt−1 j=1  and v0 is a nonnegative constant. [sent-97, score-1.481]
</p><p>25 We show in Theorem 2 that the algorithm of following the perturbed leader with adaptive weights constructed in Section 3 is asymptotically consistent in the mean in the case where vt → ∞ and ∆vt = o(vt ) as t → ∞ with a computable bound. [sent-98, score-0.808]
</p><p>26 In case where all losses are nonnegative: sti ∈ [0, +∞), we obtain the regret T  2 (2 + ε)(1 + ln N) ∑ (γ(t))1/2 ∆vt . [sent-100, score-0.698]
</p><p>27 t=1  243  V’ YUGIN  In particular, this algorithm is asymptotically consistent (in the mean) in a modiﬁed sense lim sup T →∞  1 E(s1:T − min si ) ≤ 0, 1:T i=1,. [sent-101, score-0.257]
</p><p>28 In particular, Corollary 8 of Theorem 2 says that our algorithm is asymptotically consistent (in the modiﬁed sense) in the case when one-step losses of all experts at each step t are bounded by t a , where a is a positive real number. [sent-111, score-0.571]
</p><p>29 We prove this result under an extra assumption that the volume of the game grows slowly, lim inf vt /t a+δ > 0, where δ > 0 is arbitrary. [sent-112, score-0.752]
</p><p>30 In Section 5 we consider an application of our algorithm for constructing an arbitrage strategy in some game of buying and selling shares of some stock on ﬁnancial market. [sent-114, score-0.361]
</p><p>31 Games of Prediction with Expert Advice with Unbounded One-step Losses We consider a game of prediction with expert advice with arbitrary unbounded one-step losses. [sent-120, score-0.45]
</p><p>32 (2007) we call a game with such losses “signed game” and call these losses “signed losses”. [sent-122, score-0.728]
</p><p>33 At each step t of the game, all N experts receive one-step losses sti ∈ (−∞, +∞), i = 1, . [sent-123, score-0.771]
</p><p>34 N, and the cumulative loss of the ith expert after step t is equal to i si = si 1:t 1:t−1 + st . [sent-126, score-0.599]
</p><p>35 A probabilistic learning algorithm of choosing an expert outputs at any step t the probabilities P{It = i} of following the ith expert given the cumulative losses si 1:t−1 of the experts i = 1, . [sent-127, score-0.945]
</p><p>36 N, are 1:T the cumulative losses of the experts algorithms and E is the mathematical expectation (with respect 1. [sent-137, score-0.546]
</p><p>37 T Given past cumulative losses of the experts si 1:t−1 , i = 1, . [sent-143, score-0.657]
</p><p>38 Receive the one-step losses at step t of the expert sti and suffer one-step loss st = sti of the master algorithm. [sent-147, score-1.136]
</p><p>39 In the case of bounded one-step expert losses, sti ∈ [0, 1], and a convex loss function, the well√ known learning algorithms have expected regret O( T log N) (see Lugosi and Cesa-Bianchi 2006). [sent-152, score-0.501]
</p><p>40 N T  lim sup T →∞  (2)  A probabilistic learning algorithm is called Hannan consistent if lim sup T →∞  1 T  s1:T − min si 1:T i=1,. [sent-157, score-0.254]
</p><p>41 Notice that when 0 ≤ sti ≤ 1 all expert algorithms have total loss ≤ T on ﬁrst T steps. [sent-162, score-0.426]
</p><p>42 Deﬁne the volume of a game at step t t  vt = v0 + ∑ max |sij |, j=1  i  where v0 is a nonnegative constant. [sent-166, score-0.755]
</p><p>43 A probabilistic learning algorithm is called asymptotically consistent in the mean (in the modiﬁed sense) in a game with N experts if lim sup T →∞  1 E(s1:T − min si ) ≤ 0. [sent-168, score-0.645]
</p><p>44 A game is called non-degenerate if vt → ∞ as t → ∞. [sent-177, score-0.703]
</p><p>45 The number ﬂuc(t) =  maxi |sti | ∆vt = , vt vt  is called scaled ﬂuctuation of the game at the step t. [sent-179, score-1.255]
</p><p>46 Proposition 1 For any probabilistic algorithm of choosing an expert and for any ε such that 0 < ε < 1 two experts exist such that vt → ∞ as t → ∞ and ﬂuc(t) ≥ 1 − ε, 1 1 E(s1:t − min si ) ≥ (1 − ε) 1:t i=1,2 vt 2 for all t. [sent-183, score-1.548]
</p><p>47 Given a probabilistic algorithm of choosing an expert and ε such that 0 < ε < 1, deﬁne recursively one-step losses st1 and st2 of expert 1 and expert 2 at any step t = 1, 2, . [sent-185, score-0.709]
</p><p>48 By s1 and s2 denote the cumulative losses of these experts incurred at steps ≤ t, let vt be the 1:t 1:t corresponding volume, where t = 1, 2, . [sent-189, score-1.075]
</p><p>49 2 Let st be one-step loss of the master algorithm and s1:t be its cumulative loss at step t ≥ 1. [sent-195, score-0.287]
</p><p>50 Also, since vt = vt−1 + Mt = (1 + 4/ε)vt−1 and min si ≤ vt−1 , the normalized expected 1:t i  regret of the master algorithm is bounded from below  2/ε − 1 1 1 E(s1:t − min si ) ≥ ≥ (1 − ε). [sent-197, score-0.895]
</p><p>51 Deﬁne   a(1+ln N) ln 2(e4/a −1) 1  and (5) αt = 1 − 2 ln γ(t) µt = a(γ(t))αt =  2a(e4/a − 1) (γ(t))1/2 (1 + ln N)  (6)  for all t, where e = 2. [sent-206, score-0.273]
</p><p>52 By deﬁnition vt ≥ vt−1 and µt ≤ µt−1 for t = 1, 2, . [sent-215, score-0.529]
</p><p>53 t=1  The following theorem shows that if the game is non-degenerate and ∆vt = o(vt ) as t → ∞ with a computable bound then the FPL-algorithm with variable learning rate (7) is asymptotically consistent. [sent-233, score-0.257]
</p><p>54 T Choose an expert with the minimal perturbed cumulated loss on steps < t It = argmini=1,2,. [sent-243, score-0.279]
</p><p>55 εt  Receive one-step losses sti for experts i = 1, . [sent-247, score-0.746]
</p><p>56 , N, deﬁne εt+1 by (7), and vt = vt−1 + max sti . [sent-250, score-0.784]
</p><p>57 Then for any ε > 0 the expected cumulated loss of the FPL algorithm PROT with variable learning rate (7), where a parameter a > 0 depends on ε, is bounded: T  E(s1:T ) ≤ min si + 2 (8 + ε)(1 + ln N) ∑ (γ(t))1/2 ∆vt 1:T i  (9)  t=1  for all t. [sent-253, score-0.29]
</p><p>58 3 In case of nonnegative unbounded losses sti ∈ [0, +∞) we have a bound T  E(s1:T ) ≤ min si + 2 (2 + ε)(1 + ln N) ∑ (γ(t))1/2 ∆vt . [sent-254, score-0.85]
</p><p>59 Then the algorithm PROT is asymptotically consistent in the mean lim sup T →∞  1 E(s1:T − min si ) ≤ 0. [sent-256, score-0.257]
</p><p>60 The expected one-step and cumulated losses of the FPL and IFPL algorithms at steps t and T are denoted lt = E(stIt ) and rt = E(stJt ), 3. [sent-269, score-0.352]
</p><p>61 In case of bounded losses when ∆vt = 1 we have vt = t and γ(t) = 1/t. [sent-270, score-0.806]
</p><p>62 T Deﬁne the learning rate εt′ =  1 , where µt = a(γ(t))αt , µt vt  (12)  where vt is the volume of the game at step t and αt is deﬁned by (5). [sent-276, score-1.256]
</p><p>63 Choose an expert with the minimal perturbed cumulated loss on steps ≤ t Jt = argmini=1,2,. [sent-277, score-0.279]
</p><p>64 1:t εt t  Lemma 3 The cumulated expected losses of the FPL and IFPL algorithms with learning rates deﬁned by (7) and (12) satisfy the inequality T  l1:T ≤ r1:T + 2(e4/a − 1) ∑ (γ(t))1−αt ∆vt t=1  for all T , where αt is deﬁned by (5). [sent-284, score-0.342]
</p><p>65 In case of nonnegative losses we need not to do this. [sent-295, score-0.305]
</p><p>66 We have used in transition from (20) to (21) the equality vt − vt−1 = ∆vt and the inequality j |st | ≤ ∆vt for all j and t. [sent-300, score-0.554]
</p><p>67 Therefore, we obtain  ≤ exp  4 ∆vt µt vt  P{It = j|ξi = ci , i = j} ≤ P{Jt = j|ξi = ci , i = j} ≤  ≤ exp{(4/a)(γ(t))1−αt }P{Jt = j|ξi = ci , i = j}. [sent-304, score-0.67]
</p><p>68 Lemma 4 The expected cumulative loss of the IFPL algorithm with the learning rate (12) is bounded : T  r1:T ≤ min si + a(1 + ln N) ∑ (γ(t))αt ∆vt 1:T i  (28)  t=1  for all T , where αt is deﬁned by (5). [sent-323, score-0.305]
</p><p>69 stN ) be a vector of one-step losses and s1:t = (s1 , . [sent-329, score-0.277]
</p><p>70 sN ) be a 1:t 1:t vector of cumulative losses of the experts algorithms. [sent-332, score-0.546]
</p><p>71 Recall that εt′ = 1/(µt vt ), µt ≤ µt−1 for all t, and v0 = 0, ε′ = ∞. [sent-337, score-0.529]
</p><p>72 Consider the vector of one-step losses st = st −ξ t for the moment. [sent-342, score-0.579]
</p><p>73 1 1 ′ − ε′ εt t−1  s ∑ M(˜1:t ) · ξ  =  =  s = ∑ (µt vt − µt−1 vt−1 )M(˜1:t ) · ξ . [sent-360, score-0.529]
</p><p>74 i  (34)  i=1  ∞  Since for any non-negative random variable η, E(η) = P{η ≥ y}dy, by (34) we have 0  E(max ξi − ln N) = i  ∞  P{max ξi − ln N ≥ y}dy ≤  =  i  0  ≤  ∞  0  N exp{−y − ln N}dy = 1. [sent-367, score-0.273]
</p><p>75 By (33) the expectation of (32) has the upper bound T  T  t=1  t=1  s ∑ E(M(˜1:t ) · ξ)(µt vt − µt−1 vt−1 ) ≤ (1 + ln N) ∑ µt ∆vt . [sent-369, score-0.62]
</p><p>76 ε′ T  (35)  V’ YUGIN  Combining the bounds (30)-(32) and (35), we obtain T  s ∑ M(˜1:t ) · st  r1:T = E  ≤  t=1  T  ≤ min si − µT vT + (1 + ln N) ∑ µt ∆vt ≤ 1:T i  t=1  T  ≤ min si + (1 + ln N) ∑ µt ∆vt . [sent-371, score-0.597]
</p><p>77 The inequality (13) of Lemma 3 and the inequality (28) of Lemma 4 imply the inequality E(s1:T ) ≤ min si + 1:T i  T  + ∑ (2(e4/a − 1)(γ(t))1−αt + a(1 + ln N)(γ(t))αt )∆vt . [sent-375, score-0.298]
</p><p>78 T We have ∑t=1 ∆vt = vT for all T , vt → ∞ and γ(t) → 0 as t → ∞. [sent-381, score-0.529]
</p><p>79 In case where all losses are nonnegative: sti ∈ [0, +∞), the inequality (24) can be replaced on j  j  2 s1:t−1 − s1:t−1 ≤1 vt−1  for all t and i. [sent-384, score-0.557]
</p><p>80 Put Xt = (st − E(st ))/2, where st is the loss of the FPL algorithm PROT at step t, and at = vt for all t. [sent-429, score-0.707]
</p><p>81 In case of bounded experts losses sti ∈ [0, 1], assume that an auxiliary “bad” expert i0 exists for which sti0 = 1 for all t. [sent-438, score-0.89]
</p><p>82 Then ∆vt = 1 and the volume becomes time: vt = t for all t (we put v0 = 0). [sent-439, score-0.553]
</p><p>83 N, and vt ≥ t α+δ for all t, where α and δ are positive real numbers. [sent-448, score-0.529]
</p><p>84 The FPL algorithm PROT is asymptotically consistent in the mean if vt ≥ β(t) for all t, where β(t) is an arbitrary positive unbounded non-decreasing computable function (we can get γ(t) = 1/β(t) in this case). [sent-455, score-0.711]
</p><p>85 Therefore, losses of experts and regret depend now from random perturbations: ¯ sti = sti (ξ1:t−1 ), i = 1, . [sent-485, score-1.076]
</p><p>86 We assume in Theorem 2 that in the game of prediction with expert advice regulated by the FPL-protocol the event ﬂuc(t) ≤ γ(t) for all t holds almost surely. [sent-493, score-0.403]
</p><p>87 An Example: Zero-sum Experts In this section we present an example of a game, where losses of experts cannot be bounded in advance. [sent-498, score-0.491]
</p><p>88 Two experts will represent two concurrent methods of buying and selling shares of this stock. [sent-502, score-0.281]
</p><p>89 The game between an investor and the market looks as follows: the investor can use the long and short selling. [sent-513, score-0.297]
</p><p>90 At the end of trading period the market discloses the price St+1 of the stock, and the investor incur his current income or loss st = Ct ∆St at the period t. [sent-515, score-0.343]
</p><p>91 The one-step gains st1 and st2 = −st1 are unbounded and can be positive or negative: sti ∈ (−∞, +∞). [sent-523, score-0.355]
</p><p>92 7 We interpret the expected one-step gain E(st ) gain as the weighted average of one-step gains of experts strategies. [sent-533, score-0.285]
</p><p>93 Conclusion In this paper we try to extend methods of the theory of prediction with expert advice for the case when experts one-step gains cannot be bounded in advance. [sent-567, score-0.456]
</p><p>94 New notion of volume of a game and scaled ﬂuctuation of a game are introduced in this paper. [sent-570, score-0.395]
</p><p>95 Our bounds for the regret are deﬁned in terms of a volume of the game and our learning algorithm is asymptotically consistent in the mean and almost surely. [sent-577, score-0.373]
</p><p>96 Algorithms for unbounded losses have appeared in the literature, but none of the papers deal with FPL and “fast-growing” losses. [sent-578, score-0.344]
</p><p>97 Looking closely at the requirements of this paper, the quantity ﬂuc(t) has to decrease to 0, which to imply that the rate of growth of the losses has to be slower than exponential. [sent-579, score-0.277]
</p><p>98 A motivating example of a game with two zero-sum experts from Section 5 shows some practical signiﬁcance of these problems. [sent-582, score-0.388]
</p><p>99 2009) for the case of unbounded losses in terms of the volume and scaled ﬂuctuation of a game. [sent-593, score-0.391]
</p><p>100 i  262  L EARNING IN C ASE OF U NBOUNDED L OSSES U SING FPL A LGORITHM  PROT which is asymptotically consistent in the mean for any game satisfying lim sup t→∞  ﬂuc(t) <∞ γi (t)  (49)  for some i. [sent-606, score-0.299]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('vt', 0.529), ('fpl', 0.425), ('losses', 0.277), ('sti', 0.255), ('experts', 0.214), ('prot', 0.198), ('game', 0.174), ('st', 0.151), ('expert', 0.144), ('yugin', 0.142), ('hannan', 0.119), ('si', 0.111), ('nbounded', 0.104), ('osses', 0.104), ('leader', 0.096), ('ifpl', 0.094), ('ln', 0.091), ('uc', 0.081), ('stock', 0.08), ('poland', 0.08), ('ase', 0.079), ('regret', 0.075), ('perturbed', 0.068), ('unbounded', 0.067), ('vempala', 0.065), ('advice', 0.065), ('sing', 0.06), ('hutter', 0.058), ('uctuation', 0.056), ('kalai', 0.056), ('cumulative', 0.055), ('xt', 0.055), ('asymptotically', 0.048), ('allenberg', 0.047), ('dtol', 0.047), ('investor', 0.047), ('stit', 0.047), ('ci', 0.047), ('jt', 0.044), ('lgorithm', 0.042), ('mt', 0.041), ('learner', 0.041), ('cumulated', 0.04), ('argmini', 0.038), ('rub', 0.038), ('stjt', 0.038), ('perturbations', 0.037), ('computable', 0.035), ('rt', 0.035), ('gains', 0.033), ('hedge', 0.032), ('consistent', 0.032), ('market', 0.029), ('shares', 0.029), ('russian', 0.028), ('volatilities', 0.028), ('nonnegative', 0.028), ('strategies', 0.027), ('master', 0.027), ('loss', 0.027), ('income', 0.027), ('earning', 0.026), ('inequality', 0.025), ('receive', 0.025), ('lim', 0.025), ('endfor', 0.024), ('volatility', 0.024), ('vovk', 0.024), ('macro', 0.024), ('micro', 0.024), ('volume', 0.024), ('convergent', 0.024), ('scaled', 0.023), ('period', 0.022), ('evidently', 0.022), ('brownian', 0.022), ('consistency', 0.022), ('min', 0.021), ('lugosi', 0.021), ('strategy', 0.021), ('sup', 0.02), ('almost', 0.02), ('lemma', 0.019), ('games', 0.019), ('schapire', 0.019), ('arbitrage', 0.019), ('buying', 0.019), ('defensive', 0.019), ('derandomize', 0.019), ('earns', 0.019), ('finam', 0.019), ('gazprom', 0.019), ('protected', 0.019), ('selling', 0.019), ('sij', 0.019), ('technics', 0.019), ('unrestrictedly', 0.019), ('gain', 0.019), ('warmuth', 0.019), ('price', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="73-tfidf-1" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>Author: Vladimir V. V'yugin</p><p>Abstract: In this paper the sequential prediction problem with expert advice is considered for the case where losses of experts suffered at each step cannot be bounded in advance. We present some modiﬁcation of Kalai and Vempala algorithm of following the perturbed leader where weights depend on past losses of the experts. New notions of a volume and a scaled ﬂuctuation of a game are introduced. We present a probabilistic algorithm protected from unrestrictedly large one-step losses. This algorithm has the optimal performance in the case when the scaled ﬂuctuations of one-step losses of experts of the pool tend to zero. Keywords: prediction with expert advice, follow the perturbed leader, unbounded losses, adaptive learning rate, expected bounds, Hannan consistency, online sequential prediction</p><p>2 0.079262808 <a title="73-tfidf-2" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>Author: Mark D. Reid, Robert C. Williamson</p><p>Abstract: We unify f -divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives which all are related to cost-sensitive binary classiﬁcation. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f -divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants. Keywords: classiﬁcation, loss functions, divergence, statistical information, regret bounds</p><p>3 0.074410856 <a title="73-tfidf-3" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>Author: Nicolò Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</p><p>Abstract: We investigate three variants of budgeted learning, a setting in which the learner is allowed to access a limited number of attributes from training or test examples. In the “local budget” setting, where a constraint is imposed on the number of available attributes per training example, we design and analyze an efﬁcient algorithm for learning linear predictors that actively samples the attributes of each training instance. Our analysis bounds the number of additional examples sufﬁcient to compensate for the lack of full information on the training set. This result is complemented by a general lower bound for the easier “global budget” setting, where it is only the overall number of accessible training attributes that is being constrained. In the third, “prediction on a budget” setting, when the constraint is on the number of available attributes per test example, we show that there are cases in which there exists a linear predictor with zero error but it is statistically impossible to achieve arbitrary accuracy without full information on test examples. Finally, we run simple experiments on a digit recognition problem that reveal that our algorithm has a good performance against both partial information and full information baselines. Keywords: budgeted learning, statistical learning, linear predictors, learning with partial information, learning theory</p><p>4 0.0738234 <a title="73-tfidf-4" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: The online multi-armed bandit problem and its generalizations are repeated decision making problems, where the goal is to select one of several possible decisions in every round, and incur a cost associated with the decision, in such a way that the total cost incurred over all iterations is close to the cost of the best ﬁxed decision in hindsight. The difference in these costs is known as the regret of the algorithm. The term bandit refers to the setting where one only obtains the cost of the decision used in a given iteration and no other information. A very general form of this problem is the non-stochastic bandit linear optimization problem, where the set of decisions is a convex set in some√ Euclidean space, and the cost functions are linear. ˜ Only recently an efﬁcient algorithm attaining O( T ) regret was discovered in this setting. In this paper we propose a new algorithm for the bandit linear optimization problem which √ ˜ obtains a tighter regret bound of O( Q), where Q is the total variation in the cost functions. This regret bound, previously conjectured to hold in the full information case, shows that it is possible to incur much less regret in a slowly changing environment even in the bandit setting. Our algorithm is efﬁcient and applies several new ideas to bandit optimization such as reservoir sampling. Keywords: multi-armed bandit, regret minimization, online learning</p><p>5 0.071414687 <a title="73-tfidf-5" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>Author: John Duchi, Elad Hazan, Yoram Singer</p><p>Abstract: We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms. Keywords: subgradient methods, adaptivity, online learning, stochastic convex optimization</p><p>6 0.067324914 <a title="73-tfidf-6" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>7 0.063109636 <a title="73-tfidf-7" href="./jmlr-2011-Discriminative_Learning_of_Bayesian_Networks_via_Factorized_Conditional_Log-Likelihood.html">25 jmlr-2011-Discriminative Learning of Bayesian Networks via Factorized Conditional Log-Likelihood</a></p>
<p>8 0.062939882 <a title="73-tfidf-8" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>9 0.053503793 <a title="73-tfidf-9" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>10 0.052442446 <a title="73-tfidf-10" href="./jmlr-2011-Inverse_Reinforcement_Learning_in_Partially_Observable_Environments.html">47 jmlr-2011-Inverse Reinforcement Learning in Partially Observable Environments</a></p>
<p>11 0.044557583 <a title="73-tfidf-11" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>12 0.040951792 <a title="73-tfidf-12" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>13 0.04092475 <a title="73-tfidf-13" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>14 0.04037042 <a title="73-tfidf-14" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>15 0.036462348 <a title="73-tfidf-15" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>16 0.036317065 <a title="73-tfidf-16" href="./jmlr-2011-A_Bayesian_Approximation_Method_for_Online_Ranking.html">2 jmlr-2011-A Bayesian Approximation Method for Online Ranking</a></p>
<p>17 0.034722358 <a title="73-tfidf-17" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>18 0.03292555 <a title="73-tfidf-18" href="./jmlr-2011-Cumulative_Distribution_Networks_and_the_Derivative-sum-product_Algorithm%3A_Models_and_Inference_for_Cumulative_Distribution_Functions_on_Graphs.html">21 jmlr-2011-Cumulative Distribution Networks and the Derivative-sum-product Algorithm: Models and Inference for Cumulative Distribution Functions on Graphs</a></p>
<p>19 0.028284067 <a title="73-tfidf-19" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>20 0.026722347 <a title="73-tfidf-20" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, 0.175), (2, -0.085), (3, 0.028), (4, 0.066), (5, 0.086), (6, 0.046), (7, -0.013), (8, -0.027), (9, 0.027), (10, 0.005), (11, -0.142), (12, -0.013), (13, 0.088), (14, -0.027), (15, -0.04), (16, -0.114), (17, 0.068), (18, 0.059), (19, -0.248), (20, 0.041), (21, -0.004), (22, 0.111), (23, -0.051), (24, -0.008), (25, 0.066), (26, 0.143), (27, -0.035), (28, -0.056), (29, -0.01), (30, -0.15), (31, 0.181), (32, -0.087), (33, -0.157), (34, 0.012), (35, 0.017), (36, 0.004), (37, 0.024), (38, -0.226), (39, -0.151), (40, -0.085), (41, -0.037), (42, -0.078), (43, 0.157), (44, 0.217), (45, -0.13), (46, 0.117), (47, 0.047), (48, 0.057), (49, -0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97566158 <a title="73-lsi-1" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>Author: Vladimir V. V'yugin</p><p>Abstract: In this paper the sequential prediction problem with expert advice is considered for the case where losses of experts suffered at each step cannot be bounded in advance. We present some modiﬁcation of Kalai and Vempala algorithm of following the perturbed leader where weights depend on past losses of the experts. New notions of a volume and a scaled ﬂuctuation of a game are introduced. We present a probabilistic algorithm protected from unrestrictedly large one-step losses. This algorithm has the optimal performance in the case when the scaled ﬂuctuations of one-step losses of experts of the pool tend to zero. Keywords: prediction with expert advice, follow the perturbed leader, unbounded losses, adaptive learning rate, expected bounds, Hannan consistency, online sequential prediction</p><p>2 0.45982656 <a title="73-lsi-2" href="./jmlr-2011-Discriminative_Learning_of_Bayesian_Networks_via_Factorized_Conditional_Log-Likelihood.html">25 jmlr-2011-Discriminative Learning of Bayesian Networks via Factorized Conditional Log-Likelihood</a></p>
<p>Author: Alexandra M. Carvalho, Teemu Roos, Arlindo L. Oliveira, Petri Myllymäki</p><p>Abstract: We propose an efﬁcient and parameter-free scoring criterion, the factorized conditional log-likelihood (ˆ fCLL), for learning Bayesian network classiﬁers. The proposed score is an approximation of the conditional log-likelihood criterion. The approximation is devised in order to guarantee decomposability over the network structure, as well as efﬁcient estimation of the optimal parameters, achieving the same time and space complexity as the traditional log-likelihood scoring criterion. The resulting criterion has an information-theoretic interpretation based on interaction information, which exhibits its discriminative nature. To evaluate the performance of the proposed criterion, we present an empirical comparison with state-of-the-art classiﬁers. Results on a large suite of benchmark data sets from the UCI repository show that ˆ fCLL-trained classiﬁers achieve at least as good accuracy as the best compared classiﬁers, using signiﬁcantly less computational resources. Keywords: Bayesian networks, discriminative learning, conditional log-likelihood, scoring criterion, classiﬁcation, approximation c 2011 Alexandra M. Carvalho, Teemu Roos, Arlindo L. Oliveira and Petri Myllym¨ ki. a ¨ C ARVALHO , ROOS , O LIVEIRA AND M YLLYM AKI</p><p>3 0.44695851 <a title="73-lsi-3" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>Author: Mark D. Reid, Robert C. Williamson</p><p>Abstract: We unify f -divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives which all are related to cost-sensitive binary classiﬁcation. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f -divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants. Keywords: classiﬁcation, loss functions, divergence, statistical information, regret bounds</p><p>4 0.31772161 <a title="73-lsi-4" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>Author: Nicolò Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</p><p>Abstract: We investigate three variants of budgeted learning, a setting in which the learner is allowed to access a limited number of attributes from training or test examples. In the “local budget” setting, where a constraint is imposed on the number of available attributes per training example, we design and analyze an efﬁcient algorithm for learning linear predictors that actively samples the attributes of each training instance. Our analysis bounds the number of additional examples sufﬁcient to compensate for the lack of full information on the training set. This result is complemented by a general lower bound for the easier “global budget” setting, where it is only the overall number of accessible training attributes that is being constrained. In the third, “prediction on a budget” setting, when the constraint is on the number of available attributes per test example, we show that there are cases in which there exists a linear predictor with zero error but it is statistically impossible to achieve arbitrary accuracy without full information on test examples. Finally, we run simple experiments on a digit recognition problem that reveal that our algorithm has a good performance against both partial information and full information baselines. Keywords: budgeted learning, statistical learning, linear predictors, learning with partial information, learning theory</p><p>5 0.30190849 <a title="73-lsi-5" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>Author: Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</p><p>Abstract: Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed. Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation. To solve these problems, we introduce a new framework, semiparametric statistical inference, to model-free policy evaluation. This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a uniﬁed way in terms of estimating functions. Furthermore, based on this framework, we derive an optimal estimating function with the minimum asymptotic variance and propose batch and online learning algorithms which achieve the optimality. Keywords: reinforcement learning, model-free policy evaluation, TD learning, semiparametirc model, estimating function</p><p>6 0.29105866 <a title="73-lsi-6" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>7 0.27760452 <a title="73-lsi-7" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>8 0.25868037 <a title="73-lsi-8" href="./jmlr-2011-A_Bayesian_Approximation_Method_for_Online_Ranking.html">2 jmlr-2011-A Bayesian Approximation Method for Online Ranking</a></p>
<p>9 0.24121894 <a title="73-lsi-9" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>10 0.20971796 <a title="73-lsi-10" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>11 0.20267999 <a title="73-lsi-11" href="./jmlr-2011-Anechoic_Blind_Source_Separation_Using_Wigner_Marginals.html">10 jmlr-2011-Anechoic Blind Source Separation Using Wigner Marginals</a></p>
<p>12 0.17677791 <a title="73-lsi-12" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>13 0.17505132 <a title="73-lsi-13" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>14 0.17344889 <a title="73-lsi-14" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>15 0.16712891 <a title="73-lsi-15" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>16 0.16597803 <a title="73-lsi-16" href="./jmlr-2011-Inverse_Reinforcement_Learning_in_Partially_Observable_Environments.html">47 jmlr-2011-Inverse Reinforcement Learning in Partially Observable Environments</a></p>
<p>17 0.1614913 <a title="73-lsi-17" href="./jmlr-2011-Learning_a_Robust_Relevance_Model_for_Search_Using_Kernel_Methods.html">57 jmlr-2011-Learning a Robust Relevance Model for Search Using Kernel Methods</a></p>
<p>18 0.15966652 <a title="73-lsi-18" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>19 0.15336038 <a title="73-lsi-19" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>20 0.14618845 <a title="73-lsi-20" href="./jmlr-2011-Parameter_Screening_and_Optimisation_for_ILP_using_Designed_Experiments.html">76 jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.492), (4, 0.033), (9, 0.015), (10, 0.015), (24, 0.042), (31, 0.061), (41, 0.048), (65, 0.02), (67, 0.026), (73, 0.02), (78, 0.075), (90, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81275064 <a title="73-lda-1" href="./jmlr-2011-Universality%2C_Characteristic_Kernels_and_RKHS_Embedding_of_Measures.html">98 jmlr-2011-Universality, Characteristic Kernels and RKHS Embedding of Measures</a></p>
<p>Author: Bharath K. Sriperumbudur, Kenji Fukumizu, Gert R.G. Lanckriet</p><p>Abstract: Over the last few years, two different notions of positive deﬁnite (pd) kernels—universal and characteristic—have been developing in parallel in machine learning: universal kernels are proposed in the context of achieving the Bayes risk by kernel-based classiﬁcation/regression algorithms while characteristic kernels are introduced in the context of distinguishing probability measures by embedding them into a reproducing kernel Hilbert space (RKHS). However, the relation between these two notions is not well understood. The main contribution of this paper is to clarify the relation between universal and characteristic kernels by presenting a unifying study relating them to RKHS embedding of measures, in addition to clarifying their relation to other common notions of strictly pd, conditionally strictly pd and integrally strictly pd kernels. For radial kernels on Rd , all these notions are shown to be equivalent. Keywords: kernel methods, characteristic kernels, Hilbert space embeddings, universal kernels, strictly positive deﬁnite kernels, integrally strictly positive deﬁnite kernels, conditionally strictly positive deﬁnite kernels, translation invariant kernels, radial kernels, binary classiﬁcation, homogeneity testing</p><p>same-paper 2 0.73655063 <a title="73-lda-2" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>Author: Vladimir V. V'yugin</p><p>Abstract: In this paper the sequential prediction problem with expert advice is considered for the case where losses of experts suffered at each step cannot be bounded in advance. We present some modiﬁcation of Kalai and Vempala algorithm of following the perturbed leader where weights depend on past losses of the experts. New notions of a volume and a scaled ﬂuctuation of a game are introduced. We present a probabilistic algorithm protected from unrestrictedly large one-step losses. This algorithm has the optimal performance in the case when the scaled ﬂuctuations of one-step losses of experts of the pool tend to zero. Keywords: prediction with expert advice, follow the perturbed leader, unbounded losses, adaptive learning rate, expected bounds, Hannan consistency, online sequential prediction</p><p>3 0.22678705 <a title="73-lda-3" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>Author: Nicolò Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</p><p>Abstract: We investigate three variants of budgeted learning, a setting in which the learner is allowed to access a limited number of attributes from training or test examples. In the “local budget” setting, where a constraint is imposed on the number of available attributes per training example, we design and analyze an efﬁcient algorithm for learning linear predictors that actively samples the attributes of each training instance. Our analysis bounds the number of additional examples sufﬁcient to compensate for the lack of full information on the training set. This result is complemented by a general lower bound for the easier “global budget” setting, where it is only the overall number of accessible training attributes that is being constrained. In the third, “prediction on a budget” setting, when the constraint is on the number of available attributes per test example, we show that there are cases in which there exists a linear predictor with zero error but it is statistically impossible to achieve arbitrary accuracy without full information on test examples. Finally, we run simple experiments on a digit recognition problem that reveal that our algorithm has a good performance against both partial information and full information baselines. Keywords: budgeted learning, statistical learning, linear predictors, learning with partial information, learning theory</p><p>4 0.2257002 <a title="73-lda-4" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>Author: Bruno Pelletier, Pierre Pudlo</p><p>Abstract: Following Hartigan (1975), a cluster is deﬁned as a connected component of the t-level set of the underlying density, that is, the set of points for which the density is greater than t. A clustering algorithm which combines a density estimate with spectral clustering techniques is proposed. Our algorithm is composed of two steps. First, a nonparametric density estimate is used to extract the data points for which the estimated density takes a value greater than t. Next, the extracted points are clustered based on the eigenvectors of a graph Laplacian matrix. Under mild assumptions, we prove the almost sure convergence in operator norm of the empirical graph Laplacian operator associated with the algorithm. Furthermore, we give the typical behavior of the representation of the data set into the feature space, which establishes the strong consistency of our proposed algorithm. Keywords: spectral clustering, graph, unsupervised classiﬁcation, level sets, connected components</p><p>5 0.22505213 <a title="73-lda-5" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>Author: Vanya Van Belle, Kristiaan Pelckmans, Johan A. K. Suykens, Sabine Van Huffel</p><p>Abstract: This paper studies the task of learning transformation models for ranking problems, ordinal regression and survival analysis. The present contribution describes a machine learning approach termed MINLIP . The key insight is to relate ranking criteria as the Area Under the Curve to monotone transformation functions. Consequently, the notion of a Lipschitz smoothness constant is found to be useful for complexity control for learning transformation models, much in a similar vein as the ’margin’ is for Support Vector Machines for classiﬁcation. The use of this model structure in the context of high dimensional data, as well as for estimating non-linear, and additive models based on primal-dual kernel machines, and for sparse models is indicated. Given n observations, the present method solves a quadratic program existing of O (n) constraints and O (n) unknowns, where most existing risk minimization approaches to ranking problems typically result in algorithms with O (n2 ) constraints or unknowns. We specify the MINLIP method for three different cases: the ﬁrst one concerns the preference learning problem. Secondly it is speciﬁed how to adapt the method to ordinal regression with a ﬁnite set of ordered outcomes. Finally, it is shown how the method can be used in the context of survival analysis where one models failure times, typically subject to censoring. The current approach is found to be particularly useful in this context as it can handle, in contrast with the standard statistical model for analyzing survival data, all types of censoring in a straightforward way, and because of the explicit relation with the Proportional Hazard and Accelerated Failure Time models. The advantage of the current method is illustrated on different benchmark data sets, as well as for estimating a model for cancer survival based on different micro-array and clinical data sets. Keywords: support vector machines, preference learning, ranking models, ordinal regression, survival analysis c</p><p>6 0.2226807 <a title="73-lda-6" href="./jmlr-2011-Dirichlet_Process_Mixtures_of_Generalized_Linear_Models.html">24 jmlr-2011-Dirichlet Process Mixtures of Generalized Linear Models</a></p>
<p>7 0.22107488 <a title="73-lda-7" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>8 0.22101918 <a title="73-lda-8" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>9 0.2204161 <a title="73-lda-9" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>10 0.21775508 <a title="73-lda-10" href="./jmlr-2011-Group_Lasso_Estimation_of_High-dimensional_Covariance_Matrices.html">37 jmlr-2011-Group Lasso Estimation of High-dimensional Covariance Matrices</a></p>
<p>11 0.21762532 <a title="73-lda-11" href="./jmlr-2011-Clustering_Algorithms_for_Chains.html">16 jmlr-2011-Clustering Algorithms for Chains</a></p>
<p>12 0.21748641 <a title="73-lda-12" href="./jmlr-2011-Learning_High-Dimensional_Markov_Forest_Distributions%3A_Analysis_of_Error_Rates.html">53 jmlr-2011-Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates</a></p>
<p>13 0.21640733 <a title="73-lda-13" href="./jmlr-2011-Robust_Approximate_Bilinear_Programming_for_Value_Function_Approximation.html">81 jmlr-2011-Robust Approximate Bilinear Programming for Value Function Approximation</a></p>
<p>14 0.21626532 <a title="73-lda-14" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>15 0.21611659 <a title="73-lda-15" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>16 0.21579871 <a title="73-lda-16" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>17 0.21578519 <a title="73-lda-17" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>18 0.2157248 <a title="73-lda-18" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>19 0.21520028 <a title="73-lda-19" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>20 0.21502955 <a title="73-lda-20" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
