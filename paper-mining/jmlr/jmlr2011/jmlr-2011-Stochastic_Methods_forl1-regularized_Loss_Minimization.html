<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-87" href="#">jmlr2011-87</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</h1>
<br/><p>Source: <a title="jmlr-2011-87-pdf" href="http://jmlr.org/papers/volume12/shalev-shwartz11a/shalev-shwartz11a.pdf">pdf</a></p><p>Author: Shai Shalev-Shwartz, Ambuj Tewari</p><p>Abstract: We describe and analyze two stochastic methods for ℓ1 regularized loss minimization problems, such as the Lasso. The ﬁrst method updates the weight of a single feature at each iteration while the second method updates the entire weight vector but only uses a single training example at each iteration. In both methods, the choice of feature or example is uniformly at random. Our theoretical runtime analysis suggests that the stochastic methods should outperform state-of-the-art deterministic approaches, including their deterministic counterparts, when the size of the problem is large. We demonstrate the advantage of stochastic methods by experimenting with synthetic and natural data sets.1 Keywords: L1 regularization, optimization, coordinate descent, mirror descent, sparsity</p><p>Reference: <a title="jmlr-2011-87-reference" href="../jmlr2011_reference/jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wt', 0.788), ('smida', 0.267), ('mag', 0.204), ('ewar', 0.149), ('runtim', 0.144), ('scd', 0.139), ('desc', 0.136), ('tochast', 0.136), ('hwartz', 0.127), ('runt', 0.122), ('inim', 0.114), ('oss', 0.105), ('mir', 0.1), ('ethod', 0.08), ('vt', 0.076), ('langford', 0.071), ('coordin', 0.069), ('stochast', 0.066), ('sgd', 0.064), ('rad', 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="87-tfidf-1" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>2 0.54203182 <a title="87-tfidf-2" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>3 0.2539084 <a title="87-tfidf-3" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>4 0.22292583 <a title="87-tfidf-4" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>5 0.14914742 <a title="87-tfidf-5" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>6 0.1238497 <a title="87-tfidf-6" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>7 0.058307566 <a title="87-tfidf-7" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>8 0.05636381 <a title="87-tfidf-8" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>9 0.048853543 <a title="87-tfidf-9" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>10 0.046497647 <a title="87-tfidf-10" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>11 0.044351533 <a title="87-tfidf-11" href="./jmlr-2011-On_Equivalence_Relationships_Between_Classification_and_Ranking_Algorithms.html">71 jmlr-2011-On Equivalence Relationships Between Classification and Ranking Algorithms</a></p>
<p>12 0.040452138 <a title="87-tfidf-12" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>13 0.037733555 <a title="87-tfidf-13" href="./jmlr-2011-Weisfeiler-Lehman_Graph_Kernels.html">103 jmlr-2011-Weisfeiler-Lehman Graph Kernels</a></p>
<p>14 0.033813097 <a title="87-tfidf-14" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>15 0.03318001 <a title="87-tfidf-15" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>16 0.030257929 <a title="87-tfidf-16" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>17 0.029629886 <a title="87-tfidf-17" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>18 0.029478485 <a title="87-tfidf-18" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>19 0.027601216 <a title="87-tfidf-19" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>20 0.027417542 <a title="87-tfidf-20" href="./jmlr-2011-Improved_Moves_for_Truncated_Convex_Models.html">41 jmlr-2011-Improved Moves for Truncated Convex Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.229), (1, -0.585), (2, -0.215), (3, 0.094), (4, -0.376), (5, 0.038), (6, 0.195), (7, 0.089), (8, -0.107), (9, 0.023), (10, 0.0), (11, 0.056), (12, 0.001), (13, 0.001), (14, 0.014), (15, -0.035), (16, -0.073), (17, 0.003), (18, -0.008), (19, 0.108), (20, -0.052), (21, -0.046), (22, -0.018), (23, 0.015), (24, 0.02), (25, 0.025), (26, 0.006), (27, 0.012), (28, 0.042), (29, 0.021), (30, -0.011), (31, 0.001), (32, 0.013), (33, -0.041), (34, -0.027), (35, -0.005), (36, 0.035), (37, -0.044), (38, 0.03), (39, -0.008), (40, 0.0), (41, 0.026), (42, -0.007), (43, -0.005), (44, -0.071), (45, -0.007), (46, -0.016), (47, -0.032), (48, 0.009), (49, -0.002)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98010123 <a title="87-lsi-1" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>2 0.94455349 <a title="87-lsi-2" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>3 0.69353092 <a title="87-lsi-3" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>4 0.5786534 <a title="87-lsi-4" href="./jmlr-2011-Regression_on_Fixed-Rank_Positive_Semidefinite_Matrices%3A_A_Riemannian_Approach.html">80 jmlr-2011-Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach</a></p>
<p>5 0.43194288 <a title="87-lsi-5" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>6 0.41649675 <a title="87-lsi-6" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>7 0.17008515 <a title="87-lsi-7" href="./jmlr-2011-On_Equivalence_Relationships_Between_Classification_and_Ranking_Algorithms.html">71 jmlr-2011-On Equivalence Relationships Between Classification and Ranking Algorithms</a></p>
<p>8 0.16353755 <a title="87-lsi-8" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>9 0.15587234 <a title="87-lsi-9" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>10 0.1550855 <a title="87-lsi-10" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>11 0.15136842 <a title="87-lsi-11" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>12 0.1380524 <a title="87-lsi-12" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>13 0.1339945 <a title="87-lsi-13" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>14 0.11542258 <a title="87-lsi-14" href="./jmlr-2011-Double_Updating_Online_Learning.html">28 jmlr-2011-Double Updating Online Learning</a></p>
<p>15 0.11139052 <a title="87-lsi-15" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>16 0.11110422 <a title="87-lsi-16" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>17 0.10905479 <a title="87-lsi-17" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>18 0.10272749 <a title="87-lsi-18" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>19 0.098481394 <a title="87-lsi-19" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>20 0.094041675 <a title="87-lsi-20" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.035), (8, 0.016), (11, 0.028), (17, 0.041), (24, 0.029), (31, 0.394), (37, 0.039), (39, 0.038), (50, 0.033), (67, 0.054), (84, 0.059), (86, 0.072), (90, 0.011), (96, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.63626122 <a title="87-lda-1" href="./jmlr-2011-Stochastic_Methods_forl1-regularized_Loss_Minimization.html">87 jmlr-2011-Stochastic Methods forl1-regularized Loss Minimization</a></p>
<p>2 0.30851328 <a title="87-lda-2" href="./jmlr-2011-Variable_Sparsity_Kernel_Learning.html">101 jmlr-2011-Variable Sparsity Kernel Learning</a></p>
<p>3 0.30435127 <a title="87-lda-3" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>4 0.30187958 <a title="87-lda-4" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>5 0.29995203 <a title="87-lda-5" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>6 0.29993272 <a title="87-lda-6" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>7 0.29797223 <a title="87-lda-7" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>8 0.29694396 <a title="87-lda-8" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>9 0.29447511 <a title="87-lda-9" href="./jmlr-2011-Semi-Supervised_Learning_with_Measure_Propagation.html">84 jmlr-2011-Semi-Supervised Learning with Measure Propagation</a></p>
<p>10 0.2924341 <a title="87-lda-10" href="./jmlr-2011-lp-Norm_Multiple_Kernel_Learning.html">105 jmlr-2011-lp-Norm Multiple Kernel Learning</a></p>
<p>11 0.29212236 <a title="87-lda-11" href="./jmlr-2011-Convex_and_Network_Flow_Optimization_for_Structured_Sparsity.html">20 jmlr-2011-Convex and Network Flow Optimization for Structured Sparsity</a></p>
<p>12 0.29088786 <a title="87-lda-12" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>13 0.29052001 <a title="87-lda-13" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>14 0.29008782 <a title="87-lda-14" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>15 0.2881909 <a title="87-lda-15" href="./jmlr-2011-Laplacian_Support_Vector_Machines__Trained_in_the_Primal.html">51 jmlr-2011-Laplacian Support Vector Machines  Trained in the Primal</a></p>
<p>16 0.28801107 <a title="87-lda-16" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>17 0.28626072 <a title="87-lda-17" href="./jmlr-2011-Logistic_Stick-Breaking_Process.html">61 jmlr-2011-Logistic Stick-Breaking Process</a></p>
<p>18 0.28497562 <a title="87-lda-18" href="./jmlr-2011-Kernel_Analysis_of_Deep_Networks.html">48 jmlr-2011-Kernel Analysis of Deep Networks</a></p>
<p>19 0.28474683 <a title="87-lda-19" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>20 0.28235519 <a title="87-lda-20" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
