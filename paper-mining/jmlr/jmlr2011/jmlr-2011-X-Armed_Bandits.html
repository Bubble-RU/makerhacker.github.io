<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>104 jmlr-2011-X-Armed Bandits</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-104" href="#">jmlr2011-104</a> knowledge-graph by maker-knowledge-mining</p><h1>104 jmlr-2011-X-Armed Bandits</h1>
<br/><p>Source: <a title="jmlr-2011-104-pdf" href="http://jmlr.org/papers/volume12/bubeck11a/bubeck11a.pdf">pdf</a></p><p>Author: Sébastien Bubeck, Rémi Munos, Gilles Stoltz, Csaba Szepesvári</p><p>Abstract: We consider a generalization of stochastic bandits where the set of arms, X , is allowed to be a generic measurable space and the mean-payoff function is “locally Lipschitz” with respect to a dissimilarity function that is known to the decision maker. Under this condition we construct an arm selection policy, called HOO (hierarchical optimistic optimization), with improved regret bounds compared to previous results for a large class of problems. In particular, our results imply that if X is the unit hypercube in a Euclidean space and the mean-payoff function has a ﬁnite number of global maxima around which the behavior of the function is locally continuous with a known √ smoothness degree, then the expected regret of HOO is bounded up to a logarithmic factor by n, that is, the rate of growth of the regret is independent of the dimension of the space. We also prove the minimax optimality of our algorithm when the dissimilarity is a metric. Our basic strategy has quadratic computational complexity as a function of the number of time steps and does not rely on the doubling trick. We also introduce a modiﬁed strategy, which relies on the doubling trick but runs in linearithmic time. Both results are improvements with respect to previous approaches. Keywords: bandits with inﬁnitely many arms, optimistic online optimization, regret bounds, minimax rates</p><p>Reference: <a title="jmlr-2011-104-reference" href="../jmlr2011_reference/jmlr-2011-X-Armed_Bandits_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hoo', 0.555), ('bandit', 0.336), ('regret', 0.302), ('ln', 0.245), ('nod', 0.194), ('arm', 0.191), ('dissimil', 0.161), ('toltz', 0.16), ('ubeck', 0.16), ('uno', 0.16), ('zepesv', 0.16), ('kleinberg', 0.155), ('round', 0.138), ('ih', 0.117), ('bh', 0.1), ('zoom', 0.09), ('reward', 0.089), ('dep', 0.083), ('payoff', 0.077), ('rmed', 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="104-tfidf-1" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>2 0.2159854 <a title="104-tfidf-2" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>3 0.12624109 <a title="104-tfidf-3" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>4 0.11727047 <a title="104-tfidf-4" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>5 0.11050801 <a title="104-tfidf-5" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>6 0.093122192 <a title="104-tfidf-6" href="./jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">54 jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<p>7 0.090718366 <a title="104-tfidf-7" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>8 0.085470587 <a title="104-tfidf-8" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>9 0.080985531 <a title="104-tfidf-9" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>10 0.076034546 <a title="104-tfidf-10" href="./jmlr-2011-Inverse_Reinforcement_Learning_in_Partially_Observable_Environments.html">47 jmlr-2011-Inverse Reinforcement Learning in Partially Observable Environments</a></p>
<p>11 0.067783445 <a title="104-tfidf-11" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>12 0.067698464 <a title="104-tfidf-12" href="./jmlr-2011-Adaptive_Exact_Inference_in_Graphical_Models.html">7 jmlr-2011-Adaptive Exact Inference in Graphical Models</a></p>
<p>13 0.067357354 <a title="104-tfidf-13" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>14 0.066624679 <a title="104-tfidf-14" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>15 0.053311437 <a title="104-tfidf-15" href="./jmlr-2011-Cumulative_Distribution_Networks_and_the_Derivative-sum-product_Algorithm%3A_Models_and_Inference_for_Cumulative_Distribution_Functions_on_Graphs.html">21 jmlr-2011-Cumulative Distribution Networks and the Derivative-sum-product Algorithm: Models and Inference for Cumulative Distribution Functions on Graphs</a></p>
<p>16 0.048766632 <a title="104-tfidf-16" href="./jmlr-2011-Weisfeiler-Lehman_Graph_Kernels.html">103 jmlr-2011-Weisfeiler-Lehman Graph Kernels</a></p>
<p>17 0.04539923 <a title="104-tfidf-17" href="./jmlr-2011-Theoretical_Analysis_of_Bayesian_Matrix_Factorization.html">94 jmlr-2011-Theoretical Analysis of Bayesian Matrix Factorization</a></p>
<p>18 0.043683738 <a title="104-tfidf-18" href="./jmlr-2011-Hierarchical_Knowledge_Gradient_for_Sequential_Sampling.html">38 jmlr-2011-Hierarchical Knowledge Gradient for Sequential Sampling</a></p>
<p>19 0.041330028 <a title="104-tfidf-19" href="./jmlr-2011-Parallel_Algorithm_for_Learning_Optimal_Bayesian_Network_Structure.html">75 jmlr-2011-Parallel Algorithm for Learning Optimal Bayesian Network Structure</a></p>
<p>20 0.038315941 <a title="104-tfidf-20" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.224), (1, -0.138), (2, 0.159), (3, -0.087), (4, 0.28), (5, 0.019), (6, -0.176), (7, 0.009), (8, -0.004), (9, 0.127), (10, -0.002), (11, 0.073), (12, -0.011), (13, 0.038), (14, -0.11), (15, -0.133), (16, -0.239), (17, 0.076), (18, -0.147), (19, -0.108), (20, -0.159), (21, -0.203), (22, 0.102), (23, 0.057), (24, 0.113), (25, 0.098), (26, -0.079), (27, 0.015), (28, -0.079), (29, 0.029), (30, 0.043), (31, 0.041), (32, 0.022), (33, 0.025), (34, 0.033), (35, -0.002), (36, 0.093), (37, -0.022), (38, -0.057), (39, -0.032), (40, -0.032), (41, -0.035), (42, -0.04), (43, -0.099), (44, -0.14), (45, -0.075), (46, -0.001), (47, -0.034), (48, 0.015), (49, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93859851 <a title="104-lsi-1" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>2 0.58623904 <a title="104-lsi-2" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>3 0.48611405 <a title="104-lsi-3" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>4 0.44438916 <a title="104-lsi-4" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>5 0.422277 <a title="104-lsi-5" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>6 0.39251611 <a title="104-lsi-6" href="./jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">54 jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<p>7 0.33836299 <a title="104-lsi-7" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>8 0.30929232 <a title="104-lsi-8" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>9 0.30836874 <a title="104-lsi-9" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>10 0.29348233 <a title="104-lsi-10" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>11 0.29293284 <a title="104-lsi-11" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>12 0.29004872 <a title="104-lsi-12" href="./jmlr-2011-Adaptive_Exact_Inference_in_Graphical_Models.html">7 jmlr-2011-Adaptive Exact Inference in Graphical Models</a></p>
<p>13 0.27731755 <a title="104-lsi-13" href="./jmlr-2011-Inverse_Reinforcement_Learning_in_Partially_Observable_Environments.html">47 jmlr-2011-Inverse Reinforcement Learning in Partially Observable Environments</a></p>
<p>14 0.27434754 <a title="104-lsi-14" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>15 0.25647241 <a title="104-lsi-15" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>16 0.2473183 <a title="104-lsi-16" href="./jmlr-2011-Parallel_Algorithm_for_Learning_Optimal_Bayesian_Network_Structure.html">75 jmlr-2011-Parallel Algorithm for Learning Optimal Bayesian Network Structure</a></p>
<p>17 0.24281634 <a title="104-lsi-17" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>18 0.24178068 <a title="104-lsi-18" href="./jmlr-2011-Cumulative_Distribution_Networks_and_the_Derivative-sum-product_Algorithm%3A_Models_and_Inference_for_Cumulative_Distribution_Functions_on_Graphs.html">21 jmlr-2011-Cumulative Distribution Networks and the Derivative-sum-product Algorithm: Models and Inference for Cumulative Distribution Functions on Graphs</a></p>
<p>19 0.21593615 <a title="104-lsi-19" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>20 0.20136873 <a title="104-lsi-20" href="./jmlr-2011-Weisfeiler-Lehman_Graph_Kernels.html">103 jmlr-2011-Weisfeiler-Lehman Graph Kernels</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.406), (3, 0.02), (11, 0.036), (17, 0.051), (22, 0.019), (24, 0.058), (37, 0.062), (39, 0.055), (50, 0.027), (55, 0.015), (67, 0.063), (84, 0.027), (86, 0.032), (96, 0.012), (98, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.66176564 <a title="104-lda-1" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>2 0.58568293 <a title="104-lda-2" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<p>3 0.32922938 <a title="104-lda-3" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>4 0.32856962 <a title="104-lda-4" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>5 0.32745245 <a title="104-lda-5" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>6 0.31839374 <a title="104-lda-6" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>7 0.30917284 <a title="104-lda-7" href="./jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">54 jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<p>8 0.30776161 <a title="104-lda-8" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>9 0.30724299 <a title="104-lda-9" href="./jmlr-2011-Dirichlet_Process_Mixtures_of_Generalized_Linear_Models.html">24 jmlr-2011-Dirichlet Process Mixtures of Generalized Linear Models</a></p>
<p>10 0.30626261 <a title="104-lda-10" href="./jmlr-2011-Super-Linear_Convergence_of_Dual_Augmented_Lagrangian_Algorithm_for_Sparsity_Regularized_Estimation.html">89 jmlr-2011-Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation</a></p>
<p>11 0.30535805 <a title="104-lda-11" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>12 0.3051444 <a title="104-lda-12" href="./jmlr-2011-Distance_Dependent_Chinese_Restaurant_Processes.html">26 jmlr-2011-Distance Dependent Chinese Restaurant Processes</a></p>
<p>13 0.30512822 <a title="104-lda-13" href="./jmlr-2011-Learning_High-Dimensional_Markov_Forest_Distributions%3A_Analysis_of_Error_Rates.html">53 jmlr-2011-Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates</a></p>
<p>14 0.30467686 <a title="104-lda-14" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>15 0.30369219 <a title="104-lda-15" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<p>16 0.30118015 <a title="104-lda-16" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>17 0.29867539 <a title="104-lda-17" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>18 0.29688764 <a title="104-lda-18" href="./jmlr-2011-Producing_Power-Law_Distributions_and_Damping_Word_Frequencies_with_Two-Stage_Language_Models.html">78 jmlr-2011-Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models</a></p>
<p>19 0.29667535 <a title="104-lda-19" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>20 0.29637063 <a title="104-lda-20" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<br/><br/><br/></body>
</html>
