<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-72" href="#">jmlr2011-72</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</h1>
<br/><p>Source: <a title="jmlr-2011-72-pdf" href="http://jmlr.org/papers/volume12/ryabko11a/ryabko11a.pdf">pdf</a></p><p>Author: Daniil Ryabko</p><p>Abstract: A sequence x1 , . . . , xn , . . . of discrete-valued observations is generated according to some unknown probabilistic law (measure) µ. After observing each outcome, one is required to give conditional probabilities of the next observation. The realizable case is when the measure µ belongs to an arbitrary but known class C of process measures. The non-realizable case is when µ is completely arbitrary, but the prediction performance is measured with respect to a given set C of process measures. We are interested in the relations between these problems and between their solutions, as well as in characterizing the cases when a solution exists and ﬁnding these solutions. We show that if the quality of prediction is measured using the total variation distance, then these problems coincide, while if it is measured using the expected average KL divergence, then they are different. For some of the formalizations we also show that when a solution exists it can be obtained as a Bayes mixture over a countable subset of C . We also obtain several characterization of those sets C for which solutions to the considered problems exist. As an illustration to the general results obtained, we show that a solution to the non-realizable case of the sequence prediction problem exists for the set of all ﬁnite-memory processes, but does not exist for the set of all stationary processes. It should be emphasized that the framework is completely general: the processes measures considered are not required to be i.i.d., mixing, stationary, or to belong to any parametric family. Keywords: sequence prediction, time series, online prediction, realizable sequence prediction, non-realizable sequence prediction</p><p>Reference: <a title="jmlr-2011-72-reference" href="../jmlr2011_reference/jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The realizable case is when the measure µ belongs to an arbitrary but known class C of process measures. [sent-10, score-0.25]
</p><p>2 We show that if the quality of prediction is measured using the total variation distance, then these problems coincide, while if it is measured using the expected average KL divergence, then they are different. [sent-13, score-0.342]
</p><p>3 As an illustration to the general results obtained, we show that a solution to the non-realizable case of the sequence prediction problem exists for the set of all ﬁnite-memory processes, but does not exist for the set of all stationary processes. [sent-16, score-0.304]
</p><p>4 Keywords: sequence prediction, time series, online prediction, realizable sequence prediction, non-realizable sequence prediction  1. [sent-21, score-0.393]
</p><p>5 DANIIL RYABKO  that the “true” measure that generates the data belongs to the set C of interest, and would like to construct a predictor that predicts all measures in C . [sent-45, score-0.474]
</p><p>6 The second type of questions is as follows: does there exist a predictor that predicts at least as well as any predictor ρ ∈ C , if the measure that generates the data comes possibly from outside of C ? [sent-46, score-0.54]
</p><p>7 The general question of ﬁnding predictors for an arbitrary given set C of process measures has been addressed in Ryabko and Hutter (2007, 2008); Ryabko (2010a); the latter work shows that when a solution exists it can be obtained as a Bayes mixture over a countable subset of C . [sent-58, score-0.386]
</p><p>8 The ﬁrst one is the total variation distance, which measures the difference between the forecast and the “true” conditional probabilities of all future events (not just the probability of the next outcome). [sent-76, score-0.367]
</p><p>9 Requiring that predicted and true probabilities converge in total variation is very strong; in particular, this is possible if (Blackwell and Dubins, 1962) and only if (Kalai and Lehrer, 1994) the process measure generating the data is absolutely continuous with respect to the predictor. [sent-78, score-0.439]
</p><p>10 Here we investigate what can be paralleled for the other measure of prediction quality (average KL divergence), which is much weaker, and thus allows for solutions for the cases of much larger sets C of process measures (considered either as predictors or as data generating mechanisms). [sent-80, score-0.431]
</p><p>11 The second non-realizable problem is the “fully agnostic” problem: it is to make the prediction error asymptotically as small as that of the best (for the given process measure generating the data) predictor in C (we call this Problem 3). [sent-84, score-0.38]
</p><p>12 We show that if the quality of prediction is measured in total variation then all the three problems coincide: any solution to any one of them is a solution to the other two. [sent-86, score-0.425]
</p><p>13 For the case of expected average KL divergence, all the three problems are different: the realizable case is strictly easier than non-realizable (Problem 2), which is, in turn, strictly easier than the fully agnostic case (Problem 3). [sent-87, score-0.342]
</p><p>14 We then analyse which results concerning prediction in total variation can be transferred to which of the problems concerning prediction in average KL divergence. [sent-88, score-0.44]
</p><p>15 However, for the fully agnostic case of Problem 3, we show that separability with respect to a certain topology given by KL divergence is a sufﬁcient (though not a necessary) condition for the existence of a predictor. [sent-92, score-0.39]
</p><p>16 Ryabko (1988) that gives a solution to the realizable case of this problem (that is, a predictor whose expected average KL error goes to zero if any stationary process is chosen to generate the data). [sent-95, score-0.533]
</p><p>17 Deﬁnition 1 We say that ρ predicts µ in total variation if v(µ, ρ, x1. [sent-132, score-0.361]
</p><p>18 Moreover, ρ predicts µ in total variation if (Blackwell and Dubins, 1962) and only if (Kalai and Lehrer, 1994) µ is absolutely continuous with respect to ρ. [sent-138, score-0.447]
</p><p>19 Thus, for a class C of measures there is a predictor ρ that predicts every µ ∈ C in total variation if and only if every µ ∈ C has a density with respect to ρ. [sent-140, score-0.715]
</p><p>20 Therefore, perhaps for many (if not most) practical applications this measure of the quality of prediction is too strong, and one is interested in weaker measures of performance. [sent-150, score-0.3]
</p><p>21 For two measures µ and ρ introduce the expected cumulative Kullback-Leibler divergence (KL divergence) as n µ(xt = a|x1. [sent-151, score-0.277]
</p><p>22 Deﬁnition 2 We say that ρ predicts µ in expected average KL divergence if 1 dn (µ, ρ) → 0. [sent-158, score-0.603]
</p><p>23 With prediction quality so measured, predictors exist for relatively large classes of measures; most notably, Ryabko (1988) provides a predictor which predicts every stationary process in expected average KL divergence. [sent-160, score-0.729]
</p><p>24 Lemma 4 For every ρ ∈ P there exists µ ∈ D such that dn (µ, ρ) ≥ n log |X | for all n ∈ N. [sent-200, score-0.356]
</p><p>25 Given a set of probability measures C , ﬁnd a measure ρ such that ρ predicts in total variation (expected average KL divergence) every µ ∈ C , if such a ρ exists. [sent-209, score-0.557]
</p><p>26 Given a set of process measures (predictors) C , ﬁnd a process measure ρ such that ρ predicts in total variation (in expected average KL divergence) every measure ν ∈ P such that there is µ ∈ C which predicts (in the same sense) ν. [sent-214, score-0.91]
</p><p>27 Deﬁnition 5 Introduce the almost sure total variation loss of ρ with respect to µ ltv (µ, ρ) := inf{α ∈ [0, 1] : lim sup v(µ, ρ, x1. [sent-217, score-0.443]
</p><p>28 }, n→∞  and the asymptotic KL loss 1 lKL (ν, ρ) := lim sup dn (ν, ρ). [sent-221, score-0.385]
</p><p>29 n→∞ n We can now formulate the fully agnostic version of the sequence prediction problem. [sent-222, score-0.3]
</p><p>30 Given a set of process measures (predictors) C , ﬁnd a process measure ρ such that ρ predicts at least as well as any µ in C , if any process measure ν ∈ P is chosen to generate the data: l(ν, ρ) − l(ν, µ) ≤ 0 for every ν ∈ P and every µ ∈ C , where l(·, ·) is either ltv (·, ·) or lKL (·, ·). [sent-224, score-0.695]
</p><p>31 Markov chains being a familiar object in probability and statistics, we can easily construct a predictor ρ that predicts every µ ∈ C (for example, in expected average KL divergence, see Krichevsky, 1993). [sent-228, score-0.397]
</p><p>32 In other words, we want to have a predictor that predicts any process measure whatsoever (at least) as well as any Markov predictor. [sent-239, score-0.411]
</p><p>33 It appears that this depends on the measure of predictive quality chosen: for the case of prediction in total variation distance all the three problems coincide, while for the case of prediction in expected average KL divergence they are different. [sent-245, score-0.661]
</p><p>34 Prediction in Total Variation As it was mentioned, a measure µ is absolutely continuous with respect to a measure ρ if and only if ρ predicts µ in total variation distance. [sent-247, score-0.547]
</p><p>35 This reduces studying at least Problem 1 for total variation distance to studying the relation of absolute continuity. [sent-248, score-0.293]
</p><p>36 Furthermore, we introduce the (unconditional) total variation distance between process measures. [sent-260, score-0.257]
</p><p>37 Deﬁnition 7 (unconditional total variation distance) The (unconditional) total variation distance is deﬁned as v(µ, ρ) := sup |µ(A) − ρ(A)|. [sent-261, score-0.446]
</p><p>38 (v) There exists a sequence µk ∈ C , k ∈ N such that for some (equivalently, for every) sequence of weights wk ∈ (0, 1], k ∈ N such that ∑k∈N wk = 1, the measure ν = ∑k∈N wk µk satisﬁes ν ≥tv µ for every µ ∈ C . [sent-269, score-0.483]
</p><p>39 (vi) C is separable with respect to the total variation distance. [sent-270, score-0.254]
</p><p>40 The sequence µk in the statement (v) can be taken to be any dense (in the total variation distance) countable subset of C (cf. [sent-274, score-0.359]
</p><p>41 (i) ⇒ (ii) follows from the equivalence (i) ⇔ (iv) and the transitivity of ≥tv ; (i) ⇒ (iii) follows from the transitivity of ≥tv and from Lemma 9 below: indeed, from Lemma 9 we have ltv (ν, µ) = 0 if µ ≥tv ν and ltv (ν, µ) = 1 otherwise. [sent-280, score-0.323]
</p><p>42 From this and the transitivity of ≥tv it follows that if ρ ≥tv µ then also ltv (ν, ρ) ≤ ltv (ν, µ) for all ν ∈ P . [sent-281, score-0.253]
</p><p>43 By Lebesgue decomposition theorem, the measure µ admits a representation µ = αµa + (1 − α)µs where α ∈ [0, 1] and the measures µa and µs are such that µa is absolutely continuous with respect to ρ and µs is singular with respect to ρ. [sent-291, score-0.294]
</p><p>44 Using Lemma 9 we can also deﬁne expected (rather than almost sure) total variation loss of ρ with respect to µ, as the µ-probability that v(µ, ρ) converges to 1: ′ ltv (µ, ρ) := µ{x1 , x2 , · · · ∈ X ∞ : v(µ, ρ, x1. [sent-341, score-0.358]
</p><p>45 measures does not allow for a predictor that predicts every measure in total variation (as explained in Section 2). [sent-353, score-0.7]
</p><p>46 That is why we have to consider weaker notions of predictions; from these, prediction in expected average KL divergence is perhaps one of the weakest. [sent-354, score-0.313]
</p><p>47 Prediction in Expected Average KL Divergence First of all, we have to observe that for prediction in KL divergence Problems 1, 2, and 3 are different, as the following theorem shows. [sent-357, score-0.269]
</p><p>48 For the set C1 := {γt : t ∈ X ∞ } we have a solution to Problem 1: indeed, dn (γt , γ) ≤ 1 = o(n). [sent-383, score-0.321]
</p><p>49 Indeed, if ν ∈ P is such that dn (ν, γ′ ) = o(n) then we must have ν(t1. [sent-397, score-0.259]
</p><p>50 From this and the fact that γ and γ′ coincide (up to O(1)) on all other sequences we conclude dn (ν, γ) = o(n). [sent-400, score-0.319]
</p><p>51 Indeed, for every t ∈ D we have dn (t, γt′ ) = n log 3/2 + o(n). [sent-402, score-0.356]
</p><p>52 Therefore, if ρ is a solution to Problem 3 then lim sup 1 dn (t, ρ) ≤ n 2169  DANIIL RYABKO  log 3/2 < 1 which contradicts Lemma 4. [sent-403, score-0.505]
</p><p>53 Thus, prediction in expected average KL divergence turns out to be a more complicated matter than prediction in total variation. [sent-404, score-0.449]
</p><p>54 The next idea is to try and see which of the facts about prediction in total variation can be generalized to some of the problems concerning prediction in expected average KL divergence. [sent-405, score-0.456]
</p><p>55 First, observe that, for the case of prediction in total variation, the equivalence of Problems 1 and 2 was derived from the transitivity of the relation ≥tv of absolute continuity. [sent-406, score-0.263]
</p><p>56 For the case of expected average KL divergence, the relation “ρ predicts µ in expected average KL divergence” is not transitive (and Problems 1 and 2 are not equivalent). [sent-407, score-0.284]
</p><p>57 However, for Problem 2 we are interested in the following relation: ρ “dominates” µ if ρ predicts every ν such that µ predicts ν. [sent-408, score-0.387]
</p><p>58 Denote this relation by ≥KL : Deﬁnition 11 (≥KL ) We write ρ ≥KL µ if for every ν ∈ P the equality lim sup 1 dn (ν, µ) = 0 implies n 1 lim sup n dn (ν, ρ) = 0. [sent-409, score-0.837]
</p><p>59 If there is a measure ρ such that ρ ≥KL µ for every µ ∈ C (ρ is a solution to Problem 2) then there is a sequence µk ∈ C , k ∈ N, such that ∑k∈N wk µk ≥KL µ for every µ ∈ C , where wk are some positive weights. [sent-418, score-0.439]
</p><p>60 We have seen that, in the case of prediction in total variation, separability with respect to the topology of this distance is a necessary and sufﬁcient condition for the existence of a solution to Problems 1-3. [sent-424, score-0.369]
</p><p>61 In the case of expected average KL divergence the situation is somewhat different, since, ﬁrst of all, (asymptotic average) KL divergence is not a metric. [sent-425, score-0.299]
</p><p>62 2170  R EALIZABLE AND N ONREALIZABLE P REDICTION P ROBLEMS  Deﬁnition 13 Deﬁne the distance d∞ (µ1 , µ2 ) on process measures as follows d∞ (µ1 , µ2 ) = lim sup sup n→∞ x1. [sent-427, score-0.349]
</p><p>63 Moreover, for every µ1 , µ2 we have 1 lim sup dn (µ1 , µ2 ) ≤ d∞ (µ1 , µ2 ). [sent-435, score-0.424]
</p><p>64 If C is separable with respect to d∞ then there is a solution to Problem 3 for C , for the case of prediction in expected average KL divergence. [sent-439, score-0.284]
</p><p>65 (ii) There exists a set of process measures C such that C is not separable with respect to d∞ , but there is a solution to Problem 3 for this set, for the case of prediction in expected average KL divergence. [sent-440, score-0.435]
</p><p>66 We will show that lim supn→∞ n dn (τ, ν) ≤ lim supn→∞ 1 dn (τ, µ). [sent-444, score-0.678]
</p><p>67 n )  dn (τ, ν) ≤ dn (τ, wk µk ) = Eτ log  ≤ dn (τ, µ) + sup log x1. [sent-458, score-1.043]
</p><p>68 n )  From this, dividing by n taking lim supn→∞ on both sides, we conclude 1 1 lim sup dn (τ, ν) ≤ lim sup dn (τ, µ) + ε. [sent-465, score-0.85]
</p><p>69 It is easy to check that µ1 = µ2 implies d∞ (µ1 , µ2 ) = ∞ for every µ1 , µ2 ∈ C , but the predictor ν, given by ν(xn = 0) = 1/n independently for different n, predicts every µ ∈ C in expected average KL divergence. [sent-470, score-0.436]
</p><p>70 Theorem 15 There exists a solution to Problem 3 for prediction in expected average KL divergence for the set of all ﬁnite-memory process measures M := ∪k∈N Mk . [sent-474, score-0.497]
</p><p>71 Proof This proof is based on the construction similar to the one used in Ryabko (1988) to demonstrate impossibility of consistent prediction of stationary processes without Cesaro averaging. [sent-506, score-0.252]
</p><p>72 Indeed, for any t ∈ {0, 1}∞ we have dn (t, µt ) = n log 3/2 + o(n). [sent-521, score-0.317]
</p><p>73 Then if ρ is a solution to Problem 3 for C we should have 1 lim supn→∞ n dn (t, ρ) ≤ log 3/2 < 1 for every t ∈ D , which contradicts Lemma 4. [sent-522, score-0.498]
</p><p>74 Therefore, an interesting question is to characterize those sets C of measures for which there is a predictor ρ that predicts every individual sequence at least as well as any measure from C . [sent-526, score-0.554]
</p><p>75 (i) There is a measure ρ ∈ P that predicts every individual sequence at least as well as the best measure from C : for every µ ∈ C and every sequence x1 , x2 , · · · ∈ X ∞ we have 1 1 lim inf − log ρ(x1. [sent-531, score-0.664]
</p><p>76 n→∞ n→∞ n n (ii) For every α ∈ [0, 1] the Hausdorff dimension of the set of sequences on which the average prediction error of the best measure in C is not greater than α is bounded by α/ log |X |: 1 H({x1 , x2 , · · · ∈ X ∞ : inf lim inf − log µ(x1. [sent-536, score-0.532]
</p><p>77 µ∈C n→∞ n Proof The implication (i) ⇒ (ii) follows directly from Ryabko (1986) where it is shown that for every measure ρ one must have H({x1 , x2 , · · · ∈ X ∞ : lim infn→∞ − 1 log ρ(x1. [sent-539, score-0.26]
</p><p>78 n To show the opposite implication, we again refer to Ryabko (1986): for every set A ⊂ X ∞ there is a measure ρA such that 1 lim inf − log ρA (x1. [sent-542, score-0.28]
</p><p>79 By assumption, H(Aα ) ≤ α/ log |X|, so that from (2) for all x1 , x2 , · · · ∈ Aα we obtain  1 lim inf − log ρA (x1. [sent-548, score-0.249]
</p><p>80 As a somewhat surprising result, we can see that whether the two problems are different depends on the measure of performance chosen: in the case of prediction in total variation distance they coincide, while in the case of prediction in expected average KL divergence they are different. [sent-571, score-0.661]
</p><p>81 In the latter case, the distinction becomes particularly apparent on the example of stationary processes: while a solution to the realizable problem has long been known, here we have shown that there is no solution to the agnostic version of this problem. [sent-572, score-0.486]
</p><p>82 This problem is less restrictive then the fully agnostic one (in particular, it is not concerned with the behaviour of a predictor on every deterministic sequence) but at the same time the solutions to this problem have performance guarantees far outside the model class considered. [sent-574, score-0.372]
</p><p>83 Here it is interesting to ﬁnd properties common to all or most of the prediction problems (in total variation as well as with respect to other measures of the performance), if it is at all possible. [sent-580, score-0.434]
</p><p>84 Since the latter characterizes prediction in total variation and the former characterizes prediction in KL divergence (in the sense of Problem 2), which is much weaker, it would be interesting to see exactly what properties the two relations share. [sent-584, score-0.544]
</p><p>85 While for prediction in total variation it is a natural choice, for other measures of performance, including average KL divergence, it is clear that Problems 1-3 admit non-asymptotic formulations. [sent-587, score-0.408]
</p><p>86 Proof of Theorem 12 Proof Deﬁne the sets Cµ as the set of all measures τ ∈ P such that µ predicts τ in expected average KL divergence. [sent-590, score-0.322]
</p><p>87 In other words, C + is the set of all measures that are predicted by some of the measures in C , and for each measure τ in C + we designate one “parent” measure p(τ) from C such that p(τ) predicts τ. [sent-593, score-0.488]
</p><p>88 For each µ ∈ C + let δn be any monotonically increasing function such that δn (µ) = o(n) and dn (µ, p(µ)) = o(δn (µ)). [sent-596, score-0.259]
</p><p>89 (8) µ(A) 2  DANIIL RYABKO  Moreover, dn (µ, p(µ)) = −  ∑  µ(x1. [sent-637, score-0.259]
</p><p>90 We will show that ν predicts every µ ∈ C + , and then in the end of the proof (Step r) we will show how to replace γ by a combination of a countable set of elements of C (in fact, γ is just a regularizer which ensures that ν-probability of any word is never too close to 0). [sent-680, score-0.299]
</p><p>91 Hence, ρ(Tµn \T jn ) ≤ εn for some j ≤ jµ , since otherwise mn = maxµ∈C ρ(Tµn \T jn ) > εn so that n µ µ j µ n \T n ) > εn = 1/ j n , which is a contradiction. [sent-686, score-0.517]
</p><p>92 (15)  II ≥ −µ(Tµn \T jn ) log ρ(Tµn \T jn ) − 1/2 ≥ −µ(Tµn \T jn ) log εn − 1/2. [sent-715, score-0.833]
</p><p>93 Combining (14) with the bounds (15), (16) and (17) we obtain dn (µ, ρ) ≥ − log n − µ(Tµn \T jn ) log εn − 1 − µ(X n \Tµn )n log |X |, n µ µ so that µ(Tµn \T jn ) ≤ n µ  1 dn (µ, ρ) + log n + 1 + µ(X n \Tµn )n log |X | . [sent-723, score-1.286]
</p><p>94 − log εn µ  (18)  From the fact that dn (µ, ρ) = o(n) and (10) it follows that the term in brackets is o(n), so that we can deﬁne the parameters εn in such a way that − log εn = o(n) while at the same time the bound (18) µ µ gives µ(Tµn \T jn ) = o(1). [sent-724, score-0.614]
</p><p>95 Then, using (10), we conclude n µ µ µ(X n \T jn ) ≤ µ(X n \Tµn ) + µ(Tµn \T jn ) = o(1). [sent-726, score-0.478]
</p><p>96 n n µ µ  (19)  We proceed with the proof of dn (µ, ν) = o(n). [sent-727, score-0.259]
</p><p>97 Next we use the decomposition dn (µ, ν) = −  ∑  µ(x1. [sent-739, score-0.259]
</p><p>98 n ∈T jn n µ   = (o(n) − 2 log εn + δn (µ)) + dn (µ, ρ) + µ ≤ o(n) −  ∑  ∑  µ(x1. [sent-764, score-0.297]
</p><p>99 n ) ≤ 1 + nµ(X n \T jn ) log |X | = o(n), n µ µ(x1. [sent-785, score-0.297]
</p><p>100 From (21), (22) and (23) we conclude 1 dn (ν, µ) → 0. [sent-792, score-0.259]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ryabko', 0.46), ('tv', 0.354), ('dn', 0.259), ('kl', 0.247), ('jn', 0.239), ('daniil', 0.193), ('predicts', 0.174), ('realizable', 0.156), ('predictor', 0.143), ('variation', 0.136), ('ealizable', 0.133), ('onrealizable', 0.133), ('rediction', 0.133), ('divergence', 0.129), ('agnostic', 0.119), ('prediction', 0.114), ('roblems', 0.114), ('measures', 0.107), ('ltv', 0.104), ('wk', 0.104), ('tkn', 0.088), ('stationary', 0.087), ('predictors', 0.087), ('countable', 0.086), ('lim', 0.08), ('dubins', 0.076), ('hausdorff', 0.076), ('qk', 0.063), ('solution', 0.062), ('mk', 0.062), ('wn', 0.06), ('absolutely', 0.06), ('log', 0.058), ('blackwell', 0.057), ('inf', 0.053), ('processes', 0.051), ('total', 0.051), ('measure', 0.05), ('markov', 0.046), ('sup', 0.046), ('deterministic', 0.045), ('statement', 0.045), ('separability', 0.045), ('transitivity', 0.045), ('topology', 0.045), ('plesner', 0.044), ('unconditional', 0.044), ('process', 0.044), ('tk', 0.043), ('probabilities', 0.043), ('ergodic', 0.042), ('supn', 0.042), ('separable', 0.041), ('expected', 0.041), ('sequence', 0.041), ('mn', 0.039), ('kalai', 0.039), ('every', 0.039), ('lehrer', 0.038), ('wq', 0.038), ('xn', 0.035), ('anything', 0.035), ('coincide', 0.033), ('conjecture', 0.033), ('implication', 0.033), ('fix', 0.031), ('questions', 0.03), ('aqk', 0.03), ('cesaro', 0.03), ('equiprobable', 0.03), ('forecast', 0.03), ('krichevsky', 0.03), ('lkl', 0.03), ('nonrealizable', 0.03), ('ziv', 0.03), ('generating', 0.029), ('ii', 0.029), ('markovian', 0.029), ('weaker', 0.029), ('iv', 0.028), ('relation', 0.028), ('vii', 0.027), ('sequences', 0.027), ('chain', 0.027), ('distance', 0.026), ('studying', 0.026), ('fully', 0.026), ('respect', 0.026), ('transmission', 0.026), ('theorem', 0.026), ('outcomes', 0.026), ('characterization', 0.026), ('merging', 0.025), ('guesses', 0.025), ('infn', 0.025), ('prequential', 0.025), ('rokhlin', 0.025), ('singular', 0.025), ('analyse', 0.025), ('equivalence', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="72-tfidf-1" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>Author: Daniil Ryabko</p><p>Abstract: A sequence x1 , . . . , xn , . . . of discrete-valued observations is generated according to some unknown probabilistic law (measure) µ. After observing each outcome, one is required to give conditional probabilities of the next observation. The realizable case is when the measure µ belongs to an arbitrary but known class C of process measures. The non-realizable case is when µ is completely arbitrary, but the prediction performance is measured with respect to a given set C of process measures. We are interested in the relations between these problems and between their solutions, as well as in characterizing the cases when a solution exists and ﬁnding these solutions. We show that if the quality of prediction is measured using the total variation distance, then these problems coincide, while if it is measured using the expected average KL divergence, then they are different. For some of the formalizations we also show that when a solution exists it can be obtained as a Bayes mixture over a countable subset of C . We also obtain several characterization of those sets C for which solutions to the considered problems exist. As an illustration to the general results obtained, we show that a solution to the non-realizable case of the sequence prediction problem exists for the set of all ﬁnite-memory processes, but does not exist for the set of all stationary processes. It should be emphasized that the framework is completely general: the processes measures considered are not required to be i.i.d., mixing, stationary, or to belong to any parametric family. Keywords: sequence prediction, time series, online prediction, realizable sequence prediction, non-realizable sequence prediction</p><p>2 0.15451786 <a title="72-tfidf-2" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>Author: Vianney Perchet</p><p>Abstract: We provide consistent random algorithms for sequential decision under partial monitoring, when the decision maker does not observe the outcomes but receives instead random feedback signals. Those algorithms have no internal regret in the sense that, on the set of stages where the decision maker chose his action according to a given law, the average payoff could not have been improved in average by using any other ﬁxed law. They are based on a generalization of calibration, no longer deﬁned in terms of a Vorono¨ ı diagram but instead of a Laguerre diagram (a more general concept). This allows us to bound, for the ﬁrst time in this general framework, the expected average internal, as well as the usual external, regret at stage n by O(n−1/3 ), which is known to be optimal. Keywords: repeated games, on-line learning, regret, partial monitoring, calibration, Vorono¨ and ı Laguerre diagrams</p><p>3 0.07270167 <a title="72-tfidf-3" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>Author: Mark D. Reid, Robert C. Williamson</p><p>Abstract: We unify f -divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives which all are related to cost-sensitive binary classiﬁcation. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f -divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants. Keywords: classiﬁcation, loss functions, divergence, statistical information, regret bounds</p><p>4 0.068158098 <a title="72-tfidf-4" href="./jmlr-2011-Smoothness%2C_Disagreement_Coefficient%2C_and_the_Label_Complexity_of_Agnostic_Active_Learning.html">85 jmlr-2011-Smoothness, Disagreement Coefficient, and the Label Complexity of Agnostic Active Learning</a></p>
<p>Author: Liwei Wang</p><p>Abstract: We study pool-based active learning in the presence of noise, that is, the agnostic setting. It is known that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space. Although there are many cases on which active learning is very useful, it is also easy to construct examples that no active learning algorithm can have an advantage. Previous works have shown that the label complexity of active learning relies on the disagreement coefﬁcient which often characterizes the intrinsic difﬁculty of the learning problem. In this paper, we study the disagreement coefﬁcient of classiﬁcation problems for which the classiﬁcation boundary is smooth and the data distribution has a density that can be bounded by a smooth function. We prove upper and lower bounds for the disagreement coefﬁcients of both ﬁnitely and inﬁnitely smooth problems. Combining with existing results, it shows that active learning is superior to passive supervised learning for smooth problems. Keywords: active learning, disagreement coefﬁcient, label complexity, smooth function</p><p>5 0.065002955 <a title="72-tfidf-5" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>Author: Ricardo Henao, Ole Winther</p><p>Abstract: In this paper we consider sparse and identiﬁable linear latent variable (factor) and linear Bayesian network models for parsimonious analysis of multivariate data. We propose a computationally efﬁcient method for joint parameter and model inference, and model comparison. It consists of a fully Bayesian hierarchy for sparse models using slab and spike priors (two-component δ-function and continuous mixtures), non-Gaussian latent factors and a stochastic search over the ordering of the variables. The framework, which we call SLIM (Sparse Linear Identiﬁable Multivariate modeling), is validated and bench-marked on artiﬁcial and real biological data sets. SLIM is closest in spirit to LiNGAM (Shimizu et al., 2006), but differs substantially in inference, Bayesian network structure learning and model comparison. Experimentally, SLIM performs equally well or better than LiNGAM with comparable computational complexity. We attribute this mainly to the stochastic search strategy used, and to parsimony (sparsity and identiﬁability), which is an explicit part of the model. We propose two extensions to the basic i.i.d. linear framework: non-linear dependence on observed variables, called SNIM (Sparse Non-linear Identiﬁable Multivariate modeling) and allowing for correlations between latent variables, called CSLIM (Correlated SLIM), for the temporal and/or spatial data. The source code and scripts are available from http://cogsys.imm.dtu.dk/slim/. Keywords: parsimony, sparsity, identiﬁability, factor models, linear Bayesian networks</p><p>6 0.057057038 <a title="72-tfidf-6" href="./jmlr-2011-Learning_from_Partial_Labels.html">58 jmlr-2011-Learning from Partial Labels</a></p>
<p>7 0.051166952 <a title="72-tfidf-7" href="./jmlr-2011-Learning_High-Dimensional_Markov_Forest_Distributions%3A_Analysis_of_Error_Rates.html">53 jmlr-2011-Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates</a></p>
<p>8 0.04532811 <a title="72-tfidf-8" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>9 0.041846488 <a title="72-tfidf-9" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>10 0.04095193 <a title="72-tfidf-10" href="./jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">40 jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>11 0.039527886 <a title="72-tfidf-11" href="./jmlr-2011-Logistic_Stick-Breaking_Process.html">61 jmlr-2011-Logistic Stick-Breaking Process</a></p>
<p>12 0.037569314 <a title="72-tfidf-12" href="./jmlr-2011-The_Indian_Buffet_Process%3A_An_Introduction_and_Review.html">90 jmlr-2011-The Indian Buffet Process: An Introduction and Review</a></p>
<p>13 0.034722358 <a title="72-tfidf-13" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>14 0.034572534 <a title="72-tfidf-14" href="./jmlr-2011-Universality%2C_Characteristic_Kernels_and_RKHS_Embedding_of_Measures.html">98 jmlr-2011-Universality, Characteristic Kernels and RKHS Embedding of Measures</a></p>
<p>15 0.032682508 <a title="72-tfidf-15" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>16 0.028850706 <a title="72-tfidf-16" href="./jmlr-2011-Dirichlet_Process_Mixtures_of_Generalized_Linear_Models.html">24 jmlr-2011-Dirichlet Process Mixtures of Generalized Linear Models</a></p>
<p>17 0.027734622 <a title="72-tfidf-17" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>18 0.0266305 <a title="72-tfidf-18" href="./jmlr-2011-Bayesian_Generalized_Kernel_Mixed_Models.html">13 jmlr-2011-Bayesian Generalized Kernel Mixed Models</a></p>
<p>19 0.026585659 <a title="72-tfidf-19" href="./jmlr-2011-Better_Algorithms_for_Benign_Bandits.html">14 jmlr-2011-Better Algorithms for Benign Bandits</a></p>
<p>20 0.026416207 <a title="72-tfidf-20" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.164), (1, -0.005), (2, -0.067), (3, 0.07), (4, 0.066), (5, 0.009), (6, 0.006), (7, 0.032), (8, -0.178), (9, 0.05), (10, 0.002), (11, -0.118), (12, 0.036), (13, 0.235), (14, 0.03), (15, -0.198), (16, -0.111), (17, -0.058), (18, -0.089), (19, 0.048), (20, 0.234), (21, 0.173), (22, -0.048), (23, -0.179), (24, -0.275), (25, 0.155), (26, 0.061), (27, -0.073), (28, -0.066), (29, 0.007), (30, 0.045), (31, -0.092), (32, 0.264), (33, -0.076), (34, -0.12), (35, -0.119), (36, -0.108), (37, 0.028), (38, 0.005), (39, 0.009), (40, 0.115), (41, 0.076), (42, -0.091), (43, 0.042), (44, -0.017), (45, -0.025), (46, -0.08), (47, -0.038), (48, -0.014), (49, -0.006)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96404886 <a title="72-lsi-1" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>Author: Daniil Ryabko</p><p>Abstract: A sequence x1 , . . . , xn , . . . of discrete-valued observations is generated according to some unknown probabilistic law (measure) µ. After observing each outcome, one is required to give conditional probabilities of the next observation. The realizable case is when the measure µ belongs to an arbitrary but known class C of process measures. The non-realizable case is when µ is completely arbitrary, but the prediction performance is measured with respect to a given set C of process measures. We are interested in the relations between these problems and between their solutions, as well as in characterizing the cases when a solution exists and ﬁnding these solutions. We show that if the quality of prediction is measured using the total variation distance, then these problems coincide, while if it is measured using the expected average KL divergence, then they are different. For some of the formalizations we also show that when a solution exists it can be obtained as a Bayes mixture over a countable subset of C . We also obtain several characterization of those sets C for which solutions to the considered problems exist. As an illustration to the general results obtained, we show that a solution to the non-realizable case of the sequence prediction problem exists for the set of all ﬁnite-memory processes, but does not exist for the set of all stationary processes. It should be emphasized that the framework is completely general: the processes measures considered are not required to be i.i.d., mixing, stationary, or to belong to any parametric family. Keywords: sequence prediction, time series, online prediction, realizable sequence prediction, non-realizable sequence prediction</p><p>2 0.65789306 <a title="72-lsi-2" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>Author: Vianney Perchet</p><p>Abstract: We provide consistent random algorithms for sequential decision under partial monitoring, when the decision maker does not observe the outcomes but receives instead random feedback signals. Those algorithms have no internal regret in the sense that, on the set of stages where the decision maker chose his action according to a given law, the average payoff could not have been improved in average by using any other ﬁxed law. They are based on a generalization of calibration, no longer deﬁned in terms of a Vorono¨ ı diagram but instead of a Laguerre diagram (a more general concept). This allows us to bound, for the ﬁrst time in this general framework, the expected average internal, as well as the usual external, regret at stage n by O(n−1/3 ), which is known to be optimal. Keywords: repeated games, on-line learning, regret, partial monitoring, calibration, Vorono¨ and ı Laguerre diagrams</p><p>3 0.38719881 <a title="72-lsi-3" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>Author: Mark D. Reid, Robert C. Williamson</p><p>Abstract: We unify f -divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives which all are related to cost-sensitive binary classiﬁcation. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f -divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants. Keywords: classiﬁcation, loss functions, divergence, statistical information, regret bounds</p><p>4 0.31202546 <a title="72-lsi-4" href="./jmlr-2011-Smoothness%2C_Disagreement_Coefficient%2C_and_the_Label_Complexity_of_Agnostic_Active_Learning.html">85 jmlr-2011-Smoothness, Disagreement Coefficient, and the Label Complexity of Agnostic Active Learning</a></p>
<p>Author: Liwei Wang</p><p>Abstract: We study pool-based active learning in the presence of noise, that is, the agnostic setting. It is known that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space. Although there are many cases on which active learning is very useful, it is also easy to construct examples that no active learning algorithm can have an advantage. Previous works have shown that the label complexity of active learning relies on the disagreement coefﬁcient which often characterizes the intrinsic difﬁculty of the learning problem. In this paper, we study the disagreement coefﬁcient of classiﬁcation problems for which the classiﬁcation boundary is smooth and the data distribution has a density that can be bounded by a smooth function. We prove upper and lower bounds for the disagreement coefﬁcients of both ﬁnitely and inﬁnitely smooth problems. Combining with existing results, it shows that active learning is superior to passive supervised learning for smooth problems. Keywords: active learning, disagreement coefﬁcient, label complexity, smooth function</p><p>5 0.26503465 <a title="72-lsi-5" href="./jmlr-2011-Learning_from_Partial_Labels.html">58 jmlr-2011-Learning from Partial Labels</a></p>
<p>Author: Timothee Cour, Ben Sapp, Ben Taskar</p><p>Abstract: We address the problem of partially-labeled multiclass classiﬁcation, where instead of a single label per instance, the algorithm is given a candidate set of labels, only one of which is correct. Our setting is motivated by a common scenario in many image and video collections, where only partial access to labels is available. The goal is to learn a classiﬁer that can disambiguate the partiallylabeled training instances, and generalize to unseen data. We deﬁne an intuitive property of the data distribution that sharply characterizes the ability to learn in this setting and show that effective learning is possible even when all the data is only partially labeled. Exploiting this property of the data, we propose a convex learning formulation based on minimization of a loss function appropriate for the partial label setting. We analyze the conditions under which our loss function is asymptotically consistent, as well as its generalization and transductive performance. We apply our framework to identifying faces culled from web news sources and to naming characters in TV series and movies; in particular, we annotated and experimented on a very large video data set and achieve 6% error for character naming on 16 episodes of the TV series Lost. Keywords: weakly supervised learning, multiclass classiﬁcation, convex learning, generalization bounds, names and faces</p><p>6 0.26193985 <a title="72-lsi-6" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>7 0.22030614 <a title="72-lsi-7" href="./jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">40 jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>8 0.20108926 <a title="72-lsi-8" href="./jmlr-2011-Learning_High-Dimensional_Markov_Forest_Distributions%3A_Analysis_of_Error_Rates.html">53 jmlr-2011-Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates</a></p>
<p>9 0.19780673 <a title="72-lsi-9" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>10 0.19760753 <a title="72-lsi-10" href="./jmlr-2011-Logistic_Stick-Breaking_Process.html">61 jmlr-2011-Logistic Stick-Breaking Process</a></p>
<p>11 0.18272819 <a title="72-lsi-11" href="./jmlr-2011-A_Simpler_Approach_to_Matrix_Completion.html">6 jmlr-2011-A Simpler Approach to Matrix Completion</a></p>
<p>12 0.17344911 <a title="72-lsi-12" href="./jmlr-2011-Online_Learning_in_Case_of_Unbounded_Losses_Using_Follow_the_Perturbed_Leader_Algorithm.html">73 jmlr-2011-Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</a></p>
<p>13 0.16488649 <a title="72-lsi-13" href="./jmlr-2011-The_Indian_Buffet_Process%3A_An_Introduction_and_Review.html">90 jmlr-2011-The Indian Buffet Process: An Introduction and Review</a></p>
<p>14 0.14642558 <a title="72-lsi-14" href="./jmlr-2011-LPmade%3A_Link_Prediction_Made_Easy.html">50 jmlr-2011-LPmade: Link Prediction Made Easy</a></p>
<p>15 0.14546196 <a title="72-lsi-15" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>16 0.14148314 <a title="72-lsi-16" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>17 0.13935809 <a title="72-lsi-17" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>18 0.13766029 <a title="72-lsi-18" href="./jmlr-2011-Universality%2C_Characteristic_Kernels_and_RKHS_Embedding_of_Measures.html">98 jmlr-2011-Universality, Characteristic Kernels and RKHS Embedding of Measures</a></p>
<p>19 0.13657372 <a title="72-lsi-19" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>20 0.13099019 <a title="72-lsi-20" href="./jmlr-2011-Clustering_Algorithms_for_Chains.html">16 jmlr-2011-Clustering Algorithms for Chains</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.019), (4, 0.046), (9, 0.029), (10, 0.024), (24, 0.049), (31, 0.072), (32, 0.041), (39, 0.431), (41, 0.064), (60, 0.014), (65, 0.019), (73, 0.018), (78, 0.069), (90, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70437878 <a title="72-lda-1" href="./jmlr-2011-On_the_Relation_between_Realizable_and_Nonrealizable_Cases_of_the_Sequence_Prediction_Problem.html">72 jmlr-2011-On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem</a></p>
<p>Author: Daniil Ryabko</p><p>Abstract: A sequence x1 , . . . , xn , . . . of discrete-valued observations is generated according to some unknown probabilistic law (measure) µ. After observing each outcome, one is required to give conditional probabilities of the next observation. The realizable case is when the measure µ belongs to an arbitrary but known class C of process measures. The non-realizable case is when µ is completely arbitrary, but the prediction performance is measured with respect to a given set C of process measures. We are interested in the relations between these problems and between their solutions, as well as in characterizing the cases when a solution exists and ﬁnding these solutions. We show that if the quality of prediction is measured using the total variation distance, then these problems coincide, while if it is measured using the expected average KL divergence, then they are different. For some of the formalizations we also show that when a solution exists it can be obtained as a Bayes mixture over a countable subset of C . We also obtain several characterization of those sets C for which solutions to the considered problems exist. As an illustration to the general results obtained, we show that a solution to the non-realizable case of the sequence prediction problem exists for the set of all ﬁnite-memory processes, but does not exist for the set of all stationary processes. It should be emphasized that the framework is completely general: the processes measures considered are not required to be i.i.d., mixing, stationary, or to belong to any parametric family. Keywords: sequence prediction, time series, online prediction, realizable sequence prediction, non-realizable sequence prediction</p><p>2 0.30061889 <a title="72-lda-2" href="./jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">40 jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>Author: Stéphane Gaïffas, Guillaume Lecué</p><p>Abstract: Given a ﬁnite set F of functions and a learning sample, the aim of an aggregation procedure is to have a risk as close as possible to risk of the best function in F. Up to now, optimal aggregation procedures are convex combinations of every elements of F. In this paper, we prove that optimal aggregation procedures combining only two functions in F exist. Such algorithms are of particular interest when F contains many irrelevant functions that should not appear in the aggregation procedure. Since selectors are suboptimal aggregation procedures, this proves that two is the minimal number of elements of F required for the construction of an optimal aggregation procedure in every situations. Then, we perform a numerical study for the problem of selection of the regularization parameters of the Lasso and the Elastic-net estimators. We compare on simulated examples our aggregation algorithms to aggregation with exponential weights, to Mallow’s Cp and to cross-validation selection procedures. Keywords: aggregation, exact oracle inequality, empirical risk minimization, empirical process theory, sparsity, Lasso, Lars</p><p>3 0.30005038 <a title="72-lda-3" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>Author: Vanya Van Belle, Kristiaan Pelckmans, Johan A. K. Suykens, Sabine Van Huffel</p><p>Abstract: This paper studies the task of learning transformation models for ranking problems, ordinal regression and survival analysis. The present contribution describes a machine learning approach termed MINLIP . The key insight is to relate ranking criteria as the Area Under the Curve to monotone transformation functions. Consequently, the notion of a Lipschitz smoothness constant is found to be useful for complexity control for learning transformation models, much in a similar vein as the ’margin’ is for Support Vector Machines for classiﬁcation. The use of this model structure in the context of high dimensional data, as well as for estimating non-linear, and additive models based on primal-dual kernel machines, and for sparse models is indicated. Given n observations, the present method solves a quadratic program existing of O (n) constraints and O (n) unknowns, where most existing risk minimization approaches to ranking problems typically result in algorithms with O (n2 ) constraints or unknowns. We specify the MINLIP method for three different cases: the ﬁrst one concerns the preference learning problem. Secondly it is speciﬁed how to adapt the method to ordinal regression with a ﬁnite set of ordered outcomes. Finally, it is shown how the method can be used in the context of survival analysis where one models failure times, typically subject to censoring. The current approach is found to be particularly useful in this context as it can handle, in contrast with the standard statistical model for analyzing survival data, all types of censoring in a straightforward way, and because of the explicit relation with the Proportional Hazard and Accelerated Failure Time models. The advantage of the current method is illustrated on different benchmark data sets, as well as for estimating a model for cancer survival based on different micro-array and clinical data sets. Keywords: support vector machines, preference learning, ranking models, ordinal regression, survival analysis c</p><p>4 0.29455131 <a title="72-lda-4" href="./jmlr-2011-Domain_Decomposition_Approach_for_Fast_Gaussian_Process_Regression_of_Large_Spatial_Data_Sets.html">27 jmlr-2011-Domain Decomposition Approach for Fast Gaussian Process Regression of Large Spatial Data Sets</a></p>
<p>Author: Chiwoo Park, Jianhua Z. Huang, Yu Ding</p><p>Abstract: Gaussian process regression is a ﬂexible and powerful tool for machine learning, but the high computational complexity hinders its broader applications. In this paper, we propose a new approach for fast computation of Gaussian process regression with a focus on large spatial data sets. The approach decomposes the domain of a regression function into small subdomains and infers a local piece of the regression function for each subdomain. We explicitly address the mismatch problem of the local pieces on the boundaries of neighboring subdomains by imposing continuity constraints. The new approach has comparable or better computation complexity as other competing methods, but it is easier to be parallelized for faster computation. Moreover, the method can be adaptive to non-stationary features because of its local nature and, in particular, its use of different hyperparameters of the covariance function for different local regions. We illustrate application of the method and demonstrate its advantages over existing methods using two synthetic data sets and two real spatial data sets. Keywords: domain decomposition, boundary value problem, Gaussian process regression, parallel computation, spatial prediction</p><p>5 0.28809071 <a title="72-lda-5" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<p>Author: Bruno Pelletier, Pierre Pudlo</p><p>Abstract: Following Hartigan (1975), a cluster is deﬁned as a connected component of the t-level set of the underlying density, that is, the set of points for which the density is greater than t. A clustering algorithm which combines a density estimate with spectral clustering techniques is proposed. Our algorithm is composed of two steps. First, a nonparametric density estimate is used to extract the data points for which the estimated density takes a value greater than t. Next, the extracted points are clustered based on the eigenvectors of a graph Laplacian matrix. Under mild assumptions, we prove the almost sure convergence in operator norm of the empirical graph Laplacian operator associated with the algorithm. Furthermore, we give the typical behavior of the representation of the data set into the feature space, which establishes the strong consistency of our proposed algorithm. Keywords: spectral clustering, graph, unsupervised classiﬁcation, level sets, connected components</p><p>6 0.28631309 <a title="72-lda-6" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>7 0.28630367 <a title="72-lda-7" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>8 0.28478414 <a title="72-lda-8" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>9 0.28258121 <a title="72-lda-9" href="./jmlr-2011-Efficient_Learning_with_Partially_Observed_Attributes.html">29 jmlr-2011-Efficient Learning with Partially Observed Attributes</a></p>
<p>10 0.28123865 <a title="72-lda-10" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>11 0.27904123 <a title="72-lda-11" href="./jmlr-2011-Clustering_Algorithms_for_Chains.html">16 jmlr-2011-Clustering Algorithms for Chains</a></p>
<p>12 0.27892625 <a title="72-lda-12" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>13 0.27886415 <a title="72-lda-13" href="./jmlr-2011-Learning_High-Dimensional_Markov_Forest_Distributions%3A_Analysis_of_Error_Rates.html">53 jmlr-2011-Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates</a></p>
<p>14 0.27867383 <a title="72-lda-14" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>15 0.27800986 <a title="72-lda-15" href="./jmlr-2011-Neyman-Pearson_Classification%2C_Convexity_and_Stochastic_Constraints.html">69 jmlr-2011-Neyman-Pearson Classification, Convexity and Stochastic Constraints</a></p>
<p>16 0.27795249 <a title="72-lda-16" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>17 0.27780604 <a title="72-lda-17" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>18 0.27475953 <a title="72-lda-18" href="./jmlr-2011-Parameter_Screening_and_Optimisation_for_ILP_using_Designed_Experiments.html">76 jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</a></p>
<p>19 0.27471581 <a title="72-lda-19" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<p>20 0.2726571 <a title="72-lda-20" href="./jmlr-2011-Smoothness%2C_Disagreement_Coefficient%2C_and_the_Label_Complexity_of_Agnostic_Active_Learning.html">85 jmlr-2011-Smoothness, Disagreement Coefficient, and the Label Complexity of Agnostic Active Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
