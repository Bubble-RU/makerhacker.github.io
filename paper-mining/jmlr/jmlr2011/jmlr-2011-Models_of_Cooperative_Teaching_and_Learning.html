<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>65 jmlr-2011-Models of Cooperative Teaching and Learning</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-65" href="#">jmlr2011-65</a> knowledge-graph by maker-knowledge-mining</p><h1>65 jmlr-2011-Models of Cooperative Teaching and Learning</h1>
<br/><p>Source: <a title="jmlr-2011-65-pdf" href="http://jmlr.org/papers/volume12/zilles11a/zilles11a.pdf">pdf</a></p><p>Author: Sandra Zilles, Steffen Lange, Robert Holte, Martin Zinkevich</p><p>Abstract: While most supervised machine learning models assume that training examples are sampled at random or adversarially, this article is concerned with models of learning from a cooperative teacher that selects “helpful” training examples. The number of training examples a learner needs for identifying a concept in a given class C of possible target concepts (sample complexity of C) is lower in models assuming such teachers, that is, “helpful” examples can speed up the learning process. The problem of how a teacher and a learner can cooperate in order to reduce the sample complexity, yet without using “coding tricks”, has been widely addressed. Nevertheless, the resulting teaching and learning protocols do not seem to make the teacher select intuitively “helpful” examples. The two models introduced in this paper are built on what we call subset teaching sets and recursive teaching sets. They extend previous models of teaching by letting both the teacher and the learner exploit knowing that the partner is cooperative. For this purpose, we introduce a new notion of “coding trick”/“collusion”. We show how both resulting sample complexity measures (the subset teaching dimension and the recursive teaching dimension) can be arbitrarily lower than the classic teaching dimension and known variants thereof, without using coding tricks. For instance, monomials can be taught with only two examples independent of the number of variables. The subset teaching dimension turns out to be nonmonotonic with respect to subclasses of concept classes. We discuss why this nonmonotonicity might be inherent in many interesting cooperative teaching and learning scenarios. Keywords: teaching dimension, learning Boolean functions, interactive learning, collusion c 2011 Sandra Zilles, Steffen Lange, Robert Holte and Martin Zinkevich. Z ILLES , L ANGE , H OLTE AND Z INKEVICH</p><p>Reference: <a title="jmlr-2011-65-reference" href="../jmlr2011_reference/jmlr-2011-Models_of_Cooperative_Teaching_and_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('teach', 0.926), ('btd', 0.13), ('stsk', 0.119), ('rtd', 0.116), ('monom', 0.104), ('conceiv', 0.102), ('std', 0.099), ('balbach', 0.097), ('td', 0.083), ('cz', 0.078), ('protocol', 0.069), ('goldm', 0.055), ('inkevich', 0.049), ('olt', 0.049), ('each', 0.046), ('ang', 0.041), ('oop', 0.039), ('mathia', 0.037), ('nonmonoton', 0.037), ('coop', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="65-tfidf-1" href="./jmlr-2011-Models_of_Cooperative_Teaching_and_Learning.html">65 jmlr-2011-Models of Cooperative Teaching and Learning</a></p>
<p>2 0.021187296 <a title="65-tfidf-2" href="./jmlr-2011-Bayesian_Generalized_Kernel_Mixed_Models.html">13 jmlr-2011-Bayesian Generalized Kernel Mixed Models</a></p>
<p>3 0.017418088 <a title="65-tfidf-3" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>4 0.017197225 <a title="65-tfidf-4" href="./jmlr-2011-Adaptive_Exact_Inference_in_Graphical_Models.html">7 jmlr-2011-Adaptive Exact Inference in Graphical Models</a></p>
<p>5 0.012016326 <a title="65-tfidf-5" href="./jmlr-2011-Exploiting_Best-Match_Equations_for_Efficient_Reinforcement_Learning.html">33 jmlr-2011-Exploiting Best-Match Equations for Efficient Reinforcement Learning</a></p>
<p>6 0.010820992 <a title="65-tfidf-6" href="./jmlr-2011-Learning_from_Partial_Labels.html">58 jmlr-2011-Learning from Partial Labels</a></p>
<p>7 0.0097398665 <a title="65-tfidf-7" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>8 0.0076651564 <a title="65-tfidf-8" href="./jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">68 jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>9 0.0070446543 <a title="65-tfidf-9" href="./jmlr-2011-Non-Parametric_Estimation_of_Topic_Hierarchies_from_Texts_with_Hierarchical_Dirichlet_Processes.html">70 jmlr-2011-Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes</a></p>
<p>10 0.0069910171 <a title="65-tfidf-10" href="./jmlr-2011-Learning_Multi-modal_Similarity.html">55 jmlr-2011-Learning Multi-modal Similarity</a></p>
<p>11 0.0064831777 <a title="65-tfidf-11" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>12 0.0062470865 <a title="65-tfidf-12" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>13 0.006036438 <a title="65-tfidf-13" href="./jmlr-2011-Unsupervised_Similarity-Based_Risk_Stratification_for_Cardiovascular_Events_Using_Long-Term_Time-Series_Data.html">99 jmlr-2011-Unsupervised Similarity-Based Risk Stratification for Cardiovascular Events Using Long-Term Time-Series Data</a></p>
<p>14 0.005966587 <a title="65-tfidf-14" href="./jmlr-2011-Improved_Moves_for_Truncated_Convex_Models.html">41 jmlr-2011-Improved Moves for Truncated Convex Models</a></p>
<p>15 0.0059162145 <a title="65-tfidf-15" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>16 0.005882618 <a title="65-tfidf-16" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>17 0.0058112037 <a title="65-tfidf-17" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>18 0.0055044997 <a title="65-tfidf-18" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>19 0.0054432643 <a title="65-tfidf-19" href="./jmlr-2011-Robust_Gaussian_Process_Regression_with_a_Student-tLikelihood.html">82 jmlr-2011-Robust Gaussian Process Regression with a Student-tLikelihood</a></p>
<p>20 0.005391818 <a title="65-tfidf-20" href="./jmlr-2011-Efficient_Structure_Learning_of_Bayesian_Networks_using_Constraints.html">30 jmlr-2011-Efficient Structure Learning of Bayesian Networks using Constraints</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.032), (1, 0.004), (2, 0.012), (3, 0.002), (4, -0.01), (5, -0.006), (6, 0.005), (7, 0.007), (8, -0.005), (9, -0.003), (10, -0.007), (11, 0.001), (12, 0.023), (13, -0.008), (14, 0.002), (15, -0.022), (16, 0.012), (17, -0.01), (18, -0.002), (19, -0.037), (20, -0.0), (21, -0.0), (22, -0.039), (23, -0.011), (24, -0.005), (25, 0.034), (26, 0.003), (27, -0.048), (28, 0.015), (29, -0.069), (30, -0.068), (31, -0.079), (32, -0.181), (33, -0.061), (34, -0.074), (35, 0.312), (36, -0.215), (37, 0.036), (38, -0.552), (39, -0.468), (40, -0.2), (41, 0.099), (42, 0.237), (43, 0.181), (44, -0.106), (45, 0.01), (46, 0.017), (47, 0.132), (48, 0.017), (49, 0.204)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99243879 <a title="65-lsi-1" href="./jmlr-2011-Models_of_Cooperative_Teaching_and_Learning.html">65 jmlr-2011-Models of Cooperative Teaching and Learning</a></p>
<p>2 0.14339687 <a title="65-lsi-2" href="./jmlr-2011-Bayesian_Generalized_Kernel_Mixed_Models.html">13 jmlr-2011-Bayesian Generalized Kernel Mixed Models</a></p>
<p>3 0.078027517 <a title="65-lsi-3" href="./jmlr-2011-Generalized_TD_Learning.html">36 jmlr-2011-Generalized TD Learning</a></p>
<p>4 0.070379138 <a title="65-lsi-4" href="./jmlr-2011-The_arules_R-Package_Ecosystem%3A_Analyzing_Interesting_Patterns_from_Large_Transaction_Data_Sets.html">93 jmlr-2011-The arules R-Package Ecosystem: Analyzing Interesting Patterns from Large Transaction Data Sets</a></p>
<p>5 0.069012128 <a title="65-lsi-5" href="./jmlr-2011-Non-Parametric_Estimation_of_Topic_Hierarchies_from_Texts_with_Hierarchical_Dirichlet_Processes.html">70 jmlr-2011-Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes</a></p>
<p>6 0.063934177 <a title="65-lsi-6" href="./jmlr-2011-Adaptive_Exact_Inference_in_Graphical_Models.html">7 jmlr-2011-Adaptive Exact Inference in Graphical Models</a></p>
<p>7 0.059801735 <a title="65-lsi-7" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>8 0.052430809 <a title="65-lsi-8" href="./jmlr-2011-Laplacian_Support_Vector_Machines__Trained_in_the_Primal.html">51 jmlr-2011-Laplacian Support Vector Machines  Trained in the Primal</a></p>
<p>9 0.051407732 <a title="65-lsi-9" href="./jmlr-2011-Information%2C_Divergence_and_Risk_for_Binary_Experiments.html">43 jmlr-2011-Information, Divergence and Risk for Binary Experiments</a></p>
<p>10 0.051315624 <a title="65-lsi-10" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>11 0.044343662 <a title="65-lsi-11" href="./jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">68 jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>12 0.043771558 <a title="65-lsi-12" href="./jmlr-2011-Unsupervised_Similarity-Based_Risk_Stratification_for_Cardiovascular_Events_Using_Long-Term_Time-Series_Data.html">99 jmlr-2011-Unsupervised Similarity-Based Risk Stratification for Cardiovascular Events Using Long-Term Time-Series Data</a></p>
<p>13 0.043206256 <a title="65-lsi-13" href="./jmlr-2011-Kernel_Regression_in_the_Presence_of_Correlated_Errors.html">49 jmlr-2011-Kernel Regression in the Presence of Correlated Errors</a></p>
<p>14 0.042772848 <a title="65-lsi-14" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>15 0.042593494 <a title="65-lsi-15" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>16 0.041119888 <a title="65-lsi-16" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>17 0.040194228 <a title="65-lsi-17" href="./jmlr-2011-Exploiting_Best-Match_Equations_for_Efficient_Reinforcement_Learning.html">33 jmlr-2011-Exploiting Best-Match Equations for Efficient Reinforcement Learning</a></p>
<p>18 0.038504798 <a title="65-lsi-18" href="./jmlr-2011-Structured_Variable_Selection_with_Sparsity-Inducing_Norms.html">88 jmlr-2011-Structured Variable Selection with Sparsity-Inducing Norms</a></p>
<p>19 0.037438054 <a title="65-lsi-19" href="./jmlr-2011-On_Equivalence_Relationships_Between_Classification_and_Ranking_Algorithms.html">71 jmlr-2011-On Equivalence Relationships Between Classification and Ranking Algorithms</a></p>
<p>20 0.035793625 <a title="65-lsi-20" href="./jmlr-2011-Producing_Power-Law_Distributions_and_Damping_Word_Frequencies_with_Two-Stage_Language_Models.html">78 jmlr-2011-Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.01), (3, 0.016), (11, 0.029), (17, 0.047), (19, 0.527), (22, 0.01), (24, 0.025), (37, 0.058), (39, 0.022), (67, 0.029), (84, 0.014), (86, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.66057378 <a title="65-lda-1" href="./jmlr-2011-Models_of_Cooperative_Teaching_and_Learning.html">65 jmlr-2011-Models of Cooperative Teaching and Learning</a></p>
<p>2 0.54359448 <a title="65-lda-2" href="./jmlr-2011-On_Equivalence_Relationships_Between_Classification_and_Ranking_Algorithms.html">71 jmlr-2011-On Equivalence Relationships Between Classification and Ranking Algorithms</a></p>
<p>3 0.17113069 <a title="65-lda-3" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<p>4 0.17106265 <a title="65-lda-4" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>5 0.16993637 <a title="65-lda-5" href="./jmlr-2011-Information_Rates_of_Nonparametric_Gaussian_Process_Methods.html">44 jmlr-2011-Information Rates of Nonparametric Gaussian Process Methods</a></p>
<p>6 0.16966827 <a title="65-lda-6" href="./jmlr-2011-X-Armed_Bandits.html">104 jmlr-2011-X-Armed Bandits</a></p>
<p>7 0.16949938 <a title="65-lda-7" href="./jmlr-2011-Robust_Gaussian_Process_Regression_with_a_Student-tLikelihood.html">82 jmlr-2011-Robust Gaussian Process Regression with a Student-tLikelihood</a></p>
<p>8 0.16843385 <a title="65-lda-8" href="./jmlr-2011-Forest_Density_Estimation.html">35 jmlr-2011-Forest Density Estimation</a></p>
<p>9 0.16841525 <a title="65-lda-9" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>10 0.16789126 <a title="65-lda-10" href="./jmlr-2011-An_Asymptotic_Behaviour_of_the_Marginal_Likelihood_for_General_Markov_Models.html">9 jmlr-2011-An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models</a></p>
<p>11 0.16760716 <a title="65-lda-11" href="./jmlr-2011-Learning_Latent_Tree_Graphical_Models.html">54 jmlr-2011-Learning Latent Tree Graphical Models</a></p>
<p>12 0.16681968 <a title="65-lda-12" href="./jmlr-2011-Parameter_Screening_and_Optimisation_for_ILP_using_Designed_Experiments.html">76 jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</a></p>
<p>13 0.1656827 <a title="65-lda-13" href="./jmlr-2011-Bayesian_Generalized_Kernel_Mixed_Models.html">13 jmlr-2011-Bayesian Generalized Kernel Mixed Models</a></p>
<p>14 0.16476727 <a title="65-lda-14" href="./jmlr-2011-Dirichlet_Process_Mixtures_of_Generalized_Linear_Models.html">24 jmlr-2011-Dirichlet Process Mixtures of Generalized Linear Models</a></p>
<p>15 0.16334084 <a title="65-lda-15" href="./jmlr-2011-Discriminative_Learning_of_Bayesian_Networks_via_Factorized_Conditional_Log-Likelihood.html">25 jmlr-2011-Discriminative Learning of Bayesian Networks via Factorized Conditional Log-Likelihood</a></p>
<p>16 0.16288325 <a title="65-lda-16" href="./jmlr-2011-Distance_Dependent_Chinese_Restaurant_Processes.html">26 jmlr-2011-Distance Dependent Chinese Restaurant Processes</a></p>
<p>17 0.16245466 <a title="65-lda-17" href="./jmlr-2011-Convergence_Rates_of_Efficient_Global_Optimization_Algorithms.html">18 jmlr-2011-Convergence Rates of Efficient Global Optimization Algorithms</a></p>
<p>18 0.16204226 <a title="65-lda-18" href="./jmlr-2011-Convergence_of_Distributed_Asynchronous_Learning_Vector_Quantization_Algorithms.html">19 jmlr-2011-Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms</a></p>
<p>19 0.16127187 <a title="65-lda-19" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>20 0.1606933 <a title="65-lda-20" href="./jmlr-2011-Operator_Norm_Convergence_of_Spectral_Clustering_on_Level_Sets.html">74 jmlr-2011-Operator Norm Convergence of Spectral Clustering on Level Sets</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
