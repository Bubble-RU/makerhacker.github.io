<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</title>
</head>

<body>
<p><a title="jmlr" href="../jmlr_home.html">jmlr</a> <a title="jmlr-2011" href="../home/jmlr2011_home.html">jmlr2011</a> <a title="jmlr-2011-77" href="#">jmlr2011-77</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</h1>
<br/><p>Source: <a title="jmlr-2011-77-pdf" href="http://jmlr.org/papers/volume12/gillenwater11a/gillenwater11a.pdf">pdf</a></p><p>Author: Jennifer Gillenwater, Kuzman Ganchev, João Graça, Fernando Pereira, Ben Taskar</p><p>Abstract: A strong inductive bias is essential in unsupervised grammar induction. In this paper, we explore a particular sparsity bias in dependency grammars that encourages a small number of unique dependency types. We use part-of-speech (POS) tags to group dependencies by parent-child types and investigate sparsity-inducing penalties on the posterior distributions of parent-child POS tag pairs in the posterior regularization (PR) framework of Graça et al. (2007). In experiments with 12 different languages, we achieve signiﬁcant gains in directed attachment accuracy over the standard expectation maximization (EM) baseline, with an average accuracy improvement of 6.5%, outperforming EM by at least 1% for 9 out of 12 languages. Furthermore, the new method outperforms models based on standard Bayesian sparsity-inducing parameter priors with an average improvement of 5% and positive gains of at least 1% for 9 out of 12 languages. On English text in particular, we show that our approach improves performance over other state-of-the-art techniques.</p><p>Reference: <a title="jmlr-2011-77-reference" href="../jmlr2011_reference/jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dmv', 0.541), ('pr', 0.263), ('em', 0.231), ('sdp', 0.21), ('pars', 0.208), ('tag', 0.203), ('cpi', 0.146), ('pchild', 0.139), ('gramm', 0.135), ('head', 0.135), ('anchev', 0.132), ('ereir', 0.132), ('illenw', 0.132), ('nsuperv', 0.124), ('engl', 0.124), ('sent', 0.116), ('child', 0.112), ('pstop', 0.102), ('epend', 0.1), ('gra', 0.095)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="77-tfidf-1" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>2 0.19541307 <a title="77-tfidf-2" href="./jmlr-2011-Introduction_to_the_Special_Topic_on_Grammar_Induction%2C_Representation_of_Language_and_Language_Learning.html">46 jmlr-2011-Introduction to the Special Topic on Grammar Induction, Representation of Language and Language Learning</a></p>
<p>3 0.17826171 <a title="77-tfidf-3" href="./jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">68 jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>4 0.11495803 <a title="77-tfidf-4" href="./jmlr-2011-Producing_Power-Law_Distributions_and_Damping_Word_Frequencies_with_Two-Stage_Language_Models.html">78 jmlr-2011-Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models</a></p>
<p>5 0.074259445 <a title="77-tfidf-5" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>6 0.057508256 <a title="77-tfidf-6" href="./jmlr-2011-Learning_from_Partial_Labels.html">58 jmlr-2011-Learning from Partial Labels</a></p>
<p>7 0.057408538 <a title="77-tfidf-7" href="./jmlr-2011-Learning_Multi-modal_Similarity.html">55 jmlr-2011-Learning Multi-modal Similarity</a></p>
<p>8 0.05613023 <a title="77-tfidf-8" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>9 0.04866913 <a title="77-tfidf-9" href="./jmlr-2011-Dirichlet_Process_Mixtures_of_Generalized_Linear_Models.html">24 jmlr-2011-Dirichlet Process Mixtures of Generalized Linear Models</a></p>
<p>10 0.047934156 <a title="77-tfidf-10" href="./jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">4 jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<p>11 0.043850746 <a title="77-tfidf-11" href="./jmlr-2011-A_Simpler_Approach_to_Matrix_Completion.html">6 jmlr-2011-A Simpler Approach to Matrix Completion</a></p>
<p>12 0.0431596 <a title="77-tfidf-12" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>13 0.042406648 <a title="77-tfidf-13" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>14 0.038798135 <a title="77-tfidf-14" href="./jmlr-2011-Robust_Gaussian_Process_Regression_with_a_Student-tLikelihood.html">82 jmlr-2011-Robust Gaussian Process Regression with a Student-tLikelihood</a></p>
<p>15 0.038441006 <a title="77-tfidf-15" href="./jmlr-2011-Multitask_Sparsity_via_Maximum_Entropy_Discrimination.html">67 jmlr-2011-Multitask Sparsity via Maximum Entropy Discrimination</a></p>
<p>16 0.03817942 <a title="77-tfidf-16" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>17 0.037437174 <a title="77-tfidf-17" href="./jmlr-2011-Improved_Moves_for_Truncated_Convex_Models.html">41 jmlr-2011-Improved Moves for Truncated Convex Models</a></p>
<p>18 0.034804728 <a title="77-tfidf-18" href="./jmlr-2011-Hyper-Sparse_Optimal_Aggregation.html">40 jmlr-2011-Hyper-Sparse Optimal Aggregation</a></p>
<p>19 0.034431152 <a title="77-tfidf-19" href="./jmlr-2011-Learning_with_Structured_Sparsity.html">59 jmlr-2011-Learning with Structured Sparsity</a></p>
<p>20 0.034161564 <a title="77-tfidf-20" href="./jmlr-2011-Logistic_Stick-Breaking_Process.html">61 jmlr-2011-Logistic Stick-Breaking Process</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/jmlr2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.197), (1, 0.112), (2, 0.04), (3, -0.1), (4, -0.171), (5, -0.129), (6, -0.156), (7, 0.088), (8, 0.126), (9, -0.131), (10, -0.069), (11, 0.437), (12, 0.041), (13, -0.046), (14, 0.029), (15, 0.004), (16, 0.111), (17, 0.031), (18, -0.013), (19, -0.002), (20, -0.014), (21, -0.032), (22, -0.049), (23, -0.02), (24, 0.083), (25, -0.036), (26, 0.022), (27, -0.157), (28, 0.039), (29, 0.121), (30, -0.052), (31, -0.023), (32, 0.017), (33, 0.024), (34, 0.082), (35, 0.01), (36, 0.032), (37, -0.065), (38, -0.022), (39, -0.021), (40, -0.015), (41, 0.121), (42, -0.051), (43, -0.017), (44, -0.037), (45, -0.066), (46, -0.037), (47, -0.089), (48, -0.081), (49, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93885213 <a title="77-lsi-1" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>2 0.7484681 <a title="77-lsi-2" href="./jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">68 jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>3 0.69286042 <a title="77-lsi-3" href="./jmlr-2011-Introduction_to_the_Special_Topic_on_Grammar_Induction%2C_Representation_of_Language_and_Language_Learning.html">46 jmlr-2011-Introduction to the Special Topic on Grammar Induction, Representation of Language and Language Learning</a></p>
<p>4 0.4975929 <a title="77-lsi-4" href="./jmlr-2011-Producing_Power-Law_Distributions_and_Damping_Word_Frequencies_with_Two-Stage_Language_Models.html">78 jmlr-2011-Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models</a></p>
<p>5 0.28341132 <a title="77-lsi-5" href="./jmlr-2011-Minimum_Description_Length_Penalization_for_Group_and_Multi-Task_Sparse_Learning.html">64 jmlr-2011-Minimum Description Length Penalization for Group and Multi-Task Sparse Learning</a></p>
<p>6 0.27957207 <a title="77-lsi-6" href="./jmlr-2011-The_Sample_Complexity_of_Dictionary_Learning.html">91 jmlr-2011-The Sample Complexity of Dictionary Learning</a></p>
<p>7 0.25108442 <a title="77-lsi-7" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>8 0.24412479 <a title="77-lsi-8" href="./jmlr-2011-A_Simpler_Approach_to_Matrix_Completion.html">6 jmlr-2011-A Simpler Approach to Matrix Completion</a></p>
<p>9 0.22816627 <a title="77-lsi-9" href="./jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">4 jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<p>10 0.2239152 <a title="77-lsi-10" href="./jmlr-2011-Learning_from_Partial_Labels.html">58 jmlr-2011-Learning from Partial Labels</a></p>
<p>11 0.22055508 <a title="77-lsi-11" href="./jmlr-2011-Learning_Multi-modal_Similarity.html">55 jmlr-2011-Learning Multi-modal Similarity</a></p>
<p>12 0.21913058 <a title="77-lsi-12" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>13 0.199084 <a title="77-lsi-13" href="./jmlr-2011-Computationally_Efficient_Convolved_Multiple_Output_Gaussian_Processes.html">17 jmlr-2011-Computationally Efficient Convolved Multiple Output Gaussian Processes</a></p>
<p>14 0.19542506 <a title="77-lsi-14" href="./jmlr-2011-Proximal_Methods_for_Hierarchical_Sparse_Coding.html">79 jmlr-2011-Proximal Methods for Hierarchical Sparse Coding</a></p>
<p>15 0.18254718 <a title="77-lsi-15" href="./jmlr-2011-Bayesian_Generalized_Kernel_Mixed_Models.html">13 jmlr-2011-Bayesian Generalized Kernel Mixed Models</a></p>
<p>16 0.18163395 <a title="77-lsi-16" href="./jmlr-2011-Unsupervised_Supervised_Learning_II%3A_Margin-Based_Classification_Without_Labels.html">100 jmlr-2011-Unsupervised Supervised Learning II: Margin-Based Classification Without Labels</a></p>
<p>17 0.17661582 <a title="77-lsi-17" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<p>18 0.17528509 <a title="77-lsi-18" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>19 0.16975635 <a title="77-lsi-19" href="./jmlr-2011-Faster_Algorithms_for_Max-Product_Message-Passing.html">34 jmlr-2011-Faster Algorithms for Max-Product Message-Passing</a></p>
<p>20 0.16740148 <a title="77-lsi-20" href="./jmlr-2011-Dirichlet_Process_Mixtures_of_Generalized_Linear_Models.html">24 jmlr-2011-Dirichlet Process Mixtures of Generalized Linear Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/jmlr2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.021), (11, 0.027), (17, 0.05), (22, 0.522), (24, 0.029), (37, 0.055), (39, 0.032), (57, 0.034), (67, 0.032), (70, 0.017), (84, 0.021), (86, 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75138021 <a title="77-lda-1" href="./jmlr-2011-Posterior_Sparsity_in_Unsupervised_Dependency_Parsing.html">77 jmlr-2011-Posterior Sparsity in Unsupervised Dependency Parsing</a></p>
<p>2 0.72417623 <a title="77-lda-2" href="./jmlr-2011-Learning_from_Partial_Labels.html">58 jmlr-2011-Learning from Partial Labels</a></p>
<p>3 0.71390653 <a title="77-lda-3" href="./jmlr-2011-A_Bayesian_Approach_for_Learning_and_Planning_in_Partially_Observable_Markov_Decision_Processes.html">1 jmlr-2011-A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes</a></p>
<p>4 0.29899061 <a title="77-lda-4" href="./jmlr-2011-Natural_Language_Processing_%28Almost%29_from_Scratch.html">68 jmlr-2011-Natural Language Processing (Almost) from Scratch</a></p>
<p>5 0.29741818 <a title="77-lda-5" href="./jmlr-2011-Introduction_to_the_Special_Topic_on_Grammar_Induction%2C_Representation_of_Language_and_Language_Learning.html">46 jmlr-2011-Introduction to the Special Topic on Grammar Induction, Representation of Language and Language Learning</a></p>
<p>6 0.29276419 <a title="77-lda-6" href="./jmlr-2011-Inverse_Reinforcement_Learning_in_Partially_Observable_Environments.html">47 jmlr-2011-Inverse Reinforcement Learning in Partially Observable Environments</a></p>
<p>7 0.28479046 <a title="77-lda-7" href="./jmlr-2011-Internal_Regret_with_Partial_Monitoring%3A_Calibration-Based_Optimal_Algorithms.html">45 jmlr-2011-Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms</a></p>
<p>8 0.28269136 <a title="77-lda-8" href="./jmlr-2011-Bayesian_Co-Training.html">12 jmlr-2011-Bayesian Co-Training</a></p>
<p>9 0.28082949 <a title="77-lda-9" href="./jmlr-2011-Exploiting_Best-Match_Equations_for_Efficient_Reinforcement_Learning.html">33 jmlr-2011-Exploiting Best-Match Equations for Efficient Reinforcement Learning</a></p>
<p>10 0.27899417 <a title="77-lda-10" href="./jmlr-2011-Sparse_Linear_Identifiable_Multivariate_Modeling.html">86 jmlr-2011-Sparse Linear Identifiable Multivariate Modeling</a></p>
<p>11 0.27395985 <a title="77-lda-11" href="./jmlr-2011-Two_Distributed-State_Models_For_Generating_High-Dimensional_Time_Series.html">96 jmlr-2011-Two Distributed-State Models For Generating High-Dimensional Time Series</a></p>
<p>12 0.27212441 <a title="77-lda-12" href="./jmlr-2011-Producing_Power-Law_Distributions_and_Damping_Word_Frequencies_with_Two-Stage_Language_Models.html">78 jmlr-2011-Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models</a></p>
<p>13 0.27092195 <a title="77-lda-13" href="./jmlr-2011-Learning_Transformation_Models_for_Ranking_and_Survival_Analysis.html">56 jmlr-2011-Learning Transformation Models for Ranking and Survival Analysis</a></p>
<p>14 0.27018699 <a title="77-lda-14" href="./jmlr-2011-Exploitation_of_Machine_Learning_Techniques_in_Modelling_Phrase_Movements_for_Machine_Translation.html">32 jmlr-2011-Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</a></p>
<p>15 0.2687825 <a title="77-lda-15" href="./jmlr-2011-Union_Support_Recovery_in_Multi-task_Learning.html">97 jmlr-2011-Union Support Recovery in Multi-task Learning</a></p>
<p>16 0.26745519 <a title="77-lda-16" href="./jmlr-2011-Parameter_Screening_and_Optimisation_for_ILP_using_Designed_Experiments.html">76 jmlr-2011-Parameter Screening and Optimisation for ILP using Designed Experiments</a></p>
<p>17 0.26638234 <a title="77-lda-17" href="./jmlr-2011-Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization.html">8 jmlr-2011-Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>18 0.26548329 <a title="77-lda-18" href="./jmlr-2011-A_Family_of_Simple_Non-Parametric_Kernel_Learning_Algorithms.html">4 jmlr-2011-A Family of Simple Non-Parametric Kernel Learning Algorithms</a></p>
<p>19 0.26143819 <a title="77-lda-19" href="./jmlr-2011-Waffles%3A_A_Machine_Learning_Toolkit.html">102 jmlr-2011-Waffles: A Machine Learning Toolkit</a></p>
<p>20 0.25425574 <a title="77-lda-20" href="./jmlr-2011-Large_Margin_Hierarchical_Classification_with_Mutually_Exclusive_Class_Membership.html">52 jmlr-2011-Large Margin Hierarchical Classification with Mutually Exclusive Class Membership</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
