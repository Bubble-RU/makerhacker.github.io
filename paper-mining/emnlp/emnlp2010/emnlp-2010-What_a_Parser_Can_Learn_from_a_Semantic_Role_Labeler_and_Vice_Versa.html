<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-121" href="#">emnlp2010-121</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</h1>
<br/><p>Source: <a title="emnlp-2010-121-pdf" href="http://aclweb.org/anthology//D/D10/D10-1072.pdf">pdf</a></p><p>Author: Stephen Boxwell ; Dennis Mehay ; Chris Brew</p><p>Abstract: In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. In this paper, we build a system that allows information to flow in both directions. We make use of semantic role predictions in choosing a single-best parse. This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. Our system penalizes parses that give rise to low-scoring semantic roles. To explore the consequences of this we perform two experiments. First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser’s packed chart. For both experiments, the resulting semantic predictions are then used to select parses. Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. We find that SRL performance can be improved over this baseline by selecting parses with likely semantic roles.</p><p>Reference: <a title="emnlp-2010-121-reference" href="../emnlp2010_reference/emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  ,  ,  Abstract In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. [sent-5, score-0.594]
</p><p>2 We make use of semantic role predictions in choosing a single-best parse. [sent-7, score-0.536]
</p><p>3 This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. [sent-8, score-0.776]
</p><p>4 Our system penalizes parses that give rise to low-scoring semantic roles. [sent-9, score-0.464]
</p><p>5 First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. [sent-11, score-0.368]
</p><p>6 Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. [sent-12, score-1.62]
</p><p>7 The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser’s packed chart. [sent-13, score-0.44]
</p><p>8 For both experiments, the resulting semantic predictions are then used to select parses. [sent-14, score-0.364]
</p><p>9 Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. [sent-15, score-0.588]
</p><p>10 We find that SRL performance can be improved over this baseline by selecting parses with  likely semantic roles. [sent-16, score-0.496]
</p><p>11 1 Introduction In the semantic role labeling task, words or groups of words are described in terms of their relations to a predicate. [sent-17, score-0.517]
</p><p>12 For example, the sentence Robin admires Leslie has two semantic role-bearing words: Robin is the agent or experiencer of the admire predicate, and Leslie is the patient. [sent-18, score-0.387]
</p><p>13 These semantic relations are distinct from syntactic relations like subject and object the proper nouns in the sentence Leslie is admired by Robin have the same semantic relationships as Robin admires Leslie, even though the syntax differs. [sent-19, score-0.761]
</p><p>14 Almost all automatic semantic role labeling systems take a syntactic representa–  736 tion of a sentence (taken from an automatic parser or a human annotator), and use the syntactic information to predict semantic roles. [sent-21, score-1.085]
</p><p>15 When a semantic role labeler predicts an incorrect role, it is often due to an error in the parse tree. [sent-22, score-0.883]
</p><p>16 If a semantic role labeling system relies heavily upon syntactic attachment decisions, then it will likely predict that in 1956 describes the time that asbestos was used, rather  than when it ceased to be used. [sent-24, score-0.757]
</p><p>17 , 1993), the Charniak parser (Charniak, 2001), and the C&C; parser (Clark and Curran, 2004) all produce the erroneous parse from Figure 1, the hand-annotated Propbank corpus of verbal semantic roles (Palmer et al. [sent-27, score-1.138]
</p><p>18 , 2005) correctly identifies in 1956 as a temporal modifier of stopped, rather than using. [sent-28, score-0.138]
</p><p>19 This demonstrates that while syntactic attachment decisions like these are difficult for humans and for automatic parsers, a human reader has little difficulty identifying the correct semantic relationship between the temporal modifier and the verbs. [sent-29, score-0.573]
</p><p>20 This is likely due to the fact that the meaning suggested by the parse in Figure 1 is unlikely the reader instinctively feels that a temporal modifier fits better with the verb stop than with the verb use. [sent-30, score-0.335]
</p><p>21 In this paper, we will use the idea that semantic roles predicted by correct parses are more natural than semantic roles predicted by erroneous parses. [sent-31, score-1.711]
</p><p>22 By modifying a state-of-the-art CCG semantic role labeler to predict semantic roles at parse time, or by using it to select from an n-best list, we can prefer analyses that yield likely semantic roles. [sent-32, score-2.004]
</p><p>23 Syntactic analysis is treated not as an autonomous task, but rather as a contributor to the final goal of semantic role labeling. [sent-33, score-0.46]
</p><p>24 –  2  Related Work  There has been a great deal of work in joint parsing and semantic role labeling in recent years. [sent-34, score-0.563]
</p><p>25 HHHHH VB  NP  PP  using  asbestos  in 1956  Figure 1: A parse tree based on the treebank parse of wsj 0003. [sent-47, score-0.46]
</p><p>26 Notice that the temporal adjunct is erroneously attached low. [sent-49, score-0.219]
</p><p>27 In a syntax-based SRL system, this will likely lead to a role prediction error. [sent-50, score-0.124]
</p><p>28 Many of these systems perform joint syntactic and semantic analysis by generating an n-best list of syntactic parses, labeling semantic roles on all of them, then re-ranking these parses by some means. [sent-54, score-1.364]
</p><p>29 Our approach differs from this strategy by abandoning the preliminary ranking and predicting semantic roles at parse time. [sent-55, score-0.937]
</p><p>30 By doing this, we effectively open semantic roles in the entire parse forest to examination by the ranking model, rather than restricting the model to an n-best list generated by a baseline parser. [sent-56, score-0.994]
</p><p>31 3  Why Predicting Semantic Roles in a Packed Chart is Difficult  Predicting semantic roles in the environment of a packed chart is difficult when using an atomic CFG. [sent-58, score-1.244]
</p><p>32 In order to achieve the polynomial efficiency appropriate for widecoverage parsing, it is necessary to “pack” the chart that is, to combine distinct analyses of a given span of words that produce the same category. [sent-59, score-0.294]
</p><p>33 It is straightforward to read off the highest scoring parse from a packed chart, and similarly routine to generate an n-best list containing a highly-ranked subset of the parses. [sent-62, score-0.437]
</p><p>34 However, a packed chart built on an atomic CFG does not make available all of the features that are important to many CFG-based SRL systems. [sent-63, score-0.511]
</p><p>35 In particular, the very useful treepath feature, which lists the categories touched by walking the tree from the predicate to the target word, only makes sense when you have a complete tree, so cannot easily be computed from the chart (Figure 2). [sent-64, score-0.332]
</p><p>36 H NP pPePople  PPPP  More intelligent people  V PsPaw  PPPPP  saw kids with telescopes  Figure 2: In the context of a packed chart, it is meaningless to speak of a treepath between saw and people because multiple analyses are “packed” under a single category. [sent-71, score-0.336]
</p><p>37 be lexicalized with their headwords, and this information would be useful in role labeling but even this misses vital subcategorization information that would be available in the complete parse. [sent-72, score-0.216]
</p><p>38 An ideal formalism for our purpose would condense into the category label a wide range of information about combinatory potential, heads, and syntactic dependencies. [sent-73, score-0.25]
</p><p>39 At the same time it should allow the creation of a packed chart, come with labeled training data, and have a high-quality parser and semantic role labeler already available. [sent-74, score-0.998]
</p><p>40 –  4  Combinatory Categorial Grammar  Combinatory Categorial Grammar (Steedman, 2000) is  a grammar formalism that describes words in terms of their combinatory potential. [sent-76, score-0.156]
</p><p>41 For example, determiners belong to the category np/n, or “the category of words that become noun phrases when combined with a noun to the right”. [sent-77, score-0.112]
</p><p>42 The rightmost category indicates the argument that the category is seeking, the leftmost category indicates the result of combining this category with its argument, and the slash (/ or \) indicates the direction of acrogmumbiennatti,o ann. [sent-78, score-0.224]
</p><p>43 Categories can \ be) ninedstiecdat wesi tthhein d deiraechct oiotnhe or:f a transitive verb like devoured belongs to the category  np/n pn>(s\np)/snpxs\n p x/n xp nx> <  The man devoured the steak  Figure 3: A simple CCG derivation. [sent-79, score-0.158]
</p><p>44 itvehFoamerti sgonyitsuacrelmpsvruoeinlto-  make semantic predictions at parse time, inside a packed chart, before the complete derivation is available. [sent-83, score-0.914]
</p><p>45 h)ye,Cstlremeumaovcmi (nalethglnayto,t ndhilseay,ptlfetoehncaedatueplnr fe ecsayditf cuhear eatesturi(resfel aysat ctoauoncruehntshetdtehatascot “talmhroe npxnpx\npxs/npx>   s[dcl]\np> s[dcl]< Figure 5: The single-best analysis for He will join Nov 27th according to the baseline model. [sent-85, score-0.119]
</p><p>46 Notice that the temporal adjunct is attached high, leading the semantic role labeler to fail to identify ArgM-TMP. [sent-86, score-0.806]
</p><p>47 This analysis correctly predicts Nov 27th as the ArgM-TMP of join, and the semantic model correctly re-ranks this analysis to the single-best position. [sent-89, score-0.39]
</p><p>48 common in the treebank, the baseline model identifies it as the single-best parse, and identifies the derivation in figure 6 as the second-best parse. [sent-90, score-0.172]
</p><p>49 The semantic model, however, correctly recognizes that the semantic roles predicted by the derivation in Figure 6 are superior to those predicted by the derivation in figure 5. [sent-91, score-1.299]
</p><p>50 This demonstrates how a second or third-best parse according to the baseline model can be greatly superior to the single-best in terms of semantics. [sent-92, score-0.198]
</p><p>51 One possible solution to this is to simply choose a single best derivation directly from the packed chart using the semantic model, eschewing the baseline model entirely except for breaking ties. [sent-96, score-0.929]
</p><p>52 In this approach, we use the local SRL model described in section 6 to predict semantic roles at parse time, inside the packed chart. [sent-97, score-1.228]
</p><p>53 This frees us from the need to have a complete derivation (as in the n-best list approach in Section 7). [sent-98, score-0.147]
</p><p>54 We use the semantic model to choose a single-best parse from the packed chart, then we pass this complete parse through the global SRL model to give it all the benefits afforded to the parses in the n-best approach. [sent-99, score-1.068]
</p><p>55 The results for the semantic model compared to the baseline model are shown in table 3. [sent-100, score-0.368]
</p><p>56 81 Table 3: A comparison ofthe performance ofthe baseline model and the semantic model on semantic role labeling. [sent-104, score-0.828]
</p><p>57 The semantic model, when unrestrained by the baseline model, performs substantially worse. [sent-105, score-0.368]
</p><p>58 the semantic model performs considerably worse than the baseline model. [sent-106, score-0.368]
</p><p>59 To understand why, it is necessary to remember that the semantic model uses only semantic features probabilities of rule applications are not considered. [sent-107, score-0.672]
</p><p>60 Therefore, the semantic model is perfectly happy to predict derivations with sequences of highly unlikely rule applications so long as they predict a role that the model has been trained to prefer. [sent-108, score-0.665]
</p><p>61 Apparently, the reckless pursuit of appealing semantic roles can ultimately harm semantic role labeling accuracy as well as parse accuracy. [sent-109, score-1.501]
</p><p>62 Because the averaged perceptron semantic model is not sensitive to the relationships between different semantic roles, and because Arg1 of name is a “good” semantic role, the semantic model predicts as many of them as it can. [sent-111, score-1.398]
</p><p>63 The semantic model, however, would rather predict two semantic roles than just one (because study:Arg0 is a highly appealing semantic role). [sent-117, score-1.504]
</p><p>64 Once again, the pursuit of appealing semantic roles has led the system astray. [sent-118, score-0.818]
</p><p>65 We have shown in Section 7 that the semantic model can improve SRL performance when it is constrained to the most likely PCFG derivations, but enumerating n-best lists is costly and cumbersome. [sent-119, score-0.336]
</p><p>66 We can, however, combine the semantic model with the baseline PCFG. [sent-120, score-0.368]
</p><p>67 We first identify the highest-scoring parse according to the PCFG model. [sent-122, score-0.166]
</p><p>68 This parse will be used in later processing unless we are able to identify another parse that satisfies the following criteria: 1. [sent-123, score-0.332]
</p><p>69 It must be closely related to the parse that has the best score according to the semantic model. [sent-124, score-0.502]
</p><p>70 To identify such parses, we ask the chart unpacking algorithm to generate all the parses that can be reached by making up to five attachment changes to this semantically preferred parse no more. [sent-125, score-0.604]
</p><p>71 That is, the single-best parse from the semantic model must satisfy α  log P(sem) > log P(baseline) + log(α) where the  α  value is tuned on the development set. [sent-129, score-0.502]
</p><p>72 If no semantically preferred parse meets the above criteria, the single-best PCFG parse is used. [sent-130, score-0.332]
</p><p>73 We find that the PCFG-preferred parse is used about 35% of the time and an alternative used instead about 65% of the time. [sent-131, score-0.166]
</p><p>74 0513  Table 4: SRL accuracy when the semantic model is constrained by the baseline model  9  Results and Discussion  We use the method for calculating SRL performance described in the CoNNL 2008 and 2009 shared tasks. [sent-140, score-0.401]
</p><p>75 However, because the semantic role labeler we use was not designed to work with Nombank (and it is difficult to separate Nombank and Propbank predicates from the publicly released shared task output), it is not feasible to compare results with the candidate systems described there. [sent-141, score-0.744]
</p><p>76 Notice that Rudolph Agnew, 61 and the former chairman is erroneously treated as a three-way conjunction, assigning semantic roles to all three heads. [sent-143, score-0.86]
</p><p>77 The test set scores of both of our experimental  parser  models are lower than their development set scores,where the n-best model outperforms even the Clark and Curran parser in the SRL task. [sent-149, score-0.196]
</p><p>78 We anticipate the opportunity to further explore better ways of determining n-best list size. [sent-153, score-0.104]
</p><p>79 We also anticipate the possibility of integrating the semantic model with a state-of-the-art CCG parser, potentially freeing the ranker from the limitations of a simple PCFG baseline. [sent-154, score-0.372]
</p><p>80 Because the parser can dig deeply into the chart, it is capable of choosing a parse that predicts only semantic roles that it is highly confi-  dent about. [sent-156, score-1.099]
</p><p>81 By choosing these parses (and not parses with less attractive semantic roles), the model can maximize the average score of the semantic roles it predicts. [sent-157, score-1.373]
</p><p>82 This tendency towards identifying only the most certain roles is consistent with high-precision low-recall results. [sent-158, score-0.397]
</p><p>83 The n-best parser has a much more restricted set of semantic roles from parses more closely resembling the single-best parse, and therefore is less likely to be presented with the opportunity to choose parses that do away with less likely (but still reasonable) roles. [sent-159, score-1.121]
</p><p>84 10  Conclusions and Future Work  In this paper, we discuss the procedure for identifying semantic roles at parse time, and using these roles to guide the parse. [sent-160, score-1.296]
</p><p>85 We demonstrate that using semantic roles to guide parsing can improve overall SRL performance, but that these same benefits can be realized by re-ranking an n-best list with the same model. [sent-161, score-0.813]
</p><p>86 Regardless, there are several reasons why it is useful to have the ability to predict semantic roles inside the chart. [sent-162, score-0.825]
</p><p>87 Predicting semantic roles inside the chart could be used to perform SRL on very long or unstructured passages. [sent-163, score-1.013]
</p><p>88 The Charniak parser is a CFG-style parser, making labeled dependency non-applicable. [sent-175, score-0.098]
</p><p>89 Most parsing research on the Penn Treebank (the present work included) focuses on sentences of 40 words or less, because parsing longer sentences requires an unacceptably large amount of computing resources. [sent-176, score-0.092]
</p><p>90 In practice, however, semantic roles are rarely very distant from their predicates – generally they are only a few words away; often they are adjacent. [sent-177, score-0.781]
</p><p>91 In long sentences, the prediction of an entire parse may be unnecessary for the purposes of  SRL. [sent-178, score-0.166]
</p><p>92 The CKY parsing algorithm works by first predicting all constituents spanning two words, then all constituents spanning three words, then four, and so on until it predicts constituents covering the whole sentence. [sent-179, score-0.308]
</p><p>93 By setting a maximum constituent size (say, ten or fifteen), we could abandon the goal of completing a spanning analysis in favor of identifying semantic roles in the neighborhood of their predicates, eliminating the need to unpack the chart at all. [sent-180, score-1.064]
</p><p>94 Alternately, roles predicted in the chart could even be incorporated into a low-precision-high-recall information retrieval system seeking a particular semantic relationship by scanning the chart for a particular semantic role. [sent-183, score-1.634]
</p><p>95 Another use for the packed forest of semantic roles could be to predict complete sets of roles for a given sentence using a constraint based method like integer linear programming. [sent-184, score-1.46]
</p><p>96 Integer linear programming takes a large number of candidate results (like semantic roles), and applies a set of constraints over them (like “roles may not overlap” or “no more than one of each role is allowed in each sentence”) to find the optimal set. [sent-185, score-0.46]
</p><p>97 Doing so could  743 eliminate the need to unpack the chart at all, effectively producing semantic roles without committing to a single syntactic analysis. [sent-186, score-1.098]
</p><p>98 Brutus: A semantic role labeling system incorporating CCG, CFG, and Dependency features. [sent-192, score-0.517]
</p><p>99 The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages. [sent-234, score-0.369]
</p><p>100 The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. [sent-284, score-0.453]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('roles', 0.397), ('semantic', 0.336), ('np', 0.329), ('srl', 0.254), ('chart', 0.246), ('packed', 0.237), ('labeler', 0.203), ('parse', 0.166), ('parses', 0.128), ('dcl', 0.127), ('role', 0.124), ('combinatory', 0.118), ('leslie', 0.102), ('parser', 0.098), ('ccg', 0.096), ('join', 0.087), ('pcfg', 0.086), ('meyers', 0.078), ('robin', 0.078), ('derivation', 0.078), ('erroneously', 0.076), ('mehay', 0.076), ('categorial', 0.068), ('nov', 0.065), ('nombank', 0.065), ('attachment', 0.064), ('temporal', 0.059), ('predict', 0.058), ('labeling', 0.057), ('category', 0.056), ('derivations', 0.055), ('predicts', 0.054), ('admires', 0.051), ('agnew', 0.051), ('alternately', 0.051), ('asbestos', 0.051), ('boxwell', 0.051), ('chairman', 0.051), ('conj', 0.051), ('devoured', 0.051), ('hhhhh', 0.051), ('lorillard', 0.051), ('treepath', 0.051), ('unpack', 0.051), ('choosing', 0.048), ('modifier', 0.048), ('predicates', 0.048), ('analyses', 0.048), ('parsing', 0.046), ('clause', 0.046), ('pursuit', 0.044), ('rudolph', 0.044), ('adjunct', 0.044), ('erroneous', 0.043), ('charniak', 0.043), ('clark', 0.042), ('appealing', 0.041), ('curran', 0.041), ('treebank', 0.041), ('attached', 0.04), ('stopped', 0.039), ('haji', 0.039), ('propbank', 0.039), ('rel', 0.039), ('formalism', 0.038), ('predicting', 0.038), ('syntactic', 0.038), ('predicted', 0.037), ('wsj', 0.036), ('flow', 0.036), ('seeking', 0.036), ('johansson', 0.036), ('anticipate', 0.036), ('coordination', 0.036), ('dennis', 0.036), ('complete', 0.035), ('unlikely', 0.034), ('spanning', 0.034), ('constituents', 0.034), ('list', 0.034), ('opportunity', 0.034), ('surdeanu', 0.034), ('arquez', 0.034), ('resembles', 0.034), ('inside', 0.034), ('shared', 0.033), ('attaching', 0.032), ('baseline', 0.032), ('identifies', 0.031), ('eliminate', 0.03), ('punyakanok', 0.03), ('penn', 0.029), ('restricting', 0.029), ('heavily', 0.029), ('stephen', 0.029), ('predictions', 0.028), ('beam', 0.028), ('atomic', 0.028), ('reader', 0.028), ('heads', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="121-tfidf-1" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>Author: Stephen Boxwell ; Dennis Mehay ; Chris Brew</p><p>Abstract: In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. In this paper, we build a system that allows information to flow in both directions. We make use of semantic role predictions in choosing a single-best parse. This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. Our system penalizes parses that give rise to low-scoring semantic roles. To explore the consequences of this we perform two experiments. First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser’s packed chart. For both experiments, the resulting semantic predictions are then used to select parses. Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. We find that SRL performance can be improved over this baseline by selecting parses with likely semantic roles.</p><p>2 0.23153965 <a title="121-tfidf-2" href="./emnlp-2010-Joint_Inference_for_Bilingual_Semantic_Role_Labeling.html">68 emnlp-2010-Joint Inference for Bilingual Semantic Role Labeling</a></p>
<p>Author: Tao Zhuang ; Chengqing Zong</p><p>Abstract: We show that jointly performing semantic role labeling (SRL) on bitext can improve SRL results on both sides. In our approach, we use monolingual SRL systems to produce argument candidates for predicates in bitext at first. Then, we simultaneously generate SRL results for two sides of bitext using our joint inference model. Our model prefers the bilingual SRL result that is not only reasonable on each side of bitext, but also has more consistent argument structures between two sides. To evaluate the consistency between two argument structures, we also formulate a log-linear model to compute the probability of aligning two arguments. We have experimented with our model on Chinese-English parallel PropBank data. Using our joint inference model, F1 scores of SRL results on Chinese and English text achieve 79.53% and 77.87% respectively, which are 1.52 and 1.74 points higher than the results of baseline monolingual SRL combination systems respectively.</p><p>3 0.20419674 <a title="121-tfidf-3" href="./emnlp-2010-SRL-Based_Verb_Selection_for_ESL.html">95 emnlp-2010-SRL-Based Verb Selection for ESL</a></p>
<p>Author: Xiaohua Liu ; Bo Han ; Kuan Li ; Stephan Hyeonjun Stiller ; Ming Zhou</p><p>Abstract: In this paper we develop an approach to tackle the problem of verb selection for learners of English as a second language (ESL) by using features from the output of Semantic Role Labeling (SRL). Unlike existing approaches to verb selection that use local features such as n-grams, our approach exploits semantic features which explicitly model the usage context of the verb. The verb choice highly depends on its usage context which is not consistently captured by local features. We then combine these semantic features with other local features under the generalized perceptron learning framework. Experiments on both indomain and out-of-domain corpora show that our approach outperforms the baseline and achieves state-of-the-art performance. 1</p><p>4 0.18668404 <a title="121-tfidf-4" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>Author: Tom Kwiatkowksi ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: This paper addresses the problem of learning to map sentences to logical form, given training data consisting of natural language sentences paired with logical representations of their meaning. Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method. The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences. We use higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develop an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model. Experiments demonstrate high accuracy on benchmark data sets in four languages with two different meaning representations.</p><p>5 0.16660295 <a title="121-tfidf-5" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>Author: Eugene Charniak</p><p>Abstract: We present a new syntactic parser that works left-to-right and top down, thus maintaining a fully-connected parse tree for a few alternative parse hypotheses. All of the commonly used statistical parsers use context-free dynamic programming algorithms and as such work bottom up on the entire sentence. Thus they only find a complete fully connected parse at the very end. In contrast, both subjective and experimental evidence show that people understand a sentence word-to-word as they go along, or close to it. The constraint that the parser keeps one or more fully connected syntactic trees is intended to operationalize this cognitive fact. Our parser achieves a new best result for topdown parsers of 89.4%,a 20% error reduction over the previous single-parser best result for parsers of this type of 86.8% (Roark, 2001) . The improved performance is due to embracing the very large feature set available in exchange for giving up dynamic programming.</p><p>6 0.15634461 <a title="121-tfidf-6" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>7 0.13594201 <a title="121-tfidf-7" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>8 0.11122623 <a title="121-tfidf-8" href="./emnlp-2010-Efficient_Incremental_Decoding_for_Tree-to-String_Translation.html">42 emnlp-2010-Efficient Incremental Decoding for Tree-to-String Translation</a></p>
<p>9 0.098678119 <a title="121-tfidf-9" href="./emnlp-2010-Automatic_Discovery_of_Manner_Relations_and_its_Applications.html">21 emnlp-2010-Automatic Discovery of Manner Relations and its Applications</a></p>
<p>10 0.091339238 <a title="121-tfidf-10" href="./emnlp-2010-SCFG_Decoding_Without_Binarization.html">94 emnlp-2010-SCFG Decoding Without Binarization</a></p>
<p>11 0.08115872 <a title="121-tfidf-11" href="./emnlp-2010-Soft_Syntactic_Constraints_for_Hierarchical_Phrase-Based_Translation_Using_Latent_Syntactic_Distributions.html">98 emnlp-2010-Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions</a></p>
<p>12 0.074740134 <a title="121-tfidf-12" href="./emnlp-2010-Uptraining_for_Accurate_Deterministic_Question_Parsing.html">115 emnlp-2010-Uptraining for Accurate Deterministic Question Parsing</a></p>
<p>13 0.070212498 <a title="121-tfidf-13" href="./emnlp-2010-Unsupervised_Discovery_of_Negative_Categories_in_Lexicon_Bootstrapping.html">112 emnlp-2010-Unsupervised Discovery of Negative Categories in Lexicon Bootstrapping</a></p>
<p>14 0.067314103 <a title="121-tfidf-14" href="./emnlp-2010-Improved_Fully_Unsupervised_Parsing_with_Zoomed_Learning.html">60 emnlp-2010-Improved Fully Unsupervised Parsing with Zoomed Learning</a></p>
<p>15 0.0653954 <a title="121-tfidf-15" href="./emnlp-2010-Unsupervised_Induction_of_Tree_Substitution_Grammars_for_Dependency_Parsing.html">113 emnlp-2010-Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing</a></p>
<p>16 0.064373732 <a title="121-tfidf-16" href="./emnlp-2010-Non-Isomorphic_Forest_Pair_Translation.html">86 emnlp-2010-Non-Isomorphic Forest Pair Translation</a></p>
<p>17 0.060333043 <a title="121-tfidf-17" href="./emnlp-2010-Effects_of_Empty_Categories_on_Machine_Translation.html">40 emnlp-2010-Effects of Empty Categories on Machine Translation</a></p>
<p>18 0.053853262 <a title="121-tfidf-18" href="./emnlp-2010-Evaluating_the_Impact_of_Alternative_Dependency_Graph_Encodings_on_Solving_Event_Extraction_Tasks.html">46 emnlp-2010-Evaluating the Impact of Alternative Dependency Graph Encodings on Solving Event Extraction Tasks</a></p>
<p>19 0.050770875 <a title="121-tfidf-19" href="./emnlp-2010-Confidence_in_Structured-Prediction_Using_Confidence-Weighted_Models.html">30 emnlp-2010-Confidence in Structured-Prediction Using Confidence-Weighted Models</a></p>
<p>20 0.047353473 <a title="121-tfidf-20" href="./emnlp-2010-Self-Training_with_Products_of_Latent_Variable_Grammars.html">96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.21), (1, 0.086), (2, 0.278), (3, 0.233), (4, 0.108), (5, 0.132), (6, 0.09), (7, -0.391), (8, 0.138), (9, 0.008), (10, 0.062), (11, 0.085), (12, -0.11), (13, 0.032), (14, 0.022), (15, -0.008), (16, 0.036), (17, -0.035), (18, 0.074), (19, -0.06), (20, -0.027), (21, 0.117), (22, 0.156), (23, -0.04), (24, -0.027), (25, 0.029), (26, -0.106), (27, -0.108), (28, -0.042), (29, -0.048), (30, 0.043), (31, 0.009), (32, 0.027), (33, -0.076), (34, -0.079), (35, 0.11), (36, -0.094), (37, -0.083), (38, 0.043), (39, -0.087), (40, -0.015), (41, 0.005), (42, 0.015), (43, -0.074), (44, 0.015), (45, -0.075), (46, 0.032), (47, 0.027), (48, -0.021), (49, -0.004)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97879827 <a title="121-lsi-1" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>Author: Stephen Boxwell ; Dennis Mehay ; Chris Brew</p><p>Abstract: In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. In this paper, we build a system that allows information to flow in both directions. We make use of semantic role predictions in choosing a single-best parse. This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. Our system penalizes parses that give rise to low-scoring semantic roles. To explore the consequences of this we perform two experiments. First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser’s packed chart. For both experiments, the resulting semantic predictions are then used to select parses. Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. We find that SRL performance can be improved over this baseline by selecting parses with likely semantic roles.</p><p>2 0.66519916 <a title="121-lsi-2" href="./emnlp-2010-Joint_Inference_for_Bilingual_Semantic_Role_Labeling.html">68 emnlp-2010-Joint Inference for Bilingual Semantic Role Labeling</a></p>
<p>Author: Tao Zhuang ; Chengqing Zong</p><p>Abstract: We show that jointly performing semantic role labeling (SRL) on bitext can improve SRL results on both sides. In our approach, we use monolingual SRL systems to produce argument candidates for predicates in bitext at first. Then, we simultaneously generate SRL results for two sides of bitext using our joint inference model. Our model prefers the bilingual SRL result that is not only reasonable on each side of bitext, but also has more consistent argument structures between two sides. To evaluate the consistency between two argument structures, we also formulate a log-linear model to compute the probability of aligning two arguments. We have experimented with our model on Chinese-English parallel PropBank data. Using our joint inference model, F1 scores of SRL results on Chinese and English text achieve 79.53% and 77.87% respectively, which are 1.52 and 1.74 points higher than the results of baseline monolingual SRL combination systems respectively.</p><p>3 0.6243335 <a title="121-lsi-3" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>Author: Tom Kwiatkowksi ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: This paper addresses the problem of learning to map sentences to logical form, given training data consisting of natural language sentences paired with logical representations of their meaning. Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method. The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences. We use higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develop an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model. Experiments demonstrate high accuracy on benchmark data sets in four languages with two different meaning representations.</p><p>4 0.52925581 <a title="121-lsi-4" href="./emnlp-2010-SRL-Based_Verb_Selection_for_ESL.html">95 emnlp-2010-SRL-Based Verb Selection for ESL</a></p>
<p>Author: Xiaohua Liu ; Bo Han ; Kuan Li ; Stephan Hyeonjun Stiller ; Ming Zhou</p><p>Abstract: In this paper we develop an approach to tackle the problem of verb selection for learners of English as a second language (ESL) by using features from the output of Semantic Role Labeling (SRL). Unlike existing approaches to verb selection that use local features such as n-grams, our approach exploits semantic features which explicitly model the usage context of the verb. The verb choice highly depends on its usage context which is not consistently captured by local features. We then combine these semantic features with other local features under the generalized perceptron learning framework. Experiments on both indomain and out-of-domain corpora show that our approach outperforms the baseline and achieves state-of-the-art performance. 1</p><p>5 0.51964092 <a title="121-lsi-5" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>Author: Jackie Chi Kit Cheung ; Gerald Penn</p><p>Abstract: Syntactic consistency is the preference to reuse a syntactic construction shortly after its appearance in a discourse. We present an analysis of the WSJ portion of the Penn Treebank, and show that syntactic consistency is pervasive across productions with various lefthand side nonterminals. Then, we implement a reranking constituent parser that makes use of extra-sentential context in its feature set. Using a linear-chain conditional random field, we improve parsing accuracy over the generative baseline parser on the Penn Treebank WSJ corpus, rivalling a similar model that does not make use of context. We show that the context-aware and the context-ignorant rerankers perform well on different subsets of the evaluation data, suggesting a combined approach would provide further improvement. We also compare parses made by models, and suggest that context can be useful for parsing by capturing structural dependencies between sentences as opposed to lexically governed dependencies.</p><p>6 0.48913884 <a title="121-lsi-6" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>7 0.46280208 <a title="121-lsi-7" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>8 0.3509233 <a title="121-lsi-8" href="./emnlp-2010-Automatic_Discovery_of_Manner_Relations_and_its_Applications.html">21 emnlp-2010-Automatic Discovery of Manner Relations and its Applications</a></p>
<p>9 0.33046979 <a title="121-lsi-9" href="./emnlp-2010-Efficient_Incremental_Decoding_for_Tree-to-String_Translation.html">42 emnlp-2010-Efficient Incremental Decoding for Tree-to-String Translation</a></p>
<p>10 0.30853409 <a title="121-lsi-10" href="./emnlp-2010-SCFG_Decoding_Without_Binarization.html">94 emnlp-2010-SCFG Decoding Without Binarization</a></p>
<p>11 0.30112714 <a title="121-lsi-11" href="./emnlp-2010-Improved_Fully_Unsupervised_Parsing_with_Zoomed_Learning.html">60 emnlp-2010-Improved Fully Unsupervised Parsing with Zoomed Learning</a></p>
<p>12 0.26424837 <a title="121-lsi-12" href="./emnlp-2010-Effects_of_Empty_Categories_on_Machine_Translation.html">40 emnlp-2010-Effects of Empty Categories on Machine Translation</a></p>
<p>13 0.25738013 <a title="121-lsi-13" href="./emnlp-2010-Soft_Syntactic_Constraints_for_Hierarchical_Phrase-Based_Translation_Using_Latent_Syntactic_Distributions.html">98 emnlp-2010-Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions</a></p>
<p>14 0.22890835 <a title="121-lsi-14" href="./emnlp-2010-A_Unified_Framework_for_Scope_Learning_via_Simplified_Shallow_Semantic_Parsing.html">15 emnlp-2010-A Unified Framework for Scope Learning via Simplified Shallow Semantic Parsing</a></p>
<p>15 0.22448047 <a title="121-lsi-15" href="./emnlp-2010-Unsupervised_Discovery_of_Negative_Categories_in_Lexicon_Bootstrapping.html">112 emnlp-2010-Unsupervised Discovery of Negative Categories in Lexicon Bootstrapping</a></p>
<p>16 0.21980886 <a title="121-lsi-16" href="./emnlp-2010-A_Mixture_Model_with_Sharing_for_Lexical_Semantics.html">7 emnlp-2010-A Mixture Model with Sharing for Lexical Semantics</a></p>
<p>17 0.20215794 <a title="121-lsi-17" href="./emnlp-2010-Uptraining_for_Accurate_Deterministic_Question_Parsing.html">115 emnlp-2010-Uptraining for Accurate Deterministic Question Parsing</a></p>
<p>18 0.20140323 <a title="121-lsi-18" href="./emnlp-2010-WikiWars%3A_A_New_Corpus_for_Research_on_Temporal_Expressions.html">122 emnlp-2010-WikiWars: A New Corpus for Research on Temporal Expressions</a></p>
<p>19 0.20005897 <a title="121-lsi-19" href="./emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words.html">117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</a></p>
<p>20 0.1962826 <a title="121-lsi-20" href="./emnlp-2010-Constraints_Based_Taxonomic_Relation_Classification.html">31 emnlp-2010-Constraints Based Taxonomic Relation Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.01), (12, 0.047), (29, 0.07), (30, 0.017), (52, 0.018), (56, 0.055), (62, 0.012), (66, 0.061), (72, 0.037), (76, 0.551), (87, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95040852 <a title="121-lda-1" href="./emnlp-2010-An_Approach_of_Generating_Personalized_Views_from_Normalized_Electronic_Dictionaries_%3A_A_Practical_Experiment_on_Arabic_Language.html">16 emnlp-2010-An Approach of Generating Personalized Views from Normalized Electronic Dictionaries : A Practical Experiment on Arabic Language</a></p>
<p>Author: Aida Khemakhem ; Bilel Gargouri ; Abdelmajid Ben Hamadou</p><p>Abstract: Electronic dictionaries covering all natural language levels are very relevant for the human use as well as for the automatic processing use, namely those constructed with respect to international standards. Such dictionaries are characterized by a complex structure and an important access time when using a querying system. However, the need of a user is generally limited to a part of such a dictionary according to his domain and expertise level which corresponds to a specialized dictionary. Given the importance of managing a unified dictionary and considering the personalized needs of users, we propose an approach for generating personalized views starting from a normalized dictionary with respect to Lexical Markup Framework LMF-ISO 24613 norm. This approach provides the re-use of already defined views for a community of users by managing their profiles information and promoting the materialization of the generated views. It is composed of four main steps: (i) the projection of data categories controlled by a set of constraints (related to the user‟s profiles), (ii) the selection of values with consistency checking, (iii) the automatic generation of the query‟s model and finally, (iv) the refinement of the view. The proposed approach was con- solidated by carrying out an experiment on an LMF normalized Arabic dictionary. 1</p><p>same-paper 2 0.91697687 <a title="121-lda-2" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>Author: Stephen Boxwell ; Dennis Mehay ; Chris Brew</p><p>Abstract: In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. In this paper, we build a system that allows information to flow in both directions. We make use of semantic role predictions in choosing a single-best parse. This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. Our system penalizes parses that give rise to low-scoring semantic roles. To explore the consequences of this we perform two experiments. First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser’s packed chart. For both experiments, the resulting semantic predictions are then used to select parses. Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. We find that SRL performance can be improved over this baseline by selecting parses with likely semantic roles.</p><p>3 0.68956906 <a title="121-lda-3" href="./emnlp-2010-Effects_of_Empty_Categories_on_Machine_Translation.html">40 emnlp-2010-Effects of Empty Categories on Machine Translation</a></p>
<p>Author: Tagyoung Chung ; Daniel Gildea</p><p>Abstract: We examine effects that empty categories have on machine translation. Empty categories are elements in parse trees that lack corresponding overt surface forms (words) such as dropped pronouns and markers for control constructions. We start by training machine translation systems with manually inserted empty elements. We find that inclusion of some empty categories in training data improves the translation result. We expand the experiment by automatically inserting these elements into a larger data set using various methods and training on the modified corpus. We show that even when automatic prediction of null elements is not highly accurate, it nevertheless improves the end translation result.</p><p>4 0.67784369 <a title="121-lda-4" href="./emnlp-2010-Classifying_Dialogue_Acts_in_One-on-One_Live_Chats.html">26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</a></p>
<p>Author: Su Nam Kim ; Lawrence Cavedon ; Timothy Baldwin</p><p>Abstract: We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. In particular, we investigate the effectiveness of various features and machine learners for this task. While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data.</p><p>5 0.38348156 <a title="121-lda-5" href="./emnlp-2010-Automatic_Discovery_of_Manner_Relations_and_its_Applications.html">21 emnlp-2010-Automatic Discovery of Manner Relations and its Applications</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: This paper presents a method for the automatic discovery of MANNER relations from text. An extended definition of MANNER is proposed, including restrictions on the sorts of concepts that can be part of its domain and range. The connections with other relations and the lexico-syntactic patterns that encode MANNER are analyzed. A new feature set specialized on MANNER detection is depicted and justified. Experimental results show improvement over previous attempts to extract MANNER. Combinations of MANNER with other semantic relations are also discussed.</p><p>6 0.38208148 <a title="121-lda-6" href="./emnlp-2010-Fusing_Eye_Gaze_with_Speech_Recognition_Hypotheses_to_Resolve_Exophoric_References_in_Situated_Dialogue.html">53 emnlp-2010-Fusing Eye Gaze with Speech Recognition Hypotheses to Resolve Exophoric References in Situated Dialogue</a></p>
<p>7 0.37244058 <a title="121-lda-7" href="./emnlp-2010-Efficient_Incremental_Decoding_for_Tree-to-String_Translation.html">42 emnlp-2010-Efficient Incremental Decoding for Tree-to-String Translation</a></p>
<p>8 0.36906561 <a title="121-lda-8" href="./emnlp-2010-Soft_Syntactic_Constraints_for_Hierarchical_Phrase-Based_Translation_Using_Latent_Syntactic_Distributions.html">98 emnlp-2010-Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions</a></p>
<p>9 0.36667117 <a title="121-lda-9" href="./emnlp-2010-Context_Comparison_of_Bursty_Events_in_Web_Search_and_Online_Media.html">32 emnlp-2010-Context Comparison of Bursty Events in Web Search and Online Media</a></p>
<p>10 0.35695916 <a title="121-lda-10" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>11 0.35468751 <a title="121-lda-11" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>12 0.35168707 <a title="121-lda-12" href="./emnlp-2010-SCFG_Decoding_Without_Binarization.html">94 emnlp-2010-SCFG Decoding Without Binarization</a></p>
<p>13 0.3501001 <a title="121-lda-13" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>14 0.34368426 <a title="121-lda-14" href="./emnlp-2010-Improved_Fully_Unsupervised_Parsing_with_Zoomed_Learning.html">60 emnlp-2010-Improved Fully Unsupervised Parsing with Zoomed Learning</a></p>
<p>15 0.34121463 <a title="121-lda-15" href="./emnlp-2010-Towards_Conversation_Entailment%3A_An_Empirical_Investigation.html">107 emnlp-2010-Towards Conversation Entailment: An Empirical Investigation</a></p>
<p>16 0.33966571 <a title="121-lda-16" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>17 0.33594093 <a title="121-lda-17" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>18 0.33069795 <a title="121-lda-18" href="./emnlp-2010-Evaluating_the_Impact_of_Alternative_Dependency_Graph_Encodings_on_Solving_Event_Extraction_Tasks.html">46 emnlp-2010-Evaluating the Impact of Alternative Dependency Graph Encodings on Solving Event Extraction Tasks</a></p>
<p>19 0.32365909 <a title="121-lda-19" href="./emnlp-2010-Joint_Inference_for_Bilingual_Semantic_Role_Labeling.html">68 emnlp-2010-Joint Inference for Bilingual Semantic Role Labeling</a></p>
<p>20 0.32125211 <a title="121-lda-20" href="./emnlp-2010-A_Game-Theoretic_Approach_to_Generating_Spatial_Descriptions.html">4 emnlp-2010-A Game-Theoretic Approach to Generating Spatial Descriptions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
