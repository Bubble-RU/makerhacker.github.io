<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 emnlp-2010-Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-37" href="#">emnlp2010-37</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>37 emnlp-2010-Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks</h1>
<br/><p>Source: <a title="emnlp-2010-37-pdf" href="http://aclweb.org/anthology//D/D10/D10-1098.pdf">pdf</a></p><p>Author: Laura Chiticariu ; Rajasekar Krishnamurthy ; Yunyao Li ; Frederick Reiss ; Shivakumar Vaithyanathan</p><p>Abstract: Named-entity recognition (NER) is an important task required in a wide variety of applications. While rule-based systems are appealing due to their well-known “explainability,” most, if not all, state-of-the-art results for NER tasks are based on machine learning techniques. Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition? Specifically, we have designed and implemented a high-level language NERL on top of SystemT, a general-purpose algebraic information extraction system. NERL is tuned to the needs of NER tasks and simplifies the process of building, understanding, and customizing complex rule-based named-entity annotators. We show that these customized annotators match or outperform the best published results achieved with machine learning techniques. These results confirm that we can reap the benefits of rule-based extractors’ explainability without sacrificing accuracy. We conclude by discussing lessons learned while building and customizing complex rule-based annotators and outlining several research directions towards facilitating rule development.</p><p>Reference: <a title="emnlp-2010-37-reference" href="../emnlp2010_reference/emnlp-2010-Domain_Adaptation_of_Rule-Based_Annotators_for_Named-Entity_Recognition_Tasks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks Laura Chiticariu  Rajasekar Krishnamurthy Yunyao Li Frederick Reiss Shivakumar Vaithyanathan IBM Research Almaden 650 Harry Road, San Jose, CA 95120, USA {chit i ra j ase yunyaol i frrei s s }@us . [sent-1, score-0.121]
</p><p>2 com –  ,  ,  ,  Abstract Named-entity recognition (NER) is an important task required in a wide variety of applications. [sent-5, score-0.136]
</p><p>3 While rule-based systems are appealing due to their well-known “explainability,” most, if not all, state-of-the-art results for NER tasks are based on machine learning techniques. [sent-6, score-0.112]
</p><p>4 Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition? [sent-7, score-0.135]
</p><p>5 NERL is tuned to the needs of NER tasks and simplifies the process of building, understanding, and customizing complex rule-based named-entity annotators. [sent-9, score-0.34]
</p><p>6 We show that these customized annotators match or outperform the best published results achieved with machine learning techniques. [sent-10, score-0.184]
</p><p>7 These results confirm that we can  reap the benefits of rule-based extractors’ explainability without sacrificing accuracy. [sent-11, score-0.34]
</p><p>8 We conclude by discussing lessons learned while building and customizing complex rule-based annotators and outlining several research directions towards facilitating rule development. [sent-12, score-0.625]
</p><p>9 1 Introduction Named-entity recognition (NER) is the task of identifying mentions of rigid designators from text belonging to named-entity types such as persons, organizations and locations (Nadeau and Sekine, 2007). [sent-13, score-0.279]
</p><p>10 While NER over formal text such as news articles and webpages is a well-studied problem (Bikel et 1002 al. [sent-14, score-0.091]
</p><p>11 , 2005), there has been recent work on NER over informal text such as emails and blogs (Huang et al. [sent-16, score-0.123]
</p><p>12 The techniques proposed in the literature fall under three categories: rule-based (Krupka and Hausman, 2001 ; Sekine and Nobata, 2004), machine learning-  based (O. [sent-20, score-0.065]
</p><p>13 1 Motivation Although there are well-established rule-based systems to perform NER tasks, most, if not all, state-ofthe-art results for NER tasks are based on machine learning techniques. [sent-26, score-0.036]
</p><p>14 However, the rule-based approach is still extremely appealing due to the associated transparency of the internal system state, which leads to better explainability of errors (Siniakov, 2010). [sent-27, score-0.558]
</p><p>15 Ideally, one would like to benefit from the transparency and explainability of rule-based techniques, while achieving state-of-the-art accuracy. [sent-28, score-0.449]
</p><p>16 A particularly challenging aspect of rule-based NER in practice is domain customization customizing existing annotators to produce accurate results in new domains. [sent-29, score-0.715]
</p><p>17 In machine learning-based systems, adapting to a new domain has traditionally involved acquiring additional labeled data and learning a new model from scratch. [sent-30, score-0.218]
</p><p>18 However, recent work has proposed more sophisticated approaches —  that learn a domain-independent base model, which can later be adapted to specific domains (Florian et Proce MdiInTg,s M oaf sthseac 2h0u1s0et Ctso, UnfeSrAe,nc 9e-1 o1n O Ecmtopbireirca 2l0 M10e. [sent-31, score-0.029]
</p><p>19 Sinxogfal  WC u is thiton m sipoz ra t sio an r tRSicoel qus,uti roenm(eCnSt): Cmitay , rCefoeurntoy aorspSotartse ntea m e sowritohitnheslpo cratsioanrticlse slf. [sent-38, score-0.111]
</p><p>20 Implementing a similar approach for rule-based NER typically requires a significant amount of manual effort to (a) identify the explicit semantic changes required for the new domain (e. [sent-44, score-0.265]
</p><p>21 , differences in entity type def-  inition), (b) identify the portions of the (complex) core annotator that should be modified for each difference and (c) implement the required customization rules without compromising the extraction quality of the core annotator. [sent-46, score-0.692]
</p><p>22 Domain customization of rule-based NER has not received much attention in the recent literature with a few exceptions (Petasis et al. [sent-47, score-0.363]
</p><p>23 2 Problem Statement In this paper, we explore the following natural question: Are rule-based systems still a viable approach to named-entity recognition? [sent-52, score-0.135]
</p><p>24 Specifically, (a) Is it possible to build, maintain and customize rule-based NER annotators that match the state-of-the-art results obtained using machine-learning techniques? [sent-53, score-0.179]
</p><p>25 and (b) Can this be achieved with a reasonable amount of manual effort? [sent-54, score-0.039]
</p><p>26 3 Contributions In this paper, we address the challenges mentioned above by (i) defining a taxonomy of the different types of customizations that a rule developer may perform when adapting to a new domain (Sec. [sent-56, score-0.302]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ner', 0.653), ('customization', 0.28), ('explainability', 0.28), ('customizing', 0.216), ('nerl', 0.21), ('annotators', 0.147), ('almaden', 0.14), ('transparency', 0.14), ('jansche', 0.12), ('viable', 0.108), ('abney', 0.1), ('sekine', 0.093), ('florian', 0.08), ('core', 0.079), ('recognition', 0.077), ('appealing', 0.076), ('domain', 0.072), ('adapting', 0.068), ('ra', 0.061), ('sacrificing', 0.06), ('gruhl', 0.06), ('ase', 0.06), ('compromising', 0.06), ('lessons', 0.06), ('maynard', 0.06), ('minkov', 0.06), ('required', 0.059), ('developer', 0.054), ('persons', 0.054), ('bender', 0.054), ('laura', 0.054), ('rigid', 0.054), ('road', 0.054), ('li', 0.052), ('mccallum', 0.05), ('operations', 0.05), ('sio', 0.05), ('frederick', 0.05), ('webpages', 0.05), ('wc', 0.05), ('facilitating', 0.05), ('shivakumar', 0.05), ('effort', 0.048), ('identify', 0.047), ('harry', 0.047), ('implementing', 0.047), ('extractors', 0.047), ('emails', 0.047), ('exceptions', 0.047), ('simplifies', 0.047), ('rule', 0.045), ('organizations', 0.044), ('jose', 0.044), ('bikel', 0.042), ('complex', 0.041), ('articles', 0.041), ('traditionally', 0.04), ('title', 0.04), ('manual', 0.039), ('informal', 0.038), ('sports', 0.038), ('acquiring', 0.038), ('blogs', 0.038), ('zhai', 0.038), ('discussing', 0.037), ('taxonomy', 0.037), ('statement', 0.037), ('belonging', 0.037), ('published', 0.037), ('blitzer', 0.037), ('literature', 0.036), ('tasks', 0.036), ('mentions', 0.035), ('portions', 0.034), ('finkel', 0.034), ('etzioni', 0.034), ('san', 0.034), ('hybrid', 0.032), ('maintain', 0.032), ('covering', 0.032), ('locations', 0.032), ('zhu', 0.032), ('ideally', 0.032), ('internal', 0.031), ('location', 0.031), ('extremely', 0.031), ('achieving', 0.029), ('fall', 0.029), ('adapted', 0.029), ('building', 0.029), ('document', 0.028), ('solutions', 0.028), ('ibm', 0.028), ('organization', 0.028), ('annotator', 0.027), ('proce', 0.027), ('explore', 0.027), ('rules', 0.027), ('jiang', 0.026), ('defining', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="37-tfidf-1" href="./emnlp-2010-Domain_Adaptation_of_Rule-Based_Annotators_for_Named-Entity_Recognition_Tasks.html">37 emnlp-2010-Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks</a></p>
<p>Author: Laura Chiticariu ; Rajasekar Krishnamurthy ; Yunyao Li ; Frederick Reiss ; Shivakumar Vaithyanathan</p><p>Abstract: Named-entity recognition (NER) is an important task required in a wide variety of applications. While rule-based systems are appealing due to their well-known “explainability,” most, if not all, state-of-the-art results for NER tasks are based on machine learning techniques. Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition? Specifically, we have designed and implemented a high-level language NERL on top of SystemT, a general-purpose algebraic information extraction system. NERL is tuned to the needs of NER tasks and simplifies the process of building, understanding, and customizing complex rule-based named-entity annotators. We show that these customized annotators match or outperform the best published results achieved with machine learning techniques. These results confirm that we can reap the benefits of rule-based extractors’ explainability without sacrificing accuracy. We conclude by discussing lessons learned while building and customizing complex rule-based annotators and outlining several research directions towards facilitating rule development.</p><p>2 0.16817994 <a title="37-tfidf-2" href="./emnlp-2010-Confidence_in_Structured-Prediction_Using_Confidence-Weighted_Models.html">30 emnlp-2010-Confidence in Structured-Prediction Using Confidence-Weighted Models</a></p>
<p>Author: Avihai Mejer ; Koby Crammer</p><p>Abstract: Confidence-Weighted linear classifiers (CW) and its successors were shown to perform well on binary and multiclass NLP problems. In this paper we extend the CW approach for sequence learning and show that it achieves state-of-the-art performance on four noun phrase chucking and named entity recognition tasks. We then derive few algorithmic approaches to estimate the prediction’s correctness of each label in the output sequence. We show that our approach provides a reliable relative correctness information as it outperforms other alternatives in ranking label-predictions according to their error. We also show empirically that our methods output close to absolute estimation of error. Finally, we show how to use this information to improve active learning.</p><p>3 0.098148823 <a title="37-tfidf-3" href="./emnlp-2010-The_Necessity_of_Combining_Adaptation_Methods.html">104 emnlp-2010-The Necessity of Combining Adaptation Methods</a></p>
<p>Author: Ming-Wei Chang ; Michael Connor ; Dan Roth</p><p>Abstract: Problems stemming from domain adaptation continue to plague the statistical natural language processing community. There has been continuing work trying to find general purpose algorithms to alleviate this problem. In this paper we argue that existing general purpose approaches usually only focus on one of two issues related to the difficulties faced by adaptation: 1) difference in base feature statistics or 2) task differences that can be detected with labeled data. We argue that it is necessary to combine these two classes of adaptation algorithms, using evidence collected through theoretical analysis and simulated and real-world data experiments. We find that the combined approach often outperforms the individual adaptation approaches. By combining simple approaches from each class of adaptation algorithm, we achieve state-of-the-art results for both Named Entity Recognition adaptation task and the Preposition Sense Disambiguation adaptation task. Second, we also show that applying an adaptation algorithm that finds shared representation between domains often impacts the choice in adaptation algorithm that makes use of target labeled data.</p><p>4 0.06935209 <a title="37-tfidf-4" href="./emnlp-2010-A_Multi-Pass_Sieve_for_Coreference_Resolution.html">8 emnlp-2010-A Multi-Pass Sieve for Coreference Resolution</a></p>
<p>Author: Karthik Raghunathan ; Heeyoung Lee ; Sudarshan Rangarajan ; Nate Chambers ; Mihai Surdeanu ; Dan Jurafsky ; Christopher Manning</p><p>Abstract: Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features. This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones. To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision. Each tier builds on the previous tier’s entity cluster output. Further, our model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster. This cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time. The framework is highly modular: new coreference modules can be plugged in without any change to the other modules. In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora. This suggests that sievebased approaches could be applied to other NLP tasks.</p><p>5 0.052641839 <a title="37-tfidf-5" href="./emnlp-2010-Enhancing_Mention_Detection_Using_Projection_via_Aligned_Corpora.html">44 emnlp-2010-Enhancing Mention Detection Using Projection via Aligned Corpora</a></p>
<p>Author: Yassine Benajiba ; Imed Zitouni</p><p>Abstract: The research question treated in this paper is centered on the idea of exploiting rich resources of one language to enhance the performance of a mention detection system of another one. We successfully achieve this goal by projecting information from one language to another via a parallel corpus. We examine the potential improvement using various degrees of linguistic information in a statistical framework and we show that the proposed technique is effective even when the target language model has access to a significantly rich feature set. Experimental results show up to 2.4F improvement in performance when the system has access to information obtained by projecting mentions from a resource-richlanguage mention detection system via a parallel corpus.</p><p>6 0.051008645 <a title="37-tfidf-6" href="./emnlp-2010-We%27re_Not_in_Kansas_Anymore%3A_Detecting_Domain_Changes_in_Streams.html">119 emnlp-2010-We're Not in Kansas Anymore: Detecting Domain Changes in Streams</a></p>
<p>7 0.043299362 <a title="37-tfidf-7" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<p>8 0.041458387 <a title="37-tfidf-8" href="./emnlp-2010-Improving_Mention_Detection_Robustness_to_Noisy_Input.html">62 emnlp-2010-Improving Mention Detection Robustness to Noisy Input</a></p>
<p>9 0.03480335 <a title="37-tfidf-9" href="./emnlp-2010-EMNLP_044.html">39 emnlp-2010-EMNLP 044</a></p>
<p>10 0.033522997 <a title="37-tfidf-10" href="./emnlp-2010-A_Semi-Supervised_Method_to_Learn_and_Construct_Taxonomies_Using_the_Web.html">12 emnlp-2010-A Semi-Supervised Method to Learn and Construct Taxonomies Using the Web</a></p>
<p>11 0.031556409 <a title="37-tfidf-11" href="./emnlp-2010-Hierarchical_Phrase-Based_Translation_Grammars_Extracted_from_Alignment_Posterior_Probabilities.html">57 emnlp-2010-Hierarchical Phrase-Based Translation Grammars Extracted from Alignment Posterior Probabilities</a></p>
<p>12 0.02836111 <a title="37-tfidf-12" href="./emnlp-2010-Jointly_Modeling_Aspects_and_Opinions_with_a_MaxEnt-LDA_Hybrid.html">70 emnlp-2010-Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid</a></p>
<p>13 0.027692126 <a title="37-tfidf-13" href="./emnlp-2010-Function-Based_Question_Classification_for_General_QA.html">51 emnlp-2010-Function-Based Question Classification for General QA</a></p>
<p>14 0.027259959 <a title="37-tfidf-14" href="./emnlp-2010-Exploiting_Conversation_Structure_in_Unsupervised_Topic_Segmentation_for_Emails.html">48 emnlp-2010-Exploiting Conversation Structure in Unsupervised Topic Segmentation for Emails</a></p>
<p>15 0.027145231 <a title="37-tfidf-15" href="./emnlp-2010-Automatic_Detection_and_Classification_of_Social_Events.html">20 emnlp-2010-Automatic Detection and Classification of Social Events</a></p>
<p>16 0.026557654 <a title="37-tfidf-16" href="./emnlp-2010-Efficient_Graph-Based_Semi-Supervised_Learning_of_Structured_Tagging_Models.html">41 emnlp-2010-Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models</a></p>
<p>17 0.025349822 <a title="37-tfidf-17" href="./emnlp-2010-Collective_Cross-Document_Relation_Extraction_Without_Labelled_Data.html">28 emnlp-2010-Collective Cross-Document Relation Extraction Without Labelled Data</a></p>
<p>18 0.024158634 <a title="37-tfidf-18" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>19 0.023739241 <a title="37-tfidf-19" href="./emnlp-2010-Cross_Language_Text_Classification_by_Model_Translation_and_Semi-Supervised_Learning.html">33 emnlp-2010-Cross Language Text Classification by Model Translation and Semi-Supervised Learning</a></p>
<p>20 0.023688173 <a title="37-tfidf-20" href="./emnlp-2010-Using_Universal_Linguistic_Knowledge_to_Guide_Grammar_Induction.html">116 emnlp-2010-Using Universal Linguistic Knowledge to Guide Grammar Induction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.097), (1, 0.06), (2, -0.01), (3, 0.062), (4, -0.041), (5, -0.101), (6, 0.126), (7, 0.106), (8, -0.035), (9, 0.042), (10, 0.041), (11, 0.061), (12, -0.047), (13, 0.137), (14, -0.008), (15, -0.03), (16, -0.048), (17, -0.27), (18, 0.04), (19, -0.125), (20, 0.056), (21, -0.098), (22, 0.154), (23, -0.017), (24, -0.214), (25, 0.109), (26, 0.03), (27, -0.058), (28, 0.12), (29, -0.129), (30, 0.026), (31, 0.003), (32, 0.126), (33, -0.159), (34, 0.185), (35, 0.041), (36, 0.282), (37, -0.041), (38, -0.088), (39, 0.033), (40, -0.008), (41, -0.019), (42, -0.027), (43, -0.113), (44, -0.037), (45, -0.157), (46, -0.108), (47, 0.137), (48, 0.099), (49, -0.09)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97853076 <a title="37-lsi-1" href="./emnlp-2010-Domain_Adaptation_of_Rule-Based_Annotators_for_Named-Entity_Recognition_Tasks.html">37 emnlp-2010-Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks</a></p>
<p>Author: Laura Chiticariu ; Rajasekar Krishnamurthy ; Yunyao Li ; Frederick Reiss ; Shivakumar Vaithyanathan</p><p>Abstract: Named-entity recognition (NER) is an important task required in a wide variety of applications. While rule-based systems are appealing due to their well-known “explainability,” most, if not all, state-of-the-art results for NER tasks are based on machine learning techniques. Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition? Specifically, we have designed and implemented a high-level language NERL on top of SystemT, a general-purpose algebraic information extraction system. NERL is tuned to the needs of NER tasks and simplifies the process of building, understanding, and customizing complex rule-based named-entity annotators. We show that these customized annotators match or outperform the best published results achieved with machine learning techniques. These results confirm that we can reap the benefits of rule-based extractors’ explainability without sacrificing accuracy. We conclude by discussing lessons learned while building and customizing complex rule-based annotators and outlining several research directions towards facilitating rule development.</p><p>2 0.64331132 <a title="37-lsi-2" href="./emnlp-2010-Confidence_in_Structured-Prediction_Using_Confidence-Weighted_Models.html">30 emnlp-2010-Confidence in Structured-Prediction Using Confidence-Weighted Models</a></p>
<p>Author: Avihai Mejer ; Koby Crammer</p><p>Abstract: Confidence-Weighted linear classifiers (CW) and its successors were shown to perform well on binary and multiclass NLP problems. In this paper we extend the CW approach for sequence learning and show that it achieves state-of-the-art performance on four noun phrase chucking and named entity recognition tasks. We then derive few algorithmic approaches to estimate the prediction’s correctness of each label in the output sequence. We show that our approach provides a reliable relative correctness information as it outperforms other alternatives in ranking label-predictions according to their error. We also show empirically that our methods output close to absolute estimation of error. Finally, we show how to use this information to improve active learning.</p><p>3 0.34957892 <a title="37-lsi-3" href="./emnlp-2010-We%27re_Not_in_Kansas_Anymore%3A_Detecting_Domain_Changes_in_Streams.html">119 emnlp-2010-We're Not in Kansas Anymore: Detecting Domain Changes in Streams</a></p>
<p>Author: Mark Dredze ; Tim Oates ; Christine Piatko</p><p>Abstract: Domain adaptation, the problem of adapting a natural language processing system trained in one domain to perform well in a different domain, has received significant attention. This paper addresses an important problem for deployed systems that has received little attention – detecting when such adaptation is needed by a system operating in the wild, i.e., performing classification over a stream of unlabeled examples. Our method uses Aodifst uannlaceb,e a dm eextraicm fpolre detecting tshhoifdts u sine sd Aatastreams, combined with classification margins to detect domain shifts. We empirically show effective domain shift detection on a variety of data sets and shift conditions.</p><p>4 0.26873478 <a title="37-lsi-4" href="./emnlp-2010-A_Multi-Pass_Sieve_for_Coreference_Resolution.html">8 emnlp-2010-A Multi-Pass Sieve for Coreference Resolution</a></p>
<p>Author: Karthik Raghunathan ; Heeyoung Lee ; Sudarshan Rangarajan ; Nate Chambers ; Mihai Surdeanu ; Dan Jurafsky ; Christopher Manning</p><p>Abstract: Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features. This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones. To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision. Each tier builds on the previous tier’s entity cluster output. Further, our model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster. This cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time. The framework is highly modular: new coreference modules can be plugged in without any change to the other modules. In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora. This suggests that sievebased approaches could be applied to other NLP tasks.</p><p>5 0.19071458 <a title="37-lsi-5" href="./emnlp-2010-The_Necessity_of_Combining_Adaptation_Methods.html">104 emnlp-2010-The Necessity of Combining Adaptation Methods</a></p>
<p>Author: Ming-Wei Chang ; Michael Connor ; Dan Roth</p><p>Abstract: Problems stemming from domain adaptation continue to plague the statistical natural language processing community. There has been continuing work trying to find general purpose algorithms to alleviate this problem. In this paper we argue that existing general purpose approaches usually only focus on one of two issues related to the difficulties faced by adaptation: 1) difference in base feature statistics or 2) task differences that can be detected with labeled data. We argue that it is necessary to combine these two classes of adaptation algorithms, using evidence collected through theoretical analysis and simulated and real-world data experiments. We find that the combined approach often outperforms the individual adaptation approaches. By combining simple approaches from each class of adaptation algorithm, we achieve state-of-the-art results for both Named Entity Recognition adaptation task and the Preposition Sense Disambiguation adaptation task. Second, we also show that applying an adaptation algorithm that finds shared representation between domains often impacts the choice in adaptation algorithm that makes use of target labeled data.</p><p>6 0.17102438 <a title="37-lsi-6" href="./emnlp-2010-Automatic_Keyphrase_Extraction_via_Topic_Decomposition.html">23 emnlp-2010-Automatic Keyphrase Extraction via Topic Decomposition</a></p>
<p>7 0.162663 <a title="37-lsi-7" href="./emnlp-2010-A_Semi-Supervised_Method_to_Learn_and_Construct_Taxonomies_Using_the_Web.html">12 emnlp-2010-A Semi-Supervised Method to Learn and Construct Taxonomies Using the Web</a></p>
<p>8 0.1361845 <a title="37-lsi-8" href="./emnlp-2010-Learning_First-Order_Horn_Clauses_from_Web_Text.html">72 emnlp-2010-Learning First-Order Horn Clauses from Web Text</a></p>
<p>9 0.13192442 <a title="37-lsi-9" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>10 0.13113648 <a title="37-lsi-10" href="./emnlp-2010-Exploiting_Conversation_Structure_in_Unsupervised_Topic_Segmentation_for_Emails.html">48 emnlp-2010-Exploiting Conversation Structure in Unsupervised Topic Segmentation for Emails</a></p>
<p>11 0.12412576 <a title="37-lsi-11" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<p>12 0.11964716 <a title="37-lsi-12" href="./emnlp-2010-Practical_Linguistic_Steganography_Using_Contextual_Synonym_Substitution_and_Vertex_Colour_Coding.html">91 emnlp-2010-Practical Linguistic Steganography Using Contextual Synonym Substitution and Vertex Colour Coding</a></p>
<p>13 0.11850633 <a title="37-lsi-13" href="./emnlp-2010-Function-Based_Question_Classification_for_General_QA.html">51 emnlp-2010-Function-Based Question Classification for General QA</a></p>
<p>14 0.11210193 <a title="37-lsi-14" href="./emnlp-2010-Context_Comparison_of_Bursty_Events_in_Web_Search_and_Online_Media.html">32 emnlp-2010-Context Comparison of Bursty Events in Web Search and Online Media</a></p>
<p>15 0.11077584 <a title="37-lsi-15" href="./emnlp-2010-Unsupervised_Induction_of_Tree_Substitution_Grammars_for_Dependency_Parsing.html">113 emnlp-2010-Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing</a></p>
<p>16 0.10534304 <a title="37-lsi-16" href="./emnlp-2010-Statistical_Machine_Translation_with_a_Factorized_Grammar.html">99 emnlp-2010-Statistical Machine Translation with a Factorized Grammar</a></p>
<p>17 0.10060779 <a title="37-lsi-17" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>18 0.10054317 <a title="37-lsi-18" href="./emnlp-2010-Improving_Gender_Classification_of_Blog_Authors.html">61 emnlp-2010-Improving Gender Classification of Blog Authors</a></p>
<p>19 0.098959006 <a title="37-lsi-19" href="./emnlp-2010-A_Game-Theoretic_Approach_to_Generating_Spatial_Descriptions.html">4 emnlp-2010-A Game-Theoretic Approach to Generating Spatial Descriptions</a></p>
<p>20 0.097969905 <a title="37-lsi-20" href="./emnlp-2010-Hierarchical_Phrase-Based_Translation_Grammars_Extracted_from_Alignment_Posterior_Probabilities.html">57 emnlp-2010-Hierarchical Phrase-Based Translation Grammars Extracted from Alignment Posterior Probabilities</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.036), (10, 0.039), (12, 0.034), (29, 0.048), (46, 0.443), (52, 0.051), (56, 0.03), (62, 0.018), (66, 0.096), (72, 0.042), (76, 0.012), (79, 0.015), (89, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.69841629 <a title="37-lda-1" href="./emnlp-2010-Domain_Adaptation_of_Rule-Based_Annotators_for_Named-Entity_Recognition_Tasks.html">37 emnlp-2010-Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks</a></p>
<p>Author: Laura Chiticariu ; Rajasekar Krishnamurthy ; Yunyao Li ; Frederick Reiss ; Shivakumar Vaithyanathan</p><p>Abstract: Named-entity recognition (NER) is an important task required in a wide variety of applications. While rule-based systems are appealing due to their well-known “explainability,” most, if not all, state-of-the-art results for NER tasks are based on machine learning techniques. Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition? Specifically, we have designed and implemented a high-level language NERL on top of SystemT, a general-purpose algebraic information extraction system. NERL is tuned to the needs of NER tasks and simplifies the process of building, understanding, and customizing complex rule-based named-entity annotators. We show that these customized annotators match or outperform the best published results achieved with machine learning techniques. These results confirm that we can reap the benefits of rule-based extractors’ explainability without sacrificing accuracy. We conclude by discussing lessons learned while building and customizing complex rule-based annotators and outlining several research directions towards facilitating rule development.</p><p>2 0.27753627 <a title="37-lda-2" href="./emnlp-2010-A_Hybrid_Morpheme-Word_Representation_for_Machine_Translation_of_Morphologically_Rich_Languages.html">5 emnlp-2010-A Hybrid Morpheme-Word Representation for Machine Translation of Morphologically Rich Languages</a></p>
<p>Author: Minh-Thang Luong ; Preslav Nakov ; Min-Yen Kan</p><p>Abstract: We propose a language-independent approach for improving statistical machine translation for morphologically rich languages using a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process. Our model extends the classic phrase-based model by means of (1) word boundary-aware morpheme-level phrase extraction, (2) minimum error-rate training for a morpheme-level translation model using word-level BLEU, and (3) joint scoring with morpheme- and word-level language models. Further improvements are achieved by combining our model with the classic one. The evaluation on English to Finnish using Europarl (714K sentence pairs; 15.5M English words) shows statistically significant improvements over the classic model based on BLEU and human judgments.</p><p>3 0.27726668 <a title="37-lda-3" href="./emnlp-2010-Discriminative_Sample_Selection_for_Statistical_Machine_Translation.html">35 emnlp-2010-Discriminative Sample Selection for Statistical Machine Translation</a></p>
<p>Author: Sankaranarayanan Ananthakrishnan ; Rohit Prasad ; David Stallard ; Prem Natarajan</p><p>Abstract: Production of parallel training corpora for the development of statistical machine translation (SMT) systems for resource-poor languages usually requires extensive manual effort. Active sample selection aims to reduce the labor, time, and expense incurred in producing such resources, attaining a given performance benchmark with the smallest possible training corpus by choosing informative, nonredundant source sentences from an available candidate pool for manual translation. We present a novel, discriminative sample selection strategy that preferentially selects batches of candidate sentences with constructs that lead to erroneous translations on a held-out development set. The proposed strategy supports a built-in diversity mechanism that reduces redundancy in the selected batches. Simulation experiments on English-to-Pashto and Spanish-to-English translation tasks demon- strate the superiority of the proposed approach to a number of competing techniques, such as random selection, dissimilarity-based selection, as well as a recently proposed semisupervised active learning strategy.</p><p>4 0.27380407 <a title="37-lda-4" href="./emnlp-2010-Joint_Training_and_Decoding_Using_Virtual_Nodes_for_Cascaded_Segmentation_and_Tagging_Tasks.html">69 emnlp-2010-Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks</a></p>
<p>Author: Xian Qian ; Qi Zhang ; Yaqian Zhou ; Xuanjing Huang ; Lide Wu</p><p>Abstract: Many sequence labeling tasks in NLP require solving a cascade of segmentation and tagging subtasks, such as Chinese POS tagging, named entity recognition, and so on. Traditional pipeline approaches usually suffer from error propagation. Joint training/decoding in the cross-product state space could cause too many parameters and high inference complexity. In this paper, we present a novel method which integrates graph structures of two subtasks into one using virtual nodes, and performs joint training and decoding in the factorized state space. Experimental evaluations on CoNLL 2000 shallow parsing data set and Fourth SIGHAN Bakeoff CTB POS tagging data set demonstrate the superiority of our method over cross-product, pipeline and candidate reranking approaches.</p><p>5 0.27367195 <a title="37-lda-5" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<p>Author: Samuel Brody</p><p>Abstract: We reveal a previously unnoticed connection between dependency parsing and statistical machine translation (SMT), by formulating the dependency parsing task as a problem of word alignment. Furthermore, we show that two well known models for these respective tasks (DMV and the IBM models) share common modeling assumptions. This motivates us to develop an alignment-based framework for unsupervised dependency parsing. The framework (which will be made publicly available) is flexible, modular and easy to extend. Using this framework, we implement several algorithms based on the IBM alignment models, which prove surprisingly effective on the dependency parsing task, and demonstrate the potential of the alignment-based approach.</p><p>6 0.27311313 <a title="37-lda-6" href="./emnlp-2010-Improving_Mention_Detection_Robustness_to_Noisy_Input.html">62 emnlp-2010-Improving Mention Detection Robustness to Noisy Input</a></p>
<p>7 0.26865053 <a title="37-lda-7" href="./emnlp-2010-A_Semi-Supervised_Approach_to_Improve_Classification_of_Infrequent_Discourse_Relations_Using_Feature_Vector_Extension.html">11 emnlp-2010-A Semi-Supervised Approach to Improve Classification of Infrequent Discourse Relations Using Feature Vector Extension</a></p>
<p>8 0.26839638 <a title="37-lda-8" href="./emnlp-2010-The_Necessity_of_Combining_Adaptation_Methods.html">104 emnlp-2010-The Necessity of Combining Adaptation Methods</a></p>
<p>9 0.26801139 <a title="37-lda-9" href="./emnlp-2010-Function-Based_Question_Classification_for_General_QA.html">51 emnlp-2010-Function-Based Question Classification for General QA</a></p>
<p>10 0.2680074 <a title="37-lda-10" href="./emnlp-2010-Assessing_Phrase-Based_Translation_Models_with_Oracle_Decoding.html">18 emnlp-2010-Assessing Phrase-Based Translation Models with Oracle Decoding</a></p>
<p>11 0.2668916 <a title="37-lda-11" href="./emnlp-2010-Improving_Gender_Classification_of_Blog_Authors.html">61 emnlp-2010-Improving Gender Classification of Blog Authors</a></p>
<p>12 0.26677629 <a title="37-lda-12" href="./emnlp-2010-We%27re_Not_in_Kansas_Anymore%3A_Detecting_Domain_Changes_in_Streams.html">119 emnlp-2010-We're Not in Kansas Anymore: Detecting Domain Changes in Streams</a></p>
<p>13 0.2667678 <a title="37-lda-13" href="./emnlp-2010-Maximum_Entropy_Based_Phrase_Reordering_for_Hierarchical_Phrase-Based_Translation.html">76 emnlp-2010-Maximum Entropy Based Phrase Reordering for Hierarchical Phrase-Based Translation</a></p>
<p>14 0.26601744 <a title="37-lda-14" href="./emnlp-2010-Non-Isomorphic_Forest_Pair_Translation.html">86 emnlp-2010-Non-Isomorphic Forest Pair Translation</a></p>
<p>15 0.26541483 <a title="37-lda-15" href="./emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields.html">49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</a></p>
<p>16 0.26478592 <a title="37-lda-16" href="./emnlp-2010-Word-Based_Dialect_Identification_with_Georeferenced_Rules.html">123 emnlp-2010-Word-Based Dialect Identification with Georeferenced Rules</a></p>
<p>17 0.26460347 <a title="37-lda-17" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>18 0.26414427 <a title="37-lda-18" href="./emnlp-2010-Combining_Unsupervised_and_Supervised_Alignments_for_MT%3A_An_Empirical_Study.html">29 emnlp-2010-Combining Unsupervised and Supervised Alignments for MT: An Empirical Study</a></p>
<p>19 0.26373661 <a title="37-lda-19" href="./emnlp-2010-Discriminative_Word_Alignment_with_a_Function_Word_Reordering_Model.html">36 emnlp-2010-Discriminative Word Alignment with a Function Word Reordering Model</a></p>
<p>20 0.2635695 <a title="37-lda-20" href="./emnlp-2010-Facilitating_Translation_Using_Source_Language_Paraphrase_Lattices.html">50 emnlp-2010-Facilitating Translation Using Source Language Paraphrase Lattices</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
