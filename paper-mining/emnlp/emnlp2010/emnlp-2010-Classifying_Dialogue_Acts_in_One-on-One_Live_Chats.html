<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-26" href="#">emnlp2010-26</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</h1>
<br/><p>Source: <a title="emnlp-2010-26-pdf" href="http://aclweb.org/anthology//D/D10/D10-1084.pdf">pdf</a></p><p>Author: Su Nam Kim ; Lawrence Cavedon ; Timothy Baldwin</p><p>Abstract: We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. In particular, we investigate the effectiveness of various features and machine learners for this task. While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data.</p><p>Reference: <a title="emnlp-2010-26-reference" href="../emnlp2010_reference/emnlp-2010-Classifying_Dialogue_Acts_in_One-on-One_Live_Chats_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 net  Abstract We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. [sent-4, score-1.2]
</p><p>2 While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. [sent-6, score-0.795]
</p><p>3 We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data. [sent-7, score-0.38]
</p><p>4 1 Introduction Recently, live chats have received attention due to the growing popularity of chat services and the increasing body of applications. [sent-8, score-0.551]
</p><p>5 For example, large  organizations are increasingly providing support or information services through live chat. [sent-9, score-0.223]
</p><p>6 One advantage of chat-based customer service over conventional telephone-based customer service is that it becomes possible to semi-automate aspects of the interaction (e. [sent-10, score-0.236]
</p><p>7 conventional openings or canned responses to standard questions) without the customer being aware of it taking place, something that is not possible with speech-based dialogue systems (as synthesised speech is still easily distinguishable from natural speech). [sent-12, score-0.801]
</p><p>8 Potentially huge savings can be made by organisations providing customer help services if we can increase the degree of automation of live chat. [sent-13, score-0.313]
</p><p>9 Given the increasing impact of live chat services, there is surprisingly little published computational 862 linguistic research on the topic. [sent-14, score-0.327]
</p><p>10 There has been substantially more work done on dialogue and dialogue corpora, mostly in spoken dialogue (e. [sent-15, score-2.121]
</p><p>11 (2000)) but also multimodal dialogue systems in application areas such as telephone support service (Bangalore et al. [sent-18, score-0.736]
</p><p>12 Spoken dialogue analysis introduces many complications related to the error inherent in current speech recognition technologies. [sent-20, score-0.711]
</p><p>13 As an instance of written dialogue, an advantage of live chats is that recognition errors are not such an issue, although the nature of language used in chat is typically ill-formed and turn-taking is complicated by the semi-asynchronous nature of the interaction (e. [sent-21, score-0.516]
</p><p>14 In this paper, we investigate the task of automatic classification of dialogue acts in 1-on-1 live chats, focusing on “information delivery” chats since these are proving increasingly popular as part of enterprise customer-service solutions. [sent-24, score-1.285]
</p><p>15 Our main challenge is to develop effective features and classifiers for classifying aspects of 1-on-1 live chat. [sent-25, score-0.239]
</p><p>16 Much of the work on analysing dialogue acts in spoken dialogues has relied on non-lexical features, such as prosody and acoustic features (Stolcke et al. [sent-26, score-1.084]
</p><p>17 Previous dialogue-act detection for chat systems has used bags-of-words (hereafter, BoW) as features for dialogue-act detection; this simple approach  has shown some promise (e. [sent-29, score-0.139]
</p><p>18 , 2005) have also been used for dialogue act classification. [sent-35, score-0.881]
</p><p>19 tc ho2d0s10 in A Nsastoucira tlio Lnan fogru Cagoem Ppruotcaetisosninagl, L pinag eusis 8t6ic2s–871, In this paper, we first re-examine BoW features for dialogue act classification. [sent-38, score-0.881]
</p><p>20 As a baseline, we use the work of Ivanovic (2008), which explored 1grams and 2-grams with Boolean values in 1-on-1 live chats in the MSN Online Shopping domain (this dataset is described in Section 5). [sent-39, score-0.377]
</p><p>21 We extend this work by using ideas from related research such as text categorization (Debole and Sebastiani, 2003), and explore variants of BoW based on analysis of live chats, along with feature weighting. [sent-41, score-0.188]
</p><p>22 Finally, our main aim is to explore new features based on dialogue structure and dependencies between utterances1 that can enhance the use of  BoW for dialogue act classification. [sent-42, score-1.591]
</p><p>23 Our hypothesis is that, for task-oriented 1-on-1 live chats, the structure and interactions among utterances are useful in predicting future dialogue acts: for example, conversations typically start with a greeting, and questions and answers typically appear as adjacency pairs in a conversation. [sent-43, score-1.111]
</p><p>24 Therefore, we propose new features based on structural and dependency information derived from utterances (Sections 4. [sent-44, score-0.283]
</p><p>25 2  Related Work  While there has been significant work on classifying dialogue acts, the bulk of this has been for spoken dialogue. [sent-47, score-0.8]
</p><p>26 Most such work has considered: (1) defining taxonomies of dialogue acts; (2) discovering useful features for the classification task; and (3) experimenting with different machine learning techniques. [sent-48, score-0.717]
</p><p>27 For classifying dialogue acts in spoken dialogue, various features such as dialogue cues, speech characteristics, and n-grams have been proposed. [sent-50, score-1.702]
</p><p>28 (1998) utilized the characteristics of spoken dialogues and examined speaker  direction, punctuation marks, cue phrases and ngrams for classifying spoken dialogues. [sent-52, score-0.294]
</p><p>29 (1998) used prosodic, lexical and syntactic features for spoken dialogue classification. [sent-54, score-0.749]
</p><p>30 More recently, Julia and Iftekharuddin (2008) and Sridhar et 1An utterance is the smallest unit to deliver message(s) in a turn. [sent-55, score-0.211]
</p><p>31 (2006) used n-grams from the previous 1–3 utterances in order to classify dialogue acts for the target utterance. [sent-61, score-1.073]
</p><p>32 There has been substantially less effort on classifying dialogue acts in written dialogue: Wu et al. [sent-62, score-0.928]
</p><p>33 (2002) and Forsyth (2007) have used keyword-based approaches for classifying online chats; Ivanovic (2008) tested the use of n-gram features for 1-on-1  live chats with MSN Online Shopping assistants. [sent-63, score-0.471]
</p><p>34 Various machine learning techniques have been investigated for the dialogue classification task. [sent-64, score-0.717]
</p><p>35 (Bui, 2003)) have also all been applied to automatic dialogue act classification. [sent-82, score-0.881]
</p><p>36 3  Dialogue Acts  A number ofdialogue act taxonomies have been proposed, designed mainly for spoken dialogue. [sent-83, score-0.258]
</p><p>37 , 1992) defines 42 types of dialogue acts from human-to-human telephone conversations. [sent-87, score-0.899]
</p><p>38 , 1991) defines a set of 128 dialogue acts to model task-based spoken conversations. [sent-89, score-0.94]
</p><p>39 (2002) define 15 dialogue act tags based on previouslydefined dialogue act sets (Samuel et al. [sent-91, score-1.762]
</p><p>40 Forsyth (2007) defines 15 dialogue acts for casual online conversations, based on 16 conversations with 10,567 utterances. [sent-96, score-0.961]
</p><p>41 Ivanovic (2008) proposes 12 dialogue acts based on DAMSL for 1-on-1 online customer service chats. [sent-97, score-1.038]
</p><p>42 Ivanovic’s set of dialogue acts for chat dialogues has significant overlap with the dialogue act sets of Wu et al. [sent-98, score-2.014]
</p><p>43 In our work, we re-use the set of dialogue acts proposed in Ivanovic (2008), due to our targeting the same task of 1-on-1 IM chats, and indeed experimenting over the same dataset. [sent-102, score-0.877]
</p><p>44 The definitions of the dialogue acts are provided in Table 1, along with examples. [sent-103, score-0.877]
</p><p>45 1 Bag-of-Words n-gram-based BoW features are simple yet effective for identifying similarities between two utterances, and have been used widely in previous work on dialogue act classification for online chat dialogues (Louwerse and Crossley, 2006; Ivanovic, 2008). [sent-106, score-1.211]
</p><p>46 However, chats containing large amounts of noise such as typos and emoticons pose a greater challenge for simple BoW approaches. [sent-107, score-0.189]
</p><p>47 In this work, we chose to start with a BoW approach based on our observation that commercial live chat services contain relatively less noise; in particular, the commercial agent tends to use well-formed, formulaic prose. [sent-109, score-0.426]
</p><p>48 Previously, Ivanovic (2008) explored Boolean 1864 gram and 2-gram features to classify MSN Online Shopping live chats, where a user requests assistance in purchasing an item, in response to which the commercial agent asks the customer questions and makes suggestions. [sent-110, score-0.348]
</p><p>49 While 1-grams performed well (as live chat utterances are generally shorter than, e. [sent-112, score-0.523]
</p><p>50 2 Structural Information Our motivation for using structural information as a feature is that the location of an utterance can be a strong predictor of the dialogue act. [sent-124, score-0.945]
</p><p>51 Based on the nature oflive chats, we observed that the utterance position in the chat, as well as in a turn, plays an important role when identifying its dialogue  act. [sent-132, score-0.946]
</p><p>52 For example, an utterance such as Hello will occur at the beginning of a chat while an utterance such as Have a nice day will typically appear at the end. [sent-133, score-0.586]
</p><p>53 The position of utterances in a turn can also help identify the dialogue act; i. [sent-134, score-0.968]
</p><p>54 when there are several utterances in a turn, utterances are related to each other, and thus examining the previous utterances in the same turn can help correctly predict the target utterance. [sent-136, score-0.625]
</p><p>55 You are welcome, my pleasure EXPRESSIVE: An acknowledgement of a previous utterance or an indication of the speaker’s mood. [sent-146, score-0.234]
</p><p>56 Used to confirm that the previous utterance was received/accepted. [sent-163, score-0.211]
</p><p>57 –  Table 1: The set of dialogue acts used in this research, taken from Ivanovic (2008)  the same turn. [sent-178, score-0.877]
</p><p>58 We also noticed that identifying the utterance author can help classify the dialogue act (previously used in Ivanovic (2008)). [sent-179, score-1.171]
</p><p>59 Based on these observations, we tested the follow-  ing four structural features: •  Author information,  •  Relative position in the chat,  •  Author + Relative position,  •  Author + Turn-relative position among utterances irn a given rteulranti. [sent-180, score-0.342]
</p><p>60 We illustrate our structural features in Table 2, which shows an example of a 1-on-1 live chat. [sent-181, score-0.236]
</p><p>61 The participants are the agent (A) and customer (C); Uxx indicates an utterance (U) with ID number xx. [sent-182, score-0.342]
</p><p>62 The relative position is calculated by dividing the utterance number by the total number of utterances in the dialogue; the turn-relative position is calculated by dividing the utterance position by the number of utterances in that turn. [sent-184, score-0.961]
</p><p>63 For example, for utterance 4 (U4), the relativepositionis 442, whileitsturn-relativeposition is 32 since U4 is the second utterance among U3,4,5 that the customer makes in a single turn. [sent-185, score-0.512]
</p><p>64 They used relative position, author information and automatically predicted labels from previous post(s) as dependency features for assigning a semantic label to the current target post. [sent-190, score-0.139]
</p><p>65 Similarly, by examining our chat corpus, we observed significant dependencies between utterances. [sent-191, score-0.163]
</p><p>66 agent-to-user) dialogues often contain dependencies between adjacent utterances by different authors. [sent-194, score-0.337]
</p><p>67 Another example is that when the agent makes a greeting, such as Have a nice day, then the customer will typically respond with a greeting or closing remark, and not a Yes or No. [sent-197, score-0.201]
</p><p>68 Second, the flow of dialogues is in general cohesive, unless the topic of utterances changes dramatically (e. [sent-198, score-0.313]
</p><p>69 Third, we observed that be-  tween utterances made by the same author (either agent or user), the target utterance relies on previous utterances made by the same author, especially when IDUtterance A:U1Hello Customer, welcome to MSN Shopping. [sent-202, score-0.75]
</p><p>70 A:U39 If you have any additional questions or you need additional information, please log in again to chat with us. [sent-216, score-0.139]
</p><p>71 Table 2: An example of a 1-on-1 live chat, with turn and utterance structure the agent and user repeatedly question and answer. [sent-222, score-0.477]
</p><p>72 With these observations, we checked the likelihood of dialogue act pairings between two adjacent utterances, as well as between two adjacent utterances made by the same author. [sent-223, score-1.077]
</p><p>73 Overall, we found strong co-occurrence (as measured by number of occurrences of labels across adjacency pairs) between certain pairs of dialogue acts (e. [sent-224, score-0.918]
</p><p>74 STATEMENT, on the other hand, can associate with most other dialogue acts. [sent-227, score-0.686]
</p><p>75 Based on this, we designed the following five utterance dependency features; by combining these, we obtain 3 1 feature sets. [sent-228, score-0.25]
</p><p>76 Dependency of utterances regardless of author (a) Dialogue act of previous utterance (b) Accumulated dialogue act(s) of previous  utterances (c) Accumulated dialogue acts of previous ut866 terances in a given turn 2. [sent-230, score-2.477]
</p><p>77 In contrast, instead of using utterances which indirectly encode dialogue acts, we directly use the dialogue act classifications, as done in Stolcke et al. [sent-233, score-1.763]
</p><p>78 The motivation is that, due to the high performance of simple BoW features, using dialogue acts directly would capture the dependency better than indirect information  from utterances, despite introducing some noise. [sent-235, score-0.916]
</p><p>79 We do not build a probabilistic model of dialogue transitions the way Stolcke et al. [sent-236, score-0.686]
</p><p>80 (2010) in using predicted dialogue act(s) labels learned in previous step(s) as a feature. [sent-238, score-0.707]
</p><p>81 5  Experiment Setup  As stated earlier, we use the data set from Ivanovic (2008) for our experiments; it contains 1-on-1 live chats from an information delivery task. [sent-239, score-0.397]
</p><p>82 This dataset contains 8 live chats, including 542 manuallysegmented utterances. [sent-240, score-0.188]
</p><p>83 The maximum and minimum number of utterances in a dialogue are 84 and 42, respectively; the maximum number of utterances in a turn is 14. [sent-241, score-1.115]
</p><p>84 The live chats were manually tagged with the 12 dialogue acts described in Section 3. [sent-242, score-1.254]
</p><p>85 The utterance distribution over the dialogue acts is described in Table 3. [sent-243, score-1.088]
</p><p>86 We then built a dialogue act classifier using three different machine learners: SVM-HMM (Joachims, 1998),2 naive Bayes  2http://www. [sent-246, score-0.881]
</p><p>87 Table 6 shows the results: Pos indicates the relative position of an utterance in the whole dialogue, Author means author information, and Posturn indicates the relative position of the utterance in a turn. [sent-285, score-0.599]
</p><p>88 Since we use the dialogue acts directly in utterance dependency, we first experimented using gold-standard dialogue act labels. [sent-303, score-1.969]
</p><p>89 We also tested using the dialogue acts which were automatically learned in previous steps. [sent-304, score-0.877]
</p><p>90 Table 7 shows performance using both the goldstandard and learned dialogue acts. [sent-305, score-0.686]
</p><p>91 However, List decreased the performance, as the flow of dialogues can change, and when a larger history of dialogue acts is included, it tends to introduce noise. [sent-314, score-0.994]
</p><p>92 Comparing use of gold-standard and learned dialogue acts, the reduction in accuracy was not statistically significant, indicating that we can  FeatureCRFSVMNB  C + L a b e lPLAriuestvhort. [sent-315, score-0.686]
</p><p>93 257432680542  Table 8: Accuracy with Structural and Dependency Information: C means lemmatized Unigram+Position+Author achieve high performance on dialogue act classification even with interactively-learned dialogue acts. [sent-318, score-1.598]
</p><p>94 Rows indicate the correct dialogue acts and columns indicate misclassified dialogue acts. [sent-330, score-1.563]
</p><p>95 In particularly, a large number of REQUEST and RESPONSEACK utterances were tagged as STATEMENT. [sent-332, score-0.196]
</p><p>96 869 In future work, we plan to investigate methods for  automatically cleansing the data to remove typos, and taking account of temporal gaps that can sometimes arise in online chats (e. [sent-334, score-0.232]
</p><p>97 7  Conclusion  We have explored an automated approach for classifying dialogue acts in 1-on-1 live chats in the shopping domain, using bag-of-words (BoW), structural information and utterance dependency features. [sent-337, score-1.684]
</p><p>98 Of the learners we experimented with, CRFs performed best, due to their ability to natively capture sequential dialogue act dependencies. [sent-340, score-0.95]
</p><p>99 Automatic instant messaging dialogue using statistical models and dialogue acts. [sent-472, score-1.372]
</p><p>100 Combining lexical, syntactic and prosodic cues for improved online dialog act tagging. [sent-554, score-0.365]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dialogue', 0.686), ('bow', 0.229), ('utterance', 0.211), ('utterances', 0.196), ('act', 0.195), ('acts', 0.191), ('chats', 0.189), ('live', 0.188), ('ivanovic', 0.186), ('chat', 0.139), ('dialogues', 0.117), ('customer', 0.09), ('forsyth', 0.081), ('shopping', 0.081), ('author', 0.079), ('greeting', 0.07), ('msn', 0.07), ('spoken', 0.063), ('crf', 0.06), ('stolcke', 0.058), ('yesanswer', 0.058), ('dialog', 0.058), ('bangalore', 0.058), ('classifying', 0.051), ('position', 0.049), ('yes', 0.049), ('structural', 0.048), ('ack', 0.046), ('conventionalopening', 0.046), ('damsl', 0.046), ('downplayer', 0.046), ('louwerse', 0.046), ('openquestion', 0.046), ('responseack', 0.046), ('yesnoquestion', 0.046), ('learners', 0.046), ('prosodic', 0.045), ('boolean', 0.044), ('online', 0.043), ('statement', 0.042), ('agent', 0.041), ('dependency', 0.039), ('turn', 0.037), ('lemmas', 0.037), ('request', 0.036), ('crfs', 0.035), ('brb', 0.035), ('bye', 0.035), ('conventionalclosing', 0.035), ('crossley', 0.035), ('labelauthor', 0.035), ('noanswer', 0.035), ('sridhar', 0.035), ('services', 0.035), ('shriberg', 0.033), ('samuel', 0.033), ('tf', 0.033), ('classification', 0.031), ('thanks', 0.03), ('response', 0.029), ('service', 0.028), ('discourse', 0.028), ('welcome', 0.027), ('acoustic', 0.027), ('anderson', 0.027), ('hello', 0.027), ('rq', 0.027), ('day', 0.025), ('speech', 0.025), ('dependencies', 0.024), ('cues', 0.024), ('jurafsky', 0.023), ('acknowledgement', 0.023), ('affirmative', 0.023), ('coccaro', 0.023), ('debole', 0.023), ('formulaic', 0.023), ('grau', 0.023), ('hcrc', 0.023), ('iftekharuddin', 0.023), ('misclassification', 0.023), ('natively', 0.023), ('ries', 0.023), ('witten', 0.023), ('expressive', 0.023), ('kim', 0.022), ('rochester', 0.022), ('ig', 0.022), ('telephone', 0.022), ('trains', 0.022), ('wu', 0.021), ('op', 0.021), ('accumulated', 0.021), ('conversations', 0.021), ('qu', 0.021), ('labels', 0.021), ('delivery', 0.02), ('bates', 0.02), ('adjacency', 0.02), ('casual', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="26-tfidf-1" href="./emnlp-2010-Classifying_Dialogue_Acts_in_One-on-One_Live_Chats.html">26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</a></p>
<p>Author: Su Nam Kim ; Lawrence Cavedon ; Timothy Baldwin</p><p>Abstract: We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. In particular, we investigate the effectiveness of various features and machine learners for this task. While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data.</p><p>2 0.12833893 <a title="26-tfidf-2" href="./emnlp-2010-Fusing_Eye_Gaze_with_Speech_Recognition_Hypotheses_to_Resolve_Exophoric_References_in_Situated_Dialogue.html">53 emnlp-2010-Fusing Eye Gaze with Speech Recognition Hypotheses to Resolve Exophoric References in Situated Dialogue</a></p>
<p>Author: Zahar Prasov ; Joyce Y. Chai</p><p>Abstract: In situated dialogue humans often utter linguistic expressions that refer to extralinguistic entities in the environment. Correctly resolving these references is critical yet challenging for artificial agents partly due to their limited speech recognition and language understanding capabilities. Motivated by psycholinguistic studies demonstrating a tight link between language production and human eye gaze, we have developed approaches that integrate naturally occurring human eye gaze with speech recognition hypotheses to resolve exophoric references in situated dialogue in a virtual world. In addition to incorporating eye gaze with the best recognized spoken hypothesis, we developed an algorithm to also handle multiple hypotheses modeled as word confusion networks. Our empirical results demonstrate that incorporating eye gaze with recognition hypotheses consistently outperforms the results obtained from processing recognition hypotheses alone. Incorporating eye gaze with word confusion networks further improves performance.</p><p>3 0.10293803 <a title="26-tfidf-3" href="./emnlp-2010-Towards_Conversation_Entailment%3A_An_Empirical_Investigation.html">107 emnlp-2010-Towards Conversation Entailment: An Empirical Investigation</a></p>
<p>Author: Chen Zhang ; Joyce Chai</p><p>Abstract: While a significant amount of research has been devoted to textual entailment, automated entailment from conversational scripts has received less attention. To address this limitation, this paper investigates the problem of conversation entailment: automated inference of hypotheses from conversation scripts. We examine two levels of semantic representations: a basic representation based on syntactic parsing from conversation utterances and an augmented representation taking into consideration of conversation structures. For each of these levels, we further explore two ways of capturing long distance relations between language constituents: implicit modeling based on the length of distance and explicit modeling based on actual patterns of relations. Our empirical findings have shown that the augmented representation with conversation structures is important, which achieves the best performance when combined with explicit modeling of long distance relations.</p><p>4 0.10162832 <a title="26-tfidf-4" href="./emnlp-2010-A_Game-Theoretic_Approach_to_Generating_Spatial_Descriptions.html">4 emnlp-2010-A Game-Theoretic Approach to Generating Spatial Descriptions</a></p>
<p>Author: Dave Golland ; Percy Liang ; Dan Klein</p><p>Abstract: Language is sensitive to both semantic and pragmatic effects. To capture both effects, we model language use as a cooperative game between two players: a speaker, who generates an utterance, and a listener, who responds with an action. Specifically, we consider the task of generating spatial references to objects, wherein the listener must accurately identify an object described by the speaker. We show that a speaker model that acts optimally with respect to an explicit, embedded listener model substantially outperforms one that is trained to directly generate spatial descriptions.</p><p>5 0.10090657 <a title="26-tfidf-5" href="./emnlp-2010-Better_Punctuation_Prediction_with_Dynamic_Conditional_Random_Fields.html">25 emnlp-2010-Better Punctuation Prediction with Dynamic Conditional Random Fields</a></p>
<p>Author: Wei Lu ; Hwee Tou Ng</p><p>Abstract: This paper focuses on the task of inserting punctuation symbols into transcribed conversational speech texts, without relying on prosodic cues. We investigate limitations associated with previous methods, and propose a novel approach based on dynamic conditional random fields. Different from previous work, our proposed approach is designed to jointly perform both sentence boundary and sentence type prediction, and punctuation prediction on speech utterances. We performed evaluations on a transcribed conversational speech domain consisting of both English and Chinese texts. Empirical results show that our method outperforms an approach based on linear-chain conditional random fields and other previous approaches.</p><p>6 0.063600332 <a title="26-tfidf-6" href="./emnlp-2010-Lessons_Learned_in_Part-of-Speech_Tagging_of_Conversational_Speech.html">75 emnlp-2010-Lessons Learned in Part-of-Speech Tagging of Conversational Speech</a></p>
<p>7 0.058953762 <a title="26-tfidf-7" href="./emnlp-2010-NLP_on_Spoken_Documents_Without_ASR.html">84 emnlp-2010-NLP on Spoken Documents Without ASR</a></p>
<p>8 0.044474002 <a title="26-tfidf-8" href="./emnlp-2010-Efficient_Graph-Based_Semi-Supervised_Learning_of_Structured_Tagging_Models.html">41 emnlp-2010-Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models</a></p>
<p>9 0.042094819 <a title="26-tfidf-9" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>10 0.03815328 <a title="26-tfidf-10" href="./emnlp-2010-Exploiting_Conversation_Structure_in_Unsupervised_Topic_Segmentation_for_Emails.html">48 emnlp-2010-Exploiting Conversation Structure in Unsupervised Topic Segmentation for Emails</a></p>
<p>11 0.033503965 <a title="26-tfidf-11" href="./emnlp-2010-A_Semi-Supervised_Approach_to_Improve_Classification_of_Infrequent_Discourse_Relations_Using_Feature_Vector_Extension.html">11 emnlp-2010-A Semi-Supervised Approach to Improve Classification of Infrequent Discourse Relations Using Feature Vector Extension</a></p>
<p>12 0.027813068 <a title="26-tfidf-12" href="./emnlp-2010-Improving_Gender_Classification_of_Blog_Authors.html">61 emnlp-2010-Improving Gender Classification of Blog Authors</a></p>
<p>13 0.026718268 <a title="26-tfidf-13" href="./emnlp-2010-Function-Based_Question_Classification_for_General_QA.html">51 emnlp-2010-Function-Based Question Classification for General QA</a></p>
<p>14 0.026128829 <a title="26-tfidf-14" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>15 0.026115244 <a title="26-tfidf-15" href="./emnlp-2010-Confidence_in_Structured-Prediction_Using_Confidence-Weighted_Models.html">30 emnlp-2010-Confidence in Structured-Prediction Using Confidence-Weighted Models</a></p>
<p>16 0.026091222 <a title="26-tfidf-16" href="./emnlp-2010-A_New_Approach_to_Lexical_Disambiguation_of_Arabic_Text.html">9 emnlp-2010-A New Approach to Lexical Disambiguation of Arabic Text</a></p>
<p>17 0.025955282 <a title="26-tfidf-17" href="./emnlp-2010-Joint_Training_and_Decoding_Using_Virtual_Nodes_for_Cascaded_Segmentation_and_Tagging_Tasks.html">69 emnlp-2010-Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks</a></p>
<p>18 0.025101067 <a title="26-tfidf-18" href="./emnlp-2010-Cross_Language_Text_Classification_by_Model_Translation_and_Semi-Supervised_Learning.html">33 emnlp-2010-Cross Language Text Classification by Model Translation and Semi-Supervised Learning</a></p>
<p>19 0.024086697 <a title="26-tfidf-19" href="./emnlp-2010-WikiWars%3A_A_New_Corpus_for_Research_on_Temporal_Expressions.html">122 emnlp-2010-WikiWars: A New Corpus for Research on Temporal Expressions</a></p>
<p>20 0.023768457 <a title="26-tfidf-20" href="./emnlp-2010-Incorporating_Content_Structure_into_Text_Analysis_Applications.html">64 emnlp-2010-Incorporating Content Structure into Text Analysis Applications</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.096), (1, 0.071), (2, -0.01), (3, 0.022), (4, -0.087), (5, -0.006), (6, 0.053), (7, -0.063), (8, -0.038), (9, 0.061), (10, -0.238), (11, -0.24), (12, 0.009), (13, 0.21), (14, 0.059), (15, -0.103), (16, -0.128), (17, 0.007), (18, -0.099), (19, 0.086), (20, -0.169), (21, 0.004), (22, -0.093), (23, 0.044), (24, -0.022), (25, 0.036), (26, 0.116), (27, -0.068), (28, -0.098), (29, 0.204), (30, -0.075), (31, 0.018), (32, 0.058), (33, 0.065), (34, 0.097), (35, 0.122), (36, -0.052), (37, -0.152), (38, -0.047), (39, -0.083), (40, 0.073), (41, -0.1), (42, 0.098), (43, -0.094), (44, -0.004), (45, -0.044), (46, 0.026), (47, -0.019), (48, 0.101), (49, 0.107)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97614545 <a title="26-lsi-1" href="./emnlp-2010-Classifying_Dialogue_Acts_in_One-on-One_Live_Chats.html">26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</a></p>
<p>Author: Su Nam Kim ; Lawrence Cavedon ; Timothy Baldwin</p><p>Abstract: We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. In particular, we investigate the effectiveness of various features and machine learners for this task. While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data.</p><p>2 0.80386734 <a title="26-lsi-2" href="./emnlp-2010-Fusing_Eye_Gaze_with_Speech_Recognition_Hypotheses_to_Resolve_Exophoric_References_in_Situated_Dialogue.html">53 emnlp-2010-Fusing Eye Gaze with Speech Recognition Hypotheses to Resolve Exophoric References in Situated Dialogue</a></p>
<p>Author: Zahar Prasov ; Joyce Y. Chai</p><p>Abstract: In situated dialogue humans often utter linguistic expressions that refer to extralinguistic entities in the environment. Correctly resolving these references is critical yet challenging for artificial agents partly due to their limited speech recognition and language understanding capabilities. Motivated by psycholinguistic studies demonstrating a tight link between language production and human eye gaze, we have developed approaches that integrate naturally occurring human eye gaze with speech recognition hypotheses to resolve exophoric references in situated dialogue in a virtual world. In addition to incorporating eye gaze with the best recognized spoken hypothesis, we developed an algorithm to also handle multiple hypotheses modeled as word confusion networks. Our empirical results demonstrate that incorporating eye gaze with recognition hypotheses consistently outperforms the results obtained from processing recognition hypotheses alone. Incorporating eye gaze with word confusion networks further improves performance.</p><p>3 0.65900809 <a title="26-lsi-3" href="./emnlp-2010-A_Game-Theoretic_Approach_to_Generating_Spatial_Descriptions.html">4 emnlp-2010-A Game-Theoretic Approach to Generating Spatial Descriptions</a></p>
<p>Author: Dave Golland ; Percy Liang ; Dan Klein</p><p>Abstract: Language is sensitive to both semantic and pragmatic effects. To capture both effects, we model language use as a cooperative game between two players: a speaker, who generates an utterance, and a listener, who responds with an action. Specifically, we consider the task of generating spatial references to objects, wherein the listener must accurately identify an object described by the speaker. We show that a speaker model that acts optimally with respect to an explicit, embedded listener model substantially outperforms one that is trained to directly generate spatial descriptions.</p><p>4 0.31662521 <a title="26-lsi-4" href="./emnlp-2010-Towards_Conversation_Entailment%3A_An_Empirical_Investigation.html">107 emnlp-2010-Towards Conversation Entailment: An Empirical Investigation</a></p>
<p>Author: Chen Zhang ; Joyce Chai</p><p>Abstract: While a significant amount of research has been devoted to textual entailment, automated entailment from conversational scripts has received less attention. To address this limitation, this paper investigates the problem of conversation entailment: automated inference of hypotheses from conversation scripts. We examine two levels of semantic representations: a basic representation based on syntactic parsing from conversation utterances and an augmented representation taking into consideration of conversation structures. For each of these levels, we further explore two ways of capturing long distance relations between language constituents: implicit modeling based on the length of distance and explicit modeling based on actual patterns of relations. Our empirical findings have shown that the augmented representation with conversation structures is important, which achieves the best performance when combined with explicit modeling of long distance relations.</p><p>5 0.30915481 <a title="26-lsi-5" href="./emnlp-2010-Better_Punctuation_Prediction_with_Dynamic_Conditional_Random_Fields.html">25 emnlp-2010-Better Punctuation Prediction with Dynamic Conditional Random Fields</a></p>
<p>Author: Wei Lu ; Hwee Tou Ng</p><p>Abstract: This paper focuses on the task of inserting punctuation symbols into transcribed conversational speech texts, without relying on prosodic cues. We investigate limitations associated with previous methods, and propose a novel approach based on dynamic conditional random fields. Different from previous work, our proposed approach is designed to jointly perform both sentence boundary and sentence type prediction, and punctuation prediction on speech utterances. We performed evaluations on a transcribed conversational speech domain consisting of both English and Chinese texts. Empirical results show that our method outperforms an approach based on linear-chain conditional random fields and other previous approaches.</p><p>6 0.21341723 <a title="26-lsi-6" href="./emnlp-2010-NLP_on_Spoken_Documents_Without_ASR.html">84 emnlp-2010-NLP on Spoken Documents Without ASR</a></p>
<p>7 0.21024315 <a title="26-lsi-7" href="./emnlp-2010-Lessons_Learned_in_Part-of-Speech_Tagging_of_Conversational_Speech.html">75 emnlp-2010-Lessons Learned in Part-of-Speech Tagging of Conversational Speech</a></p>
<p>8 0.19341455 <a title="26-lsi-8" href="./emnlp-2010-Improving_Gender_Classification_of_Blog_Authors.html">61 emnlp-2010-Improving Gender Classification of Blog Authors</a></p>
<p>9 0.17313914 <a title="26-lsi-9" href="./emnlp-2010-Efficient_Graph-Based_Semi-Supervised_Learning_of_Structured_Tagging_Models.html">41 emnlp-2010-Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models</a></p>
<p>10 0.15995008 <a title="26-lsi-10" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>11 0.15927464 <a title="26-lsi-11" href="./emnlp-2010-WikiWars%3A_A_New_Corpus_for_Research_on_Temporal_Expressions.html">122 emnlp-2010-WikiWars: A New Corpus for Research on Temporal Expressions</a></p>
<p>12 0.14687388 <a title="26-lsi-12" href="./emnlp-2010-A_Semi-Supervised_Approach_to_Improve_Classification_of_Infrequent_Discourse_Relations_Using_Feature_Vector_Extension.html">11 emnlp-2010-A Semi-Supervised Approach to Improve Classification of Infrequent Discourse Relations Using Feature Vector Extension</a></p>
<p>13 0.13449022 <a title="26-lsi-13" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>14 0.1313065 <a title="26-lsi-14" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>15 0.11983378 <a title="26-lsi-15" href="./emnlp-2010-Turbo_Parsers%3A_Dependency_Parsing_by_Approximate_Variational_Inference.html">110 emnlp-2010-Turbo Parsers: Dependency Parsing by Approximate Variational Inference</a></p>
<p>16 0.10743449 <a title="26-lsi-16" href="./emnlp-2010-A_Multi-Pass_Sieve_for_Coreference_Resolution.html">8 emnlp-2010-A Multi-Pass Sieve for Coreference Resolution</a></p>
<p>17 0.10195457 <a title="26-lsi-17" href="./emnlp-2010-Modeling_Perspective_Using_Adaptor_Grammars.html">81 emnlp-2010-Modeling Perspective Using Adaptor Grammars</a></p>
<p>18 0.099405862 <a title="26-lsi-18" href="./emnlp-2010-Negative_Training_Data_Can_be_Harmful_to_Text_Classification.html">85 emnlp-2010-Negative Training Data Can be Harmful to Text Classification</a></p>
<p>19 0.094829001 <a title="26-lsi-19" href="./emnlp-2010-Two_Decades_of_Unsupervised_POS_Induction%3A_How_Far_Have_We_Come%3F.html">111 emnlp-2010-Two Decades of Unsupervised POS Induction: How Far Have We Come?</a></p>
<p>20 0.09364295 <a title="26-lsi-20" href="./emnlp-2010-Cross_Language_Text_Classification_by_Model_Translation_and_Semi-Supervised_Learning.html">33 emnlp-2010-Cross Language Text Classification by Model Translation and Semi-Supervised Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.023), (10, 0.012), (11, 0.021), (12, 0.026), (25, 0.118), (29, 0.053), (30, 0.012), (32, 0.018), (52, 0.019), (56, 0.058), (62, 0.018), (66, 0.08), (72, 0.047), (76, 0.316), (79, 0.013), (82, 0.012), (87, 0.019), (89, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92306298 <a title="26-lda-1" href="./emnlp-2010-An_Approach_of_Generating_Personalized_Views_from_Normalized_Electronic_Dictionaries_%3A_A_Practical_Experiment_on_Arabic_Language.html">16 emnlp-2010-An Approach of Generating Personalized Views from Normalized Electronic Dictionaries : A Practical Experiment on Arabic Language</a></p>
<p>Author: Aida Khemakhem ; Bilel Gargouri ; Abdelmajid Ben Hamadou</p><p>Abstract: Electronic dictionaries covering all natural language levels are very relevant for the human use as well as for the automatic processing use, namely those constructed with respect to international standards. Such dictionaries are characterized by a complex structure and an important access time when using a querying system. However, the need of a user is generally limited to a part of such a dictionary according to his domain and expertise level which corresponds to a specialized dictionary. Given the importance of managing a unified dictionary and considering the personalized needs of users, we propose an approach for generating personalized views starting from a normalized dictionary with respect to Lexical Markup Framework LMF-ISO 24613 norm. This approach provides the re-use of already defined views for a community of users by managing their profiles information and promoting the materialization of the generated views. It is composed of four main steps: (i) the projection of data categories controlled by a set of constraints (related to the user‟s profiles), (ii) the selection of values with consistency checking, (iii) the automatic generation of the query‟s model and finally, (iv) the refinement of the view. The proposed approach was con- solidated by carrying out an experiment on an LMF normalized Arabic dictionary. 1</p><p>2 0.89977705 <a title="26-lda-2" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>Author: Stephen Boxwell ; Dennis Mehay ; Chris Brew</p><p>Abstract: In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. In this paper, we build a system that allows information to flow in both directions. We make use of semantic role predictions in choosing a single-best parse. This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. Our system penalizes parses that give rise to low-scoring semantic roles. To explore the consequences of this we perform two experiments. First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser’s packed chart. For both experiments, the resulting semantic predictions are then used to select parses. Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. We find that SRL performance can be improved over this baseline by selecting parses with likely semantic roles.</p><p>same-paper 3 0.78321648 <a title="26-lda-3" href="./emnlp-2010-Classifying_Dialogue_Acts_in_One-on-One_Live_Chats.html">26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</a></p>
<p>Author: Su Nam Kim ; Lawrence Cavedon ; Timothy Baldwin</p><p>Abstract: We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. In particular, we investigate the effectiveness of various features and machine learners for this task. While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data.</p><p>4 0.74085164 <a title="26-lda-4" href="./emnlp-2010-Effects_of_Empty_Categories_on_Machine_Translation.html">40 emnlp-2010-Effects of Empty Categories on Machine Translation</a></p>
<p>Author: Tagyoung Chung ; Daniel Gildea</p><p>Abstract: We examine effects that empty categories have on machine translation. Empty categories are elements in parse trees that lack corresponding overt surface forms (words) such as dropped pronouns and markers for control constructions. We start by training machine translation systems with manually inserted empty elements. We find that inclusion of some empty categories in training data improves the translation result. We expand the experiment by automatically inserting these elements into a larger data set using various methods and training on the modified corpus. We show that even when automatic prediction of null elements is not highly accurate, it nevertheless improves the end translation result.</p><p>5 0.48898268 <a title="26-lda-5" href="./emnlp-2010-Automatic_Discovery_of_Manner_Relations_and_its_Applications.html">21 emnlp-2010-Automatic Discovery of Manner Relations and its Applications</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: This paper presents a method for the automatic discovery of MANNER relations from text. An extended definition of MANNER is proposed, including restrictions on the sorts of concepts that can be part of its domain and range. The connections with other relations and the lexico-syntactic patterns that encode MANNER are analyzed. A new feature set specialized on MANNER detection is depicted and justified. Experimental results show improvement over previous attempts to extract MANNER. Combinations of MANNER with other semantic relations are also discussed.</p><p>6 0.48286068 <a title="26-lda-6" href="./emnlp-2010-Fusing_Eye_Gaze_with_Speech_Recognition_Hypotheses_to_Resolve_Exophoric_References_in_Situated_Dialogue.html">53 emnlp-2010-Fusing Eye Gaze with Speech Recognition Hypotheses to Resolve Exophoric References in Situated Dialogue</a></p>
<p>7 0.47284037 <a title="26-lda-7" href="./emnlp-2010-Context_Comparison_of_Bursty_Events_in_Web_Search_and_Online_Media.html">32 emnlp-2010-Context Comparison of Bursty Events in Web Search and Online Media</a></p>
<p>8 0.46246973 <a title="26-lda-8" href="./emnlp-2010-Efficient_Incremental_Decoding_for_Tree-to-String_Translation.html">42 emnlp-2010-Efficient Incremental Decoding for Tree-to-String Translation</a></p>
<p>9 0.45907408 <a title="26-lda-9" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>10 0.45749995 <a title="26-lda-10" href="./emnlp-2010-Soft_Syntactic_Constraints_for_Hierarchical_Phrase-Based_Translation_Using_Latent_Syntactic_Distributions.html">98 emnlp-2010-Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions</a></p>
<p>11 0.45745605 <a title="26-lda-11" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>12 0.45653507 <a title="26-lda-12" href="./emnlp-2010-Towards_Conversation_Entailment%3A_An_Empirical_Investigation.html">107 emnlp-2010-Towards Conversation Entailment: An Empirical Investigation</a></p>
<p>13 0.45458475 <a title="26-lda-13" href="./emnlp-2010-Improved_Fully_Unsupervised_Parsing_with_Zoomed_Learning.html">60 emnlp-2010-Improved Fully Unsupervised Parsing with Zoomed Learning</a></p>
<p>14 0.4470174 <a title="26-lda-14" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>15 0.44662601 <a title="26-lda-15" href="./emnlp-2010-Handling_Noisy_Queries_in_Cross_Language_FAQ_Retrieval.html">55 emnlp-2010-Handling Noisy Queries in Cross Language FAQ Retrieval</a></p>
<p>16 0.44423217 <a title="26-lda-16" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>17 0.44251227 <a title="26-lda-17" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>18 0.43536288 <a title="26-lda-18" href="./emnlp-2010-Evaluating_the_Impact_of_Alternative_Dependency_Graph_Encodings_on_Solving_Event_Extraction_Tasks.html">46 emnlp-2010-Evaluating the Impact of Alternative Dependency Graph Encodings on Solving Event Extraction Tasks</a></p>
<p>19 0.43243024 <a title="26-lda-19" href="./emnlp-2010-Non-Isomorphic_Forest_Pair_Translation.html">86 emnlp-2010-Non-Isomorphic Forest Pair Translation</a></p>
<p>20 0.43131366 <a title="26-lda-20" href="./emnlp-2010-Function-Based_Question_Classification_for_General_QA.html">51 emnlp-2010-Function-Based Question Classification for General QA</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
