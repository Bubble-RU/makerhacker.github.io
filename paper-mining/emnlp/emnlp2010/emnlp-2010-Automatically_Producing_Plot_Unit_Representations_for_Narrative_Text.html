<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-24" href="#">emnlp2010-24</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</h1>
<br/><p>Source: <a title="emnlp-2010-24-pdf" href="http://aclweb.org/anthology//D/D10/D10-1008.pdf">pdf</a></p><p>Author: Amit Goyal ; Ellen Riloff ; Hal Daume III</p><p>Abstract: In the 1980s, plot units were proposed as a conceptual knowledge structure for representing and summarizing narrative stories. Our research explores whether current NLP technology can be used to automatically produce plot unit representations for narrative text. We create a system called AESOP that exploits a variety of existing resources to identify affect states and applies “projection rules” to map the affect states onto the characters in a story. We also use corpus-based techniques to generate a new type of affect knowledge base: verbs that impart positive or negative states onto their patients (e.g., being eaten is an undesirable state, but being fed is a desirable state). We harvest these “patient polarity verbs” from a Web corpus using two techniques: co-occurrence with Evil/Kind Agent patterns, and bootstrapping over conjunctions of verbs. We evaluate the plot unit representations produced by our system on a small collection of Aesop’s fables.</p><p>Reference: <a title="emnlp-2010-24-reference" href="../emnlp2010_reference/emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract In the 1980s, plot units were proposed as a conceptual knowledge structure for representing and summarizing narrative stories. [sent-4, score-0.404]
</p><p>2 Our research explores whether current NLP technology can be used to automatically produce plot unit representations for narrative text. [sent-5, score-0.56]
</p><p>3 We create a system called AESOP that exploits a variety of existing resources to identify affect states and applies “projection rules” to  map the affect states onto the characters in a story. [sent-6, score-1.549]
</p><p>4 We also use corpus-based techniques to generate a new type of affect knowledge base: verbs that impart positive or negative states onto their patients (e. [sent-7, score-1.132]
</p><p>5 We evaluate the plot unit representations produced by our system on a small collection of Aesop’s fables. [sent-11, score-0.388]
</p><p>6 1 Introduction In the 1980s, plot units (Lehnert, 1981) were proposed as a knowledge structure for representing narrative stories and generating summaries. [sent-12, score-0.432]
</p><p>7 Plot units are fundamentally different from the story representations that preceded them because they focus on the affect states of characters and the tensions between them as the driving force behind interesting and cohesive stories. [sent-13, score-0.882]
</p><p>8 The last few decades have seen tremendous advances in NLP and the emergence of many resources that could be useful for plot unit analysis. [sent-21, score-0.382]
</p><p>9 So we embarked on a project to see whether plot unit representations can be generated automatically using current NLP technology. [sent-22, score-0.388]
</p><p>10 We created a system called AESOP that uses a variety of resources to identify words that correspond to positive, negative, and mental affect states. [sent-23, score-0.503]
</p><p>11 AESOP uses affect projection rules to map the affect states onto the characters in the story based on verb argument structure. [sent-24, score-1.415]
</p><p>12 Additionally, affect states are inferred based on syntactic properties, and causal and cross-character links are created using simple heuristics. [sent-25, score-0.952]
</p><p>13 Affect states often arise from actions that produce  good or bad states for the character that is acted upon. [sent-26, score-0.798]
</p><p>14 For example, “the cat ate the mouse ” produces a negative state for the mouse because being eaten is bad. [sent-27, score-0.363]
</p><p>15 Similarly, “the man fed the dog ” produces a positive state for the dog because being fed is generally good. [sent-28, score-0.367]
</p><p>16 We create a new type of lexicon consisting of patient polarity verbs (PPVs) that impart positive or negative states on their patients. [sent-32, score-0.975]
</p><p>17 These verbs reflect world knowledge about desirable/undesirable states for animate beings; for example, being fed, paid or adopted are generally desirable states, while being eaten, chased or hospitalized are generally undesirable states. [sent-33, score-0.504]
</p><p>18 We evaluate the plot unit representations produced by our system on a small collection of fables. [sent-37, score-0.388]
</p><p>19 2  Overview of Plot Units  Plot unit structures consist of affect states for each character, and links defining the relationships between them. [sent-38, score-0.913]
</p><p>20 Plot units include three types of affect states: positive (+), negative (-), and mental (M). [sent-39, score-0.75]
</p><p>21 Affect states can be connected by causal links and cross-character links, which explain how the narrative hangs together. [sent-40, score-0.648]
</p><p>22 Causal links exist between affect states for the same character and have four types: motivation (m), actualization (a), termination (t) and equivalence (e). [sent-41, score-0.933]
</p><p>23 To see a concrete example of a plot unit representation, a short fable, “The Father and His Sons,” is shown in Figure 1(a) and our annotation of its plot unit structure is shown in Figure 1(b). [sent-44, score-0.712]
</p><p>24 In this fable, there are two characters, the “Father” and (collectively) the “Sons”, who go through a series of affect states depicted chronologically in the two columns. [sent-45, score-0.706]
</p><p>25 The first affect state (a1) is produced from sentence #1 (s1) and is a negative state for the sons because they are quarreling. [sent-46, score-0.821]
</p><p>26 This state is shared by the 78 father (via a cross-character link) who has a negative annoyance state (a2). [sent-47, score-0.416]
</p><p>27 This latter structure (the second gray region) is an HONORED REQUEST plot unit structure. [sent-61, score-0.394]
</p><p>28 We briefly overview the variety of situations that can be represented by affect states in plot units. [sent-64, score-0.901]
</p><p>29 For example, “Max was disappointed” produces a negative affect state for Max, and “Max was pleased” produces a positive affect state for Max. [sent-66, score-1.296]
</p><p>30 Situational Affect States: Positive and negative affect states can represent good and bad situational states that characters find themselves in. [sent-67, score-1.259]
</p><p>31 These states do not represent emotion, but indicate whether a situation (state) is good or bad for a character based on world knowledge. [sent-68, score-0.439]
</p><p>32 aFnor example, “atyhe b wolf asked an eagle to extract the bone ” is a directive speech act that indicates the wolf’s plan to resolve its negative state (having a bone stuck). [sent-80, score-0.508]
</p><p>33 This example illustrates how a negative state (bone stuck) can motivate a mental state (plan). [sent-81, score-0.395]
</p><p>34 Fucoer example, if the eagle successfully extracts the bone from the wolf’s throat, then both the wolf and the  eagle will have positive affect states because both were successful in their respective goals. [sent-89, score-0.978]
</p><p>35 When a character is 79  acted upon (the patient of a verb), then the character may be in a positive or negative state depending upon whether the action was good or bad for them based on world knowledge. [sent-91, score-0.789]
</p><p>36 Consequently, we decided to create a lexicon of patient polarity verbs that produce positive or negative states for their patients. [sent-93, score-0.993]
</p><p>37 4  AESOP: Automatically Generating Plot Unit Representations  Our system, AESOP, automatically creates plot unit representations for narrative text. [sent-96, score-0.518]
</p><p>38 AESOP has four main steps: affect state recognition, character identification, affect state projection, and link creation. [sent-97, score-1.143]
</p><p>39 During affect state recognition, AESOP identifies words that may be associated with positive, negative, and mental states. [sent-98, score-0.574]
</p><p>40 AESOP then identifies the main characters in the story and applies affect projection rules to map the affect states onto these characters. [sent-99, score-1.352]
</p><p>41 During this process, some additional affect states are inferred based on verb argument structure. [sent-100, score-0.785]
</p><p>42 Finally, AESOP creates cross-character links and causal links between affect states. [sent-101, score-0.718]
</p><p>43 We also present two corpus-based methods to automatically produce a new resource for affect state recognition: a patient polarity verb lexicon. [sent-102, score-0.909]
</p><p>44 1 Recognizing Affect States The basic building blocks of plot units are affect states which come in three flavors: positive, negative, and mental. [sent-106, score-0.956]
</p><p>45 We use the verbs listed for these classes to produce M, +, and - affect states. [sent-117, score-0.522]
</p><p>46 , 2005b): We used the• w MoPrdQs Alis Lteedx as having positive or negative es uesnteidment polarity to produce +/- states, when they occur with the designated part-of-speech. [sent-119, score-0.378]
</p><p>47 , 2005): Wanet cus Oedri ethntea wioonrd Lse xliicstoend as having positive or negative polarity to produce +/- affect states, when they occur with the designated part-of-speech. [sent-126, score-0.772]
</p><p>48 3  Mapping Affect States onto Characters  Plot unit representations are not just a set of affect states, but they are structures that capture the 1We only selected fables that had two main characters. [sent-143, score-0.753]
</p><p>49 80 chronological ordering of states for each character as the narrative progresses. [sent-144, score-0.514]
</p><p>50 Consequently, every affect state needs to be attributed to a character. [sent-145, score-0.491]
</p><p>51 Since most plots revolve around events, we use verb argument structure as the primary means for projecting affect states onto characters. [sent-146, score-0.825]
</p><p>52 We developed four affect projection rules that orchestrate how affect states are assigned to the characters. [sent-147, score-1.159]
</p><p>53 2 The rules only project affect states onto AGENTS and PATIENTS that refer to a character in the story. [sent-151, score-0.884]
</p><p>54 All affect tags assigned to the VP are projected onto the AGENT. [sent-155, score-0.474]
</p><p>55 Example: “Mary laughed (+) ” projects a + affect state onto Mary. [sent-156, score-0.571]
</p><p>56 All affect tags assigned to the VP are projected onto the PATIENT. [sent-159, score-0.474]
</p><p>57 Example: “John was rewarded (+), projects a + affect state onto John. [sent-160, score-0.571]
</p><p>58 If the PATIENT is a character, then all affect tags associated with the VP are projected onto the PATIENT. [sent-163, score-0.474]
</p><p>59 Finally, if an adverb or adjectival phrase has affect, then that affect is mapped onto the preceding VP and the rules above are applied. [sent-171, score-0.5]
</p><p>60 However, we identified two cases where affect states often can be inferred based on syntactic properties. [sent-177, score-0.722]
</p><p>61 Consequently, this action should produce a positive affect state for John. [sent-182, score-0.665]
</p><p>62 To capture this intuition, in rule #4 if VERB 1 does not already have an affect state assigned to it then we produce an inferred mental state for the AGENT. [sent-191, score-0.779]
</p><p>63 5 Causal and Cross-Character Links Our research is focused primarily on creating affect states for characters, but plot unit structures also include cross-character links to connect states that are shared across characters and causal links between states for a single character. [sent-194, score-2.017]
</p><p>64 A crosscharacter link is created when two characters in a clause have affect states that originated from the same word. [sent-196, score-0.826]
</p><p>65 A causal link is created between each pair of (chronologically) consecutive affect states  for the same character. [sent-197, score-0.883]
</p><p>66 Currently, AESOP only produces forward causal links (motivation (m), actualization (a)) and does not produce backward causal links (equivalence (e), termination (t)). [sent-198, score-0.611]
</p><p>67 two affect states, the order and types ofthe two states uniquely determine which label it gets (m or a). [sent-201, score-0.682]
</p><p>68 Our intuition was that an “evil” agent will typically perform actions that are bad for the patient, while a “kind” agent will typically perform actions that are good for the patient. [sent-210, score-0.493]
</p><p>69 We manually identified 40 stereotypically evil agent words, such as monster, villain, terrorist, and murderer, and 40 stereotypically kind agent words, such as hero, angel, benefactor, and rescuer. [sent-211, score-0.629]
</p><p>70 5  Evaluation  Plot unit analysis of narrative text is enormously complex the idea of creating gold standard plot unit annotations seemed like a monumental task. [sent-241, score-0.651]
</p><p>71 We collected 34 Aesop’s fables from a web site4, choosing fables that have a true plot (some only contain quotes) and exactly two characters. [sent-245, score-0.439]
</p><p>72 In our gold standard, each affect state is annotated with the set of clauses that could legitimately produce it. [sent-252, score-0.533]
</p><p>73 During evaluation, the systemproduced affect states must be generated from the correct clause. [sent-254, score-0.682]
</p><p>74 However, for affect states that could be ascribed to multiple clauses in a sentence, the evaluation was done at the sentence level. [sent-255, score-0.682]
</p><p>75 In this case, the system-produced affect state must come from the sentence that contains one of those clauses. [sent-256, score-0.491]
</p><p>76 2  Evaluation of Affect States using External Resources  Our first set of experiments evaluates the quality of the affect states produced by AESOP using only the  external resources. [sent-262, score-0.682]
</p><p>77 Note that M and + states are also generated from the negative PPVs because they are inferred during affect projection (Section 4. [sent-274, score-0.897]
</p><p>78 The precision drop is likely due to redundancy, which creates spurious affect states. [sent-280, score-0.394]
</p><p>79 If two different words have negative polarity but refer to the same event, then only one negative affect state should be generated. [sent-281, score-0.845]
</p><p>80 But AE83 SOP will generate two affect states, so one will be spurious. [sent-282, score-0.394]
</p><p>81 The positive PPVs did generate several correct affect states (including a - state when a positive PPV was negated), but also many spurious states. [sent-287, score-0.979]
</p><p>82 Evaluating the impact of PPVs on plot unit struc-  ×  tures is an indirect way of assessing their quality because creating plot units involves many steps. [sent-293, score-0.63]
</p><p>83 The Kind Agent 5The top-ranked Evil/Kind Agent PPV lists (θ > 1) which yields 1203 kind PPVs, and 477 evil PPVs, the top 164 positive Basilisk verbs, and the 678 (unique) negative Basilisk verbs. [sent-315, score-0.393]
</p><p>84 The second column of Table 3 shows the perfor-  mance of AESOP when using gold standard affect states. [sent-329, score-0.394]
</p><p>85 Our simple heuristics for creating links work surprisingly well for xchar and a links when given perfect affect states. [sent-330, score-0.619]
</p><p>86 The third column ofTable 3 shows the results when using systemgenerated affect states. [sent-333, score-0.394]
</p><p>87 First, we created a Baseline system that is identical to AESOP except that it does not use the affect projection rules. [sent-339, score-0.451]
</p><p>88 Instead, it naively projects every affect state in a clause onto every character in that clause. [sent-340, score-0.667]
</p><p>89 This illustrates the importance of the projection rules for mapping affect states onto characters. [sent-342, score-0.845]
</p><p>90 3F 4531  Our gold standard includes pure inference affect states that are critical to the plot unit structure but come from world knowledge outside the story itself. [sent-346, score-1.072]
</p><p>91 Of 157 affect states in our test set, 14 were pure inference states. [sent-347, score-0.682]
</p><p>92 Consequently, AESOP generates more spurious affect states from the quotations when using the gold standard annotations. [sent-358, score-0.682]
</p><p>93 Other preliminary work has begun to look at plot unit modelling for single character stories (Appling and Riedl, 2009). [sent-360, score-0.48]
</p><p>94 , (Elson and McKeown, 2009)), automatic affect state analysis (Alm, 2009), and automated learning of scripts (Schank and Abelson, 1977) and other con85 ceptual knowledge structures (e. [sent-363, score-0.491]
</p><p>95 We showed that affect projection rules can effectively assign affect states to characters. [sent-374, score-1.159]
</p><p>96 Some aspects of affect state identification are closely related to Hopper and Thompson’s (1980) theory oftransitivity. [sent-376, score-0.491]
</p><p>97 AESOP produces affect states with an F score of 45%. [sent-381, score-0.73]
</p><p>98 Identifying positive states appears to be more difficult than negative or mental states. [sent-382, score-0.589]
</p><p>99 This includes the M affect states that initiate plans, the +/- completion states, as well as their corresponding links. [sent-384, score-0.682]
</p><p>100 We suspect that the relatively low recall on positive  affect states is due to our inability to accurately identify successful plan completions. [sent-385, score-0.816]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('affect', 0.394), ('ppvs', 0.354), ('states', 0.288), ('aesop', 0.268), ('plot', 0.219), ('patient', 0.195), ('agent', 0.19), ('ppv', 0.159), ('basilisk', 0.157), ('unit', 0.137), ('evil', 0.136), ('causal', 0.136), ('narrative', 0.13), ('negative', 0.118), ('polarity', 0.118), ('sons', 0.115), ('fables', 0.11), ('father', 0.104), ('positive', 0.1), ('state', 0.097), ('character', 0.096), ('links', 0.094), ('verbs', 0.086), ('mental', 0.083), ('onto', 0.08), ('characters', 0.079), ('plans', 0.075), ('fable', 0.073), ('vp', 0.069), ('link', 0.065), ('verb', 0.063), ('actualization', 0.061), ('bone', 0.061), ('wolf', 0.061), ('fed', 0.061), ('coreference', 0.059), ('projection', 0.057), ('framenet', 0.057), ('units', 0.055), ('bad', 0.055), ('eaten', 0.052), ('exhortations', 0.049), ('subgoal', 0.049), ('produces', 0.048), ('lexicon', 0.046), ('riloff', 0.045), ('agents', 0.043), ('produce', 0.042), ('rescued', 0.042), ('patients', 0.042), ('bootstrapping', 0.042), ('inferred', 0.04), ('kind', 0.039), ('act', 0.039), ('wilson', 0.038), ('gray', 0.038), ('goals', 0.037), ('eagle', 0.037), ('quarreling', 0.037), ('situational', 0.037), ('stereotypically', 0.037), ('teach', 0.037), ('xchar', 0.037), ('neutral', 0.036), ('chambers', 0.035), ('story', 0.034), ('plan', 0.034), ('representations', 0.032), ('desirable', 0.032), ('action', 0.032), ('killed', 0.031), ('resolver', 0.031), ('orientation', 0.031), ('actions', 0.029), ('choi', 0.029), ('conjunctions', 0.029), ('takamura', 0.028), ('harm', 0.028), ('lehnert', 0.028), ('seemed', 0.028), ('stuck', 0.028), ('stories', 0.028), ('sentiment', 0.028), ('rule', 0.026), ('resources', 0.026), ('voice', 0.026), ('baker', 0.026), ('undesirable', 0.026), ('rules', 0.026), ('adopted', 0.024), ('bundle', 0.024), ('chased', 0.024), ('chronologically', 0.024), ('emotion', 0.024), ('fujiki', 0.024), ('hopper', 0.024), ('hospitalized', 0.024), ('impart', 0.024), ('kasch', 0.024), ('mouse', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999881 <a title="24-tfidf-1" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>Author: Amit Goyal ; Ellen Riloff ; Hal Daume III</p><p>Abstract: In the 1980s, plot units were proposed as a conceptual knowledge structure for representing and summarizing narrative stories. Our research explores whether current NLP technology can be used to automatically produce plot unit representations for narrative text. We create a system called AESOP that exploits a variety of existing resources to identify affect states and applies “projection rules” to map the affect states onto the characters in a story. We also use corpus-based techniques to generate a new type of affect knowledge base: verbs that impart positive or negative states onto their patients (e.g., being eaten is an undesirable state, but being fed is a desirable state). We harvest these “patient polarity verbs” from a Web corpus using two techniques: co-occurrence with Evil/Kind Agent patterns, and bootstrapping over conjunctions of verbs. We evaluate the plot unit representations produced by our system on a small collection of Aesop’s fables.</p><p>2 0.096329242 <a title="24-tfidf-2" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>Author: Ahmed Hassan ; Vahed Qazvinian ; Dragomir Radev</p><p>Abstract: Mining sentiment from user generated content is a very important task in Natural Language Processing. An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web. Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums. Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics. In this work, we present a method to identify the attitude of participants in an online discussion toward one another. This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative. This is different from most of the research on social networks that has focused almost exclusively on positive links. The method is exper- imentally tested using a manually labeled set of discussion posts. The results show that the proposed method is capable of identifying attitudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.</p><p>3 0.092952058 <a title="24-tfidf-3" href="./emnlp-2010-Crouching_Dirichlet%2C_Hidden_Markov_Model%3A_Unsupervised_POS_Tagging_with_Context_Local_Tag_Generation.html">34 emnlp-2010-Crouching Dirichlet, Hidden Markov Model: Unsupervised POS Tagging with Context Local Tag Generation</a></p>
<p>Author: Taesun Moon ; Katrin Erk ; Jason Baldridge</p><p>Abstract: We define the crouching Dirichlet, hidden Markov model (CDHMM), an HMM for partof-speech tagging which draws state prior distributions for each local document context. This simple modification of the HMM takes advantage of the dichotomy in natural language between content and function words. In contrast, a standard HMM draws all prior distributions once over all states and it is known to perform poorly in unsupervised and semisupervised POS tagging. This modification significantly improves unsupervised POS tagging performance across several measures on five data sets for four languages. We also show that simply using different hyperparameter values for content and function word states in a standard HMM (which we call HMM+) is surprisingly effective.</p><p>4 0.088859737 <a title="24-tfidf-4" href="./emnlp-2010-Unsupervised_Discovery_of_Negative_Categories_in_Lexicon_Bootstrapping.html">112 emnlp-2010-Unsupervised Discovery of Negative Categories in Lexicon Bootstrapping</a></p>
<p>Author: Tara McIntosh</p><p>Abstract: Multi-category bootstrapping algorithms were developed to reduce semantic drift. By extracting multiple semantic lexicons simultaneously, a category’s search space may be restricted. The best results have been achieved through reliance on manually crafted negative categories. Unfortunately, identifying these categories is non-trivial, and their use shifts the unsupervised bootstrapping paradigm towards a supervised framework. We present NEG-FINDER, the first approach for discovering negative categories automatically. NEG-FINDER exploits unsupervised term clustering to generate multiple negative categories during bootstrapping. Our algorithm effectively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert.</p><p>5 0.084232509 <a title="24-tfidf-5" href="./emnlp-2010-SRL-Based_Verb_Selection_for_ESL.html">95 emnlp-2010-SRL-Based Verb Selection for ESL</a></p>
<p>Author: Xiaohua Liu ; Bo Han ; Kuan Li ; Stephan Hyeonjun Stiller ; Ming Zhou</p><p>Abstract: In this paper we develop an approach to tackle the problem of verb selection for learners of English as a second language (ESL) by using features from the output of Semantic Role Labeling (SRL). Unlike existing approaches to verb selection that use local features such as n-grams, our approach exploits semantic features which explicitly model the usage context of the verb. The verb choice highly depends on its usage context which is not consistently captured by local features. We then combine these semantic features with other local features under the generalized perceptron learning framework. Experiments on both indomain and out-of-domain corpora show that our approach outperforms the baseline and achieves state-of-the-art performance. 1</p><p>6 0.075494468 <a title="24-tfidf-6" href="./emnlp-2010-Negative_Training_Data_Can_be_Harmful_to_Text_Classification.html">85 emnlp-2010-Negative Training Data Can be Harmful to Text Classification</a></p>
<p>7 0.066461071 <a title="24-tfidf-7" href="./emnlp-2010-Multi-Level_Structured_Models_for_Document-Level_Sentiment_Classification.html">83 emnlp-2010-Multi-Level Structured Models for Document-Level Sentiment Classification</a></p>
<p>8 0.057411727 <a title="24-tfidf-8" href="./emnlp-2010-A_Fast_Decoder_for_Joint_Word_Segmentation_and_POS-Tagging_Using_a_Single_Discriminative_Model.html">2 emnlp-2010-A Fast Decoder for Joint Word Segmentation and POS-Tagging Using a Single Discriminative Model</a></p>
<p>9 0.056784589 <a title="24-tfidf-9" href="./emnlp-2010-A_Multi-Pass_Sieve_for_Coreference_Resolution.html">8 emnlp-2010-A Multi-Pass Sieve for Coreference Resolution</a></p>
<p>10 0.053998176 <a title="24-tfidf-10" href="./emnlp-2010-Improving_Mention_Detection_Robustness_to_Noisy_Input.html">62 emnlp-2010-Improving Mention Detection Robustness to Noisy Input</a></p>
<p>11 0.050588526 <a title="24-tfidf-11" href="./emnlp-2010-Automatic_Discovery_of_Manner_Relations_and_its_Applications.html">21 emnlp-2010-Automatic Discovery of Manner Relations and its Applications</a></p>
<p>12 0.050145213 <a title="24-tfidf-12" href="./emnlp-2010-Incorporating_Content_Structure_into_Text_Analysis_Applications.html">64 emnlp-2010-Incorporating Content Structure into Text Analysis Applications</a></p>
<p>13 0.046204343 <a title="24-tfidf-13" href="./emnlp-2010-Automatic_Detection_and_Classification_of_Social_Events.html">20 emnlp-2010-Automatic Detection and Classification of Social Events</a></p>
<p>14 0.046203326 <a title="24-tfidf-14" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>15 0.042341545 <a title="24-tfidf-15" href="./emnlp-2010-Jointly_Modeling_Aspects_and_Opinions_with_a_MaxEnt-LDA_Hybrid.html">70 emnlp-2010-Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid</a></p>
<p>16 0.039642263 <a title="24-tfidf-16" href="./emnlp-2010-An_Efficient_Algorithm_for_Unsupervised_Word_Segmentation_with_Branching_Entropy_and_MDL.html">17 emnlp-2010-An Efficient Algorithm for Unsupervised Word Segmentation with Branching Entropy and MDL</a></p>
<p>17 0.039187297 <a title="24-tfidf-17" href="./emnlp-2010-Learning_First-Order_Horn_Clauses_from_Web_Text.html">72 emnlp-2010-Learning First-Order Horn Clauses from Web Text</a></p>
<p>18 0.037275869 <a title="24-tfidf-18" href="./emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields.html">49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</a></p>
<p>19 0.03716943 <a title="24-tfidf-19" href="./emnlp-2010-Joint_Training_and_Decoding_Using_Virtual_Nodes_for_Cascaded_Segmentation_and_Tagging_Tasks.html">69 emnlp-2010-Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks</a></p>
<p>20 0.037167054 <a title="24-tfidf-20" href="./emnlp-2010-Enhancing_Domain_Portability_of_Chinese_Segmentation_Model_Using_Chi-Square_Statistics_and_Bootstrapping.html">43 emnlp-2010-Enhancing Domain Portability of Chinese Segmentation Model Using Chi-Square Statistics and Bootstrapping</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.147), (1, 0.102), (2, -0.03), (3, 0.044), (4, -0.015), (5, -0.051), (6, 0.071), (7, -0.118), (8, 0.026), (9, -0.041), (10, 0.031), (11, -0.032), (12, -0.011), (13, -0.144), (14, 0.045), (15, 0.081), (16, 0.059), (17, 0.043), (18, -0.138), (19, -0.011), (20, -0.212), (21, -0.063), (22, -0.094), (23, -0.129), (24, -0.044), (25, 0.085), (26, 0.125), (27, 0.006), (28, 0.266), (29, -0.105), (30, 0.074), (31, 0.171), (32, 0.004), (33, 0.101), (34, 0.06), (35, 0.006), (36, 0.037), (37, -0.047), (38, -0.036), (39, 0.188), (40, 0.003), (41, -0.178), (42, 0.123), (43, -0.047), (44, -0.173), (45, -0.004), (46, 0.06), (47, -0.203), (48, -0.053), (49, 0.122)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98366016 <a title="24-lsi-1" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>Author: Amit Goyal ; Ellen Riloff ; Hal Daume III</p><p>Abstract: In the 1980s, plot units were proposed as a conceptual knowledge structure for representing and summarizing narrative stories. Our research explores whether current NLP technology can be used to automatically produce plot unit representations for narrative text. We create a system called AESOP that exploits a variety of existing resources to identify affect states and applies “projection rules” to map the affect states onto the characters in a story. We also use corpus-based techniques to generate a new type of affect knowledge base: verbs that impart positive or negative states onto their patients (e.g., being eaten is an undesirable state, but being fed is a desirable state). We harvest these “patient polarity verbs” from a Web corpus using two techniques: co-occurrence with Evil/Kind Agent patterns, and bootstrapping over conjunctions of verbs. We evaluate the plot unit representations produced by our system on a small collection of Aesop’s fables.</p><p>2 0.51601571 <a title="24-lsi-2" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>Author: Ahmed Hassan ; Vahed Qazvinian ; Dragomir Radev</p><p>Abstract: Mining sentiment from user generated content is a very important task in Natural Language Processing. An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web. Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums. Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics. In this work, we present a method to identify the attitude of participants in an online discussion toward one another. This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative. This is different from most of the research on social networks that has focused almost exclusively on positive links. The method is exper- imentally tested using a manually labeled set of discussion posts. The results show that the proposed method is capable of identifying attitudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.</p><p>3 0.38942438 <a title="24-lsi-3" href="./emnlp-2010-Unsupervised_Discovery_of_Negative_Categories_in_Lexicon_Bootstrapping.html">112 emnlp-2010-Unsupervised Discovery of Negative Categories in Lexicon Bootstrapping</a></p>
<p>Author: Tara McIntosh</p><p>Abstract: Multi-category bootstrapping algorithms were developed to reduce semantic drift. By extracting multiple semantic lexicons simultaneously, a category’s search space may be restricted. The best results have been achieved through reliance on manually crafted negative categories. Unfortunately, identifying these categories is non-trivial, and their use shifts the unsupervised bootstrapping paradigm towards a supervised framework. We present NEG-FINDER, the first approach for discovering negative categories automatically. NEG-FINDER exploits unsupervised term clustering to generate multiple negative categories during bootstrapping. Our algorithm effectively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert.</p><p>4 0.35671332 <a title="24-lsi-4" href="./emnlp-2010-Automatic_Discovery_of_Manner_Relations_and_its_Applications.html">21 emnlp-2010-Automatic Discovery of Manner Relations and its Applications</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: This paper presents a method for the automatic discovery of MANNER relations from text. An extended definition of MANNER is proposed, including restrictions on the sorts of concepts that can be part of its domain and range. The connections with other relations and the lexico-syntactic patterns that encode MANNER are analyzed. A new feature set specialized on MANNER detection is depicted and justified. Experimental results show improvement over previous attempts to extract MANNER. Combinations of MANNER with other semantic relations are also discussed.</p><p>5 0.31647789 <a title="24-lsi-5" href="./emnlp-2010-Negative_Training_Data_Can_be_Harmful_to_Text_Classification.html">85 emnlp-2010-Negative Training Data Can be Harmful to Text Classification</a></p>
<p>Author: Xiao-Li Li ; Bing Liu ; See-Kiong Ng</p><p>Abstract: This paper studies the effects of training data on binary text classification and postulates that negative training data is not needed and may even be harmful for the task. Traditional binary classification involves building a classifier using labeled positive and negative training examples. The classifier is then applied to classify test instances into positive and negative classes. A fundamental assumption is that the training and test data are identically distributed. However, this assumption may not hold in practice. In this paper, we study a particular problem where the positive data is identically distributed but the negative data may or may not be so. Many practical text classification and retrieval applications fit this model. We argue that in this setting negative training data should not be used, and that PU learning can be employed to solve the problem. Empirical evaluation has been con- ducted to support our claim. This result is important as it may fundamentally change the current binary classification paradigm.</p><p>6 0.28586596 <a title="24-lsi-6" href="./emnlp-2010-Crouching_Dirichlet%2C_Hidden_Markov_Model%3A_Unsupervised_POS_Tagging_with_Context_Local_Tag_Generation.html">34 emnlp-2010-Crouching Dirichlet, Hidden Markov Model: Unsupervised POS Tagging with Context Local Tag Generation</a></p>
<p>7 0.26549193 <a title="24-lsi-7" href="./emnlp-2010-A_Fast_Decoder_for_Joint_Word_Segmentation_and_POS-Tagging_Using_a_Single_Discriminative_Model.html">2 emnlp-2010-A Fast Decoder for Joint Word Segmentation and POS-Tagging Using a Single Discriminative Model</a></p>
<p>8 0.26283434 <a title="24-lsi-8" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>9 0.25713509 <a title="24-lsi-9" href="./emnlp-2010-Nouns_are_Vectors%2C_Adjectives_are_Matrices%3A_Representing_Adjective-Noun_Constructions_in_Semantic_Space.html">87 emnlp-2010-Nouns are Vectors, Adjectives are Matrices: Representing Adjective-Noun Constructions in Semantic Space</a></p>
<p>10 0.23928611 <a title="24-lsi-10" href="./emnlp-2010-SRL-Based_Verb_Selection_for_ESL.html">95 emnlp-2010-SRL-Based Verb Selection for ESL</a></p>
<p>11 0.23761763 <a title="24-lsi-11" href="./emnlp-2010-Multi-Level_Structured_Models_for_Document-Level_Sentiment_Classification.html">83 emnlp-2010-Multi-Level Structured Models for Document-Level Sentiment Classification</a></p>
<p>12 0.22731601 <a title="24-lsi-12" href="./emnlp-2010-Learning_First-Order_Horn_Clauses_from_Web_Text.html">72 emnlp-2010-Learning First-Order Horn Clauses from Web Text</a></p>
<p>13 0.19747275 <a title="24-lsi-13" href="./emnlp-2010-Improving_Mention_Detection_Robustness_to_Noisy_Input.html">62 emnlp-2010-Improving Mention Detection Robustness to Noisy Input</a></p>
<p>14 0.19386715 <a title="24-lsi-14" href="./emnlp-2010-A_Multi-Pass_Sieve_for_Coreference_Resolution.html">8 emnlp-2010-A Multi-Pass Sieve for Coreference Resolution</a></p>
<p>15 0.17913423 <a title="24-lsi-15" href="./emnlp-2010-Towards_Conversation_Entailment%3A_An_Empirical_Investigation.html">107 emnlp-2010-Towards Conversation Entailment: An Empirical Investigation</a></p>
<p>16 0.15268995 <a title="24-lsi-16" href="./emnlp-2010-Combining_Unsupervised_and_Supervised_Alignments_for_MT%3A_An_Empirical_Study.html">29 emnlp-2010-Combining Unsupervised and Supervised Alignments for MT: An Empirical Study</a></p>
<p>17 0.15240186 <a title="24-lsi-17" href="./emnlp-2010-We%27re_Not_in_Kansas_Anymore%3A_Detecting_Domain_Changes_in_Streams.html">119 emnlp-2010-We're Not in Kansas Anymore: Detecting Domain Changes in Streams</a></p>
<p>18 0.14865546 <a title="24-lsi-18" href="./emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words.html">117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</a></p>
<p>19 0.14632547 <a title="24-lsi-19" href="./emnlp-2010-Automatic_Detection_and_Classification_of_Social_Events.html">20 emnlp-2010-Automatic Detection and Classification of Social Events</a></p>
<p>20 0.14512673 <a title="24-lsi-20" href="./emnlp-2010-Classifying_Dialogue_Acts_in_One-on-One_Live_Chats.html">26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.017), (6, 0.366), (10, 0.011), (12, 0.034), (17, 0.015), (29, 0.048), (30, 0.035), (32, 0.011), (52, 0.026), (56, 0.097), (62, 0.012), (66, 0.078), (72, 0.07), (76, 0.048), (79, 0.018), (87, 0.021), (89, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79102457 <a title="24-lda-1" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>Author: Amit Goyal ; Ellen Riloff ; Hal Daume III</p><p>Abstract: In the 1980s, plot units were proposed as a conceptual knowledge structure for representing and summarizing narrative stories. Our research explores whether current NLP technology can be used to automatically produce plot unit representations for narrative text. We create a system called AESOP that exploits a variety of existing resources to identify affect states and applies “projection rules” to map the affect states onto the characters in a story. We also use corpus-based techniques to generate a new type of affect knowledge base: verbs that impart positive or negative states onto their patients (e.g., being eaten is an undesirable state, but being fed is a desirable state). We harvest these “patient polarity verbs” from a Web corpus using two techniques: co-occurrence with Evil/Kind Agent patterns, and bootstrapping over conjunctions of verbs. We evaluate the plot unit representations produced by our system on a small collection of Aesop’s fables.</p><p>2 0.36649826 <a title="24-lda-2" href="./emnlp-2010-Summarizing_Contrastive_Viewpoints_in_Opinionated_Text.html">102 emnlp-2010-Summarizing Contrastive Viewpoints in Opinionated Text</a></p>
<p>Author: Michael Paul ; ChengXiang Zhai ; Roxana Girju</p><p>Abstract: This paper presents a two-stage approach to summarizing multiple contrastive viewpoints in opinionated text. In the first stage, we use an unsupervised probabilistic approach to model and extract multiple viewpoints in text. We experiment with a variety of lexical and syntactic features, yielding significant performance gains over bag-of-words feature sets. In the second stage, we introduce Comparative LexRank, a novel random walk formulation to score sentences and pairs of sentences from opposite viewpoints based on both their representativeness of the collection as well as their contrastiveness with each other. Exper- imental results show that the proposed approach can generate informative summaries of viewpoints in opinionated text.</p><p>3 0.36566988 <a title="24-lda-3" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>Author: Ahmed Hassan ; Vahed Qazvinian ; Dragomir Radev</p><p>Abstract: Mining sentiment from user generated content is a very important task in Natural Language Processing. An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web. Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums. Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics. In this work, we present a method to identify the attitude of participants in an online discussion toward one another. This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative. This is different from most of the research on social networks that has focused almost exclusively on positive links. The method is exper- imentally tested using a manually labeled set of discussion posts. The results show that the proposed method is capable of identifying attitudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.</p><p>4 0.36425573 <a title="24-lda-4" href="./emnlp-2010-Towards_Conversation_Entailment%3A_An_Empirical_Investigation.html">107 emnlp-2010-Towards Conversation Entailment: An Empirical Investigation</a></p>
<p>Author: Chen Zhang ; Joyce Chai</p><p>Abstract: While a significant amount of research has been devoted to textual entailment, automated entailment from conversational scripts has received less attention. To address this limitation, this paper investigates the problem of conversation entailment: automated inference of hypotheses from conversation scripts. We examine two levels of semantic representations: a basic representation based on syntactic parsing from conversation utterances and an augmented representation taking into consideration of conversation structures. For each of these levels, we further explore two ways of capturing long distance relations between language constituents: implicit modeling based on the length of distance and explicit modeling based on actual patterns of relations. Our empirical findings have shown that the augmented representation with conversation structures is important, which achieves the best performance when combined with explicit modeling of long distance relations.</p><p>5 0.36270469 <a title="24-lda-5" href="./emnlp-2010-Multi-Document_Summarization_Using_A%2A_Search_and_Discriminative_Learning.html">82 emnlp-2010-Multi-Document Summarization Using A* Search and Discriminative Learning</a></p>
<p>Author: Ahmet Aker ; Trevor Cohn ; Robert Gaizauskas</p><p>Abstract: In this paper we address two key challenges for extractive multi-document summarization: the search problem of finding the best scoring summary and the training problem of learning the best model parameters. We propose an A* search algorithm to find the best extractive summary up to a given length, which is both optimal and efficient to run. Further, we propose a discriminative training algorithm which directly maximises the quality ofthe best summary, rather than assuming a sentence-level decomposition as in earlier work. Our approach leads to significantly better results than earlier techniques across a number of evaluation metrics.</p><p>6 0.36153656 <a title="24-lda-6" href="./emnlp-2010-Title_Generation_with_Quasi-Synchronous_Grammar.html">105 emnlp-2010-Title Generation with Quasi-Synchronous Grammar</a></p>
<p>7 0.35919902 <a title="24-lda-7" href="./emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields.html">49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</a></p>
<p>8 0.35559446 <a title="24-lda-8" href="./emnlp-2010-%22Poetic%22_Statistical_Machine_Translation%3A_Rhyme_and_Meter.html">1 emnlp-2010-"Poetic" Statistical Machine Translation: Rhyme and Meter</a></p>
<p>9 0.35493332 <a title="24-lda-9" href="./emnlp-2010-Holistic_Sentiment_Analysis_Across_Languages%3A_Multilingual_Supervised_Latent_Dirichlet_Allocation.html">58 emnlp-2010-Holistic Sentiment Analysis Across Languages: Multilingual Supervised Latent Dirichlet Allocation</a></p>
<p>10 0.35457727 <a title="24-lda-10" href="./emnlp-2010-Discriminative_Sample_Selection_for_Statistical_Machine_Translation.html">35 emnlp-2010-Discriminative Sample Selection for Statistical Machine Translation</a></p>
<p>11 0.35355327 <a title="24-lda-11" href="./emnlp-2010-Context_Comparison_of_Bursty_Events_in_Web_Search_and_Online_Media.html">32 emnlp-2010-Context Comparison of Bursty Events in Web Search and Online Media</a></p>
<p>12 0.35302261 <a title="24-lda-12" href="./emnlp-2010-Joint_Training_and_Decoding_Using_Virtual_Nodes_for_Cascaded_Segmentation_and_Tagging_Tasks.html">69 emnlp-2010-Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks</a></p>
<p>13 0.35266086 <a title="24-lda-13" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>14 0.35169223 <a title="24-lda-14" href="./emnlp-2010-Classifying_Dialogue_Acts_in_One-on-One_Live_Chats.html">26 emnlp-2010-Classifying Dialogue Acts in One-on-One Live Chats</a></p>
<p>15 0.35126203 <a title="24-lda-15" href="./emnlp-2010-Incorporating_Content_Structure_into_Text_Analysis_Applications.html">64 emnlp-2010-Incorporating Content Structure into Text Analysis Applications</a></p>
<p>16 0.34957272 <a title="24-lda-16" href="./emnlp-2010-Better_Punctuation_Prediction_with_Dynamic_Conditional_Random_Fields.html">25 emnlp-2010-Better Punctuation Prediction with Dynamic Conditional Random Fields</a></p>
<p>17 0.34875488 <a title="24-lda-17" href="./emnlp-2010-Staying_Informed%3A_Supervised_and_Semi-Supervised_Multi-View_Topical_Analysis_of_Ideological_Perspective.html">100 emnlp-2010-Staying Informed: Supervised and Semi-Supervised Multi-View Topical Analysis of Ideological Perspective</a></p>
<p>18 0.34875146 <a title="24-lda-18" href="./emnlp-2010-Multi-Level_Structured_Models_for_Document-Level_Sentiment_Classification.html">83 emnlp-2010-Multi-Level Structured Models for Document-Level Sentiment Classification</a></p>
<p>19 0.34606367 <a title="24-lda-19" href="./emnlp-2010-Automatic_Detection_and_Classification_of_Social_Events.html">20 emnlp-2010-Automatic Detection and Classification of Social Events</a></p>
<p>20 0.34588784 <a title="24-lda-20" href="./emnlp-2010-Modeling_Organization_in_Student_Essays.html">80 emnlp-2010-Modeling Organization in Student Essays</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
