<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-117" href="#">emnlp2010-117</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</h1>
<br/><p>Source: <a title="emnlp-2010-117-pdf" href="http://aclweb.org/anthology//D/D10/D10-1088.pdf">pdf</a></p><p>Author: Kostadin Cholakov ; Gertjan van Noord</p><p>Abstract: Unknown words are a hindrance to the performance of hand-crafted computational grammars of natural language. However, words with incomplete and incorrect lexical entries pose an even bigger problem because they can be the cause of a parsing failure despite being listed in the lexicon of the grammar. Such lexical entries are hard to detect and even harder to correct. We employ an error miner to pinpoint words with problematic lexical entries. An automated lexical acquisition technique is then used to learn new entries for those words which allows the grammar to parse previously uncovered sentences successfully. We test our method on a large-scale grammar of Dutch and a set of sentences for which this grammar fails to produce a parse. The application of the method enables the grammar to cover 83.76% of those sentences with an accuracy of 86.15%.</p><p>Reference: <a title="emnlp-2010-117-reference" href="../emnlp2010_reference/emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 However, words with incomplete and incorrect lexical entries pose an even bigger problem because they can be the cause of a parsing failure despite being listed in the lexicon of the grammar. [sent-4, score-0.531]
</p><p>2 Such lexical entries are hard to detect and even harder to correct. [sent-5, score-0.267]
</p><p>3 We employ an error miner to pinpoint words with problematic lexical entries. [sent-6, score-0.479]
</p><p>4 An automated lexical acquisition technique is then used to learn new entries for those words which allows the grammar to parse previously uncovered sentences successfully. [sent-7, score-0.552]
</p><p>5 1 Introduction In this paper, we present an automated two-phase method for treating incomplete or incorrect lexical entries in the lexicons of large-scale computational grammars. [sent-12, score-0.311]
</p><p>6 In the first phase, error mining pinpoints words which are listed in the lexicon of a given grammar but which nevertheless often lead to a parsing failure. [sent-23, score-0.365]
</p><p>7 This indicates that the current lexical entry for such a word is either wrong or incomplete and that one or more correct entries for this word are missing from the lexicon. [sent-24, score-0.409]
</p><p>8 In the case study presented here, we employ the iterative error miner of de Kok et al. [sent-26, score-0.343]
</p><p>9 For example, the word afwater (to drain) is listed as a first person singular present verb in the Alpino lexicon. [sent-33, score-0.35]
</p><p>10 However, the error miner identifies this word as the reason for the parsing failure of 9 sen-  tences. [sent-34, score-0.343]
</p><p>11 A manual examination reveals that the word is used as a neuter noun in these cases– het afwater (the drainage). [sent-35, score-0.429]
</p><p>12 After the error miner identifies afwater as a problematic word, we employ our machine learning based LA method presented in Cholakov and van Noord (2010) to learn new entries for this word. [sent-37, score-0.88]
</p><p>13 This method has already been successfully applied to the task of learning lexical entries for unknown words and, as the error miner, it can be used ‘out of the box’ . [sent-38, score-0.383]
</p><p>14 tc ho2d0s10 in A Nsastoucira tlio Lnan fogru Cagoem Ppruotcaetisosninagl, L pinag eusis 9t0ic2s–912, try for afwater and the addition of this entry to the lexicon enables Alpino to cover the 9 problematic sentences from the Mediargus corpus. [sent-41, score-0.62]
</p><p>15 It should be noted that since our approach cannot differentiate between incomplete and incorrect entries, no entry in the lexicon is modified. [sent-42, score-0.227]
</p><p>16 We simply add the lexical entries which, according to the LA method, are most suitable for a given problematic word and assume that, if these entries are correct,  the grammar should be able to cover previously unparsable sentences in which the word occurs. [sent-43, score-0.853]
</p><p>17 Section 4 describes an experiment where error mining is performed on the Mediargus corpus and then, LA is applied to learn new lexical entries for problematic words. [sent-47, score-0.522]
</p><p>18 Section 5 discusses the effect which the addition of the new entries to the lexicon has on the parsing coverage and accuracy. [sent-48, score-0.406]
</p><p>19 2  Error Mining  The error miner of de Kok et al. [sent-51, score-0.31]
</p><p>20 (2009) combines the strengths of the error mining methods of van Noord (2004) and Sagot and de la Clergerie (2006). [sent-52, score-0.474]
</p><p>21 The iterative error mining algorithm of Sagot and de la Clergerie (2006) tackles this problem by taking the following into account: •  If a form occurs within parsable sentences, it  Ibfec aom forems le oscsc likely tfhoirn i tp atros babel eth see cause sof, a parsing failure. [sent-76, score-0.475]
</p><p>22 •  •  The suspicion of a form depends on the suspicTihoens s uosfp tihcieo onth oefr a afo formrms dine tpheen unparsable sentences it occurs in. [sent-77, score-0.22]
</p><p>23 (2009) uses a preprocessor to the iterative miner of Sagot and de la Clergerie (2006) which iterates through a sen-  tence of unigrams and expands unigrams to longer n-grams when there is evidence that this is useful. [sent-84, score-0.621]
</p><p>24 The grammar takes a ‘constructional’ approach, with rich lexical representations stored in the lexicon and a large number of detailed, construction specific rules (about 800). [sent-107, score-0.267]
</p><p>25 Currently, the lexicon contains over 100K lexical entries and a list of about 200K named entities. [sent-108, score-0.38]
</p><p>26 For example, the verb amuseert (to amuse) is assigned two lexical types– verb(hebben,sg3,intransitive) and verb(hebben,sg3,transitive)– because it can be used either transitively or intransitively. [sent-110, score-0.226]
</p><p>27 The other type features indicate that it is a present third person singular verb and it forms perfect tense with the auxiliary verb hebben. [sent-111, score-0.262]
</p><p>28 The types considered in the learning process are called universal types1 . [sent-115, score-0.234]
</p><p>29 One verb and one noun paradigm are generated for afwater. [sent-130, score-0.24]
</p><p>30 In these paradigms, afwater is listed as a first person singular present verb form and a singular het noun form, respectively. [sent-131, score-0.581]
</p><p>31 Next, syntactic features for afwater are obtained by extracting a number of sentences which it occurs in from large corpora or Internet. [sent-133, score-0.288]
</p><p>32 These sentences are parsed with a different ‘mode’ of Alpino where this word is assigned all universal types, i. [sent-134, score-0.336]
</p><p>33 Then, the lexical type that has been assigned to afwater in this parse is stored. [sent-138, score-0.348]
</p><p>34 For example, if a determiner occurs before the unknown word, all verb types are typically not taken into consideration. [sent-140, score-0.253]
</p><p>35 This heavily reduces the computational overload and makes parsing with universal types computationally feasible. [sent-141, score-0.287]
</p><p>36 When a word is assigned a verb or an adjective type by the classifier but there is no verb or adjective paradigm generated for it, all verb or adjective predictions for this word are discarded. [sent-147, score-0.602]
</p><p>37 905 These sentences are again parsed with the universal types. [sent-153, score-0.302]
</p><p>38 Then we look up the assigned universal verb types, calculate the MLE for each subcategorization frame and filter out frames with MLE below some empirical threshold. [sent-154, score-0.515]
</p><p>39 a5s bb ielelnio parsed wsi (th∼ Alpino anntedn tchees parsing creosruplutss are fed into the error miner of de Kok et al. [sent-166, score-0.428]
</p><p>40 When finished, the error miner stores the results  in a data base containing potentially problematic ngrams. [sent-171, score-0.369]
</p><p>41 Further, we select from this list only those unigrams which have lexical entries in the Alpino lexicon and occur in more than 5 sentences with no full-span parse. [sent-177, score-0.521]
</p><p>42 Sometimes, the error miner might be wrong about the exact word which causes the parsing failure for a given sentence. [sent-178, score-0.401]
</p><p>43 The small number of selected words is due to the fact that  most of the problematic 4179 unigrams represent tokenization errors (two or more words written as one) and spelling mistakes which, naturally, are not listed in the Alpino lexicon. [sent-182, score-0.222]
</p><p>44 Table 2 shows some of the problematic unigrams and their suspicions. [sent-184, score-0.222]
</p><p>45 The unigram passerde should be written as passeerde, the past singular  verb form of the verb ‘to pass’ and toegnag is the misspelled noun toegang (access). [sent-199, score-0.383]
</p><p>46 The only problematic unigram with a lexical entry in the Alpino lexicon is mistrap (misstep, to misstep). [sent-200, score-0.491]
</p><p>47 2 Applying Lexical Acquisition Our assumption is that incomplete or incorrect lexical entries prevented the production of full-span parses for the 388 sentences in which the 36 problematic words pinpointed by the error miner oc906 cur. [sent-204, score-0.761]
</p><p>48 they are treated as unknown words, and we employ the LA method presented in the previous section to learn offline new lexical entries for them. [sent-207, score-0.356]
</p><p>49 The set of universal types consists of 611types and the ME-  based classifier has been trained on the same set of 2000 words as in Cholakov and van Noord (2010). [sent-209, score-0.319]
</p><p>50 In order to increase the number of observed contexts for a given word when parsing with the universal types, up to 100 additional sentences in which the word occurs are extracted from Internet. [sent-211, score-0.323]
</p><p>51 However, when predicting new lexical entries for this word, we want to take into account only sentences where it causes a parsing failure. [sent-212, score-0.402]
</p><p>52 For example, the LA method would be able to predict a noun entry for afwater if it focuses only on contexts where it has a noun reading, i. [sent-214, score-0.432]
</p><p>53 Although we cannot be sure that the 36 words are the cause of a parsing failure in each of the uncovered sentences, this low  coverage indicates once more that Alpino has systematic problems with sentences containing these words. [sent-220, score-0.282]
</p><p>54 Then, the uncovered sentences from Internet together with the 388 problematic sentences from the Mediargus corpus are parsed with Alpino and the universal types. [sent-221, score-0.56]
</p><p>55 For example, the list of universal types assigned to afwater in (4) contains mostly noun types, i. [sent-222, score-0.535]
</p><p>56 Since a verb can have various subcategorization frames, there is one type assigned for each frame. [sent-228, score-0.242]
</p><p>57 For example, inscheppen (to spoon in(to)) receives 3 types which differ only in the subcategorization frame– verb(hebben,inf,tr. [sent-229, score-0.305]
</p><p>58 Let us examine the most frequent types of lexicon errors for the 36 problematic words by looking at the current Alpino lexical entries for some of these words and the predictions they receive from the LA method. [sent-235, score-0.592]
</p><p>59 The original Alpino entries for 19 of the 25 words predicted to be verbs are a product of a specific lexical rule in the grammar. [sent-236, score-0.295]
</p><p>60 I spoon the soup in the bowl ‘I spoon the soup into the bowl. [sent-241, score-0.461]
</p><p>61 ’ dat ik de soep de kom in schep that I the soup the bowl in spoon ‘that Ispoon the soup into the bowl’ dat ik de soep de kom inschep that I the soup the bowl in spoon ‘that Ispoon the soup into the bowl’  We see in (5-b) that the preposition in is used as a postposition in the relative clause. [sent-242, score-1.236]
</p><p>62 However, in some cases, the entries generated by this lexical rule cannot account for other possible usages of the verbs in question. [sent-248, score-0.267]
</p><p>63 Now, when the 907  LA method has predicted a transitive verb type for inscheppen, the parser should be able to cover the sentence. [sent-253, score-0.265]
</p><p>64 This should enable the parser to cover sentences like: (7)  Die moet een deel van het afwater vervoeren. [sent-261, score-0.593]
</p><p>65 Currently, their lexical entries are incomplete because they are assigned only past participle types in the lexicon. [sent-265, score-0.394]
</p><p>66 5  Results  After LA is finished, we restore the original lexical entries for the 36 words but, additionally, each word is also assigned the types which have been predicted for it by the LA method. [sent-269, score-0.378]
</p><p>67 how the parsing accuracy of Alpino changes Table 3 shows that when the Alpino lexicon is extended with the lexical entries we learnt through LA, the parser is able to cover nearly 84% of the sentences, including the ones given in (6) and (7). [sent-273, score-0.555]
</p><p>68 Since there is no suitable baseline which this result can be compared to, we developed an additional model which indicates what is likely to be the maximum coverage that Alpino can achieve for those sentences by adding new lexical entries only. [sent-274, score-0.369]
</p><p>69 In this second model, for each of the 36 words, we add to the lexicon all types which were successfully used for the respective word during the parsing with universal types. [sent-275, score-0.4]
</p><p>70 89 Table 3: Coverage results for the re-parsed 388 problematic sentences Some of the sentences which cannot be covered by both models are actually not proper sentences but fragments which were wrongly identified as sentences during tokenization. [sent-286, score-0.341]
</p><p>71 Here is a more interesting case: (9)  Als we ons naar de buffettafel begeven, mistrap ik when we us to the buffet proceed misstep I me. [sent-291, score-0.246]
</p><p>72 ’ The LA method does not predict a reflexive verb type for mistrap which prevents the production of a full-span analysis because Alpino cannot connect the reflexive pronoun me to mistrap. [sent-293, score-0.265]
</p><p>73 A reflexive verb type is among the universal types and thus, Alpino is able to use that type to deliver a full-span parse. [sent-295, score-0.421]
</p><p>74 We should note though, that LA cor908 rectly predicts a noun type for mistrap which enables Alpino to parse successfully the other 14 sentences which this word occurs in. [sent-296, score-0.28]
</p><p>75 Clearly, this baseline is expected to perform worse than both our model and the universal types one since those are able to cover most of the sentences and thus, they are likely to produce more correct dependency relations. [sent-302, score-0.366]
</p><p>76 Our model and the universal types one achieve the same accuracy for most of the sentences. [sent-312, score-0.234]
</p><p>77 However, the universal types model has an important disadvantage which, in some cases, leads to the production of wrong dependency relations. [sent-313, score-0.262]
</p><p>78 The model predicts a large number of lexical types which, in turn, leads to large lexical ambiguity. [sent-314, score-0.232]
</p><p>79 Let us consider the following example where a sentence is covered by both models but the universal types model has lower accuracy: (10)  Dat wij het rechttrokken, pleit voor onze that we it straighten. [sent-316, score-0.369]
</p><p>80 ’  Here, het is the object of the verb rechttrokken. [sent-321, score-0.25]
</p><p>81 However, although there are transitive verb types among the universal types assigned to rechttrokken, Alpino chooses to use a verb type which subcategorizes for a measure NP. [sent-322, score-0.547]
</p><p>82 Since it considers sentences containing other forms of the paradigm of rechttrokken when predicting subcategorization frames, the LA method correctly assigns only one transitive and one intransitive verb type to this word. [sent-327, score-0.362]
</p><p>83 This allows Alpino to recognize het as the object of the verb and to produce the correct dependency relation. [sent-328, score-0.25]
</p><p>84 The few cases where the universal types model outperforms ours include sentences like the one given in (9) where the application of our model could not enable Alpino to assign a full-span analysis. [sent-329, score-0.286]
</p><p>85 These types, on the other hand, could be provided by the  universal types model and could enable Alpino to cover a given sentence and thus, to produce more correct dependency relations. [sent-331, score-0.283]
</p><p>86 Then, they employ LA to learn proper lexical entries for these MWEs and add them to the lexicon of a large-scale HPSG grammar of English (ERG; (Copestake and Flickinger, 2000)). [sent-338, score-0.49]
</p><p>87 The lexicon is used in two grammars– the FRMG (Thomasset and de la Clergerie, 2005), a hybrid Tree Adjoining/Tree Insertion Grammar, and the SxLFGFR LFG grammar (Boullier and Sagot, 2006). [sent-345, score-0.457]
</p><p>88 The first step in this approach is also the application of an error miner (Sagot and de la Clergerie, 2006) which uses a parsed newspaper corpus (about 4. [sent-346, score-0.568]
</p><p>89 (2008) assign underspecified lexical entries to a given problematic unigram to allow the grammar to parse the uncovered sentences associated with this unigram. [sent-350, score-0.666]
</p><p>90 As a consequence of that, the ranked list of lexical entries for each unigram is manually validated to filter out the wrong entries. [sent-353, score-0.325]
</p><p>91 The ranking of the predictions is done by the classifier and the predicted entries are good enough to improve the parsing coverage and accuracy without any manual work involved. [sent-355, score-0.351]
</p><p>92 , a verb with a rare subcat frame) in the bottom of the ranked list because of the low number of sentences in which this entry is used. [sent-361, score-0.237]
</p><p>93 (2008) uses the lexical entries which remain after the manual validation to re-parse the newspaper corpus. [sent-365, score-0.267]
</p><p>94 However, the authors do not mention how many of the original uncovered sentences they are able to cover and therefore, we cannot compare our coverage result. [sent-369, score-0.255]
</p><p>95 Although the lexicon contains a verb entry for ‘schampte’, there is no entry handling the case when this verb combines with the particle ‘af’ . [sent-393, score-0.517]
</p><p>96 Our method is currently not able to capture these two cases since they can be identified as problematic on bigram level and not when only unigrams are  considered. [sent-397, score-0.281]
</p><p>97 Further, the definition of what the error miner considers to be a successful parse is a rather crude one. [sent-398, score-0.27]
</p><p>98 Therefore, it is possible that a word could have a problematic lexical entry even if it only occurs in sentences which are assigned a full-span parse. [sent-400, score-0.399]
</p><p>99 Lionel Nicolas, Beno ıˆt Sagot, Miguel Molinero, Jacques Farr e´, and Eric de la Clergerie. [sent-457, score-0.267]
</p><p>100 Beno ıˆt Sagot, Lionel Cl´ ement, Eric de la Clergerie, and Pierre Boullier. [sent-469, score-0.267]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('alpino', 0.622), ('afwater', 0.203), ('la', 0.193), ('entries', 0.19), ('universal', 0.185), ('miner', 0.176), ('cholakov', 0.162), ('noord', 0.162), ('het', 0.135), ('problematic', 0.133), ('verb', 0.115), ('lexicon', 0.113), ('sagot', 0.104), ('mediargus', 0.095), ('soup', 0.095), ('spoon', 0.095), ('subcategorization', 0.093), ('unigrams', 0.089), ('van', 0.085), ('bowl', 0.081), ('clergerie', 0.081), ('suspicion', 0.081), ('gertjan', 0.081), ('grammar', 0.077), ('lexical', 0.077), ('de', 0.074), ('uncovered', 0.073), ('entry', 0.07), ('inscheppen', 0.068), ('mistrap', 0.068), ('parsed', 0.065), ('noun', 0.064), ('kok', 0.063), ('mining', 0.062), ('paradigm', 0.061), ('error', 0.06), ('unknown', 0.056), ('flemish', 0.054), ('kordoni', 0.054), ('kostadin', 0.054), ('unparsable', 0.054), ('valia', 0.054), ('failure', 0.054), ('nicolas', 0.054), ('dutch', 0.054), ('parsing', 0.053), ('sentences', 0.052), ('coverage', 0.05), ('cover', 0.049), ('types', 0.049), ('acquisition', 0.049), ('beno', 0.046), ('suspicious', 0.046), ('frame', 0.046), ('incomplete', 0.044), ('adjective', 0.044), ('frames', 0.042), ('paradigms', 0.042), ('parser', 0.042), ('expfactor', 0.041), ('frmg', 0.041), ('misstep', 0.041), ('mwes', 0.041), ('rechttrokken', 0.041), ('reflexive', 0.041), ('soep', 0.041), ('af', 0.036), ('ik', 0.036), ('genoa', 0.035), ('villavicencio', 0.035), ('assigned', 0.034), ('parse', 0.034), ('particle', 0.034), ('occurs', 0.033), ('employ', 0.033), ('singular', 0.032), ('able', 0.031), ('mle', 0.031), ('multiword', 0.031), ('deep', 0.031), ('predictions', 0.03), ('unigram', 0.03), ('causes', 0.03), ('parses', 0.029), ('predicts', 0.029), ('wrong', 0.028), ('currently', 0.028), ('predicted', 0.028), ('aline', 0.027), ('boullier', 0.027), ('buffet', 0.027), ('drainage', 0.027), ('groningen', 0.027), ('ispoon', 0.027), ('kom', 0.027), ('lefff', 0.027), ('lionel', 0.027), ('moet', 0.027), ('neuter', 0.027), ('passerde', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999899 <a title="117-tfidf-1" href="./emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words.html">117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</a></p>
<p>Author: Kostadin Cholakov ; Gertjan van Noord</p><p>Abstract: Unknown words are a hindrance to the performance of hand-crafted computational grammars of natural language. However, words with incomplete and incorrect lexical entries pose an even bigger problem because they can be the cause of a parsing failure despite being listed in the lexicon of the grammar. Such lexical entries are hard to detect and even harder to correct. We employ an error miner to pinpoint words with problematic lexical entries. An automated lexical acquisition technique is then used to learn new entries for those words which allows the grammar to parse previously uncovered sentences successfully. We test our method on a large-scale grammar of Dutch and a set of sentences for which this grammar fails to produce a parse. The application of the method enables the grammar to cover 83.76% of those sentences with an accuracy of 86.15%.</p><p>2 0.095164105 <a title="117-tfidf-2" href="./emnlp-2010-Using_Universal_Linguistic_Knowledge_to_Guide_Grammar_Induction.html">116 emnlp-2010-Using Universal Linguistic Knowledge to Guide Grammar Induction</a></p>
<p>Author: Tahira Naseem ; Harr Chen ; Regina Barzilay ; Mark Johnson</p><p>Abstract: We present an approach to grammar induction that utilizes syntactic universals to improve dependency parsing across a range of languages. Our method uses a single set of manually-specified language-independent rules that identify syntactic dependencies between pairs of syntactic categories that commonly occur across languages. During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-theart unsupervised methods by a significant margin.1</p><p>3 0.08619491 <a title="117-tfidf-3" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>Author: Rebecca Dridan ; Timothy Baldwin</p><p>Abstract: Parser disambiguation with precision grammars generally takes place via statistical ranking of the parse yield of the grammar using a supervised parse selection model. In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible. Furthermore, as treebanking is generally streamlined with parse selection models, creating the initial treebank without a model requires more resources than subsequent treebanks. In this work, we show that, by taking advantage of the constrained nature of these HPSG grammars, we can learn a discriminative parse selection model from raw text in a purely unsupervised fashion. This allows us to bootstrap the treebanking process and provide better parsers faster, and with less resources.</p><p>4 0.078285426 <a title="117-tfidf-4" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>Author: Tom Kwiatkowksi ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: This paper addresses the problem of learning to map sentences to logical form, given training data consisting of natural language sentences paired with logical representations of their meaning. Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method. The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences. We use higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develop an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model. Experiments demonstrate high accuracy on benchmark data sets in four languages with two different meaning representations.</p><p>5 0.066896349 <a title="117-tfidf-5" href="./emnlp-2010-SRL-Based_Verb_Selection_for_ESL.html">95 emnlp-2010-SRL-Based Verb Selection for ESL</a></p>
<p>Author: Xiaohua Liu ; Bo Han ; Kuan Li ; Stephan Hyeonjun Stiller ; Ming Zhou</p><p>Abstract: In this paper we develop an approach to tackle the problem of verb selection for learners of English as a second language (ESL) by using features from the output of Semantic Role Labeling (SRL). Unlike existing approaches to verb selection that use local features such as n-grams, our approach exploits semantic features which explicitly model the usage context of the verb. The verb choice highly depends on its usage context which is not consistently captured by local features. We then combine these semantic features with other local features under the generalized perceptron learning framework. Experiments on both indomain and out-of-domain corpora show that our approach outperforms the baseline and achieves state-of-the-art performance. 1</p><p>6 0.056210607 <a title="117-tfidf-6" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>7 0.050953381 <a title="117-tfidf-7" href="./emnlp-2010-Nouns_are_Vectors%2C_Adjectives_are_Matrices%3A_Representing_Adjective-Noun_Constructions_in_Semantic_Space.html">87 emnlp-2010-Nouns are Vectors, Adjectives are Matrices: Representing Adjective-Noun Constructions in Semantic Space</a></p>
<p>8 0.049531732 <a title="117-tfidf-8" href="./emnlp-2010-An_Approach_of_Generating_Personalized_Views_from_Normalized_Electronic_Dictionaries_%3A_A_Practical_Experiment_on_Arabic_Language.html">16 emnlp-2010-An Approach of Generating Personalized Views from Normalized Electronic Dictionaries : A Practical Experiment on Arabic Language</a></p>
<p>9 0.047813915 <a title="117-tfidf-9" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>10 0.045295067 <a title="117-tfidf-10" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>11 0.044443212 <a title="117-tfidf-11" href="./emnlp-2010-An_Efficient_Algorithm_for_Unsupervised_Word_Segmentation_with_Branching_Entropy_and_MDL.html">17 emnlp-2010-An Efficient Algorithm for Unsupervised Word Segmentation with Branching Entropy and MDL</a></p>
<p>12 0.043061864 <a title="117-tfidf-12" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>13 0.041115738 <a title="117-tfidf-13" href="./emnlp-2010-Facilitating_Translation_Using_Source_Language_Paraphrase_Lattices.html">50 emnlp-2010-Facilitating Translation Using Source Language Paraphrase Lattices</a></p>
<p>14 0.04029819 <a title="117-tfidf-14" href="./emnlp-2010-Hierarchical_Phrase-Based_Translation_Grammars_Extracted_from_Alignment_Posterior_Probabilities.html">57 emnlp-2010-Hierarchical Phrase-Based Translation Grammars Extracted from Alignment Posterior Probabilities</a></p>
<p>15 0.038802717 <a title="117-tfidf-15" href="./emnlp-2010-Statistical_Machine_Translation_with_a_Factorized_Grammar.html">99 emnlp-2010-Statistical Machine Translation with a Factorized Grammar</a></p>
<p>16 0.038282178 <a title="117-tfidf-16" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<p>17 0.038197339 <a title="117-tfidf-17" href="./emnlp-2010-Self-Training_with_Products_of_Latent_Variable_Grammars.html">96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</a></p>
<p>18 0.037648898 <a title="117-tfidf-18" href="./emnlp-2010-Uptraining_for_Accurate_Deterministic_Question_Parsing.html">115 emnlp-2010-Uptraining for Accurate Deterministic Question Parsing</a></p>
<p>19 0.037130076 <a title="117-tfidf-19" href="./emnlp-2010-Simple_Type-Level_Unsupervised_POS_Tagging.html">97 emnlp-2010-Simple Type-Level Unsupervised POS Tagging</a></p>
<p>20 0.036996722 <a title="117-tfidf-20" href="./emnlp-2010-Latent-Descriptor_Clustering_for_Unsupervised_POS_Induction.html">71 emnlp-2010-Latent-Descriptor Clustering for Unsupervised POS Induction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.141), (1, 0.049), (2, 0.079), (3, 0.052), (4, 0.004), (5, 0.038), (6, -0.038), (7, -0.093), (8, 0.056), (9, -0.032), (10, 0.049), (11, 0.056), (12, 0.08), (13, 0.016), (14, 0.015), (15, -0.06), (16, -0.084), (17, 0.027), (18, -0.145), (19, -0.022), (20, 0.035), (21, -0.122), (22, -0.13), (23, 0.001), (24, -0.045), (25, 0.035), (26, 0.008), (27, -0.202), (28, 0.03), (29, -0.049), (30, -0.022), (31, -0.015), (32, 0.206), (33, -0.146), (34, -0.084), (35, -0.147), (36, -0.05), (37, 0.127), (38, 0.044), (39, 0.113), (40, -0.05), (41, -0.047), (42, -0.058), (43, 0.063), (44, 0.152), (45, 0.417), (46, -0.174), (47, -0.092), (48, 0.211), (49, 0.243)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95040429 <a title="117-lsi-1" href="./emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words.html">117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</a></p>
<p>Author: Kostadin Cholakov ; Gertjan van Noord</p><p>Abstract: Unknown words are a hindrance to the performance of hand-crafted computational grammars of natural language. However, words with incomplete and incorrect lexical entries pose an even bigger problem because they can be the cause of a parsing failure despite being listed in the lexicon of the grammar. Such lexical entries are hard to detect and even harder to correct. We employ an error miner to pinpoint words with problematic lexical entries. An automated lexical acquisition technique is then used to learn new entries for those words which allows the grammar to parse previously uncovered sentences successfully. We test our method on a large-scale grammar of Dutch and a set of sentences for which this grammar fails to produce a parse. The application of the method enables the grammar to cover 83.76% of those sentences with an accuracy of 86.15%.</p><p>2 0.42991164 <a title="117-lsi-2" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>Author: Tom Kwiatkowksi ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: This paper addresses the problem of learning to map sentences to logical form, given training data consisting of natural language sentences paired with logical representations of their meaning. Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method. The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences. We use higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develop an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model. Experiments demonstrate high accuracy on benchmark data sets in four languages with two different meaning representations.</p><p>3 0.39946583 <a title="117-lsi-3" href="./emnlp-2010-Using_Universal_Linguistic_Knowledge_to_Guide_Grammar_Induction.html">116 emnlp-2010-Using Universal Linguistic Knowledge to Guide Grammar Induction</a></p>
<p>Author: Tahira Naseem ; Harr Chen ; Regina Barzilay ; Mark Johnson</p><p>Abstract: We present an approach to grammar induction that utilizes syntactic universals to improve dependency parsing across a range of languages. Our method uses a single set of manually-specified language-independent rules that identify syntactic dependencies between pairs of syntactic categories that commonly occur across languages. During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-theart unsupervised methods by a significant margin.1</p><p>4 0.31916443 <a title="117-lsi-4" href="./emnlp-2010-An_Approach_of_Generating_Personalized_Views_from_Normalized_Electronic_Dictionaries_%3A_A_Practical_Experiment_on_Arabic_Language.html">16 emnlp-2010-An Approach of Generating Personalized Views from Normalized Electronic Dictionaries : A Practical Experiment on Arabic Language</a></p>
<p>Author: Aida Khemakhem ; Bilel Gargouri ; Abdelmajid Ben Hamadou</p><p>Abstract: Electronic dictionaries covering all natural language levels are very relevant for the human use as well as for the automatic processing use, namely those constructed with respect to international standards. Such dictionaries are characterized by a complex structure and an important access time when using a querying system. However, the need of a user is generally limited to a part of such a dictionary according to his domain and expertise level which corresponds to a specialized dictionary. Given the importance of managing a unified dictionary and considering the personalized needs of users, we propose an approach for generating personalized views starting from a normalized dictionary with respect to Lexical Markup Framework LMF-ISO 24613 norm. This approach provides the re-use of already defined views for a community of users by managing their profiles information and promoting the materialization of the generated views. It is composed of four main steps: (i) the projection of data categories controlled by a set of constraints (related to the user‟s profiles), (ii) the selection of values with consistency checking, (iii) the automatic generation of the query‟s model and finally, (iv) the refinement of the view. The proposed approach was con- solidated by carrying out an experiment on an LMF normalized Arabic dictionary. 1</p><p>5 0.31476131 <a title="117-lsi-5" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>Author: Shane Bergsma ; Aditya Bhargava ; Hua He ; Grzegorz Kondrak</p><p>Abstract: In many applications, replacing a complex word form by its stem can reduce sparsity, revealing connections in the data that would not otherwise be apparent. In this paper, we focus on prefix verbs: verbs formed by adding a prefix to an existing verb stem. A prefix verb is considered compositional if it can be decomposed into a semantically equivalent expression involving its stem. We develop a classifier to predict compositionality via a range of lexical and distributional features, including novel features derived from web-scale Ngram data. Results on a new annotated corpus show that prefix verb compositionality can be predicted with high accuracy. Our system also performs well when trained and tested on conventional morphological segmentations of prefix verbs.</p><p>6 0.2863391 <a title="117-lsi-6" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>7 0.24311894 <a title="117-lsi-7" href="./emnlp-2010-Nouns_are_Vectors%2C_Adjectives_are_Matrices%3A_Representing_Adjective-Noun_Constructions_in_Semantic_Space.html">87 emnlp-2010-Nouns are Vectors, Adjectives are Matrices: Representing Adjective-Noun Constructions in Semantic Space</a></p>
<p>8 0.23972005 <a title="117-lsi-8" href="./emnlp-2010-SRL-Based_Verb_Selection_for_ESL.html">95 emnlp-2010-SRL-Based Verb Selection for ESL</a></p>
<p>9 0.21755683 <a title="117-lsi-9" href="./emnlp-2010-An_Efficient_Algorithm_for_Unsupervised_Word_Segmentation_with_Branching_Entropy_and_MDL.html">17 emnlp-2010-An Efficient Algorithm for Unsupervised Word Segmentation with Branching Entropy and MDL</a></p>
<p>10 0.20665786 <a title="117-lsi-10" href="./emnlp-2010-Statistical_Machine_Translation_with_a_Factorized_Grammar.html">99 emnlp-2010-Statistical Machine Translation with a Factorized Grammar</a></p>
<p>11 0.17469937 <a title="117-lsi-11" href="./emnlp-2010-Generating_Confusion_Sets_for_Context-Sensitive_Error_Correction.html">54 emnlp-2010-Generating Confusion Sets for Context-Sensitive Error Correction</a></p>
<p>12 0.17158107 <a title="117-lsi-12" href="./emnlp-2010-A_Semi-Supervised_Approach_to_Improve_Classification_of_Infrequent_Discourse_Relations_Using_Feature_Vector_Extension.html">11 emnlp-2010-A Semi-Supervised Approach to Improve Classification of Infrequent Discourse Relations Using Feature Vector Extension</a></p>
<p>13 0.1714325 <a title="117-lsi-13" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>14 0.17093299 <a title="117-lsi-14" href="./emnlp-2010-Turbo_Parsers%3A_Dependency_Parsing_by_Approximate_Variational_Inference.html">110 emnlp-2010-Turbo Parsers: Dependency Parsing by Approximate Variational Inference</a></p>
<p>15 0.15684475 <a title="117-lsi-15" href="./emnlp-2010-Tense_Sense_Disambiguation%3A_A_New_Syntactic_Polysemy_Task.html">103 emnlp-2010-Tense Sense Disambiguation: A New Syntactic Polysemy Task</a></p>
<p>16 0.14774843 <a title="117-lsi-16" href="./emnlp-2010-Practical_Linguistic_Steganography_Using_Contextual_Synonym_Substitution_and_Vertex_Colour_Coding.html">91 emnlp-2010-Practical Linguistic Steganography Using Contextual Synonym Substitution and Vertex Colour Coding</a></p>
<p>17 0.1468959 <a title="117-lsi-17" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>18 0.13580021 <a title="117-lsi-18" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>19 0.13420168 <a title="117-lsi-19" href="./emnlp-2010-Efficient_Graph-Based_Semi-Supervised_Learning_of_Structured_Tagging_Models.html">41 emnlp-2010-Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models</a></p>
<p>20 0.13418624 <a title="117-lsi-20" href="./emnlp-2010-Improving_Mention_Detection_Robustness_to_Noisy_Input.html">62 emnlp-2010-Improving Mention Detection Robustness to Noisy Input</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(12, 0.036), (29, 0.076), (30, 0.011), (52, 0.011), (56, 0.034), (66, 0.082), (72, 0.587), (76, 0.03), (89, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93967855 <a title="117-lda-1" href="./emnlp-2010-WikiWars%3A_A_New_Corpus_for_Research_on_Temporal_Expressions.html">122 emnlp-2010-WikiWars: A New Corpus for Research on Temporal Expressions</a></p>
<p>Author: Pawel Mazur ; Robert Dale</p><p>Abstract: The reliable extraction of knowledge from text requires an appropriate treatment of the time at which reported events take place. Unfortunately, there are very few annotated data sets that support the development of techniques for event time-stamping and tracking the progression of time through a narrative. In this paper, we present a new corpus of temporally-rich documents sourced from English Wikipedia, which we have annotated with TIMEX2 tags. The corpus contains around 120000 tokens, and 2600 TIMEX2 expressions, thus comparing favourably in size to other existing corpora used in these areas. We describe the prepa- ration of the corpus, and compare the profile of the data with other existing temporally annotated corpora. We also report the results obtained when we use DANTE, our temporal expression tagger, to process this corpus, and point to where further work is required. The corpus is publicly available for research purposes.</p><p>2 0.92751533 <a title="117-lda-2" href="./emnlp-2010-An_Efficient_Algorithm_for_Unsupervised_Word_Segmentation_with_Branching_Entropy_and_MDL.html">17 emnlp-2010-An Efficient Algorithm for Unsupervised Word Segmentation with Branching Entropy and MDL</a></p>
<p>Author: Valentin Zhikov ; Hiroya Takamura ; Manabu Okumura</p><p>Abstract: This paper proposes a fast and simple unsupervised word segmentation algorithm that utilizes the local predictability of adjacent character sequences, while searching for a leasteffort representation of the data. The model uses branching entropy as a means of constraining the hypothesis space, in order to efficiently obtain a solution that minimizes the length of a two-part MDL code. An evaluation with corpora in Japanese, Thai, English, and the ”CHILDES” corpus for research in language development reveals that the algorithm achieves an accuracy, comparable to that of the state-of-the-art methods in unsupervised word segmentation, in a significantly reduced . computational time.</p><p>same-paper 3 0.88496536 <a title="117-lda-3" href="./emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words.html">117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</a></p>
<p>Author: Kostadin Cholakov ; Gertjan van Noord</p><p>Abstract: Unknown words are a hindrance to the performance of hand-crafted computational grammars of natural language. However, words with incomplete and incorrect lexical entries pose an even bigger problem because they can be the cause of a parsing failure despite being listed in the lexicon of the grammar. Such lexical entries are hard to detect and even harder to correct. We employ an error miner to pinpoint words with problematic lexical entries. An automated lexical acquisition technique is then used to learn new entries for those words which allows the grammar to parse previously uncovered sentences successfully. We test our method on a large-scale grammar of Dutch and a set of sentences for which this grammar fails to produce a parse. The application of the method enables the grammar to cover 83.76% of those sentences with an accuracy of 86.15%.</p><p>4 0.53635234 <a title="117-lda-4" href="./emnlp-2010-A_Semi-Supervised_Approach_to_Improve_Classification_of_Infrequent_Discourse_Relations_Using_Feature_Vector_Extension.html">11 emnlp-2010-A Semi-Supervised Approach to Improve Classification of Infrequent Discourse Relations Using Feature Vector Extension</a></p>
<p>Author: Hugo Hernault ; Danushka Bollegala ; Mitsuru Ishizuka</p><p>Abstract: Several recent discourse parsers have employed fully-supervised machine learning approaches. These methods require human annotators to beforehand create an extensive training corpus, which is a time-consuming and costly process. On the other hand, unlabeled data is abundant and cheap to collect. In this paper, we propose a novel semi-supervised method for discourse relation classification based on the analysis of cooccurring features in unlabeled data, which is then taken into account for extending the feature vectors given to a classifier. Our experimental results on the RST Discourse Treebank corpus and Penn Discourse Treebank indicate that the proposed method brings a significant improvement in classification accuracy and macro-average F-score when small training datasets are used. For instance, with training sets of c.a. 1000 labeled instances, the proposed method brings improvements in accuracy and macro-average F-score up to 50% compared to a baseline classifier. We believe that the proposed method is a first step towards detecting low-occurrence relations, which is useful for domains with a lack of annotated data.</p><p>5 0.48547202 <a title="117-lda-5" href="./emnlp-2010-Context_Comparison_of_Bursty_Events_in_Web_Search_and_Online_Media.html">32 emnlp-2010-Context Comparison of Bursty Events in Web Search and Online Media</a></p>
<p>Author: Yunliang Jiang ; Cindy Xide Lin ; Qiaozhu Mei</p><p>Abstract: In this paper, we conducted a systematic comparative analysis of language in different contexts of bursty topics, including web search, news media, blogging, and social bookmarking. We analyze (1) the content similarity and predictability between contexts, (2) the coverage of search content by each context, and (3) the intrinsic coherence of information in each context. Our experiments show that social bookmarking is a better predictor to the bursty search queries, but news media and social blogging media have a much more compelling coverage. This comparison provides insights on how the search behaviors and social information sharing behaviors of users are correlated to the professional news media in the context of bursty events.</p><p>6 0.4818947 <a title="117-lda-6" href="./emnlp-2010-Learning_Recurrent_Event_Queries_for_Web_Search.html">73 emnlp-2010-Learning Recurrent Event Queries for Web Search</a></p>
<p>7 0.43789551 <a title="117-lda-7" href="./emnlp-2010-Fusing_Eye_Gaze_with_Speech_Recognition_Hypotheses_to_Resolve_Exophoric_References_in_Situated_Dialogue.html">53 emnlp-2010-Fusing Eye Gaze with Speech Recognition Hypotheses to Resolve Exophoric References in Situated Dialogue</a></p>
<p>8 0.4266834 <a title="117-lda-8" href="./emnlp-2010-A_Fast_Decoder_for_Joint_Word_Segmentation_and_POS-Tagging_Using_a_Single_Discriminative_Model.html">2 emnlp-2010-A Fast Decoder for Joint Word Segmentation and POS-Tagging Using a Single Discriminative Model</a></p>
<p>9 0.41184819 <a title="117-lda-9" href="./emnlp-2010-Evaluating_Models_of_Latent_Document_Semantics_in_the_Presence_of_OCR_Errors.html">45 emnlp-2010-Evaluating Models of Latent Document Semantics in the Presence of OCR Errors</a></p>
<p>10 0.41122958 <a title="117-lda-10" href="./emnlp-2010-Automatic_Detection_and_Classification_of_Social_Events.html">20 emnlp-2010-Automatic Detection and Classification of Social Events</a></p>
<p>11 0.40514123 <a title="117-lda-11" href="./emnlp-2010-Word-Based_Dialect_Identification_with_Georeferenced_Rules.html">123 emnlp-2010-Word-Based Dialect Identification with Georeferenced Rules</a></p>
<p>12 0.40498078 <a title="117-lda-12" href="./emnlp-2010-Automatically_Producing_Plot_Unit_Representations_for_Narrative_Text.html">24 emnlp-2010-Automatically Producing Plot Unit Representations for Narrative Text</a></p>
<p>13 0.40205711 <a title="117-lda-13" href="./emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields.html">49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</a></p>
<p>14 0.40047121 <a title="117-lda-14" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>15 0.39530608 <a title="117-lda-15" href="./emnlp-2010-Enhancing_Domain_Portability_of_Chinese_Segmentation_Model_Using_Chi-Square_Statistics_and_Bootstrapping.html">43 emnlp-2010-Enhancing Domain Portability of Chinese Segmentation Model Using Chi-Square Statistics and Bootstrapping</a></p>
<p>16 0.39269164 <a title="117-lda-16" href="./emnlp-2010-Joint_Training_and_Decoding_Using_Virtual_Nodes_for_Cascaded_Segmentation_and_Tagging_Tasks.html">69 emnlp-2010-Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks</a></p>
<p>17 0.38621601 <a title="117-lda-17" href="./emnlp-2010-Minimum_Error_Rate_Training_by_Sampling_the_Translation_Lattice.html">78 emnlp-2010-Minimum Error Rate Training by Sampling the Translation Lattice</a></p>
<p>18 0.38601449 <a title="117-lda-18" href="./emnlp-2010-Function-Based_Question_Classification_for_General_QA.html">51 emnlp-2010-Function-Based Question Classification for General QA</a></p>
<p>19 0.38422409 <a title="117-lda-19" href="./emnlp-2010-Modeling_Organization_in_Student_Essays.html">80 emnlp-2010-Modeling Organization in Student Essays</a></p>
<p>20 0.38279799 <a title="117-lda-20" href="./emnlp-2010-Discriminative_Sample_Selection_for_Statistical_Machine_Translation.html">35 emnlp-2010-Discriminative Sample Selection for Statistical Machine Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
