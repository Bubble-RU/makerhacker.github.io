<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-96" href="#">emnlp2010-96</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</h1>
<br/><p>Source: <a title="emnlp-2010-96-pdf" href="http://aclweb.org/anthology//D/D10/D10-1002.pdf">pdf</a></p><p>Author: Zhongqiang Huang ; Mary Harper ; Slav Petrov</p><p>Abstract: Mary Harper†‡ ‡HLT Center of Excellence Johns Hopkins University Baltimore, MD mharpe r@ umd .edu Slav Petrov∗ ∗Google Research 76 Ninth Avenue New York, NY s lav@ google . com ting the training data and eventually begins over- fitting (Liang et al., 2007). Moreover, EM is a loWe study self-training with products of latent variable grammars in this paper. We show that increasing the quality of the automatically parsed data used for self-training gives higher accuracy self-trained grammars. Our generative self-trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without selftraining. Additionally, we show that multiple self-trained grammars can be combined in a product model to achieve even higher accuracy. The product model is most effective when the individual underlying grammars are most diverse. Combining multiple grammars that were self-trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5% on the WSJ test set and 89.6% on our Broadcast News test set.</p><p>Reference: <a title="emnlp-2010-96-reference" href="../emnlp2010_reference/emnlp-2010-Self-Training_with_Products_of_Latent_Variable_Grammars_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gramm', 0.678), ('sm', 0.236), ('round', 0.198), ('petrov', 0.192), ('regul', 0.183), ('harp', 0.181), ('broadcast', 0.17), ('selftrain', 0.143), ('wsj', 0.142), ('individ', 0.135), ('pars', 0.126), ('divers', 0.126), ('bllip', 0.125), ('unlabel', 0.117), ('produc', 0.115), ('charniak', 0.098), ('huang', 0.088), ('treebank', 0.073), ('bn', 0.071), ('rerank', 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="96-tfidf-1" href="./emnlp-2010-Self-Training_with_Products_of_Latent_Variable_Grammars.html">96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</a></p>
<p>Author: Zhongqiang Huang ; Mary Harper ; Slav Petrov</p><p>Abstract: Mary Harper†‡ ‡HLT Center of Excellence Johns Hopkins University Baltimore, MD mharpe r@ umd .edu Slav Petrov∗ ∗Google Research 76 Ninth Avenue New York, NY s lav@ google . com ting the training data and eventually begins over- fitting (Liang et al., 2007). Moreover, EM is a loWe study self-training with products of latent variable grammars in this paper. We show that increasing the quality of the automatically parsed data used for self-training gives higher accuracy self-trained grammars. Our generative self-trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without selftraining. Additionally, we show that multiple self-trained grammars can be combined in a product model to achieve even higher accuracy. The product model is most effective when the individual underlying grammars are most diverse. Combining multiple grammars that were self-trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5% on the WSJ test set and 89.6% on our Broadcast News test set.</p><p>2 0.27685866 <a title="96-tfidf-2" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>Author: Rebecca Dridan ; Timothy Baldwin</p><p>Abstract: Parser disambiguation with precision grammars generally takes place via statistical ranking of the parse yield of the grammar using a supervised parse selection model. In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible. Furthermore, as treebanking is generally streamlined with parse selection models, creating the initial treebank without a model requires more resources than subsequent treebanks. In this work, we show that, by taking advantage of the constrained nature of these HPSG grammars, we can learn a discriminative parse selection model from raw text in a purely unsupervised fashion. This allows us to bootstrap the treebanking process and provide better parsers faster, and with less resources.</p><p>3 0.24180256 <a title="96-tfidf-3" href="./emnlp-2010-Hierarchical_Phrase-Based_Translation_Grammars_Extracted_from_Alignment_Posterior_Probabilities.html">57 emnlp-2010-Hierarchical Phrase-Based Translation Grammars Extracted from Alignment Posterior Probabilities</a></p>
<p>Author: Adria de Gispert ; Juan Pino ; William Byrne</p><p>Abstract: We report on investigations into hierarchical phrase-based translation grammars based on rules extracted from posterior distributions over alignments of the parallel text. Rather than restrict rule extraction to a single alignment, such as Viterbi, we instead extract rules based on posterior distributions provided by the HMM word-to-word alignmentmodel. We define translation grammars progressively by adding classes of rules to a basic phrase-based system. We assess these grammars in terms of their expressive power, measured by their ability to align the parallel text from which their rules are extracted, and the quality of the translations they yield. In Chinese-to-English translation, we find that rule extraction from posteriors gives translation improvements. We also find that grammars with rules with only one nonterminal, when extracted from posteri- ors, can outperform more complex grammars extracted from Viterbi alignments. Finally, we show that the best way to exploit source-totarget and target-to-source alignment models is to build two separate systems and combine their output translation lattices.</p><p>4 0.18909146 <a title="96-tfidf-4" href="./emnlp-2010-Uptraining_for_Accurate_Deterministic_Question_Parsing.html">115 emnlp-2010-Uptraining for Accurate Deterministic Question Parsing</a></p>
<p>Author: Slav Petrov ; Pi-Chuan Chang ; Michael Ringgaard ; Hiyan Alshawi</p><p>Abstract: It is well known that parsing accuracies drop significantly on out-of-domain data. What is less known is that some parsers suffer more from domain shifts than others. We show that dependency parsers have more difficulty parsing questions than constituency parsers. In particular, deterministic shift-reduce dependency parsers, which are of highest interest for practical applications because of their linear running time, drop to 60% labeled accuracy on a question test set. We propose an uptraining procedure in which a deterministic parser is trained on the output of a more accurate, but slower, latent variable constituency parser (converted to dependencies). Uptraining with 100K unlabeled questions achieves results comparable to having 2K labeled questions for training. With 100K unlabeled and 2K labeled questions, uptraining is able to improve parsing accuracy to 84%, closing the gap between in-domain and out-of-domain performance.</p><p>5 0.16793971 <a title="96-tfidf-5" href="./emnlp-2010-Unsupervised_Induction_of_Tree_Substitution_Grammars_for_Dependency_Parsing.html">113 emnlp-2010-Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing</a></p>
<p>Author: Phil Blunsom ; Trevor Cohn</p><p>Abstract: Inducing a grammar directly from text is one of the oldest and most challenging tasks in Computational Linguistics. Significant progress has been made for inducing dependency grammars, however the models employed are overly simplistic, particularly in comparison to supervised parsing models. In this paper we present an approach to dependency grammar induction using tree substitution grammar which is capable of learning large dependency fragments and thereby better modelling the text. We define a hierarchical non-parametric Pitman-Yor Process prior which biases towards a small grammar with simple productions. This approach significantly improves the state-of-the-art, when measured by head attachment accuracy.</p><p>6 0.16496417 <a title="96-tfidf-6" href="./emnlp-2010-Statistical_Machine_Translation_with_a_Factorized_Grammar.html">99 emnlp-2010-Statistical Machine Translation with a Factorized Grammar</a></p>
<p>7 0.14716066 <a title="96-tfidf-7" href="./emnlp-2010-Using_Universal_Linguistic_Knowledge_to_Guide_Grammar_Induction.html">116 emnlp-2010-Using Universal Linguistic Knowledge to Guide Grammar Induction</a></p>
<p>8 0.14329825 <a title="96-tfidf-8" href="./emnlp-2010-Modeling_Perspective_Using_Adaptor_Grammars.html">81 emnlp-2010-Modeling Perspective Using Adaptor Grammars</a></p>
<p>9 0.13666326 <a title="96-tfidf-9" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>10 0.13232203 <a title="96-tfidf-10" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>11 0.11703558 <a title="96-tfidf-11" href="./emnlp-2010-Soft_Syntactic_Constraints_for_Hierarchical_Phrase-Based_Translation_Using_Latent_Syntactic_Distributions.html">98 emnlp-2010-Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions</a></p>
<p>12 0.11101703 <a title="96-tfidf-12" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>13 0.097947583 <a title="96-tfidf-13" href="./emnlp-2010-Efficient_Graph-Based_Semi-Supervised_Learning_of_Structured_Tagging_Models.html">41 emnlp-2010-Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models</a></p>
<p>14 0.097556844 <a title="96-tfidf-14" href="./emnlp-2010-Improved_Fully_Unsupervised_Parsing_with_Zoomed_Learning.html">60 emnlp-2010-Improved Fully Unsupervised Parsing with Zoomed Learning</a></p>
<p>15 0.096556209 <a title="96-tfidf-15" href="./emnlp-2010-Lessons_Learned_in_Part-of-Speech_Tagging_of_Conversational_Speech.html">75 emnlp-2010-Lessons Learned in Part-of-Speech Tagging of Conversational Speech</a></p>
<p>16 0.092644699 <a title="96-tfidf-16" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>17 0.086551011 <a title="96-tfidf-17" href="./emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words.html">117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</a></p>
<p>18 0.086365588 <a title="96-tfidf-18" href="./emnlp-2010-Combining_Unsupervised_and_Supervised_Alignments_for_MT%3A_An_Empirical_Study.html">29 emnlp-2010-Combining Unsupervised and Supervised Alignments for MT: An Empirical Study</a></p>
<p>19 0.074644893 <a title="96-tfidf-19" href="./emnlp-2010-Two_Decades_of_Unsupervised_POS_Induction%3A_How_Far_Have_We_Come%3F.html">111 emnlp-2010-Two Decades of Unsupervised POS Induction: How Far Have We Come?</a></p>
<p>20 0.071694903 <a title="96-tfidf-20" href="./emnlp-2010-Evaluating_the_Impact_of_Alternative_Dependency_Graph_Encodings_on_Solving_Event_Extraction_Tasks.html">46 emnlp-2010-Evaluating the Impact of Alternative Dependency Graph Encodings on Solving Event Extraction Tasks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.255), (1, 0.14), (2, 0.304), (3, 0.051), (4, 0.006), (5, -0.065), (6, -0.082), (7, -0.173), (8, 0.057), (9, -0.105), (10, -0.238), (11, 0.143), (12, 0.037), (13, -0.001), (14, 0.123), (15, -0.1), (16, -0.186), (17, -0.05), (18, -0.005), (19, -0.122), (20, -0.004), (21, -0.245), (22, 0.182), (23, -0.073), (24, 0.015), (25, 0.021), (26, -0.063), (27, 0.005), (28, 0.107), (29, -0.09), (30, -0.023), (31, -0.02), (32, 0.026), (33, 0.02), (34, 0.023), (35, -0.086), (36, 0.031), (37, -0.011), (38, 0.076), (39, -0.01), (40, -0.046), (41, -0.012), (42, 0.038), (43, -0.11), (44, 0.078), (45, -0.049), (46, 0.041), (47, -0.068), (48, 0.037), (49, -0.099)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.986655 <a title="96-lsi-1" href="./emnlp-2010-Self-Training_with_Products_of_Latent_Variable_Grammars.html">96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</a></p>
<p>Author: Zhongqiang Huang ; Mary Harper ; Slav Petrov</p><p>Abstract: Mary Harper†‡ ‡HLT Center of Excellence Johns Hopkins University Baltimore, MD mharpe r@ umd .edu Slav Petrov∗ ∗Google Research 76 Ninth Avenue New York, NY s lav@ google . com ting the training data and eventually begins over- fitting (Liang et al., 2007). Moreover, EM is a loWe study self-training with products of latent variable grammars in this paper. We show that increasing the quality of the automatically parsed data used for self-training gives higher accuracy self-trained grammars. Our generative self-trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without selftraining. Additionally, we show that multiple self-trained grammars can be combined in a product model to achieve even higher accuracy. The product model is most effective when the individual underlying grammars are most diverse. Combining multiple grammars that were self-trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5% on the WSJ test set and 89.6% on our Broadcast News test set.</p><p>2 0.74028414 <a title="96-lsi-2" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>Author: Rebecca Dridan ; Timothy Baldwin</p><p>Abstract: Parser disambiguation with precision grammars generally takes place via statistical ranking of the parse yield of the grammar using a supervised parse selection model. In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible. Furthermore, as treebanking is generally streamlined with parse selection models, creating the initial treebank without a model requires more resources than subsequent treebanks. In this work, we show that, by taking advantage of the constrained nature of these HPSG grammars, we can learn a discriminative parse selection model from raw text in a purely unsupervised fashion. This allows us to bootstrap the treebanking process and provide better parsers faster, and with less resources.</p><p>3 0.62379038 <a title="96-lsi-3" href="./emnlp-2010-Unsupervised_Induction_of_Tree_Substitution_Grammars_for_Dependency_Parsing.html">113 emnlp-2010-Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing</a></p>
<p>Author: Phil Blunsom ; Trevor Cohn</p><p>Abstract: Inducing a grammar directly from text is one of the oldest and most challenging tasks in Computational Linguistics. Significant progress has been made for inducing dependency grammars, however the models employed are overly simplistic, particularly in comparison to supervised parsing models. In this paper we present an approach to dependency grammar induction using tree substitution grammar which is capable of learning large dependency fragments and thereby better modelling the text. We define a hierarchical non-parametric Pitman-Yor Process prior which biases towards a small grammar with simple productions. This approach significantly improves the state-of-the-art, when measured by head attachment accuracy.</p><p>4 0.57237744 <a title="96-lsi-4" href="./emnlp-2010-Uptraining_for_Accurate_Deterministic_Question_Parsing.html">115 emnlp-2010-Uptraining for Accurate Deterministic Question Parsing</a></p>
<p>Author: Slav Petrov ; Pi-Chuan Chang ; Michael Ringgaard ; Hiyan Alshawi</p><p>Abstract: It is well known that parsing accuracies drop significantly on out-of-domain data. What is less known is that some parsers suffer more from domain shifts than others. We show that dependency parsers have more difficulty parsing questions than constituency parsers. In particular, deterministic shift-reduce dependency parsers, which are of highest interest for practical applications because of their linear running time, drop to 60% labeled accuracy on a question test set. We propose an uptraining procedure in which a deterministic parser is trained on the output of a more accurate, but slower, latent variable constituency parser (converted to dependencies). Uptraining with 100K unlabeled questions achieves results comparable to having 2K labeled questions for training. With 100K unlabeled and 2K labeled questions, uptraining is able to improve parsing accuracy to 84%, closing the gap between in-domain and out-of-domain performance.</p><p>5 0.56583631 <a title="96-lsi-5" href="./emnlp-2010-Statistical_Machine_Translation_with_a_Factorized_Grammar.html">99 emnlp-2010-Statistical Machine Translation with a Factorized Grammar</a></p>
<p>Author: Libin Shen ; Bing Zhang ; Spyros Matsoukas ; Jinxi Xu ; Ralph Weischedel</p><p>Abstract: In modern machine translation practice, a statistical phrasal or hierarchical translation system usually relies on a huge set of translation rules extracted from bi-lingual training data. This approach not only results in space and efficiency issues, but also suffers from the sparse data problem. In this paper, we propose to use factorized grammars, an idea widely accepted in the field of linguistic grammar construction, to generalize translation rules, so as to solve these two problems. We designed a method to take advantage of the XTAG English Grammar to facilitate the extraction of factorized rules. We experimented on various setups of low-resource language translation, and showed consistent significant improvement in BLEU over state-ofthe-art string-to-dependency baseline systems with 200K words of bi-lingual training data.</p><p>6 0.53781337 <a title="96-lsi-6" href="./emnlp-2010-Using_Unknown_Word_Techniques_to_Learn_Known_Words.html">117 emnlp-2010-Using Unknown Word Techniques to Learn Known Words</a></p>
<p>7 0.53358811 <a title="96-lsi-7" href="./emnlp-2010-Modeling_Perspective_Using_Adaptor_Grammars.html">81 emnlp-2010-Modeling Perspective Using Adaptor Grammars</a></p>
<p>8 0.52417874 <a title="96-lsi-8" href="./emnlp-2010-Improved_Fully_Unsupervised_Parsing_with_Zoomed_Learning.html">60 emnlp-2010-Improved Fully Unsupervised Parsing with Zoomed Learning</a></p>
<p>9 0.49634066 <a title="96-lsi-9" href="./emnlp-2010-Hierarchical_Phrase-Based_Translation_Grammars_Extracted_from_Alignment_Posterior_Probabilities.html">57 emnlp-2010-Hierarchical Phrase-Based Translation Grammars Extracted from Alignment Posterior Probabilities</a></p>
<p>10 0.4642576 <a title="96-lsi-10" href="./emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</a></p>
<p>11 0.45240539 <a title="96-lsi-11" href="./emnlp-2010-Using_Universal_Linguistic_Knowledge_to_Guide_Grammar_Induction.html">116 emnlp-2010-Using Universal Linguistic Knowledge to Guide Grammar Induction</a></p>
<p>12 0.42794138 <a title="96-lsi-12" href="./emnlp-2010-Inducing_Probabilistic_CCG_Grammars_from_Logical_Form_with_Higher-Order_Unification.html">65 emnlp-2010-Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification</a></p>
<p>13 0.40793017 <a title="96-lsi-13" href="./emnlp-2010-Evaluating_the_Impact_of_Alternative_Dependency_Graph_Encodings_on_Solving_Event_Extraction_Tasks.html">46 emnlp-2010-Evaluating the Impact of Alternative Dependency Graph Encodings on Solving Event Extraction Tasks</a></p>
<p>14 0.37353757 <a title="96-lsi-14" href="./emnlp-2010-Soft_Syntactic_Constraints_for_Hierarchical_Phrase-Based_Translation_Using_Latent_Syntactic_Distributions.html">98 emnlp-2010-Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions</a></p>
<p>15 0.36840671 <a title="96-lsi-15" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>16 0.35495824 <a title="96-lsi-16" href="./emnlp-2010-SCFG_Decoding_Without_Binarization.html">94 emnlp-2010-SCFG Decoding Without Binarization</a></p>
<p>17 0.30581322 <a title="96-lsi-17" href="./emnlp-2010-Lessons_Learned_in_Part-of-Speech_Tagging_of_Conversational_Speech.html">75 emnlp-2010-Lessons Learned in Part-of-Speech Tagging of Conversational Speech</a></p>
<p>18 0.29670814 <a title="96-lsi-18" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>19 0.2952193 <a title="96-lsi-19" href="./emnlp-2010-Combining_Unsupervised_and_Supervised_Alignments_for_MT%3A_An_Empirical_Study.html">29 emnlp-2010-Combining Unsupervised and Supervised Alignments for MT: An Empirical Study</a></p>
<p>20 0.28848669 <a title="96-lsi-20" href="./emnlp-2010-Title_Generation_with_Quasi-Synchronous_Grammar.html">105 emnlp-2010-Title Generation with Quasi-Synchronous Grammar</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.019), (4, 0.04), (7, 0.071), (24, 0.242), (25, 0.055), (31, 0.029), (35, 0.033), (38, 0.028), (39, 0.102), (46, 0.01), (47, 0.134), (49, 0.048), (54, 0.013), (58, 0.017), (61, 0.016), (62, 0.019), (71, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71440297 <a title="96-lda-1" href="./emnlp-2010-Self-Training_with_Products_of_Latent_Variable_Grammars.html">96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</a></p>
<p>Author: Zhongqiang Huang ; Mary Harper ; Slav Petrov</p><p>Abstract: Mary Harper†‡ ‡HLT Center of Excellence Johns Hopkins University Baltimore, MD mharpe r@ umd .edu Slav Petrov∗ ∗Google Research 76 Ninth Avenue New York, NY s lav@ google . com ting the training data and eventually begins over- fitting (Liang et al., 2007). Moreover, EM is a loWe study self-training with products of latent variable grammars in this paper. We show that increasing the quality of the automatically parsed data used for self-training gives higher accuracy self-trained grammars. Our generative self-trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without selftraining. Additionally, we show that multiple self-trained grammars can be combined in a product model to achieve even higher accuracy. The product model is most effective when the individual underlying grammars are most diverse. Combining multiple grammars that were self-trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5% on the WSJ test set and 89.6% on our Broadcast News test set.</p><p>2 0.62322611 <a title="96-lda-2" href="./emnlp-2010-Top-Down_Nearly-Context-Sensitive_Parsing.html">106 emnlp-2010-Top-Down Nearly-Context-Sensitive Parsing</a></p>
<p>Author: Eugene Charniak</p><p>Abstract: We present a new syntactic parser that works left-to-right and top down, thus maintaining a fully-connected parse tree for a few alternative parse hypotheses. All of the commonly used statistical parsers use context-free dynamic programming algorithms and as such work bottom up on the entire sentence. Thus they only find a complete fully connected parse at the very end. In contrast, both subjective and experimental evidence show that people understand a sentence word-to-word as they go along, or close to it. The constraint that the parser keeps one or more fully connected syntactic trees is intended to operationalize this cognitive fact. Our parser achieves a new best result for topdown parsers of 89.4%,a 20% error reduction over the previous single-parser best result for parsers of this type of 86.8% (Roark, 2001) . The improved performance is due to embracing the very large feature set available in exchange for giving up dynamic programming.</p><p>3 0.61588097 <a title="96-lda-3" href="./emnlp-2010-What_a_Parser_Can_Learn_from_a_Semantic_Role_Labeler_and_Vice_Versa.html">121 emnlp-2010-What a Parser Can Learn from a Semantic Role Labeler and Vice Versa</a></p>
<p>Author: Stephen Boxwell ; Dennis Mehay ; Chris Brew</p><p>Abstract: In many NLP systems, there is a unidirectional flow of information in which a parser supplies input to a semantic role labeler. In this paper, we build a system that allows information to flow in both directions. We make use of semantic role predictions in choosing a single-best parse. This process relies on an averaged perceptron model to distinguish likely semantic roles from erroneous ones. Our system penalizes parses that give rise to low-scoring semantic roles. To explore the consequences of this we perform two experiments. First, we use a baseline generative model to produce n-best parses, which are then re-ordered by our semantic model. Second, we use a modified version of our semantic role labeler to predict semantic roles at parse time. The performance of this modified labeler is weaker than that of our best full SRL, because it is restricted to features that can be computed directly from the parser’s packed chart. For both experiments, the resulting semantic predictions are then used to select parses. Finally, we feed the selected parses produced by each experiment to the full version of our semantic role labeler. We find that SRL performance can be improved over this baseline by selecting parses with likely semantic roles.</p><p>4 0.60758537 <a title="96-lda-4" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>Author: Rebecca Dridan ; Timothy Baldwin</p><p>Abstract: Parser disambiguation with precision grammars generally takes place via statistical ranking of the parse yield of the grammar using a supervised parse selection model. In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible. Furthermore, as treebanking is generally streamlined with parse selection models, creating the initial treebank without a model requires more resources than subsequent treebanks. In this work, we show that, by taking advantage of the constrained nature of these HPSG grammars, we can learn a discriminative parse selection model from raw text in a purely unsupervised fashion. This allows us to bootstrap the treebanking process and provide better parsers faster, and with less resources.</p><p>5 0.60339004 <a title="96-lda-5" href="./emnlp-2010-Uptraining_for_Accurate_Deterministic_Question_Parsing.html">115 emnlp-2010-Uptraining for Accurate Deterministic Question Parsing</a></p>
<p>Author: Slav Petrov ; Pi-Chuan Chang ; Michael Ringgaard ; Hiyan Alshawi</p><p>Abstract: It is well known that parsing accuracies drop significantly on out-of-domain data. What is less known is that some parsers suffer more from domain shifts than others. We show that dependency parsers have more difficulty parsing questions than constituency parsers. In particular, deterministic shift-reduce dependency parsers, which are of highest interest for practical applications because of their linear running time, drop to 60% labeled accuracy on a question test set. We propose an uptraining procedure in which a deterministic parser is trained on the output of a more accurate, but slower, latent variable constituency parser (converted to dependencies). Uptraining with 100K unlabeled questions achieves results comparable to having 2K labeled questions for training. With 100K unlabeled and 2K labeled questions, uptraining is able to improve parsing accuracy to 84%, closing the gap between in-domain and out-of-domain performance.</p><p>6 0.60012394 <a title="96-lda-6" href="./emnlp-2010-Improved_Fully_Unsupervised_Parsing_with_Zoomed_Learning.html">60 emnlp-2010-Improved Fully Unsupervised Parsing with Zoomed Learning</a></p>
<p>7 0.59696829 <a title="96-lda-7" href="./emnlp-2010-Learning_First-Order_Horn_Clauses_from_Web_Text.html">72 emnlp-2010-Learning First-Order Horn Clauses from Web Text</a></p>
<p>8 0.59692812 <a title="96-lda-8" href="./emnlp-2010-Soft_Syntactic_Constraints_for_Hierarchical_Phrase-Based_Translation_Using_Latent_Syntactic_Distributions.html">98 emnlp-2010-Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions</a></p>
<p>9 0.59340787 <a title="96-lda-9" href="./emnlp-2010-A_Multi-Pass_Sieve_for_Coreference_Resolution.html">8 emnlp-2010-A Multi-Pass Sieve for Coreference Resolution</a></p>
<p>10 0.59246838 <a title="96-lda-10" href="./emnlp-2010-Joint_Inference_for_Bilingual_Semantic_Role_Labeling.html">68 emnlp-2010-Joint Inference for Bilingual Semantic Role Labeling</a></p>
<p>11 0.59234625 <a title="96-lda-11" href="./emnlp-2010-Non-Isomorphic_Forest_Pair_Translation.html">86 emnlp-2010-Non-Isomorphic Forest Pair Translation</a></p>
<p>12 0.5910303 <a title="96-lda-12" href="./emnlp-2010-Automatic_Detection_and_Classification_of_Social_Events.html">20 emnlp-2010-Automatic Detection and Classification of Social Events</a></p>
<p>13 0.58853918 <a title="96-lda-13" href="./emnlp-2010-Function-Based_Question_Classification_for_General_QA.html">51 emnlp-2010-Function-Based Question Classification for General QA</a></p>
<p>14 0.58833772 <a title="96-lda-14" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<p>15 0.58705497 <a title="96-lda-15" href="./emnlp-2010-SRL-Based_Verb_Selection_for_ESL.html">95 emnlp-2010-SRL-Based Verb Selection for ESL</a></p>
<p>16 0.58629721 <a title="96-lda-16" href="./emnlp-2010-Unsupervised_Induction_of_Tree_Substitution_Grammars_for_Dependency_Parsing.html">113 emnlp-2010-Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing</a></p>
<p>17 0.58464384 <a title="96-lda-17" href="./emnlp-2010-A_Mixture_Model_with_Sharing_for_Lexical_Semantics.html">7 emnlp-2010-A Mixture Model with Sharing for Lexical Semantics</a></p>
<p>18 0.58453393 <a title="96-lda-18" href="./emnlp-2010-Effects_of_Empty_Categories_on_Machine_Translation.html">40 emnlp-2010-Effects of Empty Categories on Machine Translation</a></p>
<p>19 0.58210444 <a title="96-lda-19" href="./emnlp-2010-Joint_Training_and_Decoding_Using_Virtual_Nodes_for_Cascaded_Segmentation_and_Tagging_Tasks.html">69 emnlp-2010-Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks</a></p>
<p>20 0.58153343 <a title="96-lda-20" href="./emnlp-2010-Constraints_Based_Taxonomic_Relation_Classification.html">31 emnlp-2010-Constraints Based Taxonomic Relation Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
