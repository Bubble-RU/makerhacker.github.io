<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-49" href="#">emnlp2010-49</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</h1>
<br/><p>Source: <a title="emnlp-2010-49-pdf" href="http://aclweb.org/anthology//D/D10/D10-1101.pdf">pdf</a></p><p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: In this paper, we focus on the opinion target extraction as part of the opinion mining task. We model the problem as an information extraction task, which we address based on Conditional Random Fields (CRF). As a baseline we employ the supervised algorithm by Zhuang et al. (2006), which represents the state-of-the-art on the employed data. We evaluate the algorithms comprehensively on datasets from four different domains annotated with individual opinion target instances on a sentence level. Furthermore, we investigate the performance of our CRF-based approach and the baseline in a single- and cross-domain opinion target extraction setting. Our CRF-based approach improves the performance by 0.077, 0.126, 0.071 and 0. 178 regarding F-Measure in the single-domain extraction in the four domains. In the crossdomain setting our approach improves the performance by 0.409, 0.242, 0.294 and 0.343 regarding F-Measure over the baseline.</p><p>Reference: <a title="emnlp-2010-49-reference" href="../emnlp2010_reference/emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract In this paper, we focus on the opinion target extraction as part of the opinion mining task. [sent-3, score-1.543]
</p><p>2 We evaluate the algorithms comprehensively on datasets from four different domains annotated with individual opinion target instances on a sentence level. [sent-7, score-0.895]
</p><p>3 Furthermore, we investigate the performance of our CRF-based approach and the baseline in a single- and cross-domain opinion target extraction setting. [sent-8, score-0.889]
</p><p>4 As opinion mining is typically an enabling technology for another task, this overlaying system defines requirements regarding the level of granularity. [sent-20, score-0.881]
</p><p>5 All of these tasks have in common that in order to fulfill them, the opinion mining system must be capable of identifying what the opinions in the individual sentences are about, hence extract the opinion targets. [sent-33, score-1.454]
</p><p>6 Our goal in this work is to extract opinion targets from user-generated discourse, a discourse type which is quite frequently encountered today, due to the explosive growth of Web 2. [sent-34, score-0.983]
</p><p>7 The opinion targets which we aim to extract are underlined in the sentences, the corresponding opinion expressions are shown in italics. [sent-37, score-1.71]
</p><p>8 The extraction of opinion targets can be considered as an instance of an information extraction (IE) task (Cowie and Lehnert, 1996). [sent-40, score-1.171]
</p><p>9 In the opinion mining context this question has been prominently investigated with respect to opinion polarity analysis (sentiment analysis) in previous research (Aue and Gamon, 2005; Blitzer et al. [sent-46, score-1.378]
</p><p>10 Terms as “unpredictable” can express a positive opinion when uttered about the storyline of a movie but a negative opinion when the handling of a car is described. [sent-48, score-1.392]
</p><p>11 However to the best of our knowledge, these effects have not been investigated regarding the extraction of opinion targets. [sent-50, score-0.971]
</p><p>12 The contribution of this paper is a CRF-based approach for opinion targets extraction which tackles the problem of domain portability. [sent-51, score-1.137]
</p><p>13 2  Related Work  In the following we will discuss the related work regarding opinion target extraction and domain adaptation in opinion mining. [sent-60, score-1.779]
</p><p>14 The discussion of the related work on opinion target extraction is separated in supervised and unsupervised approaches. [sent-61, score-0.843]
</p><p>15 We conclude with a discussion of the related work on domain adaptation in opinion mining. [sent-62, score-0.755]
</p><p>16 1 Unsupervised Opinion Target Extraction The first work on opinion target extraction was done on customer reviews of consumer electronics. [sent-64, score-0.927]
</p><p>17 A dataset of customer reviews from five domains was annotated by the authors regarding mentioned product features with respective opinion polarities. [sent-67, score-1.137]
</p><p>18 They present and evaluate a complete system for opinion extraction which is based on a statistical analysis based on the Likelihood Ratio Test for opinion target extraction. [sent-73, score-1.5]
</p><p>19 00 in the task of opinion target (product feature) extraction, recall values are not reported. [sent-76, score-0.769]
</p><p>20 Popescu and Etzioni (2005) present the OPINE system for opinion mining on product reviews. [sent-77, score-0.723]
</p><p>21 They evaluate the opinion target extraction separately on the dataset by Hu and Liu (2004). [sent-79, score-0.955]
</p><p>22 (2007) manually create taxonomies of opinion targets for two datasets. [sent-82, score-0.983]
</p><p>23 With a handcrafted set of dependency tree paths their algorithm identifies related opinion expressions and targets. [sent-83, score-0.872]
</p><p>24 Due to the lack of a dataset annotated with opinion expressions and targets, they just evaluate the accuracy of several aspects of their algorithm by man-  ually assessing an output sample. [sent-84, score-0.91]
</p><p>25 Kim and Hovy (2006) aim at extracting opinion holders and opinion targets in newswire with semantic role labeling. [sent-87, score-1.682]
</p><p>26 They define a mapping of the semantic roles identified with FrameNet to the respective opinion elements. [sent-88, score-0.657]
</p><p>27 As a baseline, they implement an approach based on a dependency parser, which identifies the targets following the dependencies of opinion expressions. [sent-89, score-1.041]
</p><p>28 (2006) present a supervised algorithm for the extraction of opinion expression - opinion target pairs. [sent-97, score-1.594]
</p><p>29 Their algorithm learns the opinion target candidates and a combination of dependency and part-of-speech paths connecting such pairs from an annotated dataset. [sent-98, score-0.958]
</p><p>30 488 in the task of extracting opinion target - opinion expression pairs. [sent-103, score-1.5]
</p><p>31 Kessler and Nicolov (2009) solely focus on identifying which opinion expression is linked to which opinion target in a sentence. [sent-104, score-1.501]
</p><p>32 They present a dataset of car and camera reviews in which opinion expressions and opinion targets are annotated. [sent-105, score-1.948]
</p><p>33 Starting with this information, they train a machine learning classifier for identifying related opinion expressions and targets. [sent-106, score-0.749]
</p><p>34 Their algorithm receives the opinion expression and opinion target annotations as input during runtime. [sent-107, score-1.5]
</p><p>35 As the development data, we used 29 documents from the movies dataset, 23 documents from the web-services dataset and 15 documents from the cars & cameras datasets. [sent-126, score-0.937]
</p><p>36 If the vocabulary of targets is rather compact for a certain domain (corresponding to a low target type / target ratio), the training data is likely to contain the majority of the target  types, which should hence be a good indicator. [sent-129, score-0.697]
</p><p>37 At the same time, the CRF algorithm is provided with additional information to extract opinion targets which are multiword expressions, i. [sent-138, score-1.027]
</p><p>38 Short Dependency Path Previous research has successfully employed paths in the dependency parse tree to link opinion expressions and the corresponding targets (Zhuang et al. [sent-142, score-1.195]
</p><p>39 Both works identify direct dependency relations such as “amod” and “nsubj” as the most frequent and at the same time highly accurate connections between a target and an opinion expression. [sent-144, score-0.807]
</p><p>40 We hence label all tokens which  have a direct dependency relation to an opinion expression in a sentence. [sent-145, score-0.823]
</p><p>41 (2006) we can infer that opinion expressions and their target(s) are not always connected via short paths in the dependency parse tree. [sent-149, score-0.851]
</p><p>42 Since we cannot capture such paths with the abovementioned feature we introduce another feature which acts as heuristic for identifying the target to a given opinion expression. [sent-150, score-0.891]
</p><p>43 (2003) have shown that (base) noun phrases are good candidates for opinion targets in the datasets of product reviews. [sent-152, score-1.106]
</p><p>44 We therefore label the token(s) in the closest noun phrase regarding word distance to each opinion expression in a sentence. [sent-153, score-0.911]
</p><p>45 Opinion Sentence With this feature, we simply label all tokens occurring in a sentence containing an opinion expression. [sent-155, score-0.657]
</p><p>46 This feature shall enable the CRF algorithm to  distinguish between the occurence of a certain token in a sentence which contains an opinion vs. [sent-156, score-0.76]
</p><p>47 shtml 1038 Our goal is to extract individual instances of opinion targets from sentences which contain an opinion expression. [sent-162, score-1.64]
</p><p>48 We represent the possible labels following the IOB scheme: B-Target, identifying the beginning of an opinion target, I-Target identifying the continuation of a target, and O for other (non-target) tokens. [sent-171, score-0.701]
</p><p>49 (2006) and annotated regarding opinion target - opinion expression pairs. [sent-181, score-1.69]
</p><p>50 The version of the dataset used in our experiments consists of 179 blog postings regarding different digital cameras and 336 reviews of different cars. [sent-187, score-0.698]
</p><p>51 In the description of their annotation guidelines, Kessler and Nicolov (2009) refer to opinion targets as mentions. [sent-188, score-0.983]
</p><p>52 However, not only mentions which occur as opinion targets were originally annotated, but also mentions which occur in non-opinion sentences. [sent-190, score-1.037]
</p><p>53 In our experiments, we only use the mentions which occur as targets of opinion expressions. [sent-191, score-1.01]
</p><p>54 edu/ All three datasets contain annotations regarding the antecedents of anaphoric opinion targets. [sent-195, score-0.904]
</p><p>55 In our experimental setup, we do not require the algorithms to also correctly resolve the antecedent of an opinion target representy by a pronoun, as we are solely interested in evaluating the opinion target extraction not any anaphora resolution. [sent-196, score-1.592]
</p><p>56 As shown in rows 4 and 5 of Table 1, the documents from the cars and the cameras datasets exhibit a much higher density of opinions per document. [sent-197, score-0.711]
</p><p>57 5% of the sentences from the cars dataset contain an opinion and in the cameras dataset even 56. [sent-199, score-1.444]
</p><p>58 Furthermore in the cars and the cameras datasets the lexical  variability regarding the opinion targets is substantially larger than in the other two datasets: We calculate target types by counting the number of distinct opinion targets in a dataset. [sent-203, score-2.892]
</p><p>59 We divide this by the sum of all opinion target instances in the dataset. [sent-204, score-0.749]
</p><p>60 In terms of reviews this means, that in the movie reviews the same movie aspects are repeatedly commented on, while in the cars and the cameras datasets many different aspects of these entities are discussed, which in turn each occur infrequently. [sent-210, score-0.922]
</p><p>61 2 Baseline System In the task of opinion target extraction the supervised algorithm by Zhuang et al. [sent-212, score-0.864]
</p><p>62 A set of paths in a dependency tree which iden-  tify valid opinion target - opinion expression pairs In our experiments, we learn the full set of opinion targets from the labeled training data in the first step. [sent-217, score-2.586]
</p><p>63 , 2006), but we expect that this modification should be beneficial for the overall performance in terms of recall, as we do not remove any learned opinion targets from the candidate list. [sent-219, score-1.001]
</p><p>64 For each opinion target opinion expression pair from the gold standard, the shortest path connecting them is extracted from the dependency graph. [sent-221, score-1.592]
</p><p>65 Thereby, the baseline system is also capable of extracting multiword opinion targets. [sent-225, score-0.727]
</p><p>66 3 Metrics We employ the following requirements in our evaluation of the opinion target extraction: An opinion target must be extracted with exactly the span boundaries as annotated in the gold standard. [sent-227, score-1.572]
</p><p>67 5  Results and Discussion  We investigate the performance of the baseline and the CRF-based approach for opinion target extraction in a single- and cross-domain setting. [sent-237, score-0.889]
</p><p>68 2 we present the results of the two systems in the cross-domain opinion target extraction. [sent-244, score-0.749]
</p><p>69 In our task, the algorithm uses the opinion expression annotation from the gold standard. [sent-259, score-0.774]
</p><p>70 We do not remove any learned opinion target candidates from the training data (See Section 4. [sent-261, score-0.783]
</p><p>71 We assume that the recall of the algorithm is limited by a large variety of possible dependency paths between opinion targets and opinion expressions, since the algorithm cannot link targets and opinion expressions in the testing data if there is no valid candidate dependency path. [sent-264, score-2.977]
</p><p>72 Furthermore, we observe that for the cars dataset the size of the dependency path candidate list (6642 entries) was approximately five times larger than the dependency graph candidate list for the web-services dataset (1237 entries), which has a comparable size regarding documents. [sent-265, score-0.879]
</p><p>73 We assume that a large number of both the target candidates as well as the dependency path candidates introduces many false positives during the target extraction, hence lowering the precision of the algorithm on the cars dataset considerably. [sent-267, score-0.751]
</p><p>74 2 Our CRF-based Approach Table 3 shows the results of the opinion target extraction using the CRF algorithm. [sent-270, score-0.843]
</p><p>75 Although the CRF-based approach clearly outperforms the baseline system on all four datasets, we also observe the same general trend regarding the individual results: The CRF yields the best results on the movies dataset and the worst results on the cars & cameras dataset. [sent-276, score-1.185]
</p><p>76 We observe that the higher the lexical variability of the opinion targets is in a dataset, the lower the results are. [sent-278, score-1.06]
</p><p>77 The precision is considerably increased on all datasets, on the movies and cars & cameras datasets even reaching the overall highest value. [sent-281, score-0.857]
</p><p>78 The observation made in previous research that short paths in the dependency graph are a high precision indicator of related opinion expressions - opinion targets (Kessler and Nicolov, 2009) is confirmed on all datasets. [sent-283, score-1.876]
</p><p>79 Adding the information regarding opinion sentences to the basic features ofthe token string and 1041 the part-of-speech tag (row 4) yields the biggest improvements regarding F-Measure on the movies and web-services dataset (+0. [sent-284, score-1.458]
</p><p>80 On the cars & cameras dataset the recall is relatively low again. [sent-287, score-0.695]
</p><p>81 We assume that this is again due to the high lexical variability, so that the CRF algorithm will encounter many actual opinion targets in the testing data which  have not occurred in the training data and will hence not be extracted. [sent-288, score-1.061]
</p><p>82 We conclude that these two features are complementary, as they apparently indicate different kinds of opinion targets which are then correctly extracted by the CRF. [sent-290, score-1.008]
</p><p>83 If we combine each of the opinion expression related features with the label which identifies opinion sentences in general (rows 6 & 7), we observe that this feature is also complementary to the others. [sent-291, score-1.467]
</p><p>84 We have run some additional experiments in which we did not rely on the annotated opinion expressions, but employed a general pupose subjectivity lexicon4. [sent-300, score-0.705]
</p><p>85 We observe that most of the recall errors result from one-word opinion targets or the beginning of opinion targets (B-Targets) being missclassified as non-targets (movies 83%, web-services 73%, cars 68%, cameras 64%). [sent-310, score-2.602]
</p><p>86 Our results indicate that the dLn and wDs features are complementary, but apparently there are quite a few cases in which the opinion target is neither directly related to the opinion expression in the dependency graph nor close to it in the sentence. [sent-313, score-1.581]
</p><p>87 None ofthe actual targets “lens cap”, “strap” and “camera” have a short dependency path to the opinion expression and “speed” is simply the closest noun to it. [sent-317, score-1.146]
</p><p>88 Note that although both “speed” and “usability” are attributes of a camera, the opinion in this sentence is about the “lens cap” and “strap”, hence only these attributes are annotated as targets. [sent-318, score-0.722]
</p><p>89 1 Zhuang Baseline Table 4 shows the results of the opinion target extraction with the state-of-the-art system in the crossdomain setting. [sent-325, score-0.911]
</p><p>90 A quantitative error analysis has revealed that there is hardly any overlap in the opinion target candidates between domains, as reflected by the low recall in all configurations. [sent-327, score-0.823]
</p><p>91 The vocabularies of the opinion targets are too different, hence the performance of the algorithm by Zhuang et al. [sent-328, score-1.066]
</p><p>92 As we also observed in the analysis of the baseline results, the overlap of the opinion target vocabularies between domains is low, which resulted in a very small number of targets extracted by the CRF. [sent-352, score-1.198]
</p><p>93 We noticed that on the cameras dataset the results regarding F-Measure remained stable if the token feature is not used in the training. [sent-361, score-0.738]
</p><p>94 1043 In isolation, training only on the cars data yields the second highest results on the movies and webservices datasets and the highest results regarding F-Measure on the cameras data. [sent-362, score-1.06]
</p><p>95 However, the results of the cars + cameras training data combination indicate that the cameras data does not contribute any additional information during the learning, since the results on both the movies and the web-services datasets are lower than when training only on the cameras data. [sent-363, score-1.524]
</p><p>96 On the cars and the cameras dataset the cross-domain results are even closer to the single-domain results. [sent-368, score-0.675]
</p><p>97 6  Conclusions  In this paper, we have shown how a CRF-based approach for opinion target extraction performs in a single- and cross-domain setting. [sent-370, score-0.843]
</p><p>98 Our error analysis indicates that additional features, which can capture opinions in more complex sentences, are required to improve the performance of the opinion target extraction. [sent-373, score-0.789]
</p><p>99 The features we employ scale well across domains, given that the opinion target vocabularies are substantially different. [sent-375, score-0.797]
</p><p>100 Since three of the features we employed in 1044 our CRF-based approach are based on the respective opinion expressions, it is to investigate how to mitigate the possible negative effects introduced by errors in the opinion expression identification if they are not annotated in the gold standard. [sent-378, score-1.496]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('opinion', 0.657), ('cameras', 0.345), ('targets', 0.326), ('cars', 0.218), ('movies', 0.205), ('regarding', 0.181), ('zhuang', 0.17), ('dataset', 0.112), ('extraction', 0.094), ('target', 0.092), ('crf', 0.081), ('expression', 0.073), ('kessler', 0.072), ('expressions', 0.07), ('crossdomain', 0.068), ('dln', 0.066), ('datasets', 0.066), ('paths', 0.066), ('nicolov', 0.062), ('reviews', 0.06), ('domain', 0.06), ('dependency', 0.058), ('token', 0.055), ('movie', 0.053), ('darmstadt', 0.053), ('wds', 0.053), ('observe', 0.053), ('domains', 0.05), ('sentiment', 0.045), ('yields', 0.045), ('mining', 0.043), ('row', 0.042), ('camera', 0.041), ('opinions', 0.04), ('aue', 0.04), ('strap', 0.04), ('adaptation', 0.038), ('isolation', 0.035), ('hence', 0.035), ('blitzer', 0.035), ('bloom', 0.034), ('lens', 0.034), ('candidates', 0.034), ('path', 0.032), ('cap', 0.031), ('annotated', 0.03), ('hu', 0.029), ('feature', 0.027), ('mentions', 0.027), ('commented', 0.027), ('cowie', 0.027), ('hochschulstra', 0.027), ('niklas', 0.027), ('opine', 0.027), ('ssn', 0.027), ('toprak', 0.027), ('vocabularies', 0.027), ('baseline', 0.026), ('apparently', 0.025), ('car', 0.025), ('variability', 0.024), ('customer', 0.024), ('product', 0.023), ('precision', 0.023), ('gold', 0.023), ('battery', 0.023), ('iryna', 0.023), ('multiword', 0.023), ('fields', 0.023), ('rows', 0.023), ('string', 0.022), ('testing', 0.022), ('identifying', 0.022), ('employ', 0.021), ('extracting', 0.021), ('investigated', 0.021), ('algorithm', 0.021), ('jakob', 0.021), ('technische', 0.021), ('holders', 0.021), ('germany', 0.021), ('investigate', 0.02), ('overlap', 0.02), ('recall', 0.02), ('aspects', 0.02), ('counted', 0.019), ('review', 0.019), ('usability', 0.019), ('graph', 0.019), ('documents', 0.019), ('combinations', 0.019), ('speed', 0.019), ('employed', 0.018), ('stable', 0.018), ('slight', 0.018), ('effects', 0.018), ('gamon', 0.018), ('popescu', 0.018), ('usa', 0.018), ('candidate', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="49-tfidf-1" href="./emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields.html">49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: In this paper, we focus on the opinion target extraction as part of the opinion mining task. We model the problem as an information extraction task, which we address based on Conditional Random Fields (CRF). As a baseline we employ the supervised algorithm by Zhuang et al. (2006), which represents the state-of-the-art on the employed data. We evaluate the algorithms comprehensively on datasets from four different domains annotated with individual opinion target instances on a sentence level. Furthermore, we investigate the performance of our CRF-based approach and the baseline in a single- and cross-domain opinion target extraction setting. Our CRF-based approach improves the performance by 0.077, 0.126, 0.071 and 0. 178 regarding F-Measure in the single-domain extraction in the four domains. In the crossdomain setting our approach improves the performance by 0.409, 0.242, 0.294 and 0.343 regarding F-Measure over the baseline.</p><p>2 0.48540705 <a title="49-tfidf-2" href="./emnlp-2010-Jointly_Modeling_Aspects_and_Opinions_with_a_MaxEnt-LDA_Hybrid.html">70 emnlp-2010-Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid</a></p>
<p>Author: Xin Zhao ; Jing Jiang ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Discovering and summarizing opinions from online reviews is an important and challenging task. A commonly-adopted framework generates structured review summaries with aspects and opinions. Recently topic models have been used to identify meaningful review aspects, but existing topic models do not identify aspect-specific opinion words. In this paper, we propose a MaxEnt-LDA hybrid model to jointly discover both aspects and aspect-specific opinion words. We show that with a relatively small amount of training data, our model can effectively identify aspect and opinion words simultaneously. We also demonstrate the domain adaptability of our model.</p><p>3 0.090286568 <a title="49-tfidf-3" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>Author: Ahmed Hassan ; Vahed Qazvinian ; Dragomir Radev</p><p>Abstract: Mining sentiment from user generated content is a very important task in Natural Language Processing. An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web. Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums. Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics. In this work, we present a method to identify the attitude of participants in an online discussion toward one another. This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative. This is different from most of the research on social networks that has focused almost exclusively on positive links. The method is exper- imentally tested using a manually labeled set of discussion posts. The results show that the proposed method is capable of identifying attitudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.</p><p>4 0.087874971 <a title="49-tfidf-4" href="./emnlp-2010-Incorporating_Content_Structure_into_Text_Analysis_Applications.html">64 emnlp-2010-Incorporating Content Structure into Text Analysis Applications</a></p>
<p>Author: Christina Sauper ; Aria Haghighi ; Regina Barzilay</p><p>Abstract: In this paper, we investigate how modeling content structure can benefit text analysis applications such as extractive summarization and sentiment analysis. This follows the linguistic intuition that rich contextual information should be useful in these tasks. We present a framework which combines a supervised text analysis application with the induction of latent content structure. Both of these elements are learned jointly using the EM algorithm. The induced content structure is learned from a large unannotated corpus and biased by the underlying text analysis task. We demonstrate that exploiting content structure yields significant improvements over approaches that rely only on local context.1</p><p>5 0.081676327 <a title="49-tfidf-5" href="./emnlp-2010-Efficient_Graph-Based_Semi-Supervised_Learning_of_Structured_Tagging_Models.html">41 emnlp-2010-Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models</a></p>
<p>Author: Amarnag Subramanya ; Slav Petrov ; Fernando Pereira</p><p>Abstract: We describe a new scalable algorithm for semi-supervised training of conditional random fields (CRF) and its application to partof-speech (POS) tagging. The algorithm uses a similarity graph to encourage similar ngrams to have similar POS tags. We demonstrate the efficacy of our approach on a domain adaptation task, where we assume that we have access to large amounts of unlabeled data from the target domain, but no additional labeled data. The similarity graph is used during training to smooth the state posteriors on the target domain. Standard inference can be used at test time. Our approach is able to scale to very large problems and yields significantly improved target domain accuracy.</p><p>6 0.072866812 <a title="49-tfidf-6" href="./emnlp-2010-Multi-Level_Structured_Models_for_Document-Level_Sentiment_Classification.html">83 emnlp-2010-Multi-Level Structured Models for Document-Level Sentiment Classification</a></p>
<p>7 0.06929379 <a title="49-tfidf-7" href="./emnlp-2010-We%27re_Not_in_Kansas_Anymore%3A_Detecting_Domain_Changes_in_Streams.html">119 emnlp-2010-We're Not in Kansas Anymore: Detecting Domain Changes in Streams</a></p>
<p>8 0.061738066 <a title="49-tfidf-8" href="./emnlp-2010-The_Necessity_of_Combining_Adaptation_Methods.html">104 emnlp-2010-The Necessity of Combining Adaptation Methods</a></p>
<p>9 0.05741914 <a title="49-tfidf-9" href="./emnlp-2010-Holistic_Sentiment_Analysis_Across_Languages%3A_Multilingual_Supervised_Latent_Dirichlet_Allocation.html">58 emnlp-2010-Holistic Sentiment Analysis Across Languages: Multilingual Supervised Latent Dirichlet Allocation</a></p>
<p>10 0.057222076 <a title="49-tfidf-10" href="./emnlp-2010-Evaluating_the_Impact_of_Alternative_Dependency_Graph_Encodings_on_Solving_Event_Extraction_Tasks.html">46 emnlp-2010-Evaluating the Impact of Alternative Dependency Graph Encodings on Solving Event Extraction Tasks</a></p>
<p>11 0.056118254 <a title="49-tfidf-11" href="./emnlp-2010-Summarizing_Contrastive_Viewpoints_in_Opinionated_Text.html">102 emnlp-2010-Summarizing Contrastive Viewpoints in Opinionated Text</a></p>
<p>12 0.056093425 <a title="49-tfidf-12" href="./emnlp-2010-Cross_Language_Text_Classification_by_Model_Translation_and_Semi-Supervised_Learning.html">33 emnlp-2010-Cross Language Text Classification by Model Translation and Semi-Supervised Learning</a></p>
<p>13 0.05480041 <a title="49-tfidf-13" href="./emnlp-2010-Staying_Informed%3A_Supervised_and_Semi-Supervised_Multi-View_Topical_Analysis_of_Ideological_Perspective.html">100 emnlp-2010-Staying Informed: Supervised and Semi-Supervised Multi-View Topical Analysis of Ideological Perspective</a></p>
<p>14 0.047729924 <a title="49-tfidf-14" href="./emnlp-2010-Better_Punctuation_Prediction_with_Dynamic_Conditional_Random_Fields.html">25 emnlp-2010-Better Punctuation Prediction with Dynamic Conditional Random Fields</a></p>
<p>15 0.046795778 <a title="49-tfidf-15" href="./emnlp-2010-EMNLP_044.html">39 emnlp-2010-EMNLP 044</a></p>
<p>16 0.044378929 <a title="49-tfidf-16" href="./emnlp-2010-A_Semi-Supervised_Approach_to_Improve_Classification_of_Infrequent_Discourse_Relations_Using_Feature_Vector_Extension.html">11 emnlp-2010-A Semi-Supervised Approach to Improve Classification of Infrequent Discourse Relations Using Feature Vector Extension</a></p>
<p>17 0.044280235 <a title="49-tfidf-17" href="./emnlp-2010-WikiWars%3A_A_New_Corpus_for_Research_on_Temporal_Expressions.html">122 emnlp-2010-WikiWars: A New Corpus for Research on Temporal Expressions</a></p>
<p>18 0.043923728 <a title="49-tfidf-18" href="./emnlp-2010-Confidence_in_Structured-Prediction_Using_Confidence-Weighted_Models.html">30 emnlp-2010-Confidence in Structured-Prediction Using Confidence-Weighted Models</a></p>
<p>19 0.043519251 <a title="49-tfidf-19" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<p>20 0.038125388 <a title="49-tfidf-20" href="./emnlp-2010-A_Multi-Pass_Sieve_for_Coreference_Resolution.html">8 emnlp-2010-A Multi-Pass Sieve for Coreference Resolution</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.171), (1, 0.145), (2, -0.145), (3, -0.076), (4, 0.076), (5, -0.061), (6, 0.46), (7, -0.026), (8, 0.048), (9, 0.021), (10, -0.073), (11, 0.08), (12, 0.393), (13, -0.25), (14, -0.049), (15, -0.358), (16, -0.068), (17, 0.04), (18, 0.182), (19, -0.049), (20, -0.068), (21, -0.012), (22, 0.012), (23, 0.067), (24, -0.006), (25, 0.042), (26, -0.009), (27, -0.026), (28, -0.015), (29, 0.018), (30, 0.058), (31, -0.097), (32, -0.036), (33, -0.006), (34, 0.044), (35, -0.088), (36, -0.052), (37, -0.017), (38, 0.036), (39, -0.035), (40, 0.02), (41, -0.005), (42, -0.001), (43, 0.03), (44, -0.009), (45, -0.029), (46, -0.001), (47, -0.007), (48, -0.013), (49, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97935367 <a title="49-lsi-1" href="./emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields.html">49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: In this paper, we focus on the opinion target extraction as part of the opinion mining task. We model the problem as an information extraction task, which we address based on Conditional Random Fields (CRF). As a baseline we employ the supervised algorithm by Zhuang et al. (2006), which represents the state-of-the-art on the employed data. We evaluate the algorithms comprehensively on datasets from four different domains annotated with individual opinion target instances on a sentence level. Furthermore, we investigate the performance of our CRF-based approach and the baseline in a single- and cross-domain opinion target extraction setting. Our CRF-based approach improves the performance by 0.077, 0.126, 0.071 and 0. 178 regarding F-Measure in the single-domain extraction in the four domains. In the crossdomain setting our approach improves the performance by 0.409, 0.242, 0.294 and 0.343 regarding F-Measure over the baseline.</p><p>2 0.9546563 <a title="49-lsi-2" href="./emnlp-2010-Jointly_Modeling_Aspects_and_Opinions_with_a_MaxEnt-LDA_Hybrid.html">70 emnlp-2010-Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid</a></p>
<p>Author: Xin Zhao ; Jing Jiang ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Discovering and summarizing opinions from online reviews is an important and challenging task. A commonly-adopted framework generates structured review summaries with aspects and opinions. Recently topic models have been used to identify meaningful review aspects, but existing topic models do not identify aspect-specific opinion words. In this paper, we propose a MaxEnt-LDA hybrid model to jointly discover both aspects and aspect-specific opinion words. We show that with a relatively small amount of training data, our model can effectively identify aspect and opinion words simultaneously. We also demonstrate the domain adaptability of our model.</p><p>3 0.2732811 <a title="49-lsi-3" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>Author: Ahmed Hassan ; Vahed Qazvinian ; Dragomir Radev</p><p>Abstract: Mining sentiment from user generated content is a very important task in Natural Language Processing. An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web. Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums. Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics. In this work, we present a method to identify the attitude of participants in an online discussion toward one another. This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative. This is different from most of the research on social networks that has focused almost exclusively on positive links. The method is exper- imentally tested using a manually labeled set of discussion posts. The results show that the proposed method is capable of identifying attitudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.</p><p>4 0.21142979 <a title="49-lsi-4" href="./emnlp-2010-Incorporating_Content_Structure_into_Text_Analysis_Applications.html">64 emnlp-2010-Incorporating Content Structure into Text Analysis Applications</a></p>
<p>Author: Christina Sauper ; Aria Haghighi ; Regina Barzilay</p><p>Abstract: In this paper, we investigate how modeling content structure can benefit text analysis applications such as extractive summarization and sentiment analysis. This follows the linguistic intuition that rich contextual information should be useful in these tasks. We present a framework which combines a supervised text analysis application with the induction of latent content structure. Both of these elements are learned jointly using the EM algorithm. The induced content structure is learned from a large unannotated corpus and biased by the underlying text analysis task. We demonstrate that exploiting content structure yields significant improvements over approaches that rely only on local context.1</p><p>5 0.20678864 <a title="49-lsi-5" href="./emnlp-2010-Efficient_Graph-Based_Semi-Supervised_Learning_of_Structured_Tagging_Models.html">41 emnlp-2010-Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models</a></p>
<p>Author: Amarnag Subramanya ; Slav Petrov ; Fernando Pereira</p><p>Abstract: We describe a new scalable algorithm for semi-supervised training of conditional random fields (CRF) and its application to partof-speech (POS) tagging. The algorithm uses a similarity graph to encourage similar ngrams to have similar POS tags. We demonstrate the efficacy of our approach on a domain adaptation task, where we assume that we have access to large amounts of unlabeled data from the target domain, but no additional labeled data. The similarity graph is used during training to smooth the state posteriors on the target domain. Standard inference can be used at test time. Our approach is able to scale to very large problems and yields significantly improved target domain accuracy.</p><p>6 0.20086601 <a title="49-lsi-6" href="./emnlp-2010-We%27re_Not_in_Kansas_Anymore%3A_Detecting_Domain_Changes_in_Streams.html">119 emnlp-2010-We're Not in Kansas Anymore: Detecting Domain Changes in Streams</a></p>
<p>7 0.19412929 <a title="49-lsi-7" href="./emnlp-2010-Summarizing_Contrastive_Viewpoints_in_Opinionated_Text.html">102 emnlp-2010-Summarizing Contrastive Viewpoints in Opinionated Text</a></p>
<p>8 0.16490296 <a title="49-lsi-8" href="./emnlp-2010-The_Necessity_of_Combining_Adaptation_Methods.html">104 emnlp-2010-The Necessity of Combining Adaptation Methods</a></p>
<p>9 0.16082188 <a title="49-lsi-9" href="./emnlp-2010-Evaluating_the_Impact_of_Alternative_Dependency_Graph_Encodings_on_Solving_Event_Extraction_Tasks.html">46 emnlp-2010-Evaluating the Impact of Alternative Dependency Graph Encodings on Solving Event Extraction Tasks</a></p>
<p>10 0.15643016 <a title="49-lsi-10" href="./emnlp-2010-Staying_Informed%3A_Supervised_and_Semi-Supervised_Multi-View_Topical_Analysis_of_Ideological_Perspective.html">100 emnlp-2010-Staying Informed: Supervised and Semi-Supervised Multi-View Topical Analysis of Ideological Perspective</a></p>
<p>11 0.15523128 <a title="49-lsi-11" href="./emnlp-2010-Multi-Level_Structured_Models_for_Document-Level_Sentiment_Classification.html">83 emnlp-2010-Multi-Level Structured Models for Document-Level Sentiment Classification</a></p>
<p>12 0.13769361 <a title="49-lsi-12" href="./emnlp-2010-WikiWars%3A_A_New_Corpus_for_Research_on_Temporal_Expressions.html">122 emnlp-2010-WikiWars: A New Corpus for Research on Temporal Expressions</a></p>
<p>13 0.13693261 <a title="49-lsi-13" href="./emnlp-2010-Better_Punctuation_Prediction_with_Dynamic_Conditional_Random_Fields.html">25 emnlp-2010-Better Punctuation Prediction with Dynamic Conditional Random Fields</a></p>
<p>14 0.13290536 <a title="49-lsi-14" href="./emnlp-2010-EMNLP_044.html">39 emnlp-2010-EMNLP 044</a></p>
<p>15 0.13066955 <a title="49-lsi-15" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<p>16 0.12960196 <a title="49-lsi-16" href="./emnlp-2010-A_New_Approach_to_Lexical_Disambiguation_of_Arabic_Text.html">9 emnlp-2010-A New Approach to Lexical Disambiguation of Arabic Text</a></p>
<p>17 0.12492181 <a title="49-lsi-17" href="./emnlp-2010-Improving_Mention_Detection_Robustness_to_Noisy_Input.html">62 emnlp-2010-Improving Mention Detection Robustness to Noisy Input</a></p>
<p>18 0.12412853 <a title="49-lsi-18" href="./emnlp-2010-Confidence_in_Structured-Prediction_Using_Confidence-Weighted_Models.html">30 emnlp-2010-Confidence in Structured-Prediction Using Confidence-Weighted Models</a></p>
<p>19 0.12338918 <a title="49-lsi-19" href="./emnlp-2010-Unsupervised_Parse_Selection_for_HPSG.html">114 emnlp-2010-Unsupervised Parse Selection for HPSG</a></p>
<p>20 0.12109073 <a title="49-lsi-20" href="./emnlp-2010-Uptraining_for_Accurate_Deterministic_Question_Parsing.html">115 emnlp-2010-Uptraining for Accurate Deterministic Question Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.014), (10, 0.022), (12, 0.043), (29, 0.073), (30, 0.026), (45, 0.243), (52, 0.033), (56, 0.112), (62, 0.015), (66, 0.173), (72, 0.083), (76, 0.022), (87, 0.015), (89, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86256939 <a title="49-lda-1" href="./emnlp-2010-Turbo_Parsers%3A_Dependency_Parsing_by_Approximate_Variational_Inference.html">110 emnlp-2010-Turbo Parsers: Dependency Parsing by Approximate Variational Inference</a></p>
<p>Author: Andre Martins ; Noah Smith ; Eric Xing ; Pedro Aguiar ; Mario Figueiredo</p><p>Abstract: We present a unified view of two state-of-theart non-projective dependency parsers, both approximate: the loopy belief propagation parser of Smith and Eisner (2008) and the relaxed linear program of Martins et al. (2009). By representing the model assumptions with a factor graph, we shed light on the optimization problems tackled in each method. We also propose a new aggressive online algorithm to learn the model parameters, which makes use of the underlying variational representation. The algorithm does not require a learning rate parameter and provides a single framework for a wide family of convex loss functions, includ- ing CRFs and structured SVMs. Experiments show state-of-the-art performance for 14 languages.</p><p>same-paper 2 0.81713903 <a title="49-lda-2" href="./emnlp-2010-Extracting_Opinion_Targets_in_a_Single_and_Cross-Domain_Setting_with_Conditional_Random_Fields.html">49 emnlp-2010-Extracting Opinion Targets in a Single and Cross-Domain Setting with Conditional Random Fields</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: In this paper, we focus on the opinion target extraction as part of the opinion mining task. We model the problem as an information extraction task, which we address based on Conditional Random Fields (CRF). As a baseline we employ the supervised algorithm by Zhuang et al. (2006), which represents the state-of-the-art on the employed data. We evaluate the algorithms comprehensively on datasets from four different domains annotated with individual opinion target instances on a sentence level. Furthermore, we investigate the performance of our CRF-based approach and the baseline in a single- and cross-domain opinion target extraction setting. Our CRF-based approach improves the performance by 0.077, 0.126, 0.071 and 0. 178 regarding F-Measure in the single-domain extraction in the four domains. In the crossdomain setting our approach improves the performance by 0.409, 0.242, 0.294 and 0.343 regarding F-Measure over the baseline.</p><p>3 0.67201239 <a title="49-lda-3" href="./emnlp-2010-What%27s_with_the_Attitude%3F_Identifying_Sentences_with_Attitude_in_Online_Discussions.html">120 emnlp-2010-What's with the Attitude? Identifying Sentences with Attitude in Online Discussions</a></p>
<p>Author: Ahmed Hassan ; Vahed Qazvinian ; Dragomir Radev</p><p>Abstract: Mining sentiment from user generated content is a very important task in Natural Language Processing. An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web. Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums. Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics. In this work, we present a method to identify the attitude of participants in an online discussion toward one another. This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative. This is different from most of the research on social networks that has focused almost exclusively on positive links. The method is exper- imentally tested using a manually labeled set of discussion posts. The results show that the proposed method is capable of identifying attitudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.</p><p>4 0.66984838 <a title="49-lda-4" href="./emnlp-2010-Joint_Training_and_Decoding_Using_Virtual_Nodes_for_Cascaded_Segmentation_and_Tagging_Tasks.html">69 emnlp-2010-Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks</a></p>
<p>Author: Xian Qian ; Qi Zhang ; Yaqian Zhou ; Xuanjing Huang ; Lide Wu</p><p>Abstract: Many sequence labeling tasks in NLP require solving a cascade of segmentation and tagging subtasks, such as Chinese POS tagging, named entity recognition, and so on. Traditional pipeline approaches usually suffer from error propagation. Joint training/decoding in the cross-product state space could cause too many parameters and high inference complexity. In this paper, we present a novel method which integrates graph structures of two subtasks into one using virtual nodes, and performs joint training and decoding in the factorized state space. Experimental evaluations on CoNLL 2000 shallow parsing data set and Fourth SIGHAN Bakeoff CTB POS tagging data set demonstrate the superiority of our method over cross-product, pipeline and candidate reranking approaches.</p><p>5 0.66487467 <a title="49-lda-5" href="./emnlp-2010-Discriminative_Sample_Selection_for_Statistical_Machine_Translation.html">35 emnlp-2010-Discriminative Sample Selection for Statistical Machine Translation</a></p>
<p>Author: Sankaranarayanan Ananthakrishnan ; Rohit Prasad ; David Stallard ; Prem Natarajan</p><p>Abstract: Production of parallel training corpora for the development of statistical machine translation (SMT) systems for resource-poor languages usually requires extensive manual effort. Active sample selection aims to reduce the labor, time, and expense incurred in producing such resources, attaining a given performance benchmark with the smallest possible training corpus by choosing informative, nonredundant source sentences from an available candidate pool for manual translation. We present a novel, discriminative sample selection strategy that preferentially selects batches of candidate sentences with constructs that lead to erroneous translations on a held-out development set. The proposed strategy supports a built-in diversity mechanism that reduces redundancy in the selected batches. Simulation experiments on English-to-Pashto and Spanish-to-English translation tasks demon- strate the superiority of the proposed approach to a number of competing techniques, such as random selection, dissimilarity-based selection, as well as a recently proposed semisupervised active learning strategy.</p><p>6 0.66445315 <a title="49-lda-6" href="./emnlp-2010-Multi-Document_Summarization_Using_A%2A_Search_and_Discriminative_Learning.html">82 emnlp-2010-Multi-Document Summarization Using A* Search and Discriminative Learning</a></p>
<p>7 0.6610496 <a title="49-lda-7" href="./emnlp-2010-A_Semi-Supervised_Approach_to_Improve_Classification_of_Infrequent_Discourse_Relations_Using_Feature_Vector_Extension.html">11 emnlp-2010-A Semi-Supervised Approach to Improve Classification of Infrequent Discourse Relations Using Feature Vector Extension</a></p>
<p>8 0.65585822 <a title="49-lda-8" href="./emnlp-2010-Holistic_Sentiment_Analysis_Across_Languages%3A_Multilingual_Supervised_Latent_Dirichlet_Allocation.html">58 emnlp-2010-Holistic Sentiment Analysis Across Languages: Multilingual Supervised Latent Dirichlet Allocation</a></p>
<p>9 0.65405256 <a title="49-lda-9" href="./emnlp-2010-Enhancing_Domain_Portability_of_Chinese_Segmentation_Model_Using_Chi-Square_Statistics_and_Bootstrapping.html">43 emnlp-2010-Enhancing Domain Portability of Chinese Segmentation Model Using Chi-Square Statistics and Bootstrapping</a></p>
<p>10 0.65329325 <a title="49-lda-10" href="./emnlp-2010-Evaluating_Models_of_Latent_Document_Semantics_in_the_Presence_of_OCR_Errors.html">45 emnlp-2010-Evaluating Models of Latent Document Semantics in the Presence of OCR Errors</a></p>
<p>11 0.65199518 <a title="49-lda-11" href="./emnlp-2010-Towards_Conversation_Entailment%3A_An_Empirical_Investigation.html">107 emnlp-2010-Towards Conversation Entailment: An Empirical Investigation</a></p>
<p>12 0.64944959 <a title="49-lda-12" href="./emnlp-2010-The_Necessity_of_Combining_Adaptation_Methods.html">104 emnlp-2010-The Necessity of Combining Adaptation Methods</a></p>
<p>13 0.64789903 <a title="49-lda-13" href="./emnlp-2010-Non-Isomorphic_Forest_Pair_Translation.html">86 emnlp-2010-Non-Isomorphic Forest Pair Translation</a></p>
<p>14 0.64749002 <a title="49-lda-14" href="./emnlp-2010-Better_Punctuation_Prediction_with_Dynamic_Conditional_Random_Fields.html">25 emnlp-2010-Better Punctuation Prediction with Dynamic Conditional Random Fields</a></p>
<p>15 0.64722246 <a title="49-lda-15" href="./emnlp-2010-A_New_Approach_to_Lexical_Disambiguation_of_Arabic_Text.html">9 emnlp-2010-A New Approach to Lexical Disambiguation of Arabic Text</a></p>
<p>16 0.64722186 <a title="49-lda-16" href="./emnlp-2010-Negative_Training_Data_Can_be_Harmful_to_Text_Classification.html">85 emnlp-2010-Negative Training Data Can be Harmful to Text Classification</a></p>
<p>17 0.6471417 <a title="49-lda-17" href="./emnlp-2010-Predicting_the_Semantic_Compositionality_of_Prefix_Verbs.html">92 emnlp-2010-Predicting the Semantic Compositionality of Prefix Verbs</a></p>
<p>18 0.64597797 <a title="49-lda-18" href="./emnlp-2010-Title_Generation_with_Quasi-Synchronous_Grammar.html">105 emnlp-2010-Title Generation with Quasi-Synchronous Grammar</a></p>
<p>19 0.64533108 <a title="49-lda-19" href="./emnlp-2010-Automatic_Detection_and_Classification_of_Social_Events.html">20 emnlp-2010-Automatic Detection and Classification of Social Events</a></p>
<p>20 0.64480531 <a title="49-lda-20" href="./emnlp-2010-It_Depends_on_the_Translation%3A_Unsupervised_Dependency_Parsing_via_Word_Alignment.html">67 emnlp-2010-It Depends on the Translation: Unsupervised Dependency Parsing via Word Alignment</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
