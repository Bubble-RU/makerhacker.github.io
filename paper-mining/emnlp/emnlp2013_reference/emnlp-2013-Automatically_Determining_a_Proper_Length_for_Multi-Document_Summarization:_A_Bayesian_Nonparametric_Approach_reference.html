<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-36" href="../emnlp2013/emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">emnlp2013-36</a> <a title="emnlp-2013-36-reference" href="#">emnlp2013-36-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</h1>
<br/><p>Source: <a title="emnlp-2013-36-pdf" href="http://aclweb.org/anthology//D/D13/D13-1069.pdf">pdf</a></p><p>Author: Tengfei Ma ; Hiroshi Nakagawa</p><p>Abstract: Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.</p><br/>
<h2>reference text</h2><p>Christopher M. Bishop. 2006. Pattern recognition and machine learning. . Vol. 4. No. 4. New York: springer. Jaime Carbonell, and Jade Goldstein. 1998. The Use Of Mmr, Diversity-Based Reranking For Reordering Documents And Producing Summaries. Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1998. Asli Celikyilmaz and Dilek Hakkani-T u¨r. 2010. A Hybrid Hierarchical Model for Multi-Document Summarization. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 815-824. Ying-Lan Chang, Jui-Jung Hung and Jen-Tzung Chien 2011. Bayesian Nonparametric Modeling Of Hierarchical Topics And Sentences. IEEE International 745 Workshop on Machine Learningfor Signal Processing, September 18-21, 2011, Beijing, China. Thomas M. Cover, and Joy A. Thomas. 2006. Elements of information theory. Wiley-interscience, 2006. William M. Darling and Fei Song. 2011. PathSum: A Summarization Framework Based on Hierarchical Topics. Canadian AI Workshop on Text Summarization, St. John’s, Newfoundland. Samuel J. Gershman and David M. Blei. 2011. A Tuto-  rial On Bayesian Nonparametric Models. Journal of Mathematical Psychology(2011). Thomas L. Griffiths and Zoubin Ghahramani. 2005. Infinite Latent Feature Models and the Indian Buffet Process. Advances in Neural Information Processing Systems 18. Jade Goldstein, Mark Kantrowitz, Vibhu Mittal and Jaime Carbonelly. 1999. Summarizing Text Documents: Sentence Selection and Evaluation Metrics. Proceedings of SIGIR ’99 , pages 121-128. Zhanying He, Chun Chen, Jiajun Bu, CanWang, Lijun Zhang, Deng Cai and Xiaofei He. 2012. Document Summarization Based on Data Reconstruction. Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence. Michael Kaisser, Marti A. Hearst, John B. Lowe. 2008. Improving Search Results Quality by Customizing Summary Lengths. Proceedings of ACL-08: HLT, pages 701-709. Chin-Yew Lin, Guihong Cao, Jianfeng Gao, and Jian-Yun Nie. 2006. An Information-Theoretic Approach to Automatic Evaluation of Summaries. Proceedings of NAACL2006, pages 463-470. Chin-Yew Lin, and Eduard Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. Proceedings of NAACL2003. Annie Louis and Ani Nenkova. 2009. Automatically  Evaluating  Content Selection in Summarization with-  out Human Models.  Proceedings  of the  2009  Confer-  Empirical Methods in Natural Language Processing, pages 306-3 14. Singapore, 6-7 August 2009. Tengfei Ma and Xiaojun Wan. 2010. Multidocument Summarization Using Minimum Distortion. IEEE 10th International Conference on Data Mining ence on  (ICDM). Ani Nenkova vey  of  Data,  and Kathleen McKeown.  2012.  A sur-  summarization techniques. Mining Text Chapter 3, Springer Science+Business Media, text  LLC (2012).  John Paisley and Lawrence Carin. 2009. Nonparametric Factor Analysis with Beta Process Priors. Proceedings of the 26th International Conference on Machine Learning, Montreal, Canada. John Paisley, Aimee Zaas, Christopher W. Woods, Geoffrey S. Ginsburg and Lawrence Carin. 2010. A StickBreaking Construction of the Beta Process. Proceedings of the 27 th International Confer- ence on Machine Learning, Haifa, Israel, 2010. Dragomir R. Radev and Weiguo Fan. 2000. Effective search results summary size and device screen size: Is there a relationship. Proceedings of the ACL-2000 workshop on Recent advances in natural language processing and information retrieval G u¨nes Erkan, and Dragomir R. Radev. 2004. LexRank: Graph-based Lexical Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research, 22 (2004) 457-479. Noam Slonim. 2002. The Information Bottleneck: Theory and Applications. PHD Thesis of the Hebrew University . Simon Sweeney and Fabio Crestani. 2006. Effective search results summary size and device screen size: Is there a relationship. Information Processing and Management 42 (2006) 1056-1074. Simon Sweeney, Fabio Crestani and David E. Losada. 2008. ’Show me more’ : Incremental length summarisation using novelty detection. Information Processing and Management 44 (2008) 663-686. Yee Whye Teh, Dilan G ¨or ¨ur, and Zoubin Ghahramani. 2007. Stick-breaking Construction for the Indian Buf-  fet Process. Proceedings of the International Conference on Artificial Intelligence and Statistics. Y.W. Teh, M.I. Jordan, M.J. Beal and D.M. Blei. 2006. Hierarchical Dirichlet Processes. JASA , 101(476): 1566-1581. Romain Thibaux and Michael I. Jordan. 2009. Hierarchical Beta Processes and the Indian Buffet Process. AISTATS2007. 746</p>
<br/>
<br/><br/><br/></body>
</html>
