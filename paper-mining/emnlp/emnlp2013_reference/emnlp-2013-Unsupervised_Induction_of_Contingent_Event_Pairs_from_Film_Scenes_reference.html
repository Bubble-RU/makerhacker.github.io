<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-192" href="../emnlp2013/emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">emnlp2013-192</a> <a title="emnlp-2013-192-reference" href="#">emnlp2013-192-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</h1>
<br/><p>Source: <a title="emnlp-2013-192-pdf" href="http://aclweb.org/anthology//D/D13/D13-1036.pdf">pdf</a></p><p>Author: Zhichao Hu ; Elahe Rahimtoroghi ; Larissa Munishkina ; Reid Swanson ; Marilyn A. Walker</p><p>Abstract: Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning. Researchers in NLP have tackled modeling such expectations from a range of perspectives, including treating it as the inference of the CONTINGENT discourse relation, or as a type of common-sense causal reasoning. Our approach is to model likelihood between events by drawing on several of these lines of previous work. We implement and evaluate different unsupervised methods for learning event pairs that are likely to be CONTINGENT on one another. We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments ofcontingency. Our results indicate that the use of web search counts increases the av- , erage accuracy of our best method to 85.64% over a baseline of 50%, as compared to an average accuracy of 75. 15% without web search.</p><br/>
<h2>reference text</h2><p>B. Beamer and R. Girju. 2009. Using a bigram event model to predict causal potential. In Computational Linguistics and Intelligent Text Processing, p. 430– 441. Springer. C. Callison-Burch. 2009. Fast, cheap, and creative: evaluating translation quality using amazon’s mechanical turk. In Proc. of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1Volume 1, p. 286–295. Association for Computational Linguistics. N. Chambers and D. Jurafsky. 2008. Unsupervised learning of narrative event chains. Proc. of ACL-08: HLT, p. 789–797. N. Chambers and D. Jurafsky. 2009. Unsupervised learning of narrative schemas and their participants. In Proc. of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, p. 602–610. C. Chiarcos. 2012. Towards the unsupervised acquisition of discourse relations. In Proc. of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, p. 213–217. Association for Computational Linguistics. A. P. Dawid and A. M. Skene. 1979. Maximum likelihood estimation of observer error-rates using the EM algorithm. Journal of the Royal Statistical Society. Se-  ries C (Applied Statistics), 28(1):20–28. Q. X. Do, Y. S. Chan, and D. Roth. 2011. Minimally supervised event causality identification. In Proc. of the Conference on Empirical Methods in Natural Language Processing, p. 294–303. Association for Computational Linguistics. R.J. Gerrig. 1993. Experiencing narrative worlds: On the psychological activities of reading. Yale Univ Pr. A. Gordon and R. Swanson. 2009. Identifying personal stories in millions of weblog entries. In Third International Conference on Weblogs and Social Media, Data Challenge Workshop. A. Gordon, Cosmin Bejan, and Kenji Sagae. 2011. Commonsense causal reasoning using millions of personal stories. In Twenty-Fifth Conference on Artificial Intelligence (AAAI-11). A. Goyal, E. Riloff, and H. Daum e´ III. 2010. Automatically producing plot unit representations for narrative text. In Proc. of the 2010 Conference on Empirical Methods in Natural Language Processing, p. 77–86. Association for Computational Linguistics. A. C. Graesser, M. Singer, and T. Trabasso. 1994. Constructing inferences during narrative text comprehension. Psychological review, 101(3):371. D. R. Karger, S. Oh, and D. Shah. 2011. Iterative learning for reliable crowdsourcing systems. In John Shawe-Taylor, Richard S. Zemel, Peter L. Bartlett, Fernando C. N. Pereira, and Kilian Q. Weinberger, ed-  itors, NIPS, p. 1953–1961. W. Labov and J. Waletzky. 1997. Narrative analysis: Oral versions of personal experience. W. G. Lehnert. 1981 . Plot units and narrative summarization. Cognitive Science, 5(4):293–331 . Z. Lin, M.-Y. Kan, and H. T Ng. 2010. A pdtb-styled end-to-end discourse parser. In Proc. of the Conference on Empirical Methods in Natural Language Processing. Q. Liu, J. Peng, and A. Ihler. 2012. Variational inference for crowdsourcing. InAdvances in Neural Information Processing Systems 25, p. 701–709. 379 A. Louis, A. Joshi, R. Prasad, and A. Nenkova. 2010. Using entity features to classify implicit relations. In Proc. of the 11th Annual SIGdial Meeting on Discourse and Dialogue, Tokyo, Japan. M. Manshadi, R. Swanson, and A. S Gordon. 2008. Learning a probabilistic model of event sequences from internet weblog stories. In Proc. of the 21st FLAIRS Conference. E. Pitler, A. Louis, and A. Nenkova. 2009. Automatic sense prediction for implicit discourse relations in text. In Proc. of the 47th Meeting of the Association for Computational Linguistics. R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki, L. Robaldo,  A. Joshi, and B. Webber. 2008a. The penn discourse treebank 2.0. In Proc. of the 6th International Conference on Language Resources and Evaluation (LREC 2008), p. 2961–2968. R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki, L. Robaldo, A. Joshi, and B. Webber. 2008b. The Penn Discourse TreeBank 2.0. In Proc. of 6th International Conference on Language Resources and Evaluation (LREC 2008). M. Riaz and R. Girju. 2010. Another look at causality: Discovering scenario-specific contingency relationships with no supervision. In Semantic Computing (ICSC), 2010 IEEE Fourth International Conference on, p. 361–368. IEEE. R. Schank and R. Abelson. 1977. Scripts Plans Goals. Lea. R. Snow, B. O’Connor, D. Jurafsky, and A.Y. Ng. 2008. Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks. In Proc. of the Conference on Empirical Methods in Natural Language Processing, p. 254–263. Association for Computational Linguistics. R. Swanson and A. S. Gordon. 2012. Say anything: Using textual case-based reasoning to enable opendomain interactive storytelling. ACM Transactions on Interactive Intelligent Systems (TiiS), 2(3): 16. M. A. Walker, G. Lin, and J. Sawyer. 2012b. An anno-  tated corpus of film dialogue for learning and characterizing character style. In Language Resources and Evaluation Conference, LREC2012. P. Welinder, S. Branson, S. Belongie, and P. Perona. 2010. The multidimensional wisdom of crowds. In Advances in Neural Information Processing Systems 23, p. 2424–2432. Z.-M. Zhou, Y. Xu, Z.Y. Niu, M. Lan, J. Su, , and C. L. Tan. 2010. Predicting discourse connectives for implicit discourse relation recognition. In In Coling 2010: Posters, p. 1507–1514.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
