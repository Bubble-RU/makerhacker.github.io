<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 emnlp-2013-Learning Distributions over Logical Forms for Referring Expression Generation</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-119" href="../emnlp2013/emnlp-2013-Learning_Distributions_over_Logical_Forms_for_Referring_Expression_Generation.html">emnlp2013-119</a> <a title="emnlp-2013-119-reference" href="#">emnlp2013-119-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>119 emnlp-2013-Learning Distributions over Logical Forms for Referring Expression Generation</h1>
<br/><p>Source: <a title="emnlp-2013-119-pdf" href="http://aclweb.org/anthology//D/D13/D13-1197.pdf">pdf</a></p><p>Author: Nicholas FitzGerald ; Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: We present a new approach to referring expression generation, casting it as a density estimation problem where the goal is to learn distributions over logical expressions identifying sets of objects in the world. Despite an extremely large space of possible expressions, we demonstrate effective learning of a globally normalized log-linear distribution. This learning is enabled by a new, multi-stage approximate inference technique that uses a pruning model to construct only the most likely logical forms. We train and evaluate the approach on a new corpus of references to sets of visual objects. Experiments show the approach is able to learn accurate models, which generate over 87% of the expressions people used. Additionally, on the previously studied special case of single object reference, we show a 35% relative error reduction over previous state of the art.</p><br/>
<h2>reference text</h2><p>Areces, C., Koller, A., and Striegnitz, K. (2008). Referring expressions as formulas of description logic. In Proceedings of the International Natural Language Generation Conference. Artzi, Y. and Zettlemoyer, L. (201 1). Bootstrapping semantic parsers from conversations. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Artzi, Y. and Zettlemoyer, L. (2013a). UW SPF: The University of Washington Semantic Parsing Framework. Artzi, Y. and Zettlemoyer, L. (2013b). Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics, 1(1):49– 62. Barzilay, R. and Lapata, M. (2005). Collective content selection for concept-to-text generation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Berg, A. C., Berg, T. L., Daume, H., Dodge, J., Goyal, A., Han, X., Mensch, A., Mitchell, M., Sood, A., Stratos, K., et al. (2012). Understanding and predicting importance in images. In  IEEE Conference on Computer Vision andPattern Recognition. Carenini, G., Ng, R. T., and Pauls, A. (2006). Multidocument summarization of evaluative text. In Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics. Carpenter, B. (1997). Type-Logical Semantics. The MIT Press. Chen, D., Kim, J., and Mooney, R. (2010). Training a multilingual sportscaster: using perceptual context to learn language. Journal of Artificial Intelligence Research, 37(1):397–436. Chen, D. and Mooney, R. (201 1). Learning to interpret natural language navigation instructions from observations. In Proceedings ofthe National Conference on Artificial Intelligence. Dale, R. and Reiter, E. (1995). Computational interpretations of the gricean maxims in the gener1924 ation of referring expressions. Cognitive Science, 19:233–264. Dale, R. and Reiter, E. (2000). Building natural language generation systems. Cambridge University  Press. Gardent, C. (2002). Generating minimal definite descriptions. In Proceedings of the Annual Meeting of the Association for Computational Linguistics. Gatt, A. and van Deemter, K. (2007). Incremental generation of plural descriptions: Similarity and partitioning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Gatt, A., Van Der Sluis, I., and Van Deemter, K. (2007). Evaluating algorithms for the generation of referring expressions using a balanced corpus. In Proceedings ofthe European Workshop on Natural Language Generation. Grice, H. P. (1975). Logic and conversation. 1975, pages 41–58. Horacek, H. (2004). On referring to sets of objects naturally. In Natural Language Generation, pages 70–79. Springer. Kim, J. and Mooney, R. J. (2012). Unsupervised PCFG induction for grounded language learning with highly ambiguous supervision. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.  Konstas, I. and Lapata, M. (2012). Unsupervised concept-to-text generation with hypergraphs. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics. Krahmer, E. and van Deemter, K. (2012). Computational generation of referring expressions: A survey. Computational Linguistics, 38(1): 173–218. Krishnamurthy, J. and Kollar, T. (2013). Jointly learning to parse and perceive: Connecting natural language to the physical world. Transactions of the Association for Computational Linguistics, 1(2): 193–206. Liang, P., Jordan, M., and Klein, D. (2009). Learning semantic correspondences with less supervision. In Proceedings of the Annual Meeting of the Association for Computational Linguistics. Lu, W. and Ng, H. T. (201 1). A probabilistic forest-to-string model for language generation from typed lambda calculus expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Matuszek, C., FitzGerald, N., Zettlemoyer, L., Bo, L., and Fox, D. (2012a). A joint model of lan-  guage and perception for grounded attribute learning. Proceedings of the International Conference on Machine Learning. Matuszek, C., Herbst, E., Zettlemoyer, L. S., and Fox, D. (2012b). Learning to parse natural language commands to a robot control system. In Proceedings of the International Symposium on Experimental Robotics. Mitchell, M., van Deemter, K., and Reiter, E. (201 1a). Applying machine learning to the choice of size modifiers. In Proceedings of the PRECogSci Workshop. Mitchell, M., Van Deemter, K., and Reiter, E. (201 1b). Two approaches for generating size modifiers. In Proceedings of the European Workshop on Natural Language Generation. Mitchell, M., van Deemter, K., and Reiter, E. (2013). Generating expressions that refer to visible objects. In Proceedings of Conference of the North American Chapter of the Association for Computational Linguistics. Ren, Y., Van Deemter, K., and Pan, J. Z. (2010). Charting the potential of description logic for the generation of referring expressions. In Proceedings of the International Natural Language Gen-  eration Conference. Scontras, G., Graff, P., and Goodman, N. D. (2012). Comparing pluralities. Cognition, 123(1): 190– 197. Steedman, M. (201 1). Taking Scope. The MIT Press. Stone, M. (2000). On identifying sets. In Proceedings of the International Conference on Natural Language Generation. van Deemter, K. (2002). Generating referring expressions: Boolean extensions of the incremental algorithm. Computational Linguistics, 28:37–52. van Deemter, K., Gatt, A., Sluis, I. v. d., and Power, R. (2012a). Generation of referring expressions: 1925 Cognitive  Assessing the incremental algorithm. Science, 36(5):799–836. van Deemter, K., Gatt, A., van Gompel, R. P., and Krahmer, E. (2012b). Toward a computational psycholinguistics of reference production. Topics in Cognitive Science, 4(2): 166–1 83. Viethen, J. and Dale, R. (2010). Speaker-dependent variation in content selection for referring expression generation. In Proceedings of the Australasian Language Technology Workshop.  Viethen, J., Mitchell, M., and Krahmer, E. (2013). Graphs and spatial relations in the generation of referring expressions. In Proceedings of the European Workshop on Natural Language Generation. White, M. and Rajkumar, R. (2009). Perceptron reranking for ccg realization. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Winograd, T. (1972). Understanding natural language. Cognitive Psychology, 3(1): 1–191. Zelle, J. and Mooney, R. (1996). Learning to parse database queries using inductive logic programming. In Proceedings of the National Conference on Artificial Intelligence. Zettlemoyer, L. and Collins, M. (2005). Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of the Conference on Uncertainty in Artificial Intelligence. Zettlemoyer, L. and Collins, M. (2007). Online learning of relaxed CCG grammars for parsing to logical form. In Proceedings of the Joint Conference on Empirical Methods in Natural Language  Processing and Computational Natural Language Learning. Zitnick, C. L. and Parikh, D. (2013). Bringing semantics into focus using visual abstraction. In IEEE Conference on Computer Vision andPattern Recognition.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
