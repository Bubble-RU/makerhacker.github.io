<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 emnlp-2013-Automated Essay Scoring by Maximizing Human-Machine Agreement</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-28" href="../emnlp2013/emnlp-2013-Automated_Essay_Scoring_by_Maximizing_Human-Machine_Agreement.html">emnlp2013-28</a> <a title="emnlp-2013-28-reference" href="#">emnlp2013-28-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>28 emnlp-2013-Automated Essay Scoring by Maximizing Human-Machine Agreement</h1>
<br/><p>Source: <a title="emnlp-2013-28-pdf" href="http://aclweb.org/anthology//D/D13/D13-1180.pdf">pdf</a></p><p>Author: Hongbo Chen ; Ben He</p><p>Abstract: Previous approaches for automated essay scoring (AES) learn a rating model by minimizing either the classification, regression, or pairwise classification loss, depending on the learning algorithm used. In this paper, we argue that the current AES systems can be further improved by taking into account the agreement between human and machine raters. To this end, we propose a rankbased approach that utilizes listwise learning to rank algorithms for learning a rating model, where the agreement between the human and machine raters is directly incorporated into the loss function. Various linguistic and statistical features are utilized to facilitate the learning algorithms. Experiments on the publicly available English essay dataset, Automated Student Assessment Prize (ASAP), show that our proposed approach outperforms the state-of-the-art algorithms, and achieves performance comparable to professional human raters, which suggests the effectiveness of our proposed method for automated essay scoring.</p><br/>
<h2>reference text</h2><p>Y. Attali and J. Burstein. 2006. Automated essay scoring with e-rater⃝R v. 2. The Journal of Technology, Learning and Ass⃝essm v.e 2n.t, T 4h(e3 )J.o Yigal Attali, Brent Bridgeman, and Catherine Trapani. 2010. Performance of a generic approach in automated essay scoring. The Journal of Technology, Learning and Assessment, 10(3).  L. Breiman. 2001 . Random forests. Machine learning, 45(1):5–32. H.M. Breland, R.J. Jones, and L. Jenkins. 1994. The college board vocabulary study. College Entrance Examination Board. Hermann Brenner and Ulrike Kliebsch. 1996. Dependence of weighted kappa coefficients on the number of categories. Epidemiology, pages 199–202. T. Briscoe, B. Medlock, and Andersen. 2010. Automated assessment of esol free text examinations. Technical report, University of Cambridge Computer Laboratory Technical Reports, UCAM-CL-TR-790. C. Burges. 2010. From ranknet to lambdarank to lambdamart: An overview. Learning, 11:23–581 . Miao Chen and Klaus Zechner. 2011. Computing and evaluating syntactic complexity features for automated scoring of spontaneous non-native speech. In Proceedings ofthe 49thAnnual Meeting oftheAssociation for Computational Linguistics, pages 722–73 1. Hongbo Chen, Ben He, Tiejian Luo, and Baobin Li. 2012. A ranked-based learning approach to automated essay scoring. In Cloud and Green Computing (CGC), 2012 Second International Conference on, pages 448– 455. IEEE. Jacob Cohen et al. 1960. A coefficient of agreement for nominal scales. Educational and psychological measurement, 20(1):37–46. Richard Courant. 2005. Dirichlet’s principle, conformal  Ø.  mapping, and minimal surfaces. Courier Dover Publications. S. Dikli. 2006. An overview of automated scoring of essays. The Journal of Technology, Learning and Assessment, 5(1). S.T. Dumais. 2005. Latent semantic analysis. Annual Review of Information Science and Technology, 38(1): 188–230. Peter W Foltz, Darrell Laham, and Thomas K Landauer. 1999. Automated essay scoring: Applications to educational technology. In World Conference on Educational Multimedia, Hypermedia and Telecommunications, volume 1999, pages 939–944. Jerome H. Friedman. 2000. Greedy function approximation: A gradient boosting machine. Annals of Statistics, 29: 1189–1232. T. Joachims. 2006. Training linear svms in linear time. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 217–226. ACM. Dan Klein and Christopher D Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 423–430. Association for Computational Linguistics.  L.S. Larkey.  1998.  Automatic  1751 essay grading using  text categorization techniques. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pages 90–95. ACM. Heeyoung Lee, Angel Chang, Yves Peirsman, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2013. Deterministic coreference resolution based on entitycentric, precision-ranked rules. Computational Linguistics, 39(4). P. Li, C. Burges, and Q. Wu. 2007. Learning to rank using classification and gradient boosting. In Proceedings of the International Conference on Advances in Neural Information Processing Systems (NIPS). T.Y. Liu. 2009. Learning to rank for information retrieval. Foundations and Trends in Information Retrieval, 3(3):225–331. Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. Wordnet::similarity: measuring the relatedness of concepts. In Demonstration Papers at HLTNAACL 2004, pages 38–41, Boston, Massachusetts, 2-7 May. Association for Computational Linguistics, Stroudsburg, PA, USA. Donald E Powers, Jill C Burstein, Martin Chodorow, Mary E Fowles, Karen Kukich, and Graduate Record Examinations Board. 2000. Comparing the validity of automated and human essay scoring. RESEARCH REPORT-EDUCATIONAL TESTING SER-  VICE PRINCETON RR, (10). Tao Qin, Xu-Dong Zhang, Ming-Feng Tsai, De-Sheng Wang, Tie-Yan Liu, and Hang Li. 2008. Query-level loss functions for information retrieval. Inf. Process. Manage., 44(2):838–855, mar. G. Salton. 1971. The SMART Retrieval SystemExperiments in Automatic Document Processing. Prentice-Hall, Inc., Upper Saddle River, NJ, USA. Henry Scheffe. 1999. The analysis of variance, volume 72. Wiley. com. M.D. Shermis and J.C. Burstein. 2002. Automated essay scoring: A cross-disciplinary perspective. Lawrence Erlbaum. Kristina Toutanova, Dan Klein, Christopher D Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pages 173–180. Association for Computational Linguistics. Vladimir Vapnik, Steven E. Golowich, and Alex Smola. 1996. Support vector method for function approximation, regression estimation, and signal processing. In Advances in Neural Information Processing Systems 9, pages 281–287. MIT Press. D.M. Williamson. ing automated  2009. scoring.  A framework for implementIn Annual Meeting  of the  American Educational Research Association and the National Council on Measurement in Education, San Diego, CA. Q. Wu, C.J.C. Burges, K.M. Svore, and J. Gao. 2008. Ranking, boosting, and model adaptation. Technical report. H. Yannakoudakis, T. Briscoe, and B. Medlock. 2011. A new dataset and method for automatically grading esol texts. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, volume 1, pages 180– 189. Yisong Yue and C Burges. 2007. On using simultaneous perturbation stochastic approximation for learning to rank, and the empirical optimality of lambdarank. Technical report, Technical Report MSR-TR2007-1 15, Microsoft Research. 1752</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
