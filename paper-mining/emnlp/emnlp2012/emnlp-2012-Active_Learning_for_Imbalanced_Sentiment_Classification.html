<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-15" href="#">emnlp2012-15</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</h1>
<br/><p>Source: <a title="emnlp-2012-15-pdf" href="http://aclweb.org/anthology//D/D12/D12-1013.pdf">pdf</a></p><p>Author: Shoushan Li ; Shengfeng Ju ; Guodong Zhou ; Xiaojun Li</p><p>Abstract: Active learning is a promising way for sentiment classification to reduce the annotation cost. In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. This scenario posits new challenges to active learning. To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce humanannotation efforts. Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. 1</p><p>Reference: <a title="emnlp-2012-15-reference" href="../emnlp2012_reference/emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn Abstract Active learning is a promising way for sentiment classification to reduce the annotation cost. [sent-6, score-0.433]
</p><p>2 In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. [sent-7, score-1.323]
</p><p>3 To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. [sent-9, score-1.038]
</p><p>4 Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. [sent-11, score-1.135]
</p><p>5 1  Introduction  Sentiment classification is the task of identifying the sentiment polarity (e. [sent-12, score-0.378]
</p><p>6 Most of previous studies in sentiment classification focus on learning models from a large number of labeled data. [sent-22, score-0.439]
</p><p>7 In these situations, active learning approaches could be helpful by actively selecting most informative samples for manual annotation. [sent-24, score-1.054]
</p><p>8 Compared to traditional active learning for sentiment classification, active learning for imbalanced sentiment classification faces some unique challenges. [sent-25, score-1.861]
</p><p>9 Traditionally, uncertainty  has been popularly used as a basic measurement in active learning (Lewis and Gale, 2004). [sent-29, score-0.632]
</p><p>10 Therefore, how to select most informative MI samples for manual annotation without violating the basic PLraoncge uadgineg Lse oafr tnhineg 2,0 p1a2g Jeosin 13t C9–o1n4f8e,re Jnecjue Iosnla Enmd,p Kiroicraela, M 1e2t–h1o4ds Ju ilny N 20a1tu2r. [sent-30, score-0.741]
</p><p>11 lc L2a0n1g2ua Agseso Pcrioactieosnsi fnogr a Cnodm Cpoumtaptiuotna tilo Lnianlg Nuaist uircasl uncertainty requirement in active learning is challenging in imbalanced sentiment classification. [sent-32, score-1.265]
</p><p>12 In this paper, we address above challenges in active learning for imbalanced sentiment classification. [sent-33, score-1.114]
</p><p>13 We call our novel active learning approach co-selecting due to its collectively selecting informative samples through two disjoint feature subspace classifiers. [sent-37, score-1.364]
</p><p>14 To further reduce the annotation efforts, we only manually  annotate those most informative MI samples while those most informative MA samples are automatically labeled using the predicted labels provided by the first classifier. [sent-38, score-1.271]
</p><p>15 In principle, our active learning approach differs from existing ones in two main aspects. [sent-39, score-0.369]
</p><p>16 First, a certainty measurement and an uncertainty measurement are employed in two complementary subspace classifiers respectively to collectively select most informative MI samples for manual annotation. [sent-40, score-1.652]
</p><p>17 Second, most informative MA samples are automatically labeled to further reduce the annotation cost. [sent-41, score-0.668]
</p><p>18 Evaluation across four domains shows that our active learning approach is effective for imbalanced sentiment classification and significantly outperforms the state-of-the-art active learning alternatives, such as uncertainty sampling (Lewis and Gale, 2004) and co-testing (Muslea et al. [sent-42, score-1.795]
</p><p>19 Section 2 overviews the related work on sentiment classification and active learning. [sent-45, score-0.747]
</p><p>20 Section 3 proposes our active learning approach for imbalanced sentiment classification. [sent-46, score-1.114]
</p><p>21 2  Related Work  In this section, we give a brief overview sentiment classification and active learning. [sent-49, score-0.747]
</p><p>22 However, imbalanced sentiment classification is relatively new and there are only a few studies in the literature. [sent-56, score-0.863]
</p><p>23 (201 1a) pioneer the research in imbalanced sentiment classification and propose a co-training algorithm to perform semi-supervised learning for imbalanced sentiment classification with the help of a great amount of unlabeled samples. [sent-58, score-1.745]
</p><p>24 However, their semi-supervised approach to imbalanced sentiment classification suffers from  the problem that their balanced selection strategy in co-training would generate many errors in late iterations due to the imbalanced nature of the unbalanced data. [sent-59, score-1.449]
</p><p>25 In comparison, our proposed active learning approach can effectively avoid this problem. [sent-60, score-0.369]
</p><p>26 By the way, it is worth to note that the experiments therein show the superiority of undersampling over other alternatives such as costsensitive and one-class classification for imbalanced sentiment classification. [sent-61, score-0.867]
</p><p>27 (201 1b) focus on supervised learning for imbalanced sentiment classification and propose a clustering-based approach to improve traditional under-sampling approaches. [sent-63, score-0.84]
</p><p>28 Unlike all the studies mentioned above, our study pioneers active learning on imbalanced sentiment classification. [sent-65, score-1.137]
</p><p>29 However, most previous studies focus on the scenario of balanced class distribution and only a few recent studies address the active learning issue on imbalanced classification problems including Yang and Ma (2010), Zhu and Hovy (2007), Ertekin et al. [sent-74, score-1.084]
</p><p>30 Unfortunately, they straightly adopt the uncertainty sampling as the active selection strategy to address active learning in imbalanced classification, which completely ignores the class imbalance problem in the selected samples. [sent-77, score-1.659]
</p><p>31 Attenberg and Provost (2010) highlights the importance of selecting samples by considering the proportion of the classes. [sent-78, score-0.53]
</p><p>32 Their simulation experiment on text categorization confirms that selecting class-balanced samples is more important than traditional active selection strategies like uncertainty. [sent-79, score-0.929]
</p><p>33 They first select a set of uncertainty samples and then randomly select balanced samples from the uncertainty-sample set. [sent-83, score-1.244]
</p><p>34 Different from their study, our approach possesses two merits: First, two feature subspace classifiers are trained to finely integrate the certainty and uncertainty measurements. [sent-85, score-0.715]
</p><p>35 Second, the MA samples are automatically annotated,  2 Ertekin et al. [sent-86, score-0.471]
</p><p>36 (2007b) select samples closest to the hyperplane provided by the SVM classifier (within the margin). [sent-88, score-0.582]
</p><p>37 3  Active Learning for Sentiment Classification  Imbalanced  Generally, active learning can be either streambased or pool-based (Sassano, 2002). [sent-91, score-0.369]
</p><p>38 The main difference between the two is that the former scans through the data sequentially and selects informative samples individually, whereas the latter evaluates and ranks the entire collection before selecting most informative samples at batch. [sent-92, score-1.186]
</p><p>39 As a large collection of samples can easily gathered once in sentiment classification, poolbased active learning is adopted in this study. [sent-93, score-1.1]
</p><p>40 Figure 1 illustrates a standard pool-based active learning approach, where the most important issue is the sampling strategy, which evaluates the informativeness of one sample. [sent-94, score-0.414]
</p><p>41 Use current classifier to label all unlabeled samples (3). [sent-97, score-0.562]
</p><p>42 Use the sampling strategy to select n most informative samples for manual annotation (4). [sent-98, score-0.824]
</p><p>43 Move newly-labeled samples from U to L  Figure 1: Pool-based active learning 3. [sent-99, score-0.817]
</p><p>44 Certainty As one of the most popular selection strategies in active learning, uncertainty sampling depends on an uncertainty measurement to select informative samples. [sent-101, score-1.045]
</p><p>45 In imbalanced sentiment classification, MI samples are much sparse yet precious for learning and thus are believed to be more valuable for manual annotation. [sent-103, score-1.292]
</p><p>46 The key in active learning for imbalanced sentiment classification is to guarantee both the quality and quantity of newly-added MI samples. [sent-104, score-1.237]
</p><p>47 To guarantee the selection of MI samples, a certainty measurement is necessary. [sent-105, score-0.402]
</p><p>48 In this study, the certainty measurement is defined as follows:  Cer( d )ym{poasx, neg}P( y | d ) Meanwhile, in order to balance the samples in the two classes, once an informative MI sample is manually annotated, an informative MA sample is automatically labeled. [sent-106, score-1.163]
</p><p>49 However, the two sampling strategies discussed above are apparently contradicted: while the uncertainty measurement is prone to selecting the samples whose posterior probabilities are nearest to 0. [sent-108, score-0.856]
</p><p>50 5, the certainty measurement is prone to  selecting the samples whose posterior probabilities are nearest to 1. [sent-109, score-0.847]
</p><p>51 Therefore, it is essential to find a solution to balance uncertainty sampling and certainty sampling in imbalanced sentiment classification, 3. [sent-110, score-1.24]
</p><p>52 2  Co-selecting Classifiers  with  Feature  Subspace  In sentiment classification, a document is represented as a feature vector generated from the feature set F  f1 ,. [sent-111, score-0.333]
</p><p>53 In this study, we call a classifier trained with a feature subspace a feature subspace classifier. [sent-118, score-0.645]
</p><p>54 Our basic idea of balancing both the uncertainty measurement and the certainty measurement is to train two subspace classifiers to adopt them respectively. [sent-119, score-0.935]
</p><p>55 In our implementation, we randomly select two disjoint feature subspaces, each of which is used to train a subspace classifier. [sent-120, score-0.413]
</p><p>56 On one side, one subspace classifier is employed to select some certain samples; on the other side, the other classifier is employed to select the most uncertain sample from those certain samples for manual  f1S,. [sent-121, score-1.142]
</p><p>57 In this way, the selected samples are certain in terms of one feature subspace for selecting more possible MI samples. [sent-125, score-0.871]
</p><p>58 Meanwhile, the selected sample remains uncertain in terms of the other feature subspace to introduce uncertain knowledge into current learning model. [sent-126, score-0.575]
</p><p>59 We name this approach as co-selecting because it collectively selects informative samples by two separate classifiers. [sent-127, score-0.627]
</p><p>60 In our algorithm, we strictly constrain the balance of the samples between the two classes, i. [sent-129, score-0.493]
</p><p>61 Therefore, once two samples are annotated with the same class label, they will not be added to the labeled data, as shown in step (7) in Figure 2. [sent-132, score-0.564]
</p><p>62 Input: Labeled data L with balanced samples over the two classes Unlabeled pool U Output: New Labeled data L Procedure: Loop for N iterations: (1). [sent-133, score-0.53]
</p><p>63 size r (with the proportion   r/ m ) from F Generate a feature subspace from FS and train a corresponding feature subspace classifier CCer with L Generate another feature subspace from the complement set of FS , i. [sent-140, score-0.966]
</p><p>64 3  Co-selecting with Selected MA Samples Automatically Labeled  Input: Labeled data L with balanced samples over the two classes Unlabeled pool U MA and MI Label (positive or negative) Output: New Labeled data L Procedure: Loop for N iterations: (1). [sent-149, score-0.53]
</p><p>65 Generate a feature subspace from FS and train a corresponding subspace classifier CCer with L (3). [sent-151, score-0.62]
</p><p>66 In our co-selecting approach, automatically labeling those selected MA samples is easy and 143 straightforward: the subspace classifier for monitoring the certainty measurement provides an ideal solution to annotate the samples that have been predicted as majority class. [sent-159, score-1.655]
</p><p>67 Figure 3 shows  the co-selecting algorithm with those selected MA samples automatically labeled. [sent-160, score-0.537]
</p><p>68 4  Experimentation  In this section, we will systematically evaluate our active learning approach for imbalanced sentiment classification and compare it with the state-of-theart active learning alternatives. [sent-166, score-1.578]
</p><p>69 For each domain, we randomly select an initial balanced labeled data with 50 negative samples and 50 positive samples. [sent-172, score-0.697]
</p><p>70 For the unlabeled data, we randomly select 2000 negative samples, and 14580/12160/7140/7560 positive samples from the four domains respectively, keeping the same imbalanced ratio as the whole data. [sent-173, score-1.151]
</p><p>71 For the test data in each domain, we randomly extract 800 negative samples and 800 positive samples. [sent-174, score-0.543]
</p><p>72 Classification algorithm The Maximum Entropy (ME) classifier implemented with the Mallet 3 tool is mainly adopted, except that in the margin-based active learning approach (Ertekin et al. [sent-175, score-0.418]
</p><p>73 One sample  is selected in each iteration;  Uncertainty: iteratively select samples using the uncertainty measurement according to the output of ME classifier. [sent-189, score-0.905]
</p><p>74 One sample is selected in each iteration;  Certainty: iteratively select class-balanced samples using the certainty measurement according to the output of ME classifier. [sent-190, score-0.963]
</p><p>75 One positive and negative sample (the positive and negative label is provided by the ME classifier) are selected in each iteration;  Co-testing: first get contention samples (i. [sent-191, score-0.738]
</p><p>76 Note that the samples selected by these approaches are imbalanced. [sent-201, score-0.514]
</p><p>77 To address the problem of classification on imbalanced data, we adopt the under-sampling strategy which has been shown effective for supervised imbalanced sentiment classification (Li et al. [sent-202, score-1.456]
</p><p>78 Our active learning approach includes two versions: the co-selecting algorithm as described in Section 3. [sent-204, score-0.369]
</p><p>79 2 and the co-selecting with selected MA samples automatically labeled as described in Section 3. [sent-205, score-0.575]
</p><p>80 7 67 7482 8630 60 90 120 150 240 480 70 Nubmer of the manually annotated samples RandomCo-testingCo-selecting-plus  Electronic  Number of the manually annoated samples  RandomCo-testingCo-selecting-plus  0 0 . [sent-213, score-0.995]
</p><p>81 This verifies the effectiveness of automatically labeling those selected MA samples in imbalanced sentiment classification. [sent-224, score-1.304]
</p><p>82 , certainty) performs worst, which reflects that only considering sample  balance  factor  in  imbalanced  145 sentiment  classification is not helpful. [sent-227, score-0.932]
</p><p>83 Figure 5 compares our approach to other active learning approaches by varying the number of the selected samples for manually annotation. [sent-228, score-0.928]
</p><p>84 For clarity, we only include random selection and cotesting in comparison and do not show the performances of the other active learning approaches due to their similar behavior to random selection. [sent-229, score-0.451]
</p><p>85 From this figure, we can see that cotesting is effective on Book and Electronic when less than 1500 samples are selected for manual annotation but it fails to outperform random selection in the other two domains. [sent-230, score-0.725]
</p><p>86 05) when less than 4800 samples are selected for manual annotation. [sent-232, score-0.588]
</p><p>87 Figure 6 shows the performance of co-selecting-plus with varying sizes of the feature subspaces for the first subspace classifier CCer . [sent-234, score-0.435]
</p><p>88 This result also shows that the size of the feature subspace for selecting certain samples should be much less than that for selecting uncertain samples, which indicates the more important role of the uncertainty measurement in active learning. [sent-236, score-1.578]
</p><p>89 This once again verifies the importance of the uncertainty strategy in active learning. [sent-246, score-0.58]
</p><p>90 Number of MI samples selected for manual annotation In Table 1, we investigate the number of the MI samples selected for manual annotation using different active learning approaches when a total of 600 unlabeled samples are selected for annotation. [sent-247, score-2.234]
</p><p>91 From this table, we can see that almost all the existing active learning approaches can only select a small amount of MI samples, taking similar imbalanced ratios as the whole unlabeled data. [sent-248, score-0.956]
</p><p>92 Although the certainty approach could select many MI samples for annotation, this approach performs worst due to its totally ignoring the uncertainty factor. [sent-249, score-0.868]
</p><p>93 When our approach is applied, especially co-selecting-plus, more MI samples are selected for manual annotation and finally included to learn the models. [sent-250, score-0.643]
</p><p>94 This greatly improves the effectiveness of our active learning approach. [sent-251, score-0.369]
</p><p>95 Table 1: The number of MI samples selected for manual annotation when 600 samples are annotated on the whole. [sent-252, score-1.113]
</p><p>96 Precision of automatically labeled MA samples In co-selecting-plus, all the added MA samples are automatically labeled by the first subspace classifier. [sent-253, score-1.291]
</p><p>97 5% of automatically labeled MA samples are correctly annotated in Book, DVD, Electronic, and Kitchen respectively. [sent-257, score-0.531]
</p><p>98 This suggests that the subspace classifiers are able to predict the MA samples with a high precision. [sent-258, score-0.778]
</p><p>99 5  Conclusion  In this paper, we propose a novel active learning approach, named co-selecting, to reduce the  annotation cost for imbalanced sentiment classification. [sent-260, score-1.169]
</p><p>100 It first trains two complementary 146  classifiers with two disjoint feature subspaces and then uses them to collectively select most informative MI samples for manual annotation, leaving most informative MA samples for automatic annotation. [sent-261, score-1.473]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('imbalanced', 0.462), ('samples', 0.448), ('active', 0.369), ('sentiment', 0.283), ('subspace', 0.273), ('certainty', 0.209), ('uncertainty', 0.151), ('ertekin', 0.129), ('measurement', 0.112), ('mi', 0.109), ('informative', 0.104), ('classification', 0.095), ('ma', 0.091), ('ccer', 0.086), ('uncertain', 0.082), ('manual', 0.074), ('subspaces', 0.067), ('selected', 0.066), ('unlabeled', 0.065), ('select', 0.06), ('fs', 0.06), ('selecting', 0.059), ('classifiers', 0.057), ('cuncer', 0.057), ('muslea', 0.057), ('balanced', 0.056), ('class', 0.056), ('dvd', 0.056), ('annotation', 0.055), ('selection', 0.053), ('collectively', 0.052), ('classifier', 0.049), ('sample', 0.047), ('balance', 0.045), ('sampling', 0.045), ('committee', 0.044), ('doyle', 0.043), ('kitchen', 0.041), ('negative', 0.039), ('li', 0.039), ('lewis', 0.039), ('labeled', 0.038), ('strategy', 0.038), ('book', 0.035), ('positive', 0.035), ('disjoint', 0.034), ('member', 0.032), ('electronic', 0.031), ('neg', 0.031), ('minority', 0.031), ('opinion', 0.03), ('gale', 0.029), ('imbalance', 0.029), ('annoated', 0.029), ('attenberg', 0.029), ('contention', 0.029), ('cotesting', 0.029), ('kubat', 0.029), ('sensitiveness', 0.029), ('shengfeng', 0.029), ('tnrate', 0.029), ('tprate', 0.029), ('zhejiang', 0.029), ('guarantee', 0.028), ('meanwhile', 0.028), ('alternatives', 0.027), ('annotate', 0.027), ('pool', 0.026), ('pang', 0.026), ('feature', 0.025), ('hyperplane', 0.025), ('lloret', 0.025), ('nubmer', 0.025), ('precious', 0.025), ('shoushan', 0.025), ('manually', 0.024), ('proportion', 0.023), ('automatically', 0.023), ('selects', 0.023), ('proceeding', 0.023), ('studies', 0.023), ('annotated', 0.022), ('apparently', 0.022), ('cui', 0.022), ('verifies', 0.022), ('randomly', 0.021), ('loop', 0.021), ('iteratively', 0.021), ('varying', 0.021), ('adopt', 0.021), ('domains', 0.021), ('turney', 0.021), ('freund', 0.021), ('zhou', 0.02), ('blitzer', 0.019), ('wan', 0.019), ('prone', 0.019), ('thumbs', 0.019), ('bottou', 0.019), ('settles', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="15-tfidf-1" href="./emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>Author: Shoushan Li ; Shengfeng Ju ; Guodong Zhou ; Xiaojun Li</p><p>Abstract: Active learning is a promising way for sentiment classification to reduce the annotation cost. In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. This scenario posits new challenges to active learning. To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce humanannotation efforts. Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. 1</p><p>2 0.15045419 <a title="15-tfidf-2" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>Author: Natalia Ponomareva ; Mike Thelwall</p><p>Abstract: This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm. We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.</p><p>3 0.10544816 <a title="15-tfidf-3" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>Author: Jong-Hoon Oh ; Kentaro Torisawa ; Chikara Hashimoto ; Takuya Kawada ; Stijn De Saeger ; Jun'ichi Kazama ; Yiou Wang</p><p>Abstract: In this paper we explore the utility of sentiment analysis and semantic word classes for improving why-question answering on a large-scale web corpus. Our work is motivated by the observation that a why-question and its answer often follow the pattern that if something undesirable happens, the reason is also often something undesirable, and if something desirable happens, the reason is also often something desirable. To the best of our knowledge, this is the first work that introduces sentiment analysis to non-factoid question answering. We combine this simple idea with semantic word classes for ranking answers to why-questions and show that on a set of 850 why-questions our method gains 15.2% improvement in precision at the top-1 answer over a baseline state-of-the-art QA system that achieved the best performance in a shared task of Japanese non-factoid QA in NTCIR-6.</p><p>4 0.090056829 <a title="15-tfidf-4" href="./emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">76 emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>Author: Lev Ratinov ; Dan Roth</p><p>Abstract: We explore the interplay of knowledge and structure in co-reference resolution. To inject knowledge, we use a state-of-the-art system which cross-links (or “grounds”) expressions in free text to Wikipedia. We explore ways of using the resulting grounding to boost the performance of a state-of-the-art co-reference resolution system. To maximize the utility of the injected knowledge, we deploy a learningbased multi-sieve approach and develop novel entity-based features. Our end system outperforms the state-of-the-art baseline by 2 B3 F1 points on non-transcript portion of the ACE 2004 dataset.</p><p>5 0.081130743 <a title="15-tfidf-5" href="./emnlp-2012-Monte_Carlo_MCMC%3A_Efficient_Inference_by_Approximate_Sampling.html">91 emnlp-2012-Monte Carlo MCMC: Efficient Inference by Approximate Sampling</a></p>
<p>Author: Sameer Singh ; Michael Wick ; Andrew McCallum</p><p>Abstract: Conditional random fields and other graphical models have achieved state of the art results in a variety of tasks such as coreference, relation extraction, data integration, and parsing. Increasingly, practitioners are using models with more complex structure—higher treewidth, larger fan-out, more features, and more data—rendering even approximate inference methods such as MCMC inefficient. In this paper we propose an alternative MCMC sam- pling scheme in which transition probabilities are approximated by sampling from the set of relevant factors. We demonstrate that our method converges more quickly than a traditional MCMC sampler for both marginal and MAP inference. In an author coreference task with over 5 million mentions, we achieve a 13 times speedup over regular MCMC inference.</p><p>6 0.079240501 <a title="15-tfidf-6" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>7 0.071019016 <a title="15-tfidf-7" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>8 0.060140036 <a title="15-tfidf-8" href="./emnlp-2012-Exact_Sampling_and_Decoding_in_High-Order_Hidden_Markov_Models.html">43 emnlp-2012-Exact Sampling and Decoding in High-Order Hidden Markov Models</a></p>
<p>9 0.059041649 <a title="15-tfidf-9" href="./emnlp-2012-Collocation_Polarity_Disambiguation_Using_Web-based_Pseudo_Contexts.html">28 emnlp-2012-Collocation Polarity Disambiguation Using Web-based Pseudo Contexts</a></p>
<p>10 0.053747129 <a title="15-tfidf-10" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>11 0.049791146 <a title="15-tfidf-11" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>12 0.049474113 <a title="15-tfidf-12" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>13 0.048763402 <a title="15-tfidf-13" href="./emnlp-2012-Iterative_Annotation_Transformation_with_Predict-Self_Reestimation_for_Chinese_Word_Segmentation.html">68 emnlp-2012-Iterative Annotation Transformation with Predict-Self Reestimation for Chinese Word Segmentation</a></p>
<p>14 0.04782439 <a title="15-tfidf-14" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>15 0.045265581 <a title="15-tfidf-15" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>16 0.044248544 <a title="15-tfidf-16" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>17 0.04421844 <a title="15-tfidf-17" href="./emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">36 emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>18 0.043068092 <a title="15-tfidf-18" href="./emnlp-2012-Large_Scale_Decipherment_for_Out-of-Domain_Machine_Translation.html">75 emnlp-2012-Large Scale Decipherment for Out-of-Domain Machine Translation</a></p>
<p>19 0.041389722 <a title="15-tfidf-19" href="./emnlp-2012-Opinion_Target_Extraction_Using_Word-Based_Translation_Model.html">101 emnlp-2012-Opinion Target Extraction Using Word-Based Translation Model</a></p>
<p>20 0.0377701 <a title="15-tfidf-20" href="./emnlp-2012-Excitatory_or_Inhibitory%3A_A_New_Semantic_Orientation_Extracts_Contradiction_and_Causality_from_the_Web.html">44 emnlp-2012-Excitatory or Inhibitory: A New Semantic Orientation Extracts Contradiction and Causality from the Web</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.132), (1, 0.087), (2, 0.028), (3, 0.133), (4, 0.063), (5, -0.073), (6, -0.077), (7, -0.04), (8, 0.134), (9, -0.043), (10, 0.005), (11, 0.128), (12, -0.005), (13, -0.092), (14, 0.029), (15, 0.093), (16, -0.002), (17, 0.171), (18, -0.058), (19, 0.14), (20, -0.106), (21, -0.042), (22, 0.035), (23, 0.099), (24, 0.085), (25, -0.051), (26, 0.104), (27, -0.032), (28, -0.073), (29, -0.049), (30, -0.235), (31, 0.023), (32, -0.197), (33, 0.017), (34, 0.089), (35, -0.055), (36, -0.248), (37, -0.046), (38, -0.02), (39, 0.036), (40, -0.13), (41, -0.003), (42, -0.064), (43, 0.194), (44, 0.094), (45, -0.057), (46, 0.036), (47, -0.038), (48, 0.041), (49, -0.177)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98834223 <a title="15-lsi-1" href="./emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>Author: Shoushan Li ; Shengfeng Ju ; Guodong Zhou ; Xiaojun Li</p><p>Abstract: Active learning is a promising way for sentiment classification to reduce the annotation cost. In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. This scenario posits new challenges to active learning. To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce humanannotation efforts. Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. 1</p><p>2 0.59750056 <a title="15-lsi-2" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>Author: Natalia Ponomareva ; Mike Thelwall</p><p>Abstract: This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm. We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.</p><p>3 0.46184835 <a title="15-lsi-3" href="./emnlp-2012-Large_Scale_Decipherment_for_Out-of-Domain_Machine_Translation.html">75 emnlp-2012-Large Scale Decipherment for Out-of-Domain Machine Translation</a></p>
<p>Author: Qing Dou ; Kevin Knight</p><p>Abstract: We apply slice sampling to Bayesian decipherment and use our new decipherment framework to improve out-of-domain machine translation. Compared with the state of the art algorithm, our approach is highly scalable and produces better results, which allows us to decipher ciphertext with billions of tokens and hundreds of thousands of word types with high accuracy. We decipher a large amount ofmonolingual data to improve out-of-domain translation and achieve significant gains of up to 3.8 BLEU points.</p><p>4 0.34492317 <a title="15-lsi-4" href="./emnlp-2012-Exact_Sampling_and_Decoding_in_High-Order_Hidden_Markov_Models.html">43 emnlp-2012-Exact Sampling and Decoding in High-Order Hidden Markov Models</a></p>
<p>Author: Simon Carter ; Marc Dymetman ; Guillaume Bouchard</p><p>Abstract: We present a method for exact optimization and sampling from high order Hidden Markov Models (HMMs), which are generally handled by approximation techniques. Motivated by adaptive rejection sampling and heuristic search, we propose a strategy based on sequentially refining a lower-order language model that is an upper bound on the true model we wish to decode and sample from. This allows us to build tractable variable-order HMMs. The ARPA format for language models is extended to enable an efficient use of the max-backoff quantities required to compute the upper bound. We evaluate our approach on two problems: a SMS-retrieval task and a POS tagging experiment using 5-gram models. Results show that the same approach can be used for exact optimization and sampling, while explicitly constructing only a fraction of the total implicit state-space.</p><p>5 0.34445402 <a title="15-lsi-5" href="./emnlp-2012-Monte_Carlo_MCMC%3A_Efficient_Inference_by_Approximate_Sampling.html">91 emnlp-2012-Monte Carlo MCMC: Efficient Inference by Approximate Sampling</a></p>
<p>Author: Sameer Singh ; Michael Wick ; Andrew McCallum</p><p>Abstract: Conditional random fields and other graphical models have achieved state of the art results in a variety of tasks such as coreference, relation extraction, data integration, and parsing. Increasingly, practitioners are using models with more complex structure—higher treewidth, larger fan-out, more features, and more data—rendering even approximate inference methods such as MCMC inefficient. In this paper we propose an alternative MCMC sam- pling scheme in which transition probabilities are approximated by sampling from the set of relevant factors. We demonstrate that our method converges more quickly than a traditional MCMC sampler for both marginal and MAP inference. In an author coreference task with over 5 million mentions, we achieve a 13 times speedup over regular MCMC inference.</p><p>6 0.33379802 <a title="15-lsi-6" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>7 0.32413748 <a title="15-lsi-7" href="./emnlp-2012-Excitatory_or_Inhibitory%3A_A_New_Semantic_Orientation_Extracts_Contradiction_and_Causality_from_the_Web.html">44 emnlp-2012-Excitatory or Inhibitory: A New Semantic Orientation Extracts Contradiction and Causality from the Web</a></p>
<p>8 0.2743319 <a title="15-lsi-8" href="./emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">76 emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>9 0.27270767 <a title="15-lsi-9" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>10 0.2504839 <a title="15-lsi-10" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>11 0.23822217 <a title="15-lsi-11" href="./emnlp-2012-Lexical_Differences_in_Autobiographical_Narratives_from_Schizophrenic_Patients_and_Healthy_Controls.html">83 emnlp-2012-Lexical Differences in Autobiographical Narratives from Schizophrenic Patients and Healthy Controls</a></p>
<p>12 0.22007295 <a title="15-lsi-12" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>13 0.20729908 <a title="15-lsi-13" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>14 0.20332572 <a title="15-lsi-14" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>15 0.20184094 <a title="15-lsi-15" href="./emnlp-2012-Streaming_Analysis_of_Discourse_Participants.html">120 emnlp-2012-Streaming Analysis of Discourse Participants</a></p>
<p>16 0.17841536 <a title="15-lsi-16" href="./emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">36 emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>17 0.17202514 <a title="15-lsi-17" href="./emnlp-2012-Translation_Model_Based_Cross-Lingual_Language_Model_Adaptation%3A_from_Word_Models_to_Phrase_Models.html">128 emnlp-2012-Translation Model Based Cross-Lingual Language Model Adaptation: from Word Models to Phrase Models</a></p>
<p>18 0.16700011 <a title="15-lsi-18" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>19 0.16235229 <a title="15-lsi-19" href="./emnlp-2012-Iterative_Annotation_Transformation_with_Predict-Self_Reestimation_for_Chinese_Word_Segmentation.html">68 emnlp-2012-Iterative Annotation Transformation with Predict-Self Reestimation for Chinese Word Segmentation</a></p>
<p>20 0.15632257 <a title="15-lsi-20" href="./emnlp-2012-User_Demographics_and_Language_in_an_Implicit_Social_Network.html">134 emnlp-2012-User Demographics and Language in an Implicit Social Network</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.012), (16, 0.025), (18, 0.361), (34, 0.066), (60, 0.103), (63, 0.059), (64, 0.038), (65, 0.028), (70, 0.018), (73, 0.011), (74, 0.036), (76, 0.07), (80, 0.015), (86, 0.02), (95, 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75943494 <a title="15-lda-1" href="./emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>Author: Shoushan Li ; Shengfeng Ju ; Guodong Zhou ; Xiaojun Li</p><p>Abstract: Active learning is a promising way for sentiment classification to reduce the annotation cost. In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. This scenario posits new challenges to active learning. To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce humanannotation efforts. Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. 1</p><p>2 0.62930053 <a title="15-lda-2" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>Author: Mihai Surdeanu ; Julie Tibshirani ; Ramesh Nallapati ; Christopher D. Manning</p><p>Abstract: Distant supervision for relation extraction (RE) gathering training data by aligning a database of facts with text – is an efficient approach to scale RE to thousands of different relations. However, this introduces a challenging learning scenario where the relation expressed by a pair of entities found in a sentence is unknown. For example, a sentence containing Balzac and France may express BornIn or Died, an unknown relation, or no relation at all. Because of this, traditional supervised learning, which assumes that each example is explicitly mapped to a label, is not appropriate. We propose a novel approach to multi-instance multi-label learning for RE, which jointly models all the instances of a pair of entities in text and all their labels using a graphical model with latent variables. Our model performs competitively on two difficult domains. –</p><p>3 0.41638991 <a title="15-lda-3" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>Author: David McClosky ; Christopher D. Manning</p><p>Abstract: We present a distantly supervised system for extracting the temporal bounds of fluents (relations which only hold during certain times, such as attends school). Unlike previous pipelined approaches, our model does not assume independence between each fluent or even between named entities with known connections (parent, spouse, employer, etc.). Instead, we model what makes timelines of fluents consistent by learning cross-fluent constraints, potentially spanning entities as well. For example, our model learns that someone is unlikely to start a job at age two or to marry someone who hasn’t been born yet. Our system achieves a 36% error reduction over a pipelined baseline.</p><p>4 0.40411445 <a title="15-lda-4" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>Author: Lizhen Qu ; Rainer Gemulla ; Gerhard Weikum</p><p>Abstract: We propose the weakly supervised MultiExperts Model (MEM) for analyzing the semantic orientation of opinions expressed in natural language reviews. In contrast to most prior work, MEM predicts both opinion polarity and opinion strength at the level of individual sentences; such fine-grained analysis helps to understand better why users like or dislike the entity under review. A key challenge in this setting is that it is hard to obtain sentence-level training data for both polarity and strength. For this reason, MEM is weakly supervised: It starts with potentially noisy indicators obtained from coarse-grained training data (i.e., document-level ratings), a small set of diverse base predictors, and, if available, small amounts of fine-grained training data. We integrate these noisy indicators into a unified probabilistic framework using ideas from ensemble learning and graph-based semi-supervised learning. Our experiments indicate that MEM outperforms state-of-the-art methods by a significant margin.</p><p>5 0.40366328 <a title="15-lda-5" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>6 0.40043193 <a title="15-lda-6" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>7 0.39698768 <a title="15-lda-7" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>8 0.39687625 <a title="15-lda-8" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>9 0.39637536 <a title="15-lda-9" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>10 0.39300594 <a title="15-lda-10" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>11 0.39289352 <a title="15-lda-11" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>12 0.39224666 <a title="15-lda-12" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>13 0.39165768 <a title="15-lda-13" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>14 0.3904137 <a title="15-lda-14" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>15 0.39001825 <a title="15-lda-15" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>16 0.3885791 <a title="15-lda-16" href="./emnlp-2012-Fast_Large-Scale_Approximate_Graph_Construction_for_NLP.html">52 emnlp-2012-Fast Large-Scale Approximate Graph Construction for NLP</a></p>
<p>17 0.38849697 <a title="15-lda-17" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>18 0.38783368 <a title="15-lda-18" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>19 0.38738394 <a title="15-lda-19" href="./emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">47 emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>20 0.38693121 <a title="15-lda-20" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
