<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>102 emnlp-2012-Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-102" href="#">emnlp2012-102</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>102 emnlp-2012-Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems</h1>
<br/><p>Source: <a title="emnlp-2012-102-pdf" href="http://aclweb.org/anthology//D/D12/D12-1008.pdf">pdf</a></p><p>Author: Nina Dethlefs ; Helen Hastie ; Verena Rieser ; Oliver Lemon</p><p>Abstract: Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are | v not sensitive to ID by more than 23%.</p><p>Reference: <a title="emnlp-2012-102-reference" href="../emnlp2012_reference/emnlp-2012-Optimising_Incremental_Dialogue_Decisions_Using_Information_Density_for_Interactive_Systems_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 hast ie  Abstract Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. [sent-4, score-0.419]
</p><p>2 Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. [sent-5, score-0.354]
</p><p>3 1 Introduction Recent work on incremental systems has shown that adapting a system’s turn-taking behaviour to be more human-like can improve the user’s experience significantly, based on incremental models of automatic speech recognition (ASR) (Baumann et al. [sent-8, score-0.499]
</p><p>4 (2009) use maximum entropy classification to support responsive overlap in an incremental system by predicting the completions of user utterances. [sent-20, score-0.633]
</p><p>5 Recent years have seen a number of data-driven approaches to interactive systems that automatically adapt their decisions to the dialogue context using Reinforcement Learning (Levin et al. [sent-24, score-0.345]
</p><p>6 In particular, we address the problem of optimising IP strategies while allowing the system to generate and comprehend backchannels and bargeins based on a partially data-driven reward function. [sent-35, score-0.572]
</p><p>7 Our results in terms of average rewards and a human rating study show that a learning agent that is sensitive to ID can learn when it is most beneficial to generate feedback to a user, and outperforms several other agents that are not sensitive to ID. [sent-44, score-0.479]
</p><p>8 This previous work incrementally constructs IP strategies according to the predicted user reaction, whereas our approach focuses on whether and when to generate backchannels and barge-ins and how to react to user bargeins in the context of dynamically changing input hypotheses. [sent-48, score-1.135]
</p><p>9 We assume here that the choice of attributes is determined by matching the types specified in the user in83 put, so that our system only needs to choose a strategy for presenting its results. [sent-52, score-0.438]
</p><p>10 In this paper, we focus on the phenomena of backchannels and barge-ins that can act as feedback in an interaction for both user and system. [sent-60, score-0.656]
</p><p>11 Coming from the user, the system may infer that the user is following the presentation of information or is confirming a piece of information without trying to take the turn. [sent-63, score-0.506]
</p><p>12 Similarly, we can allow a system to generate backchannels to the user to confirm that it understands the user’s preferences, i. [sent-64, score-0.731]
</p><p>13 An important decision for a dialogue system is then when to generate a backchannel? [sent-67, score-0.365]
</p><p>14 The user may barge-in on the system to correct an ASR error (such as ‘Italian’ instead of ‘Indian’ in Figure 1) or the system may want to barge-in on the user to confirm a low-confidence ASR hypothesis so as to be able to start an immediate database look up for results. [sent-69, score-0.854]
</p><p>15 In the former case, the user barging-in on the system, we assume that the system has two choices: yielding the turn to the user, or trying to keep the turn. [sent-70, score-0.479]
</p><p>16 In the latter case, the system bargingin on the user, the system would have to decide ifand when it would be beneficial to barge-in on a user utterance. [sent-71, score-0.451]
</p><p>17 In the following sections, we will develop  a model of dialogue  optimisation  that can address  these question based on Hierarchical mises system behaviour based on  RL that opti-  trade-offs defined  in terms of ID. [sent-72, score-0.453]
</p><p>18 Recommendation Summary  Table 1: Examples of IP as a comparison, recommendation and summary for a user looking for Italian restaurants in  the city centre that have a good price for value. [sent-80, score-0.644]
</p><p>19 Backchannel 2 (the user backchannels)  USR I want Italian food in the centre of town  . [sent-90, score-0.502]
</p><p>20 Barge-ins 1(the user barges-in on system) USR I want Italian food in the centre of town . [sent-102, score-0.502]
</p><p>21 The agent has learnt to produce backchannels and barge-ins at the appropriate moment and alternative strategies to deal with user barge-ins. [sent-127, score-1.073]
</p><p>22 We will now transfer the notion of ID to IP and investigate the distribution of information over user restaurant queries. [sent-153, score-0.456]
</p><p>23 2 Information Density in User Utterances We aim to use ID for incremental IP in two ways: (1) to estimate the best moment for generating  backchannels or barge-ins to the user, and (2) to decide whether to yield or keep the current system turn in case of a user barge-in. [sent-155, score-1.004]
</p><p>24 To compute the ID of user and system utterances at each time step, we estimated an n−gram language hm toimdeel (using Kneser-Ney smoothing) mba lasendon a transcribed corpus of human subjects interacting with a system for restaurant recommendations of Rieser et al. [sent-161, score-0.697]
</p><p>25 1 The corpus contained user utterances as exemplified in Figure 1and allowed us to compute the ID at any point during a user utterance. [sent-163, score-0.897]
</p><p>26 Due to a lack of human data for the system utterances, we use the same corpus data to compute the ID of system The learning agent can use  utterances. [sent-168, score-0.332]
</p><p>27 this information to consider the trade-off of yielding a current turn to the user or trying to keep it, e. [sent-180, score-0.438]
</p><p>28 , in case of a user barge-in given the ID of its own turn and of the user’s incoming turn. [sent-182, score-0.444]
</p><p>29 Such decisions will be made incrementally in our domain given dynamically changing hypotheses of user input. [sent-183, score-0.407]
</p><p>30 The dialogue states can be seen as representing the system’s knowledge about the task, the user and the environment. [sent-185, score-0.656]
</p><p>31 The dialogue actions correspond to the system’s capabilities, such as present the results or barge-in on the user. [sent-186, score-0.363]
</p><p>32 In addition, we need a transition function that specifies the way that actions change the environment (as expressed in the state representation) and a reward function  which specifies a numeric value for each action taken. [sent-188, score-0.417]
</p><p>33 Since timing is crucial for incremental approaches, where processing needs to be fast, we choose a hierarchical setting for better scalability. [sent-196, score-0.299]
</p><p>34 We denote the hierarchy of RL agents as Mji where the indexes i and j only identify an agent in a unique way, they do not specify the execution sequence of subtasks, which is subject to optimisation. [sent-197, score-0.318]
</p><p>35 Rji (s′, τ|s, a) is a reward function that specifies the rewar,dτ t|hs,ata an agent a rerdce fiuvnesc ifoonr taking an action a in state s lasting τ time steps (Dietterich, 1999). [sent-200, score-0.517]
</p><p>36 The organisation of the learning process into discrete time steps allows us to define incremental hypothesis updates as state updates and transitions in an SMDP. [sent-202, score-0.341]
</p><p>37 Whenever conditions in the learning environment change, such as the recogniser’s best hypothesis of the user input, we represent them as transitions from one state to another. [sent-203, score-0.46]
</p><p>38 At each time step, the agent checks for changes in its state representation and takes the currently best action according to the new state. [sent-204, score-0.366]
</p><p>39 The best action in an incremental framework can also include generating a backchannel to the user to indicate the status of grounding or barging-in to confirm an uncertain piece of information. [sent-205, score-0.779]
</p><p>40 because the user is speaking), the system can 86 decide to do nothing. [sent-213, score-0.41]
</p><p>41 The goal of each SMDP is to find an optimal policy π∗ that maximises the reward for each visited state, according to π∗ij(s)  = argmaxQ∗ji(s,a),  (2)  where Qji (s, a) specifies the expected cumulative reward for executing action a in state s and then following π∗. [sent-214, score-0.441]
</p><p>42 1 Hierarchy of Learning Agents The HRL agent in Figure 3 shows how the tasks of (1) dealing with incrementally changing input hypotheses, (2) choosing a suitable IP strategy and (3) presenting information, are connected. [sent-218, score-0.316]
</p><p>43 It chooses when to listen to an incoming user utterance (M31) and when and how to present information (M01. [sent-226, score-0.526]
</p><p>44 The  ‘userSilence’ variable indicates whether the user is speaking or not. [sent-232, score-0.369]
</p><p>45 We distinguish actions for Information Presentation (IP), actions for attribute presentation and ordering (Slot-ordering), and incremental actions (Incremental). [sent-234, score-0.592]
</p><p>46 Whenever a user barges in over the system, these agents will decide to either yield the turn to the user or to try and keep the turn based on information density. [sent-243, score-0.884]
</p><p>47 The variables representing the status of the cuisine,  SPCurmeis naertyPCFroemsdpnatrisoRSPoertvsReicn tomendLPaorcetsion tOUPbser isrcevnt  Figure 3: Hierarchy of learning agent for incremental Information Presentation and Slot Ordering. [sent-244, score-0.473]
</p><p>48 food, location, price and service of restaurants indicate whether the slot is of interest to the user (we assume that 0 means that the user does not care about this slot), and what input confidence score is currently associated with the value of the slot. [sent-245, score-1.078]
</p><p>49 For example, if our current best hypothesis is that the user is interested in Indian restaurants, the variable ’statusCuisine’ will have a value between 1-3 indicating the strength of this hypothesis. [sent-246, score-0.369]
</p><p>50 Model M31 is called whenever the user is speaking. [sent-248, score-0.369]
</p><p>51 The system’s main choice here is to remain silent and listen to the user or barge-in to request the desired cuisine, location, or price range of a restaurant. [sent-249, score-0.437]
</p><p>52 This agent is also responsible for generating backchannels and will over time learn the best moments to do this. [sent-256, score-0.537]
</p><p>53 4 choose surface forms for presentation to the user from hand-crafted templates. [sent-260, score-0.465]
</p><p>54 The goal state is reached when all items (that the user specified in the search query) have been presented. [sent-293, score-0.419]
</p><p>55 2 The Simulated Environment For a policy to converge, a learning agent typically needs several thousand interactions in which it is exposed to a multitude of different circumstances. [sent-301, score-0.306]
</p><p>56 1 Information Presentation To learn a good IP strategy, we use a user simulation5 by Rieser et al. [sent-306, score-0.369]
</p><p>57 (2010) which was estimated from human data and uses bi-grams of the form P(au,t |IPs,t), where au,t is the predicted user reaction at t|IimPe t to the system’s IP strategy IPs,t in state s at time t. [sent-307, score-0.511]
</p><p>58 We distinguish the user reactions of select a restaurant, addMoreInfo to the current query to constrain the search, and other. [sent-308, score-0.369]
</p><p>59 The last category is usually considered an undesirable user reaction that the system should learn to avoid. [sent-309, score-0.474]
</p><p>60 In this way, we can predict the most likely user reaction to each system action. [sent-311, score-0.474]
</p><p>61 Even though previous work has shown that n-gram-based simulations can lead to dialogue inconsistencies, we assume that for the present study this does not present a problem, since we focus on generating single utterances and on obtaining user judgements for single, independent utterances. [sent-312, score-0.815]
</p><p>62 2  Input Hypothesis Updates  While the IP strategies can be used for incremental and non-incremental dialogue, the second part of the simulation deals explicitly with the dynamic environment updates that the system will need to be sensitive to in an incremental setting. [sent-315, score-0.65]
</p><p>63 We assume that for each restaurant recommendation, the user has the option of filling any or all of the attributes cuisine, food quality, location, price range and service quality. [sent-316, score-0.664]
</p><p>64 A score of 0 means that the user does not care about the attribute, 1 means that the system’s confidence in the attribute’s value is low, 2 that the confidence is medium, and 3 means that the confidence is high. [sent-321, score-0.609]
</p><p>65 For food and service quality, we assume that the user is never in-  ×  terested in bad food or service. [sent-326, score-0.607]
</p><p>66 If they change, we assume that half of the time, the user is the origin of the change (because they changed their mind) and half of the time the system is the origin of the change (because of an ASR or interpretation error). [sent-339, score-0.41]
</p><p>67 We use these PCFGs to simulate user utterances to which the system has to react. [sent-360, score-0.569]
</p><p>68 In addition to simulating user utterances, we hand-crafted context-free grammars of system utterances and augmented them with probabilities estimated using the same user corpus data as above (where again, we make the assumption that this is to some extent feasible given the shared domain). [sent-366, score-0.938]
</p><p>69 Both measures, the ID of user and system utterances, can inform the system during learning to balance the trade-off between them for generating and receiving backchannels and barge-ins. [sent-368, score-0.738]
</p><p>70 For incremental IP, we use rewards that are based on human intuition. [sent-371, score-0.349]
</p><p>71 odtreomecshtiso lnmd,ientghiangtuernls,e The agent is encouraged to choose those sequences of actions that lead to the user selecting a restaurant as quickly as possible. [sent-374, score-0.532]
</p><p>72 The agent receives the following rewards, where infoDensity(Usr) and infoDensity(Sys) refer to the ID of the current user and system utterance, respectively, as defined in Equation 1. [sent-377, score-0.693]
</p><p>73 These two measures encourage the agent to consider the trade-offs between its own ID and the one transmitted by an incoming user utterance. [sent-379, score-0.692]
</p><p>74 Barging-in on a user utterance at a low ID point then yields a small negative reward, whereas barging-in on a user utterance at a high ID point yields a high negative reward. [sent-380, score-0.98]
</p><p>75 Both rewards are negative because bargingin on the user always contains some risk. [sent-381, score-0.495]
</p><p>76 Similarly, keeping a turn over a non-dense user utterance receives a smaller negative reward than keeping it over a dense user utterance. [sent-382, score-1.049]
</p><p>77 The exact best moment for barge-ins and backchannels to occur will be subject to optimisation. [sent-384, score-0.332]
</p><p>78 6 Experimental Results The agent learns to barge-in or generate backchannels to users at points where the ID is low but rising. [sent-385, score-0.579]
</p><p>79 In particular, the agent learns to barge-in right before information density peaks in an incoming user utterance to clarify or request slots that are still open from the previous information density peak. [sent-386, score-1.101]
</p><p>80 If a user has specified their desired cuisine type but the system has received a low ASR confidence score for it, it may barge-in to clarify the slot. [sent-387, score-0.651]
</p><p>81 This case was illustrated in the last example in Figure 1, where the system clarified the previous (cuisine) slot (which is associated with a high ID)just before the user specifies the location slot (which again would have a high ID). [sent-388, score-0.541]
</p><p>82 The system learns to generate backchannels after information peaks to confirm newly acquired slots that have a high confidence. [sent-390, score-0.447]
</p><p>83 In addition, the system learns to yield its current turn to a user that is barging-in if its own ID is low, falling or rising, or if the ID of the incoming user utterance is high. [sent-392, score-1.005]
</p><p>84 Baseline 1was designed to always generate barge-ins after an information peak in a user utterance, i. [sent-396, score-0.369]
</p><p>85 Baseline 1yields a turn to a user barge-in if its own ID is low and tries to keep it otherwise. [sent-400, score-0.408]
</p><p>86 Baseline 2 generates barge-ins and backchannels randomly and at any point during a user utterance. [sent-401, score-0.656]
</p><p>87 The decision of yielding or keeping a turn in case of a user barge-in is also random. [sent-402, score-0.475]
</p><p>88 All re6Incidentally, this also helps to prevent the system yielding its turn to a user backchannel; cf. [sent-406, score-0.479]
</p><p>89 While the learnt policy and Baseline 1 appear to achieve similar performance, an absolute comparison of the last 1000 episodes of each behaviour shows that the improvement of the HRL agent over Baseline 1 corresponds to 23. [sent-414, score-0.446]
</p><p>90 Since Baseline 1 barges-in on users after an information peak, when ID may still be high, it continuously receives a negative reward reflecting the user preference for late barge-ins. [sent-420, score-0.596]
</p><p>91 As a result of this continuous negative reward, the agent will then learn to avoid barge-ins altogether, which may in turn lead to less efficient interactions because low confidence ASR scores are clarified only late in the interaction. [sent-421, score-0.403]
</p><p>92 47  43%∗∗ 26% 31%  Table 3: Comparison of policies in terms of average rewards and user ratings. [sent-427, score-0.522]
</p><p>93 2 Human Rating Study To confirm our simulation-based results, we conducted a user rating study on the CrowdFlower crowd sourcing Participants were shown user utterances along with three options of barging-in over them. [sent-430, score-0.966]
</p><p>94 These results provide evidence that an optimisation of the timing of generating barge-ins and backchannels in incremental dialogue can be sensitive to fine-grained cues in evolving ID and therefore achieve a high level of adaptivity. [sent-447, score-0.908]
</p><p>95 com 91 Regarding user ratings however, Baseline 2 was preferred over Baseline 1. [sent-456, score-0.369]
</p><p>96 We can therefore further conclude that ID can be a feasible optimisation criterion for incremental decision making. [sent-460, score-0.332]
</p><p>97 7  Conclusion and Future Work  We have presented a novel approach to incremental dialogue decision making based on Hierarchical RL combined with the notion of information density. [sent-461, score-0.547]
</p><p>98 We presented a learning agent in the domain of  IP for restaurant recommendations that was able to generate backchannels and barge-ins for higher responsiveness in interaction. [sent-462, score-0.624]
</p><p>99 Given that ID is a measure influencing human language production, we could replace our template-based surface realiser by an agent that optimises the information density of its output. [sent-465, score-0.352]
</p><p>100 Evaluation of a hierarchical reinforcement learning spoken dialogue system. [sent-497, score-0.468]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('user', 0.369), ('backchannels', 0.287), ('dialogue', 0.287), ('agent', 0.25), ('incremental', 0.223), ('id', 0.196), ('realised', 0.175), ('utterances', 0.159), ('rieser', 0.137), ('ip', 0.126), ('rewards', 0.126), ('cuisine', 0.125), ('utterance', 0.121), ('reward', 0.118), ('rl', 0.112), ('italian', 0.103), ('density', 0.102), ('restaurants', 0.101), ('cuay', 0.1), ('usr', 0.1), ('food', 0.098), ('sys', 0.097), ('presentation', 0.096), ('backchannel', 0.087), ('hrl', 0.087), ('learnt', 0.087), ('restaurant', 0.087), ('jaeger', 0.086), ('reinforcement', 0.08), ('confidence', 0.08), ('oliver', 0.078), ('indian', 0.078), ('actions', 0.076), ('dethlefs', 0.075), ('verona', 0.075), ('optimisation', 0.072), ('price', 0.068), ('agents', 0.068), ('lemon', 0.068), ('action', 0.066), ('medium', 0.065), ('reaction', 0.064), ('spoken', 0.064), ('huitl', 0.062), ('interactive', 0.058), ('policy', 0.056), ('asr', 0.055), ('optimising', 0.054), ('simulation', 0.053), ('behaviour', 0.053), ('state', 0.05), ('heriberto', 0.05), ('verena', 0.05), ('slot', 0.049), ('slots', 0.045), ('attribute', 0.045), ('moment', 0.045), ('users', 0.042), ('recommendation', 0.042), ('service', 0.042), ('system', 0.041), ('environment', 0.041), ('peaks', 0.04), ('turn', 0.039), ('rising', 0.039), ('optimise', 0.039), ('timing', 0.039), ('sigdial', 0.039), ('changing', 0.038), ('bargeins', 0.037), ('baumann', 0.037), ('buss', 0.037), ('skantze', 0.037), ('smdp', 0.037), ('transmitted', 0.037), ('hierarchical', 0.037), ('decision', 0.037), ('incoming', 0.036), ('clarify', 0.036), ('strategies', 0.035), ('rating', 0.035), ('centre', 0.035), ('confirm', 0.034), ('levy', 0.034), ('nina', 0.034), ('late', 0.034), ('updates', 0.034), ('discourse', 0.033), ('specifies', 0.033), ('receives', 0.033), ('falling', 0.03), ('op', 0.03), ('yielding', 0.03), ('city', 0.029), ('strategy', 0.028), ('roma', 0.027), ('psycholinguistic', 0.027), ('policies', 0.027), ('generation', 0.027), ('baseline', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="102-tfidf-1" href="./emnlp-2012-Optimising_Incremental_Dialogue_Decisions_Using_Information_Density_for_Interactive_Systems.html">102 emnlp-2012-Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems</a></p>
<p>Author: Nina Dethlefs ; Helen Hastie ; Verena Rieser ; Oliver Lemon</p><p>Abstract: Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are | v not sensitive to ID by more than 23%.</p><p>2 0.26362938 <a title="102-tfidf-2" href="./emnlp-2012-Generative_Goal-Driven_User_Simulation_for_Dialog_Management.html">60 emnlp-2012-Generative Goal-Driven User Simulation for Dialog Management</a></p>
<p>Author: Aciel Eshky ; Ben Allison ; Mark Steedman</p><p>Abstract: User simulation is frequently used to train statistical dialog managers for task-oriented domains. At present, goal-driven simulators (those that have a persistent notion of what they wish to achieve in the dialog) require some task-specific engineering, making them impossible to evaluate intrinsically. Instead, they have been evaluated extrinsically by means of the dialog managers they are intended to train, leading to circularity of argument. In this paper, we propose the first fully generative goal-driven simulator that is fully induced from data, without hand-crafting or goal annotation. Our goals are latent, and take the form of topics in a topic model, clustering together semantically equivalent and phonetically confusable strings, implicitly modelling synonymy and speech recognition noise. We evaluate on two standard dialog resources, the Communicator and Let’s Go datasets, and demonstrate that our model has substantially better fit to held out data than competing approaches. We also show that features derived from our model allow significantly greater improvement over a baseline at distinguishing real from randomly permuted dialogs.</p><p>3 0.14578716 <a title="102-tfidf-3" href="./emnlp-2012-Framework_of_Automatic_Text_Summarization_Using_Reinforcement_Learning.html">56 emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</a></p>
<p>Author: Seonggi Ryang ; Takeshi Abekawa</p><p>Abstract: We present a new approach to the problem of automatic text summarization called Automatic Summarization using Reinforcement Learning (ASRL) in this paper, which models the process of constructing a summary within the framework of reinforcement learning and attempts to optimize the given score function with the given feature representation of a summary. We demonstrate that the method of reinforcement learning can be adapted to automatic summarization problems naturally and simply, and other summarizing techniques, such as sentence compression, can be easily adapted as actions of the framework. The experimental results indicated ASRL was superior to the best performing method in DUC2004 and comparable to the state of the art ILP-style method, in terms of ROUGE scores. The results also revealed ASRL can search for sub-optimal solutions efficiently under conditions for effectively selecting features and the score function.</p><p>4 0.11926298 <a title="102-tfidf-4" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>Author: Jordan Boyd-Graber ; Brianna Satinoff ; He He ; Hal Daume III</p><p>Abstract: Cost-sensitive classification, where thefeatures used in machine learning tasks have a cost, has been explored as a means of balancing knowledge against the expense of incrementally obtaining new features. We introduce a setting where humans engage in classification with incrementally revealed features: the collegiate trivia circuit. By providing the community with a web-based system to practice, we collected tens of thousands of implicit word-by-word ratings of how useful features are for eliciting correct answers. Observing humans’ classification process, we improve the performance of a state-of-the art classifier. We also use the dataset to evaluate a system to compete in the incremental classification task through a reduction of reinforcement learning to classification. Our system learns when to answer a question, performing better than baselines and most human players.</p><p>5 0.1008168 <a title="102-tfidf-5" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>Author: Victor Chahuneau ; Kevin Gimpel ; Bryan R. Routledge ; Lily Scherlis ; Noah A. Smith</p><p>Abstract: We investigate the use of language in food writing, specifically on restaurant menus and in customer reviews. Our approach is to build predictive models of concrete external variables, such as restaurant menu prices. We make use of a dataset of menus and customer reviews for thousands of restaurants in several U.S. cities. By focusing on prediction tasks and doing our analysis at scale, our methodology allows quantitative, objective measurements of the words and phrases used to de- scribe food in restaurants. We also explore interactions in language use between menu prices and sentiment as expressed in user reviews.</p><p>6 0.097669654 <a title="102-tfidf-6" href="./emnlp-2012-User_Demographics_and_Language_in_an_Implicit_Social_Network.html">134 emnlp-2012-User Demographics and Language in an Implicit Social Network</a></p>
<p>7 0.082610503 <a title="102-tfidf-7" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>8 0.072477348 <a title="102-tfidf-8" href="./emnlp-2012-Revisiting_the_Predictability_of_Language%3A_Response_Completion_in_Social_Media.html">114 emnlp-2012-Revisiting the Predictability of Language: Response Completion in Social Media</a></p>
<p>9 0.067545578 <a title="102-tfidf-9" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>10 0.059729893 <a title="102-tfidf-10" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>11 0.055541039 <a title="102-tfidf-11" href="./emnlp-2012-Syntactic_Surprisal_Affects_Spoken_Word_Duration_in_Conversational_Contexts.html">122 emnlp-2012-Syntactic Surprisal Affects Spoken Word Duration in Conversational Contexts</a></p>
<p>12 0.055526428 <a title="102-tfidf-12" href="./emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">86 emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<p>13 0.042834368 <a title="102-tfidf-13" href="./emnlp-2012-Streaming_Analysis_of_Discourse_Participants.html">120 emnlp-2012-Streaming Analysis of Discourse Participants</a></p>
<p>14 0.041042648 <a title="102-tfidf-14" href="./emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">12 emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<p>15 0.040484548 <a title="102-tfidf-15" href="./emnlp-2012-A_Discriminative_Model_for_Query_Spelling_Correction_with_Latent_Structural_SVM.html">5 emnlp-2012-A Discriminative Model for Query Spelling Correction with Latent Structural SVM</a></p>
<p>16 0.039286826 <a title="102-tfidf-16" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>17 0.039260224 <a title="102-tfidf-17" href="./emnlp-2012-Supervised_Text-based_Geolocation_Using_Language_Models_on_an_Adaptive_Grid.html">121 emnlp-2012-Supervised Text-based Geolocation Using Language Models on an Adaptive Grid</a></p>
<p>18 0.039076246 <a title="102-tfidf-18" href="./emnlp-2012-A_Beam-Search_Decoder_for_Grammatical_Error_Correction.html">2 emnlp-2012-A Beam-Search Decoder for Grammatical Error Correction</a></p>
<p>19 0.038659066 <a title="102-tfidf-19" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>20 0.038195986 <a title="102-tfidf-20" href="./emnlp-2012-A_Unified_Approach_to_Transliteration-based_Text_Input_with_Online_Spelling_Correction.html">13 emnlp-2012-A Unified Approach to Transliteration-based Text Input with Online Spelling Correction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.15), (1, 0.008), (2, 0.009), (3, 0.099), (4, -0.105), (5, -0.051), (6, 0.023), (7, -0.092), (8, 0.066), (9, 0.107), (10, 0.2), (11, -0.071), (12, -0.456), (13, -0.13), (14, 0.12), (15, -0.057), (16, 0.044), (17, 0.044), (18, -0.028), (19, -0.108), (20, 0.005), (21, -0.1), (22, -0.339), (23, -0.013), (24, -0.109), (25, -0.16), (26, -0.097), (27, -0.069), (28, 0.007), (29, -0.104), (30, -0.008), (31, -0.148), (32, -0.066), (33, -0.043), (34, 0.061), (35, -0.022), (36, 0.054), (37, 0.031), (38, -0.029), (39, -0.129), (40, 0.04), (41, -0.046), (42, 0.01), (43, -0.008), (44, -0.06), (45, 0.016), (46, -0.033), (47, -0.003), (48, -0.054), (49, 0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98344302 <a title="102-lsi-1" href="./emnlp-2012-Optimising_Incremental_Dialogue_Decisions_Using_Information_Density_for_Interactive_Systems.html">102 emnlp-2012-Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems</a></p>
<p>Author: Nina Dethlefs ; Helen Hastie ; Verena Rieser ; Oliver Lemon</p><p>Abstract: Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are | v not sensitive to ID by more than 23%.</p><p>2 0.83431542 <a title="102-lsi-2" href="./emnlp-2012-Generative_Goal-Driven_User_Simulation_for_Dialog_Management.html">60 emnlp-2012-Generative Goal-Driven User Simulation for Dialog Management</a></p>
<p>Author: Aciel Eshky ; Ben Allison ; Mark Steedman</p><p>Abstract: User simulation is frequently used to train statistical dialog managers for task-oriented domains. At present, goal-driven simulators (those that have a persistent notion of what they wish to achieve in the dialog) require some task-specific engineering, making them impossible to evaluate intrinsically. Instead, they have been evaluated extrinsically by means of the dialog managers they are intended to train, leading to circularity of argument. In this paper, we propose the first fully generative goal-driven simulator that is fully induced from data, without hand-crafting or goal annotation. Our goals are latent, and take the form of topics in a topic model, clustering together semantically equivalent and phonetically confusable strings, implicitly modelling synonymy and speech recognition noise. We evaluate on two standard dialog resources, the Communicator and Let’s Go datasets, and demonstrate that our model has substantially better fit to held out data than competing approaches. We also show that features derived from our model allow significantly greater improvement over a baseline at distinguishing real from randomly permuted dialogs.</p><p>3 0.37974823 <a title="102-lsi-3" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>Author: Victor Chahuneau ; Kevin Gimpel ; Bryan R. Routledge ; Lily Scherlis ; Noah A. Smith</p><p>Abstract: We investigate the use of language in food writing, specifically on restaurant menus and in customer reviews. Our approach is to build predictive models of concrete external variables, such as restaurant menu prices. We make use of a dataset of menus and customer reviews for thousands of restaurants in several U.S. cities. By focusing on prediction tasks and doing our analysis at scale, our methodology allows quantitative, objective measurements of the words and phrases used to de- scribe food in restaurants. We also explore interactions in language use between menu prices and sentiment as expressed in user reviews.</p><p>4 0.37370488 <a title="102-lsi-4" href="./emnlp-2012-Framework_of_Automatic_Text_Summarization_Using_Reinforcement_Learning.html">56 emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</a></p>
<p>Author: Seonggi Ryang ; Takeshi Abekawa</p><p>Abstract: We present a new approach to the problem of automatic text summarization called Automatic Summarization using Reinforcement Learning (ASRL) in this paper, which models the process of constructing a summary within the framework of reinforcement learning and attempts to optimize the given score function with the given feature representation of a summary. We demonstrate that the method of reinforcement learning can be adapted to automatic summarization problems naturally and simply, and other summarizing techniques, such as sentence compression, can be easily adapted as actions of the framework. The experimental results indicated ASRL was superior to the best performing method in DUC2004 and comparable to the state of the art ILP-style method, in terms of ROUGE scores. The results also revealed ASRL can search for sub-optimal solutions efficiently under conditions for effectively selecting features and the score function.</p><p>5 0.36972353 <a title="102-lsi-5" href="./emnlp-2012-User_Demographics_and_Language_in_an_Implicit_Social_Network.html">134 emnlp-2012-User Demographics and Language in an Implicit Social Network</a></p>
<p>Author: Katja Filippova</p><p>Abstract: We consider the task of predicting the gender of the YouTube1 users and contrast two information sources: the comments they leave and the social environment induced from the affiliation graph of users and videos. We propagate gender information through the videos and show that a user’s gender can be predicted from her social environment with the accuracy above 90%. We also show that the gender can be predicted from language alone (89%). A surprising result of our study is that the latter predictions correlate more strongly with the gender predominant in the user’s environment than with the sex of the person as reported in the profile. We also investigate how the two views (linguistic and social) can be combined and analyse how prediction accuracy changes over different age groups.</p><p>6 0.31593415 <a title="102-lsi-6" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>7 0.2753405 <a title="102-lsi-7" href="./emnlp-2012-Revisiting_the_Predictability_of_Language%3A_Response_Completion_in_Social_Media.html">114 emnlp-2012-Revisiting the Predictability of Language: Response Completion in Social Media</a></p>
<p>8 0.22373387 <a title="102-lsi-8" href="./emnlp-2012-Supervised_Text-based_Geolocation_Using_Language_Models_on_an_Adaptive_Grid.html">121 emnlp-2012-Supervised Text-based Geolocation Using Language Models on an Adaptive Grid</a></p>
<p>9 0.20813529 <a title="102-lsi-9" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>10 0.19795536 <a title="102-lsi-10" href="./emnlp-2012-Syntactic_Surprisal_Affects_Spoken_Word_Duration_in_Conversational_Contexts.html">122 emnlp-2012-Syntactic Surprisal Affects Spoken Word Duration in Conversational Contexts</a></p>
<p>11 0.19680132 <a title="102-lsi-11" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>12 0.17173138 <a title="102-lsi-12" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>13 0.16688436 <a title="102-lsi-13" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>14 0.16065219 <a title="102-lsi-14" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>15 0.15757273 <a title="102-lsi-15" href="./emnlp-2012-Language_Model_Rest_Costs_and_Space-Efficient_Storage.html">74 emnlp-2012-Language Model Rest Costs and Space-Efficient Storage</a></p>
<p>16 0.15007769 <a title="102-lsi-16" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>17 0.14108044 <a title="102-lsi-17" href="./emnlp-2012-Streaming_Analysis_of_Discourse_Participants.html">120 emnlp-2012-Streaming Analysis of Discourse Participants</a></p>
<p>18 0.13622648 <a title="102-lsi-18" href="./emnlp-2012-A_Beam-Search_Decoder_for_Grammatical_Error_Correction.html">2 emnlp-2012-A Beam-Search Decoder for Grammatical Error Correction</a></p>
<p>19 0.13446581 <a title="102-lsi-19" href="./emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">86 emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<p>20 0.13239805 <a title="102-lsi-20" href="./emnlp-2012-Learning_Lexicon_Models_from_Search_Logs_for_Query_Expansion.html">78 emnlp-2012-Learning Lexicon Models from Search Logs for Query Expansion</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.07), (16, 0.056), (25, 0.013), (34, 0.051), (60, 0.048), (63, 0.036), (64, 0.012), (65, 0.013), (74, 0.038), (76, 0.034), (79, 0.01), (80, 0.011), (86, 0.474), (95, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89909965 <a title="102-lda-1" href="./emnlp-2012-Optimising_Incremental_Dialogue_Decisions_Using_Information_Density_for_Interactive_Systems.html">102 emnlp-2012-Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems</a></p>
<p>Author: Nina Dethlefs ; Helen Hastie ; Verena Rieser ; Oliver Lemon</p><p>Abstract: Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are | v not sensitive to ID by more than 23%.</p><p>2 0.79150897 <a title="102-lda-2" href="./emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">36 emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>Author: Jian Bo Yang ; Qi Mao ; Qiao Liang Xiang ; Ivor Wai-Hung Tsang ; Kian Ming Adam Chai ; Hai Leong Chieu</p><p>Abstract: We propose an adaptive ensemble method to adapt coreference resolution across domains. This method has three features: (1) it can optimize for any user-specified objective measure; (2) it can make document-specific prediction rather than rely on a fixed base model or a fixed set of base models; (3) it can automatically adjust the active ensemble members during prediction. With simplification, this method can be used in the traditional withindomain case, while still retaining the above features. To the best of our knowledge, this work is the first to both (i) develop a domain adaptation algorithm for the coreference resolution problem and (ii) have the above features as an ensemble method. Empirically, we show the benefits of (i) on the six domains of the ACE 2005 data set in domain adaptation set- ting, and of (ii) on both the MUC-6 and the ACE 2005 data sets in within-domain setting.</p><p>3 0.73117059 <a title="102-lda-3" href="./emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</a></p>
<p>Author: Mehmet Ali Yatbaz ; Enis Sert ; Deniz Yuret</p><p>Abstract: We investigate paradigmatic representations of word context in the domain of unsupervised syntactic category acquisition. Paradigmatic representations of word context are based on potential substitutes of a word in contrast to syntagmatic representations based on properties of neighboring words. We compare a bigram based baseline model with several paradigmatic models and demonstrate significant gains in accuracy. Our best model based on Euclidean co-occurrence embedding combines the paradigmatic context representation with morphological and orthographic features and achieves 80% many-to-one accuracy on a 45-tag 1M word corpus.</p><p>4 0.59270275 <a title="102-lda-4" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>Author: Yang Feng ; Yang Liu ; Qun Liu ; Trevor Cohn</p><p>Abstract: Decoding algorithms for syntax based machine translation suffer from high computational complexity, a consequence of intersecting a language model with a context free grammar. Left-to-right decoding, which generates the target string in order, can improve decoding efficiency by simplifying the language model evaluation. This paper presents a novel left to right decoding algorithm for tree-to-string translation, using a bottom-up parsing strategy and dynamic future cost estimation for each partial translation. Our method outperforms previously published tree-to-string decoders, including a competing left-to-right method.</p><p>5 0.44887209 <a title="102-lda-5" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>6 0.37452039 <a title="102-lda-6" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>7 0.36182976 <a title="102-lda-7" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>8 0.34974465 <a title="102-lda-8" href="./emnlp-2012-Fast_Large-Scale_Approximate_Graph_Construction_for_NLP.html">52 emnlp-2012-Fast Large-Scale Approximate Graph Construction for NLP</a></p>
<p>9 0.33951351 <a title="102-lda-9" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>10 0.33900848 <a title="102-lda-10" href="./emnlp-2012-Syntactic_Surprisal_Affects_Spoken_Word_Duration_in_Conversational_Contexts.html">122 emnlp-2012-Syntactic Surprisal Affects Spoken Word Duration in Conversational Contexts</a></p>
<p>11 0.33588591 <a title="102-lda-11" href="./emnlp-2012-Generative_Goal-Driven_User_Simulation_for_Dialog_Management.html">60 emnlp-2012-Generative Goal-Driven User Simulation for Dialog Management</a></p>
<p>12 0.33316106 <a title="102-lda-12" href="./emnlp-2012-Constructing_Task-Specific_Taxonomies_for_Document_Collection_Browsing.html">30 emnlp-2012-Constructing Task-Specific Taxonomies for Document Collection Browsing</a></p>
<p>13 0.32931098 <a title="102-lda-13" href="./emnlp-2012-Exploiting_Reducibility_in_Unsupervised_Dependency_Parsing.html">46 emnlp-2012-Exploiting Reducibility in Unsupervised Dependency Parsing</a></p>
<p>14 0.32761422 <a title="102-lda-14" href="./emnlp-2012-Revisiting_the_Predictability_of_Language%3A_Response_Completion_in_Social_Media.html">114 emnlp-2012-Revisiting the Predictability of Language: Response Completion in Social Media</a></p>
<p>15 0.32659411 <a title="102-lda-15" href="./emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">12 emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<p>16 0.32464075 <a title="102-lda-16" href="./emnlp-2012-Building_a_Lightweight_Semantic_Model_for_Unsupervised_Information_Extraction_on_Short_Listings.html">26 emnlp-2012-Building a Lightweight Semantic Model for Unsupervised Information Extraction on Short Listings</a></p>
<p>17 0.31422198 <a title="102-lda-17" href="./emnlp-2012-Streaming_Analysis_of_Discourse_Participants.html">120 emnlp-2012-Streaming Analysis of Discourse Participants</a></p>
<p>18 0.31316778 <a title="102-lda-18" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>19 0.31090975 <a title="102-lda-19" href="./emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">51 emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>20 0.31074515 <a title="102-lda-20" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
