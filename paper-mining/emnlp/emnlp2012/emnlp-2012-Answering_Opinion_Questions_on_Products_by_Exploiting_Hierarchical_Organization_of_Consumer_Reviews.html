<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-20" href="#">emnlp2012-20</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</h1>
<br/><p>Source: <a title="emnlp-2012-20-pdf" href="http://aclweb.org/anthology//D/D12/D12-1036.pdf">pdf</a></p><p>Author: Jianxing Yu ; Zheng-Jun Zha ; Tat-Seng Chua</p><p>Abstract: This paper proposes to generate appropriate answers for opinion questions about products by exploiting the hierarchical organization of consumer reviews. The hierarchy organizes product aspects as nodes following their parent-child relations. For each aspect, the reviews and corresponding opinions on this aspect are stored. We develop a new framework for opinion Questions Answering, which enables accurate question analysis and effective answer generation by making use the hierarchy. In particular, we first identify the (explicit/implicit) product aspects asked in the questions and their sub-aspects by referring to the hierarchy. We then retrieve the corresponding review fragments relevant to the aspects from the hierarchy. In order to gener- ate appropriate answers from the review fragments, we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects. We conduct evaluations on 11 popular products in four domains. The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products. Experimental results demonstrate the effectiveness of our approach.</p><p>Reference: <a title="emnlp-2012-20-reference" href="../emnlp2012_reference/emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The hierarchy organizes product aspects as nodes following their parent-child relations. [sent-2, score-0.634]
</p><p>2 For each aspect, the reviews and corresponding opinions on this aspect are stored. [sent-3, score-0.657]
</p><p>3 We develop a new framework for opinion Questions Answering, which enables accurate question analysis and effective answer generation by making use the hierarchy. [sent-4, score-0.821]
</p><p>4 In particular, we first identify the (explicit/implicit) product aspects asked in the questions and their sub-aspects by referring to the hierarchy. [sent-5, score-0.704]
</p><p>5 In order to gener-  ate appropriate answers from the review fragments, we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects. [sent-7, score-0.841]
</p><p>6 The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products. [sent-9, score-0.74]
</p><p>7 s g  Figure 1: Overview of product opinion-QA framework tery” of product Nokia N95. [sent-14, score-0.38]
</p><p>8 Numerous consumer reviews are now available online, and these reviews contain rich opinionated information on various aspects of products. [sent-16, score-1.055]
</p><p>9 They are naturally a valuable resource for answering opinion questions about products, such as “How do people think about the battery of Nokia N95? [sent-17, score-0.611]
</p><p>10 ” Opinion Question Answering (opinion-QA) on products seeks to uncover consumers’ thinking and feeling  about the products or aspects of products. [sent-18, score-0.373]
</p><p>11 It is different from traditional factual QA, where the questions ask for the fact, such as “Where is the capital With the rapid development of E-commerce, most retail websites encourage consumers to post reviews to express their opinions on the products. [sent-19, score-0.711]
</p><p>12 ” reveals positive opinion on the aspect “bat-  of United States? [sent-21, score-0.514]
</p><p>13 ” For a product opinionated question, the answer should not be just a best answer. [sent-24, score-0.583]
</p><p>14 Hence the answer should be a summarization of public opinions and comments on the product or specific aspect asked in the question (Jiang et al. [sent-28, score-1.358]
</p><p>15 Such answers would help users to understand the inherent reasons of the opinions on the asked aspect. [sent-31, score-0.487]
</p><p>16 ” asks for public positive and negative opinions on the aspect “camera” of product “Nokia 5800. [sent-33, score-0.719]
</p><p>17 ” The summarization of opinions on the sub-aspects such as “lens” and “resolution” would help users better understand that the public complaints on the aspect “camera” are due to the poor “lens” and/or low “resolution. [sent-34, score-0.547]
</p><p>18 Current Opinion-QA methods mainly include three components, including question analysis that identifies aspects and opinions asked in the questions, answer fragment retrieval, and answer generation which summarizes the retrieved fragments (Lloret et al. [sent-40, score-1.632]
</p><p>19 Second,  current methods cannot discover sub-aspects of the asked aspect due to its ignorance of parent-child relations among aspects. [sent-51, score-0.394]
</p><p>20 To overcome these problems, we can resort to 392 the hierarchical organization of consumer reviews on products. [sent-53, score-0.735]
</p><p>21 As illustrated in Figure 2, the hierarchy organizes product aspects as nodes, following their parent-child relations. [sent-54, score-0.634]
</p><p>22 For each aspect, the reviews and corresponding opinions on this aspect are stored. [sent-55, score-0.657]
</p><p>23 Such hierarchy can naturally facilitate to identify aspects asked in questions. [sent-56, score-0.511]
</p><p>24 While explicit aspects can be recognized by referring to the hierarchy, implicit aspects can be inferred based on the associations between sentiment terms and aspects in the hierarchy (Yu et al. [sent-57, score-0.956]
</p><p>25 Moreover, by following the parent-child relations in the hierarchy, sub-aspects of the asked aspect can be directly acquired, and the answers can  present aspects from general to specific. [sent-60, score-0.718]
</p><p>26 Motivated by the above observations, we propose to exploit the hierarchical organization of consumer reviews for product opinion-QA. [sent-61, score-0.925]
</p><p>27 As illustrated in Figure 1, our framework first organizes consumer reviews of a certain product into a hierarchical organization. [sent-62, score-0.875]
</p><p>28 The resulting hierarchy is in turn used to help question analysis and relevant review fragments retrieval. [sent-63, score-0.568]
</p><p>29 In order to generate appropriate answers from the retrieved fragments, we develop a multi-criteria optimization approach by simultaneously taking into account review salience, coherence, and diversity. [sent-64, score-0.503]
</p><p>30 The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products. [sent-67, score-0.74]
</p><p>31 The main contributions of this paper include, •  We propose to exploit the hierarchical organi-  •  •  zWaetio pnr oopfocsoen tsoum exepr rloeivtite hwes hfoierr answering opinion questions on products. [sent-70, score-0.628]
</p><p>32 Section 2 introduces the components of hierarchical organization of reviews, question analysis, and answer fragment retrieval. [sent-74, score-0.741]
</p><p>33 Section 3 elaborates the multicriteria optimization approach for answer generation  . [sent-75, score-0.443]
</p><p>34 Ellaecchti o rnev oiefw c reflects consumer opinions on the product and/or product aspects. [sent-79, score-0.846]
</p><p>35 Let q denote an opinion question, which asks for public opinions on a product or some aspects of the product. [sent-80, score-0.958]
</p><p>36 The task is to retrieve the opinionated review fragments relevant to the asked product/product aspects, and summarize these fragments to form an appropriate answer to question q. [sent-81, score-1.021]
</p><p>37 Next, we introduce the components of hierarchical organization that organizes consumer reviews into a hierarchy, question analysis which identifies the products/aspects and opinions asked in the questions, and answer fragment retrieval that retrieves review fragments relevant to the questions. [sent-82, score-1.907]
</p><p>38 (201 1) to organize consumer reviews of a product into a hierarchical organization. [sent-85, score-0.81]
</p><p>39 As shown in Figure 2, the hierarchy organizes product aspects as nodes, following their parent-child relations. [sent-86, score-0.634]
</p><p>40 In particular, this method first automatically acquires an initial aspect hierarchy from the domain knowledge and identifies aspects commented in the reviews. [sent-87, score-0.684]
</p><p>41 It then incrementally inserts the identified aspects into appropriate positions in the initial hierarchy, and finally obtains an aspect hierarchy that allocates all the newly identified aspects. [sent-88, score-0.639]
</p><p>42 The consumer reviews are then organized to their corresponding aspect nodes in the hierarchy. [sent-89, score-0.767]
</p><p>43 Sentiment classification is then performed to determine consumer opinions on the reviews. [sent-90, score-0.466]
</p><p>44 (201 1) on aspect identification, aspect hierarchy generation and sentiment classification are 0. [sent-92, score-0.813]
</p><p>45 The hierarchy has organized product aspects, which can be used to filter the noise noun phrases for accurately identifying the explicit aspects. [sent-116, score-0.452]
</p><p>46 Such associations can be learned from the hierarchy and leveraged to infer the implicit aspects (Yu et al. [sent-121, score-0.481]
</p><p>47 , 2011) it into the appropriate aspect node of a particular product hierarchy. [sent-126, score-0.486]
</p><p>48 Classifying the opinions: Given a set of testing questions, we first distinguish the opinion questions from the factual ones (Yu et al. [sent-134, score-0.539]
</p><p>49 Since the opinion questions often contain one or more sentiment terms, we classify them by employing the sentiment terms in the sentiment lexicon provided from MPQA project (Wilson et al. [sent-136, score-0.826]
</p><p>50 Subsequently, we learn a SVM sentiment classifier to determine the opinion polarity of the opinion questions. [sent-138, score-0.722]
</p><p>51 In particular, the reviews and corresponding opinions stored in the hierarchy are used as training samples, which are represented by the unigram features. [sent-139, score-0.665]
</p><p>52 Identifying the question type: Opinion questions are often categorized into four types (Ku et al. [sent-140, score-0.381]
</p><p>53 ,  394 2007), •  •  •  •  Attitude question, asking for public opinion on a product or product aspect, s puucbhl as “pWinhioant odon people think iPhone 3gs? [sent-141, score-0.824]
</p><p>54 ” Reason question, asking for the reason of publRice opinion on a product or product aspect, spuucbhas “Why do people like iPhone 3gs? [sent-142, score-0.746]
</p><p>55 These questions are used for training, with POS tags and question words (i. [sent-149, score-0.381]
</p><p>56 After analyzing the question, we retrieve all review sentences on the asked aspect and all its subaspects from a certain product hierarchy, and choose the ones relevant to the opinion asked in the question. [sent-163, score-1.11]
</p><p>57 For the single form question, we view the retrieved sentences as the answer fragments. [sent-164, score-0.468]
</p><p>58 For the comparative questions, we select comparative sentences on the compared products from the retrieved sentences, and treat them as the answer fragments. [sent-165, score-0.648]
</p><p>59 In particular, for the questions asking for reason and attitude, we generate the answers by summarizing corresponding answer fragments. [sent-167, score-0.739]
</p><p>60 For questions seeking for a target as the answer, we output the product names based on the majority voting of the opinions in the retrieved answer fragments. [sent-168, score-0.991]
</p><p>61 html consistency between the asked opinions and the major opinions in the answer fragments, and then summarize these fragments to form the answers. [sent-172, score-0.891]
</p><p>62 3  Answer Generation  Answer generation aims to generate an appropriate answer for a given opinion question based on the retrieved answer fragments, i. [sent-173, score-1.275]
</p><p>63 Hence, the task of answer generation is to select sentences from the retrieved answer fragments and order them appropriately. [sent-177, score-0.917]
</p><p>64 We incorporate multiple criteria in the answer generation process, including answer salience, coherence, and diversity. [sent-179, score-0.713]
</p><p>65 The parent-child relations between aspects is also incorporated to ensure the answer follow the general-to-specific logic. [sent-180, score-0.49]
</p><p>66 A good answer should consist of salient review sentences. [sent-185, score-0.444]
</p><p>67 To make the answer readable, the constituent sentences in the answer should be ordered properly. [sent-198, score-0.664]
</p><p>68 The coherence score of the answer is computed by summ∑ing u∑p the scores of all its adjacent sentences as,  ∑j∈S ∑i∈S hi,jci,jei,j. [sent-210, score-0.465]
</p><p>69 Centroid Distance: As aforementioned, review sentences are stored in the corresponding aspect nodes in the hierarchy. [sent-273, score-0.408]
</p><p>70 The sentence that is close to the centroid of the reviews stored in an aspect node is more likely to be salient (Erkan et al. [sent-274, score-0.662]
</p><p>71 It is an online learning algorithm, so that we can update the weight when more consumer reviews are available. [sent-289, score-0.539]
</p><p>72 Since the consumer reviews often include multiple sentences, we can directly use the adjacency of these sentences as training samples. [sent-293, score-0.614]
</p><p>73 4  Evaluations  In this section, we evaluate the effectiveness of the proposed approach, in terms of question analysis and answer generation. [sent-304, score-0.489]
</p><p>74 In addition, we created 220 questions for these products by referring to real questions in Yahoo! [sent-309, score-0.498]
</p><p>75 Each product contains 15 opinion questions and 5 factual questions, respectively. [sent-312, score-0.729]
</p><p>76 The labels include product name, product aspect, opinion, question type and question form. [sent-316, score-0.74]
</p><p>77 In addition, we sampled the top-N (N=20) sentences on each asked aspect and its sub-aspects respectively, where the sentences were ranked based on their salient weights in Section 3. [sent-324, score-0.491]
</p><p>78 We then provided such subset of review sentences to the three annotators, and let them individually create an answer of up to 100 words (i. [sent-326, score-0.451]
</p><p>79 2 Evaluations on Question Analysis We first evaluated the performance of product recognition, opinion/factual question classification, opinion classification, question type and question form  identification. [sent-340, score-1.016]
</p><p>80 The 70 implicit aspect questions in our question corpus were used here. [sent-368, score-0.672]
</p><p>81 It identifies implicit aspects by mutual clustering, and it was  398  Figure 3: Evaluations on multiple optimization criteria in terms of ROUGE-1, ROUGE-2, and ROUGE-SU4, respectively. [sent-371, score-0.381]
</p><p>82 The results show that the hierarchy can help to identify implicit aspects by exploiting the underlying associations among sentiment terms and aspects. [sent-376, score-0.594]
</p><p>83 By analyzing the results, we find that the improvements come from the use of the hierarchical organization and the answer generation algorithm which exploits multiple criteria, especially the parent-child relation among aspects. [sent-398, score-0.551]
</p><p>84 This indicates that the salience criterion is crucial for answer generation. [sent-419, score-0.449]
</p><p>85 The answer diversely comments the asked aspect and all its avail399 able sub-aspects following the general-to-specific logic. [sent-424, score-0.698]
</p><p>86 5  Related Works  In this section, we review existing works related to the four components of our approach, including organization of reviews, question analysis, answer fragment retrieval, and answer generation. [sent-426, score-1.065]
</p><p>87 (201 1) exploited the domain knowledge and consumer reviews to automatically generate a hierarchy for organizing consumer reviews. [sent-430, score-1.025]
</p><p>88 Question analysis often has to distinguish the opinion question from the factual one, and find the  key points asked in the questions, such as the product aspect and product name. [sent-431, score-1.258]
</p><p>89 (2003) proposed to separate opinions from facts at both document and sentence level, and determine the polarity on the opinionated sentences in the answer documents. [sent-433, score-0.69]
</p><p>90 In particular, they first identified the opinion questions, and classified them into six predefined question types, including holder, target, attitude, reason, majority, and yes/no. [sent-441, score-0.466]
</p><p>91 These question types and corresponding polarity on the questions were used to filter non-relevant sentences in the answer fragments. [sent-442, score-0.773]
</p><p>92 They argued that the answers should be simultaneously relevant to topics and opinions asked in  the questions. [sent-446, score-0.518]
</p><p>93 (201 1) developed a system called AQA to generate answers for questions about products (i. [sent-463, score-0.474]
</p><p>94 They argued that product questions were seldom asked for the holders, since the holders (i. [sent-469, score-0.523]
</p><p>95 Also, product questions mainly asked for majority opinions, and majority type was thus not considered. [sent-472, score-0.523]
</p><p>96 The AQA system includes five components, including question analysis, question expansion, high quality review retrieval, subjective sentence extraction, and answer grouping. [sent-473, score-0.801]
</p><p>97 The answers are generated by aggregat400 ing opinions in the retrieved fragments. [sent-474, score-0.468]
</p><p>98 6  Conclusions and Future Works  In this paper, we have developed a new product opinion-QA framework, which exploits the hierarchical organization of consumer reviews on products. [sent-475, score-0.925]
</p><p>99 With the help of the hierarchical organization, our framework can accurately identify the aspects asked in the questions and also discover their subaspects. [sent-476, score-0.595]
</p><p>100 We have further formulated the answer generation from retrieved review sentences as a multicriteria optimization problem. [sent-477, score-0.726]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('answer', 0.309), ('consumer', 0.288), ('opinion', 0.286), ('reviews', 0.251), ('aspect', 0.228), ('questions', 0.201), ('hierarchy', 0.198), ('product', 0.19), ('aspects', 0.181), ('question', 0.18), ('opinions', 0.178), ('answers', 0.177), ('salience', 0.14), ('nokia', 0.135), ('asked', 0.132), ('organization', 0.115), ('sentiment', 0.113), ('retrieved', 0.113), ('review', 0.096), ('products', 0.096), ('fragments', 0.094), ('yu', 0.093), ('lloret', 0.087), ('opinionated', 0.084), ('hierarchical', 0.081), ('public', 0.078), ('balahur', 0.072), ('helpfulness', 0.072), ('zha', 0.072), ('coherence', 0.072), ('mij', 0.067), ('organizes', 0.065), ('summarization', 0.063), ('implicit', 0.063), ('answering', 0.06), ('attitude', 0.057), ('fragment', 0.056), ('tac', 0.054), ('optimization', 0.054), ('factual', 0.052), ('asking', 0.052), ('iand', 0.052), ('aqa', 0.051), ('moghaddam', 0.051), ('criteria', 0.049), ('ku', 0.048), ('evaluations', 0.047), ('generation', 0.046), ('sentences', 0.046), ('qa', 0.045), ('asks', 0.045), ('commented', 0.043), ('wilson', 0.043), ('comparative', 0.042), ('appendix', 0.039), ('associations', 0.039), ('salient', 0.039), ('adjacent', 0.038), ('stored', 0.038), ('polarity', 0.037), ('battery', 0.036), ('camera', 0.036), ('iphone', 0.036), ('aforementioned', 0.036), ('sentence', 0.036), ('node', 0.036), ('iis', 0.035), ('updated', 0.035), ('centroid', 0.034), ('identifies', 0.034), ('ignorance', 0.034), ('leveli', 0.034), ('mizil', 0.034), ('multicriteria', 0.034), ('nishikawa', 0.034), ('ouyang', 0.034), ('reimplemented', 0.034), ('silla', 0.034), ('summ', 0.034), ('si', 0.033), ('noun', 0.033), ('wiebe', 0.032), ('appropriate', 0.032), ('identifying', 0.031), ('simultaneously', 0.031), ('svm', 0.03), ('recognizer', 0.029), ('lens', 0.029), ('adjacency', 0.029), ('consumers', 0.029), ('deshpande', 0.029), ('diversely', 0.029), ('erkan', 0.029), ('invited', 0.029), ('sons', 0.029), ('retrieval', 0.028), ('people', 0.028), ('supplementary', 0.028), ('yahoo', 0.028), ('formulated', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="20-tfidf-1" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Tat-Seng Chua</p><p>Abstract: This paper proposes to generate appropriate answers for opinion questions about products by exploiting the hierarchical organization of consumer reviews. The hierarchy organizes product aspects as nodes following their parent-child relations. For each aspect, the reviews and corresponding opinions on this aspect are stored. We develop a new framework for opinion Questions Answering, which enables accurate question analysis and effective answer generation by making use the hierarchy. In particular, we first identify the (explicit/implicit) product aspects asked in the questions and their sub-aspects by referring to the hierarchy. We then retrieve the corresponding review fragments relevant to the aspects from the hierarchy. In order to gener- ate appropriate answers from the review fragments, we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects. We conduct evaluations on 11 popular products in four domains. The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products. Experimental results demonstrate the effectiveness of our approach.</p><p>2 0.32577857 <a title="20-tfidf-2" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>Author: Jong-Hoon Oh ; Kentaro Torisawa ; Chikara Hashimoto ; Takuya Kawada ; Stijn De Saeger ; Jun'ichi Kazama ; Yiou Wang</p><p>Abstract: In this paper we explore the utility of sentiment analysis and semantic word classes for improving why-question answering on a large-scale web corpus. Our work is motivated by the observation that a why-question and its answer often follow the pattern that if something undesirable happens, the reason is also often something undesirable, and if something desirable happens, the reason is also often something desirable. To the best of our knowledge, this is the first work that introduces sentiment analysis to non-factoid question answering. We combine this simple idea with semantic word classes for ranking answers to why-questions and show that on a set of 850 why-questions our method gains 15.2% improvement in precision at the top-1 answer over a baseline state-of-the-art QA system that achieved the best performance in a shared task of Japanese non-factoid QA in NTCIR-6.</p><p>3 0.31066528 <a title="20-tfidf-3" href="./emnlp-2012-Opinion_Target_Extraction_Using_Word-Based_Translation_Model.html">101 emnlp-2012-Opinion Target Extraction Using Word-Based Translation Model</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: This paper proposes a novel approach to extract opinion targets based on wordbased translation model (WTM). At first, we apply WTM in a monolingual scenario to mine the associations between opinion targets and opinion words. Then, a graphbased algorithm is exploited to extract opinion targets, where candidate opinion relevance estimated from the mined associations, is incorporated with candidate importance to generate a global measure. By using WTM, our method can capture opinion relations more precisely, especially for long-span relations. In particular, compared with previous syntax-based methods, our method can effectively avoid noises from parsing errors when dealing with informal texts in large Web corpora. By using graph-based algorithm, opinion targets are extracted in a global process, which can effectively alleviate the problem of error propagation in traditional bootstrap-based methods, such as Double Propagation. The experimental results on three real world datasets in different sizes and languages show that our approach is more effective and robust than state-of-art methods. 1</p><p>4 0.17918116 <a title="20-tfidf-4" href="./emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">51 emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: Extracting opinion expressions from text is usually formulated as a token-level sequence labeling task tackled using Conditional Random Fields (CRFs). CRFs, however, do not readily model potentially useful segment-level information like syntactic constituent structure. Thus, we propose a semi-CRF-based approach to the task that can perform sequence labeling at the segment level. We extend the original semi-CRF model (Sarawagi and Cohen, 2004) to allow the modeling of arbitrarily long expressions while accounting for their likely syntactic structure when modeling segment boundaries. We evaluate performance on two opinion extraction tasks, and, in contrast to previous sequence labeling approaches to the task, explore the usefulness of segment- level syntactic parse features. Experimental results demonstrate that our approach outperforms state-of-the-art methods for both opinion expression tasks.</p><p>5 0.17807719 <a title="20-tfidf-5" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>Author: Jordan Boyd-Graber ; Brianna Satinoff ; He He ; Hal Daume III</p><p>Abstract: Cost-sensitive classification, where thefeatures used in machine learning tasks have a cost, has been explored as a means of balancing knowledge against the expense of incrementally obtaining new features. We introduce a setting where humans engage in classification with incrementally revealed features: the collegiate trivia circuit. By providing the community with a web-based system to practice, we collected tens of thousands of implicit word-by-word ratings of how useful features are for eliciting correct answers. Observing humans’ classification process, we improve the performance of a state-of-the art classifier. We also use the dataset to evaluate a system to compete in the incremental classification task through a reduction of reinforcement learning to classification. Our system learns when to answer a question, performing better than baselines and most human players.</p><p>6 0.13665624 <a title="20-tfidf-6" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>7 0.11388045 <a title="20-tfidf-7" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>8 0.11141022 <a title="20-tfidf-8" href="./emnlp-2012-Collocation_Polarity_Disambiguation_Using_Web-based_Pseudo_Contexts.html">28 emnlp-2012-Collocation Polarity Disambiguation Using Web-based Pseudo Contexts</a></p>
<p>9 0.11070186 <a title="20-tfidf-9" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>10 0.10952633 <a title="20-tfidf-10" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>11 0.105015 <a title="20-tfidf-11" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>12 0.084186949 <a title="20-tfidf-12" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>13 0.082304746 <a title="20-tfidf-13" href="./emnlp-2012-SSHLDA%3A_A_Semi-Supervised_Hierarchical_Topic_Model.html">115 emnlp-2012-SSHLDA: A Semi-Supervised Hierarchical Topic Model</a></p>
<p>14 0.076345749 <a title="20-tfidf-14" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>15 0.072624125 <a title="20-tfidf-15" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>16 0.071019016 <a title="20-tfidf-16" href="./emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>17 0.060065277 <a title="20-tfidf-17" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>18 0.056166999 <a title="20-tfidf-18" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>19 0.051925458 <a title="20-tfidf-19" href="./emnlp-2012-Streaming_Analysis_of_Discourse_Participants.html">120 emnlp-2012-Streaming Analysis of Discourse Participants</a></p>
<p>20 0.051570594 <a title="20-tfidf-20" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.223), (1, 0.161), (2, 0.008), (3, 0.408), (4, 0.229), (5, -0.184), (6, -0.218), (7, -0.025), (8, -0.131), (9, 0.027), (10, 0.102), (11, 0.056), (12, 0.002), (13, -0.125), (14, -0.001), (15, 0.04), (16, 0.118), (17, -0.133), (18, 0.066), (19, -0.003), (20, 0.204), (21, 0.03), (22, 0.027), (23, 0.144), (24, 0.13), (25, -0.019), (26, 0.067), (27, 0.065), (28, 0.028), (29, 0.115), (30, -0.038), (31, -0.013), (32, 0.049), (33, 0.022), (34, -0.038), (35, 0.034), (36, -0.003), (37, -0.044), (38, 0.0), (39, -0.006), (40, 0.039), (41, 0.02), (42, -0.014), (43, -0.019), (44, 0.002), (45, 0.011), (46, 0.029), (47, 0.065), (48, -0.015), (49, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98639286 <a title="20-lsi-1" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Tat-Seng Chua</p><p>Abstract: This paper proposes to generate appropriate answers for opinion questions about products by exploiting the hierarchical organization of consumer reviews. The hierarchy organizes product aspects as nodes following their parent-child relations. For each aspect, the reviews and corresponding opinions on this aspect are stored. We develop a new framework for opinion Questions Answering, which enables accurate question analysis and effective answer generation by making use the hierarchy. In particular, we first identify the (explicit/implicit) product aspects asked in the questions and their sub-aspects by referring to the hierarchy. We then retrieve the corresponding review fragments relevant to the aspects from the hierarchy. In order to gener- ate appropriate answers from the review fragments, we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects. We conduct evaluations on 11 popular products in four domains. The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products. Experimental results demonstrate the effectiveness of our approach.</p><p>2 0.79564631 <a title="20-lsi-2" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>Author: Jong-Hoon Oh ; Kentaro Torisawa ; Chikara Hashimoto ; Takuya Kawada ; Stijn De Saeger ; Jun'ichi Kazama ; Yiou Wang</p><p>Abstract: In this paper we explore the utility of sentiment analysis and semantic word classes for improving why-question answering on a large-scale web corpus. Our work is motivated by the observation that a why-question and its answer often follow the pattern that if something undesirable happens, the reason is also often something undesirable, and if something desirable happens, the reason is also often something desirable. To the best of our knowledge, this is the first work that introduces sentiment analysis to non-factoid question answering. We combine this simple idea with semantic word classes for ranking answers to why-questions and show that on a set of 850 why-questions our method gains 15.2% improvement in precision at the top-1 answer over a baseline state-of-the-art QA system that achieved the best performance in a shared task of Japanese non-factoid QA in NTCIR-6.</p><p>3 0.65629452 <a title="20-lsi-3" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>Author: Jordan Boyd-Graber ; Brianna Satinoff ; He He ; Hal Daume III</p><p>Abstract: Cost-sensitive classification, where thefeatures used in machine learning tasks have a cost, has been explored as a means of balancing knowledge against the expense of incrementally obtaining new features. We introduce a setting where humans engage in classification with incrementally revealed features: the collegiate trivia circuit. By providing the community with a web-based system to practice, we collected tens of thousands of implicit word-by-word ratings of how useful features are for eliciting correct answers. Observing humans’ classification process, we improve the performance of a state-of-the art classifier. We also use the dataset to evaluate a system to compete in the incremental classification task through a reduction of reinforcement learning to classification. Our system learns when to answer a question, performing better than baselines and most human players.</p><p>4 0.64483303 <a title="20-lsi-4" href="./emnlp-2012-Opinion_Target_Extraction_Using_Word-Based_Translation_Model.html">101 emnlp-2012-Opinion Target Extraction Using Word-Based Translation Model</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: This paper proposes a novel approach to extract opinion targets based on wordbased translation model (WTM). At first, we apply WTM in a monolingual scenario to mine the associations between opinion targets and opinion words. Then, a graphbased algorithm is exploited to extract opinion targets, where candidate opinion relevance estimated from the mined associations, is incorporated with candidate importance to generate a global measure. By using WTM, our method can capture opinion relations more precisely, especially for long-span relations. In particular, compared with previous syntax-based methods, our method can effectively avoid noises from parsing errors when dealing with informal texts in large Web corpora. By using graph-based algorithm, opinion targets are extracted in a global process, which can effectively alleviate the problem of error propagation in traditional bootstrap-based methods, such as Double Propagation. The experimental results on three real world datasets in different sizes and languages show that our approach is more effective and robust than state-of-art methods. 1</p><p>5 0.51758909 <a title="20-lsi-5" href="./emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">51 emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: Extracting opinion expressions from text is usually formulated as a token-level sequence labeling task tackled using Conditional Random Fields (CRFs). CRFs, however, do not readily model potentially useful segment-level information like syntactic constituent structure. Thus, we propose a semi-CRF-based approach to the task that can perform sequence labeling at the segment level. We extend the original semi-CRF model (Sarawagi and Cohen, 2004) to allow the modeling of arbitrarily long expressions while accounting for their likely syntactic structure when modeling segment boundaries. We evaluate performance on two opinion extraction tasks, and, in contrast to previous sequence labeling approaches to the task, explore the usefulness of segment- level syntactic parse features. Experimental results demonstrate that our approach outperforms state-of-the-art methods for both opinion expression tasks.</p><p>6 0.42890567 <a title="20-lsi-6" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>7 0.37496585 <a title="20-lsi-7" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>8 0.30940595 <a title="20-lsi-8" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>9 0.30569959 <a title="20-lsi-9" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>10 0.29128903 <a title="20-lsi-10" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>11 0.25447863 <a title="20-lsi-11" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>12 0.25157738 <a title="20-lsi-12" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>13 0.22770154 <a title="20-lsi-13" href="./emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>14 0.22340342 <a title="20-lsi-14" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>15 0.22276318 <a title="20-lsi-15" href="./emnlp-2012-SSHLDA%3A_A_Semi-Supervised_Hierarchical_Topic_Model.html">115 emnlp-2012-SSHLDA: A Semi-Supervised Hierarchical Topic Model</a></p>
<p>16 0.21503378 <a title="20-lsi-16" href="./emnlp-2012-Collocation_Polarity_Disambiguation_Using_Web-based_Pseudo_Contexts.html">28 emnlp-2012-Collocation Polarity Disambiguation Using Web-based Pseudo Contexts</a></p>
<p>17 0.20162828 <a title="20-lsi-17" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>18 0.19734074 <a title="20-lsi-18" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>19 0.18998668 <a title="20-lsi-19" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>20 0.1892287 <a title="20-lsi-20" href="./emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">86 emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.02), (16, 0.039), (19, 0.239), (25, 0.018), (34, 0.07), (45, 0.019), (60, 0.107), (63, 0.137), (64, 0.016), (65, 0.019), (70, 0.019), (74, 0.038), (76, 0.087), (80, 0.018), (86, 0.022), (95, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80945599 <a title="20-lda-1" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Tat-Seng Chua</p><p>Abstract: This paper proposes to generate appropriate answers for opinion questions about products by exploiting the hierarchical organization of consumer reviews. The hierarchy organizes product aspects as nodes following their parent-child relations. For each aspect, the reviews and corresponding opinions on this aspect are stored. We develop a new framework for opinion Questions Answering, which enables accurate question analysis and effective answer generation by making use the hierarchy. In particular, we first identify the (explicit/implicit) product aspects asked in the questions and their sub-aspects by referring to the hierarchy. We then retrieve the corresponding review fragments relevant to the aspects from the hierarchy. In order to gener- ate appropriate answers from the review fragments, we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects. We conduct evaluations on 11 popular products in four domains. The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products. Experimental results demonstrate the effectiveness of our approach.</p><p>2 0.75547689 <a title="20-lda-2" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>Author: Yang Song ; Jing Jiang ; Wayne Xin Zhao ; Sujian Li ; Houfeng Wang</p><p>Abstract: Pairwise coreference resolution models must merge pairwise coreference decisions to generate final outputs. Traditional merging methods adopt different strategies such as the bestfirst method and enforcing the transitivity constraint, but most of these methods are used independently of the pairwise learning methods as an isolated inference procedure at the end. We propose a joint learning model which combines pairwise classification and mention clustering with Markov logic. Experimental results show that our joint learning system outperforms independent learning systems. Our system gives a better performance than all the learning-based systems from the CoNLL-201 1shared task on the same dataset. Compared with the best system from CoNLL2011, which employs a rule-based method, our system shows competitive performance.</p><p>3 0.64795446 <a title="20-lda-3" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>Author: Mohamed Yahya ; Klaus Berberich ; Shady Elbassuoni ; Maya Ramanath ; Volker Tresp ; Gerhard Weikum</p><p>Abstract: The Linked Data initiative comprises structured databases in the Semantic-Web data model RDF. Exploring this heterogeneous data by structured query languages is tedious and error-prone even for skilled users. To ease the task, this paper presents a methodology for translating natural language questions into structured SPARQL queries over linked-data sources. Our method is based on an integer linear program to solve several disambiguation tasks jointly: the segmentation of questions into phrases; the mapping of phrases to semantic entities, classes, and relations; and the construction of SPARQL triple patterns. Our solution harnesses the rich type system provided by knowledge bases in the web of linked data, to constrain our semantic-coherence objective function. We present experiments on both the . in question translation and the resulting query answering.</p><p>4 0.63649797 <a title="20-lda-4" href="./emnlp-2012-An_%22AI_readability%22_Formula_for_French_as_a_Foreign_Language.html">17 emnlp-2012-An "AI readability" Formula for French as a Foreign Language</a></p>
<p>Author: Thomas Francois ; Cedrick Fairon</p><p>Abstract: This paper present a new readability formula for French as a foreign language (FFL), which relies on 46 textual features representative of the lexical, syntactic, and semantic levels as well as some of the specificities of the FFL context. We report comparisons between several techniques for feature selection and various learning algorithms. Our best model, based on support vector machines (SVM), significantly outperforms previous FFL formulas. We also found that semantic features behave poorly in our case, in contrast with some previous readability studies on English as a first language.</p><p>5 0.62731612 <a title="20-lda-5" href="./emnlp-2012-Open_Language_Learning_for_Information_Extraction.html">100 emnlp-2012-Open Language Learning for Information Extraction</a></p>
<p>Author: Mausam ; Michael Schmitz ; Stephen Soderland ; Robert Bart ; Oren Etzioni</p><p>Abstract: Open Information Extraction (IE) systems extract relational tuples from text, without requiring a pre-specified vocabulary, by identifying relation phrases and associated arguments in arbitrary sentences. However, stateof-the-art Open IE systems such as REVERB and WOE share two important weaknesses (1) they extract only relations that are mediated by verbs, and (2) they ignore context, thus extracting tuples that are not asserted as factual. This paper presents OLLIE, a substantially improved Open IE system that addresses both these limitations. First, OLLIE achieves high yield by extracting relations mediated by nouns, adjectives, and more. Second, a context-analysis step increases precision by including contextual information from the sentence in the extractions. OLLIE obtains 2.7 times the area under precision-yield curve (AUC) compared to REVERB and 1.9 times the AUC of WOEparse. –</p><p>6 0.61733538 <a title="20-lda-6" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>7 0.61109596 <a title="20-lda-7" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>8 0.61020571 <a title="20-lda-8" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>9 0.60924977 <a title="20-lda-9" href="./emnlp-2012-Modelling_Sequential_Text_with_an_Adaptive_Topic_Model.html">90 emnlp-2012-Modelling Sequential Text with an Adaptive Topic Model</a></p>
<p>10 0.60687315 <a title="20-lda-10" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>11 0.60447079 <a title="20-lda-11" href="./emnlp-2012-A_Phrase-Discovering_Topic_Model_Using_Hierarchical_Pitman-Yor_Processes.html">8 emnlp-2012-A Phrase-Discovering Topic Model Using Hierarchical Pitman-Yor Processes</a></p>
<p>12 0.60328543 <a title="20-lda-12" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>13 0.60100228 <a title="20-lda-13" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>14 0.59537488 <a title="20-lda-14" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>15 0.59437734 <a title="20-lda-15" href="./emnlp-2012-Mixed_Membership_Markov_Models_for_Unsupervised_Conversation_Modeling.html">89 emnlp-2012-Mixed Membership Markov Models for Unsupervised Conversation Modeling</a></p>
<p>16 0.59150481 <a title="20-lda-16" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>17 0.59083039 <a title="20-lda-17" href="./emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">51 emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>18 0.59007108 <a title="20-lda-18" href="./emnlp-2012-PATTY%3A_A_Taxonomy_of_Relational_Patterns_with_Semantic_Types.html">103 emnlp-2012-PATTY: A Taxonomy of Relational Patterns with Semantic Types</a></p>
<p>19 0.58750695 <a title="20-lda-19" href="./emnlp-2012-Revisiting_the_Predictability_of_Language%3A_Response_Completion_in_Social_Media.html">114 emnlp-2012-Revisiting the Predictability of Language: Response Completion in Social Media</a></p>
<p>20 0.58725947 <a title="20-lda-20" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
