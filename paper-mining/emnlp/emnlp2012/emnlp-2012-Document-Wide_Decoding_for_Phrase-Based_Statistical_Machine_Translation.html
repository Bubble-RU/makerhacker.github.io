<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-35" href="#">emnlp2012-35</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</h1>
<br/><p>Source: <a title="emnlp-2012-35-pdf" href="http://aclweb.org/anthology//D/D12/D12-1108.pdf">pdf</a></p><p>Author: Christian Hardmeier ; Joakim Nivre ; Jorg Tiedemann</p><p>Abstract: Independence between sentences is an assumption deeply entrenched in the models and algorithms used for statistical machine translation (SMT), particularly in the popular dynamic programming beam search decoding algorithm. This restriction is an obstacle to research on more sophisticated discourse-level models for SMT. We propose a stochastic local search decoding method for phrase-based SMT, which permits free document-wide dependencies in the models. We explore the stability and the search parameters ofthis method and demonstrate that it can be successfully used to optimise a document-level semantic language model. 1 Motivation In the field oftranslation studies, it is undisputed that discourse-wide context must be considered care- fully for good translation results (Hatim and Mason, 1990). By contrast, the state of the art in statistical machine translation (SMT), despite significant advances in the last twenty years, still assumes that texts can be translated sentence by sentence under strict independence assumptions, even though it is well known that certain linguistic phenomena such as pronominal anaphora cannot be translated correctly without referring to extra-sentential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm 1179 which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001 ; Tillmann and Ney, 2003). This algorithm con- structs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elimination of hypotheses from the search space if they coincide in a certain number of final words with a better hypothesis and no future expansion can possibly invert the relative ranking of the two hypotheses under the given models. Hypothesis recombination achieves a substantial reduction of the search space without affecting search optimality and makes it possible to use aggressive pruning techniques for fast search while still obtaining good results. The downside of this otherwise excellent approach is that it only works well with models that have a local dependency structure similar to that of an n-gram language model, so they only depend on a small context window for each target word. Sentence-local models with longer dependencies can be added, but doing so greatly increases the risk for search errors by inhibiting hypothesis recombination. Cross-sentence dependencies cannot be directly integrated into DP SMT decoding in LParnogcue agdein Lgesa ornf tihneg, 2 p0a1g2e Jso 1in17t C9–o1n1f9e0re,n Jce ju on Is Elanmdp,ir Kicoarlea M,e 1t2h–o1d4s J iunly N 2a0tu1r2a.l ? Lc a2n0g1u2ag Aes Psorcoicaetsiosin fgo arn Cdo Cmopmutpauti oantiaoln Lailn Ngautiustriacls any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required. Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems. Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (201 1), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences. In this paper, we present a method for decoding complete documents in phrase-based SMT. Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by the application of a series of operations using a hill climbing strategy to find a (local) maximum of the score function. This setup gives us complete freedom to define scoring functions over the entire document. Moreover, by optionally initialising the state with the output of a traditional DP decoder, we can ensure that the final hypothesis is no worse than what would have been found by DP search alone. We start by describing the decoding algorithm and the state operations used by our decoder, then we present empirical results demonstrating the effectiveness of our approach and its usability with a document-level semantic language model, and finally we discuss some related work. 2 SMT Decoding by Hill Climbing In this section, we formally describe the phrasebased SMT model implemented by our decoder as well as the decoding algorithm we use. 2.1 SMT Model Our decoder is based on local search, so its state at any time is a representation of a complete translation of the entire document. Even though the decoder operates at the document level, it is important to keep 1180 track of sentence boundaries, and the individual operations that are applied to the state are still confined to sentence scope, so it is useful to decompose the state of a document into the state of its sentences, and we define the overall state S as a sequence of sentence states: S = S1S2 . . .SN, (1) where N is the number of sentences. This implies that we constrain the decoder to emit exactly one output sentence per input sentence. Let ibe the number of a sentence and mi the number of input tokens of this sentence, p and q (with 1 ≤ p ≤ q ≤ mi) be positions in the input sentence a1n ≤d [p; q] qde ≤no mte the set ofpositions from p up to and including q. We say that [p; q] precedes [p0; q0], or [p; q] ≺ [p0; q0], if q < p0. Let Φi([p; q]) be the set of t[pra;nqs]l ≺atio [pns for the source phrase covering positions [p; q] in the input sentence ias given by the phrase table. We call A = h[p; q] ,φi an anchored phrase pair w.it Wh coverage C(A) = [p; q] nif a φ ∈ Φi([p; q]) sise a target phrase translating =th [ep source w∈o Φrds at positions [p; q] . Then a sequence of ni anchored phrase pairs Si = A1A2 . . .Ani (2) is a valid sentence state for sentence iif the following two conditions hold: 1. The coverage sets C(Aj) for j in 1, . . . , ni are mutually disjoint, and 2. the anchored phrase pairs jointly cover the complete input sentence, or [niC(Aj) = [1;mi]. (3) [j=1 Let f(S) be a scoring function mapping a state S to a real number. As usual in SMT, it is assumed that the scoring function can be decomposed into a linear combination of K feature functions hk(S), each with a constant weight λk, so f(S) =k∑K=1λkhk(S). (4) The problem addressed by the decoder is the search for the state with maximal score, such that Sˆ Sˆ = argSmaxf(S). (5) The feature functions implemented in our baseline system are identical to the ones found in the popular Moses SMT system (Koehn et al., 2007). In particular, our decoder has the following feature functions: 1. phrase translation scores provided by the phrase table including forward and backward conditional probabilities, lexical weights and a phrase penalty (Koehn et al., 2003), 2. n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3. a word penalty score, 4. a distortion model with geometric (Koehn et al., 2003), and decay 5. a feature indicating the number of times a given distortion limit is exceeded in the current state. In our experiments, the last feature is used with a fixed weight of negative infinity in order to limit the gaps between the coverage sets of adjacent anchored phrase pairs to a maximum value. In DP search, the distortion limit is usually enforced directly by the search algorithm and is not added as a feature. In our decoder, however, this restriction is not required to limit complexity, so we decided to add it among the scoring models. 2.2 Decoding Algorithm The decoding algorithm we use (algorithm 1) is very simple. It starts with a given initial document state. In the main loop, which extends from line 3 to line 12, it generates a successor state S0 for the current state S by calling the function Neighbour, which non-deterministically applies one of the operations described in section 3 of this paper to S. The score of the new state is compared to that of the previous one. If it meets a given acceptance criterion, S0 becomes the current state, else search continues from the previous state S. For the experiments in this paper, we use the hill climbing acceptance criterion, which simply accepts a new state if its score is higher than that of the current state. Other acceptance criteria are possible and could be used to endow the search algorithm with stochastic behaviour. 1181 The main loop is repeated until a maximum number of steps (step limit) is reached or until a maximum number of moves are rejected in a row (rejection limit). Algorithm 1 Decoding algorithm Input: an initial document state S; search parameters maxsteps and maxrejected Output: a modified document state 1: nsteps ← 0 2: nrejected ← 0 3: nwrhejileec nsteps < maxsteps and nrejected < maxrejected do 4: S0 ← Neighbour (S) 5: if Accept (f(S0) , f(S)) then 6: S ← S0 7: nrejected ← 0 8: elsner 9: nrejected ← nrejected + 1 10: enndr eifj 11: nsteps ← nsteps + 1 12: ennds wtephsile ← 13: return S A notable difference between this algorithm and other hill climbing algorithms that have been used for SMT decoding (Germann et al., 2004; Langlais et al., 2007) is its non-determinism. Previous work for sentence-level decoding employed a steepest ascent strategy which amounts to enumerating the complete neighbourhood of the current state as defined by the state operations and selecting the next state to be the best state found in the neighbourhood of the current one. Enumerating all neighbours of a given state, costly as it is, has the advantage that it makes it easy to prove local optimality of a state by recognising that all possible successor states have lower scores. It can be rather inefficient, since at every step only one modification will be adopted; many of the modifications that are discarded will very likely be generated anew in the next iteration. As we extend the decoder to the document level, the size of the neighbourhood that would have to be explored in this way increases considerably. Moreover, the inefficiency of the steepest ascent approach potentially increases as well. Very likely, a promising move in one sentence will remain promising after a modification has been applied to another sentence, even though this is not guaranteed to be true in the presence of cross-sentence models. We therefore adopt a first-choice hill climbing strategy that non-deterministically generates successor states and accepts the first one that meets the acceptance criterion. This frees us from the necessity of generating the full set of successors for each state. On the downside, if the full successor set is not known, it is no longer possible to prove local optimality of a state, so we are forced to use a different condition for halting the search. We use a combination of two limits: The step limit is a hard limit on the resources the user is willing to expend on the search problem. The value of the rejection limit determines how much of the neighbourhood is searched for better successors before a state is accepted as a solution; it is related to the probability that a state returned as a solution is in fact locally optimal. To simplify notations in the description of the individual state operations, we write Si −→ Si0 (6) to signify that a state operation, when presented with a document state as in equation 1 and acting on sentence i, returns a new document state of S0 = S1 . . .Si−1 Si0 Si+1 . . .SN. (7) Similarly, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (8) is equivalent to Si −→ A1 . . .Aj−1 A01 . . .A0h0 Aj+h . . .Ani (9) and indicates that the operation returns a state in which a sequence of h consecutive anchored phrase pairs has been replaced by another sequence of h0 anchored phrase pairs. 2.3 Efficiency Considerations When implementing the feature functions for the decoder, we have to exercise some care to avoid recomputing scores for the whole document at every iteration. To achieve this, the scores are computed completely only once, at the beginning of the decoding run. In subsequent iterations, scoring functions are presented with the scores of the previous 1182 iteration and a list of modifications produced by the state operation, a set of tuples hi, r, s,A01 . . .A0h0i, each indicating tthioant ,t ahe s edto ocfu tmupelnets s hhio,ru,sld, Abe modifii,e eda as described by Si :Ar . . .As −→ A01 . . .A0h0 . (10) If a feature function is decomposable in some way, as all the standard features developed under the constraints of DP search are, it can then update the state simply by subtracting and adding score components pertaining to the modified parts of the document. Feature functions have the possibility to store their own state information along with the document state to make sure the required information is available. Thus, the framework makes it possible to exploit decomposability for efficient scoring without impos- ing any particular decomposition on the features as beam search does. To make scoring even more efficient, scores are computed in two passes: First, every feature function is asked to provide an upper bound on the score that will be obtained for the new state. In some cases, it is possible to calculate reasonable upper bounds much more efficiently than computing the exact feature value. If the upper bound fails to meet the acceptance criterion, the new state is discarded right away; if not, the full score is computed and the acceptance criterion is tested again. Among the basic SMT models, this two-pass strategy is only used for the n-gram LM, which requires fairly expensive parameter lookups for scoring. The scores of all the other baseline models are fully computed during the first scoring pass. The n-gram model is more complex. In its state information, it keeps track of the LM score and LM library state for each word. The first scoring pass then identifies the words whose LM scores are affected by the current search step. This includes the words changed by the search operation as well as the words whose LM history is modified. The range of the history de- pendencies can be determined precisely by considering the “valid state length” information provided by the KenLM library. In the first pass, the LM scores of the affected words are subtracted from the total score. The model only looks up the new LM scores for the affected words and updates the total score if the new search state passes the first acceptance check. This two-pass scoring approach allows us to avoid LM lookups altogether for states that will be rejected anyhow because of low scores from the other models, e. g. because the distortion limit is violated. Model score updates become more complex and slower as the number of dependencies of a model increases. While our decoding algorithm does not impose any formal restrictions on the number or type of dependencies that can be handled, there will be practical limits beyond which decoding becomes unacceptably slow or the scoring code becomes very difficult to maintain. These limits are however fairly independent of the types of dependencies handled by a model, which permits the exploration of more varied model types than those handled by DP search. 2.4 State Initialisation Before the hill climbing decoding algorithm can be run, an initial state must be generated. The closer the initial state is to an optimum, the less work remains to be done for the algorithm. If the algorithm is to be self-contained, initialisation must be relatively uninformed and can only rely on some general prior assumptions about what might be a good initial guess. On the other hand, if optimal results are sought after, it pays off to invest some effort into a good starting point. One way to do this is to run DP search first. For uninformed initialisation, we chose to implement a very simple procedure based only on the observation that, at least for language pairs involving the major European languages, it is usually a good guess to keep the word order of the output very similar to that of the input. We therefore create the initial state by selecting, for each sentence in the document, a sequence of anchored phrase pairs covering the input sentence in monotonic order, that is, such that for all pairs of adjacent anchored phrase pairs Aj and Aj+1, we have that C(Aj) ≺ C(Aj+1 ). For initialisation with DP search, we first run the Moses decoder (Koehn et al., 2007) with default search parameters and the same models as those used by our decoder. Then we extract the best output hypothesis from the search graph of the decoder and map it into a sequence of anchored phrase pairs in the obvious way. When the document-level decoder is used with models that are incompatible with beam search, Moses can be run with a subset of the models in order to find an approximation of the solution 1183 which is then refined with the complete feature set. 3 State Operations Given a document state S, the decoder uses a neighbourhood function Neighbour to simulate a move in the state space. The neighbourhood function nondeterministically selects a type of state operation and a location in the document to apply it to and returns the resulting new state. We use a set of three operations that has the property that every possible document state can be reached from every other state in a sequence of moves. Designing operations for state transitions in local search for phrase-based SMT is a problem that has been addressed in the literature (Langlais et al., 2007; Arun et al., 2010). Our decoder’s first- choice hill climbing strategy never enumerates the full neighbourhood of a state. We therefore place less emphasis than previous work on defining a compact neighbourhood, but allow the decoder to make quite extensive changes to a state in a single step with a certain probability. Otherwise our operations are similar to those used by Arun et al. (2010). All of the operations described in this paper make changes to a single sentence only. Each time it is called, the Neighbour function selects a sentence in the document with a probability proportional to the number of input tokens in each sentence to ensure a fair distribution ofthe decoder’s attention over the words in the document regardless of varying sentence lengths. 3.1 Changing Phrase Translations The change-phrase-translation operation replaces the translation of a single phrase with a random translation with the same coverage taken from the phrase table. Formally, the operation selects an anchored phrase pair Aj by drawing uniformly from the elements of Si and then draws a new translation φ0 uniformly from the set Φi(C(Aj)). The new state is given by Si : Aj −→ hC(Aj), φ0i. (11) 3.2 Changing Word Order The swap-phrases operation affects the output word order without changing the phrase translations. It exchanges two anchored phrase pairs Aj and Aj+h, resulting in an output state of Si : Aj . . .Aj+h −→ Aj+h Aj+1 . . .Aj+h−1 Aj. (12) The start location j is drawn uniformly from the eligible sentence positions; the swap range h comes from a geometric distribution with configurable decay. Other word-order changes such as a one-way move operation that does not require another movement in exchange or more advanced permutations can easily be defined. 3.3 Resegmentation The most complex operation is resegment, which allows the decoder to modify the segmentation ofthe source phrase. It takes a number of anchored phrase pairs that form a contiguous block both in the input and in the output and replaces them with a new set of phrase pairs covering the same span of the input sentence. Formally, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (13) such that j+[h−1 [h0 [ C(Aj0) = [ C(A0j0) = [p;q] j[0=j (14) j[0=1 for some p and q, where, for j0 = 1, . . . ,h0, we have that A0j0 = h[pj0; qj0] , φj0i, all [pj0; qj0] are mutually disjoint =an hd[ peach φj0 isi randomly drawn from Φi([pj0;qj0]). Regardless of the ordering of Aj . . .Aj+h−1 , the resegment operation always generates a sequence of anchored phrase pairs in linear order, such that C(A0j0) ≺ C(A0j0+1 ) for j0 = 1, . . . ,h0 −1 . As )f o≺r Cth(eA other operations, j is− generated uniformly and h is drawn from a geometric distribution with a decay parameter. The new segmentation is generated by extending the sequence of anchored phrase pairs with random elements starting at the next free position, proceeding from left to right until the whole range [p; q] is covered. 4 Experimental Results In this section, we present the results of a series of experiments with our document decoder. The 1184 goal of our experiments is to demonstrate the behaviour of the decoder and characterise its response to changes in the fundamental search parameters. The SMT models for our experiments were created with a subset of the training data for the English-French shared task at the WMT 2011workshop (Callison-Burch et al., 2011). The phrase table was trained on Europarl, news-commentary and UN data. To reduce the training data to a manageable size, singleton phrase pairs were removed before the phrase scoring step. Significance-based filtering (Johnson et al., 2007) was applied to the resulting phrase table. The language model was a 5gram model with Kneser-Ney smoothing trained on the monolingual News corpus with IRSTLM (Federico et al., 2008). Feature weights were trained with Minimum Error-Rate Training (MERT) (Och, 2003) on the news-test2008 development set using the DP beam search decoder and the MERT implementation of the Moses toolkit (Koehn et al., 2007). Experimental results are reported for the newstest2009 test set, a corpus of 111 newswire documents totalling 2,525 sentences or 65,595 English input tokens. 4.1 Stability An important difference between our decoder and the classical DP decoder as well as previous work in SMT decoding with local search is that our decoder is inherently non-deterministic. This implies that repeated runs of the decoder with the same search parameters, input and models will not, in general, find the same local maximum of the score space. The first empirical question we ask is therefore how different the results are under repeated runs. The results in this and the next section were obtained with random state initialisation, i. e. without running the DP beam search decoder. Figure 1 shows the results of 7 decoder runs with the models described above, translating the newstest2009 test set, with a step limit of 227 and a rejection limit of 100,000. The x-axis of both plots shows the number of decoding steps on a logarithmic scale, so the number of steps is doubled between two adjacent points on the same curve. In the left plot, the y-axis indicates the model score optimised by the decoder summed over all 2525 sentences of the document. In the right plot, the case-sensitive BLEU score (Papineni et al., 2002) of the current decoder Figure 1: Score stability in repeated decoder runs state against a reference translation is displayed. We note, as expected, that the decoder achieves a considerable improvement of the initial state with diminishing returns as decoding continues. Between 28 and 214 steps, the score increases at a roughly logarithmic pace, then the curve flattens out, which is partly due to the fact that decoding for some documents effectively stopped when the maximum number of rejections was reached. The BLEU score curve shows a similar increase, from an initial score below 5 % to a maximum of around 21.5 %. This is below the score of 22.45 % achieved by the beam search decoder with the same models, which is not surprising considering that our decoder approximates a more difficult search problem, from which a number of strong independence assumptions have been lifted, without, at the moment, having any stronger models at its disposal to exploit this additional freedom for better translation. In terms of stability, there are no dramatic differences between the decoder runs. Indeed, the small differences that exist are hardly discernible in the plots. The model scores at the end of the decoding run range between −158767.9 and −158716.9, a g re rlautniv rea ndgieffe breetnwceee nof − only a6b7.o9ut a n0d.0 −3 %15.8 F1i6n.a9l, BLEU scores range from 21.41 % to 21.63 %, an interval that is not negligible, but comparable to the variance observed when, e. g., feature weights from repeated MERT runs are used with one and the same SMT system. Note that these results were obtained with random state initialisation. With DP initialisation, score differences between repeated runs rarely 1185 exceed 0.02 absolute BLEU percentage points. Overall, we conclude that the decoding results of our algorithm are reasonably stable despite the nondeterminism inherent in the procedure. In our subsequent experiments, the evaluation scores reported are calculated as the mean of three runs for each experiment. 4.2 Search Algorithm Parameters The hill climbing algorithm we use has two parameters which govern the trade-off between decoding time and the accuracy with which a local maximum is identified: The step limit stops the search process after a certain number of steps regardless of the search progress made or lack thereof. The rejection limit stops the search after a certain number of unsuccessful attempts to make a step, when continued search does not seem to be promising. In most of our experiments, we used a step limit of 227 ≈ 1.3 · 108 and a rejection limit of 105. In practice, decoding terminates by reaching the rejection limit for the vast majority of documents. We therefore examined the effect of different rejection limits on the learning curves. The results are shown in figure 2. The results show that continued search does pay off to a certain extent. Indeed, the curve for rejection limit 107 seems to indicate that the model score increases roughly logarithmically, albeit to a higher base, even after the curve has started to flatten out at 214 steps. At a certain point, however, the probability of finding a good successor state drops rather sharply by about two orders of magnitude, as Figure 2: Search performance at different rejection limits evidenced by the fact that a rejection limit of 106 does not give a large improvement over one of 105, while one of 107 does. The continued model score improvement also results in an increase in BLEU scores, and with a BLEU score of 22. 1% the system with rejection limit 107 is fairly close to the score of 22.45 % obtained by DP beam search. Obviously, more exact search comes at a cost, and in this case, it comes at a considerable cost, which is an explosion of the time required to decode the test set from 4 minutes at rejection limit 103 to 224 minutes at rejection limit 105 and 38 hours 45 minutes at limit 107. The DP decoder takes 3 1 minutes for the same task. We conclude that the rejection limit of 105 selected for our experiments, while technically suboptimal, realises a good trade-off between decoding time and accuracy. 4.3 A Semantic Document Language Model In this section, we present the results of the application of our decoder to an actual SMT model with cross-sentence features. Our model addresses the problem of lexical cohesion. In particular, it rewards the use of semantically related words in the translation output by the decoder, where semantic distance is measured with a word space model based on Latent Semantic Analysis (LSA). LSA has been applied to semantic language modelling in previous research with some success (Coccaro and Jurafsky, 1998; Bellegarda, 2000; Wandmacher and Antoine, 2007). In SMT, it has mostly been used for domain adaptation (Kim and Khudanpur, 2004; Tam et al., 1186 2007), or to measure sentence similarities (Banchs and Costa-juss a`, 2011). The model we use is inspired by Bellegarda (2000). It is a Markov model, similar to a standard n-gram model, and assigns to each content word a score given a history of n preceding content words, where n = 30 below. Scoring relies on a 30dimensional LSA word vector space trained with the S-Space software (Jurgens and Stevens, 2010). The score is defined based on the cosine similarity between the word vector of the predicted word and the mean word vector of the words in the history, which is converted to a probability by histogram lookup as suggested by Bellegarda (2000). The model is structurally different from a regular n-gram model in that word vector n-grams are defined over content words occurring in the word vector model only and can cross sentence boundaries. Stop words, identified by an extensive stop word list and amounting to around 60 % of the tokens, are scored by a different mechanism based on their relative frequency (undiscounted unigram probability) in the training corpus. In sum, the score produced by the semantic document LM has the following form: wh(er|h)α=is tεpαheuncipgors(wp)o|hrtinof w fci os nakutneskotn wpon w ,onerldse,in(ls1teh5) training corpus and ε is a small fixed probability. It is integrated into the decoder as an extra feature function. Since we lack an automatic method for training the feature weights of document-wide features, its weight was selected by grid search over a number of values, comparing translation performance for the newstest2009 test set. In these experiments, we used DP beam search to initialise the state of our local search decoder. Three results are presented (table 1): The first table row shows the baseline performance using DP beam search with standard sentence-local features only. The scores in the second row were obtained by running the hill climbing decoder with DP initialisation, but without adding any models. A marginal increase in scores for all three test sets demonstrates that the hill climbing decoder manages to fix some of the search errors made by the DP search. The last row contains the scores obtained by adding in the semantic language model. Scores are presented for three publicly available test sets from recent WMT Machine Translation shared tasks, of which one (newstest2009) was used to monitor progress during development and select the final model. Adding the semantic language model results in a small increase in NIST scores (Doddington, 2002) for all three test sets as well as a small BLEU score gain (Papineni et al., 2002) for two out of three corpora. We note that the NIST score turned out to react more sensitively to improvements due to the semantic LM in all our experiments, which is reasonable because the model specifically targets content words, which benefit from the information weighting done by the NIST score. While the results we present do not constitute compelling evidence in favour of our semantic LM in its current form, they do suggest that this model could be improved to realise higher gains from cross-sentence semantic information. They support our claim that cross- sentence models should be examined more closely and that existing methods should be adapted to deal with them, a problem addressed by our main contribution, the local search document decoder. 5 Related Work Even though DP beam search (Koehn et al., 2003) has been the dominant approach to SMT decoding in recent years, methods based on local search have been explored at various times. For word-based SMT, greedy hill-climbing techniques were advo1187 cated as a faster replacement for beam search (Germann et al., 2001 ; Germann, 2003; Germann et al., 2004), and a problem formulation specifically targeting word reordering with an efficient word reordering algorithm has been proposed (Eisner and Tromble, 2006). A local search decoder has been advanced as a faster alternative to beam search also for phrasebased SMT (Langlais et al., 2007; Langlais et al., 2008). That work anticipates many of the features found in our decoder, including the use of local search to refine an initial hypothesis produced by DP beam search. The possibility of using models that do not fit well into the beam search paradigm is mentioned and illustrated with the example of a reversed n-gram language model, which the authors claim would be difficult to implement in a beam search decoder. Similarly to the work by Germann et al. (2001), their decoder is deterministic and explores the entire neighbourhood of a state in order to identify the most promising step. Our main contribution with respect to the work by Langlais et al. (2007) is the introduction of the possibility of handling document-level models by lifting the assumption of sentence independence. As a consequence, enumerating the entire neighbourhood becomes too expensive, which is why we resort to a “first-choice” strategy that non-deterministically generates states and accepts the first one encountered that meets the acceptance criterion. More recently, Gibbs sampling was proposed as a way to generate samples from the posterior distribution of a phrase-based SMT decoder (Arun et al., 2009; Arun et al., 2010), a process that resembles local search in its use of a set of state-modifying operators to generate a sequence of decoder states. Where local search seeks for the best state attainable from a given initial state, Gibbs sampling produces a representative sample from the posterior. Like all work on SMT decoding that we know of, the Gibbs sampler presented by Arun et al. (2010) assumes independence of sentences and considers the complete neighbourhood of each state before taking a sample. 6 Conclusion In the last twenty years of SMT research, there has been a strong assumption that sentences in a text newstest2009 newstest2010 newstest201 1 BLEU NIST BLEU NIST BLEU NIST 22.56 6.513 27.27 7.034 24.94 7.170 + hill climbing 22.60 6.518 27.33 7.046 24.97 7.169 with semantic LM 22.71 6.549 27.53 7.087 24.90 7.199 DP search only DP Table 1: Experimental results with a cross-sentence semantic language model are independent of one another, and discourse context has been largely neglected. Several factors have contributed to this. Developing good discourse-level models is difficult, and considering the modest translation quality that has long been achieved by SMT, there have been more pressing problems to solve and lower hanging fruit to pick. However, we argue that the popular DP beam search algorithm, which delivers excellent decoding performance, but imposes a particular kind of local dependency structure on the feature models, has also had its share in driving researchers away from discourse-level problems. In this paper, we have presented a decoding procedure for phrase-based SMT that makes it possible to define feature models with cross-sentence dependencies. Our algorithm can be combined with DP beam search to leverage the quality of the traditional approach with increased flexibility for models at the discourse level. We have presented preliminary results on a cross-sentence semantic language model addressing the problem of lexical cohesion to demonstrate that this kind of models is worth exploring further. Besides lexical cohesion, cross-sentence models are relevant for other linguistic phenomena such as pronominal anaphora or verb tense selection. We believe that SMT research has reached a point of maturity where discourse phenomena should not be ignored any longer, and we consider our decoder to be a step towards this goal. References Abhishek Arun, Chris Dyer, Barry Haddow, Phil Blunsom, Adam Lopez, and Philipp Koehn. 2009. Monte carlo inference and maximization for phrase-based translation. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009), pages 102–1 10, Boulder, Colorado, June. Association for Computational Linguistics. Abhishek Arun, Barry Haddow, Philipp Koehn, Adam Lopez, Chris Dyer, and Phil Blunsom. 2010. Monte 1188 Ma- Carlo techniques for phrase-based translation. chine translation, 24(2): 103–121 . Rafael E. Banchs and Marta R. Costa-juss a`. 2011. A semantic feature for Statistical Machine Translation. In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 126– 134, Portland, Oregon, USA, June. Association for Computational Linguistics. Jerome R. Bellegarda. 2000. Exploiting latent semantic information in statistical language modeling. Proceedings of the IEEE, 88(8): 1279–1296. Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar Zaidan. 2011. Findings of the 2011 Workshop on Statistical Machine Translation. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 22–64, Edinburgh, Scotland, July. Association for Computational Linguistics. Noah Coccaro and Daniel Jurafsky. 1998. Towards better integration of semantic predictors in statistical language modeling. In Proceedings of the 5th International Conference on Spoken Language Processing, Sydney. George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proceedings of the second International conference on Human Language Technology Research, pages 138–145, San Diego. Jason Eisner and Roy W. Tromble. 2006. Local search with very large-scale neighborhoods for optimal permutations in machine translation. In Proceedings of the HLT-NAACL Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing, pages 57–75. Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In Interspeech 2008, pages 1618–1621 . ISCA. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2001 . Fast decoding and optimal decoding for machine translation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 228–235, Toulouse, France, July. Association for Computational Linguis- tics. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2004. Fast and optimal decoding for machine translation. Artificial Intelligence, 154(1–2): 127–143. Ulrich Germann. 2003. Greedy decoding for Statistical Machine Translation in almost linear time. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. Zhengxian Gong, Min Zhang, and Guodong Zhou. 2011. Cache-based document-level Statistical Machine Translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 909–919, Edinburgh, Scotland, UK., July. Association for Computational Linguistics. Christian Hardmeier and Marcello Federico. 2010. Modelling Pronominal Anaphora in Statistical Machine Translation. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 283–289. Basil Hatim and Ian Mason. 1990. Discourse and the Translator. Language in Social Life Series. Longman, London. Kenneth Heafield. 2011. KenLM: faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, July. Association for Computational Linguistics. Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 967– 975, Prague, Czech Republic, June. Association for Computational Linguistics. David Jurgens and Keith Stevens. 2010. The S-Space package: An open source package for word space models. In Proceedings of the ACL 2010 System Demonstrations, pages 30–35, Uppsala, Sweden, July. Association for Computational Linguistics. Woosung Kim and Sanjeev Khudanpur. 2004. Crosslingual latent semantic analysis for language modeling. In IEEE international conference on acoustics, speech, and signal processing (ICASSP), volume 1, pages 257–260, Montr ´eal. Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 conference of the North American chapter of the Association for Computational Linguistics on Human Language Technology, pages 48– 54, Edmonton. 1189 Philipp Koehn, Hieu Hoang, Alexandra Birch, et al. 2007. Moses: open source toolkit for Statistical Machine Translation. In Annual meeting of the Association for Computational Linguistics: Demonstration session, pages 177–180, Prague. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2007. A greedy decoder for phrase-based statistical machine translation. In TMI-2007: Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 104–1 13, Sk¨ ovde. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2008. Recherche locale pour la traduction statistique par segments. In TALN 2008, pages 119–128, Avignon, France, June. ATALA. Ronan Le Nagard and Philipp Koehn. 2010. Aiding pronoun translation with co-reference resolution. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 252–261, Uppsala, Sweden, July. Association for Computational Linguistics. Franz Josef Och, Nicola Ueffing, and Hermann Ney. 2001. An efficient A* search algorithm for Statistical Machine Translation. In Proceedings of the DataDriven Machine Translation Workshop, 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 55–62, Toulouse. Franz Josef Och. 2003. Minimum error rate training in Statistical Machine Translation. In Proceedings of the 41st annual meeting of the Association for Computational Linguistics, pages 160–167, Sapporo (Japan). Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of Machine Translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 3 11–3 18, Philadelphia. ACL. Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007. Bilingual LSA-based adaptation for Statistical Machine Translation. Machine Translation, 21(4): 187– 207. J o¨rg Tiedemann. 2010. To cache or not to cache? Experiments with adaptive models in Statistical Machine Translation. In Proceedings of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and Metrics MATR, pages 189–194, Uppsala, Sweden. Association for Computational Linguistics. Christoph Tillmann and Hermann Ney. 2003. Word reordering and a Dynamic Programming beam search algorithm for Statistical Machine Translation. Computational linguistics, 29(1):97–133. Christoph Tillmann, Stephan Vogel, Hermann Ney, and Alex Zubiaga. 1997. A DP-based search using monotone alignments in Statistical Translation. In Proceedings of the 35th Annual Meeting of the Association for Computational Spain, tics. Linguistics, July. Association for 289–296, Madrid, Computational Linguis- pages Tonio Wandmacher and Jean-Yves Antoine. 2007. Methods to integrate a language model with semantic information for a word prediction component. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 506–5 13, Prague, Czech Republic, June. Association for Computational Linguistics. 1190</p><p>Reference: <a title="emnlp-2012-35-reference" href="../emnlp2012_reference/emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('decod', 0.466), ('dp', 0.315), ('neighbo', 0.289), ('smt', 0.263), ('aj', 0.231), ('reject', 0.207), ('climb', 0.166), ('anch', 0.157), ('beam', 0.153), ('langla', 0.127), ('german', 0.127), ('hil', 0.123), ('search', 0.12), ('lm', 0.113), ('nreject', 0.105), ('transl', 0.102), ('arun', 0.099), ('acceiv', 0.085), ('nsteps', 0.084), ('koehn', 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="35-tfidf-1" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>Author: Christian Hardmeier ; Joakim Nivre ; Jorg Tiedemann</p><p>Abstract: Independence between sentences is an assumption deeply entrenched in the models and algorithms used for statistical machine translation (SMT), particularly in the popular dynamic programming beam search decoding algorithm. This restriction is an obstacle to research on more sophisticated discourse-level models for SMT. We propose a stochastic local search decoding method for phrase-based SMT, which permits free document-wide dependencies in the models. We explore the stability and the search parameters ofthis method and demonstrate that it can be successfully used to optimise a document-level semantic language model. 1 Motivation In the field oftranslation studies, it is undisputed that discourse-wide context must be considered care- fully for good translation results (Hatim and Mason, 1990). By contrast, the state of the art in statistical machine translation (SMT), despite significant advances in the last twenty years, still assumes that texts can be translated sentence by sentence under strict independence assumptions, even though it is well known that certain linguistic phenomena such as pronominal anaphora cannot be translated correctly without referring to extra-sentential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm 1179 which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001 ; Tillmann and Ney, 2003). This algorithm con- structs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elimination of hypotheses from the search space if they coincide in a certain number of final words with a better hypothesis and no future expansion can possibly invert the relative ranking of the two hypotheses under the given models. Hypothesis recombination achieves a substantial reduction of the search space without affecting search optimality and makes it possible to use aggressive pruning techniques for fast search while still obtaining good results. The downside of this otherwise excellent approach is that it only works well with models that have a local dependency structure similar to that of an n-gram language model, so they only depend on a small context window for each target word. Sentence-local models with longer dependencies can be added, but doing so greatly increases the risk for search errors by inhibiting hypothesis recombination. Cross-sentence dependencies cannot be directly integrated into DP SMT decoding in LParnogcue agdein Lgesa ornf tihneg, 2 p0a1g2e Jso 1in17t C9–o1n1f9e0re,n Jce ju on Is Elanmdp,ir Kicoarlea M,e 1t2h–o1d4s J iunly N 2a0tu1r2a.l ? Lc a2n0g1u2ag Aes Psorcoicaetsiosin fgo arn Cdo Cmopmutpauti oantiaoln Lailn Ngautiustriacls any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required. Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems. Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (201 1), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences. In this paper, we present a method for decoding complete documents in phrase-based SMT. Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by the application of a series of operations using a hill climbing strategy to find a (local) maximum of the score function. This setup gives us complete freedom to define scoring functions over the entire document. Moreover, by optionally initialising the state with the output of a traditional DP decoder, we can ensure that the final hypothesis is no worse than what would have been found by DP search alone. We start by describing the decoding algorithm and the state operations used by our decoder, then we present empirical results demonstrating the effectiveness of our approach and its usability with a document-level semantic language model, and finally we discuss some related work. 2 SMT Decoding by Hill Climbing In this section, we formally describe the phrasebased SMT model implemented by our decoder as well as the decoding algorithm we use. 2.1 SMT Model Our decoder is based on local search, so its state at any time is a representation of a complete translation of the entire document. Even though the decoder operates at the document level, it is important to keep 1180 track of sentence boundaries, and the individual operations that are applied to the state are still confined to sentence scope, so it is useful to decompose the state of a document into the state of its sentences, and we define the overall state S as a sequence of sentence states: S = S1S2 . . .SN, (1) where N is the number of sentences. This implies that we constrain the decoder to emit exactly one output sentence per input sentence. Let ibe the number of a sentence and mi the number of input tokens of this sentence, p and q (with 1 ≤ p ≤ q ≤ mi) be positions in the input sentence a1n ≤d [p; q] qde ≤no mte the set ofpositions from p up to and including q. We say that [p; q] precedes [p0; q0], or [p; q] ≺ [p0; q0], if q < p0. Let Φi([p; q]) be the set of t[pra;nqs]l ≺atio [pns for the source phrase covering positions [p; q] in the input sentence ias given by the phrase table. We call A = h[p; q] ,φi an anchored phrase pair w.it Wh coverage C(A) = [p; q] nif a φ ∈ Φi([p; q]) sise a target phrase translating =th [ep source w∈o Φrds at positions [p; q] . Then a sequence of ni anchored phrase pairs Si = A1A2 . . .Ani (2) is a valid sentence state for sentence iif the following two conditions hold: 1. The coverage sets C(Aj) for j in 1, . . . , ni are mutually disjoint, and 2. the anchored phrase pairs jointly cover the complete input sentence, or [niC(Aj) = [1;mi]. (3) [j=1 Let f(S) be a scoring function mapping a state S to a real number. As usual in SMT, it is assumed that the scoring function can be decomposed into a linear combination of K feature functions hk(S), each with a constant weight λk, so f(S) =k∑K=1λkhk(S). (4) The problem addressed by the decoder is the search for the state with maximal score, such that Sˆ Sˆ = argSmaxf(S). (5) The feature functions implemented in our baseline system are identical to the ones found in the popular Moses SMT system (Koehn et al., 2007). In particular, our decoder has the following feature functions: 1. phrase translation scores provided by the phrase table including forward and backward conditional probabilities, lexical weights and a phrase penalty (Koehn et al., 2003), 2. n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3. a word penalty score, 4. a distortion model with geometric (Koehn et al., 2003), and decay 5. a feature indicating the number of times a given distortion limit is exceeded in the current state. In our experiments, the last feature is used with a fixed weight of negative infinity in order to limit the gaps between the coverage sets of adjacent anchored phrase pairs to a maximum value. In DP search, the distortion limit is usually enforced directly by the search algorithm and is not added as a feature. In our decoder, however, this restriction is not required to limit complexity, so we decided to add it among the scoring models. 2.2 Decoding Algorithm The decoding algorithm we use (algorithm 1) is very simple. It starts with a given initial document state. In the main loop, which extends from line 3 to line 12, it generates a successor state S0 for the current state S by calling the function Neighbour, which non-deterministically applies one of the operations described in section 3 of this paper to S. The score of the new state is compared to that of the previous one. If it meets a given acceptance criterion, S0 becomes the current state, else search continues from the previous state S. For the experiments in this paper, we use the hill climbing acceptance criterion, which simply accepts a new state if its score is higher than that of the current state. Other acceptance criteria are possible and could be used to endow the search algorithm with stochastic behaviour. 1181 The main loop is repeated until a maximum number of steps (step limit) is reached or until a maximum number of moves are rejected in a row (rejection limit). Algorithm 1 Decoding algorithm Input: an initial document state S; search parameters maxsteps and maxrejected Output: a modified document state 1: nsteps ← 0 2: nrejected ← 0 3: nwrhejileec nsteps < maxsteps and nrejected < maxrejected do 4: S0 ← Neighbour (S) 5: if Accept (f(S0) , f(S)) then 6: S ← S0 7: nrejected ← 0 8: elsner 9: nrejected ← nrejected + 1 10: enndr eifj 11: nsteps ← nsteps + 1 12: ennds wtephsile ← 13: return S A notable difference between this algorithm and other hill climbing algorithms that have been used for SMT decoding (Germann et al., 2004; Langlais et al., 2007) is its non-determinism. Previous work for sentence-level decoding employed a steepest ascent strategy which amounts to enumerating the complete neighbourhood of the current state as defined by the state operations and selecting the next state to be the best state found in the neighbourhood of the current one. Enumerating all neighbours of a given state, costly as it is, has the advantage that it makes it easy to prove local optimality of a state by recognising that all possible successor states have lower scores. It can be rather inefficient, since at every step only one modification will be adopted; many of the modifications that are discarded will very likely be generated anew in the next iteration. As we extend the decoder to the document level, the size of the neighbourhood that would have to be explored in this way increases considerably. Moreover, the inefficiency of the steepest ascent approach potentially increases as well. Very likely, a promising move in one sentence will remain promising after a modification has been applied to another sentence, even though this is not guaranteed to be true in the presence of cross-sentence models. We therefore adopt a first-choice hill climbing strategy that non-deterministically generates successor states and accepts the first one that meets the acceptance criterion. This frees us from the necessity of generating the full set of successors for each state. On the downside, if the full successor set is not known, it is no longer possible to prove local optimality of a state, so we are forced to use a different condition for halting the search. We use a combination of two limits: The step limit is a hard limit on the resources the user is willing to expend on the search problem. The value of the rejection limit determines how much of the neighbourhood is searched for better successors before a state is accepted as a solution; it is related to the probability that a state returned as a solution is in fact locally optimal. To simplify notations in the description of the individual state operations, we write Si −→ Si0 (6) to signify that a state operation, when presented with a document state as in equation 1 and acting on sentence i, returns a new document state of S0 = S1 . . .Si−1 Si0 Si+1 . . .SN. (7) Similarly, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (8) is equivalent to Si −→ A1 . . .Aj−1 A01 . . .A0h0 Aj+h . . .Ani (9) and indicates that the operation returns a state in which a sequence of h consecutive anchored phrase pairs has been replaced by another sequence of h0 anchored phrase pairs. 2.3 Efficiency Considerations When implementing the feature functions for the decoder, we have to exercise some care to avoid recomputing scores for the whole document at every iteration. To achieve this, the scores are computed completely only once, at the beginning of the decoding run. In subsequent iterations, scoring functions are presented with the scores of the previous 1182 iteration and a list of modifications produced by the state operation, a set of tuples hi, r, s,A01 . . .A0h0i, each indicating tthioant ,t ahe s edto ocfu tmupelnets s hhio,ru,sld, Abe modifii,e eda as described by Si :Ar . . .As −→ A01 . . .A0h0 . (10) If a feature function is decomposable in some way, as all the standard features developed under the constraints of DP search are, it can then update the state simply by subtracting and adding score components pertaining to the modified parts of the document. Feature functions have the possibility to store their own state information along with the document state to make sure the required information is available. Thus, the framework makes it possible to exploit decomposability for efficient scoring without impos- ing any particular decomposition on the features as beam search does. To make scoring even more efficient, scores are computed in two passes: First, every feature function is asked to provide an upper bound on the score that will be obtained for the new state. In some cases, it is possible to calculate reasonable upper bounds much more efficiently than computing the exact feature value. If the upper bound fails to meet the acceptance criterion, the new state is discarded right away; if not, the full score is computed and the acceptance criterion is tested again. Among the basic SMT models, this two-pass strategy is only used for the n-gram LM, which requires fairly expensive parameter lookups for scoring. The scores of all the other baseline models are fully computed during the first scoring pass. The n-gram model is more complex. In its state information, it keeps track of the LM score and LM library state for each word. The first scoring pass then identifies the words whose LM scores are affected by the current search step. This includes the words changed by the search operation as well as the words whose LM history is modified. The range of the history de- pendencies can be determined precisely by considering the “valid state length” information provided by the KenLM library. In the first pass, the LM scores of the affected words are subtracted from the total score. The model only looks up the new LM scores for the affected words and updates the total score if the new search state passes the first acceptance check. This two-pass scoring approach allows us to avoid LM lookups altogether for states that will be rejected anyhow because of low scores from the other models, e. g. because the distortion limit is violated. Model score updates become more complex and slower as the number of dependencies of a model increases. While our decoding algorithm does not impose any formal restrictions on the number or type of dependencies that can be handled, there will be practical limits beyond which decoding becomes unacceptably slow or the scoring code becomes very difficult to maintain. These limits are however fairly independent of the types of dependencies handled by a model, which permits the exploration of more varied model types than those handled by DP search. 2.4 State Initialisation Before the hill climbing decoding algorithm can be run, an initial state must be generated. The closer the initial state is to an optimum, the less work remains to be done for the algorithm. If the algorithm is to be self-contained, initialisation must be relatively uninformed and can only rely on some general prior assumptions about what might be a good initial guess. On the other hand, if optimal results are sought after, it pays off to invest some effort into a good starting point. One way to do this is to run DP search first. For uninformed initialisation, we chose to implement a very simple procedure based only on the observation that, at least for language pairs involving the major European languages, it is usually a good guess to keep the word order of the output very similar to that of the input. We therefore create the initial state by selecting, for each sentence in the document, a sequence of anchored phrase pairs covering the input sentence in monotonic order, that is, such that for all pairs of adjacent anchored phrase pairs Aj and Aj+1, we have that C(Aj) ≺ C(Aj+1 ). For initialisation with DP search, we first run the Moses decoder (Koehn et al., 2007) with default search parameters and the same models as those used by our decoder. Then we extract the best output hypothesis from the search graph of the decoder and map it into a sequence of anchored phrase pairs in the obvious way. When the document-level decoder is used with models that are incompatible with beam search, Moses can be run with a subset of the models in order to find an approximation of the solution 1183 which is then refined with the complete feature set. 3 State Operations Given a document state S, the decoder uses a neighbourhood function Neighbour to simulate a move in the state space. The neighbourhood function nondeterministically selects a type of state operation and a location in the document to apply it to and returns the resulting new state. We use a set of three operations that has the property that every possible document state can be reached from every other state in a sequence of moves. Designing operations for state transitions in local search for phrase-based SMT is a problem that has been addressed in the literature (Langlais et al., 2007; Arun et al., 2010). Our decoder’s first- choice hill climbing strategy never enumerates the full neighbourhood of a state. We therefore place less emphasis than previous work on defining a compact neighbourhood, but allow the decoder to make quite extensive changes to a state in a single step with a certain probability. Otherwise our operations are similar to those used by Arun et al. (2010). All of the operations described in this paper make changes to a single sentence only. Each time it is called, the Neighbour function selects a sentence in the document with a probability proportional to the number of input tokens in each sentence to ensure a fair distribution ofthe decoder’s attention over the words in the document regardless of varying sentence lengths. 3.1 Changing Phrase Translations The change-phrase-translation operation replaces the translation of a single phrase with a random translation with the same coverage taken from the phrase table. Formally, the operation selects an anchored phrase pair Aj by drawing uniformly from the elements of Si and then draws a new translation φ0 uniformly from the set Φi(C(Aj)). The new state is given by Si : Aj −→ hC(Aj), φ0i. (11) 3.2 Changing Word Order The swap-phrases operation affects the output word order without changing the phrase translations. It exchanges two anchored phrase pairs Aj and Aj+h, resulting in an output state of Si : Aj . . .Aj+h −→ Aj+h Aj+1 . . .Aj+h−1 Aj. (12) The start location j is drawn uniformly from the eligible sentence positions; the swap range h comes from a geometric distribution with configurable decay. Other word-order changes such as a one-way move operation that does not require another movement in exchange or more advanced permutations can easily be defined. 3.3 Resegmentation The most complex operation is resegment, which allows the decoder to modify the segmentation ofthe source phrase. It takes a number of anchored phrase pairs that form a contiguous block both in the input and in the output and replaces them with a new set of phrase pairs covering the same span of the input sentence. Formally, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (13) such that j+[h−1 [h0 [ C(Aj0) = [ C(A0j0) = [p;q] j[0=j (14) j[0=1 for some p and q, where, for j0 = 1, . . . ,h0, we have that A0j0 = h[pj0; qj0] , φj0i, all [pj0; qj0] are mutually disjoint =an hd[ peach φj0 isi randomly drawn from Φi([pj0;qj0]). Regardless of the ordering of Aj . . .Aj+h−1 , the resegment operation always generates a sequence of anchored phrase pairs in linear order, such that C(A0j0) ≺ C(A0j0+1 ) for j0 = 1, . . . ,h0 −1 . As )f o≺r Cth(eA other operations, j is− generated uniformly and h is drawn from a geometric distribution with a decay parameter. The new segmentation is generated by extending the sequence of anchored phrase pairs with random elements starting at the next free position, proceeding from left to right until the whole range [p; q] is covered. 4 Experimental Results In this section, we present the results of a series of experiments with our document decoder. The 1184 goal of our experiments is to demonstrate the behaviour of the decoder and characterise its response to changes in the fundamental search parameters. The SMT models for our experiments were created with a subset of the training data for the English-French shared task at the WMT 2011workshop (Callison-Burch et al., 2011). The phrase table was trained on Europarl, news-commentary and UN data. To reduce the training data to a manageable size, singleton phrase pairs were removed before the phrase scoring step. Significance-based filtering (Johnson et al., 2007) was applied to the resulting phrase table. The language model was a 5gram model with Kneser-Ney smoothing trained on the monolingual News corpus with IRSTLM (Federico et al., 2008). Feature weights were trained with Minimum Error-Rate Training (MERT) (Och, 2003) on the news-test2008 development set using the DP beam search decoder and the MERT implementation of the Moses toolkit (Koehn et al., 2007). Experimental results are reported for the newstest2009 test set, a corpus of 111 newswire documents totalling 2,525 sentences or 65,595 English input tokens. 4.1 Stability An important difference between our decoder and the classical DP decoder as well as previous work in SMT decoding with local search is that our decoder is inherently non-deterministic. This implies that repeated runs of the decoder with the same search parameters, input and models will not, in general, find the same local maximum of the score space. The first empirical question we ask is therefore how different the results are under repeated runs. The results in this and the next section were obtained with random state initialisation, i. e. without running the DP beam search decoder. Figure 1 shows the results of 7 decoder runs with the models described above, translating the newstest2009 test set, with a step limit of 227 and a rejection limit of 100,000. The x-axis of both plots shows the number of decoding steps on a logarithmic scale, so the number of steps is doubled between two adjacent points on the same curve. In the left plot, the y-axis indicates the model score optimised by the decoder summed over all 2525 sentences of the document. In the right plot, the case-sensitive BLEU score (Papineni et al., 2002) of the current decoder Figure 1: Score stability in repeated decoder runs state against a reference translation is displayed. We note, as expected, that the decoder achieves a considerable improvement of the initial state with diminishing returns as decoding continues. Between 28 and 214 steps, the score increases at a roughly logarithmic pace, then the curve flattens out, which is partly due to the fact that decoding for some documents effectively stopped when the maximum number of rejections was reached. The BLEU score curve shows a similar increase, from an initial score below 5 % to a maximum of around 21.5 %. This is below the score of 22.45 % achieved by the beam search decoder with the same models, which is not surprising considering that our decoder approximates a more difficult search problem, from which a number of strong independence assumptions have been lifted, without, at the moment, having any stronger models at its disposal to exploit this additional freedom for better translation. In terms of stability, there are no dramatic differences between the decoder runs. Indeed, the small differences that exist are hardly discernible in the plots. The model scores at the end of the decoding run range between −158767.9 and −158716.9, a g re rlautniv rea ndgieffe breetnwceee nof − only a6b7.o9ut a n0d.0 −3 %15.8 F1i6n.a9l, BLEU scores range from 21.41 % to 21.63 %, an interval that is not negligible, but comparable to the variance observed when, e. g., feature weights from repeated MERT runs are used with one and the same SMT system. Note that these results were obtained with random state initialisation. With DP initialisation, score differences between repeated runs rarely 1185 exceed 0.02 absolute BLEU percentage points. Overall, we conclude that the decoding results of our algorithm are reasonably stable despite the nondeterminism inherent in the procedure. In our subsequent experiments, the evaluation scores reported are calculated as the mean of three runs for each experiment. 4.2 Search Algorithm Parameters The hill climbing algorithm we use has two parameters which govern the trade-off between decoding time and the accuracy with which a local maximum is identified: The step limit stops the search process after a certain number of steps regardless of the search progress made or lack thereof. The rejection limit stops the search after a certain number of unsuccessful attempts to make a step, when continued search does not seem to be promising. In most of our experiments, we used a step limit of 227 ≈ 1.3 · 108 and a rejection limit of 105. In practice, decoding terminates by reaching the rejection limit for the vast majority of documents. We therefore examined the effect of different rejection limits on the learning curves. The results are shown in figure 2. The results show that continued search does pay off to a certain extent. Indeed, the curve for rejection limit 107 seems to indicate that the model score increases roughly logarithmically, albeit to a higher base, even after the curve has started to flatten out at 214 steps. At a certain point, however, the probability of finding a good successor state drops rather sharply by about two orders of magnitude, as Figure 2: Search performance at different rejection limits evidenced by the fact that a rejection limit of 106 does not give a large improvement over one of 105, while one of 107 does. The continued model score improvement also results in an increase in BLEU scores, and with a BLEU score of 22. 1% the system with rejection limit 107 is fairly close to the score of 22.45 % obtained by DP beam search. Obviously, more exact search comes at a cost, and in this case, it comes at a considerable cost, which is an explosion of the time required to decode the test set from 4 minutes at rejection limit 103 to 224 minutes at rejection limit 105 and 38 hours 45 minutes at limit 107. The DP decoder takes 3 1 minutes for the same task. We conclude that the rejection limit of 105 selected for our experiments, while technically suboptimal, realises a good trade-off between decoding time and accuracy. 4.3 A Semantic Document Language Model In this section, we present the results of the application of our decoder to an actual SMT model with cross-sentence features. Our model addresses the problem of lexical cohesion. In particular, it rewards the use of semantically related words in the translation output by the decoder, where semantic distance is measured with a word space model based on Latent Semantic Analysis (LSA). LSA has been applied to semantic language modelling in previous research with some success (Coccaro and Jurafsky, 1998; Bellegarda, 2000; Wandmacher and Antoine, 2007). In SMT, it has mostly been used for domain adaptation (Kim and Khudanpur, 2004; Tam et al., 1186 2007), or to measure sentence similarities (Banchs and Costa-juss a`, 2011). The model we use is inspired by Bellegarda (2000). It is a Markov model, similar to a standard n-gram model, and assigns to each content word a score given a history of n preceding content words, where n = 30 below. Scoring relies on a 30dimensional LSA word vector space trained with the S-Space software (Jurgens and Stevens, 2010). The score is defined based on the cosine similarity between the word vector of the predicted word and the mean word vector of the words in the history, which is converted to a probability by histogram lookup as suggested by Bellegarda (2000). The model is structurally different from a regular n-gram model in that word vector n-grams are defined over content words occurring in the word vector model only and can cross sentence boundaries. Stop words, identified by an extensive stop word list and amounting to around 60 % of the tokens, are scored by a different mechanism based on their relative frequency (undiscounted unigram probability) in the training corpus. In sum, the score produced by the semantic document LM has the following form: wh(er|h)α=is tεpαheuncipgors(wp)o|hrtinof w fci os nakutneskotn wpon w ,onerldse,in(ls1teh5) training corpus and ε is a small fixed probability. It is integrated into the decoder as an extra feature function. Since we lack an automatic method for training the feature weights of document-wide features, its weight was selected by grid search over a number of values, comparing translation performance for the newstest2009 test set. In these experiments, we used DP beam search to initialise the state of our local search decoder. Three results are presented (table 1): The first table row shows the baseline performance using DP beam search with standard sentence-local features only. The scores in the second row were obtained by running the hill climbing decoder with DP initialisation, but without adding any models. A marginal increase in scores for all three test sets demonstrates that the hill climbing decoder manages to fix some of the search errors made by the DP search. The last row contains the scores obtained by adding in the semantic language model. Scores are presented for three publicly available test sets from recent WMT Machine Translation shared tasks, of which one (newstest2009) was used to monitor progress during development and select the final model. Adding the semantic language model results in a small increase in NIST scores (Doddington, 2002) for all three test sets as well as a small BLEU score gain (Papineni et al., 2002) for two out of three corpora. We note that the NIST score turned out to react more sensitively to improvements due to the semantic LM in all our experiments, which is reasonable because the model specifically targets content words, which benefit from the information weighting done by the NIST score. While the results we present do not constitute compelling evidence in favour of our semantic LM in its current form, they do suggest that this model could be improved to realise higher gains from cross-sentence semantic information. They support our claim that cross- sentence models should be examined more closely and that existing methods should be adapted to deal with them, a problem addressed by our main contribution, the local search document decoder. 5 Related Work Even though DP beam search (Koehn et al., 2003) has been the dominant approach to SMT decoding in recent years, methods based on local search have been explored at various times. For word-based SMT, greedy hill-climbing techniques were advo1187 cated as a faster replacement for beam search (Germann et al., 2001 ; Germann, 2003; Germann et al., 2004), and a problem formulation specifically targeting word reordering with an efficient word reordering algorithm has been proposed (Eisner and Tromble, 2006). A local search decoder has been advanced as a faster alternative to beam search also for phrasebased SMT (Langlais et al., 2007; Langlais et al., 2008). That work anticipates many of the features found in our decoder, including the use of local search to refine an initial hypothesis produced by DP beam search. The possibility of using models that do not fit well into the beam search paradigm is mentioned and illustrated with the example of a reversed n-gram language model, which the authors claim would be difficult to implement in a beam search decoder. Similarly to the work by Germann et al. (2001), their decoder is deterministic and explores the entire neighbourhood of a state in order to identify the most promising step. Our main contribution with respect to the work by Langlais et al. (2007) is the introduction of the possibility of handling document-level models by lifting the assumption of sentence independence. As a consequence, enumerating the entire neighbourhood becomes too expensive, which is why we resort to a “first-choice” strategy that non-deterministically generates states and accepts the first one encountered that meets the acceptance criterion. More recently, Gibbs sampling was proposed as a way to generate samples from the posterior distribution of a phrase-based SMT decoder (Arun et al., 2009; Arun et al., 2010), a process that resembles local search in its use of a set of state-modifying operators to generate a sequence of decoder states. Where local search seeks for the best state attainable from a given initial state, Gibbs sampling produces a representative sample from the posterior. Like all work on SMT decoding that we know of, the Gibbs sampler presented by Arun et al. (2010) assumes independence of sentences and considers the complete neighbourhood of each state before taking a sample. 6 Conclusion In the last twenty years of SMT research, there has been a strong assumption that sentences in a text newstest2009 newstest2010 newstest201 1 BLEU NIST BLEU NIST BLEU NIST 22.56 6.513 27.27 7.034 24.94 7.170 + hill climbing 22.60 6.518 27.33 7.046 24.97 7.169 with semantic LM 22.71 6.549 27.53 7.087 24.90 7.199 DP search only DP Table 1: Experimental results with a cross-sentence semantic language model are independent of one another, and discourse context has been largely neglected. Several factors have contributed to this. Developing good discourse-level models is difficult, and considering the modest translation quality that has long been achieved by SMT, there have been more pressing problems to solve and lower hanging fruit to pick. However, we argue that the popular DP beam search algorithm, which delivers excellent decoding performance, but imposes a particular kind of local dependency structure on the feature models, has also had its share in driving researchers away from discourse-level problems. In this paper, we have presented a decoding procedure for phrase-based SMT that makes it possible to define feature models with cross-sentence dependencies. Our algorithm can be combined with DP beam search to leverage the quality of the traditional approach with increased flexibility for models at the discourse level. We have presented preliminary results on a cross-sentence semantic language model addressing the problem of lexical cohesion to demonstrate that this kind of models is worth exploring further. Besides lexical cohesion, cross-sentence models are relevant for other linguistic phenomena such as pronominal anaphora or verb tense selection. We believe that SMT research has reached a point of maturity where discourse phenomena should not be ignored any longer, and we consider our decoder to be a step towards this goal. References Abhishek Arun, Chris Dyer, Barry Haddow, Phil Blunsom, Adam Lopez, and Philipp Koehn. 2009. Monte carlo inference and maximization for phrase-based translation. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009), pages 102–1 10, Boulder, Colorado, June. Association for Computational Linguistics. Abhishek Arun, Barry Haddow, Philipp Koehn, Adam Lopez, Chris Dyer, and Phil Blunsom. 2010. Monte 1188 Ma- Carlo techniques for phrase-based translation. chine translation, 24(2): 103–121 . Rafael E. Banchs and Marta R. Costa-juss a`. 2011. A semantic feature for Statistical Machine Translation. In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 126– 134, Portland, Oregon, USA, June. Association for Computational Linguistics. Jerome R. Bellegarda. 2000. Exploiting latent semantic information in statistical language modeling. Proceedings of the IEEE, 88(8): 1279–1296. Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar Zaidan. 2011. Findings of the 2011 Workshop on Statistical Machine Translation. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 22–64, Edinburgh, Scotland, July. Association for Computational Linguistics. Noah Coccaro and Daniel Jurafsky. 1998. Towards better integration of semantic predictors in statistical language modeling. In Proceedings of the 5th International Conference on Spoken Language Processing, Sydney. George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proceedings of the second International conference on Human Language Technology Research, pages 138–145, San Diego. Jason Eisner and Roy W. Tromble. 2006. Local search with very large-scale neighborhoods for optimal permutations in machine translation. In Proceedings of the HLT-NAACL Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing, pages 57–75. Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In Interspeech 2008, pages 1618–1621 . ISCA. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2001 . Fast decoding and optimal decoding for machine translation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 228–235, Toulouse, France, July. Association for Computational Linguis- tics. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2004. Fast and optimal decoding for machine translation. Artificial Intelligence, 154(1–2): 127–143. Ulrich Germann. 2003. Greedy decoding for Statistical Machine Translation in almost linear time. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. Zhengxian Gong, Min Zhang, and Guodong Zhou. 2011. Cache-based document-level Statistical Machine Translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 909–919, Edinburgh, Scotland, UK., July. Association for Computational Linguistics. Christian Hardmeier and Marcello Federico. 2010. Modelling Pronominal Anaphora in Statistical Machine Translation. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 283–289. Basil Hatim and Ian Mason. 1990. Discourse and the Translator. Language in Social Life Series. Longman, London. Kenneth Heafield. 2011. KenLM: faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, July. Association for Computational Linguistics. Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 967– 975, Prague, Czech Republic, June. Association for Computational Linguistics. David Jurgens and Keith Stevens. 2010. The S-Space package: An open source package for word space models. In Proceedings of the ACL 2010 System Demonstrations, pages 30–35, Uppsala, Sweden, July. Association for Computational Linguistics. Woosung Kim and Sanjeev Khudanpur. 2004. Crosslingual latent semantic analysis for language modeling. In IEEE international conference on acoustics, speech, and signal processing (ICASSP), volume 1, pages 257–260, Montr ´eal. Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 conference of the North American chapter of the Association for Computational Linguistics on Human Language Technology, pages 48– 54, Edmonton. 1189 Philipp Koehn, Hieu Hoang, Alexandra Birch, et al. 2007. Moses: open source toolkit for Statistical Machine Translation. In Annual meeting of the Association for Computational Linguistics: Demonstration session, pages 177–180, Prague. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2007. A greedy decoder for phrase-based statistical machine translation. In TMI-2007: Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 104–1 13, Sk¨ ovde. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2008. Recherche locale pour la traduction statistique par segments. In TALN 2008, pages 119–128, Avignon, France, June. ATALA. Ronan Le Nagard and Philipp Koehn. 2010. Aiding pronoun translation with co-reference resolution. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 252–261, Uppsala, Sweden, July. Association for Computational Linguistics. Franz Josef Och, Nicola Ueffing, and Hermann Ney. 2001. An efficient A* search algorithm for Statistical Machine Translation. In Proceedings of the DataDriven Machine Translation Workshop, 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 55–62, Toulouse. Franz Josef Och. 2003. Minimum error rate training in Statistical Machine Translation. In Proceedings of the 41st annual meeting of the Association for Computational Linguistics, pages 160–167, Sapporo (Japan). Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of Machine Translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 3 11–3 18, Philadelphia. ACL. Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007. Bilingual LSA-based adaptation for Statistical Machine Translation. Machine Translation, 21(4): 187– 207. J o¨rg Tiedemann. 2010. To cache or not to cache? Experiments with adaptive models in Statistical Machine Translation. In Proceedings of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and Metrics MATR, pages 189–194, Uppsala, Sweden. Association for Computational Linguistics. Christoph Tillmann and Hermann Ney. 2003. Word reordering and a Dynamic Programming beam search algorithm for Statistical Machine Translation. Computational linguistics, 29(1):97–133. Christoph Tillmann, Stephan Vogel, Hermann Ney, and Alex Zubiaga. 1997. A DP-based search using monotone alignments in Statistical Translation. In Proceedings of the 35th Annual Meeting of the Association for Computational Spain, tics. Linguistics, July. Association for 289–296, Madrid, Computational Linguis- pages Tonio Wandmacher and Jean-Yves Antoine. 2007. Methods to integrate a language model with semantic information for a word prediction component. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 506–5 13, Prague, Czech Republic, June. Association for Computational Linguistics. 1190</p><p>2 0.29756638 <a title="35-tfidf-2" href="./emnlp-2012-A_Beam-Search_Decoder_for_Grammatical_Error_Correction.html">2 emnlp-2012-A Beam-Search Decoder for Grammatical Error Correction</a></p>
<p>Author: Daniel Dahlmeier ; Hwee Tou Ng</p><p>Abstract: We present a novel beam-search decoder for grammatical error correction. The decoder iteratively generates new hypothesis corrections from current hypotheses and scores them based on features of grammatical correctness and fluency. These features include scores from discriminative classifiers for specific error categories, such as articles and prepositions. Unlike all previous approaches, our method is able to perform correction of whole sentences with multiple and interacting errors while still taking advantage of powerful existing classifier approaches. Our decoder achieves an F1 correction score significantly higher than all previous published scores on the Helping Our Own (HOO) shared task data set.</p><p>3 0.24397177 <a title="35-tfidf-3" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>Author: Yang Feng ; Yang Liu ; Qun Liu ; Trevor Cohn</p><p>Abstract: Decoding algorithms for syntax based machine translation suffer from high computational complexity, a consequence of intersecting a language model with a context free grammar. Left-to-right decoding, which generates the target string in order, can improve decoding efficiency by simplifying the language model evaluation. This paper presents a novel left to right decoding algorithm for tree-to-string translation, using a bottom-up parsing strategy and dynamic future cost estimation for each partial translation. Our method outperforms previously published tree-to-string decoders, including a competing left-to-right method.</p><p>4 0.20183611 <a title="35-tfidf-4" href="./emnlp-2012-Exact_Sampling_and_Decoding_in_High-Order_Hidden_Markov_Models.html">43 emnlp-2012-Exact Sampling and Decoding in High-Order Hidden Markov Models</a></p>
<p>Author: Simon Carter ; Marc Dymetman ; Guillaume Bouchard</p><p>Abstract: We present a method for exact optimization and sampling from high order Hidden Markov Models (HMMs), which are generally handled by approximation techniques. Motivated by adaptive rejection sampling and heuristic search, we propose a strategy based on sequentially refining a lower-order language model that is an upper bound on the true model we wish to decode and sample from. This allows us to build tractable variable-order HMMs. The ARPA format for language models is extended to enable an efficient use of the max-backoff quantities required to compute the upper bound. We evaluate our approach on two problems: a SMS-retrieval task and a POS tagging experiment using 5-gram models. Results show that the same approach can be used for exact optimization and sampling, while explicitly constructing only a fraction of the total implicit state-space.</p><p>5 0.19338949 <a title="35-tfidf-5" href="./emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">86 emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<p>Author: Lemao Liu ; Hailong Cao ; Taro Watanabe ; Tiejun Zhao ; Mo Yu ; Conghui Zhu</p><p>Abstract: In statistical machine translation, minimum error rate training (MERT) is a standard method for tuning a single weight with regard to a given development data. However, due to the diversity and uneven distribution of source sentences, there are two problems suffered by this method. First, its performance is highly dependent on the choice of a development set, which may lead to an unstable performance for testing. Second, translations become inconsistent at the sentence level since tuning is performed globally on a document level. In this paper, we propose a novel local training method to address these two problems. Unlike a global training method, such as MERT, in which a single weight is learned and used for all the input sentences, we perform training and testing in one step by learning a sentencewise weight for each input sentence. We pro- pose efficient incremental training methods to put the local training into practice. In NIST Chinese-to-English translation tasks, our local training method significantly outperforms MERT with the maximal improvements up to 2.0 BLEU points, meanwhile its efficiency is comparable to that of the global method.</p><p>6 0.16808006 <a title="35-tfidf-6" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>7 0.16746548 <a title="35-tfidf-7" href="./emnlp-2012-Translation_Model_Based_Cross-Lingual_Language_Model_Adaptation%3A_from_Word_Models_to_Phrase_Models.html">128 emnlp-2012-Translation Model Based Cross-Lingual Language Model Adaptation: from Word Models to Phrase Models</a></p>
<p>8 0.15062207 <a title="35-tfidf-8" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>9 0.14207472 <a title="35-tfidf-9" href="./emnlp-2012-Generalized_Higher-Order_Dependency_Parsing_with_Cube_Pruning.html">57 emnlp-2012-Generalized Higher-Order Dependency Parsing with Cube Pruning</a></p>
<p>10 0.13555595 <a title="35-tfidf-10" href="./emnlp-2012-Language_Model_Rest_Costs_and_Space-Efficient_Storage.html">74 emnlp-2012-Language Model Rest Costs and Space-Efficient Storage</a></p>
<p>11 0.12507014 <a title="35-tfidf-11" href="./emnlp-2012-A_Systematic_Comparison_of_Phrase_Table_Pruning_Techniques.html">11 emnlp-2012-A Systematic Comparison of Phrase Table Pruning Techniques</a></p>
<p>12 0.1156121 <a title="35-tfidf-12" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>13 0.10728998 <a title="35-tfidf-13" href="./emnlp-2012-Inducing_a_Discriminative_Parser_to_Optimize_Machine_Translation_Reordering.html">67 emnlp-2012-Inducing a Discriminative Parser to Optimize Machine Translation Reordering</a></p>
<p>14 0.10312881 <a title="35-tfidf-14" href="./emnlp-2012-A_Bayesian_Model_for_Learning_SCFGs_with_Discontiguous_Rules.html">1 emnlp-2012-A Bayesian Model for Learning SCFGs with Discontiguous Rules</a></p>
<p>15 0.09579888 <a title="35-tfidf-15" href="./emnlp-2012-Cross-Lingual_Language_Modeling_with_Syntactic_Reordering_for_Low-Resource_Speech_Recognition.html">31 emnlp-2012-Cross-Lingual Language Modeling with Syntactic Reordering for Low-Resource Speech Recognition</a></p>
<p>16 0.092426404 <a title="35-tfidf-16" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>17 0.090549678 <a title="35-tfidf-17" href="./emnlp-2012-Generating_Non-Projective_Word_Order_in_Statistical_Linearization.html">59 emnlp-2012-Generating Non-Projective Word Order in Statistical Linearization</a></p>
<p>18 0.090019956 <a title="35-tfidf-18" href="./emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">70 emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>19 0.086739898 <a title="35-tfidf-19" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<p>20 0.086663723 <a title="35-tfidf-20" href="./emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">12 emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.281), (1, -0.225), (2, -0.155), (3, -0.048), (4, -0.29), (5, -0.088), (6, -0.117), (7, -0.075), (8, 0.089), (9, -0.058), (10, 0.099), (11, -0.143), (12, 0.239), (13, 0.062), (14, -0.123), (15, 0.089), (16, 0.042), (17, -0.093), (18, -0.185), (19, 0.196), (20, -0.08), (21, 0.178), (22, 0.048), (23, 0.007), (24, -0.014), (25, 0.01), (26, 0.029), (27, -0.071), (28, -0.013), (29, 0.093), (30, -0.02), (31, 0.063), (32, 0.01), (33, -0.007), (34, 0.069), (35, -0.051), (36, 0.041), (37, -0.034), (38, 0.005), (39, 0.05), (40, -0.147), (41, -0.026), (42, -0.031), (43, -0.021), (44, 0.021), (45, -0.004), (46, 0.014), (47, 0.011), (48, -0.003), (49, -0.069)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95013654 <a title="35-lsi-1" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>Author: Christian Hardmeier ; Joakim Nivre ; Jorg Tiedemann</p><p>Abstract: Independence between sentences is an assumption deeply entrenched in the models and algorithms used for statistical machine translation (SMT), particularly in the popular dynamic programming beam search decoding algorithm. This restriction is an obstacle to research on more sophisticated discourse-level models for SMT. We propose a stochastic local search decoding method for phrase-based SMT, which permits free document-wide dependencies in the models. We explore the stability and the search parameters ofthis method and demonstrate that it can be successfully used to optimise a document-level semantic language model. 1 Motivation In the field oftranslation studies, it is undisputed that discourse-wide context must be considered care- fully for good translation results (Hatim and Mason, 1990). By contrast, the state of the art in statistical machine translation (SMT), despite significant advances in the last twenty years, still assumes that texts can be translated sentence by sentence under strict independence assumptions, even though it is well known that certain linguistic phenomena such as pronominal anaphora cannot be translated correctly without referring to extra-sentential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm 1179 which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001 ; Tillmann and Ney, 2003). This algorithm con- structs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elimination of hypotheses from the search space if they coincide in a certain number of final words with a better hypothesis and no future expansion can possibly invert the relative ranking of the two hypotheses under the given models. Hypothesis recombination achieves a substantial reduction of the search space without affecting search optimality and makes it possible to use aggressive pruning techniques for fast search while still obtaining good results. The downside of this otherwise excellent approach is that it only works well with models that have a local dependency structure similar to that of an n-gram language model, so they only depend on a small context window for each target word. Sentence-local models with longer dependencies can be added, but doing so greatly increases the risk for search errors by inhibiting hypothesis recombination. Cross-sentence dependencies cannot be directly integrated into DP SMT decoding in LParnogcue agdein Lgesa ornf tihneg, 2 p0a1g2e Jso 1in17t C9–o1n1f9e0re,n Jce ju on Is Elanmdp,ir Kicoarlea M,e 1t2h–o1d4s J iunly N 2a0tu1r2a.l ? Lc a2n0g1u2ag Aes Psorcoicaetsiosin fgo arn Cdo Cmopmutpauti oantiaoln Lailn Ngautiustriacls any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required. Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems. Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (201 1), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences. In this paper, we present a method for decoding complete documents in phrase-based SMT. Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by the application of a series of operations using a hill climbing strategy to find a (local) maximum of the score function. This setup gives us complete freedom to define scoring functions over the entire document. Moreover, by optionally initialising the state with the output of a traditional DP decoder, we can ensure that the final hypothesis is no worse than what would have been found by DP search alone. We start by describing the decoding algorithm and the state operations used by our decoder, then we present empirical results demonstrating the effectiveness of our approach and its usability with a document-level semantic language model, and finally we discuss some related work. 2 SMT Decoding by Hill Climbing In this section, we formally describe the phrasebased SMT model implemented by our decoder as well as the decoding algorithm we use. 2.1 SMT Model Our decoder is based on local search, so its state at any time is a representation of a complete translation of the entire document. Even though the decoder operates at the document level, it is important to keep 1180 track of sentence boundaries, and the individual operations that are applied to the state are still confined to sentence scope, so it is useful to decompose the state of a document into the state of its sentences, and we define the overall state S as a sequence of sentence states: S = S1S2 . . .SN, (1) where N is the number of sentences. This implies that we constrain the decoder to emit exactly one output sentence per input sentence. Let ibe the number of a sentence and mi the number of input tokens of this sentence, p and q (with 1 ≤ p ≤ q ≤ mi) be positions in the input sentence a1n ≤d [p; q] qde ≤no mte the set ofpositions from p up to and including q. We say that [p; q] precedes [p0; q0], or [p; q] ≺ [p0; q0], if q < p0. Let Φi([p; q]) be the set of t[pra;nqs]l ≺atio [pns for the source phrase covering positions [p; q] in the input sentence ias given by the phrase table. We call A = h[p; q] ,φi an anchored phrase pair w.it Wh coverage C(A) = [p; q] nif a φ ∈ Φi([p; q]) sise a target phrase translating =th [ep source w∈o Φrds at positions [p; q] . Then a sequence of ni anchored phrase pairs Si = A1A2 . . .Ani (2) is a valid sentence state for sentence iif the following two conditions hold: 1. The coverage sets C(Aj) for j in 1, . . . , ni are mutually disjoint, and 2. the anchored phrase pairs jointly cover the complete input sentence, or [niC(Aj) = [1;mi]. (3) [j=1 Let f(S) be a scoring function mapping a state S to a real number. As usual in SMT, it is assumed that the scoring function can be decomposed into a linear combination of K feature functions hk(S), each with a constant weight λk, so f(S) =k∑K=1λkhk(S). (4) The problem addressed by the decoder is the search for the state with maximal score, such that Sˆ Sˆ = argSmaxf(S). (5) The feature functions implemented in our baseline system are identical to the ones found in the popular Moses SMT system (Koehn et al., 2007). In particular, our decoder has the following feature functions: 1. phrase translation scores provided by the phrase table including forward and backward conditional probabilities, lexical weights and a phrase penalty (Koehn et al., 2003), 2. n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3. a word penalty score, 4. a distortion model with geometric (Koehn et al., 2003), and decay 5. a feature indicating the number of times a given distortion limit is exceeded in the current state. In our experiments, the last feature is used with a fixed weight of negative infinity in order to limit the gaps between the coverage sets of adjacent anchored phrase pairs to a maximum value. In DP search, the distortion limit is usually enforced directly by the search algorithm and is not added as a feature. In our decoder, however, this restriction is not required to limit complexity, so we decided to add it among the scoring models. 2.2 Decoding Algorithm The decoding algorithm we use (algorithm 1) is very simple. It starts with a given initial document state. In the main loop, which extends from line 3 to line 12, it generates a successor state S0 for the current state S by calling the function Neighbour, which non-deterministically applies one of the operations described in section 3 of this paper to S. The score of the new state is compared to that of the previous one. If it meets a given acceptance criterion, S0 becomes the current state, else search continues from the previous state S. For the experiments in this paper, we use the hill climbing acceptance criterion, which simply accepts a new state if its score is higher than that of the current state. Other acceptance criteria are possible and could be used to endow the search algorithm with stochastic behaviour. 1181 The main loop is repeated until a maximum number of steps (step limit) is reached or until a maximum number of moves are rejected in a row (rejection limit). Algorithm 1 Decoding algorithm Input: an initial document state S; search parameters maxsteps and maxrejected Output: a modified document state 1: nsteps ← 0 2: nrejected ← 0 3: nwrhejileec nsteps < maxsteps and nrejected < maxrejected do 4: S0 ← Neighbour (S) 5: if Accept (f(S0) , f(S)) then 6: S ← S0 7: nrejected ← 0 8: elsner 9: nrejected ← nrejected + 1 10: enndr eifj 11: nsteps ← nsteps + 1 12: ennds wtephsile ← 13: return S A notable difference between this algorithm and other hill climbing algorithms that have been used for SMT decoding (Germann et al., 2004; Langlais et al., 2007) is its non-determinism. Previous work for sentence-level decoding employed a steepest ascent strategy which amounts to enumerating the complete neighbourhood of the current state as defined by the state operations and selecting the next state to be the best state found in the neighbourhood of the current one. Enumerating all neighbours of a given state, costly as it is, has the advantage that it makes it easy to prove local optimality of a state by recognising that all possible successor states have lower scores. It can be rather inefficient, since at every step only one modification will be adopted; many of the modifications that are discarded will very likely be generated anew in the next iteration. As we extend the decoder to the document level, the size of the neighbourhood that would have to be explored in this way increases considerably. Moreover, the inefficiency of the steepest ascent approach potentially increases as well. Very likely, a promising move in one sentence will remain promising after a modification has been applied to another sentence, even though this is not guaranteed to be true in the presence of cross-sentence models. We therefore adopt a first-choice hill climbing strategy that non-deterministically generates successor states and accepts the first one that meets the acceptance criterion. This frees us from the necessity of generating the full set of successors for each state. On the downside, if the full successor set is not known, it is no longer possible to prove local optimality of a state, so we are forced to use a different condition for halting the search. We use a combination of two limits: The step limit is a hard limit on the resources the user is willing to expend on the search problem. The value of the rejection limit determines how much of the neighbourhood is searched for better successors before a state is accepted as a solution; it is related to the probability that a state returned as a solution is in fact locally optimal. To simplify notations in the description of the individual state operations, we write Si −→ Si0 (6) to signify that a state operation, when presented with a document state as in equation 1 and acting on sentence i, returns a new document state of S0 = S1 . . .Si−1 Si0 Si+1 . . .SN. (7) Similarly, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (8) is equivalent to Si −→ A1 . . .Aj−1 A01 . . .A0h0 Aj+h . . .Ani (9) and indicates that the operation returns a state in which a sequence of h consecutive anchored phrase pairs has been replaced by another sequence of h0 anchored phrase pairs. 2.3 Efficiency Considerations When implementing the feature functions for the decoder, we have to exercise some care to avoid recomputing scores for the whole document at every iteration. To achieve this, the scores are computed completely only once, at the beginning of the decoding run. In subsequent iterations, scoring functions are presented with the scores of the previous 1182 iteration and a list of modifications produced by the state operation, a set of tuples hi, r, s,A01 . . .A0h0i, each indicating tthioant ,t ahe s edto ocfu tmupelnets s hhio,ru,sld, Abe modifii,e eda as described by Si :Ar . . .As −→ A01 . . .A0h0 . (10) If a feature function is decomposable in some way, as all the standard features developed under the constraints of DP search are, it can then update the state simply by subtracting and adding score components pertaining to the modified parts of the document. Feature functions have the possibility to store their own state information along with the document state to make sure the required information is available. Thus, the framework makes it possible to exploit decomposability for efficient scoring without impos- ing any particular decomposition on the features as beam search does. To make scoring even more efficient, scores are computed in two passes: First, every feature function is asked to provide an upper bound on the score that will be obtained for the new state. In some cases, it is possible to calculate reasonable upper bounds much more efficiently than computing the exact feature value. If the upper bound fails to meet the acceptance criterion, the new state is discarded right away; if not, the full score is computed and the acceptance criterion is tested again. Among the basic SMT models, this two-pass strategy is only used for the n-gram LM, which requires fairly expensive parameter lookups for scoring. The scores of all the other baseline models are fully computed during the first scoring pass. The n-gram model is more complex. In its state information, it keeps track of the LM score and LM library state for each word. The first scoring pass then identifies the words whose LM scores are affected by the current search step. This includes the words changed by the search operation as well as the words whose LM history is modified. The range of the history de- pendencies can be determined precisely by considering the “valid state length” information provided by the KenLM library. In the first pass, the LM scores of the affected words are subtracted from the total score. The model only looks up the new LM scores for the affected words and updates the total score if the new search state passes the first acceptance check. This two-pass scoring approach allows us to avoid LM lookups altogether for states that will be rejected anyhow because of low scores from the other models, e. g. because the distortion limit is violated. Model score updates become more complex and slower as the number of dependencies of a model increases. While our decoding algorithm does not impose any formal restrictions on the number or type of dependencies that can be handled, there will be practical limits beyond which decoding becomes unacceptably slow or the scoring code becomes very difficult to maintain. These limits are however fairly independent of the types of dependencies handled by a model, which permits the exploration of more varied model types than those handled by DP search. 2.4 State Initialisation Before the hill climbing decoding algorithm can be run, an initial state must be generated. The closer the initial state is to an optimum, the less work remains to be done for the algorithm. If the algorithm is to be self-contained, initialisation must be relatively uninformed and can only rely on some general prior assumptions about what might be a good initial guess. On the other hand, if optimal results are sought after, it pays off to invest some effort into a good starting point. One way to do this is to run DP search first. For uninformed initialisation, we chose to implement a very simple procedure based only on the observation that, at least for language pairs involving the major European languages, it is usually a good guess to keep the word order of the output very similar to that of the input. We therefore create the initial state by selecting, for each sentence in the document, a sequence of anchored phrase pairs covering the input sentence in monotonic order, that is, such that for all pairs of adjacent anchored phrase pairs Aj and Aj+1, we have that C(Aj) ≺ C(Aj+1 ). For initialisation with DP search, we first run the Moses decoder (Koehn et al., 2007) with default search parameters and the same models as those used by our decoder. Then we extract the best output hypothesis from the search graph of the decoder and map it into a sequence of anchored phrase pairs in the obvious way. When the document-level decoder is used with models that are incompatible with beam search, Moses can be run with a subset of the models in order to find an approximation of the solution 1183 which is then refined with the complete feature set. 3 State Operations Given a document state S, the decoder uses a neighbourhood function Neighbour to simulate a move in the state space. The neighbourhood function nondeterministically selects a type of state operation and a location in the document to apply it to and returns the resulting new state. We use a set of three operations that has the property that every possible document state can be reached from every other state in a sequence of moves. Designing operations for state transitions in local search for phrase-based SMT is a problem that has been addressed in the literature (Langlais et al., 2007; Arun et al., 2010). Our decoder’s first- choice hill climbing strategy never enumerates the full neighbourhood of a state. We therefore place less emphasis than previous work on defining a compact neighbourhood, but allow the decoder to make quite extensive changes to a state in a single step with a certain probability. Otherwise our operations are similar to those used by Arun et al. (2010). All of the operations described in this paper make changes to a single sentence only. Each time it is called, the Neighbour function selects a sentence in the document with a probability proportional to the number of input tokens in each sentence to ensure a fair distribution ofthe decoder’s attention over the words in the document regardless of varying sentence lengths. 3.1 Changing Phrase Translations The change-phrase-translation operation replaces the translation of a single phrase with a random translation with the same coverage taken from the phrase table. Formally, the operation selects an anchored phrase pair Aj by drawing uniformly from the elements of Si and then draws a new translation φ0 uniformly from the set Φi(C(Aj)). The new state is given by Si : Aj −→ hC(Aj), φ0i. (11) 3.2 Changing Word Order The swap-phrases operation affects the output word order without changing the phrase translations. It exchanges two anchored phrase pairs Aj and Aj+h, resulting in an output state of Si : Aj . . .Aj+h −→ Aj+h Aj+1 . . .Aj+h−1 Aj. (12) The start location j is drawn uniformly from the eligible sentence positions; the swap range h comes from a geometric distribution with configurable decay. Other word-order changes such as a one-way move operation that does not require another movement in exchange or more advanced permutations can easily be defined. 3.3 Resegmentation The most complex operation is resegment, which allows the decoder to modify the segmentation ofthe source phrase. It takes a number of anchored phrase pairs that form a contiguous block both in the input and in the output and replaces them with a new set of phrase pairs covering the same span of the input sentence. Formally, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (13) such that j+[h−1 [h0 [ C(Aj0) = [ C(A0j0) = [p;q] j[0=j (14) j[0=1 for some p and q, where, for j0 = 1, . . . ,h0, we have that A0j0 = h[pj0; qj0] , φj0i, all [pj0; qj0] are mutually disjoint =an hd[ peach φj0 isi randomly drawn from Φi([pj0;qj0]). Regardless of the ordering of Aj . . .Aj+h−1 , the resegment operation always generates a sequence of anchored phrase pairs in linear order, such that C(A0j0) ≺ C(A0j0+1 ) for j0 = 1, . . . ,h0 −1 . As )f o≺r Cth(eA other operations, j is− generated uniformly and h is drawn from a geometric distribution with a decay parameter. The new segmentation is generated by extending the sequence of anchored phrase pairs with random elements starting at the next free position, proceeding from left to right until the whole range [p; q] is covered. 4 Experimental Results In this section, we present the results of a series of experiments with our document decoder. The 1184 goal of our experiments is to demonstrate the behaviour of the decoder and characterise its response to changes in the fundamental search parameters. The SMT models for our experiments were created with a subset of the training data for the English-French shared task at the WMT 2011workshop (Callison-Burch et al., 2011). The phrase table was trained on Europarl, news-commentary and UN data. To reduce the training data to a manageable size, singleton phrase pairs were removed before the phrase scoring step. Significance-based filtering (Johnson et al., 2007) was applied to the resulting phrase table. The language model was a 5gram model with Kneser-Ney smoothing trained on the monolingual News corpus with IRSTLM (Federico et al., 2008). Feature weights were trained with Minimum Error-Rate Training (MERT) (Och, 2003) on the news-test2008 development set using the DP beam search decoder and the MERT implementation of the Moses toolkit (Koehn et al., 2007). Experimental results are reported for the newstest2009 test set, a corpus of 111 newswire documents totalling 2,525 sentences or 65,595 English input tokens. 4.1 Stability An important difference between our decoder and the classical DP decoder as well as previous work in SMT decoding with local search is that our decoder is inherently non-deterministic. This implies that repeated runs of the decoder with the same search parameters, input and models will not, in general, find the same local maximum of the score space. The first empirical question we ask is therefore how different the results are under repeated runs. The results in this and the next section were obtained with random state initialisation, i. e. without running the DP beam search decoder. Figure 1 shows the results of 7 decoder runs with the models described above, translating the newstest2009 test set, with a step limit of 227 and a rejection limit of 100,000. The x-axis of both plots shows the number of decoding steps on a logarithmic scale, so the number of steps is doubled between two adjacent points on the same curve. In the left plot, the y-axis indicates the model score optimised by the decoder summed over all 2525 sentences of the document. In the right plot, the case-sensitive BLEU score (Papineni et al., 2002) of the current decoder Figure 1: Score stability in repeated decoder runs state against a reference translation is displayed. We note, as expected, that the decoder achieves a considerable improvement of the initial state with diminishing returns as decoding continues. Between 28 and 214 steps, the score increases at a roughly logarithmic pace, then the curve flattens out, which is partly due to the fact that decoding for some documents effectively stopped when the maximum number of rejections was reached. The BLEU score curve shows a similar increase, from an initial score below 5 % to a maximum of around 21.5 %. This is below the score of 22.45 % achieved by the beam search decoder with the same models, which is not surprising considering that our decoder approximates a more difficult search problem, from which a number of strong independence assumptions have been lifted, without, at the moment, having any stronger models at its disposal to exploit this additional freedom for better translation. In terms of stability, there are no dramatic differences between the decoder runs. Indeed, the small differences that exist are hardly discernible in the plots. The model scores at the end of the decoding run range between −158767.9 and −158716.9, a g re rlautniv rea ndgieffe breetnwceee nof − only a6b7.o9ut a n0d.0 −3 %15.8 F1i6n.a9l, BLEU scores range from 21.41 % to 21.63 %, an interval that is not negligible, but comparable to the variance observed when, e. g., feature weights from repeated MERT runs are used with one and the same SMT system. Note that these results were obtained with random state initialisation. With DP initialisation, score differences between repeated runs rarely 1185 exceed 0.02 absolute BLEU percentage points. Overall, we conclude that the decoding results of our algorithm are reasonably stable despite the nondeterminism inherent in the procedure. In our subsequent experiments, the evaluation scores reported are calculated as the mean of three runs for each experiment. 4.2 Search Algorithm Parameters The hill climbing algorithm we use has two parameters which govern the trade-off between decoding time and the accuracy with which a local maximum is identified: The step limit stops the search process after a certain number of steps regardless of the search progress made or lack thereof. The rejection limit stops the search after a certain number of unsuccessful attempts to make a step, when continued search does not seem to be promising. In most of our experiments, we used a step limit of 227 ≈ 1.3 · 108 and a rejection limit of 105. In practice, decoding terminates by reaching the rejection limit for the vast majority of documents. We therefore examined the effect of different rejection limits on the learning curves. The results are shown in figure 2. The results show that continued search does pay off to a certain extent. Indeed, the curve for rejection limit 107 seems to indicate that the model score increases roughly logarithmically, albeit to a higher base, even after the curve has started to flatten out at 214 steps. At a certain point, however, the probability of finding a good successor state drops rather sharply by about two orders of magnitude, as Figure 2: Search performance at different rejection limits evidenced by the fact that a rejection limit of 106 does not give a large improvement over one of 105, while one of 107 does. The continued model score improvement also results in an increase in BLEU scores, and with a BLEU score of 22. 1% the system with rejection limit 107 is fairly close to the score of 22.45 % obtained by DP beam search. Obviously, more exact search comes at a cost, and in this case, it comes at a considerable cost, which is an explosion of the time required to decode the test set from 4 minutes at rejection limit 103 to 224 minutes at rejection limit 105 and 38 hours 45 minutes at limit 107. The DP decoder takes 3 1 minutes for the same task. We conclude that the rejection limit of 105 selected for our experiments, while technically suboptimal, realises a good trade-off between decoding time and accuracy. 4.3 A Semantic Document Language Model In this section, we present the results of the application of our decoder to an actual SMT model with cross-sentence features. Our model addresses the problem of lexical cohesion. In particular, it rewards the use of semantically related words in the translation output by the decoder, where semantic distance is measured with a word space model based on Latent Semantic Analysis (LSA). LSA has been applied to semantic language modelling in previous research with some success (Coccaro and Jurafsky, 1998; Bellegarda, 2000; Wandmacher and Antoine, 2007). In SMT, it has mostly been used for domain adaptation (Kim and Khudanpur, 2004; Tam et al., 1186 2007), or to measure sentence similarities (Banchs and Costa-juss a`, 2011). The model we use is inspired by Bellegarda (2000). It is a Markov model, similar to a standard n-gram model, and assigns to each content word a score given a history of n preceding content words, where n = 30 below. Scoring relies on a 30dimensional LSA word vector space trained with the S-Space software (Jurgens and Stevens, 2010). The score is defined based on the cosine similarity between the word vector of the predicted word and the mean word vector of the words in the history, which is converted to a probability by histogram lookup as suggested by Bellegarda (2000). The model is structurally different from a regular n-gram model in that word vector n-grams are defined over content words occurring in the word vector model only and can cross sentence boundaries. Stop words, identified by an extensive stop word list and amounting to around 60 % of the tokens, are scored by a different mechanism based on their relative frequency (undiscounted unigram probability) in the training corpus. In sum, the score produced by the semantic document LM has the following form: wh(er|h)α=is tεpαheuncipgors(wp)o|hrtinof w fci os nakutneskotn wpon w ,onerldse,in(ls1teh5) training corpus and ε is a small fixed probability. It is integrated into the decoder as an extra feature function. Since we lack an automatic method for training the feature weights of document-wide features, its weight was selected by grid search over a number of values, comparing translation performance for the newstest2009 test set. In these experiments, we used DP beam search to initialise the state of our local search decoder. Three results are presented (table 1): The first table row shows the baseline performance using DP beam search with standard sentence-local features only. The scores in the second row were obtained by running the hill climbing decoder with DP initialisation, but without adding any models. A marginal increase in scores for all three test sets demonstrates that the hill climbing decoder manages to fix some of the search errors made by the DP search. The last row contains the scores obtained by adding in the semantic language model. Scores are presented for three publicly available test sets from recent WMT Machine Translation shared tasks, of which one (newstest2009) was used to monitor progress during development and select the final model. Adding the semantic language model results in a small increase in NIST scores (Doddington, 2002) for all three test sets as well as a small BLEU score gain (Papineni et al., 2002) for two out of three corpora. We note that the NIST score turned out to react more sensitively to improvements due to the semantic LM in all our experiments, which is reasonable because the model specifically targets content words, which benefit from the information weighting done by the NIST score. While the results we present do not constitute compelling evidence in favour of our semantic LM in its current form, they do suggest that this model could be improved to realise higher gains from cross-sentence semantic information. They support our claim that cross- sentence models should be examined more closely and that existing methods should be adapted to deal with them, a problem addressed by our main contribution, the local search document decoder. 5 Related Work Even though DP beam search (Koehn et al., 2003) has been the dominant approach to SMT decoding in recent years, methods based on local search have been explored at various times. For word-based SMT, greedy hill-climbing techniques were advo1187 cated as a faster replacement for beam search (Germann et al., 2001 ; Germann, 2003; Germann et al., 2004), and a problem formulation specifically targeting word reordering with an efficient word reordering algorithm has been proposed (Eisner and Tromble, 2006). A local search decoder has been advanced as a faster alternative to beam search also for phrasebased SMT (Langlais et al., 2007; Langlais et al., 2008). That work anticipates many of the features found in our decoder, including the use of local search to refine an initial hypothesis produced by DP beam search. The possibility of using models that do not fit well into the beam search paradigm is mentioned and illustrated with the example of a reversed n-gram language model, which the authors claim would be difficult to implement in a beam search decoder. Similarly to the work by Germann et al. (2001), their decoder is deterministic and explores the entire neighbourhood of a state in order to identify the most promising step. Our main contribution with respect to the work by Langlais et al. (2007) is the introduction of the possibility of handling document-level models by lifting the assumption of sentence independence. As a consequence, enumerating the entire neighbourhood becomes too expensive, which is why we resort to a “first-choice” strategy that non-deterministically generates states and accepts the first one encountered that meets the acceptance criterion. More recently, Gibbs sampling was proposed as a way to generate samples from the posterior distribution of a phrase-based SMT decoder (Arun et al., 2009; Arun et al., 2010), a process that resembles local search in its use of a set of state-modifying operators to generate a sequence of decoder states. Where local search seeks for the best state attainable from a given initial state, Gibbs sampling produces a representative sample from the posterior. Like all work on SMT decoding that we know of, the Gibbs sampler presented by Arun et al. (2010) assumes independence of sentences and considers the complete neighbourhood of each state before taking a sample. 6 Conclusion In the last twenty years of SMT research, there has been a strong assumption that sentences in a text newstest2009 newstest2010 newstest201 1 BLEU NIST BLEU NIST BLEU NIST 22.56 6.513 27.27 7.034 24.94 7.170 + hill climbing 22.60 6.518 27.33 7.046 24.97 7.169 with semantic LM 22.71 6.549 27.53 7.087 24.90 7.199 DP search only DP Table 1: Experimental results with a cross-sentence semantic language model are independent of one another, and discourse context has been largely neglected. Several factors have contributed to this. Developing good discourse-level models is difficult, and considering the modest translation quality that has long been achieved by SMT, there have been more pressing problems to solve and lower hanging fruit to pick. However, we argue that the popular DP beam search algorithm, which delivers excellent decoding performance, but imposes a particular kind of local dependency structure on the feature models, has also had its share in driving researchers away from discourse-level problems. In this paper, we have presented a decoding procedure for phrase-based SMT that makes it possible to define feature models with cross-sentence dependencies. Our algorithm can be combined with DP beam search to leverage the quality of the traditional approach with increased flexibility for models at the discourse level. We have presented preliminary results on a cross-sentence semantic language model addressing the problem of lexical cohesion to demonstrate that this kind of models is worth exploring further. Besides lexical cohesion, cross-sentence models are relevant for other linguistic phenomena such as pronominal anaphora or verb tense selection. We believe that SMT research has reached a point of maturity where discourse phenomena should not be ignored any longer, and we consider our decoder to be a step towards this goal. References Abhishek Arun, Chris Dyer, Barry Haddow, Phil Blunsom, Adam Lopez, and Philipp Koehn. 2009. Monte carlo inference and maximization for phrase-based translation. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009), pages 102–1 10, Boulder, Colorado, June. Association for Computational Linguistics. Abhishek Arun, Barry Haddow, Philipp Koehn, Adam Lopez, Chris Dyer, and Phil Blunsom. 2010. Monte 1188 Ma- Carlo techniques for phrase-based translation. chine translation, 24(2): 103–121 . Rafael E. Banchs and Marta R. Costa-juss a`. 2011. A semantic feature for Statistical Machine Translation. In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 126– 134, Portland, Oregon, USA, June. Association for Computational Linguistics. Jerome R. Bellegarda. 2000. Exploiting latent semantic information in statistical language modeling. Proceedings of the IEEE, 88(8): 1279–1296. Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar Zaidan. 2011. Findings of the 2011 Workshop on Statistical Machine Translation. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 22–64, Edinburgh, Scotland, July. Association for Computational Linguistics. Noah Coccaro and Daniel Jurafsky. 1998. Towards better integration of semantic predictors in statistical language modeling. In Proceedings of the 5th International Conference on Spoken Language Processing, Sydney. George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proceedings of the second International conference on Human Language Technology Research, pages 138–145, San Diego. Jason Eisner and Roy W. Tromble. 2006. Local search with very large-scale neighborhoods for optimal permutations in machine translation. In Proceedings of the HLT-NAACL Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing, pages 57–75. Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In Interspeech 2008, pages 1618–1621 . ISCA. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2001 . Fast decoding and optimal decoding for machine translation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 228–235, Toulouse, France, July. Association for Computational Linguis- tics. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2004. Fast and optimal decoding for machine translation. Artificial Intelligence, 154(1–2): 127–143. Ulrich Germann. 2003. Greedy decoding for Statistical Machine Translation in almost linear time. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. Zhengxian Gong, Min Zhang, and Guodong Zhou. 2011. Cache-based document-level Statistical Machine Translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 909–919, Edinburgh, Scotland, UK., July. Association for Computational Linguistics. Christian Hardmeier and Marcello Federico. 2010. Modelling Pronominal Anaphora in Statistical Machine Translation. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 283–289. Basil Hatim and Ian Mason. 1990. Discourse and the Translator. Language in Social Life Series. Longman, London. Kenneth Heafield. 2011. KenLM: faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, July. Association for Computational Linguistics. Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 967– 975, Prague, Czech Republic, June. Association for Computational Linguistics. David Jurgens and Keith Stevens. 2010. The S-Space package: An open source package for word space models. In Proceedings of the ACL 2010 System Demonstrations, pages 30–35, Uppsala, Sweden, July. Association for Computational Linguistics. Woosung Kim and Sanjeev Khudanpur. 2004. Crosslingual latent semantic analysis for language modeling. In IEEE international conference on acoustics, speech, and signal processing (ICASSP), volume 1, pages 257–260, Montr ´eal. Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 conference of the North American chapter of the Association for Computational Linguistics on Human Language Technology, pages 48– 54, Edmonton. 1189 Philipp Koehn, Hieu Hoang, Alexandra Birch, et al. 2007. Moses: open source toolkit for Statistical Machine Translation. In Annual meeting of the Association for Computational Linguistics: Demonstration session, pages 177–180, Prague. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2007. A greedy decoder for phrase-based statistical machine translation. In TMI-2007: Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 104–1 13, Sk¨ ovde. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2008. Recherche locale pour la traduction statistique par segments. In TALN 2008, pages 119–128, Avignon, France, June. ATALA. Ronan Le Nagard and Philipp Koehn. 2010. Aiding pronoun translation with co-reference resolution. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 252–261, Uppsala, Sweden, July. Association for Computational Linguistics. Franz Josef Och, Nicola Ueffing, and Hermann Ney. 2001. An efficient A* search algorithm for Statistical Machine Translation. In Proceedings of the DataDriven Machine Translation Workshop, 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 55–62, Toulouse. Franz Josef Och. 2003. Minimum error rate training in Statistical Machine Translation. In Proceedings of the 41st annual meeting of the Association for Computational Linguistics, pages 160–167, Sapporo (Japan). Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of Machine Translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 3 11–3 18, Philadelphia. ACL. Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007. Bilingual LSA-based adaptation for Statistical Machine Translation. Machine Translation, 21(4): 187– 207. J o¨rg Tiedemann. 2010. To cache or not to cache? Experiments with adaptive models in Statistical Machine Translation. In Proceedings of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and Metrics MATR, pages 189–194, Uppsala, Sweden. Association for Computational Linguistics. Christoph Tillmann and Hermann Ney. 2003. Word reordering and a Dynamic Programming beam search algorithm for Statistical Machine Translation. Computational linguistics, 29(1):97–133. Christoph Tillmann, Stephan Vogel, Hermann Ney, and Alex Zubiaga. 1997. A DP-based search using monotone alignments in Statistical Translation. In Proceedings of the 35th Annual Meeting of the Association for Computational Spain, tics. Linguistics, July. Association for 289–296, Madrid, Computational Linguis- pages Tonio Wandmacher and Jean-Yves Antoine. 2007. Methods to integrate a language model with semantic information for a word prediction component. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 506–5 13, Prague, Czech Republic, June. Association for Computational Linguistics. 1190</p><p>2 0.81139344 <a title="35-lsi-2" href="./emnlp-2012-A_Beam-Search_Decoder_for_Grammatical_Error_Correction.html">2 emnlp-2012-A Beam-Search Decoder for Grammatical Error Correction</a></p>
<p>Author: Daniel Dahlmeier ; Hwee Tou Ng</p><p>Abstract: We present a novel beam-search decoder for grammatical error correction. The decoder iteratively generates new hypothesis corrections from current hypotheses and scores them based on features of grammatical correctness and fluency. These features include scores from discriminative classifiers for specific error categories, such as articles and prepositions. Unlike all previous approaches, our method is able to perform correction of whole sentences with multiple and interacting errors while still taking advantage of powerful existing classifier approaches. Our decoder achieves an F1 correction score significantly higher than all previous published scores on the Helping Our Own (HOO) shared task data set.</p><p>3 0.69838357 <a title="35-lsi-3" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>Author: Yang Feng ; Yang Liu ; Qun Liu ; Trevor Cohn</p><p>Abstract: Decoding algorithms for syntax based machine translation suffer from high computational complexity, a consequence of intersecting a language model with a context free grammar. Left-to-right decoding, which generates the target string in order, can improve decoding efficiency by simplifying the language model evaluation. This paper presents a novel left to right decoding algorithm for tree-to-string translation, using a bottom-up parsing strategy and dynamic future cost estimation for each partial translation. Our method outperforms previously published tree-to-string decoders, including a competing left-to-right method.</p><p>4 0.65392584 <a title="35-lsi-4" href="./emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">86 emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<p>Author: Lemao Liu ; Hailong Cao ; Taro Watanabe ; Tiejun Zhao ; Mo Yu ; Conghui Zhu</p><p>Abstract: In statistical machine translation, minimum error rate training (MERT) is a standard method for tuning a single weight with regard to a given development data. However, due to the diversity and uneven distribution of source sentences, there are two problems suffered by this method. First, its performance is highly dependent on the choice of a development set, which may lead to an unstable performance for testing. Second, translations become inconsistent at the sentence level since tuning is performed globally on a document level. In this paper, we propose a novel local training method to address these two problems. Unlike a global training method, such as MERT, in which a single weight is learned and used for all the input sentences, we perform training and testing in one step by learning a sentencewise weight for each input sentence. We pro- pose efficient incremental training methods to put the local training into practice. In NIST Chinese-to-English translation tasks, our local training method significantly outperforms MERT with the maximal improvements up to 2.0 BLEU points, meanwhile its efficiency is comparable to that of the global method.</p><p>5 0.58184016 <a title="35-lsi-5" href="./emnlp-2012-Translation_Model_Based_Cross-Lingual_Language_Model_Adaptation%3A_from_Word_Models_to_Phrase_Models.html">128 emnlp-2012-Translation Model Based Cross-Lingual Language Model Adaptation: from Word Models to Phrase Models</a></p>
<p>Author: Shixiang Lu ; Wei Wei ; Xiaoyin Fu ; Bo Xu</p><p>Abstract: In this paper, we propose a novel translation model (TM) based cross-lingual data selection model for language model (LM) adaptation in statistical machine translation (SMT), from word models to phrase models. Given a source sentence in the translation task, this model directly estimates the probability that a sentence in the target LM training corpus is similar. Compared with the traditional approaches which utilize the first pass translation hypotheses, cross-lingual data selection model avoids the problem of noisy proliferation. Furthermore, phrase TM based cross-lingual data selection model is more effective than the traditional approaches based on bag-ofwords models and word-based TM, because it captures contextual information in modeling the selection of phrase as a whole. Experiments conducted on large-scale data sets demonstrate that our approach significantly outperforms the state-of-the-art approaches on both LM perplexity and SMT performance.</p><p>6 0.5102222 <a title="35-lsi-6" href="./emnlp-2012-Exact_Sampling_and_Decoding_in_High-Order_Hidden_Markov_Models.html">43 emnlp-2012-Exact Sampling and Decoding in High-Order Hidden Markov Models</a></p>
<p>7 0.48942471 <a title="35-lsi-7" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>8 0.4322398 <a title="35-lsi-8" href="./emnlp-2012-Source_Language_Adaptation_for_Resource-Poor_Machine_Translation.html">118 emnlp-2012-Source Language Adaptation for Resource-Poor Machine Translation</a></p>
<p>9 0.42291829 <a title="35-lsi-9" href="./emnlp-2012-Language_Model_Rest_Costs_and_Space-Efficient_Storage.html">74 emnlp-2012-Language Model Rest Costs and Space-Efficient Storage</a></p>
<p>10 0.38806155 <a title="35-lsi-10" href="./emnlp-2012-Generating_Non-Projective_Word_Order_in_Statistical_Linearization.html">59 emnlp-2012-Generating Non-Projective Word Order in Statistical Linearization</a></p>
<p>11 0.37726799 <a title="35-lsi-11" href="./emnlp-2012-A_Bayesian_Model_for_Learning_SCFGs_with_Discontiguous_Rules.html">1 emnlp-2012-A Bayesian Model for Learning SCFGs with Discontiguous Rules</a></p>
<p>12 0.37488827 <a title="35-lsi-12" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>13 0.32282498 <a title="35-lsi-13" href="./emnlp-2012-Generalized_Higher-Order_Dependency_Parsing_with_Cube_Pruning.html">57 emnlp-2012-Generalized Higher-Order Dependency Parsing with Cube Pruning</a></p>
<p>14 0.30124968 <a title="35-lsi-14" href="./emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">85 emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>15 0.29772136 <a title="35-lsi-15" href="./emnlp-2012-Inducing_a_Discriminative_Parser_to_Optimize_Machine_Translation_Reordering.html">67 emnlp-2012-Inducing a Discriminative Parser to Optimize Machine Translation Reordering</a></p>
<p>16 0.28927803 <a title="35-lsi-16" href="./emnlp-2012-Cross-Lingual_Language_Modeling_with_Syntactic_Reordering_for_Low-Resource_Speech_Recognition.html">31 emnlp-2012-Cross-Lingual Language Modeling with Syntactic Reordering for Low-Resource Speech Recognition</a></p>
<p>17 0.28450114 <a title="35-lsi-17" href="./emnlp-2012-Bilingual_Lexicon_Extraction_from_Comparable_Corpora_Using_Label_Propagation.html">25 emnlp-2012-Bilingual Lexicon Extraction from Comparable Corpora Using Label Propagation</a></p>
<p>18 0.27732113 <a title="35-lsi-18" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>19 0.27653328 <a title="35-lsi-19" href="./emnlp-2012-N-gram-based_Tense_Models_for_Statistical_Machine_Translation.html">95 emnlp-2012-N-gram-based Tense Models for Statistical Machine Translation</a></p>
<p>20 0.24607663 <a title="35-lsi-20" href="./emnlp-2012-A_Systematic_Comparison_of_Phrase_Table_Pruning_Techniques.html">11 emnlp-2012-A Systematic Comparison of Phrase Table Pruning Techniques</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.037), (21, 0.027), (30, 0.081), (31, 0.032), (38, 0.076), (41, 0.022), (46, 0.016), (48, 0.037), (55, 0.039), (59, 0.072), (61, 0.089), (80, 0.015), (82, 0.013), (85, 0.031), (91, 0.333)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95895362 <a title="35-lda-1" href="./emnlp-2012-Ensemble_Semantics_for_Large-scale_Unsupervised_Relation_Extraction.html">40 emnlp-2012-Ensemble Semantics for Large-scale Unsupervised Relation Extraction</a></p>
<p>Author: Bonan Min ; Shuming Shi ; Ralph Grishman ; Chin-Yew Lin</p><p>Abstract: Discovering significant types of relations from the web is challenging because of its open nature. Unsupervised algorithms are developed to extract relations from a corpus without knowing the relations in advance, but most of them rely on tagging arguments of predefined types. Recently, a new algorithm was proposed to jointly extract relations and their argument semantic classes, taking a set of relation instances extracted by an open IE algorithm as input. However, it cannot handle polysemy of relation phrases and fails to group many similar (“synonymous”) relation instances because of the sparseness of features. In this paper, we present a novel unsupervised algorithm that provides a more general treatment of the polysemy and synonymy problems. The algorithm incorporates various knowledge sources which we will show to be very effective for unsupervised extraction. Moreover, it explicitly disambiguates polysemous relation phrases and groups synonymous ones. While maintaining approximately the same precision, the algorithm achieves significant improvement on recall compared to the previous method. It is also very efficient. Experiments on a realworld dataset show that it can handle 14.7 million relation instances and extract a very large set of relations from the web. Ralph Grishman1 Chin-Yew Lin2 2Microsoft Research Asia Beijing, China { shumings cyl } @mi cro s o ft . com , that has many applications in answering factoid questions, building knowledge bases and improving search engine relevance. The web has become a massive potential source of such relations. However, its open nature brings an open-ended set of relation types. To extract these relations, a system should not assume a fixed set of relation types, nor rely on a fixed set of relation argument types. The past decade has seen some promising solutions, unsupervised relation extraction (URE) algorithms that extract relations from a corpus without knowing the relations in advance. However, most algorithms (Hasegawa et al., 2004, Shinyama and Sekine, 2006, Chen et. al, 2005) rely on tagging predefined types of entities as relation arguments, and thus are not well-suited for the open domain. Recently, Kok and Domingos (2008) proposed Semantic Network Extractor (SNE), which generates argument semantic classes and sets of synonymous relation phrases at the same time, thus avoiding the requirement of tagging relation arguments of predefined types. However, SNE has 2 limitations: 1) Following previous URE algorithms, it only uses features from the set of input relation instances for clustering. Empirically we found that it fails to group many relevant relation instances. These features, such as the surface forms of arguments and lexical sequences in between, are very sparse in practice. In contrast, there exist several well-known corpus-level semantic resources that can be automatically derived from a source corpus and are shown to be useful for generating the key elements of a relation: its 2 argument semantic classes and a set of synonymous phrases. For example, semantic classes can be derived from a source corpus with contextual distributional simi1 Introduction Relation extraction aims at discovering semantic larity and web table co-occurrences. The “synonymy” 1 problem for clustering relation instances relations between entities. It is an important task * Work done during an internship at Microsoft Research Asia 1027 LParnogcue agdein Lgesa ornf tihneg, 2 p0a1g2e Jso 1in02t C7–o1n0f3e7re,n Jce ju on Is Elanmdp,ir Kicoarlea M,e 1t2h–o1d4s J iunly N 2a0tu1r2a.l ? Lc a2n0g1u2ag Aes Psorcoicaetsiosin fgo arn Cdo Cmopmutpauti oantiaoln Lailn Ngautiustriacls could potentially be better solved by adding these resources. 2) SNE assumes that each entity or relation phrase belongs to exactly one cluster, thus is not able to effectively handle polysemy of relation phrases2. An example of a polysemous phrase is be the currency of as in 2 triples</p><p>same-paper 2 0.79173481 <a title="35-lda-2" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>Author: Christian Hardmeier ; Joakim Nivre ; Jorg Tiedemann</p><p>Abstract: Independence between sentences is an assumption deeply entrenched in the models and algorithms used for statistical machine translation (SMT), particularly in the popular dynamic programming beam search decoding algorithm. This restriction is an obstacle to research on more sophisticated discourse-level models for SMT. We propose a stochastic local search decoding method for phrase-based SMT, which permits free document-wide dependencies in the models. We explore the stability and the search parameters ofthis method and demonstrate that it can be successfully used to optimise a document-level semantic language model. 1 Motivation In the field oftranslation studies, it is undisputed that discourse-wide context must be considered care- fully for good translation results (Hatim and Mason, 1990). By contrast, the state of the art in statistical machine translation (SMT), despite significant advances in the last twenty years, still assumes that texts can be translated sentence by sentence under strict independence assumptions, even though it is well known that certain linguistic phenomena such as pronominal anaphora cannot be translated correctly without referring to extra-sentential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm 1179 which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001 ; Tillmann and Ney, 2003). This algorithm con- structs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elimination of hypotheses from the search space if they coincide in a certain number of final words with a better hypothesis and no future expansion can possibly invert the relative ranking of the two hypotheses under the given models. Hypothesis recombination achieves a substantial reduction of the search space without affecting search optimality and makes it possible to use aggressive pruning techniques for fast search while still obtaining good results. The downside of this otherwise excellent approach is that it only works well with models that have a local dependency structure similar to that of an n-gram language model, so they only depend on a small context window for each target word. Sentence-local models with longer dependencies can be added, but doing so greatly increases the risk for search errors by inhibiting hypothesis recombination. Cross-sentence dependencies cannot be directly integrated into DP SMT decoding in LParnogcue agdein Lgesa ornf tihneg, 2 p0a1g2e Jso 1in17t C9–o1n1f9e0re,n Jce ju on Is Elanmdp,ir Kicoarlea M,e 1t2h–o1d4s J iunly N 2a0tu1r2a.l ? Lc a2n0g1u2ag Aes Psorcoicaetsiosin fgo arn Cdo Cmopmutpauti oantiaoln Lailn Ngautiustriacls any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required. Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems. Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (201 1), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences. In this paper, we present a method for decoding complete documents in phrase-based SMT. Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by the application of a series of operations using a hill climbing strategy to find a (local) maximum of the score function. This setup gives us complete freedom to define scoring functions over the entire document. Moreover, by optionally initialising the state with the output of a traditional DP decoder, we can ensure that the final hypothesis is no worse than what would have been found by DP search alone. We start by describing the decoding algorithm and the state operations used by our decoder, then we present empirical results demonstrating the effectiveness of our approach and its usability with a document-level semantic language model, and finally we discuss some related work. 2 SMT Decoding by Hill Climbing In this section, we formally describe the phrasebased SMT model implemented by our decoder as well as the decoding algorithm we use. 2.1 SMT Model Our decoder is based on local search, so its state at any time is a representation of a complete translation of the entire document. Even though the decoder operates at the document level, it is important to keep 1180 track of sentence boundaries, and the individual operations that are applied to the state are still confined to sentence scope, so it is useful to decompose the state of a document into the state of its sentences, and we define the overall state S as a sequence of sentence states: S = S1S2 . . .SN, (1) where N is the number of sentences. This implies that we constrain the decoder to emit exactly one output sentence per input sentence. Let ibe the number of a sentence and mi the number of input tokens of this sentence, p and q (with 1 ≤ p ≤ q ≤ mi) be positions in the input sentence a1n ≤d [p; q] qde ≤no mte the set ofpositions from p up to and including q. We say that [p; q] precedes [p0; q0], or [p; q] ≺ [p0; q0], if q < p0. Let Φi([p; q]) be the set of t[pra;nqs]l ≺atio [pns for the source phrase covering positions [p; q] in the input sentence ias given by the phrase table. We call A = h[p; q] ,φi an anchored phrase pair w.it Wh coverage C(A) = [p; q] nif a φ ∈ Φi([p; q]) sise a target phrase translating =th [ep source w∈o Φrds at positions [p; q] . Then a sequence of ni anchored phrase pairs Si = A1A2 . . .Ani (2) is a valid sentence state for sentence iif the following two conditions hold: 1. The coverage sets C(Aj) for j in 1, . . . , ni are mutually disjoint, and 2. the anchored phrase pairs jointly cover the complete input sentence, or [niC(Aj) = [1;mi]. (3) [j=1 Let f(S) be a scoring function mapping a state S to a real number. As usual in SMT, it is assumed that the scoring function can be decomposed into a linear combination of K feature functions hk(S), each with a constant weight λk, so f(S) =k∑K=1λkhk(S). (4) The problem addressed by the decoder is the search for the state with maximal score, such that Sˆ Sˆ = argSmaxf(S). (5) The feature functions implemented in our baseline system are identical to the ones found in the popular Moses SMT system (Koehn et al., 2007). In particular, our decoder has the following feature functions: 1. phrase translation scores provided by the phrase table including forward and backward conditional probabilities, lexical weights and a phrase penalty (Koehn et al., 2003), 2. n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3. a word penalty score, 4. a distortion model with geometric (Koehn et al., 2003), and decay 5. a feature indicating the number of times a given distortion limit is exceeded in the current state. In our experiments, the last feature is used with a fixed weight of negative infinity in order to limit the gaps between the coverage sets of adjacent anchored phrase pairs to a maximum value. In DP search, the distortion limit is usually enforced directly by the search algorithm and is not added as a feature. In our decoder, however, this restriction is not required to limit complexity, so we decided to add it among the scoring models. 2.2 Decoding Algorithm The decoding algorithm we use (algorithm 1) is very simple. It starts with a given initial document state. In the main loop, which extends from line 3 to line 12, it generates a successor state S0 for the current state S by calling the function Neighbour, which non-deterministically applies one of the operations described in section 3 of this paper to S. The score of the new state is compared to that of the previous one. If it meets a given acceptance criterion, S0 becomes the current state, else search continues from the previous state S. For the experiments in this paper, we use the hill climbing acceptance criterion, which simply accepts a new state if its score is higher than that of the current state. Other acceptance criteria are possible and could be used to endow the search algorithm with stochastic behaviour. 1181 The main loop is repeated until a maximum number of steps (step limit) is reached or until a maximum number of moves are rejected in a row (rejection limit). Algorithm 1 Decoding algorithm Input: an initial document state S; search parameters maxsteps and maxrejected Output: a modified document state 1: nsteps ← 0 2: nrejected ← 0 3: nwrhejileec nsteps < maxsteps and nrejected < maxrejected do 4: S0 ← Neighbour (S) 5: if Accept (f(S0) , f(S)) then 6: S ← S0 7: nrejected ← 0 8: elsner 9: nrejected ← nrejected + 1 10: enndr eifj 11: nsteps ← nsteps + 1 12: ennds wtephsile ← 13: return S A notable difference between this algorithm and other hill climbing algorithms that have been used for SMT decoding (Germann et al., 2004; Langlais et al., 2007) is its non-determinism. Previous work for sentence-level decoding employed a steepest ascent strategy which amounts to enumerating the complete neighbourhood of the current state as defined by the state operations and selecting the next state to be the best state found in the neighbourhood of the current one. Enumerating all neighbours of a given state, costly as it is, has the advantage that it makes it easy to prove local optimality of a state by recognising that all possible successor states have lower scores. It can be rather inefficient, since at every step only one modification will be adopted; many of the modifications that are discarded will very likely be generated anew in the next iteration. As we extend the decoder to the document level, the size of the neighbourhood that would have to be explored in this way increases considerably. Moreover, the inefficiency of the steepest ascent approach potentially increases as well. Very likely, a promising move in one sentence will remain promising after a modification has been applied to another sentence, even though this is not guaranteed to be true in the presence of cross-sentence models. We therefore adopt a first-choice hill climbing strategy that non-deterministically generates successor states and accepts the first one that meets the acceptance criterion. This frees us from the necessity of generating the full set of successors for each state. On the downside, if the full successor set is not known, it is no longer possible to prove local optimality of a state, so we are forced to use a different condition for halting the search. We use a combination of two limits: The step limit is a hard limit on the resources the user is willing to expend on the search problem. The value of the rejection limit determines how much of the neighbourhood is searched for better successors before a state is accepted as a solution; it is related to the probability that a state returned as a solution is in fact locally optimal. To simplify notations in the description of the individual state operations, we write Si −→ Si0 (6) to signify that a state operation, when presented with a document state as in equation 1 and acting on sentence i, returns a new document state of S0 = S1 . . .Si−1 Si0 Si+1 . . .SN. (7) Similarly, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (8) is equivalent to Si −→ A1 . . .Aj−1 A01 . . .A0h0 Aj+h . . .Ani (9) and indicates that the operation returns a state in which a sequence of h consecutive anchored phrase pairs has been replaced by another sequence of h0 anchored phrase pairs. 2.3 Efficiency Considerations When implementing the feature functions for the decoder, we have to exercise some care to avoid recomputing scores for the whole document at every iteration. To achieve this, the scores are computed completely only once, at the beginning of the decoding run. In subsequent iterations, scoring functions are presented with the scores of the previous 1182 iteration and a list of modifications produced by the state operation, a set of tuples hi, r, s,A01 . . .A0h0i, each indicating tthioant ,t ahe s edto ocfu tmupelnets s hhio,ru,sld, Abe modifii,e eda as described by Si :Ar . . .As −→ A01 . . .A0h0 . (10) If a feature function is decomposable in some way, as all the standard features developed under the constraints of DP search are, it can then update the state simply by subtracting and adding score components pertaining to the modified parts of the document. Feature functions have the possibility to store their own state information along with the document state to make sure the required information is available. Thus, the framework makes it possible to exploit decomposability for efficient scoring without impos- ing any particular decomposition on the features as beam search does. To make scoring even more efficient, scores are computed in two passes: First, every feature function is asked to provide an upper bound on the score that will be obtained for the new state. In some cases, it is possible to calculate reasonable upper bounds much more efficiently than computing the exact feature value. If the upper bound fails to meet the acceptance criterion, the new state is discarded right away; if not, the full score is computed and the acceptance criterion is tested again. Among the basic SMT models, this two-pass strategy is only used for the n-gram LM, which requires fairly expensive parameter lookups for scoring. The scores of all the other baseline models are fully computed during the first scoring pass. The n-gram model is more complex. In its state information, it keeps track of the LM score and LM library state for each word. The first scoring pass then identifies the words whose LM scores are affected by the current search step. This includes the words changed by the search operation as well as the words whose LM history is modified. The range of the history de- pendencies can be determined precisely by considering the “valid state length” information provided by the KenLM library. In the first pass, the LM scores of the affected words are subtracted from the total score. The model only looks up the new LM scores for the affected words and updates the total score if the new search state passes the first acceptance check. This two-pass scoring approach allows us to avoid LM lookups altogether for states that will be rejected anyhow because of low scores from the other models, e. g. because the distortion limit is violated. Model score updates become more complex and slower as the number of dependencies of a model increases. While our decoding algorithm does not impose any formal restrictions on the number or type of dependencies that can be handled, there will be practical limits beyond which decoding becomes unacceptably slow or the scoring code becomes very difficult to maintain. These limits are however fairly independent of the types of dependencies handled by a model, which permits the exploration of more varied model types than those handled by DP search. 2.4 State Initialisation Before the hill climbing decoding algorithm can be run, an initial state must be generated. The closer the initial state is to an optimum, the less work remains to be done for the algorithm. If the algorithm is to be self-contained, initialisation must be relatively uninformed and can only rely on some general prior assumptions about what might be a good initial guess. On the other hand, if optimal results are sought after, it pays off to invest some effort into a good starting point. One way to do this is to run DP search first. For uninformed initialisation, we chose to implement a very simple procedure based only on the observation that, at least for language pairs involving the major European languages, it is usually a good guess to keep the word order of the output very similar to that of the input. We therefore create the initial state by selecting, for each sentence in the document, a sequence of anchored phrase pairs covering the input sentence in monotonic order, that is, such that for all pairs of adjacent anchored phrase pairs Aj and Aj+1, we have that C(Aj) ≺ C(Aj+1 ). For initialisation with DP search, we first run the Moses decoder (Koehn et al., 2007) with default search parameters and the same models as those used by our decoder. Then we extract the best output hypothesis from the search graph of the decoder and map it into a sequence of anchored phrase pairs in the obvious way. When the document-level decoder is used with models that are incompatible with beam search, Moses can be run with a subset of the models in order to find an approximation of the solution 1183 which is then refined with the complete feature set. 3 State Operations Given a document state S, the decoder uses a neighbourhood function Neighbour to simulate a move in the state space. The neighbourhood function nondeterministically selects a type of state operation and a location in the document to apply it to and returns the resulting new state. We use a set of three operations that has the property that every possible document state can be reached from every other state in a sequence of moves. Designing operations for state transitions in local search for phrase-based SMT is a problem that has been addressed in the literature (Langlais et al., 2007; Arun et al., 2010). Our decoder’s first- choice hill climbing strategy never enumerates the full neighbourhood of a state. We therefore place less emphasis than previous work on defining a compact neighbourhood, but allow the decoder to make quite extensive changes to a state in a single step with a certain probability. Otherwise our operations are similar to those used by Arun et al. (2010). All of the operations described in this paper make changes to a single sentence only. Each time it is called, the Neighbour function selects a sentence in the document with a probability proportional to the number of input tokens in each sentence to ensure a fair distribution ofthe decoder’s attention over the words in the document regardless of varying sentence lengths. 3.1 Changing Phrase Translations The change-phrase-translation operation replaces the translation of a single phrase with a random translation with the same coverage taken from the phrase table. Formally, the operation selects an anchored phrase pair Aj by drawing uniformly from the elements of Si and then draws a new translation φ0 uniformly from the set Φi(C(Aj)). The new state is given by Si : Aj −→ hC(Aj), φ0i. (11) 3.2 Changing Word Order The swap-phrases operation affects the output word order without changing the phrase translations. It exchanges two anchored phrase pairs Aj and Aj+h, resulting in an output state of Si : Aj . . .Aj+h −→ Aj+h Aj+1 . . .Aj+h−1 Aj. (12) The start location j is drawn uniformly from the eligible sentence positions; the swap range h comes from a geometric distribution with configurable decay. Other word-order changes such as a one-way move operation that does not require another movement in exchange or more advanced permutations can easily be defined. 3.3 Resegmentation The most complex operation is resegment, which allows the decoder to modify the segmentation ofthe source phrase. It takes a number of anchored phrase pairs that form a contiguous block both in the input and in the output and replaces them with a new set of phrase pairs covering the same span of the input sentence. Formally, Si : Aj . . .Aj+h−1 −→ A01 . . .A0h0 (13) such that j+[h−1 [h0 [ C(Aj0) = [ C(A0j0) = [p;q] j[0=j (14) j[0=1 for some p and q, where, for j0 = 1, . . . ,h0, we have that A0j0 = h[pj0; qj0] , φj0i, all [pj0; qj0] are mutually disjoint =an hd[ peach φj0 isi randomly drawn from Φi([pj0;qj0]). Regardless of the ordering of Aj . . .Aj+h−1 , the resegment operation always generates a sequence of anchored phrase pairs in linear order, such that C(A0j0) ≺ C(A0j0+1 ) for j0 = 1, . . . ,h0 −1 . As )f o≺r Cth(eA other operations, j is− generated uniformly and h is drawn from a geometric distribution with a decay parameter. The new segmentation is generated by extending the sequence of anchored phrase pairs with random elements starting at the next free position, proceeding from left to right until the whole range [p; q] is covered. 4 Experimental Results In this section, we present the results of a series of experiments with our document decoder. The 1184 goal of our experiments is to demonstrate the behaviour of the decoder and characterise its response to changes in the fundamental search parameters. The SMT models for our experiments were created with a subset of the training data for the English-French shared task at the WMT 2011workshop (Callison-Burch et al., 2011). The phrase table was trained on Europarl, news-commentary and UN data. To reduce the training data to a manageable size, singleton phrase pairs were removed before the phrase scoring step. Significance-based filtering (Johnson et al., 2007) was applied to the resulting phrase table. The language model was a 5gram model with Kneser-Ney smoothing trained on the monolingual News corpus with IRSTLM (Federico et al., 2008). Feature weights were trained with Minimum Error-Rate Training (MERT) (Och, 2003) on the news-test2008 development set using the DP beam search decoder and the MERT implementation of the Moses toolkit (Koehn et al., 2007). Experimental results are reported for the newstest2009 test set, a corpus of 111 newswire documents totalling 2,525 sentences or 65,595 English input tokens. 4.1 Stability An important difference between our decoder and the classical DP decoder as well as previous work in SMT decoding with local search is that our decoder is inherently non-deterministic. This implies that repeated runs of the decoder with the same search parameters, input and models will not, in general, find the same local maximum of the score space. The first empirical question we ask is therefore how different the results are under repeated runs. The results in this and the next section were obtained with random state initialisation, i. e. without running the DP beam search decoder. Figure 1 shows the results of 7 decoder runs with the models described above, translating the newstest2009 test set, with a step limit of 227 and a rejection limit of 100,000. The x-axis of both plots shows the number of decoding steps on a logarithmic scale, so the number of steps is doubled between two adjacent points on the same curve. In the left plot, the y-axis indicates the model score optimised by the decoder summed over all 2525 sentences of the document. In the right plot, the case-sensitive BLEU score (Papineni et al., 2002) of the current decoder Figure 1: Score stability in repeated decoder runs state against a reference translation is displayed. We note, as expected, that the decoder achieves a considerable improvement of the initial state with diminishing returns as decoding continues. Between 28 and 214 steps, the score increases at a roughly logarithmic pace, then the curve flattens out, which is partly due to the fact that decoding for some documents effectively stopped when the maximum number of rejections was reached. The BLEU score curve shows a similar increase, from an initial score below 5 % to a maximum of around 21.5 %. This is below the score of 22.45 % achieved by the beam search decoder with the same models, which is not surprising considering that our decoder approximates a more difficult search problem, from which a number of strong independence assumptions have been lifted, without, at the moment, having any stronger models at its disposal to exploit this additional freedom for better translation. In terms of stability, there are no dramatic differences between the decoder runs. Indeed, the small differences that exist are hardly discernible in the plots. The model scores at the end of the decoding run range between −158767.9 and −158716.9, a g re rlautniv rea ndgieffe breetnwceee nof − only a6b7.o9ut a n0d.0 −3 %15.8 F1i6n.a9l, BLEU scores range from 21.41 % to 21.63 %, an interval that is not negligible, but comparable to the variance observed when, e. g., feature weights from repeated MERT runs are used with one and the same SMT system. Note that these results were obtained with random state initialisation. With DP initialisation, score differences between repeated runs rarely 1185 exceed 0.02 absolute BLEU percentage points. Overall, we conclude that the decoding results of our algorithm are reasonably stable despite the nondeterminism inherent in the procedure. In our subsequent experiments, the evaluation scores reported are calculated as the mean of three runs for each experiment. 4.2 Search Algorithm Parameters The hill climbing algorithm we use has two parameters which govern the trade-off between decoding time and the accuracy with which a local maximum is identified: The step limit stops the search process after a certain number of steps regardless of the search progress made or lack thereof. The rejection limit stops the search after a certain number of unsuccessful attempts to make a step, when continued search does not seem to be promising. In most of our experiments, we used a step limit of 227 ≈ 1.3 · 108 and a rejection limit of 105. In practice, decoding terminates by reaching the rejection limit for the vast majority of documents. We therefore examined the effect of different rejection limits on the learning curves. The results are shown in figure 2. The results show that continued search does pay off to a certain extent. Indeed, the curve for rejection limit 107 seems to indicate that the model score increases roughly logarithmically, albeit to a higher base, even after the curve has started to flatten out at 214 steps. At a certain point, however, the probability of finding a good successor state drops rather sharply by about two orders of magnitude, as Figure 2: Search performance at different rejection limits evidenced by the fact that a rejection limit of 106 does not give a large improvement over one of 105, while one of 107 does. The continued model score improvement also results in an increase in BLEU scores, and with a BLEU score of 22. 1% the system with rejection limit 107 is fairly close to the score of 22.45 % obtained by DP beam search. Obviously, more exact search comes at a cost, and in this case, it comes at a considerable cost, which is an explosion of the time required to decode the test set from 4 minutes at rejection limit 103 to 224 minutes at rejection limit 105 and 38 hours 45 minutes at limit 107. The DP decoder takes 3 1 minutes for the same task. We conclude that the rejection limit of 105 selected for our experiments, while technically suboptimal, realises a good trade-off between decoding time and accuracy. 4.3 A Semantic Document Language Model In this section, we present the results of the application of our decoder to an actual SMT model with cross-sentence features. Our model addresses the problem of lexical cohesion. In particular, it rewards the use of semantically related words in the translation output by the decoder, where semantic distance is measured with a word space model based on Latent Semantic Analysis (LSA). LSA has been applied to semantic language modelling in previous research with some success (Coccaro and Jurafsky, 1998; Bellegarda, 2000; Wandmacher and Antoine, 2007). In SMT, it has mostly been used for domain adaptation (Kim and Khudanpur, 2004; Tam et al., 1186 2007), or to measure sentence similarities (Banchs and Costa-juss a`, 2011). The model we use is inspired by Bellegarda (2000). It is a Markov model, similar to a standard n-gram model, and assigns to each content word a score given a history of n preceding content words, where n = 30 below. Scoring relies on a 30dimensional LSA word vector space trained with the S-Space software (Jurgens and Stevens, 2010). The score is defined based on the cosine similarity between the word vector of the predicted word and the mean word vector of the words in the history, which is converted to a probability by histogram lookup as suggested by Bellegarda (2000). The model is structurally different from a regular n-gram model in that word vector n-grams are defined over content words occurring in the word vector model only and can cross sentence boundaries. Stop words, identified by an extensive stop word list and amounting to around 60 % of the tokens, are scored by a different mechanism based on their relative frequency (undiscounted unigram probability) in the training corpus. In sum, the score produced by the semantic document LM has the following form: wh(er|h)α=is tεpαheuncipgors(wp)o|hrtinof w fci os nakutneskotn wpon w ,onerldse,in(ls1teh5) training corpus and ε is a small fixed probability. It is integrated into the decoder as an extra feature function. Since we lack an automatic method for training the feature weights of document-wide features, its weight was selected by grid search over a number of values, comparing translation performance for the newstest2009 test set. In these experiments, we used DP beam search to initialise the state of our local search decoder. Three results are presented (table 1): The first table row shows the baseline performance using DP beam search with standard sentence-local features only. The scores in the second row were obtained by running the hill climbing decoder with DP initialisation, but without adding any models. A marginal increase in scores for all three test sets demonstrates that the hill climbing decoder manages to fix some of the search errors made by the DP search. The last row contains the scores obtained by adding in the semantic language model. Scores are presented for three publicly available test sets from recent WMT Machine Translation shared tasks, of which one (newstest2009) was used to monitor progress during development and select the final model. Adding the semantic language model results in a small increase in NIST scores (Doddington, 2002) for all three test sets as well as a small BLEU score gain (Papineni et al., 2002) for two out of three corpora. We note that the NIST score turned out to react more sensitively to improvements due to the semantic LM in all our experiments, which is reasonable because the model specifically targets content words, which benefit from the information weighting done by the NIST score. While the results we present do not constitute compelling evidence in favour of our semantic LM in its current form, they do suggest that this model could be improved to realise higher gains from cross-sentence semantic information. They support our claim that cross- sentence models should be examined more closely and that existing methods should be adapted to deal with them, a problem addressed by our main contribution, the local search document decoder. 5 Related Work Even though DP beam search (Koehn et al., 2003) has been the dominant approach to SMT decoding in recent years, methods based on local search have been explored at various times. For word-based SMT, greedy hill-climbing techniques were advo1187 cated as a faster replacement for beam search (Germann et al., 2001 ; Germann, 2003; Germann et al., 2004), and a problem formulation specifically targeting word reordering with an efficient word reordering algorithm has been proposed (Eisner and Tromble, 2006). A local search decoder has been advanced as a faster alternative to beam search also for phrasebased SMT (Langlais et al., 2007; Langlais et al., 2008). That work anticipates many of the features found in our decoder, including the use of local search to refine an initial hypothesis produced by DP beam search. The possibility of using models that do not fit well into the beam search paradigm is mentioned and illustrated with the example of a reversed n-gram language model, which the authors claim would be difficult to implement in a beam search decoder. Similarly to the work by Germann et al. (2001), their decoder is deterministic and explores the entire neighbourhood of a state in order to identify the most promising step. Our main contribution with respect to the work by Langlais et al. (2007) is the introduction of the possibility of handling document-level models by lifting the assumption of sentence independence. As a consequence, enumerating the entire neighbourhood becomes too expensive, which is why we resort to a “first-choice” strategy that non-deterministically generates states and accepts the first one encountered that meets the acceptance criterion. More recently, Gibbs sampling was proposed as a way to generate samples from the posterior distribution of a phrase-based SMT decoder (Arun et al., 2009; Arun et al., 2010), a process that resembles local search in its use of a set of state-modifying operators to generate a sequence of decoder states. Where local search seeks for the best state attainable from a given initial state, Gibbs sampling produces a representative sample from the posterior. Like all work on SMT decoding that we know of, the Gibbs sampler presented by Arun et al. (2010) assumes independence of sentences and considers the complete neighbourhood of each state before taking a sample. 6 Conclusion In the last twenty years of SMT research, there has been a strong assumption that sentences in a text newstest2009 newstest2010 newstest201 1 BLEU NIST BLEU NIST BLEU NIST 22.56 6.513 27.27 7.034 24.94 7.170 + hill climbing 22.60 6.518 27.33 7.046 24.97 7.169 with semantic LM 22.71 6.549 27.53 7.087 24.90 7.199 DP search only DP Table 1: Experimental results with a cross-sentence semantic language model are independent of one another, and discourse context has been largely neglected. Several factors have contributed to this. Developing good discourse-level models is difficult, and considering the modest translation quality that has long been achieved by SMT, there have been more pressing problems to solve and lower hanging fruit to pick. However, we argue that the popular DP beam search algorithm, which delivers excellent decoding performance, but imposes a particular kind of local dependency structure on the feature models, has also had its share in driving researchers away from discourse-level problems. In this paper, we have presented a decoding procedure for phrase-based SMT that makes it possible to define feature models with cross-sentence dependencies. Our algorithm can be combined with DP beam search to leverage the quality of the traditional approach with increased flexibility for models at the discourse level. We have presented preliminary results on a cross-sentence semantic language model addressing the problem of lexical cohesion to demonstrate that this kind of models is worth exploring further. Besides lexical cohesion, cross-sentence models are relevant for other linguistic phenomena such as pronominal anaphora or verb tense selection. We believe that SMT research has reached a point of maturity where discourse phenomena should not be ignored any longer, and we consider our decoder to be a step towards this goal. References Abhishek Arun, Chris Dyer, Barry Haddow, Phil Blunsom, Adam Lopez, and Philipp Koehn. 2009. Monte carlo inference and maximization for phrase-based translation. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009), pages 102–1 10, Boulder, Colorado, June. Association for Computational Linguistics. Abhishek Arun, Barry Haddow, Philipp Koehn, Adam Lopez, Chris Dyer, and Phil Blunsom. 2010. Monte 1188 Ma- Carlo techniques for phrase-based translation. chine translation, 24(2): 103–121 . Rafael E. Banchs and Marta R. Costa-juss a`. 2011. A semantic feature for Statistical Machine Translation. In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 126– 134, Portland, Oregon, USA, June. Association for Computational Linguistics. Jerome R. Bellegarda. 2000. Exploiting latent semantic information in statistical language modeling. Proceedings of the IEEE, 88(8): 1279–1296. Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar Zaidan. 2011. Findings of the 2011 Workshop on Statistical Machine Translation. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 22–64, Edinburgh, Scotland, July. Association for Computational Linguistics. Noah Coccaro and Daniel Jurafsky. 1998. Towards better integration of semantic predictors in statistical language modeling. In Proceedings of the 5th International Conference on Spoken Language Processing, Sydney. George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proceedings of the second International conference on Human Language Technology Research, pages 138–145, San Diego. Jason Eisner and Roy W. Tromble. 2006. Local search with very large-scale neighborhoods for optimal permutations in machine translation. In Proceedings of the HLT-NAACL Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing, pages 57–75. Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In Interspeech 2008, pages 1618–1621 . ISCA. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2001 . Fast decoding and optimal decoding for machine translation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 228–235, Toulouse, France, July. Association for Computational Linguis- tics. Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu, and Kenji Yamada. 2004. Fast and optimal decoding for machine translation. Artificial Intelligence, 154(1–2): 127–143. Ulrich Germann. 2003. Greedy decoding for Statistical Machine Translation in almost linear time. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. Zhengxian Gong, Min Zhang, and Guodong Zhou. 2011. Cache-based document-level Statistical Machine Translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 909–919, Edinburgh, Scotland, UK., July. Association for Computational Linguistics. Christian Hardmeier and Marcello Federico. 2010. Modelling Pronominal Anaphora in Statistical Machine Translation. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 283–289. Basil Hatim and Ian Mason. 1990. Discourse and the Translator. Language in Social Life Series. Longman, London. Kenneth Heafield. 2011. KenLM: faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, July. Association for Computational Linguistics. Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 967– 975, Prague, Czech Republic, June. Association for Computational Linguistics. David Jurgens and Keith Stevens. 2010. The S-Space package: An open source package for word space models. In Proceedings of the ACL 2010 System Demonstrations, pages 30–35, Uppsala, Sweden, July. Association for Computational Linguistics. Woosung Kim and Sanjeev Khudanpur. 2004. Crosslingual latent semantic analysis for language modeling. In IEEE international conference on acoustics, speech, and signal processing (ICASSP), volume 1, pages 257–260, Montr ´eal. Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 conference of the North American chapter of the Association for Computational Linguistics on Human Language Technology, pages 48– 54, Edmonton. 1189 Philipp Koehn, Hieu Hoang, Alexandra Birch, et al. 2007. Moses: open source toolkit for Statistical Machine Translation. In Annual meeting of the Association for Computational Linguistics: Demonstration session, pages 177–180, Prague. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2007. A greedy decoder for phrase-based statistical machine translation. In TMI-2007: Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 104–1 13, Sk¨ ovde. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2008. Recherche locale pour la traduction statistique par segments. In TALN 2008, pages 119–128, Avignon, France, June. ATALA. Ronan Le Nagard and Philipp Koehn. 2010. Aiding pronoun translation with co-reference resolution. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 252–261, Uppsala, Sweden, July. Association for Computational Linguistics. Franz Josef Och, Nicola Ueffing, and Hermann Ney. 2001. An efficient A* search algorithm for Statistical Machine Translation. In Proceedings of the DataDriven Machine Translation Workshop, 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 55–62, Toulouse. Franz Josef Och. 2003. Minimum error rate training in Statistical Machine Translation. In Proceedings of the 41st annual meeting of the Association for Computational Linguistics, pages 160–167, Sapporo (Japan). Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of Machine Translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 3 11–3 18, Philadelphia. ACL. Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007. Bilingual LSA-based adaptation for Statistical Machine Translation. Machine Translation, 21(4): 187– 207. J o¨rg Tiedemann. 2010. To cache or not to cache? Experiments with adaptive models in Statistical Machine Translation. In Proceedings of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and Metrics MATR, pages 189–194, Uppsala, Sweden. Association for Computational Linguistics. Christoph Tillmann and Hermann Ney. 2003. Word reordering and a Dynamic Programming beam search algorithm for Statistical Machine Translation. Computational linguistics, 29(1):97–133. Christoph Tillmann, Stephan Vogel, Hermann Ney, and Alex Zubiaga. 1997. A DP-based search using monotone alignments in Statistical Translation. In Proceedings of the 35th Annual Meeting of the Association for Computational Spain, tics. Linguistics, July. Association for 289–296, Madrid, Computational Linguis- pages Tonio Wandmacher and Jean-Yves Antoine. 2007. Methods to integrate a language model with semantic information for a word prediction component. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 506–5 13, Prague, Czech Republic, June. Association for Computational Linguistics. 1190</p><p>3 0.66615295 <a title="35-lda-3" href="./emnlp-2012-Open_Language_Learning_for_Information_Extraction.html">100 emnlp-2012-Open Language Learning for Information Extraction</a></p>
<p>Author: Mausam ; Michael Schmitz ; Stephen Soderland ; Robert Bart ; Oren Etzioni</p><p>Abstract: Open Information Extraction (IE) systems extract relational tuples from text, without requiring a pre-specified vocabulary, by identifying relation phrases and associated arguments in arbitrary sentences. However, stateof-the-art Open IE systems such as REVERB and WOE share two important weaknesses (1) they extract only relations that are mediated by verbs, and (2) they ignore context, thus extracting tuples that are not asserted as factual. This paper presents OLLIE, a substantially improved Open IE system that addresses both these limitations. First, OLLIE achieves high yield by extracting relations mediated by nouns, adjectives, and more. Second, a context-analysis step increases precision by including contextual information from the sentence in the extractions. OLLIE obtains 2.7 times the area under precision-yield curve (AUC) compared to REVERB and 1.9 times the AUC of WOEparse. –</p><p>4 0.64931023 <a title="35-lda-4" href="./emnlp-2012-A_Systematic_Comparison_of_Phrase_Table_Pruning_Techniques.html">11 emnlp-2012-A Systematic Comparison of Phrase Table Pruning Techniques</a></p>
<p>Author: Richard Zens ; Daisy Stanton ; Peng Xu</p><p>Abstract: When trained on very large parallel corpora, the phrase table component of a machine translation system grows to consume vast computational resources. In this paper, we introduce a novel pruning criterion that places phrase table pruning on a sound theoretical foundation. Systematic experiments on four language pairs under various data conditions show that our principled approach is superior to existing ad hoc pruning methods.</p><p>5 0.59868753 <a title="35-lda-5" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>Author: Ni Lao ; Amarnag Subramanya ; Fernando Pereira ; William W. Cohen</p><p>Abstract: We study how to extend a large knowledge base (Freebase) by reading relational information from a large Web text corpus. Previous studies on extracting relational knowledge from text show the potential of syntactic patterns for extraction, but they do not exploit background knowledge of other relations in the knowledge base. We describe a distributed, Web-scale implementation of a path-constrained random walk model that learns syntactic-semantic inference rules for binary relations from a graph representation of the parsed text and the knowledge base. Experiments show significant accuracy improvements in binary relation prediction over methods that consider only text, or only the existing knowledge base.</p><p>6 0.57300019 <a title="35-lda-6" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>7 0.57063788 <a title="35-lda-7" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>8 0.56789839 <a title="35-lda-8" href="./emnlp-2012-PATTY%3A_A_Taxonomy_of_Relational_Patterns_with_Semantic_Types.html">103 emnlp-2012-PATTY: A Taxonomy of Relational Patterns with Semantic Types</a></p>
<p>9 0.56154704 <a title="35-lda-9" href="./emnlp-2012-On_Amortizing_Inference_Cost_for_Structured_Prediction.html">99 emnlp-2012-On Amortizing Inference Cost for Structured Prediction</a></p>
<p>10 0.5561887 <a title="35-lda-10" href="./emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">85 emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>11 0.55552924 <a title="35-lda-11" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>12 0.55341923 <a title="35-lda-12" href="./emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities.html">98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</a></p>
<p>13 0.55088902 <a title="35-lda-13" href="./emnlp-2012-Source_Language_Adaptation_for_Resource-Poor_Machine_Translation.html">118 emnlp-2012-Source Language Adaptation for Resource-Poor Machine Translation</a></p>
<p>14 0.55002749 <a title="35-lda-14" href="./emnlp-2012-Language_Model_Rest_Costs_and_Space-Efficient_Storage.html">74 emnlp-2012-Language Model Rest Costs and Space-Efficient Storage</a></p>
<p>15 0.54826915 <a title="35-lda-15" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>16 0.5454945 <a title="35-lda-16" href="./emnlp-2012-Translation_Model_Based_Cross-Lingual_Language_Model_Adaptation%3A_from_Word_Models_to_Phrase_Models.html">128 emnlp-2012-Translation Model Based Cross-Lingual Language Model Adaptation: from Word Models to Phrase Models</a></p>
<p>17 0.53718048 <a title="35-lda-17" href="./emnlp-2012-A_Unified_Approach_to_Transliteration-based_Text_Input_with_Online_Spelling_Correction.html">13 emnlp-2012-A Unified Approach to Transliteration-based Text Input with Online Spelling Correction</a></p>
<p>18 0.53698075 <a title="35-lda-18" href="./emnlp-2012-A_Discriminative_Model_for_Query_Spelling_Correction_with_Latent_Structural_SVM.html">5 emnlp-2012-A Discriminative Model for Query Spelling Correction with Latent Structural SVM</a></p>
<p>19 0.53476518 <a title="35-lda-19" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>20 0.53120565 <a title="35-lda-20" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
