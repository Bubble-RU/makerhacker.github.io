<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-34" href="#">emnlp2012-34</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</h1>
<br/><p>Source: <a title="emnlp-2012-34-pdf" href="http://aclweb.org/anthology//D/D12/D12-1060.pdf">pdf</a></p><p>Author: Natalia Ponomareva ; Mike Thelwall</p><p>Abstract: This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm. We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.</p><p>Reference: <a title="emnlp-2012-34-reference" href="../emnlp2012_reference/emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. [sent-5, score-0.425]
</p><p>2 We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. [sent-7, score-0.561]
</p><p>3 Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains. [sent-8, score-0.38]
</p><p>4 1 Introduction The sentiment classification (SC) is an active area of research concerned automatic identification of sentiment strength or valence of texts. [sent-9, score-0.798]
</p><p>5 In this paper, we focus on cross-domain methods in order to take advantage of the huge amount of annotated sentiment data available on the Internet. [sent-14, score-0.399]
</p><p>6 Our aim is to find out to what extent it is possible to learn sentiment phenomena from these data and transfer them to new domains rather than induce them from scratch for each new domain. [sent-15, score-0.551]
</p><p>7 This is largely because the sentiment words and their valences depend a lot on the domain where they are expressed. [sent-20, score-0.616]
</p><p>8 For example, a word “ridiculous” in book reviews may express a negative meaning when talking about a book content, however for reviews on electronics this word can bear a positive meaning when talking about prices. [sent-22, score-0.41]
</p><p>9 Another and more common problem is related to sentiment words that are specific for each domain. [sent-23, score-0.399]
</p><p>10 At the same time, the electronics domain can contain words like “defective”, “refund”, “return”, “customer service”, which are very unusual for book reviews. [sent-25, score-0.315]
</p><p>11 Several cross-domain approaches have been suggested recently to solve the problem of accuracy loss in cross-domain sentiment classification,  namely Structural Correspondence Learning (SCL) (Blitzer et al. [sent-26, score-0.43]
</p><p>12 This data representation takes into account not only document contents but also document connectivity which is modeled as document sentiment similarity rather than content similarity. [sent-31, score-0.848]
</p><p>13 First, graph-based domain representations can benefit from two independent sources of information: scores given by a machine learning technique which indicate the probability of a document to belong to a sentiment class and similarity relations between documents. [sent-35, score-0.896]
</p><p>14 Second, unlike other suggested methods, this approach can be easily adapted to multiple classes, which makes it possible to classify documents using finer-grained sentiment scales. [sent-36, score-0.399]
</p><p>15 Moreover, in the framework of the domain adaption task, we come across the problem of choosing the best set of parameters, which, as we further demonstrate, depends on the characteristics of a corresponding domain pair. [sent-39, score-0.525]
</p><p>16 First, we compare two graph-based algorithms in cross-domain SC settings: the algorithm exploited in (Goldberg and Zhu, 2006), which seeks document sentiments as an output of an optimisation problem (OPTIM) and the algorithm adopted by (Wu et al. [sent-45, score-0.344]
</p><p>17 , 2009), that uses ranking  to assign sentiment scores (RANK). [sent-46, score-0.428]
</p><p>18 Second, as document similarity is a crucial factor for satisfactory performance of graph-based algorithms, we suggest and evaluate various sentiment similarity measures. [sent-47, score-0.697]
</p><p>19 Sentiment similarity is different from topic similarity as it compares documents with respect to the sentiment they convey rather than their topic. [sent-48, score-0.631]
</p><p>20 Finally, we discover the dependency of algorithm parameter values on domain properties and, subsequently, the impossibility to find universal parameter values suitable for all domain pairs. [sent-49, score-0.51]
</p><p>21 We discuss a possible strategy for choosing the 656 best set of parameters based on our previous study (Ponomareva and Thelwall, 2012), where we introduced two domain characteristics: domain similarity and domain complexity and demonstrated their strong correlation with cross-domain accuracy loss. [sent-50, score-0.909]
</p><p>22 In  Section 4 we discuss an issue of document similarity and select document representation that correlates best with document sentiments. [sent-54, score-0.449]
</p><p>23 2  Related work  Cross-domain sentiment analysis has received considerable attention during the last five years and, since then, several approaches to tackle this problem have emerged. [sent-57, score-0.399]
</p><p>24 Its underlying idea is to find correspondences between features from source and target domains through modeling their correlations with pivot features. [sent-64, score-0.386]
</p><p>25 Pivot features are features occurring frequently in both domains, which, at the same time, serve as good predictors of document classes, like the general sentiment words “excellent” and “awful”. [sent-65, score-0.519]
</p><p>26 The extraction of pivot features was made on the basis of their frequency in source and target corpora and their mutual information with positive and negative source labels. [sent-66, score-0.327]
</p><p>27 The correlations between the pivot features and all other features were modeled using a supervised learning of linear pivot predictors to predict occurrences of each pivot in both domains. [sent-67, score-0.275]
</p><p>28 The proposed approach was tested on review data from 4 domains (books, DVDs, kitchen appliances and electronics) and demonstrated a significant  gain of accuracy for most domain pairs compared to the baseline. [sent-68, score-0.429]
</p><p>29 However, for a few domains the performance degraded due to feature misalignment: the narrowness of the source domain and diversity of the target domain created false projections of features in the target domain. [sent-69, score-0.754]
</p><p>30 , an alignment of source and target features through their co-occurrences with general sentiment words. [sent-74, score-0.512]
</p><p>31 But instead of learning representations of pivots in source and target domains the authors used spectral clustering to align domain-specific and domain-independent words into a set of featureclusters. [sent-75, score-0.358]
</p><p>32 The constructed clusters were then used for the representation of all data examples and training the sentiment classifier. [sent-76, score-0.399]
</p><p>33 This new solution yields a significant improvement on cross-domain accuracy compared with SCL for almost all domain pairs. [sent-77, score-0.304]
</p><p>34 They compare the accuracy of their approach with an average accuracy over the results 657 with the same target domain given by SCL and SFA, and concluded that their method surpasses all existing approaches. [sent-83, score-0.4]
</p><p>35 Therefore, instead of average accuracies, the best accuracies with respect  to the same target domain should be compared. [sent-86, score-0.352]
</p><p>36 Each unlabeled document xi is connected to its kE ancehar uenslta lbaebleelded d odcoucmumenetn xts kNNL (i) (source domain neighbours). [sent-105, score-0.555]
</p><p>37 The weight between xi and xj ∈ kNNL(i) is measured by a given similarity w aNndN denoted a · wij. [sent-106, score-0.281]
</p><p>38 • Each unlabeled document xi is connected to Eitsa ckh0 nuenlaarebsetl eudnl daboeculemde dnotc xuments k0NNU(i) (target domain neighbours). [sent-107, score-0.555]
</p><p>39 The algorithm is based on the assumption that the rating function f(x) is smooth with respect to the graph, so there are no harsh jumps of sentiment between nearest neighbours. [sent-110, score-0.472]
</p><p>40 To satisfy the smoothness condition sentiment variability between the closest nodes should be minimised. [sent-111, score-0.463]
</p><p>41 2 RANK algorithm The RANK algorithm has a similar graph structure (Figure 1B): nodes represent labeled and unlabeled documents and there is a parameter (in this case γ) that controls the relative importance of labeled data over unlabeled data and is an analogue of β in OPTIM. [sent-117, score-0.265]
</p><p>42 However, there are no edges between nodes and their initial sentiments because RANK is an iterative algorithm and each iteration gives new scores to unlabeled nodes while labeled nodes remain constant. [sent-119, score-0.293]
</p><p>43 More precisely, on each iteration sentiment scores of unlabeled documents are updated on the basis of the weighted sum of sentiment scores of the nearest labeled neighbours and the nearest unlabeled neighbours. [sent-120, score-1.322]
</p><p>44 the difference in sentiment scores is less than a predefined tolerance. [sent-123, score-0.428]
</p><p>45 Using the same notation as for OPTIM we can formulate the iterative procedure in the following way:  fk(xi)  =  X γwijf(xj)+ j∈kXNNL  (i)  X  (1 − γ)wijfk−1xj)  (3)  j∈k0XNNU(i) where fk (xi) is the node sentiment score on the k-th iteration. [sent-124, score-0.428]
</p><p>46 It is worth noting that initially the authors did not consider having a different number of neighbours for the source and target domains. [sent-127, score-0.373]
</p><p>47 The only principal difference concerns the requirement of closeness of initial and final sentiment scores for  659 OPTIM. [sent-130, score-0.469]
</p><p>48 4  Measure of document similarity  A good measure of document similarity is a key factor for the successful performance of graph-based algorithms. [sent-132, score-0.418]
</p><p>49 In this section we propose and evaluate several measures of document similarity based on different vector representations and the cosine of document vectors. [sent-133, score-0.371]
</p><p>50 However, we assume that we do not know anything about the domain when measuring sentiment similarity and, thus, we should establish  the appropriate set of features only relying on our prior knowledge about sentiment words. [sent-137, score-1.104]
</p><p>51 According to previous studies, adjectives, verbs and adverbs are good indicators of sentiment (Pang and Lee, 2008), therefore, we keep only unigrams and bigrams that contain these PoS. [sent-138, score-0.399]
</p><p>52 To overcome this issue we introduce a new measure that uses sentiment dictionaries to add nouns expressing sentiments (Fidf+SOCAL). [sent-141, score-0.486]
</p><p>53 - lexicon-based: uses sentiment dictionaries to assign scores to lexical elements oftwo types: words or sentences. [sent-142, score-0.428]
</p><p>54 The dimension of the corresponding document vector representation conforms with the granularity of the sentiment scale. [sent-143, score-0.519]
</p><p>55 For example, in case of binary sentiment scales, a document vector consists of two dimensions, where first component corresponds to the percentage of positive words (sentences) and the second component to the percentage of negative words (sentences). [sent-144, score-0.545]
</p><p>56 To assign sentiment scores to lexical elements we exploit different sentiment resources, namely  Table1:CorlatinfordvaDBmrKEiLVOoIauisnmF0ilt. [sent-145, score-0.827]
</p><p>57 SentiWordNet demonstrates quite an unsatisfactory performance, while SentiStrength, being very precise, has an insufficient scope and, therefore, finds no sentiment in a substantial number of documents. [sent-157, score-0.399]
</p><p>58 The best document representation is selected on the basis of its correlation with the sentiment scores of documents. [sent-158, score-0.64]
</p><p>59 Feature-based representations demonstrate significantly better correlations with document sentiments although for some domains, like DV, the lexical element-based representation produces a similar result. [sent-163, score-0.293]
</p><p>60 Reviews are rated using a binary scale, 1-2 star reviews are considered as 660  negative and 4-5 star reviews as positive. [sent-168, score-0.252]
</p><p>61 First, we compute a baseline for each domain pair by training a Support Vector Machines (SVMs) classifier using one domain as training data and another as test data. [sent-170, score-0.434]
</p><p>62 1  domain accuracies for all domain Products on the x-axis represent source domains and products 1We should point out that in the images the shading between points is not intended to suggest interpolation but is used to highlight the overall pattern. [sent-177, score-0.698]
</p><p>63 Of course the pattern depends on a domain order on the axes, therefore, similar domains are placed together to make the regions with high and low accuracies evident. [sent-178, score-0.468]
</p><p>64 The isolines  image of the baseline accuracy delivers a good representation of domain relations. [sent-180, score-0.338]
</p><p>65 As shown in our previous study (Ponomareva and Thelwall, 2012) the first two regions conform with the most similar domain pairs BO, DV and EL, KI. [sent-182, score-0.262]
</p><p>66 We give the best accuracies achieved by these algorithms for each domain pair. [sent-187, score-0.321]
</p><p>67 In general, RANK consistently outperforms OPTIM for all domain pairs, OPTIM shows competitive performance only for the pairs of similar domains BO-DV, KI-EL and EL-KI. [sent-190, score-0.369]
</p><p>68 Such behaviour for RANK suggests a positive answer to our question stated in the title: even if domains are quite different, neighbours from the same domain will fix these discrepancies. [sent-195, score-0.629]
</p><p>69 According to Table 2, RANK surpasses SCL for almost all domain pairs with an average difference equal to 2%. [sent-202, score-0.279]
</p><p>70 However Figure 3 suggests an interesting finding: that for domains with different complexities swapping source and target also changes the method that produces the  best performance. [sent-205, score-0.265]
</p><p>71 It seems that RANK works better when the target domain is simpler, maybe because it can benefit more from in-domain neighbours of the less rich and ambiguous domain. [sent-208, score-0.559]
</p><p>72 In the future, we plan to increase the impact of lexically different but reliably labeled source data by implementing the SFA algorithm and measuring document similarity between feature clusters rather than separate features. [sent-209, score-0.322]
</p><p>73 Table 3 lists the best parameter values of the RANK algorithm over several domain pairs. [sent-211, score-0.255]
</p><p>74 Our attempt to establish some universal values valid for all domain pairs was not successful as the choice of the parameters depends upon the domain properties. [sent-212, score-0.472]
</p><p>75 The values are given on various domain pairs not have a knowledge of the parameter values which produce the best performance and, therefore, it would be useful to elaborate a strategy for choosing the optimal values with respect to a corresponding  domain pair. [sent-222, score-0.628]
</p><p>76 In our previous work (Ponomareva and Thelwall, 2012) we introduced two domain characteristics: domain similarity and domain complexity variance and proved their impact into the cross-domain accuracy loss. [sent-223, score-0.886]
</p><p>77 Domain similarity and complexity are independent properties of a domain pair as the former measures similarity of data distributions for frequent words, while the latter compares the tails of distributions. [sent-224, score-0.468]
</p><p>78 As a result, inversed χ2 was proved to be the best measure of domain similarity as it gave the highest correlation with the cross-domain accuracy drop. [sent-226, score-0.42]
</p><p>79 The percentage of rare words (words that occur less than 3 times) was found to be the closest approximation to domain complexity as it showed 663 the highest correlation with the in-domain accuracy drop. [sent-227, score-0.332]
</p><p>80 It is naturally to assume that if domain similarity and complexity are responsible for the cross-domain accuracy loss, they might influence on the parameter  values of domain adaptation algorithms. [sent-228, score-0.637]
</p><p>81 Table 4 shows that γ is the lowest for dissimilar domains with a simpler target (negative values of domain complexity variance), which means that the RANK algorithm benefits the most from unlabeled but simpler data. [sent-231, score-0.622]
</p><p>82 6 for dissimilar domains with more complex target (positive values of domain complexity variance), which shows that the impact of simpler source data, though different from target, increases. [sent-233, score-0.591]
</p><p>83 High dependency of γ on both domain characteristics is proved numerically. [sent-237, score-0.298]
</p><p>84 The correlation between γ and domain similarity and complexity reaches 0. [sent-238, score-0.39]
</p><p>85 In our opinion, that is an effect of choosing the neighbours on the basis of the quantitative threshold. [sent-241, score-0.367]
</p><p>86 Nevertheless, different domains have distinct pairwise document similarity distributions. [sent-242, score-0.361]
</p><p>87 In our further research we plan to explore the idea of a qualitative threshold, which chooses neighbours according to their similarity and uses the same similarity levels for in-domain and cross-domain graphs. [sent-245, score-0.466]
</p><p>88 7  Conclusions and future work  This paper has studied the performance of two graph-based algorithms, OPTIM and RANK when applied to cross-domain sentiment classification. [sent-246, score-0.399]
</p><p>89 In this paper, we also discuss some ideas about how to infer optimal parameter values for the algorithms on the basis of domain characteristics. [sent-250, score-0.358]
</p><p>90 In particular, the strong correlation for γ with domain similarity and complexity has been observed. [sent-251, score-0.39]
</p><p>91 Unfortunately we are not able to find any regularity in the number of source and target domain neighbours, which we think is the result of the qualitative approach to  664 selecting the closest neighbours. [sent-252, score-0.365]
</p><p>92 First, we plan to improve the RANK performance by choosing the number of neighbours on the basis of the document similarity threshold which we set equal for both in-domain and cross-domain neighbours. [sent-254, score-0.604]
</p><p>93 We expect that this modification will diminish the number of “bad” neighbours and allow us to reveal a dependency of similarity threshold on some domain properties. [sent-255, score-0.566]
</p><p>94 Finally, as all our conclusions have been drawn on a data set of 12 domain pairs, we plan to increase a number of domains to verify our findings on larger data sets. [sent-257, score-0.397]
</p><p>95 Customizing sentiment classifiers to new domains: A case study. [sent-262, score-0.399]
</p><p>96 Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. [sent-270, score-0.399]
</p><p>97 Using multiple sources to construct a sentiment sensitive thesaurus for cross-domain sentiment classification. [sent-274, score-0.828]
</p><p>98 Seeing stars when there aren’t many stars: graph-based semi-supervised learning for sentiment categorization. [sent-292, score-0.44]
</p><p>99 Seeing stars: exploiting class relationships for sentiment categorization with respect to rating scales. [sent-304, score-0.472]
</p><p>100 Bibliographies or blenders: Which resource is best for cross-domain sentiment analysis? [sent-312, score-0.399]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sentiment', 0.399), ('optim', 0.312), ('scl', 0.303), ('sfa', 0.282), ('neighbours', 0.26), ('rank', 0.224), ('domain', 0.217), ('fidf', 0.161), ('ponomareva', 0.161), ('thelwall', 0.161), ('domains', 0.152), ('xi', 0.122), ('document', 0.12), ('similarity', 0.089), ('optimisation', 0.087), ('socal', 0.087), ('sentiments', 0.087), ('reviews', 0.084), ('goldberg', 0.078), ('pivot', 0.077), ('zhu', 0.071), ('xj', 0.07), ('pang', 0.064), ('unlabeled', 0.063), ('aue', 0.061), ('isolines', 0.061), ('sentiwordnet', 0.061), ('electronics', 0.058), ('source', 0.058), ('graph', 0.056), ('target', 0.055), ('blitzer', 0.055), ('dv', 0.054), ('choosing', 0.054), ('wu', 0.054), ('accuracies', 0.054), ('basis', 0.053), ('spectral', 0.051), ('algorithms', 0.05), ('rating', 0.047), ('complexity', 0.045), ('regions', 0.045), ('proved', 0.044), ('correlations', 0.044), ('sc', 0.042), ('representations', 0.042), ('concerns', 0.041), ('stars', 0.041), ('pan', 0.041), ('cybermetrics', 0.04), ('dvds', 0.04), ('knnl', 0.04), ('kxnnl', 0.04), ('misalignment', 0.04), ('sentistrength', 0.04), ('wlv', 0.04), ('wolverhampton', 0.04), ('book', 0.04), ('correlation', 0.039), ('values', 0.038), ('characteristics', 0.037), ('bo', 0.037), ('taboada', 0.035), ('bollegala', 0.035), ('esuli', 0.035), ('regularity', 0.035), ('smoothness', 0.035), ('surpasses', 0.035), ('connected', 0.033), ('xiaojin', 0.031), ('blenders', 0.031), ('concluded', 0.031), ('libsvm', 0.031), ('natalia', 0.031), ('accuracy', 0.031), ('thesaurus', 0.03), ('nodes', 0.029), ('image', 0.029), ('gamon', 0.029), ('kitchen', 0.029), ('fk', 0.029), ('star', 0.029), ('scores', 0.029), ('solution', 0.029), ('plan', 0.028), ('compares', 0.028), ('gradient', 0.027), ('maybe', 0.027), ('labeled', 0.027), ('almost', 0.027), ('simpler', 0.026), ('respect', 0.026), ('uk', 0.026), ('variance', 0.026), ('talking', 0.026), ('wij', 0.026), ('bear', 0.026), ('tfidf', 0.026), ('negative', 0.026), ('inside', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="34-tfidf-1" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>Author: Natalia Ponomareva ; Mike Thelwall</p><p>Abstract: This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm. We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.</p><p>2 0.15544474 <a title="34-tfidf-2" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>Author: Jong-Hoon Oh ; Kentaro Torisawa ; Chikara Hashimoto ; Takuya Kawada ; Stijn De Saeger ; Jun'ichi Kazama ; Yiou Wang</p><p>Abstract: In this paper we explore the utility of sentiment analysis and semantic word classes for improving why-question answering on a large-scale web corpus. Our work is motivated by the observation that a why-question and its answer often follow the pattern that if something undesirable happens, the reason is also often something undesirable, and if something desirable happens, the reason is also often something desirable. To the best of our knowledge, this is the first work that introduces sentiment analysis to non-factoid question answering. We combine this simple idea with semantic word classes for ranking answers to why-questions and show that on a set of 850 why-questions our method gains 15.2% improvement in precision at the top-1 answer over a baseline state-of-the-art QA system that achieved the best performance in a shared task of Japanese non-factoid QA in NTCIR-6.</p><p>3 0.15045419 <a title="34-tfidf-3" href="./emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>Author: Shoushan Li ; Shengfeng Ju ; Guodong Zhou ; Xiaojun Li</p><p>Abstract: Active learning is a promising way for sentiment classification to reduce the annotation cost. In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. This scenario posits new challenges to active learning. To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce humanannotation efforts. Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. 1</p><p>4 0.13232686 <a title="34-tfidf-4" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>Author: Richard Socher ; Brody Huval ; Christopher D. Manning ; Andrew Y. Ng</p><p>Abstract: Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.</p><p>5 0.12005671 <a title="34-tfidf-5" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>Author: Lizhen Qu ; Rainer Gemulla ; Gerhard Weikum</p><p>Abstract: We propose the weakly supervised MultiExperts Model (MEM) for analyzing the semantic orientation of opinions expressed in natural language reviews. In contrast to most prior work, MEM predicts both opinion polarity and opinion strength at the level of individual sentences; such fine-grained analysis helps to understand better why users like or dislike the entity under review. A key challenge in this setting is that it is hard to obtain sentence-level training data for both polarity and strength. For this reason, MEM is weakly supervised: It starts with potentially noisy indicators obtained from coarse-grained training data (i.e., document-level ratings), a small set of diverse base predictors, and, if available, small amounts of fine-grained training data. We integrate these noisy indicators into a unified probabilistic framework using ideas from ensemble learning and graph-based semi-supervised learning. Our experiments indicate that MEM outperforms state-of-the-art methods by a significant margin.</p><p>6 0.11899964 <a title="34-tfidf-6" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>7 0.1120011 <a title="34-tfidf-7" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>8 0.105015 <a title="34-tfidf-8" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>9 0.10490745 <a title="34-tfidf-9" href="./emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">36 emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>10 0.093409546 <a title="34-tfidf-10" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>11 0.084354907 <a title="34-tfidf-11" href="./emnlp-2012-A_New_Minimally-Supervised_Framework_for_Domain_Word_Sense_Disambiguation.html">6 emnlp-2012-A New Minimally-Supervised Framework for Domain Word Sense Disambiguation</a></p>
<p>12 0.083517723 <a title="34-tfidf-12" href="./emnlp-2012-Collocation_Polarity_Disambiguation_Using_Web-based_Pseudo_Contexts.html">28 emnlp-2012-Collocation Polarity Disambiguation Using Web-based Pseudo Contexts</a></p>
<p>13 0.067431405 <a title="34-tfidf-13" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>14 0.064003572 <a title="34-tfidf-14" href="./emnlp-2012-Spectral_Dependency_Parsing_with_Latent_Variables.html">119 emnlp-2012-Spectral Dependency Parsing with Latent Variables</a></p>
<p>15 0.062854685 <a title="34-tfidf-15" href="./emnlp-2012-Opinion_Target_Extraction_Using_Word-Based_Translation_Model.html">101 emnlp-2012-Opinion Target Extraction Using Word-Based Translation Model</a></p>
<p>16 0.057959851 <a title="34-tfidf-16" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>17 0.053739835 <a title="34-tfidf-17" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>18 0.053561017 <a title="34-tfidf-18" href="./emnlp-2012-Learning_to_Map_into_a_Universal_POS_Tagset.html">81 emnlp-2012-Learning to Map into a Universal POS Tagset</a></p>
<p>19 0.049062006 <a title="34-tfidf-19" href="./emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">112 emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>20 0.048194438 <a title="34-tfidf-20" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.207), (1, 0.097), (2, 0.025), (3, 0.217), (4, 0.134), (5, -0.043), (6, -0.068), (7, 0.022), (8, 0.217), (9, -0.083), (10, 0.009), (11, 0.169), (12, 0.027), (13, -0.001), (14, 0.128), (15, 0.078), (16, 0.009), (17, 0.142), (18, -0.004), (19, 0.054), (20, -0.026), (21, -0.144), (22, 0.166), (23, -0.048), (24, 0.024), (25, -0.089), (26, 0.062), (27, -0.018), (28, -0.031), (29, -0.099), (30, -0.079), (31, -0.07), (32, -0.078), (33, -0.014), (34, 0.087), (35, 0.03), (36, -0.183), (37, -0.104), (38, -0.071), (39, -0.09), (40, -0.058), (41, 0.037), (42, -0.017), (43, -0.024), (44, 0.027), (45, -0.016), (46, 0.035), (47, 0.06), (48, 0.046), (49, -0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95878035 <a title="34-lsi-1" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>Author: Natalia Ponomareva ; Mike Thelwall</p><p>Abstract: This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm. We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.</p><p>2 0.7063399 <a title="34-lsi-2" href="./emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">15 emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>Author: Shoushan Li ; Shengfeng Ju ; Guodong Zhou ; Xiaojun Li</p><p>Abstract: Active learning is a promising way for sentiment classification to reduce the annotation cost. In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. This scenario posits new challenges to active learning. To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce humanannotation efforts. Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. 1</p><p>3 0.63473594 <a title="34-lsi-3" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>Author: Mahesh Joshi ; Mark Dredze ; William W. Cohen ; Carolyn Rose</p><p>Abstract: We present a systematic analysis of existing multi-domain learning approaches with respect to two questions. First, many multidomain learning algorithms resemble ensemble learning algorithms. (1) Are multi-domain learning improvements the result of ensemble learning effects? Second, these algorithms are traditionally evaluated in a balanced class label setting, although in practice many multidomain settings have domain-specific class label biases. When multi-domain learning is applied to these settings, (2) are multidomain methods improving because they capture domain-specific class biases? An understanding of these two issues presents a clearer idea about where the field has had success in multi-domain learning, and it suggests some important open questions for improving beyond the current state of the art.</p><p>4 0.55140275 <a title="34-lsi-4" href="./emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">139 emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<p>Author: Victor Chahuneau ; Kevin Gimpel ; Bryan R. Routledge ; Lily Scherlis ; Noah A. Smith</p><p>Abstract: We investigate the use of language in food writing, specifically on restaurant menus and in customer reviews. Our approach is to build predictive models of concrete external variables, such as restaurant menu prices. We make use of a dataset of menus and customer reviews for thousands of restaurants in several U.S. cities. By focusing on prediction tasks and doing our analysis at scale, our methodology allows quantitative, objective measurements of the words and phrases used to de- scribe food in restaurants. We also explore interactions in language use between menu prices and sentiment as expressed in user reviews.</p><p>5 0.50451881 <a title="34-lsi-5" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>Author: Fei Huang ; Alexander Yates</p><p>Abstract: Representation learning is a promising technique for discovering features that allow supervised classifiers to generalize from a source domain dataset to arbitrary new domains. We present a novel, formal statement of the representation learning task. We argue that because the task is computationally intractable in general, it is important for a representation learner to be able to incorporate expert knowledge during its search for helpful features. Leveraging the Posterior Regularization framework, we develop an architecture for incorporating biases into representation learning. We investigate three types of biases, and experiments on two domain adaptation tasks show that our biased learners identify significantly better sets of features than unbiased learners, resulting in a relative reduction in error of more than 16% for both tasks, with respect to existing state-of-the-art representation learning techniques.</p><p>6 0.49353239 <a title="34-lsi-6" href="./emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">36 emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>7 0.45802099 <a title="34-lsi-7" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>8 0.41328895 <a title="34-lsi-8" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>9 0.39482769 <a title="34-lsi-9" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>10 0.3758221 <a title="34-lsi-10" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>11 0.36584279 <a title="34-lsi-11" href="./emnlp-2012-A_New_Minimally-Supervised_Framework_for_Domain_Word_Sense_Disambiguation.html">6 emnlp-2012-A New Minimally-Supervised Framework for Domain Word Sense Disambiguation</a></p>
<p>12 0.33064178 <a title="34-lsi-12" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>13 0.29039142 <a title="34-lsi-13" href="./emnlp-2012-Collocation_Polarity_Disambiguation_Using_Web-based_Pseudo_Contexts.html">28 emnlp-2012-Collocation Polarity Disambiguation Using Web-based Pseudo Contexts</a></p>
<p>14 0.25163409 <a title="34-lsi-14" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>15 0.23907387 <a title="34-lsi-15" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>16 0.23008662 <a title="34-lsi-16" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>17 0.22802545 <a title="34-lsi-17" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>18 0.22748795 <a title="34-lsi-18" href="./emnlp-2012-Supervised_Text-based_Geolocation_Using_Language_Models_on_an_Adaptive_Grid.html">121 emnlp-2012-Supervised Text-based Geolocation Using Language Models on an Adaptive Grid</a></p>
<p>19 0.22100179 <a title="34-lsi-19" href="./emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">4 emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>20 0.21629098 <a title="34-lsi-20" href="./emnlp-2012-Spectral_Dependency_Parsing_with_Latent_Variables.html">119 emnlp-2012-Spectral Dependency Parsing with Latent Variables</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.018), (16, 0.02), (25, 0.023), (34, 0.071), (60, 0.112), (63, 0.048), (64, 0.44), (65, 0.019), (70, 0.016), (74, 0.037), (76, 0.06), (80, 0.013), (86, 0.026), (95, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91991049 <a title="34-lda-1" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>Author: Hila Weisman ; Jonathan Berant ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Learning inference relations between verbs is at the heart of many semantic applications. However, most prior work on learning such rules focused on a rather narrow set of information sources: mainly distributional similarity, and to a lesser extent manually constructed verb co-occurrence patterns. In this paper, we claim that it is imperative to utilize information from various textual scopes: verb co-occurrence within a sentence, verb cooccurrence within a document, as well as overall corpus statistics. To this end, we propose a much richer novel set of linguistically motivated cues for detecting entailment between verbs and combine them as features in a supervised classification framework. We empirically demonstrate that our model significantly outperforms previous methods and that information from each textual scope contributes to the verb entailment learning task.</p><p>2 0.86830306 <a title="34-lda-2" href="./emnlp-2012-Employing_Compositional_Semantics_and_Discourse_Consistency_in_Chinese_Event_Extraction.html">38 emnlp-2012-Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction</a></p>
<p>Author: Peifeng Li ; Guodong Zhou ; Qiaoming Zhu ; Libin Hou</p><p>Abstract: Current Chinese event extraction systems suffer much from two problems in trigger identification: unknown triggers and word segmentation errors to known triggers. To resolve these problems, this paper proposes two novel inference mechanisms to explore special characteristics in Chinese via compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1</p><p>same-paper 3 0.80724883 <a title="34-lda-3" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>Author: Natalia Ponomareva ; Mike Thelwall</p><p>Abstract: This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm. We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.</p><p>4 0.67477381 <a title="34-lda-4" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>Author: Dan Garrette ; Jason Baldridge</p><p>Abstract: Past work on learning part-of-speech taggers from tag dictionaries and raw data has reported good results, but the assumptions made about those dictionaries are often unrealistic: due to historical precedents, they assume access to information about labels in the raw and test sets. Here, we demonstrate ways to learn hidden Markov model taggers from incomplete tag dictionaries. Taking the MINGREEDY algorithm (Ravi et al., 2010) as a starting point, we improve it with several intuitive heuristics. We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data. Altogether, our augmentations produce improvements to per- formance over the original MIN-GREEDY algorithm for both English and Italian data.</p><p>5 0.47472703 <a title="34-lda-5" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>Author: Lizhen Qu ; Rainer Gemulla ; Gerhard Weikum</p><p>Abstract: We propose the weakly supervised MultiExperts Model (MEM) for analyzing the semantic orientation of opinions expressed in natural language reviews. In contrast to most prior work, MEM predicts both opinion polarity and opinion strength at the level of individual sentences; such fine-grained analysis helps to understand better why users like or dislike the entity under review. A key challenge in this setting is that it is hard to obtain sentence-level training data for both polarity and strength. For this reason, MEM is weakly supervised: It starts with potentially noisy indicators obtained from coarse-grained training data (i.e., document-level ratings), a small set of diverse base predictors, and, if available, small amounts of fine-grained training data. We integrate these noisy indicators into a unified probabilistic framework using ideas from ensemble learning and graph-based semi-supervised learning. Our experiments indicate that MEM outperforms state-of-the-art methods by a significant margin.</p><p>6 0.47226092 <a title="34-lda-6" href="./emnlp-2012-N-gram-based_Tense_Models_for_Statistical_Machine_Translation.html">95 emnlp-2012-N-gram-based Tense Models for Statistical Machine Translation</a></p>
<p>7 0.4657782 <a title="34-lda-7" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>8 0.44624966 <a title="34-lda-8" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>9 0.44406229 <a title="34-lda-9" href="./emnlp-2012-Building_a_Lightweight_Semantic_Model_for_Unsupervised_Information_Extraction_on_Short_Listings.html">26 emnlp-2012-Building a Lightweight Semantic Model for Unsupervised Information Extraction on Short Listings</a></p>
<p>10 0.44175905 <a title="34-lda-10" href="./emnlp-2012-Joint_Inference_for_Event_Timeline_Construction.html">72 emnlp-2012-Joint Inference for Event Timeline Construction</a></p>
<p>11 0.43421426 <a title="34-lda-11" href="./emnlp-2012-Constructing_Task-Specific_Taxonomies_for_Document_Collection_Browsing.html">30 emnlp-2012-Constructing Task-Specific Taxonomies for Document Collection Browsing</a></p>
<p>12 0.43064067 <a title="34-lda-12" href="./emnlp-2012-Wiki-ly_Supervised_Part-of-Speech_Tagging.html">138 emnlp-2012-Wiki-ly Supervised Part-of-Speech Tagging</a></p>
<p>13 0.41323447 <a title="34-lda-13" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>14 0.41258234 <a title="34-lda-14" href="./emnlp-2012-Automatically_Constructing_a_Normalisation_Dictionary_for_Microblogs.html">22 emnlp-2012-Automatically Constructing a Normalisation Dictionary for Microblogs</a></p>
<p>15 0.40804541 <a title="34-lda-15" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>16 0.40783674 <a title="34-lda-16" href="./emnlp-2012-Revisiting_the_Predictability_of_Language%3A_Response_Completion_in_Social_Media.html">114 emnlp-2012-Revisiting the Predictability of Language: Response Completion in Social Media</a></p>
<p>17 0.40474346 <a title="34-lda-17" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>18 0.40436876 <a title="34-lda-18" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>19 0.40410936 <a title="34-lda-19" href="./emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">64 emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<p>20 0.40379962 <a title="34-lda-20" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
