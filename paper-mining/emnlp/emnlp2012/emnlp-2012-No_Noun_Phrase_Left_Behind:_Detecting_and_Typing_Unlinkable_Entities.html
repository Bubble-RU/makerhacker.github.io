<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-98" href="#">emnlp2012-98</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</h1>
<br/><p>Source: <a title="emnlp-2012-98-pdf" href="http://aclweb.org/anthology//D/D12/D12-1082.pdf">pdf</a></p><p>Author: Thomas Lin ; Mausam ; Oren Etzioni</p><p>Abstract: Entity linking systems link noun-phrase mentions in text to their corresponding Wikipedia articles. However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles. In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities. Our proposed method for detecting unlinkable entities achieves 24% greater accuracy than a Named Entity Recognition baseline, and our method for fine-grained typing is able to propagate over 1,000 types from linked Wikipedia entities to unlinkable entities. Detection and typing of unlinkable entities can increase yield for NLP applications such as typed question answering.</p><p>Reference: <a title="emnlp-2012-98-reference" href="../emnlp2012_reference/emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles. [sent-4, score-1.066]
</p><p>2 In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities. [sent-5, score-1.15]
</p><p>3 Our proposed method for detecting unlinkable entities achieves 24% greater accuracy than a Named Entity Recognition baseline, and our method for fine-grained typing is able to propagate over 1,000 types from linked Wikipedia entities to unlinkable entities. [sent-6, score-1.929]
</p><p>4 Detection and typing of unlinkable entities can increase yield for NLP applications such as typed question answering. [sent-7, score-0.915]
</p><p>5 , 2006) is to identify the entities mentioned in text, and associate them with appropriate background information such as their type. [sent-9, score-0.406]
</p><p>6 Thus, entity linking has a limited and somewhat arbitrary range. [sent-14, score-0.406]
</p><p>7 ” “Pineapple juice” is not entity linked as a beverage because it is not prominent enough to have its own Wikipedia entry. [sent-17, score-0.555]
</p><p>8 As Table 1 shows, Wikipedia often has prominent entities, while missing tail and new entities of the same types. [sent-18, score-0.589]
</p><p>9 In scenarios such as intelligence analysis and local search, non-Wikipedia entities are often the most important. [sent-21, score-0.406]
</p><p>10 Hence, we introduce the unlinkable noun phrase problem: Given a noun phrase that does not link into Wikipedia, return whether it is an entity, as well its fine-grained semantic types. [sent-22, score-0.975]
</p><p>11 Deciding if a nonWikipedia noun phrase is an entity is challenging  because many of them are not entities (e. [sent-23, score-0.922]
</p><p>12 lc L2a0n1g2ua Agseso Pcrioactieosnsi fnogr a Cnodm Cpoumtaptiuotna tilo Lnianlg Nuaist uircasl ing semantic types is a challenge because of the diversity of entity types in general text. [sent-29, score-0.479]
</p><p>13 The first part of this paper proposes a novel method for detecting entities by observing that entities often have different usage-over-time characteristics than non-entities. [sent-31, score-0.864]
</p><p>14 , 2011) can be adapted and scaled to semantically type general noun-phrase entities using types from linked entities, by leveraging over one million different possible textual relations. [sent-34, score-0.85]
</p><p>15 Contributions of our research include: •  We motivate and introduce the unlinkable noun  •  •  •  2  phrase problem, winthriochdu ecxet ethneds u previous wnoournk in entity linking. [sent-35, score-0.875]
</p><p>16 Background  In this section we provide an overview of entity linking, how we entity link our data set, and describe how our problem and approach differ from related areas such as NER and Web extraction. [sent-39, score-0.609]
</p><p>17 1 Entity Linking Given text, the task of entity linking (Bunescu and Pas ¸ca, 2006; Cucerzan, 2007; Milne and Witten, 2008; Kulkarni et al. [sent-41, score-0.406]
</p><p>18 , 2009) is to identify the Wikipedia entities within the text, and mark them with which Wikipedia entity they correspond to. [sent-42, score-0.678]
</p><p>19 Entity linking elevates us from plain text into mean-  ingful entities that have properties, semantic types, and relationships with each other. [sent-43, score-0.603]
</p><p>20 Other entity catalogs can be used in place of Wikipedia, especially in domain-specific contexts, but general purpose linking systems all use Wikipedia because of its broad 894 general coverage, and to leverage its article texts and link structure during the linking process. [sent-44, score-0.605]
</p><p>21 A problem we observed when using entity linking systems is that despite containing over 3 million entities, Wikipedia does not cover a significant number of entities. [sent-45, score-0.453]
</p><p>22 This occurs with entities that are not prominent enough to have their own dedicated article and with entities that are very new. [sent-46, score-0.909]
</p><p>23 4 billion noun phrases participating in textual relationships, and a sizable portion of these noun phrases are entities. [sent-50, score-0.619]
</p><p>24 , 2010; Ploch, 2011), there  has been no research on whether given noun phrases that are unlinkable (for not being in Wikipedia) are entities, and how to make them usable if they are. [sent-52, score-0.599]
</p><p>25 We begin with a corpus of 15 million “(noun phrase subject, textual relation, noun phrase object)” assertions from the Web that were extracted by REVERB (Fader et al. [sent-54, score-0.656]
</p><p>26 We then employ standard entity linking techniques including string matching, prominence priors (Fader et al. [sent-57, score-0.437]
</p><p>27 In this manner, we were able to entity link the noun phrase subject of 9,699,967 extractions, while the remaining 5,028,301 extractions had no matches (mostly due to no close string matches). [sent-59, score-0.671]
</p><p>28 These are the unlinkable noun phrases we will study here. [sent-61, score-0.599]
</p><p>29 2 Named Entity Recognition Named Entity Recognition (NER) is the task of identifying named entities in text. [sent-63, score-0.478]
</p><p>30 edu text of entity linking and Wikipedia, there are many more entities than just the named entities. [sent-67, score-0.884]
</p><p>31 For example, “apple juice” and “television” are Wikipedia entities (with Wikipedia articles), but are not traditional named entities. [sent-68, score-0.478]
</p><p>32 Still, as named entities do comprise a sizable portion of our unlinkable noun phrases, we compare against a NER baseline in our entity detection step. [sent-69, score-1.281]
</p><p>33 This differs from our semantic typing of unlinked entities because our approach assumes access to corpora-level relationships between a large set of linked entities (with semantic types) and the unlinked entities. [sent-72, score-1.488]
</p><p>34 As a result we are able to propagate 1,339 Freebase semantic types from the linked entities to the unlinked entities, which is substantially more types than fine-grained NER. [sent-73, score-0.95]
</p><p>35 , 2009) to extract lists of typed entities from the Web (e. [sent-77, score-0.464]
</p><p>36 Given a noun phrase representing a person name, we return that this is a person entity even if it is not in a list of people names harvested from the Web. [sent-81, score-0.546]
</p><p>37 3  Architecture  Our goal is: given (1) a large set of linked assertions L and (2) a large set of unlinked assertions U, for each unlinkable noun phrase subject n ∈ U, predict: (1) hw uhnetlhinekra n ies an entity, saen dsu bifj so, nthe ∈n (2) trheed scett: of Freebase semantic types for n. [sent-82, score-1.35]
</p><p>38 The first component (described in Section 4) takes any  unlinkable noun phrase and outputs whether it is an entity. [sent-87, score-0.603]
</p><p>39 All n ∈ U classified as entities are placed in a steitty E. [sent-88, score-0.406]
</p><p>40 lTlh ne ∈se Ucon cdla component (described ainc eSde cintion 5) uses L and U to predict the semantic types for each entity e ∈ E. [sent-90, score-0.443]
</p><p>41 Figure 2: Usage over time for the unlinkable noun phrase “Soluble fibre,” which is an entity. [sent-94, score-0.603]
</p><p>42 4  Detecting Unlinkable Entities  This first task takes in any unlinkable noun phrase and outputs whether it is an entity. [sent-96, score-0.603]
</p><p>43 We are interested in entities that could  help populate an entity store. [sent-101, score-0.678]
</p><p>44 This is challenging because at a surface level, many entities and non-entities look similar: “Sex and the City” is an entity, while “John and David” is not. [sent-103, score-0.406]
</p><p>45 An intuition here is that when considering only unlinkable noun phrases, usage patterns across  Figure 3: Plot of  R2 vs Slope  for the usage over time of a collection of noun phrases selected for illustrative purposes. [sent-106, score-0.885]
</p><p>46 “Bluetooth technology”  R2, while  the entities often have higher slope and/or lower  actually has even higher slope, but was adjusted left to fit in this figure. [sent-108, score-0.64]
</p><p>47 Noun  phrase entities that are observed in text going back hundreds of years (e. [sent-110, score-0.478]
</p><p>48 , “Europe”) almost all have their own Wikipedia entries, so in unlinkable noun phrase space, the remaining noun phrases that are observed in text going back hundreds of years tend to be all the textual references and expressions that are not entities. [sent-112, score-0.982]
</p><p>49 We plan to use this signal to help separate the entities from the non-entities. [sent-113, score-0.406]
</p><p>50 , Figure 1) having lower slopes than entity noun phrases (e. [sent-137, score-0.512]
</p><p>51 4 million unlinked noun phrases including 17% unigrams, 5 1% bigrams, 21% trigrams, and 11% 4-grams or longer. [sent-159, score-0.441]
</p><p>52 Bigrams comprise over half the noun phrases and the books bigram data is a selfcontained download that is easier to obtain and store 897  system  correctly classified  Majority class baseline  50. [sent-160, score-0.419]
</p><p>53 In a random sample of unlinked bigrams, we found that 73% were present in the books ngram data (65% exact match, 8% caseinsensitive match only), while 27% were not (these were mostly entities or errors with non-alphabetic characters). [sent-165, score-0.751]
</p><p>54 , there are many more possible 5-grams than bigrams, so any individual 5-gram is less likely to reach the minimum threshold to be included in the books data), but as mentioned earlier, only 11% of unlinkable noun phrases were 4-grams or longer. [sent-168, score-0.74]
</p><p>55 We randomly sampled 250 unlinked bigrams that had books ngram data, and asked 2 annotators to la-  bel each as “entity,” “non-entity,” or “unclear. [sent-169, score-0.417]
</p><p>56 ” Our goal is to separate noun phrases that are clearly entities (e. [sent-170, score-0.646]
</p><p>57 , “prune juice”) from those that are clearly not entities (e. [sent-172, score-0.406]
</p><p>58 NER misses entities such as “synthetic cubism” and “hunter orange” that occur in our data but are not traditional named entities. [sent-205, score-0.478]
</p><p>59 5  Propagating Semantic Types  This second task uses a set of linked assertions L and set of unlinked assertions U to predict the semantic types for each entity e ∈ E. [sent-207, score-1.055]
</p><p>60 From L we use the set of linked entities and the textual relations they occur with. [sent-209, score-0.795]
</p><p>61 For example, L 898 might contain that the entity Microsoft links to a par-  ticular Wikipedia article, and also that it occurs with textual relations such as “has already announced” and “has released updates for. [sent-210, score-0.548]
</p><p>62 |T,h ceoirrr eesvaplounadtiionng involved only 20 semantic classes, while we use all 1,339 Freebase types covered by our entities in L. [sent-221, score-0.541]
</p><p>63 , 2008) and (Talukdar and Pereira, 2010) model relationships between instances and classes, but our unlinked entities do not come with any class information. [sent-224, score-0.634]
</p><p>64 1 Algorithm Given an entity e, our algorithm involves: (1) finding the textual relations that e is in the domain of, (2) 4data available at http://download. [sent-230, score-0.546]
</p><p>65 com/wex  predict the semantic type of a noun phrase by: (1) finding the textual relations it is in the domain of, (2) finding linked entities that are also in the domain of those textual relations, and (3) observing their semantic types. [sent-232, score-1.446]
</p><p>66 finding linked entities that are also in the domain of those textual relations, and then (3) predicting types by observing the types of those linked entities. [sent-233, score-1.024]
</p><p>67 Figure 5 illustrates how we would predict the semantic types of the noun phrase “Sun Microsystems. [sent-234, score-0.415]
</p><p>68 ” Find Similar Entities: Find the linked entities in L that are in the domain of the most relations in R. [sent-239, score-0.691]
</p><p>69 ” have the greatest overlap in textual relations because they are most often in the domain  of the same textual relations, e. [sent-241, score-0.413]
</p><p>70 Create a set S of the entities that share the most textual relations. [sent-244, score-0.591]
</p><p>71 We found keeping 10 similar entities (|S| = 10) is generally enough to predict the original entity’s types einn ethrael lfyin eanl step. [sent-245, score-0.546]
</p><p>72 Predict Types: Return the most frequent Freebase types of the entities in S as the prediction. [sent-246, score-0.478]
</p><p>73 For “Sun Microsystems,” business operation was tFhoer top predicted type s b,e”c bauussieall entities in S were observed to include business operation type. [sent-248, score-0.442]
</p><p>74 2 Edge Validity This algorithm will only be effective if entities that share textual relation strings are more likely to be of the same semantic types. [sent-250, score-0.696]
</p><p>75 To verify this, we sampled 30,000 linked entities from L that had at least 30 textual relations each, and associated each with  their 30 most frequent relations. [sent-251, score-0.795]
</p><p>76 From the 900 million possible entity pairs, we then randomly sample 500 entity pairs that shared exactly k out of 30 relations, for each k from 0 to 15. [sent-252, score-0.591]
</p><p>77 At each k we then use our sampled pairs to estimate the probability that any two entities sharing exactly k relations (out of their 30 possible) will share at least one type. [sent-253, score-0.552]
</p><p>78 We found that entities sharing more textual relations were in fact more likely to have semantic types in common. [sent-255, score-0.78]
</p><p>79 Two entities that shared exactly 0 of 30 textual relations were only 11% likely to share a semantic type, while two entities that shared exactly 10 of 30 relations were 80% likely to share a semantic type. [sent-256, score-1.369]
</p><p>80 3 Weighting Textual Relations The algorithm as currently described treats all textual relations equally, when in reality some are stronger signal to entity type than others. [sent-259, score-0.547]
</p><p>81 For example, two entities in the domain of the “came with” relation often will not share semantic types, but two entities in the domain of the “autographed” relation  will almost always share a type. [sent-260, score-1.121]
</p><p>82 To capture this intuition, we define relation weight w(r) as the observed probability (among the linked entities) that two en-  Figure 6: Entities that share more textual relations are more likely to have semantic types in common. [sent-261, score-0.612]
</p><p>83 If D(r) = all entities observed in the domain of relation r and T(e) = all Freebase types listed for entity e, then weight w(r) of a textual relation string r is:  w(r) =e1,e2∈DX(r), e16=e2|D(r)|I ·(e (1|D,e(r2) | − 1) I(e1,e2) =(01,, iofth |Ter(wei1s)e ∩. [sent-263, score-1.008]
</p><p>84 We now modify the Find Similar Entities step such that if a linked entity shares a set of relations Q with the entity being typed, then it receives a score which considers all shared relations q ∈ Q but uses the high weight lre slhaatrieonds r morPe. [sent-265, score-0.894]
</p><p>85 4 Evaluation The goal of the evaluation is to judge how well our method can predict the Freebase semantic types of entities in our scenario. [sent-269, score-0.577]
</p><p>86 Our linked entities covered 1,339 Freebase types, including many interesting types such as computer operating system, reli-  gious text, airline and baseball team. [sent-270, score-0.664]
</p><p>87 Instead, we automatically generate testing data by sampling entities from L, and then test on ability to recover the actual Freebase types (which we know). [sent-274, score-0.478]
</p><p>88 We sample a HEAD set of distinct 500 Freebase entities (drawn randomly from our set of linked extractions), and a TAIL set of 500 entities (drawn randomly from our set of linked entities). [sent-275, score-1.112]
</p><p>89 Our sampling also picks only entities that occur with at least 10 relations, which is appropriate for the Web scenario where more instances can always be queried for. [sent-277, score-0.442]
</p><p>90 For baselines we use random baseline BRandom and a frequency baseline BFrequency which always returns types in order of their frequency among all linked entities (e. [sent-278, score-0.628]
</p><p>91 For SWeighted we leave all the test set entities out when calculating global relation weights. [sent-282, score-0.448]
</p><p>92 From an assertion like “The Four Seasons is located in Hamamatsu,” our entity linker (and other entity linkers we tried) prefer linking “The Four Seasons” to Vivaldi’s music composition rather than the hotel chain. [sent-315, score-0.75]
</p><p>93 ” Our algorithm relies on accurate entity linking in L, but there is a precision/recall tradeoff to consider here because it also benefits from higher coverage of entities and relations in L. [sent-317, score-0.912]
</p><p>94 For example, an unlinkable noun phrase might simultaneously be the name of a film, a car, and a person. [sent-346, score-0.603]
</p><p>95 Instead of outputting that the noun phrase holds all of those types, a stronger output would be to realize that the noun phrase is ambiguous, determine how many senses it has, and determine which sense is being referred to in each instance. [sent-347, score-0.488]
</p><p>96 We have ideas for how to detect ambiguous entities using mutual exclusion (Carlson, 2010) and functional relations. [sent-348, score-0.44]
</p><p>97 For example, if we predict that a noun phrase has film and car types but we also observe in our linked instances that these types are  mutually exclusive, then this is good evidence that the noun phrase refers to multiple terms. [sent-349, score-0.854]
</p><p>98 8  Conclusion  In this paper we showed that while entity linking cannot link to entities outside of Wikipedia, once a  large text corpus has been entity linked, the presence and content of the existing links can be leveraged to help detect and semantically type the non-Wikipedia entities as well. [sent-357, score-1.625]
</p><p>99 We designed techniques for detecting whether unlinkable noun phrases are entities, and if they are, then propagating semantic types to them from the linked entities. [sent-358, score-0.978]
</p><p>100 Our research here takes initial steps toward a future where the vast universe of entities that are not prominent enough to include in manually-authored knowledge bases is analyzed automatically instead of being left behind. [sent-360, score-0.503]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('entities', 0.406), ('unlinkable', 0.359), ('entity', 0.272), ('slope', 0.201), ('juice', 0.185), ('noun', 0.172), ('wikipedia', 0.155), ('unlinked', 0.154), ('assertions', 0.154), ('linked', 0.15), ('freebase', 0.148), ('books', 0.141), ('textual', 0.139), ('linking', 0.134), ('ner', 0.125), ('bfrequency', 0.108), ('sweighted', 0.108), ('relations', 0.1), ('typing', 0.092), ('tail', 0.087), ('kozareva', 0.08), ('talukdar', 0.077), ('year', 0.077), ('assertion', 0.072), ('pineapple', 0.072), ('usagesinceyear', 0.072), ('phrase', 0.072), ('types', 0.072), ('named', 0.072), ('phrases', 0.068), ('link', 0.065), ('prominent', 0.065), ('semantic', 0.063), ('typed', 0.058), ('pas', 0.057), ('extractions', 0.057), ('usage', 0.057), ('fader', 0.054), ('brandom', 0.054), ('microsystems', 0.054), ('snoweight', 0.054), ('timestamped', 0.054), ('detecting', 0.052), ('reverb', 0.052), ('ngram', 0.05), ('etzioni', 0.05), ('million', 0.047), ('prices', 0.046), ('vitamin', 0.046), ('share', 0.046), ('apple', 0.046), ('oren', 0.043), ('relation', 0.042), ('quoted', 0.042), ('propagating', 0.042), ('ratinov', 0.04), ('bigrams', 0.039), ('pratim', 0.039), ('wijaya', 0.039), ('soderland', 0.038), ('class', 0.038), ('released', 0.037), ('bunescu', 0.037), ('ling', 0.037), ('instances', 0.036), ('partha', 0.036), ('airline', 0.036), ('apbres', 0.036), ('beverage', 0.036), ('buscaldi', 0.036), ('figer', 0.036), ('maj', 0.036), ('meat', 0.036), ('percentpropercaps', 0.036), ('safflower', 0.036), ('seasons', 0.036), ('tanti', 0.036), ('predict', 0.036), ('term', 0.036), ('type', 0.036), ('domain', 0.035), ('detect', 0.034), ('matches', 0.033), ('annotators', 0.033), ('fit', 0.033), ('propagate', 0.033), ('classifies', 0.033), ('enough', 0.032), ('web', 0.032), ('fictional', 0.031), ('digitized', 0.031), ('ferragina', 0.031), ('anamaria', 0.031), ('analyst', 0.031), ('prominence', 0.031), ('pantel', 0.031), ('missing', 0.031), ('people', 0.03), ('minor', 0.03), ('sun', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999863 <a title="98-tfidf-1" href="./emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities.html">98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</a></p>
<p>Author: Thomas Lin ; Mausam ; Oren Etzioni</p><p>Abstract: Entity linking systems link noun-phrase mentions in text to their corresponding Wikipedia articles. However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles. In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities. Our proposed method for detecting unlinkable entities achieves 24% greater accuracy than a Named Entity Recognition baseline, and our method for fine-grained typing is able to propagate over 1,000 types from linked Wikipedia entities to unlinkable entities. Detection and typing of unlinkable entities can increase yield for NLP applications such as typed question answering.</p><p>2 0.20661393 <a title="98-tfidf-2" href="./emnlp-2012-An_Entity-Topic_Model_for_Entity_Linking.html">19 emnlp-2012-An Entity-Topic Model for Entity Linking</a></p>
<p>Author: Xianpei Han ; Le Sun</p><p>Abstract: Entity Linking (EL) has received considerable attention in recent years. Given many name mentions in a document, the goal of EL is to predict their referent entities in a knowledge base. Traditionally, there have been two distinct directions of EL research: one focusing on the effects of mention’s context compatibility, assuming that “the referent entity of a mention is reflected by its context”; the other dealing with the effects of document’s topic coherence, assuming that “a mention ’s referent entity should be coherent with the document’ ’s main topics”. In this paper, we propose a generative model called entitytopic model, to effectively join the above two complementary directions together. By jointly modeling and exploiting the context compatibility, the topic coherence and the correlation between them, our model can – accurately link all mentions in a document using both the local information (including the words and the mentions in a document) and the global knowledge (including the topic knowledge, the entity context knowledge and the entity name knowledge). Experimental results demonstrate the effectiveness of the proposed model. 1</p><p>3 0.15341368 <a title="98-tfidf-3" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>Author: Mohamed Yahya ; Klaus Berberich ; Shady Elbassuoni ; Maya Ramanath ; Volker Tresp ; Gerhard Weikum</p><p>Abstract: The Linked Data initiative comprises structured databases in the Semantic-Web data model RDF. Exploring this heterogeneous data by structured query languages is tedious and error-prone even for skilled users. To ease the task, this paper presents a methodology for translating natural language questions into structured SPARQL queries over linked-data sources. Our method is based on an integer linear program to solve several disambiguation tasks jointly: the segmentation of questions into phrases; the mapping of phrases to semantic entities, classes, and relations; and the construction of SPARQL triple patterns. Our solution harnesses the rich type system provided by knowledge bases in the web of linked data, to constrain our semantic-coherence objective function. We present experiments on both the . in question translation and the resulting query answering.</p><p>4 0.14424123 <a title="98-tfidf-4" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>Author: Avirup Sil ; Ernest Cronin ; Penghai Nie ; Yinfei Yang ; Ana-Maria Popescu ; Alexander Yates</p><p>Abstract: Existing techniques for disambiguating named entities in text mostly focus on Wikipedia as a target catalog of entities. Yet for many types of entities, such as restaurants and cult movies, relational databases exist that contain far more extensive information than Wikipedia. This paper introduces a new task, called Open-Database Named-Entity Disambiguation (Open-DB NED), in which a system must be able to resolve named entities to symbols in an arbitrary database, without requiring labeled data for each new database. We introduce two techniques for Open-DB NED, one based on distant supervision and the other based on domain adaptation. In experiments on two domains, one with poor coverage by Wikipedia and the other with near-perfect coverage, our Open-DB NED strategies outperform a state-of-the-art Wikipedia NED system by over 25% in accuracy.</p><p>5 0.14379166 <a title="98-tfidf-5" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>6 0.14035179 <a title="98-tfidf-6" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>7 0.13027957 <a title="98-tfidf-7" href="./emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">76 emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>8 0.12969878 <a title="98-tfidf-8" href="./emnlp-2012-PATTY%3A_A_Taxonomy_of_Relational_Patterns_with_Semantic_Types.html">103 emnlp-2012-PATTY: A Taxonomy of Relational Patterns with Semantic Types</a></p>
<p>9 0.12177428 <a title="98-tfidf-9" href="./emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">47 emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>10 0.10859459 <a title="98-tfidf-10" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>11 0.10710189 <a title="98-tfidf-11" href="./emnlp-2012-Identifying_Constant_and_Unique_Relations_by_using_Time-Series_Text.html">62 emnlp-2012-Identifying Constant and Unique Relations by using Time-Series Text</a></p>
<p>12 0.1063823 <a title="98-tfidf-12" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>13 0.10514478 <a title="98-tfidf-13" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>14 0.096833564 <a title="98-tfidf-14" href="./emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">96 emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<p>15 0.084317446 <a title="98-tfidf-15" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>16 0.083439343 <a title="98-tfidf-16" href="./emnlp-2012-Ensemble_Semantics_for_Large-scale_Unsupervised_Relation_Extraction.html">40 emnlp-2012-Ensemble Semantics for Large-scale Unsupervised Relation Extraction</a></p>
<p>17 0.07503359 <a title="98-tfidf-17" href="./emnlp-2012-Open_Language_Learning_for_Information_Extraction.html">100 emnlp-2012-Open Language Learning for Information Extraction</a></p>
<p>18 0.060399711 <a title="98-tfidf-18" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>19 0.058090948 <a title="98-tfidf-19" href="./emnlp-2012-Improving_NLP_through_Marginalization_of_Hidden_Syntactic_Structure.html">65 emnlp-2012-Improving NLP through Marginalization of Hidden Syntactic Structure</a></p>
<p>20 0.057340093 <a title="98-tfidf-20" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.242), (1, 0.253), (2, -0.01), (3, -0.101), (4, -0.061), (5, -0.08), (6, 0.11), (7, 0.251), (8, -0.153), (9, -0.052), (10, -0.006), (11, -0.063), (12, -0.005), (13, -0.104), (14, 0.031), (15, 0.012), (16, 0.126), (17, -0.011), (18, -0.103), (19, 0.107), (20, 0.048), (21, -0.033), (22, 0.0), (23, -0.023), (24, -0.073), (25, 0.101), (26, 0.053), (27, -0.039), (28, -0.045), (29, -0.122), (30, 0.093), (31, 0.047), (32, -0.004), (33, 0.058), (34, 0.105), (35, 0.017), (36, -0.04), (37, -0.008), (38, -0.082), (39, 0.085), (40, 0.053), (41, 0.1), (42, -0.012), (43, -0.096), (44, 0.034), (45, 0.024), (46, -0.094), (47, -0.008), (48, 0.063), (49, 0.093)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97995001 <a title="98-lsi-1" href="./emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities.html">98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</a></p>
<p>Author: Thomas Lin ; Mausam ; Oren Etzioni</p><p>Abstract: Entity linking systems link noun-phrase mentions in text to their corresponding Wikipedia articles. However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles. In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities. Our proposed method for detecting unlinkable entities achieves 24% greater accuracy than a Named Entity Recognition baseline, and our method for fine-grained typing is able to propagate over 1,000 types from linked Wikipedia entities to unlinkable entities. Detection and typing of unlinkable entities can increase yield for NLP applications such as typed question answering.</p><p>2 0.70117682 <a title="98-lsi-2" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>Author: Avirup Sil ; Ernest Cronin ; Penghai Nie ; Yinfei Yang ; Ana-Maria Popescu ; Alexander Yates</p><p>Abstract: Existing techniques for disambiguating named entities in text mostly focus on Wikipedia as a target catalog of entities. Yet for many types of entities, such as restaurants and cult movies, relational databases exist that contain far more extensive information than Wikipedia. This paper introduces a new task, called Open-Database Named-Entity Disambiguation (Open-DB NED), in which a system must be able to resolve named entities to symbols in an arbitrary database, without requiring labeled data for each new database. We introduce two techniques for Open-DB NED, one based on distant supervision and the other based on domain adaptation. In experiments on two domains, one with poor coverage by Wikipedia and the other with near-perfect coverage, our Open-DB NED strategies outperform a state-of-the-art Wikipedia NED system by over 25% in accuracy.</p><p>3 0.69850886 <a title="98-lsi-3" href="./emnlp-2012-An_Entity-Topic_Model_for_Entity_Linking.html">19 emnlp-2012-An Entity-Topic Model for Entity Linking</a></p>
<p>Author: Xianpei Han ; Le Sun</p><p>Abstract: Entity Linking (EL) has received considerable attention in recent years. Given many name mentions in a document, the goal of EL is to predict their referent entities in a knowledge base. Traditionally, there have been two distinct directions of EL research: one focusing on the effects of mention’s context compatibility, assuming that “the referent entity of a mention is reflected by its context”; the other dealing with the effects of document’s topic coherence, assuming that “a mention ’s referent entity should be coherent with the document’ ’s main topics”. In this paper, we propose a generative model called entitytopic model, to effectively join the above two complementary directions together. By jointly modeling and exploiting the context compatibility, the topic coherence and the correlation between them, our model can – accurately link all mentions in a document using both the local information (including the words and the mentions in a document) and the global knowledge (including the topic knowledge, the entity context knowledge and the entity name knowledge). Experimental results demonstrate the effectiveness of the proposed model. 1</p><p>4 0.67265201 <a title="98-lsi-4" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>Author: Amit Singh</p><p>Abstract: Bridging the lexical gap between the user’s question and the question-answer pairs in the Q&A; archives has been a major challenge for Q&A; retrieval. State-of-the-art approaches address this issue by implicitly expanding the queries with additional words using statistical translation models. While useful, the effectiveness of these models is highly dependant on the availability of quality corpus in the absence of which they are troubled by noise issues. Moreover these models perform word based expansion in a context agnostic manner resulting in translation that might be mixed and fairly general. This results in degraded retrieval performance. In this work we address the above issues by extending the lexical word based translation model to incorporate semantic concepts (entities). We explore strategies to learn the translation probabilities between words and the concepts using the Q&A; archives and a popular entity catalog. Experiments conducted on a large scale real data show that the proposed techniques are promising.</p><p>5 0.63389766 <a title="98-lsi-5" href="./emnlp-2012-PATTY%3A_A_Taxonomy_of_Relational_Patterns_with_Semantic_Types.html">103 emnlp-2012-PATTY: A Taxonomy of Relational Patterns with Semantic Types</a></p>
<p>Author: Ndapandula Nakashole ; Gerhard Weikum ; Fabian Suchanek</p><p>Abstract: This paper presents PATTY: a large resource for textual patterns that denote binary relations between entities. The patterns are semantically typed and organized into a subsumption taxonomy. The PATTY system is based on efficient algorithms for frequent itemset mining and can process Web-scale corpora. It harnesses the rich type system and entity population of large knowledge bases. The PATTY taxonomy comprises 350,569 pattern synsets. Random-sampling-based evaluation shows a pattern accuracy of 84.7%. PATTY has 8,162 subsumptions, with a random-sampling-based precision of 75%. The PATTY resource is freely available for interactive access and download.</p><p>6 0.63095367 <a title="98-lsi-6" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>7 0.55447859 <a title="98-lsi-7" href="./emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">76 emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>8 0.48946008 <a title="98-lsi-8" href="./emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">47 emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>9 0.48271191 <a title="98-lsi-9" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>10 0.46528688 <a title="98-lsi-10" href="./emnlp-2012-Identifying_Constant_and_Unique_Relations_by_using_Time-Series_Text.html">62 emnlp-2012-Identifying Constant and Unique Relations by using Time-Series Text</a></p>
<p>11 0.43748945 <a title="98-lsi-11" href="./emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">96 emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<p>12 0.40724033 <a title="98-lsi-12" href="./emnlp-2012-Open_Language_Learning_for_Information_Extraction.html">100 emnlp-2012-Open Language Learning for Information Extraction</a></p>
<p>13 0.39750266 <a title="98-lsi-13" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>14 0.37873906 <a title="98-lsi-14" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>15 0.33264694 <a title="98-lsi-15" href="./emnlp-2012-Grounded_Models_of_Semantic_Representation.html">61 emnlp-2012-Grounded Models of Semantic Representation</a></p>
<p>16 0.31354886 <a title="98-lsi-16" href="./emnlp-2012-Ensemble_Semantics_for_Large-scale_Unsupervised_Relation_Extraction.html">40 emnlp-2012-Ensemble Semantics for Large-scale Unsupervised Relation Extraction</a></p>
<p>17 0.31059128 <a title="98-lsi-17" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>18 0.30661085 <a title="98-lsi-18" href="./emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">85 emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>19 0.28436691 <a title="98-lsi-19" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>20 0.28051153 <a title="98-lsi-20" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.026), (16, 0.03), (25, 0.024), (34, 0.047), (45, 0.012), (58, 0.257), (60, 0.186), (63, 0.073), (64, 0.028), (65, 0.058), (70, 0.016), (73, 0.017), (74, 0.035), (76, 0.046), (79, 0.01), (80, 0.019), (86, 0.023), (95, 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81969106 <a title="98-lda-1" href="./emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities.html">98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</a></p>
<p>Author: Thomas Lin ; Mausam ; Oren Etzioni</p><p>Abstract: Entity linking systems link noun-phrase mentions in text to their corresponding Wikipedia articles. However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles. In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities. Our proposed method for detecting unlinkable entities achieves 24% greater accuracy than a Named Entity Recognition baseline, and our method for fine-grained typing is able to propagate over 1,000 types from linked Wikipedia entities to unlinkable entities. Detection and typing of unlinkable entities can increase yield for NLP applications such as typed question answering.</p><p>2 0.66693687 <a title="98-lda-2" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>Author: Dan Garrette ; Jason Baldridge</p><p>Abstract: Past work on learning part-of-speech taggers from tag dictionaries and raw data has reported good results, but the assumptions made about those dictionaries are often unrealistic: due to historical precedents, they assume access to information about labels in the raw and test sets. Here, we demonstrate ways to learn hidden Markov model taggers from incomplete tag dictionaries. Taking the MINGREEDY algorithm (Ravi et al., 2010) as a starting point, we improve it with several intuitive heuristics. We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data. Altogether, our augmentations produce improvements to per- formance over the original MIN-GREEDY algorithm for both English and Italian data.</p><p>3 0.63949782 <a title="98-lda-3" href="./emnlp-2012-Grounded_Models_of_Semantic_Representation.html">61 emnlp-2012-Grounded Models of Semantic Representation</a></p>
<p>Author: Carina Silberer ; Mirella Lapata</p><p>Abstract: A popular tradition of studying semantic representation has been driven by the assumption that word meaning can be learned from the linguistic environment, despite ample evidence suggesting that language is grounded in perception and action. In this paper we present a comparative study of models that represent word meaning based on linguistic and perceptual data. Linguistic information is approximated by naturally occurring corpora and sensorimotor experience by feature norms (i.e., attributes native speakers consider important in describing the meaning of a word). The models differ in terms of the mechanisms by which they integrate the two modalities. Experimental results show that a closer correspondence to human data can be obtained by uncovering latent information shared among the textual and perceptual modalities rather than arriving at semantic knowledge by concatenating the two.</p><p>4 0.63662702 <a title="98-lda-4" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>5 0.63473916 <a title="98-lda-5" href="./emnlp-2012-Exploring_Adaptor_Grammars_for_Native_Language_Identification.html">48 emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras ; Mark Johnson</p><p>Abstract: The task of inferring the native language of an author based on texts written in a second language has generally been tackled as a classification problem, typically using as features a mix of n-grams over characters and part of speech tags (for small and fixed n) and unigram function words. To capture arbitrarily long n-grams that syntax-based approaches have suggested are useful, adaptor grammars have some promise. In this work we investigate their extension to identifying n-gram collocations of arbitrary length over a mix of PoS tags and words, using both maxent and induced syntactic language model approaches to classification. After presenting a new, simple baseline, we show that learned collocations used as features in a maxent model perform better still, but that the story is more mixed for the syntactic language model.</p><p>6 0.62985933 <a title="98-lda-6" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>7 0.62734085 <a title="98-lda-7" href="./emnlp-2012-Enlarging_Paraphrase_Collections_through_Generalization_and_Instantiation.html">39 emnlp-2012-Enlarging Paraphrase Collections through Generalization and Instantiation</a></p>
<p>8 0.62424147 <a title="98-lda-8" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>9 0.62114251 <a title="98-lda-9" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>10 0.61890274 <a title="98-lda-10" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>11 0.61854792 <a title="98-lda-11" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>12 0.6180706 <a title="98-lda-12" href="./emnlp-2012-Wiki-ly_Supervised_Part-of-Speech_Tagging.html">138 emnlp-2012-Wiki-ly Supervised Part-of-Speech Tagging</a></p>
<p>13 0.61770761 <a title="98-lda-13" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>14 0.61568272 <a title="98-lda-14" href="./emnlp-2012-An_Entity-Topic_Model_for_Entity_Linking.html">19 emnlp-2012-An Entity-Topic Model for Entity Linking</a></p>
<p>15 0.61367708 <a title="98-lda-15" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>16 0.61229914 <a title="98-lda-16" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>17 0.61221939 <a title="98-lda-17" href="./emnlp-2012-Generalizing_Sub-sentential_Paraphrase_Acquisition_across_Original_Signal_Type_of_Text_Pairs.html">58 emnlp-2012-Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs</a></p>
<p>18 0.61173075 <a title="98-lda-18" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>19 0.61045527 <a title="98-lda-19" href="./emnlp-2012-Joint_Inference_for_Event_Timeline_Construction.html">72 emnlp-2012-Joint Inference for Event Timeline Construction</a></p>
<p>20 0.60831469 <a title="98-lda-20" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
