<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-129" href="#">emnlp2012-129</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</h1>
<br/><p>Source: <a title="emnlp-2012-129-pdf" href="http://aclweb.org/anthology//D/D12/D12-1075.pdf">pdf</a></p><p>Author: Dan Garrette ; Jason Baldridge</p><p>Abstract: Past work on learning part-of-speech taggers from tag dictionaries and raw data has reported good results, but the assumptions made about those dictionaries are often unrealistic: due to historical precedents, they assume access to information about labels in the raw and test sets. Here, we demonstrate ways to learn hidden Markov model taggers from incomplete tag dictionaries. Taking the MINGREEDY algorithm (Ravi et al., 2010) as a starting point, we improve it with several intuitive heuristics. We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data. Altogether, our augmentations produce improvements to per- formance over the original MIN-GREEDY algorithm for both English and Italian data.</p><p>Reference: <a title="emnlp-2012-129-reference" href="../emnlp2012_reference/emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Here, we demonstrate ways to learn hidden Markov model taggers from incomplete tag dictionaries. [sent-4, score-0.771]
</p><p>2 We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data. [sent-7, score-2.138]
</p><p>3 However, the tag dictionaries in these cases were obtained from labeled tokens. [sent-25, score-0.766]
</p><p>4 While replicating earlier  experiments, Banko and Moore (2004) discovered that performance was highly dependent on cleaning tag dictionaries using statistics gleaned from the tokens. [sent-26, score-0.766]
</p><p>5 When the full, noisy tag dictionary was employed, Banko and Moore found accuracies dropped from 96% to 77%. [sent-28, score-0.82]
</p><p>6 However, as is often noted (including by the authors themselves), many papers that work on learning taggers from tag dictionaries make unrealistic assumptions about the tag dictionaries they use as input (Toutanova and Johnson, 2008; Ravi and Knight, 2009; Hasan and Ng, 2009). [sent-35, score-1.603]
</p><p>7 For example, tag dictionaries are typically  constructed with every token-tag pair in the data, including those that appear only in the test set. [sent-36, score-0.766]
</p><p>8 We show that it is possible to achieve good tagging accuracy using a noisy and incomplete tag dictionary that has no access to the tags of the raw and test data and no access to the tag frequency information of the labeled training data from which the dictionary is drawn. [sent-38, score-2.094]
</p><p>9 ’s (2010) model minimization approach, which reduces dictionary noise by greedily approximating the minimum set of tag bigrams needed to cover the raw data and exploits that information as a constraint on the initialization of the model before running EM. [sent-40, score-1.573]
</p><p>10 Enable the algorithm to be used with incomplete dictionaries by exploiting the type-based information provided by the tag dictionary and raw text to initialize EM, and by training a standard supervised HMM on the output of EM. [sent-43, score-1.309]
</p><p>11 Modify the method to return only the set of bigrams required to tag sentences instead of keeping all bigrams chosen by minimization. [sent-47, score-1.041]
</p><p>12 2 Type-supervised training We are primarily interested in learning taggers from tag dictionaries combined with unlabeled text. [sent-67, score-0.837]
</p><p>13 Here, we can simply exploit the tag dictionary and raw data. [sent-76, score-1.07]
</p><p>14 Given just a tag dictionary, the simplest initialization is to set all tag transitions to be uniform, ranging over all tag continuations, while for emissions, a uniform distribution over all words that occur with the tag is assigned. [sent-78, score-2.662]
</p><p>15 This may be appropriate when a complete tag dictionary is available, including complete information for words that appear only in the test data. [sent-79, score-0.88]
</p><p>16 Likewise, there will never be a situation where the tag dictionary rules out all possible tag transitions  between two adjacent tokens in training or testing. [sent-81, score-1.567]
</p><p>17 The problem with this is that estimating a model based on type-supervision requires raw text, and if we have an incomplete tag dictionary, some of the words in that text will be missing from the tag dictionary. [sent-83, score-1.579]
</p><p>18 We thus need to ensure that mass is reserved for words outside the tag dictionary at the start of EM. [sent-86, score-0.849]
</p><p>19 3 Emission probability initialization The simplest way to initialize the emission distributions is to assign a count of one to every entry in the tag dictionary, and one count for unknowns. [sent-89, score-0.815]
</p><p>20 This basic  strategy allows one to train an HMM with EM using only an incomplete tag dictionary and raw text. [sent-91, score-1.141]
</p><p>21 Specifically, if for each tag we simply assume one count for each entry in the tag dictionary and one count for unknowns and then normalize, the probability of an unknown word having a specific tag is inversely correlated with the number of word types associated with the tag in the tag dictionary. [sent-93, score-3.444]
</p><p>22 In other words, a tag that appears with a smaller number of distinct words will be seen by the HMM as being a better candidate tag for an unknown word. [sent-94, score-1.328]
</p><p>23 Note that C(w, t) comes in two varieties: w is either found in the tag dictionary (known word types), or it is not (unknown word types). [sent-97, score-0.82]
</p><p>24 We refer to the later as td-unknown: these are words that occur in the raw word sequence used for EM but which do not occur in the tag dictionary. [sent-98, score-0.879]
</p><p>25 If a word w appears C(w) times in the raw corpus, and is seen with |TD(w) | tags in the tag dictionary, then assume wfoitrh he |aTcDh t( win) TD(w): Cknown(w, t) = C(w) / |TD(w) | and Cknown(w, t) = 0 for all other t. [sent-103, score-0.952]
</p><p>26 Second, we look at td-unknown word types: those in the raw data that are not found in the tag dictionary. [sent-107, score-0.879]
</p><p>27 Given the value P(unktd|t) for the like-  lihood of an unknown word given a tag t, we can compute estimated counts Cunktd (w, t) for a tdunknown word w using Cunktd (w, t) = C(w)  ·  P(unktd |t)  where C(w), again, comes from the raw corpus. [sent-108, score-0.949]
</p><p>28 This has the effect of spreading C(w), the count of tokens of that unknown word w, across all of the possible tags, with each tag receiving a proportion of the total count as determined by P(unktd|t). [sent-109, score-0.769]
</p><p>29 edge, the tag dictionary and the raw token sequence, each telling us complementary information. [sent-112, score-1.114]
</p><p>30 First, the tag dictionary tells us about the openness of a tag—the likelihood that an unseen word will have that label—based on our previously-discussed intuition that we are more likely to see a new word with a tag that is known to be associated with many words already. [sent-113, score-1.533]
</p><p>31 4 Auto-supervPised post-EM smoothing The initialization accounting for td-unknown words given above allows EM to be run on the raw token sequence, but it provides no probability for words that are truly unseen (in either the tag dictionary or the raw data). [sent-125, score-1.505]
</p><p>32 3  Enhancing MIN-GREEDY  As was discussed above, one of the major problems for type-supervised POS-tagger training with EM is a tag dictionary with low-frequency entries such as the word “a” being associated with the foreign word tag when nearly all of its instances are as a determiner. [sent-134, score-1.474]
</p><p>33 To avoid the need for manually pruning the tag dictionary, Ravi and Knight (2009) hbi The boy sees a dog h\bi hbi  2%%  DT  1&&  DBBT  BB NN  1%%  NN  3? [sent-135, score-0.969]
</p><p>34 proposed that low-probability tags might be automatically filtered from the tag dictionary through a  model minimization procedure applied to the raw text and constrained by the full tag dictionary. [sent-142, score-1.984]
</p><p>35 1 The original MIN-GREEDY algorithm The MIN-GREEDY algorithm starts by initializing a graph with a vertex for each possible tag of each token in the raw data. [sent-147, score-0.923]
</p><p>36 The set of possible tags for each token is the set of tags associated with that word in the tag dictionary. [sent-148, score-0.819]
</p><p>37 (2010), we allow for an incomplete tag dictionary, meaning that our scenario has the additional complication that the tag set for some raw-corpus  hbi hbi  The  boy  sees  a  %% DT  DBBT  dog  825 h\bi  &&NN;&&V; B&&FBBW;%%NNh? [sent-151, score-1.714]
</p><p>38 In the first two phases, the algorithm chooses tag bigrams that form the edges of the graph. [sent-158, score-0.861]
</p><p>39 The algorithm greedily selects these edges in an attempt to quickly approximate the minimal set of tag bigrams needed to accomplish this goal. [sent-160, score-0.861]
</p><p>40 In the first phase, Greedy Set Cover, the algorithm selects tag bigrams in an effort to cover all of the word tokens. [sent-162, score-0.879]
</p><p>41 A word token is considered covered if there is at least one tag bigram edge connected to at least one of its vertices. [sent-163, score-0.791]
</p><p>42 At each iteration, the algorithm examines the entire graph, across all sentences, to find the tag bigram that, if added, would maximize the number of newly covered words. [sent-164, score-0.747]
</p><p>43 At the start of the first phase, no tag bigrams are selected. [sent-167, score-0.864]
</p><p>44 On the first iteration, the algorithm chooses the tag bigram DT→NN because this tag bigram sde thsceri tabges btwigora edges →forN a Nto btael coafu fsoeu rth wiso tradgs newly covered: The, boy, a, and dog. [sent-168, score-1.468]
</p><p>45 At this point, as the figure shows, there are five tag bigrams that would each result in covering one additional token. [sent-170, score-0.835]
</p><p>46 Since there are no tag bigrams whose choosing would result in covering more than one additional token, the algorithm randomly chooses one of these five. [sent-171, score-0.869]
</p><p>47 The second phase of the MIN-GREEDY algorithm, Greedy Path Completion, seeks to fill holes in the tag paths found in the graph. [sent-173, score-0.873]
</p><p>48 At each iteration, the algorithm finds the tag bigram that, if selected, would maximize the number ofholes that would be filled across all raw sentences. [sent-175, score-0.971]
</p><p>49 At this point, there are three tag bigrams that each fill one hole if selected, and the algorithm randomly selects one. [sent-177, score-0.9]
</p><p>50 Iteration continues until there is a complete tag path through each sentence in the raw corpus. [sent-178, score-0.971]
</p><p>51 Once a set of tag bigrams has been generated that allows for a complete tag path through every sentence of the raw corpus, MIN-GREEDY begins its final phase: Iterative Model-Fitting. [sent-180, score-1.806]
</p><p>52 Each iteration trains an HMM and then uses it to tag the raw corpus, the result of which is used to prepare inputs for the next iteration. [sent-182, score-0.924]
</p><p>53 This set is used as a hard constraint  on the allowable tag bigrams during type-supervised HMM training. [sent-184, score-0.835]
</p><p>54 While EM is running, the only tag transitions that are counted are those that fall into the minimized tag bigram set; all other transition counts are ignored. [sent-185, score-1.505]
</p><p>55 Once an HMM has been trained, it is immediately used to tag the raw corpus, producing a set of auto-labeled sentences. [sent-186, score-0.879]
</p><p>56 For the second iteration of the phase, we extract a constrained tag dictionary from the auto-labeled corpus by simply taking every word/tag pair appearing in the data. [sent-187, score-0.899]
</p><p>57 This new tag dictionary is a subset of the original, full, tag dictionary, and hopefully has fewer low-frequency entries that would cause problems for EM. [sent-188, score-1.474]
</p><p>58 We use this constrained tag dictionary to again perform type-supervised HMM training, but without any constraints on the allowable tag bigrams. [sent-189, score-1.483]
</p><p>59 Using this HMM, we can, again, tag the raw corpus, producing another set of 826 auto-labeled sentences. [sent-191, score-0.879]
</p><p>60 We can then extract the set of tag bigrams appearing in this data to produce a new set of tag transition constraints, similar to what was returned by the second phase. [sent-192, score-1.497]
</p><p>61 With this set of  tag transition constraints, and the full tag dictionary, we can perform another round of type-supervised HMM training, and repeat the entire process. [sent-193, score-1.291]
</p><p>62 The third MIN-GREEDY phase continues iterating, alternating between training an HMM using a constrained set of tag transitions and training one using a constrained tag dictionary. [sent-194, score-1.469]
</p><p>63 The size of the set of constrained tag bigrams produced is tracked on each iteration, and the algorithm is considered to have converged when this value changes by less than five percent. [sent-195, score-0.869]
</p><p>64 (2010), was performed only for scenarios with a complete tag dictionary (including all raw and test word types). [sent-198, score-1.1]
</p><p>65 Because we are interested in the more realistic scenario of an incomplete tag dictionary, we augment the original MIN-GREEDY setup with the smoothing techniques described above. [sent-200, score-0.785]
</p><p>66 2 Improving tag bigram selection One of the major problems with the MIN-GREEDY  algorithm is that its heuristics for choosing the next tag bigram frequently result in many-way ties. [sent-202, score-1.476]
</p><p>67 In the first two phases of MIN-GREEDY, the greedy procedure looks for the tag bigram that will have the most positive impact. [sent-203, score-0.852]
</p><p>68 In the Greedy Set Cover phase this means choosing the tag bigram that would cover the most new tokens, and in the Greedy Path Completion phase this means choosing the tag bigram that would fill the most holes. [sent-204, score-1.784]
</p><p>69 However, it is frequently the case that there are many distinct tag bigrams that would cover the most new tokens or fill the most holes, leaving the MIN-GREEDY algorithm with no choice but to randomly select from these options. [sent-205, score-0.989]
</p><p>70 e eAnd cdihtoiosnenal as thhbei →seDcoTnd a adnd N tNhi→rdh tag  bigrams since they tied for the most new tokens covered: one. [sent-210, score-0.905]
</p><p>71 For the state shown in this figure, there is only one uncovered token, sees, but three tag bigrams that cover it. [sent-211, score-0.879]
</p><p>72 Since each of these tag bigrams covers exactly one new word, they are all considered by MIN-GREEDY to be equally good choices as the next tag bigram for inclusion, and the algorithm will choose one at random. [sent-212, score-1.556]
</p><p>73 If we choose the tag bigram NN→VB or VB→DT, Ithf ewne exactly one new word-type/tag pair wB→oulDd b,e t hadende edx to our n reesu nlte:w se weos/rVd-Bty (since boy/NN and a/DT would already have been added  by the incorporation of previous selected tag bigrams). [sent-217, score-1.395]
</p><p>74 3 Only tag bigrams on minimization paths As was described above, the output of MINGREEDY’s second stage is a minimized set of tag bigrams which is used as a constraint on the first iteration of the third stage, Iterative Model-Fitting. [sent-223, score-2.032]
</p><p>75 However, in order to determine when to stop adding new bigrams during the first two phases, the MIN827 GREEDY algorithm must try to find complete tag paths through each sentence in the raw corpus, stopping once a tag path has been found for each one. [sent-224, score-1.871]
</p><p>76 While the algorithm is trying to select only the tag bigrams that are necessary for a complete tagging, it happens frequently that bigrams are selected that are not actually used on any tag path. [sent-225, score-1.722]
</p><p>77 Assuming eth,a Vt Bth→is tag bigram is not used on the tag path of any other sentence, it can safely be removed from the resultant set to produce a smaller set of tag bigrams, getting us even closer to the minimized set that we desire. [sent-228, score-2.115]
</p><p>78 To find the set of tag bigrams excluding these extraneous edges, we modify the MIN-GREEDY algorithm. [sent-229, score-0.835]
</p><p>79 During the first and second phases of the algorithm, we check all raw data sentences for a completed path after each tag bigram is selected. [sent-230, score-1.147]
</p><p>80 Since sentences are completed at different stages, and more tag bigrams are selected after some of these sentences are complete, it is inevitable that some sentences will end up with multiple complete tag paths by the end of the second phase. [sent-234, score-1.632]
</p><p>81 The result of this improvement is a smaller, cleaner minimized tag bigram set to be delivered to the third phase of MIN-GREEDY. [sent-240, score-0.89]
</p><p>82 Table 1: English tagging  accuracy  using  PTB  sections 00-15  to  build the tag dictionary. [sent-241, score-0.73]
</p><p>83 4 EM initialization with minimization output As a final improvement to MIN-GREEDY, we took the set of completed tag paths returned from the second phase of the algorithm, as described in the previous section, and used them as labeled data to initialize an HMM for EM training. [sent-244, score-1.124]
</p><p>84 Since we modified MIN-GREEDY to produce a set of completed tag paths for sentences, we can take this to be a complete set of labels for the raw corpus. [sent-245, score-1.025]
</p><p>85 Furthermore, since we were careful about storing paths as soon as they become completed by the minimization process, and the tag bigrams are chosen in order of frequency, there will be more highfrequency bigrams than low-frequency. [sent-246, score-1.335]
</p><p>86 We divided the TUT data, taking the first half of each of the five sections as input to the tag dictionary, the next quarter as raw data, and the last quarter as test data. [sent-268, score-0.97]
</p><p>87 All together, the tag dictionary was constructed from 41,000 tokens consisting of 7,814 word types, 8,370 word/tag pairs, per-type ambiguity of 1. [sent-269, score-0.932]
</p><p>88 the Total (all word types), Known (word types found in the tag dictionary), and Unknown (word types not found in the tag dictionary). [sent-277, score-1.258]
</p><p>89 For the smaller PTB tag dictionary and the TUT data, MIN-GREEDY actually has lower per-  formance than the HMM alone. [sent-282, score-0.843]
</p><p>90 This indicates that if the tag dictionary has a low degree of ambiguity, then MIN-GREEDY can make the situation worse. [sent-283, score-0.82]
</p><p>91 However, restricting the tag bigrams to that in the minimizationtagged output causes problems in the smaller PTB scenario, presumably falling to a local maximum like MIN-GREEDY that the other improvements are able to help the algorithm avoid. [sent-290, score-0.835]
</p><p>92 Error analysis One of the primary goals of model minimization is to automatically eliminate lowprobability entries from the tag dictionary that might confuse the EM algorithm (Ravi et al. [sent-292, score-1.023]
</p><p>93 This includes 7621 occurrences with tag DT, 3 with tag SYM (symbol), and 1 time with LS (list item marker). [sent-299, score-1.258]
</p><p>94 As such, we would want the HMM to lean heavily toward tag DT when tagging the token “a”. [sent-300, score-0.733]
</p><p>95 The minimization procedure attempts to overcome this problem by removing unlikely tags from the tag dictionary automatically. [sent-309, score-1.071]
</p><p>96 As is show in Table 3, MIN-GREEDY without our enhancements is able to reject the problematic LS as a tag for “a”, but unable to do so for SYM, resulting in 2356 tokens tagged SYM and only 4 tagged DT. [sent-310, score-0.822]
</p><p>97 Restricting the tag bigrams output from MINGREEDY tojust those on tag paths avoids LS and FW for “a” and FW for “in”. [sent-314, score-1.529]
</p><p>98 5  Conclusion  Our results show it is possible to create accurate POS-taggers using type-supervision with incom-  830 plete tag dictionaries by extending the MIN-GREEDY algorithm of Ravi et al. [sent-316, score-0.766]
</p><p>99 We agree; however, our ultimate motivation is to use this work to tackle bootstrapping from very small tag dictionaries or dictionaries obtained from linguists or resources other than a corpus, and for tag sets that are more ambiguous (e. [sent-326, score-1.532]
</p><p>100 Such efforts require automatic expansion of tag dictionaries, which then need be constrained based on available raw token sequences using methods such as those explored here. [sent-329, score-0.957]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tag', 0.629), ('raw', 0.25), ('bigrams', 0.206), ('dictionary', 0.191), ('unktd', 0.191), ('minimization', 0.178), ('hmm', 0.172), ('ravi', 0.139), ('dictionaries', 0.137), ('cknown', 0.132), ('em', 0.124), ('cunktd', 0.118), ('hbi', 0.103), ('fw', 0.098), ('phase', 0.095), ('bigram', 0.092), ('emission', 0.08), ('ti', 0.076), ('initialization', 0.075), ('minimized', 0.074), ('mingreedy', 0.074), ('sym', 0.074), ('tags', 0.073), ('incomplete', 0.071), ('taggers', 0.071), ('tokens', 0.07), ('unknown', 0.07), ('greedy', 0.068), ('paths', 0.065), ('phases', 0.063), ('path', 0.062), ('tagging', 0.06), ('dt', 0.06), ('pknown', 0.059), ('ptd', 0.059), ('sees', 0.057), ('nn', 0.057), ('ptb', 0.056), ('completed', 0.051), ('boy', 0.051), ('bi', 0.049), ('transitions', 0.048), ('vb', 0.048), ('enhancements', 0.046), ('scenario', 0.045), ('iteration', 0.045), ('token', 0.044), ('dbbt', 0.044), ('holes', 0.044), ('tut', 0.044), ('cover', 0.044), ('ambiguity', 0.042), ('sections', 0.041), ('td', 0.041), ('ls', 0.041), ('smoothing', 0.04), ('fill', 0.04), ('unknowns', 0.038), ('vaswani', 0.038), ('italian', 0.038), ('emissions', 0.037), ('banko', 0.037), ('completion', 0.036), ('knight', 0.035), ('openness', 0.034), ('choosing', 0.034), ('constrained', 0.034), ('wi', 0.033), ('transition', 0.033), ('goldberg', 0.033), ('hasan', 0.032), ('sujith', 0.032), ('initialize', 0.031), ('rb', 0.03), ('complete', 0.03), ('iterative', 0.03), ('bosco', 0.029), ('moon', 0.029), ('start', 0.029), ('tagged', 0.027), ('expectation', 0.027), ('unseen', 0.026), ('edges', 0.026), ('covered', 0.026), ('dog', 0.026), ('quarter', 0.025), ('hole', 0.025), ('christodoulopoulos', 0.025), ('plentiful', 0.025), ('entries', 0.025), ('keeps', 0.024), ('encountered', 0.024), ('likelihood', 0.024), ('uniform', 0.023), ('reject', 0.023), ('formance', 0.023), ('ccgbank', 0.023), ('added', 0.023), ('selected', 0.022), ('penn', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="129-tfidf-1" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>Author: Dan Garrette ; Jason Baldridge</p><p>Abstract: Past work on learning part-of-speech taggers from tag dictionaries and raw data has reported good results, but the assumptions made about those dictionaries are often unrealistic: due to historical precedents, they assume access to information about labels in the raw and test sets. Here, we demonstrate ways to learn hidden Markov model taggers from incomplete tag dictionaries. Taking the MINGREEDY algorithm (Ravi et al., 2010) as a starting point, we improve it with several intuitive heuristics. We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data. Altogether, our augmentations produce improvements to per- formance over the original MIN-GREEDY algorithm for both English and Italian data.</p><p>2 0.24991457 <a title="129-tfidf-2" href="./emnlp-2012-Wiki-ly_Supervised_Part-of-Speech_Tagging.html">138 emnlp-2012-Wiki-ly Supervised Part-of-Speech Tagging</a></p>
<p>Author: Shen Li ; Joao Graca ; Ben Taskar</p><p>Abstract: Despite significant recent work, purely unsupervised techniques for part-of-speech (POS) tagging have not achieved useful accuracies required by many language processing tasks. Use of parallel text between resource-rich and resource-poor languages is one source ofweak supervision that significantly improves accuracy. However, parallel text is not always available and techniques for using it require multiple complex algorithmic steps. In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary. Across eight languages for which we have labeled data to evaluate results, we achieve accuracy that significantly exceeds best unsupervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our . approach yields better out-of-domain taggers than those trained using fully supervised Penn Treebank.</p><p>3 0.13988687 <a title="129-tfidf-3" href="./emnlp-2012-Learning_to_Map_into_a_Universal_POS_Tagset.html">81 emnlp-2012-Learning to Map into a Universal POS Tagset</a></p>
<p>Author: Yuan Zhang ; Roi Reichart ; Regina Barzilay ; Amir Globerson</p><p>Abstract: We present an automatic method for mapping language-specific part-of-speech tags to a set of universal tags. This unified representation plays a crucial role in cross-lingual syntactic transfer of multilingual dependency parsers. Until now, however, such conversion schemes have been created manually. Our central hypothesis is that a valid mapping yields POS annotations with coherent linguistic properties which are consistent across source and target languages. We encode this intuition in an objective function that captures a range of distributional and typological characteristics of the derived mapping. Given the exponential size of the mapping space, we propose a novel method for optimizing over soft mappings, and use entropy regularization to drive those towards hard mappings. Our results demonstrate that automatically induced mappings rival the quality of their manually designed counterparts when evaluated in the . context of multilingual parsing.1</p><p>4 0.12512936 <a title="129-tfidf-4" href="./emnlp-2012-Part-of-Speech_Tagging_for_Chinese-English_Mixed_Texts_with_Dynamic_Features.html">106 emnlp-2012-Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features</a></p>
<p>Author: Jiayi Zhao ; Xipeng Qiu ; Shu Zhang ; Feng Ji ; Xuanjing Huang</p><p>Abstract: In modern Chinese articles or conversations, it is very popular to involve a few English words, especially in emails and Internet literature. Therefore, it becomes an important and challenging topic to analyze Chinese-English mixed texts. The underlying problem is how to tag part-of-speech (POS) for the English words involved. Due to the lack of specially annotated corpus, most of the English words are tagged as the oversimplified type, “foreign words”. In this paper, we present a method using dynamic features to tag POS of mixed texts. Experiments show that our method achieves higher performance than traditional sequence labeling methods. Meanwhile, our method also boosts the performance of POS tagging for pure Chinese texts.</p><p>5 0.12059612 <a title="129-tfidf-5" href="./emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">12 emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<p>Author: Bernd Bohnet ; Joakim Nivre</p><p>Abstract: Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins. We present a transitionbased system for joint part-of-speech tagging and labeled dependency parsing with nonprojective trees. Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages.</p><p>6 0.11934385 <a title="129-tfidf-6" href="./emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">70 emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>7 0.1193416 <a title="129-tfidf-7" href="./emnlp-2012-Assessment_of_ESL_Learners%27_Syntactic_Competence_Based_on_Similarity_Measures.html">21 emnlp-2012-Assessment of ESL Learners' Syntactic Competence Based on Similarity Measures</a></p>
<p>8 0.10325542 <a title="129-tfidf-8" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>9 0.08260601 <a title="129-tfidf-9" href="./emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">64 emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<p>10 0.079878397 <a title="129-tfidf-10" href="./emnlp-2012-Mixed_Membership_Markov_Models_for_Unsupervised_Conversation_Modeling.html">89 emnlp-2012-Mixed Membership Markov Models for Unsupervised Conversation Modeling</a></p>
<p>11 0.071062975 <a title="129-tfidf-11" href="./emnlp-2012-Unified_Dependency_Parsing_of_Chinese_Morphological_and_Syntactic_Structures.html">131 emnlp-2012-Unified Dependency Parsing of Chinese Morphological and Syntactic Structures</a></p>
<p>12 0.064843081 <a title="129-tfidf-12" href="./emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</a></p>
<p>13 0.061329626 <a title="129-tfidf-13" href="./emnlp-2012-Exploiting_Reducibility_in_Unsupervised_Dependency_Parsing.html">46 emnlp-2012-Exploiting Reducibility in Unsupervised Dependency Parsing</a></p>
<p>14 0.059654694 <a title="129-tfidf-14" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>15 0.059288844 <a title="129-tfidf-15" href="./emnlp-2012-Minimal_Dependency_Length_in_Realization_Ranking.html">88 emnlp-2012-Minimal Dependency Length in Realization Ranking</a></p>
<p>16 0.059173685 <a title="129-tfidf-16" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>17 0.056620311 <a title="129-tfidf-17" href="./emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">96 emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<p>18 0.053676266 <a title="129-tfidf-18" href="./emnlp-2012-Spectral_Dependency_Parsing_with_Latent_Variables.html">119 emnlp-2012-Spectral Dependency Parsing with Latent Variables</a></p>
<p>19 0.052050333 <a title="129-tfidf-19" href="./emnlp-2012-Exact_Sampling_and_Decoding_in_High-Order_Hidden_Markov_Models.html">43 emnlp-2012-Exact Sampling and Decoding in High-Order Hidden Markov Models</a></p>
<p>20 0.050868001 <a title="129-tfidf-20" href="./emnlp-2012-Automatically_Constructing_a_Normalisation_Dictionary_for_Microblogs.html">22 emnlp-2012-Automatically Constructing a Normalisation Dictionary for Microblogs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.205), (1, -0.109), (2, 0.189), (3, -0.024), (4, 0.028), (5, 0.109), (6, 0.065), (7, -0.018), (8, 0.069), (9, -0.273), (10, 0.156), (11, -0.055), (12, 0.014), (13, -0.098), (14, -0.163), (15, -0.179), (16, -0.052), (17, -0.018), (18, -0.02), (19, 0.055), (20, 0.202), (21, -0.035), (22, 0.061), (23, 0.025), (24, 0.082), (25, 0.123), (26, -0.133), (27, 0.061), (28, 0.08), (29, -0.114), (30, -0.008), (31, 0.092), (32, -0.145), (33, -0.007), (34, -0.018), (35, 0.058), (36, -0.001), (37, -0.137), (38, 0.152), (39, -0.046), (40, 0.053), (41, -0.129), (42, -0.014), (43, -0.061), (44, 0.011), (45, -0.009), (46, 0.03), (47, -0.087), (48, -0.055), (49, 0.078)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99063653 <a title="129-lsi-1" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>Author: Dan Garrette ; Jason Baldridge</p><p>Abstract: Past work on learning part-of-speech taggers from tag dictionaries and raw data has reported good results, but the assumptions made about those dictionaries are often unrealistic: due to historical precedents, they assume access to information about labels in the raw and test sets. Here, we demonstrate ways to learn hidden Markov model taggers from incomplete tag dictionaries. Taking the MINGREEDY algorithm (Ravi et al., 2010) as a starting point, we improve it with several intuitive heuristics. We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data. Altogether, our augmentations produce improvements to per- formance over the original MIN-GREEDY algorithm for both English and Italian data.</p><p>2 0.89537841 <a title="129-lsi-2" href="./emnlp-2012-Wiki-ly_Supervised_Part-of-Speech_Tagging.html">138 emnlp-2012-Wiki-ly Supervised Part-of-Speech Tagging</a></p>
<p>Author: Shen Li ; Joao Graca ; Ben Taskar</p><p>Abstract: Despite significant recent work, purely unsupervised techniques for part-of-speech (POS) tagging have not achieved useful accuracies required by many language processing tasks. Use of parallel text between resource-rich and resource-poor languages is one source ofweak supervision that significantly improves accuracy. However, parallel text is not always available and techniques for using it require multiple complex algorithmic steps. In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary. Across eight languages for which we have labeled data to evaluate results, we achieve accuracy that significantly exceeds best unsupervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our . approach yields better out-of-domain taggers than those trained using fully supervised Penn Treebank.</p><p>3 0.54441285 <a title="129-lsi-3" href="./emnlp-2012-Learning_to_Map_into_a_Universal_POS_Tagset.html">81 emnlp-2012-Learning to Map into a Universal POS Tagset</a></p>
<p>Author: Yuan Zhang ; Roi Reichart ; Regina Barzilay ; Amir Globerson</p><p>Abstract: We present an automatic method for mapping language-specific part-of-speech tags to a set of universal tags. This unified representation plays a crucial role in cross-lingual syntactic transfer of multilingual dependency parsers. Until now, however, such conversion schemes have been created manually. Our central hypothesis is that a valid mapping yields POS annotations with coherent linguistic properties which are consistent across source and target languages. We encode this intuition in an objective function that captures a range of distributional and typological characteristics of the derived mapping. Given the exponential size of the mapping space, we propose a novel method for optimizing over soft mappings, and use entropy regularization to drive those towards hard mappings. Our results demonstrate that automatically induced mappings rival the quality of their manually designed counterparts when evaluated in the . context of multilingual parsing.1</p><p>4 0.47656384 <a title="129-lsi-4" href="./emnlp-2012-Assessment_of_ESL_Learners%27_Syntactic_Competence_Based_on_Similarity_Measures.html">21 emnlp-2012-Assessment of ESL Learners' Syntactic Competence Based on Similarity Measures</a></p>
<p>Author: Su-Youn Yoon ; Suma Bhat</p><p>Abstract: This study presents a novel method that measures English language learners’ syntactic competence towards improving automated speech scoring systems. In contrast to most previous studies which focus on the length of production units such as the mean length of clauses, we focused on capturing the differences in the distribution of morpho-syntactic features or grammatical expressions across proficiency. We estimated the syntactic competence through the use of corpus-based NLP techniques. Assuming that the range and so- phistication of grammatical expressions can be captured by the distribution of Part-ofSpeech (POS) tags, vector space models of POS tags were constructed. We use a large corpus of English learners’ responses that are classified into four proficiency levels by human raters. Our proposed feature measures the similarity of a given response with the most proficient group and is then estimates the learner’s syntactic competence level. Widely outperforming the state-of-the-art measures of syntactic complexity, our method attained a significant correlation with humanrated scores. The correlation between humanrated scores and features based on manual transcription was 0.43 and the same based on ASR-hypothesis was slightly lower, 0.42. An important advantage of our method is its robustness against speech recognition errors not to mention the simplicity of feature generation that captures a reasonable set of learnerspecific syntactic errors. 600 Measures Suma Bhat Beckman Institute, Urbana, IL 61801 . spbhat 2 @ i l l ino i edu s</p><p>5 0.40507862 <a title="129-lsi-5" href="./emnlp-2012-Part-of-Speech_Tagging_for_Chinese-English_Mixed_Texts_with_Dynamic_Features.html">106 emnlp-2012-Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features</a></p>
<p>Author: Jiayi Zhao ; Xipeng Qiu ; Shu Zhang ; Feng Ji ; Xuanjing Huang</p><p>Abstract: In modern Chinese articles or conversations, it is very popular to involve a few English words, especially in emails and Internet literature. Therefore, it becomes an important and challenging topic to analyze Chinese-English mixed texts. The underlying problem is how to tag part-of-speech (POS) for the English words involved. Due to the lack of specially annotated corpus, most of the English words are tagged as the oversimplified type, “foreign words”. In this paper, we present a method using dynamic features to tag POS of mixed texts. Experiments show that our method achieves higher performance than traditional sequence labeling methods. Meanwhile, our method also boosts the performance of POS tagging for pure Chinese texts.</p><p>6 0.35463989 <a title="129-lsi-6" href="./emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</a></p>
<p>7 0.35390952 <a title="129-lsi-7" href="./emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">70 emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>8 0.31903231 <a title="129-lsi-8" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>9 0.31455091 <a title="129-lsi-9" href="./emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">64 emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<p>10 0.30966556 <a title="129-lsi-10" href="./emnlp-2012-Automatically_Constructing_a_Normalisation_Dictionary_for_Microblogs.html">22 emnlp-2012-Automatically Constructing a Normalisation Dictionary for Microblogs</a></p>
<p>11 0.29839194 <a title="129-lsi-11" href="./emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">12 emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<p>12 0.29377723 <a title="129-lsi-12" href="./emnlp-2012-Large_Scale_Decipherment_for_Out-of-Domain_Machine_Translation.html">75 emnlp-2012-Large Scale Decipherment for Out-of-Domain Machine Translation</a></p>
<p>13 0.26371098 <a title="129-lsi-13" href="./emnlp-2012-Mixed_Membership_Markov_Models_for_Unsupervised_Conversation_Modeling.html">89 emnlp-2012-Mixed Membership Markov Models for Unsupervised Conversation Modeling</a></p>
<p>14 0.25477847 <a title="129-lsi-14" href="./emnlp-2012-Spectral_Dependency_Parsing_with_Latent_Variables.html">119 emnlp-2012-Spectral Dependency Parsing with Latent Variables</a></p>
<p>15 0.25296658 <a title="129-lsi-15" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>16 0.25220817 <a title="129-lsi-16" href="./emnlp-2012-Minimal_Dependency_Length_in_Realization_Ranking.html">88 emnlp-2012-Minimal Dependency Length in Realization Ranking</a></p>
<p>17 0.24306639 <a title="129-lsi-17" href="./emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">96 emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<p>18 0.24205709 <a title="129-lsi-18" href="./emnlp-2012-Revisiting_the_Predictability_of_Language%3A_Response_Completion_in_Social_Media.html">114 emnlp-2012-Revisiting the Predictability of Language: Response Completion in Social Media</a></p>
<p>19 0.2418171 <a title="129-lsi-19" href="./emnlp-2012-Exploiting_Reducibility_in_Unsupervised_Dependency_Parsing.html">46 emnlp-2012-Exploiting Reducibility in Unsupervised Dependency Parsing</a></p>
<p>20 0.23877828 <a title="129-lsi-20" href="./emnlp-2012-Exploiting_Chunk-level_Features_to_Improve_Phrase_Chunking.html">45 emnlp-2012-Exploiting Chunk-level Features to Improve Phrase Chunking</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.017), (11, 0.015), (16, 0.036), (25, 0.015), (29, 0.012), (34, 0.099), (39, 0.011), (41, 0.015), (45, 0.044), (58, 0.103), (60, 0.103), (63, 0.077), (64, 0.149), (65, 0.015), (70, 0.023), (74, 0.048), (76, 0.042), (80, 0.024), (82, 0.023), (86, 0.028), (95, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89463335 <a title="129-lda-1" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>Author: Dan Garrette ; Jason Baldridge</p><p>Abstract: Past work on learning part-of-speech taggers from tag dictionaries and raw data has reported good results, but the assumptions made about those dictionaries are often unrealistic: due to historical precedents, they assume access to information about labels in the raw and test sets. Here, we demonstrate ways to learn hidden Markov model taggers from incomplete tag dictionaries. Taking the MINGREEDY algorithm (Ravi et al., 2010) as a starting point, we improve it with several intuitive heuristics. We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data. Altogether, our augmentations produce improvements to per- formance over the original MIN-GREEDY algorithm for both English and Italian data.</p><p>2 0.87179631 <a title="129-lda-2" href="./emnlp-2012-Employing_Compositional_Semantics_and_Discourse_Consistency_in_Chinese_Event_Extraction.html">38 emnlp-2012-Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction</a></p>
<p>Author: Peifeng Li ; Guodong Zhou ; Qiaoming Zhu ; Libin Hou</p><p>Abstract: Current Chinese event extraction systems suffer much from two problems in trigger identification: unknown triggers and word segmentation errors to known triggers. To resolve these problems, this paper proposes two novel inference mechanisms to explore special characteristics in Chinese via compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1</p><p>3 0.85555935 <a title="129-lda-3" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>Author: Hila Weisman ; Jonathan Berant ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Learning inference relations between verbs is at the heart of many semantic applications. However, most prior work on learning such rules focused on a rather narrow set of information sources: mainly distributional similarity, and to a lesser extent manually constructed verb co-occurrence patterns. In this paper, we claim that it is imperative to utilize information from various textual scopes: verb co-occurrence within a sentence, verb cooccurrence within a document, as well as overall corpus statistics. To this end, we propose a much richer novel set of linguistically motivated cues for detecting entailment between verbs and combine them as features in a supervised classification framework. We empirically demonstrate that our model significantly outperforms previous methods and that information from each textual scope contributes to the verb entailment learning task.</p><p>4 0.85528463 <a title="129-lda-4" href="./emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">34 emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>Author: Natalia Ponomareva ; Mike Thelwall</p><p>Abstract: This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification. In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm. We compare these graph-based methods with each other and with the other state-ofthe-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. Analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.</p><p>5 0.73716885 <a title="129-lda-5" href="./emnlp-2012-Wiki-ly_Supervised_Part-of-Speech_Tagging.html">138 emnlp-2012-Wiki-ly Supervised Part-of-Speech Tagging</a></p>
<p>Author: Shen Li ; Joao Graca ; Ben Taskar</p><p>Abstract: Despite significant recent work, purely unsupervised techniques for part-of-speech (POS) tagging have not achieved useful accuracies required by many language processing tasks. Use of parallel text between resource-rich and resource-poor languages is one source ofweak supervision that significantly improves accuracy. However, parallel text is not always available and techniques for using it require multiple complex algorithmic steps. In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary. Across eight languages for which we have labeled data to evaluate results, we achieve accuracy that significantly exceeds best unsupervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our . approach yields better out-of-domain taggers than those trained using fully supervised Penn Treebank.</p><p>6 0.73689318 <a title="129-lda-6" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>7 0.73218364 <a title="129-lda-7" href="./emnlp-2012-N-gram-based_Tense_Models_for_Statistical_Machine_Translation.html">95 emnlp-2012-N-gram-based Tense Models for Statistical Machine Translation</a></p>
<p>8 0.72218496 <a title="129-lda-8" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>9 0.71934545 <a title="129-lda-9" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>10 0.71581656 <a title="129-lda-10" href="./emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities.html">98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</a></p>
<p>11 0.71176827 <a title="129-lda-11" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>12 0.71149993 <a title="129-lda-12" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>13 0.70369327 <a title="129-lda-13" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>14 0.70351934 <a title="129-lda-14" href="./emnlp-2012-Learning_to_Map_into_a_Universal_POS_Tagset.html">81 emnlp-2012-Learning to Map into a Universal POS Tagset</a></p>
<p>15 0.70209801 <a title="129-lda-15" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>16 0.70136017 <a title="129-lda-16" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>17 0.69978482 <a title="129-lda-17" href="./emnlp-2012-Extending_Machine_Translation_Evaluation_Metrics_with_Lexical_Cohesion_to_Document_Level.html">50 emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</a></p>
<p>18 0.69962549 <a title="129-lda-18" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>19 0.69915104 <a title="129-lda-19" href="./emnlp-2012-Building_a_Lightweight_Semantic_Model_for_Unsupervised_Information_Extraction_on_Short_Listings.html">26 emnlp-2012-Building a Lightweight Semantic Model for Unsupervised Information Extraction on Short Listings</a></p>
<p>20 0.69734573 <a title="129-lda-20" href="./emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">64 emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
