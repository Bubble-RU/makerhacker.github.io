<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-16" href="#">emnlp2012-16</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</h1>
<br/><p>Source: <a title="emnlp-2012-16-pdf" href="http://aclweb.org/anthology//D/D12/D12-1016.pdf">pdf</a></p><p>Author: Michael Roth ; Anette Frank</p><p>Abstract: Generating coherent discourse is an important aspect in natural language generation. Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.</p><p>Reference: <a title="emnlp-2012-16-reference" href="../emnlp2012_reference/emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. [sent-3, score-0.251]
</p><p>2 We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. [sent-4, score-0.701]
</p><p>3 The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. [sent-5, score-0.338]
</p><p>4 Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. [sent-6, score-0.811]
</p><p>5 Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin  of at least 6. [sent-7, score-0.378]
</p><p>6 Furthermore, the entity-based approach only  investigates realization patterns for individual entities in discourse in terms of core grammatical functions. [sent-17, score-0.252]
</p><p>7 The main hypothesis of our work is that we can automatically learn context-specific realization patterns for predicate argument structures (PAS) from a semantically parsed corpus of comparable text pairs. [sent-20, score-0.588]
</p><p>8 By aligning predicates in such texts, we can investigate the factors that determine discourse coherence in the realization patterns for the involved arguments. [sent-25, score-0.962]
</p><p>9 lc L2a0n1g2ua Agseso Pcrioactieosnsi fnogr a Cnodm Cpoumtaptiuotna tilo Lnianlg Nuaist uircasl gate the factors that govern the non-realization of an argument position, as a special form of coherence inducing element in discourse. [sent-30, score-0.327]
</p><p>10 Example (1), extracted from our corpus of aligned texts,illustrates this point: Both texts report on the same event of locating victims in an avalanche. [sent-31, score-0.275]
</p><p>11 In fact, realization of this argument role would impede the fluency of discourse by being overly repetitive. [sent-35, score-0.408]
</p><p>12 Thus, our aim is to identify comparable predications across aligned texts, and to study the discourse coherence factors that determine the realization patterns of arguments in the respective discourses. [sent-46, score-0.71]
</p><p>13 This paper focuses on the first of these tasks, henceforth called predicate alignment. [sent-48, score-0.266]
</p><p>14 2 In line with data-driven approaches in NLP, we automatically align predicates in a suitable corpus of paired texts. [sent-49, score-0.509]
</p><p>15 The induced alignments will (i) serve to identify events described in both comparable texts, and (ii) provide information about the underlying argument structures and how they are realized in each context to establish a coherent discourse. [sent-50, score-0.534]
</p><p>16 172 ing such alignments as clustering provides a suitable framework to implicitly relate alignment decisions to one another, by exploiting global information encoded in a graph. [sent-54, score-0.538]
</p><p>17 Section 4 introduces a graph-based clustering model using Mincuts for the alignment of predicates. [sent-57, score-0.28]
</p><p>18 Typically, alignment models in SMT are trained by observing and (re-)estimating co-occurrence counts of word pairs in parallel sentences (Brown et al. [sent-61, score-0.244]
</p><p>19 In contrast to traditional word alignment tasks, our focus is not on pairs of isolated sentences but on aligning predicates within the discourse contexts in which they are situated. [sent-65, score-0.941]
</p><p>20 In contrast to coreference methods that identify chains of events, we are interested in pairs of corresponding predicates (and their argument structure), for which we can observe alternative realizations in discourse. [sent-103, score-0.63]
</p><p>21 3  Aligning Predicates Across Texts  This section summarizes how we built a large cor-  pus of comparable texts, as a basis for the predicate alignment task. [sent-104, score-0.527]
</p><p>22 Subsequently, we report on the preparation of an evaluation data set with manual predicate alignments across the paired texts. [sent-106, score-0.488]
</p><p>23 We conclude this 173 section with an example that showcases the potential of using aligned predicates for the study of coherence phenomena. [sent-107, score-0.597]
</p><p>24 1 Corpus Creation The goal of our work is to investigate coherence factors for argument structure realization, using comparable texts that describe the same events, but that include variation in textual presentation. [sent-110, score-0.555]
</p><p>25 2  Gold Standard Annotation  We selected 70 text pairs from the GigaPairs corpus for manual predicate alignment. [sent-129, score-0.321]
</p><p>26 We asked two students4 to tag corresponding predicates across each text pair. [sent-134, score-0.419]
</p><p>27 (2008)) the annotators were instructed to distinguish between sure and possible alignments, depending on how certainly, in their opinion, two predicates describe verbalizations of the same event. [sent-137, score-0.598]
</p><p>28 The following examples show predicate pairings marked as sure (2) and as possible alignments (3). [sent-138, score-0.606]
</p><p>29 ] In total, the annotators (A/B) aligned 487/451 sure and 221/180 possible alignments with a Kappa score (Cohen, 1960) of 0. [sent-156, score-0.402]
</p><p>30 5 For the construction of a gold standard, we merged the alignments from both annotators by taking the union of all possible alignments and the intersection of all sure alignments. [sent-158, score-0.611]
</p><p>31 Cases which involved a sure alignment on which the annotators disagreed were resolved in a group discussion with the first author. [sent-159, score-0.307]
</p><p>32 The test set contains a total of 3,453 predicates (1,53 1nouns and 1,922 verbs). [sent-161, score-0.419]
</p><p>33 4%) are between predicates of the same part-of-speech (242 noun and 423 verb pairs). [sent-166, score-0.419]
</p><p>34 5%) have been annotated between predicates with identical lemma form. [sent-168, score-0.458]
</p><p>35 5Following Brockett (2007), we computed agreement on labeled annotations, including unaligned predicate pairs as an additional null category. [sent-172, score-0.321]
</p><p>36 3 Potential for Discourse Coherence This section presents an example of an aligned predicate pair from our development set that illustrates the potential of aggregating corresponding PAS across comparable texts. [sent-174, score-0.4]
</p><p>37 In both sentences, the Arg0 role of the predicate flee is filled, but Arg1 (here: the goal) has not been realized in (4. [sent-180, score-0.266]
</p><p>38 Poten-  tial factors on the discourse level include the information status of the entity filling an argument position, and its salience at the corresponding point in discourse. [sent-185, score-0.369]
</p><p>39 Hence, we can utilize each such pair as one positive and one negative training instance for a model of discourse coherence that controls the omissibility of arguments. [sent-190, score-0.274]
</p><p>40 4  Model  For the automatic induction of predicate alignments across texts, we opt for an unsupervised graph-based clustering method. [sent-192, score-0.579]
</p><p>41 In particular, predicates are represented as nodes in such a graph and similarities between predicates as edges. [sent-194, score-0.891]
</p><p>42 We then proceed to describe various similarity measures that can be used to identify similar predicate instances. [sent-195, score-0.418]
</p><p>43 Finally, we introduce the clustering algorithm that we apply to graphs (representing pairs of documents) in order to induce alignments between corresponding predicates. [sent-196, score-0.368]
</p><p>44 1 Graph representation We build a bipartite graph representation for each pair of texts, using as vertices the predicate argument structures assigned in pre-processing (cf. [sent-198, score-0.475]
</p><p>45 We represent each predicate as a node and integrate information about arguments only implicitly. [sent-201, score-0.331]
</p><p>46 Given the sets of predicates P1 and P2 of two comparable texts T1 and T2, respectively, we formally define an undirected graph GP1,P2 as follows:  GP1,P2= hV,Ei  where  EV = = P P11∪× P P22  (1)  Edge weights. [sent-202, score-0.653]
</p><p>47 We specify the edge weight between two nodes representing predicates p1 ∈ P1 and p2 ∈ P2 as a weighted linear combinati∈on Pof four similarity measures described in the next section: WordNet and VerbNet similarity, Distributional  similarity and Argument similarity. [sent-203, score-0.674]
</p><p>48 6 Given two lemmatized predicates p1, p2 and their set of arguments A1 = args(p1), A2 = args(p2), we define the following measures. [sent-211, score-0.484]
</p><p>49 Given all pairs of synsets s1, s2 that contain the predicates p1, p2, respectively, we compute the maximal similarity using the information theoretic measure described in Lin (1998). [sent-213, score-0.577]
</p><p>50 This applies in particular to all cases that involve a predicate not present in WordNet. [sent-221, score-0.266]
</p><p>51 Richens (2008)), we further compute similarity between verbal predicates using VerbNet (Kipper  et al. [sent-224, score-0.522]
</p><p>52 Weper edseefninte f a simple similarity function that defines fixed similarity scores between 0 and 1 for pairs of predicates p1, p2 depending on their relatedness within the VerbNet class hierarchy:  simVN(p1,p2) =  010. [sent-228, score-0.68]
</p><p>53 As some predicates may not be covered by the WordNet and VerbNet hierarchies, we additionally calculate similarity based on distributional meaning in a semantic space (Landauer and Dumais, 1997). [sent-230, score-0.522]
</p><p>54 , c2000 ∈ C as dimensions of a vector space and define predicates as vimecetnosrsio using  their Pointwise Mutual Information (PMI):  p~ = (PMI(p, c1), . [sent-234, score-0.419]
</p><p>55 While the previous similarity measures are purely type-based, argument similarity integrates token-based, i. [sent-238, score-0.411]
</p><p>56 , discourse-specific, similarity information about predications by taking into account the similarity of their arguments. [sent-240, score-0.294]
</p><p>57 This measure calculates the association between the arguments A1 of the first and the arguments A2 of the second predicate by determining the ratio of overlapping words in both argument sets. [sent-241, score-0.552]
</p><p>58 3 Mincut-based Clustering Our graph clustering method uses minimum cuts (or Mincut) in order to partition the bipartite text graph into clusters of aligned predicates. [sent-246, score-0.324]
</p><p>59 The advantage of our method compared to offthe-shelf clustering techniques is two-fold: On the one hand, the clustering algorithm is free of any parameters, such as the number of clusters or a clustering threshold, that require fine-tuning. [sent-262, score-0.338]
</p><p>60 On the other hand, the approach makes use of a termination criterion that very well represents the nature of the goal of our task, namely to align pairs of predicates across comparable texts. [sent-263, score-0.6]
</p><p>61 5  Experiments  This section evaluates our graph-clustering model on the task of aligning predicates across comparable texts. [sent-265, score-0.611]
</p><p>62 For comparison to related tasks and methods, we describe different evaluation settings, vari-  Figure 1: The predicates of two sentences (white:  “The company has said it plans to restate its earnings for 2000  through 2002. [sent-266, score-0.537]
</p><p>63 1 Settings In order to benchmark our model against traditional methods for word alignment, we first apply our graph-based alignment model (Full) on three sentence-based paraphrase corpora. [sent-273, score-0.356]
</p><p>64 In a second experiment, we evaluate Full on our novel task of inducing predicate alignments across comparable monolingual texts, using the GigaPairs data set described in Section 3. [sent-277, score-0.56]
</p><p>65 We evaluate against the manually annotated gold alignments in the test data set described in Section 3. [sent-278, score-0.271]
</p><p>66 To gain more insight into the performance of the various similarity measures included in the Full model, we evaluate simplified versions that omit individual similarity measures (Full–[measure name]). [sent-280, score-0.304]
</p><p>67 The relative differences in performance against various baselines will help us quantify the differences and difficulties between a traditional sentencebased word alignment setting and our novel alignment task that operates on full texts. [sent-281, score-0.442]
</p><p>68 1 Sentence-level Alignment Setting For sentence-based predicate alignment we make use of the following three corpora that are wordaligned subsets of the paraphrase collections described in (Cohn et al. [sent-284, score-0.622]
</p><p>69 All models are evaluated against the subset of gold standard alignments (cf. [sent-298, score-0.271]
</p><p>70 In this setting, models are evaluated against the annotated gold standard alignments between predicates as described in Section 3. [sent-306, score-0.69]
</p><p>71 Since all text pairs in GigaPairs comprise multiple sentences each, the average number of predicates per text to consider (27. [sent-308, score-0.474]
</p><p>72 As the full graph representation becomes rather inefficient to handle (by default, edges are inserted between all predicate pairs), we use the development set of 10 text pairs to estimate  TaWbLloer1Gmd:AReFlaiudgsInyltfoP27r954esc. [sent-310, score-0.438]
</p><p>73 a threshold on predicate similarity for adding edges. [sent-322, score-0.369]
</p><p>74 2  Baselines  A simple baseline for both settings is to align all predicates whose lemmas are identical. [sent-330, score-0.513]
</p><p>75 In order to assess the benefits of the clustering step, we propose a second baseline that uses the same similarity measures and thresholds as our Full model, but omits the clustering step described in Section 4. [sent-332, score-0.334]
</p><p>76 Instead, it greed-  ily computes as many 1-to-1 alignments as possible, starting from the highest similarity to the learned threshold (Greedy). [sent-334, score-0.325]
</p><p>77 (2008) readily provide GIZA++ (Och and Ney, 2003) alignments as part of their word-aligned paraphrase corpus. [sent-337, score-0.389]
</p><p>78 For the experiments in the GigaPairs setting, we train our own word alignment model using the state-of-theart word alignment tool Berkeley Aligner (Liang et al. [sent-338, score-0.378]
</p><p>79 As word alignment tools require pairs of sentences as input, we first extract paraphrases in the latter setting using a re-implementation of the paraphrase detection system by Wan et al. [sent-340, score-0.448]
</p><p>80 3 Results We measure precision as the number of predicted alignments that are annotated in the gold standard divided by the total number of predictions. [sent-347, score-0.271]
</p><p>81 Recall is measured as the number of correctly predicted sure alignments divided by the total number of sure alignments in the gold standard. [sent-348, score-0.729]
</p><p>82 In fact, the results for LemmaId show that by aligning all predicates with identical lemmas, most of the sure alignments in the three settings are already covered. [sent-361, score-0.919]
</p><p>83 On the other hand, even sentence pairs that contain gold alignments are generally less parallel than in the previous settings, which make them harder to align. [sent-373, score-0.326]
</p><p>84 In contrast, we observe that the majority of all sure alignments (60. [sent-376, score-0.34]
</p><p>85 However, a significant difference can only be observed when removing the argument similarity measure, which drastically reduces the results. [sent-394, score-0.259]
</p><p>86 In total, the model missed 13 out of 35 sure alignments (Type Ierrors) and predicted 23 alignments not annotated in the gold standard (Type IIerrors). [sent-454, score-0.611]
</p><p>87 Six Type I errors (46%) occurred when the lemma of an affected predicate occurred more than once in a text and the model missed a correct link. [sent-455, score-0.305]
</p><p>88 Vice versa, identical predicates that refer to different events have been the source of 8 Type II errors (35%). [sent-456, score-0.465]
</p><p>89 Altogether, we find 15 Type II errors (65%) that are due to high predicate similarity despite low argument overlap (cf. [sent-458, score-0.525]
</p><p>90 6  Conclusion  We presented a novel task for predicate alignment across comparable monolingual texts, which we address using graph-based clustering with Mincuts. [sent-494, score-0.618]
</p><p>91 The motivation for this task is to acquire empirical data for studying discourse coherence factors related  to argument structure realization. [sent-495, score-0.485]
</p><p>92 As a first step, we constructed a data set of comparable texts that provide full discourse contexts for alternative verbalizations of the same underlying events. [sent-496, score-0.464]
</p><p>93 A subset of these pairs forms an evaluation set, annotated with gold alignments that relate predications, which exhibit a (possibly partial) corresponding argument structure. [sent-498, score-0.482]
</p><p>94 180 Our main contribution is a novel clustering approach using Mincuts for aligning predications across comparable texts. [sent-501, score-0.371]
</p><p>95 We tested our full model against two additional baselines: simple heuristic alignment based on identical lemma forms and a combination of techniques from SMT and paraphrase detection. [sent-504, score-0.459]
</p><p>96 The evaluation for our novel task was complemented by a traditional word alignment task using established paraphrase data sets. [sent-505, score-0.356]
</p><p>97 While word alignment methods from SMT outperform the competing models in the sentencebased alignment tasks, they perform poorly in the discourse setting. [sent-507, score-0.536]
</p><p>98 Even though such an optimization will result in an overall lower recall, application of the alignment model on the entire GigaPairs corpus can still provide us with a large amount of precise predicate alignments. [sent-514, score-0.455]
</p><p>99 Using this set of alignments, we will then proceed to exploit contextual information in order to learn a semantic model for discourse coherence in argument structure realization. [sent-515, score-0.43]
</p><p>100 Aligning predicate argument structures in monolingual comparable texts: A new corpus for a new task. [sent-678, score-0.494]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('predicates', 0.419), ('predicate', 0.266), ('gigapairs', 0.245), ('alignments', 0.222), ('alignment', 0.189), ('paraphrase', 0.167), ('discourse', 0.158), ('argument', 0.156), ('wordalign', 0.122), ('aligning', 0.12), ('sure', 0.118), ('coherence', 0.116), ('texts', 0.109), ('similarity', 0.103), ('mincut', 0.102), ('realization', 0.094), ('clustering', 0.091), ('verbnet', 0.088), ('leagues', 0.088), ('predications', 0.088), ('lemmaid', 0.082), ('warning', 0.082), ('gigaword', 0.074), ('comparable', 0.072), ('cohn', 0.071), ('mirkin', 0.07), ('msr', 0.069), ('entailment', 0.066), ('arguments', 0.065), ('dagan', 0.065), ('clusters', 0.065), ('full', 0.064), ('gs', 0.063), ('mtc', 0.063), ('aligned', 0.062), ('alert', 0.061), ('asterisks', 0.061), ('mincuts', 0.061), ('simarg', 0.061), ('simwn', 0.061), ('verbalizations', 0.061), ('socher', 0.059), ('smt', 0.058), ('consortium', 0.057), ('factors', 0.055), ('pairs', 0.055), ('align', 0.054), ('frank', 0.054), ('graph', 0.053), ('wordnet', 0.053), ('args', 0.053), ('entailing', 0.053), ('victims', 0.053), ('rte', 0.052), ('greedy', 0.051), ('event', 0.051), ('roth', 0.049), ('measures', 0.049), ('gold', 0.049), ('fifth', 0.048), ('recovered', 0.048), ('textual', 0.047), ('pmi', 0.047), ('events', 0.046), ('barzilay', 0.045), ('weighting', 0.045), ('pas', 0.044), ('said', 0.042), ('ido', 0.042), ('wan', 0.041), ('heidelberg', 0.041), ('meyers', 0.041), ('july', 0.041), ('anette', 0.041), ('apw', 0.041), ('bodies', 0.041), ('earnings', 0.041), ('fled', 0.041), ('parker', 0.041), ('ruppenhofer', 0.041), ('unrealized', 0.041), ('settings', 0.04), ('lemma', 0.039), ('martha', 0.039), ('brockett', 0.039), ('dolan', 0.039), ('coherent', 0.038), ('coling', 0.038), ('idf', 0.037), ('paraphrases', 0.037), ('microsoft', 0.037), ('suitable', 0.036), ('centering', 0.035), ('grosz', 0.035), ('msrpc', 0.035), ('afp', 0.035), ('analyzers', 0.035), ('bentivogli', 0.035), ('kazuaki', 0.035), ('restate', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000015 <a title="16-tfidf-1" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>Author: Michael Roth ; Anette Frank</p><p>Abstract: Generating coherent discourse is an important aspect in natural language generation. Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.</p><p>2 0.2074708 <a title="16-tfidf-2" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>Author: Michaela Regneri ; Rui Wang</p><p>Abstract: Previous work on paraphrase extraction using parallel or comparable corpora has generally not considered the documents’ discourse structure as a useful information source. We propose a novel method for collecting paraphrases relying on the sequential event order in the discourse, using multiple sequence alignment with a semantic similarity measure. We show that adding discourse information boosts the performance of sentence-level paraphrase acquisition, which consequently gives a tremendous advantage for extracting phraselevel paraphrase fragments from matched sentences. Our system beats an informed baseline by a margin of 50%.</p><p>3 0.20626779 <a title="16-tfidf-3" href="./emnlp-2012-Generalizing_Sub-sentential_Paraphrase_Acquisition_across_Original_Signal_Type_of_Text_Pairs.html">58 emnlp-2012-Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs</a></p>
<p>Author: Aurelien Max ; Houda Bouamor ; Anne Vilnat</p><p>Abstract: This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of subsentential paraphrases found in our corpus types is given.</p><p>4 0.15275745 <a title="16-tfidf-4" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>5 0.15227786 <a title="16-tfidf-5" href="./emnlp-2012-Enlarging_Paraphrase_Collections_through_Generalization_and_Instantiation.html">39 emnlp-2012-Enlarging Paraphrase Collections through Generalization and Instantiation</a></p>
<p>Author: Atsushi Fujita ; Pierre Isabelle ; Roland Kuhn</p><p>Abstract: This paper presents a paraphrase acquisition method that uncovers and exploits generalities underlying paraphrases: paraphrase patterns are first induced and then used to collect novel instances. Unlike existing methods, ours uses both bilingual parallel and monolingual corpora. While the former are regarded as a source of high-quality seed paraphrases, the latter are searched for paraphrases that match patterns learned from the seed paraphrases. We show how one can use monolingual corpora, which are far more numerous and larger than bilingual corpora, to obtain paraphrases that rival in quality those derived directly from bilingual corpora. In our experiments, the number of paraphrase pairs obtained in this way from monolingual corpora was a large multiple of the number of seed paraphrases. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrase pairs are ofreasonable quality. Remaining noise can be further reduced by filtering seed paraphrases.</p><p>6 0.14463577 <a title="16-tfidf-6" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>7 0.12000078 <a title="16-tfidf-7" href="./emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">4 emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>8 0.11756707 <a title="16-tfidf-8" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>9 0.11111895 <a title="16-tfidf-9" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>10 0.1022202 <a title="16-tfidf-10" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>11 0.089539945 <a title="16-tfidf-11" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>12 0.088022158 <a title="16-tfidf-12" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>13 0.084071234 <a title="16-tfidf-13" href="./emnlp-2012-A_Bayesian_Model_for_Learning_SCFGs_with_Discontiguous_Rules.html">1 emnlp-2012-A Bayesian Model for Learning SCFGs with Discontiguous Rules</a></p>
<p>14 0.078578167 <a title="16-tfidf-14" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>15 0.077876359 <a title="16-tfidf-15" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>16 0.077821903 <a title="16-tfidf-16" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>17 0.070644408 <a title="16-tfidf-17" href="./emnlp-2012-Minimal_Dependency_Length_in_Realization_Ranking.html">88 emnlp-2012-Minimal Dependency Length in Realization Ranking</a></p>
<p>18 0.070363812 <a title="16-tfidf-18" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>19 0.070143573 <a title="16-tfidf-19" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>20 0.06758377 <a title="16-tfidf-20" href="./emnlp-2012-Joint_Inference_for_Event_Timeline_Construction.html">72 emnlp-2012-Joint Inference for Event Timeline Construction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.29), (1, 0.07), (2, -0.249), (3, -0.05), (4, 0.111), (5, 0.211), (6, 0.065), (7, -0.088), (8, -0.095), (9, 0.033), (10, -0.081), (11, 0.01), (12, -0.032), (13, 0.06), (14, -0.003), (15, 0.044), (16, -0.032), (17, -0.057), (18, 0.065), (19, 0.06), (20, 0.024), (21, -0.027), (22, 0.013), (23, 0.072), (24, -0.011), (25, -0.002), (26, -0.048), (27, -0.096), (28, 0.104), (29, -0.014), (30, -0.097), (31, 0.02), (32, 0.06), (33, -0.177), (34, 0.099), (35, 0.148), (36, -0.043), (37, 0.038), (38, -0.072), (39, 0.055), (40, -0.019), (41, -0.2), (42, -0.051), (43, -0.11), (44, 0.045), (45, -0.031), (46, 0.094), (47, -0.014), (48, 0.0), (49, 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96195877 <a title="16-lsi-1" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>Author: Michael Roth ; Anette Frank</p><p>Abstract: Generating coherent discourse is an important aspect in natural language generation. Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.</p><p>2 0.71279508 <a title="16-lsi-2" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>Author: Michaela Regneri ; Rui Wang</p><p>Abstract: Previous work on paraphrase extraction using parallel or comparable corpora has generally not considered the documents’ discourse structure as a useful information source. We propose a novel method for collecting paraphrases relying on the sequential event order in the discourse, using multiple sequence alignment with a semantic similarity measure. We show that adding discourse information boosts the performance of sentence-level paraphrase acquisition, which consequently gives a tremendous advantage for extracting phraselevel paraphrase fragments from matched sentences. Our system beats an informed baseline by a margin of 50%.</p><p>3 0.54406369 <a title="16-lsi-3" href="./emnlp-2012-Generalizing_Sub-sentential_Paraphrase_Acquisition_across_Original_Signal_Type_of_Text_Pairs.html">58 emnlp-2012-Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs</a></p>
<p>Author: Aurelien Max ; Houda Bouamor ; Anne Vilnat</p><p>Abstract: This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of subsentential paraphrases found in our corpus types is given.</p><p>4 0.54160148 <a title="16-lsi-4" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>Author: Annie Louis ; Ani Nenkova</p><p>Abstract: We introduce a model of coherence which captures the intentional discourse structure in text. Our work is based on the hypothesis that syntax provides a proxy for the communicative goal of a sentence and therefore the sequence of sentences in a coherent discourse should exhibit detectable structural patterns. Results show that our method has high discriminating power for separating out coherent and incoherent news articles reaching accuracies of up to 90%. We also show that our syntactic patterns are correlated with manual annotations of intentional structure for academic conference articles and can successfully predict the coherence of abstract, introduction and related work sections of these articles. 59.3 (100.0) Intro 50.3 (100.0) 1166 Rel wk 55.4 (100.0) >= 0.663.8 (67.2)50.8 (71.1)58.6 (75.9) >= 0.7 67.2 (32.0) 54.4 (38.6) 63.3 (52.8) >= 0.8 74.0 (10.0) 51.6 (22.0) 63.0 (25.7) >= 0.9 91.7 (2.0) 30.6 (5.0) 68.1 (7.2) Table 9: Accuracy (% examples) above each confidence level for the conference versus workshop task. These results are shown in Table 9. The proportion of examples under each setting is also indicated. When only examples above 0.6 confidence are examined, the classifier has a higher accuracy of63.8% for abstracts and covers close to 70% of the examples. Similarly, when a cutoff of 0.7 is applied to the confidence for predicting related work sections, we achieve 63.3% accuracy for 53% of examples. So we can consider that 30 to 47% of the examples in the two sections respectively are harder to tell apart. Interestingly however even high confidence predictions on introductions remain incorrect. These results show that our model can successfully distinguish the structure of articles beyond just clearly incoherent permutation examples. 7 Conclusion Our work is the first to develop an unsupervised model for intentional structure and to show that it has good accuracy for coherence prediction and also complements entity and lexical structure of discourse. This result raises interesting questions about how patterns captured by these different coherence metrics vary and how they can be combined usefully for predicting coherence. We plan to explore these ideas in future work. We also want to analyze genre differences to understand if the strength of these coherence dimensions varies with genre. Acknowledgements This work is partially supported by a Google research grant and NSF CAREER 0953445 award. References Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computa- tional Linguistics, 34(1): 1–34. Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of NAACL-HLT, pages 113–120. Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL, pages 9–16. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL, pages 173–180. Jackie C.K. Cheung and Gerald Penn. 2010. Utilizing extra-sentential context for parsing. In Proceedings of EMNLP, pages 23–33. Christelle Cocco, Rapha ¨el Pittier, Fran ¸cois Bavaud, and Aris Xanthos. 2011. Segmentation and clustering of textual sequences: a typological approach. In Proceedings of RANLP, pages 427–433. Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 3 1:25–70. Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. Parscit: An open-source crf reference string parsing package. In Proceedings of LREC, pages 661–667. Micha Elsner and Eugene Charniak. 2008. Coreferenceinspired coherence modeling. In Proceedings of ACLHLT, Short Papers, pages 41–44. Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of ACL-HLT, pages 125–129. Micha Elsner, Joseph Austerweil, and Eugene Charniak. 2007. A unified local and global model for discourse coherence. In Proceedings of NAACL-HLT, pages 436–443. Pascale Fung and Grace Ngai. 2006. One story, one flow: Hidden markov story models for multilingual multidocument summarization. ACM Transactions on Speech and Language Processing, 3(2): 1–16. Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 3(12): 175–204. Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011. A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of EMNLP, pages 273–283. Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-HLT, pages 586–594, June. 1167 Nikiforos Karamanis, Chris Mellish, Massimo Poesio, and Jon Oberlander. 2009. Evaluating centering for information ordering using corpora. Computational Linguistics, 35(1):29–46. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL, pages 423–430. Mirella Lapata and Regina Barzilay. 2005. Automatic evaluation of text coherence: Models and representations. In Proceedings of IJCAI. Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL, pages 545–552. Maria Liakata and Larisa Soldatova. 2008. Guidelines for the annotation of general scientific concepts. JISC Project Report. Maria Liakata, Simone Teufel, Advaith Siddharthan, and Colin Batchelor. 2010. Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC. Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proceedings of EMNLP, pages 343–351. Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011. Automatically evaluating text coherence using discourse relations. In Proceedings of ACL-HLT, pages 997– 1006. Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330. Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP, pages 186–195. Dragomir R. Radev, Mark Thomas Joseph, Bryan Gibson, and Pradeep Muthukrishnan. 2009. A Bibliometric and Network Analysis ofthe field of Computational Linguistics. Journal of the American Society for Information Science and Technology. David Reitter, Johanna D. Moore, and Frank Keller. 2006. Priming of Syntactic Rules in Task-Oriented Dialogue and Spontaneous Conversation. In Proceedings of the 28th Annual Conference of the Cognitive Science Society, pages 685–690. Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Proceedings of the fifth conference on Applied natural language processing, pages 16–19. Radu Soricut and Daniel Marcu. 2006. Discourse generation using utility-trained coherence models. In Proceedings of COLING-ACL, pages 803–810. John Swales. 1990. Genre analysis: English in academic and research settings, volume 11. Cambridge University Press. Simone Teufel and Marc Moens. 2000. What’s yours and what’s mine: determining intellectual attribution in scientific text. In Proceedings of EMNLP, pages 9– 17. Simone Teufel, Jean Carletta, and Marc Moens. 1999. An annotation scheme for discourse-level argumentation in research articles. In Proceedings of EACL, pages 110–1 17. Ying Zhao, George Karypis, and Usama Fayyad. 2005. Hierarchical clustering algorithms for document datasets. Data Mining and Knowledge Discovery, 10: 141–168. 1168</p><p>5 0.53007925 <a title="16-lsi-5" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>Author: Hila Weisman ; Jonathan Berant ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Learning inference relations between verbs is at the heart of many semantic applications. However, most prior work on learning such rules focused on a rather narrow set of information sources: mainly distributional similarity, and to a lesser extent manually constructed verb co-occurrence patterns. In this paper, we claim that it is imperative to utilize information from various textual scopes: verb co-occurrence within a sentence, verb cooccurrence within a document, as well as overall corpus statistics. To this end, we propose a much richer novel set of linguistically motivated cues for detecting entailment between verbs and combine them as features in a supervised classification framework. We empirically demonstrate that our model significantly outperforms previous methods and that information from each textual scope contributes to the verb entailment learning task.</p><p>6 0.49158165 <a title="16-lsi-6" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>7 0.48641631 <a title="16-lsi-7" href="./emnlp-2012-Enlarging_Paraphrase_Collections_through_Generalization_and_Instantiation.html">39 emnlp-2012-Enlarging Paraphrase Collections through Generalization and Instantiation</a></p>
<p>8 0.45508933 <a title="16-lsi-8" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>9 0.41255119 <a title="16-lsi-9" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>10 0.40839872 <a title="16-lsi-10" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>11 0.40593961 <a title="16-lsi-11" href="./emnlp-2012-Employing_Compositional_Semantics_and_Discourse_Consistency_in_Chinese_Event_Extraction.html">38 emnlp-2012-Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction</a></p>
<p>12 0.39926752 <a title="16-lsi-12" href="./emnlp-2012-A_Bayesian_Model_for_Learning_SCFGs_with_Discontiguous_Rules.html">1 emnlp-2012-A Bayesian Model for Learning SCFGs with Discontiguous Rules</a></p>
<p>13 0.36038259 <a title="16-lsi-13" href="./emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">4 emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>14 0.35289207 <a title="16-lsi-14" href="./emnlp-2012-Towards_Efficient_Named-Entity_Rule_Induction_for_Customizability.html">125 emnlp-2012-Towards Efficient Named-Entity Rule Induction for Customizability</a></p>
<p>15 0.34919816 <a title="16-lsi-15" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>16 0.34666213 <a title="16-lsi-16" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>17 0.33535281 <a title="16-lsi-17" href="./emnlp-2012-Minimal_Dependency_Length_in_Realization_Ranking.html">88 emnlp-2012-Minimal Dependency Length in Realization Ranking</a></p>
<p>18 0.3311553 <a title="16-lsi-18" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>19 0.32795137 <a title="16-lsi-19" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>20 0.32457921 <a title="16-lsi-20" href="./emnlp-2012-Supervised_Text-based_Geolocation_Using_Language_Models_on_an_Adaptive_Grid.html">121 emnlp-2012-Supervised Text-based Geolocation Using Language Models on an Adaptive Grid</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.013), (16, 0.015), (25, 0.023), (34, 0.066), (45, 0.026), (60, 0.105), (63, 0.054), (64, 0.036), (65, 0.037), (70, 0.03), (74, 0.059), (76, 0.041), (79, 0.013), (80, 0.342), (86, 0.029), (95, 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97940511 <a title="16-lda-1" href="./emnlp-2012-On_Amortizing_Inference_Cost_for_Structured_Prediction.html">99 emnlp-2012-On Amortizing Inference Cost for Structured Prediction</a></p>
<p>Author: Vivek Srikumar ; Gourab Kundu ; Dan Roth</p><p>Abstract: This paper deals with the problem of predicting structures in the context of NLP. Typically, in structured prediction, an inference procedure is applied to each example independently of the others. In this paper, we seek to optimize the time complexity of inference over entire datasets, rather than individual examples. By considering the general inference representation provided by integer linear programs, we propose three exact inference theorems which allow us to re-use earlier solutions for certain instances, thereby completely avoiding possibly expensive calls to the inference procedure. We also identify several approximation schemes which can provide further speedup. We instantiate these ideas to the structured prediction task of semantic role labeling and show that we can achieve a speedup of over 2.5 using our approach while retaining the guarantees of exactness and a further speedup of over 3 using approximations that do not degrade performance.</p><p>same-paper 2 0.84214759 <a title="16-lda-2" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>Author: Michael Roth ; Anette Frank</p><p>Abstract: Generating coherent discourse is an important aspect in natural language generation. Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.</p><p>3 0.57461047 <a title="16-lda-3" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>4 0.55700266 <a title="16-lda-4" href="./emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">64 emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<p>Author: Alexander Rush ; Roi Reichart ; Michael Collins ; Amir Globerson</p><p>Abstract: State-of-the-art statistical parsers and POS taggers perform very well when trained with large amounts of in-domain data. When training data is out-of-domain or limited, accuracy degrades. In this paper, we aim to compensate for the lack of available training data by exploiting similarities between test set sentences. We show how to augment sentencelevel models for parsing and POS tagging with inter-sentence consistency constraints. To deal with the resulting global objective, we present an efficient and exact dual decomposition decoding algorithm. In experiments, we add consistency constraints to the MST parser and the Stanford part-of-speech tagger and demonstrate significant error reduction in the domain adaptation and the lightly supervised settings across five languages.</p><p>5 0.5337314 <a title="16-lda-5" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<p>Author: Taylor Berg-Kirkpatrick ; David Burkett ; Dan Klein</p><p>Abstract: We investigate two aspects of the empirical behavior of paired significance tests for NLP systems. First, when one system appears to outperform another, how does significance level relate in practice to the magnitude of the gain, to the size of the test set, to the similarity of the systems, and so on? Is it true that for each task there is a gain which roughly implies significance? We explore these issues across a range of NLP tasks using both large collections of past systems’ outputs and variants of single systems. Next, once significance levels are computed, how well does the standard i.i.d. notion of significance hold up in practical settings where future distributions are neither independent nor identically distributed, such as across domains? We explore this question using a range of test set variations for constituency parsing.</p><p>6 0.52744025 <a title="16-lda-6" href="./emnlp-2012-Joint_Inference_for_Event_Timeline_Construction.html">72 emnlp-2012-Joint Inference for Event Timeline Construction</a></p>
<p>7 0.52428424 <a title="16-lda-7" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>8 0.52297813 <a title="16-lda-8" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>9 0.51979589 <a title="16-lda-9" href="./emnlp-2012-Discovering_Diverse_and_Salient_Threads_in_Document_Collections.html">33 emnlp-2012-Discovering Diverse and Salient Threads in Document Collections</a></p>
<p>10 0.50858831 <a title="16-lda-10" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>11 0.50833422 <a title="16-lda-11" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>12 0.50568682 <a title="16-lda-12" href="./emnlp-2012-Learning_to_Map_into_a_Universal_POS_Tagset.html">81 emnlp-2012-Learning to Map into a Universal POS Tagset</a></p>
<p>13 0.49739462 <a title="16-lda-13" href="./emnlp-2012-Building_a_Lightweight_Semantic_Model_for_Unsupervised_Information_Extraction_on_Short_Listings.html">26 emnlp-2012-Building a Lightweight Semantic Model for Unsupervised Information Extraction on Short Listings</a></p>
<p>14 0.4970797 <a title="16-lda-14" href="./emnlp-2012-Constructing_Task-Specific_Taxonomies_for_Document_Collection_Browsing.html">30 emnlp-2012-Constructing Task-Specific Taxonomies for Document Collection Browsing</a></p>
<p>15 0.49651274 <a title="16-lda-15" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>16 0.49312645 <a title="16-lda-16" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>17 0.49191067 <a title="16-lda-17" href="./emnlp-2012-A_Discriminative_Model_for_Query_Spelling_Correction_with_Latent_Structural_SVM.html">5 emnlp-2012-A Discriminative Model for Query Spelling Correction with Latent Structural SVM</a></p>
<p>18 0.4913272 <a title="16-lda-18" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>19 0.4911314 <a title="16-lda-19" href="./emnlp-2012-Large_Scale_Decipherment_for_Out-of-Domain_Machine_Translation.html">75 emnlp-2012-Large Scale Decipherment for Out-of-Domain Machine Translation</a></p>
<p>20 0.48931697 <a title="16-lda-20" href="./emnlp-2012-Exploiting_Chunk-level_Features_to_Improve_Phrase_Chunking.html">45 emnlp-2012-Exploiting Chunk-level Features to Improve Phrase Chunking</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
