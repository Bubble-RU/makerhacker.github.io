<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-27" href="#">emnlp2012-27</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</h1>
<br/><p>Source: <a title="emnlp-2012-27-pdf" href="http://aclweb.org/anthology//D/D12/D12-1139.pdf">pdf</a></p><p>Author: Song Feng ; Ritwik Banerjee ; Yejin Choi</p><p>Abstract: Much of the writing styles recognized in rhetorical and composition theories involve deep syntactic elements. However, most previous research for computational stylometric analysis has relied on shallow lexico-syntactic patterns. Some very recent work has shown that PCFG models can detect distributional difference in syntactic styles, but without offering much insights into exactly what constitute salient stylistic elements in sentence structure characterizing each authorship. In this paper, we present a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements. We present analytic insights with respect to the authorship attribution task in two different domains. ,</p><p>Reference: <a title="emnlp-2012-27-reference" href="../emnlp2012_reference/emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Some very recent work has shown that PCFG models can detect distributional difference in syntactic styles, but without offering much insights into exactly what constitute salient stylistic elements in sentence structure characterizing each authorship. [sent-3, score-0.487]
</p><p>2 In this paper, we present a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements. [sent-4, score-0.494]
</p><p>3 We present analytic insights with respect to the authorship attribution task in two different domains. [sent-5, score-0.814]
</p><p>4 ,  1 Introduction Much of the writing styles recognized in rhetorical and composition theories involve deep syntactic elements in style (e. [sent-6, score-0.579]
</p><p>5 However, previous research for automatic authorship attribution and computational stylometric analysis have relied mostly on shallow lexico-syntactic patterns (e. [sent-9, score-0.871]
</p><p>6 edu Some very recent works have shown that PCFG models can detect distributional difference in sentence structure in gender attribution (Sarawgi et al. [sent-16, score-0.282]
</p><p>7 However,  still very little has been understood exactly what constitutes salient stylistic elements in sentence structures that characterize each author. [sent-19, score-0.334]
</p><p>8 Although the work of Wong and Dras (2011) has extracted production rules with highest information gain, their analysis stops short of providing insight any deeper than what simple n-gramlevel analysis could also provide. [sent-20, score-0.242]
</p><p>9 1 One might even wonder whether PCFG models are hinging mostly on leaf production rules, and whether there are indeed deep syntactic differences at all. [sent-21, score-0.383]
</p><p>10 In contrast, a periodic sentence starts with subordinate phrases and clauses, suspending the most 1For instance, missing determiners in English text written by Chinese speakers, or simple n-gram anomaly such as frequent use of “according to” by Chinese speak-  ers (Wong and Dras, 2011) . [sent-24, score-0.278]
</p><p>11 2 Periodic sentences were favored in classical times, while loose sentences became more popular in the modern age. [sent-25, score-0.153]
</p><p>12 PCS BAR loose  periodic  Christopher Columbus finally reached the shores of San Salvador after months of uncertainty at sea, the threat of mutiny, and a shortage of food and water. [sent-32, score-0.368]
</p><p>13 Hence, shallow lexico-syntactic analysis will not be able to catch the pronounced stylistic difference that is clear to a human reader. [sent-36, score-0.21]
</p><p>14 One might wonder whether we could gain interesting insights simply by looking at the most discriminative production rules in PCFG trees. [sent-37, score-0.277]
</p><p>15 To address this question, Table 1 shows the top ten most discriminative production rules for authorship attribution for scientific articles,3 ranked by LIBLINEAR (Fan et al. [sent-38, score-1.09]
</p><p>16 4 Note that terminal production rules are excluded so as to focus directly on syntax. [sent-40, score-0.244]
</p><p>17 We can also observe that none of the top 10 most discriminative production rules for Hobbs includes SBAR tag, which represents subordinate clauses. [sent-46, score-0.263]
</p><p>18 Can we unveil something more in deep syntactic structure that can characterize the collective syntactic difference between any two authors? [sent-48, score-0.23]
</p><p>19 For instance, what can we say about distributional difference between loose and periodic sentences discussed earlier for each author? [sent-49, score-0.294]
</p><p>20 In general, production rules in CFGs do not directly map to a wide variety of stylistic elements in rhetorical and composition theories. [sent-51, score-0.602]
</p><p>21 This is only as expected however, partly because CFGs are not designed for stylometric analysis in the first place, and also because some syntactic elements can go beyond the scope of context free grammars. [sent-52, score-0.296]
</p><p>22 As an attempt to reduce this gap between  modern statistical parsers and cognitively recognizable stylistic elements, we explore two complementary approaches: 1. [sent-53, score-0.21]
</p><p>23 Translating some of the well known stylistic elements of rhetorical theories into PCFG analysis (Section 3) . [sent-54, score-0.358]
</p><p>24 2  Data  For the empirical analysis of authorship attribution, we use two different datasets described below. [sent-59, score-0.499]
</p><p>25 Since it is nearly impossible to determine the goldstandard authorship of a paper written by multiple authors, we select 10 authors who have published at least 8 single-authored papers. [sent-63, score-0.554]
</p><p>26 5 Novels We collect 5 novels from 5 English authors: Charles Dickens, Edward Bulwer-Lytton,  Jane Austen, Thomas Hardy and Walter Scott. [sent-65, score-0.198]
</p><p>27 We point out that authorship attribution is fundamentally different from text categorization in that it is often practically impossible to collect more than several documents for each author. [sent-68, score-0.743]
</p><p>28 Therefore, it is desirable that the attribution algorithms to detect the authors based on very small samples. [sent-69, score-0.299]
</p><p>29 6 Type-II Identification – Loose/Periodic: A sentence can also be classified as loose or periodic, and we present Algorithm 2 for this identification. [sent-83, score-0.149]
</p><p>30 848 Table 3: Sentence Types (%) in scientific data. [sent-110, score-0.141]
</p><p>31 identification, it labeled all loose sentences cor-  rectly, and achieved 90% accuracy on periodic sentences. [sent-111, score-0.294]
</p><p>32 Discussion Tables 3 & 4 show the sentence type distribution in scientific data and novels, respectively. [sent-112, score-0.179]
</p><p>33 Notice that all authors use loose sentences much more often than periodic sentences, a known trend in modern English. [sent-117, score-0.349]
</p><p>34 In Table 4, we see the opposite trend among 19th-century novels: with the exception of Jane Austen, all authors utilize periodic sentences comparatively more often. [sent-118, score-0.238]
</p><p>35 Can we determine authorship solely based on the distribution of sentence types? [sent-120, score-0.537]
</p><p>36 on  8Due to space limitation, we present analyses based 4 authors from the scientific data. [sent-125, score-0.196]
</p><p>37 037 Table 4: Sentence Types (%) in Novels 4  Syntactic Elements Based on Production Rules  In this section, we examine three different aspects of syntactic elements based on production rules. [sent-142, score-0.312]
</p><p>38 1 Syntactic Variations We conjecture that the variety of syntactic structure, which most previous research in computational stylometry has not paid much attention to, provides an interesting insight into authorship. [sent-144, score-0.155]
</p><p>39 One way to quantify the degree of syntactic variations is to count the unique production rules. [sent-145, score-0.226]
</p><p>40 Our default setting is to exclude all lexicalized rules in the productions to focus directly on the syntactic varia-  tions. [sent-148, score-0.221]
</p><p>41 In our experiments (Section 6) , however, we do augment the rules with (a) ancestor nodes to capture deeper syntactic structure and (b) lexical (leaf) nodes. [sent-149, score-0.178]
</p><p>42 For instance, we find that McDon employs a wider variety of syntactic structure than others, while Lin’s writing exhibits relatively the least variation. [sent-151, score-0.198]
</p><p>43 Teihnigs indicates that Hobbs tends to use a certain subset production rules much more frequently than Joshi. [sent-196, score-0.206]
</p><p>44 Similarly, among novels, Jane Austen’s writing has the highest amount of variation, while Walter Scott’s writing style is the least varied. [sent-198, score-0.275]
</p><p>45 It is interesting to note that the authors with highest coverage – Austen and Dickens – have much lower deviation in their syntactic structure when compared to Hardy and Scott. [sent-201, score-0.17]
</p><p>46 This indicates that while Austen and Dickens consistently employ a wider variety of sentence structures in their writing, Hardy and Scott follow a relatively more uniform style with sporadic forays into diverse syntactic constructs. [sent-202, score-0.163]
</p><p>47 1 give us a better and more general insight into the characteristics of each author, its ability to provide  insight on deep syntactic structure is still limited, as it covers production rules at all levels of 1526 the tree. [sent-205, score-0.426]
</p><p>48 Tables 6 and 7 present the most discriminative sentence outlines of each author in the scientific data and novels, respectively. [sent-209, score-0.279]
</p><p>49 5  Syntactic Elements Based on Tree Topology  In this section, we investigate quantitative techniques to capture stylistic elements in the tree 9The presence of “FRAG” is not surprising. [sent-218, score-0.38]
</p><p>50 10 Notice that sentence (1) is a loose sentence, and sentence (2) is periodic. [sent-246, score-0.187]
</p><p>51 In general, loose sentences  grow deep and unbalanced, while periodic sentences are relatively more balanced and wider. [sent-247, score-0.36]
</p><p>52 For a tree t rooted at NR with a height n, let T be the set of leaf nodes, and let F be the set oTf fbuerc thateio sne nodes, fa nnodd leest, ξ(Ni, Nj) d beeno tthee t sheet length of the shortest path from Ni to Nj . [sent-248, score-0.268]
</p><p>53 Inspired by the work of Shao (1990) , we analyze tree topology with the following four measurements: •  •  •  Leaf height (hT = {hiT, Ni ∈ T }), where LhiTe = ξ(Ni, NR) Ni ∈ Th . [sent-249, score-0.224]
</p><p>54 For instance, tehree leaf height of “free” ∈of T T . [sent-250, score-0.184]
</p><p>55 Furcation height (hF = {hiF, Ni ∈ F}), Fwhurercea ahtiFio is the maximum leaf height ∈w Fith}i)n, the subtree rooted at Ni. [sent-253, score-0.277]
</p><p>56 In Figure 1, for example, the furcation height of the VP in Tree (2) (marked in triangle) is 3. [sent-254, score-0.13]
</p><p>57 Tree ( 1) and Tree (2) differ in that Tree ( 1) is highly unbalanced and grows deep, while Tree  Figure 1: Parsed trees  Metrics # of tokens maxi {hiT} maxi {{hwLi}} maxi {{σwHi}} maxi {{σσSi}}  Tree (1) 15 11 6 4. [sent-270, score-0.252]
</p><p>58 These consist of simple production rules and other syntactic features based on tree-traversals. [sent-280, score-0.288]
</p><p>59 These sets of production rules and syntax fea1528 tures are used to build SVM classifiers using LIBLINEAR (Fan et al. [sent-282, score-0.206]
</p><p>60 We would like to point out that the latter configuration is of high practical importance in authorship attribution, since we may not always have sufficient training data in realistic situations, e. [sent-285, score-0.499]
</p><p>61 Lexical tokens provide strong clues by creating features that are specific to each author: research topics in the scientific data, and proper nouns such as character names in novels. [sent-288, score-0.141]
</p><p>62 Our experimental results (Tables 11 & 12) show that not only do deep syntactic features perform well on their own, but they also significantly improve over lexical features. [sent-291, score-0.148]
</p><p>63 pr synv  synh  synv+h syn0  syn↓  synl  style11  pˆr ∗  Features Rules excluding terminal productions. [sent-293, score-0.505]
</p><p>64 , VBG → NP (for node VP) synv ∪V synh No tr∪ee s tynraversal. [sent-304, score-0.275]
</p><p>65 , {VP → VBG, VP → NP} syn↓ {∪V { edge VtoB parent node} The s∪et { oefd 1g 1e teoxtr paa stylistic ef}eatures. [sent-309, score-0.21]
</p><p>66 6 values from the distribution of sentence types (Section 3) , and 5 topological metrics (Section 5) characterizing the height, width and imbalance of a tree. [sent-310, score-0.157]
</p><p>67 Variations Each production rule is augmented with the grandparent node. [sent-311, score-0.184]
</p><p>68 Illustration: pˆ r∗ denotes the set of production rules pr (including terminal productions) that are augmented with their grandparent nodes. [sent-314, score-0.348]
</p><p>69 To quantify the amount of authorship information carried in the set style11 , we experiment with a SVM classifier using only 11 features (one for each metric) , and achieve accuracy of 42. [sent-315, score-0.499]
</p><p>70 ) , and that the classification is based on just 11 features, this experiment demonstrates how effectively the tree topology statistics capture idiolects. [sent-319, score-0.131]
</p><p>71 This is expected since tokens such as function words play an important role in determining authorship (e. [sent-321, score-0.499]
</p><p>72 A more important observation, however, is that even after removing the leaf production rules, accuracy as high as 93% (scientific) and 92. [sent-325, score-0.235]
</p><p>73 9 pˆr∗  Table 11: Authorship attribution with 20% training data. [sent-385, score-0.244]
</p><p>74 Also no-  tice that using only production rules, we achieve higher accuracy in novels (90. [sent-388, score-0.342]
</p><p>75 1%) , but the addition of style11 features yields better results with scientific data (93. [sent-389, score-0.141]
</p><p>76 In the scientific dataset, increasing the amount of training data decreases the average performance difference between lexicalized and unlexicalized features: 13. [sent-392, score-0.176]
</p><p>77 We further observe that with scientific data, increasing the amount of training data improves the average performance across all unlexicalized feature-sets from 50. [sent-398, score-0.141]
</p><p>78 While authors such as Dickens or Hardy have their unique writing styles that a classifier can learn based on few documents, capturing idiolects in the more rigid domain of scientific writing is far from obvious with little training data. [sent-405, score-0.514]
</p><p>79 1 pˆr∗  Table 12: Authorship attribution with 80% training data. [sent-466, score-0.244]
</p><p>80 Turning to lexicalized features, we note that with more training data, lexical cues perform better in scientific domain than in novels. [sent-467, score-0.176]
</p><p>81 Finally, we point out that adding the style features derived from sentence types and tree topologies almost always improves the performance. [sent-474, score-0.165]
</p><p>82 In scientific data, synv∗+h with style11 features shows the best performance (96%) , while synl∗ yields the best results for novels (95. [sent-475, score-0.339]
</p><p>83 7  Related Work  There are several hurdles in authorship attribution. [sent-480, score-0.499]
</p><p>84 , 2010) , or classical literature like novels and proses (e. [sent-484, score-0.24]
</p><p>85 (2003) employed frequency measures on ngrams for authorship attribution. [sent-491, score-0.499]
</p><p>86 The use of syntactic features from parse trees in authorship attribution was initiated by Baayen et al. [sent-495, score-0.825]
</p><p>87 Syntactic features from PCFG parse trees have also been used for gender attribution (Sarawgi et al. [sent-498, score-0.244]
</p><p>88 The primary focus of most previous research, however, was to attain better classification accuracy, rather than providing linguistic interpretations of individual authorship and their stylistic elements. [sent-501, score-0.709]
</p><p>89 Our work is the first to attempt authorship attribution of scientific papers, a contemporary domain where language is very formal, and the stylistic variations have limited scope. [sent-502, score-1.094]
</p><p>90 In addition to exploring this new domain, we also present a comparative study expounding the role of syntactic features for authorship attri-  bution in classical literature. [sent-503, score-0.623]
</p><p>91 Furthermore, our work is also the first to utilize tree topological features (Chan et al. [sent-504, score-0.141]
</p><p>92 8  Conclusion  In this paper, we have presented a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements, thus distinguishing our work from other recent work on syntactic stylometric analysis. [sent-506, score-0.704]
</p><p>93 Our analytical study provides novel statistically supported insights into stylistic elements that have not been computationally analyzed in previous literature. [sent-507, score-0.367]
</p><p>94 Measuring the usefulness of function words for authorship attribution. [sent-515, score-0.499]
</p><p>95 Outside the cave of shadows: Using syntactic annotation to enhance authorship attribution. [sent-532, score-0.581]
</p><p>96 Delta: A measure of stylistic difference and a guide to likely authorship. [sent-572, score-0.21]
</p><p>97 Bigrams of syntactic labels for authorship discrimination of short texts. [sent-608, score-0.581]
</p><p>98 Authorship attribution and verification with many authors and limited data. [sent-661, score-0.299]
</p><p>99 Language independent authorship attribution using character level language models. [sent-681, score-0.743]
</p><p>100 A framework for authorship identification of online messages: Writing-style features and classification techniques. [sent-764, score-0.551]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('authorship', 0.499), ('attribution', 0.244), ('stylistic', 0.21), ('novels', 0.198), ('periodic', 0.183), ('synv', 0.165), ('production', 0.144), ('scientific', 0.141), ('nr', 0.138), ('stylometric', 0.128), ('synl', 0.128), ('writing', 0.116), ('loose', 0.111), ('austen', 0.11), ('stamatatos', 0.11), ('synh', 0.11), ('vp', 0.108), ('pcfg', 0.106), ('height', 0.093), ('dickens', 0.092), ('leaf', 0.091), ('ni', 0.089), ('styles', 0.086), ('elements', 0.086), ('syn', 0.086), ('tree', 0.084), ('syntactic', 0.082), ('literary', 0.082), ('luyckx', 0.073), ('mcdon', 0.073), ('insights', 0.071), ('deep', 0.066), ('pr', 0.064), ('argamon', 0.063), ('baayen', 0.063), ('hardy', 0.063), ('maxi', 0.063), ('rules', 0.062), ('sbar', 0.062), ('rhetorical', 0.062), ('imbalance', 0.062), ('subordinate', 0.057), ('topological', 0.057), ('authors', 0.055), ('garcia', 0.055), ('keselj', 0.055), ('ltkop', 0.055), ('ltop', 0.055), ('mosteller', 0.055), ('sarawgi', 0.055), ('outlines', 0.053), ('hobbs', 0.053), ('raghavan', 0.053), ('shlomo', 0.053), ('identification', 0.052), ('stroudsburg', 0.05), ('dras', 0.049), ('wong', 0.049), ('npp', 0.047), ('daelemans', 0.047), ('author', 0.047), ('jane', 0.047), ('topology', 0.047), ('np', 0.046), ('style', 0.043), ('productions', 0.042), ('classical', 0.042), ('horizontal', 0.041), ('grandparent', 0.04), ('sentence', 0.038), ('terminal', 0.038), ('composition', 0.038), ('walter', 0.037), ('ss', 0.037), ('brook', 0.037), ('diederich', 0.037), ('furcation', 0.037), ('halteren', 0.037), ('hobbsjoshilinmcdon', 0.037), ('houvardas', 0.037), ('mutiny', 0.037), ('pighin', 0.037), ('sebtaurrn', 0.037), ('shores', 0.037), ('stony', 0.037), ('strunk', 0.037), ('stylometry', 0.037), ('threat', 0.037), ('vlado', 0.037), ('wallace', 0.037), ('insight', 0.036), ('lexicalized', 0.035), ('wl', 0.035), ('yejin', 0.035), ('rse', 0.035), ('nodes', 0.034), ('nl', 0.033), ('peng', 0.033), ('vbg', 0.033), ('deviation', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999875 <a title="27-tfidf-1" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>Author: Song Feng ; Ritwik Banerjee ; Yejin Choi</p><p>Abstract: Much of the writing styles recognized in rhetorical and composition theories involve deep syntactic elements. However, most previous research for computational stylometric analysis has relied on shallow lexico-syntactic patterns. Some very recent work has shown that PCFG models can detect distributional difference in syntactic styles, but without offering much insights into exactly what constitute salient stylistic elements in sentence structure characterizing each authorship. In this paper, we present a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements. We present analytic insights with respect to the authorship attribution task in two different domains. ,</p><p>2 0.09619464 <a title="27-tfidf-2" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>Author: Annie Louis ; Ani Nenkova</p><p>Abstract: We introduce a model of coherence which captures the intentional discourse structure in text. Our work is based on the hypothesis that syntax provides a proxy for the communicative goal of a sentence and therefore the sequence of sentences in a coherent discourse should exhibit detectable structural patterns. Results show that our method has high discriminating power for separating out coherent and incoherent news articles reaching accuracies of up to 90%. We also show that our syntactic patterns are correlated with manual annotations of intentional structure for academic conference articles and can successfully predict the coherence of abstract, introduction and related work sections of these articles. 59.3 (100.0) Intro 50.3 (100.0) 1166 Rel wk 55.4 (100.0) >= 0.663.8 (67.2)50.8 (71.1)58.6 (75.9) >= 0.7 67.2 (32.0) 54.4 (38.6) 63.3 (52.8) >= 0.8 74.0 (10.0) 51.6 (22.0) 63.0 (25.7) >= 0.9 91.7 (2.0) 30.6 (5.0) 68.1 (7.2) Table 9: Accuracy (% examples) above each confidence level for the conference versus workshop task. These results are shown in Table 9. The proportion of examples under each setting is also indicated. When only examples above 0.6 confidence are examined, the classifier has a higher accuracy of63.8% for abstracts and covers close to 70% of the examples. Similarly, when a cutoff of 0.7 is applied to the confidence for predicting related work sections, we achieve 63.3% accuracy for 53% of examples. So we can consider that 30 to 47% of the examples in the two sections respectively are harder to tell apart. Interestingly however even high confidence predictions on introductions remain incorrect. These results show that our model can successfully distinguish the structure of articles beyond just clearly incoherent permutation examples. 7 Conclusion Our work is the first to develop an unsupervised model for intentional structure and to show that it has good accuracy for coherence prediction and also complements entity and lexical structure of discourse. This result raises interesting questions about how patterns captured by these different coherence metrics vary and how they can be combined usefully for predicting coherence. We plan to explore these ideas in future work. We also want to analyze genre differences to understand if the strength of these coherence dimensions varies with genre. Acknowledgements This work is partially supported by a Google research grant and NSF CAREER 0953445 award. References Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computa- tional Linguistics, 34(1): 1–34. Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of NAACL-HLT, pages 113–120. Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL, pages 9–16. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL, pages 173–180. Jackie C.K. Cheung and Gerald Penn. 2010. Utilizing extra-sentential context for parsing. In Proceedings of EMNLP, pages 23–33. Christelle Cocco, Rapha ¨el Pittier, Fran ¸cois Bavaud, and Aris Xanthos. 2011. Segmentation and clustering of textual sequences: a typological approach. In Proceedings of RANLP, pages 427–433. Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 3 1:25–70. Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. Parscit: An open-source crf reference string parsing package. In Proceedings of LREC, pages 661–667. Micha Elsner and Eugene Charniak. 2008. Coreferenceinspired coherence modeling. In Proceedings of ACLHLT, Short Papers, pages 41–44. Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of ACL-HLT, pages 125–129. Micha Elsner, Joseph Austerweil, and Eugene Charniak. 2007. A unified local and global model for discourse coherence. In Proceedings of NAACL-HLT, pages 436–443. Pascale Fung and Grace Ngai. 2006. One story, one flow: Hidden markov story models for multilingual multidocument summarization. ACM Transactions on Speech and Language Processing, 3(2): 1–16. Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 3(12): 175–204. Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011. A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of EMNLP, pages 273–283. Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-HLT, pages 586–594, June. 1167 Nikiforos Karamanis, Chris Mellish, Massimo Poesio, and Jon Oberlander. 2009. Evaluating centering for information ordering using corpora. Computational Linguistics, 35(1):29–46. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL, pages 423–430. Mirella Lapata and Regina Barzilay. 2005. Automatic evaluation of text coherence: Models and representations. In Proceedings of IJCAI. Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL, pages 545–552. Maria Liakata and Larisa Soldatova. 2008. Guidelines for the annotation of general scientific concepts. JISC Project Report. Maria Liakata, Simone Teufel, Advaith Siddharthan, and Colin Batchelor. 2010. Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC. Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proceedings of EMNLP, pages 343–351. Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011. Automatically evaluating text coherence using discourse relations. In Proceedings of ACL-HLT, pages 997– 1006. Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330. Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP, pages 186–195. Dragomir R. Radev, Mark Thomas Joseph, Bryan Gibson, and Pradeep Muthukrishnan. 2009. A Bibliometric and Network Analysis ofthe field of Computational Linguistics. Journal of the American Society for Information Science and Technology. David Reitter, Johanna D. Moore, and Frank Keller. 2006. Priming of Syntactic Rules in Task-Oriented Dialogue and Spontaneous Conversation. In Proceedings of the 28th Annual Conference of the Cognitive Science Society, pages 685–690. Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Proceedings of the fifth conference on Applied natural language processing, pages 16–19. Radu Soricut and Daniel Marcu. 2006. Discourse generation using utility-trained coherence models. In Proceedings of COLING-ACL, pages 803–810. John Swales. 1990. Genre analysis: English in academic and research settings, volume 11. Cambridge University Press. Simone Teufel and Marc Moens. 2000. What’s yours and what’s mine: determining intellectual attribution in scientific text. In Proceedings of EMNLP, pages 9– 17. Simone Teufel, Jean Carletta, and Marc Moens. 1999. An annotation scheme for discourse-level argumentation in research articles. In Proceedings of EACL, pages 110–1 17. Ying Zhao, George Karypis, and Usama Fayyad. 2005. Hierarchical clustering algorithms for document datasets. Data Mining and Knowledge Discovery, 10: 141–168. 1168</p><p>3 0.092510298 <a title="27-tfidf-3" href="./emnlp-2012-Parser_Showdown_at_the_Wall_Street_Corral%3A_An_Empirical_Investigation_of_Error_Types_in_Parser_Output.html">105 emnlp-2012-Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</a></p>
<p>Author: Jonathan K. Kummerfeld ; David Hall ; James R. Curran ; Dan Klein</p><p>Abstract: Constituency parser performance is primarily interpreted through a single metric, F-score on WSJ section 23, that conveys no linguistic information regarding the remaining errors. We classify errors within a set of linguistically meaningful types using tree transformations that repair groups of errors together. We use this analysis to answer a range of questions about parser behaviour, including what linguistic constructions are difficult for stateof-the-art parsers, what types of errors are being resolved by rerankers, and what types are introduced when parsing out-of-domain text.</p><p>4 0.078171536 <a title="27-tfidf-4" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>Author: Kristian Woodsend ; Mirella Lapata</p><p>Abstract: Multi-document summarization involves many aspects of content selection and surface realization. The summaries must be informative, succinct, grammatical, and obey stylistic writing conventions. We present a method where such individual aspects are learned separately from data (without any hand-engineering) but optimized jointly using an integer linear programme. The ILP framework allows us to combine the decisions of the expert learners and to select and rewrite source content through a mixture of objective setting, soft and hard constraints. Experimental results on the TAC-08 data set show that our model achieves state-of-the-art performance using ROUGE and significantly improves the informativeness of the summaries.</p><p>5 0.077822395 <a title="27-tfidf-5" href="./emnlp-2012-Exploring_Adaptor_Grammars_for_Native_Language_Identification.html">48 emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras ; Mark Johnson</p><p>Abstract: The task of inferring the native language of an author based on texts written in a second language has generally been tackled as a classification problem, typically using as features a mix of n-grams over characters and part of speech tags (for small and fixed n) and unigram function words. To capture arbitrarily long n-grams that syntax-based approaches have suggested are useful, adaptor grammars have some promise. In this work we investigate their extension to identifying n-gram collocations of arbitrary length over a mix of PoS tags and words, using both maxent and induced syntactic language model approaches to classification. After presenting a new, simple baseline, we show that learned collocations used as features in a maxent model perform better still, but that the story is more mixed for the syntactic language model.</p><p>6 0.067963004 <a title="27-tfidf-6" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>7 0.063525006 <a title="27-tfidf-7" href="./emnlp-2012-A_Sequence_Labelling_Approach_to_Quote_Attribution.html">9 emnlp-2012-A Sequence Labelling Approach to Quote Attribution</a></p>
<p>8 0.057468463 <a title="27-tfidf-8" href="./emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">70 emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>9 0.055748723 <a title="27-tfidf-9" href="./emnlp-2012-Dynamic_Programming_for_Higher_Order_Parsing_of_Gap-Minding_Trees.html">37 emnlp-2012-Dynamic Programming for Higher Order Parsing of Gap-Minding Trees</a></p>
<p>10 0.053884383 <a title="27-tfidf-10" href="./emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision.html">133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</a></p>
<p>11 0.052564584 <a title="27-tfidf-11" href="./emnlp-2012-Unified_Dependency_Parsing_of_Chinese_Morphological_and_Syntactic_Structures.html">131 emnlp-2012-Unified Dependency Parsing of Chinese Morphological and Syntactic Structures</a></p>
<p>12 0.051525831 <a title="27-tfidf-12" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>13 0.049100891 <a title="27-tfidf-13" href="./emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">4 emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>14 0.046878364 <a title="27-tfidf-14" href="./emnlp-2012-Training_Factored_PCFGs_with_Expectation_Propagation.html">126 emnlp-2012-Training Factored PCFGs with Expectation Propagation</a></p>
<p>15 0.045507662 <a title="27-tfidf-15" href="./emnlp-2012-Assessment_of_ESL_Learners%27_Syntactic_Competence_Based_on_Similarity_Measures.html">21 emnlp-2012-Assessment of ESL Learners' Syntactic Competence Based on Similarity Measures</a></p>
<p>16 0.04449863 <a title="27-tfidf-16" href="./emnlp-2012-SSHLDA%3A_A_Semi-Supervised_Hierarchical_Topic_Model.html">115 emnlp-2012-SSHLDA: A Semi-Supervised Hierarchical Topic Model</a></p>
<p>17 0.043257795 <a title="27-tfidf-17" href="./emnlp-2012-Part-of-Speech_Tagging_for_Chinese-English_Mixed_Texts_with_Dynamic_Features.html">106 emnlp-2012-Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features</a></p>
<p>18 0.042433787 <a title="27-tfidf-18" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>19 0.041697673 <a title="27-tfidf-19" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>20 0.04143079 <a title="27-tfidf-20" href="./emnlp-2012-An_%22AI_readability%22_Formula_for_French_as_a_Foreign_Language.html">17 emnlp-2012-An "AI readability" Formula for French as a Foreign Language</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.169), (1, -0.037), (2, 0.053), (3, 0.012), (4, 0.015), (5, 0.043), (6, -0.017), (7, -0.009), (8, -0.047), (9, 0.059), (10, -0.051), (11, 0.018), (12, -0.158), (13, 0.14), (14, 0.029), (15, 0.005), (16, 0.092), (17, -0.061), (18, -0.042), (19, -0.017), (20, -0.062), (21, 0.097), (22, 0.162), (23, -0.051), (24, -0.022), (25, 0.092), (26, 0.058), (27, 0.096), (28, 0.044), (29, -0.129), (30, -0.214), (31, 0.087), (32, 0.031), (33, 0.06), (34, -0.289), (35, -0.092), (36, -0.003), (37, -0.127), (38, -0.18), (39, -0.055), (40, 0.087), (41, -0.002), (42, -0.03), (43, 0.034), (44, -0.217), (45, -0.034), (46, -0.083), (47, -0.116), (48, 0.012), (49, 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93663818 <a title="27-lsi-1" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>Author: Song Feng ; Ritwik Banerjee ; Yejin Choi</p><p>Abstract: Much of the writing styles recognized in rhetorical and composition theories involve deep syntactic elements. However, most previous research for computational stylometric analysis has relied on shallow lexico-syntactic patterns. Some very recent work has shown that PCFG models can detect distributional difference in syntactic styles, but without offering much insights into exactly what constitute salient stylistic elements in sentence structure characterizing each authorship. In this paper, we present a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements. We present analytic insights with respect to the authorship attribution task in two different domains. ,</p><p>2 0.60103089 <a title="27-lsi-2" href="./emnlp-2012-A_Sequence_Labelling_Approach_to_Quote_Attribution.html">9 emnlp-2012-A Sequence Labelling Approach to Quote Attribution</a></p>
<p>Author: Timothy O'Keefe ; Silvia Pareti ; James R. Curran ; Irena Koprinska ; Matthew Honnibal</p><p>Abstract: Quote extraction and attribution is the task of automatically extracting quotes from text and attributing each quote to its correct speaker. The present state-of-the-art system uses gold standard information from previous decisions in its features, which, when removed, results in a large drop in performance. We treat the problem as a sequence labelling task, which allows us to incorporate sequence features without using gold standard information. We present results on two new corpora and an augmented version of a third, achieving a new state-of-the-art for systems using only realistic features.</p><p>3 0.51105022 <a title="27-lsi-3" href="./emnlp-2012-Exploring_Adaptor_Grammars_for_Native_Language_Identification.html">48 emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras ; Mark Johnson</p><p>Abstract: The task of inferring the native language of an author based on texts written in a second language has generally been tackled as a classification problem, typically using as features a mix of n-grams over characters and part of speech tags (for small and fixed n) and unigram function words. To capture arbitrarily long n-grams that syntax-based approaches have suggested are useful, adaptor grammars have some promise. In this work we investigate their extension to identifying n-gram collocations of arbitrary length over a mix of PoS tags and words, using both maxent and induced syntactic language model approaches to classification. After presenting a new, simple baseline, we show that learned collocations used as features in a maxent model perform better still, but that the story is more mixed for the syntactic language model.</p><p>4 0.40397882 <a title="27-lsi-4" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>Author: Annie Louis ; Ani Nenkova</p><p>Abstract: We introduce a model of coherence which captures the intentional discourse structure in text. Our work is based on the hypothesis that syntax provides a proxy for the communicative goal of a sentence and therefore the sequence of sentences in a coherent discourse should exhibit detectable structural patterns. Results show that our method has high discriminating power for separating out coherent and incoherent news articles reaching accuracies of up to 90%. We also show that our syntactic patterns are correlated with manual annotations of intentional structure for academic conference articles and can successfully predict the coherence of abstract, introduction and related work sections of these articles. 59.3 (100.0) Intro 50.3 (100.0) 1166 Rel wk 55.4 (100.0) >= 0.663.8 (67.2)50.8 (71.1)58.6 (75.9) >= 0.7 67.2 (32.0) 54.4 (38.6) 63.3 (52.8) >= 0.8 74.0 (10.0) 51.6 (22.0) 63.0 (25.7) >= 0.9 91.7 (2.0) 30.6 (5.0) 68.1 (7.2) Table 9: Accuracy (% examples) above each confidence level for the conference versus workshop task. These results are shown in Table 9. The proportion of examples under each setting is also indicated. When only examples above 0.6 confidence are examined, the classifier has a higher accuracy of63.8% for abstracts and covers close to 70% of the examples. Similarly, when a cutoff of 0.7 is applied to the confidence for predicting related work sections, we achieve 63.3% accuracy for 53% of examples. So we can consider that 30 to 47% of the examples in the two sections respectively are harder to tell apart. Interestingly however even high confidence predictions on introductions remain incorrect. These results show that our model can successfully distinguish the structure of articles beyond just clearly incoherent permutation examples. 7 Conclusion Our work is the first to develop an unsupervised model for intentional structure and to show that it has good accuracy for coherence prediction and also complements entity and lexical structure of discourse. This result raises interesting questions about how patterns captured by these different coherence metrics vary and how they can be combined usefully for predicting coherence. We plan to explore these ideas in future work. We also want to analyze genre differences to understand if the strength of these coherence dimensions varies with genre. Acknowledgements This work is partially supported by a Google research grant and NSF CAREER 0953445 award. References Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computa- tional Linguistics, 34(1): 1–34. Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of NAACL-HLT, pages 113–120. Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL, pages 9–16. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL, pages 173–180. Jackie C.K. Cheung and Gerald Penn. 2010. Utilizing extra-sentential context for parsing. In Proceedings of EMNLP, pages 23–33. Christelle Cocco, Rapha ¨el Pittier, Fran ¸cois Bavaud, and Aris Xanthos. 2011. Segmentation and clustering of textual sequences: a typological approach. In Proceedings of RANLP, pages 427–433. Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 3 1:25–70. Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. Parscit: An open-source crf reference string parsing package. In Proceedings of LREC, pages 661–667. Micha Elsner and Eugene Charniak. 2008. Coreferenceinspired coherence modeling. In Proceedings of ACLHLT, Short Papers, pages 41–44. Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of ACL-HLT, pages 125–129. Micha Elsner, Joseph Austerweil, and Eugene Charniak. 2007. A unified local and global model for discourse coherence. In Proceedings of NAACL-HLT, pages 436–443. Pascale Fung and Grace Ngai. 2006. One story, one flow: Hidden markov story models for multilingual multidocument summarization. ACM Transactions on Speech and Language Processing, 3(2): 1–16. Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 3(12): 175–204. Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011. A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of EMNLP, pages 273–283. Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-HLT, pages 586–594, June. 1167 Nikiforos Karamanis, Chris Mellish, Massimo Poesio, and Jon Oberlander. 2009. Evaluating centering for information ordering using corpora. Computational Linguistics, 35(1):29–46. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL, pages 423–430. Mirella Lapata and Regina Barzilay. 2005. Automatic evaluation of text coherence: Models and representations. In Proceedings of IJCAI. Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL, pages 545–552. Maria Liakata and Larisa Soldatova. 2008. Guidelines for the annotation of general scientific concepts. JISC Project Report. Maria Liakata, Simone Teufel, Advaith Siddharthan, and Colin Batchelor. 2010. Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC. Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proceedings of EMNLP, pages 343–351. Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011. Automatically evaluating text coherence using discourse relations. In Proceedings of ACL-HLT, pages 997– 1006. Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330. Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP, pages 186–195. Dragomir R. Radev, Mark Thomas Joseph, Bryan Gibson, and Pradeep Muthukrishnan. 2009. A Bibliometric and Network Analysis ofthe field of Computational Linguistics. Journal of the American Society for Information Science and Technology. David Reitter, Johanna D. Moore, and Frank Keller. 2006. Priming of Syntactic Rules in Task-Oriented Dialogue and Spontaneous Conversation. In Proceedings of the 28th Annual Conference of the Cognitive Science Society, pages 685–690. Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Proceedings of the fifth conference on Applied natural language processing, pages 16–19. Radu Soricut and Daniel Marcu. 2006. Discourse generation using utility-trained coherence models. In Proceedings of COLING-ACL, pages 803–810. John Swales. 1990. Genre analysis: English in academic and research settings, volume 11. Cambridge University Press. Simone Teufel and Marc Moens. 2000. What’s yours and what’s mine: determining intellectual attribution in scientific text. In Proceedings of EMNLP, pages 9– 17. Simone Teufel, Jean Carletta, and Marc Moens. 1999. An annotation scheme for discourse-level argumentation in research articles. In Proceedings of EACL, pages 110–1 17. Ying Zhao, George Karypis, and Usama Fayyad. 2005. Hierarchical clustering algorithms for document datasets. Data Mining and Knowledge Discovery, 10: 141–168. 1168</p><p>5 0.38808873 <a title="27-lsi-5" href="./emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision.html">133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</a></p>
<p>Author: Joohyun Kim ; Raymond Mooney</p><p>Abstract: “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B ¨orschinger et al. (201 1) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (201 1). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.</p><p>6 0.34025934 <a title="27-lsi-6" href="./emnlp-2012-Parser_Showdown_at_the_Wall_Street_Corral%3A_An_Empirical_Investigation_of_Error_Types_in_Parser_Output.html">105 emnlp-2012-Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</a></p>
<p>7 0.31623366 <a title="27-lsi-7" href="./emnlp-2012-Dynamic_Programming_for_Higher_Order_Parsing_of_Gap-Minding_Trees.html">37 emnlp-2012-Dynamic Programming for Higher Order Parsing of Gap-Minding Trees</a></p>
<p>8 0.30545077 <a title="27-lsi-8" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>9 0.26367116 <a title="27-lsi-9" href="./emnlp-2012-Supervised_Text-based_Geolocation_Using_Language_Models_on_an_Adaptive_Grid.html">121 emnlp-2012-Supervised Text-based Geolocation Using Language Models on an Adaptive Grid</a></p>
<p>10 0.25076982 <a title="27-lsi-10" href="./emnlp-2012-Generating_Non-Projective_Word_Order_in_Statistical_Linearization.html">59 emnlp-2012-Generating Non-Projective Word Order in Statistical Linearization</a></p>
<p>11 0.24860297 <a title="27-lsi-11" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>12 0.24755037 <a title="27-lsi-12" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>13 0.2443132 <a title="27-lsi-13" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>14 0.23991071 <a title="27-lsi-14" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>15 0.23414569 <a title="27-lsi-15" href="./emnlp-2012-Assessment_of_ESL_Learners%27_Syntactic_Competence_Based_on_Similarity_Measures.html">21 emnlp-2012-Assessment of ESL Learners' Syntactic Competence Based on Similarity Measures</a></p>
<p>16 0.22572495 <a title="27-lsi-16" href="./emnlp-2012-An_%22AI_readability%22_Formula_for_French_as_a_Foreign_Language.html">17 emnlp-2012-An "AI readability" Formula for French as a Foreign Language</a></p>
<p>17 0.2184141 <a title="27-lsi-17" href="./emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<p>18 0.20548499 <a title="27-lsi-18" href="./emnlp-2012-Source_Language_Adaptation_for_Resource-Poor_Machine_Translation.html">118 emnlp-2012-Source Language Adaptation for Resource-Poor Machine Translation</a></p>
<p>19 0.203187 <a title="27-lsi-19" href="./emnlp-2012-Streaming_Analysis_of_Discourse_Participants.html">120 emnlp-2012-Streaming Analysis of Discourse Participants</a></p>
<p>20 0.19525027 <a title="27-lsi-20" href="./emnlp-2012-Training_Factored_PCFGs_with_Expectation_Propagation.html">126 emnlp-2012-Training Factored PCFGs with Expectation Propagation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.021), (11, 0.019), (16, 0.026), (34, 0.061), (45, 0.018), (60, 0.08), (63, 0.068), (64, 0.029), (65, 0.024), (70, 0.027), (73, 0.03), (74, 0.066), (76, 0.06), (80, 0.013), (86, 0.024), (88, 0.335), (95, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76965785 <a title="27-lda-1" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>Author: Song Feng ; Ritwik Banerjee ; Yejin Choi</p><p>Abstract: Much of the writing styles recognized in rhetorical and composition theories involve deep syntactic elements. However, most previous research for computational stylometric analysis has relied on shallow lexico-syntactic patterns. Some very recent work has shown that PCFG models can detect distributional difference in syntactic styles, but without offering much insights into exactly what constitute salient stylistic elements in sentence structure characterizing each authorship. In this paper, we present a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements. We present analytic insights with respect to the authorship attribution task in two different domains. ,</p><p>2 0.64955735 <a title="27-lda-2" href="./emnlp-2012-A_Unified_Approach_to_Transliteration-based_Text_Input_with_Online_Spelling_Correction.html">13 emnlp-2012-A Unified Approach to Transliteration-based Text Input with Online Spelling Correction</a></p>
<p>Author: Hisami Suzuki ; Jianfeng Gao</p><p>Abstract: This paper presents an integrated, end-to-end approach to online spelling correction for text input. Online spelling correction refers to the spelling correction as you type, as opposed to post-editing. The online scenario is particularly important for languages that routinely use transliteration-based text input methods, such as Chinese and Japanese, because the desired target characters cannot be input at all unless they are in the list of candidates provided by an input method, and spelling errors prevent them from appearing in the list. For example, a user might type suesheng by mistake to mean xuesheng 学生 'student' in Chinese; existing input methods fail to convert this misspelled input to the desired target Chinese characters. In this paper, we propose a unified approach to the problem of spelling correction and transliteration-based character conversion using an approach inspired by the phrasebased statistical machine translation framework. At the phrase (substring) level, k most probable pinyin (Romanized Chinese) corrections are generated using a monotone decoder; at the sentence level, input pinyin strings are directly transliterated into target Chinese characters by a decoder using a loglinear model that refer to the features of both levels. A new method of automatically deriving parallel training data from user keystroke logs is also presented. Experiments on Chinese pinyin conversion show that our integrated method reduces the character error rate by 20% (from 8.9% to 7. 12%) over the previous state-of-the art based on a noisy channel model. 609 1</p><p>3 0.41363901 <a title="27-lda-3" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>4 0.4117488 <a title="27-lda-4" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Daniel Jurafsky</p><p>Abstract: We present a new family of models for unsupervised parsing, Dependency and Boundary models, that use cues at constituent boundaries to inform head-outward dependency tree generation. We build on three intuitions that are explicit in phrase-structure grammars but only implicit in standard dependency formulations: (i) Distributions of words that occur at sentence boundaries such as English determiners resemble constituent edges. (ii) Punctuation at sentence boundaries further helps distinguish full sentences from fragments like headlines and titles, allowing us to model grammatical differences between complete and incomplete sentences. (iii) Sentence-internal punctuation boundaries help with longer-distance dependencies, since punctuation correlates with constituent edges. Our models induce state-of-the-art dependency grammars for many languages without — — special knowledge of optimal input sentence lengths or biased, manually-tuned initializers.</p><p>5 0.40635857 <a title="27-lda-5" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>Author: Lizhen Qu ; Rainer Gemulla ; Gerhard Weikum</p><p>Abstract: We propose the weakly supervised MultiExperts Model (MEM) for analyzing the semantic orientation of opinions expressed in natural language reviews. In contrast to most prior work, MEM predicts both opinion polarity and opinion strength at the level of individual sentences; such fine-grained analysis helps to understand better why users like or dislike the entity under review. A key challenge in this setting is that it is hard to obtain sentence-level training data for both polarity and strength. For this reason, MEM is weakly supervised: It starts with potentially noisy indicators obtained from coarse-grained training data (i.e., document-level ratings), a small set of diverse base predictors, and, if available, small amounts of fine-grained training data. We integrate these noisy indicators into a unified probabilistic framework using ideas from ensemble learning and graph-based semi-supervised learning. Our experiments indicate that MEM outperforms state-of-the-art methods by a significant margin.</p><p>6 0.40233192 <a title="27-lda-6" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>7 0.40222564 <a title="27-lda-7" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>8 0.39958152 <a title="27-lda-8" href="./emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">51 emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>9 0.39595118 <a title="27-lda-9" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>10 0.3948991 <a title="27-lda-10" href="./emnlp-2012-Mixed_Membership_Markov_Models_for_Unsupervised_Conversation_Modeling.html">89 emnlp-2012-Mixed Membership Markov Models for Unsupervised Conversation Modeling</a></p>
<p>11 0.39442813 <a title="27-lda-11" href="./emnlp-2012-Syntactic_Surprisal_Affects_Spoken_Word_Duration_in_Conversational_Contexts.html">122 emnlp-2012-Syntactic Surprisal Affects Spoken Word Duration in Conversational Contexts</a></p>
<p>12 0.39419678 <a title="27-lda-12" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>13 0.39401633 <a title="27-lda-13" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>14 0.39282542 <a title="27-lda-14" href="./emnlp-2012-Unambiguity_Regularization_for_Unsupervised_Learning_of_Probabilistic_Grammars.html">130 emnlp-2012-Unambiguity Regularization for Unsupervised Learning of Probabilistic Grammars</a></p>
<p>15 0.39241192 <a title="27-lda-15" href="./emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">129 emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>16 0.39231399 <a title="27-lda-16" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>17 0.39114523 <a title="27-lda-17" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>18 0.39071724 <a title="27-lda-18" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>19 0.39036098 <a title="27-lda-19" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>20 0.38875827 <a title="27-lda-20" href="./emnlp-2012-A_Phrase-Discovering_Topic_Model_Using_Hierarchical_Pitman-Yor_Processes.html">8 emnlp-2012-A Phrase-Discovering Topic Model Using Hierarchical Pitman-Yor Processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
