<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-10" href="#">emnlp2012-10</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</h1>
<br/><p>Source: <a title="emnlp-2012-10-pdf" href="http://aclweb.org/anthology//D/D12/D12-1053.pdf">pdf</a></p><p>Author: Mathias Verbeke ; Vincent Van Asch ; Roser Morante ; Paolo Frasconi ; Walter Daelemans ; Luc De Raedt</p><p>Abstract: Evidence-based medicine is an approach whereby clinical decisions are supported by the best available findings gained from scientific research. This requires efficient access to such evidence. To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the socalled PICO criteria. This paper presents an approach to automatically annotate sentences in medical abstracts with these labels. Since both structural and sequential information are important for this classification task, we use kLog, a new language for statistical relational learning with kernels. Our results show a clear improvement with respect to state-of-the-art systems.</p><p>Reference: <a title="emnlp-2012-10-reference" href="../emnlp2012_reference/emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 p- f @ ds i  Abstract Evidence-based medicine is an approach whereby clinical decisions are supported by the best available findings gained from scientific research. [sent-20, score-0.278]
</p><p>2 To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the socalled PICO criteria. [sent-22, score-0.593]
</p><p>3 This paper presents an approach to automatically annotate sentences in medical abstracts with these labels. [sent-23, score-0.524]
</p><p>4 Since both structural and sequential information are important for this classification task, we use kLog, a new language for statistical relational learning with kernels. [sent-24, score-0.153]
</p><p>5 1 Introduction Evidence-based medicine (EBM) or evidence-based practice (EBP) combines clinical expertise, the preferences and values of the patient and the best available evidence to make good patient care decisions. [sent-26, score-0.404]
</p><p>6 Clinical research findings are systematically reviewed, appraised and used to improve the patient care, for which efficient access to such evidence is required. [sent-27, score-0.082]
</p><p>7 In order to facilitate the search process, medical documents are labeled using a set of predefined medical categories, the PICO criteria. [sent-28, score-0.308]
</p><p>8 PICO is an acronym for the mnemonic concepts that are used to construct queries when searching for scientific evidence in the EBM process. [sent-29, score-0.133]
</p><p>9 The need to automatize the annotation process has initiated research into automatic approaches to annotate sentences in medical documents with the PICO labels. [sent-30, score-0.189]
</p><p>10 kLog is a new language for statistical relational learning with kernels, that is embedded in Prolog, and builds upon and links together concepts from database theory, logic programming and learning from interpretations. [sent-38, score-0.297]
</p><p>11 Learning from interpretations is a logical and relational learning setting (De Raedt et al. [sent-39, score-0.195]
</p><p>12 In a sense, each example can be viewed as a small relational database. [sent-41, score-0.153]
</p><p>13 kLog is able to transform relational into graph-based representations and apply kernel methods to extract an extended highdimensional feature space. [sent-42, score-0.285]
</p><p>14 , 2012), where we showed that a statistical relational learning approach using kLog is able to process the contextual aspects of language improving on state-of-the-art results for hedge cue detection. [sent-44, score-0.153]
</p><p>15 First, next to the relations between the words in the sentence, now also the relations between the sentences in the document become important. [sent-46, score-0.109]
</p><p>16 Second, since there are more than two categories, and each sentence can have multiple labels, the problem is now a multiclass multilabel classification task. [sent-52, score-0.074]
</p><p>17 The main contribution of this paper is that we show that kLog’s relational nature and its ability to declaratively specify and use background knowledge is beneficial for natural language learning problems. [sent-53, score-0.241]
</p><p>18 2  Related Work  EBM is an approach to clinical problem-solving based on “systematically finding, appraising, and using contemporaneous research findings as the basis for clinical decisions” (Rosenberg and Donald, 1995). [sent-60, score-0.348]
</p><p>19 The evidence-based process consists of four steps: (1) Formulating a question from a patient’s problem; (2) Searching the literature for relevant clinical articles; (3) Evaluating the evidence; And (4) implementing useful findings in clinical practice. [sent-61, score-0.348]
</p><p>20 Given the amounts of medical publications available in databases such as PubMed, automating step 2 is crucial to help doctors in their practice. [sent-62, score-0.154]
</p><p>21 The PICO concepts are: primary Problem (P) or population, main Intervention (I), main intervention Comparison (C), and 580 Outcome of intervention (O). [sent-67, score-0.416]
</p><p>22 The first attempt to classify PICO concepts is presented in Demner-Fushman and Lin (2007), who apply a rule-based approach to identify sentences where PICO concepts occur and a supervised approach to classify sentences that contain an Outcome. [sent-70, score-0.19]
</p><p>23 The system is trained on 275 abstracts manually annotated. [sent-72, score-0.335]
</p><p>24 This dataset contains 1,000 medical abstracts manually annotated with an extension of the PICO tagset, for which the definitions are listed in Table 1. [sent-78, score-0.523]
</p><p>25 The system is evaluated for 5-way and 6-way classification and results are provided apart from structured and unstructured abstracts. [sent-82, score-0.221]
</p><p>26 88% for 6-way classification, whereas for unstructured abstracts it is 71. [sent-85, score-0.489]
</p><p>27 Chung (2009) uses CRF to classify PICO concepts by combining them with general categories associated with rhetorical roles: Aim, Method, Results and Conclusion. [sent-88, score-0.163]
</p><p>28 Her system is tested on corpora of abstracts of randomized control trials. [sent-89, score-0.335]
</p><p>29 First structured abstracts with headings labeled with PICO BackgroundMaterial that informs and may place the current study in perspective, e. [sent-90, score-0.402]
</p><p>30 non-key or irrelevant sentences Table 1: Definitions of the semantic  tags  used  as  annotation categories (taken from Kim et al. [sent-95, score-0.134]
</p><p>31 A sentence level classification task is performed, assigning only one rhetorical role per sentence. [sent-98, score-0.08]
</p><p>32 Then another sentence level classification task is performed to automatically assign the labels Intervention, Participant and Outcome Measures to sentences in unstructured and structured abstracts without headings. [sent-102, score-0.625]
</p><p>33 Other work aimed at identifying rhetorical zones  in biomedical articles. [sent-106, score-0.109]
</p><p>34 In this case areas of text are classified in terms of the rhetorical categories Introduction, Methods, Results and Discussion (IMRAD) (Agarwal and Yu, 2009) or richer categories, such as problem-setting or insight (Mizuta et al. [sent-107, score-0.103]
</p><p>35 There exists a wide range of statistical relational learning systems (Getoor and Taskar, 2007; De Raedt et al. [sent-109, score-0.153]
</p><p>36 With respect to Markov Logic, two distinguishing features of kLog are that 1) it employs kernel based methods grounded in statistical learning theory, and 2) it employs a Prolog like language for defining and using background knowledge. [sent-112, score-0.185]
</p><p>37 An example interpretation can be found in Figure 3, where the hasCategory relation represents y in this case, since it is the target relation we want to predict. [sent-117, score-0.135]
</p><p>38 Hence this is a structured output task where the output is a sequence of sets of labels attached to the sentences in a given document. [sent-121, score-0.102]
</p><p>39 kLog is the new statistical relational language for learning with kernels that we use to tackle the PICO categories classification task. [sent-122, score-0.252]
</p><p>40 The novelty of kLog is that, based on the regular, linguistic features, it allows to define an extended high-dimensional feature space that is also able to take relational features into account in a principled manner. [sent-123, score-0.153]
</p><p>41 , 2012), where we showed that the relational representation of the domain as used by kLog is able to take the contextual aspects of language into account. [sent-126, score-0.153]
</p><p>42 Whereas there we only used the relations at the sentence level, the current task adds a new level of complexity, since the identification of PICO categories in abstracts also requires to take into account various relations between the sentences of an abstract. [sent-127, score-0.535]
</p><p>43 Preprocessing The sentences have been preprocessed with a named entity tagger and a dependency parser. [sent-132, score-0.104]
</p><p>44 Named entity tagging has been performed with the BiogaphTA named entity module, which  matches token sequences with entries in the UMLS database1 . [sent-133, score-0.072]
</p><p>45 UMLS integrates over 2 million names for some 900,000 concepts from more than 60 families of biomedical vocabularies (Bodenreider, 2004). [sent-134, score-0.123]
</p><p>46 This relational database representation will serve as the input for kLog. [sent-157, score-0.199]
</p><p>47 Each entity can have a number of properties attached to it, depicted by the ovals and has a unique identifier (underlined properties). [sent-161, score-0.073]
</p><p>48 As in database theory, each entity corresponds with a tuple, or fact, in the database. [sent-162, score-0.082]
</p><p>49 ,  ,  ,  ,  ,  ,  ,, ,  ,  , ,  ,  ,  ,  ,  ,  ,  ,  ,  , ,  ,  ,  ,  , ,  ,  Figure 3: Part of an example interpretation z, representing the example sentence in Figure 4. [sent-171, score-0.081]
</p><p>50 hasCategory(s4,‘background’) signifies that sentence s4 is a sentence describing background information. [sent-176, score-0.121]
</p><p>51 This relation is the target relation that we want to predict for this task and will not be taken into account as a feature, but is listed in the database and only used during the training of the model. [sent-177, score-0.206]
</p><p>52 Since the previously described entities and relationships are listed explicitly in the database, these are called extensional relations, in contrast to the intensional relations, as we will describe next. [sent-178, score-0.19]
</p><p>53 Declarative feature construction A strength of kLog is that it is also capable of constructing features declaratively, by using intensional relations. [sent-179, score-0.104]
</p><p>54 This enables one to encode additional background knowledge based on a small set of preprocessed fea583 tures, which renders experimentation very flexible and makes the results more interpretable. [sent-180, score-0.093]
</p><p>55 These intensional features are defined through definite clauses, and is done using an extension ofthe declarative programming language Prolog. [sent-182, score-0.162]
</p><p>56 We make a distinction between the features used for structured and unstructured abstracts. [sent-184, score-0.221]
</p><p>57 The relation lemmaRoot(S,L) is specified as:  ,  lemmaRoot ( S L ) ← mhaa RsWooortd( ( S, )I ) w (I L _) dh ( I root ) . [sent-186, score-0.157]
</p><p>58 The following relations are related to, and try to capture the document structure imposed by the section headers present in the structured abstracts. [sent-188, score-0.104]
</p><p>59 ,  ,  ,  ,  ; C = X)  ,  Also the sentences below a certain section header need to be marked as belonging to this section, which is done by the relation hasSectionHeader(S,X). [sent-192, score-0.114]
</p><p>60 For the unstructured abstracts, also the lemmaRoot relation is used, but next to the lemma, now also the part-of-speech tag of the root word is taken  , , , ,  ,  ,  ,  ,  into account. [sent-195, score-0.275]
</p><p>61 Since the unstructured abstracts lack section headers, other features were needed to distinguish between the different sections, for which the relation prevLemmaRoot proved to be very informative. [sent-196, score-0.533]
</p><p>62 It adds the lemma of the root word in the previous sentence as a property to the current sentence under consideration. [sent-197, score-0.165]
</p><p>63 This leads to the extensionalized database, in which both the extensional as well as the grounded intensional predicates are listed. [sent-201, score-0.156]
</p><p>64 Each interpretation is converted into a bipartite graph, for which there is a vertex for every ground atom of every E-relation, one for every ground atom of every R-relation, and an undirected edge {e, r} if an entity e participates in relationship r. [sent-207, score-0.083]
</p><p>65 This is done by means of a graph kernel κ, which calculates the similarity between two graphicalized interpretations. [sent-209, score-0.167]
</p><p>66 Any graph kernel that allows fast computations on large graphs and has a flexible bias to enable heterogeneous features can in theory be applied. [sent-210, score-0.132]
</p><p>67 NSPDK is a decomposition kernel (Haussler, 1999), in which pairs of subgraphs are compared 584  Figure 4: Graphicalization Gz of interpretation z. [sent-212, score-0.233]
</p><p>68 First of all, there is the center of the subgraph, the kernel point, which can be any entity or relation in the graph. [sent-215, score-0.212]
</p><p>69 The entities and relations  to be taken into account as kernel points are marked beforehand as a subset of the intensional and extensional domain relations. [sent-216, score-0.363]
</p><p>70 The radius r determines the size of the subgraphs and defines which entities or relations around the kernel point are taken into account. [sent-217, score-0.365]
</p><p>71 Each entity or relation that is within a number of r edges away from the kernel point is considered to be part of the subgraph. [sent-218, score-0.212]
</p><p>72 The third hyperparameter, the distance d, determines how far apart from each other the kernel points can be. [sent-219, score-0.167]
</p><p>73 Each subgraph around a kernel point that is within a distance d or less from the current kernel point will be considered. [sent-220, score-0.343]
</p><p>74 This is captured by the relation Rr,d(Av, Bu, G) between two rooted subgraphs Av, Bu and a graph G, which selects all pairs of neighborhood graphs of radius r whose roots are at distance d in a given graph G. [sent-221, score-0.237]
</p><p>75 The result of this graphicalization and feature generation process is an extended, high-dimensional feature space, which serves as input for the statistical learner in the next step. [sent-223, score-0.094]
</p><p>76 This implies that the sequence information ofthe sentences at the document level is not taken into account yet. [sent-225, score-0.073]
</p><p>77 Since the order of the sentences in the abstract is a valuable feature for this prediction problem, a learner that reflects this in the learning process is needed, although in principle any statistical learner can be used  on the feature space constructed by kLog. [sent-226, score-0.119]
</p><p>78 The qid is a special feature that is used in the structured SVM to restrict the generation of constraints. [sent-231, score-0.102]
</p><p>79 It contains 1,000 abstracts of which 500 were retrieved from MEDLINE by querying for diverse aspects in the traumatic brain injury and spinal cord injury domain. [sent-251, score-0.335]
</p><p>80 The definitions of the semantic tags used as annotations categories are a variation on the PICO tag set, with the addition of two additional categories (see Table 1in Section 2). [sent-259, score-0.114]
</p><p>81 This renders the task a multiclass multilabel classification problem. [sent-261, score-0.08]
</p><p>82 In our setup, the sentences of an abstract are taken as the processing unit and the collection of all sentences in an abstract is taken as one sequence. [sent-276, score-0.146]
</p><p>83 An am-  bitag for a sentence is retrieved by looking up the root lemma in this list. [sent-280, score-0.131]
</p><p>84 3  Parametrization  From the kernel definition it might be clear that the kLog hyperparameters, namely the distance d and radius r, can have a strong influence on the results. [sent-301, score-0.271]
</p><p>85 This is reflected by a distance and radius both set to 1, which enables to take all possible combinations of consecutive words into account and captures the relational information attached to the word in focus, i. [sent-306, score-0.292]
</p><p>86 4  Results  Experiments are run on structured and unstructured abstracts separately. [sent-318, score-0.556]
</p><p>87 In one setting, CV/6-way, we combined the labeling of the sentences with the identifi-  cation of irrelevant information, by adding the Other label as an extra class in the classification. [sent-325, score-0.077]
</p><p>88 kLog  Table 3: F-scores per class for structured (S) and unstructured (U) abstracts. [sent-362, score-0.221]
</p><p>89 (201 1), for both structured and unstructured abstracts on all classes except Population. [sent-364, score-0.556]
</p><p>90 Although to a lesser extent for the structured abstracts, the same pattern can be observed for the CV/5-way setting, where we tried to classify the sentences only, without considering the irrelevant ones. [sent-368, score-0.144]
</p><p>91 In case of the unstructured abstracts, kLog performs better on the majority of the individual classes and in overall performance for the 5-way setting, and comparable for the 4-way setting. [sent-373, score-0.154]
</p><p>92 50 Table 4: Micro-averaged F1-score obtained for structured (S) and unstructured (U) abstracts, both for 10-fold crossvalidation (CV) and on the external corpus (Ext). [sent-398, score-0.221]
</p><p>93 4 Table 6: F-scores per class for 5-way and 4-way classification over structured (S) and unstructured (U) abstracts on the external corpus. [sent-451, score-0.556]
</p><p>94 Due to kLog’s ability to take the structured input into account, we assume a correlation between the sentence structure of the label and the prediction quality. [sent-453, score-0.101]
</p><p>95 We intend to perform an extensive error analysis, in order to detect patterns which may allow us to incorporate additional declarative background knowledge into our model. [sent-454, score-0.111]
</p><p>96 5  Conclusions  We presented  a statistical relational learning ap-  proach for the automatic identification of PICO categories in medical abstracts. [sent-455, score-0.364]
</p><p>97 To this extent, we used kLog, a new framework for logical and relational learning with kernels. [sent-456, score-0.153]
</p><p>98 Due to its graphical approach, it is able to exploit the full relational representation, that is often inherent in language structure. [sent-457, score-0.153]
</p><p>99 Since contextual features are often essential and relations are prevalent, the aim of this paper was to show that statistical relational learning in general, and the graph kernel-based approach of kLog in particular, is specifically suited for problems in natural language learning. [sent-458, score-0.19]
</p><p>100 In future work, we intend to explore additional ways to incorporate background knowledge in a declarative way, since it renders the language learning problem more intuitive and gives a better understanding of feature contribution. [sent-459, score-0.151]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('klog', 0.518), ('abstracts', 0.335), ('pico', 0.311), ('intervention', 0.178), ('clinical', 0.174), ('medical', 0.154), ('unstructured', 0.154), ('relational', 0.153), ('kernel', 0.132), ('outcome', 0.104), ('intensional', 0.104), ('medicine', 0.104), ('radius', 0.104), ('raedt', 0.104), ('umls', 0.104), ('frasconi', 0.086), ('luc', 0.086), ('nextw', 0.086), ('dh', 0.074), ('daelemans', 0.074), ('kim', 0.07), ('costa', 0.069), ('ebm', 0.069), ('hasword', 0.069), ('lemmaroot', 0.069), ('moll', 0.069), ('prolog', 0.069), ('verbeke', 0.069), ('structured', 0.067), ('biomedical', 0.063), ('concepts', 0.06), ('population', 0.059), ('declarative', 0.058), ('lemma', 0.058), ('categories', 0.057), ('subgraphs', 0.054), ('background', 0.053), ('demnerfushman', 0.052), ('extensional', 0.052), ('genia', 0.052), ('graphicalization', 0.052), ('mbt', 0.052), ('interpretation', 0.047), ('rhetorical', 0.046), ('database', 0.046), ('av', 0.044), ('bmc', 0.044), ('paolo', 0.044), ('patient', 0.044), ('subgraph', 0.044), ('relation', 0.044), ('kernels', 0.042), ('interpretations', 0.042), ('irrelevant', 0.042), ('learner', 0.042), ('bioinformatics', 0.04), ('fabrizio', 0.04), ('ioannis', 0.04), ('multilabel', 0.04), ('renders', 0.04), ('tsochantaridis', 0.04), ('de', 0.04), ('root', 0.039), ('taken', 0.038), ('evidence', 0.038), ('logic', 0.038), ('identifier', 0.037), ('relations', 0.037), ('entity', 0.036), ('walter', 0.035), ('kurt', 0.035), ('distance', 0.035), ('sentences', 0.035), ('asch', 0.035), ('bioinfer', 0.035), ('cnv', 0.035), ('declaratively', 0.035), ('dina', 0.035), ('exci', 0.035), ('gdep', 0.035), ('goa', 0.035), ('graphicalized', 0.035), ('grave', 0.035), ('hascategory', 0.035), ('header', 0.035), ('ksdep', 0.035), ('mizuta', 0.035), ('mnemonic', 0.035), ('nmod', 0.035), ('nspdk', 0.035), ('onheader', 0.035), ('prevlemmaroot', 0.035), ('pyysalo', 0.035), ('qid', 0.035), ('surgi', 0.035), ('surgical', 0.035), ('tsoumakas', 0.035), ('listed', 0.034), ('sentence', 0.034), ('tagger', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="10-tfidf-1" href="./emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<p>Author: Mathias Verbeke ; Vincent Van Asch ; Roser Morante ; Paolo Frasconi ; Walter Daelemans ; Luc De Raedt</p><p>Abstract: Evidence-based medicine is an approach whereby clinical decisions are supported by the best available findings gained from scientific research. This requires efficient access to such evidence. To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the socalled PICO criteria. This paper presents an approach to automatically annotate sentences in medical abstracts with these labels. Since both structural and sequential information are important for this classification task, we use kLog, a new language for statistical relational learning with kernels. Our results show a clear improvement with respect to state-of-the-art systems.</p><p>2 0.096733376 <a title="10-tfidf-2" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>Author: Annie Louis ; Ani Nenkova</p><p>Abstract: We introduce a model of coherence which captures the intentional discourse structure in text. Our work is based on the hypothesis that syntax provides a proxy for the communicative goal of a sentence and therefore the sequence of sentences in a coherent discourse should exhibit detectable structural patterns. Results show that our method has high discriminating power for separating out coherent and incoherent news articles reaching accuracies of up to 90%. We also show that our syntactic patterns are correlated with manual annotations of intentional structure for academic conference articles and can successfully predict the coherence of abstract, introduction and related work sections of these articles. 59.3 (100.0) Intro 50.3 (100.0) 1166 Rel wk 55.4 (100.0) >= 0.663.8 (67.2)50.8 (71.1)58.6 (75.9) >= 0.7 67.2 (32.0) 54.4 (38.6) 63.3 (52.8) >= 0.8 74.0 (10.0) 51.6 (22.0) 63.0 (25.7) >= 0.9 91.7 (2.0) 30.6 (5.0) 68.1 (7.2) Table 9: Accuracy (% examples) above each confidence level for the conference versus workshop task. These results are shown in Table 9. The proportion of examples under each setting is also indicated. When only examples above 0.6 confidence are examined, the classifier has a higher accuracy of63.8% for abstracts and covers close to 70% of the examples. Similarly, when a cutoff of 0.7 is applied to the confidence for predicting related work sections, we achieve 63.3% accuracy for 53% of examples. So we can consider that 30 to 47% of the examples in the two sections respectively are harder to tell apart. Interestingly however even high confidence predictions on introductions remain incorrect. These results show that our model can successfully distinguish the structure of articles beyond just clearly incoherent permutation examples. 7 Conclusion Our work is the first to develop an unsupervised model for intentional structure and to show that it has good accuracy for coherence prediction and also complements entity and lexical structure of discourse. This result raises interesting questions about how patterns captured by these different coherence metrics vary and how they can be combined usefully for predicting coherence. We plan to explore these ideas in future work. We also want to analyze genre differences to understand if the strength of these coherence dimensions varies with genre. Acknowledgements This work is partially supported by a Google research grant and NSF CAREER 0953445 award. References Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computa- tional Linguistics, 34(1): 1–34. Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of NAACL-HLT, pages 113–120. Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL, pages 9–16. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL, pages 173–180. Jackie C.K. Cheung and Gerald Penn. 2010. Utilizing extra-sentential context for parsing. In Proceedings of EMNLP, pages 23–33. Christelle Cocco, Rapha ¨el Pittier, Fran ¸cois Bavaud, and Aris Xanthos. 2011. Segmentation and clustering of textual sequences: a typological approach. In Proceedings of RANLP, pages 427–433. Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 3 1:25–70. Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. Parscit: An open-source crf reference string parsing package. In Proceedings of LREC, pages 661–667. Micha Elsner and Eugene Charniak. 2008. Coreferenceinspired coherence modeling. In Proceedings of ACLHLT, Short Papers, pages 41–44. Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of ACL-HLT, pages 125–129. Micha Elsner, Joseph Austerweil, and Eugene Charniak. 2007. A unified local and global model for discourse coherence. In Proceedings of NAACL-HLT, pages 436–443. Pascale Fung and Grace Ngai. 2006. One story, one flow: Hidden markov story models for multilingual multidocument summarization. ACM Transactions on Speech and Language Processing, 3(2): 1–16. Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 3(12): 175–204. Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011. A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of EMNLP, pages 273–283. Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-HLT, pages 586–594, June. 1167 Nikiforos Karamanis, Chris Mellish, Massimo Poesio, and Jon Oberlander. 2009. Evaluating centering for information ordering using corpora. Computational Linguistics, 35(1):29–46. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL, pages 423–430. Mirella Lapata and Regina Barzilay. 2005. Automatic evaluation of text coherence: Models and representations. In Proceedings of IJCAI. Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL, pages 545–552. Maria Liakata and Larisa Soldatova. 2008. Guidelines for the annotation of general scientific concepts. JISC Project Report. Maria Liakata, Simone Teufel, Advaith Siddharthan, and Colin Batchelor. 2010. Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC. Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proceedings of EMNLP, pages 343–351. Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011. Automatically evaluating text coherence using discourse relations. In Proceedings of ACL-HLT, pages 997– 1006. Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330. Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP, pages 186–195. Dragomir R. Radev, Mark Thomas Joseph, Bryan Gibson, and Pradeep Muthukrishnan. 2009. A Bibliometric and Network Analysis ofthe field of Computational Linguistics. Journal of the American Society for Information Science and Technology. David Reitter, Johanna D. Moore, and Frank Keller. 2006. Priming of Syntactic Rules in Task-Oriented Dialogue and Spontaneous Conversation. In Proceedings of the 28th Annual Conference of the Cognitive Science Society, pages 685–690. Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Proceedings of the fifth conference on Applied natural language processing, pages 16–19. Radu Soricut and Daniel Marcu. 2006. Discourse generation using utility-trained coherence models. In Proceedings of COLING-ACL, pages 803–810. John Swales. 1990. Genre analysis: English in academic and research settings, volume 11. Cambridge University Press. Simone Teufel and Marc Moens. 2000. What’s yours and what’s mine: determining intellectual attribution in scientific text. In Proceedings of EMNLP, pages 9– 17. Simone Teufel, Jean Carletta, and Marc Moens. 1999. An annotation scheme for discourse-level argumentation in research articles. In Proceedings of EACL, pages 110–1 17. Ying Zhao, George Karypis, and Usama Fayyad. 2005. Hierarchical clustering algorithms for document datasets. Data Mining and Knowledge Discovery, 10: 141–168. 1168</p><p>3 0.06787201 <a title="10-tfidf-3" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>4 0.054034162 <a title="10-tfidf-4" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>Author: Mihai Surdeanu ; Julie Tibshirani ; Ramesh Nallapati ; Christopher D. Manning</p><p>Abstract: Distant supervision for relation extraction (RE) gathering training data by aligning a database of facts with text – is an efficient approach to scale RE to thousands of different relations. However, this introduces a challenging learning scenario where the relation expressed by a pair of entities found in a sentence is unknown. For example, a sentence containing Balzac and France may express BornIn or Died, an unknown relation, or no relation at all. Because of this, traditional supervised learning, which assumes that each example is explicitly mapped to a label, is not appropriate. We propose a novel approach to multi-instance multi-label learning for RE, which jointly models all the instances of a pair of entities in text and all their labels using a graphical model with latent variables. Our model performs competitively on two difficult domains. –</p><p>5 0.053467363 <a title="10-tfidf-5" href="./emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities.html">98 emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</a></p>
<p>Author: Thomas Lin ; Mausam ; Oren Etzioni</p><p>Abstract: Entity linking systems link noun-phrase mentions in text to their corresponding Wikipedia articles. However, NLP applications would gain from the ability to detect and type all entities mentioned in text, including the long tail of entities not prominent enough to have their own Wikipedia articles. In this paper we show that once the Wikipedia entities mentioned in a corpus of textual assertions are linked, this can further enable the detection and fine-grained typing of the unlinkable entities. Our proposed method for detecting unlinkable entities achieves 24% greater accuracy than a Named Entity Recognition baseline, and our method for fine-grained typing is able to propagate over 1,000 types from linked Wikipedia entities to unlinkable entities. Detection and typing of unlinkable entities can increase yield for NLP applications such as typed question answering.</p><p>6 0.050776184 <a title="10-tfidf-6" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>7 0.050235748 <a title="10-tfidf-7" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>8 0.050092552 <a title="10-tfidf-8" href="./emnlp-2012-First_Order_vs._Higher_Order_Modification_in_Distributional_Semantics.html">53 emnlp-2012-First Order vs. Higher Order Modification in Distributional Semantics</a></p>
<p>9 0.049806412 <a title="10-tfidf-9" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>10 0.049052276 <a title="10-tfidf-10" href="./emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">12 emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<p>11 0.048345305 <a title="10-tfidf-11" href="./emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">47 emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>12 0.046036463 <a title="10-tfidf-12" href="./emnlp-2012-PATTY%3A_A_Taxonomy_of_Relational_Patterns_with_Semantic_Types.html">103 emnlp-2012-PATTY: A Taxonomy of Relational Patterns with Semantic Types</a></p>
<p>13 0.045365956 <a title="10-tfidf-13" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>14 0.043835782 <a title="10-tfidf-14" href="./emnlp-2012-Resolving_This-issue_Anaphora.html">113 emnlp-2012-Resolving This-issue Anaphora</a></p>
<p>15 0.043416761 <a title="10-tfidf-15" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>16 0.041245729 <a title="10-tfidf-16" href="./emnlp-2012-Identifying_Constant_and_Unique_Relations_by_using_Time-Series_Text.html">62 emnlp-2012-Identifying Constant and Unique Relations by using Time-Series Text</a></p>
<p>17 0.040919881 <a title="10-tfidf-17" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>18 0.040848427 <a title="10-tfidf-18" href="./emnlp-2012-Ensemble_Semantics_for_Large-scale_Unsupervised_Relation_Extraction.html">40 emnlp-2012-Ensemble Semantics for Large-scale Unsupervised Relation Extraction</a></p>
<p>19 0.039687969 <a title="10-tfidf-19" href="./emnlp-2012-Improving_NLP_through_Marginalization_of_Hidden_Syntactic_Structure.html">65 emnlp-2012-Improving NLP through Marginalization of Hidden Syntactic Structure</a></p>
<p>20 0.039572734 <a title="10-tfidf-20" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.159), (1, 0.068), (2, 0.041), (3, -0.023), (4, 0.017), (5, 0.014), (6, 0.041), (7, 0.069), (8, -0.029), (9, 0.008), (10, -0.03), (11, 0.012), (12, -0.065), (13, 0.024), (14, 0.022), (15, -0.024), (16, -0.023), (17, -0.049), (18, -0.024), (19, 0.082), (20, 0.059), (21, 0.037), (22, 0.048), (23, -0.061), (24, 0.036), (25, 0.052), (26, 0.08), (27, -0.023), (28, 0.042), (29, 0.027), (30, -0.018), (31, 0.049), (32, 0.034), (33, -0.121), (34, -0.103), (35, 0.027), (36, 0.022), (37, 0.126), (38, -0.059), (39, -0.23), (40, 0.262), (41, -0.134), (42, -0.099), (43, 0.178), (44, 0.163), (45, 0.094), (46, -0.121), (47, 0.034), (48, -0.367), (49, -0.23)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91023988 <a title="10-lsi-1" href="./emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<p>Author: Mathias Verbeke ; Vincent Van Asch ; Roser Morante ; Paolo Frasconi ; Walter Daelemans ; Luc De Raedt</p><p>Abstract: Evidence-based medicine is an approach whereby clinical decisions are supported by the best available findings gained from scientific research. This requires efficient access to such evidence. To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the socalled PICO criteria. This paper presents an approach to automatically annotate sentences in medical abstracts with these labels. Since both structural and sequential information are important for this classification task, we use kLog, a new language for statistical relational learning with kernels. Our results show a clear improvement with respect to state-of-the-art systems.</p><p>2 0.52947456 <a title="10-lsi-2" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>Author: Annie Louis ; Ani Nenkova</p><p>Abstract: We introduce a model of coherence which captures the intentional discourse structure in text. Our work is based on the hypothesis that syntax provides a proxy for the communicative goal of a sentence and therefore the sequence of sentences in a coherent discourse should exhibit detectable structural patterns. Results show that our method has high discriminating power for separating out coherent and incoherent news articles reaching accuracies of up to 90%. We also show that our syntactic patterns are correlated with manual annotations of intentional structure for academic conference articles and can successfully predict the coherence of abstract, introduction and related work sections of these articles. 59.3 (100.0) Intro 50.3 (100.0) 1166 Rel wk 55.4 (100.0) >= 0.663.8 (67.2)50.8 (71.1)58.6 (75.9) >= 0.7 67.2 (32.0) 54.4 (38.6) 63.3 (52.8) >= 0.8 74.0 (10.0) 51.6 (22.0) 63.0 (25.7) >= 0.9 91.7 (2.0) 30.6 (5.0) 68.1 (7.2) Table 9: Accuracy (% examples) above each confidence level for the conference versus workshop task. These results are shown in Table 9. The proportion of examples under each setting is also indicated. When only examples above 0.6 confidence are examined, the classifier has a higher accuracy of63.8% for abstracts and covers close to 70% of the examples. Similarly, when a cutoff of 0.7 is applied to the confidence for predicting related work sections, we achieve 63.3% accuracy for 53% of examples. So we can consider that 30 to 47% of the examples in the two sections respectively are harder to tell apart. Interestingly however even high confidence predictions on introductions remain incorrect. These results show that our model can successfully distinguish the structure of articles beyond just clearly incoherent permutation examples. 7 Conclusion Our work is the first to develop an unsupervised model for intentional structure and to show that it has good accuracy for coherence prediction and also complements entity and lexical structure of discourse. This result raises interesting questions about how patterns captured by these different coherence metrics vary and how they can be combined usefully for predicting coherence. We plan to explore these ideas in future work. We also want to analyze genre differences to understand if the strength of these coherence dimensions varies with genre. Acknowledgements This work is partially supported by a Google research grant and NSF CAREER 0953445 award. References Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computa- tional Linguistics, 34(1): 1–34. Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of NAACL-HLT, pages 113–120. Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL, pages 9–16. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL, pages 173–180. Jackie C.K. Cheung and Gerald Penn. 2010. Utilizing extra-sentential context for parsing. In Proceedings of EMNLP, pages 23–33. Christelle Cocco, Rapha ¨el Pittier, Fran ¸cois Bavaud, and Aris Xanthos. 2011. Segmentation and clustering of textual sequences: a typological approach. In Proceedings of RANLP, pages 427–433. Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 3 1:25–70. Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. Parscit: An open-source crf reference string parsing package. In Proceedings of LREC, pages 661–667. Micha Elsner and Eugene Charniak. 2008. Coreferenceinspired coherence modeling. In Proceedings of ACLHLT, Short Papers, pages 41–44. Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of ACL-HLT, pages 125–129. Micha Elsner, Joseph Austerweil, and Eugene Charniak. 2007. A unified local and global model for discourse coherence. In Proceedings of NAACL-HLT, pages 436–443. Pascale Fung and Grace Ngai. 2006. One story, one flow: Hidden markov story models for multilingual multidocument summarization. ACM Transactions on Speech and Language Processing, 3(2): 1–16. Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 3(12): 175–204. Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011. A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of EMNLP, pages 273–283. Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-HLT, pages 586–594, June. 1167 Nikiforos Karamanis, Chris Mellish, Massimo Poesio, and Jon Oberlander. 2009. Evaluating centering for information ordering using corpora. Computational Linguistics, 35(1):29–46. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL, pages 423–430. Mirella Lapata and Regina Barzilay. 2005. Automatic evaluation of text coherence: Models and representations. In Proceedings of IJCAI. Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL, pages 545–552. Maria Liakata and Larisa Soldatova. 2008. Guidelines for the annotation of general scientific concepts. JISC Project Report. Maria Liakata, Simone Teufel, Advaith Siddharthan, and Colin Batchelor. 2010. Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC. Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proceedings of EMNLP, pages 343–351. Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011. Automatically evaluating text coherence using discourse relations. In Proceedings of ACL-HLT, pages 997– 1006. Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330. Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP, pages 186–195. Dragomir R. Radev, Mark Thomas Joseph, Bryan Gibson, and Pradeep Muthukrishnan. 2009. A Bibliometric and Network Analysis ofthe field of Computational Linguistics. Journal of the American Society for Information Science and Technology. David Reitter, Johanna D. Moore, and Frank Keller. 2006. Priming of Syntactic Rules in Task-Oriented Dialogue and Spontaneous Conversation. In Proceedings of the 28th Annual Conference of the Cognitive Science Society, pages 685–690. Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Proceedings of the fifth conference on Applied natural language processing, pages 16–19. Radu Soricut and Daniel Marcu. 2006. Discourse generation using utility-trained coherence models. In Proceedings of COLING-ACL, pages 803–810. John Swales. 1990. Genre analysis: English in academic and research settings, volume 11. Cambridge University Press. Simone Teufel and Marc Moens. 2000. What’s yours and what’s mine: determining intellectual attribution in scientific text. In Proceedings of EMNLP, pages 9– 17. Simone Teufel, Jean Carletta, and Marc Moens. 1999. An annotation scheme for discourse-level argumentation in research articles. In Proceedings of EACL, pages 110–1 17. Ying Zhao, George Karypis, and Usama Fayyad. 2005. Hierarchical clustering algorithms for document datasets. Data Mining and Knowledge Discovery, 10: 141–168. 1168</p><p>3 0.30892959 <a title="10-lsi-3" href="./emnlp-2012-First_Order_vs._Higher_Order_Modification_in_Distributional_Semantics.html">53 emnlp-2012-First Order vs. Higher Order Modification in Distributional Semantics</a></p>
<p>Author: Gemma Boleda ; Eva Maria Vecchi ; Miquel Cornudella ; Louise McNally</p><p>Abstract: Adjectival modification, particularly by expressions that have been treated as higherorder modifiers in the formal semantics tradition, raises interesting challenges for semantic composition in distributional semantic models. We contrast three types of adjectival modifiers intersectively used color terms (as in white towel, clearly first-order), subsectively used color terms (white wine, which have been modeled as both first- and higher-order), and intensional adjectives (former bassist, clearly higher-order) and test the ability of different composition strategies to model their behavior. In addition to opening up a new empirical domain for research on distributional semantics, our observations concerning the attested vectors for the different types of adjectives, the nouns they modify, and the resulting – – noun phrases yield insights into modification that have been little evident in the formal semantics literature to date.</p><p>4 0.26351616 <a title="10-lsi-4" href="./emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision.html">133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</a></p>
<p>Author: Joohyun Kim ; Raymond Mooney</p><p>Abstract: “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B ¨orschinger et al. (201 1) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (201 1). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.</p><p>5 0.2477818 <a title="10-lsi-5" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>Author: Ni Lao ; Amarnag Subramanya ; Fernando Pereira ; William W. Cohen</p><p>Abstract: We study how to extend a large knowledge base (Freebase) by reading relational information from a large Web text corpus. Previous studies on extracting relational knowledge from text show the potential of syntactic patterns for extraction, but they do not exploit background knowledge of other relations in the knowledge base. We describe a distributed, Web-scale implementation of a path-constrained random walk model that learns syntactic-semantic inference rules for binary relations from a graph representation of the parsed text and the knowledge base. Experiments show significant accuracy improvements in binary relation prediction over methods that consider only text, or only the existing knowledge base.</p><p>6 0.24510309 <a title="10-lsi-6" href="./emnlp-2012-Building_a_Lightweight_Semantic_Model_for_Unsupervised_Information_Extraction_on_Short_Listings.html">26 emnlp-2012-Building a Lightweight Semantic Model for Unsupervised Information Extraction on Short Listings</a></p>
<p>7 0.23764682 <a title="10-lsi-7" href="./emnlp-2012-An_%22AI_readability%22_Formula_for_French_as_a_Foreign_Language.html">17 emnlp-2012-An "AI readability" Formula for French as a Foreign Language</a></p>
<p>8 0.2325886 <a title="10-lsi-8" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>9 0.22773604 <a title="10-lsi-9" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>10 0.22467512 <a title="10-lsi-10" href="./emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</a></p>
<p>11 0.22369623 <a title="10-lsi-11" href="./emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">85 emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>12 0.21853109 <a title="10-lsi-12" href="./emnlp-2012-Lexical_Differences_in_Autobiographical_Narratives_from_Schizophrenic_Patients_and_Healthy_Controls.html">83 emnlp-2012-Lexical Differences in Autobiographical Narratives from Schizophrenic Patients and Healthy Controls</a></p>
<p>13 0.21703342 <a title="10-lsi-13" href="./emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">97 emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>14 0.21653551 <a title="10-lsi-14" href="./emnlp-2012-Improving_NLP_through_Marginalization_of_Hidden_Syntactic_Structure.html">65 emnlp-2012-Improving NLP through Marginalization of Hidden Syntactic Structure</a></p>
<p>15 0.21545102 <a title="10-lsi-15" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>16 0.21352947 <a title="10-lsi-16" href="./emnlp-2012-Exploiting_Chunk-level_Features_to_Improve_Phrase_Chunking.html">45 emnlp-2012-Exploiting Chunk-level Features to Improve Phrase Chunking</a></p>
<p>17 0.21273869 <a title="10-lsi-17" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>18 0.19982217 <a title="10-lsi-18" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>19 0.17425148 <a title="10-lsi-19" href="./emnlp-2012-Identifying_Constant_and_Unique_Relations_by_using_Time-Series_Text.html">62 emnlp-2012-Identifying Constant and Unique Relations by using Time-Series Text</a></p>
<p>20 0.17211619 <a title="10-lsi-20" href="./emnlp-2012-Cross-Lingual_Language_Modeling_with_Syntactic_Reordering_for_Low-Resource_Speech_Recognition.html">31 emnlp-2012-Cross-Lingual Language Modeling with Syntactic Reordering for Low-Resource Speech Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.025), (16, 0.037), (25, 0.025), (27, 0.355), (34, 0.048), (45, 0.013), (60, 0.092), (63, 0.056), (64, 0.019), (65, 0.032), (70, 0.03), (73, 0.024), (74, 0.042), (76, 0.045), (79, 0.015), (80, 0.027), (86, 0.025), (95, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72369111 <a title="10-lda-1" href="./emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<p>Author: Mathias Verbeke ; Vincent Van Asch ; Roser Morante ; Paolo Frasconi ; Walter Daelemans ; Luc De Raedt</p><p>Abstract: Evidence-based medicine is an approach whereby clinical decisions are supported by the best available findings gained from scientific research. This requires efficient access to such evidence. To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the socalled PICO criteria. This paper presents an approach to automatically annotate sentences in medical abstracts with these labels. Since both structural and sequential information are important for this classification task, we use kLog, a new language for statistical relational learning with kernels. Our results show a clear improvement with respect to state-of-the-art systems.</p><p>2 0.3850795 <a title="10-lda-2" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>3 0.38226339 <a title="10-lda-3" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>4 0.37629455 <a title="10-lda-4" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Daniel Jurafsky</p><p>Abstract: We present a new family of models for unsupervised parsing, Dependency and Boundary models, that use cues at constituent boundaries to inform head-outward dependency tree generation. We build on three intuitions that are explicit in phrase-structure grammars but only implicit in standard dependency formulations: (i) Distributions of words that occur at sentence boundaries such as English determiners resemble constituent edges. (ii) Punctuation at sentence boundaries further helps distinguish full sentences from fragments like headlines and titles, allowing us to model grammatical differences between complete and incomplete sentences. (iii) Sentence-internal punctuation boundaries help with longer-distance dependencies, since punctuation correlates with constituent edges. Our models induce state-of-the-art dependency grammars for many languages without — — special knowledge of optimal input sentence lengths or biased, manually-tuned initializers.</p><p>5 0.37373531 <a title="10-lda-5" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>Author: Jordan Boyd-Graber ; Brianna Satinoff ; He He ; Hal Daume III</p><p>Abstract: Cost-sensitive classification, where thefeatures used in machine learning tasks have a cost, has been explored as a means of balancing knowledge against the expense of incrementally obtaining new features. We introduce a setting where humans engage in classification with incrementally revealed features: the collegiate trivia circuit. By providing the community with a web-based system to practice, we collected tens of thousands of implicit word-by-word ratings of how useful features are for eliciting correct answers. Observing humans’ classification process, we improve the performance of a state-of-the art classifier. We also use the dataset to evaluate a system to compete in the incremental classification task through a reduction of reinforcement learning to classification. Our system learns when to answer a question, performing better than baselines and most human players.</p><p>6 0.37159142 <a title="10-lda-6" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>7 0.37114009 <a title="10-lda-7" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>8 0.3703196 <a title="10-lda-8" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>9 0.36849266 <a title="10-lda-9" href="./emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">51 emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>10 0.36771023 <a title="10-lda-10" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>11 0.36632824 <a title="10-lda-11" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>12 0.36622417 <a title="10-lda-12" href="./emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">64 emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<p>13 0.36588418 <a title="10-lda-13" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>14 0.36489639 <a title="10-lda-14" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>15 0.3643207 <a title="10-lda-15" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>16 0.36414284 <a title="10-lda-16" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>17 0.36390328 <a title="10-lda-17" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<p>18 0.36362612 <a title="10-lda-18" href="./emnlp-2012-Mixed_Membership_Markov_Models_for_Unsupervised_Conversation_Modeling.html">89 emnlp-2012-Mixed Membership Markov Models for Unsupervised Conversation Modeling</a></p>
<p>19 0.36353451 <a title="10-lda-19" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>20 0.36318663 <a title="10-lda-20" href="./emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">70 emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
