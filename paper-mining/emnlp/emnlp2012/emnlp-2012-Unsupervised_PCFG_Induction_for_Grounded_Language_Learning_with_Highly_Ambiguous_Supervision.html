<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-133" href="#">emnlp2012-133</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</h1>
<br/><p>Source: <a title="emnlp-2012-133-pdf" href="http://aclweb.org/anthology//D/D12/D12-1040.pdf">pdf</a></p><p>Author: Joohyun Kim ; Raymond Mooney</p><p>Abstract: “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B ¨orschinger et al. (201 1) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (201 1). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.</p><p>Reference: <a title="emnlp-2012-133-reference" href="../emnlp2012_reference/emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. [sent-5, score-0.119]
</p><p>2 However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (201 1). [sent-9, score-0.267]
</p><p>3 Experimental results on the navigation task demonstrates the effectiveness of our approach. [sent-11, score-0.131]
</p><p>4 Given only supervision in the form of sentences paired with relevant but ambiguous perceptual contexts, a system should learn to interpret and/or generate language describing situations and events in the world. [sent-13, score-0.142]
</p><p>5 , 2011), or understand navigation instructions by learning from action traces 433 produced when following the directions (Chen and Mooney, 2011; Tellex et al. [sent-16, score-0.358]
</p><p>6 (201 1) recently introduced an approach to grounded language learning using unsupervised induction of probabilistic context free grammars (PCFGs) to learn from ambiguous contextual supervision. [sent-19, score-0.125]
</p><p>7 Their approach first constructs  a large set of production rules from sentences paired with descriptions of their ambiguous context, and then trains the parameters of this grammar using EM. [sent-20, score-0.133]
</p><p>8 Parsing a novel sentence with this grammar gives a parse tree which contains the formal meaning representation (MR) for this sentence. [sent-21, score-0.129]
</p><p>9 In this task, each sentence in a natural-language commentary describing activity in a simulated robot soccer game is paired with the small set of actions observed within the past 5 seconds, one of which is usually described by the sentence. [sent-23, score-0.107]
</p><p>10 The navigation task studied by Chen and Mooney (201 1) provides much more ambiguous supervision. [sent-26, score-0.195]
</p><p>11 An instruction generally refers to a subgraph of this large graph. [sent-30, score-0.191]
</p><p>12 Their system first induces a semantic lexicon that maps words and short phrases to formal representations of actions and objects in the world. [sent-33, score-0.23]
</p><p>13 This lexicon is learned by finding words and phrases whose occurrence highly correlates with specific observed actions and objects in the simulated environment when executing the corresponding instruction. [sent-34, score-0.222]
</p><p>14 This learned lexicon is then used to directly infer a formal MR for observed instructional sentences using a greedy covering algorithm. [sent-35, score-0.12]
</p><p>15 These inferred MRs are then used to train a supervised semantic parser capable of mapping novel sentences to their  formal meanings. [sent-36, score-0.105]
</p><p>16 ’s PCFG approach that uses Chen and Mooney’s lexicon learner to avoid a combinatorial explosion in the number of productions. [sent-38, score-0.101]
</p><p>17 The learned lexicon is first used to build a hierarchy of semantic lexemes (i. [sent-39, score-0.271]
</p><p>18 lexicon entries) called the Lexeme Hierarchy Graph (LHG) for each ambiguous landmarks plan in the training data. [sent-41, score-0.294]
</p><p>19 The intuition behind utilizing an LHG is that the MR for each lexeme constitutes a semantic concept that corresponds to some naturallanguage (NL) word or phrase. [sent-42, score-0.202]
</p><p>20 Therefore, the LHG represents how complex semantic concepts are composed of simpler semantic concepts and ultimately connected to NL words and phrases. [sent-43, score-0.188]
</p><p>21 ’s approach instead produces NL groundings at the level of atomic MR constituents, which causes an explosion in the number of PCFG productions for complex MR languages. [sent-45, score-0.097]
</p><p>22 It then extracts the MR for a novel  1The corpus contains quite a few examples with landmarks plans containing more than 20 actions. [sent-50, score-0.201]
</p><p>23 Our approach can produce a large, combinatorial number of different MRs for a wide range of novel sentences by composing relevant MR components from the resulting parse tree, whereas B ¨orschinger et al. [sent-54, score-0.143]
</p><p>24 ’s PCFG approach as well as the navigation task and data. [sent-58, score-0.131]
</p><p>25 Particularly, their approach automatically constructs a PCFG that generates NL sentences from MRs, which indicates how atomic MR constituents are probabilistically related to NL words. [sent-67, score-0.124]
</p><p>26 The nonterminal for a composite MR generates each of its MR constituents, and each atomic MR, x, generates an NL phrase, Phrasex. [sent-69, score-0.114]
</p><p>27 Figure 1  shows one possible derivation tree for a sample NLMR pair and the PCFG rules that are constructed for it. [sent-72, score-0.097]
</p><p>28 Computing the most probable parse for a novel sentence with the trained PCFG provides its  Figure 1: Derivation tree for the NL/MR pair: THE PINK GOALIE PASSES THE BALL TO PINK 11 / pass(pink1 ,pink11) . [sent-74, score-0.097]
</p><p>29 Left side shows PCFG rules that are added for each stage (full MR to atomic MRs, and atomic MRs to NL words ). [sent-75, score-0.115]
</p><p>30 Therefore, our extension incorporates a learned lexicon to constrain the space of productions, thereby making the size of the PCFG tractable for complex MRs, and even giving it the ability to handle infinite MR languages. [sent-80, score-0.116]
</p><p>31 2 Navigation Task and Dataset We employ the task and data introduced by Chen and Mooney (201 1) whose goal is to interpret and follow NL navigation instructions in a virtual world. [sent-84, score-0.373]
</p><p>32 Figure 2 shows a sample execution path in a particular virtual world. [sent-85, score-0.097]
</p><p>33 Figure 3: Sample instruction with its constructed landmarks plan, components in bold compose the correct plan. [sent-95, score-0.247]
</p><p>34 In order to learn, their system infers the intended formal plan pi (the MR for a sentence) which produced the action sequence ai from the instruction ei. [sent-96, score-0.212]
</p><p>35 Chen and Mooney first construct a formal landmarks plan, ci, for each ai, which is a graph representing the context of every action and the world-state encountered during the  execution of the sequence. [sent-98, score-0.211]
</p><p>36 The correct plan MR, pi, is assumed to be a subgraph of ci, and this causes a combinatorial matching problem between ei and ci in order to learn the correct meaning of ei among all the possible subgraphs of ci. [sent-99, score-0.329]
</p><p>37 The landmarks and correct plans for a sample instruction are shown in Figure 3, illustrating the complexity of the MRs. [sent-100, score-0.297]
</p><p>38 Our method replaces the plan re-  finement and semantic parser parts. [sent-102, score-0.095]
</p><p>39 The lexicon is learned by evaluating pairs of n-grams, wj, and MR graphs, mj, and scoring them based on how much more likely mj is a subgraph of the context ci when w occurs in the corresponding instruction ei. [sent-104, score-0.418]
</p><p>40 Then, a plan refinement step estimates pi from ci by greedily selecting high-scoring lexemes of the form (wj, mj) whose words and phrases (wj) cover the instruction ei and introduce components (mj) from the landmarks plan ci. [sent-106, score-0.558]
</p><p>41 The trained semantic parser can parse a novel instruction into a formal plan, which is finally executed for end-to-end evaluation. [sent-108, score-0.256]
</p><p>42 As this figure indicates, our new PCFG method replaces the plan refinement and semantic parser  components in their system with a unified model that both disambiguates the training data and learns a semantic parser. [sent-110, score-0.163]
</p><p>43 We use the landmarks plans and the learned lexicon produced by Chen and Mooney (201 1) as inputs to our system. [sent-111, score-0.261]
</p><p>44 2  2In our experiments, we used the top  1,000 lexemes learned  by Chen and Mooney (2011). [sent-112, score-0.121]
</p><p>45 (201 1), our approach learns a semantic parser directly from ambiguous supervision, specifically NL instructions paired with their complete landmarks plans as context. [sent-114, score-0.504]
</p><p>46 Our method incorporates the semantic lexemes as building blocks to find correspondences between NL words and semantic concepts represented by the lexeme MRs, instead of building connections between NL words and every possible MR constituent as in B ¨orschinger et al. [sent-115, score-0.404]
</p><p>47 Particularly, we utilize the hierarchical subgraph relationships between the MRs in the learned semantic lexicon to produce  a smaller, more focused set of PCFG rules. [sent-117, score-0.219]
</p><p>48 Inspired by this idea, we introduce a directed acyclic graph called the Lexeme Hierarchy Graph (LHG) which represents the hierarchical relationships between lexeme MRs. [sent-119, score-0.157]
</p><p>49 Since complex lexeme MRs represent complicated semantic concepts while simple MRs represent simple concepts, it is natural to construct a hierarchy amongst them. [sent-120, score-0.306]
</p><p>50 Finally, a novel sentence is semantically parsed by computing its mostprobable parse using the trained PCFG, and then its MR is extracted from the resulting parse tree. [sent-122, score-0.12]
</p><p>51 1 Constructing a Lexeme Hierarchy Graph An LHG represents the hierarchy of lexical meanings relevant to a particular training instance by encoding the subgraph relations between the MRs of  relevant lexemes. [sent-124, score-0.158]
</p><p>52 First, we obtain all relevant lexemes (wij,mij) in the lexicon L, where the MR mji is a subgraph of the context ci (denoted as mji ⊂ ci). [sent-126, score-0.421]
</p><p>53 These lexemes are 3The total number of PCFG rules constructed for our navigation training sets is about 18,000, while B ¨orschinger et al. [sent-127, score-0.283]
</p><p>54 Algorithm 1 LEXEMEHIERARCHYGRAPH(LHG) Input: Training instance (ei, ci), Lexicon L Output: Lexeme hierarchy graph for (ei, ci) Find relevant lexemes (wi1, mi1) , . [sent-129, score-0.138]
</p><p>55 Then, after setting the context ci as the MR of the root node (MR(T) ← ci), lexemesa are inserted, tihne order, iondtoe (thMe graph ←to create a hierarchy of MRs, where each child’s MR is a subgraph of the MR of each of its parents. [sent-135, score-0.253]
</p><p>56 Figure 5 illustrates a sample construction of an LHG for the following landmarks plan (ci): Turn ( RIGHT ) Veri fy ( s ide :HATRACK, front : SOFA) Trave l( steps : 3 ) Veri fy ( at :EASEL ) The initial LHG may contain nodes with too many children. [sent-136, score-0.225]
</p><p>57 The MR for a pseudo-lexeme is the minimal graph, m0, that is a supergraph ofboth of the lexeme MRs that it combines. [sent-141, score-0.157]
</p><p>58 The pair of 437  (a) All relevant lexemes are obtained for the training example and ordered by the number of nodes in their MR. [sent-142, score-0.137]
</p><p>59 (c) MR [3] is not a subgraph of [1] or [2], so it is added as a child of the root. [sent-145, score-0.108]
</p><p>60 Algorithm 2 ADDINGPSEUDOLEXEMES TOLHG Input: LHG with root T Output: LHG with pseudo lexemes added procedure RECONSTRUCTLHG(T) repeat ((Ti, Tj) , m0) ← pick the most similar pair (Ti, Tj) of child)ren ← ←of pTic kand th tehe m mmoisntim siaml ex-  tension m0 s. [sent-148, score-0.119]
</p><p>61 (201 1), but instead of generating NL words from each atomic MR, words are generated from each lexeme MR, 438  Figure 6: Summary of the rule generation process. [sent-162, score-0.2]
</p><p>62 (201 1), and allow every lexeme MR to generate one or more NL words. [sent-165, score-0.157]
</p><p>63 and smaller lexeme MRs are generated from more complex ones as given by the LHGs. [sent-167, score-0.185]
</p><p>64 ci, the MR ofthe root node) conveys the intended plan and is therefore expressed in the NL instruction, we must allow each ordered subset of the children of a node (i. [sent-177, score-0.135]
</p><p>65 Every MR, m, of a lexeme node4 generates a rule Sm → Phrasem, and every Phrasem generates a sequence orfa NseL words, including one or more “content words” (Wordm) for expressing m and zero or more “extraneous” words (Word∅). [sent-182, score-0.205]
</p><p>66 However, in our approach, the correct MR is constructed by properly composing the appropriate subset of lexeme MRs from the most-probable parse tree. [sent-193, score-0.261]
</p><p>67 This allows the system to produce a wide variety of novel MRs for novel sentences, as long as the correct MR is a subgraph of the complete context (ci) for at least one of the training sentences. [sent-194, score-0.142]
</p><p>68 First, the parse tree is pruned to remove all subtrees starting with Phrasex nodes. [sent-195, score-0.097]
</p><p>69 The final output is the MR constructed by removing all of the unmarked nodes from the MR for the root node. [sent-214, score-0.114]
</p><p>70 1 Data We used the English instructions and follower data collected by MacMahon et al. [sent-218, score-0.202]
</p><p>71 6 This data contains 706 route instructions for three virtual worlds. [sent-220, score-0.276]
</p><p>72 The instructions were produced by six instructors for 126 unique starting and ending location pairs spread evenly across the three worlds, and there were 1to 15 human followers for each instruction who executed an average of 10. [sent-221, score-0.307]
</p><p>73 Each instruction is a paragraph consisting of an average of 5. [sent-223, score-0.105]
</p><p>74 g1 r87a% ph  Table 2: Successful plan execution rates for novel test data. [sent-251, score-0.116]
</p><p>75 Navigation Plan Execution Results Next, we test the end-to-end system by executing the parsed navigation plans for test instructions in novel environments to see if they reach the exact desired destinations in the environment. [sent-253, score-0.472]
</p><p>76 This is because the redundancy in the hu-  man generated instructions allows an incorrect semantic parse to be successful, as long as the errors do not affect its ability to guide the system to the correct destination. [sent-257, score-0.293]
</p><p>77 As previously mentioned, lexeme MRs are intuitively analogous to syntactic categories in that complex lexeme MRs represent complicated semantic concepts whereas higher-level syntactic categories such as S, VP, or NP represent complex syntactic structures. [sent-262, score-0.45]
</p><p>78 Even though our MR parse is restricted to be a subgraph of some training context, ci, our model allows •  for exponentially many combinations. [sent-265, score-0.132]
</p><p>79 In addition, our approach can produce a wider range of MR outputs than Chen and Mooney 44 1 (201 1)’s even though we use their semantic lexicon as input. [sent-266, score-0.109]
</p><p>80 Their system deterministically builds a supervised training set by greedily selecting highscoring lexemes, thus implicitly including only high-scoring lexemes during training. [sent-267, score-0.097]
</p><p>81 Since the semantic lexicon is an input to our system,  other approaches to lexicon learning are also easily incorporated. [sent-271, score-0.173]
</p><p>82 Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. [sent-274, score-0.183]
</p><p>83 Kim and Mooney (2010) proposed a generative semantic parsing model that first chooses which MRs to describe and then generates a hybrid tree structure (Lu et al. [sent-280, score-0.092]
</p><p>84 , 2009; Vogel and Jurafsky, 2010) use NL instructions to guide reinforcement learning from independent exploration with delayed rewards. [sent-290, score-0.202]
</p><p>85 These systems do not even need the ambiguous supervision obtained from observing humans follow instructions; however, they do not learn semantic parsers that map sentences to complex, structural representations of their meaning. [sent-291, score-0.132]
</p><p>86 Interpreting and executing NL navigation instruc-  tions is our primary task, and several other recent projects have studied related problems. [sent-292, score-0.155]
</p><p>87 Shimizu and Haas (2009) present a system that parses natural language instructions into actions. [sent-293, score-0.202]
</p><p>88 (2010) developed a system that learns to map NL instructions to executable commands for a robot navigating in an environment constructed by a laser range finder. [sent-296, score-0.306]
</p><p>89 However, their approach has limitations of ignoring any objects or other landmarks in the environment to which the instructions can refer. [sent-297, score-0.376]
</p><p>90 , 2011) which learn to follow instructions in more linguistically complex environments. [sent-300, score-0.23]
</p><p>91 However, they assume predefined spatial words, direct matching between NL words and the names of objects and other landmarks in the MR, and/or an existing syntactic parser. [sent-301, score-0.153]
</p><p>92 For example, some ofthe current lexicon entries violate the general constraint that nouns usually refer to objects and verbs to actions. [sent-305, score-0.101]
</p><p>93 8  Conclusions  We have presented a novel method for learning a semantic parser given only highly ambiguous supervision. [sent-309, score-0.137]
</p><p>94 (201 1)’s approach to reducing the problem of grounded learning of semantic parsers to PCFG induction. [sent-311, score-0.106]
</p><p>95 We use a learned semantic lexicon to aid the construction of a smaller and more focused set of PCFG productions. [sent-312, score-0.133]
</p><p>96 In addition, our algorithm for composing MRs from the final parse tree provides the flexibility to produce a wide range of novel MRs that were not seen during training. [sent-315, score-0.129]
</p><p>97 Evaluations on a previous corpus of navigational instructions for virtual environments has demonstrated the effectiveness of our method compared to a recent competing system. [sent-316, score-0.298]
</p><p>98 Learning to interpret natural language navigation instructions from observations. [sent-344, score-0.333]
</p><p>99 Generative alignment and semantic parsing for learning from ambiguous supervision. [sent-379, score-0.109]
</p><p>100 Understanding natural language commands for robotic navigation and mobile manipulation. [sent-425, score-0.153]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mr', 0.628), ('mrs', 0.328), ('nl', 0.265), ('orschinger', 0.218), ('instructions', 0.202), ('lhg', 0.191), ('pcfg', 0.178), ('mooney', 0.173), ('lexeme', 0.157), ('navigation', 0.131), ('landmarks', 0.116), ('instruction', 0.105), ('lexemes', 0.097), ('subgraph', 0.086), ('wordm', 0.079), ('ci', 0.078), ('chen', 0.068), ('lexicon', 0.064), ('ambiguous', 0.064), ('grounded', 0.061), ('mj', 0.061), ('plans', 0.057), ('actions', 0.052), ('plan', 0.05), ('mji', 0.048), ('kate', 0.048), ('zettlemoyer', 0.048), ('tj', 0.048), ('parse', 0.046), ('tellex', 0.045), ('semantic', 0.045), ('atomic', 0.043), ('raymond', 0.041), ('hierarchy', 0.041), ('virtual', 0.04), ('nodes', 0.04), ('ei', 0.039), ('execution', 0.038), ('combinatorial', 0.037), ('children', 0.037), ('objects', 0.037), ('constituents', 0.037), ('concepts', 0.035), ('robot', 0.035), ('perceptual', 0.035), ('luke', 0.034), ('joohyun', 0.034), ('phrasem', 0.034), ('phrasex', 0.034), ('placelexeme', 0.034), ('route', 0.034), ('sportscasting', 0.034), ('sm', 0.032), ('composing', 0.032), ('formal', 0.032), ('meanings', 0.031), ('environments', 0.03), ('intractably', 0.029), ('rules', 0.029), ('novel', 0.028), ('complex', 0.028), ('pruned', 0.028), ('nonterminals', 0.027), ('navigational', 0.026), ('unmarked', 0.026), ('constructed', 0.026), ('productions', 0.026), ('node', 0.026), ('correspondences', 0.025), ('action', 0.025), ('learned', 0.024), ('executing', 0.024), ('generates', 0.024), ('nonterminal', 0.023), ('tree', 0.023), ('kim', 0.023), ('refinement', 0.023), ('supervision', 0.023), ('commands', 0.022), ('federation', 0.022), ('hatrack', 0.022), ('lhgs', 0.022), ('macmahon', 0.022), ('matuszek', 0.022), ('obtainparsedoutput', 0.022), ('phm', 0.022), ('phxm', 0.022), ('reconstructlhg', 0.022), ('shimizu', 0.022), ('veri', 0.022), ('wordx', 0.022), ('child', 0.022), ('root', 0.022), ('cm', 0.021), ('environment', 0.021), ('ti', 0.02), ('constructs', 0.02), ('wj', 0.02), ('paired', 0.02), ('sample', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="133-tfidf-1" href="./emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision.html">133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</a></p>
<p>Author: Joohyun Kim ; Raymond Mooney</p><p>Abstract: “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B ¨orschinger et al. (201 1) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (201 1). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.</p><p>2 0.090291396 <a title="133-tfidf-2" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>3 0.053884383 <a title="133-tfidf-3" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>Author: Song Feng ; Ritwik Banerjee ; Yejin Choi</p><p>Abstract: Much of the writing styles recognized in rhetorical and composition theories involve deep syntactic elements. However, most previous research for computational stylometric analysis has relied on shallow lexico-syntactic patterns. Some very recent work has shown that PCFG models can detect distributional difference in syntactic styles, but without offering much insights into exactly what constitute salient stylistic elements in sentence structure characterizing each authorship. In this paper, we present a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements. We present analytic insights with respect to the authorship attribution task in two different domains. ,</p><p>4 0.048366081 <a title="133-tfidf-4" href="./emnlp-2012-Exploring_Adaptor_Grammars_for_Native_Language_Identification.html">48 emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras ; Mark Johnson</p><p>Abstract: The task of inferring the native language of an author based on texts written in a second language has generally been tackled as a classification problem, typically using as features a mix of n-grams over characters and part of speech tags (for small and fixed n) and unigram function words. To capture arbitrarily long n-grams that syntax-based approaches have suggested are useful, adaptor grammars have some promise. In this work we investigate their extension to identifying n-gram collocations of arbitrary length over a mix of PoS tags and words, using both maxent and induced syntactic language model approaches to classification. After presenting a new, simple baseline, we show that learned collocations used as features in a maxent model perform better still, but that the story is more mixed for the syntactic language model.</p><p>5 0.043486483 <a title="133-tfidf-5" href="./emnlp-2012-Grounded_Models_of_Semantic_Representation.html">61 emnlp-2012-Grounded Models of Semantic Representation</a></p>
<p>Author: Carina Silberer ; Mirella Lapata</p><p>Abstract: A popular tradition of studying semantic representation has been driven by the assumption that word meaning can be learned from the linguistic environment, despite ample evidence suggesting that language is grounded in perception and action. In this paper we present a comparative study of models that represent word meaning based on linguistic and perceptual data. Linguistic information is approximated by naturally occurring corpora and sensorimotor experience by feature norms (i.e., attributes native speakers consider important in describing the meaning of a word). The models differ in terms of the mechanisms by which they integrate the two modalities. Experimental results show that a closer correspondence to human data can be obtained by uncovering latent information shared among the textual and perceptual modalities rather than arriving at semantic knowledge by concatenating the two.</p><p>6 0.042760916 <a title="133-tfidf-6" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>7 0.040285282 <a title="133-tfidf-7" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>8 0.03895181 <a title="133-tfidf-8" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>9 0.038160466 <a title="133-tfidf-9" href="./emnlp-2012-Parser_Showdown_at_the_Wall_Street_Corral%3A_An_Empirical_Investigation_of_Error_Types_in_Parser_Output.html">105 emnlp-2012-Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</a></p>
<p>10 0.037179615 <a title="133-tfidf-10" href="./emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">96 emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<p>11 0.036812529 <a title="133-tfidf-11" href="./emnlp-2012-Training_Factored_PCFGs_with_Expectation_Propagation.html">126 emnlp-2012-Training Factored PCFGs with Expectation Propagation</a></p>
<p>12 0.036689568 <a title="133-tfidf-12" href="./emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">70 emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>13 0.036369674 <a title="133-tfidf-13" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>14 0.035311688 <a title="133-tfidf-14" href="./emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">12 emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<p>15 0.032840502 <a title="133-tfidf-15" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>16 0.032269988 <a title="133-tfidf-16" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>17 0.032149751 <a title="133-tfidf-17" href="./emnlp-2012-A_Bayesian_Model_for_Learning_SCFGs_with_Discontiguous_Rules.html">1 emnlp-2012-A Bayesian Model for Learning SCFGs with Discontiguous Rules</a></p>
<p>18 0.031722829 <a title="133-tfidf-18" href="./emnlp-2012-SSHLDA%3A_A_Semi-Supervised_Hierarchical_Topic_Model.html">115 emnlp-2012-SSHLDA: A Semi-Supervised Hierarchical Topic Model</a></p>
<p>19 0.03051205 <a title="133-tfidf-19" href="./emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">47 emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>20 0.030137684 <a title="133-tfidf-20" href="./emnlp-2012-Framework_of_Automatic_Text_Summarization_Using_Reinforcement_Learning.html">56 emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.124), (1, -0.012), (2, 0.028), (3, 0.006), (4, -0.018), (5, 0.022), (6, 0.006), (7, 0.054), (8, -0.032), (9, 0.063), (10, -0.026), (11, 0.049), (12, -0.066), (13, 0.061), (14, -0.023), (15, 0.0), (16, 0.029), (17, 0.003), (18, -0.011), (19, -0.035), (20, -0.022), (21, 0.124), (22, -0.025), (23, -0.001), (24, -0.064), (25, 0.0), (26, -0.02), (27, 0.116), (28, 0.022), (29, -0.063), (30, -0.119), (31, 0.109), (32, 0.02), (33, -0.158), (34, -0.267), (35, -0.121), (36, -0.006), (37, -0.117), (38, -0.027), (39, -0.181), (40, -0.098), (41, 0.204), (42, -0.219), (43, -0.093), (44, 0.279), (45, 0.22), (46, 0.032), (47, -0.145), (48, -0.048), (49, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95357436 <a title="133-lsi-1" href="./emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision.html">133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</a></p>
<p>Author: Joohyun Kim ; Raymond Mooney</p><p>Abstract: “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B ¨orschinger et al. (201 1) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (201 1). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.</p><p>2 0.47074661 <a title="133-lsi-2" href="./emnlp-2012-Grounded_Models_of_Semantic_Representation.html">61 emnlp-2012-Grounded Models of Semantic Representation</a></p>
<p>Author: Carina Silberer ; Mirella Lapata</p><p>Abstract: A popular tradition of studying semantic representation has been driven by the assumption that word meaning can be learned from the linguistic environment, despite ample evidence suggesting that language is grounded in perception and action. In this paper we present a comparative study of models that represent word meaning based on linguistic and perceptual data. Linguistic information is approximated by naturally occurring corpora and sensorimotor experience by feature norms (i.e., attributes native speakers consider important in describing the meaning of a word). The models differ in terms of the mechanisms by which they integrate the two modalities. Experimental results show that a closer correspondence to human data can be obtained by uncovering latent information shared among the textual and perceptual modalities rather than arriving at semantic knowledge by concatenating the two.</p><p>3 0.37431133 <a title="133-lsi-3" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>Author: Song Feng ; Ritwik Banerjee ; Yejin Choi</p><p>Abstract: Much of the writing styles recognized in rhetorical and composition theories involve deep syntactic elements. However, most previous research for computational stylometric analysis has relied on shallow lexico-syntactic patterns. Some very recent work has shown that PCFG models can detect distributional difference in syntactic styles, but without offering much insights into exactly what constitute salient stylistic elements in sentence structure characterizing each authorship. In this paper, we present a comprehensive exploration of syntactic elements in writing styles, with particular emphasis on interpretable characterization of stylistic elements. We present analytic insights with respect to the authorship attribution task in two different domains. ,</p><p>4 0.36351126 <a title="133-lsi-4" href="./emnlp-2012-Exploring_Adaptor_Grammars_for_Native_Language_Identification.html">48 emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras ; Mark Johnson</p><p>Abstract: The task of inferring the native language of an author based on texts written in a second language has generally been tackled as a classification problem, typically using as features a mix of n-grams over characters and part of speech tags (for small and fixed n) and unigram function words. To capture arbitrarily long n-grams that syntax-based approaches have suggested are useful, adaptor grammars have some promise. In this work we investigate their extension to identifying n-gram collocations of arbitrary length over a mix of PoS tags and words, using both maxent and induced syntactic language model approaches to classification. After presenting a new, simple baseline, we show that learned collocations used as features in a maxent model perform better still, but that the story is more mixed for the syntactic language model.</p><p>5 0.36138672 <a title="133-lsi-5" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>6 0.31921014 <a title="133-lsi-6" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>7 0.26726356 <a title="133-lsi-7" href="./emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">85 emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>8 0.25639427 <a title="133-lsi-8" href="./emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<p>9 0.24908687 <a title="133-lsi-9" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>10 0.23906434 <a title="133-lsi-10" href="./emnlp-2012-Building_a_Lightweight_Semantic_Model_for_Unsupervised_Information_Extraction_on_Short_Listings.html">26 emnlp-2012-Building a Lightweight Semantic Model for Unsupervised Information Extraction on Short Listings</a></p>
<p>11 0.23843887 <a title="133-lsi-11" href="./emnlp-2012-Forest_Reranking_through_Subtree_Ranking.html">55 emnlp-2012-Forest Reranking through Subtree Ranking</a></p>
<p>12 0.2382644 <a title="133-lsi-12" href="./emnlp-2012-Large_Scale_Decipherment_for_Out-of-Domain_Machine_Translation.html">75 emnlp-2012-Large Scale Decipherment for Out-of-Domain Machine Translation</a></p>
<p>13 0.22003821 <a title="133-lsi-13" href="./emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</a></p>
<p>14 0.2095238 <a title="133-lsi-14" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>15 0.19835791 <a title="133-lsi-15" href="./emnlp-2012-A_Bayesian_Model_for_Learning_SCFGs_with_Discontiguous_Rules.html">1 emnlp-2012-A Bayesian Model for Learning SCFGs with Discontiguous Rules</a></p>
<p>16 0.18312152 <a title="133-lsi-16" href="./emnlp-2012-Parser_Showdown_at_the_Wall_Street_Corral%3A_An_Empirical_Investigation_of_Error_Types_in_Parser_Output.html">105 emnlp-2012-Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</a></p>
<p>17 0.1830551 <a title="133-lsi-17" href="./emnlp-2012-Dynamic_Programming_for_Higher_Order_Parsing_of_Gap-Minding_Trees.html">37 emnlp-2012-Dynamic Programming for Higher Order Parsing of Gap-Minding Trees</a></p>
<p>18 0.16688092 <a title="133-lsi-18" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>19 0.16473605 <a title="133-lsi-19" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>20 0.15829733 <a title="133-lsi-20" href="./emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">96 emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.017), (11, 0.019), (16, 0.04), (25, 0.026), (29, 0.017), (30, 0.349), (34, 0.054), (60, 0.069), (63, 0.048), (64, 0.022), (65, 0.024), (70, 0.025), (73, 0.023), (74, 0.064), (76, 0.065), (79, 0.014), (86, 0.012), (95, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75646985 <a title="133-lda-1" href="./emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision.html">133 emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</a></p>
<p>Author: Joohyun Kim ; Raymond Mooney</p><p>Abstract: “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B ¨orschinger et al. (201 1) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (201 1). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.</p><p>2 0.49383429 <a title="133-lda-2" href="./emnlp-2012-Enlarging_Paraphrase_Collections_through_Generalization_and_Instantiation.html">39 emnlp-2012-Enlarging Paraphrase Collections through Generalization and Instantiation</a></p>
<p>Author: Atsushi Fujita ; Pierre Isabelle ; Roland Kuhn</p><p>Abstract: This paper presents a paraphrase acquisition method that uncovers and exploits generalities underlying paraphrases: paraphrase patterns are first induced and then used to collect novel instances. Unlike existing methods, ours uses both bilingual parallel and monolingual corpora. While the former are regarded as a source of high-quality seed paraphrases, the latter are searched for paraphrases that match patterns learned from the seed paraphrases. We show how one can use monolingual corpora, which are far more numerous and larger than bilingual corpora, to obtain paraphrases that rival in quality those derived directly from bilingual corpora. In our experiments, the number of paraphrase pairs obtained in this way from monolingual corpora was a large multiple of the number of seed paraphrases. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrase pairs are ofreasonable quality. Remaining noise can be further reduced by filtering seed paraphrases.</p><p>3 0.37820163 <a title="133-lda-3" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms ofweak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependencyparsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.</p><p>4 0.36492917 <a title="133-lda-4" href="./emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">124 emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Daniel Jurafsky</p><p>Abstract: We present a new family of models for unsupervised parsing, Dependency and Boundary models, that use cues at constituent boundaries to inform head-outward dependency tree generation. We build on three intuitions that are explicit in phrase-structure grammars but only implicit in standard dependency formulations: (i) Distributions of words that occur at sentence boundaries such as English determiners resemble constituent edges. (ii) Punctuation at sentence boundaries further helps distinguish full sentences from fragments like headlines and titles, allowing us to model grammatical differences between complete and incomplete sentences. (iii) Sentence-internal punctuation boundaries help with longer-distance dependencies, since punctuation correlates with constituent edges. Our models induce state-of-the-art dependency grammars for many languages without — — special knowledge of optimal input sentence lengths or biased, manually-tuned initializers.</p><p>5 0.35735229 <a title="133-lda-5" href="./emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">14 emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>Author: Lizhen Qu ; Rainer Gemulla ; Gerhard Weikum</p><p>Abstract: We propose the weakly supervised MultiExperts Model (MEM) for analyzing the semantic orientation of opinions expressed in natural language reviews. In contrast to most prior work, MEM predicts both opinion polarity and opinion strength at the level of individual sentences; such fine-grained analysis helps to understand better why users like or dislike the entity under review. A key challenge in this setting is that it is hard to obtain sentence-level training data for both polarity and strength. For this reason, MEM is weakly supervised: It starts with potentially noisy indicators obtained from coarse-grained training data (i.e., document-level ratings), a small set of diverse base predictors, and, if available, small amounts of fine-grained training data. We integrate these noisy indicators into a unified probabilistic framework using ideas from ensemble learning and graph-based semi-supervised learning. Our experiments indicate that MEM outperforms state-of-the-art methods by a significant margin.</p><p>6 0.35706609 <a title="133-lda-6" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>7 0.35460311 <a title="133-lda-7" href="./emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">51 emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>8 0.35131484 <a title="133-lda-8" href="./emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">123 emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>9 0.35127836 <a title="133-lda-9" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>10 0.34944147 <a title="133-lda-10" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>11 0.34653699 <a title="133-lda-11" href="./emnlp-2012-Mixed_Membership_Markov_Models_for_Unsupervised_Conversation_Modeling.html">89 emnlp-2012-Mixed Membership Markov Models for Unsupervised Conversation Modeling</a></p>
<p>12 0.34480432 <a title="133-lda-12" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>13 0.34445781 <a title="133-lda-13" href="./emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">23 emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>14 0.34441876 <a title="133-lda-14" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>15 0.34400049 <a title="133-lda-15" href="./emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">24 emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>16 0.34359032 <a title="133-lda-16" href="./emnlp-2012-Syntactic_Surprisal_Affects_Spoken_Word_Duration_in_Conversational_Contexts.html">122 emnlp-2012-Syntactic Surprisal Affects Spoken Word Duration in Conversational Contexts</a></p>
<p>17 0.34312859 <a title="133-lda-17" href="./emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">64 emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<p>18 0.34307089 <a title="133-lda-18" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>19 0.3413372 <a title="133-lda-19" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>20 0.34113201 <a title="133-lda-20" href="./emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">70 emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
