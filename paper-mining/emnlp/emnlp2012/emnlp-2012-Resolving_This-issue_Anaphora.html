<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>113 emnlp-2012-Resolving This-issue Anaphora</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-113" href="#">emnlp2012-113</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>113 emnlp-2012-Resolving This-issue Anaphora</h1>
<br/><p>Source: <a title="emnlp-2012-113-pdf" href="http://aclweb.org/anthology//D/D12/D12-1115.pdf">pdf</a></p><p>Author: Varada Kolhatkar ; Graeme Hirst</p><p>Abstract: We annotate and resolve a particular case of abstract anaphora, namely, thisissue anaphora. We propose a candidate ranking model for this-issue anaphora resolution that explores different issuespecific and general abstract-anaphora features. The model is not restricted to nominal or verbal antecedents; rather, it is able to identify antecedents that are arbitrary spans of text. Our results show that (a) the model outperforms the strong adjacent-sentence baseline; (b) general abstract-anaphora features, as distinguished from issue-specific features, play a crucial role in this-issue anaphora resolution, suggesting that our approach can be generalized for other NPs such as this problem and this debate; and (c) it is possible to reduce the search space in order to improve performance.</p><p>Reference: <a title="emnlp-2012-113-reference" href="../emnlp2012_reference/emnlp-2012-Resolving_This-issue_Anaphora_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('antec', 0.635), ('anaphor', 0.487), ('anaph', 0.313), ('resolv', 0.19), ('candid', 0.157), ('frll', 0.125), ('poesio', 0.086), ('issu', 0.079), ('nomin', 0.078), ('sr', 0.072), ('ip', 0.06), ('medlin', 0.06), ('constitu', 0.056), ('iverb', 0.055), ('prll', 0.055), ('rrll', 0.055), ('signal', 0.055), ('claus', 0.054), ('annot', 0.052), ('discours', 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="113-tfidf-1" href="./emnlp-2012-Resolving_This-issue_Anaphora.html">113 emnlp-2012-Resolving This-issue Anaphora</a></p>
<p>Author: Varada Kolhatkar ; Graeme Hirst</p><p>Abstract: We annotate and resolve a particular case of abstract anaphora, namely, thisissue anaphora. We propose a candidate ranking model for this-issue anaphora resolution that explores different issuespecific and general abstract-anaphora features. The model is not restricted to nominal or verbal antecedents; rather, it is able to identify antecedents that are arbitrary spans of text. Our results show that (a) the model outperforms the strong adjacent-sentence baseline; (b) general abstract-anaphora features, as distinguished from issue-specific features, play a crucial role in this-issue anaphora resolution, suggesting that our approach can be generalized for other NPs such as this problem and this debate; and (c) it is possible to reduce the search space in order to improve performance.</p><p>2 0.51230985 <a title="113-tfidf-2" href="./emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">112 emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>Author: Altaf Rahman ; Vincent Ng</p><p>Abstract: We examine the task of resolving complex cases of definite pronouns, specifically those for which traditional linguistic constraints on coreference (e.g., Binding Constraints, gender and number agreement) as well as commonly-used resolution heuristics (e.g., string-matching facilities, syntactic salience) are not useful. Being able to solve this task has broader implications in artificial intelligence: a restricted version of it, sometimes referred to as the Winograd Schema Challenge, has been suggested as a conceptually and practically appealing alternative to the Turing Test. We employ a knowledge-rich approach to this task, which yields a pronoun resolver that outperforms state-of-the-art resolvers by nearly 18 points in accuracy on our dataset.</p><p>3 0.11279811 <a title="113-tfidf-3" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>4 0.091138877 <a title="113-tfidf-4" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>Author: Yang Song ; Jing Jiang ; Wayne Xin Zhao ; Sujian Li ; Houfeng Wang</p><p>Abstract: Pairwise coreference resolution models must merge pairwise coreference decisions to generate final outputs. Traditional merging methods adopt different strategies such as the bestfirst method and enforcing the transitivity constraint, but most of these methods are used independently of the pairwise learning methods as an isolated inference procedure at the end. We propose a joint learning model which combines pairwise classification and mention clustering with Markov logic. Experimental results show that our joint learning system outperforms independent learning systems. Our system gives a better performance than all the learning-based systems from the CoNLL-201 1shared task on the same dataset. Compared with the best system from CoNLL2011, which employs a rule-based method, our system shows competitive performance.</p><p>5 0.072603703 <a title="113-tfidf-5" href="./emnlp-2012-Parser_Showdown_at_the_Wall_Street_Corral%3A_An_Empirical_Investigation_of_Error_Types_in_Parser_Output.html">105 emnlp-2012-Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</a></p>
<p>Author: Jonathan K. Kummerfeld ; David Hall ; James R. Curran ; Dan Klein</p><p>Abstract: Constituency parser performance is primarily interpreted through a single metric, F-score on WSJ section 23, that conveys no linguistic information regarding the remaining errors. We classify errors within a set of linguistically meaningful types using tree transformations that repair groups of errors together. We use this analysis to answer a range of questions about parser behaviour, including what linguistic constructions are difficult for stateof-the-art parsers, what types of errors are being resolved by rerankers, and what types are introduced when parsing out-of-domain text.</p><p>6 0.062187172 <a title="113-tfidf-6" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>7 0.056389775 <a title="113-tfidf-7" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>8 0.053002995 <a title="113-tfidf-8" href="./emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">36 emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>9 0.051631909 <a title="113-tfidf-9" href="./emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">82 emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>10 0.051513214 <a title="113-tfidf-10" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>11 0.047252644 <a title="113-tfidf-11" href="./emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">76 emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>12 0.045443416 <a title="113-tfidf-12" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>13 0.043214083 <a title="113-tfidf-13" href="./emnlp-2012-Part-of-Speech_Tagging_for_Chinese-English_Mixed_Texts_with_Dynamic_Features.html">106 emnlp-2012-Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features</a></p>
<p>14 0.042681463 <a title="113-tfidf-14" href="./emnlp-2012-Unified_Dependency_Parsing_of_Chinese_Morphological_and_Syntactic_Structures.html">131 emnlp-2012-Unified Dependency Parsing of Chinese Morphological and Syntactic Structures</a></p>
<p>15 0.042027831 <a title="113-tfidf-15" href="./emnlp-2012-Improving_NLP_through_Marginalization_of_Hidden_Syntactic_Structure.html">65 emnlp-2012-Improving NLP through Marginalization of Hidden Syntactic Structure</a></p>
<p>16 0.041285951 <a title="113-tfidf-16" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>17 0.041151304 <a title="113-tfidf-17" href="./emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">85 emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>18 0.040903043 <a title="113-tfidf-18" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>19 0.039649371 <a title="113-tfidf-19" href="./emnlp-2012-Exploiting_Reducibility_in_Unsupervised_Dependency_Parsing.html">46 emnlp-2012-Exploiting Reducibility in Unsupervised Dependency Parsing</a></p>
<p>20 0.039020386 <a title="113-tfidf-20" href="./emnlp-2012-Training_Factored_PCFGs_with_Expectation_Propagation.html">126 emnlp-2012-Training Factored PCFGs with Expectation Propagation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.169), (1, 0.16), (2, 0.026), (3, 0.151), (4, -0.045), (5, -0.236), (6, -0.032), (7, -0.1), (8, 0.09), (9, -0.09), (10, -0.185), (11, 0.231), (12, 0.279), (13, -0.074), (14, 0.294), (15, 0.067), (16, -0.028), (17, 0.007), (18, -0.173), (19, -0.009), (20, -0.046), (21, -0.19), (22, 0.099), (23, 0.125), (24, -0.28), (25, -0.067), (26, 0.107), (27, -0.054), (28, 0.29), (29, 0.217), (30, 0.014), (31, -0.005), (32, -0.056), (33, -0.044), (34, -0.001), (35, 0.012), (36, 0.029), (37, -0.044), (38, -0.035), (39, -0.095), (40, 0.054), (41, 0.024), (42, -0.054), (43, -0.021), (44, -0.009), (45, -0.075), (46, -0.06), (47, -0.005), (48, -0.014), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94695377 <a title="113-lsi-1" href="./emnlp-2012-Resolving_This-issue_Anaphora.html">113 emnlp-2012-Resolving This-issue Anaphora</a></p>
<p>Author: Varada Kolhatkar ; Graeme Hirst</p><p>Abstract: We annotate and resolve a particular case of abstract anaphora, namely, thisissue anaphora. We propose a candidate ranking model for this-issue anaphora resolution that explores different issuespecific and general abstract-anaphora features. The model is not restricted to nominal or verbal antecedents; rather, it is able to identify antecedents that are arbitrary spans of text. Our results show that (a) the model outperforms the strong adjacent-sentence baseline; (b) general abstract-anaphora features, as distinguished from issue-specific features, play a crucial role in this-issue anaphora resolution, suggesting that our approach can be generalized for other NPs such as this problem and this debate; and (c) it is possible to reduce the search space in order to improve performance.</p><p>2 0.85567063 <a title="113-lsi-2" href="./emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">112 emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>Author: Altaf Rahman ; Vincent Ng</p><p>Abstract: We examine the task of resolving complex cases of definite pronouns, specifically those for which traditional linguistic constraints on coreference (e.g., Binding Constraints, gender and number agreement) as well as commonly-used resolution heuristics (e.g., string-matching facilities, syntactic salience) are not useful. Being able to solve this task has broader implications in artificial intelligence: a restricted version of it, sometimes referred to as the Winograd Schema Challenge, has been suggested as a conceptually and practically appealing alternative to the Turing Test. We employ a knowledge-rich approach to this task, which yields a pronoun resolver that outperforms state-of-the-art resolvers by nearly 18 points in accuracy on our dataset.</p><p>3 0.19625676 <a title="113-lsi-3" href="./emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">85 emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>Author: Vivi Nastase ; Alex Judea ; Katja Markert ; Michael Strube</p><p>Abstract: Computational approaches to metonymy resolution have focused almost exclusively on the local context, especially the constraints placed on a potentially metonymic word by its grammatical collocates. We expand such approaches by taking into account the larger context. Our algorithm is tested on the data from the metonymy resolution task (Task 8) at SemEval 2007. The results show that incorporation of the global context can improve over the use of the local context alone, depending on the types of metonymies addressed. As a second contribution, we move towards unsupervised resolution of metonymies, made feasible by considering ontological relations as possible readings. We show that such an unsupervised approach delivers promising results: it beats the supervised most frequent sense baseline and performs close to a supervised approach using only standard lexico-syntactic features.</p><p>4 0.18477798 <a title="113-lsi-4" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>5 0.15915422 <a title="113-lsi-5" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>Author: Hila Weisman ; Jonathan Berant ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Learning inference relations between verbs is at the heart of many semantic applications. However, most prior work on learning such rules focused on a rather narrow set of information sources: mainly distributional similarity, and to a lesser extent manually constructed verb co-occurrence patterns. In this paper, we claim that it is imperative to utilize information from various textual scopes: verb co-occurrence within a sentence, verb cooccurrence within a document, as well as overall corpus statistics. To this end, we propose a much richer novel set of linguistically motivated cues for detecting entailment between verbs and combine them as features in a supervised classification framework. We empirically demonstrate that our model significantly outperforms previous methods and that information from each textual scope contributes to the verb entailment learning task.</p><p>6 0.15393658 <a title="113-lsi-6" href="./emnlp-2012-Minimal_Dependency_Length_in_Realization_Ranking.html">88 emnlp-2012-Minimal Dependency Length in Realization Ranking</a></p>
<p>7 0.15359141 <a title="113-lsi-7" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>8 0.14815897 <a title="113-lsi-8" href="./emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">27 emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>9 0.13888429 <a title="113-lsi-9" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>10 0.13503675 <a title="113-lsi-10" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>11 0.13495277 <a title="113-lsi-11" href="./emnlp-2012-Extending_Machine_Translation_Evaluation_Metrics_with_Lexical_Cohesion_to_Document_Level.html">50 emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</a></p>
<p>12 0.13330278 <a title="113-lsi-12" href="./emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<p>13 0.13212408 <a title="113-lsi-13" href="./emnlp-2012-Parser_Showdown_at_the_Wall_Street_Corral%3A_An_Empirical_Investigation_of_Error_Types_in_Parser_Output.html">105 emnlp-2012-Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</a></p>
<p>14 0.13094361 <a title="113-lsi-14" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>15 0.1307725 <a title="113-lsi-15" href="./emnlp-2012-Lexical_Differences_in_Autobiographical_Narratives_from_Schizophrenic_Patients_and_Healthy_Controls.html">83 emnlp-2012-Lexical Differences in Autobiographical Narratives from Schizophrenic Patients and Healthy Controls</a></p>
<p>16 0.12636614 <a title="113-lsi-16" href="./emnlp-2012-Forest_Reranking_through_Subtree_Ranking.html">55 emnlp-2012-Forest Reranking through Subtree Ranking</a></p>
<p>17 0.12367521 <a title="113-lsi-17" href="./emnlp-2012-Training_Factored_PCFGs_with_Expectation_Propagation.html">126 emnlp-2012-Training Factored PCFGs with Expectation Propagation</a></p>
<p>18 0.12100546 <a title="113-lsi-18" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>19 0.1202376 <a title="113-lsi-19" href="./emnlp-2012-A_Sequence_Labelling_Approach_to_Quote_Attribution.html">9 emnlp-2012-A Sequence Labelling Approach to Quote Attribution</a></p>
<p>20 0.11747096 <a title="113-lsi-20" href="./emnlp-2012-Open_Language_Learning_for_Information_Extraction.html">100 emnlp-2012-Open Language Learning for Information Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.319), (9, 0.019), (21, 0.103), (30, 0.035), (31, 0.039), (38, 0.018), (43, 0.019), (46, 0.024), (48, 0.036), (55, 0.042), (59, 0.049), (61, 0.091), (73, 0.011), (80, 0.03), (82, 0.01), (85, 0.044), (91, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71227193 <a title="113-lda-1" href="./emnlp-2012-Resolving_This-issue_Anaphora.html">113 emnlp-2012-Resolving This-issue Anaphora</a></p>
<p>Author: Varada Kolhatkar ; Graeme Hirst</p><p>Abstract: We annotate and resolve a particular case of abstract anaphora, namely, thisissue anaphora. We propose a candidate ranking model for this-issue anaphora resolution that explores different issuespecific and general abstract-anaphora features. The model is not restricted to nominal or verbal antecedents; rather, it is able to identify antecedents that are arbitrary spans of text. Our results show that (a) the model outperforms the strong adjacent-sentence baseline; (b) general abstract-anaphora features, as distinguished from issue-specific features, play a crucial role in this-issue anaphora resolution, suggesting that our approach can be generalized for other NPs such as this problem and this debate; and (c) it is possible to reduce the search space in order to improve performance.</p><p>2 0.64629221 <a title="113-lda-2" href="./emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">96 emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<p>Author: Nicholas Andrews ; Jason Eisner ; Mark Dredze</p><p>Abstract: Many linguistic and textual processes involve transduction of strings. We show how to learn a stochastic transducer from an unorganized collection of strings (rather than string pairs). The role of the transducer is to organize the collection. Our generative model explains similarities among the strings by supposing that some strings in the collection were not generated ab initio, but were instead derived by transduction from other, “similar” strings in the collection. Our variational EM learning algorithm alternately reestimates this phylogeny and the transducer parameters. The final learned transducer can quickly link any test name into the final phylogeny, thereby locating variants of the test name. We find that our method can effectively find name variants in a corpus of web strings used to referto persons in Wikipedia, improving over standard untrained distances such as Jaro-Winkler and Levenshtein distance.</p><p>3 0.45103097 <a title="113-lda-3" href="./emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</a></p>
<p>Author: Mehmet Ali Yatbaz ; Enis Sert ; Deniz Yuret</p><p>Abstract: We investigate paradigmatic representations of word context in the domain of unsupervised syntactic category acquisition. Paradigmatic representations of word context are based on potential substitutes of a word in contrast to syntagmatic representations based on properties of neighboring words. We compare a bigram based baseline model with several paradigmatic models and demonstrate significant gains in accuracy. Our best model based on Euclidean co-occurrence embedding combines the paradigmatic context representation with morphological and orthographic features and achieves 80% many-to-one accuracy on a 45-tag 1M word corpus.</p><p>4 0.44456074 <a title="113-lda-4" href="./emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">112 emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>Author: Altaf Rahman ; Vincent Ng</p><p>Abstract: We examine the task of resolving complex cases of definite pronouns, specifically those for which traditional linguistic constraints on coreference (e.g., Binding Constraints, gender and number agreement) as well as commonly-used resolution heuristics (e.g., string-matching facilities, syntactic salience) are not useful. Being able to solve this task has broader implications in artificial intelligence: a restricted version of it, sometimes referred to as the Winograd Schema Challenge, has been suggested as a conceptually and practically appealing alternative to the Turing Test. We employ a knowledge-rich approach to this task, which yields a pronoun resolver that outperforms state-of-the-art resolvers by nearly 18 points in accuracy on our dataset.</p><p>5 0.43270224 <a title="113-lda-5" href="./emnlp-2012-Joint_Inference_for_Event_Timeline_Construction.html">72 emnlp-2012-Joint Inference for Event Timeline Construction</a></p>
<p>Author: Quang Do ; Wei Lu ; Dan Roth</p><p>Abstract: This paper addresses the task of constructing a timeline of events mentioned in a given text. To accomplish that, we present a novel representation of the temporal structure of a news article based on time intervals. We then present an algorithmic approach that jointly optimizes the temporal structure by coupling local classifiers that predict associations and temporal relations between pairs of temporal entities with global constraints. Moreover, we present ways to leverage knowledge provided by event coreference to further improve the system performance. Overall, our experiments show that the joint inference model significantly outperformed the local classifiers by 9.2% of relative improvement in F1. The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system.</p><p>6 0.43219924 <a title="113-lda-6" href="./emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">116 emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>7 0.42930472 <a title="113-lda-7" href="./emnlp-2012-First_Order_vs._Higher_Order_Modification_in_Distributional_Semantics.html">53 emnlp-2012-First Order vs. Higher Order Modification in Distributional Semantics</a></p>
<p>8 0.42586255 <a title="113-lda-8" href="./emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">4 emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>9 0.42473415 <a title="113-lda-9" href="./emnlp-2012-Framework_of_Automatic_Text_Summarization_Using_Reinforcement_Learning.html">56 emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</a></p>
<p>10 0.42339012 <a title="113-lda-10" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>11 0.42078969 <a title="113-lda-11" href="./emnlp-2012-Forest_Reranking_through_Subtree_Ranking.html">55 emnlp-2012-Forest Reranking through Subtree Ranking</a></p>
<p>12 0.41679627 <a title="113-lda-12" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>13 0.41599756 <a title="113-lda-13" href="./emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">136 emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>14 0.41333005 <a title="113-lda-14" href="./emnlp-2012-Employing_Compositional_Semantics_and_Discourse_Consistency_in_Chinese_Event_Extraction.html">38 emnlp-2012-Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction</a></p>
<p>15 0.41246426 <a title="113-lda-15" href="./emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">76 emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>16 0.41237757 <a title="113-lda-16" href="./emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">29 emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>17 0.40905434 <a title="113-lda-17" href="./emnlp-2012-A_Discriminative_Model_for_Query_Spelling_Correction_with_Latent_Structural_SVM.html">5 emnlp-2012-A Discriminative Model for Query Spelling Correction with Latent Structural SVM</a></p>
<p>18 0.40831694 <a title="113-lda-18" href="./emnlp-2012-Assessment_of_ESL_Learners%27_Syntactic_Competence_Based_on_Similarity_Measures.html">21 emnlp-2012-Assessment of ESL Learners' Syntactic Competence Based on Similarity Measures</a></p>
<p>19 0.40760475 <a title="113-lda-19" href="./emnlp-2012-Grounded_Models_of_Semantic_Representation.html">61 emnlp-2012-Grounded Models of Semantic Representation</a></p>
<p>20 0.40758345 <a title="113-lda-20" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
