<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>emnlp 2012 knowledge graph</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="#">emnlp2012</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>emnlp 2012 knowledge graph</h1>
<br/><h3>similar papers computed by tfidf model</h3><br/><h3>similar papers computed by <a title="lsi-model" href="./emnlp2012_lsi.html">lsi model</a></h3><br/><h3>similar papers computed by <a title="lda-model" href="./emnlp2012_lda.html">lda model</a></h3><br/><h2>papers list:</h2><p>1 <a title="emnlp-2012-1" href="../emnlp2012/emnlp-2012-A_Bayesian_Model_for_Learning_SCFGs_with_Discontiguous_Rules.html">emnlp-2012-A Bayesian Model for Learning SCFGs with Discontiguous Rules</a></p>
<p>Author: Abby Levenberg ; Chris Dyer ; Phil Blunsom</p><p>Abstract: We describe a nonparametric model and corresponding inference algorithm for learning Synchronous Context Free Grammar derivations for parallel text. The model employs a Pitman-Yor Process prior which uses a novel base distribution over synchronous grammar rules. Through both synthetic grammar induction and statistical machine translation experiments, we show that our model learns complex translational correspondences— including discontiguous, many-to-many alignments—and produces competitive translation results. Further, inference is efficient and we present results on significantly larger corpora than prior work.</p><p>2 <a title="emnlp-2012-2" href="../emnlp2012/emnlp-2012-A_Beam-Search_Decoder_for_Grammatical_Error_Correction.html">emnlp-2012-A Beam-Search Decoder for Grammatical Error Correction</a></p>
<p>Author: Daniel Dahlmeier ; Hwee Tou Ng</p><p>Abstract: We present a novel beam-search decoder for grammatical error correction. The decoder iteratively generates new hypothesis corrections from current hypotheses and scores them based on features of grammatical correctness and fluency. These features include scores from discriminative classifiers for specific error categories, such as articles and prepositions. Unlike all previous approaches, our method is able to perform correction of whole sentences with multiple and interacting errors while still taking advantage of powerful existing classifier approaches. Our decoder achieves an F1 correction score significantly higher than all previous published scores on the Helping Our Own (HOO) shared task data set.</p><p>3 <a title="emnlp-2012-3" href="../emnlp2012/emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>Author: Annie Louis ; Ani Nenkova</p><p>Abstract: We introduce a model of coherence which captures the intentional discourse structure in text. Our work is based on the hypothesis that syntax provides a proxy for the communicative goal of a sentence and therefore the sequence of sentences in a coherent discourse should exhibit detectable structural patterns. Results show that our method has high discriminating power for separating out coherent and incoherent news articles reaching accuracies of up to 90%. We also show that our syntactic patterns are correlated with manual annotations of intentional structure for academic conference articles and can successfully predict the coherence of abstract, introduction and related work sections of these articles. 59.3 (100.0) Intro 50.3 (100.0) 1166 Rel wk 55.4 (100.0) >= 0.663.8 (67.2)50.8 (71.1)58.6 (75.9) >= 0.7 67.2 (32.0) 54.4 (38.6) 63.3 (52.8) >= 0.8 74.0 (10.0) 51.6 (22.0) 63.0 (25.7) >= 0.9 91.7 (2.0) 30.6 (5.0) 68.1 (7.2) Table 9: Accuracy (% examples) above each confidence level for the conference versus workshop task. These results are shown in Table 9. The proportion of examples under each setting is also indicated. When only examples above 0.6 confidence are examined, the classifier has a higher accuracy of63.8% for abstracts and covers close to 70% of the examples. Similarly, when a cutoff of 0.7 is applied to the confidence for predicting related work sections, we achieve 63.3% accuracy for 53% of examples. So we can consider that 30 to 47% of the examples in the two sections respectively are harder to tell apart. Interestingly however even high confidence predictions on introductions remain incorrect. These results show that our model can successfully distinguish the structure of articles beyond just clearly incoherent permutation examples. 7 Conclusion Our work is the first to develop an unsupervised model for intentional structure and to show that it has good accuracy for coherence prediction and also complements entity and lexical structure of discourse. This result raises interesting questions about how patterns captured by these different coherence metrics vary and how they can be combined usefully for predicting coherence. We plan to explore these ideas in future work. We also want to analyze genre differences to understand if the strength of these coherence dimensions varies with genre. Acknowledgements This work is partially supported by a Google research grant and NSF CAREER 0953445 award. References Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computa- tional Linguistics, 34(1): 1–34. Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of NAACL-HLT, pages 113–120. Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL, pages 9–16. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL, pages 173–180. Jackie C.K. Cheung and Gerald Penn. 2010. Utilizing extra-sentential context for parsing. In Proceedings of EMNLP, pages 23–33. Christelle Cocco, Rapha ¨el Pittier, Fran ¸cois Bavaud, and Aris Xanthos. 2011. Segmentation and clustering of textual sequences: a typological approach. In Proceedings of RANLP, pages 427–433. Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 3 1:25–70. Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. Parscit: An open-source crf reference string parsing package. In Proceedings of LREC, pages 661–667. Micha Elsner and Eugene Charniak. 2008. Coreferenceinspired coherence modeling. In Proceedings of ACLHLT, Short Papers, pages 41–44. Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of ACL-HLT, pages 125–129. Micha Elsner, Joseph Austerweil, and Eugene Charniak. 2007. A unified local and global model for discourse coherence. In Proceedings of NAACL-HLT, pages 436–443. Pascale Fung and Grace Ngai. 2006. One story, one flow: Hidden markov story models for multilingual multidocument summarization. ACM Transactions on Speech and Language Processing, 3(2): 1–16. Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 3(12): 175–204. Yufan Guo, Anna Korhonen, and Thierry Poibeau. 2011. A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of EMNLP, pages 273–283. Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-HLT, pages 586–594, June. 1167 Nikiforos Karamanis, Chris Mellish, Massimo Poesio, and Jon Oberlander. 2009. Evaluating centering for information ordering using corpora. Computational Linguistics, 35(1):29–46. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL, pages 423–430. Mirella Lapata and Regina Barzilay. 2005. Automatic evaluation of text coherence: Models and representations. In Proceedings of IJCAI. Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL, pages 545–552. Maria Liakata and Larisa Soldatova. 2008. Guidelines for the annotation of general scientific concepts. JISC Project Report. Maria Liakata, Simone Teufel, Advaith Siddharthan, and Colin Batchelor. 2010. Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC. Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proceedings of EMNLP, pages 343–351. Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011. Automatically evaluating text coherence using discourse relations. In Proceedings of ACL-HLT, pages 997– 1006. Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330. Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP, pages 186–195. Dragomir R. Radev, Mark Thomas Joseph, Bryan Gibson, and Pradeep Muthukrishnan. 2009. A Bibliometric and Network Analysis ofthe field of Computational Linguistics. Journal of the American Society for Information Science and Technology. David Reitter, Johanna D. Moore, and Frank Keller. 2006. Priming of Syntactic Rules in Task-Oriented Dialogue and Spontaneous Conversation. In Proceedings of the 28th Annual Conference of the Cognitive Science Society, pages 685–690. Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Proceedings of the fifth conference on Applied natural language processing, pages 16–19. Radu Soricut and Daniel Marcu. 2006. Discourse generation using utility-trained coherence models. In Proceedings of COLING-ACL, pages 803–810. John Swales. 1990. Genre analysis: English in academic and research settings, volume 11. Cambridge University Press. Simone Teufel and Marc Moens. 2000. What’s yours and what’s mine: determining intellectual attribution in scientific text. In Proceedings of EMNLP, pages 9– 17. Simone Teufel, Jean Carletta, and Marc Moens. 1999. An annotation scheme for discourse-level argumentation in research articles. In Proceedings of EACL, pages 110–1 17. Ying Zhao, George Karypis, and Usama Fayyad. 2005. Hierarchical clustering algorithms for document datasets. Data Mining and Knowledge Discovery, 10: 141–168. 1168</p><p>4 <a title="emnlp-2012-4" href="../emnlp2012/emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>Author: William Blacoe ; Mirella Lapata</p><p>Abstract: In this paper we address the problem of modeling compositional meaning for phrases and sentences using distributional methods. We experiment with several possible combinations of representation and composition, exhibiting varying degrees of sophistication. Some are shallow while others operate over syntactic structure, rely on parameter learning, or require access to very large corpora. We find that shallow approaches are as good as more computationally intensive alternatives with regards to two particular tests: (1) phrase similarity and (2) paraphrase detection. The sizes of the involved training corpora and the generated vectors are not as important as the fit between the meaning representation and compositional method.</p><p>5 <a title="emnlp-2012-5" href="../emnlp2012/emnlp-2012-A_Discriminative_Model_for_Query_Spelling_Correction_with_Latent_Structural_SVM.html">emnlp-2012-A Discriminative Model for Query Spelling Correction with Latent Structural SVM</a></p>
<p>Author: Huizhong Duan ; Yanen Li ; ChengXiang Zhai ; Dan Roth</p><p>Abstract: Discriminative training in query spelling correction is difficult due to the complex internal structures of the data. Recent work on query spelling correction suggests a two stage approach a noisy channel model that is used to retrieve a number of candidate corrections, followed by discriminatively trained ranker applied to these candidates. The ranker, however, suffers from the fact the low recall of the first, suboptimal, search stage. This paper proposes to directly optimize the search stage with a discriminative model based on latent structural SVM. In this model, we treat query spelling correction as a multiclass classification problem with structured input and output. The latent structural information is used to model the alignment of words in the spelling correction process. Experiment results show that as a standalone speller, our model outperforms all the baseline systems. It also attains a higher recall compared with the noisy channel model, and can therefore serve as a better filtering stage when combined with a ranker.</p><p>6 <a title="emnlp-2012-6" href="../emnlp2012/emnlp-2012-A_New_Minimally-Supervised_Framework_for_Domain_Word_Sense_Disambiguation.html">emnlp-2012-A New Minimally-Supervised Framework for Domain Word Sense Disambiguation</a></p>
<p>Author: Stefano Faralli ; Roberto Navigli</p><p>Abstract: We present a new minimally-supervised framework for performing domain-driven Word Sense Disambiguation (WSD). Glossaries for several domains are iteratively acquired from the Web by means of a bootstrapping technique. The acquired glosses are then used as the sense inventory for fullyunsupervised domain WSD. Our experiments, on new and gold-standard datasets, show that our wide-coverage framework enables highperformance results on dozens of domains at a coarse and fine-grained level.</p><p>7 <a title="emnlp-2012-7" href="../emnlp2012/emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>Author: Shafiq Joty ; Giuseppe Carenini ; Raymond Ng</p><p>Abstract: We propose a complete probabilistic discriminative framework for performing sentencelevel discourse analysis. Our framework comprises a discourse segmenter, based on a binary classifier, and a discourse parser, which applies an optimal CKY-like parsing algorithm to probabilities inferred from a Dynamic Conditional Random Field. We show on two corpora that our approach outperforms the state-of-the-art, often by a wide margin.</p><p>8 <a title="emnlp-2012-8" href="../emnlp2012/emnlp-2012-A_Phrase-Discovering_Topic_Model_Using_Hierarchical_Pitman-Yor_Processes.html">emnlp-2012-A Phrase-Discovering Topic Model Using Hierarchical Pitman-Yor Processes</a></p>
<p>Author: Robert Lindsey ; William Headden ; Michael Stipicevic</p><p>Abstract: Topic models traditionally rely on the bagof-words assumption. In data mining applications, this often results in end-users being presented with inscrutable lists of topical unigrams, single words inferred as representative of their topics. In this article, we present a hierarchical generative probabilistic model of topical phrases. The model simultaneously infers the location, length, and topic of phrases within a corpus and relaxes the bagof-words assumption within phrases by using a hierarchy of Pitman-Yor processes. We use Markov chain Monte Carlo techniques for approximate inference in the model and perform slice sampling to learn its hyperparameters. We show via an experiment on human subjects that our model finds substantially better, more interpretable topical phrases than do competing models.</p><p>9 <a title="emnlp-2012-9" href="../emnlp2012/emnlp-2012-A_Sequence_Labelling_Approach_to_Quote_Attribution.html">emnlp-2012-A Sequence Labelling Approach to Quote Attribution</a></p>
<p>Author: Timothy O'Keefe ; Silvia Pareti ; James R. Curran ; Irena Koprinska ; Matthew Honnibal</p><p>Abstract: Quote extraction and attribution is the task of automatically extracting quotes from text and attributing each quote to its correct speaker. The present state-of-the-art system uses gold standard information from previous decisions in its features, which, when removed, results in a large drop in performance. We treat the problem as a sequence labelling task, which allows us to incorporate sequence features without using gold standard information. We present results on two new corpora and an augmented version of a third, achieving a new state-of-the-art for systems using only realistic features.</p><p>10 <a title="emnlp-2012-10" href="../emnlp2012/emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<p>Author: Mathias Verbeke ; Vincent Van Asch ; Roser Morante ; Paolo Frasconi ; Walter Daelemans ; Luc De Raedt</p><p>Abstract: Evidence-based medicine is an approach whereby clinical decisions are supported by the best available findings gained from scientific research. This requires efficient access to such evidence. To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the socalled PICO criteria. This paper presents an approach to automatically annotate sentences in medical abstracts with these labels. Since both structural and sequential information are important for this classification task, we use kLog, a new language for statistical relational learning with kernels. Our results show a clear improvement with respect to state-of-the-art systems.</p><p>11 <a title="emnlp-2012-11" href="../emnlp2012/emnlp-2012-A_Systematic_Comparison_of_Phrase_Table_Pruning_Techniques.html">emnlp-2012-A Systematic Comparison of Phrase Table Pruning Techniques</a></p>
<p>Author: Richard Zens ; Daisy Stanton ; Peng Xu</p><p>Abstract: When trained on very large parallel corpora, the phrase table component of a machine translation system grows to consume vast computational resources. In this paper, we introduce a novel pruning criterion that places phrase table pruning on a sound theoretical foundation. Systematic experiments on four language pairs under various data conditions show that our principled approach is superior to existing ad hoc pruning methods.</p><p>12 <a title="emnlp-2012-12" href="../emnlp2012/emnlp-2012-A_Transition-Based_System_for_Joint_Part-of-Speech_Tagging_and_Labeled_Non-Projective_Dependency_Parsing.html">emnlp-2012-A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing</a></p>
<p>Author: Bernd Bohnet ; Joakim Nivre</p><p>Abstract: Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins. We present a transitionbased system for joint part-of-speech tagging and labeled dependency parsing with nonprojective trees. Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages.</p><p>13 <a title="emnlp-2012-13" href="../emnlp2012/emnlp-2012-A_Unified_Approach_to_Transliteration-based_Text_Input_with_Online_Spelling_Correction.html">emnlp-2012-A Unified Approach to Transliteration-based Text Input with Online Spelling Correction</a></p>
<p>Author: Hisami Suzuki ; Jianfeng Gao</p><p>Abstract: This paper presents an integrated, end-to-end approach to online spelling correction for text input. Online spelling correction refers to the spelling correction as you type, as opposed to post-editing. The online scenario is particularly important for languages that routinely use transliteration-based text input methods, such as Chinese and Japanese, because the desired target characters cannot be input at all unless they are in the list of candidates provided by an input method, and spelling errors prevent them from appearing in the list. For example, a user might type suesheng by mistake to mean xuesheng 学生 'student' in Chinese; existing input methods fail to convert this misspelled input to the desired target Chinese characters. In this paper, we propose a unified approach to the problem of spelling correction and transliteration-based character conversion using an approach inspired by the phrasebased statistical machine translation framework. At the phrase (substring) level, k most probable pinyin (Romanized Chinese) corrections are generated using a monotone decoder; at the sentence level, input pinyin strings are directly transliterated into target Chinese characters by a decoder using a loglinear model that refer to the features of both levels. A new method of automatically deriving parallel training data from user keystroke logs is also presented. Experiments on Chinese pinyin conversion show that our integrated method reduces the character error rate by 20% (from 8.9% to 7. 12%) over the previous state-of-the art based on a noisy channel model. 609 1</p><p>14 <a title="emnlp-2012-14" href="../emnlp2012/emnlp-2012-A_Weakly_Supervised_Model_for_Sentence-Level_Semantic_Orientation_Analysis_with_Multiple_Experts.html">emnlp-2012-A Weakly Supervised Model for Sentence-Level Semantic Orientation Analysis with Multiple Experts</a></p>
<p>Author: Lizhen Qu ; Rainer Gemulla ; Gerhard Weikum</p><p>Abstract: We propose the weakly supervised MultiExperts Model (MEM) for analyzing the semantic orientation of opinions expressed in natural language reviews. In contrast to most prior work, MEM predicts both opinion polarity and opinion strength at the level of individual sentences; such fine-grained analysis helps to understand better why users like or dislike the entity under review. A key challenge in this setting is that it is hard to obtain sentence-level training data for both polarity and strength. For this reason, MEM is weakly supervised: It starts with potentially noisy indicators obtained from coarse-grained training data (i.e., document-level ratings), a small set of diverse base predictors, and, if available, small amounts of fine-grained training data. We integrate these noisy indicators into a unified probabilistic framework using ideas from ensemble learning and graph-based semi-supervised learning. Our experiments indicate that MEM outperforms state-of-the-art methods by a significant margin.</p><p>15 <a title="emnlp-2012-15" href="../emnlp2012/emnlp-2012-Active_Learning_for_Imbalanced_Sentiment_Classification.html">emnlp-2012-Active Learning for Imbalanced Sentiment Classification</a></p>
<p>Author: Shoushan Li ; Shengfeng Ju ; Guodong Zhou ; Xiaojun Li</p><p>Abstract: Active learning is a promising way for sentiment classification to reduce the annotation cost. In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. This scenario posits new challenges to active learning. To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account. Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce humanannotation efforts. Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification. 1</p><p>16 <a title="emnlp-2012-16" href="../emnlp2012/emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>Author: Michael Roth ; Anette Frank</p><p>Abstract: Generating coherent discourse is an important aspect in natural language generation. Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.</p><p>17 <a title="emnlp-2012-17" href="../emnlp2012/emnlp-2012-An_%22AI_readability%22_Formula_for_French_as_a_Foreign_Language.html">emnlp-2012-An "AI readability" Formula for French as a Foreign Language</a></p>
<p>Author: Thomas Francois ; Cedrick Fairon</p><p>Abstract: This paper present a new readability formula for French as a foreign language (FFL), which relies on 46 textual features representative of the lexical, syntactic, and semantic levels as well as some of the specificities of the FFL context. We report comparisons between several techniques for feature selection and various learning algorithms. Our best model, based on support vector machines (SVM), significantly outperforms previous FFL formulas. We also found that semantic features behave poorly in our case, in contrast with some previous readability studies on English as a first language.</p><p>18 <a title="emnlp-2012-18" href="../emnlp2012/emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<p>Author: Taylor Berg-Kirkpatrick ; David Burkett ; Dan Klein</p><p>Abstract: We investigate two aspects of the empirical behavior of paired significance tests for NLP systems. First, when one system appears to outperform another, how does significance level relate in practice to the magnitude of the gain, to the size of the test set, to the similarity of the systems, and so on? Is it true that for each task there is a gain which roughly implies significance? We explore these issues across a range of NLP tasks using both large collections of past systems’ outputs and variants of single systems. Next, once significance levels are computed, how well does the standard i.i.d. notion of significance hold up in practical settings where future distributions are neither independent nor identically distributed, such as across domains? We explore this question using a range of test set variations for constituency parsing.</p><p>19 <a title="emnlp-2012-19" href="../emnlp2012/emnlp-2012-An_Entity-Topic_Model_for_Entity_Linking.html">emnlp-2012-An Entity-Topic Model for Entity Linking</a></p>
<p>Author: Xianpei Han ; Le Sun</p><p>Abstract: Entity Linking (EL) has received considerable attention in recent years. Given many name mentions in a document, the goal of EL is to predict their referent entities in a knowledge base. Traditionally, there have been two distinct directions of EL research: one focusing on the effects of mention’s context compatibility, assuming that “the referent entity of a mention is reflected by its context”; the other dealing with the effects of document’s topic coherence, assuming that “a mention ’s referent entity should be coherent with the document’ ’s main topics”. In this paper, we propose a generative model called entitytopic model, to effectively join the above two complementary directions together. By jointly modeling and exploiting the context compatibility, the topic coherence and the correlation between them, our model can – accurately link all mentions in a document using both the local information (including the words and the mentions in a document) and the global knowledge (including the topic knowledge, the entity context knowledge and the entity name knowledge). Experimental results demonstrate the effectiveness of the proposed model. 1</p><p>20 <a title="emnlp-2012-20" href="../emnlp2012/emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Tat-Seng Chua</p><p>Abstract: This paper proposes to generate appropriate answers for opinion questions about products by exploiting the hierarchical organization of consumer reviews. The hierarchy organizes product aspects as nodes following their parent-child relations. For each aspect, the reviews and corresponding opinions on this aspect are stored. We develop a new framework for opinion Questions Answering, which enables accurate question analysis and effective answer generation by making use the hierarchy. In particular, we first identify the (explicit/implicit) product aspects asked in the questions and their sub-aspects by referring to the hierarchy. We then retrieve the corresponding review fragments relevant to the aspects from the hierarchy. In order to gener- ate appropriate answers from the review fragments, we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects. We conduct evaluations on 11 popular products in four domains. The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products. Experimental results demonstrate the effectiveness of our approach.</p><p>21 <a title="emnlp-2012-21" href="../emnlp2012/emnlp-2012-Assessment_of_ESL_Learners%27_Syntactic_Competence_Based_on_Similarity_Measures.html">emnlp-2012-Assessment of ESL Learners' Syntactic Competence Based on Similarity Measures</a></p>
<p>22 <a title="emnlp-2012-22" href="../emnlp2012/emnlp-2012-Automatically_Constructing_a_Normalisation_Dictionary_for_Microblogs.html">emnlp-2012-Automatically Constructing a Normalisation Dictionary for Microblogs</a></p>
<p>23 <a title="emnlp-2012-23" href="../emnlp2012/emnlp-2012-Besting_the_Quiz_Master%3A_Crowdsourcing_Incremental_Classification_Games.html">emnlp-2012-Besting the Quiz Master: Crowdsourcing Incremental Classification Games</a></p>
<p>24 <a title="emnlp-2012-24" href="../emnlp2012/emnlp-2012-Biased_Representation_Learning_for_Domain_Adaptation.html">emnlp-2012-Biased Representation Learning for Domain Adaptation</a></p>
<p>25 <a title="emnlp-2012-25" href="../emnlp2012/emnlp-2012-Bilingual_Lexicon_Extraction_from_Comparable_Corpora_Using_Label_Propagation.html">emnlp-2012-Bilingual Lexicon Extraction from Comparable Corpora Using Label Propagation</a></p>
<p>26 <a title="emnlp-2012-26" href="../emnlp2012/emnlp-2012-Building_a_Lightweight_Semantic_Model_for_Unsupervised_Information_Extraction_on_Short_Listings.html">emnlp-2012-Building a Lightweight Semantic Model for Unsupervised Information Extraction on Short Listings</a></p>
<p>27 <a title="emnlp-2012-27" href="../emnlp2012/emnlp-2012-Characterizing_Stylistic_Elements_in_Syntactic_Structure.html">emnlp-2012-Characterizing Stylistic Elements in Syntactic Structure</a></p>
<p>28 <a title="emnlp-2012-28" href="../emnlp2012/emnlp-2012-Collocation_Polarity_Disambiguation_Using_Web-based_Pseudo_Contexts.html">emnlp-2012-Collocation Polarity Disambiguation Using Web-based Pseudo Contexts</a></p>
<p>29 <a title="emnlp-2012-29" href="../emnlp2012/emnlp-2012-Concurrent_Acquisition_of_Word_Meaning_and_Lexical_Categories.html">emnlp-2012-Concurrent Acquisition of Word Meaning and Lexical Categories</a></p>
<p>30 <a title="emnlp-2012-30" href="../emnlp2012/emnlp-2012-Constructing_Task-Specific_Taxonomies_for_Document_Collection_Browsing.html">emnlp-2012-Constructing Task-Specific Taxonomies for Document Collection Browsing</a></p>
<p>31 <a title="emnlp-2012-31" href="../emnlp2012/emnlp-2012-Cross-Lingual_Language_Modeling_with_Syntactic_Reordering_for_Low-Resource_Speech_Recognition.html">emnlp-2012-Cross-Lingual Language Modeling with Syntactic Reordering for Low-Resource Speech Recognition</a></p>
<p>32 <a title="emnlp-2012-32" href="../emnlp2012/emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>33 <a title="emnlp-2012-33" href="../emnlp2012/emnlp-2012-Discovering_Diverse_and_Salient_Threads_in_Document_Collections.html">emnlp-2012-Discovering Diverse and Salient Threads in Document Collections</a></p>
<p>34 <a title="emnlp-2012-34" href="../emnlp2012/emnlp-2012-Do_Neighbours_Help%3F_An_Exploration_of_Graph-based_Algorithms_for_Cross-domain_Sentiment_Classification.html">emnlp-2012-Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification</a></p>
<p>35 <a title="emnlp-2012-35" href="../emnlp2012/emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>36 <a title="emnlp-2012-36" href="../emnlp2012/emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>37 <a title="emnlp-2012-37" href="../emnlp2012/emnlp-2012-Dynamic_Programming_for_Higher_Order_Parsing_of_Gap-Minding_Trees.html">emnlp-2012-Dynamic Programming for Higher Order Parsing of Gap-Minding Trees</a></p>
<p>38 <a title="emnlp-2012-38" href="../emnlp2012/emnlp-2012-Employing_Compositional_Semantics_and_Discourse_Consistency_in_Chinese_Event_Extraction.html">emnlp-2012-Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction</a></p>
<p>39 <a title="emnlp-2012-39" href="../emnlp2012/emnlp-2012-Enlarging_Paraphrase_Collections_through_Generalization_and_Instantiation.html">emnlp-2012-Enlarging Paraphrase Collections through Generalization and Instantiation</a></p>
<p>40 <a title="emnlp-2012-40" href="../emnlp2012/emnlp-2012-Ensemble_Semantics_for_Large-scale_Unsupervised_Relation_Extraction.html">emnlp-2012-Ensemble Semantics for Large-scale Unsupervised Relation Extraction</a></p>
<p>41 <a title="emnlp-2012-41" href="../emnlp2012/emnlp-2012-Entity_based_QA_Retrieval.html">emnlp-2012-Entity based QA Retrieval</a></p>
<p>42 <a title="emnlp-2012-42" href="../emnlp2012/emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>43 <a title="emnlp-2012-43" href="../emnlp2012/emnlp-2012-Exact_Sampling_and_Decoding_in_High-Order_Hidden_Markov_Models.html">emnlp-2012-Exact Sampling and Decoding in High-Order Hidden Markov Models</a></p>
<p>44 <a title="emnlp-2012-44" href="../emnlp2012/emnlp-2012-Excitatory_or_Inhibitory%3A_A_New_Semantic_Orientation_Extracts_Contradiction_and_Causality_from_the_Web.html">emnlp-2012-Excitatory or Inhibitory: A New Semantic Orientation Extracts Contradiction and Causality from the Web</a></p>
<p>45 <a title="emnlp-2012-45" href="../emnlp2012/emnlp-2012-Exploiting_Chunk-level_Features_to_Improve_Phrase_Chunking.html">emnlp-2012-Exploiting Chunk-level Features to Improve Phrase Chunking</a></p>
<p>46 <a title="emnlp-2012-46" href="../emnlp2012/emnlp-2012-Exploiting_Reducibility_in_Unsupervised_Dependency_Parsing.html">emnlp-2012-Exploiting Reducibility in Unsupervised Dependency Parsing</a></p>
<p>47 <a title="emnlp-2012-47" href="../emnlp2012/emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>48 <a title="emnlp-2012-48" href="../emnlp2012/emnlp-2012-Exploring_Adaptor_Grammars_for_Native_Language_Identification.html">emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</a></p>
<p>49 <a title="emnlp-2012-49" href="../emnlp2012/emnlp-2012-Exploring_Topic_Coherence_over_Many_Models_and_Many_Topics.html">emnlp-2012-Exploring Topic Coherence over Many Models and Many Topics</a></p>
<p>50 <a title="emnlp-2012-50" href="../emnlp2012/emnlp-2012-Extending_Machine_Translation_Evaluation_Metrics_with_Lexical_Cohesion_to_Document_Level.html">emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</a></p>
<p>51 <a title="emnlp-2012-51" href="../emnlp2012/emnlp-2012-Extracting_Opinion_Expressions_with_semi-Markov_Conditional_Random_Fields.html">emnlp-2012-Extracting Opinion Expressions with semi-Markov Conditional Random Fields</a></p>
<p>52 <a title="emnlp-2012-52" href="../emnlp2012/emnlp-2012-Fast_Large-Scale_Approximate_Graph_Construction_for_NLP.html">emnlp-2012-Fast Large-Scale Approximate Graph Construction for NLP</a></p>
<p>53 <a title="emnlp-2012-53" href="../emnlp2012/emnlp-2012-First_Order_vs._Higher_Order_Modification_in_Distributional_Semantics.html">emnlp-2012-First Order vs. Higher Order Modification in Distributional Semantics</a></p>
<p>54 <a title="emnlp-2012-54" href="../emnlp2012/emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>55 <a title="emnlp-2012-55" href="../emnlp2012/emnlp-2012-Forest_Reranking_through_Subtree_Ranking.html">emnlp-2012-Forest Reranking through Subtree Ranking</a></p>
<p>56 <a title="emnlp-2012-56" href="../emnlp2012/emnlp-2012-Framework_of_Automatic_Text_Summarization_Using_Reinforcement_Learning.html">emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</a></p>
<p>57 <a title="emnlp-2012-57" href="../emnlp2012/emnlp-2012-Generalized_Higher-Order_Dependency_Parsing_with_Cube_Pruning.html">emnlp-2012-Generalized Higher-Order Dependency Parsing with Cube Pruning</a></p>
<p>58 <a title="emnlp-2012-58" href="../emnlp2012/emnlp-2012-Generalizing_Sub-sentential_Paraphrase_Acquisition_across_Original_Signal_Type_of_Text_Pairs.html">emnlp-2012-Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs</a></p>
<p>59 <a title="emnlp-2012-59" href="../emnlp2012/emnlp-2012-Generating_Non-Projective_Word_Order_in_Statistical_Linearization.html">emnlp-2012-Generating Non-Projective Word Order in Statistical Linearization</a></p>
<p>60 <a title="emnlp-2012-60" href="../emnlp2012/emnlp-2012-Generative_Goal-Driven_User_Simulation_for_Dialog_Management.html">emnlp-2012-Generative Goal-Driven User Simulation for Dialog Management</a></p>
<p>61 <a title="emnlp-2012-61" href="../emnlp2012/emnlp-2012-Grounded_Models_of_Semantic_Representation.html">emnlp-2012-Grounded Models of Semantic Representation</a></p>
<p>62 <a title="emnlp-2012-62" href="../emnlp2012/emnlp-2012-Identifying_Constant_and_Unique_Relations_by_using_Time-Series_Text.html">emnlp-2012-Identifying Constant and Unique Relations by using Time-Series Text</a></p>
<p>63 <a title="emnlp-2012-63" href="../emnlp2012/emnlp-2012-Identifying_Event-related_Bursts_via_Social_Media_Activities.html">emnlp-2012-Identifying Event-related Bursts via Social Media Activities</a></p>
<p>64 <a title="emnlp-2012-64" href="../emnlp2012/emnlp-2012-Improved_Parsing_and_POS_Tagging_Using_Inter-Sentence_Consistency_Constraints.html">emnlp-2012-Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints</a></p>
<p>65 <a title="emnlp-2012-65" href="../emnlp2012/emnlp-2012-Improving_NLP_through_Marginalization_of_Hidden_Syntactic_Structure.html">emnlp-2012-Improving NLP through Marginalization of Hidden Syntactic Structure</a></p>
<p>66 <a title="emnlp-2012-66" href="../emnlp2012/emnlp-2012-Improving_Transition-Based_Dependency_Parsing_with_Buffer_Transitions.html">emnlp-2012-Improving Transition-Based Dependency Parsing with Buffer Transitions</a></p>
<p>67 <a title="emnlp-2012-67" href="../emnlp2012/emnlp-2012-Inducing_a_Discriminative_Parser_to_Optimize_Machine_Translation_Reordering.html">emnlp-2012-Inducing a Discriminative Parser to Optimize Machine Translation Reordering</a></p>
<p>68 <a title="emnlp-2012-68" href="../emnlp2012/emnlp-2012-Iterative_Annotation_Transformation_with_Predict-Self_Reestimation_for_Chinese_Word_Segmentation.html">emnlp-2012-Iterative Annotation Transformation with Predict-Self Reestimation for Chinese Word Segmentation</a></p>
<p>69 <a title="emnlp-2012-69" href="../emnlp2012/emnlp-2012-Joining_Forces_Pays_Off%3A_Multilingual_Joint_Word_Sense_Disambiguation.html">emnlp-2012-Joining Forces Pays Off: Multilingual Joint Word Sense Disambiguation</a></p>
<p>70 <a title="emnlp-2012-70" href="../emnlp2012/emnlp-2012-Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">emnlp-2012-Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>71 <a title="emnlp-2012-71" href="../emnlp2012/emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>72 <a title="emnlp-2012-72" href="../emnlp2012/emnlp-2012-Joint_Inference_for_Event_Timeline_Construction.html">emnlp-2012-Joint Inference for Event Timeline Construction</a></p>
<p>73 <a title="emnlp-2012-73" href="../emnlp2012/emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>74 <a title="emnlp-2012-74" href="../emnlp2012/emnlp-2012-Language_Model_Rest_Costs_and_Space-Efficient_Storage.html">emnlp-2012-Language Model Rest Costs and Space-Efficient Storage</a></p>
<p>75 <a title="emnlp-2012-75" href="../emnlp2012/emnlp-2012-Large_Scale_Decipherment_for_Out-of-Domain_Machine_Translation.html">emnlp-2012-Large Scale Decipherment for Out-of-Domain Machine Translation</a></p>
<p>76 <a title="emnlp-2012-76" href="../emnlp2012/emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>77 <a title="emnlp-2012-77" href="../emnlp2012/emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>78 <a title="emnlp-2012-78" href="../emnlp2012/emnlp-2012-Learning_Lexicon_Models_from_Search_Logs_for_Query_Expansion.html">emnlp-2012-Learning Lexicon Models from Search Logs for Query Expansion</a></p>
<p>79 <a title="emnlp-2012-79" href="../emnlp2012/emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</a></p>
<p>80 <a title="emnlp-2012-80" href="../emnlp2012/emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>81 <a title="emnlp-2012-81" href="../emnlp2012/emnlp-2012-Learning_to_Map_into_a_Universal_POS_Tagset.html">emnlp-2012-Learning to Map into a Universal POS Tagset</a></p>
<p>82 <a title="emnlp-2012-82" href="../emnlp2012/emnlp-2012-Left-to-Right_Tree-to-String_Decoding_with_Prediction.html">emnlp-2012-Left-to-Right Tree-to-String Decoding with Prediction</a></p>
<p>83 <a title="emnlp-2012-83" href="../emnlp2012/emnlp-2012-Lexical_Differences_in_Autobiographical_Narratives_from_Schizophrenic_Patients_and_Healthy_Controls.html">emnlp-2012-Lexical Differences in Autobiographical Narratives from Schizophrenic Patients and Healthy Controls</a></p>
<p>84 <a title="emnlp-2012-84" href="../emnlp2012/emnlp-2012-Linking_Named_Entities_to_Any_Database.html">emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>85 <a title="emnlp-2012-85" href="../emnlp2012/emnlp-2012-Local_and_Global_Context_for_Supervised_and_Unsupervised_Metonymy_Resolution.html">emnlp-2012-Local and Global Context for Supervised and Unsupervised Metonymy Resolution</a></p>
<p>86 <a title="emnlp-2012-86" href="../emnlp2012/emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<p>87 <a title="emnlp-2012-87" href="../emnlp2012/emnlp-2012-Lyrics%2C_Music%2C_and_Emotions.html">emnlp-2012-Lyrics, Music, and Emotions</a></p>
<p>88 <a title="emnlp-2012-88" href="../emnlp2012/emnlp-2012-Minimal_Dependency_Length_in_Realization_Ranking.html">emnlp-2012-Minimal Dependency Length in Realization Ranking</a></p>
<p>89 <a title="emnlp-2012-89" href="../emnlp2012/emnlp-2012-Mixed_Membership_Markov_Models_for_Unsupervised_Conversation_Modeling.html">emnlp-2012-Mixed Membership Markov Models for Unsupervised Conversation Modeling</a></p>
<p>90 <a title="emnlp-2012-90" href="../emnlp2012/emnlp-2012-Modelling_Sequential_Text_with_an_Adaptive_Topic_Model.html">emnlp-2012-Modelling Sequential Text with an Adaptive Topic Model</a></p>
<p>91 <a title="emnlp-2012-91" href="../emnlp2012/emnlp-2012-Monte_Carlo_MCMC%3A_Efficient_Inference_by_Approximate_Sampling.html">emnlp-2012-Monte Carlo MCMC: Efficient Inference by Approximate Sampling</a></p>
<p>92 <a title="emnlp-2012-92" href="../emnlp2012/emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>93 <a title="emnlp-2012-93" href="../emnlp2012/emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>94 <a title="emnlp-2012-94" href="../emnlp2012/emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>95 <a title="emnlp-2012-95" href="../emnlp2012/emnlp-2012-N-gram-based_Tense_Models_for_Statistical_Machine_Translation.html">emnlp-2012-N-gram-based Tense Models for Statistical Machine Translation</a></p>
<p>96 <a title="emnlp-2012-96" href="../emnlp2012/emnlp-2012-Name_Phylogeny%3A_A_Generative_Model_of_String_Variation.html">emnlp-2012-Name Phylogeny: A Generative Model of String Variation</a></p>
<p>97 <a title="emnlp-2012-97" href="../emnlp2012/emnlp-2012-Natural_Language_Questions_for_the_Web_of_Data.html">emnlp-2012-Natural Language Questions for the Web of Data</a></p>
<p>98 <a title="emnlp-2012-98" href="../emnlp2012/emnlp-2012-No_Noun_Phrase_Left_Behind%3A_Detecting_and_Typing_Unlinkable_Entities.html">emnlp-2012-No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities</a></p>
<p>99 <a title="emnlp-2012-99" href="../emnlp2012/emnlp-2012-On_Amortizing_Inference_Cost_for_Structured_Prediction.html">emnlp-2012-On Amortizing Inference Cost for Structured Prediction</a></p>
<p>100 <a title="emnlp-2012-100" href="../emnlp2012/emnlp-2012-Open_Language_Learning_for_Information_Extraction.html">emnlp-2012-Open Language Learning for Information Extraction</a></p>
<p>101 <a title="emnlp-2012-101" href="../emnlp2012/emnlp-2012-Opinion_Target_Extraction_Using_Word-Based_Translation_Model.html">emnlp-2012-Opinion Target Extraction Using Word-Based Translation Model</a></p>
<p>102 <a title="emnlp-2012-102" href="../emnlp2012/emnlp-2012-Optimising_Incremental_Dialogue_Decisions_Using_Information_Density_for_Interactive_Systems.html">emnlp-2012-Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems</a></p>
<p>103 <a title="emnlp-2012-103" href="../emnlp2012/emnlp-2012-PATTY%3A_A_Taxonomy_of_Relational_Patterns_with_Semantic_Types.html">emnlp-2012-PATTY: A Taxonomy of Relational Patterns with Semantic Types</a></p>
<p>104 <a title="emnlp-2012-104" href="../emnlp2012/emnlp-2012-Parse%2C_Price_and_Cut-Delayed_Column_and_Row_Generation_for_Graph_Based_Parsers.html">emnlp-2012-Parse, Price and Cut-Delayed Column and Row Generation for Graph Based Parsers</a></p>
<p>105 <a title="emnlp-2012-105" href="../emnlp2012/emnlp-2012-Parser_Showdown_at_the_Wall_Street_Corral%3A_An_Empirical_Investigation_of_Error_Types_in_Parser_Output.html">emnlp-2012-Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</a></p>
<p>106 <a title="emnlp-2012-106" href="../emnlp2012/emnlp-2012-Part-of-Speech_Tagging_for_Chinese-English_Mixed_Texts_with_Dynamic_Features.html">emnlp-2012-Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features</a></p>
<p>107 <a title="emnlp-2012-107" href="../emnlp2012/emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>108 <a title="emnlp-2012-108" href="../emnlp2012/emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>109 <a title="emnlp-2012-109" href="../emnlp2012/emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>110 <a title="emnlp-2012-110" href="../emnlp2012/emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>111 <a title="emnlp-2012-111" href="../emnlp2012/emnlp-2012-Regularized_Interlingual_Projections%3A_Evaluation_on_Multilingual_Transliteration.html">emnlp-2012-Regularized Interlingual Projections: Evaluation on Multilingual Transliteration</a></p>
<p>112 <a title="emnlp-2012-112" href="../emnlp2012/emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>113 <a title="emnlp-2012-113" href="../emnlp2012/emnlp-2012-Resolving_This-issue_Anaphora.html">emnlp-2012-Resolving This-issue Anaphora</a></p>
<p>114 <a title="emnlp-2012-114" href="../emnlp2012/emnlp-2012-Revisiting_the_Predictability_of_Language%3A_Response_Completion_in_Social_Media.html">emnlp-2012-Revisiting the Predictability of Language: Response Completion in Social Media</a></p>
<p>115 <a title="emnlp-2012-115" href="../emnlp2012/emnlp-2012-SSHLDA%3A_A_Semi-Supervised_Hierarchical_Topic_Model.html">emnlp-2012-SSHLDA: A Semi-Supervised Hierarchical Topic Model</a></p>
<p>116 <a title="emnlp-2012-116" href="../emnlp2012/emnlp-2012-Semantic_Compositionality_through_Recursive_Matrix-Vector_Spaces.html">emnlp-2012-Semantic Compositionality through Recursive Matrix-Vector Spaces</a></p>
<p>117 <a title="emnlp-2012-117" href="../emnlp2012/emnlp-2012-Sketch_Algorithms_for_Estimating_Point_Queries_in_NLP.html">emnlp-2012-Sketch Algorithms for Estimating Point Queries in NLP</a></p>
<p>118 <a title="emnlp-2012-118" href="../emnlp2012/emnlp-2012-Source_Language_Adaptation_for_Resource-Poor_Machine_Translation.html">emnlp-2012-Source Language Adaptation for Resource-Poor Machine Translation</a></p>
<p>119 <a title="emnlp-2012-119" href="../emnlp2012/emnlp-2012-Spectral_Dependency_Parsing_with_Latent_Variables.html">emnlp-2012-Spectral Dependency Parsing with Latent Variables</a></p>
<p>120 <a title="emnlp-2012-120" href="../emnlp2012/emnlp-2012-Streaming_Analysis_of_Discourse_Participants.html">emnlp-2012-Streaming Analysis of Discourse Participants</a></p>
<p>121 <a title="emnlp-2012-121" href="../emnlp2012/emnlp-2012-Supervised_Text-based_Geolocation_Using_Language_Models_on_an_Adaptive_Grid.html">emnlp-2012-Supervised Text-based Geolocation Using Language Models on an Adaptive Grid</a></p>
<p>122 <a title="emnlp-2012-122" href="../emnlp2012/emnlp-2012-Syntactic_Surprisal_Affects_Spoken_Word_Duration_in_Conversational_Contexts.html">emnlp-2012-Syntactic Surprisal Affects Spoken Word Duration in Conversational Contexts</a></p>
<p>123 <a title="emnlp-2012-123" href="../emnlp2012/emnlp-2012-Syntactic_Transfer_Using_a_Bilingual_Lexicon.html">emnlp-2012-Syntactic Transfer Using a Bilingual Lexicon</a></p>
<p>124 <a title="emnlp-2012-124" href="../emnlp2012/emnlp-2012-Three_Dependency-and-Boundary_Models_for_Grammar_Induction.html">emnlp-2012-Three Dependency-and-Boundary Models for Grammar Induction</a></p>
<p>125 <a title="emnlp-2012-125" href="../emnlp2012/emnlp-2012-Towards_Efficient_Named-Entity_Rule_Induction_for_Customizability.html">emnlp-2012-Towards Efficient Named-Entity Rule Induction for Customizability</a></p>
<p>126 <a title="emnlp-2012-126" href="../emnlp2012/emnlp-2012-Training_Factored_PCFGs_with_Expectation_Propagation.html">emnlp-2012-Training Factored PCFGs with Expectation Propagation</a></p>
<p>127 <a title="emnlp-2012-127" href="../emnlp2012/emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>128 <a title="emnlp-2012-128" href="../emnlp2012/emnlp-2012-Translation_Model_Based_Cross-Lingual_Language_Model_Adaptation%3A_from_Word_Models_to_Phrase_Models.html">emnlp-2012-Translation Model Based Cross-Lingual Language Model Adaptation: from Word Models to Phrase Models</a></p>
<p>129 <a title="emnlp-2012-129" href="../emnlp2012/emnlp-2012-Type-Supervised_Hidden_Markov_Models_for_Part-of-Speech_Tagging_with_Incomplete_Tag_Dictionaries.html">emnlp-2012-Type-Supervised Hidden Markov Models for Part-of-Speech Tagging with Incomplete Tag Dictionaries</a></p>
<p>130 <a title="emnlp-2012-130" href="../emnlp2012/emnlp-2012-Unambiguity_Regularization_for_Unsupervised_Learning_of_Probabilistic_Grammars.html">emnlp-2012-Unambiguity Regularization for Unsupervised Learning of Probabilistic Grammars</a></p>
<p>131 <a title="emnlp-2012-131" href="../emnlp2012/emnlp-2012-Unified_Dependency_Parsing_of_Chinese_Morphological_and_Syntactic_Structures.html">emnlp-2012-Unified Dependency Parsing of Chinese Morphological and Syntactic Structures</a></p>
<p>132 <a title="emnlp-2012-132" href="../emnlp2012/emnlp-2012-Universal_Grapheme-to-Phoneme_Prediction_Over_Latin_Alphabets.html">emnlp-2012-Universal Grapheme-to-Phoneme Prediction Over Latin Alphabets</a></p>
<p>133 <a title="emnlp-2012-133" href="../emnlp2012/emnlp-2012-Unsupervised_PCFG_Induction_for_Grounded_Language_Learning_with_Highly_Ambiguous_Supervision.html">emnlp-2012-Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision</a></p>
<p>134 <a title="emnlp-2012-134" href="../emnlp2012/emnlp-2012-User_Demographics_and_Language_in_an_Implicit_Social_Network.html">emnlp-2012-User Demographics and Language in an Implicit Social Network</a></p>
<p>135 <a title="emnlp-2012-135" href="../emnlp2012/emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>136 <a title="emnlp-2012-136" href="../emnlp2012/emnlp-2012-Weakly_Supervised_Training_of_Semantic_Parsers.html">emnlp-2012-Weakly Supervised Training of Semantic Parsers</a></p>
<p>137 <a title="emnlp-2012-137" href="../emnlp2012/emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>138 <a title="emnlp-2012-138" href="../emnlp2012/emnlp-2012-Wiki-ly_Supervised_Part-of-Speech_Tagging.html">emnlp-2012-Wiki-ly Supervised Part-of-Speech Tagging</a></p>
<p>139 <a title="emnlp-2012-139" href="../emnlp2012/emnlp-2012-Word_Salad%3A_Relating_Food_Prices_and_Descriptions.html">emnlp-2012-Word Salad: Relating Food Prices and Descriptions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
