<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>emnlp 2011 knowledge graph</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="#">emnlp2011</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>emnlp 2011 knowledge graph</h1>
<br/><h3>similar papers computed by tfidf model</h3><br/><h3>similar papers computed by <a title="lsi-model" href="./emnlp2011_lsi.html">lsi model</a></h3><br/><h3>similar papers computed by <a title="lda-model" href="./emnlp2011_lda.html">lda model</a></h3><br/><h2>papers list:</h2><p>1 <a title="emnlp-2011-1" href="../emnlp2011/emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>Author: Christos Christodoulopoulos ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: In this paper we present a fully unsupervised syntactic class induction system formulated as a Bayesian multinomial mixture model, where each word type is constrained to belong to a single class. By using a mixture model rather than a sequence model (e.g., HMM), we are able to easily add multiple kinds of features, including those at both the type level (morphology features) and token level (context and alignment features, the latter from parallel corpora). Using only context features, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested.</p><p>2 <a title="emnlp-2011-2" href="../emnlp2011/emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>Author: Lukas Michelbacher ; Alok Kothari ; Martin Forst ; Christina Lioma ; Hinrich Schutze</p><p>Abstract: Most NLP systems use tokenization as part of preprocessing. Generally, tokenizers are based on simple heuristics and do not recognize multi-word units (MWUs) like hot dog or black hole unless a precompiled list of MWUs is available. In this paper, we propose a new cascaded model for detecting MWUs of arbitrary length for tokenization, focusing on noun phrases in the physics domain. We adopt a classification approach because unlike other work on MWUs – tokenization requires a completely automatic approach. We achieve an accuracy of 68% for recognizing non-compositional MWUs and show that our MWU recognizer improves retrieval performance when used as part of an information retrieval system. – 1</p><p>3 <a title="emnlp-2011-3" href="../emnlp2011/emnlp-2011-A_Correction_Model_for_Word_Alignments.html">emnlp-2011-A Correction Model for Word Alignments</a></p>
<p>Author: J. Scott McCarley ; Abraham Ittycheriah ; Salim Roukos ; Bing Xiang ; Jian-ming Xu</p><p>Abstract: Models of word alignment built as sequences of links have limited expressive power, but are easy to decode. Word aligners that model the alignment matrix can express arbitrary alignments, but are difficult to decode. We propose an alignment matrix model as a correction algorithm to an underlying sequencebased aligner. Then a greedy decoding algorithm enables the full expressive power of the alignment matrix formulation. Improved alignment performance is shown for all nine language pairs tested. The improved alignments also improved translation quality from Chinese to English and English to Italian.</p><p>4 <a title="emnlp-2011-4" href="../emnlp2011/emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>Author: Stephen Tratz ; Eduard Hovy</p><p>Abstract: Dependency parsers are critical components within many NLP systems. However, currently available dependency parsers each exhibit at least one of several weaknesses, including high running time, limited accuracy, vague dependency labels, and lack of nonprojectivity support. Furthermore, no commonly used parser provides additional shallow semantic interpretation, such as preposition sense disambiguation and noun compound interpretation. In this paper, we present a new dependency-tree conversion of the Penn Treebank along with its associated fine-grain dependency labels and a fast, accurate parser trained on it. We explain how a non-projective extension to shift-reduce parsing can be incorporated into non-directional easy-first parsing. The parser performs well when evaluated on the standard test section of the Penn Treebank, outperforming several popular open source dependency parsers; it is, to the best of our knowledge, the first dependency parser capable of parsing more than 75 sentences per second at over 93% accuracy.</p><p>5 <a title="emnlp-2011-5" href="../emnlp2011/emnlp-2011-A_Fast_Re-scoring_Strategy_to_Capture_Long-Distance_Dependencies.html">emnlp-2011-A Fast Re-scoring Strategy to Capture Long-Distance Dependencies</a></p>
<p>Author: Anoop Deoras ; Tomas Mikolov ; Kenneth Church</p><p>Abstract: A re-scoring strategy is proposed that makes it feasible to capture more long-distance dependencies in the natural language. Two pass strategies have become popular in a number of recognition tasks such as ASR (automatic speech recognition), MT (machine translation) and OCR (optical character recognition). The first pass typically applies a weak language model (n-grams) to a lattice and the second pass applies a stronger language model to N best lists. The stronger language model is intended to capture more longdistance dependencies. The proposed method uses RNN-LM (recurrent neural network language model), which is a long span LM, to rescore word lattices in the second pass. A hill climbing method (iterative decoding) is proposed to search over islands of confusability in the word lattice. An evaluation based on Broadcast News shows speedups of 20 over basic N best re-scoring, and word error rate reduction of 8% (relative) on a highly competitive setup.</p><p>6 <a title="emnlp-2011-6" href="../emnlp2011/emnlp-2011-A_Generate_and_Rank_Approach_to_Sentence_Paraphrasing.html">emnlp-2011-A Generate and Rank Approach to Sentence Paraphrasing</a></p>
<p>Author: Prodromos Malakasiotis ; Ion Androutsopoulos</p><p>Abstract: We present a method that paraphrases a given sentence by first generating candidate paraphrases and then ranking (or classifying) them. The candidates are generated by applying existing paraphrasing rules extracted from parallel corpora. The ranking component considers not only the overall quality of the rules that produced each candidate, but also the extent to which they preserve grammaticality and meaning in the particular context of the input sentence, as well as the degree to which the candidate differs from the input. We experimented with both a Maximum Entropy classifier and an SVR ranker. Experimental results show that incorporating features from an existing paraphrase recognizer in the ranking component improves performance, and that our overall method compares well against a state of the art paraphrase generator, when paraphrasing rules apply to the input sentences. We also propose a new methodology to evaluate the ranking components of generate-and-rank paraphrase generators, which evaluates them across different combinations of weights for grammaticality, meaning preservation, and diversity. The paper is accompanied by a paraphrasing dataset we constructed for evaluations of this kind.</p><p>7 <a title="emnlp-2011-7" href="../emnlp2011/emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>Author: Vivek Srikumar ; Dan Roth</p><p>Abstract: This paper presents a model that extends semantic role labeling. Existing approaches independently analyze relations expressed by verb predicates or those expressed as nominalizations. However, sentences express relations via other linguistic phenomena as well. Furthermore, these phenomena interact with each other, thus restricting the structures they articulate. In this paper, we use this intuition to define a joint inference model that captures the inter-dependencies between verb semantic role labeling and relations expressed using prepositions. The scarcity of jointly labeled data presents a crucial technical challenge for learning a joint model. The key strength of our model is that we use existing structure predictors as black boxes. By enforcing consistency constraints between their predictions, we show improvements in the performance of both tasks without retraining the individual models.</p><p>8 <a title="emnlp-2011-8" href="../emnlp2011/emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>Author: Amit Dubey ; Frank Keller ; Patrick Sturt</p><p>Abstract: This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chunker with a co-reference classifier. Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure. This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort. We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.</p><p>9 <a title="emnlp-2011-9" href="../emnlp2011/emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>Author: Chao Shen ; Tao Li</p><p>Abstract: In active dual supervision, not only informative examples but also features are selected for labeling to build a high quality classifier with low cost. However, how to measure the informativeness for both examples and feature on the same scale has not been well solved. In this paper, we propose a non-negative matrix factorization based approach to address this issue. We first extend the matrix factorization framework to explicitly model the corresponding relationships between feature classes and examples classes. Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled. Empirical results demonstrate the effectiveness of our proposed methods.</p><p>10 <a title="emnlp-2011-10" href="../emnlp2011/emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>Author: Wei Lu ; Hwee Tou Ng</p><p>Abstract: This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus. The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences. Sentences can then be generated based on such grammar rules with a log-linear model. To acquire such grammar rules automatically in an unsupervised manner, we also propose a novel approach with a generative model, which maps from sub-expressions of logical forms to word sequences in natural language sentences. Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.</p><p>11 <a title="emnlp-2011-11" href="../emnlp2011/emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>Author: Zhiyuan Liu ; Xinxiong Chen ; Maosong Sun</p><p>Abstract: It is popular for users in Web 2.0 era to freely annotate online resources with tags. To ease the annotation process, it has been great interest in automatic tag suggestion. We propose a method to suggest tags according to the text description of a resource. By considering both the description and tags of a given resource as summaries to the resource written in two languages, we adopt word alignment models in statistical machine translation to bridge their vocabulary gap. Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description. Experiments on real world datasets show that WTM is effective and robust compared with other methods. Moreover, WTM is relatively simple and efficient, which is practical for Web applications.</p><p>12 <a title="emnlp-2011-12" href="../emnlp2011/emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>Author: Yufan Guo ; Anna Korhonen ; Thierry Poibeau</p><p>Abstract: Documents Anna Korhonen Thierry Poibeau Computer Laboratory LaTTiCe, UMR8094 University of Cambridge, UK CNRS & ENS, France alk2 3 @ cam . ac .uk thierry .po ibeau @ ens . fr tific literature according to categories of information structure (or discourse, rhetorical, argumentative or Argumentative Zoning (AZ) analysis of the argumentative structure of a scientific paper has proved useful for a number of information access tasks. Current approaches to AZ rely on supervised machine learning (ML). – – Requiring large amounts of annotated data, these approaches are expensive to develop and port to different domains and tasks. A potential solution to this problem is to use weaklysupervised ML instead. We investigate the performance of four weakly-supervised classifiers on scientific abstract data annotated for multiple AZ classes. Our best classifier based on the combination of active learning and selftraining outperforms our best supervised classifier, yielding a high accuracy of 81% when using just 10% of the labeled data. This result suggests that weakly-supervised learning could be employed to improve the practical applicability and portability of AZ across different information access tasks.</p><p>13 <a title="emnlp-2011-13" href="../emnlp2011/emnlp-2011-A_Word_Reordering_Model_for_Improved_Machine_Translation.html">emnlp-2011-A Word Reordering Model for Improved Machine Translation</a></p>
<p>Author: Karthik Visweswariah ; Rajakrishnan Rajkumar ; Ankur Gandhe ; Ananthakrishnan Ramanathan ; Jiri Navratil</p><p>Abstract: Preordering of source side sentences has proved to be useful in improving statistical machine translation. Most work has used a parser in the source language along with rules to map the source language word order into the target language word order. The requirement to have a source language parser is a major drawback, which we seek to overcome in this paper. Instead of using a parser and then using rules to order the source side sentence we learn a model that can directly reorder source side sentences to match target word order using a small parallel corpus with highquality word alignments. Our model learns pairwise costs of a word immediately preced- ing another word. We use the Lin-Kernighan heuristic to find the best source reordering efficiently during training and testing and show that it suffices to provide good quality reordering. We show gains in translation performance based on our reordering model for translating from Hindi to English, Urdu to English (with a public dataset), and English to Hindi. For English to Hindi we show that our technique achieves better performance than a method that uses rules applied to the source side English parse.</p><p>14 <a title="emnlp-2011-14" href="../emnlp2011/emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>Author: Bryan Rink ; Sanda Harabagiu</p><p>Abstract: This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. The model discovers relation instances and their types by determining which context tokens express the relation. Additionally, the valid semantic classes for each type of relation are determined. We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. The discovered relations reveal some of the implicit semantic structure present in patient records.</p><p>15 <a title="emnlp-2011-15" href="../emnlp2011/emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>Author: Jun Xie ; Haitao Mi ; Qun Liu</p><p>Abstract: Dependency structure, as a first step towards semantics, is believed to be helpful to improve translation quality. However, previous works on dependency structure based models typically resort to insertion operations to complete translations, which make it difficult to specify ordering information in translation rules. In our model of this paper, we handle this problem by directly specifying the ordering information in head-dependents rules which represent the source side as head-dependents relations and the target side as strings. The head-dependents rules require only substitution operation, thus our model requires no heuristics or separate ordering models of the previous works to control the word order of translations. Large-scale experiments show that our model performs well on long distance reordering, and outperforms the state- of-the-art constituency-to-string model (+1.47 BLEU on average) and hierarchical phrasebased model (+0.46 BLEU on average) on two Chinese-English NIST test sets without resort to phrases or parse forest. For the first time, a source dependency structure based model catches up with and surpasses the state-of-theart translation models.</p><p>16 <a title="emnlp-2011-16" href="../emnlp2011/emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>Author: Federico Sangati ; Willem Zuidema</p><p>Abstract: We present a novel approach to Data-Oriented Parsing (DOP). Like other DOP models, our parser utilizes syntactic fragments of arbitrary size from a treebank to analyze new sentences, but, crucially, it uses only those which are encountered at least twice. This criterion allows us to work with a relatively small but representative set of fragments, which can be employed as the symbolic backbone of several probabilistic generative models. For parsing we define a transform-backtransform approach that allows us to use standard PCFG technology, making our results easily replicable. According to standard Parseval metrics, our best model is on par with many state-ofthe-art parsers, while offering some complementary benefits: a simple generative probability model, and an explicit representation of the larger units of grammar.</p><p>17 <a title="emnlp-2011-17" href="../emnlp2011/emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>Author: Florian Laws ; Christian Scheible ; Hinrich Schutze</p><p>Abstract: Supervised classification needs large amounts of annotated training data that is expensive to create. Two approaches that reduce the cost of annotation are active learning and crowdsourcing. However, these two approaches have not been combined successfully to date. We evaluate the utility of active learning in crowdsourcing on two tasks, named entity recognition and sentiment detection, and show that active learning outperforms random selection of annotation examples in a noisy crowdsourcing scenario.</p><p>18 <a title="emnlp-2011-18" href="../emnlp2011/emnlp-2011-Analyzing_Methods_for_Improving_Precision_of_Pivot_Based_Bilingual_Dictionaries.html">emnlp-2011-Analyzing Methods for Improving Precision of Pivot Based Bilingual Dictionaries</a></p>
<p>Author: Xabier Saralegi ; Iker Manterola ; Inaki San Vicente</p><p>Abstract: An A-C bilingual dictionary can be inferred by merging A-B and B-C dictionaries using B as pivot. However, polysemous pivot words often produce wrong translation candidates. This paper analyzes two methods for pruning wrong candidates: one based on exploiting the structure of the source dictionaries, and the other based on distributional similarity computed from comparable corpora. As both methods depend exclusively on easily available resources, they are well suited to less resourced languages. We studied whether these two techniques complement each other given that they are based on different paradigms. We also researched combining them by looking for the best adequacy depending on various application scenarios. ,</p><p>19 <a title="emnlp-2011-19" href="../emnlp2011/emnlp-2011-Approximate_Scalable_Bounded_Space_Sketch_for_Large_Data_NLP.html">emnlp-2011-Approximate Scalable Bounded Space Sketch for Large Data NLP</a></p>
<p>Author: Amit Goyal ; Hal Daume III</p><p>Abstract: We exploit sketch techniques, especially the Count-Min sketch, a memory, and time efficient framework which approximates the frequency of a word pair in the corpus without explicitly storing the word pair itself. These methods use hashing to deal with massive amounts of streaming text. We apply CountMin sketch to approximate word pair counts and exhibit their effectiveness on three important NLP tasks. Our experiments demonstrate that on all of the three tasks, we get performance comparable to Exact word pair counts setting and state-of-the-art system. Our method scales to 49 GB of unzipped web data using bounded space of 2 billion counters (8 GB memory).</p><p>20 <a title="emnlp-2011-20" href="../emnlp2011/emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>Author: Jiajun Zhang ; Feifei Zhai ; Chengqing Zong</p><p>Abstract: Due to its explicit modeling of the grammaticality of the output via target-side syntax, the string-to-tree model has been shown to be one of the most successful syntax-based translation models. However, a major limitation of this model is that it does not utilize any useful syntactic information on the source side. In this paper, we analyze the difficulties of incorporating source syntax in a string-totree model. We then propose a new way to use the source syntax in a fuzzy manner, both in source syntactic annotation and in rule matching. We further explore three algorithms in rule matching: 0-1 matching, likelihood matching, and deep similarity matching. Our method not only guarantees grammatical output with an explicit target tree, but also enables the system to choose the proper translation rules via fuzzy use of the source syntax. Our extensive experiments have shown significant improvements over the state-of-the-art string-to-tree system. 1</p><p>21 <a title="emnlp-2011-21" href="../emnlp2011/emnlp-2011-Bayesian_Checking_for_Topic_Models.html">emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>22 <a title="emnlp-2011-22" href="../emnlp2011/emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>23 <a title="emnlp-2011-23" href="../emnlp2011/emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p>24 <a title="emnlp-2011-24" href="../emnlp2011/emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>25 <a title="emnlp-2011-25" href="../emnlp2011/emnlp-2011-Cache-based_Document-level_Statistical_Machine_Translation.html">emnlp-2011-Cache-based Document-level Statistical Machine Translation</a></p>
<p>26 <a title="emnlp-2011-26" href="../emnlp2011/emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>27 <a title="emnlp-2011-27" href="../emnlp2011/emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>28 <a title="emnlp-2011-28" href="../emnlp2011/emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>29 <a title="emnlp-2011-29" href="../emnlp2011/emnlp-2011-Collaborative_Ranking%3A_A_Case_Study_on_Entity_Linking.html">emnlp-2011-Collaborative Ranking: A Case Study on Entity Linking</a></p>
<p>30 <a title="emnlp-2011-30" href="../emnlp2011/emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>31 <a title="emnlp-2011-31" href="../emnlp2011/emnlp-2011-Computation_of_Infix_Probabilities_for_Probabilistic_Context-Free_Grammars.html">emnlp-2011-Computation of Infix Probabilities for Probabilistic Context-Free Grammars</a></p>
<p>32 <a title="emnlp-2011-32" href="../emnlp2011/emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>33 <a title="emnlp-2011-33" href="../emnlp2011/emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>34 <a title="emnlp-2011-34" href="../emnlp2011/emnlp-2011-Corpus-Guided_Sentence_Generation_of_Natural_Images.html">emnlp-2011-Corpus-Guided Sentence Generation of Natural Images</a></p>
<p>35 <a title="emnlp-2011-35" href="../emnlp2011/emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>36 <a title="emnlp-2011-36" href="../emnlp2011/emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>37 <a title="emnlp-2011-37" href="../emnlp2011/emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>38 <a title="emnlp-2011-38" href="../emnlp2011/emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>39 <a title="emnlp-2011-39" href="../emnlp2011/emnlp-2011-Discovering_Morphological_Paradigms_from_Plain_Text_Using_a_Dirichlet_Process_Mixture_Model.html">emnlp-2011-Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model</a></p>
<p>40 <a title="emnlp-2011-40" href="../emnlp2011/emnlp-2011-Discovering_Relations_between_Noun_Categories.html">emnlp-2011-Discovering Relations between Noun Categories</a></p>
<p>41 <a title="emnlp-2011-41" href="../emnlp2011/emnlp-2011-Discriminating_Gender_on_Twitter.html">emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>42 <a title="emnlp-2011-42" href="../emnlp2011/emnlp-2011-Divide_and_Conquer%3A_Crowdsourcing_the_Creation_of_Cross-Lingual_Textual_Entailment_Corpora.html">emnlp-2011-Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora</a></p>
<p>43 <a title="emnlp-2011-43" href="../emnlp2011/emnlp-2011-Domain-Assisted_Product_Aspect_Hierarchy_Generation%3A_Towards_Hierarchical_Organization_of_Unstructured_Consumer_Reviews.html">emnlp-2011-Domain-Assisted Product Aspect Hierarchy Generation: Towards Hierarchical Organization of Unstructured Consumer Reviews</a></p>
<p>44 <a title="emnlp-2011-44" href="../emnlp2011/emnlp-2011-Domain_Adaptation_via_Pseudo_In-Domain_Data_Selection.html">emnlp-2011-Domain Adaptation via Pseudo In-Domain Data Selection</a></p>
<p>45 <a title="emnlp-2011-45" href="../emnlp2011/emnlp-2011-Dual_Decomposition_with_Many_Overlapping_Components.html">emnlp-2011-Dual Decomposition with Many Overlapping Components</a></p>
<p>46 <a title="emnlp-2011-46" href="../emnlp2011/emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>47 <a title="emnlp-2011-47" href="../emnlp2011/emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>48 <a title="emnlp-2011-48" href="../emnlp2011/emnlp-2011-Enhancing_Chinese_Word_Segmentation_Using_Unlabeled_Data.html">emnlp-2011-Enhancing Chinese Word Segmentation Using Unlabeled Data</a></p>
<p>49 <a title="emnlp-2011-49" href="../emnlp2011/emnlp-2011-Entire_Relaxation_Path_for_Maximum_Entropy_Problems.html">emnlp-2011-Entire Relaxation Path for Maximum Entropy Problems</a></p>
<p>50 <a title="emnlp-2011-50" href="../emnlp2011/emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>51 <a title="emnlp-2011-51" href="../emnlp2011/emnlp-2011-Exact_Decoding_of_Phrase-Based_Translation_Models_through_Lagrangian_Relaxation.html">emnlp-2011-Exact Decoding of Phrase-Based Translation Models through Lagrangian Relaxation</a></p>
<p>52 <a title="emnlp-2011-52" href="../emnlp2011/emnlp-2011-Exact_Inference_for_Generative_Probabilistic_Non-Projective_Dependency_Parsing.html">emnlp-2011-Exact Inference for Generative Probabilistic Non-Projective Dependency Parsing</a></p>
<p>53 <a title="emnlp-2011-53" href="../emnlp2011/emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>54 <a title="emnlp-2011-54" href="../emnlp2011/emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>55 <a title="emnlp-2011-55" href="../emnlp2011/emnlp-2011-Exploiting_Syntactic_and_Distributional_Information_for_Spelling_Correction_with_Web-Scale_N-gram_Models.html">emnlp-2011-Exploiting Syntactic and Distributional Information for Spelling Correction with Web-Scale N-gram Models</a></p>
<p>56 <a title="emnlp-2011-56" href="../emnlp2011/emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>57 <a title="emnlp-2011-57" href="../emnlp2011/emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>58 <a title="emnlp-2011-58" href="../emnlp2011/emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<p>59 <a title="emnlp-2011-59" href="../emnlp2011/emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>60 <a title="emnlp-2011-60" href="../emnlp2011/emnlp-2011-Feature-Rich_Language-Independent_Syntax-Based_Alignment_for_Statistical_Machine_Translation.html">emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</a></p>
<p>61 <a title="emnlp-2011-61" href="../emnlp2011/emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>62 <a title="emnlp-2011-62" href="../emnlp2011/emnlp-2011-Generating_Subsequent_Reference_in_Shared_Visual_Scenes%3A_Computation_vs_Re-Use.html">emnlp-2011-Generating Subsequent Reference in Shared Visual Scenes: Computation vs Re-Use</a></p>
<p>63 <a title="emnlp-2011-63" href="../emnlp2011/emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>64 <a title="emnlp-2011-64" href="../emnlp2011/emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>65 <a title="emnlp-2011-65" href="../emnlp2011/emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>66 <a title="emnlp-2011-66" href="../emnlp2011/emnlp-2011-Hierarchical_Phrase-based_Translation_Representations.html">emnlp-2011-Hierarchical Phrase-based Translation Representations</a></p>
<p>67 <a title="emnlp-2011-67" href="../emnlp2011/emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>68 <a title="emnlp-2011-68" href="../emnlp2011/emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>69 <a title="emnlp-2011-69" href="../emnlp2011/emnlp-2011-Identification_of_Multi-word_Expressions_by_Combining_Multiple_Linguistic_Information_Sources.html">emnlp-2011-Identification of Multi-word Expressions by Combining Multiple Linguistic Information Sources</a></p>
<p>70 <a title="emnlp-2011-70" href="../emnlp2011/emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>71 <a title="emnlp-2011-71" href="../emnlp2011/emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>72 <a title="emnlp-2011-72" href="../emnlp2011/emnlp-2011-Improved_Transliteration_Mining_Using_Graph_Reinforcement.html">emnlp-2011-Improved Transliteration Mining Using Graph Reinforcement</a></p>
<p>73 <a title="emnlp-2011-73" href="../emnlp2011/emnlp-2011-Improving_Bilingual_Projections_via_Sparse_Covariance_Matrices.html">emnlp-2011-Improving Bilingual Projections via Sparse Covariance Matrices</a></p>
<p>74 <a title="emnlp-2011-74" href="../emnlp2011/emnlp-2011-Inducing_Sentence_Structure_from_Parallel_Corpora_for_Reordering.html">emnlp-2011-Inducing Sentence Structure from Parallel Corpora for Reordering</a></p>
<p>75 <a title="emnlp-2011-75" href="../emnlp2011/emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>76 <a title="emnlp-2011-76" href="../emnlp2011/emnlp-2011-Language_Models_for_Machine_Translation%3A_Original_vs._Translated_Texts.html">emnlp-2011-Language Models for Machine Translation: Original vs. Translated Texts</a></p>
<p>77 <a title="emnlp-2011-77" href="../emnlp2011/emnlp-2011-Large-Scale_Cognate_Recovery.html">emnlp-2011-Large-Scale Cognate Recovery</a></p>
<p>78 <a title="emnlp-2011-78" href="../emnlp2011/emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>79 <a title="emnlp-2011-79" href="../emnlp2011/emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>80 <a title="emnlp-2011-80" href="../emnlp2011/emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>81 <a title="emnlp-2011-81" href="../emnlp2011/emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>82 <a title="emnlp-2011-82" href="../emnlp2011/emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>83 <a title="emnlp-2011-83" href="../emnlp2011/emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>84 <a title="emnlp-2011-84" href="../emnlp2011/emnlp-2011-Learning_the_Information_Status_of_Noun_Phrases_in_Spoken_Dialogues.html">emnlp-2011-Learning the Information Status of Noun Phrases in Spoken Dialogues</a></p>
<p>85 <a title="emnlp-2011-85" href="../emnlp2011/emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>86 <a title="emnlp-2011-86" href="../emnlp2011/emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>87 <a title="emnlp-2011-87" href="../emnlp2011/emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>88 <a title="emnlp-2011-88" href="../emnlp2011/emnlp-2011-Linear_Text_Segmentation_Using_Affinity_Propagation.html">emnlp-2011-Linear Text Segmentation Using Affinity Propagation</a></p>
<p>89 <a title="emnlp-2011-89" href="../emnlp2011/emnlp-2011-Linguistic_Redundancy_in_Twitter.html">emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>90 <a title="emnlp-2011-90" href="../emnlp2011/emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<p>91 <a title="emnlp-2011-91" href="../emnlp2011/emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>92 <a title="emnlp-2011-92" href="../emnlp2011/emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>93 <a title="emnlp-2011-93" href="../emnlp2011/emnlp-2011-Minimum_Imputed-Risk%3A_Unsupervised_Discriminative_Training_for_Machine_Translation.html">emnlp-2011-Minimum Imputed-Risk: Unsupervised Discriminative Training for Machine Translation</a></p>
<p>94 <a title="emnlp-2011-94" href="../emnlp2011/emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>95 <a title="emnlp-2011-95" href="../emnlp2011/emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>96 <a title="emnlp-2011-96" href="../emnlp2011/emnlp-2011-Multilayer_Sequence_Labeling.html">emnlp-2011-Multilayer Sequence Labeling</a></p>
<p>97 <a title="emnlp-2011-97" href="../emnlp2011/emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>98 <a title="emnlp-2011-98" href="../emnlp2011/emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>99 <a title="emnlp-2011-99" href="../emnlp2011/emnlp-2011-Non-parametric_Bayesian_Segmentation_of_Japanese_Noun_Phrases.html">emnlp-2011-Non-parametric Bayesian Segmentation of Japanese Noun Phrases</a></p>
<p>100 <a title="emnlp-2011-100" href="../emnlp2011/emnlp-2011-Optimal_Search_for_Minimum_Error_Rate_Training.html">emnlp-2011-Optimal Search for Minimum Error Rate Training</a></p>
<p>101 <a title="emnlp-2011-101" href="../emnlp2011/emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>102 <a title="emnlp-2011-102" href="../emnlp2011/emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>103 <a title="emnlp-2011-103" href="../emnlp2011/emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>104 <a title="emnlp-2011-104" href="../emnlp2011/emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>105 <a title="emnlp-2011-105" href="../emnlp2011/emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>106 <a title="emnlp-2011-106" href="../emnlp2011/emnlp-2011-Predicting_a_Scientific_Communitys_Response_to_an_Article.html">emnlp-2011-Predicting a Scientific Communitys Response to an Article</a></p>
<p>107 <a title="emnlp-2011-107" href="../emnlp2011/emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>108 <a title="emnlp-2011-108" href="../emnlp2011/emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>109 <a title="emnlp-2011-109" href="../emnlp2011/emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>110 <a title="emnlp-2011-110" href="../emnlp2011/emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>111 <a title="emnlp-2011-111" href="../emnlp2011/emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>112 <a title="emnlp-2011-112" href="../emnlp2011/emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>113 <a title="emnlp-2011-113" href="../emnlp2011/emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>114 <a title="emnlp-2011-114" href="../emnlp2011/emnlp-2011-Relation_Extraction_with_Relation_Topics.html">emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>115 <a title="emnlp-2011-115" href="../emnlp2011/emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>116 <a title="emnlp-2011-116" href="../emnlp2011/emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>117 <a title="emnlp-2011-117" href="../emnlp2011/emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>118 <a title="emnlp-2011-118" href="../emnlp2011/emnlp-2011-SMT_Helps_Bitext_Dependency_Parsing.html">emnlp-2011-SMT Helps Bitext Dependency Parsing</a></p>
<p>119 <a title="emnlp-2011-119" href="../emnlp2011/emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>120 <a title="emnlp-2011-120" href="../emnlp2011/emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>121 <a title="emnlp-2011-121" href="../emnlp2011/emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<p>122 <a title="emnlp-2011-122" href="../emnlp2011/emnlp-2011-Simple_Effective_Decipherment_via_Combinatorial_Optimization.html">emnlp-2011-Simple Effective Decipherment via Combinatorial Optimization</a></p>
<p>123 <a title="emnlp-2011-123" href="../emnlp2011/emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>124 <a title="emnlp-2011-124" href="../emnlp2011/emnlp-2011-Splitting_Noun_Compounds_via_Monolingual_and_Bilingual_Paraphrasing%3A_A_Study_on_Japanese_Katakana_Words.html">emnlp-2011-Splitting Noun Compounds via Monolingual and Bilingual Paraphrasing: A Study on Japanese Katakana Words</a></p>
<p>125 <a title="emnlp-2011-125" href="../emnlp2011/emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>126 <a title="emnlp-2011-126" href="../emnlp2011/emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>127 <a title="emnlp-2011-127" href="../emnlp2011/emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<p>128 <a title="emnlp-2011-128" href="../emnlp2011/emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>129 <a title="emnlp-2011-129" href="../emnlp2011/emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>130 <a title="emnlp-2011-130" href="../emnlp2011/emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>131 <a title="emnlp-2011-131" href="../emnlp2011/emnlp-2011-Syntactic_Decision_Tree_LMs%3A_Random_Selection_or_Intelligent_Design%3F.html">emnlp-2011-Syntactic Decision Tree LMs: Random Selection or Intelligent Design?</a></p>
<p>132 <a title="emnlp-2011-132" href="../emnlp2011/emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>133 <a title="emnlp-2011-133" href="../emnlp2011/emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>134 <a title="emnlp-2011-134" href="../emnlp2011/emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>135 <a title="emnlp-2011-135" href="../emnlp2011/emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>136 <a title="emnlp-2011-136" href="../emnlp2011/emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>137 <a title="emnlp-2011-137" href="../emnlp2011/emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>138 <a title="emnlp-2011-138" href="../emnlp2011/emnlp-2011-Tuning_as_Ranking.html">emnlp-2011-Tuning as Ranking</a></p>
<p>139 <a title="emnlp-2011-139" href="../emnlp2011/emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>140 <a title="emnlp-2011-140" href="../emnlp2011/emnlp-2011-Universal_Morphological_Analysis_using_Structured_Nearest_Neighbor_Prediction.html">emnlp-2011-Universal Morphological Analysis using Structured Nearest Neighbor Prediction</a></p>
<p>141 <a title="emnlp-2011-141" href="../emnlp2011/emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>142 <a title="emnlp-2011-142" href="../emnlp2011/emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>143 <a title="emnlp-2011-143" href="../emnlp2011/emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>144 <a title="emnlp-2011-144" href="../emnlp2011/emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>145 <a title="emnlp-2011-145" href="../emnlp2011/emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>146 <a title="emnlp-2011-146" href="../emnlp2011/emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>147 <a title="emnlp-2011-147" href="../emnlp2011/emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>148 <a title="emnlp-2011-148" href="../emnlp2011/emnlp-2011-Watermarking_the_Outputs_of_Structured_Prediction_with_an_application_in_Statistical_Machine_Translation..html">emnlp-2011-Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
