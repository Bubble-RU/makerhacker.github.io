<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-118" href="../emnlp2010/emnlp-2010-Utilizing_Extra-Sentential_Context_for_Parsing.html">emnlp2010-118</a> <a title="emnlp-2010-118-reference" href="#">emnlp2010-118-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>118 emnlp-2010-Utilizing Extra-Sentential Context for Parsing</h1>
<br/><p>Source: <a title="emnlp-2010-118-pdf" href="http://aclweb.org/anthology//D/D10/D10-1003.pdf">pdf</a></p><p>Author: Jackie Chi Kit Cheung ; Gerald Penn</p><p>Abstract: Syntactic consistency is the preference to reuse a syntactic construction shortly after its appearance in a discourse. We present an analysis of the WSJ portion of the Penn Treebank, and show that syntactic consistency is pervasive across productions with various lefthand side nonterminals. Then, we implement a reranking constituent parser that makes use of extra-sentential context in its feature set. Using a linear-chain conditional random field, we improve parsing accuracy over the generative baseline parser on the Penn Treebank WSJ corpus, rivalling a similar model that does not make use of context. We show that the context-aware and the context-ignorant rerankers perform well on different subsets of the evaluation data, suggesting a combined approach would provide further improvement. We also compare parses made by models, and suggest that context can be useful for parsing by capturing structural dependencies between sentences as opposed to lexically governed dependencies.</p><br/>
<h2>reference text</h2><p>J.K. Bock. 1986. Syntactic persistence in language production. Cognitive Psychology, 18(3):355–387.  A. Buch and C. Pietsch. 2010. Measuring syntactic priming in dialog corpora. In Proceedings of the Conference on Linguistic Evidence 2010: Empirical, Theoretical and Computational Perspectives. E. Charniak and M. Johnson. 2005. Coarse-to-fine n-best parsing and MaxEnt discriminative reranking. In Proceedings of the 43rd ACL, pages 173–180. Association for Computational Linguistics. K.W. Church. 2000. Empirical estimates of adaptation: the chance of two Noriegas is closer to p/2 than p2. In Proceedings of 18th COLING, pages 180–186. Association for Computational Linguistics. T. Cohn and P. Blunsom. 2005. Semantic role labelling with tree conditional random fields. In Ninth Conference on Computational Natural Language Learning, pages 169–172. M. Collins and T. Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 31(1):25–70. A. Dubey, P. Sturt, and F. Keller. 2005. Parallelism in coordination as an instance of syntactic priming: Evidence from corpus-based modeling. In Proceedings of HLT/EMNLP 2005, pages 827–834. A. Dubey, F. Keller, and P. Sturt. 2006. Integrating syntactic priming into an incremental probabilistic parser, with an application to psycholinguistic modeling. In Proceedings of the 21st COLING and the 44th ACL,  pages 417–424. Association for Computational Linguistics. J.R. Finkel, A. Kleeman, and C.D. Manning. 2008. Efficient, feature-based, conditional random field parsing. Proceedings of ACL-08: HLT, pages 959–967. S.T. Gries. 2005. Syntactic priming: A corpus-based approach. Journal of Psycholinguistic Research, 34(4):365–399. D. Hogan. 2007. Coordinate noun phrase disambiguation in a generative parsing model. In Proceedings of 45th ACL, volume 45, pages 680–687. F. Jousse, R. Gilleron, I. Tellier, and M. Tommasi. 2006. Conditional random fields for XML trees. In ECML Workshop on Mining and Learning in Graphs. S. K ¨ubler, W. Maier, E. Hinrichs, and E. Klett. 2009. Parsing coordinations. In Proceedings of the 12th EACL, pages 406–414. Association for Computational Linguistics. J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In International Conference on Machine Learning, pages 282–289. D. McClosky, E. Charniak, and M. Johnson. 2006. Effective self-training for parsing. In Proceedings of HLT-NAACL 2006. S. Petrov and D. Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of HLT-NAACL 2007, pages 404–41 1. Association for Computational Linguistics. M.J. Pickering and H.P. Branigan. 1999. Syntactic priming in language production. Trends in Cognitive Sciences, 3(4): 136–141 . D. Reitter. 2008. Context Effects in Language Production: Models of Syntactic Priming in Dialogue Cor-  pora. Ph.D. thesis, University of Edinburgh. F. Sha and F. Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings of HLT-NAACL, pages 213–220. Y. Tsuruoka, J. Tsujii, and S. Ananiadou. 2009. Fast full parsing by linear-chain conditional random fields. In Proceedings of the 12th EACL, pages 790–798. Association for Computational Linguistics. 33</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
