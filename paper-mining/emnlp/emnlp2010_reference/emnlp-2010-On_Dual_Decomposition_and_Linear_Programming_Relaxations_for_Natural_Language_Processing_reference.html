<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>88 emnlp-2010-On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-88" href="../emnlp2010/emnlp-2010-On_Dual_Decomposition_and_Linear_Programming_Relaxations_for_Natural_Language_Processing.html">emnlp2010-88</a> <a title="emnlp-2010-88-reference" href="#">emnlp2010-88-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>88 emnlp-2010-On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing</h1>
<br/><p>Source: <a title="emnlp-2010-88-pdf" href="http://aclweb.org/anthology//D/D10/D10-1001.pdf">pdf</a></p><p>Author: Alexander M Rush ; David Sontag ; Michael Collins ; Tommi Jaakkola</p><p>Abstract: This paper introduces dual decomposition as a framework for deriving inference algorithms for NLP problems. The approach relies on standard dynamic-programming algorithms as oracle solvers for sub-problems, together with a simple method for forcing agreement between the different oracles. The approach provably solves a linear programming (LP) relaxation of the global inference problem. It leads to algorithms that are simple, in that they use existing decoding algorithms; efficient, in that they avoid exact algorithms for the full model; and often exact, in that empirically they often recover the correct solution in spite of using an LP relaxation. We give experimental results on two problems: 1) the combination of two lexicalized parsing models; and 2) the combination of a lexicalized parsing model and a trigram part-of-speech tagger.</p><br/>
<h2>reference text</h2><p>Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On formal properties of simple phrase structure grammars. In Language and Information: Selected Essays on their Theory and Application, pages 116–150. X. Carreras, M. Collins, and T. Koo. 2008. TAG, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proc CONLL, pages 9–16. X. Carreras. 2007. Experiments with a higher-order  projective dependency parser. In Proc. CoNLL, pages 957–961. M. Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proc. EMNLP, page 8. M. Collins. 2003. Head-driven statistical models for natural language parsing. In Computational linguistics, volume 29, pages 589–637. G.B. Dantzig and P. Wolfe. 1960. Decomposition principle for linear programs. In Operations research, volume 8, pages 101–1 11. J. Duchi, D. Tarlow, G. Elidan, and D. Koller. 2007. Using combinatorial optimization within max-product belief propagation. In NIPS, volume 19. J. Eisner. 2000. Bilexical grammars and their cubic-time parsing algorithms. In Advances in Probabilistic and Other Parsing Technologies, pages 29–62. A. Globerson and T. Jaakkola. 2007. Fixing maxproduct: Convergent message passing algorithms for MAP LP-relaxations. In NIPS, volume 21. N. Komodakis, N. Paragios, and G. Tziritas. 2007. MRF optimization via dual decomposition: Messagepassing revisited. In International Conference on Computer Vision. T. Koo, X. Carreras, and M. Collins. 2008. Simple semisupervised dependency parsing. In Proc. ACL/HLT. T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Son-  tag. 2010. Dual Decomposition for Parsing with NonProjective Head Automata. In Proc. EMNLP, pages 63–70. B.H. Korte and J. Vygen. 2008. Combinatorial optimization: theory and algorithms. Springer Verlag. M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1994. Building a large annotated corpus of English: The Penn Treebank. In Computational linguistics, volume 19, pages 313–330. R.K. Martin, R.L. Rardin, and B.A. Campbell. 1990. Polyhedral characterization of discrete dynamic programming. Operations research, 38(1): 127–138. A.F.T. Martins, N.A. Smith, and E.P. Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proc. ACL. 11 R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. HLT/EMNLP, pages 523– 530. Angelia Nedi c´ and Asuman Ozdaglar. 2009. Approximate primal solutions and rate analysis for dual subgradient methods. SIAM Journal on Optimization, 19(4): 1757–1780. B. Pang and L. Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization  based on minimum cuts. In Proc. ACL. S. Riedel and J. Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proc. EMNLP, pages 129–137. D. Roth and W. Yih. 2005. Integer linear programming inference for conditional random fields. In Proc. ICML, pages 737–744. Hanif D. Sherali and Warren P. Adams. 1994. A hierarchy of relaxations and convex hull characterizations for mixed-integer zero–one programming problems. Discrete Applied Mathematics, 52(1):83 – 106. D.A. Smith and J. Eisner. 2008. Dependency parsing by belief propagation. In Proc. EMNLP, pages 145–156. D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and Y. Weiss. 2008. Tightening LP relaxations for MAP using message passing. In Proc. UAI. B. Taskar, D. Klein, M. Collins, D. Koller, and C. Manning. 2004. Max-margin parsing. In Proc. EMNLP, pages 1–8. K. Toutanova and C.D. Manning. 2000. Enriching the knowledge sources used in a maximum entropy partof-speech tagger. In Proc. EMNLP, pages 63–70. M. Wainwright and M. I. Jordan. 2008. Graphical Models, Exponential Families, and Variational Inference. Now Publishers Inc., Hanover, MA, USA. M. Wainwright, T. Jaakkola, and A. Willsky. 2005a. MAP estimation via agreement on trees: message-  passing and linear programming. In IEEE Transactions on Information Theory, volume 5 1, pages 3697– 3717. M. Wainwright, T. Jaakkola, and A. Willsky. 2005b. A new class of upper bounds on the log partition function. In IEEE Transactions on Information Theory, volume 51, pages 2313–2335. C. Yanover, T. Meltzer, and Y. Weiss. 2006. Linear Programming Relaxations and Belief Propagation–An Empirical Study. In The Journal of Machine Learning Research, volume 7, page 1907. MIT Press.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
