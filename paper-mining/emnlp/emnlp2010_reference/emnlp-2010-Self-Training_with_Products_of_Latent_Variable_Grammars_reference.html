<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-96" href="../emnlp2010/emnlp-2010-Self-Training_with_Products_of_Latent_Variable_Grammars.html">emnlp2010-96</a> <a title="emnlp-2010-96-reference" href="#">emnlp2010-96-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>96 emnlp-2010-Self-Training with Products of Latent Variable Grammars</h1>
<br/><p>Source: <a title="emnlp-2010-96-pdf" href="http://aclweb.org/anthology//D/D10/D10-1002.pdf">pdf</a></p><p>Author: Zhongqiang Huang ; Mary Harper ; Slav Petrov</p><p>Abstract: Mary Harper†‡ ‡HLT Center of Excellence Johns Hopkins University Baltimore, MD mharpe r@ umd .edu Slav Petrov∗ ∗Google Research 76 Ninth Avenue New York, NY s lav@ google . com ting the training data and eventually begins over- fitting (Liang et al., 2007). Moreover, EM is a loWe study self-training with products of latent variable grammars in this paper. We show that increasing the quality of the automatically parsed data used for self-training gives higher accuracy self-trained grammars. Our generative self-trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without selftraining. Additionally, we show that multiple self-trained grammars can be combined in a product model to achieve even higher accuracy. The product model is most effective when the individual underlying grammars are most diverse. Combining multiple grammars that were self-trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5% on the WSJ test set and 89.6% on our Broadcast News test set.</p><br/>
<h2>reference text</h2><p>Jason Baldridge and Miles Osborne. 2008. Active learning and logarithmic opinion pools for HPSG parse selection. Natural Language Engineering. Leo Breiman. 1996. Bagging predictors. Machine  Learning. Kenneth P. Burnham and David R. Anderson. 2002. Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach. New York: Springer-Verlag. Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In CoNLL, pages 9–16. Eugene Charniak and Mark Johnson. 2001. Edit detection and parsing for transcribed speech. In NAACL. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In ACL. Eugene Charniak, Don Blaheta, Niyu Ge, Keith Hall, John Hale, and Mark Johnson, 2000. BLLIP 1987-89 WSJ Corpus Release 1. Linguistic Data Consortium, Philadelphia. Eugene Charniak. 1997. Statistical parsing with a context-free grammar and word statistics. In ICAI. Eugene Charniak. 2000. A maximum-entropy-inspired parser. In ACL. Denis Filimonov and Mary Harper. 2009. A joint language model with fine-grain syntactic tags. In EMNLP, pages 1114–1 123, Singapore, August. Victoria Fossum and Kevin Knight. 2009. Combining constituent parsers. In NAACL, pages 253–256. John Garofolo, Jonathan Fiscus, William Fisher, and  David Pallett, 1996. CSR-IV HUB4. Linguistic Data Consortium, Philadelphia. Geoffrey E. Hinton. 1999. Products of experts. In ICANN. Zhongqiang Huang and Mary Harper. 2009. Selftraining PCFG grammars with latent annotations across languages. In EMNLP. Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In ACL. Percy Liang, Slav Petrov, Michael I. Jordan, and Dan Klein. 2007. The infinite PCFG using hierarchical Dirichlet processes. In EMNLP. Mitchell P. Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz, and Ann Taylor, 1999. Treebank-3. Linguistic Data Consortium, Philadelphia. Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Probabilistic CFG with latent annotations. In ACL. David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In HLTNAACL. Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In HLT-NAACL. Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In ACL. Slav Petrov. 2009. Coarse-to-Fine Natural Language Processing. Ph.D. thesis, University of California at Bekeley. Slav Petrov. 2010. Products of random latent variable grammars. In HLT-NAACL. Brian Roark, Mary Harper, Yang Liu, Robin Stewart, Matthew Lease, Matthew Snover, Izhak Shafran, Bonnie J. Dorr, John Hale, Anna Krasnyanskaya, and Lisa Yung. 2006. SParseval: Evaluation metrics for parsing speech. In LREC. Kenji Sagae and Alon Lavie. 2006. Parser combination by reparsing. In NAACL, pages 129–132. Andrew Smith and Miles Osborne. 2007. Diversity in logarithmic opinion pools. Lingvisticae Investigationes. Andrew Smith, Trevor Cohn, and Miles Osborne. 2005. Logarithmic opinion pools for conditional random fields. In ACL. Wen Wang and Mary P. Harper. 2002. The superarv language model: Investigating the effectiveness of tightly integrating multiple knowledge sources. In EMNLP, pages 238–247, Philadelphia, July. Ralph Weischedel, Sameer Pradhan, Lance Ramshaw, Martha Palmer, Nianwen Xue, Mitchell Marcus, Ann Taylor, Craig Greenberg, Eduard Hovy, Robert Belvin, and Ann Houston, 2008. OntoNotes Release 2.0. Linguistic Data Consortium, Philadelphia. Hui Zhang, Min Zhang, Chew Lim Tan, and Haizhou Li. 2009. K-best combination of syntactic parsers. In EMNLP, pages 1552–1560. 22</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
