<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>17 emnlp-2010-An Efficient Algorithm for Unsupervised Word Segmentation with Branching Entropy and MDL</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2010" href="../home/emnlp2010_home.html">emnlp2010</a> <a title="emnlp-2010-17" href="../emnlp2010/emnlp-2010-An_Efficient_Algorithm_for_Unsupervised_Word_Segmentation_with_Branching_Entropy_and_MDL.html">emnlp2010-17</a> <a title="emnlp-2010-17-reference" href="#">emnlp2010-17-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>17 emnlp-2010-An Efficient Algorithm for Unsupervised Word Segmentation with Branching Entropy and MDL</h1>
<br/><p>Source: <a title="emnlp-2010-17-pdf" href="http://aclweb.org/anthology//D/D10/D10-1081.pdf">pdf</a></p><p>Author: Valentin Zhikov ; Hiroya Takamura ; Manabu Okumura</p><p>Abstract: This paper proposes a fast and simple unsupervised word segmentation algorithm that utilizes the local predictability of adjacent character sequences, while searching for a leasteffort representation of the data. The model uses branching entropy as a means of constraining the hypothesis space, in order to efficiently obtain a solution that minimizes the length of a two-part MDL code. An evaluation with corpora in Japanese, Thai, English, and the ”CHILDES” corpus for research in language development reveals that the algorithm achieves an accuracy, comparable to that of the state-of-the-art methods in unsupervised word segmentation, in a significantly reduced . computational time.</p><br/>
<h2>reference text</h2><p>Bernstein-Ratner, Nan 1987. The phonology of parent child speech. Childrens Language, 6: 159–174 Brent, Michael R and Timothy A. Cartwright. 1996. Distributional Regularity and Phonotactic Constraints are Useful for Segmentation. Cognition 61: 93–125 Goldwater, Sharon. 2006. Nonparametric Bayesian Models of Lexical Acquisition. Brown University, Ph.D. Thesis Goldwater, Sharon, Thomas L. Griffiths and Mark Johnson. 2006. Contextual dependencies in unsupervised word segmentation. Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Com–  putational Linguistics, Sydney, 673–680 Goldwater, Sharon, Thomas L. Griffiths and Mark Johnson. 2009. A Bayesian framework for word segmentation: Exploring the effects of context. Cognition, 112: 1, 21–54. Harris, Zellig. 1955. From Phoneme to Morpheme. Language, 31(2): 190-222. 841 Huang, Jin H. and David Powers. 2003. Chinese Word Segmentation Based on Contextual Entropy. Proceedings of 17th Pacific Asia Conference, 152–158 Hutchens, Jason L. and Michael D. Alder. 1998. Finding structure via compression. Proceedings of the International Conference on Computational Natural Language Learning, 79–82 Jin, Zhihui and Kumiko Tanaka-Ishii. 2006. Unsupervised Segmentation of Chinese Text by Use of Branching Entropy. Proceedings of the COLING/ACL on Main conference poster sessions, 428–435 Johnson, Mark and Sharon Goldwater. 2009. Improving nonparameteric Bayesian inference: experiments on unsupervised word segmentation with adaptor grammars. Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Association for Computational Linguistics, 3 17–325. Kempe, Andre. 1999. Experiments in Unsupervised  Entropy Based Corpus Segmentation. Proceedings of CoNLL’99, pp. 371–385 Kit, Chunyu. 2003. How does lexical acquisition begin? A cognitive perspective. Cognitive Science 1(1): 1– 50. Kurohashi, Sadao and Makoto Nagao. 1998. Building a Japanese Parsed Corpus while Improving the Parsing System. Proceedings of the First International Conference on Language Resources and Evaluation, Granada, Spain, 719–724 Lafferty, John, Andrew McCallum and Fernando Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. Proceedings of the International Conference on Machine Learning. Li, Hang. 1998. A Probabilistic Approach to Lexical Semantic Knowledge Acquisition and Structural Disambiguation. University of Tokyo, Ph.D. Thesis Liang, Percy. 2005. Semi-Supervised Learning for Natural Language. Massachusets Institute of Technology, Master’s Thesis. Manber, Udi and Gene Myers. 1991. Suffix arrays: a new method for on-line string searches. SIAM Journal on Computing 22:935–948 Marcus,  Mitchell,  Grace  Robert MacIntyre,  Kim, Mary Ann Marcinkiewicz,  Ann Bies, Mark Ferguson,  Karen  and Britta Schasberger. 1994. The Penn Treebank: Annotating Predicate Argument Structure. Human Language Technology, 114–1 19 Mochihashi, Daiichi, Takeshi Yamada and Naonori Ueda. 2009. Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling. Proceedings Katz  of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, 1: 100–108 Rissanen, Jorma. 1978. Modeling by Shortest Data Description. Aulomatica, 14:465–471. Saffran, Jenny R., Richard N. Aslin and Elissa L. Newport. 1996. Statistical learning in 8-month-old infants Science; 274: 1926-1928 Tsuboi, Yuta, Hisashi Kashima., Hiroki Oda, Shinsuke Mori and Yuji Matsumoto. 2008. Training Conditional Random Fields Using Incomplete Annotations. Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1,897–904. Yu, Hua. 2000. Unsupervised word induction using MDL criterion. Proceedings of tne International Symposium of Chinese Spoken Language Processing, Beijing. Zipf, George K. 1949. Human Behavior and the Principle of Least Effort. Addison-Wesley. 842</p>
<br/>
<br/><br/><br/></body>
</html>
