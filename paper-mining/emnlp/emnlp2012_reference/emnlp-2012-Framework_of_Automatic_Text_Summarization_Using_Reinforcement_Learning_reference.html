<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-56" href="../emnlp2012/emnlp-2012-Framework_of_Automatic_Text_Summarization_Using_Reinforcement_Learning.html">emnlp2012-56</a> <a title="emnlp-2012-56-reference" href="#">emnlp2012-56-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>56 emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</h1>
<br/><p>Source: <a title="emnlp-2012-56-pdf" href="http://aclweb.org/anthology//D/D12/D12-1024.pdf">pdf</a></p><p>Author: Seonggi Ryang ; Takeshi Abekawa</p><p>Abstract: We present a new approach to the problem of automatic text summarization called Automatic Summarization using Reinforcement Learning (ASRL) in this paper, which models the process of constructing a summary within the framework of reinforcement learning and attempts to optimize the given score function with the given feature representation of a summary. We demonstrate that the method of reinforcement learning can be adapted to automatic summarization problems naturally and simply, and other summarizing techniques, such as sentence compression, can be easily adapted as actions of the framework. The experimental results indicated ASRL was superior to the best performing method in DUC2004 and comparable to the state of the art ILP-style method, in terms of ROUGE scores. The results also revealed ASRL can search for sub-optimal solutions efficiently under conditions for effectively selecting features and the score function.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
