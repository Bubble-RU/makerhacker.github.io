<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>49 emnlp-2012-Exploring Topic Coherence over Many Models and Many Topics</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-49" href="../emnlp2012/emnlp-2012-Exploring_Topic_Coherence_over_Many_Models_and_Many_Topics.html">emnlp2012-49</a> <a title="emnlp-2012-49-reference" href="#">emnlp2012-49-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>49 emnlp-2012-Exploring Topic Coherence over Many Models and Many Topics</h1>
<br/><p>Source: <a title="emnlp-2012-49-pdf" href="http://aclweb.org/anthology//D/D12/D12-1087.pdf">pdf</a></p><p>Author: Keith Stevens ; Philip Kegelmeyer ; David Andrzejewski ; David Buttler</p><p>Abstract: We apply two new automated semantic evaluations to three distinct latent topic models. Both metrics have been shown to align with human evaluations and provide a balance between internal measures of information gain and comparisons to human ratings of coherent topics. We improve upon the measures by introducing new aggregate measures that allows for comparing complete topic models. We further compare the automated measures to other metrics for topic models, comparison to manually crafted semantic tests and document classification. Our experiments reveal that LDA and LSA each have different strengths; LDA best learns descriptive topics while LSA is best at creating a compact semantic representation ofdocuments and words in a corpus.</p><br/>
<h2>reference text</h2><p>David Andrzejewski and David Buttler. 2011. Latent topic feedback for information retrieval. In Proceed6https://github.com/fozziethebeat/TopicModelComparison ings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’ 11, pages 600–608, New York, NY, USA. ACM. Robert E. Banfield, Lawrence O. Hall, Kevin W. Bowyer, and W. Philip Kegelmeyer. 2007. A comparison of decision tree ensemble creation techniques. IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(1): 173–180, January.  Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta. 2009. The WaCky wide web: A collection of very large linguistically processed webcrawled corpora. Language Resources and Evaluation, 43(3):209–226. David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993–1022, March. Samuel Brody and Mirella Lapata. 2009. Bayesian word sense induction. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’09, pages 103– 111, Stroudsburg, PA, USA. Association for Computational Linguistics. Rich Caruana, Mohamed Elhawary, Art Munson, Mirek Riedewald, Daria Sorokina, Daniel Fink, Wesley M. Hochachka, and Steve Kelling. 2006. Mining citizen science data to predict orevalence of wild bird species. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’06, pages 909–915, New York, NY, USA. ACM. Jonathan Chang, Sean Gerrish, Chong Wang, and David M Blei. 2009. Reading tea leaves : How humans interpret topic models. New York, 3 1:1–9. Chris Ding, Tao Li, and Wei Peng. 2008. On the equivalence between non-negative matrix factorization and  probabilistic latent semantic indexing. Comput. Stat. Data Anal., 52:3913–3927, April. Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. 2002. Placing search in context: the concept revisited. ACM Trans. Inf. Syst., 20: 116–13 1, January. T. L. Griffiths and M. Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences, 101(Suppl. 1):5228–5235, April. David Jurgens and Keith Stevens. 2010. The s-space package: an open source package for word space models. In Proceedings of the ACL 2010 System Demonstrations, ACLDemos ’ 10, pages 30–35, Stroudsburg, PA, USA. Association for Computational Linguistics. Thomas K Landauer and Susan T. Dutnais. 1997. A solution to platos problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review, pages 211–240. 961 Thomas K. Landauer, Peter W. Foltz, and Darrell Laham. 1998. An Introduction to Latent Semantic Analysis. Discourse Processes, (25):259–284. Daniel D. Lee and H. Sebastian Seung. 2000. Algorithms for non-negative matrix factorization. In In NIPS, pages 556–562. MIT Press. David Mimno, Hanna Wallach, Edmund Talley, Miriam  Leenders, and Andrew McCallum. 2011. Optimizing semantic coherence in topic models. In Proceedings of the 2011 Conference on Emperical Methods in Natural Language Processing, pages 262–272, Edinburgh, Scotland, UK. Association of Computational Linguistics. David Newman, Youn Noh, Edmund Talley, Sarvnaz Karimi, and Timothy Baldwin. 2010. Evaluating topic models for digital libraries. In Proceedings of the 10th annual joint conference on Digital libraries, JCDL ’ 10, pages 215–224, New York, NY, USA. ACM. V Paul Pauca, Farial Shahnaz, Michael W Berry, and Robert J Plemmons, 2004. Text mining using nonnegative matrix factorizations, volume 54, pages 452–456. SIAM. Herbert Rubenstein and John B. Goodenough. 1965. Contextual correlates of synonymy. Commun. ACM, 8:627–633, October. Evan Sandhaus. 2008. The New York Times Annotated Corpus. Tim Van de Cruys and Marianna Apidianaki. 2011. Latent semantic word sense induction and disambiguation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’ 11, pages 1476–1485, Stroudsburg, PA, USA. Association for Computational Linguistics.  Hanna Wallach, Iain Murray, Ruslan Salakhutdinov, and David Mimno. 2009. Evaluation methods for topic models. In Proceedings of the 26th International Conference on Machine Learning (ICML). Omnipress.</p>
<br/>
<br/><br/><br/></body>
</html>
