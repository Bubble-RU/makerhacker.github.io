<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 emnlp-2012-Dynamic Programming for Higher Order Parsing of Gap-Minding Trees</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-37" href="../emnlp2012/emnlp-2012-Dynamic_Programming_for_Higher_Order_Parsing_of_Gap-Minding_Trees.html">emnlp2012-37</a> <a title="emnlp-2012-37-reference" href="#">emnlp2012-37-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>37 emnlp-2012-Dynamic Programming for Higher Order Parsing of Gap-Minding Trees</h1>
<br/><p>Source: <a title="emnlp-2012-37-pdf" href="http://aclweb.org/anthology//D/D12/D12-1044.pdf">pdf</a></p><p>Author: Emily Pitler ; Sampath Kannan ; Mitchell Marcus</p><p>Abstract: We introduce gap inheritance, a new structural property on trees, which provides a way to quantify the degree to which intervals of descendants can be nested. Based on this property, two new classes of trees are derived that provide a closer approximation to the set of plausible natural language dependency trees than some alternative classes of trees: unlike projective trees, a word can have descendants in more than one interval; unlike spanning trees, these intervals cannot be nested in arbitrary ways. The 1-Inherit class of trees has exactly the same empirical coverage of natural language sentences as the class of mildly nonprojective trees, yet the optimal scoring tree can be found in an order of magnitude less time. Gap-minding trees (the second class) have the property that all edges into an interval of descendants come from the same node, and thus an algorithm which uses only single in- tervals can produce trees in which a node has descendants in multiple intervals.</p><br/>
<h2>reference text</h2><p>M. Bodirsky, M. Kuhlmann, and M. M o¨hl. 2005. Wellnested drawings as models of syntactic structure. In In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language, pages 88–1. University Press. X. Carreras, M. Collins, and T. Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, featurerich parsing. In Proceedings of CoNLL, pages 9–16. Association for Computational Linguistics. X. Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL, volume 7, pages 957–961. J. Chen-Main and A. Joshi. 2010. Unavoidable illnestedness in natural language and the adequacy of tree local-mctag induced dependency structures. In Proceedings of the Tenth International Workshop on Tree Adjoining Grammar and Related Formalisms (TAG+ 10). J. Chen-Main and A.K. Joshi. 2012. A depen-  dency perspective on the adequacy of tree local multicomponent tree adjoining grammar. In Journal of Logic and Computation. (to appear). N. Chomsky. 1981 . Lectures on Government and Binding. Dordrecht: Foris. K. Crammer and Y. Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal of Machine Learning Research, 3:95 1–991, March. J. Eisner and G. Satta. 2000. A faster parsing algorithm for lexicalized tree-adjoining grammars. In Proceedings of the 5th Workshop on Tree-Adjoining Grammars and Related Formalisms (TAG+5), pages 14–19. J. Eisner and N.A. Smith. 2010. Favor short dependencies: Parsing with soft and hard constraints on dependency length. In Harry Bunt, Paola Merlo, and Joakim Nivre, editors, Trends in Parsing Technology: Dependency Parsing, DomainAdaptation, andDeep Parsing, chapter 8, pages 121–150. Springer. J. Eisner. 2000. Bilexical grammars and their cubictime parsing algorithms. In Harry Bunt and Anton Nijholt, editors, Advances in Probabilistic and Other Parsing Technologies, pages 29–62. Kluwer Academic Publishers, October. R. Fiengo. 1977. On trace theory. Linguistic Inquiry, 8(1):35–61. C. G ´omez-Rodr ı´guez, J. Carroll, and D. Weir. 2011. Dependency parsing schemata and mildly non-projective dependency parsing. Computational Linguistics,  37(3):541–586. T. Koo and M. Collins. 2010. Efficient third-order dependency parsers. In Proceedings of ACL, pages 1–1 1. 488 T. Koo, A. Globerson, X. Carreras, and M. Collins. 2007. Structured prediction models via the matrix-tree theorem. In Proceedings of EMNLP-CoNLL. T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Sontag. 2010. Dual decomposition for parsing with nonprojective head automata. In Proceedings of EMNLP, pages 1288–1298. M. Kuhlmann and J. Nivre. 2006. Mildly nonprojective dependency structures. In Proceedings of COLING/ACL, pages 507–514. A.F.T. Martins, N.A. Smith, and E.P. Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of ACL, pages 342– 350. R. McDonald and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL, pages 8 1–88. R. McDonald and G. Satta. 2007. On the complexity of non-projective data-driven dependency parsing. In Proceedings of the 10th International Conference on Parsing Technologies, pages 121–132. R. McDonald, K. Crammer, and F. Pereira. 2005a. On-  line large-margin training of dependency parsers. In Proceedings of ACL, pages 91–98. R. McDonald, F. Pereira, K. Ribarov, and J. Haji cˇ. 2005b. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of HLT-EMNLP, pages 523–530. T. Reinhart. 1976. The Syntactic Domain of Anaphora. Ph.D. thesis, Massachusetts Institute of Technology. G. Satta and W. Schuler. 1998. Restrictions on tree adjoining languages. In Proceedings of COLING-ACL, pages 1176–1 182. D.A. Smith and N.A. Smith. 2007. Probabilistic models of nonprojective dependency trees. In Proceedings of EMNLP-CoNLL.</p>
<br/>
<br/><br/><br/></body>
</html>
