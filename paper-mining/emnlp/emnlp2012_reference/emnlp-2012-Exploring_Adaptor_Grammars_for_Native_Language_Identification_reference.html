<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>48 emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-48" href="../emnlp2012/emnlp-2012-Exploring_Adaptor_Grammars_for_Native_Language_Identification.html">emnlp2012-48</a> <a title="emnlp-2012-48-reference" href="#">emnlp2012-48-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>48 emnlp-2012-Exploring Adaptor Grammars for Native Language Identification</h1>
<br/><p>Source: <a title="emnlp-2012-48-pdf" href="http://aclweb.org/anthology//D/D12/D12-1064.pdf">pdf</a></p><p>Author: Sze-Meng Jojo Wong ; Mark Dras ; Mark Johnson</p><p>Abstract: The task of inferring the native language of an author based on texts written in a second language has generally been tackled as a classification problem, typically using as features a mix of n-grams over characters and part of speech tags (for small and fixed n) and unigram function words. To capture arbitrarily long n-grams that syntax-based approaches have suggested are useful, adaptor grammars have some promise. In this work we investigate their extension to identifying n-gram collocations of arbitrary length over a mix of PoS tags and words, using both maxent and induced syntactic language model approaches to classification. After presenting a new, simple baseline, we show that learned collocations used as features in a maxent model perform better still, but that the story is more mixed for the syntactic language model.</p><br/>
<h2>reference text</h2><p>David M. Blei, Andrew Ng, and Michael Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022. Benjamin B ¨orschinger, Bevan K. Jones, and Mark Johnson. 2011. Reducing grounded learning tasks to grammatical inference. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1416–1425, Edinburgh, Scotland, July. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and MaxEnt discriminative reranking. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 173– 180, Ann Arbor, Michigan, June. Dominique Estival, Tanja Gaustad, Son-Bao Pham, Will Radford, and Ben Hutchinson. 2007. Author profiling for English emails. In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics (PACLING), pages 263–272. Sylviane Granger, Estelle Dagneaux, Fanny Meunier,  and Magali Paquot. 2009. International Corpus of Learner English (Version 2). Presses Universitaires de Louvain, Louvian-la-Neuve. Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences, 101(suppl. 1):5228–5235. Eric A. Hardisty, Jordan Boyd-Graber, and Philip Resnik. 2010. Modeling perspective using adaptor grammars. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’ 10, pages 284–292. Shun’ichiro Ishikawa. 2011. A New Horizon in Learner Corpus Studies: The Aim of the ICNALE Project. In G. Weir, S. Ishikawa, and K. Poonpon, editors, Corpora and Language Technologies in Teaching, Learning and Research, pages 3–1 1. University of Strathclyde Press, Glasgow, UK. Mark Johnson, Thomas L. Griffiths, and Sharon Goldwater. 2007. Adaptor grammars: A framework for specifying compositional nonparametric bayesian models. In Advances in Neural Information Processing Systems 19: Proceedings of the Twentieth Annual Conference on Neural Information Processing Systems, pages 641–648. 709  Mark Johnson. 2010. PCFGs, Topic Models, Adaptor Grammars and Learning Topical Collocations and the  Structure of Proper Names. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1148–1 157, Uppsala, Sweden, July. Moshe Koppel, Jonathan Schler, and Kfir Zigdon. 2005. Automatically determining an anonymous author’s native language. In Intelligence and Security Informatics, volume 3495 of Lecture Notes in Computer Science, pages 209–217. Springer-Verlag. Moshe Koppel, Jonathan Schler, and Shlomo Argamon. 2009. Computational Methods in Authorship Attribution. Journal of the American Society for Information Science and Technology, 60(1):9–26. Percy Liang, Slav Petrov, Michael I. Jordan, and Dan Klein. 2007. The infinite pcfg using hierarchical dirichlet processes. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 688–697, Prague, Czech Republic, June. Timothy O’Donnell. 2011. Productivity and reuse in language. Ph.D. thesis, Harvard University. Jim Pitman and Marc Yor. 1997. The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator. Annals of Probability, 25(2):855–900. Oren Tsur and Ari Rappoport. 2007. Using classifier features for studying the effect of native language on the choice of written second language words. In Proceed-  ings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 9–16. Hans van Halteren. 2008. Source language markers in EUROPARL translations. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 937–944. Xuerui Wang, Andrew McCallum, and Xing Wei. 2007. Topical n-grams: Phrase and topic discovery, with an application to information retrieval. In Proceedings of the 2007 Seventh IEEE International Conference on Data Mining, ICDM ’07, pages 697–702. Sze-Meng Jojo Wong and Mark Dras. 2011. Exploiting parse structures for native language identification. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1600–1610, Edinburgh, Scotland, July. Sze-Meng Jojo Wong, Mark Dras, and Mark Johnson. 2011. Topic modeling for native language identification. In Proceedings of the Australasian Language Technology Association Workshop 2011, pages 115– 124, Canberra, Australia, December.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
