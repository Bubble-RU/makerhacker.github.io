<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>87 emnlp-2012-Lyrics, Music, and Emotions</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-87" href="../emnlp2012/emnlp-2012-Lyrics%2C_Music%2C_and_Emotions.html">emnlp2012-87</a> <a title="emnlp-2012-87-reference" href="#">emnlp2012-87-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>87 emnlp-2012-Lyrics, Music, and Emotions</h1>
<br/><p>Source: <a title="emnlp-2012-87-pdf" href="http://aclweb.org/anthology//D/D12/D12-1054.pdf">pdf</a></p><p>Author: Rada Mihalcea ; Carlo Strapparava</p><p>Abstract: In this paper, we explore the classification of emotions in songs, using the music and the lyrics representation of the songs. We introduce a novel corpus of music and lyrics, consisting of 100 songs annotated for emotions. We show that textual and musical features can both be successfully used for emotion recognition in songs. Moreover, through comparative experiments, we show that the joint use of lyrics and music brings significant improvements over each of the individual textual and musical classifiers, with error rate reductions of up to 31%.</p><br/>
<h2>reference text</h2><p>C. Alm, D. Roth, and R. Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 347– 354, Vancouver, Canada.  Z. Cataltepe, Y. Yaslan, and A. Sonmez. 2007. Music genre classification using MIDI and audio features. Journal on Advances in Signal Processing. F.R. Chaumartin. 2007. Upar7: A knowledge-based system for headline sentiment tagging. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), Prague, Czech Republic, June. M. Das, D. Howard, and S. Smith. 2000. The kinematic analysis of motion curves through MIDI data analysis. Organised Sound, 5(1): 137–145. P. Ekman. 1993. Facial expression of emotion. American Psychologist, 48:384–392. X. Hu, J. S. Downie, and A. F. Ehmann. 2009. Lyric text mining in music mood classification. In Proceedings of the International Society for Music Information Retrieval Conference, Kobe, Japan. T. Joachims. 1998. Text categorization with Support Vector Machines: learning with mny relevant features. In Proceedings of the European Conference on Machine Learning, pages 137–142, Chemnitz, Germany. P. Juslin and P. Laukka. 2003. Communication of emotion in vocal expression and music performance: Different channels, same code? Psychological Bulletin, 129:770–814. P. N. Juslin and J. A. Sloboda, editors. 2001. Music and Emotion: Theory and Research. Oxford University Press. C. Karageorghis and D. Priest. 2008. Music in sport and  exercise : An update on research and application. The Sport Journal, 11(3). P. Katz, M. Singleton, and R. Wicentowski. 2007. Swat-mp:the semeval-2007 systems for task 5 and task 14. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), Prague, Czech Republic, June. Y. Kim, E. Schmidt, R. Migneco, B. Morton, P. Richardson, J. Scott, J. Speck, and D. Turnbull. 2010. Music emotion recognition: A state of the art review. In International Symposium on Music Information Retrieval. Z. Kozareva, B. Navarro, S. Vazquez, and A. Montoyo. 2007. Ua-zbsa: A headline emotion classification through web information. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), Prague, Czech Republic, June. C. Laurier, J. Grivolla, and P. Herrera. 2008. Multimodal music mood classification using audio and lyrics. In Proceedings of the International Conference on Machine Learning and Applications, Barcelona, Spain. J. Mahedero, A. Martinez, and P. Cano. 2005. Natural language processing of lyrics. In Proceedings of MM’05, Singapore, November. 598 B. Nettl. 2000. An ethnomusicologist contemplates universals in musical sound and musical culture. In  N. Wallin, B. Merker, and S. Brown, editors, The origins of music, pages 463—472. MIT Press, Cambridge, MA. T. O’Hara. 2011. Inferring the meaning of chord sequences via lyrics. In Proceedings of 2nd Workshop on Music Recommendation and Discovery (WOMRAD 2011), Chicago, IL, October. N. Orio. 2006. Music retrieval: A tutorial and review. Foundations and Trends in Information Retrieval, 1(1): 1–90, November. A. Ortony, G. L. Clore, and M. A. Foss. 1987. The referential structure of the affective lexicon. Cognitive Science, (11). J. Pennebaker and M. Francis. 1999. Linguistic inquiry and word count: LIWC. Erlbaum Publishers. J. Pennebaker and L. King. 1999. Linguistic styles: Language use as an individual difference. Journal of Personality and Social Psychology, (77). F. Rauscher, G. Shaw, and K. Ky. 1993. Music and spatial task performance. Nature, 365. D. Rizo, P. Ponce de Leon, C. Perez-Sancho, A. Pertusa, and J. Inesta. 2006. A pattern recognition approach for melody track selection in MIDI files. In Proceedings of 7th International Symposyum on Music Information Retrieval (ISMIR-06), pages 61–66, Victoria, Canada, October. K. Scherer. 1995. Expression of emotion in voice and  music. Journal of Voice, 9:235–248. K. Scherer. 2004. Which emotions can be induced by music? what are the underlying mechanisms? and how can we measure them ? Journal of New Music Research, 33:239–251. R. Snow, B. O’Connor, D. Jurafsky, and A. Ng. 2008. Cheap and fast but is it good? evaluating non-expert annotations for natural language tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Honolulu, Hawaii. C. Strapparava and R. Mihalcea. 2007. Semeval-2007 task 14: Affective text. In Proceedings of the 4th International Workshop on the Semantic Evaluations (SemEval 2007), Prague, Czech Republic. C. Strapparava and R. Mihalcea. 2008. Learning to identify emotions in text. In Proceedings of the ACM Conference on Applied Computing ACM-SAC 2008, Fortaleza, Brazile. C. Strapparava and A. Valitutti. 2004. Wordnet-affect: an affective extension of wordnet. In Proceedings of the 4th International Conference on Language Resources and Evaluation, Lisbon. J. Sundberg. 1982. Speech, song, and emotions. In M. Clynes, editor, Music, Mind and Brain: The Neuropsychology of Music. Plenum Press, New York. –  V.  Vapnik. 1995.  The Nature of Statistical Learning The-  York. Velusamy, B. Thoshkahna, and K. Ramakrishnan. 2007. Novel melody line identification algorithm for polyphonic MIDI music. In Proceedings of 13th Inory. Springer, New  S.  ternational Multimedia Modeling Conference (MMM 2007), Singapore, January. Y. Wang, M. Kan, T. Nwe, A. Shenoy, and J. Yin. 2004. LyricAlly: Automatic synchronization of acoustic musical signals and textual lyrics. In Proceedings of MM’04, New York, October. Y. Xia, L. Wang, K.F. Wong, and M. Xu. 2008. Lyricbased song sentiment classification with sentiment vector space model. In Proceedings of the Association for Computational Linguistics, Columbus, Ohio. D. Yang and W. Lee. 2004. Disambiguating music emotion using software agents. In Proceedings of the International Conference on Music Information Retrieval, Barcelona, Spain. D. Yang and W. Lee. 2009. Music emotion identification from lyrics. In Proceedings of 11th IEEE Symposium on Multimedia. Y.-H. Yang, Y.-C. Lin, H.-T. Cheng, I.-B. Liao, Y.-C. Ho, and H. Chen. 2008. Toward multi-modal music emotion classification. In Proceedings of the 9th Pacific Rim Conference on Multimedia: Advances in Multimedia Information Processing. 599</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
