<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-79" href="../emnlp2012/emnlp-2012-Learning_Syntactic_Categories_Using_Paradigmatic_Representations_of_Word_Context.html">emnlp2012-79</a> <a title="emnlp-2012-79-reference" href="#">emnlp2012-79-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>79 emnlp-2012-Learning Syntactic Categories Using Paradigmatic Representations of Word Context</h1>
<br/><p>Source: <a title="emnlp-2012-79-pdf" href="http://aclweb.org/anthology//D/D12/D12-1086.pdf">pdf</a></p><p>Author: Mehmet Ali Yatbaz ; Enis Sert ; Deniz Yuret</p><p>Abstract: We investigate paradigmatic representations of word context in the domain of unsupervised syntactic category acquisition. Paradigmatic representations of word context are based on potential substitutes of a word in contrast to syntagmatic representations based on properties of neighboring words. We compare a bigram based baseline model with several paradigmatic models and demonstrate significant gains in accuracy. Our best model based on Euclidean co-occurrence embedding combines the paradigmatic context representation with morphological and orthographic features and achieves 80% many-to-one accuracy on a 45-tag 1M word corpus.</p><br/>
<h2>reference text</h2><p>B. Ambridge and E.V.M. Lieven, 2011. Child Language Acquisition: Contrasting Theoretical Approaches, chapter 6.1. Cambridge University Press. D. Arthur and S. Vassilvitskii. 2007. k-means++: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, pages 1027–1035. Society for Industrial and Applied Mathematics. Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylogenetic grammar induction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1288–1297, Uppsala, Sweden, July. Association for Computational Linguistics. Taylor Berg-Kirkpatrick, Alexandre Bouchard-C oˆt´ e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 582–590, Los Angeles, California, June. Association for Computational Linguistics. C. Biemann. 2006. Unsupervised part-of-speech tagging employing efficient graph clustering. In Proceedings  949 of the 21st International Conference on computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 7–12. Association for Computational Linguistics. Phil Blunsom and Trevor Cohn. 2011. A hierarchical pitman-yor process hmm for unsupervised part of speech induction. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 865–874, Portland, Oregon, USA, June. Association for Computational Linguistics. Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Classbased n-gram models of natural language. Comput. Linguist., 18:467–479, December. D. Chandler. 2007. Semiotics: the basics. The Basics Series. Routledge. Christos Christodoulopoulos, Sharon Goldwater, and Mark Steedman. 2010. Two decades of unsupervised pos induction: how far have we come? In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’ 10, pages 575– 584, Stroudsburg, PA, USA. Association for Computational Linguistics.  Christos Christodoulopoulos, Sharon Goldwater, and Mark Steedman. 2011. A bayesian mixture model for pos induction using multiple features. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK., July. Association for Computational Linguistics. Kenneth Ward Church. 1988. A stochastic parts program and noun phrase parser for unrestricted text. In Proceedings of the second conference on Applied natural language processing, ANLC ’88, pages 136–143, Stroudsburg, PA, USA. Association for Computational Linguistics. Alexander Clark. 2003. Combining distributional and morphological information for part of speech induction. In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics - Volume 1, EACL ’03, pages 59–66, Stroudsburg, PA, USA. Association for Computational Linguistics. Mathias Creutz and Krista Lagus. 2005. Inducing the morphological lexicon of a natural language from unannotated text. In Proceedings of AKRR ’05, International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning, pages 106–1 13, Espoo, Finland, June. D. Freudenthal, J.M. Pine, and F. Gobet. 2005. On the resolution of ambiguities in the extraction of syntactic  categories through chunking. Cognitive Systems Research, 6(1):17–25. Kuzman Ganchev, Jo˜ ao Gra ¸ca, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. J. Mach. Learn. Res., 99:2001–2049, August. Jianfeng Gao and Mark Johnson. 2008. A comparison of bayesian estimators for unsupervised hidden markov model pos taggers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 344–352, Stroudsburg, PA, USA. Association for Computational Linguistics. Amir Globerson, Gal Chechik, Fernando Pereira, and Naftali Tishby. 2007. Euclidean embedding of cooccurrence data. J. Mach. Learn. Res., 8:2265–2295, December. Sharon Goldwater and Tom Griffiths. 2007. A fully bayesian approach to unsupervised part-of-speech tagging. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 744–751, Prague, Czech Republic, June. Association for Computational Linguistics. David Graff, Roni Rosenfeld, and Doug Paul. 1995. Csriii text. Linguistic Data Consortium, Philadelphia. Aria Haghighi and Dan Klein. 2006. Prototype-driven learning for sequence models. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the As-  sociation of Computational Linguistics, HLT-NAACL ’06, pages 320–327, Stroudsburg, PA, USA. Association for Computational Linguistics. Mark Johnson. 2007. Why doesn’t EM find good HMM POS-taggers? In Proceedings of the 2007 Joint 950 Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 296–305, Prague, Czech Republic, June. Association for Computational Linguistics. Michael Lamar, Yariv Maron, and Elie Bienenstock. 2010a. Latent-descriptor clustering for unsupervised pos induction. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’ 10, pages 799–809, Stroudsburg, PA, USA. Association for Computational Linguistics. Michael Lamar, Yariv Maron, Mark Johnson, and Elie Bienenstock. 2010b. Svd and clustering for unsupervised pos tagging. In Proceedings of the ACL 2010 Conference Short Papers, pages 215–219, Uppsala, Sweden, July. Association for Computational Linguistics. Yoong Keok Lee, Aria Haghighi, and Regina Barzilay. 2010. Simple type-level unsupervised pos tagging. In Proceedings of the 2010 Conference on Empirical  Methods in Natural Language Processing, EMNLP ’ 10, pages 853–861, Stroudsburg, PA, USA. Association for Computational Linguistics. Mitchell P. Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz, and Ann Taylor. 1999. Treebank-3. Linguistic Data Consortium, Philadelphia. Yariv Maron, Michael Lamar, and Elie Bienenstock. 2010. Sphere embedding: An application to part-ofspeech induction. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 1567–1575. Bernard Merialdo. 1994. Tagging english text with a probabilistic model. Comput. Linguist., 20: 155–171, June. T.H. Mintz. 2003. Frequent frames as a cue for grammatical categories in child directed speech. Cognition, 90(1):91–1 17. M. Redington, N. Crater, and S. Finch. 1998. Distributional information: A powerful cue for acquiring syntactic categories. Cognitive Science, 22(4):425–469. A. Rosenberg and J. Hirschberg. 2007. V-measure: A conditional entropy-based external cluster evaluation measure. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 410–420.  2006.  Magnus Sahlgren.  The Word-Space to represent  Model:  Us-  ing distributional  analysis  syntagmatic  and paradigmatic  relations  between words in high-  dimensional vector spaces.  Ph.D. thesis, Stockholm  University. Hinrich Sch u¨tze. tagging.  1995.  Distributional  In Proceedings  part-of-speech  of the seventh conference  on European chapter of the Association for Computational Linguistics, EACL ’95, pages 141–148, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc. Andreas Stolcke. 2002. Srilm-an extensible language modeling toolkit. In Proceedings International Conference on Spoken Language Processing, pages 257– 286, November. 951</p>
<br/>
<br/><br/><br/></body>
</html>
