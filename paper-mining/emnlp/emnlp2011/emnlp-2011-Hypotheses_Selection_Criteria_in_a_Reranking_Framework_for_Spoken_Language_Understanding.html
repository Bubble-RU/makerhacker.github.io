<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-68" href="#">emnlp2011-68</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</h1>
<br/><p>Source: <a title="emnlp-2011-68-pdf" href="http://aclweb.org/anthology//D/D11/D11-1102.pdf">pdf</a></p><p>Author: Marco Dinarelli ; Sophie Rosset</p><p>Abstract: Reranking models have been successfully applied to many tasks of Natural Language Processing. However, there are two aspects of this approach that need a deeper investigation: (i) Assessment of hypotheses generated for reranking at classification phase: baseline models generate a list of hypotheses and these are used for reranking without any assessment; (ii) Detection of cases where reranking models provide a worst result: the best hypothesis provided by the reranking model is assumed to be always the best result. In some cases the reranking model provides an incorrect hypothesis while the baseline best hypothesis is correct, especially when baseline models are accurate. In this paper we propose solutions for these two aspects: (i) a semantic inconsistency metric to select possibly more correct n-best hypotheses, from a large set generated by an SLU basiline model. The selected hypotheses are reranked applying a state-of-the-art model based on Partial Tree Kernels, which encode SLU hypotheses in Support Vector Machines with complex structured features; (ii) finally, we apply a decision strategy, based on confidence values, to select the final hypothesis between the first ranked hypothesis provided by the baseline SLU model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 Sophie Rosset LIMSI-CNRS B.P. 133, 91403 Orsay Cedex France ro s set @ l ims i fr . re-ranking models.</p><p>Reference: <a title="emnlp-2011-68-reference" href="../emnlp2011_reference/emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In some cases the reranking model provides an incorrect hypothesis while the baseline best  hypothesis is correct, especially when baseline models are accurate. [sent-6, score-0.771]
</p><p>2 In this paper we propose solutions for these two aspects: (i) a semantic inconsistency metric to select possibly more correct n-best hypotheses, from a large set generated by an SLU basiline model. [sent-7, score-0.166]
</p><p>3 We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. [sent-9, score-0.78]
</p><p>4 1 Introduction Discriminative reranking is a widely used approach for several Natural Language Processing (NLP) tasks: Syntactic Parsing (Collins, 2000), Named Entity Recognition (Collins, 2000; Collins and Duffy, 2001), Semantic Role Labelling (Moschitti et al. [sent-15, score-0.459]
</p><p>5 Recently reranking approaches have been successfully applied also to Spoken Language Understanding (SLU) (Dinarelli et al. [sent-19, score-0.459]
</p><p>6 Discriminative Reranking combines two models: a first SLU model is used to generate a ranked list of n-best hypotheses; a reranking model sorts the list based on a different score and the final result  is the new top ranked hypothesis. [sent-21, score-0.527]
</p><p>7 The advantage of reranking approaches is in the possibility to learn directly complex dependencies in the output domain, as this is provided in the hypotheses generated by the baseline model. [sent-22, score-0.82]
</p><p>8 In previous approaches complex features are extracted from the hypotheses for both training and classification phase, but there are very few studies on approaches that can be applied to search in the hypotheses space generated by the baseline SLU model. [sent-23, score-0.628]
</p><p>9 This is a limitation since the larger is the hypotheses space generated, the more likely is to find a better hypothesis. [sent-25, score-0.293]
</p><p>10 On the other hand, reranking a large set of hypotheses is computationally Proce dEindgisnb oufr tgh e, 2 S0c1o1tl Canodn,f eUrKen,c Jeuol yn 2 E7m–3p1ir,ic 2a0l1 M1. [sent-26, score-0.752]
</p><p>11 tc ho2d0s1 in A Nsasotucira tlio Lnan fogru Cagoem Ppruotcaetisosninagl, L pinag uesis 1ti1c0s4–1 15, expensive, thus a strategy to select the best hypotheses to be re-ranked would overcome this problem. [sent-28, score-0.368]
</p><p>12 Another aspect of reranking that deserves to be deeper studied is its applicability. [sent-29, score-0.459]
</p><p>13 Although a reranking model improves the baseline model in the overall performance, in some cases the reranked best  hypotheses can contain more mistakes than the baseline best hypothesis. [sent-30, score-0.923]
</p><p>14 A strategy to decide when the reranking model should be applied and when the first hypothesis of the baseline model is more accurate would improve reranking performances. [sent-31, score-1.146]
</p><p>15 This provides a decision function that detects if the original top ranked hypothesis is more accurate than the reranked best hypothesis. [sent-33, score-0.263]
</p><p>16 The results show that our approach significantly improves both “traditional” reranking approaches and stateof-the-art SLU models. [sent-38, score-0.459]
</p><p>17 Section 3 describes our discriminative reranking framework for SLU, in particular the baseline model adopted, in sub-section 3. [sent-40, score-0.528]
</p><p>18 As an example,  given the following natural language sentence translated from the MEDIA corpus: “Good morning I would like to book an hotel room in London” The semantic representation extraction for the SLU task is performed in two steps: 1. [sent-50, score-0.44]
</p><p>19 Attribute-Value Extraction command-task[reservation] city[London]  object-bd[hotel]  localization-  command-task, object-bd and localization-city are three domain concepts, called also “attributes”, defined in the ontology and Null is the concept for words not associated to any concept. [sent-52, score-0.116]
</p><p>20 reservation, hotel and London are the normalized attribute values, defined also in the application ontology. [sent-54, score-0.368]
</p><p>21 , 2010), two such approaches are compared, one based on weighted ROVER (Fiscus, 1997) while the other is the reranking approach proposed in (Dinarelli et al. [sent-66, score-0.459]
</p><p>22 The second step of SLU, that is Attribute Value Extraction (from now on AVE) is performed with two approaches: a) Rule-based approaches apply Regular Expressions (RE) to map the words realizing a concept into a normalized value. [sent-73, score-0.178]
</p><p>23 Given a concept and its realizing surface form, if a RE for that concept matches the surface, the corresponding value is returned. [sent-75, score-0.294]
</p><p>24 An example of surfaces that can be mapped into the value hotel given the concept object-bd is: 1. [sent-76, score-0.446]
</p><p>25 Note that these surfaces share the same keyword  for the concept object-bd, which is “hotel”. [sent-82, score-0.168]
</p><p>26 In this case the model learns from data the conditional probability of values V , given the concept C and the corresponding sequence of words W realizing the concept: P(V |W, C). [sent-85, score-0.211]
</p><p>27 In principle, the phases from the hypotheses selection to the last, the decision strategy, can be thought of as a whole reranking model. [sent-93, score-0.834]
</p><p>28 In the next two subsection we describe the two models used for hypotheses generation and for reranking: CRF and SVM with kernel methods. [sent-94, score-0.392]
</p><p>29 2  SVM and Kernel Methods  Our reranking model is based on SVM (Vapnik, 1998) with the use of the Partial Tree Kernel defined in (Moschitti, 2006). [sent-134, score-0.459]
</p><p>30 3  Reranking Model  In order to give an effective representation to SLU hypotheses in SVM, since we are using PTK, we need to represent as trees SLU hypotheses like the one described in section 2. [sent-152, score-0.586]
</p><p>31 This problem is easily solved by transforming the hypotheses into trees like the one depicted in figure 1. [sent-153, score-0.293]
</p><p>32 They comprise domain categories like city names, hotel names, street names etc. [sent-160, score-0.305]
</p><p>33 These are ranked by the global conditional probability of the concept sequence, given the input word sequence of CRF. [sent-164, score-0.183]
</p><p>34 The n-best list produced by the baseline model is the list ofcandidate hypotheses H1, H2, . [sent-165, score-0.335]
</p><p>35 We build training pairs such that a reranker can learn to select the best one between the two hypotheses in a pair, i. [sent-171, score-0.358]
</p><p>36 1108 the more correct hypothesis with respect to a reference annotation and a given metric. [sent-173, score-0.141]
</p><p>37 In particular, we compute the edit distance of each hypothesis in the list, with respect to the manual annotation taken from the corpus. [sent-174, score-0.141]
</p><p>38 The best hypothesis Hb is used to build positive instances for the reranker as pairs (Hb, Hi) for i∈ [1. [sent-175, score-0.148]
</p><p>39 This means that, if n hypotheses are generated for a sentence, 2 · n instances are generated from them. [sent-178, score-0.293]
</p><p>40 The reranking kernel in equation 4, consisting in summing four different kernels, has been proposed in (Shen et al. [sent-183, score-0.558]
</p><p>41 The same reranking  schema has been used also in (Shen et al. [sent-189, score-0.459]
</p><p>42 , 2004) for reranking different candidate hypotheses for machine translation. [sent-190, score-0.752]
</p><p>43 For classification, observing that the model is symmetric and exploiting kernel properties, we can use, as classification instances, simple hypotheses instead of pairs. [sent-191, score-0.392]
</p><p>44 More precisely we use pairs where the second hypothesis is empty, i. [sent-192, score-0.114]
</p><p>45 1 Hypotheses Selection via Attribute Value Extraction (AVE) In previous reranking approaches (Collins, 2000; Collins and Duffy, 2002; Shen et al. [sent-207, score-0.459]
</p><p>46 , 2009b), few hypotheses are generated with the baseline model, ranked by the model probability. [sent-212, score-0.369]
</p><p>47 An interesting strategy to improve reranking performance is the selection of the best set of hypotheses to be reranked. [sent-214, score-0.849]
</p><p>48 In this work we propose a semantic inconsistency metric (SIM) based on the attribute-value extraction phase that allows to select better n-best hypotheses. [sent-215, score-0.227]
</p><p>49 We use this property to compute a semantic inconsistency value for hypotheses, which in turn allows to select hypotheses with higher probabilities to be correct. [sent-220, score-0.434]
</p><p>50 From the same sentence, the three first hypotheses that may be generated by the baseline model are: 1. [sent-224, score-0.335]
</p><p>51 obj-bd{I would like to book} obj-bd{an hotel room} loccobitjy-{bind{ { LIo nwdoounl}d 2. [sent-225, score-0.305]
</p><p>52 com-task{I would like to book} obj-bd{an hotel room} locccoitmy{-itna s Lko{nIdo wno}u 3. [sent-226, score-0.305]
</p><p>53 If we apply the AVE module to these hypotheses the result is: 1. [sent-228, score-0.344]
</p><p>54 Accordingly, the most accurate hypothesis under SIM is the second, which is also the correct one. [sent-241, score-0.142]
</p><p>55 In particular, we formalize the definition of the SIM metric above on a concept ci as SIM(ci, The value of SIM is simply 0 if the rule-based AVE module can extract a value from the surface form realizing the concept ci. [sent-243, score-0.411]
</p><p>56 For each concept in a hypothesis, we compute its semantic consistency s(ci) as  w1i,. [sent-245, score-0.142]
</p><p>57 ,m)  where P(vi |ci, is the conditional probability output by the CRF model for the value vi, given the concept ci and its realizing surface Equation 5 means that the CRF score provided for a given value is halved if SIM returns 1, i. [sent-259, score-0.278]
</p><p>58 The semantic inconsistency metric of an hypothesis Hk containing the concept sequence C1N = c1, . [sent-263, score-0.365]
</p><p>59 S(Hk) =iX=N1s(ci)  (6)  Using S(Hk) as semantic inconsistency metric, we generate a huge number of hypotheses with the baseline model and we select only the top n-best. [sent-270, score-0.476]
</p><p>60 We use these hypotheses in the discriminative reranking model, instead of the original n-best generated by the CRF model. [sent-271, score-0.779]
</p><p>61 2 Wrong Rerank Rejection After the reranking model is applied, the first hypothesis is selected as final result. [sent-274, score-0.573]
</p><p>62 This choice as-  sumes that the new hypothesis is more accurate than the one provided by the baseline model. [sent-275, score-0.21]
</p><p>63 Indeed, a reranking model must be carefully tuned in order to correctly rerank wrong first best hypotheses but keeping the original baseline best for correct hypotheses. [sent-277, score-0.908]
</p><p>64 In this situation it becomes hard to train an accurate reranking model. [sent-279, score-0.487]
</p><p>65 Our idea to overcome this problem is to apply the reranking model and then post-process results to detect when the original best hypothesis is actually better than the reranked best. [sent-280, score-0.66]
</p><p>66 Let Hcrf and HRR be the best hypothesis of the CRF and reranking (RR) models, respectively. [sent-282, score-0.573]
</p><p>67 In the same way, let SRR(Hcrf) and SRR(HRR) be the scores of the reranking model on the same hypotheses. [sent-284, score-0.459]
</p><p>68 We select the final best interpretation hypothesis for a given sentence with the decision function:  TabC MR leoEFdD+3eIlRA: TReSWxItsMunRlpotfba1sA2e. [sent-288, score-0.145]
</p><p>69 Tcrfand MRR≥ TRRoente trhse M de avndelo SpVmMen pta sreatm, aeste wre Cll h aasv tehr beesehnol odpsti fmoriz tehde Since this strategy allows to recover from reranking mistakes, we call it Wrong Rerank Rejection (WRR). [sent-298, score-0.535]
</p><p>70 The CRF model for the first SLU phase integrates a traditional set of features like word prefixes and suffixes (of length up to 5), plus some Yes/No features like “Does the word start with capital letter ? [sent-307, score-0.144]
</p><p>71 Concerning hypotheses generation, for training we generate 100 hypotheses, we select the best with respect to the edit distance and the reference annotation and we keep a total of 10 hypotheses to build pairs. [sent-316, score-0.644]
</p><p>72 For classification, with the “standard” reranking approach we generate and we keep the 10 best hypotheses. [sent-317, score-0.459]
</p><p>73 While using SIM for hypotheses selection, we generate 1. [sent-318, score-0.293]
</p><p>74 000 hypotheses and we keep the 10 best with respect to SIM. [sent-319, score-0.32]
</p><p>75 861%%% Table 4:  Results of  baseline  CRF model and  reranking  models on  MEDIA speech input  word, with label unigrams. [sent-340, score-0.501]
</p><p>76 In figure 2(a), 2(b) and 2(c) we show the curves  resulting from optimization of parameters of reranking models. [sent-349, score-0.459]
</p><p>77 In table 3 and 4 we report comparative results over the baseline CRF model, the baseline reranking model (CRF+RR) and the reranking models obtained applying the two improvements proposed in this work (CRF+RRSIM and CRF+RRWRR). [sent-355, score-1.002]
</p><p>78 As we can see, the baseline reranking model does not improve significantly the baseline CRF model. [sent-356, score-0.543]
</p><p>79 This outcome is expected since we don’t use any other information in the reranking model than the semantic tree shown in figure 1. [sent-357, score-0.513]
</p><p>80 Previous approaches like for example (Collins and Duffy, 2002), use the baseline model score as feature, as that the reranking model cannot do worst than the baseline model. [sent-358, score-0.543]
</p><p>81 2, this solution require a fine tuning of the reranking model, especially when the baseline model is relatively accurate. [sent-360, score-0.501]
</p><p>82 This means that 75% of the times the best hypothesis of CRF is correct. [sent-363, score-0.114]
</p><p>83 In turn this implies that the reranking model must not rerank 75% of times and rerank the other 25% of times, someway contrasting the evidence provided by the baseline model score. [sent-364, score-0.677]
</p><p>84 In contrast, using our WRR strategy, we can tune the reranking model to maximize reranking effect and recover from reranking errors applying WRR. [sent-365, score-1.409]
</p><p>85 As shown in tables 3 and 4, we consistently improve CRF baseline as well as reranking baseline CRF+RR, especially applying both SIM and WRR (CRF+RRWRR). [sent-366, score-0.543]
</p><p>86 s[5t%hy]pocesr fco2 tr43fC587o491Ru/2Fn76db5 /ap78srelin tadhe  reranking models showing the effect of hypotheses  selection  TaC bMlR eoEFd D6+vIRAls:P. [sent-369, score-0.805]
</p><p>87 In table 5 we report some statistics to show the effect of SIM on the 10-best hypotheses list. [sent-381, score-0.293]
</p><p>88 It is particularly interesting to see that when hypotheses selection is applied, oracle error rate (OER) drops of 2% points from an already accurate OER of 9. [sent-382, score-0.374]
</p><p>89 We pass from 2657 without SIM to  2758 applying our hypotheses selection metric. [sent-385, score-0.346]
</p><p>90 We can thus conclude that the reranking model we propose, using hypotheses selection and reranking errors recover, significantly improves baseline CRF model and “traditional” reranking models. [sent-393, score-1.765]
</p><p>91 In this respect, it is sufficient to note that our ideas comes  from the multi-stage nature of the task and of the proposed reranking framework. [sent-395, score-0.459]
</p><p>92 SLU is performed in two intertwined steps, since attribute values are extracted from syntactic chunks annotated with concept in the first step. [sent-396, score-0.179]
</p><p>93 This allows to use the model for the second step to validate the output of the first step, and vice versa, which is the principle ofour hypotheses selection metric. [sent-397, score-0.346]
</p><p>94 7  Conclusions  In this paper we propose two improvements for reranking models to be integrated in a reranking framework for Spoken Language Understanding. [sent-400, score-0.918]
</p><p>95 The reranking model is based on a CRF baseline model and Support Vector Machines with the Partial Tree Kernel for the reraning model. [sent-401, score-0.501]
</p><p>96 The two improvements we propose are: i) hypotheses selec-  tion criteria, used before applying reranking to select better hypotheses amongst those generated by CRF. [sent-402, score-1.076]
</p><p>97 ii) a strategy to recover from reranking errors called Wrong Rerank Rejection. [sent-403, score-0.535]
</p><p>98 In particular, the effectiveness of hypotheses selection is shown reporting the improvement of the Oracle Error Rate on the 10-best hypotheses list. [sent-406, score-0.639]
</p><p>99 Optimizing crfs for slu tasks in various languages using modified training criteria. [sent-468, score-0.387]
</p><p>100 Comparing stochastic approaches to spoken language understanding in multiple languages. [sent-545, score-0.101]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reranking', 0.459), ('slu', 0.387), ('hotel', 0.305), ('hypotheses', 0.293), ('crf', 0.272), ('ave', 0.168), ('hahn', 0.137), ('dinarelli', 0.116), ('concept', 0.116), ('hypothesis', 0.114), ('ptk', 0.113), ('sim', 0.102), ('kernel', 0.099), ('moschitti', 0.093), ('hcrf', 0.087), ('reranked', 0.087), ('inconsistency', 0.084), ('cn', 0.078), ('lavergne', 0.075), ('rerank', 0.075), ('hrr', 0.073), ('reservation', 0.073), ('svm', 0.071), ('spoken', 0.07), ('room', 0.068), ('attribute', 0.063), ('realizing', 0.062), ('media', 0.061), ('phase', 0.061), ('assosiation', 0.058), ('scrf', 0.058), ('srr', 0.058), ('wrr', 0.058), ('selection', 0.053), ('shen', 0.053), ('module', 0.051), ('giuseppe', 0.05), ('alessandro', 0.049), ('london', 0.047), ('interspeech', 0.045), ('regularization', 0.044), ('kernels', 0.044), ('strategy', 0.044), ('sophie', 0.044), ('french', 0.042), ('prefixes', 0.042), ('concepts', 0.042), ('baseline', 0.042), ('vapnik', 0.042), ('book', 0.041), ('collins', 0.041), ('ci', 0.041), ('suffixes', 0.041), ('hk', 0.039), ('wrong', 0.039), ('olivier', 0.037), ('elastic', 0.037), ('rosset', 0.037), ('rr', 0.037), ('raymond', 0.034), ('ranked', 0.034), ('margin', 0.034), ('transcriptions', 0.034), ('reranker', 0.034), ('duffy', 0.034), ('conditional', 0.033), ('recover', 0.032), ('select', 0.031), ('hyperplane', 0.031), ('null', 0.031), ('understanding', 0.031), ('communication', 0.031), ('phases', 0.029), ('hb', 0.029), ('bechet', 0.029), ('cedex', 0.029), ('fabrice', 0.029), ('lef', 0.029), ('lehnen', 0.029), ('orsay', 0.029), ('rover', 0.029), ('rrwrr', 0.029), ('sejnowski', 0.029), ('vre', 0.029), ('accurate', 0.028), ('tree', 0.028), ('mori', 0.028), ('respect', 0.027), ('discriminative', 0.027), ('keyword', 0.027), ('provided', 0.026), ('semantic', 0.026), ('ims', 0.025), ('cer', 0.025), ('yeh', 0.025), ('metric', 0.025), ('fields', 0.025), ('surfaces', 0.025), ('brighton', 0.025), ('renato', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="68-tfidf-1" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>Author: Marco Dinarelli ; Sophie Rosset</p><p>Abstract: Reranking models have been successfully applied to many tasks of Natural Language Processing. However, there are two aspects of this approach that need a deeper investigation: (i) Assessment of hypotheses generated for reranking at classification phase: baseline models generate a list of hypotheses and these are used for reranking without any assessment; (ii) Detection of cases where reranking models provide a worst result: the best hypothesis provided by the reranking model is assumed to be always the best result. In some cases the reranking model provides an incorrect hypothesis while the baseline best hypothesis is correct, especially when baseline models are accurate. In this paper we propose solutions for these two aspects: (i) a semantic inconsistency metric to select possibly more correct n-best hypotheses, from a large set generated by an SLU basiline model. The selected hypotheses are reranked applying a state-of-the-art model based on Partial Tree Kernels, which encode SLU hypotheses in Support Vector Machines with complex structured features; (ii) finally, we apply a decision strategy, based on confidence values, to select the final hypothesis between the first ranked hypothesis provided by the baseline SLU model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 Sophie Rosset LIMSI-CNRS B.P. 133, 91403 Orsay Cedex France ro s set @ l ims i fr . re-ranking models.</p><p>2 0.21551819 <a title="68-tfidf-2" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>Author: Katsuhiko Hayashi ; Taro Watanabe ; Masayuki Asahara ; Yuji Matsumoto</p><p>Abstract: We propose a novel forest reranking algorithm for discriminative dependency parsing based on a variant of Eisner’s generative model. In our framework, we define two kinds of generative model for reranking. One is learned from training data offline and the other from a forest generated by a baseline parser on the fly. The final prediction in the reranking stage is performed using linear interpolation of these models and discriminative model. In order to efficiently train the model from and decode on a hypergraph data structure representing a forest, we apply extended inside/outside and Viterbi algorithms. Experimental results show that our proposed forest reranking algorithm achieves significant improvement when compared with conventional approaches.</p><p>3 0.13065556 <a title="68-tfidf-3" href="./emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">127 emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<p>Author: Danilo Croce ; Alessandro Moschitti ; Roberto Basili</p><p>Abstract: Alessandro Moschitti DISI University of Trento 38123 Povo (TN), Italy mo s chitt i di s i @ .unit n . it Roberto Basili DII University of Tor Vergata 00133 Roma, Italy bas i i info .uni roma2 . it l@ over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, A central topic in natural language processing is the design of lexical and syntactic fea- tures suitable for the target application. In this paper, we study convolution dependency tree kernels for automatic engineering of syntactic and semantic patterns exploiting lexical similarities. We define efficient and powerful kernels for measuring the similarity between dependency structures, whose surface forms of the lexical nodes are in part or completely different. The experiments with such kernels for question classification show an unprecedented results, e.g. 41% of error reduction of the former state-of-the-art. Additionally, semantic role classification confirms the benefit of semantic smoothing for dependency kernels.</p><p>4 0.11952379 <a title="68-tfidf-4" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>Author: Alessandro Moschitti ; Jennifer Chu-carroll ; Siddharth Patwardhan ; James Fan ; Giuseppe Riccardi</p><p>Abstract: The last decade has seen many interesting applications of Question Answering (QA) technology. The Jeopardy! quiz show is certainly one of the most fascinating, from the viewpoints of both its broad domain and the complexity of its language. In this paper, we study kernel methods applied to syntactic/semantic structures for accurate classification of Jeopardy! definition questions. Our extensive empirical analysis shows that our classification models largely improve on classifiers based on word-language models. Such classifiers are also used in the state-of-the-art QA pipeline constituting Watson, the IBM Jeopardy! system. Our experiments measuring their impact on Watson show enhancements in QA accuracy and a consequent increase in the amount of money earned in game-based evaluation.</p><p>5 0.1046921 <a title="68-tfidf-5" href="./emnlp-2011-Multilayer_Sequence_Labeling.html">96 emnlp-2011-Multilayer Sequence Labeling</a></p>
<p>Author: Ai Azuma ; Yuji Matsumoto</p><p>Abstract: In this paper, we describe a novel approach to cascaded learning and inference on sequences. We propose a weakly joint learning model on cascaded inference on sequences, called multilayer sequence labeling. In this model, inference on sequences is modeled as cascaded decision. However, the decision on a sequence labeling sequel to other decisions utilizes the features on the preceding results as marginalized by the probabilistic models on them. It is not novel itself, but our idea central to this paper is that the probabilistic models on succeeding labeling are viewed as indirectly depending on the probabilistic models on preceding analyses. We also propose two types of efficient dynamic programming which are required in the gradient-based optimization of an objective function. One of the dynamic programming algorithms resembles back propagation algorithm for mul- tilayer feed-forward neural networks. The other is a generalized version of the forwardbackward algorithm. We also report experiments of cascaded part-of-speech tagging and chunking of English sentences and show effectiveness of the proposed method.</p><p>6 0.0859944 <a title="68-tfidf-6" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>7 0.072025917 <a title="68-tfidf-7" href="./emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">23 emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p>8 0.06971167 <a title="68-tfidf-8" href="./emnlp-2011-A_Fast_Re-scoring_Strategy_to_Capture_Long-Distance_Dependencies.html">5 emnlp-2011-A Fast Re-scoring Strategy to Capture Long-Distance Dependencies</a></p>
<p>9 0.062445335 <a title="68-tfidf-9" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>10 0.061368179 <a title="68-tfidf-10" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>11 0.061026543 <a title="68-tfidf-11" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>12 0.058480434 <a title="68-tfidf-12" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>13 0.056154493 <a title="68-tfidf-13" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>14 0.056045678 <a title="68-tfidf-14" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>15 0.051717151 <a title="68-tfidf-15" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>16 0.050440907 <a title="68-tfidf-16" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>17 0.050420001 <a title="68-tfidf-17" href="./emnlp-2011-Optimal_Search_for_Minimum_Error_Rate_Training.html">100 emnlp-2011-Optimal Search for Minimum Error Rate Training</a></p>
<p>18 0.04620868 <a title="68-tfidf-18" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>19 0.043447249 <a title="68-tfidf-19" href="./emnlp-2011-Enhancing_Chinese_Word_Segmentation_Using_Unlabeled_Data.html">48 emnlp-2011-Enhancing Chinese Word Segmentation Using Unlabeled Data</a></p>
<p>20 0.042244621 <a title="68-tfidf-20" href="./emnlp-2011-Watermarking_the_Outputs_of_Structured_Prediction_with_an_application_in_Statistical_Machine_Translation..html">148 emnlp-2011-Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, -0.013), (2, -0.038), (3, 0.009), (4, -0.009), (5, -0.025), (6, -0.071), (7, -0.145), (8, 0.182), (9, -0.031), (10, 0.077), (11, -0.098), (12, -0.092), (13, 0.252), (14, -0.239), (15, -0.041), (16, -0.071), (17, -0.051), (18, -0.057), (19, 0.044), (20, -0.003), (21, 0.039), (22, 0.097), (23, -0.053), (24, 0.24), (25, -0.159), (26, 0.168), (27, -0.076), (28, -0.015), (29, -0.039), (30, 0.174), (31, 0.032), (32, -0.033), (33, 0.225), (34, -0.06), (35, 0.031), (36, 0.007), (37, -0.019), (38, -0.126), (39, -0.032), (40, 0.0), (41, -0.014), (42, 0.08), (43, 0.03), (44, 0.069), (45, -0.173), (46, 0.112), (47, -0.113), (48, -0.061), (49, 0.107)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95758909 <a title="68-lsi-1" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>Author: Marco Dinarelli ; Sophie Rosset</p><p>Abstract: Reranking models have been successfully applied to many tasks of Natural Language Processing. However, there are two aspects of this approach that need a deeper investigation: (i) Assessment of hypotheses generated for reranking at classification phase: baseline models generate a list of hypotheses and these are used for reranking without any assessment; (ii) Detection of cases where reranking models provide a worst result: the best hypothesis provided by the reranking model is assumed to be always the best result. In some cases the reranking model provides an incorrect hypothesis while the baseline best hypothesis is correct, especially when baseline models are accurate. In this paper we propose solutions for these two aspects: (i) a semantic inconsistency metric to select possibly more correct n-best hypotheses, from a large set generated by an SLU basiline model. The selected hypotheses are reranked applying a state-of-the-art model based on Partial Tree Kernels, which encode SLU hypotheses in Support Vector Machines with complex structured features; (ii) finally, we apply a decision strategy, based on confidence values, to select the final hypothesis between the first ranked hypothesis provided by the baseline SLU model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 Sophie Rosset LIMSI-CNRS B.P. 133, 91403 Orsay Cedex France ro s set @ l ims i fr . re-ranking models.</p><p>2 0.6824218 <a title="68-lsi-2" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>Author: Katsuhiko Hayashi ; Taro Watanabe ; Masayuki Asahara ; Yuji Matsumoto</p><p>Abstract: We propose a novel forest reranking algorithm for discriminative dependency parsing based on a variant of Eisner’s generative model. In our framework, we define two kinds of generative model for reranking. One is learned from training data offline and the other from a forest generated by a baseline parser on the fly. The final prediction in the reranking stage is performed using linear interpolation of these models and discriminative model. In order to efficiently train the model from and decode on a hypergraph data structure representing a forest, we apply extended inside/outside and Viterbi algorithms. Experimental results show that our proposed forest reranking algorithm achieves significant improvement when compared with conventional approaches.</p><p>3 0.42182857 <a title="68-lsi-3" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras</p><p>Abstract: Attempts to profile authors according to their characteristics extracted from textual data, including native language, have drawn attention in recent years, via various machine learning approaches utilising mostly lexical features. Drawing on the idea of contrastive analysis, which postulates that syntactic errors in a text are to some extent influenced by the native language of an author, this paper explores the usefulness of syntactic features for native language identification. We take two types of parse substructure as features— horizontal slices of trees, and the more general feature schemas from discriminative parse reranking—and show that using this kind of syntactic feature results in an accuracy score in classification of seven native languages of around 80%, an error reduction of more than 30%.</p><p>4 0.38072196 <a title="68-lsi-4" href="./emnlp-2011-Multilayer_Sequence_Labeling.html">96 emnlp-2011-Multilayer Sequence Labeling</a></p>
<p>Author: Ai Azuma ; Yuji Matsumoto</p><p>Abstract: In this paper, we describe a novel approach to cascaded learning and inference on sequences. We propose a weakly joint learning model on cascaded inference on sequences, called multilayer sequence labeling. In this model, inference on sequences is modeled as cascaded decision. However, the decision on a sequence labeling sequel to other decisions utilizes the features on the preceding results as marginalized by the probabilistic models on them. It is not novel itself, but our idea central to this paper is that the probabilistic models on succeeding labeling are viewed as indirectly depending on the probabilistic models on preceding analyses. We also propose two types of efficient dynamic programming which are required in the gradient-based optimization of an objective function. One of the dynamic programming algorithms resembles back propagation algorithm for mul- tilayer feed-forward neural networks. The other is a generalized version of the forwardbackward algorithm. We also report experiments of cascaded part-of-speech tagging and chunking of English sentences and show effectiveness of the proposed method.</p><p>5 0.37043375 <a title="68-lsi-5" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>Author: Alessandro Moschitti ; Jennifer Chu-carroll ; Siddharth Patwardhan ; James Fan ; Giuseppe Riccardi</p><p>Abstract: The last decade has seen many interesting applications of Question Answering (QA) technology. The Jeopardy! quiz show is certainly one of the most fascinating, from the viewpoints of both its broad domain and the complexity of its language. In this paper, we study kernel methods applied to syntactic/semantic structures for accurate classification of Jeopardy! definition questions. Our extensive empirical analysis shows that our classification models largely improve on classifiers based on word-language models. Such classifiers are also used in the state-of-the-art QA pipeline constituting Watson, the IBM Jeopardy! system. Our experiments measuring their impact on Watson show enhancements in QA accuracy and a consequent increase in the amount of money earned in game-based evaluation.</p><p>6 0.33654633 <a title="68-lsi-6" href="./emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">127 emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<p>7 0.30568269 <a title="68-lsi-7" href="./emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">23 emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p>8 0.29091668 <a title="68-lsi-8" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>9 0.2513414 <a title="68-lsi-9" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>10 0.22264339 <a title="68-lsi-10" href="./emnlp-2011-Optimal_Search_for_Minimum_Error_Rate_Training.html">100 emnlp-2011-Optimal Search for Minimum Error Rate Training</a></p>
<p>11 0.22025192 <a title="68-lsi-11" href="./emnlp-2011-Syntactic_Decision_Tree_LMs%3A_Random_Selection_or_Intelligent_Design%3F.html">131 emnlp-2011-Syntactic Decision Tree LMs: Random Selection or Intelligent Design?</a></p>
<p>12 0.21979801 <a title="68-lsi-12" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>13 0.21848908 <a title="68-lsi-13" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>14 0.21724817 <a title="68-lsi-14" href="./emnlp-2011-A_Fast_Re-scoring_Strategy_to_Capture_Long-Distance_Dependencies.html">5 emnlp-2011-A Fast Re-scoring Strategy to Capture Long-Distance Dependencies</a></p>
<p>15 0.20791425 <a title="68-lsi-15" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>16 0.20139085 <a title="68-lsi-16" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>17 0.19646159 <a title="68-lsi-17" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>18 0.19325763 <a title="68-lsi-18" href="./emnlp-2011-Watermarking_the_Outputs_of_Structured_Prediction_with_an_application_in_Statistical_Machine_Translation..html">148 emnlp-2011-Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.</a></p>
<p>19 0.19239995 <a title="68-lsi-19" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>20 0.19182773 <a title="68-lsi-20" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.029), (19, 0.256), (23, 0.093), (36, 0.056), (37, 0.064), (45, 0.055), (52, 0.012), (53, 0.03), (54, 0.025), (57, 0.021), (62, 0.025), (64, 0.018), (66, 0.029), (69, 0.025), (79, 0.048), (82, 0.039), (87, 0.014), (90, 0.018), (96, 0.037), (98, 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72531682 <a title="68-lda-1" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>Author: Marco Dinarelli ; Sophie Rosset</p><p>Abstract: Reranking models have been successfully applied to many tasks of Natural Language Processing. However, there are two aspects of this approach that need a deeper investigation: (i) Assessment of hypotheses generated for reranking at classification phase: baseline models generate a list of hypotheses and these are used for reranking without any assessment; (ii) Detection of cases where reranking models provide a worst result: the best hypothesis provided by the reranking model is assumed to be always the best result. In some cases the reranking model provides an incorrect hypothesis while the baseline best hypothesis is correct, especially when baseline models are accurate. In this paper we propose solutions for these two aspects: (i) a semantic inconsistency metric to select possibly more correct n-best hypotheses, from a large set generated by an SLU basiline model. The selected hypotheses are reranked applying a state-of-the-art model based on Partial Tree Kernels, which encode SLU hypotheses in Support Vector Machines with complex structured features; (ii) finally, we apply a decision strategy, based on confidence values, to select the final hypothesis between the first ranked hypothesis provided by the baseline SLU model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous 1104 Sophie Rosset LIMSI-CNRS B.P. 133, 91403 Orsay Cedex France ro s set @ l ims i fr . re-ranking models.</p><p>2 0.568241 <a title="68-lda-2" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>3 0.49086723 <a title="68-lda-3" href="./emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">127 emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<p>Author: Danilo Croce ; Alessandro Moschitti ; Roberto Basili</p><p>Abstract: Alessandro Moschitti DISI University of Trento 38123 Povo (TN), Italy mo s chitt i di s i @ .unit n . it Roberto Basili DII University of Tor Vergata 00133 Roma, Italy bas i i info .uni roma2 . it l@ over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, A central topic in natural language processing is the design of lexical and syntactic fea- tures suitable for the target application. In this paper, we study convolution dependency tree kernels for automatic engineering of syntactic and semantic patterns exploiting lexical similarities. We define efficient and powerful kernels for measuring the similarity between dependency structures, whose surface forms of the lexical nodes are in part or completely different. The experiments with such kernels for question classification show an unprecedented results, e.g. 41% of error reduction of the former state-of-the-art. Additionally, semantic role classification confirms the benefit of semantic smoothing for dependency kernels.</p><p>4 0.48445511 <a title="68-lda-4" href="./emnlp-2011-Hierarchical_Phrase-based_Translation_Representations.html">66 emnlp-2011-Hierarchical Phrase-based Translation Representations</a></p>
<p>Author: Gonzalo Iglesias ; Cyril Allauzen ; William Byrne ; Adria de Gispert ; Michael Riley</p><p>Abstract: This paper compares several translation representations for a synchronous context-free grammar parse including CFGs/hypergraphs, finite-state automata (FSA), and pushdown automata (PDA). The representation choice is shown to determine the form and complexity of target LM intersection and shortest-path algorithms that follow. Intersection, shortest path, FSA expansion and RTN replacement algorithms are presented for PDAs. Chinese-toEnglish translation experiments using HiFST and HiPDT, FSA and PDA-based decoders, are presented using admissible (or exact) search, possible for HiFST with compact SCFG rulesets and HiPDT with compact LMs. For large rulesets with large LMs, we introduce a two-pass search strategy which we then analyze in terms of search errors and translation performance.</p><p>5 0.4833197 <a title="68-lda-5" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>Author: Jason Katz-Brown ; Slav Petrov ; Ryan McDonald ; Franz Och ; David Talbot ; Hiroshi Ichikawa ; Masakazu Seno ; Hideto Kazawa</p><p>Abstract: We propose a simple training regime that can improve the extrinsic performance of a parser, given only a corpus of sentences and a way to automatically evaluate the extrinsic quality of a candidate parse. We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system. We use a corpus of weakly-labeled reference reorderings to guide parser training. Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress.</p><p>6 0.48078731 <a title="68-lda-6" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>7 0.47858319 <a title="68-lda-7" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>8 0.47809348 <a title="68-lda-8" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>9 0.47703546 <a title="68-lda-9" href="./emnlp-2011-Identification_of_Multi-word_Expressions_by_Combining_Multiple_Linguistic_Information_Sources.html">69 emnlp-2011-Identification of Multi-word Expressions by Combining Multiple Linguistic Information Sources</a></p>
<p>10 0.47693297 <a title="68-lda-10" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>11 0.47660279 <a title="68-lda-11" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>12 0.47557983 <a title="68-lda-12" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>13 0.47505039 <a title="68-lda-13" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>14 0.47393581 <a title="68-lda-14" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>15 0.47167039 <a title="68-lda-15" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>16 0.47060129 <a title="68-lda-16" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>17 0.46962634 <a title="68-lda-17" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>18 0.46958148 <a title="68-lda-18" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>19 0.46938887 <a title="68-lda-19" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>20 0.46840578 <a title="68-lda-20" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
