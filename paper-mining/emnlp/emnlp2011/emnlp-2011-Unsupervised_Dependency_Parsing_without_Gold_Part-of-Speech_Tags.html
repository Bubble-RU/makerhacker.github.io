<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-141" href="#">emnlp2011-141</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</h1>
<br/><p>Source: <a title="emnlp-2011-141-pdf" href="http://aclweb.org/anthology//D/D11/D11-1118.pdf">pdf</a></p><p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>Reference: <a title="emnlp-2011-141-reference" href="../emnlp2011_reference/emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Mountain View, CA, 94043  ‡Department of Linguistics Stanford University Stanford, CA, 94305  Abstract We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. [sent-10, score-1.3]
</p><p>2 Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. [sent-11, score-0.487]
</p><p>3 We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. [sent-13, score-0.192]
</p><p>4 With these new induced tags as input, our state-of-  the-art dependency grammar inducer achieves 59. [sent-14, score-0.735]
</p><p>5 In this paper we focus on unsupervised part-of-speech tagging and dependency parsing two related prob1281 lems of syntax discovery. [sent-20, score-0.325]
</p><p>6 For example, to the best of our knowledge, every new state-of-the-art dependency grammar inducer since Klein and Manning (2004) relied on gold part-of-speech tags. [sent-23, score-0.643]
</p><p>7 In turn, not all unsupervised taggers actually induce word categories: Many systems known as part-of-speech disambiguators (Merialdo, 1994) rely on external dictionaries of possible tags. [sent-27, score-0.231]
</p><p>8 Our work builds on two older part-of-speech inducers word clustering algorithms of Clark (2000) and Brown et al. [sent-28, score-0.236]
</p><p>9 We investigate which properties of gold part-ofspeech tags are useful in grammar induction and parsing, and how these properties could be introduced into induced tags. [sent-31, score-0.924]
</p><p>10 We also explore the number of word classes that is good for grammar induction: —  —  —  —  × ×  in particular, whether categorization is needed at all. [sent-32, score-0.222]
</p><p>11 By removing the “unrealistic  simplification”  of us-  ing gold tags (Petrov et al. [sent-33, score-0.521]
</p><p>12 Figure 1: A de{pzende}ncy structure fo|r a s{hzort W}SJ sentence and its probability, factored by the DMV, using gold tags, after summing out PORDER (Spitkovsky et al. [sent-41, score-0.26]
</p><p>13 2  Methodology  In all experiments, we model the English grammar via Klein and Manning’s (2004) Dependency Model with Valence (DMV), induced from subsets of nottoo-long sentences of the Wall Street Journal (WSJ). [sent-43, score-0.273]
</p><p>14 1 The Model The original DMV is a single-state head automata model (Alshawi, 1996) over lexical word classes {cw} gold part-of-speech tags. [sent-45, score-0.299]
</p><p>15 3ts), ,i antuounlabeled dependencies using deterministic “headpercolation” rules (Collins, 1999), and then computing (directed) dependency accuracy scores of the corresponding induced trees. [sent-71, score-0.237]
</p><p>16 39821696265 Table 1: Directed accuracies for the “less is more” DMV, trained on WSJ15 (after 40 steps of EM) and evaluated also against WSJ15, using various lexical categories in  place of gold part-of-speech tags. [sent-95, score-0.334]
</p><p>17 For words that can take on multiple parts of speech, knowing the gold tag can reduce ambiguity, improving parsing by limiting the search space. [sent-98, score-0.358]
</p><p>18 Furthermore, pooling the statistics of words that play similar syntactic roles, as signaled by shared gold part-of-speech tags, can simplify the learning task, improving generalization by reducing sparsity. [sent-99, score-0.26]
</p><p>19 We begin with two sets of experiments that explore the impact that each of these factors has on grammar induction with the DMV. [sent-100, score-0.312]
</p><p>20 The first, most frequent class (mfc), simply maps each token to its most common gold tag in the entire —  WSJ (with ties resolved lexicographically). [sent-115, score-0.38]
</p><p>21 This approach discards two gold tags (types PDT and RBR are not most common for any of the tokens in WSJ15) and costs about three-and-a-half points of accuracy, in both supervised and unsupervised regimes. [sent-116, score-0.737]
</p><p>22 Another reassignment, union all (ua), maps each token to the set of all of its observed gold tags, again in the entire WSJ. [sent-117, score-0.297]
</p><p>23 This inflates the number of groupings by nearly a factor of ten (effectively lexicalizing the most ambiguous words),3 yet improves the oracle skyline by half-a-point over actual gold tags; however, learning is harder with this tag-set, losing more than six points in unsupervised training. [sent-118, score-0.504]
</p><p>24 Our last reassignment, most frequent pair (mfp), allows up to two of the most common tags into a token’s label set (with ties, once again, resolved lexicographically). [sent-119, score-0.297]
</p><p>25 All three models discussed below estimated the DMV without using the gold tags in any way (see Table 1: lexicalized). [sent-123, score-0.521]
</p><p>26 This model is significantly worse for supervised learning, compared even with the monosemous clusters derived from gold tags; yet it is only slightly more learnable than the broken fully-lexicalized variant. [sent-133, score-0.79]
</p><p>27 zero-out  Table 3: Representative members for two of the flat word groupings: cluster #173 (left) contains adjectives, especially ones that take comparative (or other) complements; cluster #188 comprises bare-stem verbs (infinitive stems). [sent-150, score-0.265]
</p><p>28 1284 4 Grammars over Induced Word Clusters We have demonstrated the need for grouping similar words, estimated a bound on performance losses due to monosemous clusterings and are now ready to experiment with induced part-of-speech tags. [sent-156, score-0.585]
</p><p>29 We use two sets of established, publicly-available hard clustering assignments, each computed from a much larger data set than WSJ (approximately a million words). [sent-157, score-0.192]
</p><p>30 The first is a flat mapping (200 clusters) constructed by training Clark’s (2000) distributional similarity model over several hundred million words from the British National and the English Gigaword corpora. [sent-158, score-0.215]
</p><p>31 5 The second is a hierarchical clustering binary strings up to eighteen bits long constructed by running Brown et al. [sent-159, score-0.234]
</p><p>32 1 Experiment #3: A Flat Word Clustering Our main purely unsupervised results are with a flat clustering (Clark, 2000) that groups words having  similar context distributions, according to KullbackLeibler divergence. [sent-162, score-0.493]
</p><p>33 The number of clusters (200) and the sufficient amount of training data (several hundredmillion words) were tuned to a task (NER) that is not directly related to dependency parsing. [sent-165, score-0.191]
</p><p>34 Now every token in WSJ could again be replaced by a coarse identifier (one of at most 201, instead of just 36), in both supervised and unsupervised training. [sent-168, score-0.203]
</p><p>35 ) The resulting supervised model, though not as good as the fully-lexicalized DMV, was more than five points more accurate than with gold part-ofspeech tags (see Table 1: flat). [sent-170, score-0.561]
</p><p>36 Unsupervised accuracy was lower than with gold tags (see also Table 4) but higher than with all three derived hard assignments. [sent-171, score-0.553]
</p><p>37 Models based on gold part-of-speech tags, and derived monosemous clusters (mfc, mfp and ua), shown as vertices of gold polygons. [sent-194, score-1.012]
</p><p>38 Models based on a flat (Clark, 2000) clustering indicated by squares. [sent-195, score-0.367]
</p><p>39 Results for 7 ≤ k ≤ 9 bits (approximately 100–250 nonempty clusters, 9c bloitsse to pthpreo 2xi0m0 we yus 1ed00 before) are 1285 similar to those of flat clusters (see Table 1: hierarchical). [sent-207, score-0.252]
</p><p>40 (2008) demonstrated that (constituent) grammar induction, using the singular-value decomposition (SVD-based) tagger of Sch u¨tze (1995), also works best with 100–200 clusters. [sent-209, score-0.215]
</p><p>41 Important future research directions may include learning to automatically select a good number ofword categories (in the case of flat clusterings)  and ways of using multiple clustering assignments, perhaps of different granularities/resolutions, in tandem (e. [sent-210, score-0.441]
</p><p>42 Since WSJ15 is not a standard test set, we evaluated two key experiments “less is more” with gold part-of-speech tags (#1, Table 1: gold) and with Clark’s (2000) clusters (#3, Table 1: flat) on all sentences (not just length fifteen and shorter), in Section 23 of WSJ (see Table 4). [sent-215, score-0.645]
</p><p>43 clusterings one flat and one hierarchical can be better for dependency grammar induction than monosemous syntactic categories derived from gold part-of-speech tags. [sent-225, score-1.392]
</p><p>44 And we confirmed that the unsupervised tags are worse than the actual gold tags, in a simple dependency grammar induction system. [sent-226, score-1.115]
</p><p>45 A preliminary test will simply quantify the effect of replacing gold part-of-speech tags with the monosemous flat clustering (as in experiment #3, §4. [sent-229, score-1.294]
</p><p>46 And our last experiment mwoildl gauge mthem impact ocefr using a polysemous (but still unsupervised) clustering instead, obtained by executing standard sequence labeling techniques to introduce context-sensitivity into the original (independent) assignment or words to categories. [sent-231, score-0.291]
</p><p>47 The key contribution that differentiates this model from its predecessors is that it incorporates punctuation into grammar induction (by turning it into parsing constraints, in—  stead of ignoring punctuation marks altogether). [sent-234, score-0.481]
</p><p>48 1), we modified the base system xinp exactly one way: we swapped o thuet gold part-of-speech tags and replaced them with a flat distributional similarity clustering. [sent-241, score-0.736]
</p><p>49 In contrast to simpler models, which suffer multi-point drops in accuracy from switching to unsupervised tags (e. [sent-242, score-0.461]
</p><p>50 This result improves over substantial performance degradations previously observed for unsupervised dependency parsing with induced word categories (Klein and —  Manning, 2004; Headden et al. [sent-247, score-0.494]
</p><p>51 7 One risk that arises from using gold tags is that newer systems could be finding cleverer ways to exploit manual labels (i. [sent-249, score-0.521]
</p><p>52 , developing an over-reliance on gold tags) instead of actually learning to acquire language. [sent-251, score-0.26]
</p><p>53 Part-of-speech tags are known to contain significant amounts of information for unlabeled dependency parsing (McDonald et al. [sent-252, score-0.426]
</p><p>54 d1u),ce sor is less dependent on gold tags than its predecessors. [sent-255, score-0.521]
</p><p>55 We next test this conjecture by inducing a polysemous unsupervised word clustering, then using it to induce a grammar. [sent-261, score-0.264]
</p><p>56 , 2008, §4) found thaPt simple bitag h (iHddeeand dMenark etov a models, classically trained using the Baum-Welch (Baum, 1972) variant of EM (HMM-EM), perform quite well,8 on average, across different grammar induction tasks. [sent-263, score-0.312]
</p><p>57 However, they are not better than gold tags, at least when trained using a modest amount of data. [sent-275, score-0.26]
</p><p>58 9 For this reason, we decided to relax the monosemous flat clustering, plugging it in as an initializer for the HMM. [sent-276, score-0.584]
</p><p>59 The main problem with this approach is that, at least without smoothing, every monosemous labeling is trivially at a local optimum, since P(ti | wi) is deterministic. [sent-277, score-0.371]
</p><p>60 First, we collected the MLE statistics for PR(ti+1 | ti) and PL(ti | ti+1) in WSJ, using the flat monosemous tags. [sent-280, score-0.546]
</p><p>61 In the spirit of reproducibility, we again used an off-the-shelf component for tagging-related Viterbi training converged after just 17 steps, replacing the original monosemous tags for 22,280 (of 1,028,348 non-punctuation) tokens in WSJ. [sent-283, score-0.682]
</p><p>62 ’s (2008) grammar induction experiments with induced parts-of-speech were worse than their best results using gold part-of-speech tags, most likely because they used a very small corpus (half of WSJ10) to cluster words. [sent-287, score-0.75]
</p><p>63 However, we suspect that the real gains would come from using soft clustering techniques (Hinton and Roweis, 2003; Pereira et al. [sent-289, score-0.192]
</p><p>64 ) Using this new context-sensitive hard assignment of tokens to unsupervised categories our grammar inducer attained a directed accuracy of 59. [sent-299, score-0.609]
</p><p>65 1%, nearly a full point better than with the monosemous hard assignment (see Table 5). [sent-300, score-0.404]
</p><p>66 To the best of our knowledge it is also the first state-of-the-art unsupervised dependency parser to perform better with induced categories than with gold part-of-speech tags. [sent-301, score-0.665]
</p><p>67 —  6  Related Work  Early work in dependency grammar induction already relied on gold part-of-speech tags (Carroll and Charniak, 1992). [sent-302, score-0.947]
</p><p>68 However, Klein and Manning (2004) demonstrated that effort to be worse at recovering dependency arcs than choosing parse structures at random, leading them to incorporate gold tags into the DMV. [sent-304, score-0.709]
</p><p>69 Klein and Manning (2004, §5, Figure 6) had also tesKtedle itnhe ainrd own nmnoindgel (s2 0w0i4th, i§n5d,u Fciegdu rweo 6r)d h classes, constructed using a distributional similarity clustering method (Sch u¨tze, 1995). [sent-305, score-0.232]
</p><p>70 Without gold part-ofspeech tags, their combined DMV+CCM model was about five points worse, both in (directed) unlabeled dependency accuracy (42. [sent-306, score-0.406]
</p><p>71 In constituent parsing, earlier Seginer (2007a, §6, TaIbnle c 1) tbiutiulet a fully-lexicalized grammar 0i7nad,u§c e6r, 12On the same evaluation set (WSJ10), our context-sensitive system without gold tags (Experiment #6, §5. [sent-313, score-0.703]
</p><p>72 that was competitive with DMV+CCM despite not using gold tags. [sent-316, score-0.26]
</p><p>73 Outside monolingual grammar induction, fullylexicalized statistical dependency transduction models have been trained from unannotated parallel bitexts for machine translation (Alshawi et al. [sent-322, score-0.296]
</p><p>74 (201 1) demonstrated an impressive alternative to grammar induction by projecting reference parse trees from languages that have annotations to ones that are resource-poor. [sent-325, score-0.312]
</p><p>75 13 It uses graph-based label propagation over a bilingual similarity graph for a sentence-aligned parallel corpus (Das and Petrov, 2011), inducing part-of-speech tags from a universal tag-set (Petrov et al. [sent-326, score-0.295]
</p><p>76 Even in supervised parsing we are starting to see a shift away from using gold tags. [sent-328, score-0.351]
</p><p>77 (201 1) demonstrated good results for mapping text to underspecified semantics via dependencies without resorting to gold tags. [sent-330, score-0.26]
</p><p>78 However, aside from the many systems that induce trees from gold tags, there are also unsupervised methods for inducing syntactic categories from gold trees (Finkel et al. [sent-337, score-0.794]
</p><p>79 , 1993), as well as for inducing dependencies from gold constituent annotations (Sangati and Zuidema, 2009; Chiang and Bikel, 2002). [sent-339, score-0.294]
</p><p>80 , 2007), our “punctuation” system 0w7it hev acolunatetixotnsensitive induced tags (trained on WSJ45, without gold tags) performs substantially better, scoring 5 1. [sent-345, score-0.612]
</p><p>81 Note that this is also an improvement over our system trained on the CoNLL set using gold tags: 50. [sent-347, score-0.26]
</p><p>82 1288 7  Discussion and Conclusions  Unsupervised word clustering techniques of Brown et al. [sent-350, score-0.192]
</p><p>83 And both can do better than monosemous clusters derived from gold tags in unsupervised training. [sent-353, score-1.095]
</p><p>84 We showed how Clark’s (2000) flat tags can be relaxed, using context, with the resulting polysemous clustering outperforming gold part-of-speech tags for the English dependency grammar induction task. [sent-354, score-1.639]
</p><p>85 14 Assuming that our results do generalize, it will still remain to remove the present reliance on gold tokenization and sentence boundary labels. [sent-358, score-0.26]
</p><p>86 Nevertheless, we feel that eliminating gold tags is an important step towards the goal of fully-unsupervised dependency parsing. [sent-359, score-0.635]
</p><p>87 , synonymy) is vital to grammar induction with the  DMV. [sent-363, score-0.312]
</p><p>88 Proper intrinsic evaluation of dependency grammar inducers is not yet a solved problem (Schwartz et al. [sent-374, score-0.34]
</p><p>89 —  The polysemy effect appears smaller but is less controversial: Our experiments suggest that the primary drawback of the classic clustering schemes stems from their one class per word nature and not a lack of supervision, as may be widely believed. [sent-379, score-0.271]
</p><p>90 Monosemous groupings, even if they are themselves derived from human-annotated syntactic categories, simply cannot disambiguate words the way gold tags can. [sent-380, score-0.521]
</p><p>91 By relaxing Clark’s (2000) flat clustering, using contextual cues, we improved dependency grammar induction: directed accuracy on Section 23 (all sentences) of the WSJ benchmark increased from 58. [sent-381, score-0.561]
</p><p>92 1% from slightly worse to better than with gold tags (58. [sent-383, score-0.563]
</p><p>93 —  —  Since Clark’s (2000) word clustering algorithm is already context-sensitive in training, we suspect that one could do better simply by preserving the polysemous nature of its internal representation. [sent-385, score-0.256]
</p><p>94 Importing the relevant distributions into a sequence tagger di-  rectly would make more sense than going through an intermediate monosemous summary. [sent-386, score-0.404]
</p><p>95 And exploring other uses of soft clustering algorithms perhaps as inputs to part-of-speech disambiguators may be another fruitful research direction. [sent-387, score-0.257]
</p><p>96 We believe that a joint treatment of grammar and parts-of-speech induction could fuel major advances in both tasks. [sent-388, score-0.312]
</p><p>97 Improving unsupervised dependency parsing with richer contexts and smoothing. [sent-537, score-0.291]
</p><p>98 Neutralizing linguistically problematic annotations in unsupervised dependency parsing evaluation. [sent-667, score-0.291]
</p><p>99 Baby Steps: How “Less is More” in unsupervised dependency parsing. [sent-695, score-0.24]
</p><p>100 From Baby Steps to Leapfrog: How “Less is More” in unsupervised dependency parsing. [sent-703, score-0.24]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('monosemous', 0.371), ('tags', 0.261), ('gold', 0.26), ('pstop', 0.24), ('spitkovsky', 0.196), ('dmv', 0.192), ('clustering', 0.192), ('grammar', 0.182), ('flat', 0.175), ('wsj', 0.156), ('alshawi', 0.148), ('headden', 0.136), ('induction', 0.13), ('unsupervised', 0.126), ('clark', 0.114), ('dependency', 0.114), ('vbd', 0.11), ('pattach', 0.109), ('induced', 0.091), ('inducer', 0.087), ('klein', 0.082), ('clusters', 0.077), ('categories', 0.074), ('abend', 0.068), ('disambiguators', 0.065), ('ua', 0.065), ('polysemous', 0.064), ('christodoulopoulos', 0.063), ('reichart', 0.063), ('brown', 0.061), ('petrov', 0.061), ('punctuation', 0.059), ('nns', 0.059), ('dir', 0.059), ('directed', 0.058), ('cool', 0.056), ('manning', 0.056), ('sangati', 0.051), ('groupings', 0.051), ('alia', 0.051), ('parsing', 0.051), ('tokens', 0.05), ('viterbi', 0.05), ('fifteen', 0.047), ('tag', 0.047), ('mcdonald', 0.046), ('polysemy', 0.045), ('cluster', 0.045), ('clusterings', 0.044), ('grouping', 0.044), ('ccm', 0.044), ('inducers', 0.044), ('mfc', 0.044), ('mfp', 0.044), ('porder', 0.044), ('reassignment', 0.044), ('reassignments', 0.044), ('selman', 0.044), ('skylines', 0.044), ('zoomed', 0.044), ('worse', 0.042), ('switching', 0.042), ('hierarchical', 0.042), ('finkel', 0.041), ('distributional', 0.04), ('induce', 0.04), ('supervised', 0.04), ('categorization', 0.04), ('head', 0.039), ('lexicalization', 0.038), ('synonymy', 0.038), ('inter', 0.038), ('isn', 0.038), ('ch', 0.038), ('lexicographically', 0.038), ('ablative', 0.038), ('paskin', 0.038), ('ccl', 0.038), ('degradations', 0.038), ('initializer', 0.038), ('token', 0.037), ('stanford', 0.037), ('banko', 0.037), ('nn', 0.036), ('frequent', 0.036), ('experiment', 0.035), ('tagging', 0.034), ('inducing', 0.034), ('classic', 0.034), ('zuidema', 0.034), ('hiyan', 0.034), ('skyline', 0.034), ('baby', 0.034), ('leapfrog', 0.034), ('nearly', 0.033), ('tagger', 0.033), ('thesis', 0.033), ('accuracy', 0.032), ('em', 0.032), ('arcs', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="141-tfidf-1" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>2 0.19573145 <a title="141-tfidf-2" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>Author: Ryan McDonald ; Slav Petrov ; Keith Hall</p><p>Abstract: We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data. We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsupervised parsers. We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser. Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source lan- guages can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages.</p><p>3 0.18868764 <a title="141-tfidf-3" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>Author: Shay B. Cohen ; Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages. Our approach is based on a model that locally mixes between supervised models from the helper languages. Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable. We obtain state-of-theart performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing.</p><p>4 0.15370224 <a title="141-tfidf-4" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>5 0.13891144 <a title="141-tfidf-5" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>Author: Christos Christodoulopoulos ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: In this paper we present a fully unsupervised syntactic class induction system formulated as a Bayesian multinomial mixture model, where each word type is constrained to belong to a single class. By using a mixture model rather than a sequence model (e.g., HMM), we are able to easily add multiple kinds of features, including those at both the type level (morphology features) and token level (context and alignment features, the latter from parallel corpora). Using only context features, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested.</p><p>6 0.13885891 <a title="141-tfidf-6" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>7 0.13800731 <a title="141-tfidf-7" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>8 0.13167039 <a title="141-tfidf-8" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>9 0.12649404 <a title="141-tfidf-9" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>10 0.10908768 <a title="141-tfidf-10" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>11 0.10732554 <a title="141-tfidf-11" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>12 0.09931083 <a title="141-tfidf-12" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>13 0.098141626 <a title="141-tfidf-13" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>14 0.09787941 <a title="141-tfidf-14" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>15 0.089935079 <a title="141-tfidf-15" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>16 0.089894757 <a title="141-tfidf-16" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>17 0.086549461 <a title="141-tfidf-17" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>18 0.08517544 <a title="141-tfidf-18" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>19 0.083302073 <a title="141-tfidf-19" href="./emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">15 emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>20 0.082188934 <a title="141-tfidf-20" href="./emnlp-2011-Universal_Morphological_Analysis_using_Structured_Nearest_Neighbor_Prediction.html">140 emnlp-2011-Universal Morphological Analysis using Structured Nearest Neighbor Prediction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.285), (1, 0.063), (2, -0.103), (3, 0.222), (4, -0.079), (5, 0.139), (6, -0.132), (7, -0.004), (8, -0.075), (9, 0.026), (10, -0.058), (11, 0.1), (12, 0.075), (13, 0.029), (14, 0.124), (15, 0.167), (16, 0.103), (17, 0.125), (18, -0.034), (19, 0.182), (20, -0.046), (21, 0.098), (22, -0.003), (23, 0.033), (24, -0.016), (25, 0.047), (26, -0.081), (27, -0.045), (28, -0.091), (29, -0.051), (30, -0.063), (31, 0.032), (32, 0.017), (33, 0.086), (34, -0.087), (35, -0.1), (36, -0.084), (37, -0.05), (38, 0.018), (39, 0.2), (40, -0.054), (41, -0.025), (42, 0.055), (43, 0.064), (44, -0.034), (45, 0.118), (46, 0.161), (47, -0.053), (48, -0.071), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96891046 <a title="141-lsi-1" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>2 0.70702267 <a title="141-lsi-2" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>Author: Shay B. Cohen ; Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages. Our approach is based on a model that locally mixes between supervised models from the helper languages. Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable. We obtain state-of-theart performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing.</p><p>3 0.7046659 <a title="141-lsi-3" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Daniel Jurafsky</p><p>Abstract: We present new training methods that aim to mitigate local optima and slow convergence in unsupervised training by using additional imperfect objectives. In its simplest form, lateen EM alternates between the two objectives of ordinary “soft” and “hard” expectation maximization (EM) algorithms. Switching objectives when stuck can help escape local optima. We find that applying a single such alternation already yields state-of-the-art results for English dependency grammar induction. More elaborate lateen strategies track both objectives, with each validating the moves proposed by the other. Disagreements can signal earlier opportunities to switch or terminate, saving iterations. De-emphasizing fixed points in these ways eliminates some guesswork from tuning EM. An evaluation against a suite of unsupervised dependency parsing tasks, for a vari- ety of languages, showed that lateen strategies significantly speed up training of both EM algorithms, and improve accuracy for hard EM.</p><p>4 0.60979992 <a title="141-lsi-4" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>Author: Lin Sun ; Anna Korhonen</p><p>Abstract: Most previous research on verb clustering has focussed on acquiring flat classifications from corpus data, although many manually built classifications are taxonomic in nature. Also Natural Language Processing (NLP) applications benefit from taxonomic classifications because they vary in terms of the granularity they require from a classification. We introduce a new clustering method called Hierarchical Graph Factorization Clustering (HGFC) and extend it so that it is optimal for the task. Our results show that HGFC outperforms the frequently used agglomerative clustering on a hierarchical test set extracted from VerbNet, and that it yields state-of-the-art performance also on a flat test set. We demonstrate how the method can be used to acquire novel classifications as well as to extend existing ones on the basis of some prior knowledge about the classification.</p><p>5 0.56216872 <a title="141-lsi-5" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>Author: Ryan McDonald ; Slav Petrov ; Keith Hall</p><p>Abstract: We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data. We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsupervised parsers. We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser. Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source lan- guages can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages.</p><p>6 0.49430773 <a title="141-lsi-6" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>7 0.46676242 <a title="141-lsi-7" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>8 0.44044492 <a title="141-lsi-8" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>9 0.43795958 <a title="141-lsi-9" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>10 0.43749687 <a title="141-lsi-10" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>11 0.43728948 <a title="141-lsi-11" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>12 0.41732275 <a title="141-lsi-12" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>13 0.41652867 <a title="141-lsi-13" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>14 0.39553392 <a title="141-lsi-14" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>15 0.35190955 <a title="141-lsi-15" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>16 0.35020095 <a title="141-lsi-16" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>17 0.34274584 <a title="141-lsi-17" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>18 0.33349037 <a title="141-lsi-18" href="./emnlp-2011-Syntactic_Decision_Tree_LMs%3A_Random_Selection_or_Intelligent_Design%3F.html">131 emnlp-2011-Syntactic Decision Tree LMs: Random Selection or Intelligent Design?</a></p>
<p>19 0.30165404 <a title="141-lsi-19" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>20 0.29773569 <a title="141-lsi-20" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.077), (36, 0.022), (37, 0.024), (45, 0.048), (53, 0.017), (54, 0.023), (57, 0.011), (62, 0.014), (64, 0.046), (66, 0.452), (69, 0.013), (79, 0.053), (82, 0.015), (87, 0.011), (90, 0.026), (96, 0.066), (98, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.96766734 <a title="141-lda-1" href="./emnlp-2011-Feature-Rich_Language-Independent_Syntax-Based_Alignment_for_Statistical_Machine_Translation.html">60 emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</a></p>
<p>Author: Jason Riesa ; Ann Irvine ; Daniel Marcu</p><p>Abstract: unkown-abstract</p><p>2 0.9032858 <a title="141-lda-2" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>Author: Tim Van de Cruys ; Thierry Poibeau ; Anna Korhonen</p><p>Abstract: This paper presents a novel method for the computation of word meaning in context. We make use of a factorization model in which words, together with their window-based context words and their dependency relations, are linked to latent dimensions. The factorization model allows us to determine which dimensions are important for a particular context, and adapt the dependency-based feature vector of the word accordingly. The evaluation on a lexical substitution task carried out for both English and French – indicates that our approach is able to reach better results than state-of-the-art methods in lexical substitution, while at the same time providing more accurate meaning representations. –</p><p>same-paper 3 0.9016273 <a title="141-lda-3" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>4 0.79752517 <a title="141-lda-4" href="./emnlp-2011-Universal_Morphological_Analysis_using_Structured_Nearest_Neighbor_Prediction.html">140 emnlp-2011-Universal Morphological Analysis using Structured Nearest Neighbor Prediction</a></p>
<p>Author: Young-Bum Kim ; Joao Graca ; Benjamin Snyder</p><p>Abstract: In this paper, we consider the problem of unsupervised morphological analysis from a new angle. Past work has endeavored to design unsupervised learning methods which explicitly or implicitly encode inductive biases appropriate to the task at hand. We propose instead to treat morphological analysis as a structured prediction problem, where languages with labeled data serve as training examples for unlabeled languages, without the assumption of parallel data. We define a universal morphological feature space in which every language and its morphological analysis reside. We develop a novel structured nearest neighbor prediction method which seeks to find the morphological analysis for each unlabeled lan- guage which lies as close as possible in the feature space to a training language. We apply our model to eight inflecting languages, and induce nominal morphology with substantially higher accuracy than a traditional, MDLbased approach. Our analysis indicates that accuracy continues to improve substantially as the number of training languages increases.</p><p>5 0.53889835 <a title="141-lda-5" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>Author: Diarmuid O Seaghdha ; Anna Korhonen</p><p>Abstract: This paper investigates novel methods for incorporating syntactic information in probabilistic latent variable models of lexical choice and contextual similarity. The resulting models capture the effects of context on the interpretation of a word and in particular its effect on the appropriateness of replacing that word with a potentially related one. Evaluating our techniques on two datasets, we report performance above the prior state of the art for estimating sentence similarity and ranking lexical substitutes.</p><p>6 0.53487962 <a title="141-lda-6" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>7 0.5046953 <a title="141-lda-7" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>8 0.50144637 <a title="141-lda-8" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>9 0.48165399 <a title="141-lda-9" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>10 0.47980505 <a title="141-lda-10" href="./emnlp-2011-Discovering_Morphological_Paradigms_from_Plain_Text_Using_a_Dirichlet_Process_Mixture_Model.html">39 emnlp-2011-Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model</a></p>
<p>11 0.47149587 <a title="141-lda-11" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>12 0.4627026 <a title="141-lda-12" href="./emnlp-2011-Tuning_as_Ranking.html">138 emnlp-2011-Tuning as Ranking</a></p>
<p>13 0.46213278 <a title="141-lda-13" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>14 0.45975277 <a title="141-lda-14" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>15 0.45313495 <a title="141-lda-15" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>16 0.4514561 <a title="141-lda-16" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>17 0.44277188 <a title="141-lda-17" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>18 0.44226325 <a title="141-lda-18" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>19 0.43975672 <a title="141-lda-19" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>20 0.43106791 <a title="141-lda-20" href="./emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">127 emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
