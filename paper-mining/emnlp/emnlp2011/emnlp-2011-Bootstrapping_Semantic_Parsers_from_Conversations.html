<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-24" href="#">emnlp2011-24</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</h1>
<br/><p>Source: <a title="emnlp-2011-24-pdf" href="http://aclweb.org/anthology//D/D11/D11-1039.pdf">pdf</a></p><p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>Reference: <a title="emnlp-2011-24-reference" href="../emnlp2011_reference/emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Bootstrapping Semantic Parsers from Conversations Yoav Artzi and Luke Zettlemoyer Computer Science & Engineering University of Washington Seattle, WA 98195  {yoav, l z }@ cs s Abstract Conversations provide rich opportunities for interactive, continuous learning. [sent-1, score-0.055]
</p><p>2 When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. [sent-2, score-0.151]
</p><p>3 In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. [sent-3, score-0.453]
</p><p>4 We demonstrate learning without any explicit annotation of the meanings of user utterances. [sent-4, score-0.463]
</p><p>5 Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. [sent-5, score-0.397]
</p><p>6 This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. [sent-6, score-0.583]
</p><p>7 Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean-  . [sent-7, score-0.474]
</p><p>8 1 Introduction Conversational interactions provide significant opportunities for autonomous learning. [sent-9, score-0.204]
</p><p>9 A well-defined goal allows a system to engage in remediations when confused, such as asking for clarification, rewording, or additional explanation. [sent-10, score-0.256]
</p><p>10 The user’s response to such requests provides a strong, if often indirect, signal that can be used to learn to avoid the original confusion in future conversations. [sent-11, score-0.173]
</p><p>11 In this paper, we show how to use this type of conversational feedback to learn to better recover the meaning of user utterances, by inducing semantic parsers from 421 . [sent-12, score-1.11]
</p><p>12 We believe that this style of learning will contribute to the long term goal of building self-improving dialog systems that continually learn from their mistakes, with little or no human intervention. [sent-15, score-0.386]
</p><p>13 Many dialog systems use a semantic parsing com-  ponent to analyze user utterances (e. [sent-16, score-0.728]
</p><p>14 For example, in a flight booking system, the sentence Sent: I want to go to Seattle on Friday LF: λx. [sent-22, score-0.142]
</p><p>15 to(x, SEA) ∧ date(x, FRI) might be mapped to the logical form (LF) meaning representation above, a lambda-calculus expression defining the set of flights that match the user’s desired constraints. [sent-23, score-0.254]
</p><p>16 This LF is a representation of the semantic content that comes from the sentence, and would be input to a context-dependent understanding component in a full dialog system, for example to find the date that the symbol FRI refers to. [sent-24, score-0.388]
</p><p>17 To induce semantic parsers from interactions, we consider user statements in conversational logs and model their meaning with latent variables. [sent-25, score-1.058]
</p><p>18 We demonstrate that it is often possible to use the dialog that follows a statement (including remediations such as clarifications, simplifications, etc. [sent-26, score-0.527]
</p><p>19 For example, consider the first user utterance in Figure 1, where the system failed to understand the user’s request. [sent-28, score-0.585]
</p><p>20 To complete the task, the system must use a remediation strategy. [sent-29, score-0.103]
</p><p>21 Here, it takes the initiative by ask-  ing for and confirming each flight constraint in turn. [sent-30, score-0.105]
</p><p>22 This strategy produces an unnatural conversation but provides supervision for learning the meaning of the Proce Ed iningbsu orfg th ,e S 2c0o1tl1an Cdo,n UfeKr,en Jcuely on 27 E–m31p,ir 2ic0a1l1 M. [sent-31, score-0.467]
</p><p>23 We can easily record representations of the meanings the system intended to convey at each step, as seen in Figure 1, and use this indirect supervision for learning. [sent-34, score-0.261]
</p><p>24 In any specific conversation, the system’s remediations can fail to recover aspects of the original user meaning and can introduce spurious constraints, for example when users change their goals mid conversation. [sent-36, score-0.683]
</p><p>25 To learn effectively, the model must accumulate evidence from many interactions to best recover the meaning of each specific sentence. [sent-37, score-0.426]
</p><p>26 We will learn semantic parsers defined by probabilistic Combinatory Categorial Grammars (PCCGs), which include both a lexicon and a weighted linear model for parse selection. [sent-38, score-0.313]
</p><p>27 The lexicon specifies the meanings of individual words and phrases, while the parameters of a parsing model define how to best combine word- and phrase-level mean-  ings to analyze complete sentences. [sent-39, score-0.228]
</p><p>28 To learn without labeled meaning representations, we make use of a variant of the loss-sensitive Perceptron algorithm (Singh-Miller and Collins, 2007). [sent-40, score-0.203]
</p><p>29 We define loss functions to provide a rough measure of (1) how well a candidate meaning for a utterance matches the conversation that follows it and (2) how well the candidate matches our expectations about the types of things that are often said in the dialog’s domain. [sent-41, score-0.728]
</p><p>30 These notions of loss drive not only the parameter estimation but also the grammar induction process that constructs the CCG lexicon. [sent-42, score-0.112]
</p><p>31 Experiments on conversation logs from the DARPA Communicator corpus (Walker et al. [sent-43, score-0.398]
</p><p>32 This paper makes the following contributions: •  •  A formalization of the problem of learning tAhe meaning toiof user s tthateem preonbtsle fmrom of conversational feedback, without requiring annotation. [sent-45, score-0.761]
</p><p>33 A new loss-sensitive learning algorithm for this problem tsh-sate isnidtiuvcee lse srenminagn atligc parsers frr tohmis conversation logs. [sent-46, score-0.392]
</p><p>34 •  •  Loss functions to measure the quality of hypotLhoestisca ful nuctttieornasnc toe meanings weit qhuianl tthye o conversation in which they appear. [sent-47, score-0.41]
</p><p>35 An evaluation on logs from two dialog systems 422  SYSTEM: how can ihelp you? [sent-48, score-0.422]
</p><p>36 (OPEN TASK) USER: i would like to fly from atlanta georgia to london england on september twenty fourth in the early evening iwould like to return on october first departing from london in the late morning SYSTEM: leaving what city? [sent-49, score-0.722]
</p><p>37 (CONFIRM:to(fl, LON)) what date would you like to depart atlanta? [sent-55, score-0.095]
</p><p>38 from(fl, ATL) ∧ departdate(fl, x)) USER: september twenty fourth in the early evening [conversation continues] Figure 1: Conversational excerpt from a DARPA Communicator travel-planning dialog. [sent-57, score-0.235]
</p><p>39 Each system statement is labeled with representations of its speech act and log-  ical meaning, in parentheses. [sent-58, score-0.125]
</p><p>40 Conversations of this type provide the training data to learn semantic parsers for user utterances. [sent-60, score-0.531]
</p><p>41 2  Problem  Our goal is to learn a function that maps a sentence x to a lambda-calculus expression z. [sent-62, score-0.073]
</p><p>42 We assume access to logs of conversations with automatically generated annotation of system utterance meanings, but no explicit labeling of each user utterance meaning. [sent-63, score-1.123]
</p><p>43 We define a conversation C = O) to be a se-  (U~,  sU~at  quence eoffin uett aer caonncveesr = [u0, . [sent-64, score-0.323]
</p><p>44 An object o ∈ O is an entity that is being discussed, feocrt example there would be a unique object for each flight leg discussed in a travel planning conversation. [sent-68, score-0.332]
</p><p>45 Each utterance ui = (s, x, a, z) represents the speaker s ∈ {User, System} producing the natural language sUtasteemr,eSnyt x wmh}ic hp oadssuecrtisn a speech aractl a ∈ {ASK, CONFIRM, . [sent-69, score-0.271]
</p><p>46 o}m w tithhe mseecaonnidn system eunt--  terance in Figure 1 the question x =“Leaving what city? [sent-75, score-0.047]
</p><p>47 ” is an a=ASK speech act with lambda-calculus meaning z = λx. [sent-76, score-0.167]
</p><p>48 This meaning represents the fact that the system asked for the departure city for the conversational object o = fl representing the flight leg that is currently being discussed. [sent-78, score-0.99]
</p><p>49 We will learn from conversations where the speech acts a and logical forms z for user utterances are unlabeled. [sent-79, score-0.806]
</p><p>50 Finally, since we will be analyzing sentences at a specific point in a complete conversation, we define our training data as a set {(ji, Ci) |i = 1. [sent-81, score-0.056]
</p><p>51 Each pair risa a icnognv daetrsaa atiso an Ci a{(ndj ,thCe i|nid =ex 1 ji o. [sent-85, score-0.084]
</p><p>52 e E user utterance x vine Ci wtiohnos Ce meaning we will attempt to luettaernra ntoc recover. [sent-87, score-0.668]
</p><p>53 In general, the same conversation C can be used in multiple examples, each with a diffCe creannt bseen utesendce in nin mdeuxlt. [sent-88, score-0.252]
</p><p>54 i pSleec etxioanm 8p provides twhiet hde ata diilfsof how the data was gathered for our experiments. [sent-89, score-0.034]
</p><p>55 3  Overview of Approach  We will present an algorithm for learning a weighted CCG parser, as defined in Section 5, that can be used  to map sentences to logical forms. [sent-90, score-0.159]
</p><p>56 The approach induces a lexicon to represent the meanings of words and phrases while also estimating the parameters of a weighted linear model for selecting the best parse given the lexicon. [sent-91, score-0.26]
</p><p>57 F oofr nea tcrhai example, our goal jis, tCo learn to parse ,tnhe} user utterance x at position ji i tno Ci. [sent-96, score-0.769]
</p><p>58 Tnh teo training data contains no direct evidencei nab Cout the logical form z that should be paired with x, or the CCG analysis that would be used to construct z. [sent-97, score-0.161]
</p><p>59 We model all of these choices as latent variables. [sent-98, score-0.034]
</p><p>60 To learn effectively in this complex, latent space, we introduce a loss function L(z, j,C) ∈ R that measures uhcoew a w loeslsl a logical Lfo(zrm,j z )m o∈dels the meaning for the user utterance at position j in C. [sent-99, score-1.011]
</p><p>61 In mSeecatinoinng 6, we wei ulls present tnhcee d aetta piolss otiof tnhe j lions Cs we use, which is designed to be sensitive to remediations in C (system requests for clarification, etc. [sent-100, score-0.234]
</p><p>62 )n bduot not uniquely determine which z should be selected, for example when the user prematurely ends the discussion. [sent-102, score-0.304]
</p><p>63 Then, in Section 7, we present an approach for incorporating this loss function into a complete  algorithm that induces a CCG lexicon and estimates the parameters of the parsing model. [sent-103, score-0.272]
</p><p>64 This learning setup focuses on a subproblem in dialog; semantic interpretation. [sent-104, score-0.051]
</p><p>65 We do not yet learn to recover user speech acts or integrate the logical 423 form into the context of the conversation. [sent-105, score-0.628]
</p><p>66 Each sentence is analyzed with the learned model alone; the loss function and any conversational context are not used during evaluation. [sent-114, score-0.402]
</p><p>67 Parsers that perform well in this setting will be strong candidates for inclusion in a more complete dialog system, as motivated in Section 1. [sent-115, score-0.332]
</p><p>68 4  Related Work  Most previous work on learning from conversational interactions has focused on the dialog sub-problems of response planning (e. [sent-116, score-0.783]
</p><p>69 We are not aware of previous work on inducing semantic parsers from conversations. [sent-123, score-0.194]
</p><p>70 There has been significant work on supervised learning for inducing semantic parsers. [sent-124, score-0.091]
</p><p>71 The algorithms we develop in this paper build on previous work on supervised learning of CCG parsers (Zettlemoyer and Collins, 2005; 2007), as we describe in Section 5. [sent-131, score-0.103]
</p><p>72 There is also work on learning to do semantic analysis with alternate forms of supervision. [sent-133, score-0.051]
</p><p>73 (201 1) describe approaches for learning semantic parsers from ques-  tions paired with database  answers,  wasser et al. [sent-136, score-0.154]
</p><p>74 while Gold-  work on unsuper-  Our approach provides an alterna-  tive method of supervision that could complement these approaches. [sent-138, score-0.048]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('user', 0.304), ('conversational', 0.29), ('dialog', 0.276), ('conversation', 0.252), ('fl', 0.234), ('utterance', 0.234), ('remediations', 0.172), ('conversations', 0.158), ('logs', 0.146), ('meaning', 0.13), ('communicator', 0.129), ('logical', 0.124), ('meanings', 0.121), ('ccg', 0.118), ('mooney', 0.118), ('loss', 0.112), ('interactions', 0.112), ('atlanta', 0.111), ('clarification', 0.111), ('flight', 0.105), ('ask', 0.104), ('parsers', 0.103), ('utterances', 0.097), ('lf', 0.093), ('london', 0.093), ('evening', 0.086), ('georgia', 0.086), ('leg', 0.086), ('rewording', 0.086), ('ji', 0.084), ('recover', 0.077), ('fri', 0.074), ('learn', 0.073), ('ci', 0.069), ('leaving', 0.067), ('planning', 0.067), ('twenty', 0.062), ('requests', 0.062), ('city', 0.061), ('date', 0.061), ('darpa', 0.059), ('atl', 0.058), ('complete', 0.056), ('opportunities', 0.055), ('confirm', 0.053), ('induces', 0.053), ('semantic', 0.051), ('lexicon', 0.051), ('yoav', 0.05), ('acts', 0.05), ('nx', 0.05), ('seattle', 0.05), ('september', 0.05), ('zettlemoyer', 0.048), ('supervision', 0.048), ('system', 0.047), ('indirect', 0.045), ('young', 0.042), ('feedback', 0.042), ('statement', 0.041), ('inducing', 0.04), ('response', 0.038), ('demonstrate', 0.038), ('act', 0.037), ('object', 0.037), ('hp', 0.037), ('iwould', 0.037), ('nea', 0.037), ('arriving', 0.037), ('autonomous', 0.037), ('booking', 0.037), ('continually', 0.037), ('dels', 0.037), ('departing', 0.037), ('engage', 0.037), ('eoffin', 0.037), ('excerpt', 0.037), ('frpom', 0.037), ('kleindienst', 0.037), ('lse', 0.037), ('nab', 0.037), ('ndj', 0.037), ('oofr', 0.037), ('pccgs', 0.037), ('ramaswamy', 0.037), ('ruifang', 0.037), ('toiof', 0.037), ('tthye', 0.037), ('unnatural', 0.037), ('wmh', 0.037), ('weighted', 0.035), ('latent', 0.034), ('higherorder', 0.034), ('kate', 0.034), ('accumulate', 0.034), ('aer', 0.034), ('allen', 0.034), ('artzi', 0.034), ('ata', 0.034), ('depart', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="24-tfidf-1" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>2 0.16057807 <a title="24-tfidf-2" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>3 0.14896996 <a title="24-tfidf-3" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>Author: Alan Ritter ; Colin Cherry ; William B. Dolan</p><p>Abstract: Ottawa, Ontario, K1A 0R6 Co l . Cherry@ nrc-cnrc . gc . ca in Redmond, WA 98052 bi l ldol @mi cro so ft . com large corpus of status-response pairs found on Twitter to create a system that responds to Twitter status We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.</p><p>4 0.13663188 <a title="24-tfidf-4" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>Author: Wei Lu ; Hwee Tou Ng</p><p>Abstract: This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus. The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences. Sentences can then be generated based on such grammar rules with a log-linear model. To acquire such grammar rules automatically in an unsupervised manner, we also propose a novel approach with a generative model, which maps from sub-expressions of logical forms to word sequences in natural language sentences. Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.</p><p>5 0.10368679 <a title="24-tfidf-5" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>Author: Deepak Agarwal ; Bee-Chung Chen ; Bo Pang</p><p>Abstract: In recent years, the amount of user-generated opinionated texts (e.g., reviews, user comments) continues to grow at a rapid speed: featured news stories on a major event easily attract thousands of user comments on a popular online News service. How to consume subjective information ofthis volume becomes an interesting and important research question. In contrast to previous work on review analysis that tried to filter or summarize information for a generic average user, we explore a different direction of enabling personalized recommendation of such information. For each user, our task is to rank the comments associated with a given article according to personalized user preference (i.e., whether the user is likely to like or dislike the comment). To this end, we propose a factor model that incorporates rater-comment and rater-author interactions simultaneously in a principled way. Our full model significantly outperforms strong baselines as well as related models that have been considered in previous work.</p><p>6 0.096125551 <a title="24-tfidf-6" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>7 0.093533754 <a title="24-tfidf-7" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>8 0.088877797 <a title="24-tfidf-8" href="./emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">130 emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>9 0.083241656 <a title="24-tfidf-9" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>10 0.078076959 <a title="24-tfidf-10" href="./emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">121 emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<p>11 0.073417552 <a title="24-tfidf-11" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>12 0.067818217 <a title="24-tfidf-12" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>13 0.06505359 <a title="24-tfidf-13" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>14 0.058691613 <a title="24-tfidf-14" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>15 0.052751005 <a title="24-tfidf-15" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>16 0.045155037 <a title="24-tfidf-16" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>17 0.043439105 <a title="24-tfidf-17" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>18 0.043367837 <a title="24-tfidf-18" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>19 0.03863132 <a title="24-tfidf-19" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>20 0.037329737 <a title="24-tfidf-20" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.163), (1, -0.052), (2, 0.05), (3, 0.003), (4, 0.004), (5, -0.033), (6, -0.098), (7, 0.033), (8, 0.12), (9, -0.027), (10, -0.245), (11, -0.134), (12, -0.279), (13, -0.244), (14, -0.012), (15, 0.108), (16, 0.053), (17, -0.129), (18, -0.033), (19, -0.066), (20, -0.007), (21, -0.095), (22, -0.225), (23, -0.028), (24, 0.073), (25, -0.051), (26, -0.002), (27, 0.005), (28, 0.042), (29, 0.001), (30, -0.011), (31, -0.069), (32, 0.03), (33, 0.036), (34, -0.085), (35, 0.094), (36, -0.071), (37, -0.122), (38, -0.014), (39, 0.029), (40, 0.089), (41, -0.012), (42, 0.078), (43, -0.032), (44, 0.005), (45, -0.021), (46, 0.066), (47, 0.023), (48, 0.093), (49, -0.14)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97559911 <a title="24-lsi-1" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>2 0.5641048 <a title="24-lsi-2" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>3 0.51548624 <a title="24-lsi-3" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>Author: Deepak Agarwal ; Bee-Chung Chen ; Bo Pang</p><p>Abstract: In recent years, the amount of user-generated opinionated texts (e.g., reviews, user comments) continues to grow at a rapid speed: featured news stories on a major event easily attract thousands of user comments on a popular online News service. How to consume subjective information ofthis volume becomes an interesting and important research question. In contrast to previous work on review analysis that tried to filter or summarize information for a generic average user, we explore a different direction of enabling personalized recommendation of such information. For each user, our task is to rank the comments associated with a given article according to personalized user preference (i.e., whether the user is likely to like or dislike the comment). To this end, we propose a factor model that incorporates rater-comment and rater-author interactions simultaneously in a principled way. Our full model significantly outperforms strong baselines as well as related models that have been considered in previous work.</p><p>4 0.50263983 <a title="24-lsi-4" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>Author: Benjamin Borschinger ; Bevan K. Jones ; Mark Johnson</p><p>Abstract: It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.1</p><p>5 0.45304593 <a title="24-lsi-5" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>Author: Wei Lu ; Hwee Tou Ng</p><p>Abstract: This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus. The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences. Sentences can then be generated based on such grammar rules with a log-linear model. To acquire such grammar rules automatically in an unsupervised manner, we also propose a novel approach with a generative model, which maps from sub-expressions of logical forms to word sequences in natural language sentences. Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.</p><p>6 0.45239285 <a title="24-lsi-6" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>7 0.33162403 <a title="24-lsi-7" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>8 0.31929037 <a title="24-lsi-8" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>9 0.31100905 <a title="24-lsi-9" href="./emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">130 emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>10 0.30931452 <a title="24-lsi-10" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>11 0.30842912 <a title="24-lsi-11" href="./emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">121 emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<p>12 0.28755707 <a title="24-lsi-12" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>13 0.28535551 <a title="24-lsi-13" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>14 0.27503991 <a title="24-lsi-14" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>15 0.23837288 <a title="24-lsi-15" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>16 0.23599055 <a title="24-lsi-16" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>17 0.23553152 <a title="24-lsi-17" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>18 0.20987965 <a title="24-lsi-18" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>19 0.20709573 <a title="24-lsi-19" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>20 0.20660223 <a title="24-lsi-20" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.088), (36, 0.011), (37, 0.012), (45, 0.036), (53, 0.013), (54, 0.06), (57, 0.014), (62, 0.012), (64, 0.018), (66, 0.02), (69, 0.011), (79, 0.06), (82, 0.01), (87, 0.533), (96, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85231704 <a title="24-lda-1" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>2 0.61086458 <a title="24-lda-2" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>3 0.5477587 <a title="24-lda-3" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>4 0.3004154 <a title="24-lda-4" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>5 0.2906037 <a title="24-lda-5" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>Author: Alan Ritter ; Colin Cherry ; William B. Dolan</p><p>Abstract: Ottawa, Ontario, K1A 0R6 Co l . Cherry@ nrc-cnrc . gc . ca in Redmond, WA 98052 bi l ldol @mi cro so ft . com large corpus of status-response pairs found on Twitter to create a system that responds to Twitter status We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.</p><p>6 0.27992678 <a title="24-lda-6" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>7 0.27384761 <a title="24-lda-7" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>8 0.27199662 <a title="24-lda-8" href="./emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">94 emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>9 0.26599994 <a title="24-lda-9" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>10 0.26384747 <a title="24-lda-10" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>11 0.25987953 <a title="24-lda-11" href="./emnlp-2011-Computation_of_Infix_Probabilities_for_Probabilistic_Context-Free_Grammars.html">31 emnlp-2011-Computation of Infix Probabilities for Probabilistic Context-Free Grammars</a></p>
<p>12 0.25981435 <a title="24-lda-12" href="./emnlp-2011-Generating_Subsequent_Reference_in_Shared_Visual_Scenes%3A_Computation_vs_Re-Use.html">62 emnlp-2011-Generating Subsequent Reference in Shared Visual Scenes: Computation vs Re-Use</a></p>
<p>13 0.25886825 <a title="24-lda-13" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>14 0.25732854 <a title="24-lda-14" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>15 0.25290212 <a title="24-lda-15" href="./emnlp-2011-Hierarchical_Phrase-based_Translation_Representations.html">66 emnlp-2011-Hierarchical Phrase-based Translation Representations</a></p>
<p>16 0.2516292 <a title="24-lda-16" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>17 0.24951485 <a title="24-lda-17" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>18 0.24807297 <a title="24-lda-18" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>19 0.2414009 <a title="24-lda-19" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>20 0.24068451 <a title="24-lda-20" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
