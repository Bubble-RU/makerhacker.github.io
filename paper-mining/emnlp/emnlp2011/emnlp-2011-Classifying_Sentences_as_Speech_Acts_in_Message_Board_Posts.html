<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-27" href="#">emnlp2011-27</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</h1>
<br/><p>Source: <a title="emnlp-2011-27-pdf" href="http://aclweb.org/anthology//D/D11/D11-1069.pdf">pdf</a></p><p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>Reference: <a title="emnlp-2011-27-reference" href="../emnlp2011_reference/emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. [sent-3, score-1.214]
</p><p>2 Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. [sent-4, score-1.161]
</p><p>3 We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. [sent-5, score-0.793]
</p><p>4 We evaluate our results on a collection of message board posts in the domain of veterinary medicine. [sent-6, score-0.794]
</p><p>5 From a natural language processing perspective, message board posts are an interesting hybrid text genre because they consist of both expository text and conversational text. [sent-20, score-0.774]
</p><p>6 Most message board posts contain both expository sentences as well as speech acts. [sent-24, score-1.015]
</p><p>7 The person posting a message (the “writer”) often engages in speech acts with the readers. [sent-25, score-0.856]
</p><p>8 Our research goals are twofold: (1) to distin-  guish between expository sentences and speech act sentences in message board posts, and (2) to clasProce Ed iningbsu orfg th ,e S 2c0o1tl1an Cdo,n UfeKr,en Jcuely on 27 E–m31p,ir 2ic0a1l1 M. [sent-31, score-1.393]
</p><p>9 ec th2o0d1s1 i Ans Nsoactuiartaioln La fonrg Cuaogmep Purtoatcieosnsainlg L,in pgaugies ti 7c4s8–758, sify speech act sentences into four types: Commissives, Directives, Expressives, and Representatives, following Searle’s original taxonomy (Searle, 1976). [sent-33, score-0.825]
</p><p>10 Information extraction systems could benefit from filtering speech act sentences (e. [sent-35, score-0.827]
</p><p>11 In this paper, we present sentence classifiers that can identify speech act sentences and classify them as Commissive, Directive, Expressive, and Representative. [sent-40, score-0.866]
</p><p>12 First, we explain how each speech act class is manifested in message board posts, which can be different from how they occur in spoken dialogue. [sent-41, score-1.207]
</p><p>13 Second, we train classifiers to identify speech  act sentences using a variety of lexical, syntactic, and semantic features. [sent-42, score-0.881]
</p><p>14 Finally, we evaluate our system on a collection of message board posts in the domain of veterinary medicine. [sent-43, score-0.794]
</p><p>15 2  Related Work  There has been relatively little work on applying speech act theory to written text genres, and most of the previous work has focused on email classification. [sent-44, score-0.852]
</p><p>16 Carvalho and Cohen (2006) later employed N-gram sequence features to determine which N-grams are meaningfully related to different email speech acts with a goal towards improving their earlier email classification  based on the writer’s intention. [sent-51, score-0.824]
</p><p>17 (2006) performed speech act classification in email messages following a verbal re749 sponse modes (VRM) speech act taxonomy. [sent-53, score-1.605]
</p><p>18 They also provided a comparison of VRM taxonomy with Searle’s taxonomy (Searle, 1976) of speech act classes. [sent-54, score-0.753]
</p><p>19 Mildinhall and Noyes (2008) presented a stochastic speech act model based on verbal response modes (VRM) to classify email intentions. [sent-56, score-0.877]
</p><p>20 Some research has considered speech act classes in other means of online conversations. [sent-57, score-0.782]
</p><p>21 (2004) employed speech act profiling by plotting potential dialogue categories in a radar graph to classify conversations in instant messages and chat rooms. [sent-60, score-0.856]
</p><p>22 Ravi and Kim (2007) employed speech act profiling in  online threaded discussions to determine message roles and to identify threads with questions, answers, and unanswered questions. [sent-63, score-1.02]
</p><p>23 They designed their own speech act categories based on their analysis of student interactions in discussion threads. [sent-64, score-0.753]
</p><p>24 (2009) on semi-supervised speech act recognition in both emails and forums. [sent-66, score-0.788]
</p><p>25 However, they trained their classifier on spoken telephone (SWBD-DAMSL corpus) and meeting (MRDA corpus) conversations and mapped the labelled dialog act classes of these corpora to 12 dialog act classes that they found suitable for email and forum text genres. [sent-68, score-1.246]
</p><p>26 These dialog act classes (addressed as speech acts by them) are somewhat different from Searle’s original speech act classes. [sent-69, score-1.893]
</p><p>27 Our goal was to try and use Searle’s original speech act definitions and categories as the basis for our work to the greatest extent possible, allowing for some interpretation as warranted by the WWW message board text genre. [sent-73, score-1.207]
</p><p>28 For the purposes of defining and evaluating our work, we created detailed annotation guidelines for four of Searle’s speech act classes that commonly occur in message board posts: Commissives, Directives, Expressives, and Representatives. [sent-74, score-1.296]
</p><p>29 We omitted the fifth of Searle’s original speech act classes, Declarations, because we virtually never saw declarative speech acts in our data set. [sent-75, score-1.379]
</p><p>30 1 The data set used in our study is a collection of message board posts in the domain of veterinary medicine. [sent-76, score-0.794]
</p><p>31 We designed our definitions and guidelines to reflect language use in the text genre of message board posts, trying to be as domain-independent as possible so that these definitions should also apply to message board texts rep-  resenting other topics. [sent-77, score-0.938]
</p><p>32 However, we give examples from the veterinary domain to illustrate how these speech act classes are manifested in our data set. [sent-78, score-0.967]
</p><p>33 Commissives: A Commissive speech act occurs when the speaker commits to a future course of action. [sent-79, score-0.815]
</p><p>34 However, statements indicating that an action will not occur because of circumstances beyond the writer’s control were considered to be factual statements and not speech acts (e. [sent-89, score-0.702]
</p><p>35 Directives: A Directive speech act occurs when  1Searle defines Declarative speech acts as statements that bring about a change in status or condition to an object by virtue of the statement itself. [sent-93, score-1.379]
</p><p>36 Directive speech acts are common in message board posts, especially in the initial post of each thread when the writer explicitly requests help or advice regarding a specific topic. [sent-97, score-1.219]
</p><p>37 Furthermore, many Directive speech acts are not stated as a question but as a request for assistance. [sent-103, score-0.69]
</p><p>38 Expressives: An Expressive speech act occurs in conversation when a speaker expresses his or her psychological state to the listener. [sent-107, score-0.792]
</p><p>39 Expressive speech acts are common in message boards because writers often greet readers at the beginning of a post ( “Hi everyone! [sent-109, score-0.992]
</p><p>40 Representatives: According to Searle, a Representative speech act commits the speaker to the truth of an expressed proposition. [sent-113, score-0.815]
</p><p>41 In the veterinary domain, we considered sentences to be a Representative speech act when a doctor explicitly confirmed a diagnosis or expressed their suspicion or hypothesis about the presence (or absence) of a disease or symptom. [sent-116, score-1.13]
</p><p>42 A sentence was only labelled as a Representative speech act if the writer explicitly expressed his belief. [sent-128, score-0.878]
</p><p>43 2 Features for Speech Act Classification To create speech act classifiers, we designed a variety of lexical, syntactic, and semantic features. [sent-130, score-0.793]
</p><p>44 We tried to capture linguistic properties associated with speech act expressions as well as discourse prop-  erties associated with individual sentences and the message board post as a whole. [sent-131, score-1.292]
</p><p>45 We also incorporated speech act word lists that were acquired from external resources, and used two types of semantic features to represent semantic entities associated with the veterinary domain. [sent-132, score-1.018]
</p><p>46 Except for the semantic features, all of our features are domain-independent so should be able to recognize speech act sentences across different domains. [sent-133, score-0.869]
</p><p>47 We experimented with domain-specific semantic features to test our hypothesis that Commissive speech acts can be associated with domain-specific semantic entities. [sent-134, score-0.706]
</p><p>48 2  Speech Act Word Clues  We collected speech act word lists (mostly verbs) from two external sources. [sent-176, score-0.753]
</p><p>49 We also collected a list of speech act verbs published in (Wierzbicka, 1987). [sent-179, score-0.778]
</p><p>50 The details for these speech act clue lists are given below. [sent-180, score-0.781]
</p><p>51 Searle Keywords: We created one feature for each speech act class. [sent-182, score-0.789]
</p><p>52 Wierzbicka Verbs: We created one feature that  included 228 speech act verbs listed in the book “English speech act verbs: a semantic dictionary ” 752 (Wierzbicka, 1987)2. [sent-190, score-1.607]
</p><p>53 We ran Basilisk over our collection of 15,383 veterinary message board posts to create a semantic lexicon for veterinary medicine. [sent-202, score-1.053]
</p><p>54 The DISEASE/SYMPTOM lexicon appeared to be of good quality, but it did not improve the performance of our speech act classifiers. [sent-206, score-0.787]
</p><p>55 3 Representative speech acts are typically associated with disease diagnoses 2openl ibrary . [sent-208, score-0.688]
</p><p>56 The taggers were trained on 4,629 veterinary message board posts using 10 seed words for each semantic category (see (Huang and Riloff, 2010) for details). [sent-220, score-0.889]
</p><p>57 Our speech act classidfieenrsc ues veadlu uthee ≥ tags a wsseoreci uasteedd . [sent-223, score-0.753]
</p><p>58 Because a sentence can include multiple speech acts, we created a set of binary classifiers, one for each of the four speech act classes. [sent-229, score-1.081]
</p><p>59 All four classifiers were applied to each sentence, so a sentence could be assigned multiple speech act classes. [sent-230, score-0.817]
</p><p>60 Among other things, VIN hosts message board forums where veterinarians and other veterinary professionals can discuss issues and pose questions to each other. [sent-235, score-0.733]
</p><p>61 Since the goal of our work was to study speech acts in sentences, and not the conversational dialogue between different writers, we used only the initial post of each thread. [sent-244, score-0.708]
</p><p>62 In the next section, we explain how we manually annotated each sentence in our data set to create gold standard speech act labels. [sent-247, score-0.753]
</p><p>63 Identifying speech acts is not always obvious, even to people, so we gave them detailed annotation guidelines describing the four speech act classes discussed  in Section 3. [sent-250, score-1.432]
</p><p>64 Each annotator was told to assign one or more speech act classes to each sentence (COM, DIR, EXP, REP), or to label the sentence as having no speech acts (NONE). [sent-253, score-1.408]
</p><p>65 The vast majority of sentences had either no speech acts or at most one speech act, but a small number of sentences contained multiple types of speech acts. [sent-254, score-1.258]
</p><p>66 In the first scheme, we discarded the small number of sentences that had multiple speech act labels and computed kappa on the rest. [sent-258, score-0.839]
</p><p>67 However, over 70% of the sentences in our data set have no speech act at all, so NONE was by far the most common label. [sent-261, score-0.801]
</p><p>68 Consequently, this agreement score does not necessarily reflect how consistently  the judges agreed on the four speech act classes. [sent-262, score-0.848]
</p><p>69 4Of the 594 sentences in these 50 posts, only 22 sentences contained multiple speech act classes. [sent-263, score-0.849]
</p><p>70 In the second scheme, we computed kappa for each speech act category independently. [sent-264, score-0.82]
</p><p>71 Table 2 shows the distribution of speech act labels in our data set. [sent-273, score-0.753]
</p><p>72 Directive and Expressive speech acts are by far the most common, with nearly 26% of all sentences containing one of these speech acts. [sent-277, score-0.942]
</p><p>73 1 Speech Act Filtering For our first experiment, we created a speech act filtering classifier to distinguish sentences that contain one or more speech acts from sentences that do not contain any speech acts. [sent-282, score-1.835]
</p><p>74 having one or more speech acts were positive instances, and sentences labelled as NONE were negative instances. [sent-288, score-0.697]
</p><p>75 For speech act filtering, we used the minimal lexsyn features plus the speech act clues and semantic features. [sent-298, score-1.663]
</p><p>76 89F4 Table 3: Precision, Recall, F-measure for speech act filtering. [sent-302, score-0.753]
</p><p>77 Table 3 shows the performance for speech act filtering with respect to Precision (P), Recall (R), and F-measure score (F). [sent-303, score-0.779]
</p><p>78 7 The classifier performed well, recognizing 83% of the speech act sentences with 86% precision, and 95% of the expository (no  6This is the same feature set used to produce the results for row E of Table 4. [sent-304, score-0.961]
</p><p>79 Table 4: Precision, Recall, F-measure  for four speech act classes. [sent-306, score-0.777]
</p><p>80 2  Speech Act Categorization  BASELINES Our next set of experiments focused on labelling sentences with the four specific speech act classes: Commissive, Directive. [sent-311, score-0.849]
</p><p>81 To assess the difficulty of identifying each speech act category, we created several simple baselines using our intuitions about each category. [sent-313, score-0.789]
</p><p>82 For Commissives, we created a heuristic to cap-  ture the most obvious cases of future tense (because Commissive speech acts represent a writer’s commitment toward a future course of action). [sent-314, score-0.71]
</p><p>83 Directive speech acts are often questions, so we created a baseline system that labels all sentences containing a question mark as a Directive. [sent-320, score-0.738]
</p><p>84 3, we created one classifier for each speech act category, and all four classifiers were applied to each sentence. [sent-348, score-0.883]
</p><p>85 So a sentence could receive anywhere from 0-4 speech act labels indicating how many different types of speech acts appeared in the sentence. [sent-349, score-1.379]
</p><p>86 Row C shows the results of adding the speech act clue words (see Section 3. [sent-366, score-0.781]
</p><p>87 The speech act clue words produced an additional recall gain of 3% for Expressives and 2% for Representatives, although performance on Commissives dropped 2% in both recall and precision. [sent-369, score-0.831]
</p><p>88 The Commissive speech act class benefitted the most from the rich feature set. [sent-386, score-0.753]
</p><p>89 However, there is still ample room for improvement, illustrating that speech act classification is a challenging problem. [sent-390, score-0.753]
</p><p>90 5  Conclusions  Our goal was to identify speech act sentences in message board posts and to classify the sentences with respect to four categories in Searle’s (1976) speech act taxonomy. [sent-401, score-2.26]
</p><p>91 We achieved good results for speech act filtering and the identification of Directive and Expressive speech act sentences. [sent-402, score-1.532]
</p><p>92 We found that Representative and Commissive speech acts are much more difficult to identify, although the performance of our Commissive classifier substantially improved with the addition of lexical, syntactic, and semantic features. [sent-403, score-0.696]
</p><p>93 Except for the semantic class information, our feature set is domain-independent and could be used to recognize speech act sentences  757  in message boards for any domain. [sent-404, score-1.144]
</p><p>94 Ultimately, we would like to identify the speech act expressions themselves because some sentences contain speech acts as well as factual information. [sent-407, score-1.466]
</p><p>95 Extracting the speech act expressions and clauses from message boards and similar text genres could provide better tracking of questions and answers in web forums and be used for summarization. [sent-408, score-1.129]
</p><p>96 Using speech acts to categorize email and identify email gen-  res. [sent-450, score-0.824]
</p><p>97 Toward a stochastic speech act model of email behavior. [sent-483, score-0.852]
</p><p>98 The construction of away messages: A speech act analysis. [sent-488, score-0.753]
</p><p>99 Profiling student interactions in threaded discussions with speech act classifiers. [sent-493, score-0.753]
</p><p>100 Using speech act theory to model conversations for automated classification and retrieval. [sent-531, score-0.795]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('act', 0.485), ('acts', 0.358), ('speech', 0.268), ('board', 0.259), ('commissive', 0.22), ('directive', 0.196), ('searle', 0.196), ('message', 0.195), ('veterinary', 0.185), ('commissives', 0.173), ('posts', 0.155), ('directives', 0.127), ('expressives', 0.127), ('writer', 0.102), ('email', 0.099), ('lexsyn', 0.092), ('representatives', 0.092), ('expository', 0.09), ('boards', 0.08), ('doctor', 0.075), ('representative', 0.065), ('expressive', 0.06), ('drug', 0.056), ('carvalho', 0.05), ('sentences', 0.048), ('tense', 0.048), ('basilisk', 0.046), ('twitchell', 0.046), ('conversational', 0.045), ('conversations', 0.042), ('riloff', 0.042), ('semantic', 0.04), ('classifiers', 0.04), ('row', 0.04), ('speaker', 0.039), ('disease', 0.039), ('factual', 0.039), ('judges', 0.038), ('kappa', 0.038), ('questions', 0.038), ('action', 0.037), ('keywords', 0.037), ('post', 0.037), ('created', 0.036), ('pronoun', 0.036), ('appreciate', 0.036), ('request', 0.036), ('profiling', 0.036), ('threads', 0.036), ('vin', 0.036), ('emails', 0.035), ('vrm', 0.035), ('wierzbicka', 0.035), ('person', 0.035), ('lexicon', 0.034), ('cat', 0.034), ('forums', 0.033), ('agreement', 0.033), ('anyone', 0.031), ('readers', 0.031), ('classifier', 0.03), ('genres', 0.03), ('hi', 0.03), ('plan', 0.03), ('everyone', 0.03), ('diagnosed', 0.03), ('suspicion', 0.03), ('thelen', 0.03), ('vitor', 0.03), ('genre', 0.03), ('classes', 0.029), ('category', 0.029), ('recognize', 0.028), ('question', 0.028), ('clue', 0.028), ('diseases', 0.028), ('begins', 0.028), ('stroudsburg', 0.028), ('cohen', 0.026), ('taggers', 0.026), ('checks', 0.026), ('ellen', 0.026), ('filtering', 0.026), ('classify', 0.025), ('clues', 0.025), ('verbs', 0.025), ('recall', 0.025), ('four', 0.024), ('unigram', 0.024), ('drugs', 0.024), ('forum', 0.024), ('labelling', 0.024), ('labelled', 0.023), ('commits', 0.023), ('diagnoses', 0.023), ('greet', 0.023), ('mildinhall', 0.023), ('nastri', 0.023), ('nunamaker', 0.023), ('professionals', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="27-tfidf-1" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>2 0.20379986 <a title="27-tfidf-2" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>Author: Li Wang ; Marco Lui ; Su Nam Kim ; Joakim Nivre ; Timothy Baldwin</p><p>Abstract: Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</p><p>3 0.093533754 <a title="27-tfidf-3" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>4 0.063259594 <a title="27-tfidf-4" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>Author: Alan Ritter ; Colin Cherry ; William B. Dolan</p><p>Abstract: Ottawa, Ontario, K1A 0R6 Co l . Cherry@ nrc-cnrc . gc . ca in Redmond, WA 98052 bi l ldol @mi cro so ft . com large corpus of status-response pairs found on Twitter to create a system that responds to Twitter status We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.</p><p>5 0.057660788 <a title="27-tfidf-5" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>Author: Marjorie Freedman ; Lance Ramshaw ; Elizabeth Boschee ; Ryan Gabbard ; Gary Kratkiewicz ; Nicolas Ward ; Ralph Weischedel</p><p>Abstract: We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.5 1 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1.</p><p>6 0.045414537 <a title="27-tfidf-6" href="./emnlp-2011-Linear_Text_Segmentation_Using_Affinity_Propagation.html">88 emnlp-2011-Linear Text Segmentation Using Affinity Propagation</a></p>
<p>7 0.044677731 <a title="27-tfidf-7" href="./emnlp-2011-A_Fast_Re-scoring_Strategy_to_Capture_Long-Distance_Dependencies.html">5 emnlp-2011-A Fast Re-scoring Strategy to Capture Long-Distance Dependencies</a></p>
<p>8 0.042807028 <a title="27-tfidf-8" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>9 0.038719565 <a title="27-tfidf-9" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>10 0.037330437 <a title="27-tfidf-10" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>11 0.035119247 <a title="27-tfidf-11" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>12 0.034701958 <a title="27-tfidf-12" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>13 0.034677219 <a title="27-tfidf-13" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>14 0.033519659 <a title="27-tfidf-14" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>15 0.032406073 <a title="27-tfidf-15" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>16 0.032071561 <a title="27-tfidf-16" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>17 0.031291872 <a title="27-tfidf-17" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>18 0.031199746 <a title="27-tfidf-18" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>19 0.030608598 <a title="27-tfidf-19" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>20 0.030118043 <a title="27-tfidf-20" href="./emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">121 emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.127), (1, -0.07), (2, 0.005), (3, 0.006), (4, -0.008), (5, -0.06), (6, -0.021), (7, 0.03), (8, 0.006), (9, -0.117), (10, -0.083), (11, -0.123), (12, -0.081), (13, -0.032), (14, -0.1), (15, 0.149), (16, 0.044), (17, -0.062), (18, 0.041), (19, -0.046), (20, 0.072), (21, 0.036), (22, -0.346), (23, -0.034), (24, 0.032), (25, 0.1), (26, -0.128), (27, -0.12), (28, -0.059), (29, -0.136), (30, 0.006), (31, -0.025), (32, -0.237), (33, 0.144), (34, -0.06), (35, 0.007), (36, 0.257), (37, 0.024), (38, 0.043), (39, -0.149), (40, -0.091), (41, -0.093), (42, -0.037), (43, 0.111), (44, -0.12), (45, 0.123), (46, -0.037), (47, -0.115), (48, -0.153), (49, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97068554 <a title="27-lsi-1" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>2 0.77711207 <a title="27-lsi-2" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>Author: Li Wang ; Marco Lui ; Su Nam Kim ; Joakim Nivre ; Timothy Baldwin</p><p>Abstract: Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</p><p>3 0.26799768 <a title="27-lsi-3" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>4 0.25235727 <a title="27-lsi-4" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>Author: Nikhil Dinesh ; Aravind Joshi ; Insup Lee</p><p>Abstract: The computation of logical form has been proposed as an intermediate step in the translation of sentences to logic. Logical form encodes the resolution of scope ambiguities. In this paper, we describe experiments on a modestsized corpus of regulation annotated with a novel variant of logical form, called abstract syntax trees (ASTs). The main step in computing ASTs is to order scope-taking operators. A learning model for ranking is adapted for this ordering. We design features by studying the problem ofcomparing the scope ofone operator to another. The scope comparisons are used to compute ASTs, with an F-score of 90.6% on the set of ordering decisons.</p><p>5 0.24468933 <a title="27-lsi-5" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>Author: Alan Ritter ; Colin Cherry ; William B. Dolan</p><p>Abstract: Ottawa, Ontario, K1A 0R6 Co l . Cherry@ nrc-cnrc . gc . ca in Redmond, WA 98052 bi l ldol @mi cro so ft . com large corpus of status-response pairs found on Twitter to create a system that responds to Twitter status We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.</p><p>6 0.23919049 <a title="27-lsi-6" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>7 0.19746554 <a title="27-lsi-7" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>8 0.18785144 <a title="27-lsi-8" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>9 0.17140129 <a title="27-lsi-9" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>10 0.15882939 <a title="27-lsi-10" href="./emnlp-2011-Linear_Text_Segmentation_Using_Affinity_Propagation.html">88 emnlp-2011-Linear Text Segmentation Using Affinity Propagation</a></p>
<p>11 0.15466167 <a title="27-lsi-11" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>12 0.15276846 <a title="27-lsi-12" href="./emnlp-2011-A_Fast_Re-scoring_Strategy_to_Capture_Long-Distance_Dependencies.html">5 emnlp-2011-A Fast Re-scoring Strategy to Capture Long-Distance Dependencies</a></p>
<p>13 0.15069498 <a title="27-lsi-13" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>14 0.14583841 <a title="27-lsi-14" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>15 0.14573103 <a title="27-lsi-15" href="./emnlp-2011-Divide_and_Conquer%3A_Crowdsourcing_the_Creation_of_Cross-Lingual_Textual_Entailment_Corpora.html">42 emnlp-2011-Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora</a></p>
<p>16 0.14413275 <a title="27-lsi-16" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>17 0.14408208 <a title="27-lsi-17" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>18 0.14375056 <a title="27-lsi-18" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>19 0.14205597 <a title="27-lsi-19" href="./emnlp-2011-Corpus-Guided_Sentence_Generation_of_Natural_Images.html">34 emnlp-2011-Corpus-Guided Sentence Generation of Natural Images</a></p>
<p>20 0.14064489 <a title="27-lsi-20" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(17, 0.035), (18, 0.016), (23, 0.09), (36, 0.016), (37, 0.025), (45, 0.061), (46, 0.188), (53, 0.018), (54, 0.022), (57, 0.025), (62, 0.04), (64, 0.015), (66, 0.026), (69, 0.016), (79, 0.046), (87, 0.184), (96, 0.033), (98, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75457209 <a title="27-lda-1" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>2 0.73544031 <a title="27-lda-2" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>3 0.65425247 <a title="27-lda-3" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>4 0.52519566 <a title="27-lda-4" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<p>Author: Xinyan Xiao ; Yang Liu ; Qun Liu ; Shouxun Lin</p><p>Abstract: Although discriminative training guarantees to improve statistical machine translation by incorporating a large amount of overlapping features, it is hard to scale up to large data due to decoding complexity. We propose a new algorithm to generate translation forest of training data in linear time with the help of word alignment. Our algorithm also alleviates the oracle selection problem by ensuring that a forest always contains derivations that exactly yield the reference translation. With millions of features trained on 519K sentences in 0.03 second per sentence, our system achieves significant improvement by 0.84 BLEU over the baseline system on the NIST Chinese-English test sets.</p><p>5 0.50474435 <a title="27-lda-5" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>Author: Li Wang ; Marco Lui ; Su Nam Kim ; Joakim Nivre ; Timothy Baldwin</p><p>Abstract: Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</p><p>6 0.4789601 <a title="27-lda-6" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>7 0.47330248 <a title="27-lda-7" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>8 0.47281364 <a title="27-lda-8" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>9 0.46722814 <a title="27-lda-9" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>10 0.46324766 <a title="27-lda-10" href="./emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">94 emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>11 0.45777723 <a title="27-lda-11" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>12 0.45759022 <a title="27-lda-12" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>13 0.45536327 <a title="27-lda-13" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>14 0.45416513 <a title="27-lda-14" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>15 0.45089716 <a title="27-lda-15" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>16 0.45056358 <a title="27-lda-16" href="./emnlp-2011-Large-Scale_Cognate_Recovery.html">77 emnlp-2011-Large-Scale Cognate Recovery</a></p>
<p>17 0.45015201 <a title="27-lda-17" href="./emnlp-2011-Hierarchical_Phrase-based_Translation_Representations.html">66 emnlp-2011-Hierarchical Phrase-based Translation Representations</a></p>
<p>18 0.44953212 <a title="27-lda-18" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>19 0.44490525 <a title="27-lda-19" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>20 0.44445238 <a title="27-lda-20" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
