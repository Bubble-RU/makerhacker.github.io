<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-37" href="#">emnlp2011-37</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</h1>
<br/><p>Source: <a title="emnlp-2011-37-pdf" href="http://aclweb.org/anthology//D/D11/D11-1130.pdf">pdf</a></p><p>Author: Joseph Reisinger ; Raymond Mooney</p><p>Abstract: Context-dependent word similarity can be measured over multiple cross-cutting dimensions. For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity. Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clusterings. MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich- let Allocation. Intuitively, this constraint favors feature partitions that have coherent topical semantics. Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.</p><p>Reference: <a title="emnlp-2011-37-reference" href="../emnlp2011_reference/emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Context-dependent word similarity can be measured over multiple cross-cutting dimensions. [sent-3, score-0.051]
</p><p>2 Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. [sent-5, score-0.119]
</p><p>3 MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich-  let Allocation. [sent-7, score-0.111]
</p><p>4 Intuitively, this constraint favors feature partitions that have coherent topical semantics. [sent-8, score-0.053]
</p><p>5 Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. [sent-9, score-0.188]
</p><p>6 Human knowledgebases such as Wikipedia also exhibit such multiple clustering structure (e. [sent-16, score-0.085]
</p><p>7 In this work, we introduce a novel probabilistic clustering method, Multi-View Mixture (MVM), based on cross-cutting categorization (Shafto et al. [sent-20, score-0.105]
</p><p>8 Cross-cutting categorization finds multiple feature subsets (categorization systems) that produce high quality clusterings of the data. [sent-22, score-0.164]
</p><p>9 Contextdependent variation in word usage can be accounted  for by leveraging multiple latent categorization systems. [sent-24, score-0.07]
</p><p>10 In particular, cross-cutting models can be used to capture both syntagmatic and paradigmatic notions of word relatedness, breaking up word features into multiple categorization systems and then computing similarity separately for each system. [sent-25, score-0.214]
</p><p>11 Each clustering (view) in MVM consists of a distribution over features and data and views are further subdivided into clusters based on a DPMM. [sent-27, score-0.176]
</p><p>12 tc ho2d0s1 in A Nsasotucira tlio Lnan fogru Cagoem Ppruotcaetisosninagl, L pinag uesis 1ti4c0s5–1415, We evaluate MVM against several other modelbased clustering procedures in a series of human evaluation tasks, measuring its ability to find meaningful syntagmatic and paradigmatic structure. [sent-31, score-0.168]
</p><p>13 We find that MVM finds more semantically and syntactically coherent fine-grained structure, using both common and rare n-gram contexts. [sent-32, score-0.058]
</p><p>14 The distributional hypothesis addresses the problem of modeling word similarity (Curran, 2004; Miller and Charles, 1991 ; Sch u¨tze, 1998; Turney, 2006), and can be extended to selectional preference (Resnik, 1997) and lexical substitution (McCarthy and Navigli, 2007) as well. [sent-38, score-0.066]
</p><p>15 , the triangle inequality: the sum of distances from bat to club and club to association is less than the distance from bat  to association (Griffiths et al. [sent-45, score-0.064]
</p><p>16 The cluster assumption is a natural fit for lexical semantics, as partitions can account for metric violations. [sent-56, score-0.095]
</p><p>17 The end result is a model capable of representing  multiple, overlapping similarity metrics that result in disparate valid clusterings leveraging the Subspace Hypothesis: For any pair of words, the set of “active” features governing their apparent similarity differs. [sent-57, score-0.2]
</p><p>18 For example wine and bottle are similar and wine and vinegar are similar, but it would not be reasonable to expect that the features governing such similarity computations to overlap much, despite occurring in similar documents. [sent-58, score-0.078]
</p><p>19 MVM can extract multiple competing notions of similarity, for example both paradigmatic, or thematic similarity, and syntagmatic or syntactic similarity, in addition to more fine grained relations. [sent-59, score-0.112]
</p><p>20 For example, company websites can be clustered by sector or by geographic location, with one particular clustering becoming predominant when a majority of features correlate with it. [sent-63, score-0.102]
</p><p>21 In fact, informative features in one clustering may be noise in another, e. [sent-64, score-0.086]
</p><p>22 the occurrence of CEO is not necessarily discriminative when clustering companies by industry sector, but may be useful in other clusterings. [sent-66, score-0.068]
</p><p>23 Multiple clustering is one approach to inferring feature subspaces that lead to high quality data partitions. [sent-67, score-0.068]
</p><p>24 Multiple clustering also improves the flexibility of generative clustering models, as a single model is no longer required to explain all the variance in the feature dimensions (Mansinghka et al. [sent-68, score-0.136]
</p><p>25 ruenwglfiacstndgawhtendisr_ aepsxlicojnrgeupsdtarlieynwghalynicodawres_beac_ouste psatoenmhsobiyue_rnalgictdfonerswa_lmetnvoarisyucldeotanrhseulbatyfso_rmudnki_tcorhyelaimpn  Figure 1: Example clusterings from MVM applied to Google n-gram data. [sent-70, score-0.074]
</p><p>26 Top contexts (features) for each view are shown, along with examples of word clusters. [sent-71, score-0.106]
</p><p>27 MVM is a multinomial-Dirichlet  multiple clus-  tering procedure for distributional lexical semantics that fits multiple, overlapping Dirichlet Process Mixture Models (DPMM) to a set of word data. [sent-73, score-0.092]
</p><p>28 Features are distributed across the set of clusterings (views) using LDA, and each DPMM is fit using a subset of the features. [sent-74, score-0.074]
</p><p>29 This reduces clustering noise and allows MVM to capture multiple ways in which the data can be partitioned. [sent-75, score-0.103]
</p><p>30 Figure 1 shows a simple example, and Figure 2 shows a larger sample of feature-view assignments from a 3-view MVM fit to contexts drawn from the Google n-gram corpus. [sent-76, score-0.077]
</p><p>31 |M| disparate clusterings (views) are inferred jointly from a set of data D twd|d P r1. [sent-78, score-0.09]
</p><p>32 θ|dM|  views Empirically, is represented as a set of feature-view assignments zd, sampled via the standard LDA collapsed Gibbs sampler. [sent-83, score-0.05]
</p><p>33 Conditional on the feature-view assignment tzu, a clustering is inferred for each view using the Chinese Restaurant Process representation of the DP. [sent-86, score-0.115]
</p><p>34 The clustering probability is given by ppc|z, 9 pptcmu, z,  wq  wq  m¹M 1d¹|D 1|ppwdrz ms|cm,zqppcm|zq. [sent-87, score-0.104]
</p><p>35 ppcm |zq is a prior on the clustering for view m, i. [sent-88, score-0.115]
</p><p>36 the DPMM, and ppwrdz ms |cm, zq is the like-  where  lihood of the clustering cm given the data point restricted to the features assigned to view m:  wrdz ms def twid|zid  wd  mu. [sent-90, score-0.203]
</p><p>37 Thus, we treat the m clusterings cm as conditionally independent given the feature-view assignments. [sent-91, score-0.091]
</p><p>38 The feature-view assignments tzu act as a set of  marginal constraints on the multiple clusterings, and the impact that each data point can have on each clustering is limited by the number of features assigned to it. [sent-92, score-0.103]
</p><p>39 For example, in a two-view model, zid 1might be set for all syntactic features (yielding a syntagmatic clustering) while zid 2 is set for document features (paradigmatic clustering). [sent-93, score-0.12]
</p><p>40 By allowing the clustering model capacity to vary via the DPMM, MVM can naturally account for the semantic variance of the view. [sent-94, score-0.089]
</p><p>41 View 1 cluster 2 and View 3 cluster 1 both contain pas1t4-t0e8nse verbs, but only overlap on a subset of syntactic features. [sent-100, score-0.086]
</p><p>42 The most similar model to ours is Cross-cutting categorization (CCC), which fits multiple DPMMs to non-overlapping partitions of features (Mansinghka et al. [sent-103, score-0.091]
</p><p>43 Unlike MVM, CCC partitions features among multiple DPMMs, hence all occurrences of a particular feature will end up in a single clustering, instead of assigning them softly using LDA. [sent-106, score-0.077]
</p><p>44 1 Word Representation MVM is trained as a lexical semantic model on Web-scale n-gram and semantic context data. [sent-110, score-0.057]
</p><p>45 Ngram contexts are drawn from a combination of the Google n-gram and Google books n-gram corpora, with the head word removed: e. [sent-111, score-0.092]
</p><p>46 for the term architect, we collect contexts such as the of the house, an is a, and the of the universe. [sent-113, score-0.059]
</p><p>47 Semantic contexts are derived from word occurrence in Wikipedia documents: each document a word appears in is added as a potential feature for that word. [sent-114, score-0.082]
</p><p>48 Syntax-only Words are represented as bags ofngram contexts derived slot-filling procedure described above. [sent-117, score-0.059]
</p><p>49 Syntax+Documents The syntax-only representation is augmented with additional document contexts drawn from Wikipedia. [sent-119, score-0.1]
</p><p>50 –  Models trained on the syntax-only set are only capable of capturing syntagmatic similarity relations, that is, words that tend to appear in similar contexts. [sent-120, score-0.077]
</p><p>51 In contrast, the syntax+documents set broadens the scope of modelable similarity relations, allowing for paradigmatic similarity (e. [sent-121, score-0.125]
</p><p>52 1409 Given such word representation data, MVM generates a fixed set of M context views corresponding to dominant eigenvectors in local syntactic or semantic space. [sent-124, score-0.071]
</p><p>53 Within each view, MVM partitions words into clusters based on each word’s local representation in that view; that is, based on the set of con-  text features it allocates to the view. [sent-125, score-0.095]
</p><p>54 Words have a non-uniform affinity for each view, and hence may not be present in every clustering (Figure 2). [sent-126, score-0.091]
</p><p>55 In contrast, LDA finds locally consistent collections of contexts but does not further subdivide words into clusters given that set of contexts. [sent-128, score-0.132]
</p><p>56 Two versions of the syntax-only dataset are created from different subsets of the Google n-gram corpora: (1) the common subset contains all syntactic contexts appearing more than 200 times in the combined corpus, and (2) the rare subset, containing only contexts that appear 50 times or fewer. [sent-133, score-0.166]
</p><p>57 According to the use theory of meaning, lexical semantic knowledge is equivalent to knowing the contexts that words appear in, and hence being able to form reasonable hypotheses about the relatedness of syntactic contexts. [sent-141, score-0.118]
</p><p>58 Vector space models are commonly evaluated by comparing their similarity predictions to a nominal set of human similarity judgments (Curran, 2004; Pad o´ and Lapata, 2007; Sch u¨tze, 1998; Turney, 2006). [sent-142, score-0.068]
</p><p>59 In this work, since we are evaluating models that potentially yield many different similarity scores, we take a different approach, scoring clusters on their semantic and syntactic coherence using a set intrusion task (Chang et al. [sent-143, score-0.363]
</p><p>60 In set intrusion, human raters are shown a set of options from a coherent group and asked to identify a single intruder drawn from a different group. [sent-145, score-0.1]
</p><p>61 We extend intrusion to three different lexical semantic tasks: (1) context intrusion, where the top contexts from each cluster are used, (3) document intrusion, where the top document contexts from each cluster are used, and (2) word intrusion, where the top words from each cluster are used. [sent-146, score-0.579]
</p><p>62 4 The resulting set is then shuffled, and the human raters are asked to identify the intruder, af4Choosing four elements from the cluster uniformly at random instead of the top by probability led to lower performance across all models. [sent-148, score-0.086]
</p><p>63 As the semantic coherence and distinctness from other clusters increases, this task becomes easier. [sent-151, score-0.079]
</p><p>64 Set intrusion is a more robust way to account for human similarity judgments than asking directly for a numeric score (e. [sent-152, score-0.284]
</p><p>65 A total of 1256 raters completed 30438 evaluations for 5780 unique intrusion tasks (5 evaluations per task). [sent-157, score-0.293]
</p><p>66 2736 potentially fraudulent evaluations from 11 raters were rejected. [sent-158, score-0.061]
</p><p>67 6LDA is run on a different range of M settings from MVM (50-1000 vs 3-100) in order to keep the effective number of context intrusion DPMM−0. [sent-163, score-0.25]
</p><p>68 0 % correct  word intrusion  GG  GG  G  G  G  GG  GG  GG  G  GG  G  G  GG  0. [sent-215, score-0.25]
</p><p>69 01  GGG  GG  G  G G  G  GG  word intrusion  G  G GG  GG  G  G G  GG  0. [sent-321, score-0.25]
</p><p>70 0  word intrusion  GG  GG  GG  GG  G  G  GGG  GG  GGG  G G  GG G  G GG  G  0. [sent-327, score-0.25]
</p><p>71 01u, and β P order to understand how they on the intrusion tasks and also are to various parameter run until convergence, defined log-likelihood on the training α  u  t0. [sent-364, score-0.25]
</p><p>72 Average runtimes varied from a few hours to a few days, depending on the number of clusters or topics. [sent-369, score-0.058]
</p><p>73 Overall, MVM significantly outperforms both LDA and DPMM (measured as % of intruders correctly identified) as the number of clusters increases. [sent-371, score-0.058]
</p><p>74 Coarse-grained lexical semantic distinctions are easy for humans to make, and hence models with fewer clusters tend to outperform models with more clusters. [sent-372, score-0.152]
</p><p>75 Since high granularity predictions are more clusters (and hence model capacity) roughly comparable. [sent-373, score-0.101]
</p><p>76 1 Syntax-only Model For common n-gram context features, MVM performance is significantly less variable than LDA on both the word intrusion and context intrusion tasks, and furthermore significantly outperforms DPMM (Figure 3(a)). [sent-399, score-0.5]
</p><p>77 These models vary significantly in the average number of clusters used: 373. [sent-407, score-0.058]
</p><p>78 Results from MVM have higher κ scores than LDA or DPMM; likewise Syntax+Documents data yields higher agreement, primarily due to the relative ease of the document intrusion task. [sent-425, score-0.273]
</p><p>79 Average cluster sizes are more uniform across model types for rare contexts: 384. [sent-437, score-0.07]
</p><p>80 Human performance on the context intrusion task is significantly more variable than on the wordintrusion task, reflecting the additional complexity. [sent-440, score-0.264]
</p><p>81 Qualitatively, models trained on syntax+document yield a higher degree of paradigmatic clusters which have intuitive thematic structure. [sent-472, score-0.156]
</p><p>82 Performance on document intrusion is significantly lower and more variable, reflecting the higher degree of world knowledge required. [sent-473, score-0.287]
</p><p>83 As with  the previous data set, performance of MVM models trained on syntax+documents data degrades less slowly as the cluster granularity increases (Figure 5). [sent-474, score-0.077]
</p><p>84 One interesting question is to what degree MVM views partition syntax and document features versus LDA topics. [sent-475, score-0.1]
</p><p>85 That is, to what degree do the MVM views capture purely syntagmatic or purely paradigmatic variation? [sent-476, score-0.15]
</p><p>86 We measured view entropy for all three models, treating syntactic features and document features as different class labels. [sent-477, score-0.07]
</p><p>87 MVM with M 50 views obtained an entropy score of 0. [sent-478, score-0.05]
</p><p>88 9 Thus MVM views may indeed capture pure syntactic or thematic clusterings. [sent-482, score-0.076]
</p><p>89 9The low entropy scores reflect the higher percentage of syntactic contexts overall. [sent-483, score-0.059]
</p><p>90 3 Discussion As cluster granularity increases, we find that MVM accounts for feature noise better than either LDA or DPMM, yielding more coherent clusters. [sent-485, score-0.097]
</p><p>91 , 2009) note that LDA performance degrades significantly on a related task as the number of topics increases, reflecting the increasing difficulty for  humans in grasping the connection between terms in the same topic. [sent-487, score-0.05]
</p><p>92 In this work, we find that although MVM and LDA perform similarity on average, MVM clusters are significantly more interpretable than LDA clusters as the granularity increases (Figures 4 and 5). [sent-489, score-0.184]
</p><p>93 where clusters are drawn uniformly at random from the model) and when cluster selection is biased based on model probability (results shown). [sent-493, score-0.119]
</p><p>94 Biased selection potentially gives an advantage to MVM, which generates many more small clusters than either LDA or DPMM, helping it account for noise. [sent-494, score-0.058]
</p><p>95 6  Future Work  Models based on cross-cutting categorization is a novel approach to lexical semantics and hence should be evaluated on standard baseline tasks, e. [sent-495, score-0.092]
</p><p>96 For example, clusterings that divide cities by geography or clusterings partition adjectives by their polarity. [sent-499, score-0.148]
</p><p>97 (Hierarchical Cross-Categorization) Human concept organization consists of multiple overlapping  local ontologies, similar to the loose ontological structure of Wikipedia. [sent-507, score-0.059]
</p><p>98 It would be interesting to extend MVM to model hierarchy explicitly, and compare against baselines such as Brown clustering (Brown et al. [sent-509, score-0.068]
</p><p>99 7  Conclusion  This paper introduced MVM, a novel approach to modeling lexical semantic organization using multiple cross-cutting clusterings capable of capturing multiple lexical similarity relations jointly in the same model. [sent-513, score-0.193]
</p><p>100 In addition to robustly handling homonymy and polysemy, MVM naturally captures both syntagmatic and paradigmatic notions of word similarity. [sent-514, score-0.126]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mvm', 0.817), ('lda', 0.3), ('dpmm', 0.25), ('intrusion', 0.25), ('gg', 0.148), ('clusterings', 0.074), ('clustering', 0.068), ('contexts', 0.059), ('clusters', 0.058), ('paradigmatic', 0.057), ('shafto', 0.054), ('views', 0.05), ('view', 0.047), ('raters', 0.043), ('syntagmatic', 0.043), ('cluster', 0.043), ('categorization', 0.037), ('partitions', 0.037), ('mansinghka', 0.036), ('similarity', 0.034), ('google', 0.033), ('ggg', 0.031), ('austin', 0.031), ('cuisine', 0.027), ('dpmms', 0.027), ('idon', 0.027), ('zid', 0.027), ('rare', 0.027), ('syntax', 0.027), ('notions', 0.026), ('thematic', 0.026), ('overlapping', 0.026), ('sch', 0.026), ('blank', 0.023), ('intruder', 0.023), ('document', 0.023), ('hence', 0.023), ('tze', 0.022), ('mixture', 0.022), ('rater', 0.021), ('reisinger', 0.021), ('restaurant', 0.021), ('wd', 0.021), ('subsets', 0.021), ('semantic', 0.021), ('granularity', 0.02), ('documents', 0.018), ('drawn', 0.018), ('dirichletp', 0.018), ('discretep', 0.018), ('fraudulent', 0.018), ('gorman', 0.018), ('pachinko', 0.018), ('primitives', 0.018), ('purple', 0.018), ('sector', 0.018), ('tversky', 0.018), ('tzu', 0.018), ('vikash', 0.018), ('wq', 0.018), ('zq', 0.018), ('noise', 0.018), ('humans', 0.018), ('topics', 0.018), ('cm', 0.017), ('multiple', 0.017), ('curran', 0.017), ('semantics', 0.017), ('distributional', 0.017), ('distinctions', 0.017), ('latent', 0.016), ('pad', 0.016), ('coherent', 0.016), ('clustered', 0.016), ('ms', 0.016), ('nested', 0.016), ('mccarthy', 0.016), ('scatterplot', 0.016), ('bat', 0.016), ('ccc', 0.016), ('club', 0.016), ('disparate', 0.016), ('governing', 0.016), ('korea', 0.016), ('oni', 0.016), ('ontological', 0.016), ('finds', 0.015), ('books', 0.015), ('psychological', 0.015), ('hierarchical', 0.015), ('joshua', 0.015), ('intuitive', 0.015), ('dirichlet', 0.015), ('lexical', 0.015), ('reflecting', 0.014), ('durme', 0.014), ('niu', 0.014), ('wine', 0.014), ('increases', 0.014), ('dm', 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="37-tfidf-1" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>Author: Joseph Reisinger ; Raymond Mooney</p><p>Abstract: Context-dependent word similarity can be measured over multiple cross-cutting dimensions. For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity. Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clusterings. MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich- let Allocation. Intuitively, this constraint favors feature partitions that have coherent topical semantics. Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.</p><p>2 0.13486262 <a title="37-tfidf-2" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>Author: Matthias Hartung ; Anette Frank</p><p>Abstract: This paper introduces an attribute selection task as a way to characterize the inherent meaning of property-denoting adjectives in adjective-noun phrases, such as e.g. hot in hot summer denoting the attribute TEMPERATURE, rather than TASTE. We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes. The vectors incorporate latent semantic information obtained from two variants of LDA topic models. Our LDA models outperform previous approaches on a small set of 10 attributes with considerable gains on sparse representations, which highlights the strong smoothing power of LDA models. For the first time, we extend the attribute selection task to a new data set with more than 200 classes. We observe that large-scale attribute selection is a hard problem, but a subset of attributes performs robustly on the large scale as well. Again, the LDA models outperform the VSM baseline.</p><p>3 0.093097195 <a title="37-tfidf-3" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: In this paper, we propose a novel topic model based on incorporating dictionary definitions. Traditional topic models treat words as surface strings without assuming predefined knowledge about word meaning. They infer topics only by observing surface word co-occurrence. However, the co-occurred words may not be semantically related in a manner that is relevant for topic coherence. Exploiting dictionary definitions explicitly in our model yields a better understanding of word semantics leading to better text modeling. We exploit WordNet as a lexical resource for sense definitions. We show that explicitly modeling word definitions helps improve performance significantly over the baseline for a text categorization task.</p><p>4 0.081230864 <a title="37-tfidf-4" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>Author: David Mimno ; Hanna Wallach ; Edmund Talley ; Miriam Leenders ; Andrew McCallum</p><p>Abstract: Latent variable models have the potential to add value to large document collections by discovering interpretable, low-dimensional subspaces. In order for people to use such models, however, they must trust them. Unfortunately, typical dimensionality reduction methods for text, such as latent Dirichlet allocation, often produce low-dimensional subspaces (topics) that are obviously flawed to human domain experts. The contributions of this paper are threefold: (1) An analysis of the ways in which topics can be flawed; (2) an automated evaluation metric for identifying such topics that does not rely on human annotators or reference collections outside the training data; (3) a novel statistical topic model based on this metric that significantly improves topic quality in a large-scale document collection from the National Institutes of Health (NIH).</p><p>5 0.079309173 <a title="37-tfidf-5" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>Author: Kirk Roberts ; Sanda Harabagiu</p><p>Abstract: Metonymic language is a pervasive phenomenon. Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument’s semantic class differs from the class the predicate expects. In this paper we present an unsupervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. This method also generates an enhanced probabilistic resolution of logical metonymies. The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations.</p><p>6 0.072938874 <a title="37-tfidf-6" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>7 0.071397461 <a title="37-tfidf-7" href="./emnlp-2011-Bayesian_Checking_for_Topic_Models.html">21 emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>8 0.068572693 <a title="37-tfidf-8" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>9 0.057857607 <a title="37-tfidf-9" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>10 0.04267627 <a title="37-tfidf-10" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>11 0.041930806 <a title="37-tfidf-11" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>12 0.03821509 <a title="37-tfidf-12" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>13 0.037281934 <a title="37-tfidf-13" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>14 0.034356728 <a title="37-tfidf-14" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>15 0.028098824 <a title="37-tfidf-15" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>16 0.024658881 <a title="37-tfidf-16" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>17 0.024639459 <a title="37-tfidf-17" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>18 0.024179943 <a title="37-tfidf-18" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>19 0.024009107 <a title="37-tfidf-19" href="./emnlp-2011-Discovering_Morphological_Paradigms_from_Plain_Text_Using_a_Dirichlet_Process_Mixture_Model.html">39 emnlp-2011-Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model</a></p>
<p>20 0.023382811 <a title="37-tfidf-20" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.097), (1, -0.084), (2, -0.132), (3, -0.103), (4, -0.041), (5, 0.154), (6, 0.048), (7, 0.024), (8, 0.049), (9, 0.004), (10, -0.018), (11, 0.061), (12, 0.022), (13, -0.065), (14, -0.048), (15, 0.038), (16, 0.03), (17, 0.078), (18, -0.007), (19, 0.039), (20, 0.03), (21, 0.068), (22, -0.009), (23, 0.012), (24, 0.025), (25, -0.037), (26, -0.026), (27, -0.065), (28, 0.007), (29, 0.043), (30, -0.121), (31, 0.078), (32, -0.007), (33, 0.054), (34, 0.0), (35, -0.114), (36, 0.04), (37, -0.058), (38, -0.133), (39, -0.006), (40, -0.15), (41, 0.025), (42, 0.118), (43, -0.147), (44, -0.202), (45, -0.062), (46, 0.108), (47, 0.136), (48, -0.001), (49, -0.139)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.924308 <a title="37-lsi-1" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>Author: Joseph Reisinger ; Raymond Mooney</p><p>Abstract: Context-dependent word similarity can be measured over multiple cross-cutting dimensions. For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity. Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clusterings. MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich- let Allocation. Intuitively, this constraint favors feature partitions that have coherent topical semantics. Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.</p><p>2 0.62137085 <a title="37-lsi-2" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>Author: Matthias Hartung ; Anette Frank</p><p>Abstract: This paper introduces an attribute selection task as a way to characterize the inherent meaning of property-denoting adjectives in adjective-noun phrases, such as e.g. hot in hot summer denoting the attribute TEMPERATURE, rather than TASTE. We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes. The vectors incorporate latent semantic information obtained from two variants of LDA topic models. Our LDA models outperform previous approaches on a small set of 10 attributes with considerable gains on sparse representations, which highlights the strong smoothing power of LDA models. For the first time, we extend the attribute selection task to a new data set with more than 200 classes. We observe that large-scale attribute selection is a hard problem, but a subset of attributes performs robustly on the large scale as well. Again, the LDA models outperform the VSM baseline.</p><p>3 0.56362796 <a title="37-lsi-3" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>Author: Kirk Roberts ; Sanda Harabagiu</p><p>Abstract: Metonymic language is a pervasive phenomenon. Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument’s semantic class differs from the class the predicate expects. In this paper we present an unsupervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. This method also generates an enhanced probabilistic resolution of logical metonymies. The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations.</p><p>4 0.30529568 <a title="37-lsi-4" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: In this paper, we propose a novel topic model based on incorporating dictionary definitions. Traditional topic models treat words as surface strings without assuming predefined knowledge about word meaning. They infer topics only by observing surface word co-occurrence. However, the co-occurred words may not be semantically related in a manner that is relevant for topic coherence. Exploiting dictionary definitions explicitly in our model yields a better understanding of word semantics leading to better text modeling. We exploit WordNet as a lexical resource for sense definitions. We show that explicitly modeling word definitions helps improve performance significantly over the baseline for a text categorization task.</p><p>5 0.29089794 <a title="37-lsi-5" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>Author: Diarmuid O Seaghdha ; Anna Korhonen</p><p>Abstract: This paper investigates novel methods for incorporating syntactic information in probabilistic latent variable models of lexical choice and contextual similarity. The resulting models capture the effects of context on the interpretation of a word and in particular its effect on the appropriateness of replacing that word with a potentially related one. Evaluating our techniques on two datasets, we report performance above the prior state of the art for estimating sentence similarity and ranking lexical substitutes.</p><p>6 0.29044268 <a title="37-lsi-6" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>7 0.28308272 <a title="37-lsi-7" href="./emnlp-2011-Bayesian_Checking_for_Topic_Models.html">21 emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>8 0.28277552 <a title="37-lsi-8" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>9 0.24875556 <a title="37-lsi-9" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>10 0.23640537 <a title="37-lsi-10" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>11 0.23521586 <a title="37-lsi-11" href="./emnlp-2011-Approximate_Scalable_Bounded_Space_Sketch_for_Large_Data_NLP.html">19 emnlp-2011-Approximate Scalable Bounded Space Sketch for Large Data NLP</a></p>
<p>12 0.22445059 <a title="37-lsi-12" href="./emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">23 emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p>13 0.1975372 <a title="37-lsi-13" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>14 0.17968464 <a title="37-lsi-14" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>15 0.17965917 <a title="37-lsi-15" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>16 0.17480908 <a title="37-lsi-16" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>17 0.1694617 <a title="37-lsi-17" href="./emnlp-2011-Generating_Subsequent_Reference_in_Shared_Visual_Scenes%3A_Computation_vs_Re-Use.html">62 emnlp-2011-Generating Subsequent Reference in Shared Visual Scenes: Computation vs Re-Use</a></p>
<p>18 0.16848671 <a title="37-lsi-18" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>19 0.16678587 <a title="37-lsi-19" href="./emnlp-2011-Feature-Rich_Language-Independent_Syntax-Based_Alignment_for_Statistical_Machine_Translation.html">60 emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</a></p>
<p>20 0.15674382 <a title="37-lsi-20" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.084), (36, 0.018), (37, 0.019), (45, 0.12), (52, 0.277), (53, 0.014), (54, 0.025), (57, 0.021), (62, 0.023), (64, 0.026), (66, 0.068), (69, 0.02), (79, 0.033), (82, 0.023), (87, 0.011), (96, 0.069), (98, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.78150272 <a title="37-lda-1" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>Author: Matthias Hartung ; Anette Frank</p><p>Abstract: This paper introduces an attribute selection task as a way to characterize the inherent meaning of property-denoting adjectives in adjective-noun phrases, such as e.g. hot in hot summer denoting the attribute TEMPERATURE, rather than TASTE. We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes. The vectors incorporate latent semantic information obtained from two variants of LDA topic models. Our LDA models outperform previous approaches on a small set of 10 attributes with considerable gains on sparse representations, which highlights the strong smoothing power of LDA models. For the first time, we extend the attribute selection task to a new data set with more than 200 classes. We observe that large-scale attribute selection is a hard problem, but a subset of attributes performs robustly on the large scale as well. Again, the LDA models outperform the VSM baseline.</p><p>2 0.76798379 <a title="37-lda-2" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>same-paper 3 0.76305187 <a title="37-lda-3" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>Author: Joseph Reisinger ; Raymond Mooney</p><p>Abstract: Context-dependent word similarity can be measured over multiple cross-cutting dimensions. For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity. Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clusterings. MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich- let Allocation. Intuitively, this constraint favors feature partitions that have coherent topical semantics. Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.</p><p>4 0.56121343 <a title="37-lda-4" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>5 0.55682969 <a title="37-lda-5" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>6 0.5548864 <a title="37-lda-6" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>7 0.55436605 <a title="37-lda-7" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>8 0.55307829 <a title="37-lda-8" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>9 0.53581423 <a title="37-lda-9" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>10 0.52614325 <a title="37-lda-10" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>11 0.52140993 <a title="37-lda-11" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>12 0.50851053 <a title="37-lda-12" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>13 0.50486952 <a title="37-lda-13" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>14 0.49830225 <a title="37-lda-14" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>15 0.49804431 <a title="37-lda-15" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>16 0.49676341 <a title="37-lda-16" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>17 0.49539304 <a title="37-lda-17" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>18 0.49427614 <a title="37-lda-18" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>19 0.49076393 <a title="37-lda-19" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>20 0.4906902 <a title="37-lda-20" href="./emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
