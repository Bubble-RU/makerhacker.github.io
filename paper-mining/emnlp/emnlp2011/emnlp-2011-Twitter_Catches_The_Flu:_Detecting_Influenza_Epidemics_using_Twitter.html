<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-139" href="#">emnlp2011-139</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</h1>
<br/><p>Source: <a title="emnlp-2011-139-pdf" href="http://aclweb.org/anthology//D/D11/D11-1145.pdf">pdf</a></p><p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>Reference: <a title="emnlp-2011-139-reference" href="../emnlp2011_reference/emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('influenz', 0.784), ('season', 0.313), ('tweet', 0.232), ('epidem', 0.231), ('twit', 0.178), ('peak', 0.129), ('surveil', 0.122), ('flu', 0.094), ('period', 0.081), ('clin', 0.074), ('detect', 0.074), ('drug', 0.071), ('neg', 0.069), ('excess', 0.059), ('wint', 0.059), ('correl', 0.055), ('paty', 0.052), ('breim', 0.047), ('telephon', 0.042), ('googl', 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="139-tfidf-1" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>2 0.22865263 <a title="139-tfidf-2" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>3 0.21121965 <a title="139-tfidf-3" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>Author: Fabio Massimo Zanzotto ; Marco Pennaccchiotti ; Kostas Tsioutsiouliklis</p><p>Abstract: In the last few years, the interest of the research community in micro-blogs and social media services, such as Twitter, is growing exponentially. Yet, so far not much attention has been paid on a key characteristic of microblogs: the high level of information redundancy. The aim of this paper is to systematically approach this problem by providing an operational definition of redundancy. We cast redundancy in the framework of Textual Entailment Recognition. We also provide quantitative evidence on the pervasiveness of redundancy in Twitter, and describe a dataset of redundancy-annotated tweets. Finally, we present a general purpose system for identifying redundant tweets. An extensive quantitative evaluation shows that our system successfully solves the redundancy detection task, improving over baseline systems with statistical significance.</p><p>4 0.18265118 <a title="139-tfidf-4" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>5 0.17822622 <a title="139-tfidf-5" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>Author: Roy Bar-Haim ; Elad Dinur ; Ronen Feldman ; Moshe Fresko ; Guy Goldstein</p><p>Abstract: Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. Previous work focused on aggregation of sentiment from all users. However, in this work we show that it is beneficial to distinguish expert users from non-experts. We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). In particular, we present two methods that combine expert identification and per-user unsupervised learning. These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. In addition, our work provides an in-depth analysis of the content and potential usefulness of stock tweets.</p><p>6 0.13372444 <a title="139-tfidf-6" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>7 0.10794702 <a title="139-tfidf-7" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>8 0.062058456 <a title="139-tfidf-8" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>9 0.06100649 <a title="139-tfidf-9" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>10 0.051737554 <a title="139-tfidf-10" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>11 0.048528325 <a title="139-tfidf-11" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>12 0.045922402 <a title="139-tfidf-12" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>13 0.034953009 <a title="139-tfidf-13" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>14 0.034877207 <a title="139-tfidf-14" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>15 0.033397689 <a title="139-tfidf-15" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>16 0.03168989 <a title="139-tfidf-16" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>17 0.023997994 <a title="139-tfidf-17" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>18 0.023612769 <a title="139-tfidf-18" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>19 0.021820208 <a title="139-tfidf-19" href="./emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<p>20 0.020930152 <a title="139-tfidf-20" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.103), (1, -0.276), (2, 0.245), (3, -0.008), (4, -0.096), (5, -0.003), (6, 0.014), (7, -0.008), (8, 0.016), (9, -0.02), (10, 0.005), (11, -0.011), (12, 0.006), (13, -0.016), (14, 0.02), (15, 0.003), (16, -0.024), (17, -0.038), (18, -0.001), (19, -0.029), (20, 0.006), (21, 0.014), (22, -0.021), (23, -0.004), (24, -0.057), (25, 0.023), (26, -0.026), (27, 0.017), (28, 0.032), (29, 0.039), (30, -0.042), (31, 0.002), (32, 0.025), (33, -0.004), (34, 0.027), (35, -0.002), (36, 0.002), (37, 0.052), (38, -0.073), (39, -0.079), (40, 0.043), (41, -0.049), (42, -0.069), (43, 0.044), (44, 0.032), (45, 0.016), (46, -0.117), (47, -0.004), (48, 0.078), (49, -0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9314326 <a title="139-lsi-1" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>2 0.83286673 <a title="139-lsi-2" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>Author: Roy Bar-Haim ; Elad Dinur ; Ronen Feldman ; Moshe Fresko ; Guy Goldstein</p><p>Abstract: Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. Previous work focused on aggregation of sentiment from all users. However, in this work we show that it is beneficial to distinguish expert users from non-experts. We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). In particular, we present two methods that combine expert identification and per-user unsupervised learning. These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. In addition, our work provides an in-depth analysis of the content and potential usefulness of stock tweets.</p><p>3 0.82124877 <a title="139-lsi-3" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>Author: Vahed Qazvinian ; Emily Rosengren ; Dragomir R. Radev ; Qiaozhu Mei</p><p>Abstract: A rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP). Fi- nally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations.</p><p>4 0.80335295 <a title="139-lsi-4" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>5 0.79494578 <a title="139-lsi-5" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>Author: Fabio Massimo Zanzotto ; Marco Pennaccchiotti ; Kostas Tsioutsiouliklis</p><p>Abstract: In the last few years, the interest of the research community in micro-blogs and social media services, such as Twitter, is growing exponentially. Yet, so far not much attention has been paid on a key characteristic of microblogs: the high level of information redundancy. The aim of this paper is to systematically approach this problem by providing an operational definition of redundancy. We cast redundancy in the framework of Textual Entailment Recognition. We also provide quantitative evidence on the pervasiveness of redundancy in Twitter, and describe a dataset of redundancy-annotated tweets. Finally, we present a general purpose system for identifying redundant tweets. An extensive quantitative evaluation shows that our system successfully solves the redundancy detection task, improving over baseline systems with statistical significance.</p><p>6 0.44372869 <a title="139-lsi-6" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>7 0.37929389 <a title="139-lsi-7" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>8 0.36448416 <a title="139-lsi-8" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>9 0.30553451 <a title="139-lsi-9" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>10 0.26301813 <a title="139-lsi-10" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>11 0.25626445 <a title="139-lsi-11" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>12 0.25432822 <a title="139-lsi-12" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>13 0.23893933 <a title="139-lsi-13" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>14 0.19666392 <a title="139-lsi-14" href="./emnlp-2011-Watermarking_the_Outputs_of_Structured_Prediction_with_an_application_in_Statistical_Machine_Translation..html">148 emnlp-2011-Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.</a></p>
<p>15 0.19452962 <a title="139-lsi-15" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>16 0.18075518 <a title="139-lsi-16" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>17 0.17140809 <a title="139-lsi-17" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>18 0.16527508 <a title="139-lsi-18" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>19 0.16517246 <a title="139-lsi-19" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>20 0.16465831 <a title="139-lsi-20" href="./emnlp-2011-Exploiting_Syntactic_and_Distributional_Information_for_Spelling_Correction_with_Web-Scale_N-gram_Models.html">55 emnlp-2011-Exploiting Syntactic and Distributional Information for Spelling Correction with Web-Scale N-gram Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.015), (13, 0.024), (18, 0.34), (27, 0.063), (29, 0.026), (32, 0.037), (37, 0.081), (41, 0.087), (42, 0.036), (50, 0.028), (68, 0.114), (96, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.59379774 <a title="139-lda-1" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>2 0.49315274 <a title="139-lda-2" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>Author: Tim Van de Cruys ; Thierry Poibeau ; Anna Korhonen</p><p>Abstract: This paper presents a novel method for the computation of word meaning in context. We make use of a factorization model in which words, together with their window-based context words and their dependency relations, are linked to latent dimensions. The factorization model allows us to determine which dimensions are important for a particular context, and adapt the dependency-based feature vector of the word accordingly. The evaluation on a lexical substitution task carried out for both English and French – indicates that our approach is able to reach better results than state-of-the-art methods in lexical substitution, while at the same time providing more accurate meaning representations. –</p><p>3 0.48528406 <a title="139-lda-3" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>Author: Dipak L. Chaudhari ; Om P. Damani ; Srivatsan Laxman</p><p>Abstract: Om P. Damani Srivatsan Laxman Computer Science and Engg. Microsoft Research India IIT Bombay Bangalore damani @ cse . i . ac . in itb s laxman@mi cro s o ft . com of words that co-occur in a large number of docuLexical co-occurrence is an important cue for detecting word associations. We propose a new measure of word association based on a new notion of statistical significance for lexical co-occurrences. Existing measures typically rely on global unigram frequencies to determine expected co-occurrence counts. In- stead, we focus only on documents that contain both terms (of a candidate word-pair) and ask if the distribution of the observed spans of the word-pair resembles that under a random null model. This would imply that the words in the pair are not related strongly enough for one word to influence placement of the other. However, if the words are found to occur closer together than explainable by the null model, then we hypothesize a more direct association between the words. Through extensive empirical evaluation on most of the publicly available benchmark data sets, we show the advantages of our measure over existing co-occurrence measures.</p><p>4 0.44147784 <a title="139-lda-4" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>Author: Ni Lao ; Tom Mitchell ; William W. Cohen</p><p>Abstract: t om . We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage. We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base. More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using a version of the Path Ranking Algorithm (Lao and Cohen, 2010b). We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010). This new system improves significantly over NELL’s earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks.</p><p>5 0.42751145 <a title="139-lda-5" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>Author: Diarmuid O Seaghdha ; Anna Korhonen</p><p>Abstract: This paper investigates novel methods for incorporating syntactic information in probabilistic latent variable models of lexical choice and contextual similarity. The resulting models capture the effects of context on the interpretation of a word and in particular its effect on the appropriateness of replacing that word with a potentially related one. Evaluating our techniques on two datasets, we report performance above the prior state of the art for estimating sentence similarity and ranking lexical substitutes.</p><p>6 0.42120311 <a title="139-lda-6" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>7 0.41917005 <a title="139-lda-7" href="./emnlp-2011-Collaborative_Ranking%3A_A_Case_Study_on_Entity_Linking.html">29 emnlp-2011-Collaborative Ranking: A Case Study on Entity Linking</a></p>
<p>8 0.41795495 <a title="139-lda-8" href="./emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<p>9 0.41342029 <a title="139-lda-9" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>10 0.41264865 <a title="139-lda-10" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>11 0.41208825 <a title="139-lda-11" href="./emnlp-2011-Domain_Adaptation_via_Pseudo_In-Domain_Data_Selection.html">44 emnlp-2011-Domain Adaptation via Pseudo In-Domain Data Selection</a></p>
<p>12 0.41144085 <a title="139-lda-12" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>13 0.40846685 <a title="139-lda-13" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>14 0.40822959 <a title="139-lda-14" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>15 0.40761665 <a title="139-lda-15" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>16 0.40563717 <a title="139-lda-16" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>17 0.40542275 <a title="139-lda-17" href="./emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">36 emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>18 0.40248224 <a title="139-lda-18" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>19 0.40200439 <a title="139-lda-19" href="./emnlp-2011-Tuning_as_Ranking.html">138 emnlp-2011-Tuning as Ranking</a></p>
<p>20 0.40157169 <a title="139-lda-20" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
