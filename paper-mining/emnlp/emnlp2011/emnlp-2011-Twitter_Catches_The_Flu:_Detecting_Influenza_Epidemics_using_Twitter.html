<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-139" href="#">emnlp2011-139</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</h1>
<br/><p>Source: <a title="emnlp-2011-139-pdf" href="http://aclweb.org/anthology//D/D11/D11-1145.pdf">pdf</a></p><p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>Reference: <a title="emnlp-2011-139-reference" href="../emnlp2011_reference/emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 First, the proposed system extracts influenza related tweets using Twitter API. [sent-12, score-0.944]
</p><p>2 Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. [sent-13, score-0.925]
</p><p>3 The experiment results demonstrate the feasibility of the proposed approach (0. [sent-14, score-0.051]
</p><p>4 Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0. [sent-16, score-0.258]
</p><p>5 This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. [sent-18, score-0.131]
</p><p>6 Among the numerous potential applications, this study addresses the issue of detecting influenza epidemics, which presents two outstanding advantages over current methods. [sent-31, score-0.812]
</p><p>7 Such a huge data volume dwarfs traditional surveillance resources. [sent-35, score-0.142]
</p><p>8 This characteristic is ex-  tremely suitable for influenza epidemic detection because early stage detection is important for influenza warnings. [sent-37, score-1.858]
</p><p>9 Although Twitter based influenza warnings potentially offer the advantages noted above, it might also expose inaccurate or biased information from tweets like the following (brackets [] indicate the comments):    Headache? [sent-38, score-0.949]
</p><p>10 [Suspi--‐ cions] The World Health Organization reports the avian influenza, or bird flu, epidemic has spread to nine Asian countries in the past few weeks. [sent-40, score-0.178]
</p><p>11 [Question] Although these tweets include mention of “influenza” or “flu”, they do not indicate that an influenza patient is present nearby. [sent-44, score-0.969]
</p><p>12 In our experiments, 42% of all tweets that include “influenza” are negative influenza tweets. [sent-48, score-0.984]
</p><p>13 The huge volume of such negative tweets biases the results. [sent-49, score-0.208]
</p><p>14 This paper presents a proposal of a machinelearning based classifier to filter out negative influenza tweets. [sent-50, score-0.877]
</p><p>15 First, we build an annotated corpus of pairs of a tweet and positive/negative labels. [sent-51, score-0.12]
</p><p>16 Then, a support vector machine (SVM) (Cortes and Vapnik, 1995) based sentence classifier extracts only positive influenza tweets from tweets. [sent-52, score-0.992]
</p><p>17 In the experiments, the results demonstrated the high correlation (0. [sent-53, score-0.081]
</p><p>18 The specified research point of this study is twofold: (1) This report describes that an SVM-based classifier can filter out the negative influenza tweets (f-measure=0. [sent-55, score-1.008]
</p><p>19 (2) Experiments empirically demonstrate that the proposed method detects the influenza epidemics with high accuracy (correlation ratio=0. [sent-57, score-0.972]
</p><p>20 2  Influenza Epidemic Detection  The detection of influenza epidemics is a national mission in every country for two reasons. [sent-59, score-0.993]
</p><p>21 (1) Anti-influenza drugs, which differ among influenza types, must be prepared before the epidemics. [sent-60, score-0.794]
</p><p>22 (2) We can only slightly predict what type of influenza will spread in any given season. [sent-61, score-0.825]
</p><p>23 This situation naturally demands the early detection of influenza epidemics. [sent-62, score-0.886]
</p><p>24 This section presents a description of previous methods of influenza epidemic detection. [sent-63, score-0.89]
</p><p>25 1 Traditional Approaches Most countries have their own influenza surveillance organization/center: the U. [sent-65, score-0.948]
</p><p>26 Their surveillance systems fundamentally rely on both virology and clinical data. [sent-70, score-0.206]
</p><p>27 For example, the IDSC gathers influenza patient data from 5,000 clinics and releases  summary reports. [sent-71, score-0.838]
</p><p>28 2 Recent Approaches In an attempt to provide earlier influenza detection, various new approaches are proposed each year. [sent-75, score-0.813]
</p><p>29 (2003) described a telephone triage service, a public service, to give advice to users via telephone. [sent-77, score-0.06]
</p><p>30 They investigated the number of telephone calls and reported a significant correlation with influenza epidemics. [sent-78, score-0.907]
</p><p>31 Because an influenza patient usually requires anti-influenza drugs, this approach is reasonable. [sent-80, score-0.838]
</p><p>32 However, in most countries, antiinfluenza drugs are not available at the drug store (only hospitals provide such drugs). [sent-81, score-0.079]
</p><p>33 They used Google web search queries that correlate with an influenza epidemic. [sent-84, score-0.818]
</p><p>34 Their approach demonstrated high accuracy (average correlation ratio of 0. [sent-85, score-0.099]
</p><p>35 (2009) used a query  log of a Switzerland web search engine. [sent-94, score-0.05]
</p><p>36 employs a sentence classification (discrimination of negative influenza tweets). [sent-107, score-0.853]
</p><p>37 3  Influenza Corpus  As described in Section 1, it is necessary to filter out negative influenza tweets to infer precise amounts of influenza epidemics. [sent-108, score-1.778]
</p><p>38 To do so, we con-  structed the influenza corpus (Section 3). [sent-109, score-0.794]
</p><p>39 We extracted only influenza-related tweets using a simple word look-up of “influenza”. [sent-117, score-0.131]
</p><p>40 Training Data are 5,000 tweets sent in November 2008. [sent-121, score-0.131]
</p><p>41 They were used in experiments of influenza epidemics detection. [sent-124, score-0.932]
</p><p>42 Because of the three dropout periods (Figure 1), the test data were separated into four periods (winter 2008, summer 2009, winter 2009, and summer 2010). [sent-125, score-0.28]
</p><p>43 2 Positive–negative Annotation To each tweet in the training dataset, a human annotator assigned one of two labels: positive or negative. [sent-127, score-0.163]
</p><p>44 In this labeling procedure, we regarded a tweet that meets the following two conditions as positive data. [sent-128, score-0.163]
</p><p>45 Condition 1 (A Tweet person or Surrounding persons have Flu): one or more people who have influenza should exist around the tweet person. [sent-129, score-0.914]
</p><p>46 The data include three dropout periods because the Twitter API specifications changed in those periods. [sent-134, score-0.097]
</p><p>47 The dropout periods were removed from evaluation in the experiments (Section 5). [sent-135, score-0.097]
</p><p>48 Table 1: Corpus (Tweets with a Positive or Negative Label) Positive(+1)/ Negative(--1‐) +1  Tweet  A bad influenza is going around in our lab. [sent-136, score-0.794]
</p><p>49 (Nearby people have the flu) +1 My flu is worse t han i t w as yesterday. [sent-143, score-0.172]
</p><p>50 --1‐ In the normal flu s eason, 80 percent o f d eaths occur in people over 65 (Simply a fact) --1‐  Influenza  is now r aging t hroughout J apan. [sent-144, score-0.172]
</p><p>51 ) --1‐  Bird  flu  damage  is  spreading i n J apan. [sent-151, score-0.172]
</p><p>52 The case arc “()” indicates the reason for the positive or negative annotation. [sent-155, score-0.102]
</p><p>53 4  Influenza Positive–negative Classifier  Using the corpus (Section 3), we built a classifier that judges whether a given tweet is positive or negative. [sent-166, score-0.187]
</p><p>54 The result, presented in Table 2, shows that SVM with a polynomial kernel showed feasibility from both  viewpoints of accuracy and the training time. [sent-181, score-0.051]
</p><p>55 5  Experiments  We assessed the detection performance using actual influenza reports provided by the Japanese IDSC. [sent-182, score-0.855]
</p><p>56 DRUG: The amounts of drug sales (sales of cold medicines). [sent-211, score-0.078]
</p><p>57 We split the data into four seasons as follows:  Season I: winter 2008,  Season II: summer 2009,  Season III: winter 2009,  Season IV: summer 2010. [sent-222, score-0.229]
</p><p>58 To investigate further detailed evaluations, we split the winters into two sub-seasons: before the peak and after the peak. [sent-223, score-0.149]
</p><p>59 We regard the peak point as the day with the highest number in that season. [sent-224, score-0.195]
</p><p>60 Excessive News Period: In our experimental data,  Season II and the earlier peak of Season III are special periods because news related to swine flu (H1N1 flu) is extremely hot in those seasons (Fig. [sent-226, score-0.518]
</p><p>61 We also investigated the results with and without the excessive news period. [sent-229, score-0.157]
</p><p>62 3  Evaluation Metric  The evaluation metric is based on correlation (Pearson correlation) between the gold standard  value and the estimated value. [sent-233, score-0.103]
</p><p>63 In the nonexcessive news period, the proposed method achieved the highest performance (0. [sent-236, score-0.077]
</p><p>64 This correlation is considerably higher than the query-based approach (GOOGLE), demonstrating the basic feasibility of the proposed approach. [sent-238, score-0.132]
</p><p>65 However, during the excessive news periods, the proposed method suffers from an avalanche of news, generating a news bias. [sent-239, score-0.234]
</p><p>66 1  Discussion SVM-based Negative Filtering contributes to Performance  In most seasons, the proposed SVM approach (TWEET-SVM) shows higher correlation than the simple word lookup method (TWEET-RAW). [sent-242, score-0.1]
</p><p>67 This result demonstrates the basic feasibility of the proposed approach. [sent-247, score-0.051]
</p><p>68 2  All Methods Suffer from News Bias in Excessive News Period  All methods expose the poor performance that prevails during the excessive news period (from Season II to Season III before the peak). [sent-250, score-0.231]
</p><p>69 One reason for that vulnerability is that Twitter is a kind of communication tool by which a tweet affects other people. [sent-252, score-0.12]
</p><p>70 Consequently, the possibility exists that a few tweets related to “flu” might spread widely, generating an explosive burst of influenza-related tweets. [sent-253, score-0.186]
</p><p>71 TWEET-RAW TWEET-SVM DRUG GOOGLE (Proposed  Method) Excessive news period  0. [sent-257, score-0.108]
</p><p>72 976  The number in bold indicates the significance correlation (p=0. [sent-298, score-0.081]
</p><p>73 3  Tweets have Advantages Detection  in Early Stage  From practical viewpoints, the most important task is to detect influenza epidemics before the peak (early stage detection). [sent-302, score-1.102]
</p><p>74 Consequently, the correlation of the two seasons, Season Ibefore the peak and Season III before the peak, presents the practical performance. [sent-303, score-0.23]
</p><p>75 In Season Ibefore the peak (Figure 5 Left), the proposed method (TWEET-SVM) shows the best  performance among all methods. [sent-305, score-0.168]
</p><p>76 1573 In Season II before the peak (Figure 5 Right), all methods including the proposed method showed poor correlation because they are included in the excessive news periods. [sent-306, score-0.406]
</p><p>77 During that season, the newswires heavily reported the swine flu twice (April 2009 and May 2009). [sent-307, score-0.2]
</p><p>78 4  Human Action is Sensitive demics  before Epi-  Figure 6 presents the distribution between the detected values (using GOOGLE and using TWEETSVM) and the gold standard value (before the peak is shown by “+”; that after the peak is shown as “”). [sent-313, score-0.344]
</p><p>79 Although the detected values fundamentally correlate with the gold standard, we can see different sensitivity before and after peak (The distribution before peak “+” is a higher value than after peak “-”. [sent-314, score-0.511]
</p><p>80 Results show that human action, a web search (GOOGLE) and a tweet (TWEET-SVM), highly corresponds to the real influenza before the epidemic peaks, and vice versa. [sent-316, score-1.034]
</p><p>81 More acute detection is possible if we incorporate a model considering this aspect of human nature. [sent-317, score-0.061]
</p><p>82 1574 7  Related Works  The core technology of the proposed method is to  classify whether the event is positive or negative. [sent-318, score-0.062]
</p><p>83 This task is similar to negation identification, which is a traditional topic, especially in medical fields. [sent-319, score-0.092]
</p><p>84 Previous Negation (Syntactic) Positive sentence  This study: Negative Influenza (Semantic) Positive Influenza  I don’t have the flu ! [sent-328, score-0.172]
</p><p>85 Negative sentence  Negative Influenza  I have enough flu drugs. [sent-329, score-0.172]
</p><p>86 Table 5: Our target influenza negation (semantic)  and previous negation (syntactic) Although these approaches specifically examine the syntactic negation, this study detects the negative influenza, which is a specified semantic negation. [sent-332, score-0.992]
</p><p>87 8  Conclusion  This paper proposed a new Twitter-based influenza epidemics detection method, which relies on the Natural Language Processing (NLP). [sent-340, score-1.012]
</p><p>88 Our proposed method could successfully filter out the negative influenza tweets (f-measure=0. [sent-341, score-1.003]
</p><p>89 The experiments with the test data empirically demonstrate that the proposed method detects influenza epidemics with high correlation (correlation ratio=0. [sent-343, score-1.053]
</p><p>90 1575  Figure 7: An influenza severance system “INFLU kun” using the proposed method is available at http://mednlp. [sent-346, score-0.813]
</p><p>91 Web System: The web service is also released at http://mednlp. [sent-352, score-0.07]
</p><p>92 ConText: An algorithm for identifying contextual features from clinical text. [sent-401, score-0.064]
</p><p>93 A controlled trial of automated classification of negation from clinical notes. [sent-419, score-0.123]
</p><p>94 Telephone triage: A timely data source for surveillance of influenza-like diseases. [sent-426, score-0.124]
</p><p>95 Detecting influenza epidemics using search engine query data, Nature Vol. [sent-458, score-0.958]
</p><p>96 A novel hybrid approach to automated negation detection in clinical radiology reports. [sent-465, score-0.184]
</p><p>97 Analysis of Web access logs for surveillance of influenza. [sent-492, score-0.124]
</p><p>98 Evaluation of over-the-counter pharmaceutical sales as a possible early warning indicator of human disease. [sent-499, score-0.067]
</p><p>99 Use of general purpose negation detection to augment concept indexing of medical documents: A quantitative study using theUMLS. [sent-517, score-0.153]
</p><p>100 Earthquake shakes Twitter users: real-time event detection by social sensors, in Proc. [sent-548, score-0.08]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('influenza', 0.794), ('season', 0.261), ('twitter', 0.18), ('flu', 0.172), ('peak', 0.149), ('epidemics', 0.138), ('tweets', 0.131), ('surveillance', 0.124), ('tweet', 0.12), ('excessive', 0.099), ('epidemic', 0.096), ('correlation', 0.081), ('clinical', 0.064), ('detection', 0.061), ('negation', 0.059), ('negative', 0.059), ('news', 0.058), ('periods', 0.056), ('breiman', 0.055), ('seasons', 0.055), ('period', 0.05), ('winter', 0.047), ('service', 0.046), ('patient', 0.044), ('positive', 0.043), ('google', 0.042), ('drug', 0.042), ('cortes', 0.041), ('dropout', 0.041), ('ginsberg', 0.041), ('idsc', 0.041), ('summer', 0.04), ('chapman', 0.039), ('drugs', 0.037), ('window', 0.037), ('sales', 0.036), ('tokyo', 0.035), ('medical', 0.033), ('japan', 0.032), ('telephone', 0.032), ('feasibility', 0.032), ('spread', 0.031), ('early', 0.031), ('countries', 0.03), ('disease', 0.028), ('beaffoterer', 0.028), ('dowling', 0.028), ('elkin', 0.028), ('espino', 0.028), ('huberman', 0.028), ('hulth', 0.028), ('ibefore', 0.028), ('magruder', 0.028), ('milstein', 0.028), ('mutalik', 0.028), ('polgreen', 0.028), ('ppeeaakk', 0.028), ('swine', 0.028), ('triage', 0.028), ('query', 0.026), ('svm', 0.025), ('regard', 0.025), ('health', 0.025), ('web', 0.024), ('classifier', 0.024), ('detected', 0.024), ('seas', 0.024), ('burst', 0.024), ('sakaki', 0.024), ('infection', 0.024), ('expose', 0.024), ('gold', 0.022), ('informatics', 0.022), ('detects', 0.021), ('day', 0.021), ('bagging', 0.021), ('barbosa', 0.021), ('bird', 0.021), ('earthquake', 0.021), ('hogan', 0.021), ('stage', 0.021), ('http', 0.021), ('vapnik', 0.02), ('boyd', 0.02), ('social', 0.019), ('world', 0.019), ('peaks', 0.019), ('finin', 0.019), ('viewpoints', 0.019), ('freund', 0.019), ('november', 0.019), ('proposed', 0.019), ('detecting', 0.018), ('ratio', 0.018), ('huge', 0.018), ('messages', 0.018), ('fundamentally', 0.018), ('japanese', 0.017), ('ii', 0.017), ('sentiment', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="139-tfidf-1" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>2 0.17437564 <a title="139-tfidf-2" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>3 0.15724444 <a title="139-tfidf-3" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>Author: Fabio Massimo Zanzotto ; Marco Pennaccchiotti ; Kostas Tsioutsiouliklis</p><p>Abstract: In the last few years, the interest of the research community in micro-blogs and social media services, such as Twitter, is growing exponentially. Yet, so far not much attention has been paid on a key characteristic of microblogs: the high level of information redundancy. The aim of this paper is to systematically approach this problem by providing an operational definition of redundancy. We cast redundancy in the framework of Textual Entailment Recognition. We also provide quantitative evidence on the pervasiveness of redundancy in Twitter, and describe a dataset of redundancy-annotated tweets. Finally, we present a general purpose system for identifying redundant tweets. An extensive quantitative evaluation shows that our system successfully solves the redundancy detection task, improving over baseline systems with statistical significance.</p><p>4 0.1268539 <a title="139-tfidf-4" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>5 0.12480598 <a title="139-tfidf-5" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>Author: Vahed Qazvinian ; Emily Rosengren ; Dragomir R. Radev ; Qiaozhu Mei</p><p>Abstract: A rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP). Fi- nally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations.</p><p>6 0.11982238 <a title="139-tfidf-6" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>7 0.077391744 <a title="139-tfidf-7" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>8 0.057966519 <a title="139-tfidf-8" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>9 0.047604956 <a title="139-tfidf-9" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>10 0.046350565 <a title="139-tfidf-10" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>11 0.043591853 <a title="139-tfidf-11" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>12 0.036519468 <a title="139-tfidf-12" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>13 0.034433793 <a title="139-tfidf-13" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>14 0.031483568 <a title="139-tfidf-14" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>15 0.028362187 <a title="139-tfidf-15" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>16 0.025683103 <a title="139-tfidf-16" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>17 0.024439145 <a title="139-tfidf-17" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>18 0.023273733 <a title="139-tfidf-18" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>19 0.022329781 <a title="139-tfidf-19" href="./emnlp-2011-Exploiting_Syntactic_and_Distributional_Information_for_Spelling_Correction_with_Web-Scale_N-gram_Models.html">55 emnlp-2011-Exploiting Syntactic and Distributional Information for Spelling Correction with Web-Scale N-gram Models</a></p>
<p>20 0.022237435 <a title="139-tfidf-20" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.099), (1, -0.194), (2, 0.231), (3, 0.022), (4, -0.148), (5, -0.003), (6, -0.015), (7, 0.0), (8, 0.025), (9, -0.006), (10, 0.017), (11, 0.02), (12, 0.037), (13, -0.031), (14, -0.002), (15, -0.004), (16, -0.042), (17, 0.039), (18, 0.014), (19, 0.001), (20, 0.037), (21, -0.053), (22, 0.069), (23, 0.061), (24, 0.007), (25, -0.025), (26, 0.034), (27, 0.007), (28, 0.007), (29, -0.01), (30, -0.038), (31, -0.003), (32, -0.031), (33, -0.016), (34, -0.028), (35, -0.033), (36, 0.076), (37, 0.101), (38, 0.023), (39, 0.011), (40, -0.094), (41, 0.049), (42, 0.058), (43, 0.052), (44, -0.059), (45, -0.0), (46, 0.06), (47, -0.0), (48, -0.067), (49, 0.119)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95210958 <a title="139-lsi-1" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>2 0.77666312 <a title="139-lsi-2" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>Author: Vahed Qazvinian ; Emily Rosengren ; Dragomir R. Radev ; Qiaozhu Mei</p><p>Abstract: A rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP). Fi- nally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations.</p><p>3 0.77595413 <a title="139-lsi-3" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>Author: Roy Bar-Haim ; Elad Dinur ; Ronen Feldman ; Moshe Fresko ; Guy Goldstein</p><p>Abstract: Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. Previous work focused on aggregation of sentiment from all users. However, in this work we show that it is beneficial to distinguish expert users from non-experts. We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). In particular, we present two methods that combine expert identification and per-user unsupervised learning. These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. In addition, our work provides an in-depth analysis of the content and potential usefulness of stock tweets.</p><p>4 0.77110946 <a title="139-lsi-4" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>Author: Fabio Massimo Zanzotto ; Marco Pennaccchiotti ; Kostas Tsioutsiouliklis</p><p>Abstract: In the last few years, the interest of the research community in micro-blogs and social media services, such as Twitter, is growing exponentially. Yet, so far not much attention has been paid on a key characteristic of microblogs: the high level of information redundancy. The aim of this paper is to systematically approach this problem by providing an operational definition of redundancy. We cast redundancy in the framework of Textual Entailment Recognition. We also provide quantitative evidence on the pervasiveness of redundancy in Twitter, and describe a dataset of redundancy-annotated tweets. Finally, we present a general purpose system for identifying redundant tweets. An extensive quantitative evaluation shows that our system successfully solves the redundancy detection task, improving over baseline systems with statistical significance.</p><p>5 0.66844887 <a title="139-lsi-5" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>6 0.41830587 <a title="139-lsi-6" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>7 0.38568696 <a title="139-lsi-7" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>8 0.35128978 <a title="139-lsi-8" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>9 0.30928344 <a title="139-lsi-9" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>10 0.28131226 <a title="139-lsi-10" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>11 0.22372943 <a title="139-lsi-11" href="./emnlp-2011-Watermarking_the_Outputs_of_Structured_Prediction_with_an_application_in_Statistical_Machine_Translation..html">148 emnlp-2011-Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.</a></p>
<p>12 0.19411457 <a title="139-lsi-12" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>13 0.19212089 <a title="139-lsi-13" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>14 0.18409942 <a title="139-lsi-14" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>15 0.17964579 <a title="139-lsi-15" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>16 0.17307839 <a title="139-lsi-16" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>17 0.17293952 <a title="139-lsi-17" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>18 0.15627205 <a title="139-lsi-18" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>19 0.15556177 <a title="139-lsi-19" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>20 0.15539259 <a title="139-lsi-20" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(15, 0.017), (18, 0.016), (23, 0.09), (31, 0.02), (36, 0.018), (37, 0.024), (45, 0.066), (52, 0.061), (53, 0.016), (54, 0.016), (57, 0.017), (62, 0.03), (64, 0.016), (66, 0.017), (69, 0.012), (77, 0.331), (79, 0.042), (82, 0.01), (87, 0.016), (96, 0.03), (98, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70680112 <a title="139-lda-1" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>2 0.39960155 <a title="139-lda-2" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>Author: Matthias Hartung ; Anette Frank</p><p>Abstract: This paper introduces an attribute selection task as a way to characterize the inherent meaning of property-denoting adjectives in adjective-noun phrases, such as e.g. hot in hot summer denoting the attribute TEMPERATURE, rather than TASTE. We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes. The vectors incorporate latent semantic information obtained from two variants of LDA topic models. Our LDA models outperform previous approaches on a small set of 10 attributes with considerable gains on sparse representations, which highlights the strong smoothing power of LDA models. For the first time, we extend the attribute selection task to a new data set with more than 200 classes. We observe that large-scale attribute selection is a hard problem, but a subset of attributes performs robustly on the large scale as well. Again, the LDA models outperform the VSM baseline.</p><p>3 0.3954536 <a title="139-lda-3" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>4 0.39375204 <a title="139-lda-4" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>Author: Joseph Reisinger ; Raymond Mooney</p><p>Abstract: Context-dependent word similarity can be measured over multiple cross-cutting dimensions. For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity. Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clusterings. MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich- let Allocation. Intuitively, this constraint favors feature partitions that have coherent topical semantics. Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.</p><p>5 0.37433472 <a title="139-lda-5" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>6 0.36724684 <a title="139-lda-6" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>7 0.36502838 <a title="139-lda-7" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>8 0.3617104 <a title="139-lda-8" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>9 0.36164728 <a title="139-lda-9" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>10 0.36150634 <a title="139-lda-10" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>11 0.36016801 <a title="139-lda-11" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>12 0.36010626 <a title="139-lda-12" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>13 0.35932961 <a title="139-lda-13" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>14 0.35848495 <a title="139-lda-14" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>15 0.35614964 <a title="139-lda-15" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>16 0.35597885 <a title="139-lda-16" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>17 0.35576731 <a title="139-lda-17" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>18 0.3553468 <a title="139-lda-18" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>19 0.35431194 <a title="139-lda-19" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>20 0.3541109 <a title="139-lda-20" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
