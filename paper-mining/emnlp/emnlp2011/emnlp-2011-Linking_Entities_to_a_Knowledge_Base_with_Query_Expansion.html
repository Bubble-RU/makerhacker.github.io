<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-90" href="#">emnlp2011-90</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</h1>
<br/><p>Source: <a title="emnlp-2011-90-pdf" href="http://aclweb.org/anthology//D/D11/D11-1074.pdf">pdf</a></p><p>Author: Swapna Gottipati ; Jing Jiang</p><p>Abstract: In this paper we present a novel approach to entity linking based on a statistical language model-based information retrieval with query expansion. We use both local contexts and global world knowledge to expand query language models. We place a strong emphasis on named entities in the local contexts and explore a positional language model to weigh them differently based on their distances to the query. Our experiments on the TAC-KBP 2010 data show that incorporating such contextual information indeed aids in disambiguating the named entities and consistently improves the entity linking performance. Compared with the official results from KBP 2010 participants, our system shows competitive performance.</p><p>Reference: <a title="emnlp-2011-90-reference" href="../emnlp2011_reference/emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 s g  Abstract In this paper we present a novel approach to entity linking based on a statistical language model-based information retrieval with query expansion. [sent-4, score-0.656]
</p><p>2 We use both local contexts and global world knowledge to expand query language models. [sent-5, score-0.587]
</p><p>3 Our experiments on the TAC-KBP 2010 data show that incorporating such contextual information indeed aids in disambiguating the named entities and consistently improves the entity linking performance. [sent-7, score-0.351]
</p><p>4 This task of linking mentions of entities within specific contexts to their corresponding entries in an existing knowledge base is called entity linking and has been proposed and studied in the Knowledge Base Population (KBP) track of the Text Analysis Conference (TAC) (McNamee and Dang, 2009). [sent-11, score-0.534]
</p><p>5 Besides improving an online surfer’s browsing experience, entity linking also has potential us804 Jing Jiang School of Information Systems Singapore Management University Singapore j ing j iang@ smu . [sent-12, score-0.241]
</p><p>6 The major challenge of entity linking is to resolve name ambiguities. [sent-15, score-0.437]
</p><p>7 (2) Synonymy: This type of ambiguities refers to the case when more than one name variation refers to the same entity. [sent-25, score-0.274]
</p><p>8 Synonymy affects entity linking when the entity mention in the document uses a name variation not covered in the entity’s knowledge base entry. [sent-30, score-0.691]
</p><p>9 Intuitively, to disambiguate a polysemous entity name, we should make use of the context in which the name occurs, and to address synonymy, external world knowledge is usually needed to expand acronyms or find other name variations. [sent-31, score-0.742]
</p><p>10 We use the KL-divergence retrieval model (Zhai and Lafferty, 2001) and expand the query language models by considering both the local contexts within the query documents and global world knowledge obtained from the Web. [sent-38, score-1.021]
</p><p>11 ec th2o0d1s1 i Ans Nsoactuiartaioln La fonrg Cuaogmep Purtoatcieosnsainlg L,in pgaugies ti 8c0s4–813,  We evaluate our retrieval method with query expansion on the 2010 TAC-KBP data set. [sent-41, score-0.483]
</p><p>12 We find that our expanded query language models can indeed improve the performance significantly, demonstrat-  ing the effectiveness of our principled and yet simple techniques. [sent-42, score-0.531]
</p><p>13 Each KB entry E represents a unique entity and has three fields: (1) a name string NE, which can be regarded as the official name of the entity, (2) an entity type TE, which is one of {PER, ORG, GPE, UNKNOWN}, a wnhdi (3) some disambiguation tGexPtE DE. [sent-50, score-0.974]
</p><p>14 GKivNeOnW a query Q w(3h)ic shom mcoen dsiisstasm obfi a query name string NQ and a query document DQ where the name occurs, the task is to return a single KB entry to which the query name string refers or Nil if there is no such KB entry. [sent-51, score-2.572]
</p><p>15 It is fairly natural to address entity linking by  ranking the KB entries given a query. [sent-52, score-0.321]
</p><p>16 In this section 805 we present an overview of our system, which consists of two major stages: a candidate selection stage to identify a set of candidate KB entries through name matching, and a ranking stage to link the query entity to the most likely KB entry. [sent-53, score-1.071]
</p><p>17 In both stages, we consider the query’s local context in the query document and world knowledge obtained from the Web. [sent-54, score-0.567]
</p><p>18 Intuitively, we determine whether two entities are the same by comparing their name strings. [sent-60, score-0.288]
</p><p>19 We therefore need to compare the query name string NQ with the name string NE of each KB entry. [sent-61, score-0.975]
</p><p>20 However, because of the name ambiguity problem, we cannot expect the correct KB entry to always have exactly the same name string as the query. [sent-62, score-0.641]
</p><p>21 To address this problem, we use a set of alternative name strings expanded from NQ and select KB entries whose name strings match at least one of them. [sent-63, score-0.793]
</p><p>22 These alternative name strings come from two sources: the query document DQ and the Web. [sent-64, score-0.76]
</p><p>23 First, we observe that some useful alternative name strings come from the query document. [sent-65, score-0.712]
</p><p>24 For example, a PER query name string may contain only a person’s last name but the query document contains the person’s full name, which is clearly a less ambiguous name string to use. [sent-66, score-1.631]
</p><p>25 Similarly, a GPE query name string may contain only the name of a city or town but the query document contains the state or province, which also helps disambiguate the query entity. [sent-67, score-1.733]
</p><p>26 Given query Q, let SQ denote the set of faoltlelrownaitnivge. [sent-69, score-0.393]
</p><p>27 t Ihne-istihaelllyf SNER tagger to identify named entities from the query document DQ. [sent-73, score-0.549]
</p><p>28 We denote these alternative name strings as  {NQl,i}iK=Q1,  where lindicates that these name strings come locally from DQ and KQ is the total number of such name strings. [sent-76, score-0.819]
</p><p>29 Sometimes alternative name strings have to come from external knowledge. [sent-80, score-0.339]
</p><p>30 For example, one of the queries we have contains the name string “AMPAS,” and the query document also uses only this acronym to refer to this entity. [sent-81, score-0.796]
</p><p>31 But the full name of the entity, “Academy of Motion Pictures Arts and Sciences,” is needed in order to locate the correct KB entry. [sent-82, score-0.233]
</p><p>32 Given query name string NQ, we check whether the following link exists: http : / / en . [sent-84, score-0.71]
</p><p>33 So if the link exists, we use the title of the Wikipedia page as another alternative name string for NQ. [sent-88, score-0.351]
</p><p>34 We refer to this name string as NQg to indicate that it is a global name variant. [sent-89, score-0.54]
</p><p>35 For each name string N in SQ, we find KB entries whFoosre name strings imngat Nch Nn S. [sent-92, score-0.64]
</p><p>36 We take the union of 806 Query name string (NQ): Mobile Query document (DQ): The site is near Mount Vernon in the Calvert community on the Tombigbee River, some 25 miles (40 kilometers) north of Mobile. [sent-93, score-0.339]
</p><p>37 Alternative Query Strings (SQ): fArlotmer nloatcaivle c Qounteerxyt: S t Mrionbgisle (, Mobile Mount Vernon, Mobile Calvert, Mobile River, Mobile Mexico, Mobile Alabama, Mobile Brazil Figure 1: An example GPE query from TAC 2010. [sent-96, score-0.393]
</p><p>38 Query name string (NQ): Coppola Query document (DQ): I had no idea of all these semi-obscure connections, felicia! [sent-97, score-0.339]
</p><p>39 I think I once saw a picture of him sometime ago Alternative Query Strings (SQ): fArlotmer nloactaivl eco Qnuteexryt: Coppola, Sophia Coppola, Sofia Coppola from world knowledge(Wikipedia): Sofia Coppola Figure 2: An example PER query from TAC 2010. [sent-100, score-0.457]
</p><p>40 These are steh es ectasn odfid KaBte eKntBr eenst arineds rfeofre query Q. [sent-102, score-0.393]
</p><p>41 Given a KB entry E and query Q, we score E based on the KL-divergence defined below:  s(E,Q) = −Div(θQ∥θE) = −∑p(w|θQ)logpp((ww||θθEQ)). [sent-106, score-0.528]
</p><p>42 µ  (1) Here θQ and θE are the query language model and the KB entry language model, respectively. [sent-107, score-0.528]
</p><p>43 To estimate θQ, typically we can use the empirical query word distribution:  p(w|θQ) =c(w|N,NQ|Q),  (3)  where c(w, NQ) is the count of w in NQ and |NQ | is the length of NQ. [sent-117, score-0.393]
</p><p>44 We call this model thea original query language model. [sent-118, score-0.393]
</p><p>45 After ranking the candidate KB entries in EQ using Equation (1), we perform entity linking as follows. [sent-119, score-0.347]
</p><p>46 First, using an NER tagger, we determine the entity type of the query name string NQ. [sent-120, score-0.8]
</p><p>47 The system links the query entity to this KB entry. [sent-123, score-0.509]
</p><p>48 1 that using the original query name string NQ itself may not be enough to obtain the correct KB entry, and additional words from both the query document and external knowledge can be useful. [sent-126, score-1.175]
</p><p>49 In this section, we  discuss how to expand the query language model θQ with these additional words in a principled way in order to rank KB entries based on how likely they match the query entity. [sent-128, score-0.942]
</p><p>50 During the KB entry ranking stage, if we use θQ estimated from NQ, which contains only the word 807 “Coppola,” the retrieval function is unlikely to rank the correct KB entry on the top. [sent-131, score-0.371]
</p><p>51 But if we include the contextual word “Sophia” from the query document when estimating the query language model, KL-divergence retrieval model is likely to rank the correct KB entry on the top. [sent-132, score-1.035]
</p><p>52 This idea of using contextual words to expand the query is very similar to (pseudo) relevance feedback in information retrieval. [sent-133, score-0.534]
</p><p>53 We can treat the query document DQ as our only feedback document. [sent-134, score-0.513]
</p><p>54 We then linearly interpolate the feedback language model with the original query language model to form an expanded query language model: p(w|θQL)  =  αp(w|θQ) + (1 − α)p(w|θDQ ), (5)  where α is a parameter between 0 and 1, to control the amount of feedback. [sent-143, score-0.963]
</p><p>55 L indicates that the query  expansion comes from local context. [sent-145, score-0.474]
</p><p>56 For entity linking, we suspect that named entities surrounding the query name string in DQ are particularly useful for disambiguation and thus should be emphasized over other words. [sent-148, score-0.956]
</p><p>57 Positional Model Another observation is that words closer to the query name string in the query document are likely to be more important than words farther away. [sent-151, score-1.125]
</p><p>58 Intuitively, we can use the distance between a word and the query name string to help weigh the word. [sent-152, score-0.684]
</p><p>59 2 Using Global World Knowledge Similar to the way we incorporate words from DQ into the query language model, we can also construct a feedback language model using the most likely official name ofthe query entity obtained from Wikipedia. [sent-158, score-1.242]
</p><p>60 (9)  We can then linearly interpolate θNgQ with the original query language model θQ to form an expanded query language model θQG: p(w|θQG) = αp(w|θQ) + (1− α)p(w|θNQg). [sent-160, score-0.891]
</p><p>61 (10) Here G indicates that the query expansion comes from global world knowledge. [sent-161, score-0.54]
</p><p>62 3  Combining Local Context and World Knowledge We can further combine the two kinds of additional words into the query language model as follows: p(w|θLQ+G)  =  (βp(w|θDQ) +(1 − β)p(w|θNQg)). [sent-166, score-0.393]
</p><p>63 The data set contains 2250 queries and query documents come from news wire and Web pages. [sent-172, score-0.457]
</p><p>64 This piece of text comes from a query document where the query name string is “Jackman. [sent-178, score-1.125]
</p><p>65 ” We can see that the NER tagger can help locate the full name  of the person. [sent-179, score-0.233]
</p><p>66 Methods to Compare: Recall that our system consists of a KB entry selection stage and a KB entry ranking stage. [sent-192, score-0.4]
</p><p>67 At the selection stage, a set SQ of aralntekrinnagtiv seta name strings are utisoend tstoa sgeel,ec at sceatnd Sidate KB entries. [sent-193, score-0.305]
</p><p>68 We first define a few settings where different alternative name string sets are used to select candidate KB entries: •  Q represents the baseline setting which uses only pthrees original query name string NQ hto u select candidate KB entries. [sent-194, score-1.101]
</p><p>69 •  •  •  Q+L represents the setting where alternative name strings tosbta thinee dse ftrinomg wthhee query ndaotcivuement DQ are combined with NQ to select candidate KB entries. [sent-195, score-0.758]
</p><p>70 Q+G represents the setting where the alternatQiv+eG name string hoebt saeitnteindg fr wohmer Wikipedia aiscombined with NQ to select candidate KB entries. [sent-196, score-0.337]
</p><p>71 r 1, tehntats is, a slteettrinnagtiv aes name strings from both DQ and Wikipedia are used together with NQ to select candidate KB entries. [sent-198, score-0.331]
</p><p>72 After selecting candidate KB entries, in the KB entry ranking stage, we have four options for the query language model and two options for the KB entry language model. [sent-199, score-0.724]
</p><p>73 Before examining the effect of query expansion in ranking, we now compare the effect of using different sets of alternative query name strings in the candidate KB entry selection stage. [sent-207, score-1.335]
</p><p>74 For this set of experiments, we fix the query language model to θQ and the KB entry language model to θNE in the ranking stage. [sent-208, score-0.563]
</p><p>75 the Nil case), the performance of Q, Q+L, Q+G and Q+L+G is very close, indicating that the additional alternative query name strings do not help. [sent-218, score-0.712]
</p><p>76 It shows that the alternative query name strings are most useful for queries that do have their correct entries in the KB. [sent-219, score-0.84]
</p><p>77 panded query language models θQL, θQG and We first analyze the results without using the KB disambiguation text, i. [sent-221, score-0.441]
</p><p>78 Table 5 shows the comparison between θQ and other expanded query language models in terms of micro-averaged accuracy. [sent-224, score-0.498]
</p><p>79 The results reveal that the expanded query language models can indeed improve the overall performance (the both Nil and non-Nil case) under all settings. [sent-225, score-0.498]
</p><p>80 This shows the effectiveness of using the principled query expansion technique coupled with KL-divergence retrieval model to rank KB entries. [sent-226, score-0.541]
</p><p>81 86333587 Table 5: Comparison between the performance of θQ and expanded query language models in terms of micro average  accuracy. [sent-299, score-0.534]
</p><p>82 While in Table 4 the alternative name strings do not affect the performance much for Nil queries,  now the expanded query language models actually hurt the performance for Nil queries. [sent-302, score-0.817]
</p><p>83 When we expand the query language model, we can possibly introduce noise, especially when we use the external knowledge obtained from Wikipedia, which largely depends on what Wikipedia considers to be the most popular official name of a query name string. [sent-304, score-1.353]
</p><p>84 With noisy terms in the expanded query language model we increase the chance to link the query to a KB entry which is not the correct match. [sent-305, score-1.052]
</p><p>85 The challenge is that we do not know when additional terms in the expanded query language model are noise and when they are not, because for non-Nil queries we do observe a substantial amount of improvement brought by query expansion, especially with external world knowledge. [sent-306, score-1.039]
</p><p>86 We now further study the impact of using the KB disambiguation text associated with each entry to estimate the KB entry language model used in the KLdivergence ranking function. [sent-308, score-0.353]
</p><p>87 Without the KB disambiguation text both the KB entry Mobile Alabama and the entry Mobile River are given the same score, resulting in inaccurate linking in the θNE case. [sent-313, score-0.424]
</p><p>88 However, we observe that such cases are very rare in the TAC 2010 query list and thus the overall improvement observed is minimal. [sent-315, score-0.393]
</p><p>89 69372 Table 7: The KL-divergence scores of KB entities for the query Mobile. [sent-320, score-0.466]
</p><p>90 88335577 Table 6: Comparing the performance using KB text and without using KB text for all methods using expanded query models in terms of micro average accuracy on 2250 queries. [sent-407, score-0.534]
</p><p>91 Recall that all the expanded query language models also have a control parameters α. [sent-426, score-0.498]
</p><p>92 context and the global world knowledge are weighed equally for aiding disambiguation and improving the entity linking performance. [sent-441, score-0.398]
</p><p>93 In their work, they took an assumption that every entity has a KB entry and thus the NIL entries are not handled. [sent-460, score-0.341]
</p><p>94 (2010) took the approach that large number of entities will be unlinkable, as there is a probability that the relevant KB entry is unavailable. [sent-468, score-0.234]
</p><p>95 But their proposal for handling the alias name or stage name via multiple lists is not scalable. [sent-470, score-0.53]
</p><p>96 Similarly, for acronyms we use the global knowledge that aids unabbreviating and thus entity disambiguation. [sent-472, score-0.249]
</p><p>97 We integrated some of their ideas like world knowledge with our new techniques to achieve efficient entity linking accuracy. [sent-483, score-0.316]
</p><p>98 6  Conclusions  In this paper we proposed a novel approach to entity linking based on statistical language model-based information retrieval with query expansion using the local context from the query document as well as world knowledge from the Web. [sent-484, score-1.272]
</p><p>99 Document language models, query models, and risk minimization for information retrieval. [sent-508, score-0.393]
</p><p>100 A comparative study of methods for estimating query language  models with pseudo feedback. [sent-522, score-0.429]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kb', 0.659), ('query', 0.393), ('name', 0.215), ('dq', 0.212), ('nq', 0.191), ('ql', 0.148), ('entry', 0.135), ('entity', 0.116), ('tac', 0.108), ('linking', 0.106), ('expanded', 0.105), ('mobile', 0.1), ('ne', 0.096), ('nil', 0.087), ('gpe', 0.085), ('string', 0.076), ('stage', 0.075), ('coppola', 0.074), ('entities', 0.073), ('feedback', 0.072), ('wikipedia', 0.071), ('strings', 0.07), ('queries', 0.064), ('entries', 0.064), ('world', 0.064), ('nqg', 0.062), ('sensitivity', 0.06), ('sq', 0.053), ('official', 0.053), ('zhai', 0.05), ('expansion', 0.049), ('alabama', 0.049), ('nnee', 0.049), ('disambiguation', 0.048), ('acronyms', 0.048), ('qg', 0.048), ('document', 0.048), ('river', 0.042), ('kbp', 0.042), ('positional', 0.042), ('retrieval', 0.041), ('base', 0.039), ('eq', 0.038), ('lq', 0.037), ('pseudo', 0.036), ('micro', 0.036), ('relevance', 0.035), ('ranking', 0.035), ('named', 0.035), ('chengxiang', 0.035), ('global', 0.034), ('expand', 0.034), ('alternative', 0.034), ('lv', 0.033), ('principled', 0.033), ('local', 0.032), ('mcnamee', 0.032), ('sophia', 0.032), ('population', 0.032), ('ji', 0.03), ('knowledge', 0.03), ('org', 0.029), ('link', 0.026), ('took', 0.026), ('candidate', 0.026), ('dredze', 0.025), ('alias', 0.025), ('ampas', 0.025), ('brazil', 0.025), ('calvert', 0.025), ('farlotmer', 0.025), ('fqb', 0.025), ('mount', 0.025), ('ngq', 0.025), ('sofia', 0.025), ('vernon', 0.025), ('rank', 0.025), ('zheng', 0.023), ('synonymy', 0.022), ('ner', 0.021), ('tq', 0.021), ('route', 0.021), ('aids', 0.021), ('lehmann', 0.021), ('yuanhua', 0.021), ('affects', 0.021), ('selection', 0.02), ('select', 0.02), ('management', 0.02), ('external', 0.02), ('refers', 0.02), ('lafferty', 0.019), ('ambiguities', 0.019), ('lavrenko', 0.019), ('redirect', 0.019), ('heterogenous', 0.019), ('smu', 0.019), ('careful', 0.019), ('singapore', 0.018), ('locate', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999917 <a title="90-tfidf-1" href="./emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<p>Author: Swapna Gottipati ; Jing Jiang</p><p>Abstract: In this paper we present a novel approach to entity linking based on a statistical language model-based information retrieval with query expansion. We use both local contexts and global world knowledge to expand query language models. We place a strong emphasis on named entities in the local contexts and explore a positional language model to weigh them differently based on their distances to the query. Our experiments on the TAC-KBP 2010 data show that incorporating such contextual information indeed aids in disambiguating the named entities and consistently improves the entity linking performance. Compared with the official results from KBP 2010 participants, our system shows competitive performance.</p><p>2 0.31151402 <a title="90-tfidf-2" href="./emnlp-2011-Collaborative_Ranking%3A_A_Case_Study_on_Entity_Linking.html">29 emnlp-2011-Collaborative Ranking: A Case Study on Entity Linking</a></p>
<p>Author: Zheng Chen ; Heng Ji</p><p>Abstract: In this paper, we present a new ranking scheme, collaborative ranking (CR). In contrast to traditional non-collaborative ranking scheme which solely relies on the strengths of isolated queries and one stand-alone ranking algorithm, the new scheme integrates the strengths from multiple collaborators of a query and the strengths from multiple ranking algorithms. We elaborate three specific forms of collaborative ranking, namely, micro collaborative ranking (MiCR), macro collaborative ranking (MaCR) and micro-macro collab- orative ranking (MiMaCR). Experiments on entity linking task show that our proposed scheme is indeed effective and promising.</p><p>3 0.13343954 <a title="90-tfidf-3" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>Author: Ni Lao ; Tom Mitchell ; William W. Cohen</p><p>Abstract: t om . We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage. We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base. More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using a version of the Path Ranking Algorithm (Lao and Cohen, 2010b). We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010). This new system improves significantly over NELL’s earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks.</p><p>4 0.10735326 <a title="90-tfidf-4" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>Author: Johannes Hoffart ; Mohamed Amir Yosef ; Ilaria Bordino ; Hagen Furstenau ; Manfred Pinkal ; Marc Spaniol ; Bilyana Taneva ; Stefan Thater ; Gerhard Weikum</p><p>Abstract: Disambiguating named entities in naturallanguage text maps mentions of ambiguous names onto canonical entities like people or places, registered in a knowledge base such as DBpedia or YAGO. This paper presents a robust method for collective disambiguation, by harnessing context from knowledge bases and using a new form of coherence graph. It unifies prior approaches into a comprehensive framework that combines three measures: the prior probability of an entity being mentioned, the similarity between the contexts of a mention and a candidate entity, as well as the coherence among candidate entities for all mentions together. The method builds a weighted graph of mentions and candidate entities, and computes a dense subgraph that approximates the best joint mention-entity mapping. Experiments show that the new method significantly outperforms prior methods in terms of accuracy, with robust behavior across a variety of inputs.</p><p>5 0.078607686 <a title="90-tfidf-5" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>6 0.078485265 <a title="90-tfidf-6" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>7 0.058598615 <a title="90-tfidf-7" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>8 0.056460064 <a title="90-tfidf-8" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>9 0.046818752 <a title="90-tfidf-9" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>10 0.045757275 <a title="90-tfidf-10" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>11 0.043700233 <a title="90-tfidf-11" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>12 0.040485568 <a title="90-tfidf-12" href="./emnlp-2011-Enhancing_Chinese_Word_Segmentation_Using_Unlabeled_Data.html">48 emnlp-2011-Enhancing Chinese Word Segmentation Using Unlabeled Data</a></p>
<p>13 0.039873414 <a title="90-tfidf-13" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>14 0.038957044 <a title="90-tfidf-14" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>15 0.038933083 <a title="90-tfidf-15" href="./emnlp-2011-Non-parametric_Bayesian_Segmentation_of_Japanese_Noun_Phrases.html">99 emnlp-2011-Non-parametric Bayesian Segmentation of Japanese Noun Phrases</a></p>
<p>16 0.03867586 <a title="90-tfidf-16" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>17 0.038366083 <a title="90-tfidf-17" href="./emnlp-2011-Analyzing_Methods_for_Improving_Precision_of_Pivot_Based_Bilingual_Dictionaries.html">18 emnlp-2011-Analyzing Methods for Improving Precision of Pivot Based Bilingual Dictionaries</a></p>
<p>18 0.037226196 <a title="90-tfidf-18" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>19 0.036307465 <a title="90-tfidf-19" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>20 0.035870764 <a title="90-tfidf-20" href="./emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">23 emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.124), (1, -0.098), (2, -0.046), (3, -0.054), (4, -0.063), (5, -0.117), (6, 0.011), (7, -0.111), (8, -0.082), (9, 0.242), (10, 0.076), (11, -0.13), (12, -0.193), (13, 0.135), (14, 0.137), (15, -0.194), (16, 0.349), (17, 0.197), (18, 0.134), (19, -0.106), (20, -0.122), (21, -0.053), (22, -0.02), (23, 0.197), (24, -0.099), (25, -0.107), (26, 0.031), (27, -0.127), (28, 0.019), (29, -0.064), (30, -0.159), (31, -0.091), (32, -0.03), (33, -0.0), (34, -0.013), (35, 0.042), (36, -0.012), (37, 0.025), (38, 0.003), (39, -0.109), (40, -0.106), (41, 0.008), (42, 0.002), (43, 0.034), (44, 0.034), (45, -0.092), (46, -0.019), (47, -0.018), (48, -0.072), (49, -0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97942513 <a title="90-lsi-1" href="./emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<p>Author: Swapna Gottipati ; Jing Jiang</p><p>Abstract: In this paper we present a novel approach to entity linking based on a statistical language model-based information retrieval with query expansion. We use both local contexts and global world knowledge to expand query language models. We place a strong emphasis on named entities in the local contexts and explore a positional language model to weigh them differently based on their distances to the query. Our experiments on the TAC-KBP 2010 data show that incorporating such contextual information indeed aids in disambiguating the named entities and consistently improves the entity linking performance. Compared with the official results from KBP 2010 participants, our system shows competitive performance.</p><p>2 0.9177227 <a title="90-lsi-2" href="./emnlp-2011-Collaborative_Ranking%3A_A_Case_Study_on_Entity_Linking.html">29 emnlp-2011-Collaborative Ranking: A Case Study on Entity Linking</a></p>
<p>Author: Zheng Chen ; Heng Ji</p><p>Abstract: In this paper, we present a new ranking scheme, collaborative ranking (CR). In contrast to traditional non-collaborative ranking scheme which solely relies on the strengths of isolated queries and one stand-alone ranking algorithm, the new scheme integrates the strengths from multiple collaborators of a query and the strengths from multiple ranking algorithms. We elaborate three specific forms of collaborative ranking, namely, micro collaborative ranking (MiCR), macro collaborative ranking (MaCR) and micro-macro collab- orative ranking (MiMaCR). Experiments on entity linking task show that our proposed scheme is indeed effective and promising.</p><p>3 0.39168605 <a title="90-lsi-3" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>Author: Ni Lao ; Tom Mitchell ; William W. Cohen</p><p>Abstract: t om . We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage. We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base. More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using a version of the Path Ranking Algorithm (Lao and Cohen, 2010b). We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010). This new system improves significantly over NELL’s earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks.</p><p>4 0.37733805 <a title="90-lsi-4" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>Author: Fabien Cromieres ; Sadao Kurohashi</p><p>Abstract: We propose an algorithm allowing to efficiently retrieve example treelets in a parsed tree database in order to allow on-the-fly extraction of syntactic translation rules. We also propose improvements of this algorithm allowing several kinds of flexible matchings.</p><p>5 0.32316691 <a title="90-lsi-5" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>Author: Johannes Hoffart ; Mohamed Amir Yosef ; Ilaria Bordino ; Hagen Furstenau ; Manfred Pinkal ; Marc Spaniol ; Bilyana Taneva ; Stefan Thater ; Gerhard Weikum</p><p>Abstract: Disambiguating named entities in naturallanguage text maps mentions of ambiguous names onto canonical entities like people or places, registered in a knowledge base such as DBpedia or YAGO. This paper presents a robust method for collective disambiguation, by harnessing context from knowledge bases and using a new form of coherence graph. It unifies prior approaches into a comprehensive framework that combines three measures: the prior probability of an entity being mentioned, the similarity between the contexts of a mention and a candidate entity, as well as the coherence among candidate entities for all mentions together. The method builds a weighted graph of mentions and candidate entities, and computes a dense subgraph that approximates the best joint mention-entity mapping. Experiments show that the new method significantly outperforms prior methods in terms of accuracy, with robust behavior across a variety of inputs.</p><p>6 0.2456287 <a title="90-lsi-6" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>7 0.22140256 <a title="90-lsi-7" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>8 0.1950184 <a title="90-lsi-8" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>9 0.18104453 <a title="90-lsi-9" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>10 0.16412456 <a title="90-lsi-10" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>11 0.15780286 <a title="90-lsi-11" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>12 0.15252465 <a title="90-lsi-12" href="./emnlp-2011-Learning_the_Information_Status_of_Noun_Phrases_in_Spoken_Dialogues.html">84 emnlp-2011-Learning the Information Status of Noun Phrases in Spoken Dialogues</a></p>
<p>13 0.1492468 <a title="90-lsi-13" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>14 0.14739789 <a title="90-lsi-14" href="./emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">23 emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p>15 0.14713536 <a title="90-lsi-15" href="./emnlp-2011-Analyzing_Methods_for_Improving_Precision_of_Pivot_Based_Bilingual_Dictionaries.html">18 emnlp-2011-Analyzing Methods for Improving Precision of Pivot Based Bilingual Dictionaries</a></p>
<p>16 0.14612645 <a title="90-lsi-16" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>17 0.13649416 <a title="90-lsi-17" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>18 0.12634885 <a title="90-lsi-18" href="./emnlp-2011-Enhancing_Chinese_Word_Segmentation_Using_Unlabeled_Data.html">48 emnlp-2011-Enhancing Chinese Word Segmentation Using Unlabeled Data</a></p>
<p>19 0.12433616 <a title="90-lsi-19" href="./emnlp-2011-Improving_Bilingual_Projections_via_Sparse_Covariance_Matrices.html">73 emnlp-2011-Improving Bilingual Projections via Sparse Covariance Matrices</a></p>
<p>20 0.12185169 <a title="90-lsi-20" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.089), (36, 0.028), (37, 0.015), (45, 0.521), (53, 0.015), (54, 0.023), (62, 0.019), (64, 0.012), (66, 0.023), (69, 0.021), (79, 0.029), (82, 0.011), (87, 0.012), (96, 0.019), (98, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98784077 <a title="90-lda-1" href="./emnlp-2011-Bayesian_Checking_for_Topic_Models.html">21 emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>Author: David Mimno ; David Blei</p><p>Abstract: Real document collections do not fit the independence assumptions asserted by most statistical topic models, but how badly do they violate them? We present a Bayesian method for measuring how well a topic model fits a corpus. Our approach is based on posterior predictive checking, a method for diagnosing Bayesian models in user-defined ways. Our method can identify where a topic model fits the data, where it falls short, and in which directions it might be improved.</p><p>2 0.98332793 <a title="90-lda-2" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>Author: Dipak L. Chaudhari ; Om P. Damani ; Srivatsan Laxman</p><p>Abstract: Om P. Damani Srivatsan Laxman Computer Science and Engg. Microsoft Research India IIT Bombay Bangalore damani @ cse . i . ac . in itb s laxman@mi cro s o ft . com of words that co-occur in a large number of docuLexical co-occurrence is an important cue for detecting word associations. We propose a new measure of word association based on a new notion of statistical significance for lexical co-occurrences. Existing measures typically rely on global unigram frequencies to determine expected co-occurrence counts. In- stead, we focus only on documents that contain both terms (of a candidate word-pair) and ask if the distribution of the observed spans of the word-pair resembles that under a random null model. This would imply that the words in the pair are not related strongly enough for one word to influence placement of the other. However, if the words are found to occur closer together than explainable by the null model, then we hypothesize a more direct association between the words. Through extensive empirical evaluation on most of the publicly available benchmark data sets, we show the advantages of our measure over existing co-occurrence measures.</p><p>3 0.96621716 <a title="90-lda-3" href="./emnlp-2011-Approximate_Scalable_Bounded_Space_Sketch_for_Large_Data_NLP.html">19 emnlp-2011-Approximate Scalable Bounded Space Sketch for Large Data NLP</a></p>
<p>Author: Amit Goyal ; Hal Daume III</p><p>Abstract: We exploit sketch techniques, especially the Count-Min sketch, a memory, and time efficient framework which approximates the frequency of a word pair in the corpus without explicitly storing the word pair itself. These methods use hashing to deal with massive amounts of streaming text. We apply CountMin sketch to approximate word pair counts and exhibit their effectiveness on three important NLP tasks. Our experiments demonstrate that on all of the three tasks, we get performance comparable to Exact word pair counts setting and state-of-the-art system. Our method scales to 49 GB of unzipped web data using bounded space of 2 billion counters (8 GB memory).</p><p>same-paper 4 0.93490487 <a title="90-lda-4" href="./emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<p>Author: Swapna Gottipati ; Jing Jiang</p><p>Abstract: In this paper we present a novel approach to entity linking based on a statistical language model-based information retrieval with query expansion. We use both local contexts and global world knowledge to expand query language models. We place a strong emphasis on named entities in the local contexts and explore a positional language model to weigh them differently based on their distances to the query. Our experiments on the TAC-KBP 2010 data show that incorporating such contextual information indeed aids in disambiguating the named entities and consistently improves the entity linking performance. Compared with the official results from KBP 2010 participants, our system shows competitive performance.</p><p>5 0.89184266 <a title="90-lda-5" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>Author: Emily M. Bender ; Dan Flickinger ; Stephan Oepen ; Yi Zhang</p><p>Abstract: In order to obtain a fine-grained evaluation of parser accuracy over naturally occurring text, we study 100 examples each of ten reasonably frequent linguistic phenomena, randomly selected from a parsed version of the English Wikipedia. We construct a corresponding set of gold-standard target dependencies for these 1000 sentences, operationalize mappings to these targets from seven state-of-theart parsers, and evaluate the parsers against this data to measure their level of success in identifying these dependencies.</p><p>6 0.78581238 <a title="90-lda-6" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>7 0.7396906 <a title="90-lda-7" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>8 0.73734969 <a title="90-lda-8" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>9 0.72134072 <a title="90-lda-9" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>10 0.69213355 <a title="90-lda-10" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>11 0.69086909 <a title="90-lda-11" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>12 0.67574799 <a title="90-lda-12" href="./emnlp-2011-Improving_Bilingual_Projections_via_Sparse_Covariance_Matrices.html">73 emnlp-2011-Improving Bilingual Projections via Sparse Covariance Matrices</a></p>
<p>13 0.67069048 <a title="90-lda-13" href="./emnlp-2011-Exploiting_Syntactic_and_Distributional_Information_for_Spelling_Correction_with_Web-Scale_N-gram_Models.html">55 emnlp-2011-Exploiting Syntactic and Distributional Information for Spelling Correction with Web-Scale N-gram Models</a></p>
<p>14 0.63321805 <a title="90-lda-14" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>15 0.62869787 <a title="90-lda-15" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>16 0.61782479 <a title="90-lda-16" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>17 0.61457998 <a title="90-lda-17" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>18 0.61325765 <a title="90-lda-18" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>19 0.60950094 <a title="90-lda-19" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>20 0.60413402 <a title="90-lda-20" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
