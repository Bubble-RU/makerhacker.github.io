<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>60 emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-60" href="#">emnlp2011-60</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>60 emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</h1>
<br/><p>Source: <a title="emnlp-2011-60-pdf" href="http://aclweb.org/anthology//D/D11/D11-1046.pdf">pdf</a></p><p>Author: Jason Riesa ; Ann Irvine ; Daniel Marcu</p><p>Abstract: unkown-abstract</p><p>Reference: <a title="emnlp-2011-60-reference" href="../emnlp2011_reference/emnlp-2011-Feature-Rich_Language-Independent_Syntax-Based_Alignment_for_Statistical_Machine_Translation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('np', 0.363), ('chpinap', 0.318), ('lcp', 0.318), ('lpc', 0.318), ('ossnforpej', 0.318), ('tgrnaden', 0.318), ('innp', 0.274), ('epoch', 0.23), ('yi', 0.23), ('pp', 0.208), ('xi', 0.16), ('jj', 0.155), ('gy', 0.137), ('ayr', 0.115), ('nn', 0.106), ('lc', 0.102), ('rp', 0.089), ('cr', 0.089), ('ur', 0.069), ('tn', 0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="60-tfidf-1" href="./emnlp-2011-Feature-Rich_Language-Independent_Syntax-Based_Alignment_for_Statistical_Machine_Translation.html">60 emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</a></p>
<p>Author: Jason Riesa ; Ann Irvine ; Daniel Marcu</p><p>Abstract: unkown-abstract</p><p>2 0.11167724 <a title="60-tfidf-2" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras</p><p>Abstract: Attempts to profile authors according to their characteristics extracted from textual data, including native language, have drawn attention in recent years, via various machine learning approaches utilising mostly lexical features. Drawing on the idea of contrastive analysis, which postulates that syntactic errors in a text are to some extent influenced by the native language of an author, this paper explores the usefulness of syntactic features for native language identification. We take two types of parse substructure as features— horizontal slices of trees, and the more general feature schemas from discriminative parse reranking—and show that using this kind of syntactic feature results in an accuracy score in classification of seven native languages of around 80%, an error reduction of more than 30%.</p><p>3 0.10609993 <a title="60-tfidf-3" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>Author: Amit Dubey ; Frank Keller ; Patrick Sturt</p><p>Abstract: This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chunker with a co-reference classifier. Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure. This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort. We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.</p><p>4 0.078124598 <a title="60-tfidf-4" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>Author: Juri Ganitkevitch ; Chris Callison-Burch ; Courtney Napoles ; Benjamin Van Durme</p><p>Abstract: Previous work has shown that high quality phrasal paraphrases can be extracted from bilingual parallel corpora. However, it is not clear whether bitexts are an appropriate resource for extracting more sophisticated sentential paraphrases, which are more obviously learnable from monolingual parallel corpora. We extend bilingual paraphrase extraction to syntactic paraphrases and demonstrate its ability to learn a variety of general paraphrastic transformations, including passivization, dative shift, and topicalization. We discuss how our model can be adapted to many text generation tasks by augmenting its feature set, development data, and parameter estimation routine. We illustrate this adaptation by using our paraphrase model for the task of sentence compression and achieve results competitive with state-of-the-art compression systems.</p><p>5 0.078096643 <a title="60-tfidf-5" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>Author: Jiajun Zhang ; Feifei Zhai ; Chengqing Zong</p><p>Abstract: Due to its explicit modeling of the grammaticality of the output via target-side syntax, the string-to-tree model has been shown to be one of the most successful syntax-based translation models. However, a major limitation of this model is that it does not utilize any useful syntactic information on the source side. In this paper, we analyze the difficulties of incorporating source syntax in a string-totree model. We then propose a new way to use the source syntax in a fuzzy manner, both in source syntactic annotation and in rule matching. We further explore three algorithms in rule matching: 0-1 matching, likelihood matching, and deep similarity matching. Our method not only guarantees grammatical output with an explicit target tree, but also enables the system to choose the proper translation rules via fuzzy use of the source syntax. Our extensive experiments have shown significant improvements over the state-of-the-art string-to-tree system. 1</p><p>6 0.073704667 <a title="60-tfidf-6" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>7 0.063887611 <a title="60-tfidf-7" href="./emnlp-2011-Minimum_Imputed-Risk%3A_Unsupervised_Discriminative_Training_for_Machine_Translation.html">93 emnlp-2011-Minimum Imputed-Risk: Unsupervised Discriminative Training for Machine Translation</a></p>
<p>8 0.056820534 <a title="60-tfidf-8" href="./emnlp-2011-Learning_the_Information_Status_of_Noun_Phrases_in_Spoken_Dialogues.html">84 emnlp-2011-Learning the Information Status of Noun Phrases in Spoken Dialogues</a></p>
<p>9 0.048093226 <a title="60-tfidf-9" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>10 0.035048559 <a title="60-tfidf-10" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>11 0.034521017 <a title="60-tfidf-11" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>12 0.030967832 <a title="60-tfidf-12" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<p>13 0.027537186 <a title="60-tfidf-13" href="./emnlp-2011-Exact_Inference_for_Generative_Probabilistic_Non-Projective_Dependency_Parsing.html">52 emnlp-2011-Exact Inference for Generative Probabilistic Non-Projective Dependency Parsing</a></p>
<p>14 0.025767863 <a title="60-tfidf-14" href="./emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">127 emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<p>15 0.024416242 <a title="60-tfidf-15" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>16 0.022331066 <a title="60-tfidf-16" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>17 0.019514518 <a title="60-tfidf-17" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>18 0.018644124 <a title="60-tfidf-18" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>19 0.018403316 <a title="60-tfidf-19" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>20 0.01835213 <a title="60-tfidf-20" href="./emnlp-2011-Universal_Morphological_Analysis_using_Structured_Nearest_Neighbor_Prediction.html">140 emnlp-2011-Universal Morphological Analysis using Structured Nearest Neighbor Prediction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.059), (1, 0.013), (2, -0.012), (3, -0.031), (4, -0.006), (5, 0.019), (6, -0.075), (7, -0.09), (8, 0.046), (9, -0.041), (10, -0.047), (11, 0.025), (12, 0.05), (13, 0.032), (14, 0.011), (15, 0.048), (16, -0.112), (17, 0.007), (18, -0.09), (19, 0.034), (20, -0.122), (21, 0.059), (22, 0.215), (23, 0.013), (24, 0.273), (25, -0.124), (26, -0.117), (27, -0.228), (28, 0.112), (29, 0.158), (30, 0.113), (31, -0.259), (32, 0.011), (33, 0.041), (34, 0.147), (35, -0.041), (36, -0.06), (37, 0.118), (38, -0.08), (39, 0.144), (40, -0.066), (41, 0.116), (42, -0.063), (43, 0.085), (44, 0.019), (45, -0.129), (46, -0.074), (47, -0.067), (48, 0.129), (49, -0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99518347 <a title="60-lsi-1" href="./emnlp-2011-Feature-Rich_Language-Independent_Syntax-Based_Alignment_for_Statistical_Machine_Translation.html">60 emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</a></p>
<p>Author: Jason Riesa ; Ann Irvine ; Daniel Marcu</p><p>Abstract: unkown-abstract</p><p>2 0.40099517 <a title="60-lsi-2" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>Author: Sze-Meng Jojo Wong ; Mark Dras</p><p>Abstract: Attempts to profile authors according to their characteristics extracted from textual data, including native language, have drawn attention in recent years, via various machine learning approaches utilising mostly lexical features. Drawing on the idea of contrastive analysis, which postulates that syntactic errors in a text are to some extent influenced by the native language of an author, this paper explores the usefulness of syntactic features for native language identification. We take two types of parse substructure as features— horizontal slices of trees, and the more general feature schemas from discriminative parse reranking—and show that using this kind of syntactic feature results in an accuracy score in classification of seven native languages of around 80%, an error reduction of more than 30%.</p><p>3 0.37246451 <a title="60-lsi-3" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>Author: Amit Dubey ; Frank Keller ; Patrick Sturt</p><p>Abstract: This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chunker with a co-reference classifier. Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure. This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort. We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.</p><p>4 0.3273589 <a title="60-lsi-4" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>Author: Jiajun Zhang ; Feifei Zhai ; Chengqing Zong</p><p>Abstract: Due to its explicit modeling of the grammaticality of the output via target-side syntax, the string-to-tree model has been shown to be one of the most successful syntax-based translation models. However, a major limitation of this model is that it does not utilize any useful syntactic information on the source side. In this paper, we analyze the difficulties of incorporating source syntax in a string-totree model. We then propose a new way to use the source syntax in a fuzzy manner, both in source syntactic annotation and in rule matching. We further explore three algorithms in rule matching: 0-1 matching, likelihood matching, and deep similarity matching. Our method not only guarantees grammatical output with an explicit target tree, but also enables the system to choose the proper translation rules via fuzzy use of the source syntax. Our extensive experiments have shown significant improvements over the state-of-the-art string-to-tree system. 1</p><p>5 0.32484758 <a title="60-lsi-5" href="./emnlp-2011-Minimum_Imputed-Risk%3A_Unsupervised_Discriminative_Training_for_Machine_Translation.html">93 emnlp-2011-Minimum Imputed-Risk: Unsupervised Discriminative Training for Machine Translation</a></p>
<p>Author: Zhifei Li ; Ziyuan Wang ; Jason Eisner ; Sanjeev Khudanpur ; Brian Roark</p><p>Abstract: Discriminative training for machine translation has been well studied in the recent past. A limitation of the work to date is that it relies on the availability of high-quality in-domain bilingual text for supervised training. We present an unsupervised discriminative training framework to incorporate the usually plentiful target-language monolingual data by using a rough “reverse” translation system. Intuitively, our method strives to ensure that probabilistic “round-trip” translation from a target- language sentence to the source-language and back will have low expected loss. Theoretically, this may be justified as (discriminatively) minimizing an imputed empirical risk. Empirically, we demonstrate that augmenting supervised training with unsupervised data improves translation performance over the supervised case for both IWSLT and NIST tasks.</p><p>6 0.31315735 <a title="60-lsi-6" href="./emnlp-2011-Learning_the_Information_Status_of_Noun_Phrases_in_Spoken_Dialogues.html">84 emnlp-2011-Learning the Information Status of Noun Phrases in Spoken Dialogues</a></p>
<p>7 0.27957079 <a title="60-lsi-7" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>8 0.18197604 <a title="60-lsi-8" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>9 0.14910643 <a title="60-lsi-9" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>10 0.13245614 <a title="60-lsi-10" href="./emnlp-2011-Predicting_a_Scientific_Communitys_Response_to_an_Article.html">106 emnlp-2011-Predicting a Scientific Communitys Response to an Article</a></p>
<p>11 0.1274697 <a title="60-lsi-11" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>12 0.12502982 <a title="60-lsi-12" href="./emnlp-2011-Exact_Inference_for_Generative_Probabilistic_Non-Projective_Dependency_Parsing.html">52 emnlp-2011-Exact Inference for Generative Probabilistic Non-Projective Dependency Parsing</a></p>
<p>13 0.12191447 <a title="60-lsi-13" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>14 0.11690172 <a title="60-lsi-14" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>15 0.11489591 <a title="60-lsi-15" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>16 0.11060587 <a title="60-lsi-16" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>17 0.093748674 <a title="60-lsi-17" href="./emnlp-2011-Universal_Morphological_Analysis_using_Structured_Nearest_Neighbor_Prediction.html">140 emnlp-2011-Universal Morphological Analysis using Structured Nearest Neighbor Prediction</a></p>
<p>18 0.084477298 <a title="60-lsi-18" href="./emnlp-2011-A_Generate_and_Rank_Approach_to_Sentence_Paraphrasing.html">6 emnlp-2011-A Generate and Rank Approach to Sentence Paraphrasing</a></p>
<p>19 0.084247328 <a title="60-lsi-19" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<p>20 0.083276957 <a title="60-lsi-20" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.738), (27, 0.011), (50, 0.041), (68, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76084381 <a title="60-lda-1" href="./emnlp-2011-Feature-Rich_Language-Independent_Syntax-Based_Alignment_for_Statistical_Machine_Translation.html">60 emnlp-2011-Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</a></p>
<p>Author: Jason Riesa ; Ann Irvine ; Daniel Marcu</p><p>Abstract: unkown-abstract</p><p>2 0.065387376 <a title="60-lda-2" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>Author: Zornitsa Kozareva ; Konstantin Voevodski ; Shanghua Teng</p><p>Abstract: Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels. Yet, nobody has explored the relationships between the instances themselves to enhance an initial set of class-instance pairs. We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network. We carry out a comparative study with state-of-the-art knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy.</p><p>3 0.061010174 <a title="60-lda-3" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>Author: Jiajun Zhang ; Feifei Zhai ; Chengqing Zong</p><p>Abstract: Due to its explicit modeling of the grammaticality of the output via target-side syntax, the string-to-tree model has been shown to be one of the most successful syntax-based translation models. However, a major limitation of this model is that it does not utilize any useful syntactic information on the source side. In this paper, we analyze the difficulties of incorporating source syntax in a string-totree model. We then propose a new way to use the source syntax in a fuzzy manner, both in source syntactic annotation and in rule matching. We further explore three algorithms in rule matching: 0-1 matching, likelihood matching, and deep similarity matching. Our method not only guarantees grammatical output with an explicit target tree, but also enables the system to choose the proper translation rules via fuzzy use of the source syntax. Our extensive experiments have shown significant improvements over the state-of-the-art string-to-tree system. 1</p><p>4 0.060769398 <a title="60-lda-4" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>Author: Benjamin Borschinger ; Bevan K. Jones ; Mark Johnson</p><p>Abstract: It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.1</p><p>5 0.053321037 <a title="60-lda-5" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>Author: Ziqi Zhang ; Anna Lisa Gentile ; Fabio Ciravegna</p><p>Abstract: Measuring semantic relatedness between words or concepts is a crucial process to many Natural Language Processing tasks. Exiting methods exploit semantic evidence from a single knowledge source, and are predominantly evaluated only in the general domain. This paper introduces a method of harnessing different knowledge sources under a uniform model for measuring semantic relatedness between words or concepts. Using Wikipedia and WordNet as examples, and evaluated in both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets.</p><p>6 0.049744882 <a title="60-lda-6" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>7 0.049342826 <a title="60-lda-7" href="./emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">15 emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>8 0.048677385 <a title="60-lda-8" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>9 0.046952114 <a title="60-lda-9" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>10 0.046598431 <a title="60-lda-10" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>11 0.046494558 <a title="60-lda-11" href="./emnlp-2011-Domain-Assisted_Product_Aspect_Hierarchy_Generation%3A_Towards_Hierarchical_Organization_of_Unstructured_Consumer_Reviews.html">43 emnlp-2011-Domain-Assisted Product Aspect Hierarchy Generation: Towards Hierarchical Organization of Unstructured Consumer Reviews</a></p>
<p>12 0.04590524 <a title="60-lda-12" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>13 0.045896903 <a title="60-lda-13" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>14 0.045817189 <a title="60-lda-14" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<p>15 0.045784373 <a title="60-lda-15" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>16 0.045777488 <a title="60-lda-16" href="./emnlp-2011-Enhancing_Chinese_Word_Segmentation_Using_Unlabeled_Data.html">48 emnlp-2011-Enhancing Chinese Word Segmentation Using Unlabeled Data</a></p>
<p>17 0.045661274 <a title="60-lda-17" href="./emnlp-2011-Inducing_Sentence_Structure_from_Parallel_Corpora_for_Reordering.html">74 emnlp-2011-Inducing Sentence Structure from Parallel Corpora for Reordering</a></p>
<p>18 0.045571212 <a title="60-lda-18" href="./emnlp-2011-Computation_of_Infix_Probabilities_for_Probabilistic_Context-Free_Grammars.html">31 emnlp-2011-Computation of Infix Probabilities for Probabilistic Context-Free Grammars</a></p>
<p>19 0.045368537 <a title="60-lda-19" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>20 0.045354381 <a title="60-lda-20" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
