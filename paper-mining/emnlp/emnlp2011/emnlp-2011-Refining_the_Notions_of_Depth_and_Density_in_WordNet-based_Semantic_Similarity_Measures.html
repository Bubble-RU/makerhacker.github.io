<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-112" href="#">emnlp2011-112</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</h1>
<br/><p>Source: <a title="emnlp-2011-112-pdf" href="http://aclweb.org/anthology//D/D11/D11-1093.pdf">pdf</a></p><p>Author: Tong Wang ; Graeme Hirst</p><p>Abstract: We re-investigate the rationale for and the effectiveness of adopting the notions of depth and density in WordNet-based semantic similarity measures. We show that the intuition for including these notions in WordNet-based similarity measures does not always stand up to empirical examination. In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure. We thus propose several novel definitions of depth and density, which yield significant improvement in degree of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment.</p><p>Reference: <a title="emnlp-2011-112-reference" href="../emnlp2011_reference/emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract We re-investigate the rationale for and the effectiveness of adopting the notions of depth and density in WordNet-based semantic similarity measures. [sent-3, score-1.511]
</p><p>2 We show that the intuition for including these notions in WordNet-based similarity measures does not always stand up to empirical examination. [sent-4, score-0.276]
</p><p>3 In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure. [sent-5, score-1.677]
</p><p>4 We thus propose several novel definitions of depth and density, which yield significant improvement in degree of correlation with similarity. [sent-6, score-0.796]
</p><p>5 When used in WordNet-based  semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment. [sent-7, score-0.359]
</p><p>6 1 Introduction Semantic similarity measures are widely used in natural language processing for measuring distance between meanings of words. [sent-8, score-0.213]
</p><p>7 With the existing literature focusing on carefully weighting these features to construct a better seman-  tic similarity measure, however, the rationale for adopting these features in calculating semantic similarity remains largely intuitive. [sent-26, score-0.445]
</p><p>8 To the best of our knowledge, there is no empirical study directly investigating the effectiveness of adopting structural features such as depth and density. [sent-27, score-0.585]
</p><p>9 In Section 2 we review the basic rationale for adopting depth Proce dEindgisnb oufr tgh e, 2 S0c1o1tl Canodn,f eUrKen,c Jeuol yn 2 E7m–3p1ir,ic 2a0l1 M1. [sent-30, score-0.634]
</p><p>10 tc ho2d0s1 in A Nsasotucira tlio Lnan fogru Cagoem Ppruotcaetisosninagl, L pinag uesis 1ti0c0s3–101 , and density in WordNet-based similarity measures as well as existing literature on constructing such measures. [sent-32, score-0.827]
</p><p>11 In Section 3, we show the limitations of the current definitions ofdepth and density as well as possible explanations for these limitations. [sent-33, score-0.761]
</p><p>12 The effectiveness of the new definitions is evaluated by applying them in semantic similarity measures in Section 5 and conclusions made in Section 6. [sent-35, score-0.374]
</p><p>13 2  Related Work  The following are the current definitions of depth  and density which we aim at improving. [sent-36, score-1.288]
</p><p>14 Given a node/concept c in WordNet, depth refers to the number of nodes between c and the root of WordNet, (i. [sent-37, score-0.612]
</p><p>15 , the root has depth zero, its hyponyms depth one, and so on). [sent-39, score-1.102]
</p><p>16 This is the working assumption for virtually all WordNet-based semantic similarity studies using depth and/or density. [sent-48, score-0.751]
</p><p>17 Sussna (1993) termed the use of depth as depth-relative scaling, claiming that “only-siblings deep in a tree are more closely related than onlysiblings higher in the tree”. [sent-50, score-0.551]
</p><p>18 Richardson and Smeaton (1995) gave an hypothetical example illustrating this “only-siblings” situation, where plant–animal 1Since the works we review in this section have different definitions of depth and density, we defer our formal definitions to Section 3. [sent-51, score-0.797]
</p><p>19 As for the relation between density and similarity, the intuition is that if the overall semantic mass for a given node is constant (Jiang and Conrath, 1997), then the more neighboring nodes there are in a locally connected subnetwork, the closer its members are to each other. [sent-54, score-0.811]
</p><p>20 For example, animal, person, and plant are more strongly connected with life form than aerobe andplankton because the first three words all have high density in their local network structures (Richardson and Smeaton, 1995). [sent-55, score-0.666]
</p><p>21 Note  that the notion of density here is not to be confused with the conceptual density used by Agirre and Rigau (1996), which is essentially a semantic similarity measure by itself. [sent-56, score-1.458]
</p><p>22 In general, both observations on depth and density conform to intuition and are supported qualitatively by several existing studies. [sent-57, score-1.189]
</p><p>23 2  Semantic Similarity Measures Using Depth and/or Density One of the first examples of using depth and density in WordNet-based similarity measures is that of Sussna (1993). [sent-60, score-1.378]
</p><p>24 The weight on an edge between two nodes c1 and c2 with relation r in WordNet is given as:  w(c1,c2) =w(c1→rc2)2+dw(c2→rc1) where d is the depth of the deeper of the two nodes. [sent-61, score-0.637]
</p><p>25 As depth increases, weight decreases and similarity in turn increases, conforming to Assumption 1. [sent-62, score-0.713]
</p><p>26 Note that this formulation of density contradicts Assumption 1 since it is proportional to edge weight (left-handside) and thus negatively correlated to similarity. [sent-64, score-0.614]
</p><p>27 Wu and Palmer (1994) proposed a concept similarity measure between two concepts c1 and c2 as:  sim(c1,c2) =len(c1,c)+l2e·nd(ce2p,(cc))+2·dep(c) (1) where c is the lowest common subsumer (LCS) of c1 and c2, and len(·, ·) is the number of edges between two no,d aensd. [sent-65, score-0.217]
</p><p>28 eTnh(e· r·a)t i son thalee n uism to adjust “hop ectowuenet”n (the first two terms in the denominator) with the depth of LCS: similarity between nodes with samelevel LCS is in negative proportion to hop counts, while given the same hop count, a “deeper” LCS pulls the similarity score closer to 1. [sent-66, score-1.087]
</p><p>29 3  Limitations on the Current Definitions of Depth and Density  To what extent do the notions of depth and density help towards an accurate semantic similarity measure? [sent-69, score-1.428]
</p><p>30 A direct assessment of the effectiveness of using depth and density is to examine their correlation with similarity. [sent-71, score-1.287]
</p><p>31 Empirical results in this section 1005  Figure 1: Correlation between depth and similarity. [sent-72, score-0.551]
</p><p>32 Depth is defined as the number of edges between the  root of the hierarchy and the lowest common subsumer (LCS) of two nodes under comparison, and density as the number of siblings of the LCS. [sent-74, score-0.736]
</p><p>33 2 Similarity is measured by human judgment on similarity between word pairs. [sent-75, score-0.231]
</p><p>34 RG is a collection of similarity ratings of 65 word pairs averaged over judgments from 51 human subjects on a scale of 0 to 4 (from least to most similar). [sent-78, score-0.222]
</p><p>35 These pairs were chosen to have evenly distributed similarity ratings in the original data set, and similarity judgment was elicited from 38 human judges with the same instruction as used for RG. [sent-80, score-0.453]
</p><p>36 , using the maximum or minimum depth of the two nodes instead of the LCS. [sent-87, score-0.612]
</p><p>37 Figure 2: Histogram of depth of WordNet noun synsets. [sent-89, score-0.551]
</p><p>38 1  Depth  The distribution of similarity of the combined data set over depth is plotted in Figure 1. [sent-91, score-0.713]
</p><p>39 For depth values under 5, similarity scores are fairly evenly dis-  tributed over depth, showing no statistical significance in correlation. [sent-92, score-0.791]
</p><p>40 There are many more data points with lower depth values than with higher depth values in the combined data set. [sent-96, score-1.16]
</p><p>41 In order to have a fair comparison of statistical significance tests on the two value ranges for depth, we randomly sample an equal number (100) of data points from each value range, and the correlation coefficient between depth and similarity is averaged over 100 of such samplings. [sent-97, score-0.959]
</p><p>42 Correlation coefficients for depth value under 5 versus 5 and above are ρ = 0. [sent-98, score-0.603]
</p><p>43 2 Density Comparing to depth, density exhibits much lower correlation with similarity (Figure 3-a and 3-b). [sent-109, score-0.898]
</p><p>44 We conducted correlation experiments between density and similarity with the same setting as for depth and similarity above. [sent-110, score-1.611]
</p><p>45 Data points with extremely high density values (up to over 400) are mostly idiosyncratic to the densely connected regions in WordNet and are numerically quite harmful. [sent-111, score-0.775]
</p><p>46 We thus excluded outliers with density values above 100 in the experiment. [sent-112, score-0.665]
</p><p>47 Evaluation on the combined data set shows no  correlation between density and similarity. [sent-113, score-0.736]
</p><p>48 The correlation coefficient between density and similarity ranges from 0. [sent-115, score-0.945]
</p><p>49 Data analysis suggests that density values are often biased by particular fine-grainedness of local structures in WordNet. [sent-119, score-0.643]
</p><p>50 Empirically, on the one hand, more than 90% of WordNet nodes have density values less than or equal to 3. [sent-121, score-0.704]
</p><p>51 This means that for 90% of the LCS’s, there are only three integer values for density to distinguish the varying degrees of similarity. [sent-122, score-0.643]
</p><p>52 On the other hand, there are outliers with extreme density values particular to the perhaps overly fine-grained subcat-  egorization of some WordNet concepts, and these nodes can be LCS’s of word pairs of drastically different similarity. [sent-124, score-0.726]
</p><p>53 The node person, individual, for example, can be the LCS of similar pairs such as man–woman, as well as quite dissimilar ones such as boy–sage, where the large density value does not necessarily indicate high degree of similarity. [sent-125, score-0.679]
</p><p>54 Another crucial limitation of the definition of density is the information loss on specificity. [sent-126, score-0.655]
</p><p>55 In the existing literature, density is often adopted as a proxy for the degree of specificity of a concept, i. [sent-127, score-0.687]
</p><p>56 For example, the node piano has a density value of 15 under the node percussion instrument. [sent-131, score-0.903]
</p><p>57 However, the density value of its hyponyms Grand piano, upright piano, and mechanical piano, is only 3. [sent-132, score-0.685]
</p><p>58 4  New Definitions of Depth and Density  In this section, we formalize new definitions of depth and density to correct for their current limiMCRGFG depu0. [sent-134, score-1.288]
</p><p>59 1 Depth The major problem with the current definition of depth is its failure to take into account the uneven distribution ofnumber ofnodes over the depth value. [sent-146, score-1.123]
</p><p>60 As seen in previous examples, the distribution is rather “flat” on both ends of depth value, which does not preserve the linearity of using the ordinal values of depth and thus introduces much inaccuracy. [sent-147, score-1.233]
</p><p>61 To avoid this problem, we “re-curve” depth value to the cumulative distribution. [sent-148, score-0.648]
</p><p>62 Specifically, if we  take the histogram distribution of depth value in Figure 2 as a probability density function, our approach is to project cardinal depth values onto its cumulative distribution function. [sent-149, score-1.881]
</p><p>63 The new depth is denoted depu and is defined as:  depu(c) =∑c0∈WN|{c0: d|WepN(c|0) ≤ dep(c)}| Here, dep(·) is the original depth value, and WN is tHheer set oefp a(·ll) n isod thees oinr iWgionradlN deept. [sent-150, score-1.21]
</p><p>64 Thh vea resulting depth values not only reflect the flat ends, but also preserve linearity for the depth value range in the middle. [sent-151, score-1.2]
</p><p>65 In comparison with Table 1), correlation between depu and similarity increases over the original depth values on two of the three data sets (first row in Table 2 and decreases on the RG set. [sent-152, score-0.972]
</p><p>66 However, due to the Zip-  fian nature of density’s histogram distribution (Figure 4, in contrast to Gaussian for depth in Figure 2), this is essentially to collapse most density values 1008  Figure 4: Histogram of density in WordNet. [sent-158, score-1.847]
</p><p>67 into a very small number of discrete values (which correspond to the original density of 1 to 3). [sent-159, score-0.643]
</p><p>68 Experiments show that it does not help in improving correlation with similarity scores (second row in Table 2 for denu): correlation remains the same on MC and RG, and decreases slightly on FG. [sent-160, score-0.406]
</p><p>69 Intuitively, the idea is to ensure that a node be assigned no less density mass than its parent node(s). [sent-162, score-0.685]
</p><p>70 2), the concept piano is highly specific due to its large number of siblings under the parent node percussion instruments. [sent-164, score-0.255]
</p><p>71 Consequently, the density of its child nodes upright piano and grand piano should inherit its specificity on top of their own. [sent-165, score-1.147]
</p><p>72 Formally, we redefine density recursively as follows: deni(r) = 0  deni(c) =∑h∈h|yhypepre(c)r(dce)n|i(h)+den(c) where r is the root of WordNet hierarchy (with no hypernym), and hyper(·) is the set ofhypernyms of a given concept. [sent-166, score-0.648]
</p><p>73 The resulting density values correlate significantly better with similarity. [sent-168, score-0.679]
</p><p>74 5  Using the New Definitions in Semantic Similarity Measures  In this section, we test the effectiveness of the new definitions of depth and density by using them in WordNet-based semantic similarity measures. [sent-170, score-1.488]
</p><p>75 The first one used depth only, and the second one used both depth and density. [sent-172, score-1.102]
</p><p>76 The task is to correlate the similarity measures with human judgment on similarity between word pairs. [sent-173, score-0.48]
</p><p>77 Note that there are other WordNet-based similarity measures using depth and/or density that we opt to omit for various reasons. [sent-181, score-1.378]
</p><p>78 Others use depth of the entire WordNet hierarchy instead of individual nodes as a scaling factor (e. [sent-185, score-0.646]
</p><p>79 , that of Leacock and Chodorow, 1998), which is unsuitable for illustrating the improvement brought about by the new depth and density definitions. [sent-187, score-1.165]
</p><p>80 Parameterization of the weighting of depth and density is a common practice to control their individual contribution to the final similarity score (e. [sent-188, score-1.327]
</p><p>81 3787 Table 3: Correlation between human judgment and similarity score by Wu and Palmer (1994) using two versions of depth. [sent-204, score-0.231]
</p><p>82 3715 Table 4: Correlation between human judgment and similarity score by Jiang and Conrath (1997) using different definitions of depth and density. [sent-229, score-0.905]
</p><p>83 der to parameterize depth used by Wu and Palmer in their similarity measure, we also modify Equation (1) as follows:  sim(c1,c2) =len(c1,c)+2le·nd(ce2p,αc()c)+2·depα(c) where depth is raised to the power of α to vary its contribution to the similarity score. [sent-230, score-1.426]
</p><p>84 In both models, the cumulative definition of depth depu consistently improve the performance of the similarity measures. [sent-237, score-0.914]
</p><p>85 In the Jiang and Conrath (1997) model, where density is applicable, the inheritance-based definition of density deni also results in better correlation with human judgments. [sent-238, score-1.479]
</p><p>86 The optimal result is achieved when combining the new definitions of  depth and density (row 4 in Table 4). [sent-239, score-1.288]
</p><p>87 For average performance, the improvement of all the new definitions over the original definitions is statistically significant on all three data sets according to paired t-test. [sent-240, score-0.246]
</p><p>88 6  Conclusions  This study explored effective uses of depth and/or density in WordNet-based similarity measures. [sent-241, score-1.327]
</p><p>89 This direct comparison showed that depth correlates with similarity only on certain value ranges, while density does not correlate with human judgment at all. [sent-243, score-1.478]
</p><p>90 Further investigation revealed that the problem for depth lies in the simplistic representation as its ordinal integer values. [sent-244, score-0.582]
</p><p>91 The linearity in this representation fails to take into account the conflated quantity of depth in the two extreme ends of the depth spectrum. [sent-245, score-1.173]
</p><p>92 For density, a prominent issue is the information loss on specificity of WordNet concepts, which gives an inaccurate density value that is biased by the idiosyncratic constructions in densely connected  regions in the hierarchy. [sent-246, score-0.864]
</p><p>93 We then proposed new definitions of depth and density to address these issues. [sent-247, score-1.288]
</p><p>94 For depth, linearity in different value ranges is realistically reflected by projecting the depth value to its cumulative distribution function. [sent-248, score-0.744]
</p><p>95 The loss of specificity information in density, on the other hand, is corrected by allowing concepts to inherit specificity information from their parent nodes. [sent-249, score-0.256]
</p><p>96 The new definitions show significant improvement in correlation of semantic similarity given by human judges. [sent-250, score-0.445]
</p><p>97 In addition, when used in existing WordNet-based similarity measures, they consistently improve performance and numerical stability of the parameterization of the two features. [sent-251, score-0.215]
</p><p>98 The notions of depth and density pertain to any hierarchical structure like WordNet, which suggests various extensions of this work. [sent-252, score-1.228]
</p><p>99 A natural next step of the current work is to apply the same idea to semantic taxonomies in languages other than English with available similarity judgments are also available. [sent-253, score-0.255]
</p><p>100 Extrinsic tasks using WordNet-based semantic similarity can potentially benefit from these refined notions of depth and density as well. [sent-254, score-1.428]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('density', 0.614), ('depth', 0.551), ('similarity', 0.162), ('piano', 0.138), ('definitions', 0.123), ('correlation', 0.122), ('wordnet', 0.12), ('lcs', 0.119), ('deni', 0.108), ('depu', 0.108), ('sussna', 0.092), ('conrath', 0.089), ('mc', 0.089), ('specificity', 0.073), ('cumulative', 0.072), ('rg', 0.072), ('judgment', 0.069), ('jiang', 0.065), ('notions', 0.063), ('hop', 0.062), ('nodes', 0.061), ('dep', 0.059), ('fg', 0.053), ('densely', 0.053), ('measures', 0.051), ('rationale', 0.049), ('grand', 0.046), ('percussion', 0.046), ('rmin', 0.046), ('toronto', 0.046), ('upright', 0.046), ('linearity', 0.044), ('node', 0.04), ('smeaton', 0.04), ('len', 0.04), ('histogram', 0.039), ('semantic', 0.038), ('ratings', 0.038), ('correlate', 0.036), ('correlating', 0.036), ('richardson', 0.036), ('gr', 0.034), ('adopting', 0.034), ('wu', 0.034), ('hierarchy', 0.034), ('taxonomies', 0.033), ('rb', 0.033), ('stock', 0.031), ('ordinal', 0.031), ('palmer', 0.031), ('parent', 0.031), ('bestaverage', 0.031), ('denu', 0.031), ('inherit', 0.031), ('jarmasz', 0.031), ('kozima', 0.031), ('oront', 0.031), ('rmax', 0.031), ('subnetwork', 0.031), ('connected', 0.031), ('conceptual', 0.03), ('den', 0.03), ('values', 0.029), ('chodorow', 0.028), ('hirst', 0.028), ('concepts', 0.028), ('coefficients', 0.027), ('ranges', 0.027), ('significance', 0.027), ('regions', 0.027), ('ends', 0.027), ('closer', 0.027), ('stability', 0.027), ('maxr', 0.027), ('subsumer', 0.027), ('parameterization', 0.026), ('ic', 0.026), ('value', 0.025), ('deeper', 0.025), ('limitations', 0.024), ('leaving', 0.024), ('rubenstein', 0.024), ('conform', 0.024), ('regarded', 0.023), ('resnik', 0.022), ('outliers', 0.022), ('evenly', 0.022), ('judgments', 0.022), ('electronic', 0.021), ('correlates', 0.021), ('definition', 0.021), ('animal', 0.021), ('finkelstein', 0.021), ('idiosyncratic', 0.021), ('leacock', 0.021), ('plant', 0.021), ('loss', 0.02), ('coefficient', 0.02), ('roy', 0.02), ('agirre', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999833 <a title="112-tfidf-1" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>Author: Tong Wang ; Graeme Hirst</p><p>Abstract: We re-investigate the rationale for and the effectiveness of adopting the notions of depth and density in WordNet-based semantic similarity measures. We show that the intuition for including these notions in WordNet-based similarity measures does not always stand up to empirical examination. In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure. We thus propose several novel definitions of depth and density, which yield significant improvement in degree of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment.</p><p>2 0.069262475 <a title="112-tfidf-2" href="./emnlp-2011-Approximate_Scalable_Bounded_Space_Sketch_for_Large_Data_NLP.html">19 emnlp-2011-Approximate Scalable Bounded Space Sketch for Large Data NLP</a></p>
<p>Author: Amit Goyal ; Hal Daume III</p><p>Abstract: We exploit sketch techniques, especially the Count-Min sketch, a memory, and time efficient framework which approximates the frequency of a word pair in the corpus without explicitly storing the word pair itself. These methods use hashing to deal with massive amounts of streaming text. We apply CountMin sketch to approximate word pair counts and exhibit their effectiveness on three important NLP tasks. Our experiments demonstrate that on all of the three tasks, we get performance comparable to Exact word pair counts setting and state-of-the-art system. Our method scales to 49 GB of unzipped web data using bounded space of 2 billion counters (8 GB memory).</p><p>3 0.068496861 <a title="112-tfidf-3" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: In this paper, we propose a novel topic model based on incorporating dictionary definitions. Traditional topic models treat words as surface strings without assuming predefined knowledge about word meaning. They infer topics only by observing surface word co-occurrence. However, the co-occurred words may not be semantically related in a manner that is relevant for topic coherence. Exploiting dictionary definitions explicitly in our model yields a better understanding of word semantics leading to better text modeling. We exploit WordNet as a lexical resource for sense definitions. We show that explicitly modeling word definitions helps improve performance significantly over the baseline for a text categorization task.</p><p>4 0.065568775 <a title="112-tfidf-4" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>Author: Balamurali AR ; Aditya Joshi ; Pushpak Bhattacharyya</p><p>Abstract: Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. We propose semantic features using word senses for a supervised document-level sentiment classifier. To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. We per- form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. The results show promising improvement with respect to the baseline.</p><p>5 0.061110195 <a title="112-tfidf-5" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>Author: Johannes Hoffart ; Mohamed Amir Yosef ; Ilaria Bordino ; Hagen Furstenau ; Manfred Pinkal ; Marc Spaniol ; Bilyana Taneva ; Stefan Thater ; Gerhard Weikum</p><p>Abstract: Disambiguating named entities in naturallanguage text maps mentions of ambiguous names onto canonical entities like people or places, registered in a knowledge base such as DBpedia or YAGO. This paper presents a robust method for collective disambiguation, by harnessing context from knowledge bases and using a new form of coherence graph. It unifies prior approaches into a comprehensive framework that combines three measures: the prior probability of an entity being mentioned, the similarity between the contexts of a mention and a candidate entity, as well as the coherence among candidate entities for all mentions together. The method builds a weighted graph of mentions and candidate entities, and computes a dense subgraph that approximates the best joint mention-entity mapping. Experiments show that the new method significantly outperforms prior methods in terms of accuracy, with robust behavior across a variety of inputs.</p><p>6 0.056755017 <a title="112-tfidf-6" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>7 0.054922231 <a title="112-tfidf-7" href="./emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">36 emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>8 0.049559355 <a title="112-tfidf-8" href="./emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">127 emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<p>9 0.043991026 <a title="112-tfidf-9" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>10 0.042711828 <a title="112-tfidf-10" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>11 0.041881908 <a title="112-tfidf-11" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>12 0.037733052 <a title="112-tfidf-12" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>13 0.03735305 <a title="112-tfidf-13" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>14 0.032299548 <a title="112-tfidf-14" href="./emnlp-2011-Analyzing_Methods_for_Improving_Precision_of_Pivot_Based_Bilingual_Dictionaries.html">18 emnlp-2011-Analyzing Methods for Improving Precision of Pivot Based Bilingual Dictionaries</a></p>
<p>15 0.031993777 <a title="112-tfidf-15" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>16 0.03055311 <a title="112-tfidf-16" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>17 0.030172216 <a title="112-tfidf-17" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>18 0.03013245 <a title="112-tfidf-18" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>19 0.029411243 <a title="112-tfidf-19" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>20 0.029261578 <a title="112-tfidf-20" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.108), (1, -0.039), (2, -0.034), (3, -0.052), (4, 0.034), (5, 0.014), (6, 0.013), (7, 0.011), (8, 0.063), (9, -0.005), (10, 0.072), (11, -0.03), (12, -0.016), (13, 0.04), (14, -0.019), (15, 0.023), (16, -0.099), (17, 0.111), (18, 0.046), (19, -0.047), (20, -0.046), (21, -0.161), (22, 0.045), (23, 0.102), (24, -0.063), (25, 0.143), (26, -0.008), (27, 0.228), (28, 0.059), (29, -0.121), (30, 0.032), (31, 0.14), (32, -0.144), (33, 0.124), (34, -0.055), (35, -0.114), (36, -0.105), (37, -0.119), (38, -0.03), (39, -0.095), (40, 0.115), (41, 0.06), (42, 0.017), (43, -0.086), (44, -0.14), (45, 0.227), (46, -0.066), (47, -0.017), (48, 0.004), (49, -0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9787243 <a title="112-lsi-1" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>Author: Tong Wang ; Graeme Hirst</p><p>Abstract: We re-investigate the rationale for and the effectiveness of adopting the notions of depth and density in WordNet-based semantic similarity measures. We show that the intuition for including these notions in WordNet-based similarity measures does not always stand up to empirical examination. In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure. We thus propose several novel definitions of depth and density, which yield significant improvement in degree of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment.</p><p>2 0.6301263 <a title="112-lsi-2" href="./emnlp-2011-Approximate_Scalable_Bounded_Space_Sketch_for_Large_Data_NLP.html">19 emnlp-2011-Approximate Scalable Bounded Space Sketch for Large Data NLP</a></p>
<p>Author: Amit Goyal ; Hal Daume III</p><p>Abstract: We exploit sketch techniques, especially the Count-Min sketch, a memory, and time efficient framework which approximates the frequency of a word pair in the corpus without explicitly storing the word pair itself. These methods use hashing to deal with massive amounts of streaming text. We apply CountMin sketch to approximate word pair counts and exhibit their effectiveness on three important NLP tasks. Our experiments demonstrate that on all of the three tasks, we get performance comparable to Exact word pair counts setting and state-of-the-art system. Our method scales to 49 GB of unzipped web data using bounded space of 2 billion counters (8 GB memory).</p><p>3 0.49582458 <a title="112-lsi-3" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>Author: Ziqi Zhang ; Anna Lisa Gentile ; Fabio Ciravegna</p><p>Abstract: Measuring semantic relatedness between words or concepts is a crucial process to many Natural Language Processing tasks. Exiting methods exploit semantic evidence from a single knowledge source, and are predominantly evaluated only in the general domain. This paper introduces a method of harnessing different knowledge sources under a uniform model for measuring semantic relatedness between words or concepts. Using Wikipedia and WordNet as examples, and evaluated in both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets.</p><p>4 0.43239626 <a title="112-lsi-4" href="./emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">36 emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>Author: Enrique Amigo ; Julio Gonzalo ; Jesus Gimenez ; Felisa Verdejo</p><p>Abstract: Automatically produced texts (e.g. translations or summaries) are usually evaluated with n-gram based measures such as BLEU or ROUGE, while the wide set of more sophisticated measures that have been proposed in the last years remains largely ignored for practical purposes. In this paper we first present an indepth analysis of the state of the art in order to clarify this issue. After this, we formalize and verify empirically a set of properties that every text evaluation measure based on similarity to human-produced references satisfies. These properties imply that corroborating system improvements with additional measures always increases the overall reliability of the evaluation process. In addition, the greater the heterogeneity of the measures (which is measurable) the higher their combined reliability. These results support the use of heterogeneous measures in order to consolidate text evaluation results.</p><p>5 0.42913526 <a title="112-lsi-5" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>Author: Peter Turney ; Yair Neuman ; Dan Assaf ; Yohai Cohen</p><p>Abstract: Metaphor is ubiquitous in text, even in highly technical text. Correct inference about textual entailment requires computers to distinguish the literal and metaphorical senses of a word. Past work has treated this problem as a classical word sense disambiguation task. In this paper, we take a new approach, based on research in cognitive linguistics that views metaphor as a method for transferring knowledge from a familiar, well-understood, or concrete domain to an unfamiliar, less understood, or more abstract domain. This view leads to the hypothesis that metaphorical word usage is correlated with the degree of abstractness of the word’s context. We introduce an algorithm that uses this hypothesis to classify a word sense in a given context as either literal (de- notative) or metaphorical (connotative). We evaluate this algorithm with a set of adjectivenoun phrases (e.g., in dark comedy, the adjective dark is used metaphorically; in dark hair, it is used literally) and with the TroFi (Trope Finder) Example Base of literal and nonliteral usage for fifty verbs. We achieve state-of-theart performance on both datasets.</p><p>6 0.42225415 <a title="112-lsi-6" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>7 0.38091141 <a title="112-lsi-7" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>8 0.34340155 <a title="112-lsi-8" href="./emnlp-2011-Analyzing_Methods_for_Improving_Precision_of_Pivot_Based_Bilingual_Dictionaries.html">18 emnlp-2011-Analyzing Methods for Improving Precision of Pivot Based Bilingual Dictionaries</a></p>
<p>9 0.3304444 <a title="112-lsi-9" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>10 0.26416686 <a title="112-lsi-10" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>11 0.23192433 <a title="112-lsi-11" href="./emnlp-2011-Structured_Lexical_Similarity_via_Convolution_Kernels_on_Dependency_Trees.html">127 emnlp-2011-Structured Lexical Similarity via Convolution Kernels on Dependency Trees</a></p>
<p>12 0.2107189 <a title="112-lsi-12" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>13 0.20815213 <a title="112-lsi-13" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>14 0.20144367 <a title="112-lsi-14" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<p>15 0.20112029 <a title="112-lsi-15" href="./emnlp-2011-Exploiting_Syntactic_and_Distributional_Information_for_Spelling_Correction_with_Web-Scale_N-gram_Models.html">55 emnlp-2011-Exploiting Syntactic and Distributional Information for Spelling Correction with Web-Scale N-gram Models</a></p>
<p>16 0.19292727 <a title="112-lsi-16" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>17 0.17968602 <a title="112-lsi-17" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>18 0.17893723 <a title="112-lsi-18" href="./emnlp-2011-Linear_Text_Segmentation_Using_Affinity_Propagation.html">88 emnlp-2011-Linear Text Segmentation Using Affinity Propagation</a></p>
<p>19 0.17225091 <a title="112-lsi-19" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>20 0.17078811 <a title="112-lsi-20" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.076), (33, 0.012), (36, 0.025), (37, 0.031), (42, 0.333), (45, 0.093), (53, 0.018), (54, 0.027), (57, 0.017), (62, 0.017), (64, 0.024), (66, 0.018), (69, 0.01), (79, 0.063), (82, 0.026), (87, 0.023), (90, 0.02), (96, 0.059), (97, 0.01), (98, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75235665 <a title="112-lda-1" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>Author: Tong Wang ; Graeme Hirst</p><p>Abstract: We re-investigate the rationale for and the effectiveness of adopting the notions of depth and density in WordNet-based semantic similarity measures. We show that the intuition for including these notions in WordNet-based similarity measures does not always stand up to empirical examination. In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure. We thus propose several novel definitions of depth and density, which yield significant improvement in degree of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment.</p><p>2 0.64269155 <a title="112-lda-2" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>Author: Benjamin Borschinger ; Bevan K. Jones ; Mark Johnson</p><p>Abstract: It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.1</p><p>3 0.40909058 <a title="112-lda-3" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>Author: Emily M. Bender ; Dan Flickinger ; Stephan Oepen ; Yi Zhang</p><p>Abstract: In order to obtain a fine-grained evaluation of parser accuracy over naturally occurring text, we study 100 examples each of ten reasonably frequent linguistic phenomena, randomly selected from a parsed version of the English Wikipedia. We construct a corresponding set of gold-standard target dependencies for these 1000 sentences, operationalize mappings to these targets from seven state-of-theart parsers, and evaluate the parsers against this data to measure their level of success in identifying these dependencies.</p><p>4 0.40360606 <a title="112-lda-4" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>5 0.39790073 <a title="112-lda-5" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>Author: Amit Dubey ; Frank Keller ; Patrick Sturt</p><p>Abstract: This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chunker with a co-reference classifier. Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure. This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort. We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.</p><p>6 0.39777756 <a title="112-lda-6" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>7 0.39590168 <a title="112-lda-7" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>8 0.39544657 <a title="112-lda-8" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>9 0.39448193 <a title="112-lda-9" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>10 0.39421034 <a title="112-lda-10" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>11 0.39284122 <a title="112-lda-11" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>12 0.39144245 <a title="112-lda-12" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>13 0.3900786 <a title="112-lda-13" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>14 0.3896797 <a title="112-lda-14" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>15 0.3878403 <a title="112-lda-15" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>16 0.38782063 <a title="112-lda-16" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>17 0.3874554 <a title="112-lda-17" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>18 0.38713595 <a title="112-lda-18" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>19 0.38582069 <a title="112-lda-19" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>20 0.38543999 <a title="112-lda-20" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
