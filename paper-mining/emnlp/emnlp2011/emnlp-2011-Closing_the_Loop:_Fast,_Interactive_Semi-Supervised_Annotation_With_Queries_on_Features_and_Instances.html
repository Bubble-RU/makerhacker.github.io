<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-28" href="#">emnlp2011-28</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</h1>
<br/><p>Source: <a title="emnlp-2011-28-pdf" href="http://aclweb.org/anthology//D/D11/D11-1136.pdf">pdf</a></p><p>Author: Burr Settles</p><p>Abstract: This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e.g., words) and instances (e.g., documents). We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort.</p><p>Reference: <a title="emnlp-2011-28-reference" href="../emnlp2011_reference/emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e. [sent-3, score-0.534]
</p><p>2 We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. [sent-8, score-0.243]
</p><p>3 Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort. [sent-9, score-0.327]
</p><p>4 1 Introduction In active learning, a classifier participates in its own training process by posing queries, such as requesting labels for documents in a text classification task. [sent-10, score-0.529]
</p><p>5 Nearly all previous work in active learning, however, has focused on selecting queries from the learner’s perspective. [sent-15, score-0.494]
</p><p>6 For example, experiments are often run in simulation rather than with user studies, and results are routinely evaluated in terms of training set size rather than human annotation time or labor costs (which are more reasonable measures of labeling effort). [sent-16, score-0.375]
</p><p>7 While selecting good queries is clearly important, if our goal is to reduce actual annotation effort these human factors must be taken into account. [sent-21, score-0.272]
</p><p>8 In this  work, we propose a new interactive annotation interface which addresses some of these issues; in particular it has the ability to pose queries on both features (e. [sent-22, score-0.508]
</p><p>9 On the left panel, users are presented with unlabeled documents: in this case Usenet messages that belong to one of two sportsrelated topics: baseball and hockey. [sent-29, score-0.336]
</p><p>10 Users may label documents by clicking on the class buttons listed below each text. [sent-30, score-0.257]
</p><p>11 In cases of extreme ambiguity, users may ignore a document by clicking the “X” to remove it from the pool of possible queries. [sent-31, score-0.248]
</p><p>12 On the right panel, users are given a list of feature queries organized into columns by class label. [sent-32, score-0.508]
</p><p>13 , once a user is in the baseball mindset, s/he can simply go down the list, labeling features in context: “plate,” “pitcher,” “bases,” etc. [sent-40, score-0.393]
</p><p>14 Within each column, words are sorted by how informative they are the to classifier, and users may click on words to label them. [sent-42, score-0.185]
</p><p>15 The list of previously labeled words appears at the bottom of each list (highlighted), and can be unlabeled at any time, if users later feel they made any errors. [sent-44, score-0.293]
</p><p>16 Finally, a large submit button is located at the top of the screen, which users must click to re-train the classifier and receive a new set ofqueries. [sent-45, score-0.198]
</p><p>17 The learning algorithm is actually fast enough to do this automatically after each labeling action. [sent-46, score-0.184]
</p><p>18 However, we found such a dynamically changing interface to be frustrating for users (e. [sent-47, score-0.26]
</p><p>19 Let the model be parameterized by the vector θ, with θj = P(yj) denoting the probability of class yj, and θjk = P(fk |yj) denoting the probability of generating word fk given class yj. [sent-55, score-0.468]
</p><p>20 Note that for class priPors Pj θj = 1, and for per-class word multinomials Pk Pθjk = 1. [sent-56, score-0.229]
</p><p>21 The likelihood of document x being gPenerated by class yj is given by: Pθ(x|yj) = P(|x|)  Y(θjk)fk(x), Yk  where fk (x) is the frequency count of word fk in document x. [sent-57, score-0.889]
</p><p>22 In other words, we count the fraction of times the word fk occurs in the labeled set among documents of class yj, and the prior adds mjk “hallucinated” occurrences for a smoothed version of the maximum likelihood estimate:  {hx(l), y(l)i}lL=1. [sent-62, score-0.629]
</p><p>23 (2)  Here, mjk is the prior for word fk under class yj, P(yj ∈ {0, 1} indicates the true labeling of the ith do|xcum)en ∈t {in0 ,t1he} training set, a trnude Z(fk) nisg a normalization constant summing over all words in the  |x(i))  vocabulary. [sent-64, score-0.591]
</p><p>24 This prior is important in the event that no documents are yet labeled with yj, which can be quite common early on in the active learning process. [sent-67, score-0.487]
</p><p>25 Recall that our scenario lets human annotators provide not only document labels, but feature labels as well. [sent-68, score-0.214]
</p><p>26 To make use of this additional information, we assume that labeling the word fk with a class yj increases the probability P(fk |yj) of the word appearing in documents of that cl|ayss. [sent-69, score-0.761]
</p><p>27 The pooling  multinomials algorithm averages together two sets of θjk parameters: one that is estimated from labeled data, and another derived from feature labels under the assumption of a boolean output variable (treating labeled features are “polarizing” factors). [sent-75, score-0.538]
</p><p>28 Therefore, pooling multinomials can only be applied to binary classification tasks, while our method works equally well for problems with multiple classes. [sent-76, score-0.212]
</p><p>29 The second advantage is that feature labels need not be mutually exclusive, so the word “score” could be labeled with both baseball and hockey, if necessary (e. [sent-77, score-0.316]
</p><p>30 Finally, our framework allows users to conceivably provide feature-specific priors αjk to, for example, imply that the word “inning” is a stronger indicator for baseball than the word “score” (which is a more general sports term). [sent-80, score-0.234]
</p><p>31 In fact, these texts form the pool of possible instance queries in active learning. [sent-84, score-0.576]
</p><p>32 Combining EM with pool-based active learning was previously studied in the context of instance labeling (McCallum and Nigam, 1998), and we extend the method to our interactive scenario, which supports feature labeling as well. [sent-86, score-0.77]
</p><p>33 N =ex {tx we re-estimate feature multinomials θjk, using both labeled instances from L and probabilistically-labeled ienlsetdan incestsa nfrcoems f r Uo (Eq. [sent-92, score-0.346]
</p><p>34 Also, we ignore labeled data in the initial estimation of θ0 because L is too small early in active learning to yield good results with EM. [sent-103, score-0.428]
</p><p>35 3 Selecting Instance and Feature Queries The final algorithmic component to our system is the selection of informative queries (i. [sent-107, score-0.198]
</p><p>36 Querying instances is the traditional mode of active learning, and is well-studied in the literature; see Settles (2009) for a review. [sent-110, score-0.39]
</p><p>37 In this work we use entropy-based uncertainty sampling, which ranks all instances in U by the posPterior class entropy under tihnset amnocdesel Hθ (Y |x) = Pj Pθ (yj |x) log Pθ (yj |x), and asks the user to) =lab −elP Pthe top D|x u)nlolagbPeled d|oxc)-, uments. [sent-111, score-0.357]
</p><p>38 This simple heuPristic is an approximation to querying the instance with the maximum infor−  mation gain (since the class entropy, once labeled, is zero), under the assumption that each x is representative of the underlying natural data distribution. [sent-112, score-0.208]
</p><p>39 , 2006), or (2) feature queries are posed just like instance queries: a word is presented to the annotator, who must choose among the labels (Druck et al. [sent-117, score-0.379]
</p><p>40 Recall from Figure 1 that we want to organize feature queries into columns by class label. [sent-120, score-0.365]
</p><p>41 This means our active learner must produce queries that are class-specific. [sent-121, score-0.552]
</p><p>42 To organize queries into classes, we take the top V unlabeled features and pose fk for the class yj with which it occurs most frequently, as well as any other class with which it occurs at least 75% as often. [sent-125, score-1.003]
</p><p>43 Intuitively, this approach (1) queries features that the model believes are most informative, and (2) automatically identifies classes that seem most correlated. [sent-126, score-0.277]
</p><p>44 To our knowledge, DUALIST is the first active learning environment with both of these properties. [sent-127, score-0.334]
</p><p>45 The other experiments are user studies  designed to empirically gauge how well human annotators make use of DUALIST in practice. [sent-130, score-0.191]
</p><p>46 1 Comparison of Learning Algorithms  An important question is how well our learning algorithm, “MNB/Priors,” performs relative to existing baseline methods for learning with labeled features. [sent-146, score-0.17]
</p><p>47 “MNB/Pool” is na¨ ıve Bayes trained using the pooling multinomials approach (Melville et al. [sent-154, score-0.176]
</p><p>48 Classification accuracy is reported for each model, using only the top 10 oracle-ranked features per label (and no labeled instances) for training. [sent-163, score-0.213]
</p><p>49 to us only supports labeled features (and not labeled instances as well), we limit the MNB methods to features for a fair comparison. [sent-167, score-0.4]
</p><p>50 We conservatively use only the top 10 features per class, which is meant to resemble a handful of very salient features that a human might brainstorm to jumpstart the learning process. [sent-172, score-0.167]
</p><p>51 MNB is superior when using any-  where from five to 20 oracle-ranked features per class, but as the number of feature labels increases beyond 30, GE is often more accurate (results not shown). [sent-186, score-0.174]
</p><p>52 In short, GE training is too slow and too inaccurate early in the active learning process (where labels are more scarce) to be appropriate for our scenario. [sent-189, score-0.417]
</p><p>53 To study this, we ran experiments varying α from from one to 212, using different combinations of labeled instances and/or features (again using the simulated oracle and 10-fold cross-validation). [sent-193, score-0.299]
</p><p>54 For clarity, vertical axes are scaled differently for each data set, and horizontal axes are plotted on a logarithmic scale. [sent-202, score-0.17]
</p><p>55 A second observation is that, for all but the Reuters corpus, labeling 90 additional features improves accuracy much more than labeling 100 documents. [sent-206, score-0.307]
</p><p>56 , words) is known to be generally faster and easier for humans than labeling entire instances (e. [sent-209, score-0.242]
</p><p>57 Instead, we hypothesize that in practice there may be a limited set of features with high enough information content for humans to feel confident labeling, after which they switch their attention to labeling instance queries instead. [sent-220, score-0.439]
</p><p>58 This is in contrast to most previous work, which simulates active learning by using known document labels and feature labels from a simulated oracle (which can be flawed, as we saw in the previous section). [sent-224, score-0.652]
</p><p>59 It also allows us to analyze behavioral results, which in turn may help inform future protocols for human interaction in active learning. [sent-226, score-0.296]
</p><p>60 We used three different configurations: active dual (as in Figure 1, implementing everything from Section 2), active instance (instance queries only, no features), and a passive instance baseline (instances only, but selected at random). [sent-228, score-1.036]
</p><p>61 We also began by randomly selecting instances in the active configurations, until every class has at least one labeled instance or one labeled feature. [sent-229, score-0.783]
</p><p>62 D = 2 documents and V = 100 features were selected for each round of active learning. [sent-230, score-0.398]
</p><p>63 annotation time, for each trial in the user study. [sent-236, score-0.218]
</p><p>64 The first thing to note is that the active  ues1r 0 . [sent-237, score-0.296]
</p><p>65 98765430 12pa sc8t0ive d2inu4a0slt3 60 WebKB  annotation time (sec)  Science  annotation time (sec)  Movie Reviews  annotation time (sec)  Figure 3: User experiments involving human annotators for text classification. [sent-252, score-0.269]
</p><p>66 time learning curves for a particular user (under all three experimental conditions) for each of the three corpora (one column per data set). [sent-254, score-0.182]
</p><p>67 Horizontal axes show labeling cost in terms of actual elapsed annotation time (in seconds). [sent-257, score-0.274]
</p><p>68 1473  dual configuration yields consistently better learn-  ing curves than either active or passive learning with instances alone, often getting within 90% of fullysupervised accuracy (in under six minutes). [sent-258, score-0.608]
</p><p>69 With the WebKB corpus, however, he apparently found feature queries for the course label to be easier than the other classes, and 71% of all his feature labels came from that class (sometimes noisily, e. [sent-265, score-0.538]
</p><p>70 However, we note that the active dual interface is not particularly worse in these cases, it is simply not significantly better, as in the other 13 trials. [sent-270, score-0.481]
</p><p>71 Feature queries were less costly than instances, which is consistent with findings in previous work (Raghavan et al. [sent-271, score-0.198]
</p><p>72 Interestingly, we observed that the human annotators spent most of the first three minutes performing feature-labeling actions ( ), and switched to more instance-labeling activity for the final three minutes ( ). [sent-281, score-0.415]
</p><p>73 2, it seems that the active learner is exhausting the most salient feature queries early on, and users begin to focus on more interpretable instance queries over time. [sent-283, score-1.034]
</p><p>74 However, more study (and longer annotation periods) are warranted to better understand this phenomenon, which may suggest additional user interface design improvements. [sent-284, score-0.335]
</p><p>75 In active settings, users made an average of one 1474 instance-labeling error per trial (relative to the goldstandard labels), but in the passive case this rose to  1. [sent-286, score-0.551]
</p><p>76 6, suggesting they are more accurate on the active queries. [sent-287, score-0.296]
</p><p>77 However, they also explicitly ignored more instances in the active dual condition (7. [sent-288, score-0.458]
</p><p>78 But if we look at the time users spent on these actions, they are much faster to label/ignore (9. [sent-293, score-0.193]
</p><p>79 5s) in the active dual scenario than in the active instance (10. [sent-295, score-0.71]
</p><p>80 We asked a user to employ DUALIST for 10 minutes for each of three benchmark WSD corpora (Mohammad and Pedersen, 2004): Hard (3 senses), Line (6 senses), and Serve (4 senses). [sent-310, score-0.312]
</p><p>81 However, our results were achieved in less than 10 minutes of effort each, by labeling an average of 76 sentences and 32 words or phrases per task (compared to the thousands of labeled training sentences used in previous work). [sent-316, score-0.345]
</p><p>82 We then had a user annotate phrases and patterns into five semantic classes using DUALIST: person, location, organization, date/time, and other (the background or null class). [sent-332, score-0.18]
</p><p>83 The user began by inserting simple hyponym patterns (Hearst, 1992) for their corresponding classes (e. [sent-333, score-0.216]
</p><p>84 While there is room for improvement (published results for this kind of task are often above 80% precision), it is worth noting that in this experiment the user did not provide any initial “seed examples” for each class, which is fairly common in semantic class learning. [sent-339, score-0.263]
</p><p>85 In practice, such additional seeding should help, as the active learner acquired 115 labeled instances for the null class, but fewer than a dozen for each nonnull class (in the first 20 minutes). [sent-340, score-0.661]
</p><p>86 , 2010), which allows users to broadcast short messages limited to 140 characters. [sent-353, score-0.189]
</p><p>87 To quickly build an English-language filter for Twitter, we sampled 150,000 tweets from the Twitter Streaming API and asked an annotator spend 10 minutes with DUALIST labeling English and nonEnglish messages and features. [sent-362, score-0.437]
</p><p>88 Using the same feature representation as the language filter, the annotator spent 20 minutes with DUALIST, labeling tweets and features into three mood classes: positive, negative, and neutral. [sent-374, score-0.499]
</p><p>89 The annotator began by labeling emoticons, by which the active learner was able to uncover some interesting domain-specific salient terms, e. [sent-375, score-0.58]
</p><p>90 4  Discussion and Future Work  We have presented DUALIST, a new type of dualstrategy annotation interface for semi-supervised active learning. [sent-381, score-0.487]
</p><p>91 To support this dual-query interface, we developed a novel, fast, and practical semi-  supervised learning algorithm, and demonstrated how users can employ it to rapidly develop useful natural language systems for a variety of tasks. [sent-382, score-0.181]
</p><p>92 For several of these applications, the interactivelytrained systems are able to achieve 90% of stateof-the-art performance after only a few minutes of labeling effort on the part of a human annotator. [sent-383, score-0.251]
</p><p>93 By releasing DUALIST as an open-source tool, we hope to facilitate language annotation projects and encourage more user experiments in active learning. [sent-384, score-0.548]
</p><p>94 This represents one of the first studies of an active learning system designed to compliment the strengths of both learner and annotator. [sent-385, score-0.392]
</p><p>95 Future directions along these lines include user studies of efficient annotation behaviors, which in turn might lead to new types of queries or improvements to the user interface design. [sent-386, score-0.677]
</p><p>96 Another interesting potential application is human-driven active feature induction and engineering, after Della Pietra et al. [sent-388, score-0.344]
</p><p>97 So far, attempts to “reuse” active learning data have yielded mixed results (Lewis and Catlett, 1994; Baldridge and Osborne, 2004). [sent-393, score-0.334]
</p><p>98 Practically speaking, DUALIST is designed to run on a single machine, and supports a few hundred thousand instances and features at interactive speeds on modern hardware. [sent-394, score-0.278]
</p><p>99 A unified approach to active dual supervision for labeling features and examples. [sent-410, score-0.522]
</p><p>100 Employing EM in pool-based active learning for text classification. [sent-572, score-0.334]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dualist', 0.446), ('active', 0.296), ('yj', 0.238), ('fk', 0.23), ('queries', 0.198), ('mnb', 0.191), ('user', 0.144), ('users', 0.143), ('minutes', 0.136), ('mjk', 0.127), ('class', 0.119), ('interface', 0.117), ('labeling', 0.115), ('multinomials', 0.11), ('jk', 0.101), ('instances', 0.094), ('labeled', 0.094), ('druck', 0.092), ('baseball', 0.091), ('axes', 0.085), ('labels', 0.083), ('passive', 0.078), ('reuters', 0.077), ('interactive', 0.076), ('tweets', 0.075), ('annotation', 0.074), ('melville', 0.073), ('ge', 0.07), ('dual', 0.068), ('pooling', 0.066), ('webkb', 0.064), ('nigam', 0.061), ('evaluators', 0.061), ('sentiment', 0.061), ('documents', 0.059), ('learner', 0.058), ('em', 0.056), ('unlabeled', 0.056), ('classifier', 0.055), ('movie', 0.055), ('attenberg', 0.055), ('twitter', 0.053), ('settles', 0.052), ('ig', 0.052), ('aaai', 0.051), ('instance', 0.05), ('spent', 0.05), ('feature', 0.048), ('annotators', 0.047), ('messages', 0.046), ('actions', 0.046), ('raghavan', 0.044), ('features', 0.043), ('salient', 0.043), ('acquisitions', 0.042), ('inning', 0.042), ('routinely', 0.042), ('screenshot', 0.042), ('label', 0.042), ('flexible', 0.04), ('querying', 0.039), ('wsd', 0.039), ('learning', 0.038), ('morgan', 0.037), ('rennie', 0.037), ('craven', 0.037), ('panel', 0.037), ('clicking', 0.037), ('faculty', 0.037), ('lowercased', 0.037), ('petrovi', 0.037), ('classes', 0.036), ('bayes', 0.036), ('classification', 0.036), ('simulated', 0.036), ('began', 0.036), ('document', 0.036), ('ve', 0.035), ('encourage', 0.034), ('rose', 0.034), ('multinomial', 0.034), ('mccallum', 0.034), ('accuracy', 0.034), ('humans', 0.033), ('seconds', 0.033), ('turk', 0.033), ('riloff', 0.033), ('godbole', 0.033), ('spend', 0.033), ('alpha', 0.033), ('emoticons', 0.033), ('speeds', 0.033), ('usenet', 0.033), ('supports', 0.032), ('benchmark', 0.032), ('sec', 0.032), ('pool', 0.032), ('oracle', 0.032), ('annotator', 0.032), ('fast', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000018 <a title="28-tfidf-1" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>Author: Burr Settles</p><p>Abstract: This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e.g., words) and instances (e.g., documents). We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort.</p><p>2 0.22615574 <a title="28-tfidf-2" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>Author: Chao Shen ; Tao Li</p><p>Abstract: In active dual supervision, not only informative examples but also features are selected for labeling to build a high quality classifier with low cost. However, how to measure the informativeness for both examples and feature on the same scale has not been well solved. In this paper, we propose a non-negative matrix factorization based approach to address this issue. We first extend the matrix factorization framework to explicitly model the corresponding relationships between feature classes and examples classes. Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled. Empirical results demonstrate the effectiveness of our proposed methods.</p><p>3 0.16918598 <a title="28-tfidf-3" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>Author: Florian Laws ; Christian Scheible ; Hinrich Schutze</p><p>Abstract: Supervised classification needs large amounts of annotated training data that is expensive to create. Two approaches that reduce the cost of annotation are active learning and crowdsourcing. However, these two approaches have not been combined successfully to date. We evaluate the utility of active learning in crowdsourcing on two tasks, named entity recognition and sentiment detection, and show that active learning outperforms random selection of annotation examples in a noisy crowdsourcing scenario.</p><p>4 0.14940712 <a title="28-tfidf-4" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>5 0.11808154 <a title="28-tfidf-5" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>Author: Yufan Guo ; Anna Korhonen ; Thierry Poibeau</p><p>Abstract: Documents Anna Korhonen Thierry Poibeau Computer Laboratory LaTTiCe, UMR8094 University of Cambridge, UK CNRS & ENS, France alk2 3 @ cam . ac .uk thierry .po ibeau @ ens . fr tific literature according to categories of information structure (or discourse, rhetorical, argumentative or Argumentative Zoning (AZ) analysis of the argumentative structure of a scientific paper has proved useful for a number of information access tasks. Current approaches to AZ rely on supervised machine learning (ML). – – Requiring large amounts of annotated data, these approaches are expensive to develop and port to different domains and tasks. A potential solution to this problem is to use weaklysupervised ML instead. We investigate the performance of four weakly-supervised classifiers on scientific abstract data annotated for multiple AZ classes. Our best classifier based on the combination of active learning and selftraining outperforms our best supervised classifier, yielding a high accuracy of 81% when using just 10% of the labeled data. This result suggests that weakly-supervised learning could be employed to improve the practical applicability and portability of AZ across different information access tasks.</p><p>6 0.11016963 <a title="28-tfidf-6" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>7 0.10303123 <a title="28-tfidf-7" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>8 0.099933393 <a title="28-tfidf-8" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>9 0.095420383 <a title="28-tfidf-9" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>10 0.093243331 <a title="28-tfidf-10" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>11 0.091774851 <a title="28-tfidf-11" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>12 0.083634786 <a title="28-tfidf-12" href="./emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">130 emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>13 0.082827918 <a title="28-tfidf-13" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>14 0.079659164 <a title="28-tfidf-14" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>15 0.076480128 <a title="28-tfidf-15" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>16 0.072438642 <a title="28-tfidf-16" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>17 0.071284257 <a title="28-tfidf-17" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>18 0.068861105 <a title="28-tfidf-18" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>19 0.067967519 <a title="28-tfidf-19" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>20 0.06505359 <a title="28-tfidf-20" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.242), (1, -0.237), (2, 0.101), (3, 0.04), (4, 0.04), (5, 0.018), (6, 0.009), (7, -0.133), (8, -0.085), (9, 0.093), (10, -0.013), (11, -0.194), (12, -0.054), (13, -0.066), (14, -0.027), (15, -0.037), (16, 0.078), (17, -0.133), (18, -0.203), (19, 0.138), (20, 0.066), (21, 0.159), (22, -0.029), (23, 0.127), (24, -0.09), (25, 0.055), (26, -0.013), (27, 0.168), (28, -0.017), (29, 0.112), (30, -0.055), (31, -0.071), (32, 0.028), (33, 0.11), (34, -0.039), (35, -0.016), (36, 0.051), (37, 0.009), (38, 0.078), (39, 0.05), (40, 0.191), (41, 0.102), (42, -0.042), (43, 0.015), (44, -0.021), (45, -0.012), (46, -0.012), (47, 0.064), (48, 0.08), (49, -0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95569098 <a title="28-lsi-1" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>Author: Burr Settles</p><p>Abstract: This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e.g., words) and instances (e.g., documents). We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort.</p><p>2 0.81873029 <a title="28-lsi-2" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>Author: Chao Shen ; Tao Li</p><p>Abstract: In active dual supervision, not only informative examples but also features are selected for labeling to build a high quality classifier with low cost. However, how to measure the informativeness for both examples and feature on the same scale has not been well solved. In this paper, we propose a non-negative matrix factorization based approach to address this issue. We first extend the matrix factorization framework to explicitly model the corresponding relationships between feature classes and examples classes. Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled. Empirical results demonstrate the effectiveness of our proposed methods.</p><p>3 0.76235884 <a title="28-lsi-3" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>Author: Yufan Guo ; Anna Korhonen ; Thierry Poibeau</p><p>Abstract: Documents Anna Korhonen Thierry Poibeau Computer Laboratory LaTTiCe, UMR8094 University of Cambridge, UK CNRS & ENS, France alk2 3 @ cam . ac .uk thierry .po ibeau @ ens . fr tific literature according to categories of information structure (or discourse, rhetorical, argumentative or Argumentative Zoning (AZ) analysis of the argumentative structure of a scientific paper has proved useful for a number of information access tasks. Current approaches to AZ rely on supervised machine learning (ML). – – Requiring large amounts of annotated data, these approaches are expensive to develop and port to different domains and tasks. A potential solution to this problem is to use weaklysupervised ML instead. We investigate the performance of four weakly-supervised classifiers on scientific abstract data annotated for multiple AZ classes. Our best classifier based on the combination of active learning and selftraining outperforms our best supervised classifier, yielding a high accuracy of 81% when using just 10% of the labeled data. This result suggests that weakly-supervised learning could be employed to improve the practical applicability and portability of AZ across different information access tasks.</p><p>4 0.58939844 <a title="28-lsi-4" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>Author: Florian Laws ; Christian Scheible ; Hinrich Schutze</p><p>Abstract: Supervised classification needs large amounts of annotated training data that is expensive to create. Two approaches that reduce the cost of annotation are active learning and crowdsourcing. However, these two approaches have not been combined successfully to date. We evaluate the utility of active learning in crowdsourcing on two tasks, named entity recognition and sentiment detection, and show that active learning outperforms random selection of annotation examples in a noisy crowdsourcing scenario.</p><p>5 0.51918525 <a title="28-lsi-5" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>6 0.48396942 <a title="28-lsi-6" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>7 0.44577733 <a title="28-lsi-7" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>8 0.38860124 <a title="28-lsi-8" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>9 0.379455 <a title="28-lsi-9" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>10 0.33972871 <a title="28-lsi-10" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>11 0.33390132 <a title="28-lsi-11" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>12 0.33318874 <a title="28-lsi-12" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>13 0.32576296 <a title="28-lsi-13" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>14 0.32155973 <a title="28-lsi-14" href="./emnlp-2011-Enhancing_Chinese_Word_Segmentation_Using_Unlabeled_Data.html">48 emnlp-2011-Enhancing Chinese Word Segmentation Using Unlabeled Data</a></p>
<p>15 0.31819114 <a title="28-lsi-15" href="./emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">130 emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>16 0.31569254 <a title="28-lsi-16" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>17 0.31427839 <a title="28-lsi-17" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>18 0.31141713 <a title="28-lsi-18" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>19 0.30704862 <a title="28-lsi-19" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>20 0.30130813 <a title="28-lsi-20" href="./emnlp-2011-Multilayer_Sequence_Labeling.html">96 emnlp-2011-Multilayer Sequence Labeling</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.23), (15, 0.015), (23, 0.116), (36, 0.032), (37, 0.033), (39, 0.012), (45, 0.077), (52, 0.011), (53, 0.022), (54, 0.035), (57, 0.049), (62, 0.026), (64, 0.029), (66, 0.019), (69, 0.016), (79, 0.05), (82, 0.03), (90, 0.013), (96, 0.065), (98, 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74842477 <a title="28-lda-1" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>Author: Burr Settles</p><p>Abstract: This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e.g., words) and instances (e.g., documents). We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort.</p><p>2 0.59737962 <a title="28-lda-2" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>3 0.58735955 <a title="28-lda-3" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>4 0.58558691 <a title="28-lda-4" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>Author: Jason Katz-Brown ; Slav Petrov ; Ryan McDonald ; Franz Och ; David Talbot ; Hiroshi Ichikawa ; Masakazu Seno ; Hideto Kazawa</p><p>Abstract: We propose a simple training regime that can improve the extrinsic performance of a parser, given only a corpus of sentences and a way to automatically evaluate the extrinsic quality of a candidate parse. We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system. We use a corpus of weakly-labeled reference reorderings to guide parser training. Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress.</p><p>5 0.58375001 <a title="28-lda-5" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>Author: Sebastian Riedel ; Andrew McCallum</p><p>Abstract: Extracting biomedical events from literature has attracted much recent attention. The bestperforming systems so far have been pipelines of simple subtask-specific local classifiers. A natural drawback of such approaches are cascading errors introduced in early stages of the pipeline. We present three joint models of increasing complexity designed to overcome this problem. The first model performs joint trigger and argument extraction, and lends itself to a simple, efficient and exact inference algorithm. The second model captures correlations between events, while the third model ensures consistency between arguments of the same event. Inference in these models is kept tractable through dual decomposition. The first two models outperform the previous best joint approaches and are very competitive with respect to the current state-of-theart. The third model yields the best results reported so far on the BioNLP 2009 shared task, the BioNLP 2011 Genia task and the BioNLP 2011Infectious Diseases task.</p><p>6 0.58078992 <a title="28-lda-6" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>7 0.57889575 <a title="28-lda-7" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>8 0.57872802 <a title="28-lda-8" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>9 0.57811141 <a title="28-lda-9" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>10 0.57734913 <a title="28-lda-10" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>11 0.57672191 <a title="28-lda-11" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>12 0.57648194 <a title="28-lda-12" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>13 0.57645857 <a title="28-lda-13" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>14 0.57602453 <a title="28-lda-14" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>15 0.57418001 <a title="28-lda-15" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>16 0.57362247 <a title="28-lda-16" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>17 0.57344306 <a title="28-lda-17" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>18 0.57333511 <a title="28-lda-18" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>19 0.57240146 <a title="28-lda-19" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>20 0.57228583 <a title="28-lda-20" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
