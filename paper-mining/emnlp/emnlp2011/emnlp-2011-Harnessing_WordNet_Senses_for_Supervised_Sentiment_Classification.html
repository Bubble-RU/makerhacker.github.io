<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-63" href="#">emnlp2011-63</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</h1>
<br/><p>Source: <a title="emnlp-2011-63-pdf" href="http://aclweb.org/anthology//D/D11/D11-1100.pdf">pdf</a></p><p>Author: Balamurali AR ; Aditya Joshi ; Pushpak Bhattacharyya</p><p>Abstract: Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. We propose semantic features using word senses for a supervised document-level sentiment classifier. To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. We per- form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. The results show promising improvement with respect to the baseline.</p><p>Reference: <a title="emnlp-2011-63-reference" href="../emnlp2011_reference/emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 in  Abstract Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. [sent-5, score-0.523]
</p><p>2 We propose semantic features using word senses for a supervised document-level sentiment classifier. [sent-6, score-0.791]
</p><p>3 To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. [sent-7, score-0.417]
</p><p>4 In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. [sent-8, score-0.775]
</p><p>5 Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. [sent-9, score-0.697]
</p><p>6 Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. [sent-10, score-0.741]
</p><p>7 We per-  form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. [sent-11, score-0.777]
</p><p>8 Our work explores incorporation of semantics in a supervised sentiment classifier. [sent-23, score-0.422]
</p><p>9 Harnessing WordNet senses as features helps us address two issues: 1. [sent-26, score-0.369]
</p><p>10 Since sense-based features prove to generate superior sentiment classifiers, we get an opportunity to mitigate unknown Proce dEindgisnb oufr tgh e, 2 S0c1o1tl Canodn,f eUrKen,c Jeuol yn 2 E7m–3p1ir,ic 2a0l1 M1. [sent-30, score-0.526]
</p><p>11 tc ho2d0s1 in A Nsasotucira tlio Lnan fogru Cagoem Ppruotcaetisosninagl, L pinag uesis 1ti0c8s1–1091,  synsets in the test corpus by replacing them with known synsets in the training corpus. [sent-32, score-0.514]
</p><p>12 In addition, we compare the effect of varying training samples on a sentiment classifier developed using word based features and sense based features. [sent-38, score-0.646]
</p><p>13 Our synset replacement algorithm uses Wordnet similarity-based  metrics which replace an unknown synset in the test corpus with the closest approximation in the training corpus. [sent-42, score-1.092]
</p><p>14 We explain the similaritybased replacement technique using WordNet synsets in section 4. [sent-45, score-0.436]
</p><p>15 2  Related Work  This work studies the benefit of a word sense-based feature space to supervised sentiment classification. [sent-50, score-0.503]
</p><p>16 However, a word sense-based feature space is feasible subject to verification of the hypothesis that sentiment and word senses are related. [sent-51, score-0.758]
</p><p>17 Towards this, Wiebe and Mihalcea (2006) conduct a study on hu1082  man annotation of 354 words senses with polarity and report a high inter-annotator agreement. [sent-52, score-0.479]
</p><p>18 The work in sentiment analysis using sense-based features, including ours, assumes this hypothesis that sense decides the sentiment. [sent-53, score-0.569]
</p><p>19 (2010) report performance of rule-based sentiment classification using word senses. [sent-58, score-0.487]
</p><p>20 (2009) suggest using word senses to detect sentence level polarity of news headlines. [sent-63, score-0.412]
</p><p>21 In order to do so, we use synset offsets as representation of sense-based features. [sent-74, score-0.402]
</p><p>22 However, we consider a document as a unit of sentiment classification i. [sent-79, score-0.545]
</p><p>23 This is different from Pang and Lee (2004) which suggests that sentiment is associated only with subjective content. [sent-82, score-0.393]
</p><p>24 Each word/lexeme is mapped to an appropriate synset in WordNet based on its sense and represented using the corresponding synset id of WordNet. [sent-91, score-0.98]
</p><p>25 Thus, the word love is disambiguated and replaced by the identifier 21758160 which consists of a POS category identifier 2 followed by synset offset identifier 1758160. [sent-92, score-0.626]
</p><p>26 This paper refers to synset offset as synset identifiers or simply, senses. [sent-93, score-0.885]
</p><p>27 A user will infer the negative polarity of the first sentence from the negative sense of ‘fell’ in it while the user will state that the second sentence does not carry any sentiment. [sent-103, score-0.417]
</p><p>28 This implies that there is at least one sense of the word ‘fell’ that carries sentiment and at least one that does not. [sent-104, score-0.569]
</p><p>29 ” 1083 The word deadly has senses which carry opposite polarity in the two sentences and these senses as-  sign the polarity to the corresponding sentence. [sent-110, score-0.902]
</p><p>30 ” The words vulgar and crude occur as synonyms in the synset that corresponds to the sense ‘conspicuously and tastelessly indecent’ . [sent-117, score-0.648]
</p><p>31 The three scenarios motivate the use of semantic space for sentiment prediction. [sent-124, score-0.425]
</p><p>32 2  Sense versus Lexeme-based Feature  Representation We annotate the words in the corpus with their senses using two sense disambiguation approaches. [sent-126, score-0.618]
</p><p>33 Word senses that have been manually annotated (M) 2. [sent-134, score-0.44]
</p><p>34 Word senses that have been annotated by an automatic WSD (I) 3. [sent-135, score-0.385]
</p><p>35 Manually annotated word senses and words (both separately as features) (Words + Sense(M))  4. [sent-136, score-0.385]
</p><p>36 Automatically annotated word senses and words (both separately as features) (Words + Sense(I)) Our first set of experiments compares the four feature representations to find the feature representation with which sentiment classification gives the best performance. [sent-137, score-0.872]
</p><p>37 In addition to this, we also present a partof-speech-wise analysis of benefit to SA as well as effect of varying the training samples on sentiment classification accuracy. [sent-139, score-0.577]
</p><p>38 A partially disambiguated document is a document which does not contain senses of all words. [sent-144, score-0.532]
</p><p>39 To verify this, we create different variants of the corpus by disambiguating words which have candidate senses within a threshold. [sent-146, score-0.407]
</p><p>40 For example, a partially disambiguated variant of the corpus with threshold 3 for candidate senses is created by disambiguating words which have a maximum of three candidate senses. [sent-147, score-0.49]
</p><p>41 These synsets are then used as features for classification along with lexeme based features. [sent-148, score-0.475]
</p><p>42 1 Synset Replacement Algorithm Using WordNet senses provides an opportunity to use similarity-based metrics for WordNet to reduce 1084 the effect of unknown features. [sent-151, score-0.472]
</p><p>43 If a synset encountered in a test document is not found in the training corpus, it is replaced by one of the synsets present in the training corpus. [sent-152, score-0.747]
</p><p>44 The substitute synset is deter-  mined on the basis of its similarity with the synset in the test document. [sent-153, score-0.928]
</p><p>45 The synset that is replaced is referred to as an unseen synset as it is not known to the trained model. [sent-154, score-0.834]
</p><p>46 ” The synset of ‘beautiful’ is not present in the training corpus. [sent-162, score-0.402]
</p><p>47 We evaluate a similarity metric for all synsets in the training corpus with respect to the sense of beautiful and find that the sense of lovely is closest to it. [sent-163, score-0.919]
</p><p>48 Hence, the sense of beautiful in the test document is replaced by the sense of lovely which is present in the training corpus. [sent-164, score-0.542]
</p><p>49 The algorithm follows from the fact that the similarity value for a synset with itself is maximum. [sent-166, score-0.526]
</p><p>50 2  Similarity metrics used  We conduct different runs of the replacement algorithm using three similarity metrics, namely LIN’s similarity metric, Lesk similarity metric and Leacock and Chodorow (LCH) similarity metric. [sent-168, score-0.832]
</p><p>51 We compare the benefit of each of these metrics by studying their sentiment classification performance. [sent-170, score-0.608]
</p><p>52 To create the manually annotated corpus, two human annotators annotate words in the corpus with senses for two disjoint subsets of the original corpus by Ye et al. [sent-185, score-0.44]
</p><p>53 88 Table 1: Annotation Statistics for IWSD; P- Precision,RRecall The second variant of the corpus contains word senses obtained from automatic disambiguation using IWSD. [sent-204, score-0.442]
</p><p>54 Table 1 shows that the F-score for noun synsets is high while that for adjective synsets is the lowest among all. [sent-206, score-0.557]
</p><p>55 The low recall for adjective POS based synsets can be detrimental to classification since adjectives are known to express direct sentiment (Pang et al. [sent-207, score-0.891]
</p><p>56 Hence, in the context of sentiment classification, disambiguation of adjective synsets is more critical as compared to disambigua-  tion of noun synsets. [sent-209, score-0.802]
</p><p>57 We choose to use SVM since it performs the best for sentiment classification (Pang et al. [sent-212, score-0.487]
</p><p>58 The words are not stemmed since stemming is known to be detrimental to sentiment classification (Leopold and Kindermann, 2002). [sent-216, score-0.522]
</p><p>59 46  Precision (%), NP-  the synsetrepresentation, words inthecorpus are annotated with synset identifiers along with POS category identifiers. [sent-259, score-0.508]
</p><p>60 These synset identifiers along with POS category identifiers are then used as features. [sent-262, score-0.51]
</p><p>61 2% is observed in the accuracy of sentiment prediction when manually annotated sense-based features (M) are used in place of word-based features (Words). [sent-276, score-0.625]
</p><p>62 1086 While reported results suggest that it is more difficult to detect negative sentiment than positive sentiment (Gindl and Liegl, 2008), our results show that negative recall increases by around 8% in case of sense-based representation of documents. [sent-278, score-1.001]
</p><p>63 The combined model of words and manually annotated senses (Words + Senses (M)) gives the best performance with an accuracy of 90. [sent-279, score-0.493]
</p><p>64 The dimension of feature vector is  reduced by a factor of 82% when the document is represented in synset space. [sent-284, score-0.46]
</p><p>65 A comparison of accuracy of different sense representations in Table 2 shows that manual disambiguation performs better than using automatic algorithms like IWSD. [sent-286, score-0.386]
</p><p>66 2 POS-wise analysis For each POS, we compare the performance of two models: •  Model trained on words of only that POS  •  Model trained on word senses of only that POS  Figure 1 shows the parts-of-speech-wise classification accuracy of sentiment classification for senses (manual) and words. [sent-293, score-1.3]
</p><p>67 But it can be seen that disambiguation of adverb and verb synsets impact the performance of SA higher than disambiguation of nouns and adjectives. [sent-295, score-0.56]
</p><p>68 The results prove that sentiment may be subtle at times and not expressed directly through adjectives. [sent-297, score-0.393]
</p><p>69 As manual sense annotation is an effort and cost intensive process, the parts-of-speech-wise results suggest improvements expected from an automatic WSD engine so that it can aid sentiment classification. [sent-298, score-0.751]
</p><p>70 Table 1 suggests that the WSD engine works better for noun synsets compared to adjective and adverb synsets. [sent-299, score-0.457]
</p><p>71 It should be noted that adverb and verb synsets play an important role in negative class detection. [sent-322, score-0.384]
</p><p>72 A SA sys-  tem trained on 100 training samples using manually annotated senses gives an accuracy of 87%. [sent-342, score-0.534]
</p><p>73 This implies that the synset space, in addition to benefit to sentiment prediction in general, requires lesser number of training samples in order to achieve the accuracy that lexeme space can achieve with a larger number of samples. [sent-346, score-1.058]
</p><p>74 4  Effect of Partial disambiguation  Figure 2 shows the accuracy, positive F-score and negative F-score with respect to different thresholds of candidate senses for partially disambiguated documents as described in Section 3. [sent-348, score-0.7]
</p><p>75 We compare the performance of these documents with word-based features (B) and sense-based features based on manually (M) or automatically obtained senses (I). [sent-350, score-0.495]
</p><p>76 In case of partial disambiguation using manual  annotation, disambiguating words with less than three candidate senses performs better than others. [sent-352, score-0.564]
</p><p>77 Our results show that even if highly ambiguous (in terms of senses) words are not disambiguated by a WSD engine, the performance of sentiment classification improves. [sent-356, score-0.57]
</p><p>78 5 Synset replacement using similarity metrics Table 5 shows the results of synset replacement ex-  periments performed using similarity metrics defined in section 4. [sent-359, score-1.152]
</p><p>79 The similarity metric value NA shown in the table indicates that synset replacement is not performed for the specific run of experiment. [sent-360, score-0.759]
</p><p>80 However, the improvement in classification accuracy is marginal compared to sense-based representation without synset replacement (Similarity Metric=NA). [sent-363, score-0.728]
</p><p>81 The limited improvement can be due to the fact that since LCH and LIN consider only IS-A  6Results based on LCH  and LIN similarity metric for automatic sense disambiguation is not statistically significant with α=0. [sent-366, score-0.463]
</p><p>82 1089 7 Error Analysis For sentiment classification based on semantic space, we classify the errors into four categories. [sent-450, score-0.487]
</p><p>83 Effect of low disambiguation accuracy of IWSD engine: SA using automatic sense annotation depends on the annotation system used. [sent-453, score-0.41]
</p><p>84 To assess the impact of IWSD system on sentiment classification, we compare the feature set based on manually annotated senses with the feature set based on automatically annotated senses. [sent-454, score-0.911]
</p><p>85 Table 6 shows the number of top informative features (synset) selected as the percentage of total synset features present  when the semantic representation of documentation is used. [sent-456, score-0.474]
</p><p>86 The matched synset column represents the number of IWSD synsets that match with manually annotated synsets. [sent-457, score-0.766]
</p><p>87 The reduction in the performance of SA for automatically annotated senses is because of the number of unmatched synsets. [sent-460, score-0.385]
</p><p>88 Thus, although the accuracy of IWSD is currently 70%, the table indicates that IWSD can match the performance of manually annotated senses for SA if IWSD is able to tag correctly those top information content synsets. [sent-461, score-0.493]
</p><p>89 Negation Handling: For the purpose of this work, we concentrate on words as units for sentiment determination. [sent-464, score-0.393]
</p><p>90 Syntax and its contribution in understanding sentiment is neglected  and hence, positive documents which contain negations are wrongly classified as negative. [sent-465, score-0.47]
</p><p>91 However, reviews are generic in nature and tend to express contrasting sentiment about sub-topics . [sent-481, score-0.446]
</p><p>92 Assigning an overall sentiment to a document is subjective in such cases. [sent-484, score-0.451]
</p><p>93 1090 8 Conclusion & Future Work This work presents an empirical benefit of WSD to sentiment analysis. [sent-485, score-0.442]
</p><p>94 The study shows that supervised sentiment classifier modeled on wordNet senses perform better than word-based features. [sent-486, score-0.755]
</p><p>95 Our results support the fact that not only does sense space improve the performance of a sentiment classification system, but also opens opportunities for improvement using better similarity metrics. [sent-489, score-0.819]
</p><p>96 Another line of work is in the context of cross-lingual sentiment analysis. [sent-492, score-0.393]
</p><p>97 An adapted lesk algorithm for word sense disambiguation using wordnet. [sent-504, score-0.389]
</p><p>98 Evaluation of different sentiment detection methods for polarity classification on web-based reviews, pages 35–43. [sent-521, score-0.566]
</p><p>99 Domain-specific word sense disambiguation combining corpus basedand wordnet based parameters. [sent-528, score-0.459]
</p><p>100 Combining local context with wordnet similarity for word sense identification. [sent-533, score-0.474]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('synset', 0.402), ('sentiment', 0.393), ('senses', 0.333), ('iwsd', 0.261), ('synsets', 0.257), ('replacement', 0.179), ('sense', 0.176), ('wordnet', 0.174), ('wsd', 0.159), ('similarity', 0.124), ('disambiguation', 0.109), ('lesk', 0.104), ('engine', 0.098), ('classification', 0.094), ('sa', 0.093), ('lexeme', 0.088), ('lch', 0.087), ('temp', 0.087), ('disambiguated', 0.083), ('polarity', 0.079), ('pang', 0.076), ('khapra', 0.075), ('disambiguating', 0.074), ('metrics', 0.072), ('albornoz', 0.07), ('carrillo', 0.07), ('negative', 0.068), ('fell', 0.067), ('concept', 0.067), ('bombay', 0.06), ('iit', 0.06), ('adverb', 0.059), ('document', 0.058), ('manually', 0.055), ('identifiers', 0.054), ('metric', 0.054), ('accuracy', 0.053), ('reviews', 0.053), ('akkaya', 0.052), ('deadly', 0.052), ('lovely', 0.052), ('annotated', 0.052), ('beautiful', 0.05), ('benefit', 0.049), ('manual', 0.048), ('travel', 0.047), ('leacock', 0.047), ('adjective', 0.043), ('positive', 0.042), ('samples', 0.041), ('pos', 0.041), ('fscore', 0.041), ('concepts', 0.038), ('recall', 0.037), ('unknown', 0.037), ('annotation', 0.036), ('features', 0.036), ('ye', 0.036), ('documents', 0.035), ('crude', 0.035), ('detrimental', 0.035), ('gindl', 0.035), ('leopold', 0.035), ('liegl', 0.035), ('mumbai', 0.035), ('rentoumi', 0.035), ('sensebased', 0.035), ('vulgar', 0.035), ('space', 0.032), ('lin', 0.032), ('chodorow', 0.032), ('adjectives', 0.032), ('scenario', 0.032), ('precision', 0.032), ('conduct', 0.031), ('opportunity', 0.03), ('thumbs', 0.03), ('mitigate', 0.03), ('paris', 0.03), ('na', 0.03), ('pushpak', 0.03), ('excerpt', 0.03), ('whitelaw', 0.03), ('disambiguates', 0.03), ('interjections', 0.03), ('mitesh', 0.03), ('vanilla', 0.03), ('respect', 0.03), ('replaced', 0.03), ('pedersen', 0.029), ('supervised', 0.029), ('identifier', 0.028), ('lillian', 0.028), ('kennedy', 0.027), ('offset', 0.027), ('harnessing', 0.027), ('nf', 0.027), ('wiebe', 0.026), ('impact', 0.026), ('carry', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="63-tfidf-1" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>Author: Balamurali AR ; Aditya Joshi ; Pushpak Bhattacharyya</p><p>Abstract: Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. We propose semantic features using word senses for a supervised document-level sentiment classifier. To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. We per- form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. The results show promising improvement with respect to the baseline.</p><p>2 0.25690591 <a title="63-tfidf-2" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>Author: Ainur Yessenalina ; Claire Cardie</p><p>Abstract: We present a general learning-based approach for phrase-level sentiment analysis that adopts an ordinal sentiment scale and is explicitly compositional in nature. Thus, we can model the compositional effects required for accurate assignment of phrase-level sentiment. For example, combining an adverb (e.g., “very”) with a positive polar adjective (e.g., “good”) produces a phrase (“very good”) with increased polarity over the adjective alone. Inspired by recent work on distributional approaches to compositionality, we model each word as a matrix and combine words using iterated matrix multiplication, which allows for the modeling of both additive and multiplicative semantic effects. Although the multiplication-based matrix-space framework has been shown to be a theoretically elegant way to model composition (Rudolph and Giesbrecht, 2010), training such models has to be done carefully: the optimization is nonconvex and requires a good initial starting point. This paper presents the first such algorithm for learning a matrix-space model for semantic composition. In the context of the phrase-level sentiment analysis task, our experimental results show statistically significant improvements in performance over a bagof-words model.</p><p>3 0.23001069 <a title="63-tfidf-3" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>Author: Richard Socher ; Jeffrey Pennington ; Eric H. Huang ; Andrew Y. Ng ; Christopher D. Manning</p><p>Abstract: We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model’s ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.</p><p>4 0.20489283 <a title="63-tfidf-4" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: In this paper, we propose a novel topic model based on incorporating dictionary definitions. Traditional topic models treat words as surface strings without assuming predefined knowledge about word meaning. They infer topics only by observing surface word co-occurrence. However, the co-occurred words may not be semantically related in a manner that is relevant for topic coherence. Exploiting dictionary definitions explicitly in our model yields a better understanding of word semantics leading to better text modeling. We exploit WordNet as a lexical resource for sense definitions. We show that explicitly modeling word definitions helps improve performance significantly over the baseline for a text categorization task.</p><p>5 0.20038266 <a title="63-tfidf-5" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>6 0.13997267 <a title="63-tfidf-6" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>7 0.12721583 <a title="63-tfidf-7" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>8 0.12055632 <a title="63-tfidf-8" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>9 0.082827918 <a title="63-tfidf-9" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>10 0.081492051 <a title="63-tfidf-10" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>11 0.080246054 <a title="63-tfidf-11" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>12 0.065568775 <a title="63-tfidf-12" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>13 0.064370692 <a title="63-tfidf-13" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>14 0.063497603 <a title="63-tfidf-14" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>15 0.060104325 <a title="63-tfidf-15" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>16 0.058468122 <a title="63-tfidf-16" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>17 0.055834927 <a title="63-tfidf-17" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>18 0.054419201 <a title="63-tfidf-18" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>19 0.052956525 <a title="63-tfidf-19" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>20 0.051979098 <a title="63-tfidf-20" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.2), (1, -0.234), (2, 0.054), (3, 0.023), (4, 0.418), (5, 0.104), (6, 0.107), (7, 0.106), (8, 0.047), (9, 0.03), (10, 0.085), (11, 0.096), (12, -0.001), (13, 0.109), (14, 0.019), (15, 0.03), (16, -0.04), (17, -0.053), (18, 0.047), (19, -0.006), (20, -0.108), (21, -0.047), (22, 0.058), (23, 0.045), (24, -0.044), (25, 0.069), (26, 0.063), (27, 0.016), (28, 0.0), (29, -0.11), (30, -0.048), (31, -0.016), (32, -0.066), (33, 0.066), (34, -0.05), (35, 0.069), (36, 0.027), (37, -0.08), (38, 0.008), (39, -0.001), (40, 0.127), (41, -0.013), (42, -0.003), (43, 0.075), (44, -0.036), (45, 0.031), (46, 0.009), (47, 0.068), (48, -0.058), (49, -0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95716429 <a title="63-lsi-1" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>Author: Balamurali AR ; Aditya Joshi ; Pushpak Bhattacharyya</p><p>Abstract: Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. We propose semantic features using word senses for a supervised document-level sentiment classifier. To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. We per- form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. The results show promising improvement with respect to the baseline.</p><p>2 0.75646538 <a title="63-lsi-2" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>3 0.74544853 <a title="63-lsi-3" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>Author: Richard Socher ; Jeffrey Pennington ; Eric H. Huang ; Andrew Y. Ng ; Christopher D. Manning</p><p>Abstract: We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model’s ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.</p><p>4 0.73991555 <a title="63-lsi-4" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>Author: Ainur Yessenalina ; Claire Cardie</p><p>Abstract: We present a general learning-based approach for phrase-level sentiment analysis that adopts an ordinal sentiment scale and is explicitly compositional in nature. Thus, we can model the compositional effects required for accurate assignment of phrase-level sentiment. For example, combining an adverb (e.g., “very”) with a positive polar adjective (e.g., “good”) produces a phrase (“very good”) with increased polarity over the adjective alone. Inspired by recent work on distributional approaches to compositionality, we model each word as a matrix and combine words using iterated matrix multiplication, which allows for the modeling of both additive and multiplicative semantic effects. Although the multiplication-based matrix-space framework has been shown to be a theoretically elegant way to model composition (Rudolph and Giesbrecht, 2010), training such models has to be done carefully: the optimization is nonconvex and requires a good initial starting point. This paper presents the first such algorithm for learning a matrix-space model for semantic composition. In the context of the phrase-level sentiment analysis task, our experimental results show statistically significant improvements in performance over a bagof-words model.</p><p>5 0.68148994 <a title="63-lsi-5" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>Author: Song Feng ; Ritwik Bose ; Yejin Choi</p><p>Abstract: In this paper, we introduce a connotation lexicon, a new type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war). Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment. Understanding the connotation of words would seem to require common sense and world knowledge. However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner. The key linguistic insight behind our approach is selectional preference of connotative predicates. We present graphbased algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates. Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons.</p><p>6 0.42038691 <a title="63-lsi-6" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>7 0.41420817 <a title="63-lsi-7" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>8 0.40344688 <a title="63-lsi-8" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>9 0.38359037 <a title="63-lsi-9" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>10 0.38188267 <a title="63-lsi-10" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>11 0.35900542 <a title="63-lsi-11" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>12 0.31152129 <a title="63-lsi-12" href="./emnlp-2011-Analyzing_Methods_for_Improving_Precision_of_Pivot_Based_Bilingual_Dictionaries.html">18 emnlp-2011-Analyzing Methods for Improving Precision of Pivot Based Bilingual Dictionaries</a></p>
<p>13 0.28273475 <a title="63-lsi-13" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>14 0.28271675 <a title="63-lsi-14" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>15 0.25673276 <a title="63-lsi-15" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>16 0.2495963 <a title="63-lsi-16" href="./emnlp-2011-Exploiting_Syntactic_and_Distributional_Information_for_Spelling_Correction_with_Web-Scale_N-gram_Models.html">55 emnlp-2011-Exploiting Syntactic and Distributional Information for Spelling Correction with Web-Scale N-gram Models</a></p>
<p>17 0.24093987 <a title="63-lsi-17" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>18 0.23388141 <a title="63-lsi-18" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>19 0.23372956 <a title="63-lsi-19" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>20 0.23114362 <a title="63-lsi-20" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(15, 0.024), (23, 0.107), (33, 0.016), (36, 0.024), (37, 0.017), (45, 0.082), (48, 0.359), (53, 0.03), (54, 0.024), (57, 0.015), (62, 0.023), (66, 0.024), (79, 0.042), (82, 0.014), (96, 0.054), (97, 0.023), (98, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.78370959 <a title="63-lda-1" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>Author: Lanjun Zhou ; Binyang Li ; Wei Gao ; Zhongyu Wei ; Kam-Fai Wong</p><p>Abstract: Polarity classification of opinionated sentences with both positive and negative sentiments1 is a key challenge in sentiment analysis. This paper presents a novel unsupervised method for discovering intra-sentence level discourse relations for eliminating polarity ambiguities. Firstly, a discourse scheme with discourse constraints on polarity was defined empirically based on Rhetorical Structure Theory (RST). Then, a small set of cuephrase-based patterns were utilized to collect a large number of discourse instances which were later converted to semantic sequential representations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification.</p><p>same-paper 2 0.65669745 <a title="63-lda-2" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>Author: Balamurali AR ; Aditya Joshi ; Pushpak Bhattacharyya</p><p>Abstract: Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. We propose semantic features using word senses for a supervised document-level sentiment classifier. To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. We per- form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. The results show promising improvement with respect to the baseline.</p><p>3 0.5825457 <a title="63-lda-3" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>Author: Amit Dubey ; Frank Keller ; Patrick Sturt</p><p>Abstract: This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chunker with a co-reference classifier. Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure. This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort. We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.</p><p>4 0.41293496 <a title="63-lda-4" href="./emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">94 emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>Author: Amal Al-Saif ; Katja Markert</p><p>Abstract: We present the first algorithms to automatically identify explicit discourse connectives and the relations they signal for Arabic text. First we show that, for Arabic news, most adjacent sentences are connected via explicit connectives in contrast to English, making the treatment of explicit discourse connectives for Arabic highly important. We also show that explicit Arabic discourse connectives are far more ambiguous than English ones, making their treatment challenging. In the second part of the paper, we present supervised algorithms to address automatic discourse connective identification and discourse relation recognition. Our connective identifier based on gold standard syntactic features achieves almost human performance. In addition, an identifier based solely on simple lexical and automatically derived morphological and POS features performs with high reliability, essential for languages that do not have high-quality parsers yet. Our algorithm for recognizing discourse relations performs significantly better than a baseline based on the connective surface string alone and therefore reduces the ambiguity in explicit connective interpretation.</p><p>5 0.39705232 <a title="63-lda-5" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>6 0.39421076 <a title="63-lda-6" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>7 0.39394754 <a title="63-lda-7" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>8 0.39344802 <a title="63-lda-8" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>9 0.39139315 <a title="63-lda-9" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>10 0.38883674 <a title="63-lda-10" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>11 0.38866001 <a title="63-lda-11" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>12 0.38823271 <a title="63-lda-12" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>13 0.38821456 <a title="63-lda-13" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>14 0.38749415 <a title="63-lda-14" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>15 0.38647345 <a title="63-lda-15" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>16 0.38608438 <a title="63-lda-16" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>17 0.38476589 <a title="63-lda-17" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>18 0.38467112 <a title="63-lda-18" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>19 0.38464814 <a title="63-lda-19" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>20 0.38359204 <a title="63-lda-20" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
