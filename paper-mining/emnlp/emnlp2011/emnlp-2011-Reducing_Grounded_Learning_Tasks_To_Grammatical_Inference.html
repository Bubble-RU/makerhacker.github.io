<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-111" href="#">emnlp2011-111</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</h1>
<br/><p>Source: <a title="emnlp-2011-111-pdf" href="http://aclweb.org/anthology//D/D11/D11-1131.pdf">pdf</a></p><p>Author: Benjamin Borschinger ; Bevan K. Jones ; Mark Johnson</p><p>Abstract: It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.1</p><p>Reference: <a title="emnlp-2011-111-reference" href="../emnlp2011_reference/emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 au Abstract It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. [sent-4, score-0.217]
</p><p>2 In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. [sent-5, score-0.399]
</p><p>3 We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the  literature. [sent-6, score-0.314]
</p><p>4 something that maps natural language expressions such as sentences into meaning representations such as logical forms. [sent-10, score-0.087]
</p><p>5 Obviously, this learning can neither take place in a fully supervised nor in a fully unsupervised fashion: the learner does not ‘hear’ the meanings ofthe sentences she observes, but she is also not treating them as merely meaningless strings. [sent-11, score-0.142]
</p><p>6 to  to  the linguistic input she  In this sense, learning a semantic parser seems to go beyond the well-studied task of unsupervised grammar induction. [sent-23, score-0.31]
</p><p>7 It involves not only learning a grammar for the form-side of language, i. [sent-24, score-0.085]
</p><p>8 language expressions such as sentences, but also the ‘grounding’ of this structure in meaning representations. [sent-26, score-0.087]
</p><p>9 It requires going beyond the mere linguistic input to incorporate, for example, perceptual information that provides a clue to the meaning of the observed forms. [sent-27, score-0.18]
</p><p>10 For this reason, probably, approaches to the task of learning a semantic parser employ a variety of sophisticated and task-specific techniques that go beyond (but often elaborate on)  the techniques used for grammatical inference (Lu et al. [sent-30, score-0.316]
</p><p>11 In this paper, we show that one can reduce the task of learning a semantic parser to a Probabilistic Context Free Grammar (PCFG) learning task, and more generally, that grounded learning tasks are not in principle beyond the scope of grammatical inference techniques. [sent-34, score-0.512]
</p><p>12 In particular, we show how to formulate the task of learning a semantic parser as discussed by Chen, Kim and Mooney (2008, 2010) as the task of learning a PCFG from strings. [sent-35, score-0.116]
</p><p>13 We demonstrate that a slight modification to our model so that it also learns the language’s canonical word order improves its performance even beyond the best results previously reported in the literature. [sent-40, score-0.128]
</p><p>14 This  language-independent and linguistically well motivated elaboration allows the model to learn a global fact about the language’s syntax, its canonical word order. [sent-41, score-0.141]
</p><p>15 We provide an illustration of how to reduce grounded learning tasks to grammatical inference. [sent-43, score-0.32]
</p><p>16 Secondly, we show that extending the model so that it can learn linguistically well motivated generalizations such as the canonical word order can lead to better results. [sent-44, score-0.141]
</p><p>17 Finally, we explain how to let our model additionally learn the language’s canonical word order. [sent-48, score-0.141]
</p><p>18 2  Previous Work by Chen, Kim and Mooney  In a series of recent papers, Chen, Kim and Mooney approach the task of learning a semantic parser from ambiguous training data (Chen and Mooney, 2008; Kim and Mooney, 2010; Chen et al. [sent-49, score-0.168]
</p><p>19 This  goes beyond previous work on semantic parsing such as Lu et al. [sent-51, score-0.138]
</p><p>20 (2008) or Zettlemoyer and Collins (2005) which rely on unambiguous training data where every sentence is paired only with its meaning. [sent-52, score-0.1]
</p><p>21 We acknowledge that semantic parsing constitutes a very limited kind of grounded learning but want to point out that the task has been introduced as an instance of grounded learning in the previous literature such as Chen and Mooney (2008). [sent-54, score-0.564]
</p><p>22 1417 and the correct meaning might not even be in this set. [sent-55, score-0.126]
</p><p>23 The comments are recorded with a time-stamp and then associated with all game events automatically extracted from the games which occured up to five seconds before the comment was made. [sent-57, score-0.209]
</p><p>24 This leads to an ambigu-  ous pairing of comments with candidate meanings that can be considered similar to the "linguistic input in the context of a rich, relevant, perceptual environment" to which real language learners probably have access (Chen and Mooney, 2008). [sent-58, score-0.235]
</p><p>25 Due to the fact that some comments refer to events not detected by their extraction-algorithm, not every natural language sentence has a gold matching meaning representation. [sent-60, score-0.223]
</p><p>26 In addition to the inherent ambiguity of the training examples, the learner therefore has to somehow deal with those examples which only have ‘wrong’ meanings associated with them. [sent-61, score-0.185]
</p><p>27 1 The parsing task Learning a semantic parser from the ambiguous data is, in fact, just one of three tasks discussed by Kim and Mooney (2010), henceforth KM. [sent-67, score-0.217]
</p><p>28 (2010) except for minimal differences in the number of training examples (we give one more for every English training set, and one more for the 2004 Korean training set). [sent-80, score-0.1]
</p><p>29 (2008) and is a generative model which defines a joint probability distribution over natural language sentences (NLs), meaning representations (MRs) and hybrid trees. [sent-85, score-0.151]
</p><p>30 The NLs are the natural language comments to the games, the MRs are simple logical formulae describing game events and playing the role of sentence meanings, and a hybrid tree is a tree structure that represents the correspondence between a sentence and its meaning. [sent-86, score-0.223]
</p><p>31 4 An example hybrid tree for the pair hTHE PINK GOALIE PASSES THE BALL TO PthIeNK p1ai 1r ,pass(pink1 ,pink1 1)i is given in Figure 1. [sent-88, score-0.104]
</p><p>32 Outside algorithm which deals with the hybrid tree structure and takes into account the ambiguity of the training examples. [sent-90, score-0.147]
</p><p>33 In addition to learning directly from the ambiguous training data, they also train a semantic parser in a supervised fashion on data that has been previously disambiguated by their matching model. [sent-91, score-0.168]
</p><p>34 Consequently, there are two scores for each of the 4We use SMALL CAPS for words, sans serif for MRs and MR constituents (concepts), and italics for non-terminals and Grammars. [sent-93, score-0.094]
</p><p>35 1418 S  S → pass PLAYER PLAYER PLAYER PLAYER  →  pink1  THE PINK GOALIE  PASSES  THE BALL TO  PLAYER PLAYER  →  pink1 1  PINK1 1  Figure 1: A hybrid tree for the sentence-meaning pair hTHE PINK GOALIE PASSES THE BALL TO PINK1h 1,pass(pink1 ,pink1 1)i . [sent-94, score-0.159]
</p><p>36 The internal nodes correspond ptoa tshse( p riunleks1 ,upsiendk 1to1 )die r. [sent-95, score-0.087]
</p><p>37 In effect, we show via construction that ‘grounded’ learning tasks such as learning a semantic parser from semantically enriched and ambiguous data can be reduced to ‘ungrounded’ tasks such as grammatical inference. [sent-102, score-0.296]
</p><p>38 Instead of taking the internal nodes of the trees generated by our model as corresponding to MG  production rules, we take them to correspond to MR constituents. [sent-103, score-0.087]
</p><p>39 The remaining three MR constituents correspond to the root’s daughters which we label Phrasepink1, Phrasepass and Phrasepink11. [sent-108, score-0.185]
</p><p>40 Generally speaking, we assume a special non-terminal Sm for every MR m generated by the MG, and a special non-terminal Phrasecon for each of the terminals of the MG (which loosely correspond to concepts). [sent-109, score-0.182]
</p><p>41 5 The tree’s terminals are the words that make up the sentence, and we assume them to be dominated by concept-specific pre-terminals Wordcon which correspond to concept-specific probability distributions over the language’s vocabulary. [sent-111, score-0.127]
</p><p>42 This process generates an arbitrary sequence of words semantically related to con, dominated by the corresponding pre-terminal Wordcon in our model, and words not directly semantically related to con, dominated by a special word pre-terminal Word∅. [sent-113, score-0.168]
</p><p>43 The sole further restriction is that every Phraseco∅n must contain at least one Wordcon. [sent-114, score-0.1]
</p><p>44 Trees like the one in Figure 2 can be generated by a Context-Free Grammar (CFG) which, in turn, can be trained on strings to yield a PCFG which embod5This grammar is given in the Appendix to Chen et al. [sent-115, score-0.085]
</p><p>45 1419 ies a semantic parser as will be discussed in Section 3. [sent-117, score-0.116]
</p><p>46 Every training example consists of a natural language string (the for–  mal information) and a set of candidate meanings for the string (the semantic information, its context), allowing for the possibility that none of the meanings in the context is the correct one. [sent-122, score-0.411]
</p><p>47 In order to learn from data like this within a grammatical inference framework, we have to encode the semantic information as part of the string. [sent-123, score-0.231]
</p><p>48 A sentence’s context constrains which of the many possible meanings might be expressed by the string. [sent-125, score-0.181]
</p><p>49 If the context-identifier introduced  for this context  6If we  is C1, we require  the  were to consider every possible context, we would have to consider contexts because the MG generates 2048 MRs. [sent-141, score-0.15]
</p><p>50 To enable it to do this, our grammar allows every Wordx non-terminal to be rewritten as every word of the language. [sent-163, score-0.285]
</p><p>51 Since there are sentences in the training data without the correct meaning in their context, we want to give our model the possibility of not assigning to a sentence any of the MRs licensed by its contextidentifier. [sent-164, score-0.087]
</p><p>52 al and assume a special null meaning ∅ to be present in every context. [sent-166, score-0.187]
</p><p>53 As a last complication, we deal with the fact that syntactic constituents are linearized with respect to each other. [sent-169, score-0.129]
</p><p>54 For example, if an MR has 3 proper constituents (i. [sent-170, score-0.094]
</p><p>55 excluding the MR itself), our grammar allows the corresponding 3 syntactic constituents which we might label Phrasepredicate, Phrasearg1 –  and Phrasearg2 to occur in any of the 6 possible orders. [sent-172, score-0.218]
</p><p>56 Therefore, we have an Sm rule for every context in which m occurs and for every possible order of the proper constituents of m. [sent-173, score-0.294]
</p><p>57 7 Instantiating all those schemata leads to a grammar with 33,101 rules for the English data and 30,731 rules for the Korean data. [sent-175, score-0.258]
</p><p>58 After training, the resulting PCFG embodies a semantic parser in the sense that, with a slight modification we describe in section 3. [sent-178, score-0.116]
</p><p>59 3, it can be used to parse a string into its meaning representation by determining the most likely syntactic analysis and reading offthe meaning assigned by our model at the Sm-node. [sent-179, score-0.211]
</p><p>60 To this we reply firstly, that it is true that our reduction only works for offline or batch grounded learning tasks where all the data is available to the model before the actual learning begins so that it ‘knows’ the words, the meanings and the contexts present in the data. [sent-183, score-0.423]
</p><p>61 First of all, the many specific Sm-rewrite rules reduce to the heuristic that every semantic constituent should correspond to a syntactic constituent, and the fact that natural language expressions are linearly ordered. [sent-186, score-0.253]
</p><p>62 –  7In our description,  we use context-identifiers such as C1 with a systematic ambiguity, letting them stand for the terminal symbol representing a context and, in contexts such as m∈C1,  for the represented  context  itself. [sent-188, score-0.164]
</p><p>63 1421 It simply allows for the constituents of an MR to occur in every possible order which is a very unbiased and empiricist assumption. [sent-189, score-0.194]
</p><p>64 The many re-write rules for the pre-terminal Wordxs are nothing but an explicit version of the assumption that every word the model encounters might, in principle, be semantically related to every concept it knows. [sent-195, score-0.349]
</p><p>65 Finally, the complicated looking set of rules for the internal structure of Phrasexs corresponds to a simple unigram Markov-process for generating strings. [sent-197, score-0.093]
</p><p>66 3 Training and Evaluation The CFG described in the previous section is trained on the same training data used by KM, except that we reduce it to strings (without changing the information present in the original data) by prefixing every sentence with a context-identifier. [sent-200, score-0.1]
</p><p>67 To deal with the fact that the model might not observe certain meanings during training, we apply a simple smoothing technique by using a Dirichlet prior of α=0. [sent-203, score-0.181]
</p><p>68 This is done because the task of a semantic parser is to establish a mapping between NLs and MRs, irrespective of contexts which were only used for learning the parser and should not play a role in its final performance. [sent-219, score-0.229]
</p><p>69 10 Note that the context-deletion (and the simple smoothing) enables NoWo-PCFG to parse sentences into meanings not present in the data it was trained on which, in fact, happens. [sent-221, score-0.142]
</p><p>70 For example, there are 81 meanings in the training data for the first English 9We experimented with α=0. [sent-222, score-0.142]
</p><p>71 The PCFG trained on games 2, 3 and 4 is still able to correctly assign 12 of those 81 meanings which it has not seen during the training phase which shows the effectiveness of the bottom-up constraint. [sent-230, score-0.222]
</p><p>72 This shows that it is not only possible to reduce the task of learning a semantic parser to standard grammatical inference, but that this way of approaching the problem yields comparable results. [sent-257, score-0.205]
</p><p>73 The remainder of the paper focuses on our second main point: that letting the model learn additional kinds of information, such as the language’s canonical word order, can further improve its performance. [sent-258, score-0.212]
</p><p>74 4  Extending NoWo-PCFG to WO-PCFG  We already pointed out that our model considers every possible linear order of syntactic constituents. [sent-260, score-0.1]
</p><p>75 It seems, however, to be at least a soft fact about languages that they do have a canonical word order that is more likely to be realized in its sentences than any other possible word order. [sent-263, score-0.092]
</p><p>76 In order to test whether trying to learn this order helps our model, we modify the CFG used for NoWo-PCFG so it can learn word order generalizations, and train it in the same way to yield another semantic parser, WO-PCFG. [sent-264, score-0.151]
</p><p>77 1 Setting up WO-PCFG For every possible ordering of the constituents corresponding to an MR, our grammar contains a rule. [sent-266, score-0.279]
</p><p>78 In NoWo-PCFG, these different rules all share the same parent which prevents the model from learning the probability of the different word orders corresponding to the many rules. [sent-267, score-0.089]
</p><p>79 A straight-forward way to overcome this is to annotate every Sm node with the word order of its daughter. [sent-268, score-0.1]
</p><p>80 We split every Sm non-terminal in multiple Swo non-terminals, m  {v,sv,vs,svo,sov,osv,ovs,vso,vos}  where wo ∈ indicwahteesr et wheo li ∈ne {avr, sovr,dvesr,s voof, sthove, ocsovn,osvtistu,vesnots,v othse} nonterminal rewrites as. [sent-269, score-0.31]
</p><p>81 To model that whenever it encounters a specific example that is indicative of a certain word order, this word order becomes slightly more probable for every other example as well, we have to make a further slight change to the CFG which we now describe. [sent-271, score-0.157]
</p><p>82 We introduce six new non-terminals, corresponding to the six possible word orders SVO, SOV, VSO, VOS, OSV and OVS and require every Swo nonterminal to be dominated by the compatible with its daughters linear order. [sent-273, score-0.285]
</p><p>83 WO is the set of word order non-terminals { SV O, SOV, OSV, OV S, V SO, V OS}, WOS is the set of word order annotations {v, sv, vs, svo, svo, ovs, osv, vso, vos } . [sent-278, score-0.089]
</p><p>84 We take x ⊂ wo to mean that x is compatible with wo, where v is compatible vwsi,thsv aoll, swvoor,do vosr,deorsvs, sv ois, compatible kweit hx S ⊂VO w,SoO tVo maneadn nO thSaVt, xan ids so on. [sent-279, score-0.444]
</p><p>85 All other symbols have the same  meaning  as  explained in Figure 3. [sent-281, score-0.087]
</p><p>86 More generally, every word order non-terminal can rewrite as any of the Swo non-terminals that are compatible with it. [sent-286, score-0.16]
</p><p>87 Adding this additional layer of word order abstraction leads to a grammar with 36,019 rules for English and a grammar with 33,715 rules for Korean. [sent-287, score-0.276]
</p><p>88 Those scores are, to our knowl-  edge, the highest scores previously reported for this parsing task and establish our second main point: letting the model learn the language’s word order in addition to learning the mapping from sentences to MR increases semantic parsing accuracy. [sent-292, score-0.271]
</p><p>89 It differs, however, in that it can only learn one generalization for each predicate type and no language wide generalization. [sent-296, score-0.11]
</p><p>90 The usefulness of this kind of information is impressive for English, it improves the accuracy of semantic parsing by almost 12% in F-measure and for Korean by 11. [sent-298, score-0.102]
</p><p>91 The overall slightly worse performance of our system on Korean data might stem from the fact that Korean, unlike English, has a rich morphology, and that our model does not learn anything about morphology at all. [sent-305, score-0.088]
</p><p>92 We plan on further investigating effects like this in the future, as well as applying more advanced grammatical inference algorithms. [sent-306, score-0.129]
</p><p>93 5  Conclusion and Future Work  We have shown that certain grounded learning tasks such as learning a semantic parser from semantically enriched training data can be reduced to a grammatical inference problem over strings. [sent-307, score-0.515]
</p><p>94 This allows for the application of techniques and insights developed for grammatical inference to grounded learning tasks. [sent-308, score-0.36]
</p><p>95 In addition, we have shown that letting the model learn the language’s canonical word order improves parsing performance, beyond the top scores previously reported, thus illustrating the usefullnes of linguistic knowledge for tasks like this. [sent-309, score-0.297]
</p><p>96 In future research, we plan to address the limitation of our model to a finite set of meaning representations, in particular through the use of nonparametric Bayesian models such as the Infinite PCFG model of Liang et al. [sent-310, score-0.087]
</p><p>97 Learning to sportscast: A test of grounded language acquisition. [sent-326, score-0.231]
</p><p>98 Training a multilingual sportscaster: Using perceptual context to learn language. [sent-332, score-0.106]
</p><p>99 Generative alignment and semantic parsing for learning from 1425 ambiguous supervision. [sent-362, score-0.154]
</p><p>100 A generative model for parsing natural language to meaning representations. [sent-383, score-0.136]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mrs', 0.325), ('mr', 0.323), ('korean', 0.241), ('grounded', 0.231), ('wo', 0.21), ('mooney', 0.183), ('mg', 0.172), ('meanings', 0.142), ('phrasep', 0.133), ('kim', 0.124), ('pcfg', 0.123), ('goalie', 0.111), ('pink', 0.111), ('chen', 0.109), ('player', 0.104), ('sm', 0.103), ('every', 0.1), ('cfg', 0.1), ('constituents', 0.094), ('canonical', 0.092), ('grammatical', 0.089), ('nls', 0.089), ('phrasecon', 0.089), ('phrasex', 0.089), ('vos', 0.089), ('vso', 0.089), ('meaning', 0.087), ('km', 0.087), ('grammar', 0.085), ('games', 0.08), ('ball', 0.08), ('passes', 0.075), ('letting', 0.071), ('hthe', 0.067), ('ohns', 0.067), ('osv', 0.067), ('ovs', 0.067), ('phrasepass', 0.067), ('phx', 0.067), ('phxpass', 0.067), ('schemata', 0.067), ('spass', 0.067), ('swo', 0.067), ('wordx', 0.067), ('svo', 0.064), ('hybrid', 0.064), ('parser', 0.063), ('predicate', 0.061), ('mm', 0.06), ('compatible', 0.06), ('encounters', 0.057), ('perceptual', 0.057), ('infinite', 0.056), ('pass', 0.055), ('sv', 0.054), ('rules', 0.053), ('semantic', 0.053), ('au', 0.052), ('ambiguous', 0.052), ('contexts', 0.05), ('comment', 0.05), ('learn', 0.049), ('parsing', 0.049), ('tt', 0.047), ('correspond', 0.047), ('johnson', 0.045), ('sov', 0.045), ('dominated', 0.045), ('bevan', 0.044), ('daughters', 0.044), ('greenberg', 0.044), ('joohyun', 0.044), ('phxx', 0.044), ('pphhxx', 0.044), ('pwhoxrdx', 0.044), ('wordcon', 0.044), ('wordpass', 0.044), ('wos', 0.044), ('terminal', 0.043), ('ambiguity', 0.043), ('game', 0.043), ('lu', 0.042), ('internal', 0.04), ('inference', 0.04), ('tree', 0.04), ('might', 0.039), ('semantically', 0.039), ('root', 0.038), ('seems', 0.038), ('lari', 0.038), ('observes', 0.038), ('string', 0.037), ('comments', 0.036), ('orders', 0.036), ('beyond', 0.036), ('go', 0.035), ('terminals', 0.035), ('mq', 0.035), ('linearized', 0.035), ('cience', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999911 <a title="111-tfidf-1" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>Author: Benjamin Borschinger ; Bevan K. Jones ; Mark Johnson</p><p>Abstract: It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.1</p><p>2 0.15702847 <a title="111-tfidf-2" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>Author: Wei Lu ; Hwee Tou Ng</p><p>Abstract: This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus. The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences. Sentences can then be generated based on such grammar rules with a log-linear model. To acquire such grammar rules automatically in an unsupervised manner, we also propose a novel approach with a generative model, which maps from sub-expressions of logical forms to word sequences in natural language sentences. Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.</p><p>3 0.098279692 <a title="111-tfidf-3" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>Author: Federico Sangati ; Willem Zuidema</p><p>Abstract: We present a novel approach to Data-Oriented Parsing (DOP). Like other DOP models, our parser utilizes syntactic fragments of arbitrary size from a treebank to analyze new sentences, but, crucially, it uses only those which are encountered at least twice. This criterion allows us to work with a relatively small but representative set of fragments, which can be employed as the symbolic backbone of several probabilistic generative models. For parsing we define a transform-backtransform approach that allows us to use standard PCFG technology, making our results easily replicable. According to standard Parseval metrics, our best model is on par with many state-ofthe-art parsers, while offering some complementary benefits: a simple generative probability model, and an explicit representation of the larger units of grammar.</p><p>4 0.090158887 <a title="111-tfidf-4" href="./emnlp-2011-Computation_of_Infix_Probabilities_for_Probabilistic_Context-Free_Grammars.html">31 emnlp-2011-Computation of Infix Probabilities for Probabilistic Context-Free Grammars</a></p>
<p>Author: Mark-Jan Nederhof ; Giorgio Satta</p><p>Abstract: The notion of infix probability has been introduced in the literature as a generalization of the notion of prefix (or initial substring) probability, motivated by applications in speech recognition and word error correction. For the case where a probabilistic context-free grammar is used as language model, methods for the computation of infix probabilities have been presented in the literature, based on various simplifying assumptions. Here we present a solution that applies to the problem in its full generality.</p><p>5 0.083241656 <a title="111-tfidf-5" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>6 0.072014175 <a title="111-tfidf-6" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>7 0.071611069 <a title="111-tfidf-7" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>8 0.071440808 <a title="111-tfidf-8" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>9 0.067155741 <a title="111-tfidf-9" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>10 0.066682249 <a title="111-tfidf-10" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>11 0.066021018 <a title="111-tfidf-11" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>12 0.065162592 <a title="111-tfidf-12" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>13 0.060833938 <a title="111-tfidf-13" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>14 0.058253597 <a title="111-tfidf-14" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>15 0.057919502 <a title="111-tfidf-15" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>16 0.05749768 <a title="111-tfidf-16" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>17 0.056819119 <a title="111-tfidf-17" href="./emnlp-2011-Inducing_Sentence_Structure_from_Parallel_Corpora_for_Reordering.html">74 emnlp-2011-Inducing Sentence Structure from Parallel Corpora for Reordering</a></p>
<p>18 0.056065768 <a title="111-tfidf-18" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>19 0.055488598 <a title="111-tfidf-19" href="./emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">15 emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>20 0.055198185 <a title="111-tfidf-20" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.21), (1, 0.022), (2, -0.05), (3, 0.051), (4, 0.016), (5, 0.001), (6, -0.117), (7, 0.051), (8, 0.101), (9, -0.015), (10, -0.101), (11, 0.084), (12, -0.111), (13, -0.102), (14, 0.024), (15, -0.035), (16, 0.017), (17, 0.035), (18, -0.057), (19, 0.002), (20, 0.044), (21, -0.11), (22, -0.082), (23, 0.036), (24, -0.044), (25, -0.023), (26, 0.009), (27, 0.078), (28, 0.244), (29, -0.007), (30, -0.083), (31, 0.038), (32, 0.076), (33, 0.007), (34, -0.182), (35, 0.103), (36, 0.095), (37, -0.043), (38, 0.041), (39, -0.039), (40, 0.098), (41, -0.199), (42, 0.058), (43, -0.003), (44, 0.168), (45, -0.059), (46, 0.092), (47, -0.11), (48, 0.119), (49, 0.0)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92376119 <a title="111-lsi-1" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>Author: Benjamin Borschinger ; Bevan K. Jones ; Mark Johnson</p><p>Abstract: It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.1</p><p>2 0.61947024 <a title="111-lsi-2" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>Author: Federico Sangati ; Willem Zuidema</p><p>Abstract: We present a novel approach to Data-Oriented Parsing (DOP). Like other DOP models, our parser utilizes syntactic fragments of arbitrary size from a treebank to analyze new sentences, but, crucially, it uses only those which are encountered at least twice. This criterion allows us to work with a relatively small but representative set of fragments, which can be employed as the symbolic backbone of several probabilistic generative models. For parsing we define a transform-backtransform approach that allows us to use standard PCFG technology, making our results easily replicable. According to standard Parseval metrics, our best model is on par with many state-ofthe-art parsers, while offering some complementary benefits: a simple generative probability model, and an explicit representation of the larger units of grammar.</p><p>3 0.58070791 <a title="111-lsi-3" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>Author: Wei Lu ; Hwee Tou Ng</p><p>Abstract: This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus. The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences. Sentences can then be generated based on such grammar rules with a log-linear model. To acquire such grammar rules automatically in an unsupervised manner, we also propose a novel approach with a generative model, which maps from sub-expressions of logical forms to word sequences in natural language sentences. Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.</p><p>4 0.54802573 <a title="111-lsi-4" href="./emnlp-2011-Computation_of_Infix_Probabilities_for_Probabilistic_Context-Free_Grammars.html">31 emnlp-2011-Computation of Infix Probabilities for Probabilistic Context-Free Grammars</a></p>
<p>Author: Mark-Jan Nederhof ; Giorgio Satta</p><p>Abstract: The notion of infix probability has been introduced in the literature as a generalization of the notion of prefix (or initial substring) probability, motivated by applications in speech recognition and word error correction. For the case where a probabilistic context-free grammar is used as language model, methods for the computation of infix probabilities have been presented in the literature, based on various simplifying assumptions. Here we present a solution that applies to the problem in its full generality.</p><p>5 0.53289372 <a title="111-lsi-5" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>6 0.44194812 <a title="111-lsi-6" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>7 0.3916783 <a title="111-lsi-7" href="./emnlp-2011-Inducing_Sentence_Structure_from_Parallel_Corpora_for_Reordering.html">74 emnlp-2011-Inducing Sentence Structure from Parallel Corpora for Reordering</a></p>
<p>8 0.35416564 <a title="111-lsi-8" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>9 0.34305379 <a title="111-lsi-9" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>10 0.33674443 <a title="111-lsi-10" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>11 0.3345919 <a title="111-lsi-11" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>12 0.32074836 <a title="111-lsi-12" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<p>13 0.3119058 <a title="111-lsi-13" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>14 0.31186303 <a title="111-lsi-14" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>15 0.3094621 <a title="111-lsi-15" href="./emnlp-2011-Syntactic_Decision_Tree_LMs%3A_Random_Selection_or_Intelligent_Design%3F.html">131 emnlp-2011-Syntactic Decision Tree LMs: Random Selection or Intelligent Design?</a></p>
<p>16 0.30407014 <a title="111-lsi-16" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>17 0.2802175 <a title="111-lsi-17" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>18 0.26421472 <a title="111-lsi-18" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>19 0.25921065 <a title="111-lsi-19" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>20 0.25693503 <a title="111-lsi-20" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.102), (36, 0.023), (37, 0.034), (42, 0.299), (45, 0.055), (53, 0.02), (54, 0.057), (57, 0.015), (62, 0.025), (64, 0.032), (66, 0.034), (69, 0.028), (79, 0.073), (82, 0.022), (87, 0.022), (90, 0.04), (96, 0.036), (98, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.77576524 <a title="111-lda-1" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>Author: Tong Wang ; Graeme Hirst</p><p>Abstract: We re-investigate the rationale for and the effectiveness of adopting the notions of depth and density in WordNet-based semantic similarity measures. We show that the intuition for including these notions in WordNet-based similarity measures does not always stand up to empirical examination. In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure. We thus propose several novel definitions of depth and density, which yield significant improvement in degree of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment.</p><p>same-paper 2 0.71210402 <a title="111-lda-2" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>Author: Benjamin Borschinger ; Bevan K. Jones ; Mark Johnson</p><p>Abstract: It is often assumed that ‘grounded’ learning tasks are beyond the scope of grammatical inference techniques. In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in a way that gives state of the art results. We further show that additionally letting our model learn the language’s canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.1</p><p>3 0.46556783 <a title="111-lda-3" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>4 0.46424118 <a title="111-lda-4" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>5 0.45939967 <a title="111-lda-5" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>Author: Edward Grefenstette ; Mehrnoosh Sadrzadeh</p><p>Abstract: Modelling compositional meaning for sentences using empirical distributional methods has been a challenge for computational linguists. We implement the abstract categorical model of Coecke et al. (2010) using data from the BNC and evaluate it. The implementation is based on unsupervised learning of matrices for relational words and applying them to the vectors of their arguments. The evaluation is based on the word disambiguation task developed by Mitchell and Lapata (2008) for intransitive sentences, and on a similar new experiment designed for transitive sentences. Our model matches the results of its competitors . in the first experiment, and betters them in the second. The general improvement in results with increase in syntactic complexity showcases the compositional power of our model.</p><p>6 0.457068 <a title="111-lda-6" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>7 0.45644993 <a title="111-lda-7" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>8 0.45642313 <a title="111-lda-8" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>9 0.45613506 <a title="111-lda-9" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>10 0.45519006 <a title="111-lda-10" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>11 0.45473206 <a title="111-lda-11" href="./emnlp-2011-Hierarchical_Phrase-based_Translation_Representations.html">66 emnlp-2011-Hierarchical Phrase-based Translation Representations</a></p>
<p>12 0.45445222 <a title="111-lda-12" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>13 0.4537676 <a title="111-lda-13" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>14 0.45299542 <a title="111-lda-14" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>15 0.448596 <a title="111-lda-15" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>16 0.44827342 <a title="111-lda-16" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>17 0.44720942 <a title="111-lda-17" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>18 0.44713041 <a title="111-lda-18" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>19 0.44685528 <a title="111-lda-19" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>20 0.44565824 <a title="111-lda-20" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
