<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-11" href="#">emnlp2011-11</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</h1>
<br/><p>Source: <a title="emnlp-2011-11-pdf" href="http://aclweb.org/anthology//D/D11/D11-1146.pdf">pdf</a></p><p>Author: Zhiyuan Liu ; Xinxiong Chen ; Maosong Sun</p><p>Abstract: It is popular for users in Web 2.0 era to freely annotate online resources with tags. To ease the annotation process, it has been great interest in automatic tag suggestion. We propose a method to suggest tags according to the text description of a resource. By considering both the description and tags of a given resource as summaries to the resource written in two languages, we adopt word alignment models in statistical machine translation to bridge their vocabulary gap. Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description. Experiments on real world datasets show that WTM is effective and robust compared with other methods. Moreover, WTM is relatively simple and efficient, which is practical for Web applications.</p><p>Reference: <a title="emnlp-2011-11-reference" href="../emnlp2011_reference/emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We propose a method to suggest tags according to the text description of a resource. [sent-6, score-0.418]
</p><p>2 By considering both the description and tags of a given resource as summaries to the resource written in two languages, we adopt word alignment models in statistical machine translation to bridge their vocabulary gap. [sent-7, score-0.933]
</p><p>3 Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description. [sent-8, score-1.153]
</p><p>4 Table 1 shows a book entry annotated with multiple tags by users1 . [sent-13, score-0.488]
</p><p>5 Since the tags of a resource are annotated collaboratively by multiple users, we also name these tags as social tags. [sent-23, score-0.986]
</p><p>6 For a resource, we refer to the additional information, such as the title and introduction of a book, as description, and the user-annotated social tags as annotation. [sent-24, score-0.522]
</p><p>7 Annotation Dumas (2748), Count of Monte Cristo (2716), foreign literature (1813), novel (1345), France (1096), classic (1062), revenge (913), famous book (759), . [sent-30, score-0.331]
</p><p>8 The number in the bracket after each tag is the total count ofusers that annotate the tag on this book. [sent-34, score-0.461]
</p><p>9 The task of automatic social tag suggestion is to automatically recommend tags for a user when he/she wants to annotate a resource. [sent-43, score-0.991]
</p><p>10 Social tag  suggestion, as a crucial component for social tagging systems, can help users annotate resources. [sent-44, score-0.555]
</p><p>11 Moreover, social tag suggestion is usually considered as an equivalent problem to modeling social 1577  ProceedEindgisnb oufr tghhe, 2 S0c1o1tl Canodn,f eUrKen,c Jeuol yn 2 E7m–3p1ir,ic 2a0l1 M1. [sent-45, score-0.92]
</p><p>12 For example, on a book review website, each book entry contains a title, the author(s) and an introduction of the book. [sent-50, score-0.406]
</p><p>13 Some researchers thus propose to automatically suggest tags based on resource descriptions, which are collectively known as the content-based approach. [sent-51, score-0.501]
</p><p>14 Take the book entry in Table 1 for instance, the word “popular” used in the description contrasts the tags “classic” and “famous  book” in the annotation; the word “novel” is used in the description, while most users annotate with the tag “fiction”. [sent-54, score-0.857]
</p><p>15 The vocabulary gap usually reflects in two main issues: •  •  Some tags in the annotation do appear in the corresponding description, o bnut d they may ninot t hbee statistically significant. [sent-55, score-0.327]
</p><p>16 In this paper, besides employing word alignment models to social tagging, we also propose  a method to efficiently build description-annotation pairs for sufficient learning translation probabilities by word alignment models. [sent-63, score-0.419]
</p><p>17 Based on the learned translation probabilities between words in descriptions and annotations, 1578 we regard the tagging behavior as a word trigger process: 1. [sent-64, score-0.439]
</p><p>18 A user reads the resource description to realize its substance by seeing some important words in the description. [sent-65, score-0.357]
</p><p>19 Based on this perspective, we build a simple word trigger method (WTM) for social tag suggestion. [sent-68, score-0.605]
</p><p>20 1, we use a simple example to show the basic idea of using word trigger for social tag suggestion. [sent-70, score-0.605]
</p><p>21 In this figure, some words in the first sentence of the book description in Table 1 are triggered to the tags in annotation. [sent-71, score-0.626]
</p><p>22 Figure 1: An example of the word trigger method for suggesting tags given a description. [sent-72, score-0.468]
</p><p>23 1 Social Tag Suggestion Previous work has been proposed to automatic social tag suggestion. [sent-74, score-0.435]
</p><p>24 Many researchers built tag suggestion systems based on collaborative filtering (CF) (Herlocker et al. [sent-75, score-0.488]
</p><p>25 These collaboration-based methods typically base their suggestions on the tagging history of the given resource and user, without considering resource descriptions. [sent-78, score-0.488]
</p><p>26 ,  2009) are representative CF methods for social tag suggestion. [sent-81, score-0.435]
</p><p>27 The content-based approach for social tag suggestion remedies the cold-start problem of the collaboration-based approach by suggesting tags according to resource descriptions. [sent-85, score-1.187]
</p><p>28 Therefore, the content-based approach plays an important role in social tag suggestion. [sent-86, score-0.435]
</p><p>29 Some researchers regarded social tag suggestion as a classification problem by considering each tag as a category label (Ohkura et al. [sent-87, score-0.879]
</p><p>30 Various classifiers such as Naive Bayes, kNN, SVM and neural networks have been explored to solve the social tag suggestion problem. [sent-92, score-0.682]
</p><p>31 These methods may thus be inefficient for a real-world social tagging system, where hundreds of thousands of unique tags should be considered as classification labels. [sent-95, score-0.537]
</p><p>32 By representing both tags and descriptions as the distributions of latent topics, this approach suggests tags according to their likelihood given the description (Krestel et al. [sent-99, score-0.803]
</p><p>33 What is more important, topic-based methods suggest tags by measuring the topical relevance of tags and resource descriptions. [sent-111, score-0.787]
</p><p>34 The latent topics are of concept-level which are usually too general to precisely suggest those specific tags such as named entities, e. [sent-112, score-0.359]
</p><p>35 It should also be noted that social tag suggestion is different from automatic keyphrase extraction (Turney, 2000; Frank et al. [sent-119, score-0.78]
</p><p>36 On the contrary, in social tag suggestion, the suggested tags do not necessarily appear in the given resource description. [sent-125, score-0.964]
</p><p>37 We can thus regard social tag suggestion as a task of selecting appropriate tags from a controlled tag vocabulary for the given resource description. [sent-126, score-1.378]
</p><p>38 1 Method Framework We describe the word trigger method (WTM) for social tag suggestion as a 3-stage process: 1. [sent-148, score-0.852]
</p><p>39 Given a  collection of description-annotation pairs, we adopt IBM Model-1, a widely used word alignment model, to learn the translation probabilities between words in descriptions and tags in annotations. [sent-153, score-0.528]
</p><p>40 After building translation probabilities between words and tags, given a resource description, we first compute the trigger power of each word in the description and then suggest tags according to their translation probabilities from the triggered words. [sent-156, score-1.042]
</p><p>41 In a social tagging system, a resource is denoted as r ∈ R, where R is the set of aall r resources. [sent-158, score-0.488]
</p><p>42 eEnaocthed resource c,o wnthaeirnes a description and an annotation containing a set of tags. [sent-159, score-0.366]
</p><p>43 The description dr of resource r can be regarded as a bag of words wr = {(wi, ei) , where ei is the count of word wi an=d Nr is th)e} number of unique words in r. [sent-160, score-0.396]
</p><p>44 The annotation ar of resource r is represented as tr = {(ti, where ei is the count of tag ti and Mr {is( tthe nu)}mber of unique tags for r. [sent-161, score-0.735]
</p><p>45 We assume the description and the annotation of a resource as being written in two distinct languages. [sent-164, score-0.366]
</p><p>46 1580 The annotation of a resource is a bag of tags with no position information. [sent-166, score-0.523]
</p><p>47 In a social tagging system, the length of a resource description is usually limited to hundreds of words. [sent-169, score-0.612]
</p><p>48 For example, the tag Dumas is annotated by 2, 748 users for the book in Table 1. [sent-171, score-0.479]
</p><p>49 We have to deal with the lengthunbalance between a resource description and its corresponding annotation for two reasons. [sent-172, score-0.366]
</p><p>50 The basic idea is to sample a bag of tags from the annotation according to tag weights and make the generated bag of tags with comparable length with the description. [sent-178, score-0.794]
</p><p>51 Given resource r, TFt and TF-IRFt of tag t are defined as T? [sent-182, score-0.404]
</p><p>52 We denote the ratio as δ = |wr |/ |tr |, where |wr | is the number othfe ew roartidos ains δth =e description wanhedr |tr | is| t ihse t hneu mnubmerb eofr tags ionrd dths ein na nthneo dtaetsiocnrip. [sent-191, score-0.417]
</p><p>53 3 Learning Translation Probabilities Using Word Alignment Models Suppose the source language is resource description and the target language is resource annotation. [sent-193, score-0.538]
</p><p>54 1581 Here we explore three methods to compute the trigger power of a word in a resource description: TF-IRFw, TextRank and their product. [sent-211, score-0.403]
</p><p>55 Given a resource description, TextRank first builds a term graph by connecting the terms in the description according to their semantic relations, and then run PageRank algorithm (Page et al. [sent-216, score-0.331]
</p><p>56 Emphasize Tags Appearing In Description for WTM (EWTM) In some social tagging systems, the tags that appear in the resource description are more likely to be selected by users for annotation. [sent-220, score-0.918]
</p><p>57 Therefore, we propose to emphasize the tags in the description by ranking tags as follows Pr(t|d) =  X wX∈wd  ? [sent-221, score-0.679]
</p><p>58 0, it does not emphasize the tags appearing in the description and just suggests according to their translation probabilities. [sent-229, score-0.48]
</p><p>59 R, W, T, N¯w and N¯t are the number of resources, the vocabulary of descriptions, the vocabulary of tags, the average number of words in each description and the average number of tags in each resource, respectively. [sent-238, score-0.452]
</p><p>60 com, which contains the descriptions of books and the tags collaboratively annotated by users. [sent-241, score-0.422]
</p><p>61 The dataset contains  the descriptions for academic papers (including the title and note for each paper) and the tags annotated by users. [sent-245, score-0.507]
</p><p>62 Evaluation Metrics We use precision, recall and F-measure to evaluate the performance of tag suggestion methods. [sent-248, score-0.444]
</p><p>63 For a resource, we denote the original tags (gold standard) as Ta, the suggested tags as Ts, and the correctly suggested tags as Ts ∩ Ta. [sent-249, score-0.9]
</p><p>64 In experiments, the number of suggested tags M ranges from 1to 10. [sent-255, score-0.35]
</p><p>65 Pr(w|t) is estimated by the frequency wofi tthh eth hweo targd w Pinr (thwe resource descriptions annotated with the tag t. [sent-269, score-0.57]
</p><p>66 kNN is a widely used classification method for tag suggestion, which recommends tags to a resource according to the  annotated tags of similar resources measured using vector space models (Manning et al. [sent-270, score-0.945]
</p><p>67 TAM is also a generative model which considers the words in descriptions as the topics to further generate tags for the resource. [sent-276, score-0.428]
</p><p>68 When suggesting for a given resource description with length Nw, the complexity of NB is O(NwT), kNN is O(RN¯wN¯t), CRM is O(IKNwT), TAM  3In fact, the numbers of iterations of the three methods are different from each other. [sent-283, score-0.373]
</p><p>69 This is especially valuable because WTM also shows good effectiveness for tag suggestion compared with other methods as we will shown later. [sent-288, score-0.444]
</p><p>70 The experimental results of WTM are obtained by setting parameters as follows: tag weighting type as TF-IRFt, length ratio δ = 1, harmonic factor λ = 0. [sent-290, score-0.364]
</p><p>71 Each point of a precision-recall curve represents different numbers of suggested tags from M = 1 (bottom right, with higher precision and lower recall) to M = 10 (upper left, with higher recall but lower precision) respectively. [sent-296, score-0.322]
</p><p>72 TTMhe i reason siisg nthifaitc aWntT oMn can take a good advantage of annotation count information of tags compared to other methods. [sent-302, score-0.331]
</p><p>73 The average length of resource descriptions is sThhoert a vienr atghee BenIgBtThE oXf dataset, weshcicrihp imonakse iss it difficult to determine the trigger powers of words. [sent-303, score-0.573]
</p><p>74 An Example In Table 4 we show top 10 tags suggested by NB, CRM, TAM and WTM for the book in Table 1. [sent-317, score-0.525]
</p><p>75 the results of kNN because the tags suggested by kNN are totally unrelated to the book due to the insufficient finding of nearest neighbors. [sent-333, score-0.525]
</p><p>76 From Table 4, we observe that NB, CRM and TAM, as generative models, tend to suggest general tags such as “novel”, “literature”, “classic” and “France”, and fail in suggesting specific tags such as “Alexandre Dumas” and “Count of Monte Cristo”. [sent-334, score-0.592]
</p><p>77 In Table 5, we list four important words (using TF-IRFw as weighting metric) of the description and  their corresponding tags with the highest translation probabilities. [sent-337, score-0.469]
</p><p>78 We can see that the translation probabilities can map the words in descriptions to their semantically corresponding tags in annotations. [sent-341, score-0.482]
</p><p>79 Table 5: Four important words (in bold face) in the book description in Table 1 and their corresponding tags with the highest translation probabilities. [sent-362, score-0.64]
</p><p>80 3 Parameter Influences We explore the parameter influences to WTM for social tag suggestion. [sent-364, score-0.435]
</p><p>81 The parameters include harmonic factor, length ratio, tag weighting types,  and types of word trigger strength. [sent-365, score-0.47]
</p><p>82 3 we investigate the influence of harmonic factor via the curves of Fmeasure of WTM versus the number of suggested tags on the BOOK dataset when harmonic factor λ ranges from 0. [sent-372, score-0.637]
</p><p>83 From the figure, we observe that the performance for tag suggestion is robust as the length ratio varies, except when the ratio breaks the default restriction of GIZA++ (i. [sent-387, score-0.518]
</p><p>84 Number of Suggested Tags  Figure 3: F-measure of WTM versus the number of suggested tags on the BOOK dataset when harmonic factor λ ranges from 0. [sent-390, score-0.505]
</p><p>85 Number of Suggested Tags  Figure 4: F-measure of WTM versus the number of suggested tags on the BOOK dataset when length ratio δ ranges from 10/1 to 1/5. [sent-393, score-0.444]
</p><p>86 Tag Weighting Types The influence of two weighting types, TFt and TF-IRFt, on social tag suggestion when M = 3 on the BOOK dataset is shown in Table 6. [sent-394, score-0.805]
</p><p>87 TF-IRFt tends to select the  tags more specific to the resource while TFt tends to select the most popular tags, because the latter does not consider global information (the IRFt part). [sent-395, score-0.463]
</p><p>88 Methods for Computing Word Trigger Power In Table 7, we show the performance of social tag suggestions on the BOOK dataset with different methods for computing word trigger power. [sent-411, score-0.693]
</p><p>89 Training Data Size We investigate the influence of training data size for social tag suggestion. [sent-419, score-0.469]
</p><p>90 4 Performance of EWTM At the end of this section, we investigate the performance of EWTM for social tag suggestion. [sent-430, score-0.435]
</p><p>91 Table 8 indicates that emphasizing the tags appearing in the descriptions may enhance the suggestion power of the word trigger method. [sent-435, score-0.836]
</p><p>92 The main reason 1586 of the decay is that: the resource descriptions in the BIBTEX dataset are usually too short to provide sufficient information to precisely emphasize tags. [sent-445, score-0.444]
</p><p>93 Therefore, we have to analyze the characteristics of social tagging systems to decide whether to emphasize the tags that appear in the corresponding resource descriptions. [sent-448, score-0.787]
</p><p>94 It is also worth to investigate the problem when combining with collaboration-based methods for social tag suggestion. [sent-450, score-0.435]
</p><p>95 5  Conclusion and Future Work  In this paper, we present a new perspective to social tagging and propose the word trigger method for social tag suggestion based on word alignment in statistical machine translation. [sent-451, score-1.179]
</p><p>96 Experiments show that our method is effective and efficient for social tag suggestion compared to other baselines. [sent-452, score-0.682]
</p><p>97 We will ensemble WTM with other contentbased and collaboration-based methods to build a practical social tag suggestion system. [sent-457, score-0.682]
</p><p>98 WTM and EWTM can only suggest the tags that have appeared in translation models. [sent-459, score-0.351]
</p><p>99 In future, we plan to incorporate keyphrase extraction in social tag suggestion to make it suggest more appropriate tags not only from translation models but also from the resource descriptions. [sent-460, score-1.338]
</p><p>100 Modeling social annotation data with content relevance using a topic model. [sent-631, score-0.333]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wtm', 0.506), ('tags', 0.256), ('suggestion', 0.247), ('crm', 0.24), ('social', 0.238), ('resource', 0.207), ('book', 0.203), ('tag', 0.197), ('trigger', 0.17), ('tam', 0.168), ('knn', 0.152), ('ewtm', 0.139), ('descriptions', 0.137), ('description', 0.124), ('dumas', 0.114), ('nb', 0.112), ('bibtex', 0.101), ('cristo', 0.098), ('keyphrase', 0.098), ('pr', 0.096), ('textrank', 0.079), ('harmonic', 0.071), ('monte', 0.066), ('suggested', 0.066), ('powers', 0.059), ('translation', 0.057), ('france', 0.057), ('dataset', 0.057), ('liu', 0.052), ('biography', 0.051), ('herlocker', 0.051), ('tft', 0.051), ('users', 0.05), ('alexandre', 0.046), ('alignment', 0.046), ('riezler', 0.045), ('collaborative', 0.044), ('recommender', 0.044), ('triggered', 0.043), ('tagging', 0.043), ('emphasize', 0.043), ('suggesting', 0.042), ('sigir', 0.042), ('count', 0.04), ('ibm', 0.039), ('suggest', 0.038), ('comic', 0.038), ('douban', 0.038), ('fujimura', 0.038), ('hotho', 0.038), ('iwata', 0.038), ('jaschke', 0.038), ('jeon', 0.038), ('ratio', 0.037), ('foreign', 0.037), ('vocabulary', 0.036), ('annotation', 0.035), ('topics', 0.035), ('blei', 0.034), ('influence', 0.034), ('classic', 0.033), ('literature', 0.033), ('weighting', 0.032), ('probabilities', 0.032), ('wn', 0.031), ('berger', 0.031), ('suggestions', 0.031), ('website', 0.031), ('retrieval', 0.031), ('topic', 0.03), ('latent', 0.03), ('relevance', 0.03), ('prepare', 0.03), ('wd', 0.03), ('annotated', 0.029), ('si', 0.029), ('title', 0.028), ('ranges', 0.028), ('factor', 0.027), ('preparing', 0.027), ('annotate', 0.027), ('user', 0.026), ('power', 0.026), ('bag', 0.025), ('bookmarking', 0.025), ('bundschus', 0.025), ('dalvi', 0.025), ('duygulu', 0.025), ('heymann', 0.025), ('huatfcin', 0.025), ('karimzadehgan', 0.025), ('katakis', 0.025), ('marinho', 0.025), ('mirizzi', 0.025), ('nwt', 0.025), ('ohkura', 0.025), ('onomy', 0.025), ('pef', 0.025), ('revenge', 0.025), ('tfirfw', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="11-tfidf-1" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>Author: Zhiyuan Liu ; Xinxiong Chen ; Maosong Sun</p><p>Abstract: It is popular for users in Web 2.0 era to freely annotate online resources with tags. To ease the annotation process, it has been great interest in automatic tag suggestion. We propose a method to suggest tags according to the text description of a resource. By considering both the description and tags of a given resource as summaries to the resource written in two languages, we adopt word alignment models in statistical machine translation to bridge their vocabulary gap. Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description. Experiments on real world datasets show that WTM is effective and robust compared with other methods. Moreover, WTM is relatively simple and efficient, which is practical for Web applications.</p><p>2 0.09787941 <a title="11-tfidf-2" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>3 0.08847259 <a title="11-tfidf-3" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>4 0.077194951 <a title="11-tfidf-4" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>Author: Sebastian Riedel ; Andrew McCallum</p><p>Abstract: Extracting biomedical events from literature has attracted much recent attention. The bestperforming systems so far have been pipelines of simple subtask-specific local classifiers. A natural drawback of such approaches are cascading errors introduced in early stages of the pipeline. We present three joint models of increasing complexity designed to overcome this problem. The first model performs joint trigger and argument extraction, and lends itself to a simple, efficient and exact inference algorithm. The second model captures correlations between events, while the third model ensures consistency between arguments of the same event. Inference in these models is kept tractable through dual decomposition. The first two models outperform the previous best joint approaches and are very competitive with respect to the current state-of-theart. The third model yields the best results reported so far on the BioNLP 2009 shared task, the BioNLP 2011 Genia task and the BioNLP 2011Infectious Diseases task.</p><p>5 0.073508941 <a title="11-tfidf-5" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>Author: Shay B. Cohen ; Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages. Our approach is based on a model that locally mixes between supervised models from the helper languages. Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable. We obtain state-of-theart performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing.</p><p>6 0.069381535 <a title="11-tfidf-6" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>7 0.065250821 <a title="11-tfidf-7" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>8 0.06439247 <a title="11-tfidf-8" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>9 0.059591938 <a title="11-tfidf-9" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>10 0.056743577 <a title="11-tfidf-10" href="./emnlp-2011-Corpus-Guided_Sentence_Generation_of_Natural_Images.html">34 emnlp-2011-Corpus-Guided Sentence Generation of Natural Images</a></p>
<p>11 0.054137506 <a title="11-tfidf-11" href="./emnlp-2011-A_Correction_Model_for_Word_Alignments.html">3 emnlp-2011-A Correction Model for Word Alignments</a></p>
<p>12 0.05091298 <a title="11-tfidf-12" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>13 0.050170381 <a title="11-tfidf-13" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>14 0.050135925 <a title="11-tfidf-14" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>15 0.049902994 <a title="11-tfidf-15" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>16 0.047442205 <a title="11-tfidf-16" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>17 0.043920141 <a title="11-tfidf-17" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>18 0.043445136 <a title="11-tfidf-18" href="./emnlp-2011-Cache-based_Document-level_Statistical_Machine_Translation.html">25 emnlp-2011-Cache-based Document-level Statistical Machine Translation</a></p>
<p>19 0.042902071 <a title="11-tfidf-19" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>20 0.042826574 <a title="11-tfidf-20" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.164), (1, -0.046), (2, -0.008), (3, -0.035), (4, -0.059), (5, 0.052), (6, -0.023), (7, -0.018), (8, -0.083), (9, -0.026), (10, -0.029), (11, -0.008), (12, 0.048), (13, 0.026), (14, 0.082), (15, 0.079), (16, 0.033), (17, 0.043), (18, -0.049), (19, 0.107), (20, -0.097), (21, 0.065), (22, -0.03), (23, -0.016), (24, 0.006), (25, 0.05), (26, 0.107), (27, -0.169), (28, 0.011), (29, -0.136), (30, -0.036), (31, 0.023), (32, -0.043), (33, 0.032), (34, -0.107), (35, 0.31), (36, -0.15), (37, 0.051), (38, 0.105), (39, 0.182), (40, -0.059), (41, 0.17), (42, 0.137), (43, -0.079), (44, 0.055), (45, 0.19), (46, 0.011), (47, 0.073), (48, 0.059), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95458978 <a title="11-lsi-1" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>Author: Zhiyuan Liu ; Xinxiong Chen ; Maosong Sun</p><p>Abstract: It is popular for users in Web 2.0 era to freely annotate online resources with tags. To ease the annotation process, it has been great interest in automatic tag suggestion. We propose a method to suggest tags according to the text description of a resource. By considering both the description and tags of a given resource as summaries to the resource written in two languages, we adopt word alignment models in statistical machine translation to bridge their vocabulary gap. Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description. Experiments on real world datasets show that WTM is effective and robust compared with other methods. Moreover, WTM is relatively simple and efficient, which is practical for Web applications.</p><p>2 0.4499476 <a title="11-lsi-2" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>Author: Sebastian Riedel ; Andrew McCallum</p><p>Abstract: Extracting biomedical events from literature has attracted much recent attention. The bestperforming systems so far have been pipelines of simple subtask-specific local classifiers. A natural drawback of such approaches are cascading errors introduced in early stages of the pipeline. We present three joint models of increasing complexity designed to overcome this problem. The first model performs joint trigger and argument extraction, and lends itself to a simple, efficient and exact inference algorithm. The second model captures correlations between events, while the third model ensures consistency between arguments of the same event. Inference in these models is kept tractable through dual decomposition. The first two models outperform the previous best joint approaches and are very competitive with respect to the current state-of-theart. The third model yields the best results reported so far on the BioNLP 2009 shared task, the BioNLP 2011 Genia task and the BioNLP 2011Infectious Diseases task.</p><p>3 0.44312897 <a title="11-lsi-3" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>4 0.42965016 <a title="11-lsi-4" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>Author: Shay B. Cohen ; Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages. Our approach is based on a model that locally mixes between supervised models from the helper languages. Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable. We obtain state-of-theart performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing.</p><p>5 0.41191861 <a title="11-lsi-5" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>6 0.39708355 <a title="11-lsi-6" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>7 0.39548019 <a title="11-lsi-7" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>8 0.34568274 <a title="11-lsi-8" href="./emnlp-2011-Corpus-Guided_Sentence_Generation_of_Natural_Images.html">34 emnlp-2011-Corpus-Guided Sentence Generation of Natural Images</a></p>
<p>9 0.28710112 <a title="11-lsi-9" href="./emnlp-2011-A_Correction_Model_for_Word_Alignments.html">3 emnlp-2011-A Correction Model for Word Alignments</a></p>
<p>10 0.26408982 <a title="11-lsi-10" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>11 0.25054911 <a title="11-lsi-11" href="./emnlp-2011-Predicting_a_Scientific_Communitys_Response_to_an_Article.html">106 emnlp-2011-Predicting a Scientific Communitys Response to an Article</a></p>
<p>12 0.24178304 <a title="11-lsi-12" href="./emnlp-2011-Syntactic_Decision_Tree_LMs%3A_Random_Selection_or_Intelligent_Design%3F.html">131 emnlp-2011-Syntactic Decision Tree LMs: Random Selection or Intelligent Design?</a></p>
<p>13 0.22981709 <a title="11-lsi-13" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>14 0.22686347 <a title="11-lsi-14" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>15 0.22520395 <a title="11-lsi-15" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>16 0.22120462 <a title="11-lsi-16" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>17 0.21315701 <a title="11-lsi-17" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>18 0.20621721 <a title="11-lsi-18" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>19 0.20138998 <a title="11-lsi-19" href="./emnlp-2011-Generating_Subsequent_Reference_in_Shared_Visual_Scenes%3A_Computation_vs_Re-Use.html">62 emnlp-2011-Generating Subsequent Reference in Shared Visual Scenes: Computation vs Re-Use</a></p>
<p>20 0.19838324 <a title="11-lsi-20" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(15, 0.015), (23, 0.105), (36, 0.019), (37, 0.023), (45, 0.1), (53, 0.014), (54, 0.029), (57, 0.022), (62, 0.029), (64, 0.033), (66, 0.043), (69, 0.021), (79, 0.054), (82, 0.025), (84, 0.308), (96, 0.029), (98, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75340933 <a title="11-lda-1" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>Author: Zhiyuan Liu ; Xinxiong Chen ; Maosong Sun</p><p>Abstract: It is popular for users in Web 2.0 era to freely annotate online resources with tags. To ease the annotation process, it has been great interest in automatic tag suggestion. We propose a method to suggest tags according to the text description of a resource. By considering both the description and tags of a given resource as summaries to the resource written in two languages, we adopt word alignment models in statistical machine translation to bridge their vocabulary gap. Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description. Experiments on real world datasets show that WTM is effective and robust compared with other methods. Moreover, WTM is relatively simple and efficient, which is practical for Web applications.</p><p>2 0.47471723 <a title="11-lda-2" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>Author: Amit Dubey ; Frank Keller ; Patrick Sturt</p><p>Abstract: This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chunker with a co-reference classifier. Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure. This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort. We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.</p><p>3 0.47400519 <a title="11-lda-3" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>Author: Christos Christodoulopoulos ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: In this paper we present a fully unsupervised syntactic class induction system formulated as a Bayesian multinomial mixture model, where each word type is constrained to belong to a single class. By using a mixture model rather than a sequence model (e.g., HMM), we are able to easily add multiple kinds of features, including those at both the type level (morphology features) and token level (context and alignment features, the latter from parallel corpora). Using only context features, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested.</p><p>4 0.46818045 <a title="11-lda-4" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>Author: Edward Grefenstette ; Mehrnoosh Sadrzadeh</p><p>Abstract: Modelling compositional meaning for sentences using empirical distributional methods has been a challenge for computational linguists. We implement the abstract categorical model of Coecke et al. (2010) using data from the BNC and evaluate it. The implementation is based on unsupervised learning of matrices for relational words and applying them to the vectors of their arguments. The evaluation is based on the word disambiguation task developed by Mitchell and Lapata (2008) for intransitive sentences, and on a similar new experiment designed for transitive sentences. Our model matches the results of its competitors . in the first experiment, and betters them in the second. The general improvement in results with increase in syntactic complexity showcases the compositional power of our model.</p><p>5 0.4676173 <a title="11-lda-5" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>6 0.4673945 <a title="11-lda-6" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>7 0.46734706 <a title="11-lda-7" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>8 0.46538168 <a title="11-lda-8" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>9 0.46474788 <a title="11-lda-9" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>10 0.46453953 <a title="11-lda-10" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>11 0.46342179 <a title="11-lda-11" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>12 0.46304902 <a title="11-lda-12" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>13 0.46185812 <a title="11-lda-13" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>14 0.46171138 <a title="11-lda-14" href="./emnlp-2011-Discovering_Morphological_Paradigms_from_Plain_Text_Using_a_Dirichlet_Process_Mixture_Model.html">39 emnlp-2011-Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model</a></p>
<p>15 0.46111009 <a title="11-lda-15" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>16 0.46019137 <a title="11-lda-16" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>17 0.45862305 <a title="11-lda-17" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>18 0.45711634 <a title="11-lda-18" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>19 0.45679319 <a title="11-lda-19" href="./emnlp-2011-Exploiting_Syntactic_and_Distributional_Information_for_Spelling_Correction_with_Web-Scale_N-gram_Models.html">55 emnlp-2011-Exploiting Syntactic and Distributional Information for Spelling Correction with Web-Scale N-gram Models</a></p>
<p>20 0.45669234 <a title="11-lda-20" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
