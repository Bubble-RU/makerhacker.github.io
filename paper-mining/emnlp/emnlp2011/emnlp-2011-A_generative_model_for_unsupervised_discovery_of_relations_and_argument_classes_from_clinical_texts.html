<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-14" href="#">emnlp2011-14</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</h1>
<br/><p>Source: <a title="emnlp-2011-14-pdf" href="http://aclweb.org/anthology//D/D11/D11-1048.pdf">pdf</a></p><p>Author: Bryan Rink ; Sanda Harabagiu</p><p>Abstract: This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. The model discovers relation instances and their types by determining which context tokens express the relation. Additionally, the valid semantic classes for each type of relation are determined. We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. The discovered relations reveal some of the implicit semantic structure present in patient records.</p><p>Reference: <a title="emnlp-2011-14-reference" href="../emnlp2011_reference/emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A generative model for unsupervised discovery of relations and argument classes from clinical texts Bryan Rink and Sanda Harabagiu Human Language Technology Research Institute University of Texas at Dallas Richardson, TX, USA {bryan , s anda} @ hlt . [sent-1, score-0.681]
</p><p>2 edu a  Abstract This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. [sent-3, score-0.813]
</p><p>3 The model discovers relation instances and their types by determining which context tokens express the relation. [sent-4, score-0.378]
</p><p>4 Additionally, the valid semantic classes for each type of relation are determined. [sent-5, score-0.48]
</p><p>5 We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. [sent-6, score-1.018]
</p><p>6 The discovered relations reveal some of the implicit semantic structure present in patient records. [sent-7, score-0.505]
</p><p>7 1 Introduction Semantic relations in electronic medical records (EMRs) capture important meaning about the as-  sociations between medical concepts. [sent-8, score-0.956]
</p><p>8 Knowledge about how concepts such as medical problems, treatments, and tests are related can be used to improve medical care by speeding up the retrieval of relevant patient information or alerting doctors to critical information that may have been overlooked. [sent-9, score-0.913]
</p><p>9 These textual 519 descriptions written in a patient’s record encode important information about the relationships between the problems a patients has, the treatments taken for the problems, and the tests which reveal and investigate the problems. [sent-18, score-0.315]
</p><p>10 The ability to accurately detect semantic relations in EMRs, such as Treatment-Administered-forProblem, can aid in querying medical records. [sent-19, score-0.618]
</p><p>11 If a patient’s medical record indicates a test that was found to reveal a critical problem but no subsequent treatment was performed for the problem, the patient’s record could be flagged for review. [sent-23, score-0.5]
</p><p>12 Similarly, if a Treatment-Worsens-Problem relation is detected previously in a patient’s record, that information can be brought to the attention of a doctor who advises such a treatment in the future. [sent-24, score-0.409]
</p><p>13 By considering all of the relations present in a corpus, better medical ontologies could be built automatically or existing ones can be improved by adding additional connections between concepts that have a relation in text. [sent-25, score-0.877]
</p><p>14 Given the large size of EMR repositories, we argue that it is quite important to have the ability to perform relation discovery between medical concepts. [sent-26, score-0.659]
</p><p>15 Relations between medical concepts benefit  translational medicine whenever possible relations are known. [sent-27, score-0.594]
</p><p>16 To address both the problem of discovering unknown relations between medical concepts and the related problem of generating examples for known relations, we have developed an unsupervised method. [sent-33, score-0.664]
</p><p>17 This approach has the advantages of not requiring an expensive annotation effort to provide training data for semantic relations, which is particularly difficult for medical records, characterized by many privacy concerns. [sent-34, score-0.362]
</p><p>18 Our analysis shows a high level of overlap between the manually annotated relations and those that were discovered automatically. [sent-35, score-0.358]
</p><p>19 2  Related Work  Previous methods for unsupervised relation discovery have also relied on clustering techniques. [sent-42, score-0.483]
</p><p>20 One technique uses the context of entity arguments to cluster, while another is to perform a postprocessing step to cluster relations found using an existing relation extraction system. [sent-43, score-0.796]
</p><p>21 Other approaches to unsupervised relation discovery have relied on a two-step process where a number of relations are extracted, usually from a  predicate-argument structure. [sent-49, score-0.577]
</p><p>22 Then similar relations are clustered together since synonymous predicates should be considered the same relation (e. [sent-50, score-0.523]
</p><p>23 Syed and Viegas (2010) also perform a clustering on the output of an existing relation extraction system by considering the number of times two relations share the same exact arguments. [sent-55, score-0.599]
</p><p>24 Similar relations are expected to have the same pairs of arguments (e. [sent-56, score-0.389]
</p><p>25 For instance, “penicillin” may be causally related to “allergic reaction” in one patient’s medical record but not in another. [sent-61, score-0.365]
</p><p>26 The relation between the two entities is not globally constant and should be  considered only within the scope of one patient’s records. [sent-62, score-0.428]
</p><p>27 , 2011) developed a set of annotations for medical concepts and relations on medical progress notes and discharge summaries. [sent-69, score-0.942]
</p><p>28 The advantage of our work over existing unsupervised approaches is the simultaneous clustering of both argument words and relation trigger words. [sent-72, score-0.857]
</p><p>29 These broad clusters handle: (i) synonyms, (ii) argument semantic classes, and (iii) words belonging to the same relation. [sent-73, score-0.348]
</p><p>30 1 Unsupervised Relation Discovery A simple approach to discovering relations between medical entities in clinical texts uses a clustering approach, e. [sent-75, score-0.864]
</p><p>31 We start with an assumption that relations exist between two entities, which we call arguments, and may be triggered by certain words between those entities which we call trigger words. [sent-79, score-0.62]
</p><p>32 For example, given the text “[x-ray] revealed [lung cancer]”, the first argument is x-ray, the second argument is lung cancer, and the trigger word is revealed. [sent-80, score-0.794]
</p><p>33 For instance, x-ray belongs to a class of medical tests, whereas lung cancer belongs to a  class of medical problems. [sent-82, score-0.966]
</p><p>34 While relations may exist between distant entities in text, we focus on those pairs of entities in text which have no other entities between them. [sent-83, score-0.669]
</p><p>35 This increases the likelihood of a relation existing between the entities and minimizes the number of context words (words between the entities) that are not relevant to the relation. [sent-84, score-0.455]
</p><p>36 With these assumptions we build a baseline relation discovery using LDA. [sent-85, score-0.342]
</p><p>37 Our assumption that relation arguments come from a small set of semantic classes should lead to clusters which align with relations since the two arguments of a relation will co-occur in the pseudo-documents. [sent-90, score-1.348]
</p><p>38 Furthermore, those argument tokens should co-occur with relation trigger words as well. [sent-91, score-0.757]
</p><p>39 This LDA-based approach was examined on electronic medical records from the 2010 i2b2/VA Challenge data set (Uzuner et al. [sent-92, score-0.434]
</p><p>40 The instances are pseudo-documents whose probability of being assigned to that cluster was over 70% contains manually annotated medical entities which were used to form the pairs of entities needed. [sent-95, score-0.802]
</p><p>41 The first cluster appears to contain words which indicate a relation whose two arguments are both medical problems (e. [sent-97, score-0.861]
</p><p>42 The trigger words seem to indicate a possible causal relation (e. [sent-100, score-0.551]
</p><p>43 The second cluster contains words relevant to medical tests (e. [sent-103, score-0.439]
</p><p>44 The word “patient” for instance is present in both clusters but is not a trigger word because it is likely to be seen in the context of any rela-  tion in medical text. [sent-107, score-0.7]
</p><p>45 In addition, while the LDA approach can detect argument words which co-occur with trigger words (e. [sent-109, score-0.458]
</p><p>46 An approach which models arguments separately from context words could learn the semantic classes of those arguments and thus better model relations. [sent-112, score-0.491]
</p><p>47 2  Relation Discovery Model (RDM)  The limitations identified in the LDA-based approach are solved by a novel relation discovery model (RDM) which jointly models relation argument semantic classes and considers them separately from the context words. [sent-116, score-0.996]
</p><p>48 Relations triggered by pairs of medical entities enable us to consider three observable features: (A1) the first argument; (A2) the second argument; and (CW) the context words found between A1 and A2. [sent-117, score-0.545]
</p><p>49 In the RDM, the contextual words are assumed to come from a mixture model with 2 mixture components: a relation trigger word (x = 0), or a general word (x = 1), where x is a variable representing which mixture component a word belongs to. [sent-120, score-0.646]
</p><p>50 Under the RDM’s mixture model, the probability 522 of a context word is: z) =  P(wC|tr, P(wC|tr, x = 0) P(wC|z, x = 1)  P(x = 0|tr) +  P(x = 1|tr)  Where wC is a context word, the variable tr is the relation type, and z is the general word class. [sent-123, score-0.506]
</p><p>51 In the RDM, the two argument classes are modeled jointly as P(c1, c2|tr), where c1 and c2 are two semantic classes asso|ctiated with a relation of type tr. [sent-125, score-0.779]
</p><p>52 This models the fact that a relation’s arguments do not come in a fixed order, “[MRI] revealed [tumor]” is the same type of relation as “[tumor] was revealed by [x-ray]”. [sent-129, score-0.619]
</p><p>53 Each candidate relation is modeled independently, with a total of I relation candidates. [sent-131, score-0.566]
</p><p>54 The model takes parameters for the number of relations types (R), the number of argument semantic classes (A), and the number of general word classes (K). [sent-133, score-0.658]
</p><p>55 R: (a) Draw a binomial distribution σr from Beta(αx) representing the mixture distribution for relation r (b) Draw a joint semantic class distribution ∈ RC×C from Dirichlet(α1,2). [sent-137, score-0.407]
</p><p>56 Draw a categorical relation type distribution ρ from Dirichlet(αr) 6. [sent-154, score-0.389]
</p><p>57 I:  (a) Sample a relation type tr from ρ (b) Jointly sample semantic classes  c1 and c2  fψot1rr,2 the first and second arguments from (c) Draw a general word class categorical distribution θ from Dirichlet(αz)  (d) For each token j = 1. [sent-157, score-0.909]
</p><p>58 In the RDM, words from the arguments are informed by the relation through an argument semantic class which is sampled from P(c1, c2|tr) = Furthermore, words from the context are informed by the relation type. [sent-167, score-1.022]
</p><p>59 These dependencies enable more coherent relation clusters to form during parameter estimation because argument classes and relation trigger words are co-clustered. [sent-168, score-1.221]
</p><p>60 ×  words (ω1 and ω2) depending on whether the entity occurred in the first argument or the second argument of the relation. [sent-170, score-0.43]
</p><p>61 1 Experimental Setup We evaluated the RDM using a corpus of electronic medical records provided by the 2010 i2b2/VA Challenge (Uzuner et al. [sent-186, score-0.434]
</p><p>62 We used the training set, which consists of 349 medical records from 4 hospitals, annotated with medical concepts (specifically problems, treatments, and tests), along with any relations present between those concepts. [sent-188, score-1.015]
</p><p>63 We used these manually annotated relations to evaluate how well the RDM performs at relation discovery. [sent-189, score-0.551]
</p><p>64 We assess the model using two versions of this data set consisting of: those pairs of consecutive 524  entities which have a manually annotated relation (DS 1), and secondly, all consecutive pairs of entities (DS2). [sent-193, score-0.845]
</p><p>65 2 Analysis Figure 4 illustrates four of the fifteen trigger word clusters (most likely words according to φr) learned from dataset DS 1 using the best set of parameters according to normalized mutual information (NMI) as described in section 5. [sent-199, score-0.382]
</p><p>66 Relation Type 1 Instances of this discovered relation are often found embedded in long lists of drugs prescribed to the patient. [sent-204, score-0.413]
</p><p>67 The learned relation specifically considers arguments of a drug Instances of Relation Type 1  Insta42153. [sent-211, score-0.438]
</p><p>68 The closest manually chosen relation is Treatment-AddressesProblem which included drugs as treatments. [sent-229, score-0.354]
</p><p>69 This relation is difficult to discover accurately because of the infrequent use of strong trigger words to indicate the relation. [sent-241, score-0.552]
</p><p>70 Instead, the model must rely more on the semantic classes of the arguments, which in this case will both be types of medical problems. [sent-242, score-0.471]
</p><p>71 Relation Type 4 is detecting instances where a medical test has revealed some problem. [sent-243, score-0.413]
</p><p>72 This corresponds to the Test-Reveals-Problem relation from  The fourth relation  the data. [sent-244, score-0.566]
</p><p>73 Many good trigger words for that relation have high probability under Relation 4. [sent-245, score-0.526]
</p><p>74 A comparison of the RDM’s Relation 4 with LDA’s cluster 2 from Figure 1 shows that many words not relevant to the relation itself are now absent. [sent-246, score-0.359]
</p><p>75 Argument classes  Figure 6 shows the  3 most frequent semantic classes  for the first argument of a relation (ω1). [sent-247, score-0.736]
</p><p>76 Concept 2 seems to be capturing medical problems and their descriptions. [sent-251, score-0.347]
</p><p>77 Thus the discovered argument classes show some similarity to the ones chosen by annotators. [sent-255, score-0.389]
</p><p>78 3 Evaluation For a more objective analysis of the relations detected, we evaluated the discovered relation types by comparing them with the manually annotated ones from the data using normalized mutual information (NMI) (Manning et al. [sent-257, score-0.667]
</p><p>79 The entropy is defined as  H(Ω) = −Xk|Nωk|log2|ωNk| The reference clusters consist of all relations annotated with the same relation type. [sent-265, score-0.633]
</p><p>80 The predicted clusters consist of all relations which were assigned the same relation type. [sent-266, score-0.601]
</p><p>81 For DS2 we learned the models using all of the data, and evaluated on those entity pairs which had a manual relation annotated. [sent-271, score-0.362]
</p><p>82 Two other baselines are K-means and Complete-Link hierarchical agglomerative clustering using TF-IDF vectors of the context and argument words (similar to Hasegawa et al. [sent-274, score-0.371]
</p><p>83 The first two columns of numbers show the scores when evaluation is restricted to only those pairs of concepts which had a relation identified by annotators. [sent-277, score-0.384]
</p><p>84 The last two columns are the NMI and F measure scores when each method clusters all consecutive entity pairs, but is only evaluated on those with a relation identified by annotators. [sent-278, score-0.508]
</p><p>85 Generative models on 527 the other hand can provide an estimate of the probability for each relation type on unseen text. [sent-291, score-0.326]
</p><p>86 For each model we generate 10 samples after a burn in period of 30 iterations and form clusters by assigning each pair of concepts to the relation assigned most often in the samples. [sent-292, score-0.468]
</p><p>87 6  Discussion  The relation and argument clusters determined by the RDM provide a better unsupervised relation discovery method than the baselines. [sent-295, score-0.958]
</p><p>88 The analysis shows that words highly indicative of relations are detected and clustered automatically, with-  out the need for prior annotation of relations or even the choice of a predetermined set of relation types. [sent-297, score-0.762]
</p><p>89 The fact that the discovered relations and argument classes align well with those chosen by annotators on the same data justify our assumptions about relations being present and discoverable by the way they are expressed in text. [sent-299, score-0.799]
</p><p>90 While the RDM relies in large part on trigger words for making clustering decisions it is also capable of including examples which do not contain any contextual words between the arguments. [sent-301, score-0.354]
</p><p>91 In addition to modeling trigger words, a joint distribution on argument semantic classes is also incorporated. [sent-302, score-0.587]
</p><p>92 This allows the model to determine a relation type even in the absence of triggers. [sent-303, score-0.326]
</p><p>93 By determining the semantic classes for the arguments (lung  cancer is a Problem, and XRT is a test), the set of possible relations between the arguments can be narrowed down. [sent-305, score-0.821]
</p><p>94 For instance, there may be a learned relation type such as “Cancer treatment addresses cancer problem”. [sent-308, score-0.527]
</p><p>95 In this case, seeing a type of cancer (lung cancer) and a type of cancer treatment (XRT) would be strong evidence for that type of relation, even without trigger words. [sent-309, score-0.725]
</p><p>96 7  Conclusions  We presented a novel unsupervised approach to discovering relations in the narrative of electronic medical records. [sent-310, score-0.637]
</p><p>97 We developed a generative model which can simultaneously cluster relation trigger words as well as relation arguments. [sent-311, score-0.927]
</p><p>98 Unlike many previous approaches, we assign relations to entities at the location those entities appear in text, allowing us to discover context-sensitive relations. [sent-313, score-0.495]
</p><p>99 The discovered relations can be used for a number of applications such as detecting when certain treatments were administered or determining if a necessary test has been performed. [sent-315, score-0.479]
</p><p>100 A hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing. [sent-388, score-0.417]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rdm', 0.493), ('medical', 0.317), ('relation', 0.283), ('trigger', 0.243), ('relations', 0.205), ('argument', 0.19), ('arguments', 0.155), ('treatments', 0.153), ('cancer', 0.152), ('entities', 0.145), ('tr', 0.129), ('patient', 0.127), ('clusters', 0.113), ('clustering', 0.111), ('classes', 0.109), ('nmi', 0.108), ('lda', 0.102), ('lung', 0.102), ('xrt', 0.099), ('discovered', 0.09), ('uzuner', 0.085), ('wc', 0.076), ('cluster', 0.076), ('records', 0.072), ('concepts', 0.072), ('revealed', 0.069), ('dirichlet', 0.064), ('categorical', 0.063), ('zz', 0.062), ('consecutive', 0.062), ('emrs', 0.059), ('syed', 0.059), ('tir', 0.059), ('discovery', 0.059), ('yates', 0.054), ('ds', 0.053), ('draw', 0.053), ('examination', 0.051), ('entity', 0.05), ('treatment', 0.049), ('record', 0.048), ('tests', 0.046), ('clinical', 0.046), ('hasegawa', 0.046), ('electronic', 0.045), ('semantic', 0.045), ('sample', 0.043), ('type', 0.043), ('agglomerative', 0.043), ('doctor', 0.043), ('generative', 0.042), ('tokens', 0.041), ('mixture', 0.04), ('discovering', 0.04), ('drugs', 0.04), ('edema', 0.039), ('hunger', 0.039), ('jcw', 0.039), ('tidal', 0.039), ('viegas', 0.039), ('class', 0.039), ('rr', 0.038), ('reveal', 0.038), ('blei', 0.035), ('clustered', 0.035), ('detected', 0.034), ('amig', 0.034), ('doctors', 0.034), ('hospitals', 0.034), ('trr', 0.034), ('tumor', 0.034), ('page', 0.034), ('annotated', 0.032), ('pantel', 0.032), ('concept', 0.032), ('manually', 0.031), ('administered', 0.031), ('crp', 0.031), ('discharge', 0.031), ('unsupervised', 0.03), ('problems', 0.03), ('pairs', 0.029), ('pq', 0.029), ('assess', 0.027), ('context', 0.027), ('dropped', 0.027), ('instances', 0.027), ('challenge', 0.027), ('ford', 0.027), ('triggered', 0.027), ('agichtein', 0.027), ('cars', 0.027), ('disease', 0.027), ('night', 0.027), ('texas', 0.027), ('accurately', 0.026), ('mutual', 0.026), ('causal', 0.025), ('detect', 0.025), ('griffiths', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="14-tfidf-1" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>Author: Bryan Rink ; Sanda Harabagiu</p><p>Abstract: This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. The model discovers relation instances and their types by determining which context tokens express the relation. Additionally, the valid semantic classes for each type of relation are determined. We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. The discovered relations reveal some of the implicit semantic structure present in patient records.</p><p>2 0.29786313 <a title="14-tfidf-2" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>3 0.20497724 <a title="14-tfidf-3" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>Author: Chang Wang ; James Fan ; Aditya Kalyanpur ; David Gondek</p><p>Abstract: This paper describes a novel approach to the semantic relation detection problem. Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors. Specifically, we detect a new semantic relation by projecting the new relation’s training instances onto a lower dimension topic space constructed from existing relation detectors through a three step process. First, we construct a large relation repository of more than 7,000 relations from Wikipedia. Second, we construct a set of non-redundant relation topics defined at multiple scales from the relation repository to characterize the existing relations. Similar to the topics defined over words, each relation topic is an interpretable multinomial distribution over the existing relations. Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations. The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.</p><p>4 0.14969407 <a title="14-tfidf-4" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>Author: Marjorie Freedman ; Lance Ramshaw ; Elizabeth Boschee ; Ryan Gabbard ; Gary Kratkiewicz ; Nicolas Ward ; Ralph Weischedel</p><p>Abstract: We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.5 1 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1.</p><p>5 0.14747876 <a title="14-tfidf-5" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>Author: Sebastian Riedel ; Andrew McCallum</p><p>Abstract: Extracting biomedical events from literature has attracted much recent attention. The bestperforming systems so far have been pipelines of simple subtask-specific local classifiers. A natural drawback of such approaches are cascading errors introduced in early stages of the pipeline. We present three joint models of increasing complexity designed to overcome this problem. The first model performs joint trigger and argument extraction, and lends itself to a simple, efficient and exact inference algorithm. The second model captures correlations between events, while the third model ensures consistency between arguments of the same event. Inference in these models is kept tractable through dual decomposition. The first two models outperform the previous best joint approaches and are very competitive with respect to the current state-of-theart. The third model yields the best results reported so far on the BioNLP 2009 shared task, the BioNLP 2011 Genia task and the BioNLP 2011Infectious Diseases task.</p><p>6 0.14174367 <a title="14-tfidf-6" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>7 0.11108883 <a title="14-tfidf-7" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>8 0.10899357 <a title="14-tfidf-8" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>9 0.08967559 <a title="14-tfidf-9" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>10 0.084316753 <a title="14-tfidf-10" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>11 0.083401553 <a title="14-tfidf-11" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>12 0.078723468 <a title="14-tfidf-12" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>13 0.078497969 <a title="14-tfidf-13" href="./emnlp-2011-Discovering_Relations_between_Noun_Categories.html">40 emnlp-2011-Discovering Relations between Noun Categories</a></p>
<p>14 0.075390555 <a title="14-tfidf-14" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>15 0.074181758 <a title="14-tfidf-15" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>16 0.07373973 <a title="14-tfidf-16" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>17 0.068572693 <a title="14-tfidf-17" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>18 0.066360563 <a title="14-tfidf-18" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>19 0.06439247 <a title="14-tfidf-19" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>20 0.063899539 <a title="14-tfidf-20" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.205), (1, -0.196), (2, -0.293), (3, 0.029), (4, -0.154), (5, -0.185), (6, 0.19), (7, -0.006), (8, -0.055), (9, 0.046), (10, 0.038), (11, 0.19), (12, 0.04), (13, -0.119), (14, 0.076), (15, 0.151), (16, -0.057), (17, 0.046), (18, -0.087), (19, 0.06), (20, -0.069), (21, 0.053), (22, -0.003), (23, -0.124), (24, 0.068), (25, -0.052), (26, 0.0), (27, -0.008), (28, 0.098), (29, 0.023), (30, 0.011), (31, -0.048), (32, -0.03), (33, -0.0), (34, -0.03), (35, 0.08), (36, 0.087), (37, 0.044), (38, -0.035), (39, 0.011), (40, -0.084), (41, 0.109), (42, 0.122), (43, -0.06), (44, -0.129), (45, 0.016), (46, 0.022), (47, -0.01), (48, 0.027), (49, 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96190232 <a title="14-lsi-1" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>Author: Bryan Rink ; Sanda Harabagiu</p><p>Abstract: This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. The model discovers relation instances and their types by determining which context tokens express the relation. Additionally, the valid semantic classes for each type of relation are determined. We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. The discovered relations reveal some of the implicit semantic structure present in patient records.</p><p>2 0.8091625 <a title="14-lsi-2" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>3 0.7440387 <a title="14-lsi-3" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>Author: Chang Wang ; James Fan ; Aditya Kalyanpur ; David Gondek</p><p>Abstract: This paper describes a novel approach to the semantic relation detection problem. Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors. Specifically, we detect a new semantic relation by projecting the new relation’s training instances onto a lower dimension topic space constructed from existing relation detectors through a three step process. First, we construct a large relation repository of more than 7,000 relations from Wikipedia. Second, we construct a set of non-redundant relation topics defined at multiple scales from the relation repository to characterize the existing relations. Similar to the topics defined over words, each relation topic is an interpretable multinomial distribution over the existing relations. Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations. The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.</p><p>4 0.56466234 <a title="14-lsi-4" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>Author: Marjorie Freedman ; Lance Ramshaw ; Elizabeth Boschee ; Ryan Gabbard ; Gary Kratkiewicz ; Nicolas Ward ; Ralph Weischedel</p><p>Abstract: We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.5 1 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1.</p><p>5 0.55771506 <a title="14-lsi-5" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>Author: Sebastian Riedel ; Andrew McCallum</p><p>Abstract: Extracting biomedical events from literature has attracted much recent attention. The bestperforming systems so far have been pipelines of simple subtask-specific local classifiers. A natural drawback of such approaches are cascading errors introduced in early stages of the pipeline. We present three joint models of increasing complexity designed to overcome this problem. The first model performs joint trigger and argument extraction, and lends itself to a simple, efficient and exact inference algorithm. The second model captures correlations between events, while the third model ensures consistency between arguments of the same event. Inference in these models is kept tractable through dual decomposition. The first two models outperform the previous best joint approaches and are very competitive with respect to the current state-of-theart. The third model yields the best results reported so far on the BioNLP 2009 shared task, the BioNLP 2011 Genia task and the BioNLP 2011Infectious Diseases task.</p><p>6 0.53413743 <a title="14-lsi-6" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>7 0.47174945 <a title="14-lsi-7" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>8 0.45176357 <a title="14-lsi-8" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>9 0.4439671 <a title="14-lsi-9" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>10 0.43315759 <a title="14-lsi-10" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>11 0.41168213 <a title="14-lsi-11" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>12 0.39730558 <a title="14-lsi-12" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>13 0.38624793 <a title="14-lsi-13" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>14 0.37815219 <a title="14-lsi-14" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>15 0.32218254 <a title="14-lsi-15" href="./emnlp-2011-Discovering_Relations_between_Noun_Categories.html">40 emnlp-2011-Discovering Relations between Noun Categories</a></p>
<p>16 0.30961561 <a title="14-lsi-16" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>17 0.29910907 <a title="14-lsi-17" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>18 0.28594634 <a title="14-lsi-18" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>19 0.27227348 <a title="14-lsi-19" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>20 0.25501454 <a title="14-lsi-20" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.068), (27, 0.011), (36, 0.019), (37, 0.017), (45, 0.066), (53, 0.014), (54, 0.033), (57, 0.023), (62, 0.434), (64, 0.023), (66, 0.041), (69, 0.011), (79, 0.034), (96, 0.081), (98, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89482266 <a title="14-lda-1" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>Author: Bryan Rink ; Sanda Harabagiu</p><p>Abstract: This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. The model discovers relation instances and their types by determining which context tokens express the relation. Additionally, the valid semantic classes for each type of relation are determined. We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. The discovered relations reveal some of the implicit semantic structure present in patient records.</p><p>2 0.87505817 <a title="14-lda-2" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>Author: Nikhil Dinesh ; Aravind Joshi ; Insup Lee</p><p>Abstract: The computation of logical form has been proposed as an intermediate step in the translation of sentences to logic. Logical form encodes the resolution of scope ambiguities. In this paper, we describe experiments on a modestsized corpus of regulation annotated with a novel variant of logical form, called abstract syntax trees (ASTs). The main step in computing ASTs is to order scope-taking operators. A learning model for ranking is adapted for this ordering. We design features by studying the problem ofcomparing the scope ofone operator to another. The scope comparisons are used to compute ASTs, with an F-score of 90.6% on the set of ordering decisons.</p><p>3 0.78351617 <a title="14-lda-3" href="./emnlp-2011-Optimal_Search_for_Minimum_Error_Rate_Training.html">100 emnlp-2011-Optimal Search for Minimum Error Rate Training</a></p>
<p>Author: Michel Galley ; Chris Quirk</p><p>Abstract: Minimum error rate training is a crucial component to many state-of-the-art NLP applications, such as machine translation and speech recognition. However, common evaluation functions such as BLEU or word error rate are generally highly non-convex and thus prone to search errors. In this paper, we present LP-MERT, an exact search algorithm for minimum error rate training that reaches the global optimum using a series of reductions to linear programming. Given a set of N-best lists produced from S input sentences, this algorithm finds a linear model that is globally optimal with respect to this set. We find that this algorithm is polynomial in N and in the size of the model, but exponential in S. We present extensions of this work that let us scale to reasonably large tuning sets (e.g., one thousand sentences), by either searching only promising regions of the parameter space, or by using a variant of LP-MERT that relies on a beam-search approximation. Experimental results show improvements over the standard Och algorithm.</p><p>4 0.52818495 <a title="14-lda-4" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>Author: Chang Wang ; James Fan ; Aditya Kalyanpur ; David Gondek</p><p>Abstract: This paper describes a novel approach to the semantic relation detection problem. Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors. Specifically, we detect a new semantic relation by projecting the new relation’s training instances onto a lower dimension topic space constructed from existing relation detectors through a three step process. First, we construct a large relation repository of more than 7,000 relations from Wikipedia. Second, we construct a set of non-redundant relation topics defined at multiple scales from the relation repository to characterize the existing relations. Similar to the topics defined over words, each relation topic is an interpretable multinomial distribution over the existing relations. Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations. The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.</p><p>5 0.49463463 <a title="14-lda-5" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>6 0.47763065 <a title="14-lda-6" href="./emnlp-2011-Discovering_Relations_between_Noun_Categories.html">40 emnlp-2011-Discovering Relations between Noun Categories</a></p>
<p>7 0.45266017 <a title="14-lda-7" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>8 0.43350068 <a title="14-lda-8" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>9 0.41530818 <a title="14-lda-9" href="./emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">94 emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>10 0.40249267 <a title="14-lda-10" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>11 0.40223587 <a title="14-lda-11" href="./emnlp-2011-Tuning_as_Ranking.html">138 emnlp-2011-Tuning as Ranking</a></p>
<p>12 0.40055075 <a title="14-lda-12" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>13 0.39097679 <a title="14-lda-13" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>14 0.39026994 <a title="14-lda-14" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>15 0.38428801 <a title="14-lda-15" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>16 0.3840186 <a title="14-lda-16" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>17 0.37822568 <a title="14-lda-17" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>18 0.37813398 <a title="14-lda-18" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>19 0.37294772 <a title="14-lda-19" href="./emnlp-2011-Domain-Assisted_Product_Aspect_Hierarchy_Generation%3A_Towards_Hierarchical_Organization_of_Unstructured_Consumer_Reviews.html">43 emnlp-2011-Domain-Assisted Product Aspect Hierarchy Generation: Towards Hierarchical Organization of Unstructured Consumer Reviews</a></p>
<p>20 0.37214497 <a title="14-lda-20" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
