<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-78" href="#">emnlp2011-78</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</h1>
<br/><p>Source: <a title="emnlp-2011-78-pdf" href="http://aclweb.org/anthology//D/D11/D11-1060.pdf">pdf</a></p><p>Author: Su Nam Kim ; Preslav Nakov</p><p>Abstract: Responding to the need for semantic lexical resources in natural language processing applications, we examine methods to acquire noun compounds (NCs), e.g., orange juice, together with suitable fine-grained semantic interpretations, e.g., squeezed from, which are directly usable as paraphrases. We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations. In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved accuracy due to stronger semantic restrictions.</p><p>Reference: <a title="emnlp-2011-78-reference" href="../emnlp2011_reference/emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 au Abstract Responding to the need for semantic lexical resources in natural language processing applications, we examine methods to acquire noun compounds (NCs), e. [sent-4, score-0.401]
</p><p>2 We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations. [sent-9, score-0.723]
</p><p>3 In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved  accuracy due to stronger semantic restrictions. [sent-10, score-0.338]
</p><p>4 1 Introduction Noun compounds (NCs) such as malaria mosquito and colon cancer tumor suppressor protein are challenging for text processing since the relationship between the nouns they are composed of is implicit. [sent-11, score-0.457]
</p><p>5 For example, a question answering system might need to know whether protein acting as a tumor suppressor is a good paraphrase for tumor suppressor protein. [sent-13, score-0.19]
</p><p>6 Similarly, a machine translation system facing the unknown noun compound Geneva headquarters might translate it better if it could first paraphrase it as Geneva headquarters of the WTO. [sent-14, score-0.332]
</p><p>7 Given a query for “migraine treatment”, an information retrieval system could use paraphrasing verbs like relieve and prevent for query expansion and result ranking. [sent-15, score-0.261]
</p><p>8 Most work on noun compound interpretation has focused on two-word NCs. [sent-19, score-0.348]
</p><p>9 There have been two general lines ofresearch: the first one derives the NC semantics from the semantics of the nouns it is made of (Rosario and Hearst, 2002; Moldovan et al. [sent-20, score-0.23]
</p><p>10 For example, while most NCs expressing MAKE, can be paraphrased by common patterns like be made of and be composed of, some NCs allow more specific patterns, e. [sent-31, score-0.257]
</p><p>11 Recently, the idea of using fine-grained paraphrasing verbs for NC semantics has been gaining popularity (Butnariu and Veale, 2008; Nakov, 2008b); there has also been a related shared task at SemEval-2010 (Butnariu et al. [sent-34, score-0.266]
</p><p>12 First, we extract NCs using a small number of seed patterns from a given abstract relation. [sent-46, score-0.253]
</p><p>13 This is repeated until no new NCs and patterns can be extracted or for a pre-specified number of iterations. [sent-48, score-0.195]
</p><p>14 2  Related Work  As we mentioned above, the implicit relation between the two nouns forming a noun compound can often be expressed overtly using verbal and prepositional paraphrases. [sent-54, score-0.381]
</p><p>15 649 Thus, many NLP approaches to NC semantics have used verbs and prepositions as a fine-grained semantic representation or as features when predicting coarse-grained abstract relations. [sent-56, score-0.292]
</p><p>16 Using a distribution over verbs as a semantic interpretation was also carried out in a recent challenge: SemEval-2010 Task 9 (Butnariu et al. [sent-62, score-0.227]
</p><p>17 In noun compound interpretation, verbs and prepositions can be seen as patterns connecting the two nouns in a paraphrase. [sent-65, score-0.672]
</p><p>18 For example, Hearst (1992) extracted hyponyms using patterns such as X, Y, and/or other Zs, where Z is a hypernym of X and Y. [sent-67, score-0.195]
</p><p>19 For example, Riloff and Jones (1999) used a multi-level bootstrapping algorithm to learn both a semantic lexicon and extraction patterns, e. [sent-73, score-0.367]
</p><p>20 That is, they learned semantic lexicons using extraction patterns, and then, alternatively, they extracted new patterns using these lexicons. [sent-76, score-0.279]
</p><p>21 They also introduced a second level of bootstrapping to retain the most reliable examples only. [sent-77, score-0.283]
</p><p>22 Bootstrapping has been applied to noun compound extraction as well. [sent-81, score-0.322]
</p><p>23 For example, Kim and Baldwin (2007) used it to produce a large number of semantically interpreted noun compounds from a small number of seeds. [sent-82, score-0.351]
</p><p>24 While the method acquired a large number of noun compounds without significant semantic drifting, its accuracy degraded rapidly after each iteration. [sent-85, score-0.401]
</p><p>25 Recently, Kozareva and Hovy (2010) combined patterns and bootstrapping to learn the selectional restrictions for various semantic relations. [sent-87, score-0.485]
</p><p>26 , is made of is arguably better than looks like or is dipped in for MAKE), and thus proposed that the semantics of a noun compound should be expressed as a distribution over multiple possible paraphrases. [sent-101, score-0.39]
</p><p>27 650 It easily follows that the semantics of abstract relations such as MAKE that can hold between the nouns in an NC can be represented in the same way: as a distribution over paraphrasing verbs and prepositions. [sent-104, score-0.366]
</p><p>28 For example, malaria mosquito, which expresses CAUSE, can be paraphrased using verbs like carry, which do not imply direct causation. [sent-106, score-0.202]
</p><p>29 Traditionally, the semantics of a noun compound have been represented as an abstract relation drawn from a small closed set. [sent-108, score-0.391]
</p><p>30 Moreover, speakers often use verbs to make the hidden relation between the noun in a noun compound overt. [sent-118, score-0.584]
</p><p>31 4  Method  We harvest noun compounds expressing some target abstract semantic relation (in the experiments below, this is Levi’s MAKE2), starting from a small number  of initial seed patterns: paraphrasing verbs and/or prepositions. [sent-124, score-0.735]
</p><p>32 Optionally, we might also be given a small number of noun compounds that instantiate the target abstract relation. [sent-125, score-0.351]
</p><p>33 We then learn more noun compounds and patterns for the relation by alternating between the following two bootstrapping steps, using the Web as a corpus. [sent-126, score-0.82]
</p><p>34 First, we extract more noun compounds that are paraphrasable with the available patterns (see Section 4. [sent-127, score-0.583]
</p><p>35 We then look for new patterns that can paraphrase the newlyextracted noun compounds (see Section 4. [sent-129, score-0.547]
</p><p>36 These two steps are repeated until no new noun compounds can be extracted or until a pre-determined number of iterations has been reached. [sent-131, score-0.423]
</p><p>37 (+ HPa/Mt eornf sNCs)  Figure 1: Our bootstrapping algorithm. [sent-133, score-0.283]
</p><p>38 1 Bootstrapping Step 1: Noun Compound Extraction Given a list of patterns (verbs and/or prepositions), we mine the Web to extract noun compounds that  match these patterns. [sent-135, score-0.531]
</p><p>39 We experiment with the following three bootstrapping strategies for this step:  •  •  •  651 Loose bootstrapping uses the available patLteronoss ean bdo imposes no gfu urtsheesr trheestr aivcatiiolnabs. [sent-136, score-0.566]
</p><p>40 l Strict bootstrapping requires that, in addition tSot tihcet patterns themselves, some noun compounds matching each pattern be made available as well. [sent-137, score-0.894]
</p><p>41 A pattern is only instantiated in the context of either the head or the modifier of a noun compound that is known to match it. [sent-138, score-0.497]
</p><p>42 NC-only strict bootstrapping is a stricter versNioCn- oonfl ystr sitcrtic bootstrapping, gwh ise are s ttrhiect elirs tv eor-f patterns is limited to the initial seeds. [sent-139, score-0.618]
</p><p>43 Below we describe each of the sub-steps of the NC extraction process: query generation, snippet harvesting, and noun compound acquisition & filtering. [sent-140, score-0.415]
</p><p>44 We use the first pattern for loose bootstrapping and the other two for both strict bootstrapping and NC-only strict bootstrapping. [sent-145, score-1.107]
</p><p>45 If we are further given the NC orange juice, we could also produce " j uice that was made o f * " and " * that i made o f orange s " . [sent-152, score-0.244]
</p><p>46 3 NC Extraction and Filtering Next, we process the snippets returned by the search engine and we acquire potential noun compounds from them. [sent-158, score-0.429]
</p><p>47 For loose bootstrapping, we extract two nouns, one from each end of the matched pattern, while for strict bootstrapping and for NC-only strict boot-  strapping, we only extract one noun, either preceding or following the pattern, since the other noun is already fixed. [sent-160, score-0.95]
</p><p>48 We then lemmatize the extracted noun(s) and we form NC candidates from the two arguments of the instantiated pattern, taking into account whether the pattern is active or passive. [sent-161, score-0.194]
</p><p>49 the head or the modifier are not both listed as nouns in WordNet (Fellbaum, 1998); 4. [sent-180, score-0.193]
</p><p>50 2 Bootstrapping Step 2: Pattern Extraction This is the second step of our bootstrapping algorithm as shown on Figure 1. [sent-184, score-0.283]
</p><p>51 Given a list of noun compounds, we mine the Web to extract patterns: verbs and/or prepositions that can paraphrase each  NC. [sent-185, score-0.39]
</p><p>52 For example, given orange juice, we could generate queries like " j uice that * orange s " , " j uice s whi ch * * * * * * orange s " , and " j uice s * * * orange " . [sent-194, score-0.452]
</p><p>53 We further make sure that the word sequence following the second mentioned target noun is nonempty and contains at least one non-noun, thus ensuring the snippet includes the entire noun phrase. [sent-208, score-0.351]
</p><p>54 Finally, we lemmatize the verbs to form the patterns candidates, and we apply the following pattern selection rules: 1. [sent-211, score-0.383]
</p><p>55 we filter out all patterns that were provided as initial seeds or were extracted previously; 2. [sent-212, score-0.195]
</p><p>56 we filter out all patterns that were extracted less than N times (we tried 5 and 10) and with less than M NCs per pattern (we tried 20 and 50). [sent-214, score-0.27]
</p><p>57 In this theory, noun compounds are derived from underlying relative clauses or noun phrase complement constructions by means of two general processes: predicate deletion and predicate nominalization. [sent-216, score-0.598]
</p><p>58 According rteoq Levi, predicate dnteilaelti roenfu can be applied to abstract predicates, whose semantics can be roughly approximated using five paraphrasing verbs (CAUSE, HAVE, MAKE, USE, and BE) and four  prepositions (IN, FOR, FROM, and ABOUT). [sent-225, score-0.373]
</p><p>59 653 Typically, in predicate deletion, the modifier is derived from the object of the underlying relative clause; however, the first three verbs also allow for it to be derived from the subject. [sent-226, score-0.25]
</p><p>60 In Levi’s theory, MAKE2 means that the head of the noun compound is made up of or is a product of its modifier. [sent-238, score-0.373]
</p><p>61 , chocolate bar; (c) the head represents human collectives and the modifier specifies their membership, e. [sent-243, score-0.19]
</p><p>62 As seed patterns, we use a subset of the humanproposed paraphrasing verbs and prepositions corresponding to these 20 NCs in the dataset in (Nakov, 2008b), where each NC is paraphrased by 25-30 annotators. [sent-247, score-0.371]
</p><p>63 Note that some patterns can paraphrase multiple NCs: the total number of seed NC-pattern pairs is 84. [sent-257, score-0.269]
</p><p>64 , taste like do not express the target relation MAKE2, we kept them anyway since they were proposed by several human annotators and since they do express the fine-grained semantics of some particular instances of that relation; thus, we thought they might be useful, even for the general relation. [sent-261, score-0.202]
</p><p>65 For example, taste like has been proposed 8 times for candy cigarette, 7 times for chocolate bar, and 2 times for sugar cube, and thus  it clearly correlates well with some seed examples, even if it does not express MAKE2 in general. [sent-262, score-0.201]
</p><p>66 6  Experiments and Evaluation  Using the NCs and patterns in Table 1 as initial seeds, we ran our algorithm for three iterations of loose bootstrapping and strict bootstrapping, and for two iterations of NC-only strict bootstrapping. [sent-263, score-0.959]
</p><p>67 We only performed up to three iterations because of the huge number of noun compounds extracted for NC-only strict bootstrapping (which we only ran for two iterations) and because of the low number of new NCs extracted by loose bootstrapping on iteration 3. [sent-264, score-1.346]
</p><p>68 While we could have run strict bootstrapping for more iterations, we opted for a comparable number of iterations for all three methods. [sent-265, score-0.495]
</p><p>69 Examples of noun compounds that we have extracted are bronze bell (be made of, be made from) and child team (be composed of, include). [sent-266, score-0.487]
</p><p>70 4539–––– Strict Bootstrapping  NC-only Strict Bootstrapping  Table 2: Total number and accuracy in % for NCs, patterns and NC-pattern pairs extracted and retained for each of the three methods over all iterations. [sent-281, score-0.227]
</p><p>71 3, at each iteration, we filtered out all patterns that were extracted less than N times or with less than M NCs. [sent-285, score-0.195]
</p><p>72 Note that we only used the 10 most frequent NCs per pattern as NC seeds for NC extraction in the next iteration of strict bootstrapping and NC-only strict bootstrapping. [sent-286, score-0.789]
</p><p>73 Patterns are subject to  particular NCs, and thus we show (1) the number of patterns extracted with all NCs, i. [sent-289, score-0.195]
</p><p>74 , unique NCpattern pairs, (2) the accuracy of these  pairs,4  and  (3) the number of unique patterns retained after filtering, which will be used to extract new noun compounds on the second step of the current iteration. [sent-291, score-0.563]
</p><p>75 Thus, the same bootstrapping technique evaluated against a fixed set of semantic relations (which is the more traditional approach) could arguably show bootstrapping going “offthe rails” more quickly than what we observe here. [sent-294, score-0.657]
</p><p>76 For patterns, we show the number of unique NC-pattern pairs extracted, their accuracy in %, and the number of unique patterns retained and used to extract NCs on the second step of the current iteration. [sent-316, score-0.212]
</p><p>77 All NCs were judged, except for iteration 2 of NC-only strict bootstrapping, where their number was prohibitively high and only the most frequent noun compounds extracted for each modifier and for each head were checked: 9,004 NCs for N=5 and 4,262 NCs for N=10. [sent-323, score-0.742]
</p><p>78 7  Discussion  Tables 2 and 3 show that fixing one of the two nouns in the pattern, as in strict bootstrapping and NC-only strict bootstrapping, yields significantly higher accuracy (χ2 test) for both NC and NC-pattern pair extraction compared to loose bootstrapping. [sent-332, score-0.842]
</p><p>79 655 The accuracy for NC-only strict bootstrapping is a bit higher than for strict bootstrapping, but the actual differences are probably smaller since the evaluation of the former on iteration 2 was done for the most frequent NCs, which are more accurate. [sent-333, score-0.68]
</p><p>80 Note that the number of extracted NCs is much higher with the strict methods because of the higher number of possible instantiations of the generalized query patterns. [sent-334, score-0.288]
</p><p>81 For NC-only strict bootstrapping, the number of extracted NCs grows exponentially since the number of patterns does not diminish as in the other two methods. [sent-335, score-0.378]
</p><p>82 The number of extracted patterns is similar for the different methods since we select no more than 20 of them per iteration. [sent-336, score-0.195]
</p><p>83 Note also the exception of loose bootstrapping on iteration 3. [sent-338, score-0.414]
</p><p>84 Note, however, the exception of loose bootstrapping for the first two iterations, where the less restrictive N=5 is more accurate. [sent-340, score-0.383]
</p><p>85 The results for three bootstrapping iterations using the same list of 20 initial seed NCs as in our previous experiments, are shown in Table 4. [sent-353, score-0.385]
</p><p>86 Moreover, for each extracted noun compound, we also generated a list of fine-grained paraphrasing verbs. [sent-356, score-0.268]
</p><p>87 ”, demand was tagged as a noun and thus extracted as an NC modifier instead ofgold. [sent-362, score-0.27]
</p><p>88 , while contain is a good paraphrase for toy box, the noun compound itself is not an instance of MAKE2. [sent-374, score-0.332]
</p><p>89 collocation strength for strict bootstrapping with N=5, M=50 for all three iterations (the results for the other experiments show a similar trend). [sent-384, score-0.524]
</p><p>90 9  Conclusion and Future Work  We have presented a framework for building a very large dataset of noun compounds expressing a given target abstract semantic relation. [sent-388, score-0.401]
</p><p>91 For each extracted noun compound, we generated a corresponding finegrained semantic interpretation: a frequency distribution over suitable paraphrasing verbs. [sent-389, score-0.318]
</p><p>92 We believe that having a large-scale dataset of noun compounds interpreted with both fine- and coarse-grained semantic relations would be an important contribution to the debate about which representation is preferable for different tasks. [sent-391, score-0.442]
</p><p>93 It should also help the overall advancement of the field of noun compound interpretation. [sent-392, score-0.288]
</p><p>94 Semeval-2010 task 9: The interpretation of noun compounds using paraphrasing verbs and prepositions. [sent-411, score-0.608]
</p><p>95 SemEval-2010 task 9: The interpretation of noun compounds using paraphrasing verbs and prepositions. [sent-415, score-0.608]
</p><p>96 Improving the interpretation of noun phrases with cross-linguistic information. [sent-465, score-0.205]
</p><p>97 Interpreting semantic relations in noun compounds via verb semantics. [sent-481, score-0.442]
</p><p>98 Classifying the semantic relations in noun compounds via a domain-specific lexical hierarchy. [sent-551, score-0.442]
</p><p>99 A bootstrapping method for learning semantic lexicons using extraction pattern contexts. [sent-571, score-0.442]
</p><p>100 A taxonomy, dataset, and classifier for automatic noun compound interpretation. [sent-575, score-0.288]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ncs', 0.597), ('nc', 0.294), ('bootstrapping', 0.283), ('compounds', 0.206), ('strict', 0.183), ('nakov', 0.169), ('patterns', 0.152), ('noun', 0.145), ('compound', 0.143), ('butnariu', 0.13), ('verbs', 0.117), ('levi', 0.112), ('preslav', 0.101), ('loose', 0.1), ('modifier', 0.082), ('paraphrasing', 0.08), ('pattern', 0.075), ('seed', 0.073), ('nam', 0.071), ('semantics', 0.069), ('girju', 0.063), ('hearst', 0.063), ('orange', 0.063), ('kim', 0.063), ('stan', 0.062), ('snippet', 0.061), ('interpretation', 0.06), ('nouns', 0.059), ('prepositions', 0.056), ('chocolate', 0.056), ('szpakowicz', 0.053), ('head', 0.052), ('juice', 0.052), ('mosquito', 0.052), ('paraphrasable', 0.052), ('rosario', 0.052), ('tatu', 0.052), ('uice', 0.052), ('predicate', 0.051), ('roxana', 0.051), ('semantic', 0.05), ('marti', 0.047), ('statue', 0.045), ('taste', 0.045), ('paraphrased', 0.045), ('wordnet', 0.045), ('snippets', 0.044), ('bar', 0.044), ('paraphrase', 0.044), ('queries', 0.044), ('extracted', 0.043), ('baldwin', 0.042), ('relations', 0.041), ('nastase', 0.04), ('malaria', 0.04), ('moldovan', 0.04), ('mod', 0.04), ('passive', 0.04), ('cristina', 0.039), ('lemmatize', 0.039), ('migraine', 0.039), ('suppressor', 0.039), ('veale', 0.039), ('arguments', 0.037), ('su', 0.035), ('water', 0.035), ('kozareva', 0.035), ('eaghdha', 0.035), ('engine', 0.034), ('relation', 0.034), ('extraction', 0.034), ('tumor', 0.034), ('marta', 0.034), ('vivi', 0.034), ('inflected', 0.033), ('diarmuid', 0.033), ('judged', 0.033), ('made', 0.033), ('query', 0.032), ('retained', 0.032), ('curran', 0.031), ('iteration', 0.031), ('harvest', 0.03), ('mcintosh', 0.03), ('inventory', 0.03), ('instantiations', 0.03), ('iterations', 0.029), ('collocation', 0.029), ('timothy', 0.029), ('filtering', 0.029), ('tratz', 0.028), ('cup', 0.028), ('tony', 0.028), ('drift', 0.028), ('web', 0.028), ('extract', 0.028), ('express', 0.027), ('composed', 0.027), ('riloff', 0.027), ('hypernyms', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="78-tfidf-1" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>Author: Su Nam Kim ; Preslav Nakov</p><p>Abstract: Responding to the need for semantic lexical resources in natural language processing applications, we examine methods to acquire noun compounds (NCs), e.g., orange juice, together with suitable fine-grained semantic interpretations, e.g., squeezed from, which are directly usable as paraphrases. We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations. In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved accuracy due to stronger semantic restrictions.</p><p>2 0.15279742 <a title="78-tfidf-2" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>Author: Stijn De Saeger ; Kentaro Torisawa ; Masaaki Tsuchida ; Jun'ichi Kazama ; Chikara Hashimoto ; Ichiro Yamada ; Jong Hoon Oh ; Istvan Varga ; Yulan Yan</p><p>Abstract: This paper proposes a semi-supervised relation acquisition method that does not rely on extraction patterns (e.g. “X causes Y” for causal relations) but instead learns a combination of indirect evidence for the target relation semantic word classes and partial patterns. This method can extract long tail instances of semantic relations like causality from rare and complex expressions in a large Japanese Web corpus in extreme cases, patterns that occur only once in the entire corpus. Such patterns are beyond the reach ofcurrent pattern based methods. We show that our method performs on par with state-of-the-art pattern based methods, and maintains a reasonable level of accuracy even for instances — — acquired from infrequent patterns. This ability to acquire long tail instances is crucial for risk management and innovation, where an exhaustive database of high-level semantic relations like causation is of vital importance.</p><p>3 0.12947388 <a title="78-tfidf-3" href="./emnlp-2011-Splitting_Noun_Compounds_via_Monolingual_and_Bilingual_Paraphrasing%3A_A_Study_on_Japanese_Katakana_Words.html">124 emnlp-2011-Splitting Noun Compounds via Monolingual and Bilingual Paraphrasing: A Study on Japanese Katakana Words</a></p>
<p>Author: Nobuhiro Kaji ; Masaru Kitsuregawa</p><p>Abstract: Word boundaries within noun compounds are not marked by white spaces in a number of languages, unlike in English, and it is beneficial for various NLP applications to split such noun compounds. In the case of Japanese, noun compounds made up of katakana words (i.e., transliterated foreign words) are particularly difficult to split, because katakana words are highly productive and are often outof-vocabulary. To overcome this difficulty, we propose using monolingual and bilingual paraphrases of katakana noun compounds for identifying word boundaries. Experiments demonstrated that splitting accuracy is substantially improved by extracting such paraphrases from unlabeled textual data, the Web in our case, and then using that information for constructing splitting models.</p><p>4 0.12082221 <a title="78-tfidf-4" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>Author: Marjorie Freedman ; Lance Ramshaw ; Elizabeth Boschee ; Ryan Gabbard ; Gary Kratkiewicz ; Nicolas Ward ; Ralph Weischedel</p><p>Abstract: We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.5 1 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1.</p><p>5 0.088664927 <a title="78-tfidf-5" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>Author: Lukas Michelbacher ; Alok Kothari ; Martin Forst ; Christina Lioma ; Hinrich Schutze</p><p>Abstract: Most NLP systems use tokenization as part of preprocessing. Generally, tokenizers are based on simple heuristics and do not recognize multi-word units (MWUs) like hot dog or black hole unless a precompiled list of MWUs is available. In this paper, we propose a new cascaded model for detecting MWUs of arbitrary length for tokenization, focusing on noun phrases in the physics domain. We adopt a classification approach because unlike other work on MWUs – tokenization requires a completely automatic approach. We achieve an accuracy of 68% for recognizing non-compositional MWUs and show that our MWU recognizer improves retrieval performance when used as part of an information retrieval system. – 1</p><p>6 0.075707838 <a title="78-tfidf-6" href="./emnlp-2011-A_Generate_and_Rank_Approach_to_Sentence_Paraphrasing.html">6 emnlp-2011-A Generate and Rank Approach to Sentence Paraphrasing</a></p>
<p>7 0.070398703 <a title="78-tfidf-7" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>8 0.064407468 <a title="78-tfidf-8" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>9 0.064098001 <a title="78-tfidf-9" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>10 0.060461838 <a title="78-tfidf-10" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>11 0.058701623 <a title="78-tfidf-11" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>12 0.058549043 <a title="78-tfidf-12" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>13 0.057490285 <a title="78-tfidf-13" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>14 0.052823957 <a title="78-tfidf-14" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>15 0.048896383 <a title="78-tfidf-15" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>16 0.046706825 <a title="78-tfidf-16" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>17 0.045616131 <a title="78-tfidf-17" href="./emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">23 emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p>18 0.04550698 <a title="78-tfidf-18" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>19 0.044972483 <a title="78-tfidf-19" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>20 0.044844113 <a title="78-tfidf-20" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.157), (1, -0.075), (2, -0.119), (3, -0.001), (4, -0.027), (5, -0.155), (6, 0.001), (7, 0.149), (8, -0.039), (9, 0.106), (10, 0.032), (11, -0.051), (12, 0.08), (13, -0.026), (14, -0.084), (15, -0.036), (16, -0.055), (17, -0.21), (18, 0.033), (19, 0.067), (20, 0.208), (21, -0.081), (22, 0.01), (23, 0.045), (24, 0.015), (25, 0.045), (26, 0.058), (27, 0.037), (28, -0.124), (29, -0.133), (30, -0.273), (31, -0.047), (32, -0.071), (33, -0.049), (34, -0.045), (35, -0.007), (36, -0.199), (37, 0.029), (38, 0.023), (39, -0.035), (40, -0.051), (41, -0.074), (42, -0.076), (43, 0.093), (44, -0.026), (45, 0.02), (46, 0.062), (47, -0.015), (48, 0.083), (49, 0.122)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96121043 <a title="78-lsi-1" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>Author: Su Nam Kim ; Preslav Nakov</p><p>Abstract: Responding to the need for semantic lexical resources in natural language processing applications, we examine methods to acquire noun compounds (NCs), e.g., orange juice, together with suitable fine-grained semantic interpretations, e.g., squeezed from, which are directly usable as paraphrases. We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations. In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved accuracy due to stronger semantic restrictions.</p><p>2 0.72741574 <a title="78-lsi-2" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>Author: Stijn De Saeger ; Kentaro Torisawa ; Masaaki Tsuchida ; Jun'ichi Kazama ; Chikara Hashimoto ; Ichiro Yamada ; Jong Hoon Oh ; Istvan Varga ; Yulan Yan</p><p>Abstract: This paper proposes a semi-supervised relation acquisition method that does not rely on extraction patterns (e.g. “X causes Y” for causal relations) but instead learns a combination of indirect evidence for the target relation semantic word classes and partial patterns. This method can extract long tail instances of semantic relations like causality from rare and complex expressions in a large Japanese Web corpus in extreme cases, patterns that occur only once in the entire corpus. Such patterns are beyond the reach ofcurrent pattern based methods. We show that our method performs on par with state-of-the-art pattern based methods, and maintains a reasonable level of accuracy even for instances — — acquired from infrequent patterns. This ability to acquire long tail instances is crucial for risk management and innovation, where an exhaustive database of high-level semantic relations like causation is of vital importance.</p><p>3 0.57719332 <a title="78-lsi-3" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>Author: Marjorie Freedman ; Lance Ramshaw ; Elizabeth Boschee ; Ryan Gabbard ; Gary Kratkiewicz ; Nicolas Ward ; Ralph Weischedel</p><p>Abstract: We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.5 1 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1.</p><p>4 0.55352902 <a title="78-lsi-4" href="./emnlp-2011-Splitting_Noun_Compounds_via_Monolingual_and_Bilingual_Paraphrasing%3A_A_Study_on_Japanese_Katakana_Words.html">124 emnlp-2011-Splitting Noun Compounds via Monolingual and Bilingual Paraphrasing: A Study on Japanese Katakana Words</a></p>
<p>Author: Nobuhiro Kaji ; Masaru Kitsuregawa</p><p>Abstract: Word boundaries within noun compounds are not marked by white spaces in a number of languages, unlike in English, and it is beneficial for various NLP applications to split such noun compounds. In the case of Japanese, noun compounds made up of katakana words (i.e., transliterated foreign words) are particularly difficult to split, because katakana words are highly productive and are often outof-vocabulary. To overcome this difficulty, we propose using monolingual and bilingual paraphrases of katakana noun compounds for identifying word boundaries. Experiments demonstrated that splitting accuracy is substantially improved by extracting such paraphrases from unlabeled textual data, the Web in our case, and then using that information for constructing splitting models.</p><p>5 0.5348652 <a title="78-lsi-5" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>Author: Lukas Michelbacher ; Alok Kothari ; Martin Forst ; Christina Lioma ; Hinrich Schutze</p><p>Abstract: Most NLP systems use tokenization as part of preprocessing. Generally, tokenizers are based on simple heuristics and do not recognize multi-word units (MWUs) like hot dog or black hole unless a precompiled list of MWUs is available. In this paper, we propose a new cascaded model for detecting MWUs of arbitrary length for tokenization, focusing on noun phrases in the physics domain. We adopt a classification approach because unlike other work on MWUs – tokenization requires a completely automatic approach. We achieve an accuracy of 68% for recognizing non-compositional MWUs and show that our MWU recognizer improves retrieval performance when used as part of an information retrieval system. – 1</p><p>6 0.37545809 <a title="78-lsi-6" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>7 0.30442277 <a title="78-lsi-7" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>8 0.27040768 <a title="78-lsi-8" href="./emnlp-2011-Corpus-Guided_Sentence_Generation_of_Natural_Images.html">34 emnlp-2011-Corpus-Guided Sentence Generation of Natural Images</a></p>
<p>9 0.26407117 <a title="78-lsi-9" href="./emnlp-2011-A_Generate_and_Rank_Approach_to_Sentence_Paraphrasing.html">6 emnlp-2011-A Generate and Rank Approach to Sentence Paraphrasing</a></p>
<p>10 0.2531839 <a title="78-lsi-10" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>11 0.24617721 <a title="78-lsi-11" href="./emnlp-2011-Non-parametric_Bayesian_Segmentation_of_Japanese_Noun_Phrases.html">99 emnlp-2011-Non-parametric Bayesian Segmentation of Japanese Noun Phrases</a></p>
<p>12 0.23527318 <a title="78-lsi-12" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>13 0.22650142 <a title="78-lsi-13" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>14 0.21628061 <a title="78-lsi-14" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>15 0.21440527 <a title="78-lsi-15" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>16 0.2126371 <a title="78-lsi-16" href="./emnlp-2011-Analyzing_Methods_for_Improving_Precision_of_Pivot_Based_Bilingual_Dictionaries.html">18 emnlp-2011-Analyzing Methods for Improving Precision of Pivot Based Bilingual Dictionaries</a></p>
<p>17 0.20635791 <a title="78-lsi-17" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>18 0.20634811 <a title="78-lsi-18" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>19 0.20386203 <a title="78-lsi-19" href="./emnlp-2011-Efficient_retrieval_of_tree_translation_examples_for_Syntax-Based_Machine_Translation.html">47 emnlp-2011-Efficient retrieval of tree translation examples for Syntax-Based Machine Translation</a></p>
<p>20 0.20329487 <a title="78-lsi-20" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.03), (13, 0.315), (23, 0.092), (36, 0.023), (37, 0.016), (45, 0.061), (53, 0.02), (54, 0.032), (57, 0.048), (62, 0.022), (64, 0.014), (66, 0.047), (69, 0.018), (79, 0.032), (82, 0.021), (90, 0.012), (96, 0.07), (98, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73503906 <a title="78-lda-1" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>Author: Su Nam Kim ; Preslav Nakov</p><p>Abstract: Responding to the need for semantic lexical resources in natural language processing applications, we examine methods to acquire noun compounds (NCs), e.g., orange juice, together with suitable fine-grained semantic interpretations, e.g., squeezed from, which are directly usable as paraphrases. We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations. In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved accuracy due to stronger semantic restrictions.</p><p>2 0.41669872 <a title="78-lda-2" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>3 0.41290876 <a title="78-lda-3" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>Author: Burr Settles</p><p>Abstract: This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e.g., words) and instances (e.g., documents). We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort.</p><p>4 0.41202942 <a title="78-lda-4" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>5 0.41078657 <a title="78-lda-5" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>Author: Edward Grefenstette ; Mehrnoosh Sadrzadeh</p><p>Abstract: Modelling compositional meaning for sentences using empirical distributional methods has been a challenge for computational linguists. We implement the abstract categorical model of Coecke et al. (2010) using data from the BNC and evaluate it. The implementation is based on unsupervised learning of matrices for relational words and applying them to the vectors of their arguments. The evaluation is based on the word disambiguation task developed by Mitchell and Lapata (2008) for intransitive sentences, and on a similar new experiment designed for transitive sentences. Our model matches the results of its competitors . in the first experiment, and betters them in the second. The general improvement in results with increase in syntactic complexity showcases the compositional power of our model.</p><p>6 0.40927035 <a title="78-lda-6" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>7 0.40865996 <a title="78-lda-7" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>8 0.40626723 <a title="78-lda-8" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>9 0.40525886 <a title="78-lda-9" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>10 0.40314546 <a title="78-lda-10" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>11 0.40278751 <a title="78-lda-11" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>12 0.40234351 <a title="78-lda-12" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>13 0.40211278 <a title="78-lda-13" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>14 0.40208417 <a title="78-lda-14" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>15 0.40001413 <a title="78-lda-15" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>16 0.39992183 <a title="78-lda-16" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>17 0.39989477 <a title="78-lda-17" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>18 0.39978489 <a title="78-lda-18" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>19 0.39920005 <a title="78-lda-19" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>20 0.3988834 <a title="78-lda-20" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
