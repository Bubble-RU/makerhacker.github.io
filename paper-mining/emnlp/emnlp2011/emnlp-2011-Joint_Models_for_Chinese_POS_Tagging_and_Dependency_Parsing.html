<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-75" href="#">emnlp2011-75</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</h1>
<br/><p>Source: <a title="emnlp-2011-75-pdf" href="http://aclweb.org/anthology//D/D11/D11-1109.pdf">pdf</a></p><p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>Reference: <a title="emnlp-2011-75-reference" href="../emnlp2011_reference/emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Current research usually models POS tagging and dependency parsing independently. [sent-11, score-0.644]
</p><p>2 Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. [sent-13, score-0.466]
</p><p>3 To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. [sent-14, score-0.681]
</p><p>4 We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. [sent-15, score-0.438]
</p><p>5 We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. [sent-16, score-0.34]
</p><p>6 Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1. [sent-17, score-0.552]
</p><p>7 Detailed analysis  shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. [sent-19, score-0.692]
</p><p>8 This is the fundamental reason of parsing accuracy improvement. [sent-20, score-0.355]
</p><p>9 1 Introduction In dependency parsing, features consisting of partof-speech (POS) tags are very effective, since pure lexical features lead to severe data sparseness problem. [sent-21, score-0.399]
</p><p>10 Typically, POS tagging and dependency parsing are modeled in a pipelined way. [sent-22, score-0.939]
</p><p>11 However, the pipelined method is prone to error propagation, especially for Chinese. [sent-23, score-0.368]
</p><p>12 Our experimental results show that parsing accuracy decreases by about 6% on Chinese when using automatic POS tagging results instead of gold ones (see Table 3 in Section  5). [sent-27, score-0.536]
</p><p>13 Recent research on dependency parsing usually overlooks this issue by simply adopting gold POS tags for Chinese data (Duan et al. [sent-28, score-0.612]
</p><p>14 In this paper, we address this issue by jointly optimizing POS tagging and dependency parsing. [sent-30, score-0.429]
</p><p>15 Recently, many successful joint models have been proposed, such as joint tokenization and POS tagging (Zhang and Clark, 2008a; Jiang et al. [sent-32, score-0.765]
</p><p>16 , 2009), joint lemmatization and POS tagging (Toutanova and Cherry, 2009), joint tokenization and parsing (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008), joint named entity recognition and parsing (Finkel and Manning, 2009), joint parsing and semantic role labeling (SRL) (Li et al. [sent-34, score-2.043]
</p><p>17 , 2010), joint word sense disambiguation and SRL (Che and Liu, 2010), joint tokenization and machine translation (MT) (Dyer, 2009; Xiao et al. [sent-35, score-0.54]
</p><p>18 , 2010) and joint parsing and MT (Liu and Liu, 2010). [sent-36, score-0.494]
</p><p>19 As far as we know, there are few successful mod-  els for jointly solving dependency parsing and other tasks. [sent-38, score-0.419]
</p><p>20 Being facilitated by Conference on Computational Natural Language Learning (CoNLL) 2008 and 2009 shared tasks, several joint models of dependency parsing and SRL have been proposed. [sent-39, score-0.66]
</p><p>21 Nevertheless, the top-ranked systems all adopt pipelined approaches (Surdeanu et al. [sent-40, score-0.333]
</p><p>22 Theoretically, joint modeling of POS tagging and dependency parsing should be helpful to the two individual tasks. [sent-45, score-0.928]
</p><p>23 On the one hand, syntactic information can help resolve some POS ambiguities which are difficult to handle for the sequential POS tagging models. [sent-46, score-0.325]
</p><p>24 On the other hand, more accurate POS tags should further improve dependency parsing. [sent-47, score-0.321]
</p><p>25 For joint POS tagging and dependency parsing, the major issue is to design effective decoding algorithms to capture rich features and efficiently search out the optimal results from a huge hypothesis space. [sent-48, score-0.95]
</p><p>26 1 In this paper, we propose several dynamic programming (DP) based decoding algorithms for our joint models by extending existing parsing algo-  rithms. [sent-49, score-0.769]
</p><p>27 Experimental results on Chinese Penn Treebank show that our joint models can significantly improve the state-ofthe-art parsing accuracy by about 1. [sent-51, score-0.552]
</p><p>28 Section 2 describes the pipelined method, including the POS tagging and parsing models. [sent-54, score-0.773]
</p><p>29 Section 3 discusses the joint models and the decoding algorithms, while Section 4 presents the pruning techniques. [sent-55, score-0.487]
</p><p>30 A dependency tree iis ≤de nn,oat endd by ids = {(h, m) : 0e ≤ Ah d ≤ n, d0e < m ≤ n}, wnohteerde (h, m) represents a dependency wh → wm wwhheorsee h (hea,md w)o rredp (or father) eisp wh aenncdy modifier (or child) is wm. [sent-65, score-0.58]
</p><p>31 The pipelined method treats POS tagging and dependency parsing as two cascaded problems. [sent-67, score-0.981]
</p><p>32 First, 1It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). [sent-68, score-0.422]
</p><p>33 Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). [sent-81, score-0.491]
</p><p>34 In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. [sent-82, score-0.957]
</p><p>35 In a perceptron, the score of a tag sequence is Scorepos(x, t) = wpos  ·  fpos(x, t)  where fpos(x, t) refers to the feature vector and wpos is the corresponding weight vector. [sent-83, score-0.429]
</p><p>36 ii  ein−  w1  ei  a−d2opit−  t1he  V  Given wpos, we adopt the Viterbi algorithm to get  the optimal tagging sequence. [sent-87, score-0.307]
</p><p>37 2 Dependency Parsing Recently, graph-based dependency parsing has gained more and more interest due to its state-ofthe-art accuracy. [sent-89, score-0.419]
</p><p>38 Graph-based dependency parsing views the problem as finding the highest scoring tree from a directed graph. [sent-90, score-0.462]
</p><p>39 h  m  dependency  h  s sibling  m  g  h grandparent  m  g  h  s  grand-sibling  m  h  t  s  m  tri-sibling  Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). [sent-95, score-0.424]
</p><p>40 Eisner (1996) proposes an O(n3) decoding algorithm for dependency parsing. [sent-96, score-0.362]
</p><p>41 The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3) parsing time. [sent-99, score-0.436]
</p><p>42 The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4) parsing time. [sent-100, score-0.491]
</p><p>43 We use three versions of graph-based dependency parsing models. [sent-107, score-0.465]
</p><p>44 For parsing features, we follow standard practice for graph-based dependency parsing (McDonald, 2006; Carreras, 2007; Koo and Collins, 2010). [sent-114, score-0.672]
</p><p>45 Since these features are highly related with our joint decoding algorithms, we summarize the features as follows. [sent-115, score-0.478]
</p><p>46 where b denotes an index between h and m; dir and dist are the direction and distance of (h, m) ; gdir is the direction of (g, h). [sent-117, score-0.319]
</p><p>47 To avoid producing too many sparse features, at most two word forms are used at the same time in sibling, grandparent and grand-sibling features, while POS tags are used instead for other nodes; meanwhile, at most four POS tags are considered at the same time for surrounding features. [sent-119, score-0.463]
</p><p>48 Under the joint model, the weights of POS and syntactic features, wpos⊕syn, are simultaneously learned. [sent-125, score-0.327]
</p><p>49 We expect that POS and syntactic features can interact each other to determine an optimal joint result. [sent-126, score-0.368]
</p><p>50 Similarly to the baseline dependency parsing models, we define the first-, second-, and third-order joint models according to the syntactic features contained in fsyn(. [sent-127, score-0.743]
</p><p>51 1 Joint Models of Version 1 The crucial problem for the joint method is to design effective decoding algorithms to capture rich features and efficiently search out the optimal results from a huge hypothesis space. [sent-131, score-0.521]
</p><p>52 (2005) and Koo and Collins (2010), and propose two DP based decoding algorithms for our joint models of version 1. [sent-134, score-0.48]
</p><p>53 (a)ij irr+1j  (b)  i  j  i  r  r  j  Figure 2: The DP structures and derivations of the firstorder decoding algorithm of joint models of version 1. [sent-135, score-0.505]
</p><p>54 The decoding algorithm of O1: As shown in Figure 2, the first-order joint decoding algorithm utilizes two types of dynamic programming structures. [sent-140, score-0.637]
</p><p>55 Scorejoint (x, ti, tr, tr+1, tj ,p = {(i, j)}) captures the joint features invented,p by t {h(isi jco)}m)b cinapa-tion, where p = {(i, j)} means that the newly obtsieornv,ed w scoring part ,isj )th}e m dependency (i, j). [sent-149, score-0.544]
</p><p>56 The surrounding and in between features are unavailable, because the context POS tags, such as tb and ti−1, are not contained in the DP strucAlgorithm 1 The first-order joint decoding algorithm of version 1 1: ∀0 ≤ i ≤ n,ti∈ TC(i,i)(ti,ti)= 0▹ initialization 12:: f∀o0r w = 1. [sent-151, score-0.53]
</p><p>57 10 5∞ number of candidate POS tags  k  Figure 5: Results of POS tag pruning with different pruning threshold λt on the development set. [sent-156, score-0.41]
</p><p>58 5 e2d Table 1: Performance of the second-order joint model of version 1 with different pruning threshold λt (top k = 5) on the development set. [sent-166, score-0.37]
</p><p>59 “Speed” refers to the parsing speed (the number of sentences processed per second). [sent-169, score-0.331]
</p><p>60 However, its parsing accuracy is inferior to the other two. [sent-174, score-0.311]
</p><p>61 01 produces slightly better parsing accuracy than λt = 0. [sent-176, score-0.311]
</p><p>62 From Table 1 and 2, we can have an interesting finding: it seems that the harder we filter the POS tag space, the higher tagging accuracy we get. [sent-183, score-0.364]
</p><p>63 In other words, giving the joint model less flexibility of choosing POS tags leads to better tagging performance. [sent-184, score-0.621]
</p><p>64 “Gold POS” means that gold POS tags are used as input by the pipelined parsing models; while “Auto POS” means that the POS tags are generated by the baseline POS tagging model. [sent-209, score-1.083]
</p><p>65 We can see that when using gold tags, our pipelined second- and third-order parsing models achieve best parsing accuracy, which is even higher  than the hybrid model of Zhang and Clark (2008b). [sent-232, score-0.801]
</p><p>66 Both joint models of version 1 and 2 can consistently and significantly improve the parsing accuracy by about 1. [sent-238, score-0.594]
</p><p>67 Accidentally, the parsing accuracy of the second-order joint model of version 2 is lower  DeVNErP GoVCr→ paCVDt NCVeE rGnC2143#5789021↓37294eNVrJARoNr→ paNtVJeNARVrn1#89602457 1↑09241  Table 4: Error analysis of POS tagging. [sent-240, score-0.594]
</p><p>68 The two versions of joint models performs nearly the same, which indicates that using pseudo surrounding and POS trigram features may be sufficient for the joint method on this data set. [sent-247, score-0.653]
</p><p>69 In summary, we can conclude that the joint framework is certainly helpful for dependency parsing. [sent-248, score-0.45]
</p><p>70 It is clearly shown in Table 3 that the joint method surprisingly hurts the tagging accuracy, which diverges from our discussion in Section 1. [sent-249, score-0.466]
</p><p>71 Moreover, it seems that the more syntactic features the joint method incorporates (from O1 to O3), the more the tagging accuracy drops. [sent-252, score-0.679]
</p><p>72 Comparing the parsing speed, we can find that the pruning of POS tags is very effective. [sent-259, score-0.495]
</p><p>73 7 sentences per second, while the pipelined second-order parsing model can parse 5. [sent-261, score-0.548]
</p><p>74 3 Error Analysis To find out the impact of our joint models on the individual tasks, we conduct detailed error analysis through comparing the results of the pipelined second-order parsing model and the second-order joint model of version 1. [sent-264, score-1.145]
</p><p>75 1188 Impact on POS tagging: Table 4 shows how the joint model changes the quantity of POS tagging error patterns compared with the pipelined model. [sent-265, score-0.902]
</p><p>76 In other words, resolving these ambiguities is critical and helpful from the parsing viewpoint. [sent-270, score-0.352]
</p><p>77 From another perspective, the joint model is capable of preferring the right tag with the help of syntactic structures, which is impossible for the baseline sequential labeling model. [sent-271, score-0.366]
</p><p>78 Impact on parsing: Table 5 studies the change of parsing error rates between the pipelined and joint model on different POS tag patterns. [sent-274, score-0.984]
</p><p>79 From the table, we can see the joint model can  achieve a large error reduction (0. [sent-277, score-0.314]
</p><p>80 uInc oiotnher (0 words, %th)e f joint tmheod peal can sd “oX Xb →ette Xr given tthheer c wororredcst, tags tohinant the pipelined method. [sent-280, score-0.691]
</p><p>81 Table 5: Comparison of parsing error rates on different POS tag patterns between the pipelined and joint models. [sent-286, score-1.052]
</p><p>82 Given a pattern “X → Y”, “prop” means its proportion in all occurrence of ‘X’ and “error” refers  (CoCuonut(nXt(X→Y) )),  to its parsing error rate  (  Count(wrConouglnty(X h→eadYe )d X→Y )). [sent-287, score-0.404]
</p><p>83 The last two columns give the absCooluutnet Xre→duYct )ion (-) or  increase (+) in proportion and error rate made by the joint model. [sent-288, score-0.314]
</p><p>84 This demonstrates that the joint model can do better on certain tagging error patterns. [sent-292, score-0.539]
</p><p>85 For patterns marked by ♡, the error rate of the joint mrpo datetel usually kinecdre bayse s♡ by large margin. [sent-293, score-0.382]
</p><p>86 oHfo twheever, the proportion of these patterns is substantially decreased, since the joint model can better resolve these ambiguities with the help of syntactic knowledge. [sent-294, score-0.409]
</p><p>87 In summary, we can conclude that the joint model is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. [sent-295, score-0.692]
</p><p>88 6  Related Work  Theoretically, Eisner (2000) proposes a preliminary idea of extending the decoding algorithm for de-  1189 pendency parsing to handle polysemy. [sent-297, score-0.449]
</p><p>89 In his PhD thesis, McDonald (2006) extends his second-order model with the idea of Eisner (2000) to study the impact of POS tagging errors on parsing accuracy. [sent-300, score-0.478]
</p><p>90 To make inference tractable, he uses top 2 candidate POS tags for each word based on a maximum entropy tagger, and adopts the single most likely POS tags for the surrounding and in between features. [sent-301, score-0.359]
</p><p>91 He conducts primitive experiments on English Penn Treebank, and shows that parsing accuracy can be improved from 91. [sent-302, score-0.311]
</p><p>92 7  Conclusions  In this paper, we have systematically investigated the issue of joint POS tagging and dependency parsing. [sent-306, score-0.67]
</p><p>93 We propose and compare several joint models  and their corresponding decoding algorithms which can incorporate different feature sets. [sent-307, score-0.438]
</p><p>94 We also propose an effective POS tag pruning method which can greatly improve the decoding efficiency. [sent-308, score-0.327]
</p><p>95 The experimental results show that our joint models can significantly improve the state-of-the-art parsing accuracy by more than 1. [sent-309, score-0.552]
</p><p>96 Detailed error analysis shows that the fundamental reason for the parsing accuracy improvement is that the joint method is able to choose POS tags that are helpful and discriminative from parsing viewpoint. [sent-311, score-1.12]
</p><p>97 A single generative model for joint morphological segmentation and syntactic parsing. [sent-367, score-0.333]
</p><p>98 A cascaded linear model for joint chinese word segmentation and part-of-speech tagging. [sent-381, score-0.416]
</p><p>99 An error-driven word-character hybrid model for joint chinese word segmentation and pos tagging. [sent-390, score-0.72]
</p><p>100 The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies. [sent-447, score-0.538]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pos', 0.346), ('pipelined', 0.295), ('parsing', 0.253), ('joint', 0.241), ('tagging', 0.225), ('dependency', 0.166), ('fpos', 0.162), ('decoding', 0.159), ('tags', 0.155), ('fsyn', 0.135), ('wpos', 0.135), ('dir', 0.131), ('koo', 0.12), ('scoresyn', 0.108), ('grandparent', 0.104), ('tm', 0.095), ('pruning', 0.087), ('chinese', 0.085), ('mcdonald', 0.085), ('syn', 0.084), ('gdir', 0.081), ('tag', 0.081), ('refers', 0.078), ('collins', 0.076), ('error', 0.073), ('incorporates', 0.072), ('perceptron', 0.072), ('dist', 0.069), ('patterns', 0.068), ('wm', 0.066), ('wh', 0.064), ('firstorder', 0.063), ('duan', 0.063), ('sibling', 0.062), ('tokenization', 0.058), ('srl', 0.058), ('accuracy', 0.058), ('zhang', 0.057), ('ambiguities', 0.056), ('span', 0.055), ('tj', 0.055), ('dec', 0.055), ('clark', 0.054), ('argt', 0.054), ('eisp', 0.054), ('fdep', 0.054), ('fgrd', 0.054), ('fgsib', 0.054), ('fsib', 0.054), ('harbin', 0.054), ('scorejoint', 0.054), ('scorepos', 0.054), ('whth', 0.054), ('wmtm', 0.054), ('carreras', 0.053), ('dp', 0.051), ('liu', 0.05), ('surrounding', 0.049), ('parts', 0.049), ('eisner', 0.048), ('segmentation', 0.048), ('che', 0.047), ('joakim', 0.047), ('surdeanu', 0.047), ('outermost', 0.047), ('kruengkrai', 0.047), ('tmhoede', 0.047), ('versions', 0.046), ('optimal', 0.044), ('fundamental', 0.044), ('syntactic', 0.044), ('scoring', 0.043), ('helpful', 0.043), ('simultaneously', 0.042), ('qun', 0.042), ('cascaded', 0.042), ('mihai', 0.042), ('tg', 0.042), ('deg', 0.042), ('father', 0.042), ('wanxiang', 0.042), ('version', 0.042), ('programming', 0.041), ('rates', 0.041), ('features', 0.039), ('llu', 0.039), ('levy', 0.039), ('yue', 0.039), ('algorithms', 0.038), ('incomplete', 0.038), ('adopt', 0.038), ('issue', 0.038), ('index', 0.038), ('trigram', 0.037), ('proposes', 0.037), ('spans', 0.037), ('dynamic', 0.037), ('thirdorder', 0.037), ('arquez', 0.037), ('lemmatization', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="75-tfidf-1" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>2 0.19637343 <a title="75-tfidf-2" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>Author: Stephen Tratz ; Eduard Hovy</p><p>Abstract: Dependency parsers are critical components within many NLP systems. However, currently available dependency parsers each exhibit at least one of several weaknesses, including high running time, limited accuracy, vague dependency labels, and lack of nonprojectivity support. Furthermore, no commonly used parser provides additional shallow semantic interpretation, such as preposition sense disambiguation and noun compound interpretation. In this paper, we present a new dependency-tree conversion of the Penn Treebank along with its associated fine-grain dependency labels and a fast, accurate parser trained on it. We explain how a non-projective extension to shift-reduce parsing can be incorporated into non-directional easy-first parsing. The parser performs well when evaluated on the standard test section of the Penn Treebank, outperforming several popular open source dependency parsers; it is, to the best of our knowledge, the first dependency parser capable of parsing more than 75 sentences per second at over 93% accuracy.</p><p>3 0.18672277 <a title="75-tfidf-3" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>Author: Christof Monz</p><p>Abstract: Part-of-speech language modeling is commonly used as a component in statistical machine translation systems, but there is mixed evidence that its usage leads to significant improvements. We argue that its limited effectiveness is due to the lack of lexicalization. We introduce a new approach that builds a separate local language model for each word and part-of-speech pair. The resulting models lead to more context-sensitive probability distributions and we also exploit the fact that different local models are used to estimate the language model probability of each word during decoding. Our approach is evaluated for Arabic- and Chinese-to-English translation. We show that it leads to statistically significant improvements for multiple test sets and also across different genres, when compared against a competitive baseline and a system using a part-of-speech model.</p><p>4 0.15370224 <a title="75-tfidf-4" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>5 0.15211105 <a title="75-tfidf-5" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>6 0.14866047 <a title="75-tfidf-6" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>7 0.12696101 <a title="75-tfidf-7" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>8 0.11709438 <a title="75-tfidf-8" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>9 0.11426981 <a title="75-tfidf-9" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>10 0.11181772 <a title="75-tfidf-10" href="./emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">15 emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>11 0.10887899 <a title="75-tfidf-11" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>12 0.10835069 <a title="75-tfidf-12" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>13 0.10797843 <a title="75-tfidf-13" href="./emnlp-2011-Dual_Decomposition_with_Many_Overlapping_Components.html">45 emnlp-2011-Dual Decomposition with Many Overlapping Components</a></p>
<p>14 0.10358962 <a title="75-tfidf-14" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>15 0.10339844 <a title="75-tfidf-15" href="./emnlp-2011-Exact_Decoding_of_Phrase-Based_Translation_Models_through_Lagrangian_Relaxation.html">51 emnlp-2011-Exact Decoding of Phrase-Based Translation Models through Lagrangian Relaxation</a></p>
<p>16 0.097998723 <a title="75-tfidf-16" href="./emnlp-2011-Multilayer_Sequence_Labeling.html">96 emnlp-2011-Multilayer Sequence Labeling</a></p>
<p>17 0.095202833 <a title="75-tfidf-17" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>18 0.093608297 <a title="75-tfidf-18" href="./emnlp-2011-Inducing_Sentence_Structure_from_Parallel_Corpora_for_Reordering.html">74 emnlp-2011-Inducing Sentence Structure from Parallel Corpora for Reordering</a></p>
<p>19 0.092636362 <a title="75-tfidf-19" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>20 0.089800544 <a title="75-tfidf-20" href="./emnlp-2011-SMT_Helps_Bitext_Dependency_Parsing.html">118 emnlp-2011-SMT Helps Bitext Dependency Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.313), (1, 0.123), (2, -0.025), (3, 0.195), (4, -0.065), (5, 0.085), (6, -0.044), (7, -0.15), (8, -0.01), (9, -0.082), (10, 0.042), (11, 0.008), (12, 0.137), (13, 0.088), (14, -0.001), (15, 0.019), (16, 0.008), (17, -0.054), (18, 0.144), (19, 0.117), (20, -0.083), (21, 0.014), (22, -0.034), (23, 0.016), (24, -0.053), (25, -0.016), (26, 0.066), (27, -0.073), (28, -0.21), (29, -0.14), (30, -0.019), (31, -0.05), (32, -0.067), (33, 0.025), (34, -0.011), (35, 0.207), (36, -0.074), (37, -0.017), (38, -0.032), (39, 0.1), (40, 0.005), (41, -0.09), (42, -0.028), (43, -0.051), (44, 0.069), (45, 0.005), (46, -0.045), (47, 0.101), (48, 0.095), (49, -0.175)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98434824 <a title="75-lsi-1" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>2 0.62650168 <a title="75-lsi-2" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>Author: Shay B. Cohen ; Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages. Our approach is based on a model that locally mixes between supervised models from the helper languages. Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable. We obtain state-of-theart performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing.</p><p>3 0.61567038 <a title="75-lsi-3" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>Author: Stephen Tratz ; Eduard Hovy</p><p>Abstract: Dependency parsers are critical components within many NLP systems. However, currently available dependency parsers each exhibit at least one of several weaknesses, including high running time, limited accuracy, vague dependency labels, and lack of nonprojectivity support. Furthermore, no commonly used parser provides additional shallow semantic interpretation, such as preposition sense disambiguation and noun compound interpretation. In this paper, we present a new dependency-tree conversion of the Penn Treebank along with its associated fine-grain dependency labels and a fast, accurate parser trained on it. We explain how a non-projective extension to shift-reduce parsing can be incorporated into non-directional easy-first parsing. The parser performs well when evaluated on the standard test section of the Penn Treebank, outperforming several popular open source dependency parsers; it is, to the best of our knowledge, the first dependency parser capable of parsing more than 75 sentences per second at over 93% accuracy.</p><p>4 0.58004624 <a title="75-lsi-4" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>Author: Christof Monz</p><p>Abstract: Part-of-speech language modeling is commonly used as a component in statistical machine translation systems, but there is mixed evidence that its usage leads to significant improvements. We argue that its limited effectiveness is due to the lack of lexicalization. We introduce a new approach that builds a separate local language model for each word and part-of-speech pair. The resulting models lead to more context-sensitive probability distributions and we also exploit the fact that different local models are used to estimate the language model probability of each word during decoding. Our approach is evaluated for Arabic- and Chinese-to-English translation. We show that it leads to statistically significant improvements for multiple test sets and also across different genres, when compared against a competitive baseline and a system using a part-of-speech model.</p><p>5 0.56278718 <a title="75-lsi-5" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>Author: Zhiyuan Liu ; Xinxiong Chen ; Maosong Sun</p><p>Abstract: It is popular for users in Web 2.0 era to freely annotate online resources with tags. To ease the annotation process, it has been great interest in automatic tag suggestion. We propose a method to suggest tags according to the text description of a resource. By considering both the description and tags of a given resource as summaries to the resource written in two languages, we adopt word alignment models in statistical machine translation to bridge their vocabulary gap. Based on the translation probabilities between the words in descriptions and the tags estimated on a large set of description-tags pairs, we build a word trigger method (WTM) to suggest tags according to the words in a resource description. Experiments on real world datasets show that WTM is effective and robust compared with other methods. Moreover, WTM is relatively simple and efficient, which is practical for Web applications.</p><p>6 0.52629328 <a title="75-lsi-6" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>7 0.5136618 <a title="75-lsi-7" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>8 0.4915446 <a title="75-lsi-8" href="./emnlp-2011-Dual_Decomposition_with_Many_Overlapping_Components.html">45 emnlp-2011-Dual Decomposition with Many Overlapping Components</a></p>
<p>9 0.48403904 <a title="75-lsi-9" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>10 0.47966734 <a title="75-lsi-10" href="./emnlp-2011-Multilayer_Sequence_Labeling.html">96 emnlp-2011-Multilayer Sequence Labeling</a></p>
<p>11 0.46150279 <a title="75-lsi-11" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>12 0.46087226 <a title="75-lsi-12" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>13 0.45191234 <a title="75-lsi-13" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>14 0.41523167 <a title="75-lsi-14" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>15 0.40573734 <a title="75-lsi-15" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>16 0.40396395 <a title="75-lsi-16" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>17 0.40281913 <a title="75-lsi-17" href="./emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">15 emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>18 0.39957833 <a title="75-lsi-18" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>19 0.39499825 <a title="75-lsi-19" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>20 0.37788245 <a title="75-lsi-20" href="./emnlp-2011-Exact_Decoding_of_Phrase-Based_Translation_Models_through_Lagrangian_Relaxation.html">51 emnlp-2011-Exact Decoding of Phrase-Based Translation Models through Lagrangian Relaxation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.121), (36, 0.031), (37, 0.024), (45, 0.039), (53, 0.024), (54, 0.017), (57, 0.02), (62, 0.012), (64, 0.051), (65, 0.019), (66, 0.039), (69, 0.026), (79, 0.048), (82, 0.023), (87, 0.337), (90, 0.012), (96, 0.076), (98, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92421293 <a title="75-lda-1" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>Author: Yoav Artzi ; Luke Zettlemoyer</p><p>Abstract: Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit mean- . ing annotations.</p><p>same-paper 2 0.79268956 <a title="75-lda-2" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>3 0.70397407 <a title="75-lda-3" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>4 0.4841449 <a title="75-lda-4" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>5 0.48182997 <a title="75-lda-5" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>Author: Katsuhiko Hayashi ; Taro Watanabe ; Masayuki Asahara ; Yuji Matsumoto</p><p>Abstract: We propose a novel forest reranking algorithm for discriminative dependency parsing based on a variant of Eisner’s generative model. In our framework, we define two kinds of generative model for reranking. One is learned from training data offline and the other from a forest generated by a baseline parser on the fly. The final prediction in the reranking stage is performed using linear interpolation of these models and discriminative model. In order to efficiently train the model from and decode on a hypergraph data structure representing a forest, we apply extended inside/outside and Viterbi algorithms. Experimental results show that our proposed forest reranking algorithm achieves significant improvement when compared with conventional approaches.</p><p>6 0.48164847 <a title="75-lda-6" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>7 0.47491351 <a title="75-lda-7" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>8 0.46552154 <a title="75-lda-8" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>9 0.46228495 <a title="75-lda-9" href="./emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">94 emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>10 0.46189433 <a title="75-lda-10" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>11 0.45407534 <a title="75-lda-11" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>12 0.45274818 <a title="75-lda-12" href="./emnlp-2011-Hierarchical_Phrase-based_Translation_Representations.html">66 emnlp-2011-Hierarchical Phrase-based Translation Representations</a></p>
<p>13 0.45116064 <a title="75-lda-13" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>14 0.44934127 <a title="75-lda-14" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>15 0.4459447 <a title="75-lda-15" href="./emnlp-2011-Computation_of_Infix_Probabilities_for_Probabilistic_Context-Free_Grammars.html">31 emnlp-2011-Computation of Infix Probabilities for Probabilistic Context-Free Grammars</a></p>
<p>16 0.44520262 <a title="75-lda-16" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>17 0.4450627 <a title="75-lda-17" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>18 0.44092885 <a title="75-lda-18" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>19 0.44083202 <a title="75-lda-19" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>20 0.43648547 <a title="75-lda-20" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
