<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-143" href="#">emnlp2011-143</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</h1>
<br/><p>Source: <a title="emnlp-2011-143-pdf" href="http://aclweb.org/anthology//D/D11/D11-1075.pdf">pdf</a></p><p>Author: Cane Wing-ki Leung ; Jing Jiang ; Kian Ming A. Chai ; Hai Leong Chieu ; Loo-Nin Teow</p><p>Abstract: We address the task of automatic discovery of information extraction template from a given text collection. Our approach clusters candidate slot fillers to identify meaningful template slots. We propose a generative model that incorporates distributional prior knowledge to help distribute candidates in a document into appropriate slots. Empirical results suggest that the proposed prior can bring substantial improvements to our task as compared to a K-means baseline and a Gaussian mixture model baseline. Specifically, the proposed prior has shown to be effective when coupled with discriminative features of the candidates.</p><p>Reference: <a title="emnlp-2011-143-reference" href="../emnlp2011_reference/emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('slot', 0.546), ('gmm', 0.465), ('personout', 0.208), ('personin', 0.179), ('templ', 0.151), ('incid', 0.151), ('semin', 0.141), ('nil', 0.139), ('pri', 0.134), ('fil', 0.131), ('avy', 0.124), ('garb', 0.124), ('stim', 0.113), ('bmm', 0.112), ('etim', 0.112), ('clust', 0.104), ('candid', 0.102), ('multinom', 0.096), ('centriod', 0.096), ('lnlr', 0.096)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="143-tfidf-1" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>Author: Cane Wing-ki Leung ; Jing Jiang ; Kian Ming A. Chai ; Hai Leong Chieu ; Loo-Nin Teow</p><p>Abstract: We address the task of automatic discovery of information extraction template from a given text collection. Our approach clusters candidate slot fillers to identify meaningful template slots. We propose a generative model that incorporates distributional prior knowledge to help distribute candidates in a document into appropriate slots. Empirical results suggest that the proposed prior can bring substantial improvements to our task as compared to a K-means baseline and a Gaussian mixture model baseline. Specifically, the proposed prior has shown to be effective when coupled with discriminative features of the candidates.</p><p>2 0.091054231 <a title="143-tfidf-2" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>Author: Shay B. Cohen ; Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages. Our approach is based on a model that locally mixes between supervised models from the helper languages. Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable. We obtain state-of-theart performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing.</p><p>3 0.078017704 <a title="143-tfidf-3" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>4 0.073410578 <a title="143-tfidf-4" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>Author: Andre Martins ; Noah Smith ; Mario Figueiredo ; Pedro Aguiar</p><p>Abstract: Linear models have enjoyed great success in structured prediction in NLP. While a lot of progress has been made on efficient training with several loss functions, the problem of endowing learners with a mechanism for feature selection is still unsolved. Common approaches employ ad hoc filtering or L1regularization; both ignore the structure of the feature space, preventing practicioners from encoding structural prior knowledge. We fill this gap by adopting regularizers that promote structured sparsity, along with efficient algorithms to handle them. Experiments on three tasks (chunking, entity recognition, and dependency parsing) show gains in performance, compactness, and model interpretability.</p><p>5 0.069000818 <a title="143-tfidf-5" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>6 0.065153725 <a title="143-tfidf-6" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>7 0.060914386 <a title="143-tfidf-7" href="./emnlp-2011-Discovering_Morphological_Paradigms_from_Plain_Text_Using_a_Dirichlet_Process_Mixture_Model.html">39 emnlp-2011-Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model</a></p>
<p>8 0.06075187 <a title="143-tfidf-8" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>9 0.060426034 <a title="143-tfidf-9" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>10 0.05645366 <a title="143-tfidf-10" href="./emnlp-2011-Collaborative_Ranking%3A_A_Case_Study_on_Entity_Linking.html">29 emnlp-2011-Collaborative Ranking: A Case Study on Entity Linking</a></p>
<p>11 0.056272145 <a title="143-tfidf-11" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>12 0.055564046 <a title="143-tfidf-12" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>13 0.050572187 <a title="143-tfidf-13" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>14 0.05004929 <a title="143-tfidf-14" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>15 0.048938237 <a title="143-tfidf-15" href="./emnlp-2011-Enhancing_Chinese_Word_Segmentation_Using_Unlabeled_Data.html">48 emnlp-2011-Enhancing Chinese Word Segmentation Using Unlabeled Data</a></p>
<p>16 0.048866861 <a title="143-tfidf-16" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>17 0.048629291 <a title="143-tfidf-17" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>18 0.047984973 <a title="143-tfidf-18" href="./emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">130 emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>19 0.047557972 <a title="143-tfidf-19" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>20 0.046577554 <a title="143-tfidf-20" href="./emnlp-2011-Non-parametric_Bayesian_Segmentation_of_Japanese_Noun_Phrases.html">99 emnlp-2011-Non-parametric Bayesian Segmentation of Japanese Noun Phrases</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.147), (1, -0.054), (2, -0.091), (3, 0.008), (4, -0.043), (5, -0.031), (6, 0.057), (7, 0.08), (8, -0.06), (9, 0.059), (10, -0.023), (11, 0.065), (12, 0.006), (13, -0.012), (14, -0.068), (15, 0.039), (16, -0.008), (17, -0.074), (18, -0.03), (19, 0.051), (20, -0.135), (21, 0.02), (22, 0.026), (23, 0.017), (24, 0.053), (25, -0.132), (26, 0.067), (27, -0.08), (28, -0.015), (29, 0.076), (30, 0.031), (31, 0.015), (32, -0.089), (33, -0.129), (34, 0.05), (35, 0.108), (36, -0.08), (37, -0.082), (38, 0.104), (39, -0.084), (40, 0.032), (41, 0.12), (42, 0.012), (43, 0.035), (44, 0.018), (45, 0.127), (46, 0.155), (47, -0.045), (48, 0.203), (49, 0.008)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.8799668 <a title="143-lsi-1" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>Author: Cane Wing-ki Leung ; Jing Jiang ; Kian Ming A. Chai ; Hai Leong Chieu ; Loo-Nin Teow</p><p>Abstract: We address the task of automatic discovery of information extraction template from a given text collection. Our approach clusters candidate slot fillers to identify meaningful template slots. We propose a generative model that incorporates distributional prior knowledge to help distribute candidates in a document into appropriate slots. Empirical results suggest that the proposed prior can bring substantial improvements to our task as compared to a K-means baseline and a Gaussian mixture model baseline. Specifically, the proposed prior has shown to be effective when coupled with discriminative features of the candidates.</p><p>2 0.53411156 <a title="143-lsi-2" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>Author: Andre Martins ; Noah Smith ; Mario Figueiredo ; Pedro Aguiar</p><p>Abstract: Linear models have enjoyed great success in structured prediction in NLP. While a lot of progress has been made on efficient training with several loss functions, the problem of endowing learners with a mechanism for feature selection is still unsolved. Common approaches employ ad hoc filtering or L1regularization; both ignore the structure of the feature space, preventing practicioners from encoding structural prior knowledge. We fill this gap by adopting regularizers that promote structured sparsity, along with efficient algorithms to handle them. Experiments on three tasks (chunking, entity recognition, and dependency parsing) show gains in performance, compactness, and model interpretability.</p><p>3 0.45013952 <a title="143-lsi-3" href="./emnlp-2011-Predicting_a_Scientific_Communitys_Response_to_an_Article.html">106 emnlp-2011-Predicting a Scientific Communitys Response to an Article</a></p>
<p>Author: Dani Yogatama ; Michael Heilman ; Brendan O'Connor ; Chris Dyer ; Bryan R. Routledge ; Noah A. Smith</p><p>Abstract: We consider the problem of predicting measurable responses to scientific articles based primarily on their text content. Specifically, we consider papers in two fields (economics and computational linguistics) and make predictions about downloads and within-community citations. Our approach is based on generalized linear models, allowing interpretability; a novel extension that captures first-order temporal effects is also presented. We demonstrate that text features significantly improve accuracy of predictions over metadata features like authors, topical categories, and publication venues.</p><p>4 0.39685416 <a title="143-lsi-4" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>5 0.38752577 <a title="143-lsi-5" href="./emnlp-2011-Discovering_Morphological_Paradigms_from_Plain_Text_Using_a_Dirichlet_Process_Mixture_Model.html">39 emnlp-2011-Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model</a></p>
<p>Author: Markus Dreyer ; Jason Eisner</p><p>Abstract: We present an inference algorithm that organizes observed words (tokens) into structured inflectional paradigms (types). It also naturally predicts the spelling of unobserved forms that are missing from these paradigms, and discovers inflectional principles (grammar) that generalize to wholly unobserved words. Our Bayesian generative model of the data explicitly represents tokens, types, inflections, paradigms, and locally conditioned string edits. It assumes that inflected word tokens are generated from an infinite mixture of inflectional paradigms (string tuples). Each paradigm is sampled all at once from a graphical model, whose potential functions are weighted finitestate transducers with language-specific parameters to be learned. These assumptions naturally lead to an elegant empirical Bayes inference procedure that exploits Monte Carlo EM, belief propagation, and dynamic programming. Given 50–100 seed paradigms, adding a 10million-word corpus reduces prediction error for morphological inflections by up to 10%.</p><p>6 0.37520275 <a title="143-lsi-6" href="./emnlp-2011-Relation_Extraction_with_Relation_Topics.html">114 emnlp-2011-Relation Extraction with Relation Topics</a></p>
<p>7 0.35606241 <a title="143-lsi-7" href="./emnlp-2011-Minimum_Imputed-Risk%3A_Unsupervised_Discriminative_Training_for_Machine_Translation.html">93 emnlp-2011-Minimum Imputed-Risk: Unsupervised Discriminative Training for Machine Translation</a></p>
<p>8 0.35395882 <a title="143-lsi-8" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>9 0.34956247 <a title="143-lsi-9" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>10 0.32314184 <a title="143-lsi-10" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>11 0.31786373 <a title="143-lsi-11" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>12 0.31640691 <a title="143-lsi-12" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>13 0.30878332 <a title="143-lsi-13" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>14 0.30593479 <a title="143-lsi-14" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>15 0.2939887 <a title="143-lsi-15" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>16 0.28771693 <a title="143-lsi-16" href="./emnlp-2011-Improving_Bilingual_Projections_via_Sparse_Covariance_Matrices.html">73 emnlp-2011-Improving Bilingual Projections via Sparse Covariance Matrices</a></p>
<p>17 0.28615007 <a title="143-lsi-17" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>18 0.28504059 <a title="143-lsi-18" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>19 0.28454897 <a title="143-lsi-19" href="./emnlp-2011-Bayesian_Checking_for_Topic_Models.html">21 emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>20 0.28292972 <a title="143-lsi-20" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.01), (6, 0.366), (13, 0.021), (27, 0.075), (37, 0.065), (41, 0.035), (42, 0.043), (50, 0.025), (55, 0.011), (68, 0.176), (93, 0.014), (96, 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.64473075 <a title="143-lda-1" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>Author: Cane Wing-ki Leung ; Jing Jiang ; Kian Ming A. Chai ; Hai Leong Chieu ; Loo-Nin Teow</p><p>Abstract: We address the task of automatic discovery of information extraction template from a given text collection. Our approach clusters candidate slot fillers to identify meaningful template slots. We propose a generative model that incorporates distributional prior knowledge to help distribute candidates in a document into appropriate slots. Empirical results suggest that the proposed prior can bring substantial improvements to our task as compared to a K-means baseline and a Gaussian mixture model baseline. Specifically, the proposed prior has shown to be effective when coupled with discriminative features of the candidates.</p><p>2 0.49251693 <a title="143-lda-2" href="./emnlp-2011-Linking_Entities_to_a_Knowledge_Base_with_Query_Expansion.html">90 emnlp-2011-Linking Entities to a Knowledge Base with Query Expansion</a></p>
<p>Author: Swapna Gottipati ; Jing Jiang</p><p>Abstract: In this paper we present a novel approach to entity linking based on a statistical language model-based information retrieval with query expansion. We use both local contexts and global world knowledge to expand query language models. We place a strong emphasis on named entities in the local contexts and explore a positional language model to weigh them differently based on their distances to the query. Our experiments on the TAC-KBP 2010 data show that incorporating such contextual information indeed aids in disambiguating the named entities and consistently improves the entity linking performance. Compared with the official results from KBP 2010 participants, our system shows competitive performance.</p><p>3 0.48780772 <a title="143-lda-3" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>4 0.48737359 <a title="143-lda-4" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>Author: Stephen Tratz ; Eduard Hovy</p><p>Abstract: Dependency parsers are critical components within many NLP systems. However, currently available dependency parsers each exhibit at least one of several weaknesses, including high running time, limited accuracy, vague dependency labels, and lack of nonprojectivity support. Furthermore, no commonly used parser provides additional shallow semantic interpretation, such as preposition sense disambiguation and noun compound interpretation. In this paper, we present a new dependency-tree conversion of the Penn Treebank along with its associated fine-grain dependency labels and a fast, accurate parser trained on it. We explain how a non-projective extension to shift-reduce parsing can be incorporated into non-directional easy-first parsing. The parser performs well when evaluated on the standard test section of the Penn Treebank, outperforming several popular open source dependency parsers; it is, to the best of our knowledge, the first dependency parser capable of parsing more than 75 sentences per second at over 93% accuracy.</p><p>5 0.48545688 <a title="143-lda-5" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>Author: Alan Ritter ; Colin Cherry ; William B. Dolan</p><p>Abstract: Ottawa, Ontario, K1A 0R6 Co l . Cherry@ nrc-cnrc . gc . ca in Redmond, WA 98052 bi l ldol @mi cro so ft . com large corpus of status-response pairs found on Twitter to create a system that responds to Twitter status We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.</p><p>6 0.48520976 <a title="143-lda-6" href="./emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">36 emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>7 0.48412314 <a title="143-lda-7" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>8 0.48363304 <a title="143-lda-8" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>9 0.48315626 <a title="143-lda-9" href="./emnlp-2011-A_Correction_Model_for_Word_Alignments.html">3 emnlp-2011-A Correction Model for Word Alignments</a></p>
<p>10 0.48245257 <a title="143-lda-10" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>11 0.48207456 <a title="143-lda-11" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>12 0.48196992 <a title="143-lda-12" href="./emnlp-2011-Bootstrapped_Named_Entity_Recognition_for_Product_Attribute_Extraction.html">23 emnlp-2011-Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p>13 0.48171309 <a title="143-lda-13" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>14 0.4816817 <a title="143-lda-14" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>15 0.48161757 <a title="143-lda-15" href="./emnlp-2011-A_Generate_and_Rank_Approach_to_Sentence_Paraphrasing.html">6 emnlp-2011-A Generate and Rank Approach to Sentence Paraphrasing</a></p>
<p>16 0.48160988 <a title="143-lda-16" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>17 0.4816069 <a title="143-lda-17" href="./emnlp-2011-Collaborative_Ranking%3A_A_Case_Study_on_Entity_Linking.html">29 emnlp-2011-Collaborative Ranking: A Case Study on Entity Linking</a></p>
<p>18 0.48122892 <a title="143-lda-18" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>19 0.481049 <a title="143-lda-19" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>20 0.48089674 <a title="143-lda-20" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
