<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-71" href="#">emnlp2011-71</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</h1>
<br/><p>Source: <a title="emnlp-2011-71-pdf" href="http://aclweb.org/anthology//D/D11/D11-1121.pdf">pdf</a></p><p>Author: Roy Bar-Haim ; Elad Dinur ; Ronen Feldman ; Moshe Fresko ; Guy Goldstein</p><p>Abstract: Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. Previous work focused on aggregation of sentiment from all users. However, in this work we show that it is beneficial to distinguish expert users from non-experts. We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). In particular, we present two methods that combine expert identification and per-user unsupervised learning. These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. In addition, our work provides an in-depth analysis of the content and potential usefulness of stock tweets.</p><p>Reference: <a title="emnlp-2011-71-reference" href="../emnlp2011_reference/emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 alt rowe l  Abstract Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. [sent-2, score-1.274]
</p><p>2 We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). [sent-5, score-1.42]
</p><p>3 These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. [sent-7, score-0.617]
</p><p>4 This work aims to mine useful investment information from messages published in stock microblogs. [sent-13, score-0.701]
</p><p>5 We shall henceforth refer to these messages as stock tweets. [sent-14, score-0.667]
</p><p>6 i l  transform those tweets into buy and sell decisions. [sent-18, score-0.798]
</p><p>7 Previous work on stock investment forums and microblogs usually regarded the first step (message classification) as a sentiment analysis problem, and aligned bullish with positive sentiment and bearish with negative sentiment. [sent-23, score-1.157]
</p><p>8 Trading decisions were made by aggregating the sentiment for a given stock over all the tweets, and picking stocks with strongest sentiment signal (buying the most bullish stocks and short-selling the most bearish ones). [sent-26, score-1.099]
</p><p>9 This paper presents a framework for identifying experts in  stock microblogs by monitoring their performance in a training period. [sent-29, score-0.7]
</p><p>10 tc ho2d0s11 in A Nsasotuciraatlio Lnan fogru Cagoem Ppruotcaetisosninagl, L pinagguesis 1ti3c1s0–1319, Based on the expert identification framework, we experiment with different methods for deriving predictions from stock tweets. [sent-33, score-0.714]
</p><p>11 While previous work largely aligned bullishness with message sentiment, our in-depth content analysis of stock tweets (to be presented in section 2. [sent-34, score-1.354]
</p><p>12 For example, a user reporting on making profit from a buying stock yesterday and selling it today is clearly positive about the stock, but does not express any prediction about its future performance. [sent-37, score-0.716]
</p><p>13 A tweet reporting on buying a stock by the user conveys a much stronger bullishness signal than a tweet that merely expresses an opinion. [sent-39, score-1.014]
</p><p>14 We therefore propose and compare two alternative approaches that sidestep the complexities of assessing tweets bullishness. [sent-41, score-0.613]
</p><p>15 The first approach restricts our attention to the most explicit signals of bullishness and bearishness, namely, tweets that report actual buy and sell transactions performed by the user. [sent-43, score-0.918]
</p><p>16 In the second approach we learn directly the relation between tweets content and stock prices, following previous work on predicting stock price movement from factual sources such as news articles (Lavrenko et al. [sent-44, score-1.945]
</p><p>17 This approach poses no restrictions on the tweets content and avoids any stipulated tweet classification. [sent-46, score-0.755]
</p><p>18 However, user-generated messages are largely subjective, and their correlation with the stock prices depends on user’s expertise. [sent-47, score-0.747]
</p><p>19 Two other noteworthy Twitter conventions that are also found in stock tweets are hashtags, user-defined labels starting with ‘#’, and references to other users, starting with ‘@ ’. [sent-56, score-1.202]
</p><p>20 As common with Twitter messages, stock tweets are typically abbreviated and ungrammatical utterances. [sent-58, score-1.202]
</p><p>21 The language is informal and includes many slang expressions, many of which are unique to the stock tweets community. [sent-59, score-1.202]
</p><p>22 Their unique language and terminology often make stock tweets  hard to understand for an outsider. [sent-61, score-1.202]
</p><p>23 Stock tweets also contain many sentiment expressions which may appear in many variations, e. [sent-64, score-0.736]
</p><p>24 These characteristics make the analysis of stock tweets a particularly challenging task. [sent-67, score-1.202]
</p><p>25 Based on this taxonomy we then tagged a sample of 350 tweets to obtain statistics on the frequency of each category. [sent-71, score-0.613]
</p><p>26 The sample contained only tweets that mention exactly one ticker. [sent-72, score-0.613]
</p><p>27 The following types of tweets were considered irrelevant: •  Tweets that express question. [sent-73, score-0.613]
</p><p>28 com $AAPL”) and tweets that seem  Table 1: Tweets categories and their relative frequencies  to contain no useful information (e. [sent-82, score-0.613]
</p><p>29 The rest of the tweets were classified into two major categories: Facts and Opinions. [sent-89, score-0.653]
</p><p>30 News: such tweets are generally in the form of a tweeted headline describing news or a current event generally drawn from mass media. [sent-91, score-0.639]
</p><p>31 These tweets describe patterns in the stock’s chart without the inclusion of any predicted or projected movement, an important contrast to Chart Prediction, which is an opinion tweet described below. [sent-95, score-0.781]
</p><p>32 The value of these tweets is debatable since although they provide details  of a trade, they generally describe the “exit” transaction. [sent-102, score-0.613]
</p><p>33 Recommendation: As with analyst recommendations, this category represents users who  summarize their understanding and insight into a stock with a simple and effective recommendation to take a certain course of action with regard to a particular share. [sent-111, score-0.687]
</p><p>34 Sentiment: These tweets express pure sentiment toward the stock, rather than any factual content. [sent-114, score-0.736]
</p><p>35 3  An Expert Finding Framework  In this section we present a general procedure for finding experts in stock microblogs. [sent-116, score-0.664]
</p><p>36 We assume that a stock tweet refers to exactly one stock, and therefore there is a one-to-one mapping between tweets and stocks. [sent-118, score-1.324]
</p><p>37 We define expertise as the ability to predict stock rise with high precision. [sent-120, score-0.628]
</p><p>38 Thus, a user is  an expert if a high percentage of his or her bullish tweets is followed by a stock rise. [sent-121, score-1.568]
</p><p>39 In principle, we could analogously follow bearish tweets, and see if they are followed by a stock fall. [sent-122, score-0.649]
</p><p>40 However, bearish tweets are somewhat more difficult to interpret: for example, selling a share may indicate a negative outlook on the stock, but it may also result from other considerations, e. [sent-123, score-0.719]
</p><p>41 following a trading strategy that holds the stock for a fixed period (cf. [sent-125, score-0.701]
</p><p>42 the discussion on Trade Outcome tweets in the previous section). [sent-126, score-0.613]
</p><p>43 The procedure receives a training set T of tweets posted by u, where ceaeicvhe tweet inisi nagnn soetta Tted o fw tiwthe eittss posting ytim ue,. [sent-128, score-0.757]
</p><p>44 The procedure first applies the classifier C to identify hthee p brouclleidshu tweets pinp lTie . [sent-130, score-0.648]
</p><p>45 nGi dveetner a tiwneeset th t, we observe the price change of the stock referenced by t over a one day period starting at the next trading day. [sent-133, score-0.81]
</p><p>46 The exact definition of mapping tweets to stock prices is given in section 5. [sent-134, score-1.282]
</p><p>47 A bullish tweet is considered correct if it is followed by a stock rise, and as incorrect otherwise1 . [sent-137, score-0.899]
</p><p>48 Given a set of tweets, we define its precision as the percentage of correct tweets in the set. [sent-138, score-0.641]
</p><p>49 Let Cu, Iu denote the number of correct and incorrect bullish tweets of user u, respectively. [sent-139, score-0.872]
</p><p>50 The precision of u’s bullish tweets is therefore:  Pu=CuC+u Iu Let Pbl be the baseline precision. [sent-140, score-0.811]
</p><p>51 In this work we chose the baseline precision to be the proportion of tweets that are followed by a stock rise in the whole training set (including all the users). [sent-141, score-1.269]
</p><p>52 This represents the expected precision when picking tweets at random. [sent-142, score-0.641]
</p><p>53 natives  for  the  1For about 1% of the tweets the stock price did not change in the next trading day. [sent-154, score-1.365]
</p><p>54 These tweets are also considered correct throughout this work. [sent-155, score-0.613]
</p><p>55 2), about 13% of the tweets belong to this category. [sent-158, score-0.613]
</p><p>56 Second, the buy and sell actions are usually reported using a closed set of expressions, making these tweets relatively easy to identify. [sent-161, score-0.798]
</p><p>57 A few examples for buy and sell tweets are shown in Table 2. [sent-162, score-0.798]
</p><p>58 While buy and sell transactions can be captured reasonably well by a relatively small set of patterns, the examples in Table 2 show that stock tweets have  1314  their unique language for reporting these transac-  tions, which must be investigated in order to come by these patterns. [sent-163, score-1.417]
</p><p>59 Based on our preliminary analysis of several thousand tweets, we composed a vocabulary of keywords which trade tweets must include2. [sent-165, score-0.706]
</p><p>60 Filtering out tweets that match none of the keywords removed two thirds of the tweets. [sent-167, score-0.632]
</p><p>61 Since the transaction tweets can be characterized by a closed set of recurring patterns, we developed a classifier that is based on a few dozens of manually composed pattern matching rules, formulated as regular expressions. [sent-171, score-0.695]
</p><p>62 For example, user name 2That is, we did not come across any trade tweet that does not include at least one of the keywords in the large sample we  analyzed, so we assume that such tweets are negligible. [sent-174, score-0.899]
</p><p>63 Instead, we use actual stock price movements as our labels. [sent-190, score-0.661]
</p><p>64 1 Associating Tweets with Stock Prices We used stock prices to label tweets as follows. [sent-192, score-1.282]
</p><p>65 2 Training Given the buy and sell prices associated with each tweet, we construct positive and negative training examples as follows: positive examples are tweets where ≥ 3%, and negative examples are  PSP−BPB  PSP−BPB  tweets where ≤ −3%. [sent-197, score-1.491]
</p><p>66 •  •  6  Whether the stock price was up or down 1% or more hine rt thhee previous trading day. [sent-202, score-0.752]
</p><p>67 2, 3, 4-word expressions which are typical to tweets (that is, txhperiers srseiloantisve w frequency yinp tweets is much higher than in general news text). [sent-203, score-1.252]
</p><p>68 Empirical Evaluation  In this section we focus on the empirical task of tweet ranking: ordering the tweets in the test set according to their likelihood to be followed by a stock rise. [sent-204, score-1.324]
</p><p>69 A perfect ranking would place all the correct tweets before all the incorrect ones. [sent-206, score-0.655]
</p><p>70 Tweets that do not contain exactly one stock ticker (traded in NYSE or NASDAQ) were filtered out. [sent-214, score-0.629]
</p><p>71 The same classifier is then applied to the tweets of the expert users in the test set. [sent-227, score-0.83]
</p><p>72 The tweets classified as bullish are ordered according to the ranking of their author (first all the bullish tweets 3stocktwits. [sent-228, score-1.63]
</p><p>73 com 1316 of the highest-ranked expert user, then all the bullish  tweets of the expert ranked second, and so on). [sent-229, score-1.049]
</p><p>74 3  Per-User Model  The joint all model suffers from the tweets of non-experts twice: at training time, these tweets introduce much noise into the training of the SVM model. [sent-232, score-1.226]
</p><p>75 At test time, we follow these unreliable tweets along with the more reliable tweets of the experts. [sent-233, score-1.226]
</p><p>76 The rest of the process is similar to the transaction model: the tweets of each expert u in the test set are classified using the optimized per-user classifier Cu. [sent-244, score-0.86]
</p><p>77 The final ranking is obtained by sorting the tweets that were classified as bullish according to the p-value of their author. [sent-245, score-0.847]
</p><p>78 4 Joint-Experts Model The joint experts model makes use of the experts identified by the per-user model, and builds a single joint SVM model from the tweets of these users. [sent-249, score-0.763]
</p><p>79 As with the joint all model, test tweets are ranked according to the SVM’s score. [sent-251, score-0.629]
</p><p>80 However, the model considers only the tweets of expert users in the test set. [sent-252, score-0.795]
</p><p>81 Each model was used to rank the 1317 tweets according to the confidence that they predict a positive stock price movement. [sent-256, score-1.274]
</p><p>82 Each data point corresponds to the precision obtained for the first k tweets ranked by the model, and the results for varying k values illustrate the precision/recall tradeoff of the model. [sent-257, score-0.657]
</p><p>83 For each threshold value, k is the number of tweets classified as bullish by the model. [sent-260, score-0.823]
</p><p>84 •  For methods that rank the users by their p value aFnodr moredtehro dthse th tawt ereatnsk accordingly (transaction and per user), the i-th data point corresponds to the cumulative precision for the tweets classified as bullish by the first iusers. [sent-261, score-0.931]
</p><p>85 The expected precision at any point is equal to the percentage of tweets in the test set that were followed by a stock rise, which was found to be 51. [sent-266, score-1.23]
</p><p>86 This happens because it is able to utilize only a small fraction of the tweets (explicit buy transactions). [sent-279, score-0.721]
</p><p>87 Sentiment analysis of news articles and financial blogs and their application for stock prediction were  the subject of several studies in recent years. [sent-292, score-0.637]
</p><p>88 Other works also aimed at predicting stock movement (Lavrenko et al. [sent-295, score-0.625]
</p><p>89 (2000), Koppel and Shtrimberg (2004), and Schumaker and Chen (2010) exploit stock prices for training, and thus save the need in supervised learning. [sent-299, score-0.669]
</p><p>90 Previous work on stock message boards include (Das and Chen, 2007; Antweiler and Frank, 2004; Chua et al. [sent-300, score-0.685]
</p><p>91 made use of an Australian mes-  sage board (HotCopper), where, unlike most of the stock message boards, these labels are added by the message author. [sent-306, score-0.713]
</p><p>92 However, their data set does not include stock microblogs, but tweets mentioning the official company name. [sent-308, score-1.202]
</p><p>93 Our work differs from previous work on stock messages in two vital aspects. [sent-309, score-0.667]
</p><p>94 Firstly, these works did not attempt to distinguish between experts and non-expert users, but aggregated the sentiment over all the users when studying the relation between sentiment and the stock market. [sent-310, score-0.967]
</p><p>95 8  Conclusion  This paper investigated the novel task of finding expert investors in online stock forums. [sent-312, score-0.804]
</p><p>96 We found that combin-  ing our framework with user-specific unsupervised learning allows us to predict stock price movement with high precision, and the results were shown to be statistically significant. [sent-315, score-0.697]
</p><p>97 An additional contribution of this work is an indepth analysis of stock tweets, which sheds light on their content and its potential utility. [sent-317, score-0.626]
</p><p>98 A sentiment detection engine for internet stock message boards. [sent-332, score-0.774]
</p><p>99 From tweets to polls: Linking text sentiment to public opinion time series. [sent-372, score-0.774]
</p><p>100 A discrete stock price prediction engine based on financial news. [sent-381, score-0.683]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tweets', 0.613), ('stock', 0.589), ('bullish', 0.17), ('cu', 0.128), ('expert', 0.125), ('sentiment', 0.123), ('tweet', 0.122), ('buy', 0.108), ('trading', 0.091), ('investors', 0.09), ('pbl', 0.086), ('prices', 0.08), ('iu', 0.078), ('messages', 0.078), ('sell', 0.077), ('experts', 0.075), ('trade', 0.074), ('price', 0.072), ('user', 0.071), ('bullishness', 0.07), ('message', 0.062), ('bearish', 0.06), ('cbl', 0.06), ('ibl', 0.06), ('users', 0.057), ('transaction', 0.047), ('pu', 0.047), ('chua', 0.043), ('twitter', 0.04), ('buying', 0.04), ('schumaker', 0.04), ('sprenger', 0.04), ('ticker', 0.04), ('classified', 0.04), ('svm', 0.04), ('rise', 0.039), ('movement', 0.036), ('microblogs', 0.036), ('classifier', 0.035), ('boards', 0.034), ('investment', 0.034), ('lavrenko', 0.031), ('koppel', 0.031), ('aapl', 0.03), ('antweiler', 0.03), ('bght', 0.03), ('expertpvalue', 0.03), ('outlook', 0.03), ('shtrimberg', 0.03), ('skiena', 0.03), ('welpe', 0.03), ('transactions', 0.03), ('hu', 0.028), ('precision', 0.028), ('chart', 0.027), ('exit', 0.026), ('bot', 0.026), ('news', 0.026), ('ranking', 0.024), ('recommendation', 0.023), ('cumulative', 0.023), ('financial', 0.022), ('posted', 0.022), ('forums', 0.022), ('outcome', 0.022), ('day', 0.021), ('period', 0.021), ('signals', 0.02), ('aggregation', 0.02), ('bpb', 0.02), ('devitt', 0.02), ('hare', 0.02), ('opening', 0.02), ('psp', 0.02), ('stocktwits', 0.02), ('tbullish', 0.02), ('content', 0.02), ('das', 0.019), ('public', 0.019), ('keywords', 0.019), ('opinion', 0.019), ('insight', 0.018), ('incorrect', 0.018), ('bollen', 0.017), ('indepth', 0.017), ('hite', 0.017), ('jerusalem', 0.017), ('cuc', 0.017), ('stocks', 0.017), ('transformed', 0.017), ('chen', 0.016), ('ranked', 0.016), ('bought', 0.016), ('uv', 0.016), ('davidov', 0.016), ('referenced', 0.016), ('february', 0.016), ('selling', 0.016), ('december', 0.016), ('hashtag', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="71-tfidf-1" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>Author: Roy Bar-Haim ; Elad Dinur ; Ronen Feldman ; Moshe Fresko ; Guy Goldstein</p><p>Abstract: Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. Previous work focused on aggregation of sentiment from all users. However, in this work we show that it is beneficial to distinguish expert users from non-experts. We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). In particular, we present two methods that combine expert identification and per-user unsupervised learning. These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. In addition, our work provides an in-depth analysis of the content and potential usefulness of stock tweets.</p><p>2 0.37844768 <a title="71-tfidf-2" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>Author: Fabio Massimo Zanzotto ; Marco Pennaccchiotti ; Kostas Tsioutsiouliklis</p><p>Abstract: In the last few years, the interest of the research community in micro-blogs and social media services, such as Twitter, is growing exponentially. Yet, so far not much attention has been paid on a key characteristic of microblogs: the high level of information redundancy. The aim of this paper is to systematically approach this problem by providing an operational definition of redundancy. We cast redundancy in the framework of Textual Entailment Recognition. We also provide quantitative evidence on the pervasiveness of redundancy in Twitter, and describe a dataset of redundancy-annotated tweets. Finally, we present a general purpose system for identifying redundant tweets. An extensive quantitative evaluation shows that our system successfully solves the redundancy detection task, improving over baseline systems with statistical significance.</p><p>3 0.26381898 <a title="71-tfidf-3" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>4 0.25689891 <a title="71-tfidf-4" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>5 0.25475091 <a title="71-tfidf-5" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>Author: Vahed Qazvinian ; Emily Rosengren ; Dragomir R. Radev ; Qiaozhu Mei</p><p>Abstract: A rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP). Fi- nally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations.</p><p>6 0.16333972 <a title="71-tfidf-6" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>7 0.11982238 <a title="71-tfidf-7" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>8 0.093243331 <a title="71-tfidf-8" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>9 0.076845676 <a title="71-tfidf-9" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>10 0.072956875 <a title="71-tfidf-10" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>11 0.063497603 <a title="71-tfidf-11" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>12 0.053079516 <a title="71-tfidf-12" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>13 0.053048141 <a title="71-tfidf-13" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>14 0.049258523 <a title="71-tfidf-14" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>15 0.044848073 <a title="71-tfidf-15" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>16 0.043818761 <a title="71-tfidf-16" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>17 0.042303428 <a title="71-tfidf-17" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>18 0.034677219 <a title="71-tfidf-18" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>19 0.029333934 <a title="71-tfidf-19" href="./emnlp-2011-Linear_Text_Segmentation_Using_Affinity_Propagation.html">88 emnlp-2011-Linear Text Segmentation Using Affinity Propagation</a></p>
<p>20 0.027673056 <a title="71-tfidf-20" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.133), (1, -0.348), (2, 0.441), (3, 0.077), (4, -0.174), (5, 0.026), (6, -0.022), (7, 0.021), (8, 0.073), (9, -0.015), (10, 0.019), (11, 0.104), (12, 0.094), (13, -0.051), (14, 0.004), (15, -0.05), (16, -0.079), (17, 0.057), (18, 0.054), (19, -0.027), (20, 0.017), (21, -0.068), (22, 0.048), (23, 0.065), (24, 0.054), (25, -0.012), (26, 0.022), (27, -0.03), (28, -0.06), (29, 0.05), (30, -0.042), (31, -0.035), (32, -0.021), (33, 0.031), (34, -0.001), (35, -0.091), (36, 0.053), (37, 0.048), (38, 0.012), (39, -0.015), (40, 0.05), (41, 0.011), (42, 0.021), (43, 0.024), (44, 0.027), (45, 0.071), (46, -0.035), (47, -0.057), (48, -0.028), (49, -0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98493159 <a title="71-lsi-1" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>Author: Roy Bar-Haim ; Elad Dinur ; Ronen Feldman ; Moshe Fresko ; Guy Goldstein</p><p>Abstract: Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. Previous work focused on aggregation of sentiment from all users. However, in this work we show that it is beneficial to distinguish expert users from non-experts. We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). In particular, we present two methods that combine expert identification and per-user unsupervised learning. These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. In addition, our work provides an in-depth analysis of the content and potential usefulness of stock tweets.</p><p>2 0.87083578 <a title="71-lsi-2" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>Author: Fabio Massimo Zanzotto ; Marco Pennaccchiotti ; Kostas Tsioutsiouliklis</p><p>Abstract: In the last few years, the interest of the research community in micro-blogs and social media services, such as Twitter, is growing exponentially. Yet, so far not much attention has been paid on a key characteristic of microblogs: the high level of information redundancy. The aim of this paper is to systematically approach this problem by providing an operational definition of redundancy. We cast redundancy in the framework of Textual Entailment Recognition. We also provide quantitative evidence on the pervasiveness of redundancy in Twitter, and describe a dataset of redundancy-annotated tweets. Finally, we present a general purpose system for identifying redundant tweets. An extensive quantitative evaluation shows that our system successfully solves the redundancy detection task, improving over baseline systems with statistical significance.</p><p>3 0.86881834 <a title="71-lsi-3" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>Author: Vahed Qazvinian ; Emily Rosengren ; Dragomir R. Radev ; Qiaozhu Mei</p><p>Abstract: A rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP). Fi- nally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations.</p><p>4 0.78147411 <a title="71-lsi-4" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>Author: Eiji ARAMAKI ; Sachiko MASKAWA ; Mizuki MORITA</p><p>Abstract: Sachiko MASKAWA The University of Tokyo Tokyo, Japan s achi ko . mas kawa @ gma i . com l Mizuki MORITA National Institute of Biomedical Innovation Osaka, Japan mori ta . mi zuki @ gmai l com . posts more than 5.5 million messages (tweets) every day (reported by Twitter.com in March 201 1). With the recent rise in popularity and scale of social media, a growing need exists for systems that can extract useful information from huge amounts of data. We address the issue of detecting influenza epidemics. First, the proposed system extracts influenza related tweets using Twitter API. Then, only tweets that mention actual influenza patients are extracted by the support vector machine (SVM) based classifier. The experiment results demonstrate the feasibility of the proposed approach (0.89 correlation to the gold standard). Especially at the outbreak and early spread (early epidemic stage), the proposed method shows high correlation (0.97 correlation), which outperforms the state-of-the-art methods. This paper describes that Twitter texts reflect the real world, and that NLP techniques can be applied to extract only tweets that contain useful information. 1</p><p>5 0.72516704 <a title="71-lsi-5" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>Author: John D. Burger ; John Henderson ; George Kim ; Guido Zarrella</p><p>Abstract: Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.</p><p>6 0.52494591 <a title="71-lsi-6" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>7 0.47600508 <a title="71-lsi-7" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>8 0.20644461 <a title="71-lsi-8" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>9 0.20070069 <a title="71-lsi-9" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>10 0.18851186 <a title="71-lsi-10" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>11 0.18631802 <a title="71-lsi-11" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>12 0.18148211 <a title="71-lsi-12" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>13 0.15240489 <a title="71-lsi-13" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>14 0.14775404 <a title="71-lsi-14" href="./emnlp-2011-The_Imagination_of_Crowds%3A_Conversational_AAC_Language_Modeling_using_Crowdsourcing_and_Large_Data_Sources.html">133 emnlp-2011-The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources</a></p>
<p>15 0.14161599 <a title="71-lsi-15" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>16 0.10855215 <a title="71-lsi-16" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>17 0.10436482 <a title="71-lsi-17" href="./emnlp-2011-Refining_the_Notions_of_Depth_and_Density_in_WordNet-based_Semantic_Similarity_Measures.html">112 emnlp-2011-Refining the Notions of Depth and Density in WordNet-based Semantic Similarity Measures</a></p>
<p>18 0.10028435 <a title="71-lsi-18" href="./emnlp-2011-Approximate_Scalable_Bounded_Space_Sketch_for_Large_Data_NLP.html">19 emnlp-2011-Approximate Scalable Bounded Space Sketch for Large Data NLP</a></p>
<p>19 0.098689035 <a title="71-lsi-19" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>20 0.089769363 <a title="71-lsi-20" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.315), (23, 0.093), (32, 0.011), (36, 0.022), (37, 0.021), (45, 0.067), (52, 0.051), (53, 0.012), (54, 0.02), (57, 0.013), (62, 0.024), (64, 0.013), (66, 0.02), (70, 0.019), (79, 0.04), (82, 0.017), (87, 0.021), (90, 0.016), (96, 0.042), (97, 0.023), (98, 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76654238 <a title="71-lda-1" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>Author: Roy Bar-Haim ; Elad Dinur ; Ronen Feldman ; Moshe Fresko ; Guy Goldstein</p><p>Abstract: Information published in online stock investment message boards, and more recently in stock microblogs, is considered highly valuable by many investors. Previous work focused on aggregation of sentiment from all users. However, in this work we show that it is beneficial to distinguish expert users from non-experts. We propose a general framework for identifying expert investors, and use it as a basis for several models that predict stock rise from stock microblogging messages (stock tweets). In particular, we present two methods that combine expert identification and per-user unsupervised learning. These methods were shown to achieve relatively high precision in predicting stock rise, and significantly outperform our baseline. In addition, our work provides an in-depth analysis of the content and potential usefulness of stock tweets.</p><p>2 0.68237728 <a title="71-lda-2" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>Author: Katsuhiko Hayashi ; Taro Watanabe ; Masayuki Asahara ; Yuji Matsumoto</p><p>Abstract: We propose a novel forest reranking algorithm for discriminative dependency parsing based on a variant of Eisner’s generative model. In our framework, we define two kinds of generative model for reranking. One is learned from training data offline and the other from a forest generated by a baseline parser on the fly. The final prediction in the reranking stage is performed using linear interpolation of these models and discriminative model. In order to efficiently train the model from and decode on a hypergraph data structure representing a forest, we apply extended inside/outside and Viterbi algorithms. Experimental results show that our proposed forest reranking algorithm achieves significant improvement when compared with conventional approaches.</p><p>3 0.51540142 <a title="71-lda-3" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>Author: Jason Katz-Brown ; Slav Petrov ; Ryan McDonald ; Franz Och ; David Talbot ; Hiroshi Ichikawa ; Masakazu Seno ; Hideto Kazawa</p><p>Abstract: We propose a simple training regime that can improve the extrinsic performance of a parser, given only a corpus of sentences and a way to automatically evaluate the extrinsic quality of a candidate parse. We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system. We use a corpus of weakly-labeled reference reorderings to guide parser training. Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress.</p><p>4 0.41332102 <a title="71-lda-4" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>Author: Matthias Hartung ; Anette Frank</p><p>Abstract: This paper introduces an attribute selection task as a way to characterize the inherent meaning of property-denoting adjectives in adjective-noun phrases, such as e.g. hot in hot summer denoting the attribute TEMPERATURE, rather than TASTE. We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes. The vectors incorporate latent semantic information obtained from two variants of LDA topic models. Our LDA models outperform previous approaches on a small set of 10 attributes with considerable gains on sparse representations, which highlights the strong smoothing power of LDA models. For the first time, we extend the attribute selection task to a new data set with more than 200 classes. We observe that large-scale attribute selection is a hard problem, but a subset of attributes performs robustly on the large scale as well. Again, the LDA models outperform the VSM baseline.</p><p>5 0.41204095 <a title="71-lda-5" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>Author: Joseph Reisinger ; Raymond Mooney</p><p>Abstract: Context-dependent word similarity can be measured over multiple cross-cutting dimensions. For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity. Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clusterings. MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich- let Allocation. Intuitively, this constraint favors feature partitions that have coherent topical semantics. Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.</p><p>6 0.40905249 <a title="71-lda-6" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>7 0.40629742 <a title="71-lda-7" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>8 0.39407763 <a title="71-lda-8" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>9 0.38442305 <a title="71-lda-9" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>10 0.38371614 <a title="71-lda-10" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>11 0.38362303 <a title="71-lda-11" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>12 0.38229597 <a title="71-lda-12" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>13 0.38157359 <a title="71-lda-13" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>14 0.38120133 <a title="71-lda-14" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>15 0.3793692 <a title="71-lda-15" href="./emnlp-2011-Twitter_Catches_The_Flu%3A_Detecting_Influenza_Epidemics_using_Twitter.html">139 emnlp-2011-Twitter Catches The Flu: Detecting Influenza Epidemics using Twitter</a></p>
<p>16 0.37851316 <a title="71-lda-16" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>17 0.3776044 <a title="71-lda-17" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>18 0.37754115 <a title="71-lda-18" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>19 0.37747434 <a title="71-lda-19" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>20 0.37708032 <a title="71-lda-20" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
