<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-144" href="#">emnlp2011-144</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</h1>
<br/><p>Source: <a title="emnlp-2011-144-pdf" href="http://aclweb.org/anthology//D/D11/D11-1091.pdf">pdf</a></p><p>Author: Kirk Roberts ; Sanda Harabagiu</p><p>Abstract: Metonymic language is a pervasive phenomenon. Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument’s semantic class differs from the class the predicate expects. In this paper we present an unsupervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. This method also generates an enhanced probabilistic resolution of logical metonymies. The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations.</p><p>Reference: <a title="emnlp-2011-144-reference" href="../emnlp2011_reference/emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument’s semantic class differs from the class the predicate expects. [sent-5, score-0.861]
</p><p>2 In this paper we present an unsupervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. [sent-6, score-0.452]
</p><p>3 The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations. [sent-8, score-0.369]
</p><p>4 The quality of the answers therefore depends on the ability to (1) recognize when metonymic language is used, and (2) to produce coercions that capture the user’s intention. [sent-14, score-0.3]
</p><p>5 980 taken by SemEval-2010 Task 7, which focused on the ability to recognize (a) an argument’s selectional restriction for predicates such as arrive at, cancel, or hear, and (b) the type of coercion that licensed a correct interpretation of the metonymy. [sent-16, score-0.9]
</p><p>6 However, metonymy coercion systems capable of providing the interpretations of questions (Q1) and (Q2) clearly cannot operate with the simplifications designed for this task. [sent-20, score-0.863]
</p><p>7 The model assumes that (1) arguments have a single selected class exemplified by the selectional restriction, and (2) the selected class can be inferred from the data, in part by modeling how coercive each predicate is. [sent-23, score-0.837]
</p><p>8 The selectional restrictions and coercions detected by the model reported in this paper can be used to enhance the logical metonymy approach reported in Lapata and Lascarides (2003). [sent-25, score-0.862]
</p><p>9 Section 5 describes the enhanced interpretation of logical metonymies when conventional constraints are known. [sent-33, score-0.426]
</p><p>10 Section 7 presents our experimental results in three broad tasks: (i) semantic class induction, (ii) coercion detection, and (iii) logical metonymy interpretation. [sent-35, score-1.01]
</p><p>11 Shutova (2009) extends this approach to provide sense-disambiguated interpretations from WordNet (Fellbaum, 1998) by using the alternative interpretations to disambiguate polysemous words. [sent-39, score-0.346]
</p><p>12 nNdo t{ only ,d op othdeuscee approaches assume logical metonymies have already been identified, but they are susceptible to providing interpretations that are themselves logical metonymies (e. [sent-43, score-0.863]
</p><p>13 In this paper, we propose an enhancement to resolving logical metonymies by ruling out event-invoking predicates in order to provide more semantically valid interpretations. [sent-46, score-0.539]
</p><p>14 Inspired by these results, we propose to extend selectional preference models in order to learn selectional restrictions. [sent-52, score-0.356]
</p><p>15 , 1999;  Lin and Pantel, 2001) and cluster predicates by their 981 selectional restrictions (Rumshisky et al. [sent-54, score-0.38]
</p><p>16 , 2007) but none of these provide a sufficient framework for determining if a specific argument violates its predicate’s selectional restriction. [sent-55, score-0.341]
</p><p>17 3  Unsupervised Learning of Selectional Restrictions  In predicate-argument structures, predicates impose selectional restrictions in the form of semantic expectations on their arguments. [sent-56, score-0.374]
</p><p>18 Whenever the semantic class of the argument meets these constraints a selection occurs. [sent-57, score-0.302]
</p><p>19 For example, the predicate “hear” imposes the semantics related to sound on the argument “voice”. [sent-58, score-0.413]
</p><p>20 Because the semantic class for “voice” conforms to these constraints, we call its semantic class the selected class. [sent-59, score-0.329]
</p><p>21 However, when the semantic class of the argument violates these constraints, we follow Pustejovsky et al. [sent-60, score-0.325]
</p><p>22 For example, “hear speaker” is a coercion where the argument class, person, is implicitly coerced into the  voice of the speaker, a sound. [sent-63, score-0.671]
</p><p>23 1 A Baseline Model We consider the LDA-based selectional preference model reported in O´ S ´eaghdha (2010) as a baseline for modeling selectional restrictions. [sent-65, score-0.356]
</p><p>24 Let V be the predicate vocabulary size, let A be the argument vocabulary size, and let K be the number of argument classes. [sent-67, score-0.543]
</p><p>25 Let aiv be the ith (non-unique) argument realized by predicate v. [sent-68, score-0.483]
</p><p>26 Let θv be the class distribution for predicate v and φk be the argument distribution for class k. [sent-70, score-0.638]
</p><p>27 The generative process for LDA is: For each argument class k = 1. [sent-72, score-0.28]
</p><p>28 Choose φk ∼ Dirichlet(β) For each unique predicate v = 1. [sent-75, score-0.257]
</p><p>29 Choose aiv ∼ MMuullttiinnoommiiaall((θφciv )  Following Griffiths and Steyvers (2004), we collapse θ and φ and estimate the model using Gibbs  αθ(cβa)φaKNV Figure 1: Graphical models for (a) LDA, and (b) coercion LDA (cLDA). [sent-82, score-0.529]
</p><p>30 Namely: (1) there is one selected class per predicate, and (2) the predicate’s selected class can be chosen from the classes of its arguments. [sent-87, score-0.382]
</p><p>31 We  assign a latent variable τv for each predicate v that controls how coercive v should be. [sent-89, score-0.301]
</p><p>32 The generative process for this coercion LDA model, which we denote cLDA, is: For each argument class k = 1. [sent-91, score-0.714]
</p><p>33 Choose φk ∼ Dirichlet(β) For each unique predicate v =) 1. [sent-94, score-0.257]
</p><p>34 If xiv = 1, C∼ho Boesren aiv ∼li( τMultinomial(φciv) Else Choose aiv ∼ Mu∼lti nMomultiianl(oφmsvia)l The model variable represents the selected class for predicate v. [sent-104, score-0.746]
</p><p>35 The coerced class is represented  sv  2With the exception that the probability of drawing the selected class sv is zero. [sent-105, score-0.555]
</p><p>36 982 for each argument iby civ, where xiv chooses between the selected and coerced class. [sent-107, score-0.407]
</p><p>37 In this way, highly coercive predicates have less of an impact on the argument clustering because they are more reliant on the multinomial θ. [sent-113, score-0.45]
</p><p>38 Note that Equation (2) results in a sampling of the selected class for v proportional to the number of arguments in each class for v, fulfilling our second assumption. [sent-117, score-0.338]
</p><p>39 When the predicate is very coercive, the marginal probability associated with xiv = 0 will be  sv  very low. [sent-119, score-0.504]
</p><p>40 3  Coercion Detection  After the latent parameters have been estimated, we still require a method to determine if a given predicate-argument pair is a coercion or not. [sent-122, score-0.434]
</p><p>41 sv  The cLDA model contains two useful parameters that can identify selections and coercions: the selected class s and the coercion indicator x. [sent-128, score-0.784]
</p><p>42 This yields two more coercion scoring metrics: 983 C2(v, a) = P(a|sv) = φsav  (5)  C3 (v, a) = P(xav = 0|v, a)  = 1. [sent-129, score-0.47]
</p><p>43 0 −Pi|∈IIavav|xiv sv  (6)  Where is the selected class for predicate v; Iav is the set of predicate-argument instances for predicate v and argument a; and xiv is 0 for a selection and 1 for a coercion. [sent-130, score-1.052]
</p><p>44 Of the three metrics, C3 is the most direct measure of a coercion as it represents the average decision the model learned on the same predicate-argument pair. [sent-131, score-0.46]
</p><p>45 4  Predicate Sense Induction  Our assumption of a single selected class per predicate ignores predicate polysemy. [sent-134, score-0.626]
</p><p>46 This allows separate induced predicates to each select a separate argument class. [sent-137, score-0.365]
</p><p>47 The result of predicate induction on the verb fire is shown in Table 4. [sent-158, score-0.327]
</p><p>48 One must be careful in choosing the parameters for induction, however, as it is possible to partition a unique word sense such that coercions and selections are placed in a separate clusters. [sent-162, score-0.371]
</p><p>49 5 Logical Metonymy Interpretation Logical metonymies are a unique class of coercions due to the fact that their eventive interpretation can be derived from verbal predicates. [sent-164, score-0.644]
</p><p>50 For instance, for the logical metonymy “enjoy book”, we know that  read is a good candidate interpretation because (1) books are objects whose purpose is to be read and (2) reading is an event that may be enjoyed. [sent-165, score-0.598]
</p><p>51 Conversely, for coercions with non-eventive interpretations, such as “arrive at meeting”, the interpretation (location of) is more dependent on the predicate (arrive) than the function of its argument (meeting). [sent-167, score-0.693]
</p><p>52 984 In this section, we limit our discussion of logical metonymy to the verb-object case, its corresponding baseline for ranking interpretations, and our proposed enhancements. [sent-168, score-0.455]
</p><p>53 We denote this logical metonymy ranking method as LMLL, formally defined as: LMLL (e; v, o) = Pc(v, e, o) = Pc(e)Pc(v|e)Pc(o|e, v) ≈  Pc(e)Pc(v|e)Pc(o|e)  ≈fc(vN,ef)cf(ce()o,e)  (7)  Where Pc and fc indicate probability and frequency, respectively, derived from corpus counts. [sent-175, score-0.455]
</p><p>54 Both “finish book” and “discuss book” are coercions (and logical metonymies) themselves, and do not form a valid interpretation. [sent-179, score-0.43]
</p><p>55 Instead, we can combine the corpus probability Pc(v, e, o) with the probability that the  verb-object pair (e, o) is a coercion in our model. [sent-183, score-0.434]
</p><p>56 , 1998) with at least 100 argument instances, discarding have and say, which are too semantically flexible to select from clear semantic classes and so common they distort the class distributions. [sent-203, score-0.364]
</p><p>57 , “like to swim”) for use in logical metonymy interpretation. [sent-207, score-0.429]
</p><p>58 Both LDA and cLDA  were found to perform best at 50 iterations on this data, after which their class distributions were less “smooth” and became rigidly associated with just a few classes, thus having a negative impact on coercion detection. [sent-226, score-0.559]
</p><p>59 While further iterations hurt coercion detection, only minor gains in model likelihood are seen. [sent-227, score-0.434]
</p><p>60 1 Semantic Class Induction For the evaluation of the argument classes induced by our method, we use a subset of the WordNet lexicographer files, which correspond to coarsegrained semantic classes. [sent-259, score-0.3]
</p><p>61 For this evaluation, predicate induction also improved LDA for smaller numbers of classes, but not to the degree that it improved cLDA. [sent-280, score-0.294]
</p><p>62 Without predicate induction, LDA outperforms cLDA on all six  metrics for 25 and 50 classes. [sent-281, score-0.263]
</p><p>63 With predicate induction, LDA outperforms cLDA on only one metric for 25 classes and five metrics for 50 classes. [sent-282, score-0.325]
</p><p>64 Thus the induced predicates do reduce the negative impact caused by the single selected class assumption for semantic class induction. [sent-283, score-0.517]
</p><p>65 2 Coercion Detection For the evaluation of coercion detection, we use the SemEval-2010 Task 7 data (Pustejovsky et al. [sent-285, score-0.434]
</p><p>66 This data uses the most common sense for each of five predicates (arrive, cancel, deny, finish, and hear) with a total of 2,070 sentences annotated with the argument’s source type (the argument’s semantic class) and target type (the predicate’s selected class for that argument). [sent-287, score-0.366]
</p><p>67 We ignore the actual argument classes and evaluate on the coercion type, which is a selection when the source and target type match, and a coercion otherwise. [sent-288, score-1.085]
</p><p>68 In order to evaluate unsupervised systems on this data, we use the corresponding training set (1,031 examples) to learn a threshold for coercion detection. [sent-289, score-0.465]
</p><p>69 At test time, if the model output is below the threshold, a coercion is inferred. [sent-290, score-0.434]
</p><p>70 The best overall model on this data is cLDA using the C1 coercion scoring method (Equation (4)). [sent-296, score-0.47]
</p><p>71 The use of predicate sense induction based on tiered clustering to overcome the single-class assumption caused significant degradation in performance on this task. [sent-305, score-0.523]
</p><p>72 Using automatically induced predicates instead of the surface form caused an average degradation of 2. [sent-306, score-0.258]
</p><p>73 A potential explanation for this is that the evaluated predicates have a single dominant sense, meaning the single class assumption may be valid for these predicates (the task-defined selected classes are: location for arrive, event for cancel and finish, proposition for deny, and sound for hear). [sent-308, score-0.631]
</p><p>74 Furthermore, the introduction of predicate sense induction was designed to help cLDA, and the performance degradation for these nine tests was not as large as it was for LDA. [sent-310, score-0.377]
</p><p>75 This could be overcome by a joint approach of inducing predicate classes while simultaneously detecting coercions, as the presence of many coercions would be an indicator that more induced predicates are necessary. [sent-318, score-0.735]
</p><p>76 Shutova and Teufel (2009) annotated 10 verbobject logical metonymies from Lapata and Lascarides (2003) with sense-disambiguated interpretations and organized the interpretations into clusters representing different possible meanings. [sent-321, score-0.753]
</p><p>77 The  best scores with/without induced predicates as well as using/not using a threshold-based interpretation method. [sent-323, score-0.285]
</p><p>78 The bold items indicate the best scores with/without induced predicates as well as using/not using a threshold-based  interpretation method. [sent-324, score-0.285]
</p><p>79 data contains an average of 11 interpretations per metonymy and has a reported 70% recall. [sent-325, score-0.429]
</p><p>80 Three annotators were asked to provide up to five interpretations for each metonymy (they were not provided with any verbs from which to choose, only the verbobject pair). [sent-327, score-0.499]
</p><p>81 Because our goal was recall, inter-annotator agreement was necessarily low, and each logical metonymy had an average of 11. [sent-330, score-0.429]
</p><p>82 7 Since logical metonymy interpretation is usually evaluated as a ranking task, we score our methods 7 Data available at http://www. [sent-333, score-0.53]
</p><p>83 Since the metonymies in our data are a  super-set of those in their data, and since for those metonymies our annotators provided approximately the same number of interpretations (110 versus 120), this likely indicates the remaining metonymies in our data are more difficult. [sent-344, score-0.731]
</p><p>84 Unlike coercion detection on the SemEval data, C3 performs very well, achieving the highest scores when no predicate sense induction is used. [sent-346, score-0.806]
</p><p>85 Also unlike coercion detection, LDA scores do not increase as the number of classes increase. [sent-347, score-0.496]
</p><p>86 Since LDA is a selectional preference model and its coercion scores correspond roughly to the plausibility of seeing a predicate-argument pair, it is less able to distinguish coercions in common arguments. [sent-349, score-0.882]
</p><p>87 Of the logical metonymy ranking methods, LMTH consistently produces the highest MAP scores. [sent-350, score-0.455]
</p><p>88 The best non-thresholded ranking method is LMIND, which naively combines the LMLL score with the coercion probability. [sent-352, score-0.46]
</p><p>89 This can make it difficult to learn a linear model using these scores as features, and as a result the learned weights were forced to ignore the coercion score and rely entirely on LMLL. [sent-355, score-0.46]
</p><p>90 Using induced senses did not result in the drastic and consistent degradation in performance seen on the SemEval data, and the highest non-threshold result for the Shutova and Teufel (2009) data used predicate induction. [sent-357, score-0.406]
</p><p>91 Both metonymy data sets were limited to the verbs found in Lapata and Lascarides (2003), which are still quite common (attempt, begin, enjoy, expect, finish, prefer, start, survive, try, 989 want). [sent-358, score-0.297]
</p><p>92 This suggests the potential value of sense induction  for highly polysemous predicates and further motivates the integration of sense induction within a selectional restriction model. [sent-362, score-0.566]
</p><p>93 8  Conclusion  We have presented a novel topic model that extends an unsupervised selectional preference model (LDA) to an unsupervised selectional restriction model (cLDA) using two assumptions. [sent-363, score-0.394]
</p><p>94 For the first assumption, that each predicate has a single selected class, we proposed a predicate induction method to overcome predicate polysemy. [sent-364, score-0.795]
</p><p>95 This improved results for semantic class induction but proved harmful for detecting coercions on common predicates with a single, dominant sense. [sent-365, score-0.587]
</p><p>96 Superior performance on coercion detection shows the merit of this assumption. [sent-367, score-0.477]
</p><p>97 Additionally, we proposed methods for improving an existing task, logical metonymy interpretation, using the learned parameters of our model, showing positive results. [sent-368, score-0.455]
</p><p>98 It is clear that our model may be improved by more accurate predicate sense induction. [sent-369, score-0.268]
</p><p>99 To this end, we plan to develop a model that simultaneously induces predicates and learns coercions, using knowledge of a predicate’s coerciveness to inform the induction mechanism. [sent-370, score-0.251]
</p><p>100 Sense-based interpretation of logical metonymy using a statistical method. [sent-470, score-0.504]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('coercion', 0.434), ('clda', 0.28), ('metonymy', 0.268), ('predicate', 0.233), ('coercions', 0.23), ('metonymies', 0.19), ('lda', 0.179), ('selectional', 0.163), ('xiv', 0.163), ('logical', 0.161), ('interpretations', 0.161), ('argument', 0.155), ('predicates', 0.149), ('pc', 0.147), ('enjoy', 0.147), ('civ', 0.136), ('class', 0.125), ('shutova', 0.108), ('sv', 0.108), ('lascarides', 0.105), ('book', 0.102), ('aiv', 0.095), ('tiered', 0.095), ('selections', 0.082), ('lmth', 0.081), ('interpretation', 0.075), ('metonymic', 0.07), ('coercive', 0.068), ('lmll', 0.068), ('lapata', 0.065), ('senses', 0.064), ('classes', 0.062), ('induction', 0.061), ('induced', 0.061), ('px', 0.058), ('coerced', 0.054), ('lmwt', 0.054), ('arguments', 0.053), ('teufel', 0.053), ('clustering', 0.051), ('finish', 0.049), ('degradation', 0.048), ('cancel', 0.047), ('pustejovsky', 0.047), ('rumshisky', 0.047), ('hear', 0.046), ('detection', 0.043), ('reisinger', 0.042), ('arrive', 0.041), ('coerciveness', 0.041), ('verbobject', 0.041), ('restrictions', 0.04), ('av', 0.039), ('clusters', 0.039), ('valid', 0.039), ('restriction', 0.038), ('choose', 0.037), ('eaghdha', 0.037), ('scoring', 0.036), ('dirichlet', 0.035), ('selected', 0.035), ('ekaterina', 0.035), ('rooth', 0.035), ('finishing', 0.035), ('sense', 0.035), ('semeval', 0.033), ('fire', 0.033), ('reading', 0.032), ('threshold', 0.031), ('read', 0.031), ('preference', 0.03), ('metrics', 0.03), ('verbs', 0.029), ('cluster', 0.028), ('voice', 0.028), ('multinomial', 0.027), ('bowling', 0.027), ('ffvv', 0.027), ('lmind', 0.027), ('parker', 0.027), ('vilain', 0.027), ('ranking', 0.026), ('learned', 0.026), ('iv', 0.026), ('switching', 0.026), ('discussing', 0.026), ('xk', 0.026), ('wordnet', 0.025), ('seeing', 0.025), ('sound', 0.025), ('unique', 0.024), ('polysemous', 0.024), ('violates', 0.023), ('predicateargument', 0.023), ('gun', 0.023), ('bagga', 0.023), ('deny', 0.023), ('artifact', 0.023), ('anna', 0.022), ('semantic', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="144-tfidf-1" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>Author: Kirk Roberts ; Sanda Harabagiu</p><p>Abstract: Metonymic language is a pervasive phenomenon. Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument’s semantic class differs from the class the predicate expects. In this paper we present an unsupervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. This method also generates an enhanced probabilistic resolution of logical metonymies. The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations.</p><p>2 0.11737058 <a title="144-tfidf-2" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we present a method for unsupervised semantic role induction which we formalize as a graph partitioning problem. Argument instances of a verb are represented as vertices in a graph whose edge weights quantify their role-semantic similarity. Graph partitioning is realized with an algorithm that iteratively assigns vertices to clusters based on the cluster assignments of neighboring vertices. Our method is algorithmically and conceptually simple, especially with respect to how problem-specific knowledge is incorporated into the model. Experimental results on the CoNLL 2008 benchmark dataset demonstrate that our model is competitive with other unsupervised approaches in terms of F1 whilst attaining significantly higher cluster purity.</p><p>3 0.11115523 <a title="144-tfidf-3" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>Author: Matthias Hartung ; Anette Frank</p><p>Abstract: This paper introduces an attribute selection task as a way to characterize the inherent meaning of property-denoting adjectives in adjective-noun phrases, such as e.g. hot in hot summer denoting the attribute TEMPERATURE, rather than TASTE. We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes. The vectors incorporate latent semantic information obtained from two variants of LDA topic models. Our LDA models outperform previous approaches on a small set of 10 attributes with considerable gains on sparse representations, which highlights the strong smoothing power of LDA models. For the first time, we extend the attribute selection task to a new data set with more than 200 classes. We observe that large-scale attribute selection is a hard problem, but a subset of attributes performs robustly on the large scale as well. Again, the LDA models outperform the VSM baseline.</p><p>4 0.11108883 <a title="144-tfidf-4" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>Author: Bryan Rink ; Sanda Harabagiu</p><p>Abstract: This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records. The model discovers relation instances and their types by determining which context tokens express the relation. Additionally, the valid semantic classes for each type of relation are determined. We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques. The discovered relations reveal some of the implicit semantic structure present in patient records.</p><p>5 0.099794537 <a title="144-tfidf-5" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>Author: Diarmuid O Seaghdha ; Anna Korhonen</p><p>Abstract: This paper investigates novel methods for incorporating syntactic information in probabilistic latent variable models of lexical choice and contextual similarity. The resulting models capture the effects of context on the interpretation of a word and in particular its effect on the appropriateness of replacing that word with a potentially related one. Evaluating our techniques on two datasets, we report performance above the prior state of the art for estimating sentence similarity and ranking lexical substitutes.</p><p>6 0.095771819 <a title="144-tfidf-6" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>7 0.094858915 <a title="144-tfidf-7" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>8 0.085036427 <a title="144-tfidf-8" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>9 0.079309173 <a title="144-tfidf-9" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>10 0.078439049 <a title="144-tfidf-10" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>11 0.07335411 <a title="144-tfidf-11" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>12 0.064508565 <a title="144-tfidf-12" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>13 0.061199509 <a title="144-tfidf-13" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>14 0.060371201 <a title="144-tfidf-14" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>15 0.057879973 <a title="144-tfidf-15" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>16 0.055234786 <a title="144-tfidf-16" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>17 0.055198185 <a title="144-tfidf-17" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>18 0.054139558 <a title="144-tfidf-18" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>19 0.053211272 <a title="144-tfidf-19" href="./emnlp-2011-Bayesian_Checking_for_Topic_Models.html">21 emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>20 0.052279867 <a title="144-tfidf-20" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.163), (1, -0.116), (2, -0.184), (3, -0.027), (4, -0.004), (5, 0.045), (6, 0.038), (7, 0.061), (8, 0.065), (9, 0.017), (10, -0.069), (11, 0.075), (12, 0.018), (13, -0.167), (14, -0.068), (15, 0.134), (16, -0.022), (17, 0.066), (18, -0.033), (19, 0.077), (20, 0.001), (21, 0.055), (22, 0.034), (23, 0.105), (24, 0.01), (25, -0.159), (26, -0.034), (27, -0.116), (28, 0.1), (29, 0.079), (30, -0.23), (31, 0.104), (32, -0.014), (33, 0.058), (34, -0.053), (35, 0.025), (36, -0.007), (37, 0.082), (38, -0.136), (39, -0.047), (40, 0.099), (41, -0.086), (42, 0.049), (43, -0.024), (44, -0.112), (45, -0.136), (46, -0.059), (47, 0.171), (48, -0.041), (49, -0.097)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94863802 <a title="144-lsi-1" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>Author: Kirk Roberts ; Sanda Harabagiu</p><p>Abstract: Metonymic language is a pervasive phenomenon. Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument’s semantic class differs from the class the predicate expects. In this paper we present an unsupervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. This method also generates an enhanced probabilistic resolution of logical metonymies. The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations.</p><p>2 0.64194202 <a title="144-lsi-2" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>Author: Joseph Reisinger ; Raymond Mooney</p><p>Abstract: Context-dependent word similarity can be measured over multiple cross-cutting dimensions. For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity. Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account. Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clusterings. MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich- let Allocation. Intuitively, this constraint favors feature partitions that have coherent topical semantics. Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable, isolating the impact of data only to views where they assign the most features. Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.</p><p>3 0.5170384 <a title="144-lsi-3" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we present a method for unsupervised semantic role induction which we formalize as a graph partitioning problem. Argument instances of a verb are represented as vertices in a graph whose edge weights quantify their role-semantic similarity. Graph partitioning is realized with an algorithm that iteratively assigns vertices to clusters based on the cluster assignments of neighboring vertices. Our method is algorithmically and conceptually simple, especially with respect to how problem-specific knowledge is incorporated into the model. Experimental results on the CoNLL 2008 benchmark dataset demonstrate that our model is competitive with other unsupervised approaches in terms of F1 whilst attaining significantly higher cluster purity.</p><p>4 0.46339703 <a title="144-lsi-4" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>Author: Song Feng ; Ritwik Bose ; Yejin Choi</p><p>Abstract: In this paper, we introduce a connotation lexicon, a new type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war). Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment. Understanding the connotation of words would seem to require common sense and world knowledge. However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner. The key linguistic insight behind our approach is selectional preference of connotative predicates. We present graphbased algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates. Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons.</p><p>5 0.39774585 <a title="144-lsi-5" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>Author: Vivek Srikumar ; Dan Roth</p><p>Abstract: This paper presents a model that extends semantic role labeling. Existing approaches independently analyze relations expressed by verb predicates or those expressed as nominalizations. However, sentences express relations via other linguistic phenomena as well. Furthermore, these phenomena interact with each other, thus restricting the structures they articulate. In this paper, we use this intuition to define a joint inference model that captures the inter-dependencies between verb semantic role labeling and relations expressed using prepositions. The scarcity of jointly labeled data presents a crucial technical challenge for learning a joint model. The key strength of our model is that we use existing structure predictors as black boxes. By enforcing consistency constraints between their predictions, we show improvements in the performance of both tasks without retraining the individual models.</p><p>6 0.39575246 <a title="144-lsi-6" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>7 0.36613229 <a title="144-lsi-7" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>8 0.34662297 <a title="144-lsi-8" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>9 0.34570941 <a title="144-lsi-9" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>10 0.32551914 <a title="144-lsi-10" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>11 0.31646985 <a title="144-lsi-11" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>12 0.29760721 <a title="144-lsi-12" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>13 0.29093051 <a title="144-lsi-13" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>14 0.28775811 <a title="144-lsi-14" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>15 0.27076614 <a title="144-lsi-15" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>16 0.27010491 <a title="144-lsi-16" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>17 0.25649124 <a title="144-lsi-17" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>18 0.23963577 <a title="144-lsi-18" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>19 0.23513053 <a title="144-lsi-19" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>20 0.23402292 <a title="144-lsi-20" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.087), (27, 0.342), (36, 0.017), (37, 0.027), (45, 0.073), (53, 0.015), (54, 0.041), (57, 0.029), (62, 0.028), (64, 0.015), (66, 0.039), (69, 0.013), (79, 0.037), (82, 0.031), (87, 0.012), (90, 0.015), (94, 0.017), (96, 0.07), (98, 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.77184778 <a title="144-lda-1" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>Author: Kirk Roberts ; Sanda Harabagiu</p><p>Abstract: Metonymic language is a pervasive phenomenon. Metonymic type shifting, or argument type coercion, results in a selectional restriction violation where the argument’s semantic class differs from the class the predicate expects. In this paper we present an unsupervised method that learns the selectional restriction of arguments and enables the detection of argument coercion. This method also generates an enhanced probabilistic resolution of logical metonymies. The experimental results indicate substantial improvements the detection of coercions and the ranking of metonymic interpretations.</p><p>2 0.70348537 <a title="144-lda-2" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>Author: Alessandro Moschitti ; Jennifer Chu-carroll ; Siddharth Patwardhan ; James Fan ; Giuseppe Riccardi</p><p>Abstract: The last decade has seen many interesting applications of Question Answering (QA) technology. The Jeopardy! quiz show is certainly one of the most fascinating, from the viewpoints of both its broad domain and the complexity of its language. In this paper, we study kernel methods applied to syntactic/semantic structures for accurate classification of Jeopardy! definition questions. Our extensive empirical analysis shows that our classification models largely improve on classifiers based on word-language models. Such classifiers are also used in the state-of-the-art QA pipeline constituting Watson, the IBM Jeopardy! system. Our experiments measuring their impact on Watson show enhancements in QA accuracy and a consequent increase in the amount of money earned in game-based evaluation.</p><p>3 0.70103627 <a title="144-lda-3" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>Author: Cane Wing-ki Leung ; Jing Jiang ; Kian Ming A. Chai ; Hai Leong Chieu ; Loo-Nin Teow</p><p>Abstract: We address the task of automatic discovery of information extraction template from a given text collection. Our approach clusters candidate slot fillers to identify meaningful template slots. We propose a generative model that incorporates distributional prior knowledge to help distribute candidates in a document into appropriate slots. Empirical results suggest that the proposed prior can bring substantial improvements to our task as compared to a K-means baseline and a Gaussian mixture model baseline. Specifically, the proposed prior has shown to be effective when coupled with discriminative features of the candidates.</p><p>4 0.39509347 <a title="144-lda-4" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>Author: Edward Grefenstette ; Mehrnoosh Sadrzadeh</p><p>Abstract: Modelling compositional meaning for sentences using empirical distributional methods has been a challenge for computational linguists. We implement the abstract categorical model of Coecke et al. (2010) using data from the BNC and evaluate it. The implementation is based on unsupervised learning of matrices for relational words and applying them to the vectors of their arguments. The evaluation is based on the word disambiguation task developed by Mitchell and Lapata (2008) for intransitive sentences, and on a similar new experiment designed for transitive sentences. Our model matches the results of its competitors . in the first experiment, and betters them in the second. The general improvement in results with increase in syntactic complexity showcases the compositional power of our model.</p><p>5 0.39429361 <a title="144-lda-5" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>Author: Diarmuid O Seaghdha ; Anna Korhonen</p><p>Abstract: This paper investigates novel methods for incorporating syntactic information in probabilistic latent variable models of lexical choice and contextual similarity. The resulting models capture the effects of context on the interpretation of a word and in particular its effect on the appropriateness of replacing that word with a potentially related one. Evaluating our techniques on two datasets, we report performance above the prior state of the art for estimating sentence similarity and ranking lexical substitutes.</p><p>6 0.39314291 <a title="144-lda-6" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>7 0.3912628 <a title="144-lda-7" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>8 0.38774979 <a title="144-lda-8" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>9 0.38756499 <a title="144-lda-9" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>10 0.38739076 <a title="144-lda-10" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>11 0.38597643 <a title="144-lda-11" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>12 0.38536274 <a title="144-lda-12" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>13 0.38477319 <a title="144-lda-13" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>14 0.38442326 <a title="144-lda-14" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>15 0.38273722 <a title="144-lda-15" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>16 0.38270202 <a title="144-lda-16" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>17 0.38235727 <a title="144-lda-17" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>18 0.38209262 <a title="144-lda-18" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>19 0.37955213 <a title="144-lda-19" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>20 0.37901908 <a title="144-lda-20" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
