<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>26 emnlp-2011-Class Label Enhancement via Related Instances</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-26" href="#">emnlp2011-26</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>26 emnlp-2011-Class Label Enhancement via Related Instances</h1>
<br/><p>Source: <a title="emnlp-2011-26-pdf" href="http://aclweb.org/anthology//D/D11/D11-1011.pdf">pdf</a></p><p>Author: Zornitsa Kozareva ; Konstantin Voevodski ; Shanghua Teng</p><p>Abstract: Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels. Yet, nobody has explored the relationships between the instances themselves to enhance an initial set of class-instance pairs. We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network. We carry out a comparative study with state-of-the-art knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy.</p><p>Reference: <a title="emnlp-2011-26-reference" href="../emnlp2011_reference/emnlp-2011-Class_Label_Enhancement_via_Related_Instances_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Class Label Enhancement via Related Instances  Zornitsa Kozareva USC Information Sciences Institute 4676 Admiralty Way Marina del Rey, CA 90292-6695 ko z areva @ i i s . [sent-1, score-0.08]
</p><p>2 edu Abstract Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels. [sent-2, score-0.645]
</p><p>3 Yet, nobody has explored the relationships between the instances themselves to enhance an initial set of class-instance pairs. [sent-3, score-0.365]
</p><p>4 We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network. [sent-4, score-0.454]
</p><p>5 We carry out a comparative study with state-of-the-art  knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. [sent-5, score-0.712]
</p><p>6 We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy. [sent-6, score-0.819]
</p><p>7 1 Introduction Many natural language processing applications use and rely on semantic knowledge resources. [sent-7, score-0.094]
</p><p>8 Since manually built lexical repositories such as WordNet (Fellbaum, 1998) cover a limited amount of knowledge and are tedious to maintain over time, researchers have developed algorithms for automatic knowledge extraction from structured and unstructured texts. [sent-8, score-0.423]
</p><p>9 There is a substantial body of work on extracting is-a relations (Etzioni et al. [sent-9, score-0.095]
</p><p>10 , 2003; Pantel and Pennacchiotti, 2006) and general facts (Lin and Pantel, 2001 ;Davidov and Rappoport, 118 Konstantin Voevodski Boston University  Shang-Hua Teng University of Southern California  111Cummington St. [sent-12, score-0.048]
</p><p>11 The usefulness of the generated resources has been shown to be valuable to information extraction (Riloff and Jones, 1999), question answering (Katz et al. [sent-16, score-0.09]
</p><p>12 Among the most common knowledge acquisition approaches are those based on lexical patterns (Hearst, 1992; Etzioni et al. [sent-19, score-0.051]
</p><p>13 , 2008) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). [sent-21, score-0.046]
</p><p>14 While clustering can find instances and classes that are not explicitly expressed in text, they often may not generate the granularity needed by the users. [sent-22, score-0.182]
</p><p>15 In contrast, pattern-based approaches generate highly accurate lists, but they are constraint to the information matched by the pattern and often suffer from recall. [sent-23, score-0.036]
</p><p>16 , 2006; Kozareva and Hovy, 2010) have shown that complete lists of semantic classes and instances are valuable for the enrichment of existing resources like WordNet and for taxonomy induction. [sent-25, score-0.315]
</p><p>17 Therefore, researchers have focused on the development  of methods that can automatically augment the initially extracted class-instance pairs. [sent-26, score-0.1]
</p><p>18 (Pennacchiotti and Pantel, 2009) fused information from pattern-based and distributional systems using an ensemble method and a rich set of features derived from query logs, web-crawl and Wikipedia. [sent-27, score-0.118]
</p><p>19 , 2008) improved class-instance extractions exploring the relationships between the classes and the instances to propagate the initial class-labels to the remaining unlabeled instances. [sent-29, score-0.697]
</p><p>20 Later on (Talukdar and Pereira, 2010) showed that class-instance extraction with label propagation can be further improved by adding semantic information Proce Ed iningbsu orfg th ,e S 2c0o1tl1an Cdo,n UfeKr,en Jcuely on 27 E–m31p,ir 2ic0a1l1 M. [sent-30, score-0.275]
</p><p>21 ec th2o0d1s1 i Ans Nsoactuiartaioln La fonrg Cuaogmep Purtoatcieosnsainlg L,in pgaugies ti 1c1s8–128, in the form of instance-attribute edges derived from independently developed knowledge base. [sent-32, score-0.087]
</p><p>22 , 2008) and (Talukdar and Pereira, 2010), we are interested in enriching class-instance extractions with label propagation. [sent-34, score-0.188]
</p><p>23 However, unlike the previous work, we model the relationships between the instances themselves to propagate the initial set of class labels to the remaining unlabeled instances. [sent-35, score-0.806]
</p><p>24 To our knowledge, this is the first work  to explore the connections between instances for the task of class-label propagation. [sent-36, score-0.19]
</p><p>25 Our work addresses the following question: Is it possible to effectively explore the structure of the text-mined instance-instance networks to enhance an incomplete set of class labels? [sent-37, score-0.202]
</p><p>26 Our intuition is that if an instance like bear belongs to a semantic class carnivore, and the instance bear is connected to the instance fox, then it is more likely that the unlabeled instance fox is also of class carnivore. [sent-38, score-0.904]
</p><p>27 To solve this problem, we propose two graph-based approaches that use the structure of the instanceinstance graph to propagate the class labels. [sent-39, score-0.651]
</p><p>28 Our methods are agnostic to the sources of semantic instances and classes. [sent-40, score-0.305]
</p><p>29 In this work, we carried out experiments with a state-of-the-art instance extraction system and conducted a comparative study between the original and the enhanced class-instance pairs. [sent-41, score-0.324]
</p><p>30 The results show that this labeling procedure can begin to bridge the gap between the extraction power of the pattern-based approaches and the desired recall by finding class-instance pairs that are not explicitly mentioned in text. [sent-42, score-0.049]
</p><p>31 The contributions of the paper are as follows: • We use only the relationships between the in-  •  •  sWtaen cuesse t ohnelmys tehlvee rse tlaot propagate ecltwasese lnab tehles. [sent-43, score-0.475]
</p><p>32 i We observe how often labels are propagated along tsheer edges wof o our s leambaenlstic a network, aatendd propose two ways to extend an initial set of class labels to all the instance nodes in the network. [sent-44, score-0.451]
</p><p>33 The first approach uses a linear system to compute the network centrality relative to the initially labeled instances. [sent-45, score-0.299]
</p><p>34 The second approach uses a regularization framework with respect to a random walk on the network. [sent-46, score-0.144]
</p><p>35 We evaluate the proposed approaches and show tWhaet they edi tshceov preor many new cchleasss a-nindst sahnocwe pairs compared to state-of-the-art knowledge 119 harvesting algorithm, while still maintaining high accuracy. [sent-47, score-0.279]
</p><p>36 •  We conduct a comparative study between classiWnsetacnocned actnda oinmsptaanractei-vinessttaundcye graphs ulassesdto propagate class labels. [sent-48, score-0.748]
</p><p>37 The experiments show that considering relationships between instances achieves higher accuracy. [sent-49, score-0.235]
</p><p>38 Section 3 describes the Web-based knowledge harvesting algorithm used to extract the instance network and the class-instance pairs necessary for our experimental evaluation. [sent-52, score-0.37]
</p><p>39 Section 4 describes the two graphtheoretic methods for class label propagation using an instance-instance network. [sent-53, score-0.337]
</p><p>40 Section 5 shows a comparative study between the proposed graph algorithms and different baselines. [sent-54, score-0.256]
</p><p>41 We also show a comparison between class-instance and instanceinstance graphs used in the label propagation. [sent-55, score-0.311]
</p><p>42 2  Related Work  In the past decade, we have reached a good understanding on the knowledge harvesting technology from structured (Suchanek et al. [sent-57, score-0.246]
</p><p>43 Researchers have harvested with varying success semantic lexicons (Riloff and Shepherd, 1997) and concept lists (Katz et al. [sent-59, score-0.236]
</p><p>44 Many efforts have also focused on the extraction of is-a relations (Hearst, 1992; Pas ¸ca, 2004; Etzioni et al. [sent-61, score-0.097]
</p><p>45 , 2003; Pantel and Pennacchiotti, 2006) and general facts (Etzioni et al. [sent-64, score-0.048]
</p><p>46 Various approaches have been proposed following the patterns of (Hearst, 1992) and clustering (Lin and Pantel, 2002; Davidov and Rappoport, 2008). [sent-66, score-0.046]
</p><p>47 A substantial body of work has explored issues such as reranking the harvested knowledge using mutual information (Etzioni et al. [sent-67, score-0.245]
</p><p>48 , 2009), estimating the goodness of textmining seeds (Vyas et al. [sent-69, score-0.044]
</p><p>49 , 2007b) and inducing term taxonomies with WordNet (Snow et al. [sent-72, score-0.041]
</p><p>50 , 2006) or starting from scratch (Kozareva and Hovy, 2010). [sent-73, score-0.039]
</p><p>51 Since pattern-based approaches tend to be highprecision and low-recall in nature, recently of great interest to the research community is the development of approaches that can increment the recall of the harvested class-instance pairs. [sent-74, score-0.188]
</p><p>52 (Pennacchiotti and Pantel, 2009) proposed an ensemble semantic framework that mixes distributional and patternbased systems with a large set of features from a web-crawl, query logs, and Wikipedia. [sent-75, score-0.151]
</p><p>53 , 2008) combined extractions from free text and structured sources using graph-based label propagation algorithm. [sent-77, score-0.395]
</p><p>54 (Talukdar and Pereira, 2010) conducted a comparative study of graph algorithms and showed that class-instance extraction can be improved using additional information that can be modeled as instance-attribute edges. [sent-78, score-0.305]
</p><p>55 , 2008; Talukdar and Pereira, 2010) who model classinstance relations to propagate class-labels. [sent-80, score-0.375]
</p><p>56 Although these algorithms can be applied to other relations (Alfonseca et al. [sent-81, score-0.048]
</p><p>57 , 2010), to our knowledge yet nobody has modeled the connections between the instances themselves for the task of class-label propagation. [sent-82, score-0.323]
</p><p>58 We propose regularization and centrality graph-theoretic methods, which exploit the instanceinstance network and a small set of class-instance pairs to propagate the class-labels to the remaining unlabeled instances. [sent-83, score-0.851]
</p><p>59 While objectives similar to regularization have been used for class-label propagation, the application of node centrality for this task is also novel. [sent-84, score-0.241]
</p><p>60 3  Knowledge Harvesting from the Web  Our proposed class-label enhancement approaches are agnostic to the sources of semantic instances and classes. [sent-86, score-0.387]
</p><p>61 Several methods have been developed to harvest instances from the Web (Pa ¸sca, 2004; Etzioni et al. [sent-87, score-0.216]
</p><p>62 , 2005; Pas ¸ca, 2007), it is easy to implement and requires minimum supervision (only one seed instance and a 120 lexico-syntactic pattern). [sent-92, score-0.135]
</p><p>63 For a given semantic class of interest say animals, the algorithm starts with a seed example of the class, say whales. [sent-93, score-0.265]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('talukdar', 0.329), ('kozareva', 0.309), ('propagate', 0.278), ('pantel', 0.205), ('etzioni', 0.188), ('davidov', 0.178), ('instanceinstance', 0.171), ('comparative', 0.166), ('harvesting', 0.159), ('centrality', 0.154), ('class', 0.154), ('harvested', 0.147), ('rappoport', 0.146), ('pennacchiotti', 0.139), ('pas', 0.139), ('instances', 0.136), ('extractions', 0.116), ('propagation', 0.111), ('hearst', 0.104), ('relationships', 0.099), ('sca', 0.098), ('network', 0.093), ('fox', 0.089), ('regularization', 0.087), ('katz', 0.082), ('nobody', 0.082), ('enhancement', 0.082), ('logs', 0.077), ('jain', 0.077), ('ca', 0.074), ('pereira', 0.073), ('label', 0.072), ('labels', 0.071), ('girju', 0.069), ('ensemble', 0.069), ('maintaining', 0.069), ('hovy', 0.068), ('graphs', 0.068), ('seed', 0.068), ('unlabeled', 0.068), ('instance', 0.067), ('agnostic', 0.066), ('bear', 0.064), ('cafarella', 0.064), ('unstructured', 0.064), ('sources', 0.06), ('riloff', 0.059), ('snow', 0.057), ('walk', 0.057), ('connections', 0.054), ('boston', 0.054), ('wordnet', 0.053), ('initially', 0.052), ('knowledge', 0.051), ('extraction', 0.049), ('marina', 0.049), ('repositories', 0.049), ('bloom', 0.049), ('admiralty', 0.049), ('animals', 0.049), ('classinstance', 0.049), ('enrichment', 0.049), ('fused', 0.049), ('lnab', 0.049), ('rse', 0.049), ('twhaet', 0.049), ('wof', 0.049), ('researchers', 0.048), ('enhance', 0.048), ('facts', 0.048), ('relations', 0.048), ('graph', 0.048), ('body', 0.047), ('clustering', 0.046), ('lists', 0.046), ('rey', 0.044), ('southern', 0.044), ('enrich', 0.044), ('goodness', 0.044), ('harvest', 0.044), ('lations', 0.044), ('semantic', 0.043), ('study', 0.042), ('valuable', 0.041), ('del', 0.041), ('alfonseca', 0.041), ('increment', 0.041), ('suchanek', 0.041), ('taxonomies', 0.041), ('zanzotto', 0.041), ('zornitsa', 0.041), ('conduct', 0.04), ('scratch', 0.039), ('ko', 0.039), ('tedious', 0.039), ('mixes', 0.039), ('propagated', 0.039), ('developed', 0.036), ('structured', 0.036), ('pattern', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="26-tfidf-1" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>Author: Zornitsa Kozareva ; Konstantin Voevodski ; Shanghua Teng</p><p>Abstract: Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels. Yet, nobody has explored the relationships between the instances themselves to enhance an initial set of class-instance pairs. We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network. We carry out a comparative study with state-of-the-art knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy.</p><p>2 0.11051948 <a title="26-tfidf-2" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>Author: Stijn De Saeger ; Kentaro Torisawa ; Masaaki Tsuchida ; Jun'ichi Kazama ; Chikara Hashimoto ; Ichiro Yamada ; Jong Hoon Oh ; Istvan Varga ; Yulan Yan</p><p>Abstract: This paper proposes a semi-supervised relation acquisition method that does not rely on extraction patterns (e.g. “X causes Y” for causal relations) but instead learns a combination of indirect evidence for the target relation semantic word classes and partial patterns. This method can extract long tail instances of semantic relations like causality from rare and complex expressions in a large Japanese Web corpus in extreme cases, patterns that occur only once in the entire corpus. Such patterns are beyond the reach ofcurrent pattern based methods. We show that our method performs on par with state-of-the-art pattern based methods, and maintains a reasonable level of accuracy even for instances — — acquired from infrequent patterns. This ability to acquire long tail instances is crucial for risk management and innovation, where an exhaustive database of high-level semantic relations like causation is of vital importance.</p><p>3 0.08992736 <a title="26-tfidf-3" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we present a method for unsupervised semantic role induction which we formalize as a graph partitioning problem. Argument instances of a verb are represented as vertices in a graph whose edge weights quantify their role-semantic similarity. Graph partitioning is realized with an algorithm that iteratively assigns vertices to clusters based on the cluster assignments of neighboring vertices. Our method is algorithmically and conceptually simple, especially with respect to how problem-specific knowledge is incorporated into the model. Experimental results on the CoNLL 2008 benchmark dataset demonstrate that our model is competitive with other unsupervised approaches in terms of F1 whilst attaining significantly higher cluster purity.</p><p>4 0.087058522 <a title="26-tfidf-4" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>Author: Marjorie Freedman ; Lance Ramshaw ; Elizabeth Boschee ; Ryan Gabbard ; Gary Kratkiewicz ; Nicolas Ward ; Ralph Weischedel</p><p>Abstract: We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.5 1 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1.</p><p>5 0.074993163 <a title="26-tfidf-5" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>6 0.072438642 <a title="26-tfidf-6" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>7 0.067255482 <a title="26-tfidf-7" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>8 0.064098001 <a title="26-tfidf-8" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>9 0.058761157 <a title="26-tfidf-9" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>10 0.056943957 <a title="26-tfidf-10" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>11 0.052659094 <a title="26-tfidf-11" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>12 0.04876684 <a title="26-tfidf-12" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>13 0.04712452 <a title="26-tfidf-13" href="./emnlp-2011-Linear_Text_Segmentation_Using_Affinity_Propagation.html">88 emnlp-2011-Linear Text Segmentation Using Affinity Propagation</a></p>
<p>14 0.044089217 <a title="26-tfidf-14" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>15 0.042496238 <a title="26-tfidf-15" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>16 0.041353349 <a title="26-tfidf-16" href="./emnlp-2011-Multilayer_Sequence_Labeling.html">96 emnlp-2011-Multilayer Sequence Labeling</a></p>
<p>17 0.039016042 <a title="26-tfidf-17" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>18 0.038664233 <a title="26-tfidf-18" href="./emnlp-2011-Discovering_Relations_between_Noun_Categories.html">40 emnlp-2011-Discovering Relations between Noun Categories</a></p>
<p>19 0.037654079 <a title="26-tfidf-19" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>20 0.036753953 <a title="26-tfidf-20" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.135), (1, -0.104), (2, -0.095), (3, 0.052), (4, -0.022), (5, -0.12), (6, 0.039), (7, -0.02), (8, -0.053), (9, 0.106), (10, 0.045), (11, -0.009), (12, -0.044), (13, -0.02), (14, -0.043), (15, 0.061), (16, -0.075), (17, -0.076), (18, -0.044), (19, 0.066), (20, 0.111), (21, -0.008), (22, -0.003), (23, 0.077), (24, 0.089), (25, 0.049), (26, -0.016), (27, 0.071), (28, -0.06), (29, 0.057), (30, -0.055), (31, 0.017), (32, -0.121), (33, 0.141), (34, 0.012), (35, -0.136), (36, -0.131), (37, 0.049), (38, -0.112), (39, -0.118), (40, 0.066), (41, -0.003), (42, -0.015), (43, 0.076), (44, 0.259), (45, -0.03), (46, 0.094), (47, 0.245), (48, -0.175), (49, -0.118)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97109705 <a title="26-lsi-1" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>Author: Zornitsa Kozareva ; Konstantin Voevodski ; Shanghua Teng</p><p>Abstract: Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels. Yet, nobody has explored the relationships between the instances themselves to enhance an initial set of class-instance pairs. We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network. We carry out a comparative study with state-of-the-art knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy.</p><p>2 0.52723289 <a title="26-lsi-2" href="./emnlp-2011-Relation_Acquisition_using_Word_Classes_and_Partial_Patterns.html">113 emnlp-2011-Relation Acquisition using Word Classes and Partial Patterns</a></p>
<p>Author: Stijn De Saeger ; Kentaro Torisawa ; Masaaki Tsuchida ; Jun'ichi Kazama ; Chikara Hashimoto ; Ichiro Yamada ; Jong Hoon Oh ; Istvan Varga ; Yulan Yan</p><p>Abstract: This paper proposes a semi-supervised relation acquisition method that does not rely on extraction patterns (e.g. “X causes Y” for causal relations) but instead learns a combination of indirect evidence for the target relation semantic word classes and partial patterns. This method can extract long tail instances of semantic relations like causality from rare and complex expressions in a large Japanese Web corpus in extreme cases, patterns that occur only once in the entire corpus. Such patterns are beyond the reach ofcurrent pattern based methods. We show that our method performs on par with state-of-the-art pattern based methods, and maintains a reasonable level of accuracy even for instances — — acquired from infrequent patterns. This ability to acquire long tail instances is crucial for risk management and innovation, where an exhaustive database of high-level semantic relations like causation is of vital importance.</p><p>3 0.46025211 <a title="26-lsi-3" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>Author: Marjorie Freedman ; Lance Ramshaw ; Elizabeth Boschee ; Ryan Gabbard ; Gary Kratkiewicz ; Nicolas Ward ; Ralph Weischedel</p><p>Abstract: We report on empirical results in extreme extraction. It is extreme in that (1) from receipt of the ontology specifying the target concepts and relations, development is limited to one week and that (2) relatively little training data is assumed. We are able to surpass human recall and achieve an F1 of 0.5 1 on a question-answering task with less than 50 hours of effort using a hybrid approach that mixes active learning, bootstrapping, and limited (5 hours) manual rule writing. We compare the performance of three systems: extraction with handwritten rules, bootstrapped extraction, and a combination. We show that while the recall of the handwritten rules surpasses that of the learned system, the learned system is able to improve the overall recall and F1.</p><p>4 0.43838882 <a title="26-lsi-4" href="./emnlp-2011-Harnessing_different_knowledge_sources_to_measure_semantic_relatedness_under_a_uniform_model.html">64 emnlp-2011-Harnessing different knowledge sources to measure semantic relatedness under a uniform model</a></p>
<p>Author: Ziqi Zhang ; Anna Lisa Gentile ; Fabio Ciravegna</p><p>Abstract: Measuring semantic relatedness between words or concepts is a crucial process to many Natural Language Processing tasks. Exiting methods exploit semantic evidence from a single knowledge source, and are predominantly evaluated only in the general domain. This paper introduces a method of harnessing different knowledge sources under a uniform model for measuring semantic relatedness between words or concepts. Using Wikipedia and WordNet as examples, and evaluated in both the general and biomedical domains, it successfully combines strengths from both knowledge sources and outperforms stateof-the-art on many datasets.</p><p>5 0.41104507 <a title="26-lsi-5" href="./emnlp-2011-Multilayer_Sequence_Labeling.html">96 emnlp-2011-Multilayer Sequence Labeling</a></p>
<p>Author: Ai Azuma ; Yuji Matsumoto</p><p>Abstract: In this paper, we describe a novel approach to cascaded learning and inference on sequences. We propose a weakly joint learning model on cascaded inference on sequences, called multilayer sequence labeling. In this model, inference on sequences is modeled as cascaded decision. However, the decision on a sequence labeling sequel to other decisions utilizes the features on the preceding results as marginalized by the probabilistic models on them. It is not novel itself, but our idea central to this paper is that the probabilistic models on succeeding labeling are viewed as indirectly depending on the probabilistic models on preceding analyses. We also propose two types of efficient dynamic programming which are required in the gradient-based optimization of an objective function. One of the dynamic programming algorithms resembles back propagation algorithm for mul- tilayer feed-forward neural networks. The other is a generalized version of the forwardbackward algorithm. We also report experiments of cascaded part-of-speech tagging and chunking of English sentences and show effectiveness of the proposed method.</p><p>6 0.39513147 <a title="26-lsi-6" href="./emnlp-2011-Linear_Text_Segmentation_Using_Affinity_Propagation.html">88 emnlp-2011-Linear Text Segmentation Using Affinity Propagation</a></p>
<p>7 0.37909526 <a title="26-lsi-7" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>8 0.36722147 <a title="26-lsi-8" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>9 0.36263365 <a title="26-lsi-9" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>10 0.34257564 <a title="26-lsi-10" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>11 0.33445999 <a title="26-lsi-11" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>12 0.31187186 <a title="26-lsi-12" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>13 0.29306105 <a title="26-lsi-13" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>14 0.27065659 <a title="26-lsi-14" href="./emnlp-2011-Structured_Sparsity_in_Structured_Prediction.html">129 emnlp-2011-Structured Sparsity in Structured Prediction</a></p>
<p>15 0.23780304 <a title="26-lsi-15" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>16 0.22397792 <a title="26-lsi-16" href="./emnlp-2011-A_Non-negative_Matrix_Factorization_Based_Approach_for_Active_Dual_Supervision_from_Document_and_Word_Labels.html">9 emnlp-2011-A Non-negative Matrix Factorization Based Approach for Active Dual Supervision from Document and Word Labels</a></p>
<p>17 0.21725771 <a title="26-lsi-17" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>18 0.20358054 <a title="26-lsi-18" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>19 0.18936048 <a title="26-lsi-19" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>20 0.18660522 <a title="26-lsi-20" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.45), (23, 0.089), (33, 0.01), (36, 0.037), (37, 0.015), (45, 0.055), (54, 0.012), (57, 0.038), (62, 0.026), (66, 0.037), (69, 0.013), (79, 0.033), (82, 0.02), (96, 0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75547814 <a title="26-lda-1" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>Author: Zornitsa Kozareva ; Konstantin Voevodski ; Shanghua Teng</p><p>Abstract: Class-instance label propagation algorithms have been successfully used to fuse information from multiple sources in order to enrich a set of unlabeled instances with class labels. Yet, nobody has explored the relationships between the instances themselves to enhance an initial set of class-instance pairs. We propose two graph-theoretic methods (centrality and regularization), which start with a small set of labeled class-instance pairs and use the instance-instance network to extend the class labels to all instances in the network. We carry out a comparative study with state-of-the-art knowledge harvesting algorithm and show that our approach can learn additional class labels while maintaining high accuracy. We conduct a comparative study between class-instance and instance-instance graphs used to propagate the class labels and show that the latter one achieves higher accuracy.</p><p>2 0.48696706 <a title="26-lda-2" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>Author: Puyang Xu ; Asela Gunawardana ; Sanjeev Khudanpur</p><p>Abstract: We propose an efficient way to train maximum entropy language models (MELM) and neural network language models (NNLM). The advantage of the proposed method comes from a more robust and efficient subsampling technique. The original multi-class language modeling problem is transformed into a set of binary problems where each binary classifier predicts whether or not a particular word will occur. We show that the binarized model is as powerful as the standard model and allows us to aggressively subsample negative training examples without sacrificing predictive performance. Empirical results show that we can train MELM and NNLM at 1% ∼ 5% of the strtaaninda MrdE complexity LwMith a no %los ∼s 5in% performance.</p><p>3 0.32173836 <a title="26-lda-3" href="./emnlp-2011-Large-Scale_Noun_Compound_Interpretation_Using_Bootstrapping_and_the_Web_as_a_Corpus.html">78 emnlp-2011-Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus</a></p>
<p>Author: Su Nam Kim ; Preslav Nakov</p><p>Abstract: Responding to the need for semantic lexical resources in natural language processing applications, we examine methods to acquire noun compounds (NCs), e.g., orange juice, together with suitable fine-grained semantic interpretations, e.g., squeezed from, which are directly usable as paraphrases. We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations. In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved accuracy due to stronger semantic restrictions.</p><p>4 0.28050804 <a title="26-lda-4" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>5 0.27813435 <a title="26-lda-5" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>Author: Burr Settles</p><p>Abstract: This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e.g., words) and instances (e.g., documents). We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort.</p><p>6 0.27548999 <a title="26-lda-6" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>7 0.27367502 <a title="26-lda-7" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>8 0.27265942 <a title="26-lda-8" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>9 0.27198988 <a title="26-lda-9" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>10 0.27093562 <a title="26-lda-10" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>11 0.27061298 <a title="26-lda-11" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>12 0.27031824 <a title="26-lda-12" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>13 0.27024996 <a title="26-lda-13" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>14 0.27022246 <a title="26-lda-14" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>15 0.2698468 <a title="26-lda-15" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>16 0.26981279 <a title="26-lda-16" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>17 0.26951596 <a title="26-lda-17" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>18 0.26929981 <a title="26-lda-18" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>19 0.26878542 <a title="26-lda-19" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>20 0.26852468 <a title="26-lda-20" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
