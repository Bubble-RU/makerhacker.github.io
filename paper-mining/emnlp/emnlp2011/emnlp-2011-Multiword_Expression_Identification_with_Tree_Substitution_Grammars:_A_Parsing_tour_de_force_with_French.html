<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-97" href="#">emnlp2011-97</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</h1>
<br/><p>Source: <a title="emnlp-2011-97-pdf" href="http://aclweb.org/anthology//D/D11/D11-1067.pdf">pdf</a></p><p>Author: Spence Green ; Marie-Catherine de Marneffe ; John Bauer ; Christopher D. Manning</p><p>Abstract: Multiword expressions (MWE), a known nuisance for both linguistics and NLP, blur the lines between syntax and semantics. Previous work on MWE identification has relied primarily on surface statistics, which perform poorly for longer MWEs and cannot model discontinuous expressions. To address these problems, we show that even the simplest parsing models can effectively identify MWEs of arbitrary length, and that Tree Substitution Grammars achieve the best results. Our experiments show a 36.4% F1 absolute improvement for French over an n-gram surface statistics baseline, currently the predominant method for MWE identification. Our models are useful for several NLP tasks in which MWE pre-grouping has improved accuracy. 1</p><p>Reference: <a title="emnlp-2011-97-reference" href="../emnlp2011_reference/emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French Spence Green*, Marie-Catherine de Marneffe†, John Bauer*, and Christopher D. [sent-1, score-0.214]
</p><p>2 Previous work on MWE identification has relied primarily on surface statistics, which perform poorly for longer MWEs and cannot model discontinuous expressions. [sent-4, score-0.101]
</p><p>3 To address these problems, we show that even the simplest parsing models can effectively identify MWEs of arbitrary length, and that Tree Substitution Grammars achieve the best results. [sent-5, score-0.051]
</p><p>4 , 2002) such as traffic light, or as “frequently occurring phrasal units which are subject to a certain level of semantic opaqueness, or noncompositionality” (Rayson et al. [sent-11, score-0.092]
</p><p>5 The French adverb terme ‘in the end’ can be modified by a small set of adjectives, and in turn some of these adjectives can be modified by an adverb such as très ‘very’. [sent-20, score-0.165]
</p><p>6 Merging known MWEs into single tokens has been shown to improve accuracy for a variety of NLP tasks: dependency parsing (Nivre and Nilsson, 2004), constituency parsing (Arun and Keller, 2005), sentence generation (Hogan et al. [sent-22, score-0.13]
</p><p>7 For unlabeled text, the best MWE identification methods, which are based on surface statistics (Pecina, 2010), suffer from sparsity induced by longer n-grams (Ramisch et al. [sent-25, score-0.072]
</p><p>8 Parsing models naturally accommodate discontinuous MWEs like phrasal verbs, and provide syntactic subcategorization. [sent-32, score-0.087]
</p><p>9 Consequently, our experimental results also provide a better baseline for parsing raw French text. [sent-97, score-0.051]
</p><p>10 For example, Gross (1986) shows that dictionaries contain about 1,500 single-word adverbs but that French con726 tains over 5,000 multiword adverbs. [sent-101, score-0.101]
</p><p>11 , noun trousse de secours ‘first-aid kit’ ; verb faire mainbasse [do hand-low] ‘seize’ ; adverb comme dans du beurre [as in butter] ‘easily’ ; adjective ‘à part entière’ ‘wholly’). [sent-104, score-0.179]
</p><p>12 POS tags for MWEs are given not only at the MWE level, but also internally: most tokens that constitute an MWE also have a POS tag. [sent-107, score-0.071]
</p><p>13 MWE Tagging We marked MWEs with a flat bracketing in which the phrasal label is the MWElevel POS tag with an “MW” prefix, and the preterminals are the internal POS tags for each terminal. [sent-115, score-0.166]
</p><p>14 , adverb la va vite ‘in ahurry’ : P D V ADV [at the goes quick]), and some words appear only as part of an MWE, such as insu in l’insu de ‘to the ignorance of’. [sent-119, score-0.173]
</p><p>15 Labels We augmented the basic FTB label set— which contains 14 POS tags and 19 phrasal tags—in two ways. [sent-120, score-0.101]
</p><p>16 labels shown in Table 3, resulting in 24 total phrasal categories. [sent-124, score-0.058]
</p><p>17 tag  Corrections Historically, the FTB suffered from annotation errors such as missing POS and phrasal tags (Arun and Keller, 2005). [sent-125, score-0.132]
</p><p>18 We restored the labels by first assigning each token its most frequent POS tag elsewhere in the treebank, and then assigning the most frequent MWE phrasal category for the resulting  POS sequence. [sent-128, score-0.089]
</p><p>19 However, they used a previous release of the treebank with 12,531 trees. [sent-130, score-0.05]
</p><p>20 3We automate tree manipulation with Tregex/Tsurgeon (Levy and Andrew, 2006). [sent-141, score-0.046]
</p><p>21 Syntactically regular MWEs were given internal structure, while all other MWEs were concatenated into single tokens. [sent-149, score-0.064]
</p><p>22 For example, nouns followed by adjectives, such as loi agraire ‘land law’ or Union monétaire et économique ‘monetary and economic  Union’ were considered syntactically regular. [sent-150, score-0.067]
</p><p>23 They are MWEs because the choice of adjective is arbitrary (loi agraire and not *loi agricole, similarly to ‘coal black’ but not * ‘crow black’ for example), but their syntactic structure is not intrinsic to MWEs. [sent-151, score-0.06]
</p><p>24 As a result, most results for French parsing are analogous to early results for Chinese, which used gold word segmentation, and Arabic, which used gold clitic segmentation. [sent-156, score-0.051]
</p><p>25 To set a baseline prior to grammar development, we trained the Stanford parser (Klein and Manning, 2003) with no grammar features, achieving 74. [sent-161, score-0.156]
</p><p>26 In the Lexicon-Grammar, MWEs are classified according to their global POS tags (noun, verb, adverb, adjective), and described in terms of the sequence of the POS tags of the words that constitute the MWE (e. [sent-167, score-0.086]
</p><p>27 , “N de N” garde d’enfant [guard of  child] ‘daycare’, pied de guerre [foot of war] ‘at the ready’). [sent-169, score-0.183]
</p><p>28 N P D N: impôt sur le revenu ‘income tax’, ministre de l’économie ‘finance minister’ 728 MWA Multiword adjectives appear with different POS sequences (3). [sent-190, score-0.107]
</p><p>29 Some items in (3b) allow internal variation: some adverbs or adjectives can be added to both examples given (àtrès haut risque, de toute dernière minute). [sent-192, score-0.168]
</p><p>30 Some MWVs containing a noun or an adjective allow the insertion of a modifier (e. [sent-198, score-0.067]
</p><p>31 When an adverb intervenes between the main verb and its complement, the FTB marks the two parts of the MWV discontinuously (e. [sent-201, score-0.068]
</p><p>32 The first is a manually-annotated grammar that we incorporate into the Stanfordparser. [sent-209, score-0.06]
</p><p>33 Manual annotation results in human interpretable grammars that can inform future treebank annotation decisions. [sent-210, score-0.083]
</p><p>34 Moreover, the grammar can be used as the base distribution in our second model, a Probabilistic Tree Substitution Grammar (PTSG) parser. [sent-211, score-0.06]
</p><p>35 PTSGs learn parameters for tree Feature —  tagPA markInf markPart markVN markCoord markDe markP markMWE  States  Tags  F1  ∆F1  4325 4509 4510 4511 5986 7361 7521 7523 7867  31 215 216 217 217 217 233 235 235  74. [sent-212, score-0.046]
</p><p>36 11  Table 4: Effects on grammar size and labeled F1 for each of the manual state splits (development set, sentences ≤  o4f0 wheo mrdsan). [sent-230, score-0.06]
</p><p>37 Most of the features are POS splits as many phrasal tag splits did not lead to any improvement. [sent-245, score-0.089]
</p><p>38 We opted to keep the COORD phrasal tag, and to capture parallelism in coordination, we mark COORD with the type of its child (NP, AP, VPinf, etc. [sent-249, score-0.058]
</p><p>39 markDe identifies the preposition de and its variants (du, des, d’) which is very frequent and appears in several different contexts. [sent-251, score-0.078]
</p><p>40 However, recall that in our representation, (5a) should receive a flat analysis as MWV, whereas (5b) should have a conventional analysis of the verb kicked and its two arguments. [sent-267, score-0.054]
</p><p>41 An alternate view of parsing is one in which new utterances are built from previously observed fragments. [sent-268, score-0.051]
</p><p>42 This is the original motivation for data oriented parsing (DOP) (Bod, 1992), in which “idiomaticity is the rule rather than the exception”  (Scha, 1990). [sent-269, score-0.051]
</p><p>43 If we have seen the collocation kicked the bucket several times before, we should store that whole fragment for later use. [sent-270, score-0.103]
</p><p>44 bS = 1 SNuufmficbieern to fst saitteisstic ss ∈ ∈o fS z Change in counts by setting m sites in S  Table 5: DP-TSG model notation. [sent-278, score-0.08]
</p><p>45 t ∈ Σ are terminals; e ∈ R are elementary trees;5 ♦t ∈ ΣV a rise a unique ;st eart ∈ symbol; alenmd θc,e ∈ rθe are parameters afo urn eiaquche tree fragment. [sent-282, score-0.082]
</p><p>46 And dP θTSG∈ ∈de θriv aaretion is created by successively applying the substitution operator to the leftmost frontier node (denoted by c+). [sent-283, score-0.067]
</p><p>47 In the supervised setting, DP-TSG grammar extraction reduces to a segmentation problem. [sent-285, score-0.06]
</p><p>48 We have a treebank T that we segment into the set R, a process that we model with Bayes’ rule: p(R | T) ∝ p(T | R) p(R) (1) Since the tree fragments completely specify each tree, p(T | R) is either 0 or 1, so all work is perftorerme,e pd( by |th Re prior over t 0he o set ,o sfo elementary trees. [sent-286, score-0.132]
</p><p>49 ) Base Distribution The base distribution P0 is the same maximum likelihood PCFG used in the Stan5We use the terms tree fragment and elementary tree interchangeably. [sent-297, score-0.177]
</p><p>50 730 NP+ PUNC-(1)  N+  N-  PUNC+(2)  “  Jacques  Chirac  “  Figure 1: Example of two conflicting sites of the same  =def  type. [sent-298, score-0.08]
</p><p>51 However, the two sites conflict since the probabilities of setting bs1 and bs2 both depend on counts for  the tree fragment rooted at NP. [sent-301, score-0.175]
</p><p>52 Consequently, sites (1) and (2) are not exchangeable: the probabilities of their assignments depend on the order in which they are sampled. [sent-302, score-0.08]
</p><p>53 We sample binary variables bs associated with each non-terminal node/site in the treebank. [sent-312, score-0.06]
</p><p>54 The key idea is to select a block of exchangeable sites S of the same type that do not conflict (Figure 1). [sent-313, score-0.109]
</p><p>55 Since the sites in S are exchangeable, we can set bS randomly so long as we know m, the number of sites with bs = 1. [sent-314, score-0.22]
</p><p>56 Decoding We compute the rule score of each tree fragment from a single grammar sample as follows:  θc,e=nc,e(nzc,)·( +z) α +cP α0(ce|c)  (5)  To make the grammar more robust, we also include all CFG rules in P0 with zero counts in n. [sent-322, score-0.215]
</p><p>57 Consider a unique tree fragment ei rooted at X with frontier γ, which is a sequence of terminals and non-terminals. [sent-326, score-0.124]
</p><p>58 We encode this fragment as an SCFG rule of the form [X  → γ  , X  →  i,Y1, . [sent-327, score-0.049]
</p><p>59 8 During decoding, the input is rewritten as a sequence of tree fragment (rule) indices {i, j,k, . [sent-334, score-0.095]
</p><p>60 , 2010) to recover the Viterbi derivation under a DP-TSG grammar sample. [sent-342, score-0.06]
</p><p>61 1 Standard Parsing Experiments We evaluate parsing accuracy of the Stanford and DP-TSG models (Table 6). [sent-344, score-0.051]
</p><p>62 , For the DP-TSG, we initialized all bs with fair coin tosses and ran for 400 iterations, after which likelihood stopped improving. [sent-346, score-0.06]
</p><p>63 415 Table 6: Standard parsing experiments (test set, sentences ≤ 40 words). [sent-356, score-0.051]
</p><p>64 In terms of parsing accuracy, the Berkeley parser exceeds both Stanford and DP-TSG. [sent-368, score-0.087]
</p><p>65 2 MWE Identification Experiments Table 7 lists overall and per-category MWE identifi-  cation results for the parsing models. [sent-381, score-0.051]
</p><p>66 Although DPTSG is less accurate as a general parsing model, it is more effective at identifying MWEs. [sent-382, score-0.051]
</p><p>67 A state-of-the-art, language independent package that implements this approach for higher order n-grams is mwet oolkit (Ramisch et al. [sent-384, score-0.127]
</p><p>68 Model mwet oolkit All PA-PCFG mwet oolkit Filter PA-PCFG+Features DP-TSG  F1 15. [sent-427, score-0.254]
</p><p>69 1  Table 8: MWE identification F1 of the best parsing model vs. [sent-432, score-0.091]
</p><p>70 the mwetoolkit baseline (test set, sentences ≤ 40 wvso. [sent-433, score-0.069]
</p><p>71 PwAe-tPoCoFlGk+iFtea btausreelsin ein c(tleusdte sse tth, ese grammar ≤fe 4a0tures in Table 4, which is the CFG from which the TSG is extracted. [sent-435, score-0.06]
</p><p>72 mwetoolkit and the CFG from the which the TSG is extracted. [sent-439, score-0.069]
</p><p>73 Some specific sequences like “[MWN [coup de N]]” are part of the grammar: such rules can indeed generate quite a few MWEs, e. [sent-445, score-0.078]
</p><p>74 , coup de pied ‘kick’, coup de coeur, coup de foudre ‘love at first sight’, coup de main ‘help’, coup d’état, coup de (note that only some of these MWEs are seen in the training  grâce  configuration details. [sent-447, score-0.981]
</p><p>75 MWN  NP  N  P  tour de  -  passe passe N  (a) Reference  -N  N  PP  tour PNP de  MWN N passe  -N -  passe  (b) DP-TSG Figure 2: Example of an MWE error for tour de passepasse ‘magic trick’. [sent-449, score-0.624]
</p><p>76 For MWV, “V de N” as in avoir de cesse ‘give no peace’, perdre de vue [lose from sight] ‘forget’, prendre de vitesse [take from speed] ‘outpace’), is learned. [sent-451, score-0.352]
</p><p>77 For prepositions, the grammar stores full subtrees of MWPs, but can also generalize the structure of very frequent sequences: “en N de” occurs in many multiword prepositions (e. [sent-452, score-0.161]
</p><p>78 , en compagnie de, en face de, en matière de, en terme de, en cours de, en faveur de, en raison de, en fonction de). [sent-454, score-0.584]
</p><p>79 The TSG grammar thus provides a categorization of MWEs consistent with the Lexicon-Grammar. [sent-455, score-0.06]
</p><p>80 It also learns verbal phrases which contain discontinuous MWVs  due to the insertion of an adverb or negation such as “[VN [MWV va] [MWADV d’ailleurs] [MWV bon train]]” [go indeed well], “[VN [MWV a] [ADV jamais] [MWV été question d’]]” [has never been in question]. [sent-456, score-0.131]
</p><p>81 Figure 2 shows an example where the parser only found a subpart of the MWN tour de passe-passe ‘magic trick’. [sent-460, score-0.172]
</p><p>82 The DP-TSG is not immune to false positives: in Le marché national, fait-on remarquer, est enfin en régression . [sent-466, score-0.073]
</p><p>83 ‘The national economy, people at last note, is going down’ the parser tags marché national as MWN. [sent-469, score-0.079]
</p><p>84 For an overview of ngram methods like mwet oo lkit, see Pecina (2010). [sent-479, score-0.081]
</p><p>85 733 MWN  NP  campNagnedPepromNotion campNagneP PNP (a) DP-TSG  de  N  promotion (b) Stanford NP  NP  emNp(loc)isDPàM-TWSAdoGDmVNicle empNlo(dis)StPaànPford NmPicle  Figure 4: Correct analyses by DP-TSG. [sent-480, score-0.078]
</p><p>86 Recent statistical parsing work on French has included Stochastic Tree Insertion Grammars (STIGs), which are related to TAGs, but with a restricted adjunction operation. [sent-489, score-0.078]
</p><p>87 4% F1 absolute improvement for MWE identification over a state-ofthe-art n-gram surface statistics package. [sent-495, score-0.072]
</p><p>88 While the DP-TSG, which  is a relatively new parsing model, still lags state-ofthe-art parsers in terms of overall labeling accuracy, we have shown that it is already very effective for other tasks like MWE identification. [sent-498, score-0.051]
</p><p>89 We plan to improve the DP-TSG by experimenting with alternate parsing objectives (Cohn et al. [sent-499, score-0.051]
</p><p>90 1 Notes on the Rising Factorial The rising factorial—also known as the ascending factorial or Pochhammer symbol—arises in the context of samples from a Dirichlet process (see Prop. [sent-507, score-0.1]
</p><p>91 For a positive integer n and a complex number x, the rising factorial is defined14 by  xn  xn = x(x + 1) . [sent-509, score-0.1]
</p><p>92 (x + n − 1) = Y(x + j 1) Yn  −  (7)  Yj=1  The rising factorial can be generalized to a complex number α with the gamma function:  xα=Γ(xΓ( +x) α)  (8)  14We adopt the notation of Knuth (1992). [sent-512, score-0.1]
</p><p>93 2  mwetoolkit Configuration  We configured mwetoolkit15 with the four standard lexical features: the maximum likelihood estimator, Dice’s coefficient, pointwise mutual information (PMI), and Student’s t-score. [sent-517, score-0.069]
</p><p>94 Although mwet oolkit defaults to a linear kernel, we achieved higher accuracy on the development set with an RBF kernel. [sent-527, score-0.127]
</p><p>95 15We re-implemented mwetoolkit in Java for compatibility with Weka and our pre-processing routines. [sent-538, score-0.069]
</p><p>96 Statistical French dependency parsing: treebank conversion and first results. [sent-595, score-0.05]
</p><p>97 Task-based evaluation of multiword expressions: a pilot study in statistical machine translation. [sent-601, score-0.101]
</p><p>98 mwe toolkit : a framework for multiword expression identification. [sent-733, score-0.645]
</p><p>99 Cross parser evaluation and tagset variation: a French treebank study. [sent-775, score-0.086]
</p><p>100 The use of shared forests in tree adjoining grammar parsing. [sent-797, score-0.137]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mwe', 0.544), ('mwes', 0.485), ('ftb', 0.289), ('mwv', 0.174), ('french', 0.163), ('tsg', 0.134), ('mwn', 0.121), ('multiword', 0.101), ('coup', 0.094), ('candito', 0.092), ('mwet', 0.081), ('crabb', 0.081), ('seddah', 0.08), ('sites', 0.08), ('de', 0.078), ('en', 0.073), ('mwetoolkit', 0.069), ('adverb', 0.068), ('mwc', 0.067), ('pos', 0.063), ('abeill', 0.063), ('grammar', 0.06), ('bs', 0.06), ('phrasal', 0.058), ('tour', 0.058), ('arun', 0.058), ('kicked', 0.054), ('mwadv', 0.054), ('passe', 0.054), ('ramisch', 0.052), ('factorial', 0.052), ('parsing', 0.051), ('treebank', 0.05), ('fragment', 0.049), ('rising', 0.048), ('tree', 0.046), ('oolkit', 0.046), ('ptsg', 0.046), ('tags', 0.043), ('avoir', 0.04), ('loi', 0.04), ('mwa', 0.04), ('mwns', 0.04), ('schluter', 0.04), ('stigs', 0.04), ('texte', 0.04), ('identification', 0.04), ('dp', 0.038), ('stanford', 0.038), ('substitution', 0.038), ('cfg', 0.038), ('adv', 0.036), ('elementary', 0.036), ('parser', 0.036), ('np', 0.035), ('evalb', 0.035), ('gross', 0.035), ('internal', 0.034), ('units', 0.034), ('insertion', 0.034), ('adjective', 0.033), ('grammars', 0.033), ('berkeley', 0.032), ('surface', 0.032), ('tag', 0.031), ('minute', 0.031), ('adjoining', 0.031), ('cohn', 0.031), ('concatenated', 0.03), ('adjectives', 0.029), ('pecina', 0.029), ('frontier', 0.029), ('exchangeable', 0.029), ('discontinuous', 0.029), ('liang', 0.028), ('tokens', 0.028), ('satisfaction', 0.027), ('pcfg', 0.027), ('adjunction', 0.027), ('agraire', 0.027), ('coord', 0.027), ('derni', 0.027), ('donner', 0.027), ('haut', 0.027), ('insu', 0.027), ('magic', 0.027), ('markde', 0.027), ('markmwe', 0.027), ('markp', 0.027), ('markpart', 0.027), ('markvn', 0.027), ('mettre', 0.027), ('mft', 0.027), ('mwcl', 0.027), ('mwd', 0.027), ('mwi', 0.027), ('mwp', 0.027), ('mwpro', 0.027), ('mwvs', 0.027), ('pied', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="97-tfidf-1" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>Author: Spence Green ; Marie-Catherine de Marneffe ; John Bauer ; Christopher D. Manning</p><p>Abstract: Multiword expressions (MWE), a known nuisance for both linguistics and NLP, blur the lines between syntax and semantics. Previous work on MWE identification has relied primarily on surface statistics, which perform poorly for longer MWEs and cannot model discontinuous expressions. To address these problems, we show that even the simplest parsing models can effectively identify MWEs of arbitrary length, and that Tree Substitution Grammars achieve the best results. Our experiments show a 36.4% F1 absolute improvement for French over an n-gram surface statistics baseline, currently the predominant method for MWE identification. Our models are useful for several NLP tasks in which MWE pre-grouping has improved accuracy. 1</p><p>2 0.54356664 <a title="97-tfidf-2" href="./emnlp-2011-Identification_of_Multi-word_Expressions_by_Combining_Multiple_Linguistic_Information_Sources.html">69 emnlp-2011-Identification of Multi-word Expressions by Combining Multiple Linguistic Information Sources</a></p>
<p>Author: Yulia Tsvetkov ; Shuly Wintner</p><p>Abstract: We propose an architecture for expressing various linguistically-motivated features that help identify multi-word expressions in natural language texts. The architecture combines various linguistically-motivated classification features in a Bayesian Network. We introduce novel ways for computing many of these features, and manually define linguistically-motivated interrelationships among them, which the Bayesian network models. Our methodology is almost entirely unsupervised and completely languageindependent; it relies on few language resources and is thus suitable for a large number of languages. Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic con- structions. We demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines.</p><p>3 0.11605214 <a title="97-tfidf-3" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>Author: Federico Sangati ; Willem Zuidema</p><p>Abstract: We present a novel approach to Data-Oriented Parsing (DOP). Like other DOP models, our parser utilizes syntactic fragments of arbitrary size from a treebank to analyze new sentences, but, crucially, it uses only those which are encountered at least twice. This criterion allows us to work with a relatively small but representative set of fragments, which can be employed as the symbolic backbone of several probabilistic generative models. For parsing we define a transform-backtransform approach that allows us to use standard PCFG technology, making our results easily replicable. According to standard Parseval metrics, our best model is on par with many state-ofthe-art parsers, while offering some complementary benefits: a simple generative probability model, and an explicit representation of the larger units of grammar.</p><p>4 0.10181699 <a title="97-tfidf-4" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>Author: Enrique Henestroza Anguiano ; Marie Candito</p><p>Abstract: This paper develops a framework for syntactic dependency parse correction. Dependencies in an input parse tree are revised by selecting, for a given dependent, the best governor from within a small set of candidates. We use a discriminative linear ranking model to select the best governor from a group of candidates for a dependent, and our model includes a rich feature set that encodes syntactic structure in the input parse tree. The parse correction framework is parser-agnostic, and can correct attachments using either a generic model or specialized models tailored to difficult attachment types like coordination and pp-attachment. Our experiments show that parse correction, combining a generic model with specialized models for difficult attachment types, can successfully improve the quality of predicted parse trees output by sev- eral representative state-of-the-art dependency parsers for French.</p><p>5 0.075440943 <a title="97-tfidf-5" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><p>6 0.074842617 <a title="97-tfidf-6" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>7 0.069024317 <a title="97-tfidf-7" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>8 0.06617827 <a title="97-tfidf-8" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>9 0.063677877 <a title="97-tfidf-9" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>10 0.061783437 <a title="97-tfidf-10" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>11 0.060559679 <a title="97-tfidf-11" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>12 0.06051958 <a title="97-tfidf-12" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>13 0.05913204 <a title="97-tfidf-13" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>14 0.056670055 <a title="97-tfidf-14" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>15 0.056006454 <a title="97-tfidf-15" href="./emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">15 emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>16 0.055703722 <a title="97-tfidf-16" href="./emnlp-2011-Latent_Vector_Weighting_for_Word_Meaning_in_Context.html">80 emnlp-2011-Latent Vector Weighting for Word Meaning in Context</a></p>
<p>17 0.054449391 <a title="97-tfidf-17" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>18 0.053195734 <a title="97-tfidf-18" href="./emnlp-2011-Statistical_Machine_Translation_with_Local_Language_Models.html">125 emnlp-2011-Statistical Machine Translation with Local Language Models</a></p>
<p>19 0.053180784 <a title="97-tfidf-19" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>20 0.047862049 <a title="97-tfidf-20" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.186), (1, 0.047), (2, -0.045), (3, 0.096), (4, -0.003), (5, 0.074), (6, -0.27), (7, 0.201), (8, -0.026), (9, -0.239), (10, 0.626), (11, -0.109), (12, -0.092), (13, -0.235), (14, 0.178), (15, -0.107), (16, 0.021), (17, 0.006), (18, -0.064), (19, 0.024), (20, -0.018), (21, 0.055), (22, -0.053), (23, -0.069), (24, 0.062), (25, -0.059), (26, -0.045), (27, -0.037), (28, -0.023), (29, 0.011), (30, 0.002), (31, -0.008), (32, 0.045), (33, 0.03), (34, 0.003), (35, 0.041), (36, 0.009), (37, -0.004), (38, -0.016), (39, 0.023), (40, 0.008), (41, -0.016), (42, 0.013), (43, 0.003), (44, 0.018), (45, 0.022), (46, -0.015), (47, 0.023), (48, -0.02), (49, -0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92289209 <a title="97-lsi-1" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>Author: Spence Green ; Marie-Catherine de Marneffe ; John Bauer ; Christopher D. Manning</p><p>Abstract: Multiword expressions (MWE), a known nuisance for both linguistics and NLP, blur the lines between syntax and semantics. Previous work on MWE identification has relied primarily on surface statistics, which perform poorly for longer MWEs and cannot model discontinuous expressions. To address these problems, we show that even the simplest parsing models can effectively identify MWEs of arbitrary length, and that Tree Substitution Grammars achieve the best results. Our experiments show a 36.4% F1 absolute improvement for French over an n-gram surface statistics baseline, currently the predominant method for MWE identification. Our models are useful for several NLP tasks in which MWE pre-grouping has improved accuracy. 1</p><p>2 0.89605117 <a title="97-lsi-2" href="./emnlp-2011-Identification_of_Multi-word_Expressions_by_Combining_Multiple_Linguistic_Information_Sources.html">69 emnlp-2011-Identification of Multi-word Expressions by Combining Multiple Linguistic Information Sources</a></p>
<p>Author: Yulia Tsvetkov ; Shuly Wintner</p><p>Abstract: We propose an architecture for expressing various linguistically-motivated features that help identify multi-word expressions in natural language texts. The architecture combines various linguistically-motivated classification features in a Bayesian Network. We introduce novel ways for computing many of these features, and manually define linguistically-motivated interrelationships among them, which the Bayesian network models. Our methodology is almost entirely unsupervised and completely languageindependent; it relies on few language resources and is thus suitable for a large number of languages. Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic con- structions. We demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines.</p><p>3 0.30307993 <a title="97-lsi-3" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>Author: Federico Sangati ; Willem Zuidema</p><p>Abstract: We present a novel approach to Data-Oriented Parsing (DOP). Like other DOP models, our parser utilizes syntactic fragments of arbitrary size from a treebank to analyze new sentences, but, crucially, it uses only those which are encountered at least twice. This criterion allows us to work with a relatively small but representative set of fragments, which can be employed as the symbolic backbone of several probabilistic generative models. For parsing we define a transform-backtransform approach that allows us to use standard PCFG technology, making our results easily replicable. According to standard Parseval metrics, our best model is on par with many state-ofthe-art parsers, while offering some complementary benefits: a simple generative probability model, and an explicit representation of the larger units of grammar.</p><p>4 0.21043237 <a title="97-lsi-4" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>Author: Emily M. Bender ; Dan Flickinger ; Stephan Oepen ; Yi Zhang</p><p>Abstract: In order to obtain a fine-grained evaluation of parser accuracy over naturally occurring text, we study 100 examples each of ten reasonably frequent linguistic phenomena, randomly selected from a parsed version of the English Wikipedia. We construct a corresponding set of gold-standard target dependencies for these 1000 sentences, operationalize mappings to these targets from seven state-of-theart parsers, and evaluate the parsers against this data to measure their level of success in identifying these dependencies.</p><p>5 0.20459819 <a title="97-lsi-5" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>Author: Enrique Henestroza Anguiano ; Marie Candito</p><p>Abstract: This paper develops a framework for syntactic dependency parse correction. Dependencies in an input parse tree are revised by selecting, for a given dependent, the best governor from within a small set of candidates. We use a discriminative linear ranking model to select the best governor from a group of candidates for a dependent, and our model includes a rich feature set that encodes syntactic structure in the input parse tree. The parse correction framework is parser-agnostic, and can correct attachments using either a generic model or specialized models tailored to difficult attachment types like coordination and pp-attachment. Our experiments show that parse correction, combining a generic model with specialized models for difficult attachment types, can successfully improve the quality of predicted parse trees output by sev- eral representative state-of-the-art dependency parsers for French.</p><p>6 0.18944062 <a title="97-lsi-6" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>7 0.17466809 <a title="97-lsi-7" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>8 0.17086862 <a title="97-lsi-8" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>9 0.16724962 <a title="97-lsi-9" href="./emnlp-2011-A_Cascaded_Classification_Approach_to_Semantic_Head_Recognition.html">2 emnlp-2011-A Cascaded Classification Approach to Semantic Head Recognition</a></p>
<p>10 0.15557079 <a title="97-lsi-10" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>11 0.15189727 <a title="97-lsi-11" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>12 0.15125431 <a title="97-lsi-12" href="./emnlp-2011-Unsupervised_Structure_Prediction_with_Non-Parallel_Multilingual_Guidance.html">146 emnlp-2011-Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance</a></p>
<p>13 0.1491634 <a title="97-lsi-13" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>14 0.14816411 <a title="97-lsi-14" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>15 0.14767715 <a title="97-lsi-15" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>16 0.13278361 <a title="97-lsi-16" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>17 0.12986633 <a title="97-lsi-17" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>18 0.12955807 <a title="97-lsi-18" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>19 0.12199517 <a title="97-lsi-19" href="./emnlp-2011-A_Simple_Word_Trigger_Method_for_Social_Tag_Suggestion.html">11 emnlp-2011-A Simple Word Trigger Method for Social Tag Suggestion</a></p>
<p>20 0.12062434 <a title="97-lsi-20" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(15, 0.016), (23, 0.074), (25, 0.306), (36, 0.041), (37, 0.018), (45, 0.053), (53, 0.028), (54, 0.03), (57, 0.017), (62, 0.027), (64, 0.027), (66, 0.056), (69, 0.013), (79, 0.049), (82, 0.021), (87, 0.011), (90, 0.05), (96, 0.038), (98, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73605007 <a title="97-lda-1" href="./emnlp-2011-Multiword_Expression_Identification_with_Tree_Substitution_Grammars%3A_A_Parsing_tour_de_force_with_French.html">97 emnlp-2011-Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French</a></p>
<p>Author: Spence Green ; Marie-Catherine de Marneffe ; John Bauer ; Christopher D. Manning</p><p>Abstract: Multiword expressions (MWE), a known nuisance for both linguistics and NLP, blur the lines between syntax and semantics. Previous work on MWE identification has relied primarily on surface statistics, which perform poorly for longer MWEs and cannot model discontinuous expressions. To address these problems, we show that even the simplest parsing models can effectively identify MWEs of arbitrary length, and that Tree Substitution Grammars achieve the best results. Our experiments show a 36.4% F1 absolute improvement for French over an n-gram surface statistics baseline, currently the predominant method for MWE identification. Our models are useful for several NLP tasks in which MWE pre-grouping has improved accuracy. 1</p><p>2 0.40864193 <a title="97-lda-2" href="./emnlp-2011-Accurate_Parsing_with_Compact_Tree-Substitution_Grammars%3A_Double-DOP.html">16 emnlp-2011-Accurate Parsing with Compact Tree-Substitution Grammars: Double-DOP</a></p>
<p>Author: Federico Sangati ; Willem Zuidema</p><p>Abstract: We present a novel approach to Data-Oriented Parsing (DOP). Like other DOP models, our parser utilizes syntactic fragments of arbitrary size from a treebank to analyze new sentences, but, crucially, it uses only those which are encountered at least twice. This criterion allows us to work with a relatively small but representative set of fragments, which can be employed as the symbolic backbone of several probabilistic generative models. For parsing we define a transform-backtransform approach that allows us to use standard PCFG technology, making our results easily replicable. According to standard Parseval metrics, our best model is on par with many state-ofthe-art parsers, while offering some complementary benefits: a simple generative probability model, and an explicit representation of the larger units of grammar.</p><p>3 0.39408785 <a title="97-lda-3" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>Author: Amit Dubey ; Frank Keller ; Patrick Sturt</p><p>Abstract: This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chunker with a co-reference classifier. Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure. This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort. We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.</p><p>4 0.39393103 <a title="97-lda-4" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>Author: Edward Grefenstette ; Mehrnoosh Sadrzadeh</p><p>Abstract: Modelling compositional meaning for sentences using empirical distributional methods has been a challenge for computational linguists. We implement the abstract categorical model of Coecke et al. (2010) using data from the BNC and evaluate it. The implementation is based on unsupervised learning of matrices for relational words and applying them to the vectors of their arguments. The evaluation is based on the word disambiguation task developed by Mitchell and Lapata (2008) for intransitive sentences, and on a similar new experiment designed for transitive sentences. Our model matches the results of its competitors . in the first experiment, and betters them in the second. The general improvement in results with increase in syntactic complexity showcases the compositional power of our model.</p><p>5 0.39346382 <a title="97-lda-5" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>Author: Christos Christodoulopoulos ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: In this paper we present a fully unsupervised syntactic class induction system formulated as a Bayesian multinomial mixture model, where each word type is constrained to belong to a single class. By using a mixture model rather than a sequence model (e.g., HMM), we are able to easily add multiple kinds of features, including those at both the type level (morphology features) and token level (context and alignment features, the latter from parallel corpora). Using only context features, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested.</p><p>6 0.38986912 <a title="97-lda-6" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>7 0.38931799 <a title="97-lda-7" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>8 0.38653407 <a title="97-lda-8" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>9 0.38382211 <a title="97-lda-9" href="./emnlp-2011-Universal_Morphological_Analysis_using_Structured_Nearest_Neighbor_Prediction.html">140 emnlp-2011-Universal Morphological Analysis using Structured Nearest Neighbor Prediction</a></p>
<p>10 0.38321459 <a title="97-lda-10" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>11 0.38132465 <a title="97-lda-11" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>12 0.37989652 <a title="97-lda-12" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>13 0.37894282 <a title="97-lda-13" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>14 0.37709463 <a title="97-lda-14" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>15 0.37706763 <a title="97-lda-15" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>16 0.37650925 <a title="97-lda-16" href="./emnlp-2011-A_novel_dependency-to-string_model_for_statistical_machine_translation.html">15 emnlp-2011-A novel dependency-to-string model for statistical machine translation</a></p>
<p>17 0.3764827 <a title="97-lda-17" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>18 0.37646276 <a title="97-lda-18" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>19 0.37610212 <a title="97-lda-19" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>20 0.37603241 <a title="97-lda-20" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
