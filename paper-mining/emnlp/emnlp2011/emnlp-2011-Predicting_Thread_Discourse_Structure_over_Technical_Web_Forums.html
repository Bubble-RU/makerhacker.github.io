<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-105" href="#">emnlp2011-105</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</h1>
<br/><p>Source: <a title="emnlp-2011-105-pdf" href="http://aclweb.org/anthology//D/D11/D11-1002.pdf">pdf</a></p><p>Author: Li Wang ; Marco Lui ; Su Nam Kim ; Joakim Nivre ; Timothy Baldwin</p><p>Abstract: Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</p><p>Reference: <a title="emnlp-2011-105-reference" href="../emnlp2011_reference/emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 net  Abstract Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. [sent-12, score-0.741]
</p><p>2 However, the complex structure of forum threads can make it difficult for users to extract relevant information. [sent-13, score-0.385]
</p><p>3 The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. [sent-14, score-0.533]
</p><p>4 In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. [sent-15, score-0.461]
</p><p>5 Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. [sent-16, score-0.895]
</p><p>6 We also experiment with “in  situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads. [sent-18, score-0.312]
</p><p>7 This research aims at enhancing information access and support sharing, by mining the discourse structure of troubleshooting-oriented web user forum threads. [sent-28, score-0.386]
</p><p>8 Previous research has shown that simple thread structure information (e. [sent-29, score-0.563]
</p><p>9 In doing so, we hope to be able to perform richer visualisation of thread structure (e. [sent-34, score-0.563]
</p><p>10 highlighting the key posts which appear to have led to a successful resolution to a problem), and more finegrained weighting of posts in threads for search purposes. [sent-36, score-0.965]
</p><p>11 To illustrate the task, we use an example thread, made up of 5 posts from 4 distinct participants, from  the CNET forum dataset of Kim et al. [sent-37, score-0.491]
</p><p>12 The discourse structure of the thread is modelled as a rooted directed acyclic graph ProceEed i n bgusr ogfh t,h Sec 2o0t1la1n Cd,o UnfKer, Jeunlcye o 2n7– E3m1,p 2ir0ic1a1l. [sent-39, score-0.704]
</p><p>13 c e2th0o1d1s A ins Nocaitautiroanl L foarn Cguoamgpeu Ptartoicoensaslin Lgin,g puaigsetisc 1s3–25,  0+Question-QØuestion  Figure 1: A snippeted and annotated CNET thread (DAG) with a dialogue act label associated with each  edge of the graph. [sent-41, score-0.915]
</p><p>14 In this example, UserA initiates the thread with a question (dialogue act = QuestionQuestion) in the first post, by asking how to create an interactive input box on a webpage. [sent-42, score-0.684]
</p><p>15 UserA responds to UserC to confirm the details of the solution (dialogue act = Answer-Confirmation), and at the same time, adds extra information to his/her original question (dialogue act = Question-Add); i. [sent-44, score-0.304]
</p><p>16 , this one post has two distinct dependency links associated with it. [sent-46, score-0.292]
</p><p>17 To predict thread discourse structure of this type, we jointly classify the links and dialogue acts between posts, experimenting with a variety of supervised classification methods, namely dependency parsing and linear-chain conditional random fields. [sent-48, score-1.229]
</p><p>18 (2010b) who first proposed the task of thread discourse analysis, but only carried out experiments on post linking and post dialogue act classification as separate tasks. [sent-50, score-1.551]
</p><p>19 , 2010b), whereby a novel post-level dialogue act set was proposed, and used as the basis for annotation of a set of threads taken from CNET. [sent-54, score-0.584]
</p><p>20 In the original work, we proposed a set of novel features, which we applied to the separate tasks ofpost link classification and dialogue act classification. [sent-55, score-0.601]
</p><p>21 We later applied the same basic methodology to dialogue act classification over one-on-one live chat data with provided message dependencies (Kim et al. [sent-56, score-0.472]
</p><p>22 In both cases, however,  we tackled only a single task, either link classification (optionally given dialogue act tags) or dialogue act classification, but never the two together. [sent-58, score-0.986]
</p><p>23 In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. [sent-59, score-1.511]
</p><p>24 link classification) and dialogue act tagging have been studied largely as independent tasks. [sent-62, score-0.514]
</p><p>25 Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al. [sent-63, score-0.557]
</p><p>26 , 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. [sent-64, score-0.53]
</p><p>27 For a more complete review of models for discourse disentanglement and dialogue act tagging, see Kim et al. [sent-83, score-0.553]
</p><p>28 (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. [sent-87, score-0.472]
</p><p>29 In their approach, the predictions of a multi-layer perceptron classifier on dialogue act boundaries were fed into an n-gram language model, which was used for the joint segmentation and classification of dialogue acts. [sent-88, score-0.808]
</p><p>30 These results suggest that the thread structural representation used in this research, which includes both linking struc15 ture and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. [sent-104, score-0.938]
</p><p>31 Another related research area is post-level classification, such as general post quality classification (Weimer et al. [sent-105, score-0.291]
</p><p>32 , 2008; Lui and Baldwin, 2009) that thread discourse structure can significantly improve the classification accuracy for postlevel tasks. [sent-112, score-0.791]
</p><p>33 question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge  bases for Community Question Answering (cQA) services such as Yahoo! [sent-115, score-0.657]
</p><p>34 Our thread discourse structure prediction task includes joint classification of post roles (i. [sent-121, score-1.03]
</p><p>35 3  Task Description and Data Set  The main task performed in this research is joint classification of inter-post links (Link) and dialogue acts (DA) within forum threads. [sent-124, score-0.575]
</p><p>36 In this, we assume that a post can only link to an earlier post (or a virtual root node), and that dialogue acts are labels on edges. [sent-125, score-0.848]
</p><p>37 if a post both confirms the validity of an answer and adds extra information to the  original question (as happens in Post4 in Figure 1). [sent-128, score-0.295]
</p><p>38 We experiment with two different approaches to joint classification: (1) a linear-chain CRF over combined Link/DA post labels; and (2) a dependency parser. [sent-129, score-0.293]
</p><p>39 in a 4-post thread, posts 2 and 3 may be dependent on post 1, and post 4 dependent on post 2; around 2% of the threads in our dataset contain nonprojective dependencies. [sent-133, score-1.194]
</p><p>40 multi-headedness: it is possible for a given post to have multiple heads, including the possibility of multiple dependency links to the same post  (e. [sent-134, score-0.496]
</p><p>41 adding extra information to a question [Question-Add] as well as retracting information from the original question [QuestionCorrection]); around 6% of the threads in our dataset contain multi-headed dependencies. [sent-136, score-0.285]
</p><p>42 in instances where a user hijacks a thread to ask their own unrelated question, or submit an unrelated spam post; around 2% of the threads in our dataset contain disconnected sub-graphs. [sent-139, score-0.903]
</p><p>43 In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. [sent-144, score-1.33]
</p><p>44 This is intended to simulate the more realistic setting of incrementally crawling/updating thread data, but needing to predict discourse structure for partial 16 threads. [sent-145, score-0.73]
</p><p>45 (2010b),1 which contains 1332 annotated posts spanning 315 threads, collected from the Operating System, Software, Hardware and Web Development sub-forums of cnet. [sent-149, score-0.383]
</p><p>46 2 Each post is labelled with one or more links (including the possibility of null-links, where the post doesn’t link to any other post), and each link is labelled with a dialogue act. [sent-150, score-1.035]
</p><p>47 The dialogue act set is made up of 5 super-categories: Question, Answer, Resolution (confirmation of the question being resolved), Reproduction (external confirmation of a proposed so-  lution working) and Other. [sent-151, score-0.457]
</p><p>48 For full details of the dialogue act tagset, see Kim et al. [sent-157, score-0.385]
</p><p>49 Unless otherwise noted, evaluation is over the combined link and dialogue act tag, including the combination of superclass and subclass for the Question and Answer dialogue acts. [sent-162, score-0.798]
</p><p>50 1 Learners  To predict thread discourse structure, we use a structured classification approach based on the findings of Kim et al. [sent-167, score-0.758]
</p><p>51 In our case, our tokens are thread posts, with much greater scope for feature engineering than single words, and techni-  cal challenges in scaling the underlying implementations to handle potentially much larger feature sets. [sent-183, score-0.53]
</p><p>52 In presenting the thread data to MaltParser, we represent the nulllink from the initial post of each thread, as well as any disconnected posts, as the root. [sent-190, score-0.83]
</p><p>53 To the best of our knowledge, there is no past work on using dependency parsing to learn thread  discourse structure. [sent-191, score-0.764]
</p><p>54 In our choice of parsing algorithm, we are also unable to detect posts with multiple heads, but can potentially detect disconnected sub-graphs. [sent-194, score-0.518]
</p><p>55 2  Features  The features used in our classifiers are as follows: Structural Features:  Initiator a binary feature indicating whether the current post’s author is the thread initiator. [sent-196, score-0.552]
</p><p>56 Position the relative position of the current post, as a ratio over the total number of posts in the thread. [sent-197, score-0.383]
</p><p>57 the UserProf features for the standalone linking task take the form of the link labels (and not dialogue act labels) of the posts by the relevant author in the training data. [sent-207, score-0.919]
</p><p>58 Table 1 shows the feature representation of the third post in a thread FeatureValueExplanation Initiator1. [sent-208, score-0.734]
</p><p>59 0 most similar to post 1 UserProf counts for posts of each class from the same author in the training data  x  Table 1: The feature presentation of the third post in a thread of length 8 of length 8. [sent-215, score-1.368]
</p><p>60 5  Classification Methodology  All our experiments were carried out based on stratified 10-fold cross-validation, stratifying at the thread level to ensure that all posts from a given thread occur in a single fold. [sent-219, score-1.443]
</p><p>61 the proportion of  threads where all posts have been correctly classified4), where space allows. [sent-222, score-0.582]
</p><p>62 Initial experiments showed it is hard for learners to discover which posts have multiple links, largely due to the sparsity of multi-headed posts (which account for less than 5% of the total posts). [sent-225, score-0.794]
</p><p>63 html # pars ingalg  4Classification accuracy = F-score at the thread-level, each thread is assigned a single label of correct or incorrect. [sent-228, score-0.53]
</p><p>64 Even if the same number of labels is predicted for both Link and DA, if multiple tags are predicted in both cases, we are left with the problem of determining which link label to combine with which dialogue act label. [sent-233, score-0.514]
</p><p>65 2 In Situ Thread Classification One of the biggest challenges in classifying the discourse structure of a forum thread is that threads evolve over time, as new posts are posted. [sent-237, score-1.425]
</p><p>66 In order to capture this phenomenon, and compare the accuracy of different models when applied to partial thread data (artificially cutting off a thread at post N) vs. [sent-238, score-1.29]
</p><p>67 5 This is done in the following way: classification over the first two posts only ([1, 2]), the first four posts ([1, 4]), the first six  posts ([1, 6]), the first eight posts ([1, 8]), and all posts ([all]). [sent-240, score-2.002]
</p><p>68 In each case, we limit the test data only, meaning that the only variable in play is the extent of thread context used to learn the thread discourse structure for the given set of posts. [sent-241, score-1.234]
</p><p>69 5In practice, completeness is defined at a given point in time, when the crawl was done, and it is highly likely that some of the “complete” threads had extra posts after the crawl. [sent-245, score-0.608]
</p><p>70 A stronger baseline is to classify all first posts as 0+QuestionQuestion and all subsequent posts as 1+Answeranswer, which achieves a post-level F-score of 0. [sent-258, score-0.766]
</p><p>71 2  Post Position-based Result Breakdown  One question in thread discourse structure classification is how accurate the predictions are at different depths in a thread (e. [sent-357, score-1.391]
</p><p>72 A breakdown of results across posts at different positions is presented in Figure 2. [sent-361, score-0.426]
</p><p>73 The overall trend for both CRFSGD and MaltParser is that it becomes increasingly hard to classify posts as we continue through a thread, due to greater variability in discourse structure and greater sparsity in the data. [sent-362, score-0.557]
</p><p>74 However, it is interesting to note that the results for CRFSGD actually improve from posts 7 and 8 ([7, 8]) to posts 9 and onwards ([9, ]). [sent-363, score-0.766]
</p><p>75 To further investigate this effect, we performed class decomposition over the joint classification predictions, and performed a similar breakdown of posts 20  Figure 2: Breakdown of post-level Link-DA results for CRFSGD and MaltParser based on post position Decomposed Link  Fµ0. [sent-364, score-0.777]
</p><p>76 It is clear that the anomaly for CRFSGD comes from the DA component, due to there being greater predictability in the dialogue for final posts in a thread (users tend to confirm a successful resolution of the problem, or report on successful external reproduction of the solution). [sent-367, score-1.174]
</p><p>77 MaltParser seems less adept at identifying that a post is at the end of a thread, and predicting the dialogue act accordingly. [sent-368, score-0.617]
</p><p>78 The higher results for Link are to be expected, as throughout the thread, most posts tend to link locally. [sent-370, score-0.512]
</p><p>79 l7]38  Table 5: Post-level Link-DA F-score for CRFSGD/MaltParser, based on in situ classification over sub-threads  of  different lengths (indicated in the rows), broken down over different post extents (indicated in the columns)  6. [sent-381, score-0.408]
</p><p>80 2, we simulate in situ thread discourse structure prediction by removing differing numbers ofposts from the tail ofthe thread, and applying the trained model over the resultant sub-threads. [sent-383, score-0.8]
</p><p>81 we cannot return results for posts 1–4 ([1, 4]) when the size of the test thread was only two posts ([1, 2]). [sent-387, score-1.296]
</p><p>82 From this, we can conclude that it is possible to apply our method to partial threads without any reduction in effectiveness relative to classification over complete threads. [sent-389, score-0.312]
</p><p>83 To gain a deeper insight into the behaviour of the feature, we binned the posts according to the number oftimes the author had posted in the training data, evaluated based on a 21  BHiinghus2c24or. [sent-393, score-0.43]
</p><p>84 742∼ 14 8134505793 3097957 Table 6: Statistics for the 4 groups of users user score (uscore) for each user:  uscorei=Pjn=in1ispi,j where ni is the number of posts by user i, and spi,j is the number of posts by user ithat occur as training instances for other posts by the same author. [sent-395, score-1.428]
</p><p>85 uscore reflects the average training–test post ratio per user in cross-validation. [sent-396, score-0.346]
</p><p>86 Note that as we include all posts from a given thread in a single partition during crossvalidation, it is possible for an author to have posted 4 times, but have a uscore of 0 due to those posts all occurring in the same thread. [sent-397, score-1.382]
</p><p>87 The users were binned into 4 groups of roughly equal post size. [sent-399, score-0.274]
</p><p>88 The detailed statistics are shown in Table 6, noting that the high-frequency bin (“High”) contains posts from a single user. [sent-400, score-0.383]
</p><p>89 We  present the post-level micro-averaged F-score for posts in each bin based on CRFSGD, with and without user profile features, in Figure 4. [sent-401, score-0.5]
</p><p>90 In fact, a statistically significant difference was observed only for users with no posts in the training data (uscore = 0), where the F-score jumped over 10% in absolute terms for both the Low and Very Low bins. [sent-403, score-0.428]
</p><p>91 Our explanation for this effect is that the  Post-level joinUts celra Gsrosuipfication  Figure 4: results for users binned by uscore, based on CRFSGD with and without UserProf features)  lack of user profile information is predictive of the sort of posts we can expect from a user (i. [sent-404, score-0.648]
</p><p>92 7  Conclusions and Future Work  In this research, we explored the joint classification of web user forum thread discourse structure, in the form of a rooted directed acyclic graph over posts, with edges labelled with dialogue acts. [sent-407, score-1.303]
</p><p>93 Three classification approaches were proposed: separately predicting Link and DA labels, and composing them into a joint class; predicting a combined Link-DA class using a structured classifier; and applying dependency parsing to the problem. [sent-408, score-0.296]
</p><p>94 We also examined the task of in situ classification of dialogue structure, in the form of predicting the discourse structure of partial threads, as contrasted with classifying only complete threads. [sent-410, score-0.703]
</p><p>95 We found that there was no drop in F-score over different subextents of the thread in classifying partial threads,  despite the relative lack of thread context. [sent-411, score-1.117]
</p><p>96 Our user profile features were found to be the pick of our features, but counter-intuitively, to bene22 fit users with no posts in the training data, rather than prolific users. [sent-414, score-0.545]
</p><p>97 Acknowledgements The authors wish to acknowledge the development efforts of Johan Hall in configuring MaltParser to handle numeric features, and be able to parse thread structures. [sent-416, score-0.53]
</p><p>98 It pays to be picky: An evaluation of thread retrieval in online forums. [sent-482, score-0.58]
</p><p>99 Automatic instant messaging dialogue using statistical models and dialogue acts. [sent-507, score-0.549]
</p><p>100 Towards internet-age pharmacovigilance: Extracting adverse drug reactions from user posts in healthrelated social networks. [sent-531, score-0.461]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('thread', 0.53), ('posts', 0.383), ('crfsgd', 0.34), ('dialogue', 0.261), ('post', 0.204), ('threads', 0.199), ('maltparser', 0.161), ('discourse', 0.141), ('link', 0.129), ('act', 0.124), ('userprof', 0.117), ('forum', 0.108), ('forums', 0.1), ('disconnected', 0.096), ('situ', 0.096), ('classification', 0.087), ('lui', 0.085), ('user', 0.078), ('da', 0.074), ('kim', 0.071), ('uscore', 0.064), ('ros', 0.055), ('dependency', 0.054), ('acts', 0.05), ('initiator', 0.046), ('seo', 0.046), ('users', 0.045), ('breakdown', 0.043), ('carolyn', 0.042), ('confirmation', 0.042), ('weimer', 0.042), ('predictions', 0.04), ('parsing', 0.039), ('profile', 0.039), ('labelled', 0.037), ('joakim', 0.037), ('cong', 0.037), ('dummy', 0.036), ('joint', 0.035), ('answer', 0.035), ('baldwin', 0.034), ('nivre', 0.034), ('links', 0.034), ('crf', 0.033), ('newsgroup', 0.033), ('structure', 0.033), ('cnet', 0.032), ('fscores', 0.032), ('initiation', 0.032), ('shriberg', 0.032), ('signifies', 0.032), ('wanas', 0.032), ('wolf', 0.032), ('classifying', 0.031), ('question', 0.03), ('timothy', 0.03), ('wang', 0.029), ('composition', 0.029), ('predicting', 0.028), ('learners', 0.028), ('carvalho', 0.027), ('messaging', 0.027), ('disentanglement', 0.027), ('online', 0.027), ('web', 0.026), ('extra', 0.026), ('email', 0.026), ('mcdonald', 0.026), ('partial', 0.026), ('class', 0.025), ('binned', 0.025), ('nam', 0.025), ('pages', 0.024), ('chan', 0.024), ('retrieval', 0.023), ('elsner', 0.023), ('subclass', 0.023), ('proceedings', 0.022), ('author', 0.022), ('decomposed', 0.022), ('classifications', 0.022), ('lemon', 0.022), ('labelling', 0.022), ('conference', 0.021), ('answeranswer', 0.021), ('conor', 0.021), ('decomp', 0.021), ('elsas', 0.021), ('excount', 0.021), ('extents', 0.021), ('fortuna', 0.021), ('hayes', 0.021), ('interactively', 0.021), ('mcaarltflpsagrsder', 0.021), ('muthmann', 0.021), ('postsim', 0.021), ('qucount', 0.021), ('questionquestion', 0.021), ('schuth', 0.021), ('sondhi', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="105-tfidf-1" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>Author: Li Wang ; Marco Lui ; Su Nam Kim ; Joakim Nivre ; Timothy Baldwin</p><p>Abstract: Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</p><p>2 0.20379986 <a title="105-tfidf-2" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>3 0.14252537 <a title="105-tfidf-3" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>Author: Yuanbin Wu ; Qi Zhang ; Xuanjing Huang ; Lide Wu</p><p>Abstract: Based on analysis of on-line review corpus we observe that most sentences have complicated opinion structures and they cannot be well represented by existing methods, such as frame-based and feature-based ones. In this work, we propose a novel graph-based representation for sentence level sentiment. An integer linear programming-based structural learning method is then introduced to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach.</p><p>4 0.1159291 <a title="105-tfidf-4" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>Author: Alan Ritter ; Colin Cherry ; William B. Dolan</p><p>Abstract: Ottawa, Ontario, K1A 0R6 Co l . Cherry@ nrc-cnrc . gc . ca in Redmond, WA 98052 bi l ldol @mi cro so ft . com large corpus of status-response pairs found on Twitter to create a system that responds to Twitter status We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.</p><p>5 0.094828919 <a title="105-tfidf-5" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>Author: Lanjun Zhou ; Binyang Li ; Wei Gao ; Zhongyu Wei ; Kam-Fai Wong</p><p>Abstract: Polarity classification of opinionated sentences with both positive and negative sentiments1 is a key challenge in sentiment analysis. This paper presents a novel unsupervised method for discovering intra-sentence level discourse relations for eliminating polarity ambiguities. Firstly, a discourse scheme with discourse constraints on polarity was defined empirically based on Rhetorical Structure Theory (RST). Then, a small set of cuephrase-based patterns were utilized to collect a large number of discourse instances which were later converted to semantic sequential representations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification.</p><p>6 0.068010211 <a title="105-tfidf-6" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>7 0.066966973 <a title="105-tfidf-7" href="./emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">94 emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>8 0.063678339 <a title="105-tfidf-8" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>9 0.058691613 <a title="105-tfidf-9" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>10 0.058300357 <a title="105-tfidf-10" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>11 0.055139851 <a title="105-tfidf-11" href="./emnlp-2011-Evaluating_Dependency_Parsing%3A_Robust_and_Heuristics-Free_Cross-Annotation_Evaluation.html">50 emnlp-2011-Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</a></p>
<p>12 0.054722164 <a title="105-tfidf-12" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>13 0.053866848 <a title="105-tfidf-13" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>14 0.053026736 <a title="105-tfidf-14" href="./emnlp-2011-Learning_the_Information_Status_of_Noun_Phrases_in_Spoken_Dialogues.html">84 emnlp-2011-Learning the Information Status of Noun Phrases in Spoken Dialogues</a></p>
<p>15 0.049791183 <a title="105-tfidf-15" href="./emnlp-2011-Generating_Subsequent_Reference_in_Shared_Visual_Scenes%3A_Computation_vs_Re-Use.html">62 emnlp-2011-Generating Subsequent Reference in Shared Visual Scenes: Computation vs Re-Use</a></p>
<p>16 0.049451955 <a title="105-tfidf-16" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>17 0.048920039 <a title="105-tfidf-17" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<p>18 0.047102679 <a title="105-tfidf-18" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>19 0.043046776 <a title="105-tfidf-19" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>20 0.040441655 <a title="105-tfidf-20" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.153), (1, -0.081), (2, 0.012), (3, 0.081), (4, 0.012), (5, -0.072), (6, 0.013), (7, 0.022), (8, -0.0), (9, -0.237), (10, -0.133), (11, -0.192), (12, -0.034), (13, 0.041), (14, -0.04), (15, 0.082), (16, 0.092), (17, -0.045), (18, 0.109), (19, -0.086), (20, 0.043), (21, 0.09), (22, -0.415), (23, -0.021), (24, 0.06), (25, 0.112), (26, -0.104), (27, -0.111), (28, -0.067), (29, -0.129), (30, 0.029), (31, 0.023), (32, -0.22), (33, 0.09), (34, -0.005), (35, -0.029), (36, 0.202), (37, 0.046), (38, -0.012), (39, -0.06), (40, -0.018), (41, -0.03), (42, -0.151), (43, -0.027), (44, -0.079), (45, 0.024), (46, -0.026), (47, -0.059), (48, -0.006), (49, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94434094 <a title="105-lsi-1" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>Author: Li Wang ; Marco Lui ; Su Nam Kim ; Joakim Nivre ; Timothy Baldwin</p><p>Abstract: Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</p><p>2 0.82479346 <a title="105-lsi-2" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>3 0.45723638 <a title="105-lsi-3" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>Author: Yuanbin Wu ; Qi Zhang ; Xuanjing Huang ; Lide Wu</p><p>Abstract: Based on analysis of on-line review corpus we observe that most sentences have complicated opinion structures and they cannot be well represented by existing methods, such as frame-based and feature-based ones. In this work, we propose a novel graph-based representation for sentence level sentiment. An integer linear programming-based structural learning method is then introduced to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach.</p><p>4 0.32361978 <a title="105-lsi-4" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<p>Author: Alan Ritter ; Colin Cherry ; William B. Dolan</p><p>Abstract: Ottawa, Ontario, K1A 0R6 Co l . Cherry@ nrc-cnrc . gc . ca in Redmond, WA 98052 bi l ldol @mi cro so ft . com large corpus of status-response pairs found on Twitter to create a system that responds to Twitter status We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.</p><p>5 0.31066242 <a title="105-lsi-5" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>Author: Lanjun Zhou ; Binyang Li ; Wei Gao ; Zhongyu Wei ; Kam-Fai Wong</p><p>Abstract: Polarity classification of opinionated sentences with both positive and negative sentiments1 is a key challenge in sentiment analysis. This paper presents a novel unsupervised method for discovering intra-sentence level discourse relations for eliminating polarity ambiguities. Firstly, a discourse scheme with discourse constraints on polarity was defined empirically based on Rhetorical Structure Theory (RST). Then, a small set of cuephrase-based patterns were utilized to collect a large number of discourse instances which were later converted to semantic sequential representations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification.</p><p>6 0.28157002 <a title="105-lsi-6" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>7 0.24157336 <a title="105-lsi-7" href="./emnlp-2011-Modelling_Discourse_Relations_for_Arabic.html">94 emnlp-2011-Modelling Discourse Relations for Arabic</a></p>
<p>8 0.23837806 <a title="105-lsi-8" href="./emnlp-2011-Learning_the_Information_Status_of_Noun_Phrases_in_Spoken_Dialogues.html">84 emnlp-2011-Learning the Information Status of Noun Phrases in Spoken Dialogues</a></p>
<p>9 0.20895876 <a title="105-lsi-9" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>10 0.19421275 <a title="105-lsi-10" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>11 0.19095746 <a title="105-lsi-11" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>12 0.18599138 <a title="105-lsi-12" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>13 0.18425199 <a title="105-lsi-13" href="./emnlp-2011-Generating_Subsequent_Reference_in_Shared_Visual_Scenes%3A_Computation_vs_Re-Use.html">62 emnlp-2011-Generating Subsequent Reference in Shared Visual Scenes: Computation vs Re-Use</a></p>
<p>14 0.16688953 <a title="105-lsi-14" href="./emnlp-2011-Watermarking_the_Outputs_of_Structured_Prediction_with_an_application_in_Statistical_Machine_Translation..html">148 emnlp-2011-Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.</a></p>
<p>15 0.16503513 <a title="105-lsi-15" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>16 0.16308889 <a title="105-lsi-16" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>17 0.16193499 <a title="105-lsi-17" href="./emnlp-2011-Discriminating_Gender_on_Twitter.html">41 emnlp-2011-Discriminating Gender on Twitter</a></p>
<p>18 0.1616191 <a title="105-lsi-18" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>19 0.16025071 <a title="105-lsi-19" href="./emnlp-2011-A_Weakly-supervised_Approach_to_Argumentative_Zoning_of_Scientific_Documents.html">12 emnlp-2011-A Weakly-supervised Approach to Argumentative Zoning of Scientific Documents</a></p>
<p>20 0.15896659 <a title="105-lsi-20" href="./emnlp-2011-Parse_Correction_with_Specialized_Models_for_Difficult_Attachment_Types.html">102 emnlp-2011-Parse Correction with Specialized Models for Difficult Attachment Types</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(17, 0.324), (23, 0.095), (36, 0.03), (37, 0.032), (45, 0.062), (53, 0.021), (54, 0.02), (57, 0.023), (62, 0.015), (64, 0.026), (66, 0.019), (79, 0.037), (82, 0.026), (87, 0.038), (90, 0.021), (96, 0.062), (98, 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74552613 <a title="105-lda-1" href="./emnlp-2011-Predicting_Thread_Discourse_Structure_over_Technical_Web_Forums.html">105 emnlp-2011-Predicting Thread Discourse Structure over Technical Web Forums</a></p>
<p>Author: Li Wang ; Marco Lui ; Su Nam Kim ; Joakim Nivre ; Timothy Baldwin</p><p>Abstract: Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</p><p>2 0.58775175 <a title="105-lda-2" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Daniel Jurafsky</p><p>Abstract: We present new training methods that aim to mitigate local optima and slow convergence in unsupervised training by using additional imperfect objectives. In its simplest form, lateen EM alternates between the two objectives of ordinary “soft” and “hard” expectation maximization (EM) algorithms. Switching objectives when stuck can help escape local optima. We find that applying a single such alternation already yields state-of-the-art results for English dependency grammar induction. More elaborate lateen strategies track both objectives, with each validating the moves proposed by the other. Disagreements can signal earlier opportunities to switch or terminate, saving iterations. De-emphasizing fixed points in these ways eliminates some guesswork from tuning EM. An evaluation against a suite of unsupervised dependency parsing tasks, for a vari- ety of languages, showed that lateen strategies significantly speed up training of both EM algorithms, and improve accuracy for hard EM.</p><p>3 0.43463773 <a title="105-lda-3" href="./emnlp-2011-Classifying_Sentences_as_Speech_Acts_in_Message_Board_Posts.html">27 emnlp-2011-Classifying Sentences as Speech Acts in Message Board Posts</a></p>
<p>Author: Ashequl Qadir ; Ellen Riloff</p><p>Abstract: This research studies the text genre of message board forums, which contain a mixture of expository sentences that present factual information and conversational sentences that include communicative acts between the writer and readers. Our goal is to create sentence classifiers that can identify whether a sentence contains a speech act, and can recognize sentences containing four different speech act classes: Commissives, Directives, Expressives, and Representatives. We conduct experiments using a wide variety of features, including lexical and syntactic features, speech act word lists from external resources, and domain-specific semantic class features. We evaluate our results on a collection of message board posts in the domain of veterinary medicine.</p><p>4 0.41039822 <a title="105-lda-4" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<p>Author: Zhenghua Li ; Min Zhang ; Wanxiang Che ; Ting Liu ; Wenliang Chen ; Haizhou Li</p><p>Abstract: Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.</p><p>5 0.40809497 <a title="105-lda-5" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>6 0.40008953 <a title="105-lda-6" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>7 0.39838982 <a title="105-lda-7" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>8 0.39655808 <a title="105-lda-8" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>9 0.39249191 <a title="105-lda-9" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>10 0.39167425 <a title="105-lda-10" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>11 0.3915447 <a title="105-lda-11" href="./emnlp-2011-Hypotheses_Selection_Criteria_in_a_Reranking_Framework_for_Spoken_Language_Understanding.html">68 emnlp-2011-Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding</a></p>
<p>12 0.39137134 <a title="105-lda-12" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>13 0.3911849 <a title="105-lda-13" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>14 0.39048213 <a title="105-lda-14" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>15 0.39004779 <a title="105-lda-15" href="./emnlp-2011-Third-order_Variational_Reranking_on_Packed-Shared_Dependency_Forests.html">134 emnlp-2011-Third-order Variational Reranking on Packed-Shared Dependency Forests</a></p>
<p>16 0.39004192 <a title="105-lda-16" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>17 0.38876069 <a title="105-lda-17" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>18 0.38815257 <a title="105-lda-18" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>19 0.38803217 <a title="105-lda-19" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>20 0.38620654 <a title="105-lda-20" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
