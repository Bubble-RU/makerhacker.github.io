<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-61" href="#">emnlp2011-61</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</h1>
<br/><p>Source: <a title="emnlp-2011-61-pdf" href="http://aclweb.org/anthology//D/D11/D11-1105.pdf">pdf</a></p><p>Author: Peng Li ; Yinglin Wang ; Wei Gao ; Jing Jiang</p><p>Abstract: In this paper, we propose a novel approach to automatic generation of aspect-oriented summaries from multiple documents. We first develop an event-aspect LDA model to cluster sentences into aspects. We then use extended LexRank algorithm to rank the sentences in each cluster. We use Integer Linear Programming for sentence selection. Key features of our method include automatic grouping of semantically related sentences and sentence ranking based on extension of random walk model. Also, we implement a new sentence compression algorithm which use dependency tree instead of parser tree. We compare our method with four baseline methods. Quantitative evaluation based on Rouge metric demonstrates the effectiveness and advantages of our method.</p><p>Reference: <a title="emnlp-2011-61-reference" href="../emnlp2011_reference/emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Key features of our method include automatic grouping of semantically related sentences and sentence ranking based on extension of random walk model. [sent-12, score-0.313]
</p><p>2 Also, we implement a new sentence compression algorithm which use dependency tree instead of parser tree. [sent-13, score-0.393]
</p><p>3 A summary should follow a readable structure and cover all the aspects users are interested in. [sent-19, score-0.293]
</p><p>4 For example, a summary about natural disasters should include aspects about what happened, when/where it happened, reasons, damages, rescue efforts, etc. [sent-20, score-0.293]
</p><p>5 Our goal is to automatically collect 1137 aspects and construct summaries from multiple documents. [sent-22, score-0.282]
</p><p>6 Furthermore, combined with search engines and question&answering; systems, we can better organize the summary content based on aspects to improve user experience. [sent-27, score-0.348]
</p><p>7 Despite its usefulness, the problem of modeling domain specific aspects for multi-document summarization has not been well studied. [sent-28, score-0.292]
</p><p>8 They introduced a general content distribution and several specific content distributions to discover the topic and aspects for a single document collection. [sent-31, score-0.47]
</p><p>9 However, the aspects may be shared not only across documents in a single collection, but also across documents in different  topic-related collections. [sent-32, score-0.22]
</p><p>10 Their model is conceptually inadequate for simultaneously summarizing multiple topic-related document collections. [sent-33, score-0.211]
</p><p>11 Furthermore, their sentence selection method based on KLdivergence cannot prevent redundancy across different aspects. [sent-34, score-0.366]
</p><p>12 We propose a novel extraction-based approach which consists of four main steps listed below: Sentence Clustering: Our goal in this step is to automatically identify the different aspects and cluster sentences into aspects (See Section 2). [sent-39, score-0.384]
</p><p>13 Sentence Compression: In this step, we aim to improve the linguistic quality of the summaries by simplifying the sentence expressions. [sent-44, score-0.279]
</p><p>14 Sentence Selection: Finally, we select one compressed version of the sentences from each aspect cluster. [sent-46, score-0.442]
</p><p>15 Our evaluation shows that our method obtains better ROUGE recall score compared with four baseline methods, and it also achieve reasonably high-quality aspect clusters in terms of purity. [sent-49, score-0.349]
</p><p>16 2  Sentence Clustering  In this step, our goal is to discover event aspects con-  tained in a document set and cluster sentences into aspects. [sent-50, score-0.476]
</p><p>17 The main difference between our event-aspect model and entity-aspect model is that we introduce an additional layer of event topics and the separation of general and specific aspects. [sent-53, score-0.213]
</p><p>18 Interesting aspects may include “what happened, when, where, perpetrators, reasons, who affected, damages and countermeasures,” etc2. [sent-59, score-0.203]
</p><p>19 We found that the entity-aspect model does not have enough capacity to cluster sentences into aspects (See Section 6). [sent-62, score-0.24]
</p><p>20 We also found that their one aspect per sentence assumption is not very strong in this scenario. [sent-64, score-0.407]
</p><p>21 Although a sentence may belong to a single general aspect, it still contains multiple specific aspect words like second sentence in Table 1. [sent-65, score-0.559]
</p><p>22 Therefore, We assume that each sentence belongs to both a general aspect and a specific aspect. [sent-66, score-0.45]
</p><p>23 Suppose that for a given event topic, there are in total C specific events for which we need to  simultaneously generate summaries. [sent-69, score-0.225]
</p><p>24 For each event topic, there is a background model ϕB that generates words commonly used in all documents, and there are AG general aspect models ϕga (1 ≤ ga ≤ AG), where AG is the number of general aspects. [sent-73, score-0.72]
</p><p>25 ≤Fo Ar each specific event in a topic, there are AS specific aspect 2http  . [sent-74, score-0.512]
</p><p>26 countermeasures  countermeasures Poli / GA are / S clo se /B t o / S ident i ce fying/ GA s omeone /B re spons ible / GA for / S the / S att ack /B . [sent-79, score-0.244]
</p><p>27 models ϕsa (1 ≤ sa ≤ AS), where AS is the number of specific aspects, Aand also there are D document models ϕd (1 ≤ d ≤ D), where D is the number of docume(n1ts i≤n th dis ≤ ≤co Dlle)c,t wionh. [sent-87, score-0.387]
</p><p>28 We also introduce an aspect distribution θ that controls how often a general or a specific aspect occurs in the collection, where θ is sampled from another Dirichlet prior with parameter α. [sent-91, score-0.639]
</p><p>29 There is also a multinomial distribution π that controls in each sentence how often we encounter a background word, a document word, or an aspect word. [sent-92, score-0.595]
</p><p>30 Let Sd denote the number of sentences in document d, Nd,s denote the number of words (after stop word removal) in sentence s of document d, and wd,s,n denote the n’th word in this sentence. [sent-94, score-0.435]
</p><p>31 We introduce hidden variables zgda,s and zsda,s to indicate that a sentence s of document d belongs to which general or specific aspects . [sent-95, score-0.404]
</p><p>32 We introduce hidden variables yd,s,n for each word to indicate whether a word is generated from the background model, the document model, or the aspect model. [sent-96, score-0.486]
</p><p>33 We also introduce hidden variables ld,s,n to indicate whether the n’th word in sentence s of document d is generated from the general aspect model. [sent-97, score-0.515]
</p><p>34 Note that the values of δ0, δ1, α1, α2, β 1139 SA: specific aspect word. [sent-100, score-0.341]
</p><p>35 With the assignment, sentences are naturally clustered into aspects, and words are labeled as either a background word, a document word, a general aspect word or a specific aspect word. [sent-107, score-0.916]
</p><p>36 3  Sentence Ranking  In this step, we want to order the clustered sentences so that the representative sentences can be ranked higher in each aspect. [sent-114, score-0.232]
</p><p>37 FDorra wea σch ∼ ∼ev Benett topic, there is a background model ϕB, and there are general aspect ga, where 1 ≤ ga ,≤ a (a) draw ϕB ∼ Dir(β) (b) draw ϕga ∼ Dir(β) 3. [sent-119, score-0.784]
</p><p>38 For each document collection, there are specific aspect sa, where 1 ≤ sa ≤ AS  nAdG t  (a) draw ϕsa ∼ Dir(β) 4. [sent-120, score-0.781]
</p><p>39 , D, (a) draw ϕd ∼ Dir(β) (b) for each sentence s = 1, . [sent-124, score-0.205]
</p><p>40 draw wd,s,n ∼ Multi(ϕB) ifyd,s,n = 1, wd,s,n ∼ ∼Mu Mltui(ltϕid()ϕ if yd,s,n = 2, wd,s,n ∼ if yd,s,n = 3 and ld,s,n =ti( 1 or wd,s,n ∼ if yd,s,n = 3 and ld,s,n = 0  Multi(ϕzds,as)  Multi(ϕzdg,as)  Figure 1: The document generation process. [sent-136, score-0.236]
</p><p>41 The LexRank score of a sentence gives the expected probability that a random walk will visit that sentence in the long run. [sent-138, score-0.253]
</p><p>42 More specifically, we scale sim(u, v) by the likelihood that the two sentences represent the same general aspect ga or specific aspect sa: ∑AG  sim′(u,v) = sim(u,v)[g∑a=1P(ga|u)P(ga|v)  ∑AS  +s∑a=1P(sa|u)P(sa|v)] where the value P(ga|u) and P(sa|u) can be computed by our event-aspect dm Pod(esl. [sent-143, score-0.902]
</p><p>43 We found that sentence ranking is better conducted before the compression because the precompressed sentences are more informative and the similarity function in LexRank can be better off with the complete information. [sent-145, score-0.527]
</p><p>44 4  Sentence Compression  It has been shown that sentence compression can improve linguistic quality of summaries (Zajic et al. [sent-146, score-0.563]
</p><p>45 Commonly used “Syntactic parse and trim” approach may produce poor compression results. [sent-149, score-0.284]
</p><p>46 Furthermore, some important temporal modifier, numeric modifier and clausal complement need to be retained because they reflect content aspects of the summary. [sent-151, score-0.235]
</p><p>47 Traverse the subtrees and generate all possible compression alternatives using the subtree root node, then keep the top two longest sub sentences. [sent-162, score-0.318]
</p><p>48 5  Sentence Selection  After sentence pruning, we prepare for the final event summary generation process. [sent-165, score-0.418]
</p><p>49 In this step, we select one compressed version of the sentence from each aspect cluster. [sent-166, score-0.502]
</p><p>50 To avoid redundancy between aspects, we use Integer Linear Programming to optimize a global objective function for sentence selection. [sent-167, score-0.217]
</p><p>51 Assume that there are in total K aspects in an event topic. [sent-171, score-0.272]
</p><p>52 For each aspect j, there are in total R ranked sentences. [sent-172, score-0.358]
</p><p>53 lis the ranked position of the sentence in this aspect cluster. [sent-175, score-0.467]
</p><p>54 Objective Function Top ranked sentences are the most relevant corresponding to the related aspects which we want to include in the final summary. [sent-176, score-0.253]
</p><p>55 ∑K  ∑Rj  min(∑∑l · Sjl) ∑j=1  ∑l=1  Exclusivity Constraints To prevent redundancy in each aspect, we just choose one sentence from each general or specific aspect cluster. [sent-178, score-0.618]
</p><p>56 If sentence-similarity sim(sjl , sj′l′) between sentence sjl and sj′l′ is above 0. [sent-186, score-0.315]
</p><p>57 6  Evaluation  In order to systematically evaluate our method, we want to check (1) whether the whole system is effec-  tive, which means to quantitatively evaluate summary quality, and (2) whether individual components like clustering and compression algorithms are useful. [sent-200, score-0.476]
</p><p>58 1 Data We use TAC2010 Summarization task data set for the summary content evaluation. [sent-202, score-0.204]
</p><p>59 Each specific event includes an event statement and 20 relevant newswire articles which have been divided into 2 sets: Document Set A and Document Set B. [sent-205, score-0.34]
</p><p>60 Assessors wrote model summaries for each event, so we can compare our automatic generated summaries with the model summaries. [sent-208, score-0.276]
</p><p>61 After labeling process, we run sentence ranking, compression and selection module to get final aspect-oriented summarizations. [sent-210, score-0.482]
</p><p>62 2 Quality of summary We use the ROUGE (Lin and Hovy, 2003) metric for measuring the summarization system performance. [sent-212, score-0.254]
</p><p>63 Baseline 1 In this baseline, we try to compare different sentence clustering algorithms in the multi-document summarization scenario. [sent-219, score-0.257]
</p><p>64 We use the same ranking, compression, and selection components to generate aspect-oriented summaries for comparison. [sent-224, score-0.227]
</p><p>65 Baseline 2 In this baseline, we compare our method with traditional ranking and selection summary generation framework (Erkan and Radev, 2004; Nenkova and Vanderwende, 2005) to show that our sentence clustering component is necessary in aspect-oriented summarization system. [sent-225, score-0.612]
</p><p>66 Also we want check whether sentence ranking combined with greedy based sentence selection can prevent redundancy effectively. [sent-226, score-0.614]
</p><p>67 We follow LexRank based sentence ranking combined with greedy sentence selection methods. [sent-227, score-0.446]
</p><p>68 One is to select the top ranked sentence simultaneously by removing 10 redundant neighbor sentences from the sentence similarity graph if the summary length is less then 100 words. [sent-231, score-0.628]
</p><p>69 The other is to select top ranked sentences as long as the redundancy score (similarity) between a candidate sentence and 5http : / / glaro s . [sent-237, score-0.359]
</p><p>70 edu / gkhome / clut o /  clut o  / overview  current summary is under 0. [sent-240, score-0.241]
</p><p>71 Baseline 3 In this baseline, we compare our ILP based sentence selection with KL-divergence based sentence selection. [sent-243, score-0.307]
</p><p>72 The KL-divergence formula we use is below,  KL(PS||QD) =∑wP(w)logQP((ww)) where P(S) is the empirical unigram distribution of the candidate summary S, and Q(D) is the unigram distribution of document collection D. [sent-244, score-0.299]
</p><p>73 After ranking sentences for each aspect, we add the sentence with the highest ranking score from each aspect sentence cluster as long as the KL-divergence between candidate and current summary does not decrease. [sent-247, score-0.931]
</p><p>74 To our knowledge, this  is the first work to directly compare Integer Linear Programming based sentence selection with KLdivergence based sentence selection in summarization generation framework. [sent-249, score-0.533]
</p><p>75 The KL-divergence based greedy sentence selection algorithm is similar to Baseline 3. [sent-253, score-0.252]
</p><p>76 For fair comparison, Baselines 1, 2, 3 and 4 use the same sentence compression algorithm and have the summary length no more then 100 words. [sent-254, score-0.542]
</p><p>77 For BL-2, we can see that traditional ranking plus greedy selec-  tion summary generation framework is not suitable 1143 for the aspect-oriented summarization task. [sent-258, score-0.425]
</p><p>78 More specifically, greedy-based sentence selection can not prevent redundancy effectively. [sent-259, score-0.366]
</p><p>79 BL-3 evaluation results showed that ILP-based sentence selection is better then KL-divergence selection in terms of preventing redundancy across different aspects. [sent-260, score-0.395]
</p><p>80 They use the same KL-divergence based sentence selection, but topic model they use are different, and also BL-3 has a sentence ranking process. [sent-262, score-0.368]
</p><p>81 It is expected because our event-aspect model can better find the aspects and also prove that our LexRank based sentence ranking combined with ILP-based sentence selection can prevent redundancy. [sent-264, score-0.596]
</p><p>82 Due to TAC2010 summarization community just compute ROUGE-2 and ROUGE-SU4 metrics for participants, our ROUGE-2 metric ranked 11 out of 23, ROUGE-SU4 metric ranked 12 out of 23. [sent-265, score-0.225]
</p><p>83 3  Quality of aspect-oriented sentence clusters  To judge the quality of the aspect-oriented sentence clusters, we ask the human judges to group the ground truth sentences based on the aspect relatedness in each event topic. [sent-276, score-0.808]
</p><p>84 In our experiments, we set the number of general aspect clusters AG is 5 and specific aspect clusters AS is 3. [sent-279, score-0.741]
</p><p>85 We can see from Table 4 that our generated aspect clusters can achieve reasonably good performance. [sent-280, score-0.349]
</p><p>86 4  Quality of sentence compression  To judge the quality of the dependency tree based sentence compression algorithm, we ask the human judges to choose 20 sentences from each event topic then score them. [sent-289, score-1.092]
</p><p>87 To evaluate the effectiveness of sentence compression component, we conduct the system without sentence compression component, then compare it with our system. [sent-293, score-0.786]
</p><p>88 In Table 3, we can see that sentence compression can improve the system performance. [sent-294, score-0.393]
</p><p>89 The way we separate words into stop words, background words, document words and aspect words bears similarity to that used in (Daum ´e III and Marcu, 2006; Haghighi and Vanderwende, 2009). [sent-301, score-0.547]
</p><p>90 The main difference between event-aspect model and entityaspect model is our model further consider aspect granularity and add a layer to model topic-related events. [sent-305, score-0.455]
</p><p>91 Filippova and Strube (2008) proposed a dependency tree based sentence compression algorithm. [sent-306, score-0.393]
</p><p>92 They used trained perceptron algorithm for ranking excerpts, whereas we give an extended LexRank with integer linear programming to optimize sentence selection for our aspect-oriented multi-document summarization. [sent-315, score-0.416]
</p><p>93 We also proposed dependency tree compression algorithm to prune sentence for improving linguistic quality of the summaries. [sent-320, score-0.425]
</p><p>94 Finally we use Integer Linear Programming Framework to select aspect relevant sentences. [sent-321, score-0.331]
</p><p>95 We found that our method gave overallbetter ROUGE scores than four baseline methods, and the new sentence clustering and compression algorithm are robust. [sent-323, score-0.436]
</p><p>96 Currently the sentence compression algorithm may generate meaningless subtrees. [sent-326, score-0.393]
</p><p>97 For example, we know that the “who-affected” aspect is related to person, and “when, where” are related to Time and Location. [sent-329, score-0.298]
</p><p>98 Modeling general and specific aspects of documents with a probabilistic topic model. [sent-338, score-0.29]
</p><p>99 Generating templates of entity summaries with an entityaspect model and pattern mining. [sent-386, score-0.253]
</p><p>100 Multicandidate reduction: Sentence compression as a tool for document summarization tasks. [sent-436, score-0.497]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lexrank', 0.389), ('aspect', 0.298), ('compression', 0.284), ('sa', 0.236), ('ga', 0.214), ('sjl', 0.206), ('summary', 0.149), ('aspects', 0.144), ('summaries', 0.138), ('event', 0.128), ('entityaspect', 0.115), ('hiersum', 0.115), ('sentence', 0.109), ('redundancy', 0.108), ('document', 0.108), ('multi', 0.107), ('summarization', 0.105), ('rouge', 0.103), ('countermeasures', 0.099), ('draw', 0.096), ('columbine', 0.092), ('selection', 0.089), ('dir', 0.086), ('sim', 0.086), ('ranking', 0.085), ('ag', 0.084), ('happened', 0.083), ('background', 0.08), ('vanderwende', 0.078), ('integer', 0.075), ('gillick', 0.071), ('sauper', 0.071), ('jumping', 0.069), ('summari', 0.069), ('topic', 0.065), ('redundant', 0.065), ('compressed', 0.062), ('stop', 0.061), ('ranked', 0.06), ('prevent', 0.06), ('damages', 0.059), ('attack', 0.059), ('paul', 0.058), ('programming', 0.058), ('sj', 0.056), ('content', 0.055), ('greedy', 0.054), ('simultaneously', 0.054), ('rj', 0.054), ('erkan', 0.054), ('clusters', 0.051), ('opinionated', 0.05), ('haghighi', 0.05), ('clause', 0.05), ('summarizing', 0.049), ('sentences', 0.049), ('cluster', 0.047), ('viewpoints', 0.047), ('abduction', 0.046), ('clut', 0.046), ('favre', 0.046), ('filippova', 0.046), ('freshman', 0.046), ('ident', 0.046), ('malaysia', 0.046), ('massacre', 0.046), ('yinglin', 0.046), ('zajic', 0.046), ('specific', 0.043), ('lda', 0.043), ('clustering', 0.043), ('collection', 0.042), ('layer', 0.042), ('articles', 0.041), ('clustered', 0.04), ('visiting', 0.039), ('benoit', 0.039), ('kldivergence', 0.039), ('parataxis', 0.039), ('shanghai', 0.039), ('documents', 0.038), ('clausal', 0.036), ('bus', 0.036), ('trim', 0.036), ('roxana', 0.036), ('chemudugunta', 0.036), ('damping', 0.036), ('nenkova', 0.036), ('extension', 0.035), ('walk', 0.035), ('representative', 0.034), ('root', 0.034), ('select', 0.033), ('locate', 0.033), ('mead', 0.033), ('purity', 0.033), ('judges', 0.032), ('generation', 0.032), ('quality', 0.032), ('land', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="61-tfidf-1" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>Author: Peng Li ; Yinglin Wang ; Wei Gao ; Jing Jiang</p><p>Abstract: In this paper, we propose a novel approach to automatic generation of aspect-oriented summaries from multiple documents. We first develop an event-aspect LDA model to cluster sentences into aspects. We then use extended LexRank algorithm to rank the sentences in each cluster. We use Integer Linear Programming for sentence selection. Key features of our method include automatic grouping of semantically related sentences and sentence ranking based on extension of random walk model. Also, we implement a new sentence compression algorithm which use dependency tree instead of parser tree. We compare our method with four baseline methods. Quantitative evaluation based on Rouge metric demonstrates the effectiveness and advantages of our method.</p><p>2 0.16832079 <a title="61-tfidf-2" href="./emnlp-2011-Domain-Assisted_Product_Aspect_Hierarchy_Generation%3A_Towards_Hierarchical_Organization_of_Unstructured_Consumer_Reviews.html">43 emnlp-2011-Domain-Assisted Product Aspect Hierarchy Generation: Towards Hierarchical Organization of Unstructured Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Kai Wang ; Tat-Seng Chua</p><p>Abstract: This paper presents a domain-assisted approach to organize various aspects of a product into a hierarchy by integrating domain knowledge (e.g., the product specifications), as well as consumer reviews. Based on the derived hierarchy, we generate a hierarchical organization of consumer reviews on various product aspects and aggregate consumer opinions on these aspects. With such organization, user can easily grasp the overview of consumer reviews. Furthermore, we apply the hierarchy to the task of implicit aspect identification which aims to infer implicit aspects of the reviews that do not explicitly express those aspects but actually comment on them. The experimental results on 11popular products in four domains demonstrate the effectiveness of our approach.</p><p>3 0.14683685 <a title="61-tfidf-3" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>Author: Rui Yan ; Liang Kong ; Congrui Huang ; Xiaojun Wan ; Xiaoming Li ; Yan Zhang</p><p>Abstract: We investigate an important and challenging problem in summary generation, i.e., Evolutionary Trans-Temporal Summarization (ETTS), which generates news timelines from massive data on the Internet. ETTS greatly facilitates fast news browsing and knowledge comprehension, and hence is a necessity. Given the collection oftime-stamped web documents related to the evolving news, ETTS aims to return news evolution along the timeline, consisting of individual but correlated summaries on each date. Existing summarization algorithms fail to utilize trans-temporal characteristics among these component summaries. We propose to model trans-temporal correlations among component summaries for timelines, using inter-date and intra-date sen- tence dependencies, and present a novel combination. We develop experimental systems to compare 5 rival algorithms on 6 instinctively different datasets which amount to 10251 documents. Evaluation results in ROUGE metrics indicate the effectiveness of the proposed approach based on trans-temporal information. 1</p><p>4 0.14311831 <a title="61-tfidf-4" href="./emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">130 emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>Author: Rui Yan ; Jian-Yun Nie ; Xiaoming Li</p><p>Abstract: Most traditional summarization methods treat their outputs as static and plain texts, which fail to capture user interests during summarization because the generated summaries are the same for different users. However, users have individual preferences on a particular source document collection and obviously a universal summary for all users might not always be satisfactory. Hence we investigate an important and challenging problem in summary generation, i.e., Interactive Personalized Summarization (IPS), which generates summaries in an interactive and personalized manner. Given the source documents, IPS captures user interests by enabling interactive clicks and incorporates personalization by modeling captured reader preference. We develop . experimental systems to compare 5 rival algorithms on 4 instinctively different datasets which amount to 5197 documents. Evaluation results in ROUGE metrics indicate the comparable performance between IPS and the best competing system but IPS produces summaries with much more user satisfaction according to evaluator ratings. Besides, low ROUGE consistency among these user preferred summaries indicates the existence of personalization.</p><p>5 0.13123788 <a title="61-tfidf-5" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>Author: Juri Ganitkevitch ; Chris Callison-Burch ; Courtney Napoles ; Benjamin Van Durme</p><p>Abstract: Previous work has shown that high quality phrasal paraphrases can be extracted from bilingual parallel corpora. However, it is not clear whether bitexts are an appropriate resource for extracting more sophisticated sentential paraphrases, which are more obviously learnable from monolingual parallel corpora. We extend bilingual paraphrase extraction to syntactic paraphrases and demonstrate its ability to learn a variety of general paraphrastic transformations, including passivization, dative shift, and topicalization. We discuss how our model can be adapted to many text generation tasks by augmenting its feature set, development data, and parameter estimation routine. We illustrate this adaptation by using our paraphrase model for the task of sentence compression and achieve results competitive with state-of-the-art compression systems.</p><p>6 0.093695149 <a title="61-tfidf-6" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>7 0.077507943 <a title="61-tfidf-7" href="./emnlp-2011-Bayesian_Checking_for_Topic_Models.html">21 emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>8 0.077035069 <a title="61-tfidf-8" href="./emnlp-2011-Optimizing_Semantic_Coherence_in_Topic_Models.html">101 emnlp-2011-Optimizing Semantic Coherence in Topic Models</a></p>
<p>9 0.074594989 <a title="61-tfidf-9" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>10 0.074538805 <a title="61-tfidf-10" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>11 0.069249019 <a title="61-tfidf-11" href="./emnlp-2011-Linguistic_Redundancy_in_Twitter.html">89 emnlp-2011-Linguistic Redundancy in Twitter</a></p>
<p>12 0.065723188 <a title="61-tfidf-12" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>13 0.062134154 <a title="61-tfidf-13" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>14 0.061375361 <a title="61-tfidf-14" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>15 0.060822748 <a title="61-tfidf-15" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>16 0.060741458 <a title="61-tfidf-16" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>17 0.056168947 <a title="61-tfidf-17" href="./emnlp-2011-Exploring_Supervised_LDA_Models_for_Assigning_Attributes_to_Adjective-Noun_Phrases.html">56 emnlp-2011-Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases</a></p>
<p>18 0.055678617 <a title="61-tfidf-18" href="./emnlp-2011-Probabilistic_models_of_similarity_in_syntactic_context.html">107 emnlp-2011-Probabilistic models of similarity in syntactic context</a></p>
<p>19 0.055019893 <a title="61-tfidf-19" href="./emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">36 emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>20 0.053847633 <a title="61-tfidf-20" href="./emnlp-2011-Joint_Models_for_Chinese_POS_Tagging_and_Dependency_Parsing.html">75 emnlp-2011-Joint Models for Chinese POS Tagging and Dependency Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.209), (1, -0.092), (2, -0.079), (3, -0.146), (4, -0.009), (5, 0.053), (6, 0.015), (7, -0.064), (8, 0.071), (9, 0.016), (10, -0.081), (11, -0.164), (12, -0.005), (13, 0.067), (14, 0.328), (15, -0.002), (16, -0.215), (17, 0.05), (18, 0.051), (19, 0.112), (20, 0.06), (21, 0.019), (22, 0.074), (23, -0.111), (24, -0.002), (25, -0.071), (26, 0.124), (27, -0.033), (28, 0.003), (29, -0.011), (30, -0.009), (31, -0.032), (32, -0.096), (33, -0.1), (34, 0.031), (35, -0.103), (36, 0.172), (37, -0.257), (38, 0.001), (39, 0.104), (40, -0.076), (41, -0.13), (42, 0.045), (43, 0.114), (44, 0.018), (45, -0.104), (46, -0.104), (47, 0.024), (48, -0.022), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96007735 <a title="61-lsi-1" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>Author: Peng Li ; Yinglin Wang ; Wei Gao ; Jing Jiang</p><p>Abstract: In this paper, we propose a novel approach to automatic generation of aspect-oriented summaries from multiple documents. We first develop an event-aspect LDA model to cluster sentences into aspects. We then use extended LexRank algorithm to rank the sentences in each cluster. We use Integer Linear Programming for sentence selection. Key features of our method include automatic grouping of semantically related sentences and sentence ranking based on extension of random walk model. Also, we implement a new sentence compression algorithm which use dependency tree instead of parser tree. We compare our method with four baseline methods. Quantitative evaluation based on Rouge metric demonstrates the effectiveness and advantages of our method.</p><p>2 0.77016467 <a title="61-lsi-2" href="./emnlp-2011-Domain-Assisted_Product_Aspect_Hierarchy_Generation%3A_Towards_Hierarchical_Organization_of_Unstructured_Consumer_Reviews.html">43 emnlp-2011-Domain-Assisted Product Aspect Hierarchy Generation: Towards Hierarchical Organization of Unstructured Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Kai Wang ; Tat-Seng Chua</p><p>Abstract: This paper presents a domain-assisted approach to organize various aspects of a product into a hierarchy by integrating domain knowledge (e.g., the product specifications), as well as consumer reviews. Based on the derived hierarchy, we generate a hierarchical organization of consumer reviews on various product aspects and aggregate consumer opinions on these aspects. With such organization, user can easily grasp the overview of consumer reviews. Furthermore, we apply the hierarchy to the task of implicit aspect identification which aims to infer implicit aspects of the reviews that do not explicitly express those aspects but actually comment on them. The experimental results on 11popular products in four domains demonstrate the effectiveness of our approach.</p><p>3 0.53968865 <a title="61-lsi-3" href="./emnlp-2011-Timeline_Generation_through_Evolutionary_Trans-Temporal_Summarization.html">135 emnlp-2011-Timeline Generation through Evolutionary Trans-Temporal Summarization</a></p>
<p>Author: Rui Yan ; Liang Kong ; Congrui Huang ; Xiaojun Wan ; Xiaoming Li ; Yan Zhang</p><p>Abstract: We investigate an important and challenging problem in summary generation, i.e., Evolutionary Trans-Temporal Summarization (ETTS), which generates news timelines from massive data on the Internet. ETTS greatly facilitates fast news browsing and knowledge comprehension, and hence is a necessity. Given the collection oftime-stamped web documents related to the evolving news, ETTS aims to return news evolution along the timeline, consisting of individual but correlated summaries on each date. Existing summarization algorithms fail to utilize trans-temporal characteristics among these component summaries. We propose to model trans-temporal correlations among component summaries for timelines, using inter-date and intra-date sen- tence dependencies, and present a novel combination. We develop experimental systems to compare 5 rival algorithms on 6 instinctively different datasets which amount to 10251 documents. Evaluation results in ROUGE metrics indicate the effectiveness of the proposed approach based on trans-temporal information. 1</p><p>4 0.47638136 <a title="61-lsi-4" href="./emnlp-2011-Summarize_What_You_Are_Interested_In%3A_An_Optimization_Framework_for_Interactive_Personalized_Summarization.html">130 emnlp-2011-Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization</a></p>
<p>Author: Rui Yan ; Jian-Yun Nie ; Xiaoming Li</p><p>Abstract: Most traditional summarization methods treat their outputs as static and plain texts, which fail to capture user interests during summarization because the generated summaries are the same for different users. However, users have individual preferences on a particular source document collection and obviously a universal summary for all users might not always be satisfactory. Hence we investigate an important and challenging problem in summary generation, i.e., Interactive Personalized Summarization (IPS), which generates summaries in an interactive and personalized manner. Given the source documents, IPS captures user interests by enabling interactive clicks and incorporates personalization by modeling captured reader preference. We develop . experimental systems to compare 5 rival algorithms on 4 instinctively different datasets which amount to 5197 documents. Evaluation results in ROUGE metrics indicate the comparable performance between IPS and the best competing system but IPS produces summaries with much more user satisfaction according to evaluator ratings. Besides, low ROUGE consistency among these user preferred summaries indicates the existence of personalization.</p><p>5 0.37811461 <a title="61-lsi-5" href="./emnlp-2011-Ranking_Human_and_Machine_Summarization_Systems.html">110 emnlp-2011-Ranking Human and Machine Summarization Systems</a></p>
<p>Author: Peter Rankel ; John Conroy ; Eric Slud ; Dianne O'Leary</p><p>Abstract: The Text Analysis Conference (TAC) ranks summarization systems by their average score over a collection of document sets. We investigate the statistical appropriateness of this score and propose an alternative that better distinguishes between human and machine evaluation systems.</p><p>6 0.32764286 <a title="61-lsi-6" href="./emnlp-2011-Learning_Local_Content_Shift_Detectors_from_Document-level_Information.html">82 emnlp-2011-Learning Local Content Shift Detectors from Document-level Information</a></p>
<p>7 0.28862473 <a title="61-lsi-7" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>8 0.2840735 <a title="61-lsi-8" href="./emnlp-2011-Unsupervised_Information_Extraction_with_Distributional_Prior_Knowledge.html">143 emnlp-2011-Unsupervised Information Extraction with Distributional Prior Knowledge</a></p>
<p>9 0.27885222 <a title="61-lsi-9" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>10 0.2733548 <a title="61-lsi-10" href="./emnlp-2011-Computing_Logical_Form_on_Regulatory_Texts.html">32 emnlp-2011-Computing Logical Form on Regulatory Texts</a></p>
<p>11 0.26012731 <a title="61-lsi-11" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>12 0.25471801 <a title="61-lsi-12" href="./emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</a></p>
<p>13 0.24342328 <a title="61-lsi-13" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>14 0.2433888 <a title="61-lsi-14" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>15 0.23343004 <a title="61-lsi-15" href="./emnlp-2011-A_Generate_and_Rank_Approach_to_Sentence_Paraphrasing.html">6 emnlp-2011-A Generate and Rank Approach to Sentence Paraphrasing</a></p>
<p>16 0.22645371 <a title="61-lsi-16" href="./emnlp-2011-Bayesian_Checking_for_Topic_Models.html">21 emnlp-2011-Bayesian Checking for Topic Models</a></p>
<p>17 0.21841647 <a title="61-lsi-17" href="./emnlp-2011-Watermarking_the_Outputs_of_Structured_Prediction_with_an_application_in_Statistical_Machine_Translation..html">148 emnlp-2011-Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.</a></p>
<p>18 0.21020414 <a title="61-lsi-18" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>19 0.20795575 <a title="61-lsi-19" href="./emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">36 emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>20 0.20737639 <a title="61-lsi-20" href="./emnlp-2011-Lexical_Co-occurrence%2C_Statistical_Significance%2C_and_Word_Association.html">86 emnlp-2011-Lexical Co-occurrence, Statistical Significance, and Word Association</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.276), (23, 0.16), (36, 0.016), (37, 0.017), (45, 0.101), (53, 0.022), (54, 0.028), (57, 0.036), (62, 0.022), (64, 0.03), (66, 0.018), (69, 0.031), (79, 0.036), (82, 0.017), (87, 0.021), (90, 0.015), (96, 0.047), (98, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78290331 <a title="61-lda-1" href="./emnlp-2011-Generating_Aspect-oriented_Multi-Document_Summarization_with_Event-aspect_model.html">61 emnlp-2011-Generating Aspect-oriented Multi-Document Summarization with Event-aspect model</a></p>
<p>Author: Peng Li ; Yinglin Wang ; Wei Gao ; Jing Jiang</p><p>Abstract: In this paper, we propose a novel approach to automatic generation of aspect-oriented summaries from multiple documents. We first develop an event-aspect LDA model to cluster sentences into aspects. We then use extended LexRank algorithm to rank the sentences in each cluster. We use Integer Linear Programming for sentence selection. Key features of our method include automatic grouping of semantically related sentences and sentence ranking based on extension of random walk model. Also, we implement a new sentence compression algorithm which use dependency tree instead of parser tree. We compare our method with four baseline methods. Quantitative evaluation based on Rouge metric demonstrates the effectiveness and advantages of our method.</p><p>2 0.5884167 <a title="61-lda-2" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>Author: Burr Settles</p><p>Abstract: This paper describes DUALIST, an active learning annotation paradigm which solicits and learns from labels on both features (e.g., words) and instances (e.g., documents). We present a novel semi-supervised training algorithm developed for this setting, which is (1) fast enough to support real-time interactive speeds, and (2) at least as accurate as preexisting methods for learning with mixed feature and instance labels. Human annotators in user studies were able to produce near-stateof-the-art classifiers—on several corpora in a variety of application domains—with only a few minutes of effort.</p><p>3 0.58578855 <a title="61-lda-3" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>4 0.58351463 <a title="61-lda-4" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>Author: Limin Yao ; Aria Haghighi ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity. Concretely, we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them. The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types. Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions. We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.</p><p>5 0.58146453 <a title="61-lda-5" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>Author: Alan Ritter ; Sam Clark ; Mausam ; Oren Etzioni</p><p>Abstract: People tweet more than 100 Million times daily, yielding a noisy, informal, but sometimes informative corpus of 140-character messages that mirrors the zeitgeist in an unprecedented manner. The performance of standard NLP tools is severely degraded on tweets. This paper addresses this issue by re-building the NLP pipeline beginning with part-of-speech tagging, through chunking, to named-entity recognition. Our novel T-NER system doubles F1 score compared with the Stanford NER system. T-NER leverages the redundancy inherent in tweets to achieve this performance, using LabeledLDA to exploit Freebase dictionaries as a source of distant supervision. LabeledLDA outperforms cotraining, increasing F1 by 25% over ten common entity types. Our NLP tools are available at: http : / / github .com/ aritt er /twitte r_nlp</p><p>6 0.57677579 <a title="61-lda-6" href="./emnlp-2011-Fast_Generation_of_Translation_Forest_for_Large-Scale_SMT_Discriminative_Training.html">58 emnlp-2011-Fast Generation of Translation Forest for Large-Scale SMT Discriminative Training</a></p>
<p>7 0.57575333 <a title="61-lda-7" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>8 0.57520431 <a title="61-lda-8" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>9 0.57473814 <a title="61-lda-9" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>10 0.57456344 <a title="61-lda-10" href="./emnlp-2011-A_Generate_and_Rank_Approach_to_Sentence_Paraphrasing.html">6 emnlp-2011-A Generate and Rank Approach to Sentence Paraphrasing</a></p>
<p>11 0.57353032 <a title="61-lda-11" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>12 0.57343411 <a title="61-lda-12" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>13 0.57208794 <a title="61-lda-13" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>14 0.57191885 <a title="61-lda-14" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>15 0.57008129 <a title="61-lda-15" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>16 0.56996185 <a title="61-lda-16" href="./emnlp-2011-Lateen_EM%3A_Unsupervised_Training_with_Multiple_Objectives%2C_Applied_to_Dependency_Grammar_Induction.html">79 emnlp-2011-Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction</a></p>
<p>17 0.56878352 <a title="61-lda-17" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>18 0.56839991 <a title="61-lda-18" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>19 0.56778187 <a title="61-lda-19" href="./emnlp-2011-Efficient_Subsampling_for_Training_Complex_Language_Models.html">46 emnlp-2011-Efficient Subsampling for Training Complex Language Models</a></p>
<p>20 0.56735176 <a title="61-lda-20" href="./emnlp-2011-Splitting_Noun_Compounds_via_Monolingual_and_Bilingual_Paraphrasing%3A_A_Study_on_Japanese_Katakana_Words.html">124 emnlp-2011-Splitting Noun Compounds via Monolingual and Bilingual Paraphrasing: A Study on Japanese Katakana Words</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
