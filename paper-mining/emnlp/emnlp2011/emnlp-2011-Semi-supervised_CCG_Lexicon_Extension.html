<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>121 emnlp-2011-Semi-supervised CCG Lexicon Extension</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-121" href="#">emnlp2011-121</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>121 emnlp-2011-Semi-supervised CCG Lexicon Extension</h1>
<br/><p>Source: <a title="emnlp-2011-121-pdf" href="http://aclweb.org/anthology//D/D11/D11-1115.pdf">pdf</a></p><p>Author: Emily Thomforde ; Mark Steedman</p><p>Abstract: This paper introduces Chart Inference (CI), an algorithm for deriving a CCG category for an unknown word from a partial parse chart. It is shown to be faster and more precise than a baseline brute-force method, and to achieve wider coverage than a rule-based system. In addition, we show the application of CI to a domain adaptation task for question words, which are largely missing in the Penn Treebank. When used in combination with self-training, CI increases the precision of the baseline StatCCG parser over subjectextraction questions by 50%. An error analysis shows that CI contributes to the increase by expanding the number of category types available to the parser, while self-training adjusts the counts.</p><p>Reference: <a title="emnlp-2011-121-reference" href="../emnlp2011_reference/emnlp-2011-Semi-supervised_CCG_Lexicon_Extension_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract This paper introduces Chart Inference (CI), an algorithm for deriving a CCG category for an unknown word from a partial parse chart. [sent-6, score-0.535]
</p><p>2 In addition, we show the application of CI to a domain adaptation task for question words, which are largely missing in the Penn Treebank. [sent-8, score-0.141]
</p><p>3 When used in combination with self-training, CI increases the precision of the baseline StatCCG parser over subjectextraction questions by 50%. [sent-9, score-0.122]
</p><p>4 An error analysis shows that CI contributes to the increase by expanding the number of category types available to the parser, while self-training adjusts the counts. [sent-10, score-0.424]
</p><p>5 1 Introduction  Unseen lexical items are a major cause of error in strongly lexicalised parsers such as those based on CCG (Clark and Curran, 2003; Hockenmaier, 2003). [sent-11, score-0.169]
</p><p>6 The problem is especially acute for less privileged languages, but even in the case of English, we are aware of many category types entirely missing from the Penn Treebank (Clark et al. [sent-12, score-0.566]
</p><p>7 In the case of totally unseen words, the standard method used by StatCCG (Hockenmaier, 2003) and many other treebank parsers is part-of-speech backoff, which is quite effective, affording an F-score of 93% over dependencies in §00 in the optimal configu9r3a%tio onv. [sent-14, score-0.057]
</p><p>8 e Irt d iesp deinfdficeunlcti etos say 0h0o win backing oaffl caoffnefcigtsdependency errors, but when we examine category match accuracy of the CCGBank-trained parser, we find that POS backoff has been used on 19. [sent-15, score-0.573]
</p><p>9 Of the 3320 items the parser labelled incorrectly, 675 (20. [sent-20, score-0.255]
</p><p>10 3%) are words that are missing from the lexicon entirely. [sent-21, score-0.315]
</p><p>11 1 In the best case, if we were able to learn lexical entries for those 675, we could transfer them to lexical treatment, which is 93. [sent-22, score-0.086]
</p><p>12 Under these conditions, we predict a further 63 1 word/category pairs to be tagged correctly by the parser, reducing the error rate from 7. [sent-25, score-0.053]
</p><p>13 d F fuortrh learning uwcionrgds p afrrsoimng unlabelled data would result in the recovery of interesting and important category types that are missing from our standard lexical resources. [sent-28, score-0.787]
</p><p>14 This paper introduces Chart Inference (CI) as a strategy for deducing a ranked set of possible categories for an unknown word using the partial chart formed from the known words that surround it. [sent-29, score-0.644]
</p><p>15 CCG (Steedman, 2000) is particularly suited to this problem, because category types can be inferred from the types of the surrounding constituents. [sent-30, score-0.378]
</p><p>16 CI is designed to take advantage of this property of generative CCGBank-trained parser, and of access to the full inventory of CCG combinators and non-  combinatory unary rules from the trained model. [sent-31, score-0.345]
</p><p>17 It is capable of learning category types that are completely missing from the lexicon, and is superior to existing learning systems in both precision and efficiency. [sent-32, score-0.511]
</p><p>18 The first compares three word-learning methods for their ability to converge to a toy target lexicon. [sent-34, score-0.19]
</p><p>19 The final experiment shows how Chart Induction can be effectively used in a domain adaptation task where a small number of category types are known to be missing from the lexicon. [sent-39, score-0.529]
</p><p>20 Since the learning portion of the algorithm is unsupervised, it has access to an essentially unlimited amount of unlabelled data, and it can afford to skip any sentence that does not conform to the one-unseen-word restriction. [sent-41, score-0.369]
</p><p>21 Attempting two or more OOL words at a time from one sentence would compound the search space and the error rate. [sent-42, score-0.053]
</p><p>22 We do not address the much harder problem of hypothesising missing categories for known words, which should presumably be handled by quite other methods, such as prior offline generalization of the lexicon. [sent-43, score-0.268]
</p><p>23 1 A Brute-force System One of the early lexical acquisition systems using Categorial Grammar was that of Watkinson and Manandhar (1999; 2000; 2001a; 2001b). [sent-45, score-0.043]
</p><p>24 This system attempted to simultaneously learn a CG lexicon and annotate unlabelled text with parse derivations. [sent-46, score-0.517]
</p><p>25 Using a stripped-down parser that only utilised the forward- and backward-application rules, they iteratively learned the lexicon from the feedback from online parsing. [sent-47, score-0.296]
</p><p>26 The system decided which parse was best based on the lexicon, and then decided which additions to the lexicon to make based on principles  of compression. [sent-48, score-0.385]
</p><p>27 After each change, the system reexamined the parses for previous sentences and updated them to reflect the new lexicon. [sent-49, score-0.07]
</p><p>28 They report fully convergent results on two toy corpora, but the parsing accuracy of the system trained on natural language data was far below the state of the art. [sent-50, score-0.308]
</p><p>29 However, they do show categorial grammar to be a promising basis for artificial language acquisition, because CCG makes learning the lexicon and learning the grammar the same task (Watkinson and Manandhar, 1999). [sent-51, score-0.397]
</p><p>30 They 1247 also showed that seeding the lexicon with examples of lexical items (closed-class words in their case), rather than just a list of possible category types, increased its chances of converging. [sent-52, score-0.66]
</p><p>31 This approach of automating the learning process differs from the previous language learning methods described, in that it doesn’t require the specification of any particular patterns, only knowledge ofthe grammar formalism. [sent-53, score-0.118]
</p><p>32 For this paper, as a baseline, we implement a generalised version of Watkinson and Manandhar’s mechanism for determining the category γ  of a single OOL word in a sentence where the rest of the words C1. [sent-54, score-0.449]
</p><p>33 This is equivalent to backing off to the set of all known category types; the learner returns the category that maximises the probability of the completed parse tree. [sent-61, score-0.806]
</p><p>34 We ignore the optimisation and compression steps of the original system. [sent-62, score-0.046]
</p><p>35 (2009a; 2009b) developed a learning system based on handwritten translation rules for deducing the category (X) of a single unknown word in a sentence consisting of a sequence of partiallyparsed constituents (A. [sent-65, score-0.662]
</p><p>36 Their system was based on a small inventory of inference rules that eliminated ambiguity in the ordering of arguments. [sent-68, score-0.24]
</p><p>37 For example, one of the Level 3 inference rules specifies the order of the arguments in the deduced category: A X B C → D ⇒ X = ((D\A)/C)/B WA iXth Bou Ct →this D i⇒nd Xuct =iv (e( D bi\aAs /tChe) Blearner would have to deal with the ambiguity of the options ((D/C)/B)\A and ((D/C)\A)/B at minimum. [sent-69, score-0.171]
</p><p>38 In  (a(dDdi/tiCo)n/ they Alim anitded (( (tDh/eCir l)e\Aarn)/eBr to CG-compatible parse structures and their constituent strings to length 4. [sent-70, score-0.048]
</p><p>39 Their argument is that only this minimal bias is needed to learn syntactic structures, including the fronting of polar interrogative auxiliaries and auxiliary word order (should > have > been), from a training set that did not explicitly contain full evidence for them. [sent-71, score-0.137]
</p><p>40 (2009b) used the full set of CCG combinators to generate learned categories, they employed a post-processing step to filter spurious categories by checking whether the category DERIVE([C1 . [sent-73, score-0.567]
</p><p>41 /\CAn]−a,1βd\AγC,)/1n∈γS,X  Figure 1: Generalised recursive rule-based algorithm, where [C1. [sent-79, score-0.049]
</p><p>42 Cn] is a sequence of categories, one of which is X, β is a result category, and γ is the (initially empty) category set. [sent-82, score-0.278]
</p><p>43 participated in a CG-only derivation (using application rules only). [sent-83, score-0.13]
</p><p>44 This is effective in limiting spurious derivations, but at the expense of reduced recall on those sentences for whose analysis CCG rules of composition etc. [sent-84, score-0.156]
</p><p>45 Their rules were effective for their toy-scale datasets, but for the purposes of this paper we have implemented a generalised version of the recursive algorithm for use in wide-coverage parsing. [sent-86, score-0.304]
</p><p>46 It takes a sequence of categorial constituents, all known except one (X),  and builds a candidate set of categories (γ) for the unknown word by recursively applying Yao’s Level 0 and Level 1inference rules. [sent-88, score-0.305]
</p><p>47 3 Chart Inference Both Watkinson’s and Yao’s experiments were fully convergent over toy datasets, but did not scale to realistic corpora. [sent-90, score-0.308]
</p><p>48 Watkinson attempted to learn from the LLL corpus (Kazakov et al. [sent-91, score-0.058]
</p><p>49 , 1998), but attributed the failure to the small amount of training data relative to the corpus, and the naive initial category set. [sent-92, score-0.363]
</p><p>50 Yao’s method was only ever designed as a proof-ofconcept to show how much of the language can be learned from partial evidence, and was not meant to be run in earnest in a real-world learning setting. [sent-93, score-0.121]
</p><p>51 For 1248 one, the rules do not cover the full set of partial parse conditions, and further to that, they do not allow for partial parses to be reanalysed within the learning framework. [sent-94, score-0.408]
</p><p>52 To that end, we have developed a learning algorithm that is capable of operating within the oneunknown-word-per-sentence learning setting established by the two baseline systems, that is able to  invent new category types, and that is able to take advantage of the full generality of CCG. [sent-95, score-0.465]
</p><p>53 This section shows that it performs as well as the previous two systems on a toy corpus, and the next section proves that it more readily scales to natural language domains. [sent-96, score-0.19]
</p><p>54 Mellish (1989) established a two-stage bidirectional chart parser for diagnosing errors in input text. [sent-97, score-0.409]
</p><p>55 His method relied heavily on heuristic rules, and the only evaluation he did was on number of cycles needed for each type of error, and number of solutions produced. [sent-98, score-0.118]
</p><p>56 His method was designed for use in producing parses where the original parser failed, dealing with omissions, insertions, and misspelled/unknown words. [sent-99, score-0.234]
</p><p>57 The only method used to rank the possible solutions was heuristic scores. [sent-100, score-0.042]
</p><p>58 Kato (1994) implemented a revised system that used a generalised top-down parser, rather than a chart, and was able to get the number of cycles to decrease. [sent-101, score-0.287]
</p><p>59 In both cases the evaluation was only on a toy corpus, and they did not evaluate on whether the systems diagnosed the errors correctly, or whether the solution they offered was accurate. [sent-102, score-0.279]
</p><p>60 They also had  to deal with cases where the error was ambiguous, for example, where an inserted word could be interpreted as a misspelling or vice-versa. [sent-103, score-0.096]
</p><p>61 Where Mellish uses the two-stage parsing process to complete malformed parses, we use it to diagnose unknown lexical items. [sent-104, score-0.183]
</p><p>62 In addition, we work on the scale of a full grammar and wide-coverage parser, using modern lexical corpora. [sent-105, score-0.158]
</p><p>63 Our method is a wrapper for a naive generative CCG parser StatOpenCCG (Christodoulopoulos, 2008), a statistical extension to OpenCCG (White and Baldridge, 2003). [sent-106, score-0.164]
</p><p>64 In the general case, the parser is trained on all the labelled data available in a particular learning setting, then the learner discovers new lexical items from unlabelled text. [sent-107, score-0.575]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('category', 0.278), ('ccg', 0.271), ('watkinson', 0.255), ('unlabelled', 0.237), ('yao', 0.201), ('toy', 0.19), ('chart', 0.19), ('lexicon', 0.174), ('generalised', 0.171), ('manandhar', 0.153), ('ci', 0.142), ('missing', 0.141), ('parser', 0.122), ('convergent', 0.118), ('deducing', 0.118), ('statccg', 0.118), ('thomforde', 0.102), ('combinator', 0.102), ('combinators', 0.102), ('backing', 0.102), ('mellish', 0.102), ('ool', 0.102), ('backoff', 0.096), ('steedman', 0.092), ('categorial', 0.089), ('unknown', 0.089), ('rules', 0.084), ('partial', 0.079), ('cycles', 0.076), ('hockenmaier', 0.076), ('items', 0.073), ('spurious', 0.072), ('parses', 0.07), ('inventory', 0.069), ('grammar', 0.067), ('categories', 0.067), ('ax', 0.066), ('known', 0.06), ('labelled', 0.06), ('attempted', 0.058), ('iv', 0.058), ('unseen', 0.057), ('decided', 0.056), ('error', 0.053), ('xx', 0.051), ('diagnosing', 0.051), ('diagnose', 0.051), ('diagnosed', 0.051), ('etos', 0.051), ('automating', 0.051), ('bou', 0.051), ('privileged', 0.051), ('additions', 0.051), ('invent', 0.051), ('irt', 0.051), ('vulnerable', 0.051), ('types', 0.05), ('constituents', 0.05), ('recursive', 0.049), ('full', 0.048), ('parse', 0.048), ('clark', 0.047), ('edinburgh', 0.046), ('established', 0.046), ('participated', 0.046), ('lll', 0.046), ('seeding', 0.046), ('win', 0.046), ('polar', 0.046), ('optimisation', 0.046), ('outlined', 0.046), ('chances', 0.046), ('cg', 0.046), ('conform', 0.046), ('acute', 0.046), ('inference', 0.044), ('lexical', 0.043), ('christodoulopoulos', 0.043), ('handwritten', 0.043), ('deduced', 0.043), ('failure', 0.043), ('misspelling', 0.043), ('interrogative', 0.043), ('afford', 0.043), ('adjusts', 0.043), ('unlimited', 0.043), ('eliminated', 0.043), ('capable', 0.042), ('naive', 0.042), ('solutions', 0.042), ('designed', 0.042), ('introduces', 0.041), ('learner', 0.04), ('brute', 0.04), ('revised', 0.04), ('attempting', 0.04), ('sms', 0.038), ('recovery', 0.038), ('bi', 0.038), ('offered', 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="121-tfidf-1" href="./emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">121 emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<p>Author: Emily Thomforde ; Mark Steedman</p><p>Abstract: This paper introduces Chart Inference (CI), an algorithm for deriving a CCG category for an unknown word from a partial parse chart. It is shown to be faster and more precise than a baseline brute-force method, and to achieve wider coverage than a rule-based system. In addition, we show the application of CI to a domain adaptation task for question words, which are largely missing in the Penn Treebank. When used in combination with self-training, CI increases the precision of the baseline StatCCG parser over subjectextraction questions by 50%. An error analysis shows that CI contributes to the increase by expanding the number of category types available to the parser, while self-training adjusts the counts.</p><p>2 0.18695882 <a title="121-tfidf-2" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>Author: Yue Zhang ; Stephen Clark</p><p>Abstract: Machine-produced text often lacks grammaticality and fluency. This paper studies grammaticality improvement using a syntax-based algorithm based on CCG. The goal of the search problem is to find an optimal parse tree among all that can be constructed through selection and ordering of the input words. The search problem, which is significantly harder than parsing, is solved by guided learning for best-first search. In a standard word ordering task, our system gives a BLEU score of 40. 1, higher than the previous result of 33.7 achieved by a dependency-based system.</p><p>3 0.17111504 <a title="121-tfidf-3" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>4 0.10341901 <a title="121-tfidf-4" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>Author: Jiajun Zhang ; Feifei Zhai ; Chengqing Zong</p><p>Abstract: Due to its explicit modeling of the grammaticality of the output via target-side syntax, the string-to-tree model has been shown to be one of the most successful syntax-based translation models. However, a major limitation of this model is that it does not utilize any useful syntactic information on the source side. In this paper, we analyze the difficulties of incorporating source syntax in a string-totree model. We then propose a new way to use the source syntax in a fuzzy manner, both in source syntactic annotation and in rule matching. We further explore three algorithms in rule matching: 0-1 matching, likelihood matching, and deep similarity matching. Our method not only guarantees grammatical output with an explicit target tree, but also enables the system to choose the proper translation rules via fuzzy use of the source syntax. Our extensive experiments have shown significant improvements over the state-of-the-art string-to-tree system. 1</p><p>5 0.086105689 <a title="121-tfidf-5" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>Author: Emily M. Bender ; Dan Flickinger ; Stephan Oepen ; Yi Zhang</p><p>Abstract: In order to obtain a fine-grained evaluation of parser accuracy over naturally occurring text, we study 100 examples each of ten reasonably frequent linguistic phenomena, randomly selected from a parsed version of the English Wikipedia. We construct a corresponding set of gold-standard target dependencies for these 1000 sentences, operationalize mappings to these targets from seven state-of-theart parsers, and evaluate the parsers against this data to measure their level of success in identifying these dependencies.</p><p>6 0.085000463 <a title="121-tfidf-6" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>7 0.078076959 <a title="121-tfidf-7" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>8 0.067813158 <a title="121-tfidf-8" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>9 0.063923135 <a title="121-tfidf-9" href="./emnlp-2011-A_Fast%2C_Accurate%2C_Non-Projective%2C_Semantically-Enriched_Parser.html">4 emnlp-2011-A Fast, Accurate, Non-Projective, Semantically-Enriched Parser</a></p>
<p>10 0.063721217 <a title="121-tfidf-10" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>11 0.063511483 <a title="121-tfidf-11" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>12 0.060493797 <a title="121-tfidf-12" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>13 0.059738733 <a title="121-tfidf-13" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>14 0.058519378 <a title="121-tfidf-14" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>15 0.057568815 <a title="121-tfidf-15" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>16 0.054158352 <a title="121-tfidf-16" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>17 0.052487157 <a title="121-tfidf-17" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>18 0.052186195 <a title="121-tfidf-18" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>19 0.051848359 <a title="121-tfidf-19" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>20 0.050647829 <a title="121-tfidf-20" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.194), (1, 0.031), (2, -0.031), (3, 0.075), (4, 0.027), (5, -0.036), (6, -0.129), (7, 0.067), (8, 0.092), (9, 0.022), (10, -0.148), (11, 0.097), (12, -0.208), (13, -0.13), (14, 0.032), (15, 0.004), (16, -0.005), (17, -0.152), (18, 0.026), (19, -0.081), (20, -0.074), (21, -0.061), (22, 0.108), (23, -0.094), (24, -0.175), (25, -0.097), (26, 0.005), (27, -0.071), (28, -0.219), (29, 0.064), (30, 0.056), (31, 0.015), (32, 0.098), (33, 0.259), (34, -0.049), (35, -0.087), (36, -0.044), (37, 0.022), (38, 0.145), (39, -0.032), (40, -0.176), (41, 0.091), (42, 0.062), (43, -0.018), (44, 0.069), (45, 0.099), (46, -0.164), (47, -0.072), (48, 0.013), (49, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96735686 <a title="121-lsi-1" href="./emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">121 emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<p>Author: Emily Thomforde ; Mark Steedman</p><p>Abstract: This paper introduces Chart Inference (CI), an algorithm for deriving a CCG category for an unknown word from a partial parse chart. It is shown to be faster and more precise than a baseline brute-force method, and to achieve wider coverage than a rule-based system. In addition, we show the application of CI to a domain adaptation task for question words, which are largely missing in the Penn Treebank. When used in combination with self-training, CI increases the precision of the baseline StatCCG parser over subjectextraction questions by 50%. An error analysis shows that CI contributes to the increase by expanding the number of category types available to the parser, while self-training adjusts the counts.</p><p>2 0.81212926 <a title="121-lsi-2" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>Author: Yue Zhang ; Stephen Clark</p><p>Abstract: Machine-produced text often lacks grammaticality and fluency. This paper studies grammaticality improvement using a syntax-based algorithm based on CCG. The goal of the search problem is to find an optimal parse tree among all that can be constructed through selection and ordering of the input words. The search problem, which is significantly harder than parsing, is solved by guided learning for best-first search. In a standard word ordering task, our system gives a BLEU score of 40. 1, higher than the previous result of 33.7 achieved by a dependency-based system.</p><p>3 0.58393496 <a title="121-lsi-3" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>4 0.36891398 <a title="121-lsi-4" href="./emnlp-2011-Parser_Evaluation_over_Local_and_Non-Local_Deep_Dependencies_in_a_Large_Corpus.html">103 emnlp-2011-Parser Evaluation over Local and Non-Local Deep Dependencies in a Large Corpus</a></p>
<p>Author: Emily M. Bender ; Dan Flickinger ; Stephan Oepen ; Yi Zhang</p><p>Abstract: In order to obtain a fine-grained evaluation of parser accuracy over naturally occurring text, we study 100 examples each of ten reasonably frequent linguistic phenomena, randomly selected from a parsed version of the English Wikipedia. We construct a corresponding set of gold-standard target dependencies for these 1000 sentences, operationalize mappings to these targets from seven state-of-theart parsers, and evaluate the parsers against this data to measure their level of success in identifying these dependencies.</p><p>5 0.30834094 <a title="121-lsi-5" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>Author: Jiajun Zhang ; Feifei Zhai ; Chengqing Zong</p><p>Abstract: Due to its explicit modeling of the grammaticality of the output via target-side syntax, the string-to-tree model has been shown to be one of the most successful syntax-based translation models. However, a major limitation of this model is that it does not utilize any useful syntactic information on the source side. In this paper, we analyze the difficulties of incorporating source syntax in a string-totree model. We then propose a new way to use the source syntax in a fuzzy manner, both in source syntactic annotation and in rule matching. We further explore three algorithms in rule matching: 0-1 matching, likelihood matching, and deep similarity matching. Our method not only guarantees grammatical output with an explicit target tree, but also enables the system to choose the proper translation rules via fuzzy use of the source syntax. Our extensive experiments have shown significant improvements over the state-of-the-art string-to-tree system. 1</p><p>6 0.30474305 <a title="121-lsi-6" href="./emnlp-2011-Bootstrapping_Semantic_Parsers_from_Conversations.html">24 emnlp-2011-Bootstrapping Semantic Parsers from Conversations</a></p>
<p>7 0.2923395 <a title="121-lsi-7" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>8 0.28852925 <a title="121-lsi-8" href="./emnlp-2011-Heuristic_Search_for_Non-Bottom-Up_Tree_Structure_Prediction.html">65 emnlp-2011-Heuristic Search for Non-Bottom-Up Tree Structure Prediction</a></p>
<p>9 0.27007505 <a title="121-lsi-9" href="./emnlp-2011-Multi-Source_Transfer_of_Delexicalized_Dependency_Parsers.html">95 emnlp-2011-Multi-Source Transfer of Delexicalized Dependency Parsers</a></p>
<p>10 0.24843718 <a title="121-lsi-10" href="./emnlp-2011-Training_dependency_parsers_by_jointly_optimizing_multiple_objectives.html">137 emnlp-2011-Training dependency parsers by jointly optimizing multiple objectives</a></p>
<p>11 0.2425179 <a title="121-lsi-11" href="./emnlp-2011-Approximate_Scalable_Bounded_Space_Sketch_for_Large_Data_NLP.html">19 emnlp-2011-Approximate Scalable Bounded Space Sketch for Large Data NLP</a></p>
<p>12 0.24146739 <a title="121-lsi-12" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>13 0.23155928 <a title="121-lsi-13" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>14 0.22815579 <a title="121-lsi-14" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>15 0.22404277 <a title="121-lsi-15" href="./emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</a></p>
<p>16 0.21823092 <a title="121-lsi-16" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>17 0.21613197 <a title="121-lsi-17" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>18 0.20475504 <a title="121-lsi-18" href="./emnlp-2011-A_Probabilistic_Forest-to-String_Model_for_Language_Generation_from_Typed_Lambda_Calculus_Expressions.html">10 emnlp-2011-A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions</a></p>
<p>19 0.20391451 <a title="121-lsi-19" href="./emnlp-2011-Simple_Effective_Decipherment_via_Combinatorial_Optimization.html">122 emnlp-2011-Simple Effective Decipherment via Combinatorial Optimization</a></p>
<p>20 0.20342225 <a title="121-lsi-20" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.05), (37, 0.013), (45, 0.032), (53, 0.011), (57, 0.017), (66, 0.02), (79, 0.721), (96, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96823299 <a title="121-lda-1" href="./emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">121 emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<p>Author: Emily Thomforde ; Mark Steedman</p><p>Abstract: This paper introduces Chart Inference (CI), an algorithm for deriving a CCG category for an unknown word from a partial parse chart. It is shown to be faster and more precise than a baseline brute-force method, and to achieve wider coverage than a rule-based system. In addition, we show the application of CI to a domain adaptation task for question words, which are largely missing in the Penn Treebank. When used in combination with self-training, CI increases the precision of the baseline StatCCG parser over subjectextraction questions by 50%. An error analysis shows that CI contributes to the increase by expanding the number of category types available to the parser, while self-training adjusts the counts.</p><p>2 0.88094264 <a title="121-lda-2" href="./emnlp-2011-Relaxed_Cross-lingual_Projection_of_Constituent_Syntax.html">115 emnlp-2011-Relaxed Cross-lingual Projection of Constituent Syntax</a></p>
<p>Author: Wenbin Jiang ; Qun Liu ; Yajuan Lv</p><p>Abstract: We propose a relaxed correspondence assumption for cross-lingual projection of constituent syntax, which allows a supposed constituent of the target sentence to correspond to an unrestricted treelet in the source parse. Such a relaxed assumption fundamentally tolerates the syntactic non-isomorphism between languages, and enables us to learn the target-language-specific syntactic idiosyncrasy rather than a strained grammar directly projected from the source language syntax. Based on this assumption, a novel constituency projection method is also proposed in order to induce a projected constituent treebank from the source-parsed bilingual corpus. Experiments show that, the parser trained on the projected treebank dramatically outperforms previous projected and unsupervised parsers.</p><p>3 0.83247364 <a title="121-lda-3" href="./emnlp-2011-Corroborating_Text_Evaluation_Results_with_Heterogeneous_Measures.html">36 emnlp-2011-Corroborating Text Evaluation Results with Heterogeneous Measures</a></p>
<p>Author: Enrique Amigo ; Julio Gonzalo ; Jesus Gimenez ; Felisa Verdejo</p><p>Abstract: Automatically produced texts (e.g. translations or summaries) are usually evaluated with n-gram based measures such as BLEU or ROUGE, while the wide set of more sophisticated measures that have been proposed in the last years remains largely ignored for practical purposes. In this paper we first present an indepth analysis of the state of the art in order to clarify this issue. After this, we formalize and verify empirically a set of properties that every text evaluation measure based on similarity to human-produced references satisfies. These properties imply that corroborating system improvements with additional measures always increases the overall reliability of the evaluation process. In addition, the greater the heterogeneity of the measures (which is measurable) the higher their combined reliability. These results support the use of heterogeneous measures in order to consolidate text evaluation results.</p><p>4 0.81750607 <a title="121-lda-4" href="./emnlp-2011-Corpus-Guided_Sentence_Generation_of_Natural_Images.html">34 emnlp-2011-Corpus-Guided Sentence Generation of Natural Images</a></p>
<p>Author: Yezhou Yang ; Ching Teo ; Hal Daume III ; Yiannis Aloimonos</p><p>Abstract: We propose a sentence generation strategy that describes images by predicting the most likely nouns, verbs, scenes and prepositions that make up the core sentence structure. The input are initial noisy estimates of the objects and scenes detected in the image using state of the art trained detectors. As predicting actions from still images directly is unreliable, we use a language model trained from the English Gigaword corpus to obtain their estimates; together with probabilities of co-located nouns, scenes and prepositions. We use these estimates as parameters on a HMM that models the sentence generation process, with hidden nodes as sentence components and image detections as the emissions. Experimental results show that our strategy of combining vision and language produces readable and de- , scriptive sentences compared to naive strategies that use vision alone.</p><p>5 0.47190279 <a title="121-lda-5" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>Author: Tom Kwiatkowski ; Luke Zettlemoyer ; Sharon Goldwater ; Mark Steedman</p><p>Abstract: We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance greatly from the lexical factoring. benefits</p><p>6 0.42864287 <a title="121-lda-6" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>7 0.41251579 <a title="121-lda-7" href="./emnlp-2011-Reducing_Grounded_Learning_Tasks_To_Grammatical_Inference.html">111 emnlp-2011-Reducing Grounded Learning Tasks To Grammatical Inference</a></p>
<p>8 0.40244168 <a title="121-lda-8" href="./emnlp-2011-Extreme_Extraction_-_Machine_Reading_in_a_Week.html">57 emnlp-2011-Extreme Extraction - Machine Reading in a Week</a></p>
<p>9 0.39715096 <a title="121-lda-9" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<p>10 0.3955434 <a title="121-lda-10" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>11 0.38983542 <a title="121-lda-11" href="./emnlp-2011-Better_Evaluation_Metrics_Lead_to_Better_Machine_Translation.html">22 emnlp-2011-Better Evaluation Metrics Lead to Better Machine Translation</a></p>
<p>12 0.3778671 <a title="121-lda-12" href="./emnlp-2011-Exploiting_Parse_Structures_for_Native_Language_Identification.html">54 emnlp-2011-Exploiting Parse Structures for Native Language Identification</a></p>
<p>13 0.37603709 <a title="121-lda-13" href="./emnlp-2011-Computation_of_Infix_Probabilities_for_Probabilistic_Context-Free_Grammars.html">31 emnlp-2011-Computation of Infix Probabilities for Probabilistic Context-Free Grammars</a></p>
<p>14 0.36465988 <a title="121-lda-14" href="./emnlp-2011-Augmenting_String-to-Tree_Translation_Models_with_Fuzzy_Use_of_Source-side_Syntax.html">20 emnlp-2011-Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax</a></p>
<p>15 0.36164144 <a title="121-lda-15" href="./emnlp-2011-Using_Syntactic_and_Semantic_Structural_Kernels_for_Classifying_Definition_Questions_in_Jeopardy%21.html">147 emnlp-2011-Using Syntactic and Semantic Structural Kernels for Classifying Definition Questions in Jeopardy!</a></p>
<p>16 0.36139494 <a title="121-lda-16" href="./emnlp-2011-Identifying_Relations_for_Open_Information_Extraction.html">70 emnlp-2011-Identifying Relations for Open Information Extraction</a></p>
<p>17 0.36085644 <a title="121-lda-17" href="./emnlp-2011-Learning_Sentential_Paraphrases_from_Bilingual_Parallel_Corpora_for_Text-to-Text_Generation.html">83 emnlp-2011-Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a></p>
<p>18 0.35918066 <a title="121-lda-18" href="./emnlp-2011-Learning_to_Simplify_Sentences_with_Quasi-Synchronous_Grammar_and_Integer_Programming.html">85 emnlp-2011-Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</a></p>
<p>19 0.35629261 <a title="121-lda-19" href="./emnlp-2011-Discovering_Relations_between_Noun_Categories.html">40 emnlp-2011-Discovering Relations between Noun Categories</a></p>
<p>20 0.35432819 <a title="121-lda-20" href="./emnlp-2011-Data-Driven_Response_Generation_in_Social_Media.html">38 emnlp-2011-Data-Driven Response Generation in Social Media</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
