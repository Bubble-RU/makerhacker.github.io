<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-81" href="#">emnlp2011-81</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</h1>
<br/><p>Source: <a title="emnlp-2011-81-pdf" href="http://aclweb.org/anthology//D/D11/D11-1101.pdf">pdf</a></p><p>Author: Song Feng ; Ritwik Bose ; Yejin Choi</p><p>Abstract: In this paper, we introduce a connotation lexicon, a new type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war). Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment. Understanding the connotation of words would seem to require common sense and world knowledge. However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner. The key linguistic insight behind our approach is selectional preference of connotative predicates. We present graphbased algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates. Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons.</p><p>Reference: <a title="emnlp-2011-81-reference" href="../emnlp2011_reference/emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment. [sent-8, score-0.526]
</p><p>2 Understanding the connotation of words would seem to require common sense and world knowledge. [sent-9, score-0.58]
</p><p>3 However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner. [sent-10, score-0.713]
</p><p>4 The key linguistic insight behind our approach is selectional preference  of connotative predicates. [sent-11, score-0.624]
</p><p>5 We present graphbased algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates. [sent-12, score-1.273]
</p><p>6 Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons. [sent-13, score-1.179]
</p><p>7 (2005a)): the latter concerns words that express sentiment either explicitly or implicitly, while the former concerns words that evoke or even simply associate with a specific polarity of sentiment. [sent-17, score-0.453]
</p><p>8 To our knowledge, there has been no previous research that investigates polarized connotation lexicons. [sent-18, score-0.58]
</p><p>9 Understanding the connotation of words would seem to require common sense and world knowledge at first glance, which in turn might seem to require human encoding of knowledge base. [sent-19, score-0.58]
</p><p>10 However, we demonstrate that much of the connotative polarity of words can be inferred from natural language  text in a nearly unsupervised manner. [sent-20, score-0.713]
</p><p>11 We define a connotative predicate as a predicate that has selectional preference on the connotative polarity of some of its semantic arguments. [sent-22, score-1.54]
</p><p>12 For instance, in the case of the connotative predicate “prevent”, there is strong selectional preference on negative connotation with respect to the thematic role (semantic role) “THEME”. [sent-23, score-1.353]
</p><p>13 That is, statistically speaking, people tend to associate negative connotation with the THEME of “prevent”, e. [sent-24, score-0.656]
</p><p>14 In other words, In this  introduce a connotation lexicon, of lexicon that lists words with connotative polarity, i. [sent-29, score-1.273]
</p><p>15 Connotation lexicons differ from sentiment lexicons that are studied in much of previous research (e. [sent-36, score-0.371]
</p><p>16 , Esuli and Sebas1092 paper, we  a new type  even though it is perfectly valid to use words with positive connotation in the THEME role of “prevent”, statistically more dominant connotative polarity is negative. [sent-38, score-1.363]
</p><p>17 edTpsictHl,aEirtMen,-E preference of connotative predicates is that of semantic prosody in corpus linguistics. [sent-45, score-0.865]
</p><p>18 , “cause”) can be perceived with positive or negative polarity because they tend to collocate with words with corresponding polarity (e. [sent-48, score-0.465]
</p><p>19 In this work, we demonstrate that statistical approaches that exploit this very concept of semantic prosody can successfully infer connotative polarity of words. [sent-52, score-0.736]
</p><p>20 Figure 1 depicts the mutually reinforcing relation between connotative predicates (nodes on the left-hand side) and words with connotative polarity (node on the right-hand side). [sent-54, score-1.571]
</p><p>21 For brevity, we only consider connotation of words that appear in the THEME thematic role. [sent-56, score-0.58]
</p><p>22 We expect that words that appear often in the THEME role of various positively (or negatively) connotative predicates are likely to be words with positive (or negative) connotation. [sent-57, score-0.924]
</p><p>23 Likewise, predicates whose THEME contains words with mostly positive (or negative) connotation are likely to be positively (or negatively) connotative predicates. [sent-58, score-1.504]
</p><p>24 In short, we can induce the connotative polarity of words using connotative predicates, and inversely, we can learn new connotative predicates based on words with connotative polarity. [sent-59, score-2.61]
</p><p>25 We hypothesize that this mutually reinforcing re1093  OAPv rle vrocveioandmt e PTrIConra mcgnidoce tdinroytn  Figure 1: Bipartite graph of connotative predicates and arguments. [sent-60, score-0.973]
</p><p>26 lation between connotative predicates and their arguments can be captured via graph centrality in graph-based algorithms. [sent-62, score-0.99]
</p><p>27 Given a small set of seed words for connotative predicates, our algorithms collectively learn connotation lexicon together with connotative predicates in a nearly unsupervised manner. [sent-63, score-2.154]
</p><p>28 Empirical study demonstrates that our graph based algorithms are highly effective in learning both connotation lexicon and connotative predicates. [sent-66, score-1.388]
</p><p>29 Finally, we quantify the practical value of our connotation lexicon in concrete sentiment analysis applications, and demonstrate that the connotation lexicon is of great value for sentiment classification tasks complementing conventional sentiment lexicons. [sent-67, score-2.204]
</p><p>30 2  Connotation Lexicon & Connotative  Predicate In this section, we define connotation lexicon and connotative predicates more formally, and contrast them against words in conventional sentiment lexicons. [sent-68, score-1.802]
</p><p>31 •  •  Words with positive connotation: In this work, we dithefin peo wsitoivrdes cwointhn positive connotation as those that describe physical objects or abstract concepts that people generally value, cherish or care about. [sent-71, score-0.72]
</p><p>32 However, a substantial number of words with positive connotation are purely objective, such as “life”, “health”, “tenure”, or “scientific”. [sent-76, score-0.65]
</p><p>33 Note that this explicit and intentional inclusion of objective terms makes connotation lexicons differ from sentiment lexicons: most conventional sentiment lexicons have focused on subjective words by definition (e. [sent-83, score-1.215]
</p><p>34 2 Connotative Predicate In this work, connotative predicates are those that exhibit selectional preference on the connotative polarity of some oftheir arguments. [sent-91, score-1.583]
</p><p>35 We emphasize that the polarity of connotative predicates does not coincide with the polarity of sentiment in conventional sentiment lexicons, as will be elaborated below. [sent-92, score-1.636]
</p><p>36 •  Positively connotative predicate: In this work, we dec ofinnen positively ceodincnaottea:tive predicates as those that expect positive connotation  in some arguments. [sent-93, score-1.504]
</p><p>37 For example, “congratulate” or “save” are positively connotative predicates that expect words with positive connotation in the THEME argument: people typically congratulate something positive, and save something people care about. [sent-94, score-1.549]
</p><p>38 Negatively connotative predicate: In this work, we ydef cionnen negatively ceodnincoattae:tive predicates as those that expect negative connotation in some arguments. [sent-96, score-1.485]
</p><p>39 For instance, predicates such as “prevent” or “suffer” tend to project negative connotation in the THEME argument. [sent-97, score-0.902]
</p><p>40 1094 Note that positively connotative predicates are not necessarily positive sentiment words. [sent-99, score-1.149]
</p><p>41 For instance “save” is not a positive sentiment word in the lexicon published by Wilson et al. [sent-100, score-0.444]
</p><p>42 Inversely, (strongly) positive sentiment words are not necessarily (strongly) positively connotative predicates, e. [sent-102, score-0.884]
</p><p>43 Likewise, negatively connotative predicates are not necessarily negative sentiment words. [sent-105, score-1.13]
</p><p>44 For instance, predicates •  such as “prevent”, “detect”, or “cause” are not negative sentiment words, but they tend to correlate with negative connotation in the THEME argument. [sent-106, score-1.184]
</p><p>45 Inversely, (strongly) negative sentiment words are not necessarily (strongly) negatively connotative predicates, e. [sent-107, score-0.865]
</p><p>46 Figure 1depicts the key intuition as a bipartite graph, where the nodes on the left-hand side correspond to connotative predicates, and the nodes on the right-hand side correspond to words in the THEME argument. [sent-111, score-0.679]
</p><p>47 There is an edge between a predicate p and an argument a, if the argument a appears in the THEME role of the predicate p. [sent-112, score-0.361]
</p><p>48 For instance, some of the  predicates might be negated, changing the semantic dynamics between the predicate and the argument. [sent-116, score-0.376]
</p><p>49 We hypothesize that by focusing on the important part ofthe graph via centrality analysis ,it is possible to infer connotative polarity ofwords despite various noise introduced in the graph structure. [sent-121, score-0.993]
</p><p>50 This implies that it is important to construct the graph structure so as to capture important linguistic relations between predicates and arguments. [sent-122, score-0.38]
</p><p>51 4  Lexicon Induction using HITS  The graph representation described thus far (Section 3) captures general semantic relations between predicates and arguments, rather than those specific to connotative predicates and arguments. [sent-138, score-1.189]
</p><p>52 Therefore in this section, we explore techniques to augment the graph representation so as to bias the centrality 1095 of the graph toward connotative predicates and arguments. [sent-139, score-1.094]
</p><p>53 In order to establish a learning bias, we start with a small set of seed words for just connotative predicates. [sent-140, score-0.616]
</p><p>54 Notice that the mutually reinforcing relationship is precisely what we intend to model between connotative predicates and arguments. [sent-151, score-0.858]
</p><p>55 Let G = (P, A, E) be the bipartite graph, where P is the set of nodes corresponding to connotative predicates, A is the set of nodes corresponding to arguments, and E is the set of edges among nodes. [sent-152, score-0.655]
</p><p>56 (Pi, Aj) ∈ E if and only if the predicate Pi and the argument Ai occur together as a predicate argument pair in the corpus. [sent-153, score-0.342]
</p><p>57 That is, G+ learns positively connotative predicates and arguments, while G− learns neg-  atively connotative predicates and arguments. [sent-163, score-1.663]
</p><p>58 In this method, when constructing the bipartite graph, we limit the set of predicates P to only those words in the seed set, instead of including all words that can be predicates. [sent-166, score-0.378]
</p><p>59 The truncated graph is very effective in reducing the level of noise that can be introduced by predicates of the opposite polarity. [sent-168, score-0.487]
</p><p>60 It may seem like we cannot discover new connotative predicates in the truncated graph however, as the graph structure is limited only to the seed predicates. [sent-169, score-1.197]
</p><p>61 For instance, we start with the graph G = (Po, A, E(Po)) that is truncated only on the lefthand side, with the seed predicates Po. [sent-173, score-0.538]
</p><p>62 Let Ao be the new words with connotation that are found in the first round. [sent-177, score-0.58]
</p><p>63 We now set Ao as seed words for the second phase of HITS, where we construct a new graph G = (P, Ao, E(Ao)) that is truncated only on the right-hand side, with full candidate words for predicates included on the left-hand side. [sent-178, score-0.538]
</p><p>64 This alternation can be repeated multiple times to discover 1096 many new connotative predicates and arguments. [sent-179, score-0.809]
</p><p>65 3 Prior Knowledge via Focussed Graph In the truncated graph described above, one potential concern is that the discovery of new words with connotation is limited to those that happen to correlate well with the seed predicates. [sent-181, score-0.853]
</p><p>66 That is, we assign high weights to those edges that connect a seed predicate with an argument, while assigning low weights for those edges that connect to a predicate outside the seed set. [sent-184, score-0.418]
</p><p>67 This way, we allow predicates not in the seed set to participate in hubs and authority scores, but in a much suppressed way. [sent-185, score-0.406]
</p><p>68 To do so, when constructing the bipartite graph, we limit the set of predicates P to only those words in the seed set, instead of including all words that can be predicates. [sent-215, score-0.378]
</p><p>69 Graph truncation eliminates the noise that can be introduced by predicates of the opposite polarity. [sent-216, score-0.328]
</p><p>70 1097 6 The Use of Google Web 1T Data In order to implement the network of connotative predicates and arguments, we need a substantially large amount of documents. [sent-235, score-0.809]
</p><p>71 In other words, we expect that good predicates will be supported by good arguments, and vice versa, thereby resulting in a reliable set of predicates —  ××  and arguments that are mutually supported by each other. [sent-271, score-0.591]
</p><p>72 ]n−2 [a] (see Section 6), we collect two sets of n-gram records: one set using the positive connotative predicates, and the other using the negative connotative predicates. [sent-274, score-1.215]
</p><p>73 ]n−2 as f2 The number of occurrences of [a] as f3  We then obtain the score σa+ for positive connotation and σa− for negative connotation using the following equations that take a linear combination of f1, f2, and f3 that we computed above with respect to each polarity. [sent-276, score-1.287]
</p><p>74 1 Comparison against Sentiment Lexicon The polarity defined in the connotation lexicon differs from that of conventional sentiment lexicons in which we aim to recognize more subtle sentiment that correlates with words. [sent-280, score-1.46]
</p><p>75 Nevertheless, we provide agreement statistics between our connotation lexicon and conventional sentiment lexicons for comparison purposes. [sent-281, score-1.066]
</p><p>76 For polarity λ ∈ {+, −}, let countsentlex(λ) denote tFhoer t pootalal intyum λbe ∈r {o+f w,−or}d,s elatb ceoleudn as λ in a given sentiment lexicon, and let countagreement(λ) denote the total number of words labeled as λ by both the given sentiment lexicon and our connotation lexicon. [sent-284, score-1.348]
</p><p>77 In addition, let countoverlap(λ) denote the total number of words that are labeled as λ by our connotation lexicon that are also included in the reference  lexicon with or without the same polarity. [sent-285, score-0.878]
</p><p>78 2  Extrinsic Evaluation via Sentiment Analysis Next we perform extrinsic evaluation to quantify the practical value of our connotation lexicon in concrete sentiment analysis applications. [sent-301, score-0.986]
</p><p>79 In particular, we make use of our connotation lexicon for binary 1099 sentiment classification tasks in two different ways: •  Unsupervised classification by voting. [sent-302, score-0.954]
</p><p>80 Notice that the use of Top 6k words from our connotation lexicon along with OpinionFinder lexicon boost the performance up to 78. [sent-316, score-0.878]
</p><p>81 This result shows that our connotation lexicon nicely complements existing sentiment lexicon, improving practical sentiment analysis tasks. [sent-319, score-1.179]
</p><p>82 3 Intrinsic Evaluation via Human Judgment In order to measure the quality of the connotation lexicon, we also perform human judgment study on a subset of the lexicon. [sent-336, score-0.604]
</p><p>83 Human judges are asked to quantify the degree of connotative polarity of each given word using an integer value between 1and 5, where 1and 5 correspond to the most negative and positive connotation respectively. [sent-337, score-1.452]
</p><p>84 When computing the annotator agreement score or evaluating our connotation lexicon against human judgment, we consolidate 1 and 2 into a single negative class and 4 and 5 into a single positive class. [sent-338, score-0.856]
</p><p>85 The words were presented in a random order so that the human judges will not know which words are from the General In-  quirer lexicon and which are from our connotative lexicon. [sent-343, score-0.693]
</p><p>86 Note that some words appear in both positive and negative connotation graphs, while others appear in only one of them. [sent-345, score-0.707]
</p><p>87 For instance, if a given word x appears as an argument for only positive connotative predicates, but never for negative ones, then x would appear only in the positive connotation graph. [sent-346, score-1.381]
</p><p>88 This means that for such word, we can assume the connotative polarity even without applying the algorithms for graph centrality. [sent-347, score-0.828]
</p><p>89 Therefore, we first evaluate the accuracy of the polarity of such words that appear only in one of the connotation graphs. [sent-348, score-0.749]
</p><p>90 5% by lenient evaluation, where lenient evaluation counts words in our polarized connotation lexicon to be correct if the human judges assign non-conflicting polarities, i. [sent-351, score-0.801]
</p><p>91 For words that appear in both positive and nega-  tive connotation graphs, we determine the final polarity of such words as one with higher scores given by HITS or PageRank. [sent-354, score-0.819]
</p><p>92 We are not aware of any previous research that made use of HITS algorithm for connotation or sentiment lexicon induction. [sent-366, score-0.954]
</p><p>93 We conjecture that this trend of broader coverage suggests that such lexicons are practically more useful than sentiment lexicons that include only those words that are strictly subjective. [sent-388, score-0.371]
</p><p>94 In this work, we 1101 make this transition more explicit and intentional,  by introducing a novel connotation lexicon. [sent-389, score-0.58]
</p><p>95 (1957), it has been discussed that connotative meaning of words can be measured in multiple scales of semantic differential, for example, the degree of “goodness” and “badness”. [sent-394, score-0.544]
</p><p>96 9 Conclusion We introduced the connotation lexicon, a novel lex-  icon that list words with connotative polarity, which will be made publically available. [sent-397, score-1.124]
</p><p>97 We also presented graph-based algorithms for learning connotation lexicon together with connotative predicates in a nearly unsupervised manner. [sent-398, score-1.538]
</p><p>98 Our approaches are grounded on the linguistic insight with respect to the selectional preference of connotative predicates. [sent-399, score-0.624]
</p><p>99 Empirical study demonstrates the practical value of the connotation lexicon for sentiment analysis encouraging further research in this direction. [sent-400, score-0.954]
</p><p>100 Building lexicon for sentiment analysis from massive collection of HTML documents. [sent-450, score-0.374]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('connotation', 0.58), ('connotative', 0.544), ('predicates', 0.265), ('sentiment', 0.225), ('polarity', 0.169), ('lexicon', 0.149), ('pagerank', 0.121), ('graph', 0.115), ('predicate', 0.111), ('theme', 0.09), ('hits', 0.088), ('truncated', 0.086), ('lexicons', 0.073), ('seed', 0.072), ('positive', 0.07), ('argument', 0.06), ('negative', 0.057), ('wilson', 0.055), ('esuli', 0.049), ('positively', 0.045), ('hubs', 0.042), ('truncation', 0.042), ('bipartite', 0.041), ('prevent', 0.041), ('conventional', 0.039), ('negatively', 0.039), ('pj', 0.038), ('ai', 0.038), ('arguments', 0.037), ('kleinberg', 0.036), ('lenient', 0.036), ('mohammad', 0.034), ('undirected', 0.033), ('inquirer', 0.033), ('emotion', 0.033), ('promotion', 0.033), ('preference', 0.033), ('asymmetric', 0.032), ('subjectivity', 0.032), ('quantify', 0.032), ('authorities', 0.032), ('evoked', 0.032), ('inversely', 0.032), ('lij', 0.032), ('opinionfinder', 0.032), ('teleportation', 0.032), ('velikovich', 0.03), ('centrality', 0.029), ('selectional', 0.028), ('fabrizio', 0.027), ('congratulate', 0.027), ('hub', 0.027), ('focussed', 0.027), ('prec', 0.027), ('authority', 0.027), ('edges', 0.026), ('pi', 0.026), ('explore', 0.026), ('graphs', 0.025), ('side', 0.025), ('reinforcing', 0.025), ('mutually', 0.024), ('judgment', 0.024), ('freq', 0.023), ('prosody', 0.023), ('nodes', 0.022), ('ao', 0.022), ('pmi', 0.022), ('aj', 0.021), ('rounds', 0.021), ('wiebe', 0.021), ('twitter', 0.021), ('adreevskaia', 0.021), ('baccianella', 0.021), ('bianchini', 0.021), ('frowny', 0.021), ('kamps', 0.021), ('louw', 0.021), ('osgood', 0.021), ('owu', 0.021), ('proportionate', 0.021), ('sentiwordnet', 0.021), ('smiley', 0.021), ('stefanowitsch', 0.021), ('truncating', 0.021), ('tthaabtl', 0.021), ('directed', 0.021), ('noise', 0.021), ('andrea', 0.02), ('cancer', 0.02), ('concerns', 0.02), ('prior', 0.019), ('associate', 0.019), ('insight', 0.019), ('po', 0.019), ('edge', 0.019), ('web', 0.019), ('save', 0.018), ('theresa', 0.018), ('war', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="81-tfidf-1" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>Author: Song Feng ; Ritwik Bose ; Yejin Choi</p><p>Abstract: In this paper, we introduce a connotation lexicon, a new type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war). Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment. Understanding the connotation of words would seem to require common sense and world knowledge. However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner. The key linguistic insight behind our approach is selectional preference of connotative predicates. We present graphbased algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates. Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons.</p><p>2 0.18633251 <a title="81-tfidf-2" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>3 0.17943345 <a title="81-tfidf-3" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>Author: Ainur Yessenalina ; Claire Cardie</p><p>Abstract: We present a general learning-based approach for phrase-level sentiment analysis that adopts an ordinal sentiment scale and is explicitly compositional in nature. Thus, we can model the compositional effects required for accurate assignment of phrase-level sentiment. For example, combining an adverb (e.g., “very”) with a positive polar adjective (e.g., “good”) produces a phrase (“very good”) with increased polarity over the adjective alone. Inspired by recent work on distributional approaches to compositionality, we model each word as a matrix and combine words using iterated matrix multiplication, which allows for the modeling of both additive and multiplicative semantic effects. Although the multiplication-based matrix-space framework has been shown to be a theoretically elegant way to model composition (Rudolph and Giesbrecht, 2010), training such models has to be done carefully: the optimization is nonconvex and requires a good initial starting point. This paper presents the first such algorithm for learning a matrix-space model for semantic composition. In the context of the phrase-level sentiment analysis task, our experimental results show statistically significant improvements in performance over a bagof-words model.</p><p>4 0.14764719 <a title="81-tfidf-4" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>Author: Richard Socher ; Jeffrey Pennington ; Eric H. Huang ; Andrew Y. Ng ; Christopher D. Manning</p><p>Abstract: We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model’s ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.</p><p>5 0.12721583 <a title="81-tfidf-5" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>Author: Balamurali AR ; Aditya Joshi ; Pushpak Bhattacharyya</p><p>Abstract: Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. We propose semantic features using word senses for a supervised document-level sentiment classifier. To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. We per- form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. The results show promising improvement with respect to the baseline.</p><p>6 0.096747711 <a title="81-tfidf-6" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>7 0.095771819 <a title="81-tfidf-7" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>8 0.087198325 <a title="81-tfidf-8" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>9 0.085593499 <a title="81-tfidf-9" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>10 0.0775778 <a title="81-tfidf-10" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>11 0.055797644 <a title="81-tfidf-11" href="./emnlp-2011-Minimally_Supervised_Event_Causality_Identification.html">92 emnlp-2011-Minimally Supervised Event Causality Identification</a></p>
<p>12 0.053678412 <a title="81-tfidf-12" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>13 0.05068329 <a title="81-tfidf-13" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>14 0.047541745 <a title="81-tfidf-14" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>15 0.044848073 <a title="81-tfidf-15" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>16 0.04207433 <a title="81-tfidf-16" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>17 0.041955397 <a title="81-tfidf-17" href="./emnlp-2011-Simple_Effective_Decipherment_via_Combinatorial_Optimization.html">122 emnlp-2011-Simple Effective Decipherment via Combinatorial Optimization</a></p>
<p>18 0.037761297 <a title="81-tfidf-18" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<p>19 0.037472479 <a title="81-tfidf-19" href="./emnlp-2011-A_generative_model_for_unsupervised_discovery_of_relations_and_argument_classes_from_clinical_texts.html">14 emnlp-2011-A generative model for unsupervised discovery of relations and argument classes from clinical texts</a></p>
<p>20 0.034503184 <a title="81-tfidf-20" href="./emnlp-2011-Semi-supervised_CCG_Lexicon_Extension.html">121 emnlp-2011-Semi-supervised CCG Lexicon Extension</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.137), (1, -0.181), (2, 0.048), (3, 0.083), (4, 0.325), (5, -0.032), (6, 0.09), (7, 0.073), (8, -0.007), (9, 0.011), (10, 0.021), (11, 0.139), (12, -0.013), (13, 0.0), (14, 0.056), (15, 0.056), (16, -0.082), (17, 0.011), (18, 0.033), (19, -0.014), (20, -0.014), (21, -0.009), (22, 0.029), (23, 0.023), (24, -0.017), (25, -0.077), (26, -0.017), (27, -0.142), (28, 0.065), (29, 0.002), (30, -0.061), (31, 0.095), (32, 0.009), (33, 0.034), (34, -0.03), (35, 0.019), (36, -0.125), (37, 0.067), (38, -0.147), (39, -0.097), (40, 0.035), (41, -0.052), (42, -0.01), (43, -0.062), (44, -0.021), (45, -0.094), (46, -0.004), (47, 0.061), (48, -0.11), (49, 0.075)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96158808 <a title="81-lsi-1" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>Author: Song Feng ; Ritwik Bose ; Yejin Choi</p><p>Abstract: In this paper, we introduce a connotation lexicon, a new type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war). Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment. Understanding the connotation of words would seem to require common sense and world knowledge. However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner. The key linguistic insight behind our approach is selectional preference of connotative predicates. We present graphbased algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates. Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons.</p><p>2 0.71750122 <a title="81-lsi-2" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>3 0.59171152 <a title="81-lsi-3" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>Author: Ainur Yessenalina ; Claire Cardie</p><p>Abstract: We present a general learning-based approach for phrase-level sentiment analysis that adopts an ordinal sentiment scale and is explicitly compositional in nature. Thus, we can model the compositional effects required for accurate assignment of phrase-level sentiment. For example, combining an adverb (e.g., “very”) with a positive polar adjective (e.g., “good”) produces a phrase (“very good”) with increased polarity over the adjective alone. Inspired by recent work on distributional approaches to compositionality, we model each word as a matrix and combine words using iterated matrix multiplication, which allows for the modeling of both additive and multiplicative semantic effects. Although the multiplication-based matrix-space framework has been shown to be a theoretically elegant way to model composition (Rudolph and Giesbrecht, 2010), training such models has to be done carefully: the optimization is nonconvex and requires a good initial starting point. This paper presents the first such algorithm for learning a matrix-space model for semantic composition. In the context of the phrase-level sentiment analysis task, our experimental results show statistically significant improvements in performance over a bagof-words model.</p><p>4 0.56118351 <a title="81-lsi-4" href="./emnlp-2011-Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions.html">120 emnlp-2011-Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</a></p>
<p>Author: Richard Socher ; Jeffrey Pennington ; Eric H. Huang ; Andrew Y. Ng ; Christopher D. Manning</p><p>Abstract: We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model’s ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.</p><p>5 0.55516022 <a title="81-lsi-5" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>Author: Balamurali AR ; Aditya Joshi ; Pushpak Bhattacharyya</p><p>Abstract: Traditional approaches to sentiment classification rely on lexical features, syntax-based features or a combination of the two. We propose semantic features using word senses for a supervised document-level sentiment classifier. To highlight the benefit of sense-based features, we compare word-based representation of documents with a sense-based representation where WordNet senses of the words are used as features. In addition, we highlight the benefit of senses by presenting a part-ofspeech-wise effect on sentiment classification. Finally, we show that even if a WSD engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. Since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on WordNet to address the problem of not finding a sense in the training corpus. We per- form experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. The results show promising improvement with respect to the baseline.</p><p>6 0.48546687 <a title="81-lsi-6" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>7 0.45329157 <a title="81-lsi-7" href="./emnlp-2011-Unsupervised_Learning_of_Selectional_Restrictions_and_Detection_of_Argument_Coercions.html">144 emnlp-2011-Unsupervised Learning of Selectional Restrictions and Detection of Argument Coercions</a></p>
<p>8 0.37367269 <a title="81-lsi-8" href="./emnlp-2011-Unsupervised_Semantic_Role_Induction_with_Graph_Partitioning.html">145 emnlp-2011-Unsupervised Semantic Role Induction with Graph Partitioning</a></p>
<p>9 0.3592394 <a title="81-lsi-9" href="./emnlp-2011-Literal_and_Metaphorical_Sense_Identification_through_Concrete_and_Abstract_Context.html">91 emnlp-2011-Literal and Metaphorical Sense Identification through Concrete and Abstract Context</a></p>
<p>10 0.31844345 <a title="81-lsi-10" href="./emnlp-2011-Unsupervised_Discovery_of_Discourse_Relations_for_Eliminating_Intra-sentence_Polarity_Ambiguities.html">142 emnlp-2011-Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities</a></p>
<p>11 0.27064967 <a title="81-lsi-11" href="./emnlp-2011-Active_Learning_with_Amazon_Mechanical_Turk.html">17 emnlp-2011-Active Learning with Amazon Mechanical Turk</a></p>
<p>12 0.26901859 <a title="81-lsi-12" href="./emnlp-2011-Class_Label_Enhancement_via_Related_Instances.html">26 emnlp-2011-Class Label Enhancement via Related Instances</a></p>
<p>13 0.22538653 <a title="81-lsi-13" href="./emnlp-2011-A_Joint_Model_for_Extended_Semantic_Role_Labeling.html">7 emnlp-2011-A Joint Model for Extended Semantic Role Labeling</a></p>
<p>14 0.20801064 <a title="81-lsi-14" href="./emnlp-2011-Hierarchical_Verb_Clustering_Using_Graph_Factorization.html">67 emnlp-2011-Hierarchical Verb Clustering Using Graph Factorization</a></p>
<p>15 0.206879 <a title="81-lsi-15" href="./emnlp-2011-Random_Walk_Inference_and_Learning_in_A_Large_Scale_Knowledge_Base.html">109 emnlp-2011-Random Walk Inference and Learning in A Large Scale Knowledge Base</a></p>
<p>16 0.19134693 <a title="81-lsi-16" href="./emnlp-2011-Rumor_has_it%3A_Identifying_Misinformation_in_Microblogs.html">117 emnlp-2011-Rumor has it: Identifying Misinformation in Microblogs</a></p>
<p>17 0.19041935 <a title="81-lsi-17" href="./emnlp-2011-Improved_Transliteration_Mining_Using_Graph_Reinforcement.html">72 emnlp-2011-Improved Transliteration Mining Using Graph Reinforcement</a></p>
<p>18 0.18927528 <a title="81-lsi-18" href="./emnlp-2011-Identifying_and_Following_Expert_Investors_in_Stock_Microblogs.html">71 emnlp-2011-Identifying and Following Expert Investors in Stock Microblogs</a></p>
<p>19 0.1806543 <a title="81-lsi-19" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>20 0.17547044 <a title="81-lsi-20" href="./emnlp-2011-Lexical_Generalization_in_CCG_Grammar_Induction_for_Semantic_Parsing.html">87 emnlp-2011-Lexical Generalization in CCG Grammar Induction for Semantic Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.101), (36, 0.017), (37, 0.031), (45, 0.076), (53, 0.018), (54, 0.034), (57, 0.021), (62, 0.021), (64, 0.02), (66, 0.028), (69, 0.023), (70, 0.013), (71, 0.25), (79, 0.042), (82, 0.016), (90, 0.015), (96, 0.068), (97, 0.071), (98, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76684415 <a title="81-lda-1" href="./emnlp-2011-Learning_General_Connotation_of_Words_using_Graph-based_Algorithms.html">81 emnlp-2011-Learning General Connotation of Words using Graph-based Algorithms</a></p>
<p>Author: Song Feng ; Ritwik Bose ; Yejin Choi</p><p>Abstract: In this paper, we introduce a connotation lexicon, a new type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war). Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment. Understanding the connotation of words would seem to require common sense and world knowledge. However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner. The key linguistic insight behind our approach is selectional preference of connotative predicates. We present graphbased algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates. Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons.</p><p>2 0.57170045 <a title="81-lda-2" href="./emnlp-2011-Compositional_Matrix-Space_Models_for_Sentiment_Analysis.html">30 emnlp-2011-Compositional Matrix-Space Models for Sentiment Analysis</a></p>
<p>Author: Ainur Yessenalina ; Claire Cardie</p><p>Abstract: We present a general learning-based approach for phrase-level sentiment analysis that adopts an ordinal sentiment scale and is explicitly compositional in nature. Thus, we can model the compositional effects required for accurate assignment of phrase-level sentiment. For example, combining an adverb (e.g., “very”) with a positive polar adjective (e.g., “good”) produces a phrase (“very good”) with increased polarity over the adjective alone. Inspired by recent work on distributional approaches to compositionality, we model each word as a matrix and combine words using iterated matrix multiplication, which allows for the modeling of both additive and multiplicative semantic effects. Although the multiplication-based matrix-space framework has been shown to be a theoretically elegant way to model composition (Rudolph and Giesbrecht, 2010), training such models has to be done carefully: the optimization is nonconvex and requires a good initial starting point. This paper presents the first such algorithm for learning a matrix-space model for semantic composition. In the context of the phrase-level sentiment analysis task, our experimental results show statistically significant improvements in performance over a bagof-words model.</p><p>3 0.54871392 <a title="81-lda-3" href="./emnlp-2011-Personalized_Recommendation_of_User_Comments_via_Factor_Models.html">104 emnlp-2011-Personalized Recommendation of User Comments via Factor Models</a></p>
<p>Author: Deepak Agarwal ; Bee-Chung Chen ; Bo Pang</p><p>Abstract: In recent years, the amount of user-generated opinionated texts (e.g., reviews, user comments) continues to grow at a rapid speed: featured news stories on a major event easily attract thousands of user comments on a popular online News service. How to consume subjective information ofthis volume becomes an interesting and important research question. In contrast to previous work on review analysis that tried to filter or summarize information for a generic average user, we explore a different direction of enabling personalized recommendation of such information. For each user, our task is to rank the comments associated with a given article according to personalized user preference (i.e., whether the user is likely to like or dislike the comment). To this end, we propose a factor model that incorporates rater-comment and rater-author interactions simultaneously in a principled way. Our full model significantly outperforms strong baselines as well as related models that have been considered in previous work.</p><p>4 0.53974962 <a title="81-lda-4" href="./emnlp-2011-Cooooooooooooooollllllllllllll%21%21%21%21%21%21%21%21%21%21%21%21%21%21_Using_Word_Lengthening_to_Detect_Sentiment_in_Microblogs.html">33 emnlp-2011-Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs</a></p>
<p>Author: Samuel Brody ; Nicholas Diakopoulos</p><p>Abstract: We present an automatic method which leverages word lengthening to adapt a sentiment lexicon specifically for Twitter and similar social messaging networks. The contributions of the paper are as follows. First, we call attention to lengthening as a widespread phenomenon in microblogs and social messaging, and demonstrate the importance of handling it correctly. We then show that lengthening is strongly associated with subjectivity and sentiment. Finally, we present an automatic method which leverages this association to detect domain-specific sentiment- and emotionbearing words. We evaluate our method by comparison to human judgments, and analyze its strengths and weaknesses. Our results are of interest to anyone analyzing sentiment in microblogs and social networks, whether for research or commercial purposes.</p><p>5 0.51377147 <a title="81-lda-5" href="./emnlp-2011-Quasi-Synchronous_Phrase_Dependency_Grammars_for_Machine_Translation.html">108 emnlp-2011-Quasi-Synchronous Phrase Dependency Grammars for Machine Translation</a></p>
<p>Author: Kevin Gimpel ; Noah A. Smith</p><p>Abstract: We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009). This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model. We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser. For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices. We demonstrate performance improvements for Chinese-English and UrduEnglish translation over a phrase-based baseline. We also investigate the use of unsupervised dependency parsers, reporting encouraging preliminary results.</p><p>6 0.50758892 <a title="81-lda-6" href="./emnlp-2011-Structured_Relation_Discovery_using_Generative_Models.html">128 emnlp-2011-Structured Relation Discovery using Generative Models</a></p>
<p>7 0.50451827 <a title="81-lda-7" href="./emnlp-2011-Closing_the_Loop%3A_Fast%2C_Interactive_Semi-Supervised_Annotation_With_Queries_on_Features_and_Instances.html">28 emnlp-2011-Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances</a></p>
<p>8 0.50367779 <a title="81-lda-8" href="./emnlp-2011-Soft_Dependency_Constraints_for_Reordering_in_Hierarchical_Phrase-Based_Translation.html">123 emnlp-2011-Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation</a></p>
<p>9 0.50083047 <a title="81-lda-9" href="./emnlp-2011-Experimental_Support_for_a_Categorical_Compositional_Distributional_Model_of_Meaning.html">53 emnlp-2011-Experimental Support for a Categorical Compositional Distributional Model of Meaning</a></p>
<p>10 0.50069559 <a title="81-lda-10" href="./emnlp-2011-Structural_Opinion_Mining_for_Graph-based_Sentiment_Representation.html">126 emnlp-2011-Structural Opinion Mining for Graph-based Sentiment Representation</a></p>
<p>11 0.49942088 <a title="81-lda-11" href="./emnlp-2011-A_Bayesian_Mixture_Model_for_PoS_Induction_Using_Multiple_Features.html">1 emnlp-2011-A Bayesian Mixture Model for PoS Induction Using Multiple Features</a></p>
<p>12 0.49933481 <a title="81-lda-12" href="./emnlp-2011-Training_a_Parser_for_Machine_Translation_Reordering.html">136 emnlp-2011-Training a Parser for Machine Translation Reordering</a></p>
<p>13 0.49781933 <a title="81-lda-13" href="./emnlp-2011-Fast_and_Robust_Joint_Models_for_Biomedical_Event_Extraction.html">59 emnlp-2011-Fast and Robust Joint Models for Biomedical Event Extraction</a></p>
<p>14 0.49646291 <a title="81-lda-14" href="./emnlp-2011-Cross-Cutting_Models_of_Lexical_Semantics.html">37 emnlp-2011-Cross-Cutting Models of Lexical Semantics</a></p>
<p>15 0.49549842 <a title="81-lda-15" href="./emnlp-2011-Syntax-Based_Grammaticality_Improvement_using_CCG_and_Guided_Search.html">132 emnlp-2011-Syntax-Based Grammaticality Improvement using CCG and Guided Search</a></p>
<p>16 0.49415988 <a title="81-lda-16" href="./emnlp-2011-Robust_Disambiguation_of_Named_Entities_in_Text.html">116 emnlp-2011-Robust Disambiguation of Named Entities in Text</a></p>
<p>17 0.49403259 <a title="81-lda-17" href="./emnlp-2011-Harnessing_WordNet_Senses_for_Supervised_Sentiment_Classification.html">63 emnlp-2011-Harnessing WordNet Senses for Supervised Sentiment Classification</a></p>
<p>18 0.49395809 <a title="81-lda-18" href="./emnlp-2011-A_Model_of_Discourse_Predictions_in_Human_Sentence_Processing.html">8 emnlp-2011-A Model of Discourse Predictions in Human Sentence Processing</a></p>
<p>19 0.49361902 <a title="81-lda-19" href="./emnlp-2011-Named_Entity_Recognition_in_Tweets%3A_An_Experimental_Study.html">98 emnlp-2011-Named Entity Recognition in Tweets: An Experimental Study</a></p>
<p>20 0.49300224 <a title="81-lda-20" href="./emnlp-2011-Correcting_Semantic_Collocation_Errors_with_L1-induced_Paraphrases.html">35 emnlp-2011-Correcting Semantic Collocation Errors with L1-induced Paraphrases</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
