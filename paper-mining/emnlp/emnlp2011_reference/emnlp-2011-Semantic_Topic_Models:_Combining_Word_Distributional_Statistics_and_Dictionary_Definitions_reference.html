<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-119" href="../emnlp2011/emnlp-2011-Semantic_Topic_Models%3A_Combining_Word_Distributional_Statistics_and_Dictionary_Definitions.html">emnlp2011-119</a> <a title="emnlp-2011-119-reference" href="#">emnlp2011-119-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>119 emnlp-2011-Semantic Topic Models: Combining Word Distributional Statistics and Dictionary Definitions</h1>
<br/><p>Source: <a title="emnlp-2011-119-pdf" href="http://aclweb.org/anthology//D/D11/D11-1051.pdf">pdf</a></p><p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: In this paper, we propose a novel topic model based on incorporating dictionary definitions. Traditional topic models treat words as surface strings without assuming predefined knowledge about word meaning. They infer topics only by observing surface word co-occurrence. However, the co-occurred words may not be semantically related in a manner that is relevant for topic coherence. Exploiting dictionary definitions explicitly in our model yields a better understanding of word semantics leading to better text modeling. We exploit WordNet as a lexical resource for sense definitions. We show that explicitly modeling word definitions helps improve performance significantly over the baseline for a text categorization task.</p><br/>
<h2>reference text</h2><p>Satanjeev Banerjee and Ted Pedersen. 2003. Extended gloss overlaps as a measure of semantic relatedness. In Proceedings of the 18th International Joint Conference on Artificial Intelligence, pages 805–810. David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022. Jordan Boyd-Graber and David turning predominant senses word sense disambiguation. 4th International Workshop tions, pages 277–281 .  M. Blei. 2007. Putop: into a topic model for In Proceedings of the on Semantic Evalua-  Jordan Boyd-Graber, David M. Blei, and Xiaojin Zhu. 2007. A topic model for word sense disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning  (EMNLP-CoNLL), pages 1024–1033. Samuel Brody word sense Conference pages 103–1  and Mirella Lapata. 2009. Bayesian induction. In Proceedings of the 12th of the European Chapter of the ACL, 11.  Jun Fu Cai, Wee Sun Lee, and Yee Whye Teh. 2007. Improving word sense disambiguation using topic features. In Proceedings of 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1015–1023. Chaitanya Chemudugunta, Padhraic Smyth, and Mark Steyvers. 2008. Combining concept hierarchies and statistical topic models. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 1469–1470. Hal Daume. 2009. Markov random topic fields. In Proceedings of the ACL-IJCNLP Conference, pages 293–296. Laura Dietz, Steffen Bickel, and Tobias Scheffer. 2007. Unsupervised prediction of citation influence. In Proceedings of the 24th international conference on Machine learning, pages 233–240. Christiane Fellbaum.  1998. WordNet: An Electronic  Lexical Database. MIT Press. Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences, 101:5228–5235. Thomas L. Griffiths, Mark Steyvers, David M. Blei, and Joshua B. Tenenbaum. 2005. Integrating topics and syntax. In Advances in Neural Information Processing Systems. Weiwei Guo and Mona Diab. 2010. Combining orthogonal monolingual and multilingual sources of evidence for all words wsd. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1542–1551 . Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The weka data mining software: an update. SIGKDD Explor. Newsl., 11:10–18. Linlin Li, Benjamin Roth, and Caroline Sporleder. 2010. Topic models for word sense disambiguation and token-based idiom detection. In Proceedings of the 48thAnnual Meeting ofthe Associationfor Computational Linguistics, pages 1138–1 147. Qiaozhu Mei, Deng Cai, Duo Zhang, and Chengxiang  Zhai. 2008. Topic modeling with network regularization. In Proceedings of the 17th international conference on World Wide Web, pages 101–1 10. Rada Mihalcea. 2005. Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling. In Proceedings of the Joint Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 411–418. Sameer S. Pradhan, Edward Loper, Dmitriy Dligach, and Martha Palmer. 2007. Semeval-2007 task 17: English lexical sample, srl and all words. In Pro-  cmeaendti ncg Esv oaflu thaetio 4nths, I pnatgerensa 8t7io–n92a.l A WCoLrk.shop on S5e6-1  Ravi Sinha and Rada Mihalcea. 2007. Unsupervised graph-based word sense disambiguation using measures of word semantic similarity. In Proceedings of the IEEE International Conference on Semantic Computing, pages 363–369. Benjamin Snyder and Martha Palmer. 2004. The english all-words task. In Senseval-3: Third International Workshop on the Evaluation ofSystemsfor the Semantic Analysis of Text, pages 41–43. ACL. Ivan Titov and Ryan McDonald.  2008.  Modeling  online reviews with multi-grain topic models. In Proceedings of the 17th international conference on World Wide Web, pages 111–120.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
