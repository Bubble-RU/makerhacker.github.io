<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-141" href="../emnlp2011/emnlp-2011-Unsupervised_Dependency_Parsing_without_Gold_Part-of-Speech_Tags.html">emnlp2011-141</a> <a title="emnlp-2011-141-reference" href="#">emnlp2011-141-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>141 emnlp-2011-Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</h1>
<br/><p>Source: <a title="emnlp-2011-141-pdf" href="http://aclweb.org/anthology//D/D11/D11-1118.pdf">pdf</a></p><p>Author: Valentin I. Spitkovsky ; Hiyan Alshawi ; Angel X. Chang ; Daniel Jurafsky</p><p>Abstract: We show that categories induced by unsupervised word clustering can surpass the performance of gold part-of-speech tags in dependency grammar induction. Unlike classic clustering algorithms, our method allows a word to have different tags in different contexts. In an ablative analysis, we first demonstrate that this context-dependence is crucial to the superior performance of gold tags — requiring a word to always have the same part-ofspeech significantly degrades the performance of manual tags in grammar induction, eliminating the advantage that human annotation has over unsupervised tags. We then introduce a sequence modeling technique that combines the output of a word clustering algorithm with context-colored noise, to allow words to be tagged differently in different contexts. With these new induced tags as input, our state-of- the-art dependency grammar inducer achieves 59. 1% directed accuracy on Section 23 (all sentences) of the Wall Street Journal (WSJ) corpus — 0.7% higher than using gold tags.</p><br/>
<h2>reference text</h2><p>O. Abend, R. Reichart, and A. Rappoport. 2010. Improved unsupervised POS induction through prototype discovery. In ACL. H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning dependency translation models as collections of finite-state head transducers. Computational Linguistics, 26. H. Alshawi, P.-C. Chang, and M. Ringgaard. 2011. De-  terministic statistical mapping of sentences to underspecied semantics. In IWCS. H. Alshawi. 1996. Head automata for speech translation. In ICSLP. J. K. Baker. 1979. Trainable grammars for speech recognition. In Speech Communication Papers for the 97th Meeting of the Acoustical Society of America. M. Banko and R. C. Moore. 2004. Part of speech tagging in context. In COLING. L. E. Baum. 1972. An inequality and associated maximization technique in statistical estimation for probabilistic functions ofMarkov processes. In Inequalities. R. Bod. 2006. An all-subtrees approach to unsupervised parsing. In COLING-ACL. P. F. Brown, V. J. Della Pietra, P. V. deSouza, J. C. Lai, and R. L. Mercer. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18. G. Carroll and E. Charniak. 1992. Two experiments on learning probabilistic dependency grammars from corpora. Technical report, Brown University. D. Chiang and D. M. Bikel. 2002. Recovering latent information in treebanks. In COLING. C. Christodoulopoulos, S. Goldwater, and M. Steedman. 2010. Two decades of unsupervised POS induction: How far have we come? In EMNLP. A. Clark. 2000. Inducing syntactic categories by context distribution clustering. In CoNLL-LLL.  M. Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania. B. Cramer. 2007. Limitations of current grammar induction algorithms. In ACL: Student Research. D. Das and S. Petrov. 2011. Unsupervised part-ofspeech tagging with bilingual graph-based projections. In ACL. J. R. Finkel and C. D. Manning. 2009. Joint parsing and named entity recognition. In NAACL-HLT. J. R. Finkel, T. Grenager, and C. D. Manning. 2007. The infinite tree. In ACL. J. Gao and M. Johnson. 2008. A comparison of Bayesian estimators for unsupervised Hidden Markov Model POS taggers. In EMNLP. W. P. Headden, III, D. McClosky, and E. Charniak. 2008. Evaluating unsupervised part-of-speech tagging for grammar induction. In COLING. W. P. Headden, III, M. Johnson, and D. McClosky. 2009. Improving unsupervised dependency parsing with richer contexts and smoothing. In NAACL-HLT. G. Hinton and S. Roweis. 2003. Stochastic neighbor embedding. In NIPS. R. Johansson and P. Nugues. 2007. Extended constituent-to-dependency conversion for English. In NODALIDA. D. Klein and C. D. Manning. 2004. Corpus-based induc-  tion of syntactic structure: Models of dependency and constituency. In ACL. D. Klein. 2005. The Unsupervised Learning of Natural Language Structure. Ph.D. thesis, Stanford University. T. Koo. 2010. Advances in Discriminative Dependency Parsing. Ph.D. thesis, MIT. J. Kupiec. 1992. Robust part-of-speech tagging using a hidden Markov model. Computer Speech and Language, 6. D. M. Magerman. 1995. Statistical decision-tree models for parsing. In ACL. M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19. R. McDonald, S. Petrov, and K. Hall. 2011. Multisource transfer of delexicalized dependency parsers. In EMNLP. B. Merialdo. 1994. Tagging English text with a probabilistic model. Computational Linguistics, 20. J. Nivre, J. Hall, S. K ¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In EMNLPCoNLL. M. A. Paskin. 2001 . Grammatical bigrams. In NIPS. F. Pereira, N. Tishby, and L. Lee. 1993. Distributional clustering of English words. In ACL. S. Petrov, P.-C. Chang, M. Ringgaard, and H. Alshawi.  2010. Uptraining for accurate deterministic question parsing. In EMNLP. S. Petrov, D. Das, and R. McDonald. 2011. A universal part-of-speech tagset. In ArXiv. R. Reichart and A. Rappoport. 2010. Improved fully unsupervised parsing with zoomed learning. In EMNLP. F. Sangati and W. Zuidema. 2009. Unsupervised methods for head assignments. In EACL. H. Sch u¨tze. 1995. Distributional part-of-speech tagging. In EACL. R. Schwartz, O. Abend, R. Reichart, and A. Rappoport. 2011. Neutralizing linguistically problematic annotations in unsupervised dependency parsing evaluation. In ACL. 1290 Y. Seginer. 2007a. Fast unsupervised incremental parsing. In ACL. Y. Seginer. 2007b. Learning Syntactic Structure. Ph.D. thesis, University of Amsterdam. B. Selman, H. A. Kautz, and B. Cohen. 1994. Noise strategies for improving local search. In AAAI. V. I. Spitkovsky, H. Alshawi, and D. Jurafsky. 2009. Baby Steps: How “Less is More” in unsupervised dependency parsing. In NIPS: Grammar Induction, Representation of Language and Language Learning. V. I. Spitkovsky, H. Alshawi, and D. Jurafsky. 2010a. From Baby Steps to Leapfrog: How “Less is More” in unsupervised dependency parsing. In NAACL-HLT.  V. I. Spitkovsky, H. Alshawi, D. Jurafsky, and C. D. Manning. 2010b. Viterbi training improves unsupervised dependency parsing. In CoNLL. V. I. Spitkovsky, H. Alshawi, and D. Jurafsky. 2011. Punctuation: Making a point in unsupervised dependency parsing. In CoNLL. H. Yamada and Y. Matsumoto. 2003. Statistical dependency analysis with support vector machines. In IWPT. D. Yuret. 1998. Discovery of Linguistic Relations Using Lexical Attraction. Ph.D. thesis, MIT.</p>
<br/>
<br/><br/><br/></body>
</html>
