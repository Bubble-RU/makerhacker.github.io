<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>138 emnlp-2011-Tuning as Ranking</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2011" href="../home/emnlp2011_home.html">emnlp2011</a> <a title="emnlp-2011-138" href="../emnlp2011/emnlp-2011-Tuning_as_Ranking.html">emnlp2011-138</a> <a title="emnlp-2011-138-reference" href="#">emnlp2011-138-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>138 emnlp-2011-Tuning as Ranking</h1>
<br/><p>Source: <a title="emnlp-2011-138-pdf" href="http://aclweb.org/anthology//D/D11/D11-1125.pdf">pdf</a></p><p>Author: Mark Hopkins ; Jonathan May</p><p>Abstract: We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999). Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features. Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement. It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours. We establish PROâ€™s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
