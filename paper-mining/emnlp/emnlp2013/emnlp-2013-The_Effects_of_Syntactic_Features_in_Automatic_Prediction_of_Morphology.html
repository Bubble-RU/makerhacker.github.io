<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-181" href="#">emnlp2013-181</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</h1>
<br/><p>Source: <a title="emnlp-2013-181-pdf" href="http://aclweb.org/anthology//D/D13/D13-1033.pdf">pdf</a></p><p>Author: Wolfgang Seeker ; Jonas Kuhn</p><p>Abstract: Morphology and syntax interact considerably in many languages and language processing should pay attention to these interdependencies. We analyze the effect of syntactic features when used in automatic morphology prediction on four typologically different languages. We show that predicting morphology for languages with highly ambiguous word forms profits from taking the syntactic context of words into account and results in state-ofthe-art models.</p><p>Reference: <a title="emnlp-2013-181-reference" href="../emnlp2013_reference/emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We analyze the effect of syntactic features when used in automatic morphology prediction on four typologically different languages. [sent-4, score-0.577]
</p><p>2 We show that predicting morphology for languages with highly ambiguous word forms profits from taking the syntactic context of words into account and results in state-ofthe-art models. [sent-5, score-0.69]
</p><p>3 1 Introduction In this paper, we investigate the interplay between syntax and morphology with respect to the task of assigning morphological descriptions (or tags) to each token of a sentence. [sent-6, score-1.161]
</p><p>4 Specifically, we examine the effect of syntactic information when it is integrated into the feature model of a morphological tag-  ger. [sent-7, score-0.647]
</p><p>5 We test the effect of syntactic features on four languages Czech, German, Hungarian, and Spanish and find that syntactic features improve our tagger considerably for Czech and German, but not for Hungarian and Spanish. [sent-8, score-0.563]
</p><p>6 Our analysis of constructions that show morpho-syntactic agreement suggests that syntactic features are important if the language shows frequent word form syncretisms1 that can be disambiguated by the syntactic context. [sent-9, score-0.418]
</p><p>7 The meaning of a sentence is structurally encoded –  –  1Syncretism describes the situation where a word form is ambiguous between several different morphological descriptions within its inflection paradigm. [sent-10, score-0.598]
</p><p>8 Automatic analysis of languages with rich morphology needs to pay attention to the interaction between morphology and syntax in order to arrive at suitable computational models. [sent-14, score-1.092]
</p><p>9 In many languages, two words that participate in a syntactic relation show covariance in some or all of their morphological features (so-called agreement, Corbett (2006)). [sent-19, score-0.676]
</p><p>10 The interdependency between morphology and syntax in the example thus manifests itself in the morphological disambiguation of a highly syncretic  word form because of its government or agreement relation to its respective syntactic head/dependents. [sent-44, score-1.352]
</p><p>11 4 Furthermore, not all languages show this kind of relationship between morphological forms and syntactic relation as demonstrated for German. [sent-46, score-0.768]
</p><p>12 In the remainder of the paper, we show empirically that taking syntactic information into account produces state-of-the-art models for languages with  a high interdependency between morphology and syntax. [sent-50, score-0.628]
</p><p>13 We use a simple setup, where we combine a morphological tagger and a dependency parser in a bootstrapping architecture in order to analyze the effect of syntactic information on the performance of the morphological tagger (Section 2). [sent-51, score-1.497]
</p><p>14 Using syntactic features in morphology prediction requires a syntactically annotated corpus for training a statistical parser, which may not be available for languages with few resources. [sent-52, score-0.74]
</p><p>15 We furthermore expect that the improved morphological information also improves parsing performance and present a preliminary experiment in Section 4. [sent-54, score-0.574]
</p><p>16 2  Experiments  In this section, we present a series of experiments that investigate the effect of syntactic information on the prediction of morphological features. [sent-55, score-0.688]
</p><p>17 As we will see in the experiments, it is relatively easy to predict the morphological information annotated in the Spanish data set. [sent-60, score-0.498]
</p><p>18 Czech and Hungarian represent languages with very rich morphological systems both in verbal and nominal morphological paradigms. [sent-61, score-1.151]
</p><p>19 They differ significantly in the way in which morphological information is encoded in word forms. [sent-62, score-0.498]
</p><p>20 Czech, a Slavic language, is an inflecting language, where one suffix may signal several different morphological categories simultaneously (e. [sent-63, score-0.524]
</p><p>21 In contrast, Hungarian, a Finno-Ugric language, is of the agglutinating type, where each morphological category is marked by its own morpheme. [sent-66, score-0.498]
</p><p>22 Form syncretisms emerge when the same word form is am-  biguous between several different morphological descriptions, and they are a major challenge to automatic morphological analysis. [sent-68, score-1.041]
</p><p>23 2 System Description To test our hypotheses, we implemented a tagger that assigns full morphological descriptions to each token in a sentence. [sent-81, score-0.702]
</p><p>24 The system was inspired by the  morphological tagger included in mate-tools. [sent-82, score-0.611]
</p><p>25 5 Like the tagger provided with mate-tools, it is a classifier that tags each token using the surrounding tokens in 5A collection of language independent, data-driven analysis tools for lemmatization, pos-tagging, morphological analysis, and dependency parsing: http://code. [sent-83, score-0.736]
</p><p>26 For our experiments, we use a bootstrapping approach: the parser uses the output ofthe morphology in its feature set, and the morphological tagger we  want to analyze uses the output of the parser as syntactic features. [sent-92, score-1.315]
</p><p>27 Since it is best to keep the training setting as similar as possible to the test setting, we use 10-fold jackknifing to annotate our training data with predicted morphology or syntax respectively. [sent-93, score-0.795]
</p><p>28 It is not necessary to separate partof-speech and lemma from the prediction of morphology and, in fact, many systems perform these steps simultaneously (e. [sent-108, score-0.469]
</p><p>29 Doing morphology prediction as a separate step allows us to use lemma and part-of-speech information in the feature set. [sent-112, score-0.469]
</p><p>30 form means word form, lemma is lemma, pos is part-of-speech, s1/p1 stand for suffix and prefix of length 1 (characters), tag is the morphological tag predicted by the system, 1b/1a means 1 token before/after the current token, and + marks feature conjunctions. [sent-114, score-0.7]
</p><p>31 The baseline system does not make use of any syntactic information but predicts morphological information based solely on tokens and their linear context. [sent-117, score-0.751]
</p><p>32 The case feature extracts the case value from previously assigned morphological tags. [sent-129, score-0.498]
</p><p>33 After training the baseline models, we use them to annotate the whole data set with morphological information (using 10-fold jackknifing for the training portions). [sent-133, score-0.718]
</p><p>34 At this point, all our data sets are annotated with predicted morphology from our baseline system and with syntactic information from the parser, which uses the morphological information from our baseline system in its feature set. [sent-135, score-1.184]
</p><p>35 We can now retrain our morphological tagger using features that are derived from the dependency trees provided by the parser. [sent-136, score-0.681]
</p><p>36 Note that this is not a stacking architecture, since the second system does not use the predicted morphology output from the baseline system. [sent-137, score-0.467]
</p><p>37 We extract two kinds of syntactic features: features of the syntactic head of the current token, and dev set test set all oov all oov Czech morfette90. [sent-139, score-0.588]
</p><p>38 61  Table 3: The effect of syntactic features when predicting morphological information. [sent-203, score-0.71]
</p><p>39 This is likely due to the way these languages encode morphological information and may be different for other languages. [sent-210, score-0.619]
</p><p>40 The first two are baseline experiments, where we use the off-the-shelf morphological tagger morfette (Chrupała et al. [sent-215, score-0.692]
</p><p>41 92 Spanish  our baseline pred syntax gold syntax  98. [sent-263, score-0.66]
</p><p>42 64  Table 4: The effect of syntactic features when predicting morphology using lexicons. [sent-275, score-0.57]
</p><p>43 4 Syntax vs Lexicon The current state-of-the-art in predicting morphological features makes use of morphological lexicons (e. [sent-295, score-1.059]
</p><p>44 Lexicons define the possible morphological descriptions of a word and a statistical model selects the most probable one among them. [sent-299, score-0.532]
</p><p>45 In the following experiment, we test whether the contribution of syntactic features is similar or different to the contribution of morphological lexicons. [sent-300, score-0.676]
</p><p>46 7 We extend our system from the previous experiment to include information from a morphological dictionaries. [sent-304, score-0.525]
</p><p>47 For Czech, we use the morphological analyzer distributed with the Prague Dependency Treebank 2 (Haji ˇc et al. [sent-305, score-0.498]
</p><p>48 , 2006), and for Spanish, we use the morphological analyzer included in Freeling (Carreras et al. [sent-309, score-0.498]
</p><p>49 The output of the analyzers is given to the system as features that simply record the presence of a particular morphological analysis for the current word. [sent-311, score-0.587]
</p><p>50 The system can thus use the output of any tool regardless of its annotation scheme, especially if the annotation scheme of the treebank is different from the one of the morphological analyzer. [sent-312, score-0.572]
</p><p>51 Table 4 presents the results of experiments where we add the output of the morphological analyzers to our system. [sent-313, score-0.531]
</p><p>52 As expected, the information from the morphological lexicon improves the overall performance 7Lexicons are also often used to speed up processing considerably by restricting the search space of the statistical model. [sent-317, score-0.498]
</p><p>53 This shows that even with the considerable amounts of training data available nowadays, rule-based morphological analyzers are important resources for morphological description (cf. [sent-320, score-1.087]
</p><p>54 The contribution of syntactic features in German and Czech is almost the same as in the previous experiment, indicating that the syntactic features contribute information that is orthogonal to that of the morphological lexicon. [sent-322, score-0.854]
</p><p>55 The lexicon provides lexical knowledge about a word form, while the syntactic features provide the syntactic context that is needed in German and Czech to decide on the right morphological tag. [sent-323, score-0.825]
</p><p>56 5 Language Differences From the previous experiments, we conclude that  syntactic features help in the prediction of morphology for Czech and German, but not for Hungarian and Spanish. [sent-325, score-0.577]
</p><p>57 Agreement is a phenomenon where morphology and syntax strongly interact. [sent-328, score-0.579]
</p><p>58 If the syntactic information helps with predicting morphological information, we expect this to be particularly helpful with getting agreement right. [sent-330, score-0.772]
</p><p>59 We compare the baseline system that does not use any syntactic information with the output of the morphological tagger that uses the gold syntax. [sent-340, score-0.861]
</p><p>60 68 Table 5: Agreement counts in morphological annotation compared between the baseline system and the oracle system using gold syntax. [sent-369, score-0.653]
</p><p>61 For Hungarian, the reason lies within the inflectional paradigms of the language, which do not show any form syncretism, mean-  ing that word forms in Hungarian are usually not ambiguous within one morphological category (e. [sent-374, score-0.554]
</p><p>62 Making a morphological tag prediction, however, is difficult only if the word form itself is ambiguous between several morphological tags. [sent-377, score-1.024]
</p><p>63 Due to the way featurama works, we cannot use features from the morphological tags (the dynamic features). [sent-388, score-0.617]
</p><p>64 Without a treebank to train the parser, the morphology cannot profit from syntactic features. [sent-408, score-0.584]
</p><p>65 # of sentences in training data of syntactic parser Figure 2: Dependency between amount of training data for syntactic parser and quality of morphological prediction. [sent-411, score-1.02]
</p><p>66 to provide a parsing quality that is sufficient for the morphological tagger. [sent-412, score-0.574]
</p><p>67 The morphological tagger is then trained on the full training set and applied to development and test set. [sent-418, score-0.618]
</p><p>68 Figure 2 shows the dependency between the amount of training data given to the parser and the quality of the morphological tagger using syntactic features provided by this parser. [sent-419, score-0.942]
</p><p>69 For both languages, German and Czech, we find that already 1,000 sentences are enough training data for the parser to provide useful syntactic information to the morphological tagger. [sent-421, score-0.759]
</p><p>70 We conclude that using syntactic features for morphological prediction is viable even if there is only small amounts of syntactic data available to train the parser. [sent-423, score-0.897]
</p><p>71 Table 8 shows the performance of the morphological tagger when using the output of both parsers as syntactic features. [sent-448, score-0.733]
</p><p>72 For Czech, both parsers seem to supply similar information to the morphological tagger, while for German, using the full parser is clearly better. [sent-449, score-0.644]
</p><p>73 In both cases, the morphological tagger outperforms the models that do not use syntactic information (cf. [sent-450, score-0.733]
</p><p>74 We conclude that even with a simple parser and little training data, the morphology can make use of syntactic information to some extent. [sent-453, score-0.619]
</p><p>75 50 Table 8: Simple parser vs full parser morphological quality. [sent-478, score-0.756]
</p><p>76 The parsing models were trained on the first 5,000 sentences of the training data, the morphological tagger was trained on the full training set. [sent-479, score-0.694]
</p><p>77 In the previous sections, we show that syntactic information improves a model for predicting morphology for Czech and German, where syntax and morphology interact considerably. [sent-481, score-1.12]
</p><p>78 A natural question then is whether the improvement also occurs in the other direction, namely whether the improved morphology also leads to better parsing models. [sent-482, score-0.434]
</p><p>79 In the previous experiments, we run a 10-fold jackknifing process to annotate the training data with morphological information using no syntactic features and afterwards use jackknifing with the parser to annotate syntax. [sent-483, score-1.142]
</p><p>80 We can apply the same process once more with the morphology prediction in order to annotate the training data with morphological information that is predicted using the syntactic features. [sent-485, score-1.145]
</p><p>81 A parser trained on this data will then use the improved morphology as features. [sent-486, score-0.47]
</p><p>82 If the improved morphology has an impact on the parser, the quality of the second parsing model should then be superior to the first parsing  model, which uses the morphology predicted without syntactic information. [sent-487, score-1.056]
</p><p>83 Note that for the following experiments, neither morphology model uses the morphological lexicon. [sent-488, score-0.856]
</p><p>84 Table 9 presents the evaluation of the two parsing models (one using morphology without syntactic features, the other one using the improved morphology). [sent-489, score-0.583]
</p><p>85 34 Table 9: Impact of the improved morphology on the quality of the dependency parser for Czech and German. [sent-507, score-0.538]
</p><p>86 However, the question how to make use of the improved morphology in parsing clearly needs more research in the future. [sent-511, score-0.434]
</p><p>87 The most common approach is the combination of a morphological lexicon with a statistical disambiguation model (Hakkani-T u¨r et al. [sent-514, score-0.533]
</p><p>88 (2010), who annotate a treebank with morphological information after the syntax had been annotated already. [sent-520, score-0.826]
</p><p>89 The system used a finite-state morphology to propose a set of candidate tags for each word, which is then further restricted using hand-crafted rules over the already available syntax tree. [sent-521, score-0.606]
</p><p>90 The problem of modeling the interaction between morphology and syntax has recently attracted some attention in the SPMRL workshops (Tsarfaty et al. [sent-526, score-0.579]
</p><p>91 (2013) show that case information is the most helpful morphological feature for parsing Arabic, but only if it is given as gold information, whereas using case information from an automatic system may even harm the performance. [sent-530, score-0.659]
</p><p>92 For Hebrew, this problem has also been addressed by jointly modeling segmentation, morphological prediction, and syntax (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Goldberg and Elhadad, 2013). [sent-535, score-0.719]
</p><p>93 6  Conclusion  In this paper, we have demonstrated that using syntactic information for predicting morphological information is helpful if the language shows form syncretism in combination with morphosyntactic phenomena like agreement. [sent-536, score-0.812]
</p><p>94 We also showed that  only small amounts of training data for a statistical parser would be needed to improve the morphological tagger. [sent-538, score-0.641]
</p><p>95 Making use of the improved morphology in the dependency parser is not straight-forward and requires more investigation in the future. [sent-539, score-0.538]
</p><p>96 Modeling the interaction between morphology and syntax is important for building successful parsing pipelines for languages with free word order and rich morphology. [sent-540, score-0.81]
</p><p>97 Word segmentation, unknown-word resolution, and morphological agreement in a hebrew parsing system. [sent-629, score-0.692]
</p><p>98 A single generative model for joint morphological segmentation and syntactic parsing. [sent-633, score-0.647]
</p><p>99 A discriminative model for joint morphological disambiguation and dependency parsing. [sent-669, score-0.601]
</p><p>100 A syntax-first approach to 344 high-quality morphological analysis and lemma disambiguation for the tba-d/z treebank. [sent-732, score-0.603]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('morphological', 0.498), ('morphology', 0.358), ('hungarian', 0.303), ('czech', 0.258), ('syntax', 0.221), ('german', 0.193), ('syntactic', 0.149), ('haji', 0.146), ('spanish', 0.134), ('languages', 0.121), ('pred', 0.117), ('jackknifing', 0.117), ('parser', 0.112), ('oov', 0.094), ('agreement', 0.091), ('featurama', 0.09), ('tagger', 0.086), ('parsing', 0.076), ('tsarfaty', 0.075), ('goldberg', 0.073), ('jan', 0.072), ('lemma', 0.07), ('dependency', 0.068), ('morphosyntactic', 0.066), ('syncretism', 0.065), ('morfette', 0.065), ('annotate', 0.06), ('vincze', 0.059), ('seeker', 0.059), ('gold', 0.058), ('uas', 0.057), ('token', 0.05), ('veronika', 0.048), ('np', 0.047), ('treebank', 0.047), ('las', 0.046), ('corbett', 0.045), ('reut', 0.045), ('spoustov', 0.045), ('syncretisms', 0.045), ('dev', 0.045), ('daughter', 0.044), ('pos', 0.043), ('baseline', 0.043), ('syntactically', 0.042), ('elra', 0.042), ('tiger', 0.042), ('prediction', 0.041), ('morphologically', 0.04), ('static', 0.04), ('jonas', 0.039), ('nek', 0.039), ('predicted', 0.039), ('gender', 0.038), ('yoav', 0.038), ('inflection', 0.038), ('wolfgang', 0.036), ('ld', 0.036), ('chrupa', 0.036), ('disambiguation', 0.035), ('rich', 0.034), ('full', 0.034), ('tokens', 0.034), ('predicting', 0.034), ('descriptions', 0.034), ('kuhn', 0.033), ('analyzers', 0.033), ('noun', 0.031), ('num', 0.031), ('modern', 0.031), ('amounts', 0.031), ('attila', 0.03), ('catholic', 0.03), ('greville', 0.03), ('hohensee', 0.03), ('profit', 0.03), ('regionen', 0.03), ('sentencebased', 0.03), ('votrubec', 0.03), ('bohnet', 0.03), ('features', 0.029), ('pages', 0.029), ('gen', 0.028), ('inflectional', 0.028), ('ambiguous', 0.028), ('head', 0.028), ('hebrew', 0.027), ('cambridge', 0.027), ('resources', 0.027), ('european', 0.027), ('system', 0.027), ('determiner', 0.026), ('petr', 0.026), ('sima', 0.026), ('spmrl', 0.026), ('dmor', 0.026), ('freeling', 0.026), ('inflecting', 0.026), ('szeged', 0.026), ('zsibrita', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="181-tfidf-1" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>Author: Wolfgang Seeker ; Jonas Kuhn</p><p>Abstract: Morphology and syntax interact considerably in many languages and language processing should pay attention to these interdependencies. We analyze the effect of syntactic features when used in automatic morphology prediction on four typologically different languages. We show that predicting morphology for languages with highly ambiguous word forms profits from taking the syntactic context of words into account and results in state-ofthe-art models.</p><p>2 0.36173484 <a title="181-tfidf-2" href="./emnlp-2013-Exploring_the_Utility_of_Joint_Morphological_and_Syntactic_Learning_from_Child-directed_Speech.html">83 emnlp-2013-Exploring the Utility of Joint Morphological and Syntactic Learning from Child-directed Speech</a></p>
<p>Author: Stella Frank ; Frank Keller ; Sharon Goldwater</p><p>Abstract: Frank Keller keller@ inf .ed .ac .uk Sharon Goldwater sgwater@ inf .ed .ac .uk ILCC, School of Informatics University of Edinburgh Edinburgh, EH8 9AB, UK interactions are often (but not necessarily) synergisChildren learn various levels of linguistic structure concurrently, yet most existing models of language acquisition deal with only a single level of structure, implicitly assuming a sequential learning process. Developing models that learn multiple levels simultaneously can provide important insights into how these levels might interact synergistically dur- ing learning. Here, we present a model that jointly induces syntactic categories and morphological segmentations by combining two well-known models for the individual tasks. We test on child-directed utterances in English and Spanish and compare to single-task baselines. In the morphologically poorer language (English), the model improves morphological segmentation, while in the morphologically richer language (Spanish), it leads to better syntactic categorization. These results provide further evidence that joint learning is useful, but also suggest that the benefits may be different for typologically different languages.</p><p>3 0.34592342 <a title="181-tfidf-3" href="./emnlp-2013-Efficient_Higher-Order_CRFs_for_Morphological_Tagging.html">70 emnlp-2013-Efficient Higher-Order CRFs for Morphological Tagging</a></p>
<p>Author: Thomas Mueller ; Helmut Schmid ; Hinrich Schutze</p><p>Abstract: Training higher-order conditional random fields is prohibitive for huge tag sets. We present an approximated conditional random field using coarse-to-fine decoding and early updating. We show that our implementation yields fast and accurate morphological taggers across six languages with different morphological properties and that across languages higher-order models give significant improvements over 1st-order models.</p><p>4 0.27438387 <a title="181-tfidf-4" href="./emnlp-2013-Translating_into_Morphologically_Rich_Languages_with_Synthetic_Phrases.html">186 emnlp-2013-Translating into Morphologically Rich Languages with Synthetic Phrases</a></p>
<p>Author: Victor Chahuneau ; Eva Schlinger ; Noah A. Smith ; Chris Dyer</p><p>Abstract: Translation into morphologically rich languages is an important but recalcitrant problem in MT. We present a simple and effective approach that deals with the problem in two phases. First, a discriminative model is learned to predict inflections of target words from rich source-side annotations. Then, this model is used to create additional sentencespecific word- and phrase-level translations that are added to a standard translation model as “synthetic” phrases. Our approach relies on morphological analysis of the target language, but we show that an unsupervised Bayesian model of morphology can successfully be used in place of a supervised analyzer. We report significant improvements in translation quality when translating from English to Russian, Hebrew and Swahili.</p><p>5 0.26360014 <a title="181-tfidf-5" href="./emnlp-2013-Automatic_Extraction_of_Morphological_Lexicons_from_Morphologically_Annotated_Corpora.html">30 emnlp-2013-Automatic Extraction of Morphological Lexicons from Morphologically Annotated Corpora</a></p>
<p>Author: Ramy Eskander ; Nizar Habash ; Owen Rambow</p><p>Abstract: We present a method for automatically learning inflectional classes and associated lemmas from morphologically annotated corpora. The method consists of a core languageindependent algorithm, which can be optimized for specific languages. The method is demonstrated on Egyptian Arabic and German, two morphologically rich languages. Our best method for Egyptian Arabic provides an error reduction of 55.6% over a simple baseline; our best method for German achieves a 66.7% error reduction.</p><p>6 0.19559953 <a title="181-tfidf-6" href="./emnlp-2013-Adaptor_Grammars_for_Learning_Non-Concatenative_Morphology.html">19 emnlp-2013-Adaptor Grammars for Learning Non-Concatenative Morphology</a></p>
<p>7 0.10078106 <a title="181-tfidf-7" href="./emnlp-2013-Source-Side_Classifier_Preordering_for_Machine_Translation.html">175 emnlp-2013-Source-Side Classifier Preordering for Machine Translation</a></p>
<p>8 0.096104085 <a title="181-tfidf-8" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>9 0.091062151 <a title="181-tfidf-9" href="./emnlp-2013-Improving_Statistical_Machine_Translation_with_Word_Class_Models.html">104 emnlp-2013-Improving Statistical Machine Translation with Word Class Models</a></p>
<p>10 0.088244133 <a title="181-tfidf-10" href="./emnlp-2013-Dependency-Based_Decipherment_for_Resource-Limited_Machine_Translation.html">57 emnlp-2013-Dependency-Based Decipherment for Resource-Limited Machine Translation</a></p>
<p>11 0.086947739 <a title="181-tfidf-11" href="./emnlp-2013-Factored_Soft_Source_Syntactic_Constraints_for_Hierarchical_Machine_Translation.html">84 emnlp-2013-Factored Soft Source Syntactic Constraints for Hierarchical Machine Translation</a></p>
<p>12 0.083166435 <a title="181-tfidf-12" href="./emnlp-2013-Ubertagging%3A_Joint_Segmentation_and_Supertagging_for_English.html">190 emnlp-2013-Ubertagging: Joint Segmentation and Supertagging for English</a></p>
<p>13 0.070695534 <a title="181-tfidf-13" href="./emnlp-2013-Monolingual_Marginal_Matching_for_Translation_Model_Adaptation.html">135 emnlp-2013-Monolingual Marginal Matching for Translation Model Adaptation</a></p>
<p>14 0.067219734 <a title="181-tfidf-14" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<p>15 0.066256128 <a title="181-tfidf-15" href="./emnlp-2013-Dynamic_Feature_Selection_for_Dependency_Parsing.html">66 emnlp-2013-Dynamic Feature Selection for Dependency Parsing</a></p>
<p>16 0.064001955 <a title="181-tfidf-16" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>17 0.061971001 <a title="181-tfidf-17" href="./emnlp-2013-Dependency_Language_Models_for_Sentence_Completion.html">58 emnlp-2013-Dependency Language Models for Sentence Completion</a></p>
<p>18 0.059917822 <a title="181-tfidf-18" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>19 0.05905851 <a title="181-tfidf-19" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>20 0.054409247 <a title="181-tfidf-20" href="./emnlp-2013-Combining_PCFG-LA_Models_with_Dual_Decomposition%3A_A_Case_Study_with_Function_Labels_and_Binarization.html">50 emnlp-2013-Combining PCFG-LA Models with Dual Decomposition: A Case Study with Function Labels and Binarization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.22), (1, -0.109), (2, 0.015), (3, -0.177), (4, -0.479), (5, -0.133), (6, -0.206), (7, -0.145), (8, 0.083), (9, -0.122), (10, 0.038), (11, 0.012), (12, -0.045), (13, -0.112), (14, -0.064), (15, -0.016), (16, -0.111), (17, 0.064), (18, -0.075), (19, -0.038), (20, 0.063), (21, 0.06), (22, -0.1), (23, 0.038), (24, 0.049), (25, 0.013), (26, -0.038), (27, 0.04), (28, -0.022), (29, 0.079), (30, 0.04), (31, 0.023), (32, 0.07), (33, 0.063), (34, -0.021), (35, -0.062), (36, 0.001), (37, 0.003), (38, 0.035), (39, 0.003), (40, 0.048), (41, 0.076), (42, 0.037), (43, 0.01), (44, -0.052), (45, 0.043), (46, 0.064), (47, 0.045), (48, -0.005), (49, -0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96167725 <a title="181-lsi-1" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>Author: Wolfgang Seeker ; Jonas Kuhn</p><p>Abstract: Morphology and syntax interact considerably in many languages and language processing should pay attention to these interdependencies. We analyze the effect of syntactic features when used in automatic morphology prediction on four typologically different languages. We show that predicting morphology for languages with highly ambiguous word forms profits from taking the syntactic context of words into account and results in state-ofthe-art models.</p><p>2 0.77962708 <a title="181-lsi-2" href="./emnlp-2013-Exploring_the_Utility_of_Joint_Morphological_and_Syntactic_Learning_from_Child-directed_Speech.html">83 emnlp-2013-Exploring the Utility of Joint Morphological and Syntactic Learning from Child-directed Speech</a></p>
<p>Author: Stella Frank ; Frank Keller ; Sharon Goldwater</p><p>Abstract: Frank Keller keller@ inf .ed .ac .uk Sharon Goldwater sgwater@ inf .ed .ac .uk ILCC, School of Informatics University of Edinburgh Edinburgh, EH8 9AB, UK interactions are often (but not necessarily) synergisChildren learn various levels of linguistic structure concurrently, yet most existing models of language acquisition deal with only a single level of structure, implicitly assuming a sequential learning process. Developing models that learn multiple levels simultaneously can provide important insights into how these levels might interact synergistically dur- ing learning. Here, we present a model that jointly induces syntactic categories and morphological segmentations by combining two well-known models for the individual tasks. We test on child-directed utterances in English and Spanish and compare to single-task baselines. In the morphologically poorer language (English), the model improves morphological segmentation, while in the morphologically richer language (Spanish), it leads to better syntactic categorization. These results provide further evidence that joint learning is useful, but also suggest that the benefits may be different for typologically different languages.</p><p>3 0.76827443 <a title="181-lsi-3" href="./emnlp-2013-Efficient_Higher-Order_CRFs_for_Morphological_Tagging.html">70 emnlp-2013-Efficient Higher-Order CRFs for Morphological Tagging</a></p>
<p>Author: Thomas Mueller ; Helmut Schmid ; Hinrich Schutze</p><p>Abstract: Training higher-order conditional random fields is prohibitive for huge tag sets. We present an approximated conditional random field using coarse-to-fine decoding and early updating. We show that our implementation yields fast and accurate morphological taggers across six languages with different morphological properties and that across languages higher-order models give significant improvements over 1st-order models.</p><p>4 0.76190072 <a title="181-lsi-4" href="./emnlp-2013-Automatic_Extraction_of_Morphological_Lexicons_from_Morphologically_Annotated_Corpora.html">30 emnlp-2013-Automatic Extraction of Morphological Lexicons from Morphologically Annotated Corpora</a></p>
<p>Author: Ramy Eskander ; Nizar Habash ; Owen Rambow</p><p>Abstract: We present a method for automatically learning inflectional classes and associated lemmas from morphologically annotated corpora. The method consists of a core languageindependent algorithm, which can be optimized for specific languages. The method is demonstrated on Egyptian Arabic and German, two morphologically rich languages. Our best method for Egyptian Arabic provides an error reduction of 55.6% over a simple baseline; our best method for German achieves a 66.7% error reduction.</p><p>5 0.70668966 <a title="181-lsi-5" href="./emnlp-2013-Translating_into_Morphologically_Rich_Languages_with_Synthetic_Phrases.html">186 emnlp-2013-Translating into Morphologically Rich Languages with Synthetic Phrases</a></p>
<p>Author: Victor Chahuneau ; Eva Schlinger ; Noah A. Smith ; Chris Dyer</p><p>Abstract: Translation into morphologically rich languages is an important but recalcitrant problem in MT. We present a simple and effective approach that deals with the problem in two phases. First, a discriminative model is learned to predict inflections of target words from rich source-side annotations. Then, this model is used to create additional sentencespecific word- and phrase-level translations that are added to a standard translation model as “synthetic” phrases. Our approach relies on morphological analysis of the target language, but we show that an unsupervised Bayesian model of morphology can successfully be used in place of a supervised analyzer. We report significant improvements in translation quality when translating from English to Russian, Hebrew and Swahili.</p><p>6 0.61821526 <a title="181-lsi-6" href="./emnlp-2013-Adaptor_Grammars_for_Learning_Non-Concatenative_Morphology.html">19 emnlp-2013-Adaptor Grammars for Learning Non-Concatenative Morphology</a></p>
<p>7 0.54998451 <a title="181-lsi-7" href="./emnlp-2013-Ubertagging%3A_Joint_Segmentation_and_Supertagging_for_English.html">190 emnlp-2013-Ubertagging: Joint Segmentation and Supertagging for English</a></p>
<p>8 0.49294972 <a title="181-lsi-8" href="./emnlp-2013-Assembling_the_Kazakh_Language_Corpus.html">26 emnlp-2013-Assembling the Kazakh Language Corpus</a></p>
<p>9 0.42937842 <a title="181-lsi-9" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>10 0.39853278 <a title="181-lsi-10" href="./emnlp-2013-With_Blinkers_on%3A_Robust_Prediction_of_Eye_Movements_across_Readers.html">203 emnlp-2013-With Blinkers on: Robust Prediction of Eye Movements across Readers</a></p>
<p>11 0.37150282 <a title="181-lsi-11" href="./emnlp-2013-Source-Side_Classifier_Preordering_for_Machine_Translation.html">175 emnlp-2013-Source-Side Classifier Preordering for Machine Translation</a></p>
<p>12 0.36757514 <a title="181-lsi-12" href="./emnlp-2013-Joint_Parsing_and_Disfluency_Detection_in_Linear_Time.html">116 emnlp-2013-Joint Parsing and Disfluency Detection in Linear Time</a></p>
<p>13 0.33681175 <a title="181-lsi-13" href="./emnlp-2013-Dynamic_Feature_Selection_for_Dependency_Parsing.html">66 emnlp-2013-Dynamic Feature Selection for Dependency Parsing</a></p>
<p>14 0.32080019 <a title="181-lsi-14" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<p>15 0.28118873 <a title="181-lsi-15" href="./emnlp-2013-Dependency-Based_Decipherment_for_Resource-Limited_Machine_Translation.html">57 emnlp-2013-Dependency-Based Decipherment for Resource-Limited Machine Translation</a></p>
<p>16 0.27554962 <a title="181-lsi-16" href="./emnlp-2013-Combining_PCFG-LA_Models_with_Dual_Decomposition%3A_A_Case_Study_with_Function_Labels_and_Binarization.html">50 emnlp-2013-Combining PCFG-LA Models with Dual Decomposition: A Case Study with Function Labels and Binarization</a></p>
<p>17 0.27168941 <a title="181-lsi-17" href="./emnlp-2013-Word_Level_Language_Identification_in_Online_Multilingual_Communication.html">204 emnlp-2013-Word Level Language Identification in Online Multilingual Communication</a></p>
<p>18 0.26369408 <a title="181-lsi-18" href="./emnlp-2013-Dependency_Language_Models_for_Sentence_Completion.html">58 emnlp-2013-Dependency Language Models for Sentence Completion</a></p>
<p>19 0.25427485 <a title="181-lsi-19" href="./emnlp-2013-Improving_Statistical_Machine_Translation_with_Word_Class_Models.html">104 emnlp-2013-Improving Statistical Machine Translation with Word Class Models</a></p>
<p>20 0.24824253 <a title="181-lsi-20" href="./emnlp-2013-Shift-Reduce_Word_Reordering_for_Machine_Translation.html">171 emnlp-2013-Shift-Reduce Word Reordering for Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.041), (11, 0.194), (14, 0.051), (18, 0.032), (22, 0.036), (30, 0.054), (45, 0.016), (50, 0.012), (51, 0.185), (58, 0.012), (59, 0.014), (66, 0.101), (71, 0.019), (75, 0.027), (77, 0.079), (90, 0.013), (96, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.80364561 <a title="181-lda-1" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>Author: Xinjie Zhou ; Xiaojun Wan ; Jianguo Xiao</p><p>Abstract: Microblog messages pose severe challenges for current sentiment analysis techniques due to some inherent characteristics such as the length limit and informal writing style. In this paper, we study the problem of extracting opinion targets of Chinese microblog messages. Such fine-grained word-level task has not been well investigated in microblogs yet. We propose an unsupervised label propagation algorithm to address the problem. The opinion targets of all messages in a topic are collectively extracted based on the assumption that similar messages may focus on similar opinion targets. Topics in microblogs are identified by hashtags or using clustering algorithms. Experimental results on Chinese microblogs show the effectiveness of our framework and algorithms.</p><p>same-paper 2 0.8003242 <a title="181-lda-2" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>Author: Wolfgang Seeker ; Jonas Kuhn</p><p>Abstract: Morphology and syntax interact considerably in many languages and language processing should pay attention to these interdependencies. We analyze the effect of syntactic features when used in automatic morphology prediction on four typologically different languages. We show that predicting morphology for languages with highly ambiguous word forms profits from taking the syntactic context of words into account and results in state-ofthe-art models.</p><p>3 0.7238217 <a title="181-lda-3" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>Author: Jun-Ping Ng ; Min-Yen Kan ; Ziheng Lin ; Wei Feng ; Bin Chen ; Jian Su ; Chew Lim Tan</p><p>Abstract: In this paper we classify the temporal relations between pairs of events on an article-wide basis. This is in contrast to much of the existing literature which focuses on just event pairs which are found within the same or adjacent sentences. To achieve this, we leverage on discourse analysis as we believe that it provides more useful semantic information than typical lexico-syntactic features. We propose the use of several discourse analysis frameworks, including 1) Rhetorical Structure Theory (RST), 2) PDTB-styled discourse relations, and 3) topical text segmentation. We explain how features derived from these frameworks can be effectively used with support vector machines (SVM) paired with convolution kernels. Experiments show that our proposal is effective in improving on the state-of-the-art significantly by as much as 16% in terms of F1, even if we only adopt less-than-perfect automatic discourse analyzers and parsers. Making use of more accurate discourse analysis can further boost gains to 35%.</p><p>4 0.71350312 <a title="181-lda-4" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>5 0.71161449 <a title="181-lda-5" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>Author: Kuzman Ganchev ; Dipanjan Das</p><p>Abstract: We present a framework for cross-lingual transfer of sequence information from a resource-rich source language to a resourceimpoverished target language that incorporates soft constraints via posterior regularization. To this end, we use automatically word aligned bitext between the source and target language pair, and learn a discriminative conditional random field model on the target side. Our posterior regularization constraints are derived from simple intuitions about the task at hand and from cross-lingual alignment information. We show improvements over strong baselines for two tasks: part-of-speech tagging and namedentity segmentation.</p><p>6 0.7087121 <a title="181-lda-6" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>7 0.70834035 <a title="181-lda-7" href="./emnlp-2013-Monolingual_Marginal_Matching_for_Translation_Model_Adaptation.html">135 emnlp-2013-Monolingual Marginal Matching for Translation Model Adaptation</a></p>
<p>8 0.7060166 <a title="181-lda-8" href="./emnlp-2013-Efficient_Higher-Order_CRFs_for_Morphological_Tagging.html">70 emnlp-2013-Efficient Higher-Order CRFs for Morphological Tagging</a></p>
<p>9 0.70457113 <a title="181-lda-9" href="./emnlp-2013-Bilingual_Word_Embeddings_for_Phrase-Based_Machine_Translation.html">38 emnlp-2013-Bilingual Word Embeddings for Phrase-Based Machine Translation</a></p>
<p>10 0.70435894 <a title="181-lda-10" href="./emnlp-2013-Translating_into_Morphologically_Rich_Languages_with_Synthetic_Phrases.html">186 emnlp-2013-Translating into Morphologically Rich Languages with Synthetic Phrases</a></p>
<p>11 0.70170736 <a title="181-lda-11" href="./emnlp-2013-Dependency-Based_Decipherment_for_Resource-Limited_Machine_Translation.html">57 emnlp-2013-Dependency-Based Decipherment for Resource-Limited Machine Translation</a></p>
<p>12 0.69795513 <a title="181-lda-12" href="./emnlp-2013-Interactive_Machine_Translation_using_Hierarchical_Translation_Models.html">107 emnlp-2013-Interactive Machine Translation using Hierarchical Translation Models</a></p>
<p>13 0.69692558 <a title="181-lda-13" href="./emnlp-2013-Automatic_Extraction_of_Morphological_Lexicons_from_Morphologically_Annotated_Corpora.html">30 emnlp-2013-Automatic Extraction of Morphological Lexicons from Morphologically Annotated Corpora</a></p>
<p>14 0.69675779 <a title="181-lda-14" href="./emnlp-2013-What_is_Hidden_among_Translation_Rules.html">201 emnlp-2013-What is Hidden among Translation Rules</a></p>
<p>15 0.6959734 <a title="181-lda-15" href="./emnlp-2013-Exploring_the_Utility_of_Joint_Morphological_and_Syntactic_Learning_from_Child-directed_Speech.html">83 emnlp-2013-Exploring the Utility of Joint Morphological and Syntactic Learning from Child-directed Speech</a></p>
<p>16 0.69511282 <a title="181-lda-16" href="./emnlp-2013-Source-Side_Classifier_Preordering_for_Machine_Translation.html">175 emnlp-2013-Source-Side Classifier Preordering for Machine Translation</a></p>
<p>17 0.69418508 <a title="181-lda-17" href="./emnlp-2013-Where_Not_to_Eat%3F_Improving_Public_Policy_by_Predicting_Hygiene_Inspections_Using_Online_Reviews.html">202 emnlp-2013-Where Not to Eat? Improving Public Policy by Predicting Hygiene Inspections Using Online Reviews</a></p>
<p>18 0.69360197 <a title="181-lda-18" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>19 0.69180965 <a title="181-lda-19" href="./emnlp-2013-Translation_with_Source_Constituency_and_Dependency_Trees.html">187 emnlp-2013-Translation with Source Constituency and Dependency Trees</a></p>
<p>20 0.69029063 <a title="181-lda-20" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
