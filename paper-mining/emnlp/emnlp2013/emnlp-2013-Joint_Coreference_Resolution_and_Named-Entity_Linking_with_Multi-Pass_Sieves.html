<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-112" href="#">emnlp2013-112</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</h1>
<br/><p>Source: <a title="emnlp-2013-112-pdf" href="http://aclweb.org/anthology//D/D13/D13-1029.pdf">pdf</a></p><p>Author: Hannaneh Hajishirzi ; Leila Zilles ; Daniel S. Weld ; Luke Zettlemoyer</p><p>Abstract: Many errors in coreference resolution come from semantic mismatches due to inadequate world knowledge. Errors in named-entity linking (NEL), on the other hand, are often caused by superficial modeling of entity context. This paper demonstrates that these two tasks are complementary. We introduce NECO, a new model for named entity linking and coreference resolution, which solves both problems jointly, reducing the errors made on each. NECO extends the Stanford deterministic coreference system by automatically linking mentions to Wikipedia and introducing new NEL-informed mention-merging sieves. Linking improves mention-detection and enables new semantic attributes to be incorporated from Freebase, while coreference provides better context modeling by propagating named-entity links within mention clusters. Experiments show consistent improve- ments across a number of datasets and experimental conditions, including over 11% reduction in MUC coreference error and nearly 21% reduction in F1 NEL error on ACE 2004 newswire data.</p><p>Reference: <a title="emnlp-2013-112-reference" href="../emnlp2013_reference/emnlp-2013-Joint_Coreference_Resolution_and_Named-Entity_Linking_with_Multi-Pass_Sieves_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu z l s  ,  ,  ,  Abstract Many errors in coreference resolution come from semantic mismatches due to inadequate world knowledge. [sent-4, score-0.432]
</p><p>2 We introduce NECO, a new model for named entity linking and coreference resolution, which solves both problems jointly, reducing the errors made on each. [sent-7, score-0.569]
</p><p>3 NECO extends the Stanford deterministic coreference system by automatically linking mentions to Wikipedia and introducing new NEL-informed mention-merging sieves. [sent-8, score-0.658]
</p><p>4 Linking improves mention-detection and enables new semantic attributes to be incorporated from Freebase, while coreference provides better context modeling by propagating named-entity links within mention clusters. [sent-9, score-0.724]
</p><p>5 Experiments show consistent improve-  ments across a number of datasets and experimental conditions, including over 11% reduction in MUC coreference error and nearly 21% reduction in F1 NEL error on ACE 2004 newswire data. [sent-10, score-0.329]
</p><p>6 Coreference resolution is the task of determining when two textual mentions name the same individ289  g[Mranicdhoa eple Eni nsnge ro]f1 [a[nHdo [nDgo Knoanldg] T3sDanisgn]e2yalnan do]u4ncye dst ehre[dfaayn. [sent-13, score-0.311]
</p><p>7 d [the President]2and welcomed Figure 1: A text passage illustrating interactions between coreference resolution and NEL. [sent-15, score-0.399]
</p><p>8 The biggest challenge in coreference resolution accounting for 42% of errors in the stateof-the-art Stanford system is the inability to reason effectively about background semantic knowledge (Lee et al. [sent-17, score-0.432]
</p><p>9 Named-entity linking (NEL) is the task of matching textual mentions to corresponding entities in a knowledge base, such as Wikipedia or Freebase. [sent-25, score-0.385]
</p><p>10 Such links provide rich sources of semantic knowledge about entity attributes Freebase includes president as Tsang’s title and Di sneyland as having the attribute park. [sent-26, score-0.361]
</p><p>11 But NEL is itself a challenging problem, and finding the correct link requires disambiguating based on the mention string and often non-local contextual features. [sent-27, score-0.296]
</p><p>12 —  —  —  However, these mentions could be clustered with a coreference model, allowing for improved NEL through link propagation from the easier mentions. [sent-29, score-0.562]
</p><p>13 hc o2d0s1 i3n A Nsastoucria lti Loan fgoura Cgoem Ppruotcaetsiosin agl, L piang eusis 2t8ic9s–29 , We present NECO, a new algorithm for jointly solving named entity linking and coreference resolution. [sent-32, score-0.536]
</p><p>14 NECO extends the Stanford’s sieve-based model, in which a high recall mention detection phase is followed by a sequence of cluster merging operations ordered by decreasing precision (Raghunathan et al. [sent-35, score-0.378]
</p><p>15 We use NEL to increase recall during the mention detection phase and introduce two new cluster-merging sieves, which compare the Freebase attributes of entities. [sent-39, score-0.387]
</p><p>16 NECO also improves NEL by initially favoring high precision linking results and then propagating links and attributes as clusters are formed. [sent-40, score-0.478]
</p><p>17 1 Background  We make use of existing models for coreference res-  olution and named entity linking. [sent-50, score-0.385]
</p><p>18 1  Coreference Resolution  Coreference resolution is the the task of identifying all text spans (called mentions) that refer to the same entity, forming mention clusters. [sent-56, score-0.331]
</p><p>19 Stanford’s Sieve Model is a state-of-the-art coreference resolver comprising a pipeline of “sieves” that merge coreferent mentions according to deterministic rules. [sent-57, score-0.584]
</p><p>20 2 Named Entity Linking Named-entity linking (NEL) is the task of identifying mentions in a text and linking them to the entity they name in a knowledge base, usually Wikipedia. [sent-62, score-0.573]
</p><p>21 WikipediaMiner links mentions based on a notion of semantic similarity to Wikipedia pages, considering all substrings up to a fixed length. [sent-65, score-0.297]
</p><p>22 The semantic scoring function includes ngram statistics and also counts shared links to other unambiguous mentions in the text. [sent-67, score-0.317]
</p><p>23 }p }b e b teh teh em NenEtiLon osu mi tf mromen tcioornes,fe mrence mention detection (c) Let M ← =MC {mR ∪| M i =NE 1L. [sent-80, score-0.282]
</p><p>24 If all rules of sieve S are satisfied for clu)st 6=ers l( ci and cj A. [sent-100, score-0.388]
</p><p>25 or Cef ←ere nCce ∪ c {lcust}er \s {Cc and} linked Wikipedia pages l(ci)∀ci ∈ C • ••  Figure 2: NECO: A joint algorithm for named-entity linking and coreference resolution. [sent-106, score-0.533]
</p><p>26 3 Joint Coreference and Linking We introduce a joint model for coreference resolution and NEL. [sent-108, score-0.399]
</p><p>27 Building on the Stanford sieve architecture, our algorithm incrementally constructs clusters of mentions using deterministic coreference rules under NEL constraints. [sent-109, score-0.767]
</p><p>28 The in-  put to NECO is a document and the output is a set C of coreference clusters, with links l(c) to Wikipedia pages for a subset of the clusters c ∈ C. [sent-111, score-0.455]
</p><p>29 Step 2 repeatedly merges coreference clusters, while ensuring that NEL constraints (Sec. [sent-116, score-0.362]
</p><p>30 2, NECO combines mentions from the base coreference and NEL systems. [sent-127, score-0.484]
</p><p>31 Let MCR be the set of mentions returned by using Stanford’s rule-based mention detection algorithm (Lee et al. [sent-128, score-0.443]
</p><p>32 For mentions m output by the base NEL systems, we assign an exact link l(m) if the entire mention span is linked. [sent-137, score-0.535]
</p><p>33 Mentions m0 that differ from an exact linked mention m by only a pre- or post-fix stop word are similarly assigned exact links l(m0) = l(m). [sent-138, score-0.495]
</p><p>34 For example, the mention “the president” will be assigned the same link as “president” but “The governor of Alaska Sarah Palin” would not be assigned an exact link to Sarah Pal in. [sent-139, score-0.442]
</p><p>35 For mentions m0 that do not receive an exact link, we assign a head link h(m0) if the head word2 m has been linked, by setting h(m0) = l(m). [sent-140, score-0.393]
</p><p>36 For instance, the head link for the mention “President Clinton” (with “Clinton” as head word) will be the Wikipedia title of Bi l Cl inton. [sent-141, score-0.372]
</p><p>37 We use head links for the l Relaxed NEL sieve (Sec. [sent-142, score-0.327]
</p><p>38 Next, we define L(m) to be the set con2A head word is assigned  to every  mention with the Stanford  parser head finding rules (Klein and Manning, 2003). [sent-145, score-0.294]
</p><p>39 After updating the entity links for all mentions, NECO prunes spurious mentions that begin or end with a stop word where the remaining subexpression of the mention exists in M. [sent-153, score-0.608]
</p><p>40 2 also assigns attributes for a mention m linked to Wikipedia page l(m), at both coarse and fine-grained levels, based on information from the Freebase entry corresponding to exact link l(m) or head link h(m). [sent-157, score-0.709]
</p><p>41 These attributes are part of the original Stanford coreference system and are used to avoid merging conflicting clusters. [sent-159, score-0.455]
</p><p>42 In order to account for both links to specific peo292 ple (Barack Obama) and generic links to positions held by people (President), we include the type PERSON ifthe linked entity has any ofthe Freebase types person, job title, or government office or title. [sent-162, score-0.367]
</p><p>43 For example, the mention “Indonesia” is assigned fine-grained attributes such as book subject, military power, and olympic participating country. [sent-167, score-0.339]
</p><p>44 These finegrained attributes are used in the Relaxed NEL sieve (Sec. [sent-170, score-0.311]
</p><p>45 Clusters ci and cj are inconsistent if both are linked (i. [sent-176, score-0.294]
</p><p>46 5 Merging Clusters and Update Entity Links When two clusters ci and cj are merged to form a new cluster ck, the entity link information L(ck), l(ck), and h(ck) must be updated (Step 2 of Fig. [sent-182, score-0.471]
</p><p>47 We set L(ck) to the union ofthe linked entities found in l(ci) and l(cj) and merge coarse attributes at this point. [sent-184, score-0.345]
</p><p>48 In order to set the exact and head entity links l(ck) and h(ck), we use the exemplar mention Exemplar(ck) that denotes the most representative mention of the cluster. [sent-185, score-0.758]
</p><p>49 Mentions appearing earlier in text, proper mentions, and mentions that have exact or head named-entity links are preferred to those which do not. [sent-189, score-0.398]
</p><p>50 6  NEL Sieves  Finally, we introduce two new sieves that use NEL information at the beginning and end of the Stanford sieves pipeline in the merging stage (Step 2 of Fig. [sent-192, score-0.286]
</p><p>51 Exact NEL sieve The Exact NEL sieve merges two clusters ci and cj if both are linked and their links match, l(ci) = l(cj). [sent-194, score-0.895]
</p><p>52 For example, all mentions that have been linked to Barack Obama will  become members of the same coreference cluster. [sent-195, score-0.58]
</p><p>53 Relaxed NEL sieve The Relaxed NEL sieve uses fine-grained attributes of the linked mentions to merge proper nouns with common nouns when they share attributes. [sent-197, score-0.87]
</p><p>54 For example, this sieve is able to merge the proper mention “Disneyland” with the “the mysterious park”, because park is one of the fine-grained attributes assigned to Di sneyland. [sent-198, score-0.663]
</p><p>55 Because this sieve has low precision, we only allow merges between mentions that have a maximum distance of three sentences between one another. [sent-201, score-0.44]
</p><p>56 293 4 Experimental Setup Core Components and Baselines The Stanford sieve-based coreference system (Lee et al. [sent-203, score-0.286]
</p><p>57 We also optimized for the set of fine-grained attributes to import from Wikipedia and Freebase, and the best way to incorporate the NEL constraints into the sieve architecture. [sent-209, score-0.335]
</p><p>58 The CONLL  coreference dataset includes text from five different domains: broadcast conversation (BC), broadcast  news (BN), magazine (MZ), newswire (NW), and web data (WB) (Pradhan et al. [sent-212, score-0.456]
</p><p>59 MUC is a link-based metric which measures how many clusters need to be merged to cover the gold clusters and favors larger clusters; B3 computes the proportion of intersection between predicted and gold clusters for every mention and favors singletons (Recasens and Hovy, 2010). [sent-222, score-0.584]
</p><p>60 We computed the scores using the Stanford  coreference software for ACE2004 and using the CoNLL scorer for the CoNLL 2011 dataset. [sent-223, score-0.286]
</p><p>61 5  Experimental Results  We first look at NECO’s performance at coreference resolution and then evaluate its ability at NEL. [sent-224, score-0.399]
</p><p>62 Results with Predicted Mentions Overall System Performance on ACE Data Table 1 shows NECO’s performance at coreference resolution on ACE- compared to the Stanford sieve implementation (Lee et al. [sent-227, score-0.589]
</p><p>63 Inspection shows that some of the errors introduced by MNEL are actually due to correctly linked entities that were not annotated as mentions in the dataset, but also some improperly linked mentions. [sent-236, score-0.459]
</p><p>64 Updating coarse attributes tends to increase precision because it prevents dangerous merges, such as merging “Staples” with the mention “it” in a situation when “Staples” refers to the person entity Todd Staple s. [sent-245, score-0.536]
</p><p>65 Fine-grained attributes also help with recall, when merging a specific name of an entity with a mention that uses a more general term; for instance, “Hong Kong Disneyland” can be merged with “the mysterious park” because “park” is a finegrained attribute for D i sneyland. [sent-246, score-0.533]
</p><p>66 CoNLL, on the other hand, contains a wider variety of texts, some of which do not mention many named entities in Wikipedia. [sent-278, score-0.28]
</p><p>67 These domains especially benefit from the improved mention detection and pruning provided by NEL, and strong linking benefitted both precision and recall in these domains. [sent-281, score-0.475]
</p><p>68 2  Coreference Results with Gold Linking  Some of the errors introduced in our system are due to incorrect or incomplete links discovered by the automatic linking system. [sent-284, score-0.283]
</p><p>69 424 Gold Mentions  Predicted Mentions  Table 4: Coreference results on ACE-NWIRE-NEL with gold and predicted mentions and gold or automatic linking. [sent-307, score-0.329]
</p><p>70 First, it reduces the coreference errors caused by incorrect NEL links. [sent-309, score-0.341]
</p><p>71 For instance, gold linking replaces the erroneous link generated by our NEL systems for “Nasser al-Kidwa” to the correct Wikipedia entity. [sent-310, score-0.277]
</p><p>72 As another example, two mentions of “Rutgers” will not be merged if one links to the university and the other links to their football team. [sent-311, score-0.421]
</p><p>73 Second, gold linking leads to better mention detection and better linked mentions. [sent-312, score-0.54]
</p><p>74 For instance, under gold linking, the whole mention, “The governor of Alaska, Sarah Palin,” is linked to the politician, while automatic linking systems only link the substring containing her name, “Sarah Palin. [sent-313, score-0.4]
</p><p>75 ” Still, gold NEL cannot compensate for all coreference errors in cases of generic or unlinked entities. [sent-314, score-0.389]
</p><p>76 3  Coreference Results with Gold Mentions  Many of the previous papers evaluate coreference resolution assuming gold mentions so we also run under that condition (Table 5) using ACENWIRE data. [sent-316, score-0.645]
</p><p>77 As the table shows, with gold mentions our system outperforms Haghighi and Klein (2009), Poon and Domingos (2008), Finkel and Manning (2008) and the Stanford sieve algorithm across  all metrics. [sent-317, score-0.436]
</p><p>78 4  Improving Named Entity Linking  While our previous experiments show that namedentity linking can improve coreference resolution, we now address the question of whether coreference techniques can help NEL. [sent-320, score-0.723]
</p><p>79 For instance, our system correctly adds links from “Bullock” to the entity Sandra Bul lock because coreference resolution merges two mentions. [sent-324, score-0.623]
</p><p>80 4We take the union of all the links returned by GLOW and WikipediaMiner, but if they link a mention to two different entities, we use only the output of WikipediaMiner. [sent-327, score-0.395]
</p><p>81 Despite the improvements that come from NEL, a large portion of coreference errors can still be attributed to incomplete semantic information, including precision errors caused by incorrect linking. [sent-338, score-0.411]
</p><p>82 Overly gen-  eral fine-grained attributes caused precision errors in cases where many proper noun mentions were potential antecedents for a common noun. [sent-340, score-0.433]
</p><p>83 Although attributes such as country are useful for resolving a generic “country” mention, this information is insufficient when two distinct mentions such as “China” and “Russia” both have the country attribute. [sent-341, score-0.359]
</p><p>84 Earlier coreference resolution systems used shallow semantics and pioneered knowledge extraction from online encyclopedias (Ponzetto and Strube, 2006; Daum e´ III and Marcu, 2005; Ng, 2007). [sent-347, score-0.399]
</p><p>85 Some recent work shows improvement in coreference resolution by incorporating semantic information from  Web-scale structured knowledge bases. [sent-348, score-0.399]
</p><p>86 Haghighi and Klein (2009) use a rule-based system to extract fine-grained attributes for mentions by analyzing 297 precise constructs (e. [sent-349, score-0.319]
</p><p>87 Subsequently, Haghighi and Klein (2010) used a generative approach to learn entity types from an initial list of unambiguous mention types. [sent-352, score-0.311]
</p><p>88 (2013) use a ranked list of candidate entities for each mention and maintain the ranked list when mentions are merged. [sent-358, score-0.452]
</p><p>89 Ratinov and Roth (2012) investigated using NEL  to improve coreference resolution, but did not consider a joint approach. [sent-360, score-0.286]
</p><p>90 They extracted attributes from Wikipedia categories and used them as features in a learned mention-pair model, but did not do mention detection. [sent-361, score-0.339]
</p><p>91 (2009) present an elegant collective disambiguation model, but do not exploit the syntactic nuances gleaned by within-document coreference resolution. [sent-371, score-0.286]
</p><p>92 7 Conclusions Observing that existing coreference resolution and named-entity linking have complementary strengths Error Type Percentage Example Extra mentions31. [sent-374, score-0.55]
</p><p>93 For precision errors, the wrongly merged mention is bolded. [sent-407, score-0.28]
</p><p>94 It would be interesting to more tightly integrate the NEL system so it operates on clusters rather than individual mentions after —  each sieve merges an unlinked cluster, the algorithm would retry NEL with the new context information. [sent-413, score-0.532]
</p><p>95 Easy victories and  uphill battles in coreference resolution. [sent-443, score-0.286]
</p><p>96 Simple coreference resolution with rich syntactic and semantic features. [sent-457, score-0.399]
</p><p>97 Stanford’s multi-pass sieve coreference resolution system at the CoNLL-201 1shared task. [sent-474, score-0.589]
</p><p>98 Supervised noun phrase coreference research: The first fifteen years. [sent-491, score-0.286]
</p><p>99 Exploiting semantic role labeling, Wordnet and Wikipedia for coreference resolution. [sent-498, score-0.286]
</p><p>100 CoNLL-201 1 shared task: modeling unrestricted coreference in OntoNotes. [sent-506, score-0.286]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nel', 0.622), ('neco', 0.324), ('coreference', 0.286), ('mention', 0.218), ('mentions', 0.198), ('sieve', 0.19), ('linking', 0.151), ('attributes', 0.121), ('cj', 0.113), ('ace', 0.113), ('resolution', 0.113), ('sieves', 0.107), ('freebase', 0.104), ('links', 0.099), ('linked', 0.096), ('wikipediaminer', 0.089), ('ci', 0.085), ('glow', 0.078), ('link', 0.078), ('wikipedia', 0.076), ('ck', 0.075), ('entity', 0.073), ('exemplar', 0.071), ('clusters', 0.07), ('mnel', 0.067), ('stanford', 0.063), ('conll', 0.062), ('merge', 0.053), ('merges', 0.052), ('muc', 0.052), ('merging', 0.048), ('gold', 0.048), ('broadcast', 0.047), ('relaxed', 0.046), ('disneyland', 0.045), ('staples', 0.045), ('ratinov', 0.044), ('newswire', 0.043), ('president', 0.042), ('exact', 0.041), ('coarse', 0.039), ('disney', 0.039), ('head', 0.038), ('mi', 0.037), ('park', 0.037), ('precision', 0.037), ('entities', 0.036), ('predicted', 0.035), ('milne', 0.035), ('lleett', 0.034), ('magazine', 0.033), ('clinton', 0.033), ('hong', 0.033), ('errors', 0.033), ('heeyoung', 0.03), ('mj', 0.03), ('lee', 0.029), ('mz', 0.029), ('durrett', 0.028), ('sarah', 0.028), ('kong', 0.027), ('cluster', 0.027), ('detection', 0.027), ('governor', 0.027), ('attribute', 0.026), ('confidence', 0.026), ('named', 0.026), ('haghighi', 0.025), ('klein', 0.025), ('witten', 0.025), ('merged', 0.025), ('pipeline', 0.024), ('constraints', 0.024), ('pradhan', 0.023), ('bn', 0.023), ('deterministic', 0.023), ('dan', 0.023), ('alaska', 0.022), ('dill', 0.022), ('fooord', 0.022), ('gieovleds', 0.022), ('hannaneh', 0.022), ('mcr', 0.022), ('mysterious', 0.022), ('nsntae', 0.022), ('palin', 0.022), ('semtag', 0.022), ('suharto', 0.022), ('unlinked', 0.022), ('caused', 0.022), ('proper', 0.022), ('recall', 0.021), ('pruning', 0.021), ('unambiguous', 0.02), ('drops', 0.02), ('spurious', 0.02), ('country', 0.02), ('instance', 0.02), ('raghunathan', 0.019), ('appositives', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999762 <a title="112-tfidf-1" href="./emnlp-2013-Joint_Coreference_Resolution_and_Named-Entity_Linking_with_Multi-Pass_Sieves.html">112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</a></p>
<p>Author: Hannaneh Hajishirzi ; Leila Zilles ; Daniel S. Weld ; Luke Zettlemoyer</p><p>Abstract: Many errors in coreference resolution come from semantic mismatches due to inadequate world knowledge. Errors in named-entity linking (NEL), on the other hand, are often caused by superficial modeling of entity context. This paper demonstrates that these two tasks are complementary. We introduce NECO, a new model for named entity linking and coreference resolution, which solves both problems jointly, reducing the errors made on each. NECO extends the Stanford deterministic coreference system by automatically linking mentions to Wikipedia and introducing new NEL-informed mention-merging sieves. Linking improves mention-detection and enables new semantic attributes to be incorporated from Freebase, while coreference provides better context modeling by propagating named-entity links within mention clusters. Experiments show consistent improve- ments across a number of datasets and experimental conditions, including over 11% reduction in MUC coreference error and nearly 21% reduction in F1 NEL error on ACE 2004 newswire data.</p><p>2 0.37986144 <a title="112-tfidf-2" href="./emnlp-2013-Easy_Victories_and_Uphill_Battles_in_Coreference_Resolution.html">67 emnlp-2013-Easy Victories and Uphill Battles in Coreference Resolution</a></p>
<p>Author: Greg Durrett ; Dan Klein</p><p>Abstract: Classical coreference systems encode various syntactic, discourse, and semantic phenomena explicitly, using heterogenous features computed from hand-crafted heuristics. In contrast, we present a state-of-the-art coreference system that captures such phenomena implicitly, with a small number of homogeneous feature templates examining shallow properties of mentions. Surprisingly, our features are actually more effective than the corresponding hand-engineered ones at modeling these key linguistic phenomena, allowing us to win “easy victories” without crafted heuristics. These features are successful on syntax and discourse; however, they do not model semantic compatibility well, nor do we see gains from experiments with shallow semantic features from the literature, suggesting that this approach to semantics is an “uphill battle.” Nonetheless, our final system1 outperforms the Stanford system (Lee et al. (201 1), the winner of the CoNLL 2011 shared task) by 3.5% absolute on the CoNLL metric and outperforms the IMS system (Bj o¨rkelund and Farkas (2012), the best publicly available English coreference system) by 1.9% absolute.</p><p>3 0.33657032 <a title="112-tfidf-3" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>Author: Jonathan K. Kummerfeld ; Dan Klein</p><p>Abstract: Coreference resolution metrics quantify errors but do not analyze them. Here, we consider an automated method of categorizing errors in the output of a coreference system into intuitive underlying error types. Using this tool, we first compare the error distributions across a large set of systems, then analyze common errors across the top ten systems, empirically characterizing the major unsolved challenges of the coreference resolution task.</p><p>4 0.29081771 <a title="112-tfidf-4" href="./emnlp-2013-A_Constrained_Latent_Variable_Model_for_Coreference_Resolution.html">1 emnlp-2013-A Constrained Latent Variable Model for Coreference Resolution</a></p>
<p>Author: Kai-Wei Chang ; Rajhans Samdani ; Dan Roth</p><p>Abstract: Coreference resolution is a well known clustering task in Natural Language Processing. In this paper, we describe the Latent Left Linking model (L3M), a novel, principled, and linguistically motivated latent structured prediction approach to coreference resolution. We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning. Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches as well as some structured prediction models proposed in the literature.</p><p>5 0.22624208 <a title="112-tfidf-5" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>Author: Fang Kong ; Hwee Tou Ng</p><p>Abstract: Coreference resolution plays a critical role in discourse analysis. This paper focuses on exploiting zero pronouns to improve Chinese coreference resolution. In particular, a simplified semantic role labeling framework is proposed to identify clauses and to detect zero pronouns effectively, and two effective methods (refining syntactic parser and refining learning example generation) are employed to exploit zero pronouns for Chinese coreference resolution. Evaluation on the CoNLL-2012 shared task data set shows that zero pronouns can significantly improve Chinese coreference resolution.</p><p>6 0.19401069 <a title="112-tfidf-6" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>7 0.14431491 <a title="112-tfidf-7" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>8 0.13551098 <a title="112-tfidf-8" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>9 0.10580499 <a title="112-tfidf-9" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>10 0.10444896 <a title="112-tfidf-10" href="./emnlp-2013-Microblog_Entity_Linking_by_Leveraging_Extra_Posts.html">130 emnlp-2013-Microblog Entity Linking by Leveraging Extra Posts</a></p>
<p>11 0.077213429 <a title="112-tfidf-11" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<p>12 0.071767494 <a title="112-tfidf-12" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>13 0.070403486 <a title="112-tfidf-13" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>14 0.067564934 <a title="112-tfidf-14" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>15 0.063863449 <a title="112-tfidf-15" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>16 0.062098611 <a title="112-tfidf-16" href="./emnlp-2013-Learning_Biological_Processes_with_Global_Constraints.html">118 emnlp-2013-Learning Biological Processes with Global Constraints</a></p>
<p>17 0.056950811 <a title="112-tfidf-17" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>18 0.056305338 <a title="112-tfidf-18" href="./emnlp-2013-Event-Based_Time_Label_Propagation_for_Automatic_Dating_of_News_Articles.html">74 emnlp-2013-Event-Based Time Label Propagation for Automatic Dating of News Articles</a></p>
<p>19 0.052752316 <a title="112-tfidf-19" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>20 0.05221919 <a title="112-tfidf-20" href="./emnlp-2013-Chinese_Zero_Pronoun_Resolution%3A_Some_Recent_Advances.html">45 emnlp-2013-Chinese Zero Pronoun Resolution: Some Recent Advances</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.197), (1, 0.279), (2, 0.426), (3, -0.126), (4, 0.066), (5, -0.032), (6, 0.039), (7, -0.014), (8, 0.033), (9, -0.032), (10, -0.029), (11, -0.041), (12, -0.006), (13, 0.007), (14, -0.078), (15, -0.064), (16, 0.008), (17, -0.002), (18, -0.024), (19, -0.014), (20, -0.088), (21, -0.093), (22, -0.007), (23, -0.014), (24, 0.081), (25, 0.021), (26, 0.013), (27, -0.056), (28, 0.049), (29, 0.025), (30, 0.029), (31, -0.057), (32, 0.045), (33, -0.031), (34, -0.091), (35, -0.018), (36, 0.034), (37, -0.059), (38, -0.017), (39, -0.041), (40, -0.007), (41, -0.012), (42, 0.001), (43, 0.009), (44, 0.027), (45, 0.026), (46, 0.033), (47, -0.042), (48, -0.055), (49, -0.006)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9792316 <a title="112-lsi-1" href="./emnlp-2013-Joint_Coreference_Resolution_and_Named-Entity_Linking_with_Multi-Pass_Sieves.html">112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</a></p>
<p>Author: Hannaneh Hajishirzi ; Leila Zilles ; Daniel S. Weld ; Luke Zettlemoyer</p><p>Abstract: Many errors in coreference resolution come from semantic mismatches due to inadequate world knowledge. Errors in named-entity linking (NEL), on the other hand, are often caused by superficial modeling of entity context. This paper demonstrates that these two tasks are complementary. We introduce NECO, a new model for named entity linking and coreference resolution, which solves both problems jointly, reducing the errors made on each. NECO extends the Stanford deterministic coreference system by automatically linking mentions to Wikipedia and introducing new NEL-informed mention-merging sieves. Linking improves mention-detection and enables new semantic attributes to be incorporated from Freebase, while coreference provides better context modeling by propagating named-entity links within mention clusters. Experiments show consistent improve- ments across a number of datasets and experimental conditions, including over 11% reduction in MUC coreference error and nearly 21% reduction in F1 NEL error on ACE 2004 newswire data.</p><p>2 0.90815222 <a title="112-lsi-2" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>Author: Jonathan K. Kummerfeld ; Dan Klein</p><p>Abstract: Coreference resolution metrics quantify errors but do not analyze them. Here, we consider an automated method of categorizing errors in the output of a coreference system into intuitive underlying error types. Using this tool, we first compare the error distributions across a large set of systems, then analyze common errors across the top ten systems, empirically characterizing the major unsolved challenges of the coreference resolution task.</p><p>3 0.86767852 <a title="112-lsi-3" href="./emnlp-2013-Easy_Victories_and_Uphill_Battles_in_Coreference_Resolution.html">67 emnlp-2013-Easy Victories and Uphill Battles in Coreference Resolution</a></p>
<p>Author: Greg Durrett ; Dan Klein</p><p>Abstract: Classical coreference systems encode various syntactic, discourse, and semantic phenomena explicitly, using heterogenous features computed from hand-crafted heuristics. In contrast, we present a state-of-the-art coreference system that captures such phenomena implicitly, with a small number of homogeneous feature templates examining shallow properties of mentions. Surprisingly, our features are actually more effective than the corresponding hand-engineered ones at modeling these key linguistic phenomena, allowing us to win “easy victories” without crafted heuristics. These features are successful on syntax and discourse; however, they do not model semantic compatibility well, nor do we see gains from experiments with shallow semantic features from the literature, suggesting that this approach to semantics is an “uphill battle.” Nonetheless, our final system1 outperforms the Stanford system (Lee et al. (201 1), the winner of the CoNLL 2011 shared task) by 3.5% absolute on the CoNLL metric and outperforms the IMS system (Bj o¨rkelund and Farkas (2012), the best publicly available English coreference system) by 1.9% absolute.</p><p>4 0.8671968 <a title="112-lsi-4" href="./emnlp-2013-A_Constrained_Latent_Variable_Model_for_Coreference_Resolution.html">1 emnlp-2013-A Constrained Latent Variable Model for Coreference Resolution</a></p>
<p>Author: Kai-Wei Chang ; Rajhans Samdani ; Dan Roth</p><p>Abstract: Coreference resolution is a well known clustering task in Natural Language Processing. In this paper, we describe the Latent Left Linking model (L3M), a novel, principled, and linguistically motivated latent structured prediction approach to coreference resolution. We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning. Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches as well as some structured prediction models proposed in the literature.</p><p>5 0.72280419 <a title="112-lsi-5" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>Author: Fang Kong ; Hwee Tou Ng</p><p>Abstract: Coreference resolution plays a critical role in discourse analysis. This paper focuses on exploiting zero pronouns to improve Chinese coreference resolution. In particular, a simplified semantic role labeling framework is proposed to identify clauses and to detect zero pronouns effectively, and two effective methods (refining syntactic parser and refining learning example generation) are employed to exploit zero pronouns for Chinese coreference resolution. Evaluation on the CoNLL-2012 shared task data set shows that zero pronouns can significantly improve Chinese coreference resolution.</p><p>6 0.62277579 <a title="112-lsi-6" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>7 0.52760333 <a title="112-lsi-7" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>8 0.51882833 <a title="112-lsi-8" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>9 0.40757954 <a title="112-lsi-9" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>10 0.33769396 <a title="112-lsi-10" href="./emnlp-2013-Microblog_Entity_Linking_by_Leveraging_Extra_Posts.html">130 emnlp-2013-Microblog Entity Linking by Leveraging Extra Posts</a></p>
<p>11 0.32799867 <a title="112-lsi-11" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>12 0.2956861 <a title="112-lsi-12" href="./emnlp-2013-Chinese_Zero_Pronoun_Resolution%3A_Some_Recent_Advances.html">45 emnlp-2013-Chinese Zero Pronoun Resolution: Some Recent Advances</a></p>
<p>13 0.28533509 <a title="112-lsi-13" href="./emnlp-2013-Using_Soft_Constraints_in_Joint_Inference_for_Clinical_Concept_Recognition.html">198 emnlp-2013-Using Soft Constraints in Joint Inference for Clinical Concept Recognition</a></p>
<p>14 0.28453544 <a title="112-lsi-14" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>15 0.28071654 <a title="112-lsi-15" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>16 0.27721968 <a title="112-lsi-16" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>17 0.25568941 <a title="112-lsi-17" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<p>18 0.23234181 <a title="112-lsi-18" href="./emnlp-2013-Event-Based_Time_Label_Propagation_for_Automatic_Dating_of_News_Articles.html">74 emnlp-2013-Event-Based Time Label Propagation for Automatic Dating of News Articles</a></p>
<p>19 0.22339652 <a title="112-lsi-19" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>20 0.21904401 <a title="112-lsi-20" href="./emnlp-2013-Learning_Biological_Processes_with_Global_Constraints.html">118 emnlp-2013-Learning Biological Processes with Global Constraints</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.026), (18, 0.024), (22, 0.039), (30, 0.043), (51, 0.17), (58, 0.031), (66, 0.024), (71, 0.015), (75, 0.057), (77, 0.02), (90, 0.013), (95, 0.021), (96, 0.388), (97, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9517653 <a title="112-lda-1" href="./emnlp-2013-Scaling_to_Large3_Data%3A_An_Efficient_and_Effective_Method_to_Compute_Distributional_Thesauri.html">165 emnlp-2013-Scaling to Large3 Data: An Efficient and Effective Method to Compute Distributional Thesauri</a></p>
<p>Author: Martin Riedl ; Chris Biemann</p><p>Abstract: We introduce a new highly scalable approach for computing Distributional Thesauri (DTs). By employing pruning techniques and a distributed framework, we make the computation for very large corpora feasible on comparably small computational resources. We demonstrate this by releasing a DT for the whole vocabulary of Google Books syntactic n-grams. Evaluating against lexical resources using two measures, we show that our approach produces higher quality DTs than previous approaches, and is thus preferable in terms of speed and quality for large corpora.</p><p>2 0.85935736 <a title="112-lda-2" href="./emnlp-2013-A_Walk-Based_Semantically_Enriched_Tree_Kernel_Over_Distributed_Word_Representations.html">17 emnlp-2013-A Walk-Based Semantically Enriched Tree Kernel Over Distributed Word Representations</a></p>
<p>Author: Shashank Srivastava ; Dirk Hovy ; Eduard Hovy</p><p>Abstract: In this paper, we propose a walk-based graph kernel that generalizes the notion of treekernels to continuous spaces. Our proposed approach subsumes a general framework for word-similarity, and in particular, provides a flexible way to incorporate distributed representations. Using vector representations, such an approach captures both distributional semantic similarities among words as well as the structural relations between them (encoded as the structure of the parse tree). We show an efficient formulation to compute this kernel using simple matrix operations. We present our results on three diverse NLP tasks, showing state-of-the-art results.</p><p>same-paper 3 0.85893083 <a title="112-lda-3" href="./emnlp-2013-Joint_Coreference_Resolution_and_Named-Entity_Linking_with_Multi-Pass_Sieves.html">112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</a></p>
<p>Author: Hannaneh Hajishirzi ; Leila Zilles ; Daniel S. Weld ; Luke Zettlemoyer</p><p>Abstract: Many errors in coreference resolution come from semantic mismatches due to inadequate world knowledge. Errors in named-entity linking (NEL), on the other hand, are often caused by superficial modeling of entity context. This paper demonstrates that these two tasks are complementary. We introduce NECO, a new model for named entity linking and coreference resolution, which solves both problems jointly, reducing the errors made on each. NECO extends the Stanford deterministic coreference system by automatically linking mentions to Wikipedia and introducing new NEL-informed mention-merging sieves. Linking improves mention-detection and enables new semantic attributes to be incorporated from Freebase, while coreference provides better context modeling by propagating named-entity links within mention clusters. Experiments show consistent improve- ments across a number of datasets and experimental conditions, including over 11% reduction in MUC coreference error and nearly 21% reduction in F1 NEL error on ACE 2004 newswire data.</p><p>4 0.81184983 <a title="112-lda-4" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>Author: Baichuan Li ; Jing Liu ; Chin-Yew Lin ; Irwin King ; Michael R. Lyu</p><p>Abstract: Social media like forums and microblogs have accumulated a huge amount of user generated content (UGC) containing human knowledge. Currently, most of UGC is listed as a whole or in pre-defined categories. This “list-based” approach is simple, but hinders users from browsing and learning knowledge of certain topics effectively. To address this problem, we propose a hierarchical entity-based approach for structuralizing UGC in social media. By using a large-scale entity repository, we design a three-step framework to organize UGC in a novel hierarchical structure called “cluster entity tree (CET)”. With Yahoo! Answers as a test case, we conduct experiments and the results show the effectiveness of our framework in constructing CET. We further evaluate the performance of CET on UGC organization in both user and system aspects. From a user aspect, our user study demonstrates that, with CET-based structure, users perform significantly better in knowledge learning than using traditional list-based approach. From a system aspect, CET substantially boosts the performance of two information retrieval models (i.e., vector space model and query likelihood language model).</p><p>5 0.80658787 <a title="112-lda-5" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>Author: Qiming Diao ; Jing Jiang</p><p>Abstract: With the rapid growth of social media, Twitter has become one of the most widely adopted platforms for people to post short and instant message. On the one hand, people tweets about their daily lives, and on the other hand, when major events happen, people also follow and tweet about them. Moreover, people’s posting behaviors on events are often closely tied to their personal interests. In this paper, we try to model topics, events and users on Twitter in a unified way. We propose a model which combines an LDA-like topic model and the Recurrent Chinese Restaurant Process to capture topics and events. We further propose a duration-based regularization component to find bursty events. We also propose to use event-topic affinity vectors to model the asso- . ciation between events and topics. Our experiments shows that our model can accurately identify meaningful events and the event-topic affinity vectors are effective for event recommendation and grouping events by topics.</p><p>6 0.61880517 <a title="112-lda-6" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>7 0.61081409 <a title="112-lda-7" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>8 0.59739316 <a title="112-lda-8" href="./emnlp-2013-Microblog_Entity_Linking_by_Leveraging_Extra_Posts.html">130 emnlp-2013-Microblog Entity Linking by Leveraging Extra Posts</a></p>
<p>9 0.5917421 <a title="112-lda-9" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>10 0.58787233 <a title="112-lda-10" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>11 0.57394236 <a title="112-lda-11" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>12 0.57039928 <a title="112-lda-12" href="./emnlp-2013-A_Constrained_Latent_Variable_Model_for_Coreference_Resolution.html">1 emnlp-2013-A Constrained Latent Variable Model for Coreference Resolution</a></p>
<p>13 0.57019824 <a title="112-lda-13" href="./emnlp-2013-Easy_Victories_and_Uphill_Battles_in_Coreference_Resolution.html">67 emnlp-2013-Easy Victories and Uphill Battles in Coreference Resolution</a></p>
<p>14 0.56339377 <a title="112-lda-14" href="./emnlp-2013-Well-Argued_Recommendation%3A_Adaptive_Models_Based_on_Words_in_Recommender_Systems.html">200 emnlp-2013-Well-Argued Recommendation: Adaptive Models Based on Words in Recommender Systems</a></p>
<p>15 0.55436867 <a title="112-lda-15" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>16 0.55326921 <a title="112-lda-16" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>17 0.54890883 <a title="112-lda-17" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>18 0.53877276 <a title="112-lda-18" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>19 0.53805244 <a title="112-lda-19" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>20 0.53442812 <a title="112-lda-20" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
