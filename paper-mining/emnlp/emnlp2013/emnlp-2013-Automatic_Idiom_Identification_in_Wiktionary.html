<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>32 emnlp-2013-Automatic Idiom Identification in Wiktionary</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-32" href="#">emnlp2013-32</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>32 emnlp-2013-Automatic Idiom Identification in Wiktionary</h1>
<br/><p>Source: <a title="emnlp-2013-32-pdf" href="http://aclweb.org/anthology//D/D13/D13-1145.pdf">pdf</a></p><p>Author: Grace Muzny ; Luke Zettlemoyer</p><p>Abstract: Online resources, such as Wiktionary, provide an accurate but incomplete source ofidiomatic phrases. In this paper, we study the problem of automatically identifying idiomatic dictionary entries with such resources. We train an idiom classifier on a newly gathered corpus of over 60,000 Wiktionary multi-word definitions, incorporating features that model whether phrase meanings are constructed compositionally. Experiments demonstrate that the learned classifier can provide high quality idiom labels, more than doubling the number of idiomatic entries from 7,764 to 18,155 at precision levels of over 65%. These gains also translate to idiom detection in sentences, by simply using known word sense disambiguation algorithms to match phrases to their definitions. In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over 28 percentage points.</p><p>Reference: <a title="emnlp-2013-32-reference" href="../emnlp2013_reference/emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Automatic Idiom Identification in Wiktionary Grace Muzny and Luke Zettlemoyer Computer Science & Engineering University of Washington Seattle, WA 98195  {mu z nyg  ,l z }@ c s s  Abstract Online resources, such as Wiktionary, provide an accurate but incomplete source ofidiomatic phrases. [sent-1, score-0.051]
</p><p>2 In this paper, we study the problem of automatically identifying idiomatic dictionary entries with such resources. [sent-2, score-0.688]
</p><p>3 We train an idiom classifier on a newly gathered corpus of over 60,000 Wiktionary multi-word definitions, incorporating features that model whether phrase meanings are constructed compositionally. [sent-3, score-0.506]
</p><p>4 Experiments demonstrate that the learned classifier can provide high quality idiom labels, more than doubling the number of idiomatic entries from 7,764 to 18,155 at precision levels of over 65%. [sent-4, score-0.957]
</p><p>5 These gains also translate to idiom detection in sentences, by simply using known word sense disambiguation algorithms to match phrases to their definitions. [sent-5, score-0.545]
</p><p>6 In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over  28 percentage points. [sent-6, score-0.42]
</p><p>7 For example, a diamond in the rough can be the literal unpolished object or a crude but lovable person. [sent-8, score-0.321]
</p><p>8 We use Wiktionary as a large, but incomplete, reference for idiomatic entries; individual entries can be marked as idiomatic but, in practice, most are . [sent-12, score-1.133]
</p><p>9 Using these incomplete annotations as supervision, we train a binary Perceptron classifier for identifying idiomatic dictionary entries. [sent-15, score-0.695]
</p><p>10 We introduce new lexical and graph-based features that use WordNet and Wiktionary to compute semantic relatedness. [sent-16, score-0.027]
</p><p>11 This allows us to learn, for example, that the words in the phrase diamond in the rough are more closely related to the words in its literal definition than the idiomatic one. [sent-17, score-0.967]
</p><p>12 Experiments demon-  strate that the classifier achieves precision of over 65% at recall over 52% and that, when used to fill in missing Wiktionary idiom labels, it more than doubles the number of idioms from 7,764 to 18,155. [sent-18, score-0.535]
</p><p>13 These gains also translate to idiom detection in sentences, by simply using the Lesk word sense disambiguation (WSD) algorithm (1986) to match phrases to their definitions. [sent-19, score-0.545]
</p><p>14 This approach allows for scalable detection with no restrictions on the syntactic structure or context of the target phrase. [sent-20, score-0.154]
</p><p>15 In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over 28 percentage points. [sent-21, score-0.42]
</p><p>16 2  Related Work  To the best of our knowledge, this work represents the first attempt to identify dictionary entries as idiomatic and the first to reduce idiom detection to identification via a dictionary. [sent-22, score-1.229]
</p><p>17 Previous idiom detection systems fall in one of two paradigms: phrase classification, where a phrase p is always idiomatic or literal, e. [sent-23, score-1.125]
</p><p>18 , 2010), or token classification, where each occurrence of a phrase p can be  idiomatic or literal, e. [sent-27, score-0.591]
</p><p>19 Most previous idiom detection systems have focused on specific syntactic constructions. [sent-32, score-0.433]
</p><p>20 (2010) consider subject/verb (campaign surged) and verb/direct-object idioms (stir excitement) while Fazly and Stevenson (2006), Cook et al. [sent-34, score-0.141]
</p><p>21 (2007), and Diab and Bhutada (2009) detect verb/noun idioms (blow smoke). [sent-35, score-0.141]
</p><p>22 Fothergill and Baldwin (2012) are syntactically unconstrained, but only study Japanese idioms. [sent-36, score-0.03]
</p><p>23 Although we focus on identifying idiomatic dictionary entries, one advantage of our approach is that it enables syntactically unconstrained token-level detection for any phrase in the dictionary. [sent-37, score-0.893]
</p><p>24 3  Formal Problem Definitions  Identification For identification, we assume data of the form {(hpi, dii , yi) : i = 1. [sent-38, score-0.063]
</p><p>25 n} where pi tihs eth feo phrase assoic,iyate)d :w iith = =def 1in. [sent-41, score-0.075]
</p><p>26 For example, this would inc∈lud {el ibteortahl ,th iedi loimtearatilc pair h r“ elexaavme pfoler, dead”, “uTlod  ianbcalnuddoen b a person or aotlh peari living acvreea ftourre d tehadat” i,s “ Tinojured or otherwise incapacitated, assuming that the death of the one abandoned will soon follow. [sent-45, score-0.056]
</p><p>27 ”i and tdheea tihdi oofm thateic o pair h “nldeoavnee dfo wr dead”, “ foToll disregard or bypass as unimportant. [sent-46, score-0.032]
</p><p>28 Gr diveaedn hpi, dii, we gaairmd toor predict yi. [sent-48, score-0.028]
</p><p>29 Detection To evaluate identification in the context of detection, we assume data {(hpi, eii , yi) : tie = f1 . [sent-49, score-0.183]
</p><p>30 en ei whose idiomatic status is labeled yi ∈ {idiomatic, literal}. [sent-56, score-0.558]
</p><p>31 One such idiomatic pair is h“heart mtoa heart”, “They seat s cdohw indi oamnda hca pda a long ohveaerrdtu teo h heeaartr ”to, h “eTahrte yab soautt tdhoew fnutu arned do fh tahdei ar relationship. [sent-57, score-0.625]
</p><p>32 4  Data  We gathered phrases, definitions, and example sentences from the English-language Wiktionary dump from November 13th, 2012. [sent-60, score-0.066]
</p><p>33 FigAuTDUrlnaetion1S:aetN dumeTDbsvtreofdi4L52c76,t 8e0o13rn2a7lyeId61it93o,r587me60sa4twich536eTa4,o1c3827hta094lc13s  1418  for the Wiktionary identification data. [sent-63, score-0.133]
</p><p>34 TD eaestvaSetL13ite67r01alIdi6o3m3950atic1T5o0 t5a15l  Figure 2: Number of sentences of each class for the Wiktionary detection data. [sent-64, score-0.128]
</p><p>35 the pair h “weapons of mass destruction”, r“aPselu—rael gfo. [sent-67, score-0.03]
</p><p>36 r tmhe o pfa weapon aopfo mass destruction” iwas removed while the pair h “weapon  odfes mtrauscst destruction”, m“oAv chemical, biological, reaadpioonlogical, nuclear or other weapon that . [sent-68, score-0.248]
</p><p>37 y according to Etahec hid piaoirm lpa,bdeils w ains Wiktionary, producing tinheg Train, Unannotated Dev, and Unannotated Test data sets. [sent-75, score-0.028]
</p><p>38 In practice, this produces a noisy assignment because a majority of the idiomatic senses are not marked. [sent-76, score-0.544]
</p><p>39 The development and test sets were annotated to correct these potential omissions. [sent-77, score-0.034]
</p><p>40 Annotators used the definition of an idiom as a “phrase with a non-compositional meaning” to produce the Annotated Dev and Annotated Test data sets. [sent-78, score-0.36]
</p><p>41 Two annotators marked each dictionary entry as literal, idiomatic, or indeterminable. [sent-81, score-0.126]
</p><p>42 Detection For detection, we gathered the example sentences provided, when available, for each defi-  nition used in our annotated identification data sets. [sent-86, score-0.258]
</p><p>43 ment and test data containing idiomatic and literal phrase usages. [sent-88, score-0.805]
</p><p>44 In all, there were over 1,300 unique phrases, half of which had more than one possible dictionary definition in Wiktionary. [sent-89, score-0.127]
</p><p>45 5  Identification Model  For identification, we use a linear model that predicts class y∗ ∈ {literal, idiomatic} for an input pair hp, di with phrase p arnald, iddeifoinmiatitoicn} d f. [sent-91, score-0.141]
</p><p>46 All models are trained on the same, unannotated training data. [sent-95, score-0.066]
</p><p>47 Features The features that were developed fall into two categories: lexical and graph-based features. [sent-96, score-0.053]
</p><p>48 The lexical features were motivated by the intuition that literal phrases are more likely to have closely related words in d to those in p because literal phrases do not break the principle of compositionality. [sent-97, score-0.543]
</p><p>49 •  synonym overlap: Let S be the set of synonyms as doevefirnleadp: :in L Wiktionary efo sre atll o fw soyrnd-s in pP. [sent-100, score-0.113]
</p><p>50 Then, we define the synonym overlap =  |S1| Ps∈S count(s, d). [sent-101, score-0.126]
</p><p>51 PThen, we define the antonym overlap =  |A1| Pa∈A count(a, d). [sent-103, score-0.13]
</p><p>52 Let distance(w, v, rel, n) be the minimum distance via links of type rel in WordNet from a word w to a word v, up to a threshold max integer value n, and 0 otherwise. [sent-108, score-0.039]
</p><p>53 i Tfehaet sreet nofsynsets Synp, all synsets from all words in p, and the set of synsets Synd, all synsets from all words in d, are connected by a shared antonym. [sent-110, score-0.271]
</p><p>54 Experiments  We report identification and detection results, varying the data labeling and choice of feature sets. [sent-113, score-0.261]
</p><p>55 1 Identification Random Baseline We use a proportionally random baseline for the identification task that classifies according to the proportion of literal definitions seen in the training data. [sent-115, score-0.434]
</p><p>56 Results are reported for the original, unannotated test set, and the same test examples  with corrected idiom labels. [sent-117, score-0.371]
</p><p>57 All models increased  4The first relation expanded was the antonym relation. [sent-118, score-0.089]
</p><p>58 Figure 4: Precision and recall with varied features on the annotated test set. [sent-120, score-0.096]
</p><p>59 We selected our operating point to optimize F-measure, but we see that the graph features perform well across all recall levels and that adding the lexical features provides consistent improvement in  precision. [sent-123, score-0.055]
</p><p>60 However, other points are possible, especially when aiming for high precision to extend the labels in Wiktionary. [sent-124, score-0.057]
</p><p>61 For example, the original 7,764 entries can be extended to 18,155 at 65% precision, 9,594 at 80%, or 27,779 at 52. [sent-125, score-0.075]
</p><p>62 Finally, Figures 5 and 6 present qualitative results, including newly discovered idioms and high scoring false identifications. [sent-127, score-0.17]
</p><p>63 Analysis reveals where our system has room to improve—errors most often occur with phrases that are specific to a certain field, such 5We also ran ablations demonstrating that removing each feature from the Lexical+Graph model hurt performance, but omit the detailed results for space. [sent-128, score-0.044]
</p><p>64 as sports or mathematics, and with phrases whose words also appear in their definitions. [sent-129, score-0.044]
</p><p>65 2 Detection Approach We use the Lesk (1986) algorithm to perform WSD, matching an input phrase p from sentence e to the definition d in Wiktionary that defines the sense p is being used in. [sent-131, score-0.161]
</p><p>66 The final classification y is then assigned to hp, di by the identification model. [sent-132, score-0.199]
</p><p>67 The  baseline for this experiment is a model that assigns the default labels within Wiktionary to the disambiguated definition. [sent-134, score-0.027]
</p><p>68 The Annotated model is the Lexical+Graph model shown in Figure 3 evaluated on the annotated data. [sent-135, score-0.034]
</p><p>69 The +Default setting augments the identification model by labeling the hp, ei as indtisom theati idc einf eifiitchaetri othne m mmododeell b or tahbee original hlpa,beeil within Wiktionary identifies it as such. [sent-136, score-0.158]
</p><p>70 7  Conclusions  We presented a supervised approach to classifying definitions as idiomatic or literal that more than dou1420  DMeofdauelltR60e. [sent-137, score-0.789]
</p><p>71 bles the number of marked idioms in Wiktionary, even when training on incomplete data. [sent-148, score-0.218]
</p><p>72 When combined with the Lesk word sense algorithm, this approach provides a complete idiom detector for any phrase in the dictionary. [sent-149, score-0.443]
</p><p>73 We expect that semi-supervised learning techniques could better recover the missing labels and boost overall performance. [sent-150, score-0.027]
</p><p>74 We also think it should be possible to scale the detection approach, perhaps with automatic dictionary definition discovery, and evaluate it on more varied sentence types. [sent-151, score-0.289]
</p><p>75 A clustering approach for nearly unsupervised recognition of nonliteral language. [sent-158, score-0.028]
</p><p>76 Pulling their  weight: Exploiting syntactic forms for the automatic identification of idiomatic expressions in context. [sent-171, score-0.689]
</p><p>77 In Proceedings of the workshop on a broader perspective on multiword expressions. [sent-172, score-0.07]
</p><p>78 Automatically constructing a lexicon of verb phrase idiomatic combinations. [sent-190, score-0.591]
</p><p>79 Large margin clas-  sification using the perceptron algorithm. [sent-203, score-0.036]
</p><p>80 Automatic identification of non-compositional multi-word expressions using latent semantic analysis. [sent-217, score-0.173]
</p><p>81 Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. [sent-222, score-0.093]
</p><p>82 Classifier combination for contextual idiom detection without labelled data. [sent-228, score-0.433]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('idiomatic', 0.516), ('wiktionary', 0.443), ('idiom', 0.305), ('literal', 0.214), ('idioms', 0.141), ('shutova', 0.138), ('identification', 0.133), ('detection', 0.128), ('ddistance', 0.127), ('hpi', 0.127), ('hp', 0.108), ('fazly', 0.101), ('destruction', 0.095), ('weapon', 0.095), ('cook', 0.089), ('antonym', 0.089), ('synonym', 0.085), ('lesk', 0.083), ('synsets', 0.081), ('phrase', 0.075), ('entries', 0.075), ('dictionary', 0.072), ('multiword', 0.07), ('di', 0.066), ('unannotated', 0.066), ('gathered', 0.066), ('diamond', 0.063), ('dii', 0.063), ('fothergill', 0.063), ('gedigian', 0.063), ('definitions', 0.059), ('budanitsky', 0.055), ('birke', 0.055), ('zesch', 0.055), ('definition', 0.055), ('incomplete', 0.051), ('eii', 0.05), ('sag', 0.05), ('heart', 0.047), ('metaphor', 0.047), ('unconstrained', 0.047), ('dead', 0.044), ('rough', 0.044), ('phrases', 0.044), ('freund', 0.042), ('yi', 0.042), ('overlap', 0.041), ('wsd', 0.04), ('expressions', 0.04), ('diab', 0.039), ('rel', 0.039), ('katz', 0.039), ('disambiguation', 0.037), ('perceptron', 0.036), ('boosts', 0.036), ('baldwin', 0.036), ('annotated', 0.034), ('varied', 0.034), ('complete', 0.032), ('wr', 0.032), ('sense', 0.031), ('classifier', 0.031), ('mass', 0.03), ('precision', 0.03), ('syntactically', 0.03), ('newly', 0.029), ('entry', 0.028), ('senses', 0.028), ('wordnet', 0.028), ('recall', 0.028), ('toor', 0.028), ('catching', 0.028), ('ftourre', 0.028), ('mtoa', 0.028), ('ains', 0.028), ('abandoned', 0.028), ('atll', 0.028), ('bhutada', 0.028), ('capitals', 0.028), ('mise', 0.028), ('nonliteral', 0.028), ('oav', 0.028), ('pda', 0.028), ('pfa', 0.028), ('proportionally', 0.028), ('smoke', 0.028), ('sreet', 0.028), ('utlod', 0.028), ('yab', 0.028), ('lexical', 0.027), ('dev', 0.027), ('labels', 0.027), ('marked', 0.026), ('fall', 0.026), ('scalable', 0.026), ('identifying', 0.025), ('augments', 0.025), ('nition', 0.025), ('pine', 0.025), ('arned', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000011 <a title="32-tfidf-1" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>Author: Grace Muzny ; Luke Zettlemoyer</p><p>Abstract: Online resources, such as Wiktionary, provide an accurate but incomplete source ofidiomatic phrases. In this paper, we study the problem of automatically identifying idiomatic dictionary entries with such resources. We train an idiom classifier on a newly gathered corpus of over 60,000 Wiktionary multi-word definitions, incorporating features that model whether phrase meanings are constructed compositionally. Experiments demonstrate that the learned classifier can provide high quality idiom labels, more than doubling the number of idiomatic entries from 7,764 to 18,155 at precision levels of over 65%. These gains also translate to idiom detection in sentences, by simply using known word sense disambiguation algorithms to match phrases to their definitions. In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over 28 percentage points.</p><p>2 0.23978293 <a title="32-tfidf-2" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<p>Author: Karl Pichotta ; John DeNero</p><p>Abstract: We address the problem of identifying multiword expressions in a language, focusing on English phrasal verbs. Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages. Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking-oriented boosting algorithm produces a comprehensive set ofEnglish phrasal verbs, achieving performance comparable to a human-curated set.</p><p>3 0.073774107 <a title="32-tfidf-3" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>Author: Yiping Jin ; Min-Yen Kan ; Jun-Ping Ng ; Xiangnan He</p><p>Abstract: This paper presents DefMiner, a supervised sequence labeling system that identifies scientific terms and their accompanying definitions. DefMiner achieves 85% F1 on a Wikipedia benchmark corpus, significantly improving the previous state-of-the-art by 8%. We exploit DefMiner to process the ACL Anthology Reference Corpus (ARC) – a large, real-world digital library of scientific articles in computational linguistics. The resulting automatically-acquired glossary represents the terminology defined over several thousand individual research articles. We highlight several interesting observations: more definitions are introduced for conference and workshop papers over the years and that multiword terms account for slightly less than half of all terms. Obtaining a list of popular , defined terms in a corpus ofcomputational linguistics papers, we find that concepts can often be categorized into one of three categories: resources, methodologies and evaluation metrics.</p><p>4 0.073454022 <a title="32-tfidf-4" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>Author: Kuzman Ganchev ; Dipanjan Das</p><p>Abstract: We present a framework for cross-lingual transfer of sequence information from a resource-rich source language to a resourceimpoverished target language that incorporates soft constraints via posterior regularization. To this end, we use automatically word aligned bitext between the source and target language pair, and learn a discriminative conditional random field model on the target side. Our posterior regularization constraints are derived from simple intuitions about the task at hand and from cross-lingual alignment information. We show improvements over strong baselines for two tasks: part-of-speech tagging and namedentity segmentation.</p><p>5 0.073268712 <a title="32-tfidf-5" href="./emnlp-2013-Detecting_Compositionality_of_Multi-Word_Expressions_using_Nearest_Neighbours_in_Vector_Space_Models.html">60 emnlp-2013-Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models</a></p>
<p>Author: Douwe Kiela ; Stephen Clark</p><p>Abstract: We present a novel unsupervised approach to detecting the compositionality of multi-word expressions. We compute the compositionality of a phrase through substituting the constituent words with their “neighbours” in a semantic vector space and averaging over the distance between the original phrase and the substituted neighbour phrases. Several methods of obtaining neighbours are presented. The results are compared to existing supervised results and achieve state-of-the-art performance on a verb-object dataset of human compositionality ratings.</p><p>6 0.057533264 <a title="32-tfidf-6" href="./emnlp-2013-Word_Level_Language_Identification_in_Online_Multilingual_Communication.html">204 emnlp-2013-Word Level Language Identification in Online Multilingual Communication</a></p>
<p>7 0.054511886 <a title="32-tfidf-7" href="./emnlp-2013-Scaling_Semantic_Parsers_with_On-the-Fly_Ontology_Matching.html">164 emnlp-2013-Scaling Semantic Parsers with On-the-Fly Ontology Matching</a></p>
<p>8 0.05245059 <a title="32-tfidf-8" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>9 0.046211611 <a title="32-tfidf-9" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>10 0.042874046 <a title="32-tfidf-10" href="./emnlp-2013-Animacy_Detection_with_Voting_Models.html">23 emnlp-2013-Animacy Detection with Voting Models</a></p>
<p>11 0.038072687 <a title="32-tfidf-11" href="./emnlp-2013-Deriving_Adjectival_Scales_from_Continuous_Space_Word_Representations.html">59 emnlp-2013-Deriving Adjectival Scales from Continuous Space Word Representations</a></p>
<p>12 0.036464825 <a title="32-tfidf-12" href="./emnlp-2013-Learning_Distributions_over_Logical_Forms_for_Referring_Expression_Generation.html">119 emnlp-2013-Learning Distributions over Logical Forms for Referring Expression Generation</a></p>
<p>13 0.036140095 <a title="32-tfidf-13" href="./emnlp-2013-Naive_Bayes_Word_Sense_Induction.html">138 emnlp-2013-Naive Bayes Word Sense Induction</a></p>
<p>14 0.036069725 <a title="32-tfidf-14" href="./emnlp-2013-Prior_Disambiguation_of_Word_Tensors_for_Constructing_Sentence_Vectors.html">154 emnlp-2013-Prior Disambiguation of Word Tensors for Constructing Sentence Vectors</a></p>
<p>15 0.034384899 <a title="32-tfidf-15" href="./emnlp-2013-Max-Violation_Perceptron_and_Forced_Decoding_for_Scalable_MT_Training.html">128 emnlp-2013-Max-Violation Perceptron and Forced Decoding for Scalable MT Training</a></p>
<p>16 0.032596383 <a title="32-tfidf-16" href="./emnlp-2013-Automatically_Identifying_Pseudepigraphic_Texts.html">37 emnlp-2013-Automatically Identifying Pseudepigraphic Texts</a></p>
<p>17 0.031847641 <a title="32-tfidf-17" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>18 0.031765539 <a title="32-tfidf-18" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>19 0.031733997 <a title="32-tfidf-19" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>20 0.031612407 <a title="32-tfidf-20" href="./emnlp-2013-Improving_Pivot-Based_Statistical_Machine_Translation_Using_Random_Walk.html">103 emnlp-2013-Improving Pivot-Based Statistical Machine Translation Using Random Walk</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.128), (1, -0.003), (2, -0.01), (3, -0.017), (4, -0.008), (5, 0.094), (6, -0.026), (7, 0.009), (8, -0.049), (9, -0.056), (10, 0.057), (11, 0.102), (12, 0.088), (13, 0.174), (14, 0.074), (15, -0.007), (16, -0.079), (17, -0.007), (18, 0.03), (19, -0.159), (20, 0.013), (21, 0.079), (22, -0.059), (23, 0.119), (24, 0.099), (25, -0.011), (26, 0.185), (27, -0.029), (28, -0.058), (29, 0.014), (30, 0.124), (31, 0.018), (32, -0.046), (33, -0.312), (34, 0.024), (35, 0.007), (36, -0.006), (37, -0.014), (38, 0.115), (39, -0.073), (40, -0.097), (41, 0.017), (42, -0.028), (43, 0.088), (44, 0.05), (45, -0.048), (46, -0.102), (47, 0.124), (48, -0.058), (49, 0.096)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94328022 <a title="32-lsi-1" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>Author: Grace Muzny ; Luke Zettlemoyer</p><p>Abstract: Online resources, such as Wiktionary, provide an accurate but incomplete source ofidiomatic phrases. In this paper, we study the problem of automatically identifying idiomatic dictionary entries with such resources. We train an idiom classifier on a newly gathered corpus of over 60,000 Wiktionary multi-word definitions, incorporating features that model whether phrase meanings are constructed compositionally. Experiments demonstrate that the learned classifier can provide high quality idiom labels, more than doubling the number of idiomatic entries from 7,764 to 18,155 at precision levels of over 65%. These gains also translate to idiom detection in sentences, by simply using known word sense disambiguation algorithms to match phrases to their definitions. In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over 28 percentage points.</p><p>2 0.72458488 <a title="32-lsi-2" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<p>Author: Karl Pichotta ; John DeNero</p><p>Abstract: We address the problem of identifying multiword expressions in a language, focusing on English phrasal verbs. Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages. Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking-oriented boosting algorithm produces a comprehensive set ofEnglish phrasal verbs, achieving performance comparable to a human-curated set.</p><p>3 0.49373329 <a title="32-lsi-3" href="./emnlp-2013-Detecting_Compositionality_of_Multi-Word_Expressions_using_Nearest_Neighbours_in_Vector_Space_Models.html">60 emnlp-2013-Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models</a></p>
<p>Author: Douwe Kiela ; Stephen Clark</p><p>Abstract: We present a novel unsupervised approach to detecting the compositionality of multi-word expressions. We compute the compositionality of a phrase through substituting the constituent words with their “neighbours” in a semantic vector space and averaging over the distance between the original phrase and the substituted neighbour phrases. Several methods of obtaining neighbours are presented. The results are compared to existing supervised results and achieve state-of-the-art performance on a verb-object dataset of human compositionality ratings.</p><p>4 0.44660127 <a title="32-lsi-4" href="./emnlp-2013-Animacy_Detection_with_Voting_Models.html">23 emnlp-2013-Animacy Detection with Voting Models</a></p>
<p>Author: Joshua Moore ; Christopher J.C. Burges ; Erin Renshaw ; Wen-tau Yih</p><p>Abstract: Animacy detection is a problem whose solution has been shown to be beneficial for a number of syntactic and semantic tasks. We present a state-of-the-art system for this task which uses a number of simple classifiers with heterogeneous data sources in a voting scheme. We show how this framework can give us direct insight into the behavior of the system, allowing us to more easily diagnose sources of error.</p><p>5 0.44572762 <a title="32-lsi-5" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>Author: Yiping Jin ; Min-Yen Kan ; Jun-Ping Ng ; Xiangnan He</p><p>Abstract: This paper presents DefMiner, a supervised sequence labeling system that identifies scientific terms and their accompanying definitions. DefMiner achieves 85% F1 on a Wikipedia benchmark corpus, significantly improving the previous state-of-the-art by 8%. We exploit DefMiner to process the ACL Anthology Reference Corpus (ARC) – a large, real-world digital library of scientific articles in computational linguistics. The resulting automatically-acquired glossary represents the terminology defined over several thousand individual research articles. We highlight several interesting observations: more definitions are introduced for conference and workshop papers over the years and that multiword terms account for slightly less than half of all terms. Obtaining a list of popular , defined terms in a corpus ofcomputational linguistics papers, we find that concepts can often be categorized into one of three categories: resources, methodologies and evaluation metrics.</p><p>6 0.38904926 <a title="32-lsi-6" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>7 0.2974714 <a title="32-lsi-7" href="./emnlp-2013-Word_Level_Language_Identification_in_Online_Multilingual_Communication.html">204 emnlp-2013-Word Level Language Identification in Online Multilingual Communication</a></p>
<p>8 0.28755069 <a title="32-lsi-8" href="./emnlp-2013-Growing_Multi-Domain_Glossaries_from_a_Few_Seeds_using_Probabilistic_Topic_Models.html">92 emnlp-2013-Growing Multi-Domain Glossaries from a Few Seeds using Probabilistic Topic Models</a></p>
<p>9 0.28741914 <a title="32-lsi-9" href="./emnlp-2013-Translation_with_Source_Constituency_and_Dependency_Trees.html">187 emnlp-2013-Translation with Source Constituency and Dependency Trees</a></p>
<p>10 0.28645515 <a title="32-lsi-10" href="./emnlp-2013-Naive_Bayes_Word_Sense_Induction.html">138 emnlp-2013-Naive Bayes Word Sense Induction</a></p>
<p>11 0.2646758 <a title="32-lsi-11" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>12 0.25877461 <a title="32-lsi-12" href="./emnlp-2013-Learning_Distributions_over_Logical_Forms_for_Referring_Expression_Generation.html">119 emnlp-2013-Learning Distributions over Logical Forms for Referring Expression Generation</a></p>
<p>13 0.2418955 <a title="32-lsi-13" href="./emnlp-2013-Elephant%3A_Sequence_Labeling_for_Word_and_Sentence_Segmentation.html">72 emnlp-2013-Elephant: Sequence Labeling for Word and Sentence Segmentation</a></p>
<p>14 0.24099945 <a title="32-lsi-14" href="./emnlp-2013-Tree_Kernel-based_Negation_and_Speculation_Scope_Detection_with_Structured_Syntactic_Parse_Features.html">188 emnlp-2013-Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features</a></p>
<p>15 0.23563422 <a title="32-lsi-15" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<p>16 0.23557931 <a title="32-lsi-16" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<p>17 0.22634389 <a title="32-lsi-17" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>18 0.22247049 <a title="32-lsi-18" href="./emnlp-2013-Using_Crowdsourcing_to_get_Representations_based_on_Regular_Expressions.html">196 emnlp-2013-Using Crowdsourcing to get Representations based on Regular Expressions</a></p>
<p>19 0.21991158 <a title="32-lsi-19" href="./emnlp-2013-The_VerbCorner_Project%3A_Toward_an_Empirically-Based_Semantic_Decomposition_of_Verbs.html">183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</a></p>
<p>20 0.21905945 <a title="32-lsi-20" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.01), (18, 0.019), (22, 0.024), (30, 0.03), (51, 0.766), (66, 0.013), (75, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99799943 <a title="32-lda-1" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>Author: Peter Rebersek ; Mateja Verlic</p><p>Abstract: In this paper we present a novel approach to automatic creation of anchor texts for hyperlinks in a document pointing to similar documents. Methods used in this approach rank parts of a document based on the similarity to a presumably related document. Ranks are then used to automatically construct the best anchor text for a link inside original document to the compared document. A number of different methods from information retrieval and natural language processing are adapted for this task. Automatically constructed anchor texts are manually evaluated in terms of relatedness to linked documents and compared to baseline consisting of originally inserted anchor texts. Additionally we use crowdsourcing for evaluation of original anchors and au- tomatically constructed anchors. Results show that our best adapted methods rival the precision of the baseline method.</p><p>same-paper 2 0.99688119 <a title="32-lda-2" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>Author: Grace Muzny ; Luke Zettlemoyer</p><p>Abstract: Online resources, such as Wiktionary, provide an accurate but incomplete source ofidiomatic phrases. In this paper, we study the problem of automatically identifying idiomatic dictionary entries with such resources. We train an idiom classifier on a newly gathered corpus of over 60,000 Wiktionary multi-word definitions, incorporating features that model whether phrase meanings are constructed compositionally. Experiments demonstrate that the learned classifier can provide high quality idiom labels, more than doubling the number of idiomatic entries from 7,764 to 18,155 at precision levels of over 65%. These gains also translate to idiom detection in sentences, by simply using known word sense disambiguation algorithms to match phrases to their definitions. In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over 28 percentage points.</p><p>3 0.99453878 <a title="32-lda-3" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>4 0.99285436 <a title="32-lda-4" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<p>Author: Vikas Ganjigunte Ashok ; Song Feng ; Yejin Choi</p><p>Abstract: Predicting the success of literary works is a curious question among publishers and aspiring writers alike. We examine the quantitative connection, if any, between writing style and successful literature. Based on novels over several different genres, we probe the predictive power of statistical stylometry in discriminating successful literary works, and identify characteristic stylistic elements that are more prominent in successful writings. Our study reports for the first time that statistical stylometry can be surprisingly effective in discriminating highly successful literature from less successful counterpart, achieving accuracy up to 84%. Closer analyses lead to several new insights into characteristics ofthe writing style in successful literature, including findings that are contrary to the conventional wisdom with respect to good writing style and readability. ,</p><p>5 0.99137676 <a title="32-lda-5" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<p>Author: Karl Pichotta ; John DeNero</p><p>Abstract: We address the problem of identifying multiword expressions in a language, focusing on English phrasal verbs. Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages. Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking-oriented boosting algorithm produces a comprehensive set ofEnglish phrasal verbs, achieving performance comparable to a human-curated set.</p><p>6 0.99077487 <a title="32-lda-6" href="./emnlp-2013-Orthonormal_Explicit_Topic_Analysis_for_Cross-Lingual_Document_Matching.html">148 emnlp-2013-Orthonormal Explicit Topic Analysis for Cross-Lingual Document Matching</a></p>
<p>7 0.98935491 <a title="32-lda-7" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>8 0.98610955 <a title="32-lda-8" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>9 0.93016094 <a title="32-lda-9" href="./emnlp-2013-Detecting_Compositionality_of_Multi-Word_Expressions_using_Nearest_Neighbours_in_Vector_Space_Models.html">60 emnlp-2013-Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models</a></p>
<p>10 0.92699862 <a title="32-lda-10" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>11 0.92131603 <a title="32-lda-11" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>12 0.91755086 <a title="32-lda-12" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>13 0.91741365 <a title="32-lda-13" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>14 0.91648459 <a title="32-lda-14" href="./emnlp-2013-Automatically_Identifying_Pseudepigraphic_Texts.html">37 emnlp-2013-Automatically Identifying Pseudepigraphic Texts</a></p>
<p>15 0.91615576 <a title="32-lda-15" href="./emnlp-2013-MCTest%3A_A_Challenge_Dataset_for_the_Open-Domain_Machine_Comprehension_of_Text.html">126 emnlp-2013-MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</a></p>
<p>16 0.91456455 <a title="32-lda-16" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>17 0.9124741 <a title="32-lda-17" href="./emnlp-2013-Authorship_Attribution_of_Micro-Messages.html">27 emnlp-2013-Authorship Attribution of Micro-Messages</a></p>
<p>18 0.90731627 <a title="32-lda-18" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>19 0.90623659 <a title="32-lda-19" href="./emnlp-2013-Assembling_the_Kazakh_Language_Corpus.html">26 emnlp-2013-Assembling the Kazakh Language Corpus</a></p>
<p>20 0.90158802 <a title="32-lda-20" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
