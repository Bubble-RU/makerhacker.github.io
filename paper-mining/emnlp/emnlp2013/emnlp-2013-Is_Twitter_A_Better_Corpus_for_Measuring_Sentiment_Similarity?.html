<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-109" href="#">emnlp2013-109</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</h1>
<br/><p>Source: <a title="emnlp-2013-109-pdf" href="http://aclweb.org/anthology//D/D13/D13-1091.pdf">pdf</a></p><p>Author: Shi Feng ; Le Zhang ; Binyang Li ; Daling Wang ; Ge Yu ; Kam-Fai Wong</p><p>Abstract: Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people’s sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.</p><p>Reference: <a title="emnlp-2013-109-reference" href="../emnlp2013_reference/emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 hakn  Abstract Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. [sent-15, score-0.467]
</p><p>2 However, no work is done for comparing different corpora in the polarity classification task. [sent-16, score-0.326]
</p><p>3 In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. [sent-18, score-0.909]
</p><p>4 1 Introduction Measuring semantic similarity for words and short texts has long been a fundamental problem for many  applications such as word sense disambiguation, query expansion, search advertising and so on. [sent-20, score-0.378]
</p><p>5 Determining the word’s polarity plays a critical role in opinion mining and sentiment analysis task. [sent-21, score-0.689]
</p><p>6 A lot of papers have been published for designing appropriate similarity measurements. [sent-23, score-0.174]
</p><p>7 One direction is 897 to learn similarity from the knowledge base or concept taxonomy (Lin, 1998; Resnik, 1999). [sent-24, score-0.207]
</p><p>8 Another direction is to learn semantic similarity with the help of large corpus such as Web or Wikipedia data (Sahami and Heilman, 2006; Yih and Meek, 2007; Bollegala et al. [sent-25, score-0.238]
</p><p>9 The basic assumption of this kind of methods is that the word with similar semantic meanings of-  ten co-occur in the given corpus. [sent-27, score-0.064]
</p><p>10 Extensive experiments have validated the effectiveness of the corpusbased method in polarity classification task (Turney, 2002; Kaji and Kitsuregawa, 2007; Velikovich et al. [sent-28, score-0.361]
</p><p>11 For example, PMI is a well-known similarity measurement (Turney, 2002), which makes use of the whole Web as the corpus, and utilizes the search engine hits number to estimate the co-occurrence probability of the give word pairs. [sent-30, score-0.282]
</p><p>12 However, according to Kanayama’s investigation, only 60% co-occurrences in the same window in Web pages reflect the same sentiment orientation (Kanayama and Nasukawa, 2006). [sent-32, score-0.555]
</p><p>13 Therefore, we may ask the question whether the choosing of corpus can change the performance of sim and is there any better corpus than the Web page data for measuring the sentiment similarity? [sent-33, score-0.66]
</p><p>14 Everyday, enormous numbers of tweets that contain people’s rich sentiments are published in Twitter. [sent-34, score-0.253]
</p><p>15 The Twitter may be a good source for measuring the sentiment similarity. [sent-35, score-0.524]
</p><p>16 Compared with the Web page data, the tweets have a higher rate of subjective text posts. [sent-36, score-0.258]
</p><p>17 The length limitation can guarantee the  polarity consistency of each tweet. [sent-37, score-0.403]
</p><p>18 Moreover, the tweets contain graphical emoticons, which can be ProceSe datintlges, o Wfa tsh ein 2g01to3n, C UoSnfAe,re 1n8c-e2 o1n O Ecmtopbier ic 2a0l1 M3. [sent-38, score-0.201]
</p><p>19 hc o2d0s1 i3n A Nsastoucria lti Loan fgoura Cgoem Ppruotcaetsiosin agl, L piang eusis 8t9ic7s–902, considered as natural sentiment labels for the corresponding tweets in Twitter. [sent-40, score-0.601]
</p><p>20 In this paper, we attempt to empirically evaluate the performance of different corpora in sentiment similarity measurement task. [sent-41, score-0.678]
</p><p>21 2  The Characteristics of Twitter Data  As the world’s second largest SNS website, at the end of 2012 Twitter had aggregated more than 500 million registered users, among which 200 million were active users . [sent-43, score-0.177]
</p><p>22 More than 400 million tweets are posted every day. [sent-44, score-0.261]
</p><p>23 (1) She had a headache and feeling light headed with no energy. [sent-46, score-0.1]
</p><p>24 We observe that comparing with the other corpus, the Twitter data has several advantages in measuring the sentiment similarity. [sent-54, score-0.57]
</p><p>25 So there are huge amount of subjective texts with various topics generated in the millions of tweets everyday. [sent-59, score-0.289]
</p><p>26 So the sentiments in tweets are usually concise, straightforward and polarity consistent. [sent-64, score-0.5]
</p><p>27 Users tend to utilize emoticons to emphasize their sentiment feelings. [sent-66, score-0.561]
</p><p>28 1% tweets contain at least one emoticon (Yang and Leskovec, 2011). [sent-68, score-0.201]
</p><p>29 Since the tweets have the length limitation, the sentiments expressed in these short texts are usually consistent with the embedded emoticons, such as the word fun and headache in above examples. [sent-69, score-0.465]
</p><p>30 In addition to the above advantages, there are al-  so some disadvantages for measuring sentiment similarity using Twitter data. [sent-70, score-0.749]
</p><p>31 The spam tweets that 898 caused by advertisements may add noise and bias during the similarity measurement. [sent-71, score-0.412]
</p><p>32 The short length may also bring in lower co-occurrence probability of words. [sent-72, score-0.069]
</p><p>33 These disadvantages set obstacles for measuring sentiment similarity by using Twitter data as corpus. [sent-74, score-0.749]
</p><p>34 In the experiment section, we will see if we can overcome these drawbacks and get benefit from the advantages of Twitter data. [sent-75, score-0.088]
</p><p>35 3  The Corpus-based Sentiment Similarity Measurements  The intuition behind the corpus-based semantic similarity measuring method is that the words with similar meanings tend to co-occur in the corpus. [sent-76, score-0.362]
</p><p>36 Given the word wi, wj, we use the notation P(wi) to denote the occurrence counts of word wi in the corpus C. [sent-77, score-0.181]
</p><p>37 e Itns this paper, we utilize these classical measurements to evaluate the quality of the corpus in polarity classification task. [sent-85, score-0.406]
</p><p>38 Google is the world’s largest search engine, which has indexed a huge number of Web pages. [sent-86, score-0.091]
</p><p>39 Using the extreme large indexed Web pages as corpus, Cilibrasi and Vitanyi (2007) presented a method for measuring similarity between words and phrases based on information distance and Kolmogorov complexity. [sent-87, score-0.398]
</p><p>40 The search result page counts of Google  were utilized to estimate the occurrence frequencies of the words in the corpus. [sent-88, score-0.108]
</p><p>41 Cilibrasi and Vitanyi have validated the effectiveness of Google distance in measuring the semantic similarity between concept words. [sent-90, score-0.429]
</p><p>42 Based on the above formulas, we compare the Twitter data with the Web and Wikipedia data as the similarity measurement corpus. [sent-91, score-0.246]
</p><p>43 Given a candidate word w, we firstly measure its sentiment similarity with a positive seed word and a negative seed word respectively in Formula (1), and the difference of sim is used to further detect the polarity of w. [sent-92, score-1.427]
</p><p>44 The above four similarity measurements serve as  sim with Web, Wikipedia and Twitter data as corpus. [sent-93, score-0.365]
</p><p>45 Turney (2002) chose excellent and poor as seed words. [sent-94, score-0.385]
</p><p>46 However, using isolated seed words may cause the bias problem. [sent-95, score-0.247]
</p><p>47 Therefore, we further select two groups of seed words that are lack of sensitivity to context and form a positive seed set PS and a negative seed set NS (Turney, 2003). [sent-96, score-0.782]
</p><p>48 For calculating page counts in Web data, the candidate words were launched to Google from February 2013 to April 2013. [sent-100, score-0.108]
</p><p>49 We also conduct the experiments on the Google Web 1T data that consists of Google n-gram counts (frequency of occurrence of each n-gram) for 1 ≤ n ≤ 5 (Brants and Franz, 2006). [sent-101, score-0.051]
</p><p>50 gTrahem )W feobr 11T ≤ ≤da nta provides a tnsic aen approximation to the word co-occurrence statistics in Web pages in a predefined window size (1 ≤ n ≤ 5). [sent-102, score-0.096]
</p><p>51 The English Wikipedia dump 1 we used was extracted at the end of March 2013, which contained more than 13 million articles. [sent-104, score-0.06]
</p><p>52 Two well-know sentiment lexicons are utilized as gold standard for polarity classification task. [sent-107, score-0.732]
</p><p>53 The statistics of Liu’s sentiment lexicon (Liu et al. [sent-108, score-0.437]
</p><p>54 For each word w in the lexicons, we employ the Formula (6) to calculate the word’s polarity using different corpora. [sent-111, score-0.247]
</p><p>55 SO(w) =sepX∈PSsim(w,sep) −senX∈NSsim(w,sen)(6)  MLPiQuAPo2 s, 03it0 v64e#Ne4 g, 7a18t5i3 ve#  Based on the Formula(6) and the sentiment seed words, we can measure the sentiment polarity of the given candidate words. [sent-115, score-1.294]
</p><p>56 The Twitter corpus corresponds to the 476 million Twitter tweets (Yang and Leskovec, 2011), which includes over 476 million  Twitter posts from 20 million users, covering a 7 month period from June 1, 2009 to December 3 1, 2009. [sent-118, score-0.381]
</p><p>57 We filter out the non-English tweets and the spam tweets that have only few words with URLs. [sent-119, score-0.439]
</p><p>58 The tweets that contain three or more trending topics 899 Table 1: Lexicon size 4. [sent-120, score-0.201]
</p><p>59 2 Experiment Results Firstly, we chose the seed words excellent and poor as Turney’s (2002) settings. [sent-121, score-0.385]
</p><p>60 The polarity classification accuracies are shown in Table 2. [sent-122, score-0.329]
</p><p>61 34535G224036788D249743615635442 Table 2: Polarity classification accuracies using excellent and poor as seed words natural window size (140 characters) have a positive impact on determining the word’s polarity. [sent-135, score-0.513]
</p><p>62 The Google based method gets a lower accuracy, this may be due to the length of Web documents which can not usually guarantee the semantic consistency in the returned data. [sent-136, score-0.208]
</p><p>63 Even though two words appear in one page (returned by Google), they might not be semantically related. [sent-137, score-0.057]
</p><p>64 After detailed analysis, we find that  although the small window size (4 or 5) can guarantee the semantic consistency, the short length also brings in lower co-occurrence probability. [sent-140, score-0.216]
</p><p>65 To tackle the low co-occurrence problem, the seed word sets are selected as Turney’s (2003) settings. [sent-143, score-0.247]
</p><p>66 Table 3 shows that the performance ofTwitter corpus is much improved since the multiple seed words alleviate the problem of low co-occurrence probability in tweets. [sent-148, score-0.247]
</p><p>67 Generally, when using the seed word groups the Twitter can achieve a much better performance than all the other corpora. [sent-149, score-0.288]
</p><p>68 546 7329 851673  Table 3: Polarity classification accuracies using the seed word groups  We further add the emoticons ‘:)’ and ‘:(’ into the seed word groups, denoted by Twitter+ in Table 3. [sent-160, score-0.778]
</p><p>69 We can see that the performances are further improved by considering emoticons as seed words. [sent-162, score-0.408]
</p><p>70 The above experiment results have validated the effectiveness of Twitter data as a better corpus for measuring the sentiment similarity. [sent-163, score-0.633]
</p><p>71 The results also reveal the potential usefulness of Twitter corpus in semantic similarity measurement. [sent-164, score-0.238]
</p><p>72 5  Related Work  Detecting the polarity of words is the fundamental problem for most of sentiment analysis tasks (Hatzivassiloglou and McKeown, 1997; Pang and Lee, 2007; Feldman, 2013). [sent-165, score-0.703]
</p><p>73 Many methods have been proposed to measure the words’ or short texts similarity based on large corpus (Sahami and Heilman, 2006; Yih and Meek, 2007; Gabrilovich and Markovitch, 2007). [sent-166, score-0.258]
</p><p>74 (201 1) submitted the word to the search engine, and the related result pages were employed to represent the meaning of the original word. [sent-168, score-0.05]
</p><p>75 (2006) proposed a method to measure the semantic similarity of words or short texts, considering both corpus-based and knowledge-based information. [sent-170, score-0.275]
</p><p>76 (2012; 2013a; 2013b) introduced the concept of sentiment similarity, which was considered as different from the traditional semantic similarity, and more focused on revealing the underlying sentiment relations between words. [sent-173, score-0.864]
</p><p>77 (2013b) proposed a hidden emotional model to calculating the sentiment similarity of word pairs. [sent-175, score-0.609]
</p><p>78 (2013) generated wordsentiment association lexicons from Tweets with the help of hashtags and emoticons. [sent-178, score-0.073]
</p><p>79 Pak and Paroubek (2010) collected tweets with happy and sad emoticons as training corpus, and built sentiment classifier based on traditional machine learning methods. [sent-179, score-0.762]
</p><p>80 Brody and Diakopoulos (201 1) showed that lengthening was strongly associated with subjectivity and sentiment in tweets. [sent-180, score-0.444]
</p><p>81 (2010) treated 50 Twitter tags and 15 smileys as sentiment labels and a supervised sentiment classification framework was proposed to classify the tweets. [sent-182, score-0.847]
</p><p>82 The previous literatures have showed that the emoticons can be treated as natural sentiment labels of the tweets. [sent-183, score-0.561]
</p><p>83 6  Conclusion and Future Work  The quality of corpus may affect the performance of sentiment similarity measurement. [sent-184, score-0.574]
</p><p>84 In this paper, we compare the Twitter data with the Google, Web1T and Wikipedia data in polarity classification  task. [sent-185, score-0.294]
</p><p>85 The experiment results validate that when using the seed word groups the Twitter can achieve a much better performance than the other corpora and adding emoticons as seed words can further improve the performance. [sent-186, score-0.77]
</p><p>86 It is observed that the twitter corpus is a potential good source for measuring sentiment similarity between words. [sent-187, score-1.08]
</p><p>87 In future work, we intend to design new similarity measurements that can make best of the advantages of Twitter data. [sent-188, score-0.332]
</p><p>88 In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 562–570, Edinburgh, UK, ACL. [sent-216, score-0.05]
</p><p>89 In Proceedings of the 23rd International Conference on Computational Linguistics, pages 241– 249, Beijing, China, ACL. [sent-228, score-0.05]
</p><p>90 In Proceedings of the 20th International Joint Conference on Artificial Intelligence, pages 1606–161 1, Hyderabad, India. [sent-236, score-0.05]
</p><p>91 In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 174–181, Madrid, Spain, ACL. [sent-240, score-0.05]
</p><p>92 In Proceedings of the 9th International Workshop on Knowledge Discovery on the Web and 1st International Workshop on Social Networks Analysis, pages 118–138, San Jose, CA, USA, Springer. [sent-245, score-0.05]
</p><p>93 In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 355–363, Sydney, Australia, ACL. [sent-253, score-0.05]
</p><p>94 In Proceedings of the 19th International Conference on World Wide Web, pages 591–600, Raleigh, North Carolina, USA, ACM. [sent-258, score-0.05]
</p><p>95 In Proceedings of the 17th International Conference on Computational Linguistics, pages 768–774, Montreal, Quebec, Canada, ACL. [sent-262, score-0.05]
</p><p>96 In Proceedings of the 14th international conference on World Wide Web, pages 342–35 1, Chiba, Japan, ACM. [sent-266, score-0.05]
</p><p>97 In Proceedings ofthe 21st National Conference on Artificial Intelligence and the 18th Innovative Applications of Artificial Intelligence Conference, pages 775–780, Boston, Massachusetts, USA, AAAI Press. [sent-270, score-0.05]
</p><p>98 In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelli-  gence, pages 1706–1712, Toronto, Ontario, Canada, AAAI Press. [sent-274, score-0.05]
</p><p>99 In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence, pages 711–717, Bellevue, Washington, USA, AAAI Press. [sent-278, score-0.05]
</p><p>100 Measuring praise and criticism: Inference of semantic orientation from association. [sent-313, score-0.123]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sentiment', 0.4), ('twitter', 0.382), ('seed', 0.247), ('polarity', 0.247), ('tweets', 0.201), ('similarity', 0.174), ('emoticons', 0.161), ('wj', 0.137), ('wi', 0.13), ('measuring', 0.124), ('measurements', 0.112), ('formula', 0.111), ('google', 0.103), ('mohtarami', 0.102), ('turney', 0.101), ('excellent', 0.098), ('web', 0.092), ('cilibrasi', 0.088), ('kanayama', 0.088), ('sim', 0.079), ('measurement', 0.072), ('sahami', 0.07), ('china', 0.068), ('wikipedia', 0.067), ('validated', 0.067), ('bollegala', 0.065), ('semantic', 0.064), ('mitra', 0.062), ('gabrilovich', 0.062), ('million', 0.06), ('orientation', 0.059), ('headache', 0.059), ('sep', 0.059), ('vitanyi', 0.059), ('xiaodan', 0.059), ('hong', 0.058), ('kong', 0.058), ('aaai', 0.057), ('page', 0.057), ('users', 0.057), ('lan', 0.056), ('fundamental', 0.056), ('yih', 0.052), ('sentiments', 0.052), ('canada', 0.051), ('disadvantages', 0.051), ('velikovich', 0.051), ('jw', 0.051), ('kwak', 0.051), ('counts', 0.051), ('indexed', 0.05), ('pages', 0.05), ('chew', 0.047), ('hatzivassiloglou', 0.047), ('meek', 0.047), ('pak', 0.047), ('texts', 0.047), ('classification', 0.047), ('advantages', 0.046), ('window', 0.046), ('limitation', 0.044), ('usa', 0.044), ('lengthening', 0.044), ('markovitch', 0.044), ('kaji', 0.044), ('consistency', 0.043), ('opinion', 0.042), ('lim', 0.042), ('experiment', 0.042), ('huge', 0.041), ('leskovec', 0.041), ('headed', 0.041), ('groups', 0.041), ('poor', 0.04), ('davidov', 0.039), ('sen', 0.039), ('java', 0.039), ('lexicons', 0.038), ('fun', 0.037), ('spam', 0.037), ('thumbs', 0.037), ('mohammad', 0.037), ('lexicon', 0.037), ('guarantee', 0.037), ('short', 0.037), ('engine', 0.036), ('man', 0.036), ('heilman', 0.036), ('accuracies', 0.035), ('artificial', 0.035), ('columbia', 0.035), ('nice', 0.035), ('hashtags', 0.035), ('emotional', 0.035), ('firstly', 0.033), ('taxonomy', 0.033), ('proceedings', 0.033), ('corpora', 0.032), ('returned', 0.032), ('length', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999893 <a title="109-tfidf-1" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>Author: Shi Feng ; Le Zhang ; Binyang Li ; Daling Wang ; Ge Yu ; Kam-Fai Wong</p><p>Abstract: Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people’s sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.</p><p>2 0.3952238 <a title="109-tfidf-2" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>3 0.32150793 <a title="109-tfidf-3" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: Theresa Wilson Human Language Technology Center of Excellence Johns Hopkins University Baltimore, MD t aw@ j hu .edu differences may Different demographics, e.g., gender or age, can demonstrate substantial variation in their language use, particularly in informal contexts such as social media. In this paper we focus on learning gender differences in the use of subjective language in English, Spanish, and Russian Twitter data, and explore cross-cultural differences in emoticon and hashtag use for male and female users. We show that gender differences in subjective language can effectively be used to improve sentiment analysis, and in particular, polarity classification for Spanish and Russian. Our results show statistically significant relative F-measure improvement over the gender-independent baseline 1.5% and 1% for Russian, 2% and 0.5% for Spanish, and 2.5% and 5% for English for polarity and subjectivity classification.</p><p>4 0.1912328 <a title="109-tfidf-4" href="./emnlp-2013-Sarcasm_as_Contrast_between_a_Positive_Sentiment_and_Negative_Situation.html">163 emnlp-2013-Sarcasm as Contrast between a Positive Sentiment and Negative Situation</a></p>
<p>Author: Ellen Riloff ; Ashequl Qadir ; Prafulla Surve ; Lalindra De Silva ; Nathan Gilbert ; Ruihong Huang</p><p>Abstract: A common form of sarcasm on Twitter consists of a positive sentiment contrasted with a negative situation. For example, many sarcastic tweets include a positive sentiment, such as “love” or “enjoy”, followed by an expression that describes an undesirable activity or state (e.g., “taking exams” or “being ignored”). We have developed a sarcasm recognizer to identify this type of sarcasm in tweets. We present a novel bootstrapping algorithm that automatically learns lists of positive sentiment phrases and negative situation phrases from sarcastic tweets. We show that identifying contrasting contexts using the phrases learned through bootstrapping yields improved recall for sarcasm recognition.</p><p>5 0.17810172 <a title="109-tfidf-5" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>Author: Richard Socher ; Alex Perelygin ; Jean Wu ; Jason Chuang ; Christopher D. Manning ; Andrew Ng ; Christopher Potts</p><p>Abstract: Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.</p><p>6 0.17736125 <a title="109-tfidf-6" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>7 0.16163754 <a title="109-tfidf-7" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>8 0.15647501 <a title="109-tfidf-8" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>9 0.15559177 <a title="109-tfidf-9" href="./emnlp-2013-Authorship_Attribution_of_Micro-Messages.html">27 emnlp-2013-Authorship Attribution of Micro-Messages</a></p>
<p>10 0.15204462 <a title="109-tfidf-10" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>11 0.11921445 <a title="109-tfidf-11" href="./emnlp-2013-A_Study_on_Bootstrapping_Bilingual_Vector_Spaces_from_Non-Parallel_Data_%28and_Nothing_Else%29.html">13 emnlp-2013-A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data (and Nothing Else)</a></p>
<p>12 0.11362666 <a title="109-tfidf-12" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>13 0.11135665 <a title="109-tfidf-13" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>14 0.11132129 <a title="109-tfidf-14" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>15 0.099346735 <a title="109-tfidf-15" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>16 0.097968273 <a title="109-tfidf-16" href="./emnlp-2013-Learning_Latent_Word_Representations_for_Domain_Adaptation_using_Supervised_Word_Clustering.html">120 emnlp-2013-Learning Latent Word Representations for Domain Adaptation using Supervised Word Clustering</a></p>
<p>17 0.095091142 <a title="109-tfidf-17" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>18 0.087568164 <a title="109-tfidf-18" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<p>19 0.080629528 <a title="109-tfidf-19" href="./emnlp-2013-Building_Specialized_Bilingual_Lexicons_Using_Large_Scale_Background_Knowledge.html">42 emnlp-2013-Building Specialized Bilingual Lexicons Using Large Scale Background Knowledge</a></p>
<p>20 0.078057632 <a title="109-tfidf-20" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.253), (1, 0.132), (2, -0.326), (3, -0.31), (4, 0.241), (5, -0.157), (6, -0.025), (7, -0.141), (8, 0.121), (9, 0.124), (10, -0.034), (11, 0.06), (12, 0.052), (13, -0.022), (14, -0.042), (15, -0.1), (16, -0.015), (17, 0.013), (18, 0.07), (19, 0.048), (20, -0.085), (21, -0.033), (22, -0.021), (23, 0.001), (24, -0.018), (25, -0.107), (26, 0.017), (27, 0.047), (28, 0.042), (29, -0.002), (30, -0.011), (31, 0.014), (32, 0.05), (33, 0.014), (34, -0.065), (35, 0.038), (36, -0.002), (37, -0.041), (38, -0.058), (39, 0.003), (40, -0.023), (41, -0.042), (42, -0.022), (43, 0.028), (44, 0.024), (45, -0.071), (46, -0.052), (47, -0.012), (48, -0.001), (49, -0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9716447 <a title="109-lsi-1" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>Author: Shi Feng ; Le Zhang ; Binyang Li ; Daling Wang ; Ge Yu ; Kam-Fai Wong</p><p>Abstract: Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people’s sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.</p><p>2 0.85766792 <a title="109-lsi-2" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: Theresa Wilson Human Language Technology Center of Excellence Johns Hopkins University Baltimore, MD t aw@ j hu .edu differences may Different demographics, e.g., gender or age, can demonstrate substantial variation in their language use, particularly in informal contexts such as social media. In this paper we focus on learning gender differences in the use of subjective language in English, Spanish, and Russian Twitter data, and explore cross-cultural differences in emoticon and hashtag use for male and female users. We show that gender differences in subjective language can effectively be used to improve sentiment analysis, and in particular, polarity classification for Spanish and Russian. Our results show statistically significant relative F-measure improvement over the gender-independent baseline 1.5% and 1% for Russian, 2% and 0.5% for Spanish, and 2.5% and 5% for English for polarity and subjectivity classification.</p><p>3 0.83756083 <a title="109-lsi-3" href="./emnlp-2013-Sarcasm_as_Contrast_between_a_Positive_Sentiment_and_Negative_Situation.html">163 emnlp-2013-Sarcasm as Contrast between a Positive Sentiment and Negative Situation</a></p>
<p>Author: Ellen Riloff ; Ashequl Qadir ; Prafulla Surve ; Lalindra De Silva ; Nathan Gilbert ; Ruihong Huang</p><p>Abstract: A common form of sarcasm on Twitter consists of a positive sentiment contrasted with a negative situation. For example, many sarcastic tweets include a positive sentiment, such as “love” or “enjoy”, followed by an expression that describes an undesirable activity or state (e.g., “taking exams” or “being ignored”). We have developed a sarcasm recognizer to identify this type of sarcasm in tweets. We present a novel bootstrapping algorithm that automatically learns lists of positive sentiment phrases and negative situation phrases from sarcastic tweets. We show that identifying contrasting contexts using the phrases learned through bootstrapping yields improved recall for sarcasm recognition.</p><p>4 0.83407795 <a title="109-lsi-4" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>5 0.68410194 <a title="109-lsi-5" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>6 0.65193117 <a title="109-lsi-6" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>7 0.55066818 <a title="109-lsi-7" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>8 0.53685653 <a title="109-lsi-8" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>9 0.49613729 <a title="109-lsi-9" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>10 0.44653767 <a title="109-lsi-10" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>11 0.42447236 <a title="109-lsi-11" href="./emnlp-2013-Authorship_Attribution_of_Micro-Messages.html">27 emnlp-2013-Authorship Attribution of Micro-Messages</a></p>
<p>12 0.4149518 <a title="109-lsi-12" href="./emnlp-2013-Understanding_and_Quantifying_Creativity_in_Lexical_Composition.html">191 emnlp-2013-Understanding and Quantifying Creativity in Lexical Composition</a></p>
<p>13 0.36256072 <a title="109-lsi-13" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>14 0.36005208 <a title="109-lsi-14" href="./emnlp-2013-Using_Crowdsourcing_to_get_Representations_based_on_Regular_Expressions.html">196 emnlp-2013-Using Crowdsourcing to get Representations based on Regular Expressions</a></p>
<p>15 0.35656357 <a title="109-lsi-15" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>16 0.33680695 <a title="109-lsi-16" href="./emnlp-2013-A_Study_on_Bootstrapping_Bilingual_Vector_Spaces_from_Non-Parallel_Data_%28and_Nothing_Else%29.html">13 emnlp-2013-A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data (and Nothing Else)</a></p>
<p>17 0.31243411 <a title="109-lsi-17" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<p>18 0.30391571 <a title="109-lsi-18" href="./emnlp-2013-Detecting_Promotional_Content_in_Wikipedia.html">61 emnlp-2013-Detecting Promotional Content in Wikipedia</a></p>
<p>19 0.30123147 <a title="109-lsi-19" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>20 0.29123747 <a title="109-lsi-20" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.025), (18, 0.02), (22, 0.044), (30, 0.068), (43, 0.016), (50, 0.01), (51, 0.111), (66, 0.538), (71, 0.035), (75, 0.02), (96, 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90723813 <a title="109-lda-1" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>Author: Shi Feng ; Le Zhang ; Binyang Li ; Daling Wang ; Ge Yu ; Kam-Fai Wong</p><p>Abstract: Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people’s sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.</p><p>2 0.81611288 <a title="109-lda-2" href="./emnlp-2013-Translating_into_Morphologically_Rich_Languages_with_Synthetic_Phrases.html">186 emnlp-2013-Translating into Morphologically Rich Languages with Synthetic Phrases</a></p>
<p>Author: Victor Chahuneau ; Eva Schlinger ; Noah A. Smith ; Chris Dyer</p><p>Abstract: Translation into morphologically rich languages is an important but recalcitrant problem in MT. We present a simple and effective approach that deals with the problem in two phases. First, a discriminative model is learned to predict inflections of target words from rich source-side annotations. Then, this model is used to create additional sentencespecific word- and phrase-level translations that are added to a standard translation model as “synthetic” phrases. Our approach relies on morphological analysis of the target language, but we show that an unsupervised Bayesian model of morphology can successfully be used in place of a supervised analyzer. We report significant improvements in translation quality when translating from English to Russian, Hebrew and Swahili.</p><p>3 0.79387629 <a title="109-lda-3" href="./emnlp-2013-What_is_Hidden_among_Translation_Rules.html">201 emnlp-2013-What is Hidden among Translation Rules</a></p>
<p>Author: Libin Shen ; Bowen Zhou</p><p>Abstract: Most of the machine translation systems rely on a large set of translation rules. These rules are treated as discrete and independent events. In this short paper, we propose a novel method to model rules as observed generation output of a compact hidden model, which leads to better generalization capability. We present a preliminary generative model to test this idea. Experimental results show about one point improvement on TER-BLEU over a strong baseline in Chinese-to-English translation.</p><p>4 0.63650864 <a title="109-lda-4" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>Author: Jun-Ping Ng ; Min-Yen Kan ; Ziheng Lin ; Wei Feng ; Bin Chen ; Jian Su ; Chew Lim Tan</p><p>Abstract: In this paper we classify the temporal relations between pairs of events on an article-wide basis. This is in contrast to much of the existing literature which focuses on just event pairs which are found within the same or adjacent sentences. To achieve this, we leverage on discourse analysis as we believe that it provides more useful semantic information than typical lexico-syntactic features. We propose the use of several discourse analysis frameworks, including 1) Rhetorical Structure Theory (RST), 2) PDTB-styled discourse relations, and 3) topical text segmentation. We explain how features derived from these frameworks can be effectively used with support vector machines (SVM) paired with convolution kernels. Experiments show that our proposal is effective in improving on the state-of-the-art significantly by as much as 16% in terms of F1, even if we only adopt less-than-perfect automatic discourse analyzers and parsers. Making use of more accurate discourse analysis can further boost gains to 35%.</p><p>5 0.49604809 <a title="109-lda-5" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: Theresa Wilson Human Language Technology Center of Excellence Johns Hopkins University Baltimore, MD t aw@ j hu .edu differences may Different demographics, e.g., gender or age, can demonstrate substantial variation in their language use, particularly in informal contexts such as social media. In this paper we focus on learning gender differences in the use of subjective language in English, Spanish, and Russian Twitter data, and explore cross-cultural differences in emoticon and hashtag use for male and female users. We show that gender differences in subjective language can effectively be used to improve sentiment analysis, and in particular, polarity classification for Spanish and Russian. Our results show statistically significant relative F-measure improvement over the gender-independent baseline 1.5% and 1% for Russian, 2% and 0.5% for Spanish, and 2.5% and 5% for English for polarity and subjectivity classification.</p><p>6 0.49192122 <a title="109-lda-6" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>7 0.45224193 <a title="109-lda-7" href="./emnlp-2013-Automatic_Extraction_of_Morphological_Lexicons_from_Morphologically_Annotated_Corpora.html">30 emnlp-2013-Automatic Extraction of Morphological Lexicons from Morphologically Annotated Corpora</a></p>
<p>8 0.45107234 <a title="109-lda-8" href="./emnlp-2013-Adaptor_Grammars_for_Learning_Non-Concatenative_Morphology.html">19 emnlp-2013-Adaptor Grammars for Learning Non-Concatenative Morphology</a></p>
<p>9 0.44913372 <a title="109-lda-9" href="./emnlp-2013-Exploring_the_Utility_of_Joint_Morphological_and_Syntactic_Learning_from_Child-directed_Speech.html">83 emnlp-2013-Exploring the Utility of Joint Morphological and Syntactic Learning from Child-directed Speech</a></p>
<p>10 0.44145018 <a title="109-lda-10" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>11 0.44100943 <a title="109-lda-11" href="./emnlp-2013-Deriving_Adjectival_Scales_from_Continuous_Space_Word_Representations.html">59 emnlp-2013-Deriving Adjectival Scales from Continuous Space Word Representations</a></p>
<p>12 0.43545425 <a title="109-lda-12" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<p>13 0.43409321 <a title="109-lda-13" href="./emnlp-2013-A_Joint_Learning_Model_of_Word_Segmentation%2C_Lexical_Acquisition%2C_and_Phonetic_Variability.html">8 emnlp-2013-A Joint Learning Model of Word Segmentation, Lexical Acquisition, and Phonetic Variability</a></p>
<p>14 0.42379069 <a title="109-lda-14" href="./emnlp-2013-Breaking_Out_of_Local_Optima_with_Count_Transforms_and_Model_Recombination%3A_A_Study_in_Grammar_Induction.html">40 emnlp-2013-Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction</a></p>
<p>15 0.42325574 <a title="109-lda-15" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>16 0.42311564 <a title="109-lda-16" href="./emnlp-2013-Bilingual_Word_Embeddings_for_Phrase-Based_Machine_Translation.html">38 emnlp-2013-Bilingual Word Embeddings for Phrase-Based Machine Translation</a></p>
<p>17 0.41072902 <a title="109-lda-17" href="./emnlp-2013-Naive_Bayes_Word_Sense_Induction.html">138 emnlp-2013-Naive Bayes Word Sense Induction</a></p>
<p>18 0.41000724 <a title="109-lda-18" href="./emnlp-2013-Recurrent_Continuous_Translation_Models.html">156 emnlp-2013-Recurrent Continuous Translation Models</a></p>
<p>19 0.40901837 <a title="109-lda-19" href="./emnlp-2013-Interactive_Machine_Translation_using_Hierarchical_Translation_Models.html">107 emnlp-2013-Interactive Machine Translation using Hierarchical Translation Models</a></p>
<p>20 0.40801024 <a title="109-lda-20" href="./emnlp-2013-Modeling_and_Learning_Semantic_Co-Compositionality_through_Prototype_Projections_and_Neural_Networks.html">134 emnlp-2013-Modeling and Learning Semantic Co-Compositionality through Prototype Projections and Neural Networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
