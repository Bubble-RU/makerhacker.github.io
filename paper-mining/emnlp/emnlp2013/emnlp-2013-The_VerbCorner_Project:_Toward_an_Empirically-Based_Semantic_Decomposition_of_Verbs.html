<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-183" href="#">emnlp2013-183</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</h1>
<br/><p>Source: <a title="emnlp-2013-183-pdf" href="http://aclweb.org/anthology//D/D13/D13-1149.pdf">pdf</a></p><p>Author: Joshua K. Hartshorne ; Claire Bonial ; Martha Palmer</p><p>Abstract: This research describes efforts to use crowdsourcing to improve the validity of the semantic predicates in VerbNet, a lexicon of about 6300 English verbs. The current semantic predicates can be thought of semantic primitives, into which the concepts denoted by a verb can be decomposed. For example, the verb spray (of the Spray class), involves the predicates MOTION, NOT, and LOCATION, where the event can be decomposed into an AGENT causing a THEME that was originally not in a particular location to now be in that location. Although VerbNet’s predicates are theoretically well-motivated, systematic empirical data is scarce. This paper describes a recently-launched attempt to address this issue with a series of human judgment tasks, posed to subjects in the form of games.</p><p>Reference: <a title="emnlp-2013-183-reference" href="../emnlp2013_reference/emnlp-2013-The_VerbCorner_Project%3A_Toward_an_Empirically-Based_Semantic_Decomposition_of_Verbs_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract This research describes efforts to use crowdsourcing to improve the validity of the semantic predicates in VerbNet, a lexicon of about 6300 English verbs. [sent-3, score-0.262]
</p><p>2 The current semantic predicates can be thought of semantic primitives, into which the concepts denoted by a verb can be decomposed. [sent-4, score-0.492]
</p><p>3 For example, the verb spray (of the Spray class), involves the predicates MOTION, NOT, and LOCATION, where the event can be decomposed into an AGENT causing a THEME that was originally not in a particular location to now be in that location. [sent-5, score-0.461]
</p><p>4 Although VerbNet’s predicates are theoretically well-motivated, systematic empirical data is scarce. [sent-6, score-0.192]
</p><p>5 Of particular importance is propositional meaning: To understand “Jessica sprayed paint on the wall,” it is not enough to know who Jessica is, what paint is, and where the wall is, but that, by the end of the event, some quantity of paint that was not previously on the wall now is. [sent-9, score-1.044]
</p><p>6 edu  ,  recursively induces lambda expressions from them, and uses clustering to derive progressively abstract knowledge. [sent-13, score-0.06]
</p><p>7 An alternative is to take a human-inspired approach, mapping the linguistic input onto the kinds of representations that linguistic and psychological research suggests are the representations employed by humans. [sent-14, score-0.056]
</p><p>8 For instance, a given verb can appear in some syntactic frames (Sally broke the vase. [sent-17, score-0.269]
</p><p>9 ) and not others (*Sally broke the vase to the floor. [sent-20, score-0.166]
</p><p>10 When verbs are –  –  classified according to the syntactic frames they can appear in, most if not all the verbs in a class involve the same set of abstract semantic features. [sent-23, score-0.383]
</p><p>11 ) have been singled out by developmental psychologists as part of “core knowledge” a set of early-learned or perhaps innate concepts upon which –  1Whether all verbs in a class share the same abstract predicates or merely most is an area of active research (Levin and Rappaport Hovav, 2005). [sent-25, score-0.432]
</p><p>12 Thus these semantic features/predicates may be not only crucial to describing linguistic meaning but may be central organizing principles for a human’s (reasonably successful) thinking about and conceptualization of the world. [sent-29, score-0.07]
</p><p>13 VerbNet classifies verbs based on the syntactic frames they can appear in, providing a semantic description of each frame for each class. [sent-34, score-0.318]
</p><p>14 “Syntax” provides semantic role labels for each of the NPs and PPs, which are invoked in “Semantics”. [sent-38, score-0.117]
</p><p>15 Note that this cap-  tures only the core aspects of semantics shared by all verbs in the class; differences between verbs in the same class (e. [sent-40, score-0.341]
</p><p>16 Importantly, the semantics of the sentence is dependent on both the matrix verb (paint) and the syntactic frame. [sent-44, score-0.151]
</p><p>17 Famously, when inserted in the slightly different frame NP V NP. [sent-45, score-0.054]
</p><p>18 THEME “Sally sprayed the wall with paint” “spray” entails that destination (the wall) is now fully painted, an entailment that does not follow in the example –  –  1439 above (Pinker, 1989). [sent-47, score-0.44]
</p><p>19 2  Uses and Limitations  VerbNet has been used in a variety of NLP applications, such as semantic role labeling (Swier and Stevenson, 2004), inferencing (Zaenen et al. [sent-49, score-0.07]
</p><p>20 While such applications have been successful thus far, an important constraint on how well VerbNetbased NLP applications can be expected to perform is the accuracy of the semantics encoded in Verb-  Net. [sent-52, score-0.052]
</p><p>21 Leaving aside miscategorized verbs and other inaccuracies, as noted above VerbNet assumes that all verbs in the same class share the same core predicates, which may or may not be empirically justified. [sent-54, score-0.289]
</p><p>22 Given the number of semantic predicates (146),2 verb entries (6580), and unique verb lemmas (6284) it is not feasible for a single research team to check, particularly since after a certain number of verbs, intuitions become less clear. [sent-55, score-0.568]
</p><p>23 In any case, it may not be ideal to rely solely on the intuitions of invested researchers, whose intuitions about subtle judgments may be clouded by theoretical commitments (Gibson and Federenko, 2013); the only way to ensure this is not the case is through independent validation. [sent-56, score-0.391]
</p><p>24 Unfortunately, of the 280 verb classes in VerbNet, this has been done for only a few (cf Ambridge et al. [sent-57, score-0.099]
</p><p>25 3  VerbCorner  The VerbCorner project was designed to address these issues by crowd-sourcing the semantic judgments online (gameswithwords. [sent-59, score-0.283]
</p><p>26 Several previous projects have successfully crowdsourced linguistic annotations, such as Phrase De-  tectives, where volunteers have contributed 2. [sent-61, score-0.133]
</p><p>27 1 Developing Semantic Annotation Tasks Collecting accurate judgments on subtle questions from naive participants with limited metalinguistic 2Note that these vary in applicability from those specific to a small number of verbs (CHARACTERIZE, CONSPIRE) to those frequently invoked (BEGIN, EXIST). [sent-66, score-0.446]
</p><p>28 Rare is the non-linguist who can immediately answer the question, “Does the verb ‘throw,’ when used transitively, entail a change of location on the part of its THEME? [sent-68, score-0.099]
</p><p>29 ” Thus, we began by developing tasks that isolate semantic features in a way accessible to untrained annotators. [sent-69, score-0.07]
</p><p>30 We converted the metalinguistic judgments (“Does this verb entail this abstract predicate? [sent-70, score-0.329]
</p><p>31 For instance, in “Simon Says Freeze”, a task designed to elicit judgments about movement, the Galactic Overlord (Simon) decrees “Galactic Stay  Where You Are Day,” during which nobody is allowed to move from their current location. [sent-73, score-0.368]
</p><p>32 In “Explode on Contact”, designed to elicit judgments about physical contact, objects and people explode when they touch one another. [sent-75, score-0.364]
</p><p>33 The participant reads descriptions of events and decides whether anything has exploded. [sent-76, score-0.078]
</p><p>34 3 Each task was piloted until inter-coder reliability was acceptably high and the modal response nearly always corresponded with researcher intuitions. [sent-77, score-0.41]
</p><p>35 2 Crowd-sourcing Semantic Judgments The pilot experiments showed that it is possible to elicit reliable semantic judgments corresponding to VerbNet predicates from naive participants (see section 3. [sent-80, score-0.677]
</p><p>36 At the project website, volunteers choose one of the tasks from a list and begin tagging sentences. [sent-82, score-0.133]
</p><p>37 The sentences are sampled smartly, avoid-  ing sentences already tagged by that volunteer and biased in favor of of the sentences with the fewest 3Note that each task is designed to elicit judgments about entailments – things that must be true rather than are merely likely to be true. [sent-83, score-0.575]
</p><p>38 If John greeted Bill, they might have come into contact (e. [sent-84, score-0.082]
</p><p>39 Previous work suggests that it is entailments that matter, particularly for explaining the syntactic behavior of verbs (Levin and Rappaport Hovav, 2005) 1440 judgments so far. [sent-87, score-0.359]
</p><p>40 Rather than assessing annotator quality through gold standard trials with known answers (which wastes data the answers to these trials are known), approximately 150 sentences were chosen to be “over-sampled. [sent-88, score-0.182]
</p><p>41 ” As the volunteer tags sentences, approximately one out of every five are from this over-sampled set until that volunteer has tagged all of them. [sent-89, score-0.302]
</p><p>42 This guarantees that any given volunteer will have tried some sentences targeted by many other volunteers, allowing inter-annotator agreement to be used to assess annotator quality. [sent-90, score-0.213]
</p><p>43 org), a popular “Citizen Science” platform, volunteers are encouraged but required to register –  (requiring registration prior to seeing the tasks was found to be a significant barrier to entry). [sent-92, score-0.188]
</p><p>44 Registration allows collecting linguistic and educational background from the volunteer, and also makes it possible to track the same volunteer across sessions. [sent-93, score-0.151]
</p><p>45 Multiple gamification elements were incorporated into VerbCorner in order to recruit and motivate volunteers. [sent-94, score-0.055]
</p><p>46 Each task has a leaderboard, where the volunteer can see his/her rank out of all volunteers in terms of number of contributions made. [sent-95, score-0.284]
</p><p>47 Finally, at random intervals bonus points are awarded, with the explanation for the bonus points tailored to the task’s backstory. [sent-98, score-0.11]
</p><p>48 After six weeks, 555 volunteers had provided at least one annotation, for a total of 39,274 annotations, demonstrating the feasibility of collecting large numbers of annotations through this method. [sent-100, score-0.133]
</p><p>49 3 Case Study: Equilibrium “Equilibrium” was designed to elicit judgments about application of force, frequently argued to be  a core semantic feature in the sense discussed above (Pinker, 1989). [sent-102, score-0.442]
</p><p>50 The backstory involves the “Zen Dimension,” in which nobody is allowed to exert force on anything else. [sent-103, score-0.156]
</p><p>51 The participant reads descriptions of events (Sally sprayed paint onto the wall) and decides whether they would be allowable in the Zen Dimension and, in particular, which participants in the event are illegally applying force. [sent-104, score-0.692]
</p><p>52 In order to minimize unwanted effects of world knowledge, the verb’s arguments are replaced with nonsense words or randomly chosen proper names (Sally sprayed the dax onto the blicket). [sent-105, score-0.318]
</p><p>53 However, this greatly increases the number of annotators needed and quickly becomes infeasible. [sent-108, score-0.052]
</p><p>54 1 Pilot Results The task was piloted on 138 sentences, which comprised all possible syntactic frames for three verbs  from each of five verb classes in VerbNet. [sent-111, score-0.348]
</p><p>55 After two rounds of piloting (between the first and second, wording in the backstory was adjusted for clarity based on pilot subject feedback and results), Kripp’s alpha reached . [sent-112, score-0.137]
</p><p>56 Importantly, the modal response matched the intuitions of the researchers in 137 of 138 cases. [sent-114, score-0.312]
</p><p>57 Individual annotators annotated anywhere from 1 to 195 sentences (mean=8, median=4). [sent-119, score-0.052]
</p><p>58 5 Comparing the modal response with the researchers’ intuitions resulted in a match for 184 of 194 sentences. [sent-121, score-0.312]
</p><p>59 In general, where the modal response 4The remaining case was “The crose smashed sondily. [sent-122, score-0.259]
</p><p>60 ” for which four pilot subjects thought involved the crose applying force – matching researcher intuition – and four thought did not involve any application of force, perhaps interpreting the  sentence was a passive. [sent-123, score-0.504]
</p><p>61 5These are the same 15 verbs used in the piloting. [sent-124, score-0.119]
</p><p>62 Compare Sally sprayed the dax onto Mary and Sally sprayed the dax onto the blicket. [sent-127, score-0.636]
</p><p>63 1441 did not match researcher intuitions, the modal response was itself not popular, comprising an average of 53% of responses, compared with an average of 77% where the modal response matched researcher intuitions. [sent-128, score-0.71]
</p><p>64 An-  notating every verb in each ofits syntactic frames for each semantic predicate would take many millions of judgments. [sent-133, score-0.244]
</p><p>65 However, most of the semantic predicates employed in VerbNet are very narrow in scope and only apply to a few classes. [sent-134, score-0.262]
</p><p>66 Thus, we have begun with broad predicates that are thought to apply to many verbs and are adding progressively narrower predicates as work progresses. [sent-135, score-0.624]
</p><p>67 At the current rate, we should complete annotation for the half-dozen most frequent semantic predicates in the space of a year. [sent-136, score-0.262]
</p><p>68 Future work will explore using an individual annotator’s history across trials to weight that user’s contributions, something that VerbCorner was specifically designed to allow (see above). [sent-137, score-0.098]
</p><p>69 How to assess annotator quality without gold standard data is an active area of research (Passonneau and Carpenter, 2013; Rzhetsky, Shatkay and Wilbur, 2009; Whitehill et al. [sent-138, score-0.062]
</p><p>70 This algorithm is shown to outperform using the modal response. [sent-141, score-0.133]
</p><p>71 Note that this necessarily biases against annotators with few responses. [sent-142, score-0.052]
</p><p>72 In our case study above, excluding annotators who contributed small numbers of annotations led to progressively worse match to researcher intuition, suggesting that the loss in data caused by excluding these annotations may not be worth the increased confidence in annotation quality. [sent-143, score-0.263]
</p><p>73 The above work shows the feasibility of crowdsourcing VerbNet semantic entailments, as has been shown for a handful of other linguistic judgments (Artignan, Hascoet and Lafourcade, 2009; Poesio et al. [sent-145, score-0.245]
</p><p>74 There are many domains in which gold standard human judgments are scarce; crowd-sourcing has considerable potential at addressing this need. [sent-148, score-0.175]
</p><p>75 The retreat from overgeneralization in child language acquisition: Word learning, morphology, and verb argument structure. [sent-158, score-0.136]
</p><p>76 The need for quantitative methods in syntax and semantics research. [sent-203, score-0.052]
</p><p>77 Using lexico-syntactic ontology design patterns for ontology creation and population. [sent-247, score-0.092]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('verbnet', 0.356), ('verbcorner', 0.245), ('sally', 0.237), ('paint', 0.213), ('predicates', 0.192), ('sprayed', 0.191), ('judgments', 0.175), ('researcher', 0.151), ('volunteer', 0.151), ('theme', 0.144), ('destination', 0.142), ('volunteers', 0.133), ('modal', 0.133), ('verbs', 0.119), ('rappaport', 0.109), ('spray', 0.109), ('intuitions', 0.108), ('levin', 0.108), ('elicit', 0.108), ('wall', 0.107), ('verb', 0.099), ('broke', 0.095), ('pilot', 0.082), ('ambridge', 0.082), ('contact', 0.082), ('cosmides', 0.082), ('hovav', 0.082), ('pinker', 0.082), ('whitehill', 0.082), ('frames', 0.075), ('response', 0.071), ('dax', 0.071), ('vase', 0.071), ('semantic', 0.07), ('press', 0.069), ('entailments', 0.065), ('annotator', 0.062), ('event', 0.061), ('thought', 0.061), ('trials', 0.06), ('progressively', 0.06), ('oxford', 0.058), ('agent', 0.058), ('jessica', 0.057), ('onto', 0.056), ('artignan', 0.055), ('backstory', 0.055), ('bonus', 0.055), ('crose', 0.055), ('galactic', 0.055), ('gamification', 0.055), ('hascoet', 0.055), ('kipper', 0.055), ('laurence', 0.055), ('leaderboard', 0.055), ('margolis', 0.055), ('metalinguistic', 0.055), ('piloted', 0.055), ('registration', 0.055), ('rzhetsky', 0.055), ('shatkay', 0.055), ('spelke', 0.055), ('swier', 0.055), ('tooby', 0.055), ('venhuizen', 0.055), ('motion', 0.054), ('force', 0.054), ('frame', 0.054), ('annotators', 0.052), ('semantics', 0.052), ('core', 0.051), ('poesio', 0.05), ('participants', 0.05), ('cambridge', 0.05), ('zen', 0.047), ('joanis', 0.047), ('equilibrium', 0.047), ('invoked', 0.047), ('nobody', 0.047), ('funk', 0.047), ('maynard', 0.047), ('poon', 0.046), ('ontology', 0.046), ('cognitive', 0.046), ('carpenter', 0.043), ('developmental', 0.043), ('explode', 0.043), ('allowable', 0.043), ('stimuli', 0.04), ('participant', 0.04), ('zaenen', 0.04), ('chklovski', 0.04), ('passonneau', 0.04), ('causation', 0.04), ('gibson', 0.04), ('perhaps', 0.04), ('reads', 0.038), ('merely', 0.038), ('designed', 0.038), ('argument', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="183-tfidf-1" href="./emnlp-2013-The_VerbCorner_Project%3A_Toward_an_Empirically-Based_Semantic_Decomposition_of_Verbs.html">183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</a></p>
<p>Author: Joshua K. Hartshorne ; Claire Bonial ; Martha Palmer</p><p>Abstract: This research describes efforts to use crowdsourcing to improve the validity of the semantic predicates in VerbNet, a lexicon of about 6300 English verbs. The current semantic predicates can be thought of semantic primitives, into which the concepts denoted by a verb can be decomposed. For example, the verb spray (of the Spray class), involves the predicates MOTION, NOT, and LOCATION, where the event can be decomposed into an AGENT causing a THEME that was originally not in a particular location to now be in that location. Although VerbNet’s predicates are theoretically well-motivated, systematic empirical data is scarce. This paper describes a recently-launched attempt to address this issue with a series of human judgment tasks, posed to subjects in the form of games.</p><p>2 0.11114489 <a title="183-tfidf-2" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>Author: Wiltrud Kessler ; Jonas Kuhn</p><p>Abstract: This short paper presents a pilot study investigating the training of a standard Semantic Role Labeling (SRL) system on product reviews for the new task of detecting comparisons. An (opinionated) comparison consists of a comparative “predicate” and up to three “arguments”: the entity evaluated positively, the entity evaluated negatively, and the aspect under which the comparison is made. In user-generated product reviews, the “predicate” and “arguments” are expressed in highly heterogeneous ways; but since the elements are textually annotated in existing datasets, SRL is technically applicable. We address the interesting question how well training an outof-the-box SRL model works for English data. We observe that even without any feature engineering or other major adaptions to our task, the system outperforms a reasonable heuristic baseline in all steps (predicate identification, argument identification and argument classification) and in three different datasets.</p><p>3 0.10508352 <a title="183-tfidf-3" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>Author: Mike Lewis ; Mark Steedman</p><p>Abstract: Creating a language-independent meaning representation would benefit many crosslingual NLP tasks. We introduce the first unsupervised approach to this problem, learning clusters of semantically equivalent English and French relations between referring expressions, based on their named-entity arguments in large monolingual corpora. The clusters can be used as language-independent semantic relations, by mapping clustered expressions in different languages onto the same relation. Our approach needs no parallel text for training, but outperforms a baseline that uses machine translation on a cross-lingual question answering task. We also show how to use the semantics to improve the accuracy of machine translation, by using it in a simple reranker.</p><p>4 0.10220379 <a title="183-tfidf-4" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: This paper presents a novel approach to determine textual similarity. A layered methodology to transform text into logic forms is proposed, and semantic features are derived from a logic prover. Experimental results show that incorporating the semantic structure of sentences is beneficial. When training data is unavailable, scores obtained from the logic prover in an unsupervised manner outperform supervised methods.</p><p>5 0.092253186 <a title="183-tfidf-5" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>Author: Jonathan Berant ; Andrew Chou ; Roy Frostig ; Percy Liang</p><p>Abstract: In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset ofCai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.</p><p>6 0.066320047 <a title="183-tfidf-6" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<p>7 0.060666323 <a title="183-tfidf-7" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>8 0.0601601 <a title="183-tfidf-8" href="./emnlp-2013-Learning_Biological_Processes_with_Global_Constraints.html">118 emnlp-2013-Learning Biological Processes with Global Constraints</a></p>
<p>9 0.056303021 <a title="183-tfidf-9" href="./emnlp-2013-Automatic_Knowledge_Acquisition_for_Case_Alternation_between_the_Passive_and_Active_Voices_in_Japanese.html">33 emnlp-2013-Automatic Knowledge Acquisition for Case Alternation between the Passive and Active Voices in Japanese</a></p>
<p>10 0.05415282 <a title="183-tfidf-10" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>11 0.051454663 <a title="183-tfidf-11" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>12 0.050017584 <a title="183-tfidf-12" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>13 0.047421239 <a title="183-tfidf-13" href="./emnlp-2013-Prior_Disambiguation_of_Word_Tensors_for_Constructing_Sentence_Vectors.html">154 emnlp-2013-Prior Disambiguation of Word Tensors for Constructing Sentence Vectors</a></p>
<p>14 0.045993049 <a title="183-tfidf-14" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>15 0.044566114 <a title="183-tfidf-15" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>16 0.044564459 <a title="183-tfidf-16" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>17 0.044272043 <a title="183-tfidf-17" href="./emnlp-2013-Building_Event_Threads_out_of_Multiple_News_Articles.html">41 emnlp-2013-Building Event Threads out of Multiple News Articles</a></p>
<p>18 0.044028968 <a title="183-tfidf-18" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>19 0.042293593 <a title="183-tfidf-19" href="./emnlp-2013-MCTest%3A_A_Challenge_Dataset_for_the_Open-Domain_Machine_Comprehension_of_Text.html">126 emnlp-2013-MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</a></p>
<p>20 0.041769646 <a title="183-tfidf-20" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.142), (1, 0.071), (2, -0.04), (3, 0.055), (4, -0.039), (5, 0.085), (6, -0.107), (7, -0.02), (8, 0.047), (9, 0.007), (10, 0.038), (11, 0.029), (12, 0.109), (13, -0.013), (14, 0.05), (15, 0.093), (16, -0.011), (17, -0.061), (18, -0.037), (19, -0.018), (20, 0.039), (21, 0.146), (22, -0.088), (23, -0.055), (24, 0.034), (25, 0.087), (26, -0.066), (27, 0.114), (28, 0.013), (29, -0.016), (30, -0.008), (31, -0.023), (32, -0.131), (33, -0.076), (34, -0.088), (35, 0.055), (36, 0.017), (37, 0.1), (38, -0.143), (39, -0.048), (40, -0.112), (41, 0.043), (42, 0.149), (43, -0.113), (44, -0.157), (45, 0.015), (46, -0.103), (47, -0.023), (48, -0.038), (49, -0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95170534 <a title="183-lsi-1" href="./emnlp-2013-The_VerbCorner_Project%3A_Toward_an_Empirically-Based_Semantic_Decomposition_of_Verbs.html">183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</a></p>
<p>Author: Joshua K. Hartshorne ; Claire Bonial ; Martha Palmer</p><p>Abstract: This research describes efforts to use crowdsourcing to improve the validity of the semantic predicates in VerbNet, a lexicon of about 6300 English verbs. The current semantic predicates can be thought of semantic primitives, into which the concepts denoted by a verb can be decomposed. For example, the verb spray (of the Spray class), involves the predicates MOTION, NOT, and LOCATION, where the event can be decomposed into an AGENT causing a THEME that was originally not in a particular location to now be in that location. Although VerbNet’s predicates are theoretically well-motivated, systematic empirical data is scarce. This paper describes a recently-launched attempt to address this issue with a series of human judgment tasks, posed to subjects in the form of games.</p><p>2 0.67283195 <a title="183-lsi-2" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>Author: Wiltrud Kessler ; Jonas Kuhn</p><p>Abstract: This short paper presents a pilot study investigating the training of a standard Semantic Role Labeling (SRL) system on product reviews for the new task of detecting comparisons. An (opinionated) comparison consists of a comparative “predicate” and up to three “arguments”: the entity evaluated positively, the entity evaluated negatively, and the aspect under which the comparison is made. In user-generated product reviews, the “predicate” and “arguments” are expressed in highly heterogeneous ways; but since the elements are textually annotated in existing datasets, SRL is technically applicable. We address the interesting question how well training an outof-the-box SRL model works for English data. We observe that even without any feature engineering or other major adaptions to our task, the system outperforms a reasonable heuristic baseline in all steps (predicate identification, argument identification and argument classification) and in three different datasets.</p><p>3 0.5566566 <a title="183-lsi-3" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: This paper presents a novel approach to determine textual similarity. A layered methodology to transform text into logic forms is proposed, and semantic features are derived from a logic prover. Experimental results show that incorporating the semantic structure of sentences is beneficial. When training data is unavailable, scores obtained from the logic prover in an unsupervised manner outperform supervised methods.</p><p>4 0.50111604 <a title="183-lsi-4" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>Author: Mike Lewis ; Mark Steedman</p><p>Abstract: Creating a language-independent meaning representation would benefit many crosslingual NLP tasks. We introduce the first unsupervised approach to this problem, learning clusters of semantically equivalent English and French relations between referring expressions, based on their named-entity arguments in large monolingual corpora. The clusters can be used as language-independent semantic relations, by mapping clustered expressions in different languages onto the same relation. Our approach needs no parallel text for training, but outperforms a baseline that uses machine translation on a cross-lingual question answering task. We also show how to use the semantics to improve the accuracy of machine translation, by using it in a simple reranker.</p><p>5 0.47943208 <a title="183-lsi-5" href="./emnlp-2013-Automatic_Knowledge_Acquisition_for_Case_Alternation_between_the_Passive_and_Active_Voices_in_Japanese.html">33 emnlp-2013-Automatic Knowledge Acquisition for Case Alternation between the Passive and Active Voices in Japanese</a></p>
<p>Author: Ryohei Sasano ; Daisuke Kawahara ; Sadao Kurohashi ; Manabu Okumura</p><p>Abstract: We present a method for automatically acquiring knowledge for case alternation between the passive and active voices in Japanese. By leveraging several linguistic constraints on alternation patterns and lexical case frames obtained from a large Web corpus, our method aligns a case frame in the passive voice to a corresponding case frame in the active voice and finds an alignment between their cases. We then apply the acquired knowledge to a case alternation task and prove its usefulness.</p><p>6 0.44249552 <a title="183-lsi-6" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>7 0.38632476 <a title="183-lsi-7" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>8 0.38601449 <a title="183-lsi-8" href="./emnlp-2013-The_Topology_of_Semantic_Knowledge.html">182 emnlp-2013-The Topology of Semantic Knowledge</a></p>
<p>9 0.33105442 <a title="183-lsi-9" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>10 0.32460645 <a title="183-lsi-10" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>11 0.29768544 <a title="183-lsi-11" href="./emnlp-2013-Animacy_Detection_with_Voting_Models.html">23 emnlp-2013-Animacy Detection with Voting Models</a></p>
<p>12 0.28442264 <a title="183-lsi-12" href="./emnlp-2013-Prior_Disambiguation_of_Word_Tensors_for_Constructing_Sentence_Vectors.html">154 emnlp-2013-Prior Disambiguation of Word Tensors for Constructing Sentence Vectors</a></p>
<p>13 0.27297977 <a title="183-lsi-13" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>14 0.27209327 <a title="183-lsi-14" href="./emnlp-2013-Learning_Biological_Processes_with_Global_Constraints.html">118 emnlp-2013-Learning Biological Processes with Global Constraints</a></p>
<p>15 0.26837507 <a title="183-lsi-15" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<p>16 0.26292866 <a title="183-lsi-16" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<p>17 0.26144278 <a title="183-lsi-17" href="./emnlp-2013-Modeling_and_Learning_Semantic_Co-Compositionality_through_Prototype_Projections_and_Neural_Networks.html">134 emnlp-2013-Modeling and Learning Semantic Co-Compositionality through Prototype Projections and Neural Networks</a></p>
<p>18 0.25654438 <a title="183-lsi-18" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>19 0.25418136 <a title="183-lsi-19" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>20 0.2521396 <a title="183-lsi-20" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.042), (9, 0.014), (18, 0.024), (22, 0.039), (30, 0.033), (51, 0.2), (63, 0.394), (66, 0.028), (71, 0.028), (75, 0.034), (77, 0.021), (90, 0.025), (96, 0.018), (97, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80388093 <a title="183-lda-1" href="./emnlp-2013-The_VerbCorner_Project%3A_Toward_an_Empirically-Based_Semantic_Decomposition_of_Verbs.html">183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</a></p>
<p>Author: Joshua K. Hartshorne ; Claire Bonial ; Martha Palmer</p><p>Abstract: This research describes efforts to use crowdsourcing to improve the validity of the semantic predicates in VerbNet, a lexicon of about 6300 English verbs. The current semantic predicates can be thought of semantic primitives, into which the concepts denoted by a verb can be decomposed. For example, the verb spray (of the Spray class), involves the predicates MOTION, NOT, and LOCATION, where the event can be decomposed into an AGENT causing a THEME that was originally not in a particular location to now be in that location. Although VerbNet’s predicates are theoretically well-motivated, systematic empirical data is scarce. This paper describes a recently-launched attempt to address this issue with a series of human judgment tasks, posed to subjects in the form of games.</p><p>2 0.51671982 <a title="183-lda-2" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>3 0.47511074 <a title="183-lda-3" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>Author: Gary Patterson ; Andrew Kehler</p><p>Abstract: We present a classification model that predicts the presence or omission of a lexical connective between two clauses, based upon linguistic features of the clauses and the type of discourse relation holding between them. The model is trained on a set of high frequency relations extracted from the Penn Discourse Treebank and achieves an accuracy of 86.6%. Analysis of the results reveals that the most informative features relate to the discourse dependencies between sequences of coherence relations in the text. We also present results of an experiment that provides insight into the nature and difficulty of the task.</p><p>4 0.47373664 <a title="183-lda-4" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>Author: Silvia Pareti ; Tim O'Keefe ; Ioannis Konstas ; James R. Curran ; Irena Koprinska</p><p>Abstract: Direct quotations are used for opinion mining and information extraction as they have an easy to extract span and they can be attributed to a speaker with high accuracy. However, simply focusing on direct quotations ignores around half of all reported speech, which is in the form of indirect or mixed speech. This work presents the first large-scale experiments in indirect and mixed quotation extraction and attribution. We propose two methods of extracting all quote types from news articles and evaluate them on two large annotated corpora, one of which is a contribution of this work. We further show that direct quotation attribution methods can be successfully applied to indirect and mixed quotation attribution.</p><p>5 0.47327027 <a title="183-lda-5" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>Author: Jason Weston ; Antoine Bordes ; Oksana Yakhnenko ; Nicolas Usunier</p><p>Abstract: This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.</p><p>6 0.47270933 <a title="183-lda-6" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>7 0.47174758 <a title="183-lda-7" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>8 0.47109753 <a title="183-lda-8" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>9 0.4707211 <a title="183-lda-9" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>10 0.46994138 <a title="183-lda-10" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>11 0.469365 <a title="183-lda-11" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>12 0.46907014 <a title="183-lda-12" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>13 0.46895477 <a title="183-lda-13" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>14 0.4687258 <a title="183-lda-14" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<p>15 0.46816355 <a title="183-lda-15" href="./emnlp-2013-MCTest%3A_A_Challenge_Dataset_for_the_Open-Domain_Machine_Comprehension_of_Text.html">126 emnlp-2013-MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</a></p>
<p>16 0.46745294 <a title="183-lda-16" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>17 0.46715075 <a title="183-lda-17" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>18 0.46645653 <a title="183-lda-18" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>19 0.46642593 <a title="183-lda-19" href="./emnlp-2013-Exploring_Representations_from_Unlabeled_Data_with_Co-training_for_Chinese_Word_Segmentation.html">82 emnlp-2013-Exploring Representations from Unlabeled Data with Co-training for Chinese Word Segmentation</a></p>
<p>20 0.46594292 <a title="183-lda-20" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
