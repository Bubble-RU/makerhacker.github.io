<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-91" href="#">emnlp2013-91</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</h1>
<br/><p>Source: <a title="emnlp-2013-91-pdf" href="http://aclweb.org/anthology//D/D13/D13-1035.pdf">pdf</a></p><p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>Reference: <a title="emnlp-2013-91-reference" href="../emnlp2013_reference/emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Grounding Strategic Conversation: Using negotiation dialogues to predict trades in a win-lose game  Ana ı¨s Cadilhac  Nicholas Asher  IRIT  IRIT, CNRS  Univ. [sent-1, score-0.609]
</p><p>2 Toulouse, France  Toulouse, France  cadi lhac@ i rit . [sent-2, score-0.052]
</p><p>3 fr  Abstract This paper describes a method that predicts which trades players execute during a winlose game. [sent-4, score-0.373]
</p><p>4 Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. [sent-5, score-0.445]
</p><p>5 This in turn yields equilibrium trading moves via principles from game theory. [sent-6, score-0.444]
</p><p>6 We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success. [sent-7, score-0.693]
</p><p>7 1 Introduction Rational agents act so as to maximise their expected  utilities—an optimal trade off between what they prefer and what they believe they can achieve (Savage, 1954). [sent-8, score-0.381]
</p><p>8 Solving a game problem involves finding equilibrium strategies: an optimal action for each player that maximises his expected utility, assuming that the other players perform their specified action (Shoham and Leyton-Brown, 2009). [sent-9, score-0.661]
</p><p>9 Calculating equilibria thus requires knowledge of the other players’ preferences but almost all bargaining games occur under the handicap of imperfect information about this (Osborne and Rubinstein, 1994). [sent-10, score-0.442]
</p><p>10 Players therefore try to extract their opponents’ preferences from what they say, likewise revealing their own preferences in their own utterances. [sent-11, score-0.434]
</p><p>11 These elicited preferences guide an agent’s decisions, like choosing to make such and such a bargain with such and such a person. [sent-12, score-0.217]
</p><p>12 uk  dialogue is thus crucial for analyzing the agents’  strategic reasoning in real game scenarios. [sent-19, score-0.585]
</p><p>13 In this paper, we design a model that maps what people say in a win-lose game into a prediction of exactly which players, if any, trade with each other, and exactly what resources they exchange. [sent-20, score-0.466]
</p><p>14 , 2004), a representation of preferences for which algorithms for computing equilibrium strategies exist. [sent-23, score-0.311]
</p><p>15 We adapt those algorithms to predict the trades executed in the game. [sent-24, score-0.242]
</p><p>16 The algorithm for construcing CP-nets uses only the output of our classifiers, which in turn rely entirely on shallow features in the raw text and robust parsers. [sent-25, score-0.056]
</p><p>17 Our study exploits a corpus of negotiation dialogues from an online version of the win lose game The Settlers of Catan. [sent-28, score-0.487]
</p><p>18 Section 4 introduces our method for constructing the agents’ preferences from the dialogues. [sent-30, score-0.217]
</p><p>19 We use this in Section 5 to predict whether a trade is executed as a result of the ProceSe datintlges, o Wfa tsh ein 2g01to3n, C UoSnfAe,re 1n8c-e2 o1n O Ecmtopbier ic 2a0l1 M3. [sent-31, score-0.337]
</p><p>20 hc o2d0s1 i3n A Nsastoucria lti Loan fgoura Cgoem Ppruotcaetsiosin agl, L piang eusis 3t5ic7s–368, players’ negotiations, and if so we predict who took part in the trade, and what they exchanged. [sent-33, score-0.036]
</p><p>21 Our method shows promising results, beating baselines that don’t adequately track or reason about preferences. [sent-34, score-0.038]
</p><p>22 com) is a winlose game that involves negotiations over restricted resources. [sent-38, score-0.298]
</p><p>23 Each player (three or more) acquires resources (of 5 types: ore, wood, wheat, clay, sheep), which they use in different combinations to build  roads, settlements and cities, which in turn earns them points towards winning. [sent-39, score-0.244]
</p><p>24 Players acquire resources in several ways, in particular through agreed trades with other players. [sent-41, score-0.21]
</p><p>25 , robbing) are hidden from view, so players lack complete information about their opponents’ resources. [sent-44, score-0.152]
</p><p>26 Our corpus contains conversations of humans playing an online version of Settlers (Afantenos et al. [sent-45, score-0.026]
</p><p>27 Players must converse in a chat interface to carry out trades. [sent-47, score-0.075]
</p><p>28 Our experiments use 10 Settlers games, consisting of more than 2000 individual dialogue turns (see Section 3). [sent-49, score-0.286]
</p><p>29 Other pragmatic inferences, which are dependent on reasoning about intentions, speech acts and discourse structure, are also ubiquitous. [sent-56, score-0.132]
</p><p>30 implies an offer for the speaker to receive ore in exchange for something  from someone unspecified, and its response I’ve got wheat not only implies a willingness to exchange wheat for something, but as a response to the question it also implies a refusal to give any ore. [sent-58, score-1.053]
</p><p>31 More generally, a dialogue turn in our corpus can express an offer, a counteroffer, an acceptance or rejection of an offer, or a commentary on the above or on moves in the game. [sent-59, score-0.432]
</p><p>32 , which players 358 a speaker wants to execute a trade with; or what resources to exchange. [sent-62, score-0.616]
</p><p>33 For instance, the utterance Anybody have any sheep for wheat? [sent-63, score-0.121]
</p><p>34 First, it conveys the speaker’s preference to trade with someone unspecified. [sent-65, score-0.386]
</p><p>35 Other informative but underspecified preferences include: the speaker’s preference to acquire some sheep over alternatives; and in a context where she receives sheep, a preference to give away some of her wheat over the alternatives. [sent-66, score-0.769]
</p><p>36 Crucially, it does not convey a preference to give away wheat in a context where she receives nothing or something other than sheep. [sent-67, score-0.391]
</p><p>37 In line with a non-cooperative bargaining game,  the preferences and offers that a speaker reveals are less specific than an executable trade requires, where the trading partners and the type of resources offered and received must all be defined. [sent-68, score-0.898]
</p><p>38 Such general dialogue moves are essentially information seeking— evidence that humans playing Settlers have imperfect information about their opponents’ preferences. [sent-69, score-0.398]
</p><p>39 In fact, many offers to trade result in no trade being agreed to and executed. [sent-70, score-0.489]
</p><p>40 While observed negotiation failure would be puzzling in a bargaining game with perfect information (Osborne and Rubinstein, 1994), it occurs relatively frequently in Settlers. [sent-71, score-0.536]
</p><p>41 ); and (3) associated infor-  mation about the givable and/or receivable resources that EDUs express. [sent-73, score-0.494]
</p><p>42 Two annotators received training on 77 dialogues, totaling 699 EDUs. [sent-74, score-0.034]
</p><p>43 They then both annotated the remaining dialogues independently (2741 EDUs and 511 dialogues in total). [sent-75, score-0.224]
</p><p>44 79) Each turn logs what a player enters in the chat window and also aspects of the game state at the time: ID Dialogue Act Text Speaker Addressee Resource 1Offeri need clay, any1 have? [sent-79, score-0.448]
</p><p>45 ) 2  Refusal  Nope, sorry  inca  Rainbow  3  Refusal  Not at the moment, unfortunately. [sent-81, score-0.043]
</p><p>46 ariachiba  Rainbow  4  Refusal  need mine sorry  Kittles  Rainbow  5  Offer  no one has ore to giv? [sent-82, score-0.163]
</p><p>47 Rainbow  All  6  Accept  oh yeah me  Kittles  Rainbow  Not givable (Anaphoric, ? [sent-83, score-0.238]
</p><p>48 ) Anaphora Link:(mine , clay )  7  Counteroffer  ore for wheat again? [sent-84, score-0.584]
</p><p>49 Kittles  Rainbow  8  Accept  ya  Rainbow  Kittles  9  Accept  ok  Kittles  Receivable (ore, ? [sent-85, score-0.038]
</p><p>50 his resources, the state of the game board and a time stamp. [sent-89, score-0.19]
</p><p>51 The annotators then have to specify the dialogue act of each EDU: Offer, Counteroffer, Accept or Refusal (of an offer addressed to the emitter), and Other. [sent-91, score-0.542]
</p><p>52 Other labels units that either comment on strategic moves in the game or are not directly pertinent to bargaining. [sent-92, score-0.358]
</p><p>53 Annotators also specify the ad-  dressee of the EDU and its surface type: Question, Request or Assertion. [sent-93, score-0.027]
</p><p>54 80) Annotators also specify for each EDU and its dialogue act an associated feature structure, which captures (partial) information that the EDU expresses about the type and quantity of resources that are of the following four attributes: Givable, Not Givable, Receivable or Not Receivable. [sent-96, score-0.476]
</p><p>55 We allow attributes to have unknown values: the annotation tool inserts a ? [sent-100, score-0.062]
</p><p>56 We also insist that the annotators resolve anaphoric dependencies when specifying values to attributes, as shown in EDU (4) in Table 1. [sent-102, score-0.085]
</p><p>57 4  Dialogue act and resource prediction  Predicting the executed trades from the dialogues  starts with three sub-tasks: automatically identifying each EDU’s dialogue act; detecting the EDU’s resources; and specifying the attributes of those resources (i. [sent-103, score-0.918]
</p><p>58 1 Identifying dialogue acts As is well established, one EDU’s dialogue act depends on previous dialogue acts (Stolcke et al. [sent-108, score-1.144]
</p><p>59 Since labeling is sequential, we use Conditional Random Fields (CRFs) to learn dialogue acts. [sent-111, score-0.286]
</p><p>60 CRFs have been shown to yield better results in dialogue act classification on online chat than HMM-SVN and Naive Bayes (Kim et al. [sent-112, score-0.463]
</p><p>61 6 features were used exclusively as unigrams: the EDU’s position in the  dialogue, its first and last words, its subject lemma, a boolean feature to indicate if the current speaker is the one that initiates the dialogue and the position of the speaker’s first turn in the dialogue. [sent-116, score-0.533]
</p><p>62 We have 15 unigram and bigram features (at levels 0 and -1), as well as templates that combine feature values for the two levels. [sent-117, score-0.028]
</p><p>63 These include 14 boolean features that indicate if the EDU contains: bargaining verbs (e. [sent-118, score-0.254]
</p><p>64 you), resource tokens as encoded in a task dedicated lexicon (e. [sent-122, score-0.089]
</p><p>65 one, none), anaphoric pronouns, occurrences of “for” prepositional phrases (e. [sent-126, score-0.051]
</p><p>66 , 2011)), words of politeness, exclamation marks, questions, and finally whether the EDU’s speaker has talked previously in the dialogue. [sent-131, score-0.132]
</p><p>67 In addition, 3 unigram and bigram booleans indicate whether the current EDU contains the most frequent tokens, couple oftokens and syntactic patterns in our corpus. [sent-133, score-0.028]
</p><p>68 Finally, we use 2 composed bigram features that encode whether the EDU contains an accep-  tance or refusal word, given that the previous EDU is a question. [sent-134, score-0.173]
</p><p>69 To assign sequential tags of dialogue acts within a negotiation dialogue, we use the CRF++ tool (crfpp . [sent-135, score-0.529]
</p><p>70 Each EDU is associated with a dialogue act resulting in 410 Offer, 197 Counteroffer, 179 Accept, 398 Refusal and 1557 Other. [sent-139, score-0.388]
</p><p>71 We use 10-fold cross-validation to evaluate our model, computing precision, recall and Fscore for each class and global accuracy from the total number of true positives, false positives, false negatives and true negatives obtained by summing over all fold decisions. [sent-140, score-0.058]
</p><p>72 Errors in theAccept class were often due to misspelling or to chat style conversation; e. [sent-147, score-0.075]
</p><p>73 2 Finding resource text spans Since the resource vocabulary in The Settlers of Catan is a closed set composed of words denoting specific resources (e. [sent-151, score-0.239]
</p><p>74 , clay, wood) and their synonyms (brick), we use a simple rule to detect them: a noun phrase (NP) is a resource text span if and 360 only if it contains a lemma from our resource lexicon. [sent-153, score-0.208]
</p><p>75 A closed set resource vocabulary is common to many different types of negotiation dialogues. [sent-154, score-0.24]
</p><p>76 We used the Stanford parser (Klein and Manning, 2003) to obtain the NPs: there are 4361 NPs, where (by the  gold standard annotations) 21% are resources and 79% are not. [sent-155, score-0.061]
</p><p>77 9%, clearly beating both the frequency and random baselines for this task. [sent-158, score-0.038]
</p><p>78 3  Recognizing the type of resources  Recall that each resource within an EDU can be the value of four types of attributes: Givable, Receivable, Not Givable or Not Receivable (cf. [sent-160, score-0.15]
</p><p>79 We predict these attributes using CRFs with the following features. [sent-163, score-0.098]
</p><p>80 Additionally, we have a set of unigram and bigram boolean features that indicate if the current EDU contains the most frequent verbs in the corpus. [sent-166, score-0.087]
</p><p>81 5  ×  Predicting Players’ Strategic Actions  We aim to capture the evolution of commitments to certain preferences as the dialogue proceeds so as to predict the agents’ bargaining behavior. [sent-178, score-0.734]
</p><p>82 In other words, we wish to predict which of the 61 possible trade actions is executed at the end of each dialogue. [sent-179, score-0.337]
</p><p>83 The possible trades vary over which partner the player whose turn it is trades with (3 options in a 4 player game), the resources exchanged (assuming each partner gives one type of resource and receives another type yields 5 4 = 20 possibilities), or there iasn no trade; i. [sent-180, score-0.856]
</p><p>84 , (3 20) + 10 = 6ss1i possible oarc ttihoenrse iisn nthoe t hypothesis space (we predict ptohes types cotifo re-  sources that are exchanged, but not their quantity). [sent-182, score-0.036]
</p><p>85 We predict the executed action by identifying the equilibrium trade entailed by the model of the players’ preferences, which in turn we construct dynamically from the output of the classifiers in Section 4. [sent-183, score-0.572]
</p><p>86 We use the attributes of resources in the EDUs (Givable, etc. [sent-184, score-0.123]
</p><p>87 ) to identify the preference that a speaker conveys in the EDU, and we use the dialogue acts (Offer, Accept, etc. [sent-185, score-0.656]
</p><p>88 ) to update a model of the preferences expressed so far in the dialogue with this new preference (see Section 5. [sent-186, score-0.604]
</p><p>89 Our model of preferences consists of a set of partial CP-nets, one for each player (see Section 5. [sent-188, score-0.344]
</p><p>90 The resulting CP-nets are then used to infer the executed trading action (if any) automatically, via wellunderstood principles from game theory for identifying rational behavior (Bonzon, 2007). [sent-190, score-0.416]
</p><p>91 CP-nets are compatible with the kind of partial information about preferences that utterances reveal, and inference with CP-nets is com-  361 putationally efficient. [sent-195, score-0.217]
</p><p>92 The CPnet structures the decision maker’s preferences under a ceterisparibus assumption: outcomes are compared, other things being equal. [sent-197, score-0.243]
</p><p>93 More formally, let V be a finite set of variables whose combination of values determine all outcomes O. [sent-198, score-0.026]
</p><p>94 X is conditionally preferentially independent ofY given Z ifand only if∀z ∈ D(Z), ∀x1, x2 ∈ D(X) gainvden ∀y1, y2 ∈ D(Y ), x1y1z ? [sent-215, score-0.068]
</p><p>95 T isha at is, T = {CPT(Xj): Xj ∈ V }, where CPT(Xj) specifies for ePaTc(hX Xcombinatio∈n p of values of the parent variables Pa(Xj) either p : xj ? [sent-219, score-0.089]
</p><p>96 xj or p : xj ∼ xj where the ¯ ¯symbol sets the var? [sent-221, score-0.267]
</p><p>97 We discuss below how a CP-net predicts rational action, but first we describe how CP-nets are constructed from the dialogues. [sent-223, score-0.043]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dialogue', 0.286), ('clay', 0.238), ('givable', 0.238), ('wheat', 0.226), ('preferences', 0.217), ('trade', 0.215), ('bargaining', 0.195), ('receivable', 0.195), ('game', 0.19), ('rainbow', 0.173), ('refusal', 0.173), ('settlers', 0.173), ('players', 0.152), ('negotiation', 0.151), ('speaker', 0.132), ('player', 0.127), ('edu', 0.124), ('ore', 0.12), ('trades', 0.12), ('dialogues', 0.112), ('counteroffer', 0.108), ('kittles', 0.108), ('act', 0.102), ('preference', 0.101), ('accept', 0.098), ('edus', 0.096), ('equilibrium', 0.094), ('offer', 0.093), ('acts', 0.092), ('resource', 0.089), ('xj', 0.089), ('catan', 0.087), ('sheep', 0.087), ('executed', 0.086), ('chat', 0.075), ('strategic', 0.069), ('irit', 0.065), ('maf', 0.065), ('negotiations', 0.065), ('opponents', 0.065), ('toulouse', 0.065), ('wood', 0.064), ('agents', 0.064), ('attributes', 0.062), ('resources', 0.061), ('boolean', 0.059), ('benamara', 0.056), ('turn', 0.056), ('moves', 0.056), ('rit', 0.052), ('anaphoric', 0.051), ('action', 0.049), ('trading', 0.048), ('conveys', 0.045), ('conversation', 0.045), ('boutilier', 0.043), ('cadilhac', 0.043), ('exchanged', 0.043), ('pertinent', 0.043), ('preferentially', 0.043), ('rubinstein', 0.043), ('sorry', 0.043), ('winlose', 0.043), ('rational', 0.043), ('reasoning', 0.04), ('beating', 0.038), ('cpt', 0.038), ('ok', 0.038), ('partner', 0.038), ('receives', 0.037), ('predict', 0.036), ('dynamically', 0.036), ('agent', 0.035), ('acceptance', 0.034), ('annotators', 0.034), ('utterance', 0.034), ('exploits', 0.034), ('france', 0.032), ('crfs', 0.031), ('receive', 0.031), ('lemma', 0.03), ('execute', 0.03), ('imperfect', 0.03), ('asher', 0.03), ('independence', 0.03), ('offers', 0.03), ('osborne', 0.029), ('agreed', 0.029), ('negatives', 0.029), ('fr', 0.028), ('unigram', 0.028), ('request', 0.027), ('something', 0.027), ('specify', 0.027), ('outcomes', 0.026), ('playing', 0.026), ('wants', 0.026), ('graphical', 0.026), ('conditionally', 0.025), ('someone', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="91-tfidf-1" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>2 0.11834854 <a title="91-tfidf-2" href="./emnlp-2013-A_Generative_Joint%2C_Additive%2C_Sequential_Model_of_Topics_and_Speech_Acts_in_Patient-Doctor_Communication.html">6 emnlp-2013-A Generative Joint, Additive, Sequential Model of Topics and Speech Acts in Patient-Doctor Communication</a></p>
<p>Author: Byron C. Wallace ; Thomas A Trikalinos ; M. Barton Laws ; Ira B. Wilson ; Eugene Charniak</p><p>Abstract: We develop a novel generative model of conversation that jointly captures both the topical content and the speech act type associated with each utterance. Our model expresses both token emission and state transition probabilities as log-linear functions of separate components corresponding to topics and speech acts (and their interactions). We apply this model to a dataset comprising annotated patient-physician visits and show that the proposed joint approach outperforms a baseline univariate model.</p><p>3 0.087865986 <a title="91-tfidf-3" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>4 0.062403094 <a title="91-tfidf-4" href="./emnlp-2013-Towards_Situated_Dialogue%3A_Revisiting_Referring_Expression_Generation.html">185 emnlp-2013-Towards Situated Dialogue: Revisiting Referring Expression Generation</a></p>
<p>Author: Rui Fang ; Changsong Liu ; Lanbo She ; Joyce Y. Chai</p><p>Abstract: In situated dialogue, humans and agents have mismatched capabilities of perceiving the shared environment. Their representations of the shared world are misaligned. Thus referring expression generation (REG) will need to take this discrepancy into consideration. To address this issue, we developed a hypergraph-based approach to account for group-based spatial relations and uncertainties in perceiving the environment. Our empirical results have shown that this approach outperforms a previous graph-based approach with an absolute gain of 9%. However, while these graph-based approaches perform effectively when the agent has perfect knowledge or perception of the environment (e.g., 84%), they perform rather poorly when the agent has imperfect perception of the environment (e.g., 45%). This big performance gap calls for new solutions to REG that can mediate a shared perceptual basis in situated dialogue.</p><p>5 0.053120099 <a title="91-tfidf-5" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>Author: Hao Wang ; Zhengdong Lu ; Hang Li ; Enhong Chen</p><p>Abstract: Natural language conversation is widely regarded as a highly difficult problem, which is usually attacked with either rule-based or learning-based models. In this paper we propose a retrieval-based automatic response model for short-text conversation, to exploit the vast amount of short conversation instances available on social media. For this purpose we introduce a dataset of short-text conversation based on the real-world instances from Sina Weibo (a popular Chinese microblog service), which will be soon released to public. This dataset provides rich collection of instances for the research on finding natural and relevant short responses to a given short text, and useful for both training and testing of conversation models. This dataset consists of both naturally formed conversations, manually labeled data, and a large repository of candidate responses. Our preliminary experiments demonstrate that the simple retrieval-based conversation model performs reasonably well when combined with the rich instances in our dataset.</p><p>6 0.045703813 <a title="91-tfidf-6" href="./emnlp-2013-Question_Difficulty_Estimation_in_Community_Question_Answering_Services.html">155 emnlp-2013-Question Difficulty Estimation in Community Question Answering Services</a></p>
<p>7 0.043029774 <a title="91-tfidf-7" href="./emnlp-2013-Predicting_the_Resolution_of_Referring_Expressions_from_User_Behavior.html">153 emnlp-2013-Predicting the Resolution of Referring Expressions from User Behavior</a></p>
<p>8 0.040851995 <a title="91-tfidf-8" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>9 0.035358418 <a title="91-tfidf-9" href="./emnlp-2013-Single-Document_Summarization_as_a_Tree_Knapsack_Problem.html">174 emnlp-2013-Single-Document Summarization as a Tree Knapsack Problem</a></p>
<p>10 0.033780895 <a title="91-tfidf-10" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>11 0.031600486 <a title="91-tfidf-11" href="./emnlp-2013-Exploiting_Language_Models_for_Visual_Recognition.html">78 emnlp-2013-Exploiting Language Models for Visual Recognition</a></p>
<p>12 0.030308038 <a title="91-tfidf-12" href="./emnlp-2013-Word_Level_Language_Identification_in_Online_Multilingual_Communication.html">204 emnlp-2013-Word Level Language Identification in Online Multilingual Communication</a></p>
<p>13 0.029985465 <a title="91-tfidf-13" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>14 0.029434921 <a title="91-tfidf-14" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<p>15 0.028070213 <a title="91-tfidf-15" href="./emnlp-2013-Using_Crowdsourcing_to_get_Representations_based_on_Regular_Expressions.html">196 emnlp-2013-Using Crowdsourcing to get Representations based on Regular Expressions</a></p>
<p>16 0.027673962 <a title="91-tfidf-16" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>17 0.02733821 <a title="91-tfidf-17" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>18 0.027130764 <a title="91-tfidf-18" href="./emnlp-2013-Easy_Victories_and_Uphill_Battles_in_Coreference_Resolution.html">67 emnlp-2013-Easy Victories and Uphill Battles in Coreference Resolution</a></p>
<p>19 0.026436767 <a title="91-tfidf-19" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>20 0.025990285 <a title="91-tfidf-20" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.099), (1, 0.029), (2, -0.016), (3, 0.008), (4, -0.038), (5, 0.029), (6, -0.001), (7, 0.003), (8, -0.006), (9, -0.007), (10, -0.068), (11, 0.025), (12, 0.004), (13, 0.053), (14, 0.038), (15, 0.087), (16, 0.027), (17, 0.003), (18, -0.044), (19, 0.11), (20, 0.169), (21, 0.112), (22, 0.039), (23, 0.025), (24, 0.052), (25, -0.048), (26, 0.03), (27, -0.124), (28, -0.114), (29, 0.11), (30, -0.007), (31, 0.04), (32, 0.032), (33, 0.101), (34, 0.081), (35, -0.112), (36, -0.055), (37, -0.081), (38, -0.229), (39, -0.058), (40, -0.068), (41, -0.061), (42, -0.062), (43, -0.093), (44, -0.023), (45, -0.148), (46, -0.013), (47, -0.073), (48, -0.247), (49, -0.102)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97330421 <a title="91-lsi-1" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>2 0.69477993 <a title="91-lsi-2" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>3 0.68109792 <a title="91-lsi-3" href="./emnlp-2013-A_Generative_Joint%2C_Additive%2C_Sequential_Model_of_Topics_and_Speech_Acts_in_Patient-Doctor_Communication.html">6 emnlp-2013-A Generative Joint, Additive, Sequential Model of Topics and Speech Acts in Patient-Doctor Communication</a></p>
<p>Author: Byron C. Wallace ; Thomas A Trikalinos ; M. Barton Laws ; Ira B. Wilson ; Eugene Charniak</p><p>Abstract: We develop a novel generative model of conversation that jointly captures both the topical content and the speech act type associated with each utterance. Our model expresses both token emission and state transition probabilities as log-linear functions of separate components corresponding to topics and speech acts (and their interactions). We apply this model to a dataset comprising annotated patient-physician visits and show that the proposed joint approach outperforms a baseline univariate model.</p><p>4 0.40329674 <a title="91-lsi-4" href="./emnlp-2013-Predicting_the_Resolution_of_Referring_Expressions_from_User_Behavior.html">153 emnlp-2013-Predicting the Resolution of Referring Expressions from User Behavior</a></p>
<p>Author: Nikos Engonopoulos ; Martin Villalba ; Ivan Titov ; Alexander Koller</p><p>Abstract: We present a statistical model for predicting how the user of an interactive, situated NLP system resolved a referring expression. The model makes an initial prediction based on the meaning of the utterance, and revises it continuously based on the user’s behavior. The combined model outperforms its components in predicting reference resolution and when to give feedback.</p><p>5 0.35200214 <a title="91-lsi-5" href="./emnlp-2013-Feature_Noising_for_Log-Linear_Structured_Prediction.html">86 emnlp-2013-Feature Noising for Log-Linear Structured Prediction</a></p>
<p>Author: Sida Wang ; Mengqiu Wang ; Stefan Wager ; Percy Liang ; Christopher D. Manning</p><p>Abstract: NLP models have many and sparse features, and regularization is key for balancing model overfitting versus underfitting. A recently repopularized form of regularization is to generate fake training data by repeatedly adding noise to real data. We reinterpret this noising as an explicit regularizer, and approximate it with a second-order formula that can be used during training without actually generating fake data. We show how to apply this method to structured prediction using multinomial logistic regression and linear-chain CRFs. We tackle the key challenge of developing a dynamic program to compute the gradient of the regularizer efficiently. The regularizer is a sum over inputs, so we can estimate it more accurately via a semi-supervised or transductive extension. Applied to text classification and NER, our method provides a > 1% absolute performance gain over use of standard L2 regularization.</p><p>6 0.34691983 <a title="91-lsi-6" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>7 0.31240621 <a title="91-lsi-7" href="./emnlp-2013-Towards_Situated_Dialogue%3A_Revisiting_Referring_Expression_Generation.html">185 emnlp-2013-Towards Situated Dialogue: Revisiting Referring Expression Generation</a></p>
<p>8 0.2432691 <a title="91-lsi-8" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>9 0.22988757 <a title="91-lsi-9" href="./emnlp-2013-Open-Domain_Fine-Grained_Class_Extraction_from_Web_Search_Queries.html">142 emnlp-2013-Open-Domain Fine-Grained Class Extraction from Web Search Queries</a></p>
<p>10 0.21288085 <a title="91-lsi-10" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>11 0.20897621 <a title="91-lsi-11" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>12 0.20466746 <a title="91-lsi-12" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>13 0.20067042 <a title="91-lsi-13" href="./emnlp-2013-Question_Difficulty_Estimation_in_Community_Question_Answering_Services.html">155 emnlp-2013-Question Difficulty Estimation in Community Question Answering Services</a></p>
<p>14 0.19480032 <a title="91-lsi-14" href="./emnlp-2013-Joint_Parsing_and_Disfluency_Detection_in_Linear_Time.html">116 emnlp-2013-Joint Parsing and Disfluency Detection in Linear Time</a></p>
<p>15 0.18996242 <a title="91-lsi-15" href="./emnlp-2013-Interpreting_Anaphoric_Shell_Nouns_using_Antecedents_of_Cataphoric_Shell_Nouns_as_Training_Data.html">108 emnlp-2013-Interpreting Anaphoric Shell Nouns using Antecedents of Cataphoric Shell Nouns as Training Data</a></p>
<p>16 0.18630251 <a title="91-lsi-16" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>17 0.18585655 <a title="91-lsi-17" href="./emnlp-2013-Animacy_Detection_with_Voting_Models.html">23 emnlp-2013-Animacy Detection with Voting Models</a></p>
<p>18 0.17787839 <a title="91-lsi-18" href="./emnlp-2013-The_VerbCorner_Project%3A_Toward_an_Empirically-Based_Semantic_Decomposition_of_Verbs.html">183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</a></p>
<p>19 0.17720194 <a title="91-lsi-19" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<p>20 0.1765848 <a title="91-lsi-20" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.042), (18, 0.01), (22, 0.012), (30, 0.036), (50, 0.013), (51, 0.75), (66, 0.016), (75, 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99773026 <a title="91-lda-1" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>Author: Peter Rebersek ; Mateja Verlic</p><p>Abstract: In this paper we present a novel approach to automatic creation of anchor texts for hyperlinks in a document pointing to similar documents. Methods used in this approach rank parts of a document based on the similarity to a presumably related document. Ranks are then used to automatically construct the best anchor text for a link inside original document to the compared document. A number of different methods from information retrieval and natural language processing are adapted for this task. Automatically constructed anchor texts are manually evaluated in terms of relatedness to linked documents and compared to baseline consisting of originally inserted anchor texts. Additionally we use crowdsourcing for evaluation of original anchors and au- tomatically constructed anchors. Results show that our best adapted methods rival the precision of the baseline method.</p><p>same-paper 2 0.99653667 <a title="91-lda-2" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>3 0.99545634 <a title="91-lda-3" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>Author: Grace Muzny ; Luke Zettlemoyer</p><p>Abstract: Online resources, such as Wiktionary, provide an accurate but incomplete source ofidiomatic phrases. In this paper, we study the problem of automatically identifying idiomatic dictionary entries with such resources. We train an idiom classifier on a newly gathered corpus of over 60,000 Wiktionary multi-word definitions, incorporating features that model whether phrase meanings are constructed compositionally. Experiments demonstrate that the learned classifier can provide high quality idiom labels, more than doubling the number of idiomatic entries from 7,764 to 18,155 at precision levels of over 65%. These gains also translate to idiom detection in sentences, by simply using known word sense disambiguation algorithms to match phrases to their definitions. In a set of Wiktionary definition example sentences, the more complete set of idioms boosts detection recall by over 28 percentage points.</p><p>4 0.99321949 <a title="91-lda-4" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<p>Author: Vikas Ganjigunte Ashok ; Song Feng ; Yejin Choi</p><p>Abstract: Predicting the success of literary works is a curious question among publishers and aspiring writers alike. We examine the quantitative connection, if any, between writing style and successful literature. Based on novels over several different genres, we probe the predictive power of statistical stylometry in discriminating successful literary works, and identify characteristic stylistic elements that are more prominent in successful writings. Our study reports for the first time that statistical stylometry can be surprisingly effective in discriminating highly successful literature from less successful counterpart, achieving accuracy up to 84%. Closer analyses lead to several new insights into characteristics ofthe writing style in successful literature, including findings that are contrary to the conventional wisdom with respect to good writing style and readability. ,</p><p>5 0.99093252 <a title="91-lda-5" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<p>Author: Karl Pichotta ; John DeNero</p><p>Abstract: We address the problem of identifying multiword expressions in a language, focusing on English phrasal verbs. Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages. Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking-oriented boosting algorithm produces a comprehensive set ofEnglish phrasal verbs, achieving performance comparable to a human-curated set.</p><p>6 0.99002576 <a title="91-lda-6" href="./emnlp-2013-Orthonormal_Explicit_Topic_Analysis_for_Cross-Lingual_Document_Matching.html">148 emnlp-2013-Orthonormal Explicit Topic Analysis for Cross-Lingual Document Matching</a></p>
<p>7 0.98919511 <a title="91-lda-7" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>8 0.98784423 <a title="91-lda-8" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>9 0.93250674 <a title="91-lda-9" href="./emnlp-2013-Detecting_Compositionality_of_Multi-Word_Expressions_using_Nearest_Neighbours_in_Vector_Space_Models.html">60 emnlp-2013-Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models</a></p>
<p>10 0.92937559 <a title="91-lda-10" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>11 0.92682219 <a title="91-lda-11" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>12 0.92027342 <a title="91-lda-12" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>13 0.91965055 <a title="91-lda-13" href="./emnlp-2013-MCTest%3A_A_Challenge_Dataset_for_the_Open-Domain_Machine_Comprehension_of_Text.html">126 emnlp-2013-MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</a></p>
<p>14 0.91957819 <a title="91-lda-14" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>15 0.91931915 <a title="91-lda-15" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>16 0.91773427 <a title="91-lda-16" href="./emnlp-2013-Automatically_Identifying_Pseudepigraphic_Texts.html">37 emnlp-2013-Automatically Identifying Pseudepigraphic Texts</a></p>
<p>17 0.91532922 <a title="91-lda-17" href="./emnlp-2013-Authorship_Attribution_of_Micro-Messages.html">27 emnlp-2013-Authorship Attribution of Micro-Messages</a></p>
<p>18 0.91166508 <a title="91-lda-18" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>19 0.91055536 <a title="91-lda-19" href="./emnlp-2013-Assembling_the_Kazakh_Language_Corpus.html">26 emnlp-2013-Assembling the Kazakh Language Corpus</a></p>
<p>20 0.90528613 <a title="91-lda-20" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
