<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-97" href="#">emnlp2013-97</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</h1>
<br/><p>Source: <a title="emnlp-2013-97-pdf" href="http://aclweb.org/anthology//D/D13/D13-1102.pdf">pdf</a></p><p>Author: Ahmed Hassan</p><p>Abstract: Web search users frequently modify their queries in hope of receiving better results. This process is referred to as “Query Reformulation”. Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance. In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig- nificantly improve query reformulation performance using features of query concepts.</p><p>Reference: <a title="emnlp-2013-97-reference" href="../emnlp2013_reference/emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract Web search users frequently modify their queries in hope of receiving better results. [sent-2, score-0.422]
</p><p>2 Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. [sent-4, score-1.047]
</p><p>3 Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. [sent-5, score-1.659]
</p><p>4 In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. [sent-7, score-0.955]
</p><p>5 We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig-  nificantly improve query reformulation performance using features of query concepts. [sent-8, score-2.517]
</p><p>6 Oftentimes, users modify their search queries in hope of getting better results. [sent-11, score-0.422]
</p><p>7 Typical search users have low tolerance to viewing lowly ranked search results and they prefer to reformulate the query rather than wade through result listings (Jansen and Spink, 2006). [sent-12, score-0.843]
</p><p>8 Previous studies have also shown that 37% of search queries are reformulations to previous queries (Jansen et al. [sent-13, score-0.828]
</p><p>9 Understanding query reformulation behavior and being able to accurately identify reformulation queries have several benefits. [sent-16, score-1.88]
</p><p>10 One of these benefits is learning from user behavior to better suggest automatic query refinements or query alterations. [sent-17, score-1.317]
</p><p>11 Another benefit is using query reformulation predic-  tion to identify boundaries between search tasks and hence segmenting user activities into topically coherent units. [sent-18, score-1.339]
</p><p>12 Also, if we are able to accurately identify query reformulations, then we will be in a better position to evaluate the satisfaction of users with query results. [sent-19, score-1.278]
</p><p>13 Identifying query reformulation can be very useful for finding cases where the users are not satisfied even after a click on a result that may have seemed relevant given its title and summary but then turned out to be not relevant to the user’s information need. [sent-21, score-1.201]
</p><p>14 Previous work on query reformulation has either focused on automatic query refinement by the search system, e. [sent-22, score-1.767]
</p><p>15 , 2008) or on defining taxonomies for query reformulation strategies, e. [sent-26, score-1.151]
</p><p>16 Other work has proposed solutions for the query reformulation prediction problem or for the similar problem of task boundary identification (Radlinski and Joachims, 2005; Jones and  Klinkner, 2008). [sent-29, score-1.111]
</p><p>17 The two queries are very likely to have been issued by a user who is planning to travel to New York City. [sent-34, score-0.415]
</p><p>18 Hence, most of the solutions proposed in previous work for this problem will incorrectly assume that the second query is a reformulation of the first due to the high word overlap ratio and the small edit distance. [sent-36, score-1.175]
</p><p>19 Hence, despite similar in terms of shared terms, the two queries have differ-  ent intents and are not reformulations of one another. [sent-39, score-0.502]
</p><p>20 To this end, we conducted a study where we collected thousands of consecutive queries and trained judges to label them as either reformulations or not. [sent-40, score-0.527]
</p><p>21 We then built a classifier to identify query reformulation pairs and showed that the proposed classifier outperforms the state-of-the-art methods on identifying query reformulations. [sent-41, score-1.784]
</p><p>22 2  Related Work  There are three areas of work related to the research presented in this paper: (i) query reformulation taxonomies, (ii) automatic query refinement, and (iii) search tasks boundary identification. [sent-43, score-1.775]
</p><p>23 1 Query Reformulation Taxonomies Existing research has studied how web search engines can propose reformulations, but has given less attention to how people perform query reformulations. [sent-46, score-0.72]
</p><p>24 Most of the research on manual query re-  formulation has focused on building taxonomies of query reformulation. [sent-47, score-1.238]
</p><p>25 These taxonomies are generally constructed by examining a small set of query logs. [sent-48, score-0.656]
</p><p>26 (2007) identified 6 different kinds of reformulation states (New, Assistance, Content Change, Generalization, Reformulation, and Specialization) and provided heuristics for identifying them. [sent-51, score-0.543]
</p><p>27 They also used them to predict when a user is most receptive to automatic query suggestions. [sent-52, score-0.693]
</p><p>28 (2006) constructed a taxonomy of query re-finding by manually examining query logs, and implemented algorithms to identify repeat queries, equal click queries and overlapping click queries. [sent-62, score-1.556]
</p><p>29 This line of work is relevant to our work because it studies query reformulation strategies. [sent-67, score-1.077]
</p><p>30 Our work is different because we build a machine-learned predictive model to identify query reformulation while this line of work mainly focuses on defining taxonomies for reformulation strategies. [sent-68, score-1.673]
</p><p>31 2 Automatic Query Refinement A close problem that has received most of the research attention in this area is the problem of automatically generating query refinements. [sent-70, score-0.582]
</p><p>32 These refinements are typically offered as query suggestions to the users or used to alter the user query before submitting it to the search engine. [sent-71, score-1.483]
</p><p>33 (2008) introduced the concept of the query-flow graph where every query is represented by a node and edges connect queries if it is likely for users to move from one query to another. [sent-73, score-1.566]
</p><p>34 (2008) used random walks over a bipartite graph of queries and URLs to find query refinements. [sent-75, score-0.863]
</p><p>35 Query logs were used to suggest query re-  finements in (Baeza-Yates et al. [sent-76, score-0.646]
</p><p>36 Other research has adopted methods based on query expansion (Mitra et al. [sent-79, score-0.582]
</p><p>37 This line of work is different from our work because it focuses on automatically generating query refinements while this work focuses on identifying cases of manual query reformulations. [sent-82, score-1.277]
</p><p>38 3 Search Task Boundary Identification The problem of classifying the boundaries of the user search tasks within sessions in web search logs has been widely addressed before. [sent-84, score-0.437]
</p><p>39 This problem is closely related to the problem of identifying query reformulation. [sent-85, score-0.63]
</p><p>40 On the other hand, a  query reformulation is intended to modify a previous query in hope of getting better results to satisfy the same information need. [sent-89, score-1.708]
</p><p>41 From these definitions, it is clear how query reformulation and task boundary detection are two sides of the same problem. [sent-90, score-1.111]
</p><p>42 A query-flow graph represents chains of related queries in query logs. [sent-93, score-0.863]
</p><p>43 They use this model for finding logical session boundaries and query recommendation. [sent-94, score-0.695]
</p><p>44 He demonstrated that time interval, search pattern and position of a query in a user session, are effective for shifting to a new topic. [sent-96, score-0.775]
</p><p>45 Our work is different because it goes beyond the bag of words approach and tries to assess query similarity based on the concepts represented in each query. [sent-108, score-0.779]
</p><p>46 3  Problem Definition  We start by defining some terms that will be used throughout the paper: Definition: Query Reformulation is the act of submitting a query Q2 to modify a previous search query Q1 in hope of retrieving better results to satisfy the same information need. [sent-110, score-1.271]
</p><p>47 Our objective is to solve the following problem: Given a query Q1, and the following query Q2, predict whether Q2 is reformulation of Q1. [sent-117, score-1.659]
</p><p>48 4  Approach  In this section, we propose methods for predicting whether the current query has been issued by the user to reformulate the previous query. [sent-118, score-0.754]
</p><p>49 This becomes a frequent problems with queries when users do not observe the correct word boundaries (for example: “southjerseycraigslist” for “south jersey craiglist”) or when users are searching for a part of a URL (for example “quincycollege” for “quincy college”). [sent-125, score-0.472]
</p><p>50 2 Queries to Concepts Lexical similarity between queries has been often used to identify related queries (Jansen et al. [sent-129, score-0.62]
</p><p>51 Take the following query pair as an example Q1: weather in new york city and Q2: “hotels in new york city”. [sent-135, score-0.746]
</p><p>52 Hence, any lexical similarity feature would predict that the user submitted Q2 as a reformulation of Q1. [sent-137, score-0.66]
</p><p>53 What we would like to do is to have a query representation that recognizes the difference between Q1 and Q2. [sent-138, score-0.582]
</p><p>54 If we look closely at the two queries, we will notice that in the first query, the user is looking for the “weather”, while in the second query the user is looking for “hotels”. [sent-139, score-0.804]
</p><p>55 To build such a representation, we start by segmenting  each query into phrases. [sent-141, score-0.582]
</p><p>56 Query segmentation is the process of taking a users search query and dividing the tokens into individual phrases or semantic units (Bergsma and Wang, 2007). [sent-142, score-0.796]
</p><p>57 Many approaches to query segmentation have been presented in recent research. [sent-143, score-0.628]
</p><p>58 On the other hand, many unsupervised methods for query segmentation have also been proposed (Hagen et al. [sent-146, score-0.628]
</p><p>59 We opt for the unsupervised techniques to perform query segmentation. [sent-152, score-0.582]
</p><p>60 A seg-  mentation for a query is obtained by computing the pointwise mutual information score for each pair of consecutive words. [sent-154, score-0.606]
</p><p>61 no break can be introduced between “hotels” and “in” or “in” and “new York” in the query “hotels in new york city”). [sent-165, score-0.66]
</p><p>62 In addition to breaking the query into phrases, we were also interested in grouping multi-word keywords together (e. [sent-167, score-0.652]
</p><p>63 The intuition behind that is that a query containing the keyword “new york” and another containing the keyword “new mexico” should not be awarded because they share the word “new”. [sent-171, score-0.77]
</p><p>64 For example the query “kodak easyshare recharger chord” consists of a single semantic unit (phrase) and two keywords “Kodak easyshare” and “recharger cord”. [sent-194, score-0.738]
</p><p>65 This shows that the user had two different intents even though most of the words in the two queries are shared. [sent-199, score-0.429]
</p><p>66 To capture concept similarity, 1004  we define four different ways of matching concepts ranked from the most to the least strict: •  •  •  •  Exact Match: The head and the attributes of the tEwxoa concepts m Thatech he exactly. [sent-202, score-0.447]
</p><p>67 , sJ}, can dbse, d Qef i=ned {q as: YI  XJ  P(S|Q) =iY=1jX=1P(si|qj)P(qj|Q)  (2)  where P(q|Q) is the unigram probability of wwoherdre q Pin( query Q. [sent-229, score-0.582]
</p><p>68 We used the following features to predict the query reformulation type: • Length (num. [sent-257, score-1.077]
</p><p>69 of concepts in Q1 but not in Q2  •  1if Q1 contains all Q2s concepts  •  1if Q2 contains all Q1s concepts  •  all concept features above recomputed for keyawllor cdosn cinespteta fdea otufr concepts 1006  5  Experiments and Results  5. [sent-269, score-0.751]
</p><p>70 1 Data Our data consists of query pairs randomly sampled from the queries submitted to a commercial search engine during a week in mid-2012. [sent-270, score-1.009]
</p><p>71 Every record in our data consisted of a consecutive query pair (Qi,Qi+1) submitted to the search engine by the  same user and in the same session (i. [sent-271, score-0.934]
</p><p>72 Identical queries were excluded from the data because they are always labeled as reformulation and their label is very easy to predict. [sent-276, score-0.776]
</p><p>73 All data in the session to which the sampled query pair belongs were recorded. [sent-278, score-0.653]
</p><p>74 In addition to queries, the data contained a timestamp for each page view, all elements shown in response to that query (e. [sent-279, score-0.582]
</p><p>75 Additionally, they were also shown  queries and clicks before and after the query pair of interest. [sent-288, score-0.912]
</p><p>76 They were asked to then use their assessment of the user’s objectives to determine whether Qi+1 is a reformulation of Qi. [sent-289, score-0.495]
</p><p>77 Each query pair was labeled by three judges and the majority vote among judges was used. [sent-290, score-0.658]
</p><p>78 Because the number of positive instances is much smaller than the number of negative instances, we used all positive instances and an equal number of randomly selected negative instances leaving us with approximately 6000 query pairs. [sent-291, score-0.582]
</p><p>79 45  Figure Types  2 Distribution  of Query  Reformulation  query is intended to correct spelling mistakes), and Same Intent (second query is intended to express the same intent in a different way). [sent-294, score-1.383]
</p><p>80 2 Predicting Query Reformulation In this section we describe the experiments we conducted to evaluate the reformulation prediction classifier. [sent-296, score-0.495]
</p><p>81 We compare the performance of four different systems: •  The first one, Heuristic, simply computes the similarity o bneet,w Heeenu two queries as otmhep percentage of common words to the length of the longer query in terms of the number of words. [sent-298, score-0.894]
</p><p>82 The second query is predicted to be a reformulation of the first if similarity ≥ τsim and the time difference ≤ τtime mmiilnaruitteys. [sent-307, score-1.108]
</p><p>83 The concept features were able to achieve higher precision rates while not sacrificing recall because they were more effective in eliminating false reformulation cases. [sent-329, score-0.581]
</p><p>84 The classifier also failed in cases where the keyword extractor and/or the POS tagger failed to cor-  rectly parse the queries (e. [sent-337, score-0.519]
</p><p>85 In many such cases, the query was a non wellformed sequence of words (e. [sent-342, score-0.582]
</p><p>86 3 Predicting Reformulation Type We conducted another experiment to evaluate the performance of the reformulation type classifier. [sent-348, score-0.495]
</p><p>87 We performed experiments using the data described earlier where judges were asked to select the type of reformulation for every reformulation query. [sent-349, score-1.028]
</p><p>88 The figure shows that most popular reformulations types are those where users move to a more specific intent or express the same intent in a different way. [sent-351, score-0.387]
</p><p>89 Reformulations with spelling suggestions and query generalizations are less popular. [sent-352, score-0.631]
</p><p>90 6  Conclusions  Identifying query reformulations is an interesting and useful application in Information Retrieval. [sent-358, score-0.766]
</p><p>91 Reformulation identification is useful for automatic query refinements, task boundary identification and satisfaction prediction. [sent-359, score-0.644]
</p><p>92 Previous work on this problem has adopted a bag-of-words approach where lexical similarity and word overlap are the key features for identifying query reformulation. [sent-360, score-0.693]
</p><p>93 We proposed a method for identifying concepts in search queries and using them to identify query reformula-  tions. [sent-361, score-1.186]
</p><p>94 The proposed method outperforms previous work because it can better represent the information intent underlying the query and hence can better assess query similarity. [sent-362, score-1.236]
</p><p>95 We also showed that we can reliably predict the type of the reformulation with high accuracy. [sent-364, score-0.495]
</p><p>96 Learning lexicon models from search logs for query expansion. [sent-426, score-0.728]
</p><p>97 Exploring web scale language models for search query processing. [sent-460, score-0.72]
</p><p>98 Patterns and transitions of query reformulation during web searching. [sent-485, score-1.133]
</p><p>99 Beyond the session timeout: Automatic hierarchical segmentation of search topics in query logs. [sent-489, score-0.781]
</p><p>100 Patterns of search: Analyzing and modeling web query refinement. [sent-497, score-0.638]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('query', 0.582), ('reformulation', 0.495), ('queries', 0.281), ('reformulations', 0.184), ('concepts', 0.166), ('user', 0.111), ('jansen', 0.101), ('klinkner', 0.099), ('jones', 0.098), ('keyword', 0.094), ('search', 0.082), ('proceeding', 0.075), ('taxonomies', 0.074), ('hotels', 0.073), ('intent', 0.072), ('session', 0.071), ('keywords', 0.07), ('mins', 0.068), ('edit', 0.066), ('logs', 0.064), ('concept', 0.062), ('users', 0.059), ('radlinski', 0.057), ('web', 0.056), ('head', 0.053), ('weather', 0.052), ('hagen', 0.049), ('boldi', 0.049), ('clicks', 0.049), ('timeout', 0.049), ('spelling', 0.049), ('intended', 0.049), ('failed', 0.048), ('identifying', 0.048), ('segmentation', 0.046), ('match', 0.045), ('bhama', 0.043), ('easyshare', 0.043), ('kodak', 0.043), ('lucchese', 0.043), ('nnx', 0.043), ('recharger', 0.043), ('tommy', 0.043), ('boundaries', 0.042), ('click', 0.042), ('refinements', 0.042), ('engine', 0.041), ('york', 0.039), ('break', 0.039), ('judges', 0.038), ('reformulate', 0.038), ('qj', 0.037), ('intents', 0.037), ('rosie', 0.037), ('xi', 0.036), ('acm', 0.036), ('boundary', 0.034), ('lau', 0.034), ('city', 0.034), ('noun', 0.032), ('overlap', 0.032), ('gao', 0.032), ('similarity', 0.031), ('searching', 0.031), ('qi', 0.03), ('sigir', 0.03), ('bergsma', 0.029), ('anick', 0.028), ('annudm', 0.028), ('cord', 0.028), ('perfume', 0.028), ('spink', 0.028), ('teevan', 0.028), ('tnheu', 0.028), ('satisfaction', 0.028), ('levenshtein', 0.028), ('specification', 0.028), ('boosted', 0.027), ('phrases', 0.027), ('identify', 0.027), ('cikm', 0.027), ('lemma', 0.027), ('refinement', 0.026), ('white', 0.025), ('potthast', 0.025), ('rug', 0.025), ('recomputed', 0.025), ('berger', 0.025), ('ryen', 0.025), ('submits', 0.025), ('submitting', 0.025), ('classifier', 0.025), ('consecutive', 0.024), ('false', 0.024), ('url', 0.023), ('seek', 0.023), ('www', 0.023), ('cases', 0.023), ('submitted', 0.023), ('issued', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="97-tfidf-1" href="./emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching.html">97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</a></p>
<p>Author: Ahmed Hassan</p><p>Abstract: Web search users frequently modify their queries in hope of receiving better results. This process is referred to as “Query Reformulation”. Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance. In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig- nificantly improve query reformulation performance using features of query concepts.</p><p>2 0.31328896 <a title="97-tfidf-2" href="./emnlp-2013-Improving_Web_Search_Ranking_by_Incorporating_Structured_Annotation_of_Queries.html">105 emnlp-2013-Improving Web Search Ranking by Incorporating Structured Annotation of Queries</a></p>
<p>Author: Xiao Ding ; Zhicheng Dou ; Bing Qin ; Ting Liu ; Ji-rong Wen</p><p>Abstract: Web users are increasingly looking for structured data, such as lyrics, job, or recipes, using unstructured queries on the web. However, retrieving relevant results from such data is a challenging problem due to the unstructured language of the web queries. In this paper, we propose a method to improve web search ranking by detecting Structured Annotation of queries based on top search results. In a structured annotation, the original query is split into different units that are associated with semantic attributes in the corresponding domain. We evaluate our techniques using real world queries and achieve significant improvement. . 1</p><p>3 0.16311027 <a title="97-tfidf-3" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<p>Author: Artem Sokokov ; Laura Jehl ; Felix Hieber ; Stefan Riezler</p><p>Abstract: We present an approach to learning bilingual n-gram correspondences from relevance rankings of English documents for Japanese queries. We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR). We propose an efficient boosting algorithm that deals with very large cross-product spaces of word correspondences. We show in an experimental evaluation on patent prior art search that our approach, and in particular a consensus-based combination of boosting and translation-based approaches, yields substantial improvements in CLIR performance. Our training and test data are made publicly available.</p><p>4 0.14341544 <a title="97-tfidf-4" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>Author: Jerome White ; Douglas W. Oard ; Nitendra Rajput ; Marion Zalk</p><p>Abstract: Building search engines that can respond to spoken queries with spoken content requires that the system not just be able to find useful responses, but also that it know when it has heard enough about what the user wants to be able to do so. This paper describes a simulation study with queries spoken by non-native speakers that suggests that indicates that finding relevant content is often possible within a half minute, and that combining features based on automatically recognized words with features designed for automated prediction of query difficulty can serve as a useful basis for predicting when that useful content has been found.</p><p>5 0.12601726 <a title="97-tfidf-5" href="./emnlp-2013-Identifying_Multiple_Userids_of_the_Same_Author.html">95 emnlp-2013-Identifying Multiple Userids of the Same Author</a></p>
<p>Author: Tieyun Qian ; Bing Liu</p><p>Abstract: This paper studies the problem of identifying users who use multiple userids to post in social media. Since multiple userids may belong to the same author, it is hard to directly apply supervised learning to solve the problem. This paper proposes a new method, which still uses supervised learning but does not require training documents from the involved userids. Instead, it uses documents from other userids for classifier building. The classifier can be applied to documents of the involved userids. This is possible because we transform the document space to a similarity space and learning is performed in this new space. Our evaluation is done in the online review domain. The experimental results using a large number of userids and their reviews show that the proposed method is highly effective. 1</p><p>6 0.097441278 <a title="97-tfidf-6" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>7 0.091314055 <a title="97-tfidf-7" href="./emnlp-2013-Open-Domain_Fine-Grained_Class_Extraction_from_Web_Search_Queries.html">142 emnlp-2013-Open-Domain Fine-Grained Class Extraction from Web Search Queries</a></p>
<p>8 0.086009584 <a title="97-tfidf-8" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>9 0.080591552 <a title="97-tfidf-9" href="./emnlp-2013-An_Efficient_Language_Model_Using_Double-Array_Structures.html">20 emnlp-2013-An Efficient Language Model Using Double-Array Structures</a></p>
<p>10 0.080077924 <a title="97-tfidf-10" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>11 0.066906556 <a title="97-tfidf-11" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>12 0.064498447 <a title="97-tfidf-12" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>13 0.059048742 <a title="97-tfidf-13" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>14 0.058385849 <a title="97-tfidf-14" href="./emnlp-2013-Using_Soft_Constraints_in_Joint_Inference_for_Clinical_Concept_Recognition.html">198 emnlp-2013-Using Soft Constraints in Joint Inference for Clinical Concept Recognition</a></p>
<p>15 0.056898437 <a title="97-tfidf-15" href="./emnlp-2013-Well-Argued_Recommendation%3A_Adaptive_Models_Based_on_Words_in_Recommender_Systems.html">200 emnlp-2013-Well-Argued Recommendation: Adaptive Models Based on Words in Recommender Systems</a></p>
<p>16 0.053449057 <a title="97-tfidf-16" href="./emnlp-2013-A_Joint_Learning_Model_of_Word_Segmentation%2C_Lexical_Acquisition%2C_and_Phonetic_Variability.html">8 emnlp-2013-A Joint Learning Model of Word Segmentation, Lexical Acquisition, and Phonetic Variability</a></p>
<p>17 0.050953828 <a title="97-tfidf-17" href="./emnlp-2013-Building_Specialized_Bilingual_Lexicons_Using_Large_Scale_Background_Knowledge.html">42 emnlp-2013-Building Specialized Bilingual Lexicons Using Large Scale Background Knowledge</a></p>
<p>18 0.050143976 <a title="97-tfidf-18" href="./emnlp-2013-Automatically_Classifying_Edit_Categories_in_Wikipedia_Revisions.html">34 emnlp-2013-Automatically Classifying Edit Categories in Wikipedia Revisions</a></p>
<p>19 0.049401335 <a title="97-tfidf-19" href="./emnlp-2013-Fast_Joint_Compression_and_Summarization_via_Graph_Cuts.html">85 emnlp-2013-Fast Joint Compression and Summarization via Graph Cuts</a></p>
<p>20 0.048207555 <a title="97-tfidf-20" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.175), (1, 0.043), (2, -0.043), (3, 0.019), (4, -0.021), (5, 0.02), (6, 0.104), (7, 0.223), (8, 0.123), (9, -0.094), (10, -0.082), (11, 0.219), (12, -0.109), (13, -0.117), (14, 0.119), (15, -0.057), (16, -0.156), (17, -0.347), (18, 0.2), (19, 0.03), (20, 0.101), (21, -0.159), (22, -0.197), (23, 0.036), (24, -0.064), (25, 0.007), (26, -0.053), (27, -0.02), (28, 0.05), (29, 0.145), (30, -0.079), (31, 0.006), (32, 0.002), (33, 0.018), (34, 0.005), (35, -0.047), (36, 0.029), (37, 0.026), (38, 0.062), (39, -0.007), (40, -0.019), (41, 0.001), (42, 0.031), (43, 0.005), (44, 0.036), (45, -0.0), (46, -0.036), (47, -0.044), (48, -0.029), (49, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98483855 <a title="97-lsi-1" href="./emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching.html">97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</a></p>
<p>Author: Ahmed Hassan</p><p>Abstract: Web search users frequently modify their queries in hope of receiving better results. This process is referred to as “Query Reformulation”. Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance. In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig- nificantly improve query reformulation performance using features of query concepts.</p><p>2 0.92918479 <a title="97-lsi-2" href="./emnlp-2013-Improving_Web_Search_Ranking_by_Incorporating_Structured_Annotation_of_Queries.html">105 emnlp-2013-Improving Web Search Ranking by Incorporating Structured Annotation of Queries</a></p>
<p>Author: Xiao Ding ; Zhicheng Dou ; Bing Qin ; Ting Liu ; Ji-rong Wen</p><p>Abstract: Web users are increasingly looking for structured data, such as lyrics, job, or recipes, using unstructured queries on the web. However, retrieving relevant results from such data is a challenging problem due to the unstructured language of the web queries. In this paper, we propose a method to improve web search ranking by detecting Structured Annotation of queries based on top search results. In a structured annotation, the original query is split into different units that are associated with semantic attributes in the corresponding domain. We evaluate our techniques using real world queries and achieve significant improvement. . 1</p><p>3 0.71983945 <a title="97-lsi-3" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>Author: Jerome White ; Douglas W. Oard ; Nitendra Rajput ; Marion Zalk</p><p>Abstract: Building search engines that can respond to spoken queries with spoken content requires that the system not just be able to find useful responses, but also that it know when it has heard enough about what the user wants to be able to do so. This paper describes a simulation study with queries spoken by non-native speakers that suggests that indicates that finding relevant content is often possible within a half minute, and that combining features based on automatically recognized words with features designed for automated prediction of query difficulty can serve as a useful basis for predicting when that useful content has been found.</p><p>4 0.64560431 <a title="97-lsi-4" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<p>Author: Artem Sokokov ; Laura Jehl ; Felix Hieber ; Stefan Riezler</p><p>Abstract: We present an approach to learning bilingual n-gram correspondences from relevance rankings of English documents for Japanese queries. We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR). We propose an efficient boosting algorithm that deals with very large cross-product spaces of word correspondences. We show in an experimental evaluation on patent prior art search that our approach, and in particular a consensus-based combination of boosting and translation-based approaches, yields substantial improvements in CLIR performance. Our training and test data are made publicly available.</p><p>5 0.5703724 <a title="97-lsi-5" href="./emnlp-2013-Open-Domain_Fine-Grained_Class_Extraction_from_Web_Search_Queries.html">142 emnlp-2013-Open-Domain Fine-Grained Class Extraction from Web Search Queries</a></p>
<p>Author: Marius Pasca</p><p>Abstract: This paper introduces a method for extracting fine-grained class labels ( “countries with double taxation agreements with india ”) from Web search queries. The class labels are more numerous and more diverse than those produced by current extraction methods. Also extracted are representative sets of instances (singapore, united kingdom) for the class labels.</p><p>6 0.52746749 <a title="97-lsi-6" href="./emnlp-2013-Identifying_Multiple_Userids_of_the_Same_Author.html">95 emnlp-2013-Identifying Multiple Userids of the Same Author</a></p>
<p>7 0.39590734 <a title="97-lsi-7" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>8 0.36317259 <a title="97-lsi-8" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>9 0.33854645 <a title="97-lsi-9" href="./emnlp-2013-An_Efficient_Language_Model_Using_Double-Array_Structures.html">20 emnlp-2013-An Efficient Language Model Using Double-Array Structures</a></p>
<p>10 0.32645908 <a title="97-lsi-10" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>11 0.29135296 <a title="97-lsi-11" href="./emnlp-2013-Learning_to_Freestyle%3A_Hip_Hop_Challenge-Response_Induction_via_Transduction_Rule_Segmentation.html">122 emnlp-2013-Learning to Freestyle: Hip Hop Challenge-Response Induction via Transduction Rule Segmentation</a></p>
<p>12 0.24880794 <a title="97-lsi-12" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>13 0.24600333 <a title="97-lsi-13" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>14 0.23729226 <a title="97-lsi-14" href="./emnlp-2013-Well-Argued_Recommendation%3A_Adaptive_Models_Based_on_Words_in_Recommender_Systems.html">200 emnlp-2013-Well-Argued Recommendation: Adaptive Models Based on Words in Recommender Systems</a></p>
<p>15 0.2171375 <a title="97-lsi-15" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>16 0.21653609 <a title="97-lsi-16" href="./emnlp-2013-Online_Learning_for_Inexact_Hypergraph_Search.html">141 emnlp-2013-Online Learning for Inexact Hypergraph Search</a></p>
<p>17 0.20727423 <a title="97-lsi-17" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>18 0.20727284 <a title="97-lsi-18" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>19 0.20207617 <a title="97-lsi-19" href="./emnlp-2013-Using_Soft_Constraints_in_Joint_Inference_for_Clinical_Concept_Recognition.html">198 emnlp-2013-Using Soft Constraints in Joint Inference for Clinical Concept Recognition</a></p>
<p>20 0.18930206 <a title="97-lsi-20" href="./emnlp-2013-Animacy_Detection_with_Voting_Models.html">23 emnlp-2013-Animacy Detection with Voting Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.045), (18, 0.027), (22, 0.046), (29, 0.345), (30, 0.074), (45, 0.022), (50, 0.018), (51, 0.16), (66, 0.039), (71, 0.034), (75, 0.025), (77, 0.02), (90, 0.018), (96, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.78402603 <a title="97-lda-1" href="./emnlp-2013-Cascading_Collective_Classification_for_Bridging_Anaphora_Recognition_using_a_Rich_Linguistic_Feature_Set.html">43 emnlp-2013-Cascading Collective Classification for Bridging Anaphora Recognition using a Rich Linguistic Feature Set</a></p>
<p>Author: Yufang Hou ; Katja Markert ; Michael Strube</p><p>Abstract: Recognizing bridging anaphora is difficult due to the wide variation within the phenomenon, the resulting lack of easily identifiable surface markers and their relative rarity. We develop linguistically motivated discourse structure, lexico-semantic and genericity detection features and integrate these into a cascaded minority preference algorithm that models bridging recognition as a subtask of learning finegrained information status (IS). We substantially improve bridging recognition without impairing performance on other IS classes.</p><p>same-paper 2 0.76793778 <a title="97-lda-2" href="./emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching.html">97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</a></p>
<p>Author: Ahmed Hassan</p><p>Abstract: Web search users frequently modify their queries in hope of receiving better results. This process is referred to as “Query Reformulation”. Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance. In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig- nificantly improve query reformulation performance using features of query concepts.</p><p>3 0.76190901 <a title="97-lda-3" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>Author: Mikhail Ageev ; Dmitry Lagun ; Eugene Agichtein</p><p>Abstract: Passage retrieval is a crucial first step of automatic Question Answering (QA). While existing passage retrieval algorithms are effective at selecting document passages most similar to the question, or those that contain the expected answer types, they do not take into account which parts of the document the searchers actually found useful. We propose, to the best of our knowledge, the first successful attempt to incorporate searcher examination data into passage retrieval for question answering. Specifically, we exploit detailed examination data, such as mouse cursor movements and scrolling, to infer the parts of the document the searcher found interesting, and then incorporate this signal into passage retrieval for QA. Our extensive experiments and analysis demonstrate that our method significantly improves passage retrieval, compared to using textual features alone. As an additional contribution, we make available to the research community the code and the search behavior data used in this study, with the hope of encouraging further research in this area.</p><p>4 0.68897688 <a title="97-lda-4" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<p>Author: Artem Sokokov ; Laura Jehl ; Felix Hieber ; Stefan Riezler</p><p>Abstract: We present an approach to learning bilingual n-gram correspondences from relevance rankings of English documents for Japanese queries. We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR). We propose an efficient boosting algorithm that deals with very large cross-product spaces of word correspondences. We show in an experimental evaluation on patent prior art search that our approach, and in particular a consensus-based combination of boosting and translation-based approaches, yields substantial improvements in CLIR performance. Our training and test data are made publicly available.</p><p>5 0.52813405 <a title="97-lda-5" href="./emnlp-2013-Improving_Web_Search_Ranking_by_Incorporating_Structured_Annotation_of_Queries.html">105 emnlp-2013-Improving Web Search Ranking by Incorporating Structured Annotation of Queries</a></p>
<p>Author: Xiao Ding ; Zhicheng Dou ; Bing Qin ; Ting Liu ; Ji-rong Wen</p><p>Abstract: Web users are increasingly looking for structured data, such as lyrics, job, or recipes, using unstructured queries on the web. However, retrieving relevant results from such data is a challenging problem due to the unstructured language of the web queries. In this paper, we propose a method to improve web search ranking by detecting Structured Annotation of queries based on top search results. In a structured annotation, the original query is split into different units that are associated with semantic attributes in the corresponding domain. We evaluate our techniques using real world queries and achieve significant improvement. . 1</p><p>6 0.49495238 <a title="97-lda-6" href="./emnlp-2013-Interpreting_Anaphoric_Shell_Nouns_using_Antecedents_of_Cataphoric_Shell_Nouns_as_Training_Data.html">108 emnlp-2013-Interpreting Anaphoric Shell Nouns using Antecedents of Cataphoric Shell Nouns as Training Data</a></p>
<p>7 0.4926554 <a title="97-lda-7" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>8 0.49217123 <a title="97-lda-8" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>9 0.49061817 <a title="97-lda-9" href="./emnlp-2013-Identifying_Multiple_Userids_of_the_Same_Author.html">95 emnlp-2013-Identifying Multiple Userids of the Same Author</a></p>
<p>10 0.48840305 <a title="97-lda-10" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>11 0.48839152 <a title="97-lda-11" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>12 0.48699263 <a title="97-lda-12" href="./emnlp-2013-Of_Words%2C_Eyes_and_Brains%3A_Correlating_Image-Based_Distributional_Semantic_Models_with_Neural_Representations_of_Concepts.html">140 emnlp-2013-Of Words, Eyes and Brains: Correlating Image-Based Distributional Semantic Models with Neural Representations of Concepts</a></p>
<p>13 0.48652861 <a title="97-lda-13" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>14 0.48645756 <a title="97-lda-14" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>15 0.48425379 <a title="97-lda-15" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>16 0.48389903 <a title="97-lda-16" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>17 0.48350367 <a title="97-lda-17" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>18 0.4830181 <a title="97-lda-18" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>19 0.4828749 <a title="97-lda-19" href="./emnlp-2013-Interactive_Machine_Translation_using_Hierarchical_Translation_Models.html">107 emnlp-2013-Interactive Machine Translation using Hierarchical Translation Models</a></p>
<p>20 0.48285949 <a title="97-lda-20" href="./emnlp-2013-Exploring_Representations_from_Unlabeled_Data_with_Co-training_for_Chinese_Word_Segmentation.html">82 emnlp-2013-Exploring Representations from Unlabeled Data with Co-training for Chinese Word Segmentation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
