<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-5" href="#">emnlp2013-5</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</h1>
<br/><p>Source: <a title="emnlp-2013-5-pdf" href="http://aclweb.org/anthology//D/D13/D13-1070.pdf">pdf</a></p><p>Author: Maria Liakata ; Simon Dobnik ; Shyamasree Saha ; Colin Batchelor ; Dietrich Rebholz-Schuhmann</p><p>Abstract: We present a method which exploits automatically generated scientific discourse annotations to create a content model for the summarisation of scientific articles. Full papers are first automatically annotated using the CoreSC scheme, which captures 11 contentbased concepts such as Hypothesis, Result, Conclusion etc at the sentence level. A content model which follows the sequence of CoreSC categories observed in abstracts is used to provide the skeleton of the summary, making a distinction between dependent and independent categories. Summary creation is also guided by the distribution of CoreSC categories found in the full articles, in order to adequately represent the article content. Fi- nally, we demonstrate the usefulness of the summaries by evaluating them in a complex question answering task. Results are very encouraging as summaries of papers from automatically obtained CoreSCs enable experts to answer 66% of complex content-related questions designed on the basis of paper abstracts. The questions were answered with a precision of 75%, where the upper bound for human summaries (abstracts) was 95%.</p><p>Reference: <a title="emnlp-2013-5-reference" href="../emnlp2013_reference/emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('coresc', 0.81), ('liakat', 0.244), ('sum', 0.174), ('teufel', 0.17), ('answ', 0.14), ('autosumm', 0.103), ('zon', 0.102), ('rhet', 0.09), ('categ', 0.088), ('diverg', 0.085), ('expert', 0.073), ('cit', 0.07), ('quest', 0.067), ('unjust', 0.067), ('ring', 0.064), ('moen', 0.061), ('qazvin', 0.061), ('artic', 0.06), ('bac', 0.056), ('bionlp', 0.056)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="5-tfidf-1" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<p>Author: Maria Liakata ; Simon Dobnik ; Shyamasree Saha ; Colin Batchelor ; Dietrich Rebholz-Schuhmann</p><p>Abstract: We present a method which exploits automatically generated scientific discourse annotations to create a content model for the summarisation of scientific articles. Full papers are first automatically annotated using the CoreSC scheme, which captures 11 contentbased concepts such as Hypothesis, Result, Conclusion etc at the sentence level. A content model which follows the sequence of CoreSC categories observed in abstracts is used to provide the skeleton of the summary, making a distinction between dependent and independent categories. Summary creation is also guided by the distribution of CoreSC categories found in the full articles, in order to adequately represent the article content. Fi- nally, we demonstrate the usefulness of the summaries by evaluating them in a complex question answering task. Results are very encouraging as summaries of papers from automatically obtained CoreSCs enable experts to answer 66% of complex content-related questions designed on the basis of paper abstracts. The questions were answered with a precision of 75%, where the upper bound for human summaries (abstracts) was 95%.</p><p>2 0.13576099 <a title="5-tfidf-2" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>Author: Aliaksei Severyn ; Alessandro Moschitti</p><p>Abstract: This paper proposes a framework for automatically engineering features for two important tasks of question answering: answer sentence selection and answer extraction. We represent question and answer sentence pairs with linguistic structures enriched by semantic information, where the latter is produced by automatic classifiers, e.g., question classifier and Named Entity Recognizer. Tree kernels applied to such structures enable a simple way to generate highly discriminative structural features that combine syntactic and semantic information encoded in the input trees. We conduct experiments on a public benchmark from TREC to compare with previous systems for answer sentence selection and answer extraction. The results show that our models greatly improve on the state of the art, e.g., up to 22% on F1 (relative improvement) for answer extraction, while using no additional resources and no manual feature engineering.</p><p>3 0.09250021 <a title="5-tfidf-3" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>Author: Tengfei Ma ; Hiroshi Nakagawa</p><p>Abstract: Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.</p><p>4 0.091639489 <a title="5-tfidf-4" href="./emnlp-2013-Question_Difficulty_Estimation_in_Community_Question_Answering_Services.html">155 emnlp-2013-Question Difficulty Estimation in Community Question Answering Services</a></p>
<p>Author: Jing Liu ; Quan Wang ; Chin-Yew Lin ; Hsiao-Wuen Hon</p><p>Abstract: In this paper, we address the problem of estimating question difficulty in community question answering services. We propose a competition-based model for estimating question difficulty by leveraging pairwise comparisons between questions and users. Our experimental results show that our model significantly outperforms a PageRank-based approach. Most importantly, our analysis shows that the text of question descriptions reflects the question difficulty. This implies the possibility of predicting question difficulty from the text of question descriptions.</p><p>5 0.091290474 <a title="5-tfidf-5" href="./emnlp-2013-Modeling_Scientific_Impact_with_Topical_Influence_Regression.html">133 emnlp-2013-Modeling Scientific Impact with Topical Influence Regression</a></p>
<p>Author: James Foulds ; Padhraic Smyth</p><p>Abstract: When reviewing scientific literature, it would be useful to have automatic tools that identify the most influential scientific articles as well as how ideas propagate between articles. In this context, this paper introduces topical influence, a quantitative measure of the extent to which an article tends to spread its topics to the articles that cite it. Given the text of the articles and their citation graph, we show how to learn a probabilistic model to recover both the degree of topical influence of each article and the influence relationships between articles. Experimental results on corpora from two well-known computer science conferences are used to illustrate and validate the proposed approach.</p><p>6 0.0788773 <a title="5-tfidf-6" href="./emnlp-2013-MCTest%3A_A_Challenge_Dataset_for_the_Open-Domain_Machine_Comprehension_of_Text.html">126 emnlp-2013-MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</a></p>
<p>7 0.076673999 <a title="5-tfidf-7" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>8 0.065352567 <a title="5-tfidf-8" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>9 0.061884027 <a title="5-tfidf-9" href="./emnlp-2013-Single-Document_Summarization_as_a_Tree_Knapsack_Problem.html">174 emnlp-2013-Single-Document Summarization as a Tree Knapsack Problem</a></p>
<p>10 0.055000369 <a title="5-tfidf-10" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>11 0.054878727 <a title="5-tfidf-11" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>12 0.054830134 <a title="5-tfidf-12" href="./emnlp-2013-Fast_Joint_Compression_and_Summarization_via_Graph_Cuts.html">85 emnlp-2013-Fast Joint Compression and Summarization via Graph Cuts</a></p>
<p>13 0.051429007 <a title="5-tfidf-13" href="./emnlp-2013-Lexical_Chain_Based_Cohesion_Models_for_Document-Level_Statistical_Machine_Translation.html">125 emnlp-2013-Lexical Chain Based Cohesion Models for Document-Level Statistical Machine Translation</a></p>
<p>14 0.04771715 <a title="5-tfidf-14" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>15 0.045219507 <a title="5-tfidf-15" href="./emnlp-2013-Deriving_Adjectival_Scales_from_Continuous_Space_Word_Representations.html">59 emnlp-2013-Deriving Adjectival Scales from Continuous Space Word Representations</a></p>
<p>16 0.043504443 <a title="5-tfidf-16" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>17 0.043263104 <a title="5-tfidf-17" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>18 0.041970514 <a title="5-tfidf-18" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>19 0.040779382 <a title="5-tfidf-19" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>20 0.039862338 <a title="5-tfidf-20" href="./emnlp-2013-Leveraging_Lexical_Cohesion_and_Disruption_for_Topic_Segmentation.html">124 emnlp-2013-Leveraging Lexical Cohesion and Disruption for Topic Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.132), (1, -0.056), (2, 0.008), (3, -0.074), (4, -0.116), (5, 0.036), (6, 0.054), (7, 0.021), (8, -0.033), (9, -0.091), (10, -0.033), (11, -0.044), (12, -0.168), (13, 0.041), (14, -0.045), (15, -0.011), (16, -0.023), (17, 0.011), (18, -0.004), (19, 0.055), (20, -0.059), (21, 0.093), (22, 0.029), (23, -0.026), (24, 0.027), (25, -0.057), (26, 0.001), (27, -0.03), (28, 0.032), (29, 0.104), (30, -0.026), (31, -0.054), (32, 0.026), (33, 0.066), (34, 0.028), (35, -0.079), (36, 0.072), (37, -0.035), (38, 0.01), (39, 0.029), (40, -0.051), (41, 0.05), (42, 0.082), (43, -0.062), (44, -0.108), (45, -0.114), (46, 0.001), (47, 0.088), (48, -0.033), (49, 0.23)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88814354 <a title="5-lsi-1" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<p>Author: Maria Liakata ; Simon Dobnik ; Shyamasree Saha ; Colin Batchelor ; Dietrich Rebholz-Schuhmann</p><p>Abstract: We present a method which exploits automatically generated scientific discourse annotations to create a content model for the summarisation of scientific articles. Full papers are first automatically annotated using the CoreSC scheme, which captures 11 contentbased concepts such as Hypothesis, Result, Conclusion etc at the sentence level. A content model which follows the sequence of CoreSC categories observed in abstracts is used to provide the skeleton of the summary, making a distinction between dependent and independent categories. Summary creation is also guided by the distribution of CoreSC categories found in the full articles, in order to adequately represent the article content. Fi- nally, we demonstrate the usefulness of the summaries by evaluating them in a complex question answering task. Results are very encouraging as summaries of papers from automatically obtained CoreSCs enable experts to answer 66% of complex content-related questions designed on the basis of paper abstracts. The questions were answered with a precision of 75%, where the upper bound for human summaries (abstracts) was 95%.</p><p>2 0.56443721 <a title="5-lsi-2" href="./emnlp-2013-Question_Difficulty_Estimation_in_Community_Question_Answering_Services.html">155 emnlp-2013-Question Difficulty Estimation in Community Question Answering Services</a></p>
<p>Author: Jing Liu ; Quan Wang ; Chin-Yew Lin ; Hsiao-Wuen Hon</p><p>Abstract: In this paper, we address the problem of estimating question difficulty in community question answering services. We propose a competition-based model for estimating question difficulty by leveraging pairwise comparisons between questions and users. Our experimental results show that our model significantly outperforms a PageRank-based approach. Most importantly, our analysis shows that the text of question descriptions reflects the question difficulty. This implies the possibility of predicting question difficulty from the text of question descriptions.</p><p>3 0.52102309 <a title="5-lsi-3" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>Author: Aliaksei Severyn ; Alessandro Moschitti</p><p>Abstract: This paper proposes a framework for automatically engineering features for two important tasks of question answering: answer sentence selection and answer extraction. We represent question and answer sentence pairs with linguistic structures enriched by semantic information, where the latter is produced by automatic classifiers, e.g., question classifier and Named Entity Recognizer. Tree kernels applied to such structures enable a simple way to generate highly discriminative structural features that combine syntactic and semantic information encoded in the input trees. We conduct experiments on a public benchmark from TREC to compare with previous systems for answer sentence selection and answer extraction. The results show that our models greatly improve on the state of the art, e.g., up to 22% on F1 (relative improvement) for answer extraction, while using no additional resources and no manual feature engineering.</p><p>4 0.49280801 <a title="5-lsi-4" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>Author: Mikhail Ageev ; Dmitry Lagun ; Eugene Agichtein</p><p>Abstract: Passage retrieval is a crucial first step of automatic Question Answering (QA). While existing passage retrieval algorithms are effective at selecting document passages most similar to the question, or those that contain the expected answer types, they do not take into account which parts of the document the searchers actually found useful. We propose, to the best of our knowledge, the first successful attempt to incorporate searcher examination data into passage retrieval for question answering. Specifically, we exploit detailed examination data, such as mouse cursor movements and scrolling, to infer the parts of the document the searcher found interesting, and then incorporate this signal into passage retrieval for QA. Our extensive experiments and analysis demonstrate that our method significantly improves passage retrieval, compared to using textual features alone. As an additional contribution, we make available to the research community the code and the search behavior data used in this study, with the hope of encouraging further research in this area.</p><p>5 0.48968247 <a title="5-lsi-5" href="./emnlp-2013-Modeling_Scientific_Impact_with_Topical_Influence_Regression.html">133 emnlp-2013-Modeling Scientific Impact with Topical Influence Regression</a></p>
<p>Author: James Foulds ; Padhraic Smyth</p><p>Abstract: When reviewing scientific literature, it would be useful to have automatic tools that identify the most influential scientific articles as well as how ideas propagate between articles. In this context, this paper introduces topical influence, a quantitative measure of the extent to which an article tends to spread its topics to the articles that cite it. Given the text of the articles and their citation graph, we show how to learn a probabilistic model to recover both the degree of topical influence of each article and the influence relationships between articles. Experimental results on corpora from two well-known computer science conferences are used to illustrate and validate the proposed approach.</p><p>6 0.48117 <a title="5-lsi-6" href="./emnlp-2013-MCTest%3A_A_Challenge_Dataset_for_the_Open-Domain_Machine_Comprehension_of_Text.html">126 emnlp-2013-MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</a></p>
<p>7 0.47930992 <a title="5-lsi-7" href="./emnlp-2013-Single-Document_Summarization_as_a_Tree_Knapsack_Problem.html">174 emnlp-2013-Single-Document Summarization as a Tree Knapsack Problem</a></p>
<p>8 0.44814223 <a title="5-lsi-8" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>9 0.42890662 <a title="5-lsi-9" href="./emnlp-2013-Lexical_Chain_Based_Cohesion_Models_for_Document-Level_Statistical_Machine_Translation.html">125 emnlp-2013-Lexical Chain Based Cohesion Models for Document-Level Statistical Machine Translation</a></p>
<p>10 0.41538978 <a title="5-lsi-10" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>11 0.38261598 <a title="5-lsi-11" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>12 0.36059201 <a title="5-lsi-12" href="./emnlp-2013-Using_Topic_Modeling_to_Improve_Prediction_of_Neuroticism_and_Depression_in_College_Students.html">199 emnlp-2013-Using Topic Modeling to Improve Prediction of Neuroticism and Depression in College Students</a></p>
<p>13 0.3473891 <a title="5-lsi-13" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>14 0.34698084 <a title="5-lsi-14" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>15 0.34408629 <a title="5-lsi-15" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>16 0.3428801 <a title="5-lsi-16" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>17 0.33525836 <a title="5-lsi-17" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>18 0.33372307 <a title="5-lsi-18" href="./emnlp-2013-Deriving_Adjectival_Scales_from_Continuous_Space_Word_Representations.html">59 emnlp-2013-Deriving Adjectival Scales from Continuous Space Word Representations</a></p>
<p>19 0.3304185 <a title="5-lsi-19" href="./emnlp-2013-Detecting_Promotional_Content_in_Wikipedia.html">61 emnlp-2013-Detecting Promotional Content in Wikipedia</a></p>
<p>20 0.32116908 <a title="5-lsi-20" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.028), (25, 0.022), (29, 0.022), (39, 0.302), (45, 0.011), (47, 0.059), (51, 0.078), (65, 0.156), (69, 0.033), (73, 0.105), (79, 0.045), (84, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.70871562 <a title="5-lda-1" href="./emnlp-2013-Lexical_Chain_Based_Cohesion_Models_for_Document-Level_Statistical_Machine_Translation.html">125 emnlp-2013-Lexical Chain Based Cohesion Models for Document-Level Statistical Machine Translation</a></p>
<p>Author: Deyi Xiong ; Yang Ding ; Min Zhang ; Chew Lim Tan</p><p>Abstract: Lexical chains provide a representation of the lexical cohesion structure of a text. In this paper, we propose two lexical chain based cohesion models to incorporate lexical cohesion into document-level statistical machine translation: 1) a count cohesion model that rewards a hypothesis whenever a chain word occurs in the hypothesis, 2) and a probability cohesion model that further takes chain word translation probabilities into account. We compute lexical chains for each source document to be translated and generate target lexical chains based on the computed source chains via maximum entropy classifiers. We then use the generated target chains to provide constraints for word selection in document-level machine translation through the two proposed lexical chain based cohesion models. We verify the effectiveness of the two models using a hierarchical phrase-based translation system. Ex- periments on large-scale training data show that they can substantially improve translation quality in terms of BLEU and that the probability cohesion model outperforms previous models based on lexical cohesion devices.</p><p>same-paper 2 0.7044819 <a title="5-lda-2" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<p>Author: Maria Liakata ; Simon Dobnik ; Shyamasree Saha ; Colin Batchelor ; Dietrich Rebholz-Schuhmann</p><p>Abstract: We present a method which exploits automatically generated scientific discourse annotations to create a content model for the summarisation of scientific articles. Full papers are first automatically annotated using the CoreSC scheme, which captures 11 contentbased concepts such as Hypothesis, Result, Conclusion etc at the sentence level. A content model which follows the sequence of CoreSC categories observed in abstracts is used to provide the skeleton of the summary, making a distinction between dependent and independent categories. Summary creation is also guided by the distribution of CoreSC categories found in the full articles, in order to adequately represent the article content. Fi- nally, we demonstrate the usefulness of the summaries by evaluating them in a complex question answering task. Results are very encouraging as summaries of papers from automatically obtained CoreSCs enable experts to answer 66% of complex content-related questions designed on the basis of paper abstracts. The questions were answered with a precision of 75%, where the upper bound for human summaries (abstracts) was 95%.</p><p>3 0.65462995 <a title="5-lda-3" href="./emnlp-2013-Appropriately_Incorporating_Statistical_Significance_in_PMI.html">25 emnlp-2013-Appropriately Incorporating Statistical Significance in PMI</a></p>
<p>Author: Om P. Damani ; Shweta Ghonge</p><p>Abstract: Two recent measures incorporate the notion of statistical significance in basic PMI formulation. In some tasks, we find that the new measures perform worse than the PMI. Our analysis shows that while the basic ideas in incorporating statistical significance in PMI are reasonable, they have been applied slightly inappropriately. By fixing this, we get new measures that improve performance over not just PMI but on other popular co-occurrence measures as well. In fact, the revised measures perform reasonably well compared with more resource intensive non co-occurrence based methods also.</p><p>4 0.57589984 <a title="5-lda-4" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>Author: Hao Wang ; Zhengdong Lu ; Hang Li ; Enhong Chen</p><p>Abstract: Natural language conversation is widely regarded as a highly difficult problem, which is usually attacked with either rule-based or learning-based models. In this paper we propose a retrieval-based automatic response model for short-text conversation, to exploit the vast amount of short conversation instances available on social media. For this purpose we introduce a dataset of short-text conversation based on the real-world instances from Sina Weibo (a popular Chinese microblog service), which will be soon released to public. This dataset provides rich collection of instances for the research on finding natural and relevant short responses to a given short text, and useful for both training and testing of conversation models. This dataset consists of both naturally formed conversations, manually labeled data, and a large repository of candidate responses. Our preliminary experiments demonstrate that the simple retrieval-based conversation model performs reasonably well when combined with the rich instances in our dataset.</p><p>5 0.56984723 <a title="5-lda-5" href="./emnlp-2013-Measuring_Ideological_Proportions_in_Political_Speeches.html">129 emnlp-2013-Measuring Ideological Proportions in Political Speeches</a></p>
<p>Author: Yanchuan Sim ; Brice D. L. Acree ; Justin H. Gross ; Noah A. Smith</p><p>Abstract: We seek to measure political candidates’ ideological positioning from their speeches. To accomplish this, we infer ideological cues from a corpus of political writings annotated with known ideologies. We then represent the speeches of U.S. Presidential candidates as sequences of cues and lags (filler distinguished only by its length in words). We apply a domain-informed Bayesian HMM to infer the proportions of ideologies each candidate uses in each campaign. The results are validated against a set of preregistered, domain expertauthored hypotheses.</p><p>6 0.56979442 <a title="5-lda-6" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>7 0.56805199 <a title="5-lda-7" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>8 0.56682682 <a title="5-lda-8" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>9 0.56633425 <a title="5-lda-9" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>10 0.5643599 <a title="5-lda-10" href="./emnlp-2013-Building_Event_Threads_out_of_Multiple_News_Articles.html">41 emnlp-2013-Building Event Threads out of Multiple News Articles</a></p>
<p>11 0.56372786 <a title="5-lda-11" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>12 0.56250244 <a title="5-lda-12" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>13 0.56184036 <a title="5-lda-13" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<p>14 0.5598442 <a title="5-lda-14" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>15 0.5597893 <a title="5-lda-15" href="./emnlp-2013-Exploiting_Language_Models_for_Visual_Recognition.html">78 emnlp-2013-Exploiting Language Models for Visual Recognition</a></p>
<p>16 0.55970258 <a title="5-lda-16" href="./emnlp-2013-Structured_Penalties_for_Log-Linear_Language_Models.html">176 emnlp-2013-Structured Penalties for Log-Linear Language Models</a></p>
<p>17 0.55918598 <a title="5-lda-17" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>18 0.55851781 <a title="5-lda-18" href="./emnlp-2013-Image_Description_using_Visual_Dependency_Representations.html">98 emnlp-2013-Image Description using Visual Dependency Representations</a></p>
<p>19 0.55817527 <a title="5-lda-19" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>20 0.5563404 <a title="5-lda-20" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
