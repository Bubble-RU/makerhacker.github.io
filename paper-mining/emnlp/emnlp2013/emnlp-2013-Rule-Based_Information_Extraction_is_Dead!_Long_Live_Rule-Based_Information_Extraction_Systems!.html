<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-161" href="#">emnlp2013-161</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</h1>
<br/><p>Source: <a title="emnlp-2013-161-pdf" href="http://aclweb.org/anthology//D/D13/D13-1079.pdf">pdf</a></p><p>Author: Laura Chiticariu ; Yunyao Li ; Frederick R. Reiss</p><p>Abstract: The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape ofIE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.</p><p>Reference: <a title="emnlp-2013-161-reference" href="../emnlp2013_reference/emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com s  Abstract The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). [sent-10, score-0.383]
</p><p>2 We surveyed the landscape ofIE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. [sent-11, score-0.622]
</p><p>3 We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. [sent-12, score-0.423]
</p><p>4 We make a case for the importance of rule-based IE to industry practitioners. [sent-13, score-0.192]
</p><p>5 We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice. [sent-14, score-0.475]
</p><p>6 1 Introduction  The recent growth of “Big Data” analytics over large quantities of unstructured text has led to increased interest in information extraction technologies from both academia and industry (Mendel, 2013). [sent-15, score-0.757]
</p><p>7 Most recent academic research in this area starts from the assumption that statistical machine learning is the best approach to solving information extraction problems. [sent-16, score-0.17]
</p><p>8 Figure 1 shows empirical evidence of this trend drawn from a survey of recent published research papers. [sent-17, score-0.047]
</p><p>9 We examined the EMNLP, ACL, and NAACL conference proceedings from 2003 through 2012 and identified 177 different EMNLP research papers on the topic of entity extraction. [sent-18, score-0.123]
</p><p>10 The rule-based approach, although largely ignored in the research community, dominates the commercial market. [sent-20, score-0.229]
</p><p>11 We focus on entity extraction, as it is a classical IE task, and most industrial IE systems offer this feature. [sent-22, score-0.108]
</p><p>12 The left side of the graph shows the breakdown of research papers according to this categorization. [sent-23, score-0.058]
</p><p>13 Only six papers relied solely on rules to perform the extraction tasks described. [sent-24, score-0.204]
</p><p>14 The remainder relied entirely or substantially on statistical techniques. [sent-25, score-0.045]
</p><p>15 As shown in Figure 2, these fractions were roughly constant across the 10-year period studied, indicating that attitudes regarding the relative importance ofthe different techniques have remained constant. [sent-26, score-0.04]
</p><p>16 hc o2d0s1 i3n A Nsastoucria lti Loan fgoura Cgoem Ppruotcaetsiosin agl, L piang eusis 8t2ic7s–832, En@ty Extrac@on Papers by Year  Year  of$ PublicaAon  Figure 2: The conference paper data (left-hand bar) from Figure 1, broken down by year of publication. [sent-29, score-0.061]
</p><p>17 The relative fractions of the three different techniques have not changed significantly over time. [sent-30, score-0.04]
</p><p>18 The papers that use a mixture of rulebased and machine learning techniques were generally written so as to obfuscate the use of rules, emphasizing the machine learning aspect of the work. [sent-32, score-0.111]
</p><p>19 In the commercial world, the situation is largely reversed. [sent-36, score-0.178]
</p><p>20 The right side of Figure 1 shows the result of a parallel survey of commercial entity extraction products from 54 different vendors listed in (Yuen and Koehler-Kruener, 2012). [sent-37, score-0.651]
</p><p>21 We studied analyst reports and product literature, then classified each product according to the same three categories. [sent-38, score-0.08]
</p><p>22 Table 1 shows the 41 products considered in the study 1. [sent-39, score-0.046]
</p><p>23 We conducted this industry survey in 2013, one year after the ten-year run of NLP papers we stud-  ied. [sent-40, score-0.358]
</p><p>24 One would expect the industrial landscape to reflect the research efforts of the previous 10 years, as mature technology moved from academia to industry. [sent-41, score-0.238]
</p><p>25 Instead, results of this second survey showed the opposite effect, with rule-based systems comprising the largest fraction of those surveyed. [sent-42, score-0.047]
</p><p>26 Only 1/3 of the vendors relied entirely on machine learning. [sent-43, score-0.305]
</p><p>27 Among public companies and private compa1Other products do not offer entity extraction, or we did not find sufficient evidence to classify the technology. [sent-44, score-0.148]
</p><p>28 828 Table 1: Vendors and products considered in the study. [sent-45, score-0.046]
</p><p>29 2  Explaining the Disconnect  What is the source of this disconnect between research and industry? [sent-49, score-0.151]
</p><p>30 Indeed, many of the smaller companies we surveyed were founded by NLP researchers, and many of the larger vendors actively publish in the NLP literature. [sent-51, score-0.343]
</p><p>31 We believe that the disconnect arises from a difference in how the two communities measure the costs and benefits of information extraction. [sent-52, score-0.326]
</p><p>32 Table 2 summarizes the pros and cons of machine learning (ML) and rule-based IE technologies (Atzmueller and Kluegl, 2008; Grimes, 2011; Leung et al. [sent-53, score-0.241]
</p><p>33 On the surface, both academia and commercial vendors acknowledge essentially the same pros and cons for the two ap-  proaches. [sent-59, score-0.778]
</p><p>34 However, the two communities weight the pros and cons significantly differently, leading to the drastic disconnect in Figure 1. [sent-60, score-0.441]
</p><p>35 Academic papers evaluate IE performance in terms of precision and recall over standard labeled data sets. [sent-62, score-0.058]
</p><p>36 This simple, clean, and objective measure is useful for judging competitions, but the reality of the business world is 829 much more fluid and less well-defined. [sent-63, score-0.221]
</p><p>37 In a business context, definitions of even basic entities like “product” and “revenue” vary widely from one company to another. [sent-64, score-0.185]
</p><p>38 In real-world applications, the output of extraction is often the input to a larger process, and it is the quality of the larger process that drives business value. [sent-67, score-0.286]
</p><p>39 To be useful in a business context, IE must function well with metrics that are ill-defined and subject to change. [sent-70, score-0.185]
</p><p>40 The commercial world greatly values rule-based IE for its interpretability, which makes IE programs easier to adopt, understand, debug, and maintain in the face of changing requirements (Kluegl et al. [sent-72, score-0.205]
</p><p>41 Furthermore, rule-based IE programs are valued for allowing one to easily incorporate domain knowledge, which is essential for targeting specific business problems (Grimes, 2011). [sent-74, score-0.26]
</p><p>42 As an example, an application may pose simple requirements to its entity recognition component to output only full person names, and not include salutation. [sent-75, score-0.065]
</p><p>43 With a rulebased system, such a requirement translates to removing a few rules. [sent-76, score-0.053]
</p><p>44 In a business setting,  the most significant costs of using information extraction are the labor cost of developing or adapting extractors for a particular business problem, and the hardware cost of compute resources required by the system. [sent-79, score-0.634]
</p><p>45 NLP researchers generally have a well-developed sense of the labor cost of writing extraction rules, viewing this task as a “tedious and time-consuming process” that “is not really practical” (Yakushiji et al. [sent-80, score-0.208]
</p><p>46 But there is a strong tendency in the NLP literature to ignore the complex and time-consuming tasks inherent in solving an extraction problem using machine learning. [sent-83, score-0.101]
</p><p>47 Not surprisingly, in industry, ML-based systems are often deemed risky to adopt and difficult to understand and maintain, largely due to model opaqueness (Fry, 2011; Wagstaff, 2012; Malioutov and Varshney, 2013). [sent-86, score-0.046]
</p><p>48 The infeasibility of gathering labeled data in many real-world scenarios further increases the risk of committing to a ML-based solution. [sent-87, score-0.04]
</p><p>49 A measure of the system’s scalability and runtime efficiency, hardware costs are a function of two metrics: throughput and memory footprint. [sent-88, score-0.207]
</p><p>50 These figures, while extremely important for commercial vendors, are typically not reported in NLP literature. [sent-89, score-0.132]
</p><p>51 Nevertheless, our experience in practice suggests that ML-based approaches are much slower, and require more memory compared to rule-based approaches, whose throughput can be in the order of MB/second/core for complex extraction tasks like NER (Chiticariu et al. [sent-90, score-0.151]
</p><p>52 Finally, we believe that the  most notable reason behind the academic community’s steering away from rule-based IE systems is the (false) perception of lack of research problems. [sent-93, score-0.162]
</p><p>53 830 3  Bridging the Gap  As NLP researchers who also work regularly with business customers, we have become increasingly worried about the gap in perception between information extraction research and industry. [sent-98, score-0.444]
</p><p>54 The recent growth of Big Data analytics has turned IE into big business (Mendel, 2013). [sent-99, score-0.56]
</p><p>55 If current trends continue, the business world will move ahead with unprincipled, ad-hoc solutions to customers’ business problems, while researchers pursue ever more complex and impractical statistical approaches that become increasingly irrelevant. [sent-100, score-0.505]
</p><p>56 Eventually, the gap between  research and practice will become insurmountable, an outcome in neither community’s best interest. [sent-101, score-0.05]
</p><p>57 The academic NLP community needs to stop treating rule-based IE as a dead-end technology. [sent-102, score-0.175]
</p><p>58 As discussed in Section 2, the domination of rule-based IE systems in the industry is well-justified. [sent-103, score-0.192]
</p><p>59 Even in their current form, with ad-hoc solutions built on techniques from the early 1980’s, rule-based systems serve the industry needs better than the latest ML techniques. [sent-104, score-0.192]
</p><p>60 Nonetheless, there is an enormous untapped opportunity for researchers to make the rule-based approach more principled, effective, and efficient. [sent-105, score-0.064]
</p><p>61 In the remainder of this section, we lay out a research agenda centered around capturing this opportunity. [sent-106, score-0.115]
</p><p>62 Specifically, taking a systemic approach to rule-based IE, one can identify a set of research problems by separating rule development and deployment. [sent-107, score-0.216]
</p><p>63 In particular, we believe research should focus on: (a) data models and rule language, (b) systems research in rule evaluation and (c) machine learning research for learning problems in this richer target language. [sent-108, score-0.327]
</p><p>64 If research on rule-based IE is to move  forward in a principled way, the community needs a standard way to express rules. [sent-110, score-0.106]
</p><p>65 We believe that the NLP community can replicate the success of the SQL language in connecting data management research and practice. [sent-111, score-0.155]
</p><p>66 An earlier attempt in late 1980’s to formalize a rule language resulted in the Common Pattern Specification Language (CPSL) (Appelt and Onyshkevych, 1998). [sent-113, score-0.12]
</p><p>67 While CPSL did not succeed due to multiple drawbacks, including expressivity limitations, performance limitations, and its lack of support for core operations such as part of speech (Chiticariu et al. [sent-114, score-0.061]
</p><p>68 Meanwhile, a number of declarative IE languages developed in the database community, including AQL (Chiticariu et al. [sent-119, score-0.128]
</p><p>69 However, they largely remain unknown in the NLP community. [sent-126, score-0.046]
</p><p>70 We believe now is the right time to establish a standard IE rule language, drawing from existing proposals and experience over the past 30 years. [sent-127, score-0.169]
</p><p>71 Towards this goal, IE researchers need to answer the following questions: What is the right data model to capture text, annotations over text, and their properties? [sent-128, score-0.064]
</p><p>72 Can we establish a standard declarative extensible rule language for processing data in this model with a clear set of constructs that is sufficiently expressive to solve most IE tasks encountered so far? [sent-129, score-0.248]
</p><p>73 ” As in the database community, initial research should focus on systemic issues such  as data representation and speeding up rule evaluation via automatic performance optimization. [sent-133, score-0.178]
</p><p>74 Once baseline systems are established, system-related research would naturally diverge in several directions, such as extending the language with new primitives (and corresponding optimizations), and exploring modern hardware. [sent-134, score-0.092]
</p><p>75 (One need not worry about choosing the language, nor runtime efficiency. [sent-137, score-0.037]
</p><p>76 ) With an expressive rule language, a major challenge is to prevent the system from generating arbitrarily complex rule sets, which would be difficult to understand or maintain. [sent-138, score-0.24]
</p><p>77 Finally, it is conceivable that some problems will not fit in the target language, and therefore will need alternative solutions. [sent-140, score-0.038]
</p><p>78 –  4  –  Conclusion  While rule-based IE dominates the commercial world, it is widely considered obsolete by the academia. [sent-142, score-0.183]
</p><p>79 We made a case for the importance of rule-based approaches to industry practitioners. [sent-143, score-0.192]
</p><p>80 Specifically, we call  for the standardization of an IE rule language and outline an ambitious research agenda for NLP researchers who wish to tackle research problems of wide interest and value in the industry. [sent-145, score-0.297]
</p><p>81 Empirical study on the performance stability of named entity recognition model across domains. [sent-186, score-0.065]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ie', 0.375), ('analytics', 0.282), ('vendors', 0.26), ('industry', 0.192), ('business', 0.185), ('disconnect', 0.151), ('academia', 0.145), ('chiticariu', 0.145), ('kluegl', 0.145), ('commercial', 0.132), ('declarative', 0.128), ('pros', 0.126), ('rule', 0.12), ('atzmueller', 0.116), ('reiss', 0.116), ('sql', 0.116), ('cons', 0.115), ('community', 0.106), ('extraction', 0.101), ('primitives', 0.092), ('almaden', 0.087), ('cpsl', 0.087), ('yakushiji', 0.087), ('ibm', 0.085), ('costs', 0.077), ('yunyao', 0.075), ('agenda', 0.075), ('gate', 0.075), ('frederick', 0.073), ('academic', 0.069), ('ml', 0.066), ('entity', 0.065), ('jose', 0.064), ('researchers', 0.064), ('year', 0.061), ('expressivity', 0.061), ('nlp', 0.06), ('attensity', 0.058), ('cunningham', 0.058), ('extrac', 0.058), ('fagin', 0.058), ('grimes', 0.058), ('infosphere', 0.058), ('jape', 0.058), ('krishnan', 0.058), ('leung', 0.058), ('mendel', 0.058), ('putthividhya', 0.058), ('rajasekar', 0.058), ('systemic', 0.058), ('systemt', 0.058), ('specification', 0.058), ('papers', 0.058), ('big', 0.056), ('laura', 0.053), ('rulebased', 0.053), ('emnlp', 0.052), ('dominates', 0.051), ('gap', 0.05), ('throughput', 0.05), ('landscape', 0.05), ('malioutov', 0.05), ('developers', 0.05), ('revenue', 0.05), ('roberts', 0.05), ('communities', 0.049), ('believe', 0.049), ('survey', 0.047), ('largely', 0.046), ('appelt', 0.046), ('surveyed', 0.046), ('products', 0.046), ('relied', 0.045), ('perception', 0.044), ('hardware', 0.043), ('industrial', 0.043), ('yuen', 0.043), ('labor', 0.043), ('sap', 0.043), ('server', 0.04), ('lay', 0.04), ('feldman', 0.04), ('fractions', 0.04), ('shivakumar', 0.04), ('gathering', 0.04), ('krishnamurthy', 0.04), ('product', 0.04), ('san', 0.04), ('jain', 0.038), ('customers', 0.038), ('problems', 0.038), ('companies', 0.037), ('programs', 0.037), ('growth', 0.037), ('runtime', 0.037), ('mausam', 0.037), ('world', 0.036), ('accomplish', 0.035), ('ahead', 0.035), ('ty', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="161-tfidf-1" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>Author: Laura Chiticariu ; Yunyao Li ; Frederick R. Reiss</p><p>Abstract: The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape ofIE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.</p><p>2 0.073698476 <a title="161-tfidf-2" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>Author: Jinpeng Wang ; Wayne Xin Zhao ; Haitian Wei ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Hot trends are likely to bring new business opportunities. For example, “Air Pollution” might lead to a significant increase of the sales of related products, e.g., mouth mask. For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. In this paper, we take the initiative to study the task of how to identify trend related products. The major novelty of our work is that we automatically learn commercial intents revealed from microblogs. We carefully construct a data collection for this task and present quite a few insightful findings. In order to solve this problem, we further propose a graph based method, which jointly models relevance and associativity. We perform extensive experiments and the results showed that our methods are very effective.</p><p>3 0.070819199 <a title="161-tfidf-3" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>Author: Oier Lopez de Lacalle ; Mirella Lapata</p><p>Abstract: In this paper we present an unsupervised approach to relational information extraction. Our model partitions tuples representing an observed syntactic relationship between two named entities (e.g., “X was born in Y” and “X is from Y”) into clusters corresponding to underlying semantic relation types (e.g., BornIn, Located). Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task. Evaluation results on the ACE 2007 English Relation Detection and Categorization (RDC) task show that our model outperforms competitive unsupervised approaches by a wide margin and is able to produce clusters shaped by both the data and the rules.</p><p>4 0.066503018 <a title="161-tfidf-4" href="./emnlp-2013-A_Convex_Alternative_to_IBM_Model_2.html">2 emnlp-2013-A Convex Alternative to IBM Model 2</a></p>
<p>Author: Andrei Simion ; Michael Collins ; Cliff Stein</p><p>Abstract: The IBM translation models have been hugely influential in statistical machine translation; they are the basis of the alignment models used in modern translation systems. Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are non-convex, and hence have multiple local optima. In this paper we introduce a convex relaxation of IBM Model 2, and describe an optimization algorithm for the relaxation based on a subgradient method combined with exponentiated-gradient updates. Our approach gives the same level of alignment accuracy as IBM Model 2.</p><p>5 0.05515926 <a title="161-tfidf-5" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>Author: Baichuan Li ; Jing Liu ; Chin-Yew Lin ; Irwin King ; Michael R. Lyu</p><p>Abstract: Social media like forums and microblogs have accumulated a huge amount of user generated content (UGC) containing human knowledge. Currently, most of UGC is listed as a whole or in pre-defined categories. This “list-based” approach is simple, but hinders users from browsing and learning knowledge of certain topics effectively. To address this problem, we propose a hierarchical entity-based approach for structuralizing UGC in social media. By using a large-scale entity repository, we design a three-step framework to organize UGC in a novel hierarchical structure called “cluster entity tree (CET)”. With Yahoo! Answers as a test case, we conduct experiments and the results show the effectiveness of our framework in constructing CET. We further evaluate the performance of CET on UGC organization in both user and system aspects. From a user aspect, our user study demonstrates that, with CET-based structure, users perform significantly better in knowledge learning than using traditional list-based approach. From a system aspect, CET substantially boosts the performance of two information retrieval models (i.e., vector space model and query likelihood language model).</p><p>6 0.049044285 <a title="161-tfidf-6" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>7 0.046907004 <a title="161-tfidf-7" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>8 0.046318505 <a title="161-tfidf-8" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>9 0.045606028 <a title="161-tfidf-9" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>10 0.044902246 <a title="161-tfidf-10" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>11 0.043018993 <a title="161-tfidf-11" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>12 0.042882476 <a title="161-tfidf-12" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>13 0.041244406 <a title="161-tfidf-13" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>14 0.040217966 <a title="161-tfidf-14" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>15 0.039508853 <a title="161-tfidf-15" href="./emnlp-2013-MCTest%3A_A_Challenge_Dataset_for_the_Open-Domain_Machine_Comprehension_of_Text.html">126 emnlp-2013-MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</a></p>
<p>16 0.039195232 <a title="161-tfidf-16" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>17 0.038838375 <a title="161-tfidf-17" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<p>18 0.038558919 <a title="161-tfidf-18" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>19 0.037950482 <a title="161-tfidf-19" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>20 0.037896637 <a title="161-tfidf-20" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.152), (1, 0.032), (2, -0.022), (3, 0.002), (4, 0.005), (5, 0.02), (6, -0.003), (7, 0.034), (8, 0.067), (9, 0.034), (10, -0.015), (11, 0.007), (12, -0.048), (13, -0.004), (14, 0.003), (15, 0.001), (16, 0.043), (17, 0.022), (18, 0.053), (19, -0.027), (20, 0.012), (21, 0.044), (22, 0.02), (23, -0.044), (24, -0.005), (25, -0.016), (26, -0.011), (27, -0.101), (28, -0.009), (29, -0.127), (30, -0.066), (31, 0.106), (32, -0.031), (33, -0.029), (34, 0.1), (35, 0.02), (36, 0.053), (37, -0.046), (38, -0.036), (39, 0.008), (40, -0.015), (41, -0.019), (42, 0.053), (43, -0.076), (44, -0.033), (45, 0.004), (46, -0.017), (47, -0.016), (48, -0.064), (49, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93583232 <a title="161-lsi-1" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>Author: Laura Chiticariu ; Yunyao Li ; Frederick R. Reiss</p><p>Abstract: The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape ofIE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.</p><p>2 0.52988279 <a title="161-lsi-2" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>Author: Jinpeng Wang ; Wayne Xin Zhao ; Haitian Wei ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Hot trends are likely to bring new business opportunities. For example, “Air Pollution” might lead to a significant increase of the sales of related products, e.g., mouth mask. For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. In this paper, we take the initiative to study the task of how to identify trend related products. The major novelty of our work is that we automatically learn commercial intents revealed from microblogs. We carefully construct a data collection for this task and present quite a few insightful findings. In order to solve this problem, we further propose a graph based method, which jointly models relevance and associativity. We perform extensive experiments and the results showed that our methods are very effective.</p><p>3 0.49252573 <a title="161-lsi-3" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>Author: Baichuan Li ; Jing Liu ; Chin-Yew Lin ; Irwin King ; Michael R. Lyu</p><p>Abstract: Social media like forums and microblogs have accumulated a huge amount of user generated content (UGC) containing human knowledge. Currently, most of UGC is listed as a whole or in pre-defined categories. This “list-based” approach is simple, but hinders users from browsing and learning knowledge of certain topics effectively. To address this problem, we propose a hierarchical entity-based approach for structuralizing UGC in social media. By using a large-scale entity repository, we design a three-step framework to organize UGC in a novel hierarchical structure called “cluster entity tree (CET)”. With Yahoo! Answers as a test case, we conduct experiments and the results show the effectiveness of our framework in constructing CET. We further evaluate the performance of CET on UGC organization in both user and system aspects. From a user aspect, our user study demonstrates that, with CET-based structure, users perform significantly better in knowledge learning than using traditional list-based approach. From a system aspect, CET substantially boosts the performance of two information retrieval models (i.e., vector space model and query likelihood language model).</p><p>4 0.45386237 <a title="161-lsi-4" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>Author: William Yang Wang ; Edward Lin ; John Kominek</p><p>Abstract: We propose a Laplacian structured sparsity model to study computational branding analytics. To do this, we collected customer reviews from Starbucks, Dunkin’ Donuts, and other coffee shops across 38 major cities in the Midwest and Northeastern regions of USA. We study the brand related language use through these reviews, with focuses on the brand satisfaction and gender factors. In particular, we perform three tasks: automatic brand identification from raw text, joint brand-satisfaction prediction, and joint brandgender-satisfaction prediction. This work extends previous studies in text classification by incorporating the dependency and interaction among local features in the form of structured sparsity in a log-linear model. Our quantitative evaluation shows that our approach which combines the advantages of graphical modeling and sparsity modeling techniques significantly outperforms various standard and stateof-the-art text classification algorithms. In addition, qualitative analysis of our model reveals important features of the language uses associated with the specific brands.</p><p>5 0.44827414 <a title="161-lsi-5" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>Author: Ruiji Fu ; Bing Qin ; Ting Liu</p><p>Abstract: Hypernym discovery aims to extract such noun pairs that one noun is a hypernym of the other. Most previous methods are based on lexical patterns but perform badly on opendomain data. Other work extracts hypernym relations from encyclopedias but has limited coverage. This paper proposes a simple yet effective distant supervision framework for Chinese open-domain hypernym discovery. Given an entity name, we try to discover its hypernyms by leveraging knowledge from multiple sources, i.e., search engine results, encyclopedias, and morphology of the entity name. First, we extract candidate hypernyms from the above sources. Then, we apply a statistical ranking model to select correct hypernyms. A set of novel features is proposed for the rank- ing model. We also present a heuristic strategy to build a large-scale noisy training data for the model without human annotation. Experimental results demonstrate that our approach outperforms the state-of-the-art methods on a manually labeled test dataset.</p><p>6 0.44749048 <a title="161-lsi-6" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>7 0.44676915 <a title="161-lsi-7" href="./emnlp-2013-Animacy_Detection_with_Voting_Models.html">23 emnlp-2013-Animacy Detection with Voting Models</a></p>
<p>8 0.42800227 <a title="161-lsi-8" href="./emnlp-2013-Unsupervised_Spectral_Learning_of_WCFG_as_Low-rank_Matrix_Completion.html">195 emnlp-2013-Unsupervised Spectral Learning of WCFG as Low-rank Matrix Completion</a></p>
<p>9 0.41702574 <a title="161-lsi-9" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>10 0.4161717 <a title="161-lsi-10" href="./emnlp-2013-Open-Domain_Fine-Grained_Class_Extraction_from_Web_Search_Queries.html">142 emnlp-2013-Open-Domain Fine-Grained Class Extraction from Web Search Queries</a></p>
<p>11 0.41593707 <a title="161-lsi-11" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>12 0.41398162 <a title="161-lsi-12" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>13 0.41345352 <a title="161-lsi-13" href="./emnlp-2013-Feature_Noising_for_Log-Linear_Structured_Prediction.html">86 emnlp-2013-Feature Noising for Log-Linear Structured Prediction</a></p>
<p>14 0.41250154 <a title="161-lsi-14" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>15 0.40955439 <a title="161-lsi-15" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>16 0.39885041 <a title="161-lsi-16" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>17 0.39630061 <a title="161-lsi-17" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>18 0.3892028 <a title="161-lsi-18" href="./emnlp-2013-A_Multi-Teraflop_Constituency_Parser_using_GPUs.html">10 emnlp-2013-A Multi-Teraflop Constituency Parser using GPUs</a></p>
<p>19 0.38791355 <a title="161-lsi-19" href="./emnlp-2013-What_is_Hidden_among_Translation_Rules.html">201 emnlp-2013-What is Hidden among Translation Rules</a></p>
<p>20 0.37253571 <a title="161-lsi-20" href="./emnlp-2013-Breaking_Out_of_Local_Optima_with_Count_Transforms_and_Model_Recombination%3A_A_Study_in_Grammar_Induction.html">40 emnlp-2013-Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.03), (18, 0.021), (22, 0.026), (30, 0.057), (50, 0.014), (51, 0.104), (66, 0.025), (71, 0.584), (75, 0.032), (77, 0.012), (96, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92349052 <a title="161-lda-1" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>Author: Laura Chiticariu ; Yunyao Li ; Frederick R. Reiss</p><p>Abstract: The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape ofIE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.</p><p>2 0.73975521 <a title="161-lda-2" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>Author: Qi Zhang ; Jin Qian ; Huan Chen ; Jihua Kang ; Xuanjing Huang</p><p>Abstract: Explanatory sentences are employed to clarify reasons, details, facts, and so on. High quality online product reviews usually include not only positive or negative opinions, but also a variety of explanations of why these opinions were given. These explanations can help readers get easily comprehensible information of the discussed products and aspects. Moreover, explanatory relations can also benefit sentiment analysis applications. In this work, we focus on the task of identifying subjective text segments and extracting their corresponding explanations from product reviews in discourse level. We propose a novel joint extraction method using firstorder logic to model rich linguistic features and long distance constraints. Experimental results demonstrate the effectiveness of the proposed method.</p><p>3 0.6873551 <a title="161-lda-3" href="./emnlp-2013-Paraphrasing_4_Microblog_Normalization.html">151 emnlp-2013-Paraphrasing 4 Microblog Normalization</a></p>
<p>Author: Wang Ling ; Chris Dyer ; Alan W Black ; Isabel Trancoso</p><p>Abstract: Compared to the edited genres that have played a central role in NLP research, microblog texts use a more informal register with nonstandard lexical items, abbreviations, and free orthographic variation. When confronted with such input, conventional text analysis tools often perform poorly. Normalization replacing orthographically or lexically idiosyncratic forms with more standard variants can improve performance. We propose a method for learning normalization rules from machine translations of a parallel corpus of microblog messages. To validate the utility of our approach, we evaluate extrinsically, showing that normalizing English tweets and then translating improves translation quality (compared to translating unnormalized text) using three standard web translation services as well as a phrase-based translation system trained — — on parallel microblog data.</p><p>4 0.62861776 <a title="161-lda-4" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>Author: Gyorgy Szarvas ; Robert Busa-Fekete ; Eyke Hullermeier</p><p>Abstract: The problem to replace a word with a synonym that fits well in its sentential context is known as the lexical substitution task. In this paper, we tackle this task as a supervised ranking problem. Given a dataset of target words, their sentential contexts and the potential substitutions for the target words, the goal is to train a model that accurately ranks the candidate substitutions based on their contextual fitness. As a key contribution, we customize and evaluate several learning-to-rank models to the lexical substitution task, including classification-based and regression-based approaches. On two datasets widely used for lexical substitution, our best models signifi- cantly advance the state-of-the-art.</p><p>5 0.41062766 <a title="161-lda-5" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>Author: Jinpeng Wang ; Wayne Xin Zhao ; Haitian Wei ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Hot trends are likely to bring new business opportunities. For example, “Air Pollution” might lead to a significant increase of the sales of related products, e.g., mouth mask. For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. In this paper, we take the initiative to study the task of how to identify trend related products. The major novelty of our work is that we automatically learn commercial intents revealed from microblogs. We carefully construct a data collection for this task and present quite a few insightful findings. In order to solve this problem, we further propose a graph based method, which jointly models relevance and associativity. We perform extensive experiments and the results showed that our methods are very effective.</p><p>6 0.38625461 <a title="161-lda-6" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>7 0.36525357 <a title="161-lda-7" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>8 0.35805935 <a title="161-lda-8" href="./emnlp-2013-Where_Not_to_Eat%3F_Improving_Public_Policy_by_Predicting_Hygiene_Inspections_Using_Online_Reviews.html">202 emnlp-2013-Where Not to Eat? Improving Public Policy by Predicting Hygiene Inspections Using Online Reviews</a></p>
<p>9 0.35595268 <a title="161-lda-9" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>10 0.33465895 <a title="161-lda-10" href="./emnlp-2013-Using_Crowdsourcing_to_get_Representations_based_on_Regular_Expressions.html">196 emnlp-2013-Using Crowdsourcing to get Representations based on Regular Expressions</a></p>
<p>11 0.33139589 <a title="161-lda-11" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>12 0.32797682 <a title="161-lda-12" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<p>13 0.32282224 <a title="161-lda-13" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>14 0.32136193 <a title="161-lda-14" href="./emnlp-2013-Identifying_Manipulated_Offerings_on_Review_Portals.html">94 emnlp-2013-Identifying Manipulated Offerings on Review Portals</a></p>
<p>15 0.32046121 <a title="161-lda-15" href="./emnlp-2013-A_Convex_Alternative_to_IBM_Model_2.html">2 emnlp-2013-A Convex Alternative to IBM Model 2</a></p>
<p>16 0.3187032 <a title="161-lda-16" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>17 0.31840864 <a title="161-lda-17" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>18 0.31476378 <a title="161-lda-18" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>19 0.31476173 <a title="161-lda-19" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>20 0.31458125 <a title="161-lda-20" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
