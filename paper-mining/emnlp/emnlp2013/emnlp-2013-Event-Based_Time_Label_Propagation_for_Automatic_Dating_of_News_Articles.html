<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>74 emnlp-2013-Event-Based Time Label Propagation for Automatic Dating of News Articles</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-74" href="#">emnlp2013-74</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>74 emnlp-2013-Event-Based Time Label Propagation for Automatic Dating of News Articles</h1>
<br/><p>Source: <a title="emnlp-2013-74-pdf" href="http://aclweb.org/anthology//D/D13/D13-1001.pdf">pdf</a></p><p>Author: Tao Ge ; Baobao Chang ; Sujian Li ; Zhifang Sui</p><p>Abstract: Since many applications such as timeline summaries and temporal IR involving temporal analysis rely on document timestamps, the task of automatic dating of documents has been increasingly important. Instead of using feature-based methods as conventional models, our method attempts to date documents in a year level by exploiting relative temporal relations between documents and events, which are very effective for dating documents. Based on this intuition, we proposed an eventbased time label propagation model called confidence boosting in which time label information can be propagated between documents and events on a bipartite graph. The experiments show that our event-based propagation model can predict document timestamps in high accuracy and the model combined with a MaxEnt classifier outperforms the state-ofthe-art method for this task especially when the size of the training set is small.</p><p>Reference: <a title="emnlp-2013-74-reference" href="../emnlp2013_reference/emnlp-2013-Event-Based_Time_Label_Propagation_for_Automatic_Dating_of_News_Articles_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn i  ,  ,  ,  Abstract Since many applications such as timeline summaries and temporal IR involving temporal analysis rely on document timestamps, the task of automatic dating of documents has been increasingly important. [sent-6, score-1.169]
</p><p>2 Instead of using feature-based methods as conventional models, our method attempts to date documents in a year level by exploiting relative temporal relations between documents and events, which are very effective for dating documents. [sent-7, score-1.047]
</p><p>3 Based on this intuition, we proposed an eventbased time label propagation model called confidence boosting in which time label information can be propagated between documents and events on a bipartite graph. [sent-8, score-1.492]
</p><p>4 The experiments show that our event-based propagation model can predict document timestamps in high accuracy and the model combined with a MaxEnt classifier outperforms the state-ofthe-art method for this task especially when  the size of the training set is small. [sent-9, score-0.735]
</p><p>5 In the applications involving temporal analysis, document timestamps are very useful. [sent-11, score-0.671]
</p><p>6 One typical method for dating document is based on temporal language models, which were first used for dating by de Jong et al. [sent-20, score-0.833]
</p><p>7 In Chambers’s work, discriminative classifiers maximum entropy (MaxEnt) classifiers were used by incorporating linguistic features and temporal constraints for training, which outperforms the previous temporal language models on a subset of Gigaword Corpus (Graff et al. [sent-24, score-0.649]
</p><p>8 Unlike the previous methods, this paper exploits relative temporal relations between events and documents for dating documents on the basis of an understanding of document content. [sent-33, score-1.187]
</p><p>9 It is known that each event in a news article has a relative temporal relation with the document. [sent-34, score-0.659]
</p><p>10 In the example, “last year” is an important cue to infer that the event mentioned by the documents occurred in 2002 if we know the timestamp of D1 is 2003. [sent-36, score-0.653]
</p><p>11 In this way, the timestamp of the labeled document (D1) is propagated to the unlabeled document (D2) through the event both of them mention, which is the main intuition of this paper. [sent-38, score-0.837]
</p><p>12 Therefore, if one knows a document timestamp, time of events  the document mentions can be obtained by analyzing the relative temporal relations between the document and the events. [sent-43, score-0.909]
</p><p>13 2 Based on the intuition, we proposed an eventbased time label propagation model called confidence boosting in which timestamps are propagated according to relative temporal relations between documents and events. [sent-45, score-1.783]
</p><p>14 To our knowledge, it is the first time that the relative temporal relations between documents and events are exploited for dating documents, which is proved to be effective by the experimental results. [sent-47, score-0.948]
</p><p>15 2  Event-based Time Label Propogation  As mentioned above, the relative temporal relations between documents and events are useful for dating documents. [sent-48, score-0.948]
</p><p>16 By analyzing the temporal relations, even if there are only a small number of documents  labeled with timestamps, this information can be propagated to documents connected with them on a bipartite graph using breadth first traversal (BFS). [sent-49, score-1.051]
</p><p>17 A document node is a single document while an event node represents an event. [sent-51, score-0.677]
</p><p>18 The edge between a document node and an event node means that the document mentions the event. [sent-52, score-0.677]
</p><p>19 The label propagation from node ito node j will occur if BFS condition which is defined as follows is s? [sent-54, score-0.669]
</p><p>20 the event nodes it mentions according to the relative temporal relations. [sent-61, score-0.664]
</p><p>21 Then, these event nodes propagate their timestamps to other documents which mention them. [sent-62, score-0.735]
</p><p>22 By repeating this process, the timestamp of the document can be propagated to documents which are reachable from the initially labeled document on the bipartite graph. [sent-63, score-1.035]
</p><p>23 Although the BFS-based propagation process can propagate timestamps from few labeled documents to a large number of unlabeled ones, it has two shortcomings for this task. [sent-64, score-0.835]
</p><p>24 If such an error occurred at the beginning of the propagation  process, it would lead to propagation of errors. [sent-66, score-0.675]
</p><p>25 Figure 2: Conflict of predictions during propagation To address the problems of the BFS-based method, we proposed a novel propagation model called confidence boosting model which improves the BFS-based model by optimizing the global confidence of the bipartite graph. [sent-68, score-1.544]
</p><p>26 In the confidence boosting model, every node in the bipartite graph has a confidence which measures the credibility of the predicted timestamp of the node. [sent-69, score-1.375]
</p><p>27 When the timestamp of a node is propagated to other nodes, its confidence will be also propagated to the target nodes with some loss. [sent-70, score-0.945]
</p><p>28 Formally, the confidence decay process is described as follows: c(j) = c(i) σ(i, j) where c(i) decn(ojt)es = cc (oni)fi ×de σnc(ei, o)f node i and σ(i, j) is the decay factor from node i to node j. [sent-72, score-0.783]
</p><p>29 For guaranteeing that timestamps can be propagated on the bipartite graph cred3 ibly, we define the following condition which is cal? [sent-73, score-0.647]
</p><p>30 conc(fiid)e ×nc σe (bio,ojs)ti >ng c (mj)odel, propagation from node ito node j will occur only if CB condition is satisfied. [sent-76, score-0.648]
</p><p>31 When timestamps are propagated on the bipartite graph, timestamps and confidence of nodes will be updated dynamically. [sent-77, score-1.116]
</p><p>32 A node with high confidence is more active than nodes with low confidence to propagate its timestamp because a node with high confidence is more likely to satisfy the CB condition for propagating its timestamp. [sent-78, score-1.433]
</p><p>33 Therefore, the  confidence boosting model can address both propagation of errors and conflict of predictions which cannot be tackled by the BFS-based model. [sent-80, score-0.777]
</p><p>34 First, the relative temporal relations between documents and events are usually unavailable. [sent-82, score-0.716]
</p><p>35 Therefore, each event is connected with only one document in the bipartite graph and thus cannot propagate its timestamp to other documents unless we perform event coreference resolution. [sent-84, score-1.29]
</p><p>36 Third, propagations from generic events are very likely to lead to propagation errors because generic events can happen in any year. [sent-85, score-0.824]
</p><p>37 Also, how to set the confidence and decay factors reasonably in practice for a confidence boosting model is worthy of investigation. [sent-86, score-0.742]
</p><p>38 We first discuss the event extraction and processing involving relative temporal relation mining, event coreference resolution and distinguishing specific extractions from generic ones in Section 3. [sent-89, score-1.542]
</p><p>39 However, extractions extracted by ReVerb cannot be used directly for our propagation models for three main reasons. [sent-100, score-0.685]
</p><p>40 First, the relative temporal relations between documents and the extractions are unavailable. [sent-101, score-0.954]
</p><p>41 For addressing the three challenges for the propagation models, we first presented a rule-based method for mining the relative temporal relations between extractions and documents in Section 3. [sent-104, score-1.281]
</p><p>42 1 Relative temporal relation mining We used a rule-based method to extract temporal expressions and used Stanford parser (De Marneffe et al. [sent-115, score-0.653]
</p><p>43 Specifically, we define that an extraction is associated with a temporal expression if there is an arc from the predicate of the extraction to the temporal expression in the dependency tree. [sent-117, score-0.79]
</p><p>44 Case 2: The extraction is associated with a relative temporal expression (not involving year) in the sen4  Table 1: Instances of various temporal expressions  tence. [sent-121, score-0.81]
</p><p>45 In this case, the time of the extraction is equal to the creation time of the document: Y (ex) = Y (d) Case 3: The extraction is associated with a relative temporal expression (involving specific year gap) in the sentence. [sent-122, score-0.711]
</p><p>46 Therefore, we heuristically consider the year of the extraction is the same with that of its source document in this case:  ±  Y (ex) = Y (d) In the cases except case 1, the relative temporal relation between an extraction and the document it comes from can be determined. [sent-128, score-0.807]
</p><p>47 To evaluate the performance of the rule-based method, we sampled 3,000 extractions from documents written in the year of 1995-1999 of Gigaword corpus and manually labeled these extractions with a timestamp based on their context and their corresponding document timestamps as golden standard. [sent-129, score-1.556]
</p><p>48 } where Ck is the set of extractions in case k and doc(ex) is the document which extraction ex comes from. [sent-139, score-0.619]
</p><p>49 For finding such coreferential event extractions efficiently, hierarchical agglomerative clustering (HAC) is used to cluster highly similar extractions into one cluster. [sent-146, score-1.02]
</p><p>50 Note that it is less meaningful to cluster the extractions from the same document because coreferential extractions from the same document are not helpful for  timestamp propagations. [sent-148, score-1.267]
</p><p>51 In practice, it is difficult for us to directly evaluate the performance of the coreference resolution of event extractions without golden standard which requires much labors for manual annotations. [sent-154, score-0.671]
</p><p>52 Note that timestamp of an extraction is assigned based on its document timestamp using the method proposed in Section 3. [sent-156, score-0.642]
</p><p>53 3  Distinguishing specific events from generic ones Not all extractions extracted by ReVerb refer to a specific event. [sent-167, score-0.648]
</p><p>54 In other words, it is not able to indicate a certain timestamp and thus propagations from a generic event node are very likely to result in propagation errors. [sent-170, score-1.068]
</p><p>55 For our task, such specific event extractions which are associated with one certain timestamp are desirable. [sent-172, score-0.836]
</p><p>56 For the sake of distinguishing such extractions from the generic ones, a MaxEnt classifier is used to classify extractions as either specific ones or generic ones. [sent-173, score-0.997]
</p><p>57 2 for event coreference resolution on extractions from all documents written in May and June of 1995-1999 and then analyzed each cluster. [sent-177, score-0.828]
</p><p>58 If extractions in a cluster have different timestamps, then the extractions in this cluster will be labeled as generic extractions (negative); otherwise, extractions in the cluster are labeled as specific ones (positive). [sent-178, score-1.796]
</p><p>59 2 Confidence boosting After extracting and processing the event extractions, relative temporal relations between documents and events can be constructed. [sent-196, score-1.084]
</p><p>60 Slightly different with the event node mentioned in Section 2, an event node in practice is a cluster of coreferential extractions and it can be connected with multiple document nodes. [sent-199, score-1.257]
</p><p>61 According to the definition, we set the confidence of initially labeled nodes to 1 and set confidence of nodes without any timestamp to 0 in practice. [sent-208, score-0.971]
</p><p>62 When the timestamp of a node is propagated to another node, its confidence will be propagated to the target node with some loss, as discussed in Section 2. [sent-209, score-1.035]
</p><p>63 The first one is the credibility of the relative temporal relation between two nodes and the other one depends on whether an extraction refers to a specific event. [sent-211, score-0.668]
</p><p>64 Relative temporal relations between documents and extractions we mined using the rule-based method in Section 3. [sent-212, score-0.874]
</p><p>65 Formally, we used π(i, j) to de-  note the credibility of the relative temporal relation between node iand node j. [sent-216, score-0.772]
</p><p>66 If the credibility of the relative temporal relation between i and j is low, propagation from node ito j probably leads to error. [sent-218, score-0.979]
</p><p>67 In addition, whether an extraction refers to a generic event or a specific one exerts an impact on the confidence loss. [sent-222, score-0.671]
</p><p>68 Since our propagation model assumes that extractions in a cluster are coreferent and thus they should have the same timestamp, propagations from a generic event node are very likely to result in propagation errors. [sent-224, score-1.558]
</p><p>69 Therefore, the timestamp of a generic event node in fact is less credible for propagations and confidence of such event nodes should be low for limiting propagations from the nodes. [sent-225, score-1.391]
</p><p>70 For this reason, propagation from a document node to a generic event  ×  node leads to much loss of confidence. [sent-226, score-1.012]
</p><p>71 2 Confidence boosting algorithm In confidence boosting model, the propagation from ito j will occur only if the CB condition is 7  Figure 4: Algorithm of confidence boosting satisfied. [sent-235, score-1.395]
</p><p>72 The confidence boosting propagation process can be described as figure 4. [sent-236, score-0.769]
</p><p>73 Whenever timestamps are propagated to other nodes, the global confidence of the bipartite graph will increase. [sent-237, score-0.869]
</p><p>74 In this model, a node with high confidence is more active than nodes with low confidence to propagate its timestamp. [sent-239, score-0.767]
</p><p>75 Therefore, the confidence boosting model can alleviate the problem of propagation of errors to some extent and handle conflict of predictions. [sent-241, score-0.777]
</p><p>76 3  Proof of the optimality of confidence boosting Proof by contradiction can be used to prove that propagation orders do not affect the optimality of the confidence boosting model. [sent-248, score-1.167]
</p><p>77 Proof Assume by contradiction that there is some node that does not reach its highest confidence it can reach when a confidence boosting process in propagation order A ends: ∃vt s. [sent-249, score-1.222]
</p><p>78 cA(vt) < c∗ (vt) where cA(vt) is the confidence of vt when the propagation process in order A ends and c∗ (vt) is the highest confidence that vt can reach. [sent-251, score-1.335]
</p><p>79 Assume that (v1, v2, · · · , vt−1 , vt) is the optimal propagation path from the propagation source node v1 to the node vt that leads to the highest confidence of vt, which means that c∗ (vt) = c∗ (vt−1) σ(vt−1 , vt),  ××  c∗ (vt−1 ) = c∗ (vt−2) σ(vt−2 , vt−1), . [sent-252, score-1.38]
</p><p>80 Since v1 is the source node whose timestamp is initially labeled and its confidence is 1, the inequality cA(v1) < c∗ (v1) cannot hold. [sent-258, score-0.712]
</p><p>81 Therefore, it can be proved that each node on the bipartite graph must reach the highest confidence it can reach so that the global confidence of the bipartite graph must be optimal when confidence boosting propagation process ends no matter what order time labels are propagated in. [sent-260, score-2.179]
</p><p>82 4  Experiments  In this section, we evaluate the performance of our time label propagation models and different automatic document dating models on the Gigaword dataset. [sent-261, score-0.688]
</p><p>83 Pre-processing Many extractions extracted by ReVerb are short and uninformative and do not carry any valuable information for propagating temporal information. [sent-267, score-0.671]
</p><p>84 These extractions may affect the performance of event coreference resolution and the rule-based method proposed in Section 3. [sent-269, score-0.671]
</p><p>85 Evaluation To evaluate the performance of the propagation models for the task of dating on different sizes of the training set, we used different sizes of the labeled documents for training and considered the remaining documents as the test set. [sent-277, score-0.891]
</p><p>86 For the MaxEnt classifier, unigrams and named entities are simply selected as features and the initially labeled documents as well as documents labeled during propagation process are used for training. [sent-282, score-0.792]
</p><p>87 When only 1,000 documents are initially labeled with timestamps, the confidence boosting model can propagate their timestamps to more than 400,000 documents with an accuracy of 9  0. [sent-354, score-1.127]
</p><p>88 However, as shown in table 5, hardly can the propagation process propagate timestamps to all documents. [sent-357, score-0.634]
</p><p>89 Also, the event coreference resolution phase does not guarantee finding all coreferential extractions; in other words, recall of event coreference resolution is not 100%. [sent-361, score-0.676]
</p><p>90 Compared with the previous models, the propagation models predict the document timestamps much  more accurately especially in the case where the size of the training set is small. [sent-370, score-0.688]
</p><p>91 When the size of the training set is 1,000, our BFS-based model and confidence boosting model combined with the MaxEnt classifier outperform Chambers’s joint model which is considered the state-of-the-art model for the task of automatic dating of documents by 38. [sent-371, score-0.807]
</p><p>92 In contrast, our propagation models can predict timestamps of documents with an understanding of document content, which allows our method to date documents more credibly than the baseline methods. [sent-375, score-1.052]
</p><p>93 Also, by comparing table 5 with table 6, it can be found that prop accuracy is almost always higher than overall accuracy, which also verifies that the propagation models are more credible for dating document than the feature-based models. [sent-376, score-0.844]
</p><p>94 Therefore, even if a small number of documents are labeled, the labeled information can be propagated to large numbers of articles through the connections  between documents and events according to relative time relations. [sent-378, score-0.712]
</p><p>95 Additionally, some event nodes on the bipartite graph may be labeled with a timestamp during the process of propagation as a byproduct. [sent-382, score-1.156]
</p><p>96 The temporal information of the events would be useful for other temporal analysis tasks. [sent-383, score-0.746]
</p><p>97 Kanhabua and Norvag (2009) improved temporal language models by incorporating 10 temporal entropy and search statistics and applying two filtering techniques to the unigrams in the model. [sent-386, score-0.649]
</p><p>98 Compared with these methods, our event-based propagation models exploit relative temporal relations between documents and events for dating document on a basis of an understanding of document content, which is more reasonable and also proved to be more effective by the experimental results. [sent-393, score-1.465]
</p><p>99 6  Conclusion  The main contribution of this paper is exploiting relative temporal relations between events and documents for the document dating task. [sent-394, score-1.03]
</p><p>100 The experimental results show that our event-based propagation model can predict document timestamps in high accuracy and the model combined with a MaxEnt classifier outperforms the state-of-the-art method on a dataredundant dataset. [sent-397, score-0.735]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('extractions', 0.358), ('propagation', 0.327), ('temporal', 0.313), ('confidence', 0.261), ('timestamp', 0.24), ('timestamps', 0.228), ('vt', 0.213), ('bipartite', 0.209), ('event', 0.209), ('dating', 0.206), ('boosting', 0.159), ('documents', 0.157), ('prop', 0.137), ('propagated', 0.128), ('node', 0.126), ('events', 0.12), ('document', 0.108), ('ex', 0.099), ('maxent', 0.099), ('generic', 0.091), ('relative', 0.08), ('credibility', 0.076), ('bfs', 0.075), ('propagations', 0.075), ('chambers', 0.067), ('cb', 0.066), ('year', 0.063), ('nodes', 0.062), ('decay', 0.061), ('coreference', 0.058), ('propagate', 0.057), ('extraction', 0.054), ('timeline', 0.05), ('coreferential', 0.05), ('jong', 0.05), ('resolution', 0.046), ('relations', 0.046), ('cluster', 0.045), ('labeled', 0.044), ('credible', 0.043), ('graph', 0.043), ('initially', 0.041), ('reverb', 0.04), ('condition', 0.039), ('creation', 0.038), ('ends', 0.038), ('dnode', 0.037), ('enode', 0.037), ('eventbased', 0.037), ('labeleddocnodes', 0.037), ('purity', 0.037), ('nathanael', 0.035), ('ca', 0.034), ('reach', 0.033), ('hac', 0.033), ('conflict', 0.03), ('ito', 0.03), ('news', 0.03), ('specific', 0.029), ('ratio', 0.029), ('gigaword', 0.029), ('reached', 0.028), ('expression', 0.028), ('relation', 0.027), ('refers', 0.027), ('time', 0.026), ('discussed', 0.026), ('mentioned', 0.026), ('threshold', 0.026), ('predict', 0.025), ('distinguishing', 0.025), ('credibly', 0.025), ('eritrea', 0.025), ('kalczynski', 0.025), ('kanhabua', 0.025), ('offensive', 0.025), ('reacheddocnodes', 0.025), ('spo', 0.025), ('timeliness', 0.025), ('loss', 0.025), ('undesirable', 0.025), ('date', 0.025), ('classifier', 0.024), ('iand', 0.024), ('accuracy', 0.023), ('entropy', 0.023), ('proof', 0.022), ('mention', 0.022), ('involving', 0.022), ('lof', 0.022), ('accident', 0.022), ('rebels', 0.022), ('accused', 0.022), ('died', 0.022), ('eastern', 0.022), ('process', 0.022), ('ones', 0.021), ('label', 0.021), ('occurred', 0.021), ('binh', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="74-tfidf-1" href="./emnlp-2013-Event-Based_Time_Label_Propagation_for_Automatic_Dating_of_News_Articles.html">74 emnlp-2013-Event-Based Time Label Propagation for Automatic Dating of News Articles</a></p>
<p>Author: Tao Ge ; Baobao Chang ; Sujian Li ; Zhifang Sui</p><p>Abstract: Since many applications such as timeline summaries and temporal IR involving temporal analysis rely on document timestamps, the task of automatic dating of documents has been increasingly important. Instead of using feature-based methods as conventional models, our method attempts to date documents in a year level by exploiting relative temporal relations between documents and events, which are very effective for dating documents. Based on this intuition, we proposed an eventbased time label propagation model called confidence boosting in which time label information can be propagated between documents and events on a bipartite graph. The experiments show that our event-based propagation model can predict document timestamps in high accuracy and the model combined with a MaxEnt classifier outperforms the state-ofthe-art method for this task especially when the size of the training set is small.</p><p>2 0.23420407 <a title="74-tfidf-2" href="./emnlp-2013-Building_Event_Threads_out_of_Multiple_News_Articles.html">41 emnlp-2013-Building Event Threads out of Multiple News Articles</a></p>
<p>Author: Xavier Tannier ; Veronique Moriceau</p><p>Abstract: We present an approach for building multidocument event threads from a large corpus of newswire articles. An event thread is basically a succession of events belonging to the same story. It helps the reader to contextualize the information contained in a single article, by navigating backward or forward in the thread from this article. A specific effort is also made on the detection of reactions to a particular event. In order to build these event threads, we use a cascade of classifiers and other modules, taking advantage of the redundancy of information in the newswire corpus. We also share interesting comments concerning our manual annotation procedure for building a training and testing set1.</p><p>3 0.22386843 <a title="74-tfidf-3" href="./emnlp-2013-Learning_Biological_Processes_with_Global_Constraints.html">118 emnlp-2013-Learning Biological Processes with Global Constraints</a></p>
<p>Author: Aju Thalappillil Scaria ; Jonathan Berant ; Mengqiu Wang ; Peter Clark ; Justin Lewis ; Brittany Harding ; Christopher D. Manning</p><p>Abstract: Biological processes are complex phenomena involving a series of events that are related to one another through various relationships. Systems that can understand and reason over biological processes would dramatically improve the performance of semantic applications involving inference such as question answering (QA) – specifically “How? ” and “Why? ” questions. In this paper, we present the task of process extraction, in which events within a process and the relations between the events are automatically extracted from text. We represent processes by graphs whose edges describe a set oftemporal, causal and co-reference event-event relations, and characterize the structural properties of these graphs (e.g., the graphs are connected). Then, we present a method for extracting relations between the events, which exploits these structural properties by performing joint in- ference over the set of extracted relations. On a novel dataset containing 148 descriptions of biological processes (released with this paper), we show significant improvement comparing to baselines that disregard process structure.</p><p>4 0.2130478 <a title="74-tfidf-4" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>Author: Jun-Ping Ng ; Min-Yen Kan ; Ziheng Lin ; Wei Feng ; Bin Chen ; Jian Su ; Chew Lim Tan</p><p>Abstract: In this paper we classify the temporal relations between pairs of events on an article-wide basis. This is in contrast to much of the existing literature which focuses on just event pairs which are found within the same or adjacent sentences. To achieve this, we leverage on discourse analysis as we believe that it provides more useful semantic information than typical lexico-syntactic features. We propose the use of several discourse analysis frameworks, including 1) Rhetorical Structure Theory (RST), 2) PDTB-styled discourse relations, and 3) topical text segmentation. We explain how features derived from these frameworks can be effectively used with support vector machines (SVM) paired with convolution kernels. Experiments show that our proposal is effective in improving on the state-of-the-art significantly by as much as 16% in terms of F1, even if we only adopt less-than-perfect automatic discourse analyzers and parsers. Making use of more accurate discourse analysis can further boost gains to 35%.</p><p>5 0.17636541 <a title="74-tfidf-5" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>6 0.15324578 <a title="74-tfidf-6" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>7 0.14261234 <a title="74-tfidf-7" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>8 0.12789656 <a title="74-tfidf-8" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>9 0.10346665 <a title="74-tfidf-9" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>10 0.10023175 <a title="74-tfidf-10" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>11 0.088927314 <a title="74-tfidf-11" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>12 0.07344944 <a title="74-tfidf-12" href="./emnlp-2013-Easy_Victories_and_Uphill_Battles_in_Coreference_Resolution.html">67 emnlp-2013-Easy Victories and Uphill Battles in Coreference Resolution</a></p>
<p>13 0.070605405 <a title="74-tfidf-13" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>14 0.067457937 <a title="74-tfidf-14" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>15 0.063780196 <a title="74-tfidf-15" href="./emnlp-2013-Generating_Coherent_Event_Schemas_at_Scale.html">90 emnlp-2013-Generating Coherent Event Schemas at Scale</a></p>
<p>16 0.061536204 <a title="74-tfidf-16" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>17 0.06092995 <a title="74-tfidf-17" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>18 0.060494516 <a title="74-tfidf-18" href="./emnlp-2013-Orthonormal_Explicit_Topic_Analysis_for_Cross-Lingual_Document_Matching.html">148 emnlp-2013-Orthonormal Explicit Topic Analysis for Cross-Lingual Document Matching</a></p>
<p>19 0.060490258 <a title="74-tfidf-19" href="./emnlp-2013-Learning_Latent_Word_Representations_for_Domain_Adaptation_using_Supervised_Word_Clustering.html">120 emnlp-2013-Learning Latent Word Representations for Domain Adaptation using Supervised Word Clustering</a></p>
<p>20 0.059683062 <a title="74-tfidf-20" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.196), (1, 0.195), (2, -0.014), (3, 0.266), (4, 0.056), (5, -0.212), (6, -0.143), (7, 0.023), (8, -0.124), (9, -0.003), (10, 0.063), (11, 0.023), (12, 0.01), (13, -0.035), (14, 0.02), (15, -0.028), (16, -0.104), (17, 0.042), (18, -0.058), (19, 0.056), (20, 0.01), (21, -0.177), (22, -0.044), (23, -0.019), (24, 0.047), (25, 0.038), (26, 0.056), (27, -0.017), (28, 0.037), (29, 0.066), (30, 0.06), (31, -0.046), (32, -0.069), (33, 0.033), (34, 0.027), (35, 0.06), (36, 0.035), (37, 0.044), (38, -0.003), (39, -0.001), (40, 0.022), (41, -0.016), (42, 0.015), (43, 0.075), (44, 0.041), (45, 0.026), (46, 0.104), (47, 0.008), (48, -0.037), (49, 0.115)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97468716 <a title="74-lsi-1" href="./emnlp-2013-Event-Based_Time_Label_Propagation_for_Automatic_Dating_of_News_Articles.html">74 emnlp-2013-Event-Based Time Label Propagation for Automatic Dating of News Articles</a></p>
<p>Author: Tao Ge ; Baobao Chang ; Sujian Li ; Zhifang Sui</p><p>Abstract: Since many applications such as timeline summaries and temporal IR involving temporal analysis rely on document timestamps, the task of automatic dating of documents has been increasingly important. Instead of using feature-based methods as conventional models, our method attempts to date documents in a year level by exploiting relative temporal relations between documents and events, which are very effective for dating documents. Based on this intuition, we proposed an eventbased time label propagation model called confidence boosting in which time label information can be propagated between documents and events on a bipartite graph. The experiments show that our event-based propagation model can predict document timestamps in high accuracy and the model combined with a MaxEnt classifier outperforms the state-ofthe-art method for this task especially when the size of the training set is small.</p><p>2 0.85979426 <a title="74-lsi-2" href="./emnlp-2013-Building_Event_Threads_out_of_Multiple_News_Articles.html">41 emnlp-2013-Building Event Threads out of Multiple News Articles</a></p>
<p>Author: Xavier Tannier ; Veronique Moriceau</p><p>Abstract: We present an approach for building multidocument event threads from a large corpus of newswire articles. An event thread is basically a succession of events belonging to the same story. It helps the reader to contextualize the information contained in a single article, by navigating backward or forward in the thread from this article. A specific effort is also made on the detection of reactions to a particular event. In order to build these event threads, we use a cascade of classifiers and other modules, taking advantage of the redundancy of information in the newswire corpus. We also share interesting comments concerning our manual annotation procedure for building a training and testing set1.</p><p>3 0.80114192 <a title="74-lsi-3" href="./emnlp-2013-Learning_Biological_Processes_with_Global_Constraints.html">118 emnlp-2013-Learning Biological Processes with Global Constraints</a></p>
<p>Author: Aju Thalappillil Scaria ; Jonathan Berant ; Mengqiu Wang ; Peter Clark ; Justin Lewis ; Brittany Harding ; Christopher D. Manning</p><p>Abstract: Biological processes are complex phenomena involving a series of events that are related to one another through various relationships. Systems that can understand and reason over biological processes would dramatically improve the performance of semantic applications involving inference such as question answering (QA) – specifically “How? ” and “Why? ” questions. In this paper, we present the task of process extraction, in which events within a process and the relations between the events are automatically extracted from text. We represent processes by graphs whose edges describe a set oftemporal, causal and co-reference event-event relations, and characterize the structural properties of these graphs (e.g., the graphs are connected). Then, we present a method for extracting relations between the events, which exploits these structural properties by performing joint in- ference over the set of extracted relations. On a novel dataset containing 148 descriptions of biological processes (released with this paper), we show significant improvement comparing to baselines that disregard process structure.</p><p>4 0.7221998 <a title="74-lsi-4" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>Author: Jun-Ping Ng ; Min-Yen Kan ; Ziheng Lin ; Wei Feng ; Bin Chen ; Jian Su ; Chew Lim Tan</p><p>Abstract: In this paper we classify the temporal relations between pairs of events on an article-wide basis. This is in contrast to much of the existing literature which focuses on just event pairs which are found within the same or adjacent sentences. To achieve this, we leverage on discourse analysis as we believe that it provides more useful semantic information than typical lexico-syntactic features. We propose the use of several discourse analysis frameworks, including 1) Rhetorical Structure Theory (RST), 2) PDTB-styled discourse relations, and 3) topical text segmentation. We explain how features derived from these frameworks can be effectively used with support vector machines (SVM) paired with convolution kernels. Experiments show that our proposal is effective in improving on the state-of-the-art significantly by as much as 16% in terms of F1, even if we only adopt less-than-perfect automatic discourse analyzers and parsers. Making use of more accurate discourse analysis can further boost gains to 35%.</p><p>5 0.69513255 <a title="74-lsi-5" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>Author: Zhichao Hu ; Elahe Rahimtoroghi ; Larissa Munishkina ; Reid Swanson ; Marilyn A. Walker</p><p>Abstract: Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning. Researchers in NLP have tackled modeling such expectations from a range of perspectives, including treating it as the inference of the CONTINGENT discourse relation, or as a type of common-sense causal reasoning. Our approach is to model likelihood between events by drawing on several of these lines of previous work. We implement and evaluate different unsupervised methods for learning event pairs that are likely to be CONTINGENT on one another. We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments ofcontingency. Our results indicate that the use of web search counts increases the av- , erage accuracy of our best method to 85.64% over a baseline of 50%, as compared to an average accuracy of 75. 15% without web search.</p><p>6 0.60002387 <a title="74-lsi-6" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>7 0.55812365 <a title="74-lsi-7" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>8 0.51032305 <a title="74-lsi-8" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>9 0.39159068 <a title="74-lsi-9" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>10 0.31631652 <a title="74-lsi-10" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>11 0.31623617 <a title="74-lsi-11" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>12 0.30026343 <a title="74-lsi-12" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>13 0.28820342 <a title="74-lsi-13" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>14 0.27542236 <a title="74-lsi-14" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>15 0.26962015 <a title="74-lsi-15" href="./emnlp-2013-Orthonormal_Explicit_Topic_Analysis_for_Cross-Lingual_Document_Matching.html">148 emnlp-2013-Orthonormal Explicit Topic Analysis for Cross-Lingual Document Matching</a></p>
<p>16 0.26743269 <a title="74-lsi-16" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>17 0.26304391 <a title="74-lsi-17" href="./emnlp-2013-Automatically_Identifying_Pseudepigraphic_Texts.html">37 emnlp-2013-Automatically Identifying Pseudepigraphic Texts</a></p>
<p>18 0.24818006 <a title="74-lsi-18" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>19 0.2468784 <a title="74-lsi-19" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<p>20 0.24634407 <a title="74-lsi-20" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.022), (18, 0.02), (22, 0.567), (30, 0.042), (51, 0.124), (66, 0.019), (71, 0.02), (75, 0.045), (77, 0.011), (90, 0.01), (96, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9247703 <a title="74-lda-1" href="./emnlp-2013-Event-Based_Time_Label_Propagation_for_Automatic_Dating_of_News_Articles.html">74 emnlp-2013-Event-Based Time Label Propagation for Automatic Dating of News Articles</a></p>
<p>Author: Tao Ge ; Baobao Chang ; Sujian Li ; Zhifang Sui</p><p>Abstract: Since many applications such as timeline summaries and temporal IR involving temporal analysis rely on document timestamps, the task of automatic dating of documents has been increasingly important. Instead of using feature-based methods as conventional models, our method attempts to date documents in a year level by exploiting relative temporal relations between documents and events, which are very effective for dating documents. Based on this intuition, we proposed an eventbased time label propagation model called confidence boosting in which time label information can be propagated between documents and events on a bipartite graph. The experiments show that our event-based propagation model can predict document timestamps in high accuracy and the model combined with a MaxEnt classifier outperforms the state-ofthe-art method for this task especially when the size of the training set is small.</p><p>2 0.91056687 <a title="74-lda-2" href="./emnlp-2013-Appropriately_Incorporating_Statistical_Significance_in_PMI.html">25 emnlp-2013-Appropriately Incorporating Statistical Significance in PMI</a></p>
<p>Author: Om P. Damani ; Shweta Ghonge</p><p>Abstract: Two recent measures incorporate the notion of statistical significance in basic PMI formulation. In some tasks, we find that the new measures perform worse than the PMI. Our analysis shows that while the basic ideas in incorporating statistical significance in PMI are reasonable, they have been applied slightly inappropriately. By fixing this, we get new measures that improve performance over not just PMI but on other popular co-occurrence measures as well. In fact, the revised measures perform reasonably well compared with more resource intensive non co-occurrence based methods also.</p><p>3 0.86961287 <a title="74-lda-3" href="./emnlp-2013-Building_Event_Threads_out_of_Multiple_News_Articles.html">41 emnlp-2013-Building Event Threads out of Multiple News Articles</a></p>
<p>Author: Xavier Tannier ; Veronique Moriceau</p><p>Abstract: We present an approach for building multidocument event threads from a large corpus of newswire articles. An event thread is basically a succession of events belonging to the same story. It helps the reader to contextualize the information contained in a single article, by navigating backward or forward in the thread from this article. A specific effort is also made on the detection of reactions to a particular event. In order to build these event threads, we use a cascade of classifiers and other modules, taking advantage of the redundancy of information in the newswire corpus. We also share interesting comments concerning our manual annotation procedure for building a training and testing set1.</p><p>4 0.8563059 <a title="74-lda-4" href="./emnlp-2013-Multi-Domain_Adaptation_for_SMT_Using_Multi-Task_Learning.html">136 emnlp-2013-Multi-Domain Adaptation for SMT Using Multi-Task Learning</a></p>
<p>Author: Lei Cui ; Xilun Chen ; Dongdong Zhang ; Shujie Liu ; Mu Li ; Ming Zhou</p><p>Abstract: Domain adaptation for SMT usually adapts models to an individual specific domain. However, it often lacks some correlation among different domains where common knowledge could be shared to improve the overall translation quality. In this paper, we propose a novel multi-domain adaptation approach for SMT using Multi-Task Learning (MTL), with in-domain models tailored for each specific domain and a general-domain model shared by different domains. The parameters of these models are tuned jointly via MTL so that they can learn general knowledge more accurately and exploit domain knowledge better. Our experiments on a largescale English-to-Chinese translation task validate that the MTL-based adaptation approach significantly and consistently improves the translation quality compared to a non-adapted baseline. Furthermore, it also outperforms the individual adaptation of each specific domain.</p><p>5 0.60795563 <a title="74-lda-5" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>Author: Zhiyuan Chen ; Arjun Mukherjee ; Bing Liu ; Meichun Hsu ; Malu Castellanos ; Riddhiman Ghosh</p><p>Abstract: Aspect extraction is one of the key tasks in sentiment analysis. In recent years, statistical models have been used for the task. However, such models without any domain knowledge often produce aspects that are not interpretable in applications. To tackle the issue, some knowledge-based topic models have been proposed, which allow the user to input some prior domain knowledge to generate coherent aspects. However, existing knowledge-based topic models have several major shortcomings, e.g., little work has been done to incorporate the cannot-link type of knowledge or to automatically adjust the number of topics based on domain knowledge. This paper proposes a more advanced topic model, called MC-LDA (LDA with m-set and c-set), to address these problems, which is based on an Extended generalized Pólya urn (E-GPU) model (which is also proposed in this paper). Experiments on real-life product reviews from a variety of domains show that MCLDA outperforms the existing state-of-the-art models markedly.</p><p>6 0.6018557 <a title="74-lda-6" href="./emnlp-2013-Automatic_Domain_Partitioning_for_Multi-Domain_Learning.html">29 emnlp-2013-Automatic Domain Partitioning for Multi-Domain Learning</a></p>
<p>7 0.59826189 <a title="74-lda-7" href="./emnlp-2013-Learning_Biological_Processes_with_Global_Constraints.html">118 emnlp-2013-Learning Biological Processes with Global Constraints</a></p>
<p>8 0.53725249 <a title="74-lda-8" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>9 0.53584278 <a title="74-lda-9" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>10 0.52704805 <a title="74-lda-10" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>11 0.52442205 <a title="74-lda-11" href="./emnlp-2013-An_Empirical_Study_Of_Semi-Supervised_Chinese_Word_Segmentation_Using_Co-Training.html">21 emnlp-2013-An Empirical Study Of Semi-Supervised Chinese Word Segmentation Using Co-Training</a></p>
<p>12 0.52421266 <a title="74-lda-12" href="./emnlp-2013-Learning_Latent_Word_Representations_for_Domain_Adaptation_using_Supervised_Word_Clustering.html">120 emnlp-2013-Learning Latent Word Representations for Domain Adaptation using Supervised Word Clustering</a></p>
<p>13 0.51400357 <a title="74-lda-13" href="./emnlp-2013-Flexible_and_Efficient_Hypergraph_Interactions_for_Joint_Hierarchical_and_Forest-to-String_Decoding.html">88 emnlp-2013-Flexible and Efficient Hypergraph Interactions for Joint Hierarchical and Forest-to-String Decoding</a></p>
<p>14 0.50662392 <a title="74-lda-14" href="./emnlp-2013-Lexical_Chain_Based_Cohesion_Models_for_Document-Level_Statistical_Machine_Translation.html">125 emnlp-2013-Lexical Chain Based Cohesion Models for Document-Level Statistical Machine Translation</a></p>
<p>15 0.49901056 <a title="74-lda-15" href="./emnlp-2013-Translation_with_Source_Constituency_and_Dependency_Trees.html">187 emnlp-2013-Translation with Source Constituency and Dependency Trees</a></p>
<p>16 0.49571735 <a title="74-lda-16" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<p>17 0.49361259 <a title="74-lda-17" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>18 0.4924314 <a title="74-lda-18" href="./emnlp-2013-Generating_Coherent_Event_Schemas_at_Scale.html">90 emnlp-2013-Generating Coherent Event Schemas at Scale</a></p>
<p>19 0.49144667 <a title="74-lda-19" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>20 0.48514503 <a title="74-lda-20" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
