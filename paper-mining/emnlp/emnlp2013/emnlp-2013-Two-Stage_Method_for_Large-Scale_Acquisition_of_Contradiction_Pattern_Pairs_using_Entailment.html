<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-189" href="#">emnlp2013-189</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</h1>
<br/><p>Source: <a title="emnlp-2013-189-pdf" href="http://aclweb.org/anthology//D/D13/D13-1065.pdf">pdf</a></p><p>Author: Julien Kloetzer ; Stijn De Saeger ; Kentaro Torisawa ; Chikara Hashimoto ; Jong-Hoon Oh ; Motoki Sano ; Kiyonori Ohtake</p><p>Abstract: In this paper we propose a two-stage method to acquire contradiction relations between typed lexico-syntactic patterns such as Xdrug prevents Ydisease and Ydisease caused by Xdrug. In the first stage, we train an SVM classifier to detect contradiction pattern pairs in a large web archive by exploiting the excitation polarity (Hashimoto et al., 2012) of the patterns. In the second stage, we enlarge the first stage classifier’s training data with new contradiction pairs obtained by combining the output of the first stage’s classifier and that of an entailment classifier. We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%. We plan to release this resource to the NLP community. 1</p><p>Reference: <a title="emnlp-2013-189-reference" href="../emnlp2013_reference/emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp en j l  Abstract In this paper we propose a two-stage method to acquire contradiction relations between typed lexico-syntactic patterns such as Xdrug prevents Ydisease and Ydisease caused by Xdrug. [sent-4, score-0.845]
</p><p>2 In the first stage, we train an SVM classifier to detect contradiction pattern pairs in a large web archive by exploiting the excitation polarity (Hashimoto et al. [sent-5, score-1.132]
</p><p>3 In the second stage, we enlarge the first stage classifier’s training data with new contradiction pairs obtained by combining the output of the first stage’s classifier and that of an entailment classifier. [sent-7, score-1.027]
</p><p>4 We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%. [sent-8, score-0.986]
</p><p>5 (2009) pointed out that a contradiction recognition system can detect conflicts and anomalies in large bodies of texts and flag them to help users identify unreliable information. [sent-12, score-0.579]
</p><p>6 For example, many Japanese web pages claim that agaricus prevents cancer, where agaricus is a species of mushroom found in a variety of commercial products. [sent-13, score-0.291]
</p><p>7 Likewise, we believe that contradiction recognition is also useful when dealing with non-factual information that occupy most of our daily lives. [sent-21, score-0.579]
</p><p>8 To hso“Xlve w itlhle w problem ”d,e“sXcr wibieldl s above, we can easily develop a system that can find contradictory text fragments from the web like “agaricus promotes cancer” and “agaricus prevents cancer” from the discovered contradictory pattern pairs. [sent-34, score-0.507]
</p><p>9 In the first stage, we build a classifier BASE to recognize contradictions between binary patterns, and a classifier ENT to recognize entailment. [sent-37, score-0.496]
</p><p>10 In the second stage, we combine the contradiction pairs recognized by BASE and the entailment pairs recognized by ENT to expand BASE’s training data and train a new contradiction classifier, EXP. [sent-38, score-1.688]
</p><p>11 This expansion using entailment is one key idea of this work: we acquired 750,000 contradiction pairs with 80% precision using the expanded training data, more than doubling the 285,000 pairs acquired at the same precision level without expansion. [sent-39, score-1.42]
</p><p>12 (2012) previously showed that excitation polarities are useful to recognize contradictions between phrases that consist of a noun and a predicate, such as “promote cancer” and “prevent cancer”. [sent-45, score-0.615]
</p><p>13 As exemplified by the agaricus and TPP examples, contradictions between binary patterns that include two variables such as “X promotes Y” or “X will wipe out Y” are more useful than those between unary patterns. [sent-47, score-0.873]
</p><p>14 We also show that it is not trivial to recognize contradictions be-  tween binary patterns using contradictions between unary patterns. [sent-48, score-1.013]
</p><p>15 Most works dealing with contradiction recognition up till now (Harabagiu et al. [sent-49, score-0.579]
</p><p>16 , 2011) focus on recognizing contradictions between full sentences or documents, not text fragments that match our relatively short patterns (survey in Section 5). [sent-54, score-0.425]
</p><p>17 We expect that the contradictory pattern pairs we acquired can be used as building blocks in such full-fledged contradiction recognition for full sentences or documents, similarly to antonym pairs in Harabagiu et al. [sent-55, score-1.151]
</p><p>18 Also, we should emphasize that our method focuses on the most challenging part of contradiction recognition according to the classification of De Marneffe et al. [sent-57, score-0.579]
</p><p>19 Since we discard patterns with negations, an evident source of contradictions like h“X causes Y”, “X does not cause Y”i, mdicotsito osf our output are “nXon d-toreisvi nalo ccaounstrea Ydi”ci-, tions related to high-level semantic phenomena, e. [sent-59, score-0.489]
</p><p>20 Classifiers BASE and  EXP recognize contradiction relations between binary patterns, and ENT recognizes entailment relations between binary patterns. [sent-69, score-0.958]
</p><p>21 The contradiction pairs recognized by BASE and the entailment pairs recognized by ENT are combined to generate new contradiction pairs, part of which are then added to BASE training data to train the EXP classifier. [sent-70, score-1.65]
</p><p>22 Our final output is the set of all binary pattern pairs regarded as contradictions by EXP. [sent-71, score-0.636]
</p><p>23 Logically speaking, patterns p and r are contradictory if there exists a pattern q such that p entails q and q contradicts r. [sent-74, score-0.533]
</p><p>24 For example, since “X causes Y” entails “X promotes Y” and “X promotes Y” contradicts “X prevents Y”, then “X causes Y” contradicts “X prevents Y”. [sent-75, score-0.606]
</p><p>25 Hence, by combining entailment and contradiction pairs, we can obtain more contradiction pairs. [sent-76, score-1.386]
</p><p>26 Following this property of contradiction relations, we collect a set of pattern pairs {hp, ri} for which  695 there exists a pattern q such that ENT recognizes that p entails q and BASE recognizes that q contradicts r. [sent-77, score-1.215]
</p><p>27 Then we rank these pairs based on a novel scoring function called Contradiction Derivation Precision (CDP) and expand BASE training data by adding to it the top-ranked pairs according to CDP in order to train EXP. [sent-78, score-0.302]
</p><p>28 This ranking scheme selects highly accurate contradiction pairs and prevents errors caused by BASE and ENT from being propagated to EXP. [sent-79, score-0.776]
</p><p>29 In the following, after defining the patterns for which we acquire contradiction relations, we describe BASE, EXP, ENT, and our expansion scheme. [sent-80, score-0.797]
</p><p>30 Since typed patterns can distinguish between multiple senses of ambiguous patterns, they greatly reduce errors due to pattern ambiguity (De Saeger et al. [sent-87, score-0.303]
</p><p>31 The binary patterns and their co-occurring noun pairs were extracted from our corpus of 600 million Japanese web pages dependency parsed with KNP (Kurohashi and Nagao, 1994). [sent-92, score-0.358]
</p><p>32 Based on our observation that patterns in meaningful contradiction and entail-  ment pairs tend to share many co-occurring noun pairs, we used as input to our classifiers the set Pall of 792 million pattern pairs for which both patterns share three co-occurring noun pairs. [sent-95, score-1.32]
</p><p>33 An important point to be stressed here is that we restricted the pattern pairs to be classified by BASE by exploiting their excitation polarity, a semantic orientation proposed by Hashimoto et al. [sent-99, score-0.485]
</p><p>34 Excitation characterizes unary patterns as excitatory, inhibitory, or neutral. [sent-101, score-0.296]
</p><p>35 Neutral unary patterns like “close to X” are neither excitatory nor inhibitory. [sent-103, score-0.371]
</p><p>36 (2012) showing that two unary patterns with opposite polarity have a higher chance to be a contradiction, we extracted from set Pall the set Popp of binary pattern pairs that contain unary patterns with opposite excitation polarities as sub-patterns. [sent-106, score-1.201]
</p><p>37 696 h“Y cause X”, “Y prevent X”i is an example of such a pair usisenc Xe” t,h“eY unary sub-patterns x“acmaupslee oXf” aucndh “prevent X” are respectively excitatory and inhibitory. [sent-107, score-0.334]
</p><p>38 We used here 6,470 excitation unary patterns hand-labeled as either excitatory (4,882 patterns) or inhibitory (1,588 patterns). [sent-108, score-0.622]
</p><p>39 Set Popp contains 8 million pattern pairs with roughly 38% true contradiction pairs, and is the input to BASE. [sent-109, score-0.898]
</p><p>40 Instead we automatically generated training data from a smaller set of (non-)contradiction unary pattern pairs. [sent-114, score-0.329]
</p><p>41 We first prepared a set of roughly 800 unary pattern pairs hand-labeled by three human annotators as contradictions (238 pairs) and noncontradictions (558 pairs) using majority vote. [sent-115, score-0.791]
</p><p>42 (2012), we selected these unary pattern pairs among pairs with high distributional similarity, with and without restricting them to having opposite excitation polarity, such as to get a fair distribution of contradictions and noncontradictions. [sent-119, score-1.129]
</p><p>43 We then extracted from set Pall all 256,000 pattern pairs containing a contradictory unary pattern pair, and all 5. [sent-120, score-0.721]
</p><p>44 2 million pattern pairs containing a non-contradictory unary pattern pair, which we respectively used as positive and negative training data (estimated 79% and 73% accuracy from 200 handlabeled samples). [sent-121, score-0.674]
</p><p>45 46 million binary pattern pairs in Pall with a hand-labeled unary pattern pair in Pall, there are only 237,000 pairs in Popp. [sent-135, score-0.876]
</p><p>46 Effect of Excitation Polarities We also empirically examined the effect of the restriction on the patterns using excitation polarities. [sent-138, score-0.35]
</p><p>47 1) and 250 manually annotated samples (majority vote from 3 annotators) from top ranked pairs of Pall to draw precision curves for BASE over the top 2 million binary pairs from both Popp and Pall. [sent-141, score-0.465]
</p><p>48 The precision over Popp is higher than that over Pall with a large margin, suggesting that the restriction using excitation polarities is beneficial. [sent-146, score-0.32]
</p><p>49 3 ENT: First stage Classifier for Entailment ENT is an SVM classifier for entailment trained us-  ing 27,500 hand-annotated binary pattern pairs (set Trainent, 45% of positive entailment pairs) created for some previous work (Kloetzer et al. [sent-148, score-0.874]
</p><p>50 5 million pattern pairs with a positive SVM score as entailment pairs. [sent-153, score-0.547]
</p><p>51 The training data expansion process is based on the following logical constraint: if a pattern p entails a pattern q and pattern q contradicts a third pattern r,  then p must contradict r. [sent-158, score-0.811]
</p><p>52 964(815p,r) Algorithm 1Training data expansion: C is the top 5% output of BASE, E is the top output of ENT (score > 0) 1: procedure EXPAND(C, E) 2: Compute the set of expanded pairs C0 = {hp, ri | ∃q : hp, qi ∈ E,hq, ri ∈ C}. [sent-161, score-0.363]
</p><p>53 6: end procedure  causes Y” (pattern p) entails “X promotes Y” (pattern q) and the latter contradicts “X prevents Y” (pattern r), we conclude that “X causes Y” (p) contradicts “X prevents Y” (r). [sent-165, score-0.532]
</p><p>54 We call the former contradiction hq, ri a source contradiction pair, and the later pair hp, ri an expanded ctroandtircatdioicnti poani pair. [sent-166, score-1.438]
</p><p>55 CDP was designed according to the following assumption: a source contradiction pair that derives correct expanded pairs with a high precision should be reliable. [sent-172, score-0.948]
</p><p>56 Probably, all the expanded pairs derived from such a reliable source pair will be correct and should be included in the new training data . [sent-173, score-0.326]
</p><p>57 A source contradiction pair that derives true contradiction pairs with  a high precision is regarded as a reliable source contradiction pair. [sent-176, score-2.014]
</p><p>58 CDP, which is defined over a expanded pairs, is the maximum precision among that of the source contradiction pairs that derive a given expanded pair. [sent-177, score-1.016]
</p><p>59 We first define CDPsub(q, r) over a source contradiction pair hq, ri as the ratio of expanded pairs torbatdaiicnteiodn fr paomir hq, ri ws hthoese r StioVM of score dise dapb oavirse tohbrteasihnoedld α. [sent-178, score-0.991]
</p><p>60 mTh hisq ,raritio w corresponds t soc othree precision of the expanded pairs derived from the source contradiction pair hq, ri. [sent-179, score-0.948]
</p><p>61 CDPsub(q,r) =|{hp,ri ∈ Ex|(Eqx,r()q, |r S)|c(p,r) > α}| Here Ex(q, r) is the set of expanded pairs derived from a source pair hq, ri, and Sc is the SVM score given by BASE. [sent-180, score-0.326]
</p><p>62 o4r6e such that pattern pairs for which BASE gives a score over α corresponds to the top 5% of BASE’s output. [sent-182, score-0.284]
</p><p>63 CDP(p, r) over an expanded pair is defined as follows, where Source(p, r) is the set of source contradiction pairs that were derived into the expanded pair hp, ri. [sent-183, score-1.073]
</p><p>64 We propose to remove from the negative training samples of EXP any pattern pair that may conflict with the newly added positives; we call this step negative cleaning. [sent-188, score-0.331]
</p><p>65 Intuitively, since the content word pairs in a pattern pair should present some of the strongest evidence for determining the patterns (non-)contradiction status, we remove any negative sample that shares a  content word pair with one of the added expanded pairs. [sent-189, score-0.647]
</p><p>66 The final training data for EXP, set Trainexp, consists of the following: (1) positive samples from Trainbase, (2) (positive) expanded pairs, and (3) negative training samples from Trainbase, cleaned using negative cleaning. [sent-190, score-0.324]
</p><p>67 1 Development and Test Data  We asked three human annotators to label 3,000 binary pattern pairs randomly sampled from Popp as contradiction or non-contradiction to be used as development (1,000 pairs) and test (2,000 pairs) sets. [sent-197, score-0.933]
</p><p>68 We considered a pattern pair as a true contradiction relation if at least two out of the three annotators marked it as positive. [sent-198, score-0.805]
</p><p>69 We then say binary patterns such as “X causes Y” and “X prevents Y” are contradictory if the above definition holds for any noun pair that can instantiate the patterns’ variables in the provided semantic class pair. [sent-205, score-0.452]
</p><p>70 (2007) and provided the annotators with three random noun pairs that cooccur with the patterns as a proxy for the class pair. [sent-207, score-0.301]
</p><p>71 The annotators marked a given pattern pair as positive if the contradiction relation between the patterns held for all three noun pairs presented. [sent-208, score-1.082]
</p><p>72 HAS: an adaptation of the contradiction extraction method presented in Hashimoto et al. [sent-217, score-0.579]
</p><p>73 For a binary pattern pair we first extracted its unary pattern pair with opposite polarity (or one at random in case there are two) and scored it based on our implementation of Hashimoto et al. [sent-219, score-0.659]
</p><p>74 (2012); the score is based on the distributional similarity between unary patterns and an excitation score obtained using a minimally supervised method based on the spin model. [sent-220, score-0.526]
</p><p>75 We then scored the binary pattern pair by the score of this unary pattern pair. [sent-221, score-0.577]
</p><p>76 We ranked the pattern pairs of our test set (2,000 random pairs from set Popp) based on the score pro•  duced by each method. [sent-222, score-0.416]
</p><p>77 PROPOSED clearly outperformed BASE and acquired around 750,000 contradiction pattern pairs with an estimated precision of 80%, out of which some examples are shown in Table 3. [sent-226, score-0.954]
</p><p>78 These pairs cover 26,941 content word pairs and reduce to 272,164 untyped pairs, showing that PROPOSED does not just acquire a handful of contradictions in many different class pairs. [sent-227, score-0.62]
</p><p>79 With the same precision, BASE and PROP-SCORE acquired only 285,000 pairs (covering 11,794 content word pairs) and 636,000 pairs respectively. [sent-229, score-0.312]
</p><p>80 As to why adding only 6,000 top pairs ranked by CDP performs better than adding 30,000 pairs ranked by SVM score, the pattern pairs added in PROP-SCORE had high SVM scores given by BASE and as such are already handled nicely by BASE. [sent-233, score-0.548]
</p><p>81 The interaction between contradiction and entailment that forms the basis for our expansion method has a natural interpretation as an optimization problem. [sent-238, score-0.856]
</p><p>82 e(p, q) and c(p, q) are the score given respectively by ENT and BASE, and  β is a prior defining the weight of a pair as neither entailment nor contradiction that shall be set before any experimentation. [sent-243, score-0.857]
</p><p>83 Finally, Equation (3) states that a given pattern pair cannot be a contradiction pair and an entailment pair at the same time. [sent-245, score-1.109]
</p><p>84 More specifically, for any word pair hwp, wqi taken from a pattern pair hp, qi we mark thhwep presence onf hwp, wqi ittne renac pha orf h tph,eq ile wxieca ml resources as a binary f,ewaqtuire in. [sent-266, score-0.375]
</p><p>85 Distributional similarity values between patterns are based on the idea that patterns that appear in similar contexts tend to have similar meanings and as such are useful to recognize entailment (Lin and Pantel, 2001). [sent-274, score-0.502]
</p><p>86 We computed as features several distributional similarity measures on the sets of each pattern’s co-occurring noun pairs and their POS tags, of nouns co-occurring in each variable slot, and with each of the pattern’s unary sub-patterns. [sent-275, score-0.364]
</p><p>87 5  Related Work  A number of previous work dealt with the recognition of contradictions between sentences. [sent-278, score-0.306]
</p><p>88 (2006) proposed a contradiction detection method that focuses on negation, antonymy and some discourse information. [sent-280, score-0.579]
</p><p>89 While we do not deal ourselves directly with sentences, we expect that the binary pattern pairs we acquire can play a role similar to that of basic linguistic resources such 4 http://nlp. [sent-287, score-0.38]
</p><p>90 (2008) presented a method for detecting contradictions between functional re-  lations like “X was born in Y”, but these constitute only a part of the semantic relations expressed by the binary patterns we deal with in this paper. [sent-296, score-0.471]
</p><p>91 Voorhees (2008) analyzed the contradiction recognition-task of the RTE3 contest. [sent-298, score-0.579]
</p><p>92 Magnini and Cabrio (2010) examined relations between contradictions and textual entailment samples. [sent-299, score-0.558]
</p><p>93 (2008) presented a typology of contradictions, and showed that contradictions can arise from a multitude of phenomena. [sent-301, score-0.306]
</p><p>94 They showed contradictions based on lexical or world knowledge are challenging and require a highlevel understanding of language and/or the world. [sent-302, score-0.306]
</p><p>95 As stated in the introduction, these are the types of contradictions our method focuses on. [sent-303, score-0.306]
</p><p>96 6  Conclusion  This paper showed how to acquire a large number of contradiction pairs between lexico-syntactic binary patterns by exploiting (1) the interaction between contradiction and entailment, and (2) excitation polarities. [sent-304, score-1.706]
</p><p>97 In the end, we could acquire 750,000 typed contradiction pattern pairs with an estimated 80%  precision. [sent-305, score-0.945]
</p><p>98 The resulting contradiction pairs covered ones deeply related to world knowledge such as the pair h“X reassures Y”, “X betrays Y”i . [sent-306, score-0.811]
</p><p>99 Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web. [sent-379, score-0.579]
</p><p>100 Grasping major statements and their contradictions toward information credibility analysis of web contents. [sent-386, score-0.344]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contradiction', 0.579), ('contradictions', 0.306), ('entailment', 0.228), ('cdp', 0.214), ('excitation', 0.201), ('unary', 0.177), ('pattern', 0.152), ('base', 0.149), ('hashimoto', 0.142), ('pairs', 0.132), ('pall', 0.126), ('popp', 0.126), ('patterns', 0.119), ('expanded', 0.118), ('agaricus', 0.113), ('contradictory', 0.108), ('contradicts', 0.098), ('ent', 0.093), ('hp', 0.086), ('samples', 0.077), ('excitatory', 0.075), ('trainbase', 0.075), ('cancer', 0.074), ('promotes', 0.074), ('saeger', 0.066), ('tpp', 0.066), ('prevents', 0.065), ('alagin', 0.063), ('epq', 0.063), ('exp', 0.061), ('page', 0.059), ('svm', 0.057), ('entails', 0.056), ('torisawa', 0.056), ('hq', 0.055), ('stage', 0.052), ('agricultural', 0.05), ('cpq', 0.05), ('inhibitory', 0.05), ('acquire', 0.05), ('pair', 0.05), ('expansion', 0.049), ('acquired', 0.048), ('polarities', 0.046), ('berant', 0.046), ('binary', 0.046), ('ilp', 0.046), ('japanese', 0.046), ('precision', 0.043), ('ri', 0.043), ('kawahara', 0.042), ('japan', 0.04), ('antonyms', 0.04), ('causes', 0.038), ('statements', 0.038), ('bobrow', 0.038), ('cdpsub', 0.038), ('kloetzer', 0.038), ('murakami', 0.038), ('ohki', 0.038), ('wipe', 0.038), ('expand', 0.038), ('classifier', 0.036), ('recognize', 0.036), ('million', 0.035), ('kurohashi', 0.033), ('harabagiu', 0.032), ('prevent', 0.032), ('typed', 0.032), ('polarity', 0.032), ('restriction', 0.03), ('distributional', 0.029), ('marneffe', 0.029), ('negations', 0.028), ('qi', 0.027), ('positives', 0.027), ('noun', 0.026), ('source', 0.026), ('kazama', 0.026), ('inui', 0.026), ('negation', 0.026), ('negative', 0.026), ('allographic', 0.025), ('betrays', 0.025), ('hwp', 0.025), ('juman', 0.025), ('kiyonori', 0.025), ('masuda', 0.025), ('matsuyoshi', 0.025), ('nichols', 0.025), ('nict', 0.025), ('reassures', 0.025), ('strengthen', 0.025), ('trainexp', 0.025), ('wqi', 0.025), ('ydisease', 0.025), ('textual', 0.024), ('annotators', 0.024), ('recognizes', 0.023), ('trivial', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999887 <a title="189-tfidf-1" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>Author: Julien Kloetzer ; Stijn De Saeger ; Kentaro Torisawa ; Chikara Hashimoto ; Jong-Hoon Oh ; Motoki Sano ; Kiyonori Ohtake</p><p>Abstract: In this paper we propose a two-stage method to acquire contradiction relations between typed lexico-syntactic patterns such as Xdrug prevents Ydisease and Ydisease caused by Xdrug. In the first stage, we train an SVM classifier to detect contradiction pattern pairs in a large web archive by exploiting the excitation polarity (Hashimoto et al., 2012) of the patterns. In the second stage, we enlarge the first stage classifier’s training data with new contradiction pairs obtained by combining the output of the first stage’s classifier and that of an entailment classifier. We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%. We plan to release this resource to the NLP community. 1</p><p>2 0.069291696 <a title="189-tfidf-2" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>Author: Benjamin Roth ; Dietrich Klakow</p><p>Abstract: Distant supervision is a scheme to generate noisy training data for relation extraction by aligning entities of a knowledge base with text. In this work we combine the output of a discriminative at-least-one learner with that of a generative hierarchical topic model to reduce the noise in distant supervision data. The combination significantly increases the ranking quality of extracted facts and achieves state-of-the-art extraction performance in an end-to-end setting. A simple linear interpolation of the model scores performs better than a parameter-free scheme based on nondominated sorting.</p><p>3 0.061870772 <a title="189-tfidf-3" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>Author: Jonathan Berant ; Andrew Chou ; Roy Frostig ; Percy Liang</p><p>Abstract: In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset ofCai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.</p><p>4 0.056241296 <a title="189-tfidf-4" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: This paper presents a novel approach to determine textual similarity. A layered methodology to transform text into logic forms is proposed, and semantic features are derived from a logic prover. Experimental results show that incorporating the semantic structure of sentences is beneficial. When training data is unavailable, scores obtained from the logic prover in an unsupervised manner outperform supervised methods.</p><p>5 0.048261918 <a title="189-tfidf-5" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>6 0.042842168 <a title="189-tfidf-6" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>7 0.04221141 <a title="189-tfidf-7" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>8 0.039388254 <a title="189-tfidf-8" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>9 0.037960671 <a title="189-tfidf-9" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<p>10 0.037397522 <a title="189-tfidf-10" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>11 0.037388626 <a title="189-tfidf-11" href="./emnlp-2013-Automatic_Knowledge_Acquisition_for_Case_Alternation_between_the_Passive_and_Active_Voices_in_Japanese.html">33 emnlp-2013-Automatic Knowledge Acquisition for Case Alternation between the Passive and Active Voices in Japanese</a></p>
<p>12 0.037138734 <a title="189-tfidf-12" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>13 0.036821999 <a title="189-tfidf-13" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>14 0.03628144 <a title="189-tfidf-14" href="./emnlp-2013-Authorship_Attribution_of_Micro-Messages.html">27 emnlp-2013-Authorship Attribution of Micro-Messages</a></p>
<p>15 0.035865564 <a title="189-tfidf-15" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>16 0.035648547 <a title="189-tfidf-16" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>17 0.03432196 <a title="189-tfidf-17" href="./emnlp-2013-Optimal_Incremental_Parsing_via_Best-First_Dynamic_Programming.html">146 emnlp-2013-Optimal Incremental Parsing via Best-First Dynamic Programming</a></p>
<p>18 0.034037922 <a title="189-tfidf-18" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>19 0.033613224 <a title="189-tfidf-19" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<p>20 0.032736849 <a title="189-tfidf-20" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.131), (1, 0.034), (2, -0.033), (3, 0.008), (4, -0.004), (5, 0.03), (6, -0.022), (7, -0.005), (8, 0.05), (9, -0.004), (10, 0.035), (11, 0.046), (12, -0.023), (13, 0.045), (14, 0.005), (15, 0.01), (16, -0.044), (17, 0.024), (18, 0.013), (19, 0.042), (20, -0.036), (21, 0.082), (22, 0.019), (23, 0.07), (24, -0.002), (25, 0.057), (26, 0.005), (27, 0.049), (28, 0.006), (29, 0.065), (30, -0.015), (31, 0.059), (32, 0.009), (33, 0.027), (34, 0.067), (35, 0.132), (36, 0.011), (37, -0.06), (38, -0.023), (39, 0.004), (40, -0.026), (41, 0.067), (42, -0.114), (43, 0.125), (44, 0.062), (45, -0.006), (46, 0.012), (47, -0.138), (48, 0.024), (49, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92953503 <a title="189-lsi-1" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>Author: Julien Kloetzer ; Stijn De Saeger ; Kentaro Torisawa ; Chikara Hashimoto ; Jong-Hoon Oh ; Motoki Sano ; Kiyonori Ohtake</p><p>Abstract: In this paper we propose a two-stage method to acquire contradiction relations between typed lexico-syntactic patterns such as Xdrug prevents Ydisease and Ydisease caused by Xdrug. In the first stage, we train an SVM classifier to detect contradiction pattern pairs in a large web archive by exploiting the excitation polarity (Hashimoto et al., 2012) of the patterns. In the second stage, we enlarge the first stage classifier’s training data with new contradiction pairs obtained by combining the output of the first stage’s classifier and that of an entailment classifier. We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%. We plan to release this resource to the NLP community. 1</p><p>2 0.56534016 <a title="189-lsi-2" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>Author: Benjamin Roth ; Dietrich Klakow</p><p>Abstract: Distant supervision is a scheme to generate noisy training data for relation extraction by aligning entities of a knowledge base with text. In this work we combine the output of a discriminative at-least-one learner with that of a generative hierarchical topic model to reduce the noise in distant supervision data. The combination significantly increases the ranking quality of extracted facts and achieves state-of-the-art extraction performance in an end-to-end setting. A simple linear interpolation of the model scores performs better than a parameter-free scheme based on nondominated sorting.</p><p>3 0.51501197 <a title="189-lsi-3" href="./emnlp-2013-Noise-Aware_Character_Alignment_for_Bootstrapping_Statistical_Machine_Transliteration_from_Bilingual_Corpora.html">139 emnlp-2013-Noise-Aware Character Alignment for Bootstrapping Statistical Machine Transliteration from Bilingual Corpora</a></p>
<p>Author: Katsuhito Sudoh ; Shinsuke Mori ; Masaaki Nagata</p><p>Abstract: This paper proposes a novel noise-aware character alignment method for bootstrapping statistical machine transliteration from automatically extracted phrase pairs. The model is an extension of a Bayesian many-to-many alignment method for distinguishing nontransliteration (noise) parts in phrase pairs. It worked effectively in the experiments of bootstrapping Japanese-to-English statistical machine transliteration in patent domain using patent bilingual corpora.</p><p>4 0.47769603 <a title="189-lsi-4" href="./emnlp-2013-Automatic_Knowledge_Acquisition_for_Case_Alternation_between_the_Passive_and_Active_Voices_in_Japanese.html">33 emnlp-2013-Automatic Knowledge Acquisition for Case Alternation between the Passive and Active Voices in Japanese</a></p>
<p>Author: Ryohei Sasano ; Daisuke Kawahara ; Sadao Kurohashi ; Manabu Okumura</p><p>Abstract: We present a method for automatically acquiring knowledge for case alternation between the passive and active voices in Japanese. By leveraging several linguistic constraints on alternation patterns and lexical case frames obtained from a large Web corpus, our method aligns a case frame in the passive voice to a corresponding case frame in the active voice and finds an alignment between their cases. We then apply the acquired knowledge to a case alternation task and prove its usefulness.</p><p>5 0.43896529 <a title="189-lsi-5" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>6 0.40694964 <a title="189-lsi-6" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>7 0.40577695 <a title="189-lsi-7" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>8 0.4024131 <a title="189-lsi-8" href="./emnlp-2013-Detecting_Promotional_Content_in_Wikipedia.html">61 emnlp-2013-Detecting Promotional Content in Wikipedia</a></p>
<p>9 0.37615374 <a title="189-lsi-9" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>10 0.37556466 <a title="189-lsi-10" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>11 0.37107632 <a title="189-lsi-11" href="./emnlp-2013-Automatically_Classifying_Edit_Categories_in_Wikipedia_Revisions.html">34 emnlp-2013-Automatically Classifying Edit Categories in Wikipedia Revisions</a></p>
<p>12 0.37102029 <a title="189-lsi-12" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>13 0.36955765 <a title="189-lsi-13" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<p>14 0.34837908 <a title="189-lsi-14" href="./emnlp-2013-Shift-Reduce_Word_Reordering_for_Machine_Translation.html">171 emnlp-2013-Shift-Reduce Word Reordering for Machine Translation</a></p>
<p>15 0.34739491 <a title="189-lsi-15" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>16 0.34655303 <a title="189-lsi-16" href="./emnlp-2013-Multi-Relational_Latent_Semantic_Analysis.html">137 emnlp-2013-Multi-Relational Latent Semantic Analysis</a></p>
<p>17 0.34531894 <a title="189-lsi-17" href="./emnlp-2013-Cascading_Collective_Classification_for_Bridging_Anaphora_Recognition_using_a_Rich_Linguistic_Feature_Set.html">43 emnlp-2013-Cascading Collective Classification for Bridging Anaphora Recognition using a Rich Linguistic Feature Set</a></p>
<p>18 0.33950478 <a title="189-lsi-18" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>19 0.33824921 <a title="189-lsi-19" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<p>20 0.33460709 <a title="189-lsi-20" href="./emnlp-2013-Improving_Alignment_of_System_Combination_by_Using_Multi-objective_Optimization.html">101 emnlp-2013-Improving Alignment of System Combination by Using Multi-objective Optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.035), (18, 0.046), (22, 0.039), (30, 0.073), (43, 0.015), (50, 0.023), (51, 0.161), (66, 0.032), (71, 0.029), (75, 0.034), (77, 0.01), (90, 0.029), (96, 0.026), (98, 0.337)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72492266 <a title="189-lda-1" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>Author: Julien Kloetzer ; Stijn De Saeger ; Kentaro Torisawa ; Chikara Hashimoto ; Jong-Hoon Oh ; Motoki Sano ; Kiyonori Ohtake</p><p>Abstract: In this paper we propose a two-stage method to acquire contradiction relations between typed lexico-syntactic patterns such as Xdrug prevents Ydisease and Ydisease caused by Xdrug. In the first stage, we train an SVM classifier to detect contradiction pattern pairs in a large web archive by exploiting the excitation polarity (Hashimoto et al., 2012) of the patterns. In the second stage, we enlarge the first stage classifier’s training data with new contradiction pairs obtained by combining the output of the first stage’s classifier and that of an entailment classifier. We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%. We plan to release this resource to the NLP community. 1</p><p>2 0.49870223 <a title="189-lda-2" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>3 0.4981856 <a title="189-lda-3" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>Author: Jason Weston ; Antoine Bordes ; Oksana Yakhnenko ; Nicolas Usunier</p><p>Abstract: This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.</p><p>4 0.4979448 <a title="189-lda-4" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>Author: Xiaoqing Zheng ; Hanyang Chen ; Tianyu Xu</p><p>Abstract: This study explores the feasibility of performing Chinese word segmentation (CWS) and POS tagging by deep learning. We try to avoid task-specific feature engineering, and use deep layers of neural networks to discover relevant features to the tasks. We leverage large-scale unlabeled data to improve internal representation of Chinese characters, and use these improved representations to enhance supervised word segmentation and POS tagging models. Our networks achieved close to state-of-theart performance with minimal computational cost. We also describe a perceptron-style algorithm for training the neural networks, as an alternative to maximum-likelihood method, to speed up the training process and make the learning algorithm easier to be implemented.</p><p>5 0.4950822 <a title="189-lda-5" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>Author: Kuzman Ganchev ; Dipanjan Das</p><p>Abstract: We present a framework for cross-lingual transfer of sequence information from a resource-rich source language to a resourceimpoverished target language that incorporates soft constraints via posterior regularization. To this end, we use automatically word aligned bitext between the source and target language pair, and learn a discriminative conditional random field model on the target side. Our posterior regularization constraints are derived from simple intuitions about the task at hand and from cross-lingual alignment information. We show improvements over strong baselines for two tasks: part-of-speech tagging and namedentity segmentation.</p><p>6 0.49492413 <a title="189-lda-6" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>7 0.49433479 <a title="189-lda-7" href="./emnlp-2013-Prior_Disambiguation_of_Word_Tensors_for_Constructing_Sentence_Vectors.html">154 emnlp-2013-Prior Disambiguation of Word Tensors for Constructing Sentence Vectors</a></p>
<p>8 0.49331826 <a title="189-lda-8" href="./emnlp-2013-Of_Words%2C_Eyes_and_Brains%3A_Correlating_Image-Based_Distributional_Semantic_Models_with_Neural_Representations_of_Concepts.html">140 emnlp-2013-Of Words, Eyes and Brains: Correlating Image-Based Distributional Semantic Models with Neural Representations of Concepts</a></p>
<p>9 0.49235216 <a title="189-lda-9" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>10 0.49226886 <a title="189-lda-10" href="./emnlp-2013-Exploring_Representations_from_Unlabeled_Data_with_Co-training_for_Chinese_Word_Segmentation.html">82 emnlp-2013-Exploring Representations from Unlabeled Data with Co-training for Chinese Word Segmentation</a></p>
<p>11 0.49169937 <a title="189-lda-11" href="./emnlp-2013-Scaling_Semantic_Parsers_with_On-the-Fly_Ontology_Matching.html">164 emnlp-2013-Scaling Semantic Parsers with On-the-Fly Ontology Matching</a></p>
<p>12 0.4913241 <a title="189-lda-12" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>13 0.49117479 <a title="189-lda-13" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>14 0.4906204 <a title="189-lda-14" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>15 0.49054986 <a title="189-lda-15" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>16 0.49050704 <a title="189-lda-16" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>17 0.49030808 <a title="189-lda-17" href="./emnlp-2013-A_Study_on_Bootstrapping_Bilingual_Vector_Spaces_from_Non-Parallel_Data_%28and_Nothing_Else%29.html">13 emnlp-2013-A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data (and Nothing Else)</a></p>
<p>18 0.49029276 <a title="189-lda-18" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>19 0.48994535 <a title="189-lda-19" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<p>20 0.48989561 <a title="189-lda-20" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
