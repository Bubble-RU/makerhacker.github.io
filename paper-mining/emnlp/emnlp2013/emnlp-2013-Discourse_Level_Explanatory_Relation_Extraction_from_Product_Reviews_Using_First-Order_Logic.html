<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-63" href="#">emnlp2013-63</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</h1>
<br/><p>Source: <a title="emnlp-2013-63-pdf" href="http://aclweb.org/anthology//D/D13/D13-1097.pdf">pdf</a></p><p>Author: Qi Zhang ; Jin Qian ; Huan Chen ; Jihua Kang ; Xuanjing Huang</p><p>Abstract: Explanatory sentences are employed to clarify reasons, details, facts, and so on. High quality online product reviews usually include not only positive or negative opinions, but also a variety of explanations of why these opinions were given. These explanations can help readers get easily comprehensible information of the discussed products and aspects. Moreover, explanatory relations can also benefit sentiment analysis applications. In this work, we focus on the task of identifying subjective text segments and extracting their corresponding explanations from product reviews in discourse level. We propose a novel joint extraction method using firstorder logic to model rich linguistic features and long distance constraints. Experimental results demonstrate the effectiveness of the proposed method.</p><p>Reference: <a title="emnlp-2013-63-reference" href="../emnlp2013_reference/emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('claus', 0.419), ('formula', 0.376), ('mln', 0.276), ('firstword', 0.249), ('subjlexicon', 0.207), ('subs', 0.206), ('subject', 0.202), ('opin', 0.192), ('relationlexicon', 0.187), ('explain', 0.176), ('discours', 0.166), ('pred', 0.147), ('senty', 0.144), ('dep', 0.132), ('domingo', 0.118), ('expl', 0.092), ('markov', 0.076), ('log', 0.064), ('pos', 0.064), ('andrzejewsk', 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="63-tfidf-1" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>Author: Qi Zhang ; Jin Qian ; Huan Chen ; Jihua Kang ; Xuanjing Huang</p><p>Abstract: Explanatory sentences are employed to clarify reasons, details, facts, and so on. High quality online product reviews usually include not only positive or negative opinions, but also a variety of explanations of why these opinions were given. These explanations can help readers get easily comprehensible information of the discussed products and aspects. Moreover, explanatory relations can also benefit sentiment analysis applications. In this work, we focus on the task of identifying subjective text segments and extracting their corresponding explanations from product reviews in discourse level. We propose a novel joint extraction method using firstorder logic to model rich linguistic features and long distance constraints. Experimental results demonstrate the effectiveness of the proposed method.</p><p>2 0.24260896 <a title="63-tfidf-2" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>Author: Gary Patterson ; Andrew Kehler</p><p>Abstract: We present a classification model that predicts the presence or omission of a lexical connective between two clauses, based upon linguistic features of the clauses and the type of discourse relation holding between them. The model is trained on a set of high frequency relations extracted from the Penn Discourse Treebank and achieves an accuracy of 86.6%. Analysis of the results reveals that the most informative features relate to the discourse dependencies between sequences of coherence relations in the text. We also present results of an experiment that provides insight into the nature and difficulty of the task.</p><p>3 0.21007019 <a title="63-tfidf-3" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>4 0.18515542 <a title="63-tfidf-4" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>5 0.17075518 <a title="63-tfidf-5" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>Author: Xinjie Zhou ; Xiaojun Wan ; Jianguo Xiao</p><p>Abstract: Microblog messages pose severe challenges for current sentiment analysis techniques due to some inherent characteristics such as the length limit and informal writing style. In this paper, we study the problem of extracting opinion targets of Chinese microblog messages. Such fine-grained word-level task has not been well investigated in microblogs yet. We propose an unsupervised label propagation algorithm to address the problem. The opinion targets of all messages in a topic are collectively extracted based on the assumption that similar messages may focus on similar opinion targets. Topics in microblogs are identified by hashtags or using clustering algorithms. Experimental results on Chinese microblogs show the effectiveness of our framework and algorithms.</p><p>6 0.15746476 <a title="63-tfidf-6" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>7 0.15660846 <a title="63-tfidf-7" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>8 0.14132254 <a title="63-tfidf-8" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>9 0.1370105 <a title="63-tfidf-9" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>10 0.12630706 <a title="63-tfidf-10" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>11 0.11538359 <a title="63-tfidf-11" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>12 0.10896789 <a title="63-tfidf-12" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>13 0.1063181 <a title="63-tfidf-13" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>14 0.10352962 <a title="63-tfidf-14" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>15 0.096625566 <a title="63-tfidf-15" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>16 0.094384156 <a title="63-tfidf-16" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>17 0.091548987 <a title="63-tfidf-17" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<p>18 0.082396679 <a title="63-tfidf-18" href="./emnlp-2013-Sarcasm_as_Contrast_between_a_Positive_Sentiment_and_Negative_Situation.html">163 emnlp-2013-Sarcasm as Contrast between a Positive Sentiment and Negative Situation</a></p>
<p>19 0.082350634 <a title="63-tfidf-19" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>20 0.078471377 <a title="63-tfidf-20" href="./emnlp-2013-Learning_Distributions_over_Logical_Forms_for_Referring_Expression_Generation.html">119 emnlp-2013-Learning Distributions over Logical Forms for Referring Expression Generation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.239), (1, -0.18), (2, 0.108), (3, 0.087), (4, 0.059), (5, -0.005), (6, 0.035), (7, 0.053), (8, 0.186), (9, 0.101), (10, 0.164), (11, 0.098), (12, -0.2), (13, -0.018), (14, -0.127), (15, 0.199), (16, -0.016), (17, -0.126), (18, -0.001), (19, 0.075), (20, -0.051), (21, -0.056), (22, 0.077), (23, 0.12), (24, -0.017), (25, -0.047), (26, 0.009), (27, -0.071), (28, -0.033), (29, -0.063), (30, -0.085), (31, 0.065), (32, 0.112), (33, -0.02), (34, -0.006), (35, -0.091), (36, -0.1), (37, -0.052), (38, -0.06), (39, 0.021), (40, 0.055), (41, 0.074), (42, 0.023), (43, -0.055), (44, 0.048), (45, -0.04), (46, 0.003), (47, 0.038), (48, 0.016), (49, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93793088 <a title="63-lsi-1" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>Author: Qi Zhang ; Jin Qian ; Huan Chen ; Jihua Kang ; Xuanjing Huang</p><p>Abstract: Explanatory sentences are employed to clarify reasons, details, facts, and so on. High quality online product reviews usually include not only positive or negative opinions, but also a variety of explanations of why these opinions were given. These explanations can help readers get easily comprehensible information of the discussed products and aspects. Moreover, explanatory relations can also benefit sentiment analysis applications. In this work, we focus on the task of identifying subjective text segments and extracting their corresponding explanations from product reviews in discourse level. We propose a novel joint extraction method using firstorder logic to model rich linguistic features and long distance constraints. Experimental results demonstrate the effectiveness of the proposed method.</p><p>2 0.67464393 <a title="63-lsi-2" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>Author: Gary Patterson ; Andrew Kehler</p><p>Abstract: We present a classification model that predicts the presence or omission of a lexical connective between two clauses, based upon linguistic features of the clauses and the type of discourse relation holding between them. The model is trained on a set of high frequency relations extracted from the Penn Discourse Treebank and achieves an accuracy of 86.6%. Analysis of the results reveals that the most informative features relate to the discourse dependencies between sequences of coherence relations in the text. We also present results of an experiment that provides insight into the nature and difficulty of the task.</p><p>3 0.66753012 <a title="63-lsi-3" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>4 0.57342976 <a title="63-lsi-4" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>Author: Thomas Scholz ; Stefan Conrad</p><p>Abstract: A very valuable piece of information in newspaper articles is the tonality of extracted statements. For the analysis of tonality of newspaper articles either a big human effort is needed, when it is carried out by media analysts, or an automated approach which has to be as accurate as possible for a Media Response Analysis (MRA). To this end, we will compare several state-of-the-art approaches for Opinion Mining in newspaper articles in this paper. Furthermore, we will introduce a new technique to extract entropy-based word connections which identifies the word combinations which create a tonality. In the evaluation, we use two different corpora consisting of news articles, by which we show that the new approach achieves better results than the four state-of-the-art methods.</p><p>5 0.5540362 <a title="63-lsi-5" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>6 0.53973007 <a title="63-lsi-6" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>7 0.50463766 <a title="63-lsi-7" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>8 0.49950686 <a title="63-lsi-8" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>9 0.47038397 <a title="63-lsi-9" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>10 0.44986033 <a title="63-lsi-10" href="./emnlp-2013-The_VerbCorner_Project%3A_Toward_an_Empirically-Based_Semantic_Decomposition_of_Verbs.html">183 emnlp-2013-The VerbCorner Project: Toward an Empirically-Based Semantic Decomposition of Verbs</a></p>
<p>11 0.44173807 <a title="63-lsi-11" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>12 0.43236333 <a title="63-lsi-12" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>13 0.41960078 <a title="63-lsi-13" href="./emnlp-2013-Single-Document_Summarization_as_a_Tree_Knapsack_Problem.html">174 emnlp-2013-Single-Document Summarization as a Tree Knapsack Problem</a></p>
<p>14 0.41356611 <a title="63-lsi-14" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>15 0.39953965 <a title="63-lsi-15" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>16 0.39890301 <a title="63-lsi-16" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<p>17 0.37550601 <a title="63-lsi-17" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>18 0.37077886 <a title="63-lsi-18" href="./emnlp-2013-Sarcasm_as_Contrast_between_a_Positive_Sentiment_and_Negative_Situation.html">163 emnlp-2013-Sarcasm as Contrast between a Positive Sentiment and Negative Situation</a></p>
<p>19 0.36709169 <a title="63-lsi-19" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>20 0.35770279 <a title="63-lsi-20" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.03), (24, 0.013), (25, 0.05), (29, 0.03), (37, 0.019), (45, 0.012), (47, 0.064), (51, 0.04), (65, 0.175), (69, 0.035), (73, 0.094), (79, 0.093), (84, 0.04), (96, 0.212)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78439671 <a title="63-lda-1" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>Author: Qi Zhang ; Jin Qian ; Huan Chen ; Jihua Kang ; Xuanjing Huang</p><p>Abstract: Explanatory sentences are employed to clarify reasons, details, facts, and so on. High quality online product reviews usually include not only positive or negative opinions, but also a variety of explanations of why these opinions were given. These explanations can help readers get easily comprehensible information of the discussed products and aspects. Moreover, explanatory relations can also benefit sentiment analysis applications. In this work, we focus on the task of identifying subjective text segments and extracting their corresponding explanations from product reviews in discourse level. We propose a novel joint extraction method using firstorder logic to model rich linguistic features and long distance constraints. Experimental results demonstrate the effectiveness of the proposed method.</p><p>2 0.72679067 <a title="63-lda-2" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>Author: Swapna Gottipati ; Minghui Qiu ; Yanchuan Sim ; Jing Jiang ; Noah A. Smith</p><p>Abstract: We explore Debatepedia, a communityauthored encyclopedia of sociopolitical debates, as evidence for inferring a lowdimensional, human-interpretable representation in the domain of issues and positions. We introduce a generative model positing latent topics and cross-cutting positions that gives special treatment to person mentions and opinion words. We evaluate the resulting representation’s usefulness in attaching opinionated documents to arguments and its consistency with human judgments about positions.</p><p>3 0.71301919 <a title="63-lda-3" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>4 0.70850199 <a title="63-lda-4" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>Author: Aliaksei Severyn ; Alessandro Moschitti</p><p>Abstract: This paper proposes a framework for automatically engineering features for two important tasks of question answering: answer sentence selection and answer extraction. We represent question and answer sentence pairs with linguistic structures enriched by semantic information, where the latter is produced by automatic classifiers, e.g., question classifier and Named Entity Recognizer. Tree kernels applied to such structures enable a simple way to generate highly discriminative structural features that combine syntactic and semantic information encoded in the input trees. We conduct experiments on a public benchmark from TREC to compare with previous systems for answer sentence selection and answer extraction. The results show that our models greatly improve on the state of the art, e.g., up to 22% on F1 (relative improvement) for answer extraction, while using no additional resources and no manual feature engineering.</p><p>5 0.70800269 <a title="63-lda-5" href="./emnlp-2013-Sarcasm_as_Contrast_between_a_Positive_Sentiment_and_Negative_Situation.html">163 emnlp-2013-Sarcasm as Contrast between a Positive Sentiment and Negative Situation</a></p>
<p>Author: Ellen Riloff ; Ashequl Qadir ; Prafulla Surve ; Lalindra De Silva ; Nathan Gilbert ; Ruihong Huang</p><p>Abstract: A common form of sarcasm on Twitter consists of a positive sentiment contrasted with a negative situation. For example, many sarcastic tweets include a positive sentiment, such as “love” or “enjoy”, followed by an expression that describes an undesirable activity or state (e.g., “taking exams” or “being ignored”). We have developed a sarcasm recognizer to identify this type of sarcasm in tweets. We present a novel bootstrapping algorithm that automatically learns lists of positive sentiment phrases and negative situation phrases from sarcastic tweets. We show that identifying contrasting contexts using the phrases learned through bootstrapping yields improved recall for sarcasm recognition.</p><p>6 0.70558959 <a title="63-lda-6" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>7 0.70121318 <a title="63-lda-7" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>8 0.698874 <a title="63-lda-8" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>9 0.69606251 <a title="63-lda-9" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>10 0.69402689 <a title="63-lda-10" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>11 0.69312537 <a title="63-lda-11" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>12 0.69229829 <a title="63-lda-12" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>13 0.69072908 <a title="63-lda-13" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>14 0.68706959 <a title="63-lda-14" href="./emnlp-2013-Studying_the_Recursive_Behaviour_of_Adjectival_Modification_with_Compositional_Distributional_Semantics.html">177 emnlp-2013-Studying the Recursive Behaviour of Adjectival Modification with Compositional Distributional Semantics</a></p>
<p>15 0.6858539 <a title="63-lda-15" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>16 0.68524617 <a title="63-lda-16" href="./emnlp-2013-Image_Description_using_Visual_Dependency_Representations.html">98 emnlp-2013-Image Description using Visual Dependency Representations</a></p>
<p>17 0.68522114 <a title="63-lda-17" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>18 0.6849125 <a title="63-lda-18" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<p>19 0.68489945 <a title="63-lda-19" href="./emnlp-2013-Measuring_Ideological_Proportions_in_Political_Speeches.html">129 emnlp-2013-Measuring Ideological Proportions in Political Speeches</a></p>
<p>20 0.68237758 <a title="63-lda-20" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
