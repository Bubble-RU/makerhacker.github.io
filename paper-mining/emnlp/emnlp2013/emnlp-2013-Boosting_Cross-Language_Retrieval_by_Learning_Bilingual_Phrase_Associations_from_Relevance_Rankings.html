<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-39" href="#">emnlp2013-39</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</h1>
<br/><p>Source: <a title="emnlp-2013-39-pdf" href="http://aclweb.org/anthology//D/D13/D13-1175.pdf">pdf</a></p><p>Author: Artem Sokokov ; Laura Jehl ; Felix Hieber ; Stefan Riezler</p><p>Abstract: We present an approach to learning bilingual n-gram correspondences from relevance rankings of English documents for Japanese queries. We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR). We propose an efficient boosting algorithm that deals with very large cross-product spaces of word correspondences. We show in an experimental evaluation on patent prior art search that our approach, and in particular a consensus-based combination of boosting and translation-based approaches, yields substantial improvements in CLIR performance. Our training and test data are made publicly available.</p><p>Reference: <a title="emnlp-2013-39-reference" href="../emnlp2013_reference/emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pat', 0.519), ('clir', 0.377), ('psq', 0.36), ('query', 0.237), ('boost', 0.175), ('pre', 0.166), ('transl', 0.137), ('dt', 0.121), ('wh', 0.117), ('retriev', 0.113), ('rank', 0.113), ('smt', 0.103), ('japanes', 0.097), ('sigir', 0.092), ('magdy', 0.082), ('docu', 0.081), ('stopword', 0.08), ('tur', 0.066), ('lexp', 0.065), ('pnbest', 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999863 <a title="39-tfidf-1" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<p>Author: Artem Sokokov ; Laura Jehl ; Felix Hieber ; Stefan Riezler</p><p>Abstract: We present an approach to learning bilingual n-gram correspondences from relevance rankings of English documents for Japanese queries. We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR). We propose an efficient boosting algorithm that deals with very large cross-product spaces of word correspondences. We show in an experimental evaluation on patent prior art search that our approach, and in particular a consensus-based combination of boosting and translation-based approaches, yields substantial improvements in CLIR performance. Our training and test data are made publicly available.</p><p>2 0.19837841 <a title="39-tfidf-2" href="./emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching.html">97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</a></p>
<p>Author: Ahmed Hassan</p><p>Abstract: Web search users frequently modify their queries in hope of receiving better results. This process is referred to as “Query Reformulation”. Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance. In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig- nificantly improve query reformulation performance using features of query concepts.</p><p>3 0.14558613 <a title="39-tfidf-3" href="./emnlp-2013-Improving_Web_Search_Ranking_by_Incorporating_Structured_Annotation_of_Queries.html">105 emnlp-2013-Improving Web Search Ranking by Incorporating Structured Annotation of Queries</a></p>
<p>Author: Xiao Ding ; Zhicheng Dou ; Bing Qin ; Ting Liu ; Ji-rong Wen</p><p>Abstract: Web users are increasingly looking for structured data, such as lyrics, job, or recipes, using unstructured queries on the web. However, retrieving relevant results from such data is a challenging problem due to the unstructured language of the web queries. In this paper, we propose a method to improve web search ranking by detecting Structured Annotation of queries based on top search results. In a structured annotation, the original query is split into different units that are associated with semantic attributes in the corresponding domain. We evaluate our techniques using real world queries and achieve significant improvement. . 1</p><p>4 0.11681171 <a title="39-tfidf-4" href="./emnlp-2013-Multi-Domain_Adaptation_for_SMT_Using_Multi-Task_Learning.html">136 emnlp-2013-Multi-Domain Adaptation for SMT Using Multi-Task Learning</a></p>
<p>Author: Lei Cui ; Xilun Chen ; Dongdong Zhang ; Shujie Liu ; Mu Li ; Ming Zhou</p><p>Abstract: Domain adaptation for SMT usually adapts models to an individual specific domain. However, it often lacks some correlation among different domains where common knowledge could be shared to improve the overall translation quality. In this paper, we propose a novel multi-domain adaptation approach for SMT using Multi-Task Learning (MTL), with in-domain models tailored for each specific domain and a general-domain model shared by different domains. The parameters of these models are tuned jointly via MTL so that they can learn general knowledge more accurately and exploit domain knowledge better. Our experiments on a largescale English-to-Chinese translation task validate that the MTL-based adaptation approach significantly and consistently improves the translation quality compared to a non-adapted baseline. Furthermore, it also outperforms the individual adaptation of each specific domain.</p><p>5 0.11624712 <a title="39-tfidf-5" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>Author: Benjamin Roth ; Dietrich Klakow</p><p>Abstract: Distant supervision is a scheme to generate noisy training data for relation extraction by aligning entities of a knowledge base with text. In this work we combine the output of a discriminative at-least-one learner with that of a generative hierarchical topic model to reduce the noise in distant supervision data. The combination significantly increases the ranking quality of extracted facts and achieves state-of-the-art extraction performance in an end-to-end setting. A simple linear interpolation of the model scores performs better than a parameter-free scheme based on nondominated sorting.</p><p>6 0.10643543 <a title="39-tfidf-6" href="./emnlp-2013-Noise-Aware_Character_Alignment_for_Bootstrapping_Statistical_Machine_Transliteration_from_Bilingual_Corpora.html">139 emnlp-2013-Noise-Aware Character Alignment for Bootstrapping Statistical Machine Transliteration from Bilingual Corpora</a></p>
<p>7 0.09895464 <a title="39-tfidf-7" href="./emnlp-2013-Monolingual_Marginal_Matching_for_Translation_Model_Adaptation.html">135 emnlp-2013-Monolingual Marginal Matching for Translation Model Adaptation</a></p>
<p>8 0.095218994 <a title="39-tfidf-8" href="./emnlp-2013-Max-Margin_Synchronous_Grammar_Induction_for_Machine_Translation.html">127 emnlp-2013-Max-Margin Synchronous Grammar Induction for Machine Translation</a></p>
<p>9 0.094813362 <a title="39-tfidf-9" href="./emnlp-2013-Identifying_Phrasal_Verbs_Using_Many_Bilingual_Corpora.html">96 emnlp-2013-Identifying Phrasal Verbs Using Many Bilingual Corpora</a></p>
<p>10 0.092704199 <a title="39-tfidf-10" href="./emnlp-2013-An_Efficient_Language_Model_Using_Double-Array_Structures.html">20 emnlp-2013-An Efficient Language Model Using Double-Array Structures</a></p>
<p>11 0.090575226 <a title="39-tfidf-11" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>12 0.087801844 <a title="39-tfidf-12" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>13 0.085574225 <a title="39-tfidf-13" href="./emnlp-2013-Improving_Statistical_Machine_Translation_with_Word_Class_Models.html">104 emnlp-2013-Improving Statistical Machine Translation with Word Class Models</a></p>
<p>14 0.084581964 <a title="39-tfidf-14" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>15 0.083580755 <a title="39-tfidf-15" href="./emnlp-2013-A_Systematic_Exploration_of_Diversity_in_Machine_Translation.html">15 emnlp-2013-A Systematic Exploration of Diversity in Machine Translation</a></p>
<p>16 0.083206274 <a title="39-tfidf-16" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>17 0.08175189 <a title="39-tfidf-17" href="./emnlp-2013-Improving_Pivot-Based_Statistical_Machine_Translation_Using_Random_Walk.html">103 emnlp-2013-Improving Pivot-Based Statistical Machine Translation Using Random Walk</a></p>
<p>18 0.077740505 <a title="39-tfidf-18" href="./emnlp-2013-Anchor_Graph%3A_Global_Reordering_Contexts_for_Statistical_Machine_Translation.html">22 emnlp-2013-Anchor Graph: Global Reordering Contexts for Statistical Machine Translation</a></p>
<p>19 0.07725887 <a title="39-tfidf-19" href="./emnlp-2013-Building_Specialized_Bilingual_Lexicons_Using_Large_Scale_Background_Knowledge.html">42 emnlp-2013-Building Specialized Bilingual Lexicons Using Large Scale Background Knowledge</a></p>
<p>20 0.075480096 <a title="39-tfidf-20" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.229), (1, 0.106), (2, -0.018), (3, 0.008), (4, -0.092), (5, 0.104), (6, 0.046), (7, -0.066), (8, -0.168), (9, -0.038), (10, 0.007), (11, -0.104), (12, 0.146), (13, -0.036), (14, -0.124), (15, 0.154), (16, 0.126), (17, -0.049), (18, 0.098), (19, -0.136), (20, 0.055), (21, -0.07), (22, 0.023), (23, 0.043), (24, -0.006), (25, 0.027), (26, 0.054), (27, -0.038), (28, 0.014), (29, 0.013), (30, -0.026), (31, 0.053), (32, -0.013), (33, -0.075), (34, 0.032), (35, -0.04), (36, 0.012), (37, 0.0), (38, -0.069), (39, -0.1), (40, -0.081), (41, 0.007), (42, -0.035), (43, 0.005), (44, -0.076), (45, 0.118), (46, -0.054), (47, -0.069), (48, -0.026), (49, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92137307 <a title="39-lsi-1" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<p>Author: Artem Sokokov ; Laura Jehl ; Felix Hieber ; Stefan Riezler</p><p>Abstract: We present an approach to learning bilingual n-gram correspondences from relevance rankings of English documents for Japanese queries. We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR). We propose an efficient boosting algorithm that deals with very large cross-product spaces of word correspondences. We show in an experimental evaluation on patent prior art search that our approach, and in particular a consensus-based combination of boosting and translation-based approaches, yields substantial improvements in CLIR performance. Our training and test data are made publicly available.</p><p>2 0.74708003 <a title="39-lsi-2" href="./emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching.html">97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</a></p>
<p>Author: Ahmed Hassan</p><p>Abstract: Web search users frequently modify their queries in hope of receiving better results. This process is referred to as “Query Reformulation”. Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance. In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig- nificantly improve query reformulation performance using features of query concepts.</p><p>3 0.73192066 <a title="39-lsi-3" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>Author: Jerome White ; Douglas W. Oard ; Nitendra Rajput ; Marion Zalk</p><p>Abstract: Building search engines that can respond to spoken queries with spoken content requires that the system not just be able to find useful responses, but also that it know when it has heard enough about what the user wants to be able to do so. This paper describes a simulation study with queries spoken by non-native speakers that suggests that indicates that finding relevant content is often possible within a half minute, and that combining features based on automatically recognized words with features designed for automated prediction of query difficulty can serve as a useful basis for predicting when that useful content has been found.</p><p>4 0.66990435 <a title="39-lsi-4" href="./emnlp-2013-Improving_Web_Search_Ranking_by_Incorporating_Structured_Annotation_of_Queries.html">105 emnlp-2013-Improving Web Search Ranking by Incorporating Structured Annotation of Queries</a></p>
<p>Author: Xiao Ding ; Zhicheng Dou ; Bing Qin ; Ting Liu ; Ji-rong Wen</p><p>Abstract: Web users are increasingly looking for structured data, such as lyrics, job, or recipes, using unstructured queries on the web. However, retrieving relevant results from such data is a challenging problem due to the unstructured language of the web queries. In this paper, we propose a method to improve web search ranking by detecting Structured Annotation of queries based on top search results. In a structured annotation, the original query is split into different units that are associated with semantic attributes in the corresponding domain. We evaluate our techniques using real world queries and achieve significant improvement. . 1</p><p>5 0.58402926 <a title="39-lsi-5" href="./emnlp-2013-Open-Domain_Fine-Grained_Class_Extraction_from_Web_Search_Queries.html">142 emnlp-2013-Open-Domain Fine-Grained Class Extraction from Web Search Queries</a></p>
<p>Author: Marius Pasca</p><p>Abstract: This paper introduces a method for extracting fine-grained class labels ( “countries with double taxation agreements with india ”) from Web search queries. The class labels are more numerous and more diverse than those produced by current extraction methods. Also extracted are representative sets of instances (singapore, united kingdom) for the class labels.</p><p>6 0.56915027 <a title="39-lsi-6" href="./emnlp-2013-Identifying_Multiple_Userids_of_the_Same_Author.html">95 emnlp-2013-Identifying Multiple Userids of the Same Author</a></p>
<p>7 0.53691828 <a title="39-lsi-7" href="./emnlp-2013-An_Efficient_Language_Model_Using_Double-Array_Structures.html">20 emnlp-2013-An Efficient Language Model Using Double-Array Structures</a></p>
<p>8 0.47216487 <a title="39-lsi-8" href="./emnlp-2013-Orthonormal_Explicit_Topic_Analysis_for_Cross-Lingual_Document_Matching.html">148 emnlp-2013-Orthonormal Explicit Topic Analysis for Cross-Lingual Document Matching</a></p>
<p>9 0.47160807 <a title="39-lsi-9" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>10 0.46610576 <a title="39-lsi-10" href="./emnlp-2013-Converting_Continuous-Space_Language_Models_into_N-Gram_Language_Models_for_Statistical_Machine_Translation.html">52 emnlp-2013-Converting Continuous-Space Language Models into N-Gram Language Models for Statistical Machine Translation</a></p>
<p>11 0.46105739 <a title="39-lsi-11" href="./emnlp-2013-Noise-Aware_Character_Alignment_for_Bootstrapping_Statistical_Machine_Transliteration_from_Bilingual_Corpora.html">139 emnlp-2013-Noise-Aware Character Alignment for Bootstrapping Statistical Machine Transliteration from Bilingual Corpora</a></p>
<p>12 0.45558619 <a title="39-lsi-12" href="./emnlp-2013-A_Study_on_Bootstrapping_Bilingual_Vector_Spaces_from_Non-Parallel_Data_%28and_Nothing_Else%29.html">13 emnlp-2013-A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data (and Nothing Else)</a></p>
<p>13 0.45351055 <a title="39-lsi-13" href="./emnlp-2013-Monolingual_Marginal_Matching_for_Translation_Model_Adaptation.html">135 emnlp-2013-Monolingual Marginal Matching for Translation Model Adaptation</a></p>
<p>14 0.42827004 <a title="39-lsi-14" href="./emnlp-2013-Building_Specialized_Bilingual_Lexicons_Using_Large_Scale_Background_Knowledge.html">42 emnlp-2013-Building Specialized Bilingual Lexicons Using Large Scale Background Knowledge</a></p>
<p>15 0.41672379 <a title="39-lsi-15" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>16 0.40960914 <a title="39-lsi-16" href="./emnlp-2013-Improving_Statistical_Machine_Translation_with_Word_Class_Models.html">104 emnlp-2013-Improving Statistical Machine Translation with Word Class Models</a></p>
<p>17 0.40502506 <a title="39-lsi-17" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>18 0.40314645 <a title="39-lsi-18" href="./emnlp-2013-Bilingual_Word_Embeddings_for_Phrase-Based_Machine_Translation.html">38 emnlp-2013-Bilingual Word Embeddings for Phrase-Based Machine Translation</a></p>
<p>19 0.39860037 <a title="39-lsi-19" href="./emnlp-2013-Improving_Pivot-Based_Statistical_Machine_Translation_Using_Random_Walk.html">103 emnlp-2013-Improving Pivot-Based Statistical Machine Translation Using Random Walk</a></p>
<p>20 0.38608837 <a title="39-lsi-20" href="./emnlp-2013-A_Systematic_Exploration_of_Diversity_in_Machine_Translation.html">15 emnlp-2013-A Systematic Exploration of Diversity in Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.28), (11, 0.029), (23, 0.065), (24, 0.026), (25, 0.048), (29, 0.041), (47, 0.057), (51, 0.045), (65, 0.092), (69, 0.048), (73, 0.118), (79, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70114338 <a title="39-lda-1" href="./emnlp-2013-Boosting_Cross-Language_Retrieval_by_Learning_Bilingual_Phrase_Associations_from_Relevance_Rankings.html">39 emnlp-2013-Boosting Cross-Language Retrieval by Learning Bilingual Phrase Associations from Relevance Rankings</a></p>
<p>Author: Artem Sokokov ; Laura Jehl ; Felix Hieber ; Stefan Riezler</p><p>Abstract: We present an approach to learning bilingual n-gram correspondences from relevance rankings of English documents for Japanese queries. We show that directly optimizing cross-lingual rankings rivals and complements machine translation-based cross-language information retrieval (CLIR). We propose an efficient boosting algorithm that deals with very large cross-product spaces of word correspondences. We show in an experimental evaluation on patent prior art search that our approach, and in particular a consensus-based combination of boosting and translation-based approaches, yields substantial improvements in CLIR performance. Our training and test data are made publicly available.</p><p>2 0.66343445 <a title="39-lda-2" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>Author: Filipe Mesquita ; Jordan Schmidek ; Denilson Barbosa</p><p>Abstract: A large number of Open Relation Extraction approaches have been proposed recently, covering a wide range of NLP machinery, from “shallow” (e.g., part-of-speech tagging) to “deep” (e.g., semantic role labeling–SRL). A natural question then is what is the tradeoff between NLP depth (and associated computational cost) versus effectiveness. This paper presents a fair and objective experimental comparison of 8 state-of-the-art approaches over 5 different datasets, and sheds some light on the issue. The paper also describes a novel method, EXEMPLAR, which adapts ideas from SRL to less costly NLP machinery, resulting in substantial gains both in efficiency and effectiveness, over binary and n-ary relation extraction tasks.</p><p>3 0.5440259 <a title="39-lda-3" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>Author: Qiming Diao ; Jing Jiang</p><p>Abstract: With the rapid growth of social media, Twitter has become one of the most widely adopted platforms for people to post short and instant message. On the one hand, people tweets about their daily lives, and on the other hand, when major events happen, people also follow and tweet about them. Moreover, people’s posting behaviors on events are often closely tied to their personal interests. In this paper, we try to model topics, events and users on Twitter in a unified way. We propose a model which combines an LDA-like topic model and the Recurrent Chinese Restaurant Process to capture topics and events. We further propose a duration-based regularization component to find bursty events. We also propose to use event-topic affinity vectors to model the asso- . ciation between events and topics. Our experiments shows that our model can accurately identify meaningful events and the event-topic affinity vectors are effective for event recommendation and grouping events by topics.</p><p>4 0.54308534 <a title="39-lda-4" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>5 0.53938824 <a title="39-lda-5" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>Author: Xiao Cheng ; Dan Roth</p><p>Abstract: Wikification, commonly referred to as Disambiguation to Wikipedia (D2W), is the task of identifying concepts and entities in text and disambiguating them into the most specific corresponding Wikipedia pages. Previous approaches to D2W focused on the use of local and global statistics over the given text, Wikipedia articles and its link structures, to evaluate context compatibility among a list of probable candidates. However, these methods fail (often, embarrassingly), when some level of text understanding is needed to support Wikification. In this paper we introduce a novel approach to Wikification by incorporating, along with statistical methods, richer relational analysis of the text. We provide an extensible, efficient and modular Integer Linear Programming (ILP) formulation of Wikification that incorporates the entity-relation inference problem, and show that the ability to identify relations in text helps both candi- date generation and ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task.</p><p>6 0.53837383 <a title="39-lda-6" href="./emnlp-2013-Max-Margin_Synchronous_Grammar_Induction_for_Machine_Translation.html">127 emnlp-2013-Max-Margin Synchronous Grammar Induction for Machine Translation</a></p>
<p>7 0.53811646 <a title="39-lda-7" href="./emnlp-2013-Structured_Penalties_for_Log-Linear_Language_Models.html">176 emnlp-2013-Structured Penalties for Log-Linear Language Models</a></p>
<p>8 0.53676414 <a title="39-lda-8" href="./emnlp-2013-Translation_with_Source_Constituency_and_Dependency_Trees.html">187 emnlp-2013-Translation with Source Constituency and Dependency Trees</a></p>
<p>9 0.53543353 <a title="39-lda-9" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>10 0.5347544 <a title="39-lda-10" href="./emnlp-2013-Dynamic_Feature_Selection_for_Dependency_Parsing.html">66 emnlp-2013-Dynamic Feature Selection for Dependency Parsing</a></p>
<p>11 0.53359592 <a title="39-lda-11" href="./emnlp-2013-Regularized_Minimum_Error_Rate_Training.html">159 emnlp-2013-Regularized Minimum Error Rate Training</a></p>
<p>12 0.53295362 <a title="39-lda-12" href="./emnlp-2013-Scaling_Semantic_Parsers_with_On-the-Fly_Ontology_Matching.html">164 emnlp-2013-Scaling Semantic Parsers with On-the-Fly Ontology Matching</a></p>
<p>13 0.53219372 <a title="39-lda-13" href="./emnlp-2013-Optimal_Beam_Search_for_Machine_Translation.html">145 emnlp-2013-Optimal Beam Search for Machine Translation</a></p>
<p>14 0.53142548 <a title="39-lda-14" href="./emnlp-2013-Combining_PCFG-LA_Models_with_Dual_Decomposition%3A_A_Case_Study_with_Function_Labels_and_Binarization.html">50 emnlp-2013-Combining PCFG-LA Models with Dual Decomposition: A Case Study with Function Labels and Binarization</a></p>
<p>15 0.53111267 <a title="39-lda-15" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>16 0.5310939 <a title="39-lda-16" href="./emnlp-2013-Centering_Similarity_Measures_to_Reduce_Hubs.html">44 emnlp-2013-Centering Similarity Measures to Reduce Hubs</a></p>
<p>17 0.52975166 <a title="39-lda-17" href="./emnlp-2013-Russian_Stress_Prediction_using_Maximum_Entropy_Ranking.html">162 emnlp-2013-Russian Stress Prediction using Maximum Entropy Ranking</a></p>
<p>18 0.52949041 <a title="39-lda-18" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>19 0.52948356 <a title="39-lda-19" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>20 0.52804142 <a title="39-lda-20" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
