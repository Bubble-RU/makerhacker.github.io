<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-197" href="#">emnlp2013-197</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</h1>
<br/><p>Source: <a title="emnlp-2013-197-pdf" href="http://aclweb.org/anthology//D/D13/D13-1076.pdf">pdf</a></p><p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>Reference: <a title="emnlp-2013-197-reference" href="../emnlp2013_reference/emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 clai re gardent @ l ori a fr Abstract This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. [sent-3, score-0.655]
</p><p>2 The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode. [sent-4, score-0.121]
</p><p>3 1 Introduction One strand of work in dialog research targets the rapid prototyping of virtual humans capable of conducting a conversation with humans in the context of a virtual world. [sent-5, score-0.667]
</p><p>4 In particular, question answering (QA) characters can respond to a restricted set of topics after training on a set of dialogs whose utter-  ances are annotated with dialogue acts (Leuski and Traum, 2008). [sent-6, score-0.306]
</p><p>5 , 2009), the size of the training corpus is a major factor in allowing QA characters that are both robust and accurate. [sent-8, score-0.062]
</p><p>6 In addition, the training corpus should arguably be of good quality in that (i) it should contain the various ways of expressing the same content (paraphrases) and (ii) the data should not be skewed. [sent-9, score-0.097]
</p><p>7 In sum, the ideal training data should be large (more data is better data) ; balanced (similar amount of data for each class targeted by the classifier) and varied (it should encompass the largest possible number of paraphrases and synonyms for the utterances of each class). [sent-10, score-0.572]
</p><p>8 In this paper, we explore different ways of improving and complementing the training data of a 808 Lina M. [sent-11, score-0.033]
</p><p>9 We expand the size and  the quality (less skewed data) of the training corpus using paraphrase generation techniques. [sent-15, score-0.091]
</p><p>10 And we investigate how various resources (synonym dictionaries, WordNet, distributional neighbours) can be used to handle unseen words at run time. [sent-18, score-0.161]
</p><p>11 2  Related work  Previous work on improving robustness of supervised dialog systems includes detecting and handling out of domain utterances for generating feedback (Lane et al. [sent-19, score-0.669]
</p><p>12 , 2004) ; using domain-restricted lexical semantics (Hardy et al. [sent-20, score-0.073]
</p><p>13 , 2004) ; and work on manual data expansion (DeVault et al. [sent-21, score-0.094]
</p><p>14 Our work follows up on this research but provides a systematic investigation of how data expansion, lemmatisation and synonym handling impacts the performance of a supervised QA engine. [sent-23, score-0.894]
</p><p>15 3  Experimental Setup We run our experiments on a dialog engine developed for a serious game called Mission Plastechnologie. [sent-24, score-0.481]
</p><p>16 In this game, the player must interact with  different virtual humans through a sequence of 12 subdialogs, each ofthem occurring in a different part of the virtual world. [sent-25, score-0.303]
</p><p>17 The training corpus consists of around 1250 Human-Human dialogues which were manually annotated with dialog moves. [sent-27, score-0.501]
</p><p>18 As the following dialog excerpt illustrates, the dialogs are conducted in French and each dialog turn is manually annotated using a set of 28 dialog acts. [sent-28, score-1.218]
</p><p>19 hc o2d0s1 i3n A Nsastoucriaalti Loann fgoura Cgoem Ppruotcaetsiosinnagl, L pianggeusis 8t0ic8s–813,  a more detailed presentation  of the training corpus  and of the annotation scheme, the reader is referred to (Rojas-Barahona et al. [sent-31, score-0.062]
</p><p>20 , 2012a) dialog : 01_dialogDirecteur-Tue Jun 14 11 :04 :23 2011 >M. [sent-32, score-0.379]
</p><p>21 Jasper : Pour faire votre manette, il vous faut des plans. [sent-41, score-0.108]
</p><p>22 || inform(do(first_step)) (To build the joystick you will need the plans. [sent-43, score-0.054]
</p><p>23 )  Dialog Systems For our experiments, we use a hybrid dialog system similar to that described in (Rojas Barahona et al. [sent-48, score-0.379]
</p><p>24 This system combines a classifier for interpreting the players utterances with an information state dialog manager which selects an appropriate system response based on the dialog move assigned by the classifier to the user turn. [sent-50, score-1.009]
</p><p>25 The classifier is a logistic regression classifier 1 which was trained for each subdialog in the game. [sent-51, score-0.116]
</p><p>26 The features used for training are the set of content words which are associated with a given dialog move and which remain after TF*IDF 2 filtering. [sent-52, score-0.479]
</p><p>27 Note that in this experiment, we do not use contextual features such as the dialog acts labeling the previous turns. [sent-53, score-0.467]
</p><p>28 First, we want to focus on the impact of synonym handling, paraphrasing and lemmatisation on dialog management. [sent-55, score-1.227]
</p><p>29 Removing contextual features allows us to focus on how content features (content words) can be improved by these mechanisms. [sent-56, score-0.066]
</p><p>30 Second, when evaluating on the H-C corpus (see below), contextual features are often incorrect (because the system might incorrectly interpret and thus label a user turn). [sent-57, score-0.12]
</p><p>31 Excluding contextual features from training allows for a fair comparison between the H-H and the H-C evaluation. [sent-58, score-0.064]
</p><p>32 On the other hand, we report accuracy on a corpus of 550 Human-Computer (H-C) dialogues obtained by having 22 subjects play the game against the QA character trained on the H-H corpus. [sent-64, score-0.166]
</p><p>33 As we shall see below, performance decreases in this second evaluation suggesting that subjects produce different turns when playing with a computer than with a human thereby inducing a weak out-of-domain effect and negatively impacting classification. [sent-65, score-0.132]
</p><p>34 Evaluation on the H-H corpus therefore gives a measure of how well the techniques explored help improving the dialog engine when used in a real life setting. [sent-66, score-0.408]
</p><p>35 Conversely, in the H-C evaluation, training (H-H data) and test (H-C data) sets were collected under different conditions with different subjects therefore significance was computed using the McNemar sign-test (Dietterich, 1998). [sent-70, score-0.068]
</p><p>36 Lemmatisation We use the French version of Treetagger to lemmatise both the training and the test data. [sent-72, score-0.033]
</p><p>37 As we shall see, the lemma and the POS tag provided by TreeTagger are also used to lookup synonym dictionaries and EuroWordNet when using synonym handling at run time. [sent-79, score-1.123]
</p><p>38 , 2011) showed that enriching the training corpus with manually added paraphrases increases accuracy. [sent-81, score-0.418]
</p><p>39 Here we exploit automatically acquired paraphrases and use these not only to increase the size of the training corpus but also to better balance it4. [sent-82, score-0.417]
</p><p>40 First, we generated paraphrases using a pivot machine translation approach where each user utterance in the training corpus (around 3610 utterances) was translated into some target language and back into French. [sent-84, score-0.464]
</p><p>41 The category with lowest number of paraphrases is greet, with 62 paraphrases, hence lp = 62. [sent-88, score-0.38]
</p><p>42 Second, we eliminate from these paraphrases, words that are likely to be incorrect lexical translations by removing words with low normalized term 4. [sent-90, score-0.073]
</p><p>43 The Emospeech data is highly skewed with some classes being populated with many utterances and others with few. [sent-91, score-0.155]
</p><p>44 810  FIGURE 1: Algorithm for augmenting the training data with paraphrases. [sent-92, score-0.06]
</p><p>45 , lexical  µ  translations given by few translations and/or translation systems. [sent-96, score-0.105]
</p><p>46 We then preprocessed the paraphrases in the same way the utterances of the initial training corpus were preprocessed i. [sent-97, score-0.583]
</p><p>47 , utterances were unaccented, converted to lower-case and stop words were removed, the remaining words were filtered with TF*IDF. [sent-99, score-0.126]
</p><p>48 Third, we added the paraphrases to the training data seeking to improve the balance between dialog moves per dialog, as shown in Figure 1. [sent-101, score-0.741]
</p><p>49 To this end, we look for the category c with the lowest number of paraphrases lp (line 5). [sent-102, score-0.38]
</p><p>50 We then compute the deviation di for each dialog move ci from the mean in the original training set (line 9). [sent-103, score-0.525]
</p><p>51 If the deviation di is lower than the standard deviation then we add lp number of paraphrases instances (line 11). [sent-104, score-0.514]
</p><p>52 In this dialogue the player is supposed to ask information about the joystick plans (find_plans, which is the mandatory goal). [sent-107, score-0.29]
</p><p>53 l2p  The categories cover mandatory and optional goals and general dialogue acts, such as greetings, asking for help, confirm and disconfirm, acknowledgment and out of topic questions (i. [sent-108, score-0.189]
</p><p>54 When an unknown word w is detected in a player utterance at runtime, we search for a word w0 which occurs in the training data and is either a synonym of w or a distributional neighbour. [sent-113, score-0.701]
</p><p>55 After disambiguation, we substitute the unknown word for the synonym. [sent-114, score-0.11]
</p><p>56 To identify synonyms, we make use of two lexical resources namely, the French version of EuroWordNet (EWN) (Vossen, 1998), which includes 92833 synonyms, hyperonyms and hyponyms pairs, and a synonym lexicon for French (DIC) 6 which contains 38505 lemmas and 254149 synonym pairs. [sent-115, score-0.941]
</p><p>57 To identify distributional neighbours, we con-  structed semantic word spaces for each subdialog in the EmoSpeech corpus 7 using random indexing (RI) 8 on the training corpus expanded with paraphrases. [sent-117, score-0.199]
</p><p>58 Using the cosine measure as similarity metrics, we then retrieve for any unknown word w, the word w0 which is most similar to w and which appear in the training corpus. [sent-118, score-0.143]
</p><p>59 Or we pick the synonym with highest probability based on a trigram language model trained on the H-H corpus9. [sent-122, score-0.415]
</p><p>60 5  Results and Discussion  Table 2 summarises the results obtained in four main configurations : (i) with and without paraphrases ; (ii) with and without synonym handling ; (iii) with and without lemmatisation ; and (iv) when 5. [sent-123, score-1.223]
</p><p>61 We also used distributional semantics from the Gigaword corpus but the results were poor probably because of the very  different text genre and domains between the the Gigaword and the MP game. [sent-130, score-0.115]
</p><p>62 Topics are Dialog acts while documents are utterances ; we used the S-Space Package http : / / code . [sent-132, score-0.209]
</p><p>63 com/  pro j ect s / s rilm)  811 combining lemmatisation with synonym handling. [sent-138, score-0.756]
</p><p>64 We also compare the results obtained when evaluating using 10-fold cross validation on the training data (H-H dialogs) vs. [sent-139, score-0.062]
</p><p>65 Overall Impact The largest performance gain is obtained by a combination of the three techniques explored in this paper namely, data expansion, synonym handling and lemmatisation (+8. [sent-141, score-0.923]
</p><p>66 Impact of Lexical Substitution at Run Time Because of space restrictions, we do not report here the results obtained using lexical resources without lemmatisation. [sent-144, score-0.081]
</p><p>67 However, we found that lexical resources are only useful when combined with lemmatisation. [sent-145, score-0.081]
</p><p>68 This is unsurprising since synonym dictio-  naries and EuroWordNet only contain lemmas. [sent-146, score-0.415]
</p><p>69 Indeed when distributional neighbours are used, lemmatisation has little impact (e. [sent-147, score-0.562]
</p><p>70 1 1% using distributional neighbours without lemmatisation on the H-H corpus without paraphrases vs. [sent-150, score-0.828]
</p><p>71 Another important issue when searching for a word synonym concerns lexical disambiguation : the synonym used to replace an unknown word should capture the meaning of that word in its given context. [sent-153, score-1.02]
</p><p>72 We tried using a language model trained on the training corpus to choose between synonym candidates (i. [sent-154, score-0.477]
</p><p>73 , selecting the synonym yielding the highest sentence probability when substituting that synonym for the unknown word) but did not obtain a significant improvement. [sent-156, score-0.987]
</p><p>74 In contrast, it is noticeable that synonym handling has a higher impact when using EuroWordNet as a lexical resource. [sent-157, score-0.686]
</p><p>75 Since EuroWordNet contain categorial information while the synonym dictionaries we used do not, this suggests that the categorial disambiguation provided by TreeTagger helps identifying an appropriate synonym in EuroWordNet. [sent-158, score-0.973]
</p><p>76 Finally, it is clear that the lexical resources used  for this experiment are limited in coverage and quality. [sent-159, score-0.081]
</p><p>77 We observed in particular that some words which are very frequent in the training data (and thus which could be used to replace unknown words) do not occur in the synonym dictionaries. [sent-160, score-0.558]
</p><p>78 For instance when using paraphrases and dictionaries (fourth row and  (p  < 0. [sent-161, score-0.369]
</p><p>79 fourth column in Table 2) 50% of the unknown words were solved, 17% were illformed and 33% remained unsolved. [sent-164, score-0.144]
</p><p>80 To compensate this deficiency, we tried combining the three lexical resources in various ways (taking the union or combining them in a pipeline using the first resource that would yield a synonym). [sent-165, score-0.081]
</p><p>81 However the results did not improve and even in some cases worsened due probably to the insufficient lexical disambiguation. [sent-166, score-0.041]
</p><p>82 Interestingly, the results show that paraphrases always improves synonym handling presumably because it increases the size of the known vocabulary thereby increasing the possibility of finding a known synonym. [sent-167, score-0.999]
</p><p>83 In sum, synonym handling helps most when (i) words are lemmatised and (ii) unknown words can be at least partially (i. [sent-168, score-0.744]
</p><p>84 Moreover since data expansion increases the set of known words available as potential synonyms for unknown words, combining synonym handling with data expansion further improves accuracy. [sent-171, score-0.99]
</p><p>85 Impact ofLemmatisation When evaluating using cross validation on the training corpus, lemmatisation increases accuracy by up to 3. [sent-172, score-0.43]
</p><p>86 42 points indicating that unseen word forms negatively impact accuracy. [sent-173, score-0.161]
</p><p>87 Noticeably however, lemmatisation has no significant impact when evaluating on the H-C corpus. [sent-174, score-0.462]
</p><p>88 This in turn suggests that the lower accuracy obtained on the H-C corpus results not from unseen word forms but from unseen lemmas. [sent-175, score-0.101]
</p><p>89 Impact of Paraphrases On the H-H corpus, data expansion has no significant impact when used alone. [sent-176, score-0.186]
</p><p>90 Thus, data expansion is best used in combination  812 with lemmatisation and their combination permits creating better, more balanced and more general training data. [sent-179, score-0.56]
</p><p>91 On the H-C corpus however, the impact is negative or insignificant suggesting that the decrease in performance on the H-C corpus is due to content words that are new with respect to the training data i. [sent-180, score-0.218]
</p><p>92 , content words for which neither a synonym nor a lemma can be found in the expanded training data. [sent-182, score-0.508]
</p><p>93 Conclusion While classifiers are routinely trained on dialog data to model the dialog management process, the impact of such basic factors as lemmatisation, automatic data expansion and synonym handling has remained largely unexplored. [sent-183, score-1.531]
</p><p>94 The empirical evaluation described here suggests that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode. [sent-184, score-0.121]
</p><p>95 First, syn-  onym handling is best used in combination with POS tagging and lemmatisation because these supports partial lexical semantic disambiguation. [sent-187, score-0.549]
</p><p>96 Second, data expansion permits expanding the set of known words thereby increasing the possibility of finding a known synonym to replace an unknown word with. [sent-188, score-0.743]
</p><p>97 Example-based training of dialogue planning incorporating user and situation models. [sent-208, score-0.199]
</p><p>98 A statistical approach for text processing in virtual humans. [sent-212, score-0.112]
</p><p>99 Building and exploiting a corpus of dialog interactions between french speaking virtual and human agents. [sent-234, score-0.607]
</p><p>100 Towards natural language understanding of partial speech recognition results in dialogue systems. [sent-249, score-0.135]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('synonym', 0.415), ('dialog', 0.379), ('lemmatisation', 0.341), ('paraphrases', 0.329), ('eurowordnet', 0.161), ('handling', 0.138), ('dialogue', 0.135), ('barahona', 0.134), ('emospeech', 0.134), ('rojas', 0.134), ('utterances', 0.126), ('virtual', 0.112), ('unknown', 0.11), ('lina', 0.108), ('expansion', 0.094), ('impact', 0.092), ('french', 0.087), ('synonyms', 0.084), ('devault', 0.081), ('dialogs', 0.081), ('lemmatised', 0.081), ('treetagger', 0.079), ('qa', 0.076), ('neighbours', 0.075), ('gardent', 0.064), ('dialogues', 0.06), ('acts', 0.057), ('distributional', 0.054), ('alejandra', 0.054), ('dic', 0.054), ('ewn', 0.054), ('faire', 0.054), ('greet', 0.054), ('hardy', 0.054), ('joystick', 0.054), ('mandatory', 0.054), ('subdialog', 0.054), ('vous', 0.054), ('deviation', 0.053), ('je', 0.051), ('lp', 0.051), ('claire', 0.049), ('conversely', 0.047), ('substituting', 0.047), ('player', 0.047), ('leuski', 0.047), ('lefff', 0.047), ('lorenzo', 0.047), ('vossen', 0.047), ('mallet', 0.047), ('lane', 0.043), ('testset', 0.043), ('utterance', 0.042), ('game', 0.042), ('lexical', 0.041), ('tf', 0.041), ('dictionaries', 0.04), ('resources', 0.04), ('pour', 0.04), ('disambiguation', 0.039), ('nancy', 0.037), ('situated', 0.037), ('unseen', 0.036), ('content', 0.035), ('subjects', 0.035), ('remained', 0.034), ('permits', 0.034), ('sagae', 0.034), ('thereby', 0.034), ('training', 0.033), ('negatively', 0.033), ('preprocessed', 0.033), ('move', 0.032), ('translations', 0.032), ('humans', 0.032), ('semantics', 0.032), ('categorial', 0.032), ('mcnemar', 0.032), ('classifier', 0.031), ('contextual', 0.031), ('user', 0.031), ('run', 0.031), ('shall', 0.03), ('lemmas', 0.03), ('tag', 0.029), ('combination', 0.029), ('corpus', 0.029), ('serious', 0.029), ('skewed', 0.029), ('evaluating', 0.029), ('di', 0.028), ('known', 0.028), ('idf', 0.028), ('increases', 0.027), ('augmenting', 0.027), ('robustness', 0.026), ('http', 0.026), ('acquired', 0.026), ('pos', 0.026), ('lemma', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="197-tfidf-1" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>2 0.10664304 <a title="197-tfidf-2" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>3 0.087865986 <a title="197-tfidf-3" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>4 0.087863877 <a title="197-tfidf-4" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>Author: Gyorgy Szarvas ; Robert Busa-Fekete ; Eyke Hullermeier</p><p>Abstract: The problem to replace a word with a synonym that fits well in its sentential context is known as the lexical substitution task. In this paper, we tackle this task as a supervised ranking problem. Given a dataset of target words, their sentential contexts and the potential substitutions for the target words, the goal is to train a model that accurately ranks the candidate substitutions based on their contextual fitness. As a key contribution, we customize and evaluate several learning-to-rank models to the lexical substitution task, including classification-based and regression-based approaches. On two datasets widely used for lexical substitution, our best models signifi- cantly advance the state-of-the-art.</p><p>5 0.082432307 <a title="197-tfidf-5" href="./emnlp-2013-A_Generative_Joint%2C_Additive%2C_Sequential_Model_of_Topics_and_Speech_Acts_in_Patient-Doctor_Communication.html">6 emnlp-2013-A Generative Joint, Additive, Sequential Model of Topics and Speech Acts in Patient-Doctor Communication</a></p>
<p>Author: Byron C. Wallace ; Thomas A Trikalinos ; M. Barton Laws ; Ira B. Wilson ; Eugene Charniak</p><p>Abstract: We develop a novel generative model of conversation that jointly captures both the topical content and the speech act type associated with each utterance. Our model expresses both token emission and state transition probabilities as log-linear functions of separate components corresponding to topics and speech acts (and their interactions). We apply this model to a dataset comprising annotated patient-physician visits and show that the proposed joint approach outperforms a baseline univariate model.</p><p>6 0.072245769 <a title="197-tfidf-6" href="./emnlp-2013-Detecting_Compositionality_of_Multi-Word_Expressions_using_Nearest_Neighbours_in_Vector_Space_Models.html">60 emnlp-2013-Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models</a></p>
<p>7 0.071448743 <a title="197-tfidf-7" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>8 0.065005362 <a title="197-tfidf-8" href="./emnlp-2013-Predicting_the_Resolution_of_Referring_Expressions_from_User_Behavior.html">153 emnlp-2013-Predicting the Resolution of Referring Expressions from User Behavior</a></p>
<p>9 0.05245059 <a title="197-tfidf-9" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>10 0.050704252 <a title="197-tfidf-10" href="./emnlp-2013-Monolingual_Marginal_Matching_for_Translation_Model_Adaptation.html">135 emnlp-2013-Monolingual Marginal Matching for Translation Model Adaptation</a></p>
<p>11 0.045046259 <a title="197-tfidf-11" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>12 0.043790754 <a title="197-tfidf-12" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>13 0.043115944 <a title="197-tfidf-13" href="./emnlp-2013-Improving_Statistical_Machine_Translation_with_Word_Class_Models.html">104 emnlp-2013-Improving Statistical Machine Translation with Word Class Models</a></p>
<p>14 0.039478175 <a title="197-tfidf-14" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>15 0.036783375 <a title="197-tfidf-15" href="./emnlp-2013-Towards_Situated_Dialogue%3A_Revisiting_Referring_Expression_Generation.html">185 emnlp-2013-Towards Situated Dialogue: Revisiting Referring Expression Generation</a></p>
<p>16 0.036114376 <a title="197-tfidf-16" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>17 0.035771724 <a title="197-tfidf-17" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>18 0.035552081 <a title="197-tfidf-18" href="./emnlp-2013-Appropriately_Incorporating_Statistical_Significance_in_PMI.html">25 emnlp-2013-Appropriately Incorporating Statistical Significance in PMI</a></p>
<p>19 0.035364076 <a title="197-tfidf-19" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>20 0.035120875 <a title="197-tfidf-20" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.138), (1, 0.005), (2, -0.036), (3, -0.007), (4, -0.041), (5, 0.044), (6, -0.016), (7, 0.027), (8, -0.048), (9, -0.072), (10, 0.002), (11, 0.06), (12, 0.029), (13, 0.067), (14, 0.054), (15, 0.036), (16, 0.0), (17, 0.033), (18, -0.029), (19, 0.097), (20, 0.096), (21, 0.058), (22, 0.039), (23, 0.032), (24, 0.089), (25, -0.056), (26, -0.021), (27, -0.087), (28, -0.147), (29, 0.151), (30, 0.077), (31, 0.153), (32, 0.117), (33, 0.042), (34, 0.135), (35, -0.068), (36, -0.016), (37, -0.124), (38, -0.186), (39, -0.115), (40, -0.072), (41, -0.183), (42, -0.115), (43, -0.008), (44, 0.007), (45, -0.038), (46, -0.064), (47, -0.057), (48, -0.064), (49, -0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94652492 <a title="197-lsi-1" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>2 0.78199542 <a title="197-lsi-2" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>3 0.48749006 <a title="197-lsi-3" href="./emnlp-2013-A_Generative_Joint%2C_Additive%2C_Sequential_Model_of_Topics_and_Speech_Acts_in_Patient-Doctor_Communication.html">6 emnlp-2013-A Generative Joint, Additive, Sequential Model of Topics and Speech Acts in Patient-Doctor Communication</a></p>
<p>Author: Byron C. Wallace ; Thomas A Trikalinos ; M. Barton Laws ; Ira B. Wilson ; Eugene Charniak</p><p>Abstract: We develop a novel generative model of conversation that jointly captures both the topical content and the speech act type associated with each utterance. Our model expresses both token emission and state transition probabilities as log-linear functions of separate components corresponding to topics and speech acts (and their interactions). We apply this model to a dataset comprising annotated patient-physician visits and show that the proposed joint approach outperforms a baseline univariate model.</p><p>4 0.48223397 <a title="197-lsi-4" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>Author: Gyorgy Szarvas ; Robert Busa-Fekete ; Eyke Hullermeier</p><p>Abstract: The problem to replace a word with a synonym that fits well in its sentential context is known as the lexical substitution task. In this paper, we tackle this task as a supervised ranking problem. Given a dataset of target words, their sentential contexts and the potential substitutions for the target words, the goal is to train a model that accurately ranks the candidate substitutions based on their contextual fitness. As a key contribution, we customize and evaluate several learning-to-rank models to the lexical substitution task, including classification-based and regression-based approaches. On two datasets widely used for lexical substitution, our best models signifi- cantly advance the state-of-the-art.</p><p>5 0.46127403 <a title="197-lsi-5" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>Author: Yangfeng Ji ; Jacob Eisenstein</p><p>Abstract: Matrix and tensor factorization have been applied to a number of semantic relatedness tasks, including paraphrase identification. The key idea is that similarity in the latent space implies semantic relatedness. We describe three ways in which labeled data can improve the accuracy of these approaches on paraphrase classification. First, we design a new discriminative term-weighting metric called TF-KLD, which outperforms TF-IDF. Next, we show that using the latent representation from matrix factorization as features in a classification algorithm substantially improves accuracy. Finally, we combine latent features with fine-grained n-gram overlap features, yielding performance that is 3% more accurate than the prior state-of-the-art.</p><p>6 0.42843664 <a title="197-lsi-6" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>7 0.42185891 <a title="197-lsi-7" href="./emnlp-2013-Scaling_to_Large3_Data%3A_An_Efficient_and_Effective_Method_to_Compute_Distributional_Thesauri.html">165 emnlp-2013-Scaling to Large3 Data: An Efficient and Effective Method to Compute Distributional Thesauri</a></p>
<p>8 0.41292128 <a title="197-lsi-8" href="./emnlp-2013-Predicting_the_Resolution_of_Referring_Expressions_from_User_Behavior.html">153 emnlp-2013-Predicting the Resolution of Referring Expressions from User Behavior</a></p>
<p>9 0.33335188 <a title="197-lsi-9" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>10 0.30950379 <a title="197-lsi-10" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>11 0.28898862 <a title="197-lsi-11" href="./emnlp-2013-Naive_Bayes_Word_Sense_Induction.html">138 emnlp-2013-Naive Bayes Word Sense Induction</a></p>
<p>12 0.28798944 <a title="197-lsi-12" href="./emnlp-2013-Multi-Relational_Latent_Semantic_Analysis.html">137 emnlp-2013-Multi-Relational Latent Semantic Analysis</a></p>
<p>13 0.26944897 <a title="197-lsi-13" href="./emnlp-2013-Towards_Situated_Dialogue%3A_Revisiting_Referring_Expression_Generation.html">185 emnlp-2013-Towards Situated Dialogue: Revisiting Referring Expression Generation</a></p>
<p>14 0.26902851 <a title="197-lsi-14" href="./emnlp-2013-Detecting_Compositionality_of_Multi-Word_Expressions_using_Nearest_Neighbours_in_Vector_Space_Models.html">60 emnlp-2013-Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models</a></p>
<p>15 0.26556399 <a title="197-lsi-15" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>16 0.26026765 <a title="197-lsi-16" href="./emnlp-2013-Monolingual_Marginal_Matching_for_Translation_Model_Adaptation.html">135 emnlp-2013-Monolingual Marginal Matching for Translation Model Adaptation</a></p>
<p>17 0.25187239 <a title="197-lsi-17" href="./emnlp-2013-Automated_Essay_Scoring_by_Maximizing_Human-Machine_Agreement.html">28 emnlp-2013-Automated Essay Scoring by Maximizing Human-Machine Agreement</a></p>
<p>18 0.24214402 <a title="197-lsi-18" href="./emnlp-2013-Automatically_Classifying_Edit_Categories_in_Wikipedia_Revisions.html">34 emnlp-2013-Automatically Classifying Edit Categories in Wikipedia Revisions</a></p>
<p>19 0.23886885 <a title="197-lsi-19" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>20 0.23773141 <a title="197-lsi-20" href="./emnlp-2013-Animacy_Detection_with_Voting_Models.html">23 emnlp-2013-Animacy Detection with Voting Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.052), (13, 0.34), (18, 0.033), (22, 0.038), (30, 0.067), (50, 0.01), (51, 0.181), (66, 0.04), (71, 0.029), (75, 0.067), (77, 0.035), (90, 0.011), (96, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75172913 <a title="197-lda-1" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>2 0.7046138 <a title="197-lda-2" href="./emnlp-2013-Simple_Customization_of_Recursive_Neural_Networks_for_Semantic_Relation_Classification.html">172 emnlp-2013-Simple Customization of Recursive Neural Networks for Semantic Relation Classification</a></p>
<p>Author: Kazuma Hashimoto ; Makoto Miwa ; Yoshimasa Tsuruoka ; Takashi Chikayama</p><p>Abstract: In this paper, we present a recursive neural network (RNN) model that works on a syntactic tree. Our model differs from previous RNN models in that the model allows for an explicit weighting of important phrases for the target task. We also propose to average parameters in training. Our experimental results on semantic relation classification show that both phrase categories and task-specific weighting significantly improve the prediction accuracy of the model. We also show that averaging the model parameters is effective in stabilizing the learning and improves generalization capacity. The proposed model marks scores competitive with state-of-the-art RNN-based models.</p><p>3 0.53323764 <a title="197-lda-3" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>Author: Xiaoqing Zheng ; Hanyang Chen ; Tianyu Xu</p><p>Abstract: This study explores the feasibility of performing Chinese word segmentation (CWS) and POS tagging by deep learning. We try to avoid task-specific feature engineering, and use deep layers of neural networks to discover relevant features to the tasks. We leverage large-scale unlabeled data to improve internal representation of Chinese characters, and use these improved representations to enhance supervised word segmentation and POS tagging models. Our networks achieved close to state-of-theart performance with minimal computational cost. We also describe a perceptron-style algorithm for training the neural networks, as an alternative to maximum-likelihood method, to speed up the training process and make the learning algorithm easier to be implemented.</p><p>4 0.53252029 <a title="197-lda-4" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>Author: Mike Lewis ; Mark Steedman</p><p>Abstract: Creating a language-independent meaning representation would benefit many crosslingual NLP tasks. We introduce the first unsupervised approach to this problem, learning clusters of semantically equivalent English and French relations between referring expressions, based on their named-entity arguments in large monolingual corpora. The clusters can be used as language-independent semantic relations, by mapping clustered expressions in different languages onto the same relation. Our approach needs no parallel text for training, but outperforms a baseline that uses machine translation on a cross-lingual question answering task. We also show how to use the semantics to improve the accuracy of machine translation, by using it in a simple reranker.</p><p>5 0.53141248 <a title="197-lda-5" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>6 0.52841634 <a title="197-lda-6" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>7 0.52832472 <a title="197-lda-7" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>8 0.52740496 <a title="197-lda-8" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>9 0.52727783 <a title="197-lda-9" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>10 0.52655679 <a title="197-lda-10" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>11 0.52652627 <a title="197-lda-11" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>12 0.52584881 <a title="197-lda-12" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>13 0.52571869 <a title="197-lda-13" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>14 0.52458507 <a title="197-lda-14" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>15 0.52374232 <a title="197-lda-15" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>16 0.52209008 <a title="197-lda-16" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>17 0.52203441 <a title="197-lda-17" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<p>18 0.52170819 <a title="197-lda-18" href="./emnlp-2013-Document_Summarization_via_Guided_Sentence_Compression.html">65 emnlp-2013-Document Summarization via Guided Sentence Compression</a></p>
<p>19 0.5216437 <a title="197-lda-19" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>20 0.52148432 <a title="197-lda-20" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
