<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-170" href="#">emnlp2013-170</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</h1>
<br/><p>Source: <a title="emnlp-2013-170-pdf" href="http://aclweb.org/anthology//D/D13/D13-1125.pdf">pdf</a></p><p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>Reference: <a title="emnlp-2013-170-reference" href="../emnlp2013_reference/emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 a word’s prior polarity) is a challenging task for sentiment analysis. [sent-5, score-0.25]
</p><p>2 In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity  scores. [sent-7, score-0.416]
</p><p>3 Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. [sent-8, score-0.712]
</p><p>4 We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered. [sent-9, score-0.484]
</p><p>5 1 Introduction Many approaches to sentiment analysis make use of lexical resources i. [sent-10, score-0.168]
</p><p>6 lists of positive and negative words often deployed as baselines or as features for other methods (usually machine learning based) for sentiment analysis research (Liu and Zhang, 2012). [sent-12, score-0.232]
</p><p>7 For example, wonderful has a positive connotation prior polarity while horrible has a negative one. [sent-16, score-0.48]
</p><p>8 eu  needing deep semantic analysis or word sense disambiguation to assign an affective score to a word and are domain independent (they are thus less precise but more portable). [sent-20, score-0.166]
</p><p>9 Given that SWN provides polarities scores for each word sense (also called ‘posterior polarities’), it is necessary to derive prior polarities from the posteriors. [sent-22, score-0.715]
</p><p>10 For example, the word cold has a posterior polarity for the meaning “having a low temperature” like in “cold beer” that is different from the one in “cold which refers to “being emotionless”. [sent-23, score-0.487]
</p><p>11 This information must be considered when reconstructing the prior polarity of cold. [sent-24, score-0.384]
</p><p>12 Several formulae to compute prior polarities starting from posterior polarities scores have been used –  –  –  –  person”  in the literature. [sent-25, score-1.162]
</p><p>13 We show that researchers have not paid sufficient attention to this posterior-to-prior polarity issue. [sent-27, score-0.27]
</p><p>14 On top of this, we attempt to outperform the state-of-the-art formula using a learning framework that combines the various formulae together. [sent-29, score-0.503]
</p><p>15 In Section 2 we briefly describe our approach and how it differentiates from similar sentiment analysis tasks. [sent-35, score-0.136]
</p><p>16 Then, in Sections 3 and 4, we present SentiWordNet and overview various posterior-to-prior polarity formulae based on this resource that appeared in the literature (included some new ones we identified as potentially relevant). [sent-36, score-0.781]
</p><p>17 Finally, in the two last sections, we present a series of experiments, both in regression and classification tasks, that give an answer to the aforementioned research questions. [sent-39, score-0.192]
</p><p>18 2  Proposed Approach  In the broad field of Sentiment Analysis we will focus on the specific problem of posterior-to-prior polarity assessment, using both regression and classifi-  cation experiments. [sent-41, score-0.397]
</p><p>19 For the regression task, we tackled the problem of assigning affective scores (along a continuum between -1 and 1) to words using the posterior-to-prior polarity formulae. [sent-43, score-0.544]
</p><p>20 In these experiments we will also use a learning framework which combines the various formulae together. [sent-45, score-0.435]
</p><p>21 the posterior polarities provided by SWN combined in various ways), we can give a better prediction. [sent-48, score-0.322]
</p><p>22 1260 The regression task is harder than binary classification, since we want to assess not only that pretty, beautiful and gorgeous are positive words, but also to define a partial or total order so that gorgeous is more positive than beautiful which, in turn, is more positive than pretty. [sent-49, score-0.268]
</p><p>23 This is fundamental for tasks such as affective modification of existing texts,  where words’ polarity together with their score are necessary for creating multiple graded variations of the original text (Guerini et al. [sent-50, score-0.388]
</p><p>24 Some of the work that addresses the problem of sentiment strength are presented in (Wilson et al. [sent-52, score-0.184]
</p><p>25 , 2010), however, their approach is modeled as a multi-class classification problem (neutral, low, medium or high sentiment) at the sentence level, rather than a regression problem at the word level. [sent-54, score-0.192]
</p><p>26 On the other hand, even if approaches that go beyond pure prior polarities e. [sent-58, score-0.376]
</p><p>27 using word bigram features (Wang and Manning, 2012) are better for sentiment analysis tasks, there are tasks that are intrinsically based on the notion of words’ prior polarity. [sent-60, score-0.25]
</p><p>28 For example Mitsubishi changed the name of one of its SUV for the Spanish market, since the original name Pajero had a very negative prior polarity, as it meant ‘wanker’ in Spanish (Piller, 2003). [sent-64, score-0.163]
</p><p>29 To our knowledge, the only work trying to address the SWN posterior-to-prior polarity issue, comparing some of the approaches appeared in the literature is (Gatti and Guerini, 2012). [sent-65, score-0.3]
</p><p>30 However, in our previous study we only considered a regression framework, we did not use machine learning and we only tested SWN1. [sent-66, score-0.127]
</p><p>31 These scores – automatically assigned starting from a bunch of seed terms – represent the positive and negative valence (or posterior polarity) of the synset and are inherited by  each lemma-PoS in the synset. [sent-70, score-0.302]
</p><p>32 In Table 1, the first 5 senses of cold#a present all possible combinations, included mixed scores (cold#a# 4), where positive and negative valences are assigned to the same sense. [sent-73, score-0.247]
</p><p>33 In –  SWN3 the annotation algorithm used in SWN1 was revised, leading to an increase in the accuracy of posterior polarities over the previous version. [sent-90, score-0.322]
</p><p>34 4  Prior Polarities Formulae  In this section we review the main strategies for computing prior polarities used in previous studies. [sent-91, score-0.376]
</p><p>35 All the proposed approaches try to estimate the prior polarity score from the posterior polarities of all the senses for a single lemma-PoS. [sent-92, score-0.828]
</p><p>36 Given a lemma-PoS with n senses (lemma#P oS #n), every formula f is independently applied to all the Pos ( s ) and Neg ( s ) . [sent-93, score-0.19]
</p><p>37 To obtain a final prior polarity that ranges from -1 to 1, the negative sign is imposed. [sent-97, score-0.433]
</p><p>38 So, considering the first 5 senses of cold#a in Table 1, f(posScore) will be derived from the P os ( s ) values <0. [sent-98, score-0.179]
</p><p>39 Then, the final polarity strength returned will be either fm or fd. [sent-109, score-0.364]
</p><p>40 The formulae (f) we tested are the following: fs. [sent-110, score-0.435]
</p><p>41 It calculates the mean of the positive and negative scores for all the senses of the given  lemma#PoS. [sent-118, score-0.247]
</p><p>42 , 2009), it considers only those senses that have a P os ( s ) greater than or equal to the corresponding Neg ( s ) , and greater than 0 (the stronglyPos set). [sent-124, score-0.179]
</p><p>43 This formula weighs each sense with a geometric series of ratio 1/2. [sent-131, score-0.148]
</p><p>44 The rationale behind this choice is based on the assumption that more frequent senses should bear more “affective weight” than rare senses when computing the prior polarity of a word. [sent-132, score-0.628]
</p><p>45 Similar to the previous one, this formula weighs each lemma with a harmonic series, see for  example (Denecke, 2008). [sent-135, score-0.236]
</p><p>46 On top of these formulae, we implemented some new formulae that were relevant to our task and have not been implemented before. [sent-136, score-0.435]
</p><p>47 These formulae mimic the ones discussed previously, but they are built under a different assumption: that the saliency (Giora, 1997) of a word’s prior polarity might be more related to its posterior polarities score, rather than to sense frequencies. [sent-137, score-1.189]
</p><p>48 Like w1 and w2, but senses are ordered by strength (sorting Pos(s) and Neg ( s ) independently). [sent-151, score-0.17]
</p><p>49 median: return the median of the senses ordered  by polarity score. [sent-157, score-0.424]
</p><p>50 Finally, we implemented two variants of a prior polarity random baseline to asses possible advantages of approaches using SWN: rnd. [sent-159, score-0.384]
</p><p>51 In classification SVMs use the geometric mean to discriminate between the positive and negative classes, while the GP model uses the posterior probability distribution over each class. [sent-176, score-0.221]
</p><p>52 Both frameworks support learning algorithms for regression and classification. [sent-177, score-0.127]
</p><p>53 GP regression models with Gaussian noise are a rare exception where the exact inference with likelihood functions is tractable, see §2 in (Rasmussen and Williams, 2006). [sent-182, score-0.127]
</p><p>54 2) and the linear logistic (lll) and probit regression (prl) likelihood functions are evaluated in classification. [sent-186, score-0.159]
</p><p>55 In our classification experiments we tried all possible combinations of kernels and likelihood functions, while in the regression tests we ranged only on different kernels. [sent-187, score-0.226]
</p><p>56 Since the prior polarities formulae tend to cluster in groups that provide similar re-  sults (Gatti and Guerini, 2012) creating noise for the learner we want to understand whether feature selection approaches can boost the performance of SVMs. [sent-195, score-0.843]
</p><p>57 For this reason, we also test feature selection prior to the SVM training. [sent-196, score-0.146]
</p><p>58 Re-sampling of the training data is performed several times and a Lasso regression model is fit on each sample. [sent-198, score-0.127]
</p><p>59 6  Gold Standards  To assess how well prior polarity formulae perform, a gold standard with word polarities provided by human annotators is needed. [sent-206, score-1.081]
</p><p>60 , 2005) uses a similar binomial annotation for single words; another interesting resource is WordNetAffect (Strapparava and Valitutti, 2004) but it labels words senses and it cannot be used for the prior polarity validation task. [sent-215, score-0.552]
</p><p>61 In the following we describe in detail the two resources we used for our experiments, namely ANEW for the regression experiments and the General Inquirer (GI) for the classification ones. [sent-216, score-0.224]
</p><p>62 no context was provided) this resource represents a human validation of prior polarities scores for the given words, and can be used as a gold standard. [sent-223, score-0.451]
</p><p>63 For this paper we consider the P o s it iv and Negat iv categories (1,915 words the former, 2,291 words the latter, for a total of 4,206 affective words). [sent-232, score-0.176]
</p><p>64 7  Experiments  In order to use the ANEW dataset to measure prior polarities formulae performance, we had to assign a PoS to all the words to obtain the SWN lemma#PoS format. [sent-233, score-0.811]
</p><p>65 , 2008) and check if the lemma is present instead5. [sent-235, score-0.136]
</p><p>66 Note that a lemma can have more than one PoS, for example, writer is present only as a noun (writ er#n), while yellow is present as a verb, a noun and an adjective (yel low#v, yel low#n, ye l low#a). [sent-240, score-0.168]
</p><p>67 For each lemma#PoS in GI and ANEW, we then applied the prior polarity formulae described in Section 4, using both SWN1 and SWN3 and annotated the results. [sent-250, score-0.819]
</p><p>68 According to the nature of the human labels (real numbers or -1/1), we ran several regression and classification experiments. [sent-251, score-0.192]
</p><p>69 To evaluate the performance of our regression experiments on ANEW we used the Mean Absolute Error (MAE), that averages the error over a given test set. [sent-256, score-0.127]
</p><p>70 In the following sections, to check if there was a statisti-  –  –  cally significant difference in the results, we used Student’s t-test for regression experiments, while an approximate randomization test (Yeh, 2000) was used for the classification experiments. [sent-260, score-0.192]
</p><p>71 In Tables 2 and 3, the results of regression experiments over the ANEW dataset, using SWN1 and SWN3, are presented. [sent-261, score-0.127]
</p><p>72 Note that for classification we report the generics f and not the fm and fd variants. [sent-264, score-0.162]
</p><p>73 So, using SWN for posteriorto-prior polarity computation brings benefits, since it increases the performance above the baseline in words’ prior polarity assessment. [sent-270, score-0.654]
</p><p>74 The formulae described in Section 4 have very different results,  along a continuum. [sent-285, score-0.435]
</p><p>75 Furthermore, the new formulae we introduced, based on the “posterior polarities saliency” hypothesis, proved to be among the best performing in all experiments. [sent-289, score-0.735]
</p><p>76 This entails that there is room for inspecting new formulae variants other than those already proposed in the literature. [sent-290, score-0.435]
</p><p>77 On a side note, the approaches that rely on only one sense polarity (namely fs, median and max) have similar results which do not differ significantly from swnrnd (for maxm, fsd and fsm in Table 2, and for maxm in Table 3). [sent-292, score-0.495]
</p><p>78 001); in Ta-  1266  ble 3, fs, max and median in both their fm and fd variants are significantly different from the best performing w2nm (p < 0. [sent-295, score-0.167]
</p><p>79 For classification, in Table 4 and 5 the difference between the corresponding best performing formula and the single senses formulae is always significant (at least p < 0. [sent-297, score-0.663]
</p><p>80 Combining the formulae in a learning framework further improves the results over the best performing formulae, both in regression (MAEµ with SWN1 0. [sent-302, score-0.6]
</p><p>81 There is no significant difference in using linear logistic and probit regression likelihoods. [sent-326, score-0.159]
</p><p>82 This is not surprising due the high level of redundancy in the formulae scores. [sent-328, score-0.435]
</p><p>83 Interestingly, inspecting the most frequent selected features by SV Mfs, we see that features from different groups are selected, and even the worst performing formulae can add information, confirming the idea that viewing the same information from different perspectives (i. [sent-329, score-0.473]
</p><p>84 the posterior polarities provided by SWN combined in var-  ious ways) can give better predictions. [sent-331, score-0.322]
</p><p>85 In Table 6 we report the results for the best performing formulae and learning algorithm on the GI PoS classes. [sent-334, score-0.473]
</p><p>86 Instead, in Table 8 which displays the results along gender and polarity dimensions there is no statistically significant difference in MAE on positive words between male and female, while there is a strong statistical significance for negative words (p < 0. [sent-366, score-0.459]
</p><p>87 Interestingly, there is also a large difference between positive and negative affective words (both for male and female dimensions). [sent-368, score-0.325]
</p><p>88 This difference is maximum for male scores on positive words compared to female scores on negative words (0. [sent-369, score-0.265]
</p><p>89 (2013) inspected the differences in prior polarity assessment due to gender. [sent-375, score-0.384]
</p><p>90 –  –  At this stage we can only note that prior polarities calculated with SWN are closer to ANEW male annotations than female ones. [sent-376, score-0.487]
</p><p>91 n0g13SWN3 10  Conclusions  We have presented a study on the posterior-to-prior polarity issue, i. [sent-390, score-0.27]
</p><p>92 the problem of computing words’ prior polarity starting from their posterior polarities. [sent-392, score-0.444]
</p><p>93 Indeed, we showed that the better variants outperform the others on different datasets both in regression and classification tasks, and that they can represent a fairer state-of-art baseline approach using SentiWordNet. [sent-394, score-0.23]
</p><p>94 On top of this, we also showed that these state-ofthe-art formulae can be further outperformed using a learning framework that combines the various formulae together. [sent-395, score-0.87]
</p><p>95 Using syntactic and contextual information for sentiment polarity analysis. [sent-418, score-0.406]
</p><p>96 0: An enhanced lexical resource for sentiment analysis and opinion mining. [sent-426, score-0.217]
</p><p>97 Sentiment polarity  identification in financial news: A cohesion-based approach. [sent-479, score-0.27]
</p><p>98 Sentence level subjectivity and sentiment analysis experiments in NTCIR-7 MOAT challenge. [sent-601, score-0.136]
</p><p>99 Development of a novel algorithm for sentiment analysis  based on adverb-adjective-noun combinations. [sent-625, score-0.136]
</p><p>100 Baselines and bigrams: Simple, good sentiment and topic classification. [sent-669, score-0.136]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('formulae', 0.435), ('swn', 0.323), ('polarity', 0.27), ('polarities', 0.262), ('anew', 0.256), ('sentiwordnet', 0.18), ('cold', 0.157), ('negscore', 0.145), ('sentiment', 0.136), ('lemma', 0.136), ('posscore', 0.129), ('regression', 0.127), ('gps', 0.126), ('senses', 0.122), ('affective', 0.118), ('prior', 0.114), ('guerini', 0.113), ('inquirer', 0.09), ('rasmussen', 0.084), ('valence', 0.083), ('mae', 0.083), ('gi', 0.082), ('neviarouskaya', 0.081), ('neg', 0.079), ('svms', 0.073), ('williams', 0.069), ('formula', 0.068), ('classification', 0.065), ('gatti', 0.065), ('lasswell', 0.065), ('maxm', 0.065), ('zbal', 0.065), ('pos', 0.062), ('posterior', 0.06), ('male', 0.059), ('os', 0.057), ('trento', 0.055), ('female', 0.052), ('strapparava', 0.051), ('fd', 0.051), ('negative', 0.049), ('fsm', 0.048), ('sommarive', 0.048), ('strength', 0.048), ('sense', 0.048), ('positive', 0.047), ('resource', 0.046), ('fm', 0.046), ('esuli', 0.045), ('gaussian', 0.044), ('gp', 0.042), ('dunphy', 0.042), ('mfs', 0.042), ('lemmatize', 0.042), ('emotion', 0.039), ('povo', 0.038), ('fairer', 0.038), ('rnd', 0.038), ('lrec', 0.038), ('harvard', 0.038), ('performing', 0.038), ('annotator', 0.037), ('bradley', 0.036), ('opinion', 0.035), ('gender', 0.034), ('kernels', 0.034), ('synset', 0.034), ('stone', 0.034), ('standards', 0.034), ('median', 0.032), ('arousal', 0.032), ('blending', 0.032), ('chowdhury', 0.032), ('denecke', 0.032), ('devitt', 0.032), ('fbk', 0.032), ('fsd', 0.032), ('meinshausen', 0.032), ('paltoglou', 0.032), ('pianta', 0.032), ('probit', 0.032), ('stronglypos', 0.032), ('textpro', 0.032), ('thet', 0.032), ('turchi', 0.032), ('warriner', 0.032), ('weighs', 0.032), ('yel', 0.032), ('resources', 0.032), ('selection', 0.032), ('pages', 0.031), ('literature', 0.03), ('revised', 0.029), ('iv', 0.029), ('wilson', 0.029), ('tables', 0.029), ('scores', 0.029), ('italy', 0.028), ('sv', 0.028), ('sebastiani', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="170-tfidf-1" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>2 0.16516547 <a title="170-tfidf-2" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: Theresa Wilson Human Language Technology Center of Excellence Johns Hopkins University Baltimore, MD t aw@ j hu .edu differences may Different demographics, e.g., gender or age, can demonstrate substantial variation in their language use, particularly in informal contexts such as social media. In this paper we focus on learning gender differences in the use of subjective language in English, Spanish, and Russian Twitter data, and explore cross-cultural differences in emoticon and hashtag use for male and female users. We show that gender differences in subjective language can effectively be used to improve sentiment analysis, and in particular, polarity classification for Spanish and Russian. Our results show statistically significant relative F-measure improvement over the gender-independent baseline 1.5% and 1% for Russian, 2% and 0.5% for Spanish, and 2.5% and 5% for English for polarity and subjectivity classification.</p><p>3 0.16316837 <a title="170-tfidf-3" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>4 0.16163754 <a title="170-tfidf-4" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>Author: Shi Feng ; Le Zhang ; Binyang Li ; Daling Wang ; Ge Yu ; Kam-Fai Wong</p><p>Abstract: Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people’s sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.</p><p>5 0.099943437 <a title="170-tfidf-5" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>Author: Daniel Preotiuc-Pietro ; Trevor Cohn</p><p>Abstract: Temporal variations of text are usually ignored in NLP applications. However, text use changes with time, which can affect many applications. In this paper we model periodic distributions of words over time. Focusing on hashtag frequency in Twitter, we first automatically identify the periodic patterns. We use this for regression in order to forecast the volume of a hashtag based on past data. We use Gaussian Processes, a state-ofthe-art bayesian non-parametric model, with a novel periodic kernel. We demonstrate this in a text classification setting, assigning the tweet hashtag based on the rest of its text. This method shows significant improvements over competitive baselines.</p><p>6 0.087082475 <a title="170-tfidf-6" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>7 0.084526964 <a title="170-tfidf-7" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>8 0.076786362 <a title="170-tfidf-8" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>9 0.071794972 <a title="170-tfidf-9" href="./emnlp-2013-Sarcasm_as_Contrast_between_a_Positive_Sentiment_and_Negative_Situation.html">163 emnlp-2013-Sarcasm as Contrast between a Positive Sentiment and Negative Situation</a></p>
<p>10 0.070844561 <a title="170-tfidf-10" href="./emnlp-2013-A_Walk-Based_Semantically_Enriched_Tree_Kernel_Over_Distributed_Word_Representations.html">17 emnlp-2013-A Walk-Based Semantically Enriched Tree Kernel Over Distributed Word Representations</a></p>
<p>11 0.067282625 <a title="170-tfidf-11" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>12 0.064655855 <a title="170-tfidf-12" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>13 0.061155431 <a title="170-tfidf-13" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>14 0.05541236 <a title="170-tfidf-14" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>15 0.05454509 <a title="170-tfidf-15" href="./emnlp-2013-Naive_Bayes_Word_Sense_Induction.html">138 emnlp-2013-Naive Bayes Word Sense Induction</a></p>
<p>16 0.054169618 <a title="170-tfidf-16" href="./emnlp-2013-Understanding_and_Quantifying_Creativity_in_Lexical_Composition.html">191 emnlp-2013-Understanding and Quantifying Creativity in Lexical Composition</a></p>
<p>17 0.053115748 <a title="170-tfidf-17" href="./emnlp-2013-Learning_Latent_Word_Representations_for_Domain_Adaptation_using_Supervised_Word_Clustering.html">120 emnlp-2013-Learning Latent Word Representations for Domain Adaptation using Supervised Word Clustering</a></p>
<p>18 0.049304523 <a title="170-tfidf-18" href="./emnlp-2013-Learning_Topics_and_Positions_from_Debatepedia.html">121 emnlp-2013-Learning Topics and Positions from Debatepedia</a></p>
<p>19 0.046797272 <a title="170-tfidf-19" href="./emnlp-2013-Prior_Disambiguation_of_Word_Tensors_for_Constructing_Sentence_Vectors.html">154 emnlp-2013-Prior Disambiguation of Word Tensors for Constructing Sentence Vectors</a></p>
<p>20 0.045867421 <a title="170-tfidf-20" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.167), (1, 0.054), (2, -0.163), (3, -0.176), (4, 0.068), (5, -0.042), (6, -0.012), (7, -0.13), (8, 0.057), (9, 0.079), (10, -0.019), (11, 0.006), (12, -0.005), (13, 0.021), (14, 0.009), (15, -0.019), (16, -0.041), (17, 0.048), (18, 0.088), (19, 0.089), (20, 0.036), (21, 0.034), (22, -0.012), (23, 0.039), (24, 0.029), (25, -0.078), (26, -0.09), (27, -0.066), (28, 0.002), (29, -0.025), (30, 0.064), (31, 0.076), (32, -0.137), (33, -0.069), (34, 0.035), (35, 0.044), (36, 0.057), (37, -0.018), (38, -0.036), (39, -0.112), (40, 0.063), (41, 0.008), (42, -0.048), (43, 0.094), (44, -0.063), (45, 0.036), (46, 0.014), (47, -0.003), (48, -0.026), (49, -0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92992443 <a title="170-lsi-1" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>2 0.69290954 <a title="170-lsi-2" href="./emnlp-2013-Opinion_Mining_in_Newspaper_Articles_by_Entropy-Based_Word_Connections.html">144 emnlp-2013-Opinion Mining in Newspaper Articles by Entropy-Based Word Connections</a></p>
<p>Author: Thomas Scholz ; Stefan Conrad</p><p>Abstract: A very valuable piece of information in newspaper articles is the tonality of extracted statements. For the analysis of tonality of newspaper articles either a big human effort is needed, when it is carried out by media analysts, or an automated approach which has to be as accurate as possible for a Media Response Analysis (MRA). To this end, we will compare several state-of-the-art approaches for Opinion Mining in newspaper articles in this paper. Furthermore, we will introduce a new technique to extract entropy-based word connections which identifies the word combinations which create a tonality. In the evaluation, we use two different corpora consisting of news articles, by which we show that the new approach achieves better results than the four state-of-the-art methods.</p><p>3 0.66661602 <a title="170-lsi-3" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: Theresa Wilson Human Language Technology Center of Excellence Johns Hopkins University Baltimore, MD t aw@ j hu .edu differences may Different demographics, e.g., gender or age, can demonstrate substantial variation in their language use, particularly in informal contexts such as social media. In this paper we focus on learning gender differences in the use of subjective language in English, Spanish, and Russian Twitter data, and explore cross-cultural differences in emoticon and hashtag use for male and female users. We show that gender differences in subjective language can effectively be used to improve sentiment analysis, and in particular, polarity classification for Spanish and Russian. Our results show statistically significant relative F-measure improvement over the gender-independent baseline 1.5% and 1% for Russian, 2% and 0.5% for Spanish, and 2.5% and 5% for English for polarity and subjectivity classification.</p><p>4 0.66070741 <a title="170-lsi-4" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>5 0.65613043 <a title="170-lsi-5" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>Author: Shi Feng ; Le Zhang ; Binyang Li ; Daling Wang ; Ge Yu ; Kam-Fai Wong</p><p>Abstract: Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people’s sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.</p><p>6 0.64770216 <a title="170-lsi-6" href="./emnlp-2013-Sarcasm_as_Contrast_between_a_Positive_Sentiment_and_Negative_Situation.html">163 emnlp-2013-Sarcasm as Contrast between a Positive Sentiment and Negative Situation</a></p>
<p>7 0.59961355 <a title="170-lsi-7" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>8 0.49834064 <a title="170-lsi-8" href="./emnlp-2013-Using_Crowdsourcing_to_get_Representations_based_on_Regular_Expressions.html">196 emnlp-2013-Using Crowdsourcing to get Representations based on Regular Expressions</a></p>
<p>9 0.4765397 <a title="170-lsi-9" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>10 0.45556012 <a title="170-lsi-10" href="./emnlp-2013-A_Walk-Based_Semantically_Enriched_Tree_Kernel_Over_Distributed_Word_Representations.html">17 emnlp-2013-A Walk-Based Semantically Enriched Tree Kernel Over Distributed Word Representations</a></p>
<p>11 0.43866664 <a title="170-lsi-11" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>12 0.42873594 <a title="170-lsi-12" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>13 0.41193733 <a title="170-lsi-13" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>14 0.40036941 <a title="170-lsi-14" href="./emnlp-2013-Automated_Essay_Scoring_by_Maximizing_Human-Machine_Agreement.html">28 emnlp-2013-Automated Essay Scoring by Maximizing Human-Machine Agreement</a></p>
<p>15 0.36626962 <a title="170-lsi-15" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>16 0.34226686 <a title="170-lsi-16" href="./emnlp-2013-Understanding_and_Quantifying_Creativity_in_Lexical_Composition.html">191 emnlp-2013-Understanding and Quantifying Creativity in Lexical Composition</a></p>
<p>17 0.34199321 <a title="170-lsi-17" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>18 0.34029409 <a title="170-lsi-18" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>19 0.33390841 <a title="170-lsi-19" href="./emnlp-2013-Centering_Similarity_Measures_to_Reduce_Hubs.html">44 emnlp-2013-Centering Similarity Measures to Reduce Hubs</a></p>
<p>20 0.32488197 <a title="170-lsi-20" href="./emnlp-2013-Tree_Kernel-based_Negation_and_Speculation_Scope_Detection_with_Structured_Syntactic_Parse_Features.html">188 emnlp-2013-Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.032), (10, 0.013), (18, 0.033), (22, 0.042), (30, 0.067), (50, 0.019), (51, 0.172), (66, 0.066), (71, 0.049), (74, 0.321), (75, 0.016), (77, 0.019), (90, 0.016), (96, 0.023), (97, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73238343 <a title="170-lda-1" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>2 0.6467936 <a title="170-lda-2" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<p>Author: Wenliang Chen ; Min Zhang ; Yue Zhang</p><p>Abstract: In current dependency parsing models, conventional features (i.e. base features) defined over surface words and part-of-speech tags in a relatively high-dimensional feature space may suffer from the data sparseness problem and thus exhibit less discriminative power on unseen data. In this paper, we propose a novel semi-supervised approach to addressing the problem by transforming the base features into high-level features (i.e. meta features) with the help of a large amount of automatically parsed data. The meta features are used together with base features in our final parser. Our studies indicate that our proposed approach is very effective in processing unseen data and features. Experiments on Chinese and English data sets show that the final parser achieves the best-reported accuracy on the Chinese data and comparable accuracy with the best known parsers on the English data.</p><p>3 0.62636578 <a title="170-lda-3" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>Author: Zhiyuan Chen ; Arjun Mukherjee ; Bing Liu ; Meichun Hsu ; Malu Castellanos ; Riddhiman Ghosh</p><p>Abstract: Aspect extraction is one of the key tasks in sentiment analysis. In recent years, statistical models have been used for the task. However, such models without any domain knowledge often produce aspects that are not interpretable in applications. To tackle the issue, some knowledge-based topic models have been proposed, which allow the user to input some prior domain knowledge to generate coherent aspects. However, existing knowledge-based topic models have several major shortcomings, e.g., little work has been done to incorporate the cannot-link type of knowledge or to automatically adjust the number of topics based on domain knowledge. This paper proposes a more advanced topic model, called MC-LDA (LDA with m-set and c-set), to address these problems, which is based on an Extended generalized Pólya urn (E-GPU) model (which is also proposed in this paper). Experiments on real-life product reviews from a variety of domains show that MCLDA outperforms the existing state-of-the-art models markedly.</p><p>4 0.5363878 <a title="170-lda-4" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>5 0.53637552 <a title="170-lda-5" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>Author: Jun-Ping Ng ; Min-Yen Kan ; Ziheng Lin ; Wei Feng ; Bin Chen ; Jian Su ; Chew Lim Tan</p><p>Abstract: In this paper we classify the temporal relations between pairs of events on an article-wide basis. This is in contrast to much of the existing literature which focuses on just event pairs which are found within the same or adjacent sentences. To achieve this, we leverage on discourse analysis as we believe that it provides more useful semantic information than typical lexico-syntactic features. We propose the use of several discourse analysis frameworks, including 1) Rhetorical Structure Theory (RST), 2) PDTB-styled discourse relations, and 3) topical text segmentation. We explain how features derived from these frameworks can be effectively used with support vector machines (SVM) paired with convolution kernels. Experiments show that our proposal is effective in improving on the state-of-the-art significantly by as much as 16% in terms of F1, even if we only adopt less-than-perfect automatic discourse analyzers and parsers. Making use of more accurate discourse analysis can further boost gains to 35%.</p><p>6 0.53200859 <a title="170-lda-6" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>7 0.53197747 <a title="170-lda-7" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>8 0.52951616 <a title="170-lda-8" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>9 0.52906924 <a title="170-lda-9" href="./emnlp-2013-Exploring_Representations_from_Unlabeled_Data_with_Co-training_for_Chinese_Word_Segmentation.html">82 emnlp-2013-Exploring Representations from Unlabeled Data with Co-training for Chinese Word Segmentation</a></p>
<p>10 0.5284903 <a title="170-lda-10" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>11 0.52756 <a title="170-lda-11" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>12 0.52655661 <a title="170-lda-12" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>13 0.52654678 <a title="170-lda-13" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>14 0.52641016 <a title="170-lda-14" href="./emnlp-2013-Of_Words%2C_Eyes_and_Brains%3A_Correlating_Image-Based_Distributional_Semantic_Models_with_Neural_Representations_of_Concepts.html">140 emnlp-2013-Of Words, Eyes and Brains: Correlating Image-Based Distributional Semantic Models with Neural Representations of Concepts</a></p>
<p>15 0.5259403 <a title="170-lda-15" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>16 0.5250622 <a title="170-lda-16" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<p>17 0.52501917 <a title="170-lda-17" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>18 0.5240218 <a title="170-lda-18" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>19 0.5239678 <a title="170-lda-19" href="./emnlp-2013-Bilingual_Word_Embeddings_for_Phrase-Based_Machine_Translation.html">38 emnlp-2013-Bilingual Word Embeddings for Phrase-Based Machine Translation</a></p>
<p>20 0.52384531 <a title="170-lda-20" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
