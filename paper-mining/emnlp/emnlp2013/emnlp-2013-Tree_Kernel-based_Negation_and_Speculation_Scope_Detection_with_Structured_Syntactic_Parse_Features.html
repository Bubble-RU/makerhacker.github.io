<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>188 emnlp-2013-Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-188" href="#">emnlp2013-188</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>188 emnlp-2013-Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features</h1>
<br/><p>Source: <a title="emnlp-2013-188-pdf" href="http://aclweb.org/anthology//D/D13/D13-1099.pdf">pdf</a></p><p>Author: Bowei Zou ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Scope detection is a key task in information extraction. This paper proposes a new approach for tree kernel-based scope detection by using the structured syntactic parse information. In addition, we have explored the way of selecting compatible features for different part-of-speech cues. Experiments on the BioScope corpus show that both constituent and dependency structured syntactic parse features have the advantage in capturing the potential relationships between cues and their scopes. Compared with the state of the art scope detection systems, our system achieves substantial improvement.</p><p>Reference: <a title="emnlp-2013-188-reference" href="../emnlp2013_reference/emnlp-2013-Tree_Kernel-based_Negation_and_Speculation_Scope_Detection_with_Structured_Syntactic_Parse_Features_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features Bowei Zou Guodong Zhou Qiaoming Zhu* Natural Language Processing Lab, School of Computer Science and Technology Soochow University, Suzhou, 215006, China z oubowe i gmai l com, @ . [sent-1, score-0.02]
</p><p>2 cn  Abstract Scope detection is a key task in information extraction. [sent-4, score-0.173]
</p><p>3 This paper proposes a new approach for tree kernel-based scope detection by using the structured syntactic parse information. [sent-5, score-1.078]
</p><p>4 In addition, we have explored the way of selecting compatible features for different part-of-speech cues. [sent-6, score-0.039]
</p><p>5 Experiments on the BioScope corpus show that both constituent and dependency structured syntactic parse features have the advantage in capturing the potential relationships between cues and their scopes. [sent-7, score-0.433]
</p><p>6 Compared with the state of the art scope detection systems, our system achieves substantial improvement. [sent-8, score-0.784]
</p><p>7 1 Introduction The task of scope detection is to detect the linguistic scope dominated by a specific cue. [sent-9, score-1.405]
</p><p>8 Current researches in this field focus on two semantic aspects: negation and speculation. [sent-10, score-0.183]
</p><p>9 The negative  scope detection is to detect the linguistic scope which is repudiated by a negative word (viz. [sent-11, score-1.526]
</p><p>10 In other side, the speculative scope detection is to detect the uncertain part in a sentence corresponding to the speculative word (viz. [sent-15, score-1.589]
</p><p>11 See the sentence 1) below, the negative cue “not” dominates the scope of “not expensive”. [sent-19, score-0.825]
</p><p>12 Similarly, the speculative cue “possible” in sentence 2) dominates the uncertain scope “the possible future scenarios”. [sent-20, score-1.182]
</p><p>13 * Corresponding author  968 The negative and speculative scope detection task consists of two basic stages. [sent-23, score-1.174]
</p><p>14 The first one is to identify the sentences involving negative or speculative meaning. [sent-24, score-0.446]
</p><p>15 The second stage is to detect the linguistic scope of the cue in sentences (Velldal et al, 2012). [sent-25, score-0.799]
</p><p>16 That is, by given golden cues, we detect their linguistic scopes. [sent-27, score-0.157]
</p><p>17 We propose a tree kernel-based negation and speculation scope detection with structured syntactic parse features. [sent-28, score-1.495]
</p><p>18 In detail, we regard the scope detection task as a binary classification issue, which is to classify the tokens in a sentence as being inside or outside the scope. [sent-29, score-0.747]
</p><p>19 In the basic framework, we focus on the analysis and application of structured syntactic parse features as follows: Both constituent and dependency syntactic features have been proved to be effective in scope detection (Özgür al, 2009; Øvrelid et al, 2010). [sent-30, score-1.166]
</p><p>20 et However, these flat features are hardly to reflect the information implicit in syntactic parse tree structures. [sent-31, score-0.355]
</p><p>21 Our intuition is that the segments of the syntactic parse tree around a negative or speculative cue is effective for scope detection. [sent-32, score-1.467]
</p><p>22 The related structures normally underlay the indirect clues to identify the relations between cues and their scopes, e. [sent-33, score-0.265]
</p><p>23 , in sentence 1), “but something”, as a frequently co-occurred syntactic structure with “not something”, is an effective clue to determine the linguistic scope of “not”. [sent-35, score-0.734]
</p><p>24 The tree kernel classifier (Moschitti, 2006) based on support vector machines uses a kernel  function between two trees, affording a comparison between their substructures. [sent-36, score-0.251]
</p><p>25 Therefore, a tree kernel-based scope detection approach with structured syntactic parse tree is employed. [sent-37, score-1.17]
</p><p>26 The tree ProceSe datintlges, o Wfa tsh ein 2g01to3n, C UoSnfAe,re 1n8c-e2 o1n O Ecmtopbier ic 2a0l1 M3. [sent-38, score-0.092]
</p><p>27 hc o2d0s1 i3n A Nsastoucria lti Loan fgoura Cgoem Ppruotcaetsiosin agl, L piang eusis 9t6ic8s–976, kernel has been already proved to be effective in semantic role labeling (Che et al, 2006) and relation extraction (Zhou et al, 2007). [sent-40, score-0.134]
</p><p>28 In addition, the empirical observation shows that features have imbalanced efficiency for scope classification, which is normally affected by the part-of-speech (abbr. [sent-41, score-0.65]
</p><p>29 Hence, we build the discriminative classifiers for each kind of POS of cues, then explore and select the most compatible features for them. [sent-43, score-0.06]
</p><p>30 We construct a scope detection system by using the structured syntactic parse features based tree kernel classification. [sent-44, score-1.145]
</p><p>31 Compared with the state of the art scope detection systems, our system achieves the performance of accuracy 76. [sent-45, score-0.784]
</p><p>32 2  Related Work  Most of the previous studies on negation and speculation scope detection task can be divided into two main aspects: the heuristic rule based methods and the machine learning based methods. [sent-54, score-1.305]
</p><p>33 1  Heuristic Rule based Methods  The initial studies for scope detection are to compile effective heuristic rules (Chapman et al, 2001 ; Goldin et al, 2003). [sent-57, score-0.936]
</p><p>34 Recently, the heuristic rule based methods have further involved the syntactic features. [sent-58, score-0.219]
</p><p>35 Huang et al (2007) implemented a hybrid approach to automated negation scope detection. [sent-59, score-1.037]
</p><p>36 They combined the regular expression matching with grammatical parsing: negations are classified on the basis of syntactic categories and located in parse trees. [sent-60, score-0.271]
</p><p>37 Their hybrid approach is able to identi-  fy negated concepts in radiology reports even when they are located at some distance from the negative term. [sent-61, score-0.295]
</p><p>38 Özgüret al (2009)  969  hypothesized that the scope of a speculation cue can be characterized by its part-of-speech and the syntactic structure of the sentence and developed rules to map the scope of a cue to the nodes in the syntactic parse tree. [sent-62, score-2.315]
</p><p>39 By given golden speculation cues, their rule-based method achieves the accuracies of 79. [sent-63, score-0.348]
</p><p>40 Øvrelid et al (2010) constructed a small set of heuristic rules which define the scope for each cue. [sent-66, score-0.969]
</p><p>41 Apostolova et al (201 1) presented a linguistically motivated rule-based system for the detection of negation and speculation scopes that performs on  par with state-of-the-art machine learning systems. [sent-68, score-1.127]
</p><p>42 The rules are automatically extracted from the BioScope corpus and encode lexico-syntactic patterns in a user-friendly format. [sent-69, score-0.036]
</p><p>43 While their system was developed and tested using a biomedical corpus, the rule extraction mechanism is not domainspecific. [sent-70, score-0.108]
</p><p>44 The heuristic rule based methods have bad robustness in detecting scopes crossing different meaning aspects (e. [sent-71, score-0.498]
</p><p>45 2 Machine Learning based Methods The machine learning based methods have been ignored until the release of the BioScope corpus (Szarvas et al, 2008), where the large-scale data of manually annotated cues and corresponding scopes can support machine learning well. [sent-79, score-0.376]
</p><p>46 Morante et al (2008) formulated scope detection as a chunk classification problem. [sent-80, score-1.073]
</p><p>47 It is worth noting that they also proposed an effective proper post-processing approach to ensure the consecutiveness of scope. [sent-81, score-0.055]
</p><p>48 Then, for further improving the scope detection, Morante et al (2009a) applied a meta-learner that uses the predictions of the three  classifiers (TiMBL/SVM/CRF) to predict the scope. [sent-82, score-0.87]
</p><p>49 For the competitive task in CoNLL’2010 (Farkas et al, 2010), Morante et al (2010) used a memory-based classifier based on the k-nearest neighbor rule to determine if a token is the first token in a scope sequence, the last, or neither. [sent-83, score-1.031]
</p><p>50 Therefore, in order to guarantee that all scopes are continuous sequences of tokens they apply a first post-processing step that builds the sequence of scope. [sent-84, score-0.234]
</p><p>51 The existing machine learning based approaches substantially improve the robustness of scope detection, and have nearly 80% accuracy. [sent-85, score-0.597]
</p><p>52 However, the approaches ignore the availability of the structured syntactic parse information. [sent-86, score-0.281]
</p><p>53 This information involves more clues which can well reflect the relations between cues and scopes. [sent-87, score-0.209]
</p><p>54 Sánchez et al (2010) employed a tree kernel based classifier with CCG structures to identify speculative sentences on Wikipedia dataset. [sent-88, score-0.894]
</p><p>55 3  Corpus  We have employed the BioScope corpus (Szarvas  et al, 2008; Vincze et al, 2008)1, an open resource from the biomedical domain, as the benchmark corpus. [sent-90, score-0.096]
</p><p>56 The corpus contains annotations at the token level for negative and speculative cues and at the sentence level for their linguistic scope (as shown in Figure 1). [sent-91, score-1.22]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('scope', 0.555), ('speculative', 0.373), ('al', 0.294), ('speculation', 0.261), ('bioscope', 0.215), ('scopes', 0.215), ('detection', 0.173), ('negation', 0.156), ('cue', 0.147), ('cues', 0.141), ('morante', 0.129), ('parse', 0.114), ('tree', 0.092), ('nchez', 0.086), ('heuristic', 0.084), ('syntactic', 0.079), ('zg', 0.075), ('vrelid', 0.075), ('negative', 0.073), ('szarvas', 0.068), ('vincze', 0.068), ('kernel', 0.067), ('structured', 0.065), ('golden', 0.06), ('detect', 0.058), ('uncertain', 0.057), ('crossing', 0.057), ('rule', 0.056), ('clinical', 0.054), ('biomedical', 0.052), ('dominates', 0.05), ('abstracts', 0.049), ('scenarios', 0.046), ('located', 0.046), ('reports', 0.045), ('aspects', 0.044), ('robustness', 0.042), ('clues', 0.042), ('normally', 0.04), ('compatible', 0.039), ('linguistic', 0.039), ('token', 0.039), ('gdzhou', 0.037), ('radiology', 0.037), ('rules', 0.036), ('something', 0.036), ('compile', 0.034), ('imbalanced', 0.034), ('zou', 0.034), ('ret', 0.034), ('constituent', 0.034), ('effective', 0.034), ('proved', 0.033), ('hybrid', 0.032), ('suzhou', 0.032), ('fy', 0.032), ('negations', 0.032), ('negated', 0.03), ('qiaoming', 0.03), ('chunk', 0.03), ('soochow', 0.03), ('suda', 0.03), ('chair', 0.03), ('farkas', 0.03), ('art', 0.029), ('par', 0.028), ('expensive', 0.028), ('zhou', 0.028), ('researches', 0.027), ('clue', 0.027), ('achieves', 0.027), ('ccg', 0.026), ('moschitti', 0.026), ('reflect', 0.026), ('hypothesized', 0.025), ('dominated', 0.025), ('chapman', 0.025), ('classifier', 0.025), ('che', 0.024), ('guodong', 0.024), ('employed', 0.023), ('availability', 0.023), ('characterized', 0.023), ('neighbor', 0.023), ('hardly', 0.022), ('indirect', 0.022), ('flat', 0.022), ('formulated', 0.021), ('noting', 0.021), ('inspection', 0.021), ('classifiers', 0.021), ('benchmark', 0.021), ('lab', 0.021), ('affected', 0.021), ('guidelines', 0.021), ('gmai', 0.02), ('studies', 0.02), ('structures', 0.02), ('release', 0.02), ('tokens', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="188-tfidf-1" href="./emnlp-2013-Tree_Kernel-based_Negation_and_Speculation_Scope_Detection_with_Structured_Syntactic_Parse_Features.html">188 emnlp-2013-Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features</a></p>
<p>Author: Bowei Zou ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Scope detection is a key task in information extraction. This paper proposes a new approach for tree kernel-based scope detection by using the structured syntactic parse information. In addition, we have explored the way of selecting compatible features for different part-of-speech cues. Experiments on the BioScope corpus show that both constituent and dependency structured syntactic parse features have the advantage in capturing the potential relationships between cues and their scopes. Compared with the state of the art scope detection systems, our system achieves substantial improvement.</p><p>2 0.071795367 <a title="188-tfidf-2" href="./emnlp-2013-A_Walk-Based_Semantically_Enriched_Tree_Kernel_Over_Distributed_Word_Representations.html">17 emnlp-2013-A Walk-Based Semantically Enriched Tree Kernel Over Distributed Word Representations</a></p>
<p>Author: Shashank Srivastava ; Dirk Hovy ; Eduard Hovy</p><p>Abstract: In this paper, we propose a walk-based graph kernel that generalizes the notion of treekernels to continuous spaces. Our proposed approach subsumes a general framework for word-similarity, and in particular, provides a flexible way to incorporate distributed representations. Using vector representations, such an approach captures both distributional semantic similarities among words as well as the structural relations between them (encoded as the structure of the parse tree). We show an efficient formulation to compute this kernel using simple matrix operations. We present our results on three diverse NLP tasks, showing state-of-the-art results.</p><p>3 0.069855124 <a title="188-tfidf-3" href="./emnlp-2013-Recursive_Deep_Models_for_Semantic_Compositionality_Over_a_Sentiment_Treebank.html">158 emnlp-2013-Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></p>
<p>Author: Richard Socher ; Alex Perelygin ; Jean Wu ; Jason Chuang ; Christopher D. Manning ; Andrew Ng ; Christopher Potts</p><p>Abstract: Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.</p><p>4 0.053975709 <a title="188-tfidf-4" href="./emnlp-2013-Measuring_Ideological_Proportions_in_Political_Speeches.html">129 emnlp-2013-Measuring Ideological Proportions in Political Speeches</a></p>
<p>Author: Yanchuan Sim ; Brice D. L. Acree ; Justin H. Gross ; Noah A. Smith</p><p>Abstract: We seek to measure political candidates’ ideological positioning from their speeches. To accomplish this, we infer ideological cues from a corpus of political writings annotated with known ideologies. We then represent the speeches of U.S. Presidential candidates as sequences of cues and lags (filler distinguished only by its length in words). We apply a domain-informed Bayesian HMM to infer the proportions of ideologies each candidate uses in each campaign. The results are validated against a set of preregistered, domain expertauthored hypotheses.</p><p>5 0.052216414 <a title="188-tfidf-5" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>Author: Aliaksei Severyn ; Alessandro Moschitti</p><p>Abstract: This paper proposes a framework for automatically engineering features for two important tasks of question answering: answer sentence selection and answer extraction. We represent question and answer sentence pairs with linguistic structures enriched by semantic information, where the latter is produced by automatic classifiers, e.g., question classifier and Named Entity Recognizer. Tree kernels applied to such structures enable a simple way to generate highly discriminative structural features that combine syntactic and semantic information encoded in the input trees. We conduct experiments on a public benchmark from TREC to compare with previous systems for answer sentence selection and answer extraction. The results show that our models greatly improve on the state of the art, e.g., up to 22% on F1 (relative improvement) for answer extraction, while using no additional resources and no manual feature engineering.</p><p>6 0.041735511 <a title="188-tfidf-6" href="./emnlp-2013-Translation_with_Source_Constituency_and_Dependency_Trees.html">187 emnlp-2013-Translation with Source Constituency and Dependency Trees</a></p>
<p>7 0.040703259 <a title="188-tfidf-7" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>8 0.039458901 <a title="188-tfidf-8" href="./emnlp-2013-Factored_Soft_Source_Syntactic_Constraints_for_Hierarchical_Machine_Translation.html">84 emnlp-2013-Factored Soft Source Syntactic Constraints for Hierarchical Machine Translation</a></p>
<p>9 0.038405575 <a title="188-tfidf-9" href="./emnlp-2013-Breaking_Out_of_Local_Optima_with_Count_Transforms_and_Model_Recombination%3A_A_Study_in_Grammar_Induction.html">40 emnlp-2013-Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction</a></p>
<p>10 0.037122294 <a title="188-tfidf-10" href="./emnlp-2013-Identifying_Manipulated_Offerings_on_Review_Portals.html">94 emnlp-2013-Identifying Manipulated Offerings on Review Portals</a></p>
<p>11 0.036386013 <a title="188-tfidf-11" href="./emnlp-2013-Using_Soft_Constraints_in_Joint_Inference_for_Clinical_Concept_Recognition.html">198 emnlp-2013-Using Soft Constraints in Joint Inference for Clinical Concept Recognition</a></p>
<p>12 0.036236361 <a title="188-tfidf-12" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>13 0.035466686 <a title="188-tfidf-13" href="./emnlp-2013-Online_Learning_for_Inexact_Hypergraph_Search.html">141 emnlp-2013-Online Learning for Inexact Hypergraph Search</a></p>
<p>14 0.035369385 <a title="188-tfidf-14" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>15 0.034261074 <a title="188-tfidf-15" href="./emnlp-2013-Max-Margin_Synchronous_Grammar_Induction_for_Machine_Translation.html">127 emnlp-2013-Max-Margin Synchronous Grammar Induction for Machine Translation</a></p>
<p>16 0.031991675 <a title="188-tfidf-16" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>17 0.031261008 <a title="188-tfidf-17" href="./emnlp-2013-Source-Side_Classifier_Preordering_for_Machine_Translation.html">175 emnlp-2013-Source-Side Classifier Preordering for Machine Translation</a></p>
<p>18 0.031039901 <a title="188-tfidf-18" href="./emnlp-2013-Dependency_Language_Models_for_Sentence_Completion.html">58 emnlp-2013-Dependency Language Models for Sentence Completion</a></p>
<p>19 0.031021442 <a title="188-tfidf-19" href="./emnlp-2013-Joint_Parsing_and_Disfluency_Detection_in_Linear_Time.html">116 emnlp-2013-Joint Parsing and Disfluency Detection in Linear Time</a></p>
<p>20 0.030831579 <a title="188-tfidf-20" href="./emnlp-2013-Dynamic_Feature_Selection_for_Dependency_Parsing.html">66 emnlp-2013-Dynamic Feature Selection for Dependency Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.112), (1, 0.007), (2, -0.007), (3, 0.0), (4, -0.031), (5, 0.026), (6, 0.013), (7, -0.021), (8, 0.004), (9, 0.039), (10, -0.017), (11, 0.041), (12, -0.093), (13, 0.067), (14, 0.048), (15, 0.07), (16, -0.059), (17, 0.035), (18, 0.037), (19, -0.026), (20, 0.031), (21, -0.022), (22, 0.021), (23, -0.038), (24, -0.057), (25, 0.064), (26, -0.013), (27, -0.019), (28, 0.016), (29, -0.058), (30, -0.011), (31, -0.002), (32, -0.092), (33, -0.103), (34, 0.034), (35, -0.091), (36, 0.135), (37, 0.023), (38, 0.121), (39, -0.022), (40, -0.047), (41, 0.032), (42, -0.141), (43, -0.031), (44, -0.106), (45, 0.024), (46, 0.031), (47, -0.012), (48, 0.047), (49, -0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96558797 <a title="188-lsi-1" href="./emnlp-2013-Tree_Kernel-based_Negation_and_Speculation_Scope_Detection_with_Structured_Syntactic_Parse_Features.html">188 emnlp-2013-Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features</a></p>
<p>Author: Bowei Zou ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Scope detection is a key task in information extraction. This paper proposes a new approach for tree kernel-based scope detection by using the structured syntactic parse information. In addition, we have explored the way of selecting compatible features for different part-of-speech cues. Experiments on the BioScope corpus show that both constituent and dependency structured syntactic parse features have the advantage in capturing the potential relationships between cues and their scopes. Compared with the state of the art scope detection systems, our system achieves substantial improvement.</p><p>2 0.5819729 <a title="188-lsi-2" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>Author: Daniel Preotiuc-Pietro ; Trevor Cohn</p><p>Abstract: Temporal variations of text are usually ignored in NLP applications. However, text use changes with time, which can affect many applications. In this paper we model periodic distributions of words over time. Focusing on hashtag frequency in Twitter, we first automatically identify the periodic patterns. We use this for regression in order to forecast the volume of a hashtag based on past data. We use Gaussian Processes, a state-ofthe-art bayesian non-parametric model, with a novel periodic kernel. We demonstrate this in a text classification setting, assigning the tweet hashtag based on the rest of its text. This method shows significant improvements over competitive baselines.</p><p>3 0.55317771 <a title="188-lsi-3" href="./emnlp-2013-A_Walk-Based_Semantically_Enriched_Tree_Kernel_Over_Distributed_Word_Representations.html">17 emnlp-2013-A Walk-Based Semantically Enriched Tree Kernel Over Distributed Word Representations</a></p>
<p>Author: Shashank Srivastava ; Dirk Hovy ; Eduard Hovy</p><p>Abstract: In this paper, we propose a walk-based graph kernel that generalizes the notion of treekernels to continuous spaces. Our proposed approach subsumes a general framework for word-similarity, and in particular, provides a flexible way to incorporate distributed representations. Using vector representations, such an approach captures both distributional semantic similarities among words as well as the structural relations between them (encoded as the structure of the parse tree). We show an efficient formulation to compute this kernel using simple matrix operations. We present our results on three diverse NLP tasks, showing state-of-the-art results.</p><p>4 0.43147185 <a title="188-lsi-4" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>Author: Yiping Jin ; Min-Yen Kan ; Jun-Ping Ng ; Xiangnan He</p><p>Abstract: This paper presents DefMiner, a supervised sequence labeling system that identifies scientific terms and their accompanying definitions. DefMiner achieves 85% F1 on a Wikipedia benchmark corpus, significantly improving the previous state-of-the-art by 8%. We exploit DefMiner to process the ACL Anthology Reference Corpus (ARC) – a large, real-world digital library of scientific articles in computational linguistics. The resulting automatically-acquired glossary represents the terminology defined over several thousand individual research articles. We highlight several interesting observations: more definitions are introduced for conference and workshop papers over the years and that multiword terms account for slightly less than half of all terms. Obtaining a list of popular , defined terms in a corpus ofcomputational linguistics papers, we find that concepts can often be categorized into one of three categories: resources, methodologies and evaluation metrics.</p><p>5 0.40818 <a title="188-lsi-5" href="./emnlp-2013-A_Multi-Teraflop_Constituency_Parser_using_GPUs.html">10 emnlp-2013-A Multi-Teraflop Constituency Parser using GPUs</a></p>
<p>Author: John Canny ; David Hall ; Dan Klein</p><p>Abstract: Constituency parsing with rich grammars remains a computational challenge. Graphics Processing Units (GPUs) have previously been used to accelerate CKY chart evaluation, but gains over CPU parsers were modest. In this paper, we describe a collection of new techniques that enable chart evaluation at close to the GPU’s practical maximum speed (a Teraflop), or around a half-trillion rule evaluations per second. Net parser performance on a 4-GPU system is over 1 thousand length30 sentences/second (1 trillion rules/sec), and 400 general sentences/second for the Berkeley Parser Grammar. The techniques we introduce include grammar compilation, recursive symbol blocking, and cache-sharing.</p><p>6 0.39382774 <a title="188-lsi-6" href="./emnlp-2013-A_Synchronous_Context_Free_Grammar_for_Time_Normalization.html">14 emnlp-2013-A Synchronous Context Free Grammar for Time Normalization</a></p>
<p>7 0.38744494 <a title="188-lsi-7" href="./emnlp-2013-Learning_to_Freestyle%3A_Hip_Hop_Challenge-Response_Induction_via_Transduction_Rule_Segmentation.html">122 emnlp-2013-Learning to Freestyle: Hip Hop Challenge-Response Induction via Transduction Rule Segmentation</a></p>
<p>8 0.3757773 <a title="188-lsi-8" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>9 0.34536502 <a title="188-lsi-9" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>10 0.33554697 <a title="188-lsi-10" href="./emnlp-2013-Where_Not_to_Eat%3F_Improving_Public_Policy_by_Predicting_Hygiene_Inspections_Using_Online_Reviews.html">202 emnlp-2013-Where Not to Eat? Improving Public Policy by Predicting Hygiene Inspections Using Online Reviews</a></p>
<p>11 0.33208135 <a title="188-lsi-11" href="./emnlp-2013-Success_with_Style%3A_Using_Writing_Style_to_Predict_the_Success_of_Novels.html">178 emnlp-2013-Success with Style: Using Writing Style to Predict the Success of Novels</a></p>
<p>12 0.3317852 <a title="188-lsi-12" href="./emnlp-2013-Assembling_the_Kazakh_Language_Corpus.html">26 emnlp-2013-Assembling the Kazakh Language Corpus</a></p>
<p>13 0.3313621 <a title="188-lsi-13" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>14 0.3302505 <a title="188-lsi-14" href="./emnlp-2013-Automatically_Detecting_and_Attributing_Indirect_Quotations.html">35 emnlp-2013-Automatically Detecting and Attributing Indirect Quotations</a></p>
<p>15 0.32412115 <a title="188-lsi-15" href="./emnlp-2013-Flexible_and_Efficient_Hypergraph_Interactions_for_Joint_Hierarchical_and_Forest-to-String_Decoding.html">88 emnlp-2013-Flexible and Efficient Hypergraph Interactions for Joint Hierarchical and Forest-to-String Decoding</a></p>
<p>16 0.31671306 <a title="188-lsi-16" href="./emnlp-2013-Breaking_Out_of_Local_Optima_with_Count_Transforms_and_Model_Recombination%3A_A_Study_in_Grammar_Induction.html">40 emnlp-2013-Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction</a></p>
<p>17 0.31541523 <a title="188-lsi-17" href="./emnlp-2013-Using_Soft_Constraints_in_Joint_Inference_for_Clinical_Concept_Recognition.html">198 emnlp-2013-Using Soft Constraints in Joint Inference for Clinical Concept Recognition</a></p>
<p>18 0.30859241 <a title="188-lsi-18" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>19 0.30429897 <a title="188-lsi-19" href="./emnlp-2013-Translation_with_Source_Constituency_and_Dependency_Trees.html">187 emnlp-2013-Translation with Source Constituency and Dependency Trees</a></p>
<p>20 0.30099893 <a title="188-lsi-20" href="./emnlp-2013-Measuring_Ideological_Proportions_in_Political_Speeches.html">129 emnlp-2013-Measuring Ideological Proportions in Political Speeches</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.043), (18, 0.022), (22, 0.039), (30, 0.107), (49, 0.306), (50, 0.016), (51, 0.201), (66, 0.033), (71, 0.035), (75, 0.046), (77, 0.017), (96, 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.82220858 <a title="188-lda-1" href="./emnlp-2013-Tree_Kernel-based_Negation_and_Speculation_Scope_Detection_with_Structured_Syntactic_Parse_Features.html">188 emnlp-2013-Tree Kernel-based Negation and Speculation Scope Detection with Structured Syntactic Parse Features</a></p>
<p>Author: Bowei Zou ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Scope detection is a key task in information extraction. This paper proposes a new approach for tree kernel-based scope detection by using the structured syntactic parse information. In addition, we have explored the way of selecting compatible features for different part-of-speech cues. Experiments on the BioScope corpus show that both constituent and dependency structured syntactic parse features have the advantage in capturing the potential relationships between cues and their scopes. Compared with the state of the art scope detection systems, our system achieves substantial improvement.</p><p>2 0.61698169 <a title="188-lda-2" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>Author: Xiaoqing Zheng ; Hanyang Chen ; Tianyu Xu</p><p>Abstract: This study explores the feasibility of performing Chinese word segmentation (CWS) and POS tagging by deep learning. We try to avoid task-specific feature engineering, and use deep layers of neural networks to discover relevant features to the tasks. We leverage large-scale unlabeled data to improve internal representation of Chinese characters, and use these improved representations to enhance supervised word segmentation and POS tagging models. Our networks achieved close to state-of-theart performance with minimal computational cost. We also describe a perceptron-style algorithm for training the neural networks, as an alternative to maximum-likelihood method, to speed up the training process and make the learning algorithm easier to be implemented.</p><p>3 0.61350513 <a title="188-lda-3" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>4 0.61158228 <a title="188-lda-4" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>Author: Margaret Mitchell ; Jacqui Aguilar ; Theresa Wilson ; Benjamin Van Durme</p><p>Abstract: We propose a novel approach to sentiment analysis for a low resource setting. The intuition behind this work is that sentiment expressed towards an entity, targeted sentiment, may be viewed as a span of sentiment expressed across the entity. This representation allows us to model sentiment detection as a sequence tagging problem, jointly discovering people and organizations along with whether there is sentiment directed towards them. We compare performance in both Spanish and English on microblog data, using only a sentiment lexicon as an external resource. By leveraging linguisticallyinformed features within conditional random fields (CRFs) trained to minimize empirical risk, our best models in Spanish significantly outperform a strong baseline, and reach around 90% accuracy on the combined task of named entity recognition and sentiment prediction. Our models in English, trained on a much smaller dataset, are not yet statistically significant against their baselines.</p><p>5 0.61053085 <a title="188-lda-5" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<p>Author: Yiping Jin ; Min-Yen Kan ; Jun-Ping Ng ; Xiangnan He</p><p>Abstract: This paper presents DefMiner, a supervised sequence labeling system that identifies scientific terms and their accompanying definitions. DefMiner achieves 85% F1 on a Wikipedia benchmark corpus, significantly improving the previous state-of-the-art by 8%. We exploit DefMiner to process the ACL Anthology Reference Corpus (ARC) – a large, real-world digital library of scientific articles in computational linguistics. The resulting automatically-acquired glossary represents the terminology defined over several thousand individual research articles. We highlight several interesting observations: more definitions are introduced for conference and workshop papers over the years and that multiword terms account for slightly less than half of all terms. Obtaining a list of popular , defined terms in a corpus ofcomputational linguistics papers, we find that concepts can often be categorized into one of three categories: resources, methodologies and evaluation metrics.</p><p>6 0.60922205 <a title="188-lda-6" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<p>7 0.60816145 <a title="188-lda-7" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>8 0.6066801 <a title="188-lda-8" href="./emnlp-2013-A_Study_on_Bootstrapping_Bilingual_Vector_Spaces_from_Non-Parallel_Data_%28and_Nothing_Else%29.html">13 emnlp-2013-A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data (and Nothing Else)</a></p>
<p>9 0.60645568 <a title="188-lda-9" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>10 0.60588735 <a title="188-lda-10" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>11 0.60548353 <a title="188-lda-11" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>12 0.60545403 <a title="188-lda-12" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>13 0.60527182 <a title="188-lda-13" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>14 0.6048795 <a title="188-lda-14" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>15 0.60473961 <a title="188-lda-15" href="./emnlp-2013-Bilingual_Word_Embeddings_for_Phrase-Based_Machine_Translation.html">38 emnlp-2013-Bilingual Word Embeddings for Phrase-Based Machine Translation</a></p>
<p>16 0.60470295 <a title="188-lda-16" href="./emnlp-2013-A_Systematic_Exploration_of_Diversity_in_Machine_Translation.html">15 emnlp-2013-A Systematic Exploration of Diversity in Machine Translation</a></p>
<p>17 0.60436594 <a title="188-lda-17" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>18 0.60387641 <a title="188-lda-18" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>19 0.60346395 <a title="188-lda-19" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>20 0.60296732 <a title="188-lda-20" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
