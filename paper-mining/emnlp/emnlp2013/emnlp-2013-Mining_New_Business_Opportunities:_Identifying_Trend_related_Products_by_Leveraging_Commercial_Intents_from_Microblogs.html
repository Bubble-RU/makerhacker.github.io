<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-131" href="#">emnlp2013-131</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</h1>
<br/><p>Source: <a title="emnlp-2013-131-pdf" href="http://aclweb.org/anthology//D/D13/D13-1132.pdf">pdf</a></p><p>Author: Jinpeng Wang ; Wayne Xin Zhao ; Haitian Wei ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Hot trends are likely to bring new business opportunities. For example, “Air Pollution” might lead to a significant increase of the sales of related products, e.g., mouth mask. For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. In this paper, we take the initiative to study the task of how to identify trend related products. The major novelty of our work is that we automatically learn commercial intents revealed from microblogs. We carefully construct a data collection for this task and present quite a few insightful findings. In order to solve this problem, we further propose a graph based method, which jointly models relevance and associativity. We perform extensive experiments and the results showed that our methods are very effective.</p><p>Reference: <a title="emnlp-2013-131-reference" href="../emnlp2013_reference/emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. [sent-14, score-0.496]
</p><p>2 In this paper, we take the initiative to study the task of how to identify trend related products. [sent-15, score-0.385]
</p><p>3 Faced with trenddriven business opportunities, e-commerce companies typically ask workers to manually identify related products and make heuristic rules to match user queries (e. [sent-31, score-0.507]
</p><p>4 To improve trend-driven e-commerce, in this pa-  per, we propose to study the novel task of automatically identifying trend related products. [sent-34, score-0.385]
</p><p>5 Taobao), which indicates a strong correlation between hot trends and product sale. [sent-45, score-0.465]
</p><p>6 Without prior knowledge and experiences, it is particularly difficult to make rapid response to relate the trend to can-  didate products. [sent-49, score-0.387]
</p><p>7 Our solution is to leverage trendrelated commercial intents from microblogs by mining users’ real-time response to a trending topic. [sent-50, score-0.433]
</p><p>8 , a microblog user may complain about the air quality and evince  mouth mask in a tweet. [sent-63, score-0.494]
</p><p>9 Second, how to achieve a comprehensive coverage of related products but not hurting precision. [sent-65, score-0.387]
</p><p>10 The above solution will miss the related products which have not been discussed in microblogs. [sent-66, score-0.421]
</p><p>11 Our idea is to take the associativity between products in-  to consideration. [sent-67, score-0.653]
</p><p>12 For example, we can define product associativity to be the similarity between product descriptions, or the ratio of historical purchase records in e-commerce companies. [sent-69, score-0.79]
</p><p>13 However, one-step associativity may not fully discover the underlying relatedness between products due to the fact that the product associativity is indeed transitive. [sent-70, score-1.197]
</p><p>14 Given a trend, the algorithm runs in an iterative way and seeks a trade-off between relevance and associativity by propagating the scores on the product graph. [sent-75, score-0.636]
</p><p>15 To the best of our knowledge, our work was the first to consider identifying trend related products by leveraging commercial intents from microblogs. [sent-78, score-0.995]
</p><p>16 We present the data collection and empirical analysis of the impact of hot trends on product sale in Section 3. [sent-81, score-0.577]
</p><p>17 2  Problem Definition  A trend is a hot topic widely discussed by the public,  e. [sent-86, score-0.539]
</p><p>18 Usually, a trend e can be described by a small set of keywords denoted by Ke and a corresponding time span Te. [sent-89, score-0.567]
</p><p>19 T Krenadnd-r aela ctoerdre Psproondduicntgs iIdmeen stpifaicna Ttion: Given a trend e, we assume that the following inputs are available: 1) tweets that contain trend keywords Ke aanvadi 2) a product tdsat thabatas ceo nwtahiinch tr provides a set Kof candidate products P = {p1, p2 , . [sent-90, score-1.57]
</p><p>20 The objective of trend-related products identification is to identify products in P that are related ttiof ctraetnidon e sw tioth idine nthtief yti pmroe span iTne ,P de thnaotte adre by PR. [sent-96, score-0.765]
</p><p>21 In this example, we can see that a few users tweet their product needs related to the trend “Air Pollution”. [sent-99, score-0.651]
</p><p>22 We take Taobao as the product database and present a few related products in it. [sent-100, score-0.596]
</p><p>23 Data and Observations  As discussed earlier, hot trends may exert positive effects on the sale of related products. [sent-110, score-0.422]
</p><p>24 In this section, we will construct a deep analysis on this point by presenting quantitative answers to the following two problems: • Q1: What is the proportion of hot trends that potentially lead to business opportunities, and how is their impact on related products? [sent-111, score-0.405]
</p><p>25 We jointly consider microblogs and e-commerce platforms: we obtain hot trends in microblogs and manually identify trend-related products in e-commerce websites. [sent-116, score-0.788]
</p><p>26 Since trend detection is not our focus, we directly obtained trends from “trending topics” provided by the microblog platform. [sent-123, score-0.491]
</p><p>27 We consider these keywords to be trend  keywords. [sent-128, score-0.547]
</p><p>28 These keywords are dynamically updated and we monitor the trend lists in the considered time 3http://www. [sent-129, score-0.547]
</p><p>29 We define the start and end time of a trend to be the first day and the last day on the trend list respectively, which spans the active interval of a trend. [sent-136, score-0.797]
</p><p>30 We only keep the trend which has an active interval with more than one day. [sent-137, score-0.418]
</p><p>31 For each trend, we use the trend keywords to retrieve all related tweets in the active interval, and use the pattern based method in (Hollerit et al. [sent-138, score-0.67]
</p><p>32 We present a few example patterns used for extracting product keywords in Table 2. [sent-140, score-0.4]
</p><p>33 After that we can obtain a set of product keywords for each trend. [sent-141, score-0.4]
</p><p>34 For each trend, we have the product keyword set together with the trend keywords as described above. [sent-147, score-0.834]
</p><p>35 We use these keywords to retrieve candidate products in the product search engine of Taobao within the active interval of the trend. [sent-148, score-0.875]
</p><p>36 For each candidate product, we further crawl its product page and obtain corresponding related products suggested by Taobao, which are treated as candidate, too. [sent-149, score-0.63]
</p><p>37 The judge is required to make a binary decision whether a product is related to a trend by following a detailed guideline compiled by a senior officer of an e-commerce company in Beijing. [sent-151, score-0.594]
</p><p>38 For each trend, we provide the trend keywords, product keywords in tweets, related tweets, related news articles from China Daily6. [sent-152, score-0.814]
</p><p>39 We only keep the products with the same judgments and the trends with at least one related product. [sent-167, score-0.494]
</p><p>40 Since current e-commerce search engines mainly adopt keyword matching based retrieval method, we further examine the performance of simply using trend keywords as queries. [sent-169, score-0.698]
</p><p>41 We compute the percentage of related/unrelated products with at least one trend keyword in their description. [sent-170, score-0.792]
</p><p>42 Recall that each trend has a category label and possibly a set of related products identified by the judges. [sent-184, score-0.743]
</p><p>43 We refer to a trend with related products as a business-related trend. [sent-185, score-0.743]
</p><p>44 We can see that about 36% of all trends have corresponding related products in Taobao, which indicates that these trends highly relate to business. [sent-188, score-0.601]
</p><p>45 As we discussed earlier, these trends may have indirect impact on product sales. [sent-195, score-0.39]
</p><p>46 1340 Next we continue to examine the impact of hot trends on the sale of related products. [sent-201, score-0.427]
</p><p>47 2, the average sale of related products in all categories gradually increased with trends going on. [sent-204, score-0.566]
</p><p>48 , movie tickets; while products related to China tend to be commodities (e. [sent-208, score-0.415]
</p><p>49 , the mouth masks for the trend of “Air Pollution”) or trending products (e. [sent-210, score-0.954]
</p><p>50 A2: Recall we have discussed that product associativity is useful for improving the coverage of related products. [sent-214, score-0.567]
</p><p>51 Here we would like to quantitatively examine the associativity between related products given a trend. [sent-215, score-0.712]
</p><p>52 For a trend, we first compute the average pairwise similarity between related products in terms of their descriptive texts (e. [sent-216, score-0.439]
</p><p>53 Since there are more unrelated products,  we randomly sample an equal number of unrelated products from the candidate products we previously generated. [sent-219, score-0.802]
</p><p>54 112, while the average similarities of unrelated-unrelated and related-unrelated  Figure 2: An illustrative analysis of the impact on related products in five categories. [sent-223, score-0.46]
</p><p>55 4  The Proposed Method  In this section, we present a graph based ranking algorithm jointly models the relevance of a product and the associativity between products. [sent-229, score-0.66]
</p><p>56 Recall that we have collected a set of product keywords and a set of candidate products for each trend. [sent-230, score-0.792]
</p><p>57 Our aim is to re-rank these candidate products to obtain a better ranking of related products. [sent-231, score-0.421]
</p><p>58 We adopt a biased random walk algorithm: 1) relevance is modeled as biased restart probability and 2) associativity is modeled through random walk on the product graph. [sent-232, score-0.76]
</p><p>59 1 Modeling the Product Relevance Recall that in Section 2 we use the pattern based method to extract product keywords from tweets related to a trend. [sent-234, score-0.495]
</p><p>60 However, to stimulate the real sce-  nario that we want to identify the related products at the beginning of a trend, we only keep the keywords which were contained in tweets published in the first three days when a trend began. [sent-235, score-1.0]
</p><p>61 1341 product keywords directly reveal users’ commercial intents on the trends. [sent-237, score-0.652]
</p><p>62 A good weighting method should be able to leverage commercial interests/intents of users well and emphasize the keywords users really focus on. [sent-241, score-0.413]
</p><p>63 We denote the intent vector of a trend e by Product relevance. [sent-252, score-0.416]
</p><p>64 We denote the weight vector of product p by We measure the product relevance between e and p as rel(e,p) = 4. [sent-256, score-0.55]
</p><p>65 We can see there are four related products for the trend “Air Pollution”. [sent-259, score-0.743]
</p><p>66 Now we expect to mine more related products with “mouth mask” as a known related produc-  e. [sent-261, score-0.416]
</p><p>67 We represent each candidate product as a vertex in the graph and built the link with the cosine similarity between the descriptive texts of two products as the link weight. [sent-277, score-0.653]
</p><p>68 10 We denote the similarity matrix by MP×P and Mi,j denotes the similarity between products pi and pj. [sent-278, score-0.402]
</p><p>69 With this method, it is easy to see that relatedness score can be propagated on the product graph, which better captures underlying associativity between products. [sent-280, score-0.544]
</p><p>70 During the iteration, each product begins to collect relevance evidence from its neighbors on the product graph: the more relevant neighbors it has, the larger score it obtains. [sent-293, score-0.55]
</p><p>71 At the beginning, only “mouth mask” has a large relevance score, with the iteration going on, the relatedness score will be propagated between products on the graph. [sent-303, score-0.53]
</p><p>72 2 Methods to Compare We compare the following methods for inferring relating products: SALES: we rank the candidate products by their historical sales volume descendingly. [sent-314, score-0.468]
</p><p>73 TREND: we use trend keywords as queries and rank the products by their relevance. [sent-315, score-0.905]
</p><p>74 JMRAr+a: it is our method which considers both relevance and associativity in Section 4. [sent-322, score-0.427]
</p><p>75 First, SALES has the worst performance due to the fact that a trend usually happen unexpectedly and historical records may not predict it well. [sent-334, score-0.398]
</p><p>76 This is mainly because that very few related products can be identified only based on trend keywords so feedback method does not work very well on it. [sent-336, score-0.98]
</p><p>77 Note that the major difference between JMRAr and TREND is that JMRAr makes uses of both trend keywords  1343 and product keywords extracted from microblogs. [sent-338, score-0.947]
</p><p>78 This observation supports our assumption that product associativity is very important in this task. [sent-345, score-0.504]
</p><p>79 2 Cold Start It is noteworthy that we have considered all the candidate products within the entire active interval of a trend when constructing the test collection. [sent-367, score-0.81]
</p><p>80 This is mainly to obtain a good coverage of related products since some e-commerce companies might release new products as the response to a trend. [sent-368, score-0.835]
</p><p>81 In the real application scenario, an effective method is expected to identify related products at the beginning of a trend when the e-commerce workers may not make any response to the trend. [sent-372, score-0.774]
</p><p>82 How would it be if we do not have the manually generated trend keywords from workers in product titles and descriptions? [sent-373, score-0.781]
</p><p>83 We first use keyword matching methods to obtain all the products that related to trend keywords. [sent-378, score-0.821]
</p><p>84 , title and description) of these products has been refined to match trend queries by sellers in e-commerce websites. [sent-381, score-0.786]
</p><p>85 We further removed all the trend keywords in the desriptive text of these products, and gradually add the trend keywords back to original products. [sent-382, score-1.094]
</p><p>86 First, performance of all these methods improve with the increase of products with trend keywords. [sent-387, score-0.714]
</p><p>87 In this case, “Houseplant” is identified to be related because it is very similar to “Air Detector” (We have presented the corresponding most associative products in brackets in Table 5). [sent-402, score-0.387]
</p><p>88 Search engine retrieval errors: in this paper, we rely on nthee rTetaroiebavoal product sinear thchis engine for candidate product generation. [sent-409, score-0.474]
</p><p>89 Clearly, pseudorelevance feedback will also bring additional ir-  µ  relevant products if top search results contain irrelevant ones. [sent-414, score-0.425]
</p><p>90 Sample keywords learnt from microblogs: air pollution, mouth mask, air, air purifier, respirator, house, mask, warm, bus, car, purified water  1@P0 0 0. [sent-417, score-0.67]
</p><p>91 a) The impact of the damping factor and b) the impact of the number of top products used for pseudo feedback. [sent-420, score-0.509]
</p><p>92 , Intuitively, a larger value of emphasize the associativity more while a smaller value emphasize the relevance more. [sent-427, score-0.427]
</p><p>93 We further examine the impact of the num1345 ber of top products used for pseudo feedback for JMRAr+fb and JMRAr+a+fb. [sent-434, score-0.521]
</p><p>94 We use JMRAr+a+fb as the examined method since both relevance and associativity relies on the text information. [sent-442, score-0.427]
</p><p>95 title is usually carefully compiled by e-commerce sellers, thus it reveals the most highlights of the products but very short; while description contains more informative text but tends to incorporate noise. [sent-448, score-0.444]
</p><p>96 Sicne we group products by the categorial label, the number of candidate products is usually very small. [sent-457, score-0.772]
</p><p>97 Our work do not explicitly incorporate a trend detection component, instead we make use of the trending topics provided by the microblogs platforms. [sent-472, score-0.506]
</p><p>98 In addition, we also present how to make use ofthese identified intents and our paper focuses on how to identify trend related products for e-commerce companies to improve service when faced with hot trends. [sent-482, score-1.073]
</p><p>99 8  Conclusions  In this paper, we make the first attempt to identify trend related products by leveraging commercial intents from microblogs. [sent-483, score-0.995]
</p><p>100 For future work, we will consider incorporating a trend detection component into our method, which can be more flexible to adapt to various trend signals. [sent-490, score-0.712]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('jmrar', 0.436), ('products', 0.358), ('trend', 0.356), ('associativity', 0.295), ('fb', 0.214), ('product', 0.209), ('keywords', 0.191), ('mouth', 0.165), ('air', 0.157), ('hot', 0.149), ('intents', 0.144), ('mask', 0.144), ('relevance', 0.132), ('pollution', 0.113), ('commercial', 0.108), ('trends', 0.107), ('taobao', 0.094), ('keyword', 0.078), ('microblogs', 0.075), ('trending', 0.075), ('sale', 0.072), ('tweets', 0.066), ('intent', 0.06), ('business', 0.059), ('cold', 0.058), ('users', 0.057), ('sales', 0.056), ('buy', 0.049), ('hollerit', 0.047), ('jmra', 0.047), ('purifier', 0.047), ('pseudo', 0.047), ('feedback', 0.046), ('restart', 0.044), ('title', 0.044), ('relatedness', 0.04), ('impact', 0.04), ('walk', 0.04), ('companies', 0.037), ('houseplant', 0.035), ('plants', 0.035), ('strohmaier', 0.035), ('weibo', 0.035), ('purchase', 0.035), ('discussed', 0.034), ('interval', 0.034), ('candidate', 0.034), ('opportunities', 0.033), ('kr', 0.033), ('salton', 0.033), ('illustrative', 0.033), ('china', 0.031), ('response', 0.031), ('oll', 0.031), ('chakrabarti', 0.031), ('exert', 0.031), ('descriptive', 0.03), ('examine', 0.03), ('media', 0.03), ('related', 0.029), ('movie', 0.028), ('sellers', 0.028), ('active', 0.028), ('microblog', 0.028), ('social', 0.028), ('event', 0.026), ('zhao', 0.026), ('retweet', 0.026), ('sakaki', 0.026), ('unrelated', 0.026), ('titles', 0.025), ('jointly', 0.024), ('ashkan', 0.024), ('bahmani', 0.024), ('damping', 0.024), ('jinpeng', 0.024), ('phelan', 0.024), ('rtt', 0.024), ('trenddriven', 0.024), ('sina', 0.023), ('xiaoming', 0.023), ('wayne', 0.023), ('start', 0.023), ('platforms', 0.022), ('movies', 0.022), ('similarity', 0.022), ('largest', 0.022), ('usually', 0.022), ('retrieval', 0.022), ('release', 0.022), ('proportion', 0.021), ('search', 0.021), ('twitter', 0.021), ('gerard', 0.021), ('welch', 0.021), ('kwak', 0.021), ('potter', 0.021), ('description', 0.02), ('historical', 0.02), ('span', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="131-tfidf-1" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>Author: Jinpeng Wang ; Wayne Xin Zhao ; Haitian Wei ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Hot trends are likely to bring new business opportunities. For example, “Air Pollution” might lead to a significant increase of the sales of related products, e.g., mouth mask. For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. In this paper, we take the initiative to study the task of how to identify trend related products. The major novelty of our work is that we automatically learn commercial intents revealed from microblogs. We carefully construct a data collection for this task and present quite a few insightful findings. In order to solve this problem, we further propose a graph based method, which jointly models relevance and associativity. We perform extensive experiments and the results showed that our methods are very effective.</p><p>2 0.084783748 <a title="131-tfidf-2" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>Author: Qiming Diao ; Jing Jiang</p><p>Abstract: With the rapid growth of social media, Twitter has become one of the most widely adopted platforms for people to post short and instant message. On the one hand, people tweets about their daily lives, and on the other hand, when major events happen, people also follow and tweet about them. Moreover, people’s posting behaviors on events are often closely tied to their personal interests. In this paper, we try to model topics, events and users on Twitter in a unified way. We propose a model which combines an LDA-like topic model and the Recurrent Chinese Restaurant Process to capture topics and events. We further propose a duration-based regularization component to find bursty events. We also propose to use event-topic affinity vectors to model the asso- . ciation between events and topics. Our experiments shows that our model can accurately identify meaningful events and the event-topic affinity vectors are effective for event recommendation and grouping events by topics.</p><p>3 0.073698476 <a title="131-tfidf-3" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>Author: Laura Chiticariu ; Yunyao Li ; Frederick R. Reiss</p><p>Abstract: The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape ofIE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.</p><p>4 0.06638623 <a title="131-tfidf-4" href="./emnlp-2013-Is_Twitter_A_Better_Corpus_for_Measuring_Sentiment_Similarity%3F.html">109 emnlp-2013-Is Twitter A Better Corpus for Measuring Sentiment Similarity?</a></p>
<p>Author: Shi Feng ; Le Zhang ; Binyang Li ; Daling Wang ; Ge Yu ; Kam-Fai Wong</p><p>Abstract: Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word’s sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people’s sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.</p><p>5 0.064498447 <a title="131-tfidf-5" href="./emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching.html">97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</a></p>
<p>Author: Ahmed Hassan</p><p>Abstract: Web search users frequently modify their queries in hope of receiving better results. This process is referred to as “Query Reformulation”. Previous research has mainly focused on proposing query reformulations in the form of suggested queries for users. Some research has studied the problem of predicting whether the current query is a reformulation of the previous query or not. However, this work has been limited to bag-of-words models where the main signals being used are word overlap, character level edit distance and word level edit distance. In this work, we show that relying solely on surface level text similarity results in many false positives where queries with different intents yet similar topics are mistakenly predicted as query reformulations. We propose a new representation for Web search queries based on identifying the concepts in queries and show that we can sig- nificantly improve query reformulation performance using features of query concepts.</p><p>6 0.062760085 <a title="131-tfidf-6" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>7 0.057628963 <a title="131-tfidf-7" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>8 0.057439096 <a title="131-tfidf-8" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>9 0.052772064 <a title="131-tfidf-9" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>10 0.052613944 <a title="131-tfidf-10" href="./emnlp-2013-A_Walk-Based_Semantically_Enriched_Tree_Kernel_Over_Distributed_Word_Representations.html">17 emnlp-2013-A Walk-Based Semantically Enriched Tree Kernel Over Distributed Word Representations</a></p>
<p>11 0.051809885 <a title="131-tfidf-11" href="./emnlp-2013-Authorship_Attribution_of_Micro-Messages.html">27 emnlp-2013-Authorship Attribution of Micro-Messages</a></p>
<p>12 0.05125441 <a title="131-tfidf-12" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>13 0.047852799 <a title="131-tfidf-13" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>14 0.045302875 <a title="131-tfidf-14" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>15 0.043398011 <a title="131-tfidf-15" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>16 0.042786129 <a title="131-tfidf-16" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>17 0.041945904 <a title="131-tfidf-17" href="./emnlp-2013-Semi-Supervised_Feature_Transformation_for_Dependency_Parsing.html">168 emnlp-2013-Semi-Supervised Feature Transformation for Dependency Parsing</a></p>
<p>18 0.040895358 <a title="131-tfidf-18" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>19 0.038121115 <a title="131-tfidf-19" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>20 0.03784705 <a title="131-tfidf-20" href="./emnlp-2013-Automatic_Domain_Partitioning_for_Multi-Domain_Learning.html">29 emnlp-2013-Automatic Domain Partitioning for Multi-Domain Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.127), (1, 0.066), (2, -0.083), (3, -0.001), (4, 0.04), (5, -0.035), (6, 0.033), (7, 0.065), (8, 0.034), (9, -0.007), (10, -0.048), (11, 0.07), (12, -0.055), (13, -0.033), (14, 0.017), (15, -0.051), (16, 0.016), (17, 0.024), (18, -0.037), (19, -0.018), (20, -0.007), (21, -0.071), (22, -0.036), (23, 0.027), (24, -0.112), (25, 0.073), (26, -0.071), (27, 0.029), (28, -0.075), (29, -0.028), (30, -0.062), (31, 0.052), (32, 0.08), (33, -0.069), (34, 0.135), (35, 0.059), (36, -0.007), (37, 0.008), (38, 0.033), (39, -0.033), (40, -0.027), (41, 0.09), (42, 0.072), (43, -0.111), (44, -0.108), (45, 0.018), (46, -0.014), (47, -0.044), (48, -0.049), (49, 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9555912 <a title="131-lsi-1" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>Author: Jinpeng Wang ; Wayne Xin Zhao ; Haitian Wei ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Hot trends are likely to bring new business opportunities. For example, “Air Pollution” might lead to a significant increase of the sales of related products, e.g., mouth mask. For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. In this paper, we take the initiative to study the task of how to identify trend related products. The major novelty of our work is that we automatically learn commercial intents revealed from microblogs. We carefully construct a data collection for this task and present quite a few insightful findings. In order to solve this problem, we further propose a graph based method, which jointly models relevance and associativity. We perform extensive experiments and the results showed that our methods are very effective.</p><p>2 0.5512591 <a title="131-lsi-2" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>Author: William Yang Wang ; Edward Lin ; John Kominek</p><p>Abstract: We propose a Laplacian structured sparsity model to study computational branding analytics. To do this, we collected customer reviews from Starbucks, Dunkin’ Donuts, and other coffee shops across 38 major cities in the Midwest and Northeastern regions of USA. We study the brand related language use through these reviews, with focuses on the brand satisfaction and gender factors. In particular, we perform three tasks: automatic brand identification from raw text, joint brand-satisfaction prediction, and joint brandgender-satisfaction prediction. This work extends previous studies in text classification by incorporating the dependency and interaction among local features in the form of structured sparsity in a log-linear model. Our quantitative evaluation shows that our approach which combines the advantages of graphical modeling and sparsity modeling techniques significantly outperforms various standard and stateof-the-art text classification algorithms. In addition, qualitative analysis of our model reveals important features of the language uses associated with the specific brands.</p><p>3 0.51415467 <a title="131-lsi-3" href="./emnlp-2013-Open-Domain_Fine-Grained_Class_Extraction_from_Web_Search_Queries.html">142 emnlp-2013-Open-Domain Fine-Grained Class Extraction from Web Search Queries</a></p>
<p>Author: Marius Pasca</p><p>Abstract: This paper introduces a method for extracting fine-grained class labels ( “countries with double taxation agreements with india ”) from Web search queries. The class labels are more numerous and more diverse than those produced by current extraction methods. Also extracted are representative sets of instances (singapore, united kingdom) for the class labels.</p><p>4 0.47740039 <a title="131-lsi-4" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>5 0.45637432 <a title="131-lsi-5" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>Author: Laura Chiticariu ; Yunyao Li ; Frederick R. Reiss</p><p>Abstract: The rise of “Big Data” analytics over unstructured text has led to renewed interest in information extraction (IE). We surveyed the landscape ofIE technologies and identified a major disconnect between industry and academia: while rule-based IE dominates the commercial world, it is widely regarded as dead-end technology by the academia. We believe the disconnect stems from the way in which the two communities measure the benefits and costs of IE, as well as academia’s perception that rulebased IE is devoid of research challenges. We make a case for the importance of rule-based IE to industry practitioners. We then lay out a research agenda in advancing the state-of-theart in rule-based IE systems which we believe has the potential to bridge the gap between academic research and industry practice.</p><p>6 0.44956669 <a title="131-lsi-6" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>7 0.44940725 <a title="131-lsi-7" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>8 0.42966184 <a title="131-lsi-8" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>9 0.42750677 <a title="131-lsi-9" href="./emnlp-2013-A_Unified_Model_for_Topics%2C_Events_and_Users_on_Twitter.html">16 emnlp-2013-A Unified Model for Topics, Events and Users on Twitter</a></p>
<p>10 0.41270232 <a title="131-lsi-10" href="./emnlp-2013-Centering_Similarity_Measures_to_Reduce_Hubs.html">44 emnlp-2013-Centering Similarity Measures to Reduce Hubs</a></p>
<p>11 0.40058225 <a title="131-lsi-11" href="./emnlp-2013-Well-Argued_Recommendation%3A_Adaptive_Models_Based_on_Words_in_Recommender_Systems.html">200 emnlp-2013-Well-Argued Recommendation: Adaptive Models Based on Words in Recommender Systems</a></p>
<p>12 0.38119555 <a title="131-lsi-12" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>13 0.37879944 <a title="131-lsi-13" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>14 0.37377381 <a title="131-lsi-14" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>15 0.3598105 <a title="131-lsi-15" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<p>16 0.34994471 <a title="131-lsi-16" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>17 0.3493351 <a title="131-lsi-17" href="./emnlp-2013-Automatic_Domain_Partitioning_for_Multi-Domain_Learning.html">29 emnlp-2013-Automatic Domain Partitioning for Multi-Domain Learning</a></p>
<p>18 0.34843916 <a title="131-lsi-18" href="./emnlp-2013-Improving_Web_Search_Ranking_by_Incorporating_Structured_Annotation_of_Queries.html">105 emnlp-2013-Improving Web Search Ranking by Incorporating Structured Annotation of Queries</a></p>
<p>19 0.34751299 <a title="131-lsi-19" href="./emnlp-2013-Identifying_Web_Search_Query_Reformulation_using_Concept_based_Matching.html">97 emnlp-2013-Identifying Web Search Query Reformulation using Concept based Matching</a></p>
<p>20 0.34052765 <a title="131-lsi-20" href="./emnlp-2013-A_Walk-Based_Semantically_Enriched_Tree_Kernel_Over_Distributed_Word_Representations.html">17 emnlp-2013-A Walk-Based Semantically Enriched Tree Kernel Over Distributed Word Representations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.023), (18, 0.018), (22, 0.055), (29, 0.02), (30, 0.063), (50, 0.015), (51, 0.127), (58, 0.355), (66, 0.045), (71, 0.086), (75, 0.029), (90, 0.016), (96, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74861884 <a title="131-lda-1" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>Author: Jinpeng Wang ; Wayne Xin Zhao ; Haitian Wei ; Hongfei Yan ; Xiaoming Li</p><p>Abstract: Hot trends are likely to bring new business opportunities. For example, “Air Pollution” might lead to a significant increase of the sales of related products, e.g., mouth mask. For ecommerce companies, it is very important to make rapid and correct response to these hot trends in order to improve product sales. In this paper, we take the initiative to study the task of how to identify trend related products. The major novelty of our work is that we automatically learn commercial intents revealed from microblogs. We carefully construct a data collection for this task and present quite a few insightful findings. In order to solve this problem, we further propose a graph based method, which jointly models relevance and associativity. We perform extensive experiments and the results showed that our methods are very effective.</p><p>2 0.6325711 <a title="131-lda-2" href="./emnlp-2013-Easy_Victories_and_Uphill_Battles_in_Coreference_Resolution.html">67 emnlp-2013-Easy Victories and Uphill Battles in Coreference Resolution</a></p>
<p>Author: Greg Durrett ; Dan Klein</p><p>Abstract: Classical coreference systems encode various syntactic, discourse, and semantic phenomena explicitly, using heterogenous features computed from hand-crafted heuristics. In contrast, we present a state-of-the-art coreference system that captures such phenomena implicitly, with a small number of homogeneous feature templates examining shallow properties of mentions. Surprisingly, our features are actually more effective than the corresponding hand-engineered ones at modeling these key linguistic phenomena, allowing us to win “easy victories” without crafted heuristics. These features are successful on syntax and discourse; however, they do not model semantic compatibility well, nor do we see gains from experiments with shallow semantic features from the literature, suggesting that this approach to semantics is an “uphill battle.” Nonetheless, our final system1 outperforms the Stanford system (Lee et al. (201 1), the winner of the CoNLL 2011 shared task) by 3.5% absolute on the CoNLL metric and outperforms the IMS system (Bj o¨rkelund and Farkas (2012), the best publicly available English coreference system) by 1.9% absolute.</p><p>3 0.62254816 <a title="131-lda-3" href="./emnlp-2013-Improving_Web_Search_Ranking_by_Incorporating_Structured_Annotation_of_Queries.html">105 emnlp-2013-Improving Web Search Ranking by Incorporating Structured Annotation of Queries</a></p>
<p>Author: Xiao Ding ; Zhicheng Dou ; Bing Qin ; Ting Liu ; Ji-rong Wen</p><p>Abstract: Web users are increasingly looking for structured data, such as lyrics, job, or recipes, using unstructured queries on the web. However, retrieving relevant results from such data is a challenging problem due to the unstructured language of the web queries. In this paper, we propose a method to improve web search ranking by detecting Structured Annotation of queries based on top search results. In a structured annotation, the original query is split into different units that are associated with semantic attributes in the corresponding domain. We evaluate our techniques using real world queries and achieve significant improvement. . 1</p><p>4 0.49466664 <a title="131-lda-4" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>Author: Jonathan K. Kummerfeld ; Dan Klein</p><p>Abstract: Coreference resolution metrics quantify errors but do not analyze them. Here, we consider an automated method of categorizing errors in the output of a coreference system into intuitive underlying error types. Using this tool, we first compare the error distributions across a large set of systems, then analyze common errors across the top ten systems, empirically characterizing the major unsolved challenges of the coreference resolution task.</p><p>5 0.47168651 <a title="131-lda-5" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>Author: Fang Kong ; Hwee Tou Ng</p><p>Abstract: Coreference resolution plays a critical role in discourse analysis. This paper focuses on exploiting zero pronouns to improve Chinese coreference resolution. In particular, a simplified semantic role labeling framework is proposed to identify clauses and to detect zero pronouns effectively, and two effective methods (refining syntactic parser and refining learning example generation) are employed to exploit zero pronouns for Chinese coreference resolution. Evaluation on the CoNLL-2012 shared task data set shows that zero pronouns can significantly improve Chinese coreference resolution.</p><p>6 0.45251897 <a title="131-lda-6" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>7 0.45232829 <a title="131-lda-7" href="./emnlp-2013-Chinese_Zero_Pronoun_Resolution%3A_Some_Recent_Advances.html">45 emnlp-2013-Chinese Zero Pronoun Resolution: Some Recent Advances</a></p>
<p>8 0.44857305 <a title="131-lda-8" href="./emnlp-2013-Paraphrasing_4_Microblog_Normalization.html">151 emnlp-2013-Paraphrasing 4 Microblog Normalization</a></p>
<p>9 0.4472042 <a title="131-lda-9" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>10 0.43171 <a title="131-lda-10" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>11 0.4312945 <a title="131-lda-11" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>12 0.43106914 <a title="131-lda-12" href="./emnlp-2013-Joint_Coreference_Resolution_and_Named-Entity_Linking_with_Multi-Pass_Sieves.html">112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</a></p>
<p>13 0.42394701 <a title="131-lda-13" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>14 0.42356375 <a title="131-lda-14" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>15 0.42158002 <a title="131-lda-15" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>16 0.42074472 <a title="131-lda-16" href="./emnlp-2013-Exploiting_Discourse_Analysis_for_Article-Wide_Temporal_Classification.html">76 emnlp-2013-Exploiting Discourse Analysis for Article-Wide Temporal Classification</a></p>
<p>17 0.41974628 <a title="131-lda-17" href="./emnlp-2013-Microblog_Entity_Linking_by_Leveraging_Extra_Posts.html">130 emnlp-2013-Microblog Entity Linking by Leveraging Extra Posts</a></p>
<p>18 0.41813576 <a title="131-lda-18" href="./emnlp-2013-A_temporal_model_of_text_periodicities_using_Gaussian_Processes.html">18 emnlp-2013-A temporal model of text periodicities using Gaussian Processes</a></p>
<p>19 0.41539854 <a title="131-lda-19" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>20 0.41535482 <a title="131-lda-20" href="./emnlp-2013-Cascading_Collective_Classification_for_Bridging_Anaphora_Recognition_using_a_Rich_Linguistic_Feature_Set.html">43 emnlp-2013-Cascading Collective Classification for Bridging Anaphora Recognition using a Rich Linguistic Feature Set</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
