<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-36" href="#">emnlp2013-36</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</h1>
<br/><p>Source: <a title="emnlp-2013-36-pdf" href="http://aclweb.org/anthology//D/D13/D13-1069.pdf">pdf</a></p><p>Author: Tengfei Ma ; Hiroshi Nakagawa</p><p>Abstract: Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.</p><p>Reference: <a title="emnlp-2013-36-reference" href="../emnlp2013_reference/emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp  ,  Abstract Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. [sent-6, score-0.496]
</p><p>2 In various summarization tasks, the summary length is manually defined. [sent-7, score-0.93]
</p><p>3 However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. [sent-8, score-0.988]
</p><p>4 It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. [sent-9, score-0.548]
</p><p>5 In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. [sent-10, score-0.591]
</p><p>6 Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination. [sent-12, score-0.393]
</p><p>7 1 Introduction Text summarization is the process of generating a short version of a given text to indicate its main topics. [sent-13, score-0.422]
</p><p>8 As the number of documents on the web exponentially increases, text summarization has attracted increasing attention, because it can help people get the most important information within a short time. [sent-14, score-0.454]
</p><p>9 736 In most of the existing summarization systems, people need to first define a constant length to restrict all the output summaries. [sent-15, score-0.524]
</p><p>10 Take the multi-document summarization as an example, generating the summaries of the same length for a 5-document cluster and a 50-document cluster is intuitively improper. [sent-17, score-0.876]
</p><p>11 Research on summary length dates back in the late 90s. [sent-20, score-0.555]
</p><p>12 (1999) studied the characteristics of a good summary (single-document summarization for news) and showed an empirical distribution of summary length over document size. [sent-22, score-1.403]
</p><p>13 However, the length problem has been gradually ignored later, since researchers need to fix the length so as to estimate different summarization models conveniently. [sent-23, score-0.673]
</p><p>14 A typical instance is the Document Understanding Conferences (DUC)1 , which provide authoritative evaluation for summarization systems. [sent-24, score-0.375]
</p><p>15 The DUC conferences collect news aritcles as the input data and define various summarization tasks, such as generic multi-document summarization, query-focused summarization and update summarization. [sent-25, score-0.787]
</p><p>16 hc o2d0s1 i3n A Nsastoucria lti Loan fgoura Cgoem Ppruotcaetsiosin agl, L piang eusis 7t3ic6s–746, summaries are provided to evaluate the results ofdifferent summarization systems. [sent-30, score-0.619]
</p><p>17 Limiting the length of summaries contributed a lot to the development of summarization techniques, but as we discussed before, in many cases keeping the summaries of the same size is not a good choice. [sent-31, score-1.012]
</p><p>18 Moreover, even in constant-length summarization, how to define a proper size of summaries for the summarization tasks is quite a problem. [sent-32, score-0.659]
</p><p>19 A short summary may sacrifice the coverage, while a long summary may cause redundance. [sent-35, score-0.812]
</p><p>20 In this work, we aim to find the proper length for document summarization automatically and generate varying-length summaries based on the document itself. [sent-37, score-0.942]
</p><p>21 The varying-length summarization is more robust for unbalanced clusters. [sent-38, score-0.403]
</p><p>22 It can also  provide a recommended size as the predefined summary length for general constant-length summarization systems. [sent-39, score-0.995]
</p><p>23 We advance a Bayesian nonparametric model of extractive multi-document summarization to achieve this goal. [sent-40, score-0.521]
</p><p>24 In order to integrate the BNP methods into document summarization, we follow the assumption that the original documents should be recovered from the reconstruction of summaries (Ma and Wan, 2010; He et al. [sent-44, score-0.544]
</p><p>25 Then we construct a Bayesian framework for summarization and use the variational approximation for inference. [sent-47, score-0.447]
</p><p>26 Besides, we reorganize the original documents to generate some new datasets, and examine how the summary length  changes on the new data. [sent-49, score-0.672]
</p><p>27 The results prove that our summary length determination is rational and neces737  sary on unbalanced data. [sent-50, score-0.627]
</p><p>28 It demonstrated that an evaluation of summarization systems must take into account both the compression ratios and the characteristics of the documents. [sent-55, score-0.498]
</p><p>29 (2008) developed an incremental summary containing additional sentences that provide context. [sent-58, score-0.437]
</p><p>30 (2008) studied the impact of query types on summary length of search results. [sent-60, score-0.555]
</p><p>31 Other than the content of original  documents, there are also some other factors affecting summary length especially in specific applications. [sent-61, score-0.624]
</p><p>32 For example, Sweeney and Crestani (2006) studied the relation between screen size and summary length on mobile platforms. [sent-62, score-0.603]
</p><p>33 The conclusion of their work is the optimal summary size always falls into the shorter one regardless of the screen size. [sent-63, score-0.454]
</p><p>34 In sum, the previous works on summary length mostly put their attention on the empirical study of the phenomenon, factors and impacts of summary length. [sent-64, score-0.992]
</p><p>35 Nevertheless, they demonstrated the importance of summary length in summarization and the reasonability of determining summary length based on content of news documents (Goldstein et al. [sent-66, score-1.564]
</p><p>36 As our model is mainly applied for generic summarization of news articles, we do not consider the factor of screen size in mobile applications. [sent-69, score-0.423]
</p><p>37 Recently, some BNP models are also involved in document summarization approaches (Celikyilmaz and Hakkani-T u¨r, 2010; Chang et al. [sent-78, score-0.442]
</p><p>38 BNP here only impacts the number and the structure of the latent topics, but the summarization framework is still constant-length. [sent-82, score-0.402]
</p><p>39 Our  BNP summarization model differs from the previous models. [sent-83, score-0.375]
</p><p>40 The BNP method in our model are directly used to determine the number of summary sentences but not latent topics. [sent-85, score-0.464]
</p><p>41 1 The Beta Process and the Bernoulli process The beta process(BP) (Thibaux and Jordan, 2007; Paisley and Carin, 2009) and the related Indian buffet process(IBP) (Griffiths and Ghahramani, 2005) are widely applied to factor/feature analysis. [sent-89, score-0.38]
</p><p>42 bFetinai ptero Approximation: BThe beta process is defined on an infinite parameter space, but sometimes we can also use its finite approximation by simply setting N to a large number (Paisley and Carin, 2009). [sent-98, score-0.417]
</p><p>43 e to the conjugation between the beta process priors and Bernoulli process, the posterior of B given M samples X1, X2, . [sent-106, score-0.38]
</p><p>44 arginalizing over the beta process measure B and taking α = 1, provides a predictive distribution on indicators known as the Indian buffet process (IBP) (Thibaux and Jordan, 2007). [sent-115, score-0.427]
</p><p>45 2 Framework of BNP Summarization Most existing approaches for generic extractive summarization are based on sentence ranking. [sent-119, score-0.419]
</p><p>46 One approach to global optimization of summarization is to regard the summarization as a reconstruction process (Ma and Wan, 2010; He et al. [sent-123, score-0.913]
</p><p>47 Considering a good summary must catch most of the important information in original documents, the original documents are assumed able to be recovered from summaries with some information loss. [sent-125, score-0.805]
</p><p>48 Then the summarization problem is turned into finding the sentences that cause the least reconstruction error (or information loss). [sent-126, score-0.522]
</p><p>49 In this paper, we follow the assumption and formulate summarization as a Bayesian framework. [sent-127, score-0.375]
</p><p>50 , sN], we denote all corresponding summary sentences as V = [v1, . [sent-136, score-0.437]
</p><p>51 , vn] , where n is the number of summary sentences and N is the number of all sentences in the cluster. [sent-139, score-0.468]
</p><p>52 Following the reconstruction assumption, a candidate sentence vi can be approximated by the linear combination of summary sentences: si ? [sent-141, score-0.522]
</p><p>53 Thus the document can also be approximately represented by a linear combination of summary sentences (because it is the sum of the sentences). [sent-147, score-0.504]
</p><p>54 , 2012) aims to find the summary sentence set that ? [sent-154, score-0.406]
</p><p>55 Now we consider the reconstruction for each document, if we see the document xi as the dependent variable, and the summary sentence set S as the  ? [sent-165, score-0.686]
</p><p>56 As our system is an extractive summarization model, all the summary sentences are from the original document cluster. [sent-175, score-0.961]
</p><p>57 Integrating tehe w eliingehatrs {rweconstruc}tio inn (4) and the beta process3 (1), we get the complete process of summary sentence selection as follows. [sent-193, score-0.741]
</p><p>58 As zi is a binary vector, we only calculate the probability of zij = 1and zij = 0. [sent-227, score-0.483]
</p><p>59 (19)  5 Experiments To test the capability ofour BNP summarization systems, we design a series of experiments. [sent-265, score-0.375]
</p><p>60 To demonstrate the summaries extracted by our model have good qualities and the summary length determined by the model is reasonable. [sent-267, score-0.852]
</p><p>61 To give examples where varying summary length is necessary. [sent-269, score-0.591]
</p><p>62 1 Evaluation of Summary Qualities First, we implement our BNP summarization model on the DUC2004 dataset, with summary length not limited. [sent-278, score-0.93]
</p><p>63 For the sentence selection step, we use the variational inference described in Section 4, where the parameters in the beta process (5) are set as γ = 1, α = 1. [sent-281, score-0.38]
</p><p>64 The summaries that we finally generate have an average length of 164 words. [sent-282, score-0.393]
</p><p>65 The met-  ric of Rouge f-measure takes into consideration the summary length in evaluation, so it is proper for our experiments. [sent-297, score-0.595]
</p><p>66 The reason that the Linear system gets a little better result may be its weights for linear combination of summary sentences are guaranteed nonnegative while in our model the weights are zeromean Gaussian variables. [sent-306, score-0.437]
</p><p>67 This result partly demonstrates our length  determination is rational and it can be used as the recommended length for some constant-length summarization systems, such as the Linear . [sent-312, score-0.751]
</p><p>68 Louis and Nenkova (2009) advanced an automatic summary evaluation without human models. [sent-336, score-0.406]
</p><p>69 They used the Jensen-Shannon divergence(JSD) between the input documents and the summaries as a feature, and got high correlation with human evaluations and the rouge metric. [sent-337, score-0.399]
</p><p>70 Recently, it has also been successfully employed for text clustering (Slonim, 2002) and document summarization (Ma and Wan, 2010). [sent-344, score-0.442]
</p><p>71 A good summary balances the compression ratio and the information loss, thus minimizing the function (20). [sent-348, score-0.482]
</p><p>72 So we use the function (20)(we set β = 1) to compare which summary is a better compression. [sent-349, score-0.406]
</p><p>73 The JS-divergence (JSD), which has been proved to have high correlation with manual evaluation (Louis and Nenkova, 2009) for constant-length summary evaluation, is utilized as the distortion in the function. [sent-350, score-0.442]
</p><p>74 4, the curve of ratedist values has a inverse tendency of Rouge measures (Rouge-1, Rouge-2, Rouge-L and Rouge-SU4 are all listed here), and the best performance also occurs around the summary length of 164 words. [sent-360, score-0.594]
</p><p>75 This even more clearly reveals that the BNP summarization achieves a perfect tradeoff between compactness and informativeness. [sent-361, score-0.415]
</p><p>76 3 Necessity of Varying Summary Length In this section, we discuss the necessity of length determination and how summary length changes according to the input data. [sent-381, score-0.748]
</p><p>77 Now we use them to indicate varying summary length is necessary when the input data varies a lot. [sent-383, score-0.591]
</p><p>78 Table 1shows the average summary length of different data sets. [sent-384, score-0.555]
</p><p>79 The results satisfy the intuitive ex-  pectation of summary length change. [sent-385, score-0.555]
</p><p>80 When we split a 10-document cluster into two 5-document parts, we expect the average summary length of the new clusters to be a little smaller than the original cluster but much larger than half of the original length, because all the documents concentrate on the same themes. [sent-386, score-0.866]
</p><p>81 When we combine two clusters into one, the summary length should be smaller than the sum of the summary lengths of two original clusters due to some unavoidable common background information but much larger than the summary length of original clusters. [sent-387, score-1.762]
</p><p>82 1O6ri4ginalSe1pa15rateCom2b5i0ned1Com2b3i1ned2 Table 1: Average summary length (number of words) on different datasets We also run the Linear Representation system at different lengths on the new datasets and evaluate the qualities. [sent-388, score-0.703]
</p><p>83 Results in Table 2,3,4 show the summaries which do not change the predefined length  5 perform significantly worse than the BNP summarization. [sent-390, score-0.424]
</p><p>84 So varying summary length is necessary when the input changes a lot, and our model can just give a good match to the new data. [sent-392, score-0.591]
</p><p>85 This characteristic also can be used to give recommended summary length for extractive summarization systems when given unknown data. [sent-393, score-1.008]
</p><p>86 4007 Table 2: Comparison of summary lengths on Separate Dataset. [sent-397, score-0.48]
</p><p>87 3wN2oP3r8ds Table 3: Comparison of summary lengths on Combined1 Dataset. [sent-401, score-0.48]
</p><p>88 Then we observe the summary length distributions and compression ratios according to document  size(the length of the whole documents in a cluster). [sent-402, score-0.973]
</p><p>89 3wN3oP2r6ds Table 4: Comparison of summary lengths on Combined2 Dataset. [sent-407, score-0.48]
</p><p>90 Figure 6: The distribution of summary word length. [sent-412, score-0.406]
</p><p>91 6 Conclusion and Future Work In this paper, we present a new problem of finding a proper summary length for multi-document summarization based on the document content. [sent-414, score-1.037]
</p><p>92 We use the beta process as the prior to construct a Bayesian framework for summary sentence selec-  tion. [sent-416, score-0.741]
</p><p>93 We demonstrate the summaries we extract have good qualities and the length determination of our system is rational. [sent-418, score-0.49]
</p><p>94 A system which can determine the best length even for abstractive summarization will be better. [sent-421, score-0.524]
</p><p>95 In future we may consider more human factors, and prove the summary length determined by our system agrees with human preference. [sent-423, score-0.555]
</p><p>96 In addition, in the experiments, we only use the imbalanced datasets as the example that intuitively needs varying the summary length. [sent-424, score-0.479]
</p><p>97 However, the data type is also important to impact the summary length. [sent-425, score-0.406]
</p><p>98 In future, we may extend the work by studying more cases that need varying summary length. [sent-426, score-0.442]
</p><p>99 Effective search results summary size and device screen size: Is there a relationship. [sent-520, score-0.454]
</p><p>100 Effective search results summary size and device screen size: Is there a relationship. [sent-532, score-0.454]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('summary', 0.406), ('bnp', 0.394), ('summarization', 0.375), ('beta', 0.261), ('summaries', 0.244), ('zij', 0.203), ('length', 0.149), ('reconstruction', 0.116), ('paisley', 0.108), ('nonparametric', 0.102), ('ln', 0.098), ('xi', 0.097), ('bernoulli', 0.083), ('bayesian', 0.081), ('goldstein', 0.08), ('bk', 0.08), ('documents', 0.079), ('zi', 0.077), ('rouge', 0.076), ('compression', 0.076), ('ij', 0.076), ('lengths', 0.074), ('buffet', 0.072), ('jsd', 0.072), ('sjtsj', 0.072), ('sweeney', 0.072), ('indian', 0.071), ('zj', 0.071), ('document', 0.067), ('jn', 0.063), ('bp', 0.063), ('duc', 0.062), ('exp', 0.06), ('cluster', 0.054), ('carin', 0.054), ('gershman', 0.054), ('ibp', 0.054), ('kaisser', 0.054), ('ma', 0.054), ('gamma', 0.053), ('qualities', 0.053), ('wan', 0.051), ('clusters', 0.048), ('infinite', 0.048), ('screen', 0.048), ('process', 0.047), ('hdp', 0.047), ('qj', 0.047), ('ratios', 0.047), ('zin', 0.047), ('variational', 0.045), ('nj', 0.044), ('extractive', 0.044), ('nenkova', 0.044), ('determination', 0.044), ('conjugate', 0.043), ('proper', 0.04), ('compactness', 0.04), ('inverse', 0.039), ('posterior', 0.039), ('original', 0.038), ('wj', 0.037), ('datasets', 0.037), ('update', 0.037), ('varying', 0.036), ('distortion', 0.036), ('bcovi', 0.036), ('bep', 0.036), ('crestani', 0.036), ('darling', 0.036), ('invgamma', 0.036), ('ratedistortion', 0.036), ('sjt', 0.036), ('sjzij', 0.036), ('slonim', 0.036), ('tengfei', 0.036), ('wjvj', 0.036), ('thibaux', 0.036), ('recommended', 0.034), ('finite', 0.034), ('louis', 0.033), ('priors', 0.033), ('factors', 0.031), ('predefined', 0.031), ('jade', 0.031), ('celikyilmaz', 0.031), ('mmr', 0.031), ('sentences', 0.031), ('teh', 0.031), ('topic', 0.03), ('lexrank', 0.028), ('unbalanced', 0.028), ('nakagawa', 0.028), ('improper', 0.028), ('lnp', 0.028), ('selection', 0.027), ('latent', 0.027), ('symbol', 0.027), ('approximation', 0.027), ('prior', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999899 <a title="36-tfidf-1" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>Author: Tengfei Ma ; Hiroshi Nakagawa</p><p>Abstract: Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.</p><p>2 0.26411209 <a title="36-tfidf-2" href="./emnlp-2013-Document_Summarization_via_Guided_Sentence_Compression.html">65 emnlp-2013-Document Summarization via Guided Sentence Compression</a></p>
<p>Author: Chen Li ; Fei Liu ; Fuliang Weng ; Yang Liu</p><p>Abstract: Joint compression and summarization has been used recently to generate high quality summaries. However, such word-based joint optimization is computationally expensive. In this paper we adopt the ‘sentence compression + sentence selection’ pipeline approach for compressive summarization, but propose to perform summary guided compression, rather than generic sentence-based compression. To create an annotated corpus, the human annotators were asked to compress sentences while explicitly given the important summary words in the sentences. Using this corpus, we train a supervised sentence compression model using a set of word-, syntax-, and documentlevel features. During summarization, we use multiple compressed sentences in the integer linear programming framework to select . salient summary sentences. Our results on the TAC 2008 and 2011 summarization data sets show that by incorporating the guided sentence compression model, our summarization system can yield significant performance gain as compared to the state-of-the-art.</p><p>3 0.2549414 <a title="36-tfidf-3" href="./emnlp-2013-Fast_Joint_Compression_and_Summarization_via_Graph_Cuts.html">85 emnlp-2013-Fast Joint Compression and Summarization via Graph Cuts</a></p>
<p>Author: Xian Qian ; Yang Liu</p><p>Abstract: Extractive summarization typically uses sentences as summarization units. In contrast, joint compression and summarization can use smaller units such as words and phrases, resulting in summaries containing more information. The goal of compressive summarization is to find a subset of words that maximize the total score of concepts and cutting dependency arcs under the grammar constraints and summary length constraint. We propose an efficient decoding algorithm for fast compressive summarization using graph cuts. Our approach first relaxes the length constraint using Lagrangian relaxation. Then we propose to bound the relaxed objective function by the supermodular binary quadratic programming problem, which can be solved efficiently using graph max-flow/min-cut. Since finding the tightest lower bound suffers from local optimality, we use convex relaxation for initialization. Experimental results on TAC2008 dataset demonstrate our method achieves competitive ROUGE score and has good readability, while is much faster than the integer linear programming (ILP) method.</p><p>4 0.22183631 <a title="36-tfidf-4" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<p>Author: Maria Liakata ; Simon Dobnik ; Shyamasree Saha ; Colin Batchelor ; Dietrich Rebholz-Schuhmann</p><p>Abstract: We present a method which exploits automatically generated scientific discourse annotations to create a content model for the summarisation of scientific articles. Full papers are first automatically annotated using the CoreSC scheme, which captures 11 contentbased concepts such as Hypothesis, Result, Conclusion etc at the sentence level. A content model which follows the sequence of CoreSC categories observed in abstracts is used to provide the skeleton of the summary, making a distinction between dependent and independent categories. Summary creation is also guided by the distribution of CoreSC categories found in the full articles, in order to adequately represent the article content. Fi- nally, we demonstrate the usefulness of the summaries by evaluating them in a complex question answering task. Results are very encouraging as summaries of papers from automatically obtained CoreSCs enable experts to answer 66% of complex content-related questions designed on the basis of paper abstracts. The questions were answered with a precision of 75%, where the upper bound for human summaries (abstracts) was 95%.</p><p>5 0.19121805 <a title="36-tfidf-5" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>6 0.17866407 <a title="36-tfidf-6" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>7 0.14870356 <a title="36-tfidf-7" href="./emnlp-2013-Single-Document_Summarization_as_a_Tree_Knapsack_Problem.html">174 emnlp-2013-Single-Document Summarization as a Tree Knapsack Problem</a></p>
<p>8 0.11897044 <a title="36-tfidf-8" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>9 0.093107879 <a title="36-tfidf-9" href="./emnlp-2013-Overcoming_the_Lack_of_Parallel_Data_in_Sentence_Compression.html">149 emnlp-2013-Overcoming the Lack of Parallel Data in Sentence Compression</a></p>
<p>10 0.075625129 <a title="36-tfidf-10" href="./emnlp-2013-Improvements_to_the_Bayesian_Topic_N-Gram_Models.html">100 emnlp-2013-Improvements to the Bayesian Topic N-Gram Models</a></p>
<p>11 0.071696848 <a title="36-tfidf-11" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<p>12 0.060506541 <a title="36-tfidf-12" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>13 0.057307974 <a title="36-tfidf-13" href="./emnlp-2013-Orthonormal_Explicit_Topic_Analysis_for_Cross-Lingual_Document_Matching.html">148 emnlp-2013-Orthonormal Explicit Topic Analysis for Cross-Lingual Document Matching</a></p>
<p>14 0.05627178 <a title="36-tfidf-14" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>15 0.055910777 <a title="36-tfidf-15" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>16 0.053453464 <a title="36-tfidf-16" href="./emnlp-2013-Learning_Latent_Word_Representations_for_Domain_Adaptation_using_Supervised_Word_Clustering.html">120 emnlp-2013-Learning Latent Word Representations for Domain Adaptation using Supervised Word Clustering</a></p>
<p>17 0.05207843 <a title="36-tfidf-17" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>18 0.049281642 <a title="36-tfidf-18" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>19 0.047808595 <a title="36-tfidf-19" href="./emnlp-2013-Building_Event_Threads_out_of_Multiple_News_Articles.html">41 emnlp-2013-Building Event Threads out of Multiple News Articles</a></p>
<p>20 0.044675279 <a title="36-tfidf-20" href="./emnlp-2013-Recursive_Autoencoders_for_ITG-Based_Translation.html">157 emnlp-2013-Recursive Autoencoders for ITG-Based Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.177), (1, 0.062), (2, -0.084), (3, 0.21), (4, -0.097), (5, -0.084), (6, 0.415), (7, -0.204), (8, 0.041), (9, -0.05), (10, 0.071), (11, -0.052), (12, 0.071), (13, -0.056), (14, -0.008), (15, 0.028), (16, 0.109), (17, -0.076), (18, -0.086), (19, -0.046), (20, -0.07), (21, -0.06), (22, -0.048), (23, -0.0), (24, 0.022), (25, 0.024), (26, 0.023), (27, -0.035), (28, 0.041), (29, -0.03), (30, 0.01), (31, 0.142), (32, 0.043), (33, -0.087), (34, 0.011), (35, -0.192), (36, -0.049), (37, -0.03), (38, 0.001), (39, 0.023), (40, -0.04), (41, 0.079), (42, 0.041), (43, 0.042), (44, -0.012), (45, -0.008), (46, -0.043), (47, -0.025), (48, -0.033), (49, -0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97556931 <a title="36-lsi-1" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>Author: Tengfei Ma ; Hiroshi Nakagawa</p><p>Abstract: Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.</p><p>2 0.79410267 <a title="36-lsi-2" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>3 0.79384381 <a title="36-lsi-3" href="./emnlp-2013-Fast_Joint_Compression_and_Summarization_via_Graph_Cuts.html">85 emnlp-2013-Fast Joint Compression and Summarization via Graph Cuts</a></p>
<p>Author: Xian Qian ; Yang Liu</p><p>Abstract: Extractive summarization typically uses sentences as summarization units. In contrast, joint compression and summarization can use smaller units such as words and phrases, resulting in summaries containing more information. The goal of compressive summarization is to find a subset of words that maximize the total score of concepts and cutting dependency arcs under the grammar constraints and summary length constraint. We propose an efficient decoding algorithm for fast compressive summarization using graph cuts. Our approach first relaxes the length constraint using Lagrangian relaxation. Then we propose to bound the relaxed objective function by the supermodular binary quadratic programming problem, which can be solved efficiently using graph max-flow/min-cut. Since finding the tightest lower bound suffers from local optimality, we use convex relaxation for initialization. Experimental results on TAC2008 dataset demonstrate our method achieves competitive ROUGE score and has good readability, while is much faster than the integer linear programming (ILP) method.</p><p>4 0.76185131 <a title="36-lsi-4" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<p>Author: Maria Liakata ; Simon Dobnik ; Shyamasree Saha ; Colin Batchelor ; Dietrich Rebholz-Schuhmann</p><p>Abstract: We present a method which exploits automatically generated scientific discourse annotations to create a content model for the summarisation of scientific articles. Full papers are first automatically annotated using the CoreSC scheme, which captures 11 contentbased concepts such as Hypothesis, Result, Conclusion etc at the sentence level. A content model which follows the sequence of CoreSC categories observed in abstracts is used to provide the skeleton of the summary, making a distinction between dependent and independent categories. Summary creation is also guided by the distribution of CoreSC categories found in the full articles, in order to adequately represent the article content. Fi- nally, we demonstrate the usefulness of the summaries by evaluating them in a complex question answering task. Results are very encouraging as summaries of papers from automatically obtained CoreSCs enable experts to answer 66% of complex content-related questions designed on the basis of paper abstracts. The questions were answered with a precision of 75%, where the upper bound for human summaries (abstracts) was 95%.</p><p>5 0.64781892 <a title="36-lsi-5" href="./emnlp-2013-Single-Document_Summarization_as_a_Tree_Knapsack_Problem.html">174 emnlp-2013-Single-Document Summarization as a Tree Knapsack Problem</a></p>
<p>Author: Tsutomu Hirao ; Yasuhisa Yoshida ; Masaaki Nishino ; Norihito Yasuda ; Masaaki Nagata</p><p>Abstract: Recent studies on extractive text summarization formulate it as a combinatorial optimization problem such as a Knapsack Problem, a Maximum Coverage Problem or a Budgeted Median Problem. These methods successfully improved summarization quality, but they did not consider the rhetorical relations between the textual units of a source document. Thus, summaries generated by these methods may lack logical coherence. This paper proposes a single document summarization method based on the trimming of a discourse tree. This is a two-fold process. First, we propose rules for transforming a rhetorical structure theorybased discourse tree into a dependency-based discourse tree, which allows us to take a tree- . trimming approach to summarization. Second, we formulate the problem of trimming a dependency-based discourse tree as a Tree Knapsack Problem, then solve it with integer linear programming (ILP). Evaluation results showed that our method improved ROUGE scores.</p><p>6 0.64207852 <a title="36-lsi-6" href="./emnlp-2013-Document_Summarization_via_Guided_Sentence_Compression.html">65 emnlp-2013-Document Summarization via Guided Sentence Compression</a></p>
<p>7 0.61352414 <a title="36-lsi-7" href="./emnlp-2013-Optimized_Event_Storyline_Generation_based_on_Mixture-Event-Aspect_Model.html">147 emnlp-2013-Optimized Event Storyline Generation based on Mixture-Event-Aspect Model</a></p>
<p>8 0.49633461 <a title="36-lsi-8" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>9 0.34607205 <a title="36-lsi-9" href="./emnlp-2013-Overcoming_the_Lack_of_Parallel_Data_in_Sentence_Compression.html">149 emnlp-2013-Overcoming the Lack of Parallel Data in Sentence Compression</a></p>
<p>10 0.30534545 <a title="36-lsi-10" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<p>11 0.27609786 <a title="36-lsi-11" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>12 0.27538019 <a title="36-lsi-12" href="./emnlp-2013-Improvements_to_the_Bayesian_Topic_N-Gram_Models.html">100 emnlp-2013-Improvements to the Bayesian Topic N-Gram Models</a></p>
<p>13 0.25521171 <a title="36-lsi-13" href="./emnlp-2013-Orthonormal_Explicit_Topic_Analysis_for_Cross-Lingual_Document_Matching.html">148 emnlp-2013-Orthonormal Explicit Topic Analysis for Cross-Lingual Document Matching</a></p>
<p>14 0.25047821 <a title="36-lsi-14" href="./emnlp-2013-Unsupervised_Spectral_Learning_of_WCFG_as_Low-rank_Matrix_Completion.html">195 emnlp-2013-Unsupervised Spectral Learning of WCFG as Low-rank Matrix Completion</a></p>
<p>15 0.2449501 <a title="36-lsi-15" href="./emnlp-2013-Modeling_Scientific_Impact_with_Topical_Influence_Regression.html">133 emnlp-2013-Modeling Scientific Impact with Topical Influence Regression</a></p>
<p>16 0.23956776 <a title="36-lsi-16" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>17 0.22383751 <a title="36-lsi-17" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<p>18 0.21977821 <a title="36-lsi-18" href="./emnlp-2013-Mining_New_Business_Opportunities%3A_Identifying_Trend_related_Products_by_Leveraging_Commercial_Intents_from_Microblogs.html">131 emnlp-2013-Mining New Business Opportunities: Identifying Trend related Products by Leveraging Commercial Intents from Microblogs</a></p>
<p>19 0.21558078 <a title="36-lsi-19" href="./emnlp-2013-Naive_Bayes_Word_Sense_Induction.html">138 emnlp-2013-Naive Bayes Word Sense Induction</a></p>
<p>20 0.19453226 <a title="36-lsi-20" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.084), (9, 0.025), (18, 0.032), (22, 0.038), (30, 0.084), (50, 0.017), (51, 0.142), (66, 0.032), (71, 0.024), (75, 0.058), (77, 0.02), (79, 0.273), (90, 0.015), (95, 0.052), (96, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74751979 <a title="36-lda-1" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>Author: Tengfei Ma ; Hiroshi Nakagawa</p><p>Abstract: Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.</p><p>2 0.57122397 <a title="36-lda-2" href="./emnlp-2013-Document_Summarization_via_Guided_Sentence_Compression.html">65 emnlp-2013-Document Summarization via Guided Sentence Compression</a></p>
<p>Author: Chen Li ; Fei Liu ; Fuliang Weng ; Yang Liu</p><p>Abstract: Joint compression and summarization has been used recently to generate high quality summaries. However, such word-based joint optimization is computationally expensive. In this paper we adopt the ‘sentence compression + sentence selection’ pipeline approach for compressive summarization, but propose to perform summary guided compression, rather than generic sentence-based compression. To create an annotated corpus, the human annotators were asked to compress sentences while explicitly given the important summary words in the sentences. Using this corpus, we train a supervised sentence compression model using a set of word-, syntax-, and documentlevel features. During summarization, we use multiple compressed sentences in the integer linear programming framework to select . salient summary sentences. Our results on the TAC 2008 and 2011 summarization data sets show that by incorporating the guided sentence compression model, our summarization system can yield significant performance gain as compared to the state-of-the-art.</p><p>3 0.55848926 <a title="36-lda-3" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>Author: Hrushikesh Mohapatra ; Siddhanth Jain ; Soumen Chakrabarti</p><p>Abstract: Web search can be enhanced in powerful ways if token spans in Web text are annotated with disambiguated entities from large catalogs like Freebase. Entity annotators need to be trained on sample mention snippets. Wikipedia entities and annotated pages offer high-quality labeled data for training and evaluation. Unfortunately, Wikipedia features only one-ninth the number of entities as Freebase, and these are a highly biased sample of well-connected, frequently mentioned “head” entities. To bring hope to “tail” entities, we broaden our goal to a second task: assigning types to entities in Freebase but not Wikipedia. The two tasks are synergistic: knowing the types of unfamiliar entities helps disambiguate mentions, and words in mention contexts help assign types to entities. We present TMI, a bipartite graphical model for joint type-mention inference. TMI attempts no schema integration or entity resolution, but exploits the above-mentioned synergy. In experiments involving 780,000 people in Wikipedia, 2.3 million people in Freebase, 700 million Web pages, and over 20 professional editors, TMI shows considerable annotation accuracy improvement (e.g., 70%) compared to baselines (e.g., 46%), especially for “tail” and emerging entities. We also compare with Google’s recent annotations of the same corpus with Freebase entities, and report considerable improvements within the people domain.</p><p>4 0.5566504 <a title="36-lda-4" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>Author: Xiaoqing Zheng ; Hanyang Chen ; Tianyu Xu</p><p>Abstract: This study explores the feasibility of performing Chinese word segmentation (CWS) and POS tagging by deep learning. We try to avoid task-specific feature engineering, and use deep layers of neural networks to discover relevant features to the tasks. We leverage large-scale unlabeled data to improve internal representation of Chinese characters, and use these improved representations to enhance supervised word segmentation and POS tagging models. Our networks achieved close to state-of-theart performance with minimal computational cost. We also describe a perceptron-style algorithm for training the neural networks, as an alternative to maximum-likelihood method, to speed up the training process and make the learning algorithm easier to be implemented.</p><p>5 0.55543602 <a title="36-lda-5" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>6 0.5502997 <a title="36-lda-6" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>7 0.55002761 <a title="36-lda-7" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<p>8 0.54647046 <a title="36-lda-8" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>9 0.54629725 <a title="36-lda-9" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>10 0.54296261 <a title="36-lda-10" href="./emnlp-2013-Detecting_Promotional_Content_in_Wikipedia.html">61 emnlp-2013-Detecting Promotional Content in Wikipedia</a></p>
<p>11 0.54254484 <a title="36-lda-11" href="./emnlp-2013-A_Constrained_Latent_Variable_Model_for_Coreference_Resolution.html">1 emnlp-2013-A Constrained Latent Variable Model for Coreference Resolution</a></p>
<p>12 0.54078156 <a title="36-lda-12" href="./emnlp-2013-Of_Words%2C_Eyes_and_Brains%3A_Correlating_Image-Based_Distributional_Semantic_Models_with_Neural_Representations_of_Concepts.html">140 emnlp-2013-Of Words, Eyes and Brains: Correlating Image-Based Distributional Semantic Models with Neural Representations of Concepts</a></p>
<p>13 0.53870261 <a title="36-lda-13" href="./emnlp-2013-Fast_Joint_Compression_and_Summarization_via_Graph_Cuts.html">85 emnlp-2013-Fast Joint Compression and Summarization via Graph Cuts</a></p>
<p>14 0.53861892 <a title="36-lda-14" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>15 0.5378226 <a title="36-lda-15" href="./emnlp-2013-Feature_Noising_for_Log-Linear_Structured_Prediction.html">86 emnlp-2013-Feature Noising for Log-Linear Structured Prediction</a></p>
<p>16 0.53761935 <a title="36-lda-16" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>17 0.53683764 <a title="36-lda-17" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>18 0.53678012 <a title="36-lda-18" href="./emnlp-2013-Interactive_Machine_Translation_using_Hierarchical_Translation_Models.html">107 emnlp-2013-Interactive Machine Translation using Hierarchical Translation Models</a></p>
<p>19 0.53650057 <a title="36-lda-19" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>20 0.53491819 <a title="36-lda-20" href="./emnlp-2013-Mining_Scientific_Terms_and_their_Definitions%3A_A_Study_of_the_ACL_Anthology.html">132 emnlp-2013-Mining Scientific Terms and their Definitions: A Study of the ACL Anthology</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
