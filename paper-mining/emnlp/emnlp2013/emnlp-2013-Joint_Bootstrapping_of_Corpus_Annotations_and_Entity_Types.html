<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-110" href="#">emnlp2013-110</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</h1>
<br/><p>Source: <a title="emnlp-2013-110-pdf" href="http://aclweb.org/anthology//D/D13/D13-1042.pdf">pdf</a></p><p>Author: Hrushikesh Mohapatra ; Siddhanth Jain ; Soumen Chakrabarti</p><p>Abstract: Web search can be enhanced in powerful ways if token spans in Web text are annotated with disambiguated entities from large catalogs like Freebase. Entity annotators need to be trained on sample mention snippets. Wikipedia entities and annotated pages offer high-quality labeled data for training and evaluation. Unfortunately, Wikipedia features only one-ninth the number of entities as Freebase, and these are a highly biased sample of well-connected, frequently mentioned “head” entities. To bring hope to “tail” entities, we broaden our goal to a second task: assigning types to entities in Freebase but not Wikipedia. The two tasks are synergistic: knowing the types of unfamiliar entities helps disambiguate mentions, and words in mention contexts help assign types to entities. We present TMI, a bipartite graphical model for joint type-mention inference. TMI attempts no schema integration or entity resolution, but exploits the above-mentioned synergy. In experiments involving 780,000 people in Wikipedia, 2.3 million people in Freebase, 700 million Web pages, and over 20 professional editors, TMI shows considerable annotation accuracy improvement (e.g., 70%) compared to baselines (e.g., 46%), especially for “tail” and emerging entities. We also compare with Google’s recent annotations of the same corpus with Freebase entities, and report considerable improvements within the people domain.</p><p>Reference: <a title="emnlp-2013-110-reference" href="../emnlp2013_reference/emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Joint Bootstrapping of Corpus Annotations Hrushikesh Mohapatra  Siddhanth Jain IIT Bombay  and  Entity  Types  Soumen Chakrabarti∗  Abstract Web search can be enhanced in powerful ways if token spans in Web text are annotated with disambiguated entities from large catalogs like Freebase. [sent-1, score-0.256]
</p><p>2 Wikipedia entities and annotated pages offer high-quality labeled data for training and evaluation. [sent-3, score-0.256]
</p><p>3 Unfortunately, Wikipedia features only one-ninth the number of entities as Freebase, and these are a highly biased sample of well-connected, frequently mentioned “head” entities. [sent-4, score-0.281]
</p><p>4 To bring hope to “tail” entities, we broaden our goal to a second task: assigning types to entities in Freebase but not Wikipedia. [sent-5, score-0.316]
</p><p>5 The two tasks are synergistic: knowing the types of unfamiliar entities helps disambiguate mentions, and words in mention contexts help assign types to entities. [sent-6, score-0.555]
</p><p>6 TMI attempts no schema integration or entity resolution, but exploits the above-mentioned synergy. [sent-8, score-0.172]
</p><p>7 3 million people in Freebase, 700 million Web pages, and over 20 professional editors, TMI shows considerable annotation accuracy improvement (e. [sent-10, score-0.184]
</p><p>8 A key enabling component for such enhanced search capability is a type and entity catalog. [sent-19, score-0.269]
</p><p>9 This includes a directed acyclic graph of types under the subTypeOf relation between types, and entities attached to one or more types via instanceOf edges. [sent-20, score-0.438]
</p><p>10 , the word “Albert”) are identified as a mention of an entity (e. [sent-28, score-0.254]
</p><p>11 Primary goal corpus annotation: We have thus established a pressing need to bootstrap from a small entity catalog W (such as Wikipedia entities), and a small reference corpus CW (e. [sent-50, score-0.248]
</p><p>12 , Wikipedia text) reliably annotated with entities from W, to a much larger catalog F (e. [sent-52, score-0.375]
</p><p>13 We can and will use entities in F ∩ W1 in the bootstrapping process, ebu ent tihtiee sr ieanl challenge is to annotate C with mentions m of entities in F \ W. [sent-57, score-0.572]
</p><p>14 th Teh eimremfoerdei,at the entity neighborhood N(e) oafl the candidate entity e in the Freebase graph. [sent-61, score-0.42]
</p><p>15 , if m also reliably mentions some entity in N(e), then e becomes a stronger candidate. [sent-64, score-0.275]
</p><p>16 Unfortunately, for many “tail” entities e ∈ F \ W, N(e) is sparse. [sent-65, score-0.256]
</p><p>17 Secondary goal — entity typing: If we had available a suitable type catalog T with associated entitaibelse i na W, wblheic tyhp ien tautarnlo hgav Te w knitohw ans toecxitautaeld mentions, we can build models of contexts referring to types like chemists, sports people and politicans. [sent-69, score-0.51]
</p><p>18 e I reverse dlei-, rection: words in mention contexts may help assign types to entities in F \ W. [sent-73, score-0.462]
</p><p>19 , 2007) as  the type catalog T accompanying entities in W. [sent-75, score-0.429]
</p><p>20 We report on extensive experiments using YAGO types, Wikipedia entities and text, Freebase entities, and text from ClueWeb122, a 700-millionpage Web corpus. [sent-81, score-0.256]
</p><p>21 First, we evaluate TMI on over 1100 entities in F ∩ W and 5500 snippets from Wikipedia text, nw Fhere ∩ ∩i tW visibly improves upon b fraosmelines and a recently proposed alternative method (Zheng et al. [sent-83, score-0.468]
</p><p>22 2  Related work  The vast majority of entity annotation work (Mihalcea and Csomai, 2007; Cucerzan, 2007; Milne and Witten, 2008; Kulkarni et al. [sent-96, score-0.229]
</p><p>23 , 2011) use entity names for distant supervision in POS tagging, chunking and broad named entity typing in short tweets, which are different from our goals. [sent-105, score-0.413]
</p><p>24 (a) Easy case where Freebase neighbors of 0ggbn2k match snippet and salient text, and type links are also available. [sent-112, score-0.419]
</p><p>25 (b) No match exists between Freebase neighborhood and snippet, but type links help attach the snippet to 03nmvfz. [sent-113, score-0.446]
</p><p>26 (c) Freebase provides no types, but we can provide types from YAGO based on snippet and salient text,  which also match neighbors of 0bhbqmm. [sent-114, score-0.382]
</p><p>27 , 2013) propose integer linear program formulations for inferring types of emerging entities from the way their mentions are embedded in curated relation-revealing  phrases. [sent-117, score-0.416]
</p><p>28 , 2012) earlier approached the problem using weight propagation in a bipartite graph connecting unknown to known entities via textual relation patterns. [sent-119, score-0.319]
</p><p>29 1 shows three Freebase entities mentioned as “John Williams” in Web text, represented as nodes with Freebase “MID”s e = 0ggbn2k, 03nmvfz, and 0bhbqmm, embedded in their Freebase graph neighborhoods. [sent-139, score-0.346]
</p><p>30 Unlike YAGO, where each entity is attached to one or more types, e = 0bhbqmm does not have a type link. [sent-142, score-0.301]
</p><p>31 Also shown are three mention contexts, each represented by the snippet immediately surrounding the mention, and salient words from the documents containing each snippet. [sent-145, score-0.404]
</p><p>32 2 we will describe how to learn associations between Freebase paths around entities and their YAGO types. [sent-149, score-0.293]
</p><p>33 The snippet and salient words show reasonable overlap with N(e). [sent-150, score-0.322]
</p><p>34 Nevertheless, the snippet can be reliably annotated with 03nmvfz if we can learn associations between types American football player and Athlete (or their approximate YAGO target types) and several context/salient words (see  §3. [sent-154, score-0.376]
</p><p>35 1 Designing the target type space By typing two people called John Williams as actor and footballer, we may also disambiguate their mentions accurately. [sent-161, score-0.329]
</p><p>36 Therefore, we need a wellorganized type space where the types • collectively cover most entities of interest, • offer reasonable type prediction accuracy, and • can be selected algorithmically, for any domain. [sent-162, score-0.51]
</p><p>37 Most entities in F \ W can be accu-  439 if t has < Nlow = 5000 member entities then reject t from our type space return if t has > Nhigh = 25000 member entities then for each immediate child t0 ⊂ t do call ChooseTypes(t0) else accept t into our type space (but do not recurse) Fig. [sent-165, score-1.024]
</p><p>38 2 Predicting types from entity neighborhood There will generally not be a simple mapping between Freebase and target types. [sent-173, score-0.308]
</p><p>39 , entity e may be known as a Mayor in Freebase, but the closest YAGO type may be Politician. [sent-176, score-0.269]
</p><p>40 , e = 03nmvfz may have an edge labeled playedFor to a node representing the Wikipedia entity P itt sburgh Steelers, which has a type link to NFL team. [sent-180, score-0.355]
</p><p>41 Prune1 removes paths from the whole Freebase graph that pass through nodes /user/root and /common/topic, Prune2 also removes node /people/person, and Prune3 removes several other high degree hubs. [sent-185, score-0.229]
</p><p>42 1(b), we need to model the association between target YAGO types and the mention contexts of Wikipedia entities known to belong to those types. [sent-196, score-0.433]
</p><p>43 For each target YAGO type t, we sample positive entities e ∈ F ∩ W, and for each e, we collect, from Wikipedia ∈a nFno ∩taWte,d a text, a corpus o wf snippets mentioning e. [sent-199, score-0.539]
</p><p>44 At this point each target type is associated with a “corpus” of contexts, each represented by snippet words. [sent-203, score-0.37]
</p><p>45 4 Entity neighborhood match with snippet The third signal is a staple of any disambiguation work: match the occurrence context against the neighborhood in the structured representation. [sent-209, score-0.457]
</p><p>46 As in WSD, many approaches to Wikification measure some local consistency between a mention m and the neighborhood N(e) of a candidate entity e. [sent-212, score-0.33]
</p><p>47 From snippet m we extract all phrases P(m) excluding the mention words. [sent-214, score-0.355]
</p><p>48 Each mention like m1 has to choose at most one entity from among candidate aliasing entities like e and e0. [sent-221, score-0.51]
</p><p>49 Each entity e ∈ F \ W has to choose one type (for simplicity we ignore zero or more tohsaen o one types as possibilities) from candidates like t and t0. [sent-222, score-0.329]
</p><p>50 • In aggregate, the non-mention tokens in the context of m1, m2 (shown as gray horizontal lines) match well the language model associated with mentions of entities of type t (rather than t0). [sent-226, score-0.413]
</p><p>51 Associated with each entity e ∈ F \ W there is a Ahidssdoecni type wviatrhiab ealec (node) Te, ∈wh Fich \ can tthaekree on a value from (some subset of) the type catalog T . [sent-231, score-0.442]
</p><p>52 Assvoacluiaet fedro mwi (thso emaceh s umbesnettio onf) m (along awtaitloh git Ts snippet context and all its observable features) there is a hidden entity variable Em, which can take on values from some subset of entities. [sent-232, score-0.445]
</p><p>53 (For simplicity, we assume that entities in F ∩ W have already been annaosstautmede tinh atht een corpus, a Fnd ∩ no m aovfe i nalterereasdty m beenetnio ann-s such entities. [sent-233, score-0.256]
</p><p>54 , XXe  Xm  (1)  eX X,m  where node log potentials are called φe, φm, edge log potentials are called ψe,m, and α, β are tuned constants. [sent-235, score-0.274]
</p><p>55 1 Node log potentials Each node Te is associated with a node potential table, mapping from possible types in Te to nonnegabtleiv,e m potentials. [sent-240, score-0.246]
</p><p>56 Each node Em is associated with a node potential table, mapping from possible entities in Em to  ×  nonnegative potentials. [sent-243, score-0.348]
</p><p>57 This could be because the snippet mentions an entity outside F (and outside W), or the system wishes to ensure high precision at some cost to recall. [sent-264, score-0.505]
</p><p>58 Rejection is modeled by adding, for each snippet m, a pseudo or “null” entity (also called “no annotation” NA, null or nil in the TAC-KBP5 community). [sent-265, score-0.475]
</p><p>59 Put differently, φ⊥m (t) will be constant (say, zero) for all snippets m and types t. [sent-281, score-0.246]
</p><p>60 Even if we do not know the entity mentioned in m, the non-mention text in m will have differential affinity to different types, obtained from §3. [sent-282, score-0.197]
</p><p>61 For a different entity Em = e0 and type Te0 = t assignment to win, αφm (e0) +βφe0 (t) +ψe0,m(t, e0) must exceed the null score above. [sent-285, score-0.332]
</p><p>62 4  Inference and training  The goal of collective inference will be to assign a type value to each Te and an entity value to each Em. [sent-288, score-0.298]
</p><p>63 1, we restrict to entities from F ∩ W and Wikipedia text, fsotrri wt htoic ehn ground mtrut Fh ∩an Wnota antidon W i sk apveadiilaable. [sent-302, score-0.294]
</p><p>64 2, we evaluate TMI and baselines on ClueWeb12 and entities from Freebase, not limited to Wikipedia. [sent-304, score-0.283]
</p><p>65 1 Reference corpus CW with F ∩ W entities Limited to people, |F| = 2323792, |W| = 807381, |F \ W| = 1544942, a=nd 2 |F 7∩9 W| = 7=78 8805703. [sent-309, score-0.256]
</p><p>66 Then we collect all entities mentioned by these phrases. [sent-322, score-0.281]
</p><p>67 Overall we collect about 1100 entities and 5500 distinct mentions. [sent-323, score-0.256]
</p><p>68 , 2012), who sample entities from much fewer than 130, and largely well-separated types: professional athletes, academics, actors, films, books, hotels, and tourist attractions. [sent-325, score-0.286]
</p><p>69 , 2012) did not “complete” their entity sets with aliased entities. [sent-330, score-0.203]
</p><p>70 TMI solves two tasks simultaneously: assign types to entities and entities to snippets. [sent-335, score-0.629]
</p><p>71 So the first baseline, T0, is one that solves the typing task separately, and the second, A0, does snippet annotation separately. [sent-336, score-0.427]
</p><p>72 , 2012) does only snippet annotation; they do not consider typing entities. [sent-338, score-0.342]
</p><p>73 Idnli one we heelirmefionraete w aell r snippets twsi tohf ground ternuttsh. [sent-347, score-0.224]
</p><p>74 Ianre et ahels other, snippets mm raertkuerndi n⊥g i⊥n ground t srnuitphp are iInncl thuede odth. [sent-351, score-0.224]
</p><p>75 6 shows snippet annotation accuracy (fraction of snippets labeled with the correct entity) when ⊥ is not allowed as an entity. [sent-366, score-0.543]
</p><p>76 423 and choosing the entity with the largest prior gives an accuracy of 0. [sent-369, score-0.199]
</p><p>77 Each bucket covers a range of degrees of entity nodes in Freebase, while roughly balacing the number of snippets in each bucket. [sent-410, score-0.393]
</p><p>78 10: Seed mentions for confusion clusters for Web corpus C and entities in F. [sent-424, score-0.341]
</p><p>79 Therefore, the flow ofinformation between type and entity assignments is, in principle, bidirectional, in the regime of such entities. [sent-426, score-0.269]
</p><p>80 2 Payload corpus C with entities in F Recall our main goal is to annotate payload corpus C with entities in all of F. [sent-428, score-0.575]
</p><p>81 ∩E Wntit aiensd i Cn F \ W may not come with reference  mentions, san ind Fth \eir W type yan ndo entity neighborhoods may be sparse. [sent-430, score-0.269]
</p><p>82 IE anntditi beass eilni Fes \ vWer dCo annodt hFav \e ground tarlultehn types Einn tthiteie type catalog T (here, YAGO), nor snippets labeled by humans as mentioning them. [sent-432, score-0.457]
</p><p>83 3 million Freebase entities connected to /people/person via type links. [sent-438, score-0.353]
</p><p>84 Note that entities in W can and do contend with entities in F \ W. [sent-445, score-0.512]
</p><p>85 From these we collected 304,309 snippets where the mention phrase is marked by the NER as a person. [sent-464, score-0.268]
</p><p>86 Because the editors are trained professionals (unlike Mechanical Turks), we increased our evaluation coverage by having each type or entity assignment reviewed by one editor. [sent-470, score-0.334]
</p><p>87 Pooling: Ideally, editors can be asked to find the best type or entity for each entity or snippet, but, given the size and diversity of Freebase, the cognitive burden would be unacceptable. [sent-471, score-0.498]
</p><p>88 In the Wikipedia corpus CW, a snippet marked ⊥ (no entity) by an algorithm can a b sen judged a lkoesds ⊥of ( rneoc aenll i tfy Wikipedia ground truth annotates it with an entity. [sent-472, score-0.311]
</p><p>89 Unfortunately, this is no longer practical for Web corpus C,  because 8,217 snippets marked ⊥ would have to be manually inspected aentds compared wwoithu a large number of candidate entities in Freebase. [sent-473, score-0.442]
</p><p>90 ) Recall is evaluated with respect to the union of snippets annoted with a non-⊥ entity by at least one competing algorithm, nwoitnh- agreement yin a case sotf o more othmapne one. [sent-476, score-0.358]
</p><p>91 To understand TMI’s performance across a diversity of Freebase entity nodes  e, as a function of 1. [sent-493, score-0.207]
</p><p>92 the number of snippets claimed to mention e, we disaggregate the data of Fig. [sent-495, score-0.299]
</p><p>93 14: 0/1 accuracy and F1 for snippets, payload corpus C and entities in F. [sent-511, score-0.346]
</p><p>94 consecutive degrees, roughly balancing the number of snippets per bucket, as shown in Fig. [sent-512, score-0.186]
</p><p>95 At the very low end of almost disconnected entity nodes, no algorithm does very well, because these entities are also hardly ever mentioned. [sent-514, score-0.428]
</p><p>96 3 Comparison with FACC1 After collecting our pool of snippets as in §5. [sent-519, score-0.186]
</p><p>97 6  Conclusion  We presented a formal model for bootstrapping from YAGO types and entities annotated in Wikipedia to two tasks, 1. [sent-529, score-0.316]
</p><p>98 Experiments show that TMI’s snippet annotation accuracy, especially for relatively weakly-connected Freebase entities, is superior to baselines. [sent-533, score-0.33]
</p><p>99 Collective annotation of 446 Wikipedia entities in Web text. [sent-573, score-0.313]
</p><p>100 Mining entity types from query logs via user intent modeling. [sent-604, score-0.232]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tmi', 0.531), ('freebase', 0.387), ('snippet', 0.273), ('entities', 0.256), ('yago', 0.208), ('snippets', 0.186), ('entity', 0.172), ('wikipedia', 0.147), ('zheng', 0.108), ('type', 0.097), ('williams', 0.095), ('editorial', 0.095), ('mention', 0.082), ('neighborhood', 0.076), ('catalog', 0.076), ('people', 0.07), ('typing', 0.069), ('potentials', 0.068), ('gabrilovich', 0.065), ('payload', 0.063), ('em', 0.062), ('reject', 0.062), ('types', 0.06), ('mentions', 0.06), ('te', 0.06), ('milne', 0.06), ('annotation', 0.057), ('web', 0.051), ('salient', 0.049), ('signals', 0.049), ('cw', 0.048), ('choosetypes', 0.047), ('node', 0.046), ('tail', 0.046), ('witten', 0.044), ('reliably', 0.043), ('uninformed', 0.041), ('emerging', 0.04), ('edge', 0.04), ('secondary', 0.038), ('unambiguous', 0.038), ('ground', 0.038), ('hoffart', 0.037), ('suchanek', 0.037), ('paths', 0.037), ('credit', 0.036), ('contexts', 0.035), ('nodes', 0.035), ('tfidf', 0.035), ('disambiguate', 0.033), ('annotations', 0.033), ('assignment', 0.033), ('ritter', 0.033), ('soumen', 0.033), ('salton', 0.033), ('bipartite', 0.033), ('attached', 0.032), ('disambiguation', 0.032), ('editors', 0.032), ('aliased', 0.031), ('athlete', 0.031), ('dco', 0.031), ('disaggregate', 0.031), ('eunice', 0.031), ('fnd', 0.031), ('puritan', 0.031), ('sawant', 0.031), ('steelers', 0.031), ('touchdown', 0.031), ('tripartite', 0.031), ('yard', 0.031), ('graph', 0.03), ('null', 0.03), ('professional', 0.03), ('assign', 0.029), ('john', 0.029), ('kulkarni', 0.029), ('solves', 0.028), ('gerhard', 0.028), ('accuracy', 0.027), ('nakashole', 0.027), ('mcgill', 0.027), ('chakrabarti', 0.027), ('minister', 0.027), ('baselines', 0.027), ('judgment', 0.027), ('removes', 0.027), ('path', 0.026), ('seed', 0.026), ('matches', 0.026), ('log', 0.026), ('nw', 0.026), ('mentioned', 0.025), ('confusion', 0.025), ('backs', 0.025), ('burden', 0.025), ('quarter', 0.025), ('nfl', 0.025), ('quarterback', 0.025), ('believed', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000011 <a title="110-tfidf-1" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>Author: Hrushikesh Mohapatra ; Siddhanth Jain ; Soumen Chakrabarti</p><p>Abstract: Web search can be enhanced in powerful ways if token spans in Web text are annotated with disambiguated entities from large catalogs like Freebase. Entity annotators need to be trained on sample mention snippets. Wikipedia entities and annotated pages offer high-quality labeled data for training and evaluation. Unfortunately, Wikipedia features only one-ninth the number of entities as Freebase, and these are a highly biased sample of well-connected, frequently mentioned “head” entities. To bring hope to “tail” entities, we broaden our goal to a second task: assigning types to entities in Freebase but not Wikipedia. The two tasks are synergistic: knowing the types of unfamiliar entities helps disambiguate mentions, and words in mention contexts help assign types to entities. We present TMI, a bipartite graphical model for joint type-mention inference. TMI attempts no schema integration or entity resolution, but exploits the above-mentioned synergy. In experiments involving 780,000 people in Wikipedia, 2.3 million people in Freebase, 700 million Web pages, and over 20 professional editors, TMI shows considerable annotation accuracy improvement (e.g., 70%) compared to baselines (e.g., 46%), especially for “tail” and emerging entities. We also compare with Google’s recent annotations of the same corpus with Freebase entities, and report considerable improvements within the people domain.</p><p>2 0.19582884 <a title="110-tfidf-2" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>Author: Jason Weston ; Antoine Bordes ; Oksana Yakhnenko ; Nicolas Usunier</p><p>Abstract: This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.</p><p>3 0.18230504 <a title="110-tfidf-3" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>Author: Baichuan Li ; Jing Liu ; Chin-Yew Lin ; Irwin King ; Michael R. Lyu</p><p>Abstract: Social media like forums and microblogs have accumulated a huge amount of user generated content (UGC) containing human knowledge. Currently, most of UGC is listed as a whole or in pre-defined categories. This “list-based” approach is simple, but hinders users from browsing and learning knowledge of certain topics effectively. To address this problem, we propose a hierarchical entity-based approach for structuralizing UGC in social media. By using a large-scale entity repository, we design a three-step framework to organize UGC in a novel hierarchical structure called “cluster entity tree (CET)”. With Yahoo! Answers as a test case, we conduct experiments and the results show the effectiveness of our framework in constructing CET. We further evaluate the performance of CET on UGC organization in both user and system aspects. From a user aspect, our user study demonstrates that, with CET-based structure, users perform significantly better in knowledge learning than using traditional list-based approach. From a system aspect, CET substantially boosts the performance of two information retrieval models (i.e., vector space model and query likelihood language model).</p><p>4 0.17315724 <a title="110-tfidf-4" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>Author: Zhengyan He ; Shujie Liu ; Yang Song ; Mu Li ; Ming Zhou ; Houfeng Wang</p><p>Abstract: Entity disambiguation works by linking ambiguous mentions in text to their corresponding real-world entities in knowledge base. Recent collective disambiguation methods enforce coherence among contextual decisions at the cost of non-trivial inference processes. We propose a fast collective disambiguation approach based on stacking. First, we train a local predictor g0 with learning to rank as base learner, to generate initial ranking list of candidates. Second, top k candidates of related instances are searched for constructing expressive global coherence features. A global predictor g1 is trained in the augmented feature space and stacking is employed to tackle the train/test mismatch problem. The proposed method is fast and easy to implement. Experiments show its effectiveness over various algorithms on several public datasets. By learning a rich semantic relatedness measure be- . tween entity categories and context document, performance is further improved.</p><p>5 0.145357 <a title="110-tfidf-5" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>Author: Jonathan Berant ; Andrew Chou ; Roy Frostig ; Percy Liang</p><p>Abstract: In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset ofCai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.</p><p>6 0.13551098 <a title="110-tfidf-6" href="./emnlp-2013-Joint_Coreference_Resolution_and_Named-Entity_Linking_with_Multi-Pass_Sieves.html">112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</a></p>
<p>7 0.13500325 <a title="110-tfidf-7" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>8 0.12687682 <a title="110-tfidf-8" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>9 0.11449888 <a title="110-tfidf-9" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>10 0.11444028 <a title="110-tfidf-10" href="./emnlp-2013-Scaling_Semantic_Parsers_with_On-the-Fly_Ontology_Matching.html">164 emnlp-2013-Scaling Semantic Parsers with On-the-Fly Ontology Matching</a></p>
<p>11 0.092673153 <a title="110-tfidf-11" href="./emnlp-2013-Microblog_Entity_Linking_by_Leveraging_Extra_Posts.html">130 emnlp-2013-Microblog Entity Linking by Leveraging Extra Posts</a></p>
<p>12 0.078618675 <a title="110-tfidf-12" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>13 0.078388453 <a title="110-tfidf-13" href="./emnlp-2013-Easy_Victories_and_Uphill_Battles_in_Coreference_Resolution.html">67 emnlp-2013-Easy Victories and Uphill Battles in Coreference Resolution</a></p>
<p>14 0.071635537 <a title="110-tfidf-14" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>15 0.070143931 <a title="110-tfidf-15" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>16 0.069316372 <a title="110-tfidf-16" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>17 0.062958546 <a title="110-tfidf-17" href="./emnlp-2013-Improving_Learning_and_Inference_in_a_Large_Knowledge-Base_using_Latent_Syntactic_Cues.html">102 emnlp-2013-Improving Learning and Inference in a Large Knowledge-Base using Latent Syntactic Cues</a></p>
<p>18 0.060909286 <a title="110-tfidf-18" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>19 0.059544984 <a title="110-tfidf-19" href="./emnlp-2013-Open_Domain_Targeted_Sentiment.html">143 emnlp-2013-Open Domain Targeted Sentiment</a></p>
<p>20 0.059313685 <a title="110-tfidf-20" href="./emnlp-2013-A_Constrained_Latent_Variable_Model_for_Coreference_Resolution.html">1 emnlp-2013-A Constrained Latent Variable Model for Coreference Resolution</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.206), (1, 0.157), (2, 0.106), (3, -0.025), (4, 0.025), (5, 0.119), (6, -0.001), (7, 0.135), (8, 0.218), (9, 0.002), (10, 0.106), (11, -0.024), (12, -0.046), (13, -0.05), (14, -0.18), (15, -0.098), (16, 0.035), (17, -0.004), (18, 0.022), (19, 0.055), (20, -0.157), (21, -0.087), (22, 0.048), (23, 0.146), (24, 0.04), (25, 0.044), (26, 0.106), (27, -0.06), (28, -0.063), (29, -0.086), (30, 0.029), (31, -0.047), (32, 0.05), (33, 0.015), (34, 0.027), (35, -0.049), (36, 0.068), (37, 0.05), (38, -0.11), (39, -0.045), (40, -0.045), (41, 0.02), (42, -0.031), (43, -0.049), (44, -0.007), (45, 0.05), (46, 0.067), (47, 0.073), (48, -0.059), (49, 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96680093 <a title="110-lsi-1" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>Author: Hrushikesh Mohapatra ; Siddhanth Jain ; Soumen Chakrabarti</p><p>Abstract: Web search can be enhanced in powerful ways if token spans in Web text are annotated with disambiguated entities from large catalogs like Freebase. Entity annotators need to be trained on sample mention snippets. Wikipedia entities and annotated pages offer high-quality labeled data for training and evaluation. Unfortunately, Wikipedia features only one-ninth the number of entities as Freebase, and these are a highly biased sample of well-connected, frequently mentioned “head” entities. To bring hope to “tail” entities, we broaden our goal to a second task: assigning types to entities in Freebase but not Wikipedia. The two tasks are synergistic: knowing the types of unfamiliar entities helps disambiguate mentions, and words in mention contexts help assign types to entities. We present TMI, a bipartite graphical model for joint type-mention inference. TMI attempts no schema integration or entity resolution, but exploits the above-mentioned synergy. In experiments involving 780,000 people in Wikipedia, 2.3 million people in Freebase, 700 million Web pages, and over 20 professional editors, TMI shows considerable annotation accuracy improvement (e.g., 70%) compared to baselines (e.g., 46%), especially for “tail” and emerging entities. We also compare with Google’s recent annotations of the same corpus with Freebase entities, and report considerable improvements within the people domain.</p><p>2 0.72696543 <a title="110-lsi-2" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>Author: Zhengyan He ; Shujie Liu ; Yang Song ; Mu Li ; Ming Zhou ; Houfeng Wang</p><p>Abstract: Entity disambiguation works by linking ambiguous mentions in text to their corresponding real-world entities in knowledge base. Recent collective disambiguation methods enforce coherence among contextual decisions at the cost of non-trivial inference processes. We propose a fast collective disambiguation approach based on stacking. First, we train a local predictor g0 with learning to rank as base learner, to generate initial ranking list of candidates. Second, top k candidates of related instances are searched for constructing expressive global coherence features. A global predictor g1 is trained in the augmented feature space and stacking is employed to tackle the train/test mismatch problem. The proposed method is fast and easy to implement. Experiments show its effectiveness over various algorithms on several public datasets. By learning a rich semantic relatedness measure be- . tween entity categories and context document, performance is further improved.</p><p>3 0.70844322 <a title="110-lsi-3" href="./emnlp-2013-A_Hierarchical_Entity-Based_Approach_to_Structuralize_User_Generated_Content_in_Social_Media%3A_A_Case_of_Yahoo%21_Answers.html">7 emnlp-2013-A Hierarchical Entity-Based Approach to Structuralize User Generated Content in Social Media: A Case of Yahoo! Answers</a></p>
<p>Author: Baichuan Li ; Jing Liu ; Chin-Yew Lin ; Irwin King ; Michael R. Lyu</p><p>Abstract: Social media like forums and microblogs have accumulated a huge amount of user generated content (UGC) containing human knowledge. Currently, most of UGC is listed as a whole or in pre-defined categories. This “list-based” approach is simple, but hinders users from browsing and learning knowledge of certain topics effectively. To address this problem, we propose a hierarchical entity-based approach for structuralizing UGC in social media. By using a large-scale entity repository, we design a three-step framework to organize UGC in a novel hierarchical structure called “cluster entity tree (CET)”. With Yahoo! Answers as a test case, we conduct experiments and the results show the effectiveness of our framework in constructing CET. We further evaluate the performance of CET on UGC organization in both user and system aspects. From a user aspect, our user study demonstrates that, with CET-based structure, users perform significantly better in knowledge learning than using traditional list-based approach. From a system aspect, CET substantially boosts the performance of two information retrieval models (i.e., vector space model and query likelihood language model).</p><p>4 0.70558602 <a title="110-lsi-4" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>Author: Jason Weston ; Antoine Bordes ; Oksana Yakhnenko ; Nicolas Usunier</p><p>Abstract: This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.</p><p>5 0.68217486 <a title="110-lsi-5" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>Author: Ruiji Fu ; Bing Qin ; Ting Liu</p><p>Abstract: Hypernym discovery aims to extract such noun pairs that one noun is a hypernym of the other. Most previous methods are based on lexical patterns but perform badly on opendomain data. Other work extracts hypernym relations from encyclopedias but has limited coverage. This paper proposes a simple yet effective distant supervision framework for Chinese open-domain hypernym discovery. Given an entity name, we try to discover its hypernyms by leveraging knowledge from multiple sources, i.e., search engine results, encyclopedias, and morphology of the entity name. First, we extract candidate hypernyms from the above sources. Then, we apply a statistical ranking model to select correct hypernyms. A set of novel features is proposed for the rank- ing model. We also present a heuristic strategy to build a large-scale noisy training data for the model without human annotation. Experimental results demonstrate that our approach outperforms the state-of-the-art methods on a manually labeled test dataset.</p><p>6 0.59925902 <a title="110-lsi-6" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>7 0.51332134 <a title="110-lsi-7" href="./emnlp-2013-Joint_Coreference_Resolution_and_Named-Entity_Linking_with_Multi-Pass_Sieves.html">112 emnlp-2013-Joint Coreference Resolution and Named-Entity Linking with Multi-Pass Sieves</a></p>
<p>8 0.45518255 <a title="110-lsi-8" href="./emnlp-2013-Semantic_Parsing_on_Freebase_from_Question-Answer_Pairs.html">166 emnlp-2013-Semantic Parsing on Freebase from Question-Answer Pairs</a></p>
<p>9 0.42433363 <a title="110-lsi-9" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>10 0.40848947 <a title="110-lsi-10" href="./emnlp-2013-Error-Driven_Analysis_of_Challenges_in_Coreference_Resolution.html">73 emnlp-2013-Error-Driven Analysis of Challenges in Coreference Resolution</a></p>
<p>11 0.40581754 <a title="110-lsi-11" href="./emnlp-2013-Microblog_Entity_Linking_by_Leveraging_Extra_Posts.html">130 emnlp-2013-Microblog Entity Linking by Leveraging Extra Posts</a></p>
<p>12 0.3908639 <a title="110-lsi-12" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>13 0.38052601 <a title="110-lsi-13" href="./emnlp-2013-Scaling_Semantic_Parsers_with_On-the-Fly_Ontology_Matching.html">164 emnlp-2013-Scaling Semantic Parsers with On-the-Fly Ontology Matching</a></p>
<p>14 0.37683091 <a title="110-lsi-14" href="./emnlp-2013-Detection_of_Product_Comparisons_-_How_Far_Does_an_Out-of-the-Box_Semantic_Role_Labeling_System_Take_You%3F.html">62 emnlp-2013-Detection of Product Comparisons - How Far Does an Out-of-the-Box Semantic Role Labeling System Take You?</a></p>
<p>15 0.36220661 <a title="110-lsi-15" href="./emnlp-2013-Improving_Learning_and_Inference_in_a_Large_Knowledge-Base_using_Latent_Syntactic_Cues.html">102 emnlp-2013-Improving Learning and Inference in a Large Knowledge-Base using Latent Syntactic Cues</a></p>
<p>16 0.33993903 <a title="110-lsi-16" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>17 0.32823375 <a title="110-lsi-17" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>18 0.28926796 <a title="110-lsi-18" href="./emnlp-2013-Measuring_Ideological_Proportions_in_Political_Speeches.html">129 emnlp-2013-Measuring Ideological Proportions in Political Speeches</a></p>
<p>19 0.2777563 <a title="110-lsi-19" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>20 0.2741769 <a title="110-lsi-20" href="./emnlp-2013-Application_of_Localized_Similarity_for_Web_Documents.html">24 emnlp-2013-Application of Localized Similarity for Web Documents</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.038), (9, 0.03), (18, 0.033), (19, 0.029), (22, 0.049), (29, 0.011), (30, 0.065), (36, 0.019), (45, 0.013), (50, 0.021), (51, 0.194), (66, 0.04), (71, 0.034), (75, 0.035), (77, 0.019), (95, 0.166), (96, 0.054), (97, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.96478671 <a title="110-lda-1" href="./emnlp-2013-Fast_Joint_Compression_and_Summarization_via_Graph_Cuts.html">85 emnlp-2013-Fast Joint Compression and Summarization via Graph Cuts</a></p>
<p>Author: Xian Qian ; Yang Liu</p><p>Abstract: Extractive summarization typically uses sentences as summarization units. In contrast, joint compression and summarization can use smaller units such as words and phrases, resulting in summaries containing more information. The goal of compressive summarization is to find a subset of words that maximize the total score of concepts and cutting dependency arcs under the grammar constraints and summary length constraint. We propose an efficient decoding algorithm for fast compressive summarization using graph cuts. Our approach first relaxes the length constraint using Lagrangian relaxation. Then we propose to bound the relaxed objective function by the supermodular binary quadratic programming problem, which can be solved efficiently using graph max-flow/min-cut. Since finding the tightest lower bound suffers from local optimality, we use convex relaxation for initialization. Experimental results on TAC2008 dataset demonstrate our method achieves competitive ROUGE score and has good readability, while is much faster than the integer linear programming (ILP) method.</p><p>2 0.93855524 <a title="110-lda-2" href="./emnlp-2013-A_Constrained_Latent_Variable_Model_for_Coreference_Resolution.html">1 emnlp-2013-A Constrained Latent Variable Model for Coreference Resolution</a></p>
<p>Author: Kai-Wei Chang ; Rajhans Samdani ; Dan Roth</p><p>Abstract: Coreference resolution is a well known clustering task in Natural Language Processing. In this paper, we describe the Latent Left Linking model (L3M), a novel, principled, and linguistically motivated latent structured prediction approach to coreference resolution. We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning. Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches as well as some structured prediction models proposed in the literature.</p><p>same-paper 3 0.8988238 <a title="110-lda-3" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>Author: Hrushikesh Mohapatra ; Siddhanth Jain ; Soumen Chakrabarti</p><p>Abstract: Web search can be enhanced in powerful ways if token spans in Web text are annotated with disambiguated entities from large catalogs like Freebase. Entity annotators need to be trained on sample mention snippets. Wikipedia entities and annotated pages offer high-quality labeled data for training and evaluation. Unfortunately, Wikipedia features only one-ninth the number of entities as Freebase, and these are a highly biased sample of well-connected, frequently mentioned “head” entities. To bring hope to “tail” entities, we broaden our goal to a second task: assigning types to entities in Freebase but not Wikipedia. The two tasks are synergistic: knowing the types of unfamiliar entities helps disambiguate mentions, and words in mention contexts help assign types to entities. We present TMI, a bipartite graphical model for joint type-mention inference. TMI attempts no schema integration or entity resolution, but exploits the above-mentioned synergy. In experiments involving 780,000 people in Wikipedia, 2.3 million people in Freebase, 700 million Web pages, and over 20 professional editors, TMI shows considerable annotation accuracy improvement (e.g., 70%) compared to baselines (e.g., 46%), especially for “tail” and emerging entities. We also compare with Google’s recent annotations of the same corpus with Freebase entities, and report considerable improvements within the people domain.</p><p>4 0.86911637 <a title="110-lda-4" href="./emnlp-2013-Document_Summarization_via_Guided_Sentence_Compression.html">65 emnlp-2013-Document Summarization via Guided Sentence Compression</a></p>
<p>Author: Chen Li ; Fei Liu ; Fuliang Weng ; Yang Liu</p><p>Abstract: Joint compression and summarization has been used recently to generate high quality summaries. However, such word-based joint optimization is computationally expensive. In this paper we adopt the ‘sentence compression + sentence selection’ pipeline approach for compressive summarization, but propose to perform summary guided compression, rather than generic sentence-based compression. To create an annotated corpus, the human annotators were asked to compress sentences while explicitly given the important summary words in the sentences. Using this corpus, we train a supervised sentence compression model using a set of word-, syntax-, and documentlevel features. During summarization, we use multiple compressed sentences in the integer linear programming framework to select . salient summary sentences. Our results on the TAC 2008 and 2011 summarization data sets show that by incorporating the guided sentence compression model, our summarization system can yield significant performance gain as compared to the state-of-the-art.</p><p>5 0.83251995 <a title="110-lda-5" href="./emnlp-2013-Using_Soft_Constraints_in_Joint_Inference_for_Clinical_Concept_Recognition.html">198 emnlp-2013-Using Soft Constraints in Joint Inference for Clinical Concept Recognition</a></p>
<p>Author: Prateek Jindal ; Dan Roth</p><p>Abstract: This paper introduces IQPs (Integer Quadratic Programs) as a way to model joint inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints.</p><p>6 0.80877423 <a title="110-lda-6" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>7 0.80870086 <a title="110-lda-7" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>8 0.80766064 <a title="110-lda-8" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>9 0.80727404 <a title="110-lda-9" href="./emnlp-2013-Joint_Learning_and_Inference_for_Grammatical_Error_Correction.html">114 emnlp-2013-Joint Learning and Inference for Grammatical Error Correction</a></p>
<p>10 0.80006564 <a title="110-lda-10" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<p>11 0.7892229 <a title="110-lda-11" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>12 0.78653467 <a title="110-lda-12" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>13 0.78029722 <a title="110-lda-13" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>14 0.77810293 <a title="110-lda-14" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>15 0.7764563 <a title="110-lda-15" href="./emnlp-2013-Feature_Noising_for_Log-Linear_Structured_Prediction.html">86 emnlp-2013-Feature Noising for Log-Linear Structured Prediction</a></p>
<p>16 0.77614862 <a title="110-lda-16" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>17 0.77603412 <a title="110-lda-17" href="./emnlp-2013-Overcoming_the_Lack_of_Parallel_Data_in_Sentence_Compression.html">149 emnlp-2013-Overcoming the Lack of Parallel Data in Sentence Compression</a></p>
<p>18 0.77419186 <a title="110-lda-18" href="./emnlp-2013-Cross-Lingual_Discriminative_Learning_of_Sequence_Models_with_Posterior_Regularization.html">53 emnlp-2013-Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization</a></p>
<p>19 0.77245641 <a title="110-lda-19" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>20 0.77129239 <a title="110-lda-20" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
