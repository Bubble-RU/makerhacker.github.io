<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-194" href="#">emnlp2013-194</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</h1>
<br/><p>Source: <a title="emnlp-2013-194-pdf" href="http://aclweb.org/anthology//D/D13/D13-1040.pdf">pdf</a></p><p>Author: Oier Lopez de Lacalle ; Mirella Lapata</p><p>Abstract: In this paper we present an unsupervised approach to relational information extraction. Our model partitions tuples representing an observed syntactic relationship between two named entities (e.g., “X was born in Y” and “X is from Y”) into clusters corresponding to underlying semantic relation types (e.g., BornIn, Located). Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task. Evaluation results on the ACE 2007 English Relation Detection and Categorization (RDC) task show that our model outperforms competitive unsupervised approaches by a wide margin and is able to produce clusters shaped by both the data and the rules.</p><p>Reference: <a title="emnlp-2013-194-reference" href="../emnlp2013_reference/emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Our model partitions tuples representing an observed syntactic relationship between two named entities (e. [sent-7, score-0.537]
</p><p>2 , “X was born in Y” and “X is from Y”) into clusters corresponding to underlying semantic relation types (e. [sent-9, score-0.348]
</p><p>3 Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task. [sent-12, score-0.603]
</p><p>4 Standard supervised techniques can yield high performance when large amounts of hand-labeled data are available for a fixed inventory of relation types (e. [sent-20, score-0.25]
</p><p>5 (201 1), for example, propose  a series of topic models which perform relation discovery by clustering tuples representing an observed syntactic relationship between two named entities (e. [sent-26, score-0.859]
</p><p>6 , 2003) in that a document consists of relation tuples rather than individual words; moreover, tuples have features each of which is generated independently from a hidden relation (e. [sent-31, score-1.307]
</p><p>7 Since these features are local, they cannot capture more global constraints pertaining to the relation extraction task. [sent-34, score-0.314]
</p><p>8 Such constraints may take the form of restrictions on which tuples should be clustered together or not. [sent-35, score-0.427]
</p><p>9 For instance, different types of named entities may be indicative of different relations (ORG-LOC entities often express a Location relation whereas PER-PER entities express Business or Family relations) and thus tuples bearing these entities should not be grouped together. [sent-36, score-1.178]
</p><p>10 Another example are tuples with identical or similar features which intuitively should be clustered together. [sent-37, score-0.427]
</p><p>11 In this paper, we propose an unsupervised approach to relation extraction which does not reProceSe datintlges, o Wfa tsh ein 2g01to3n, C UoSnfAe,re 1n8c-e2 o1n O Ecmtopbier ic 2a0l1 M3. [sent-38, score-0.355]
</p><p>12 We encode domain knowledge as First Order Logic (FOL) rules and automatically integrate them with a topic model to produce clusters shaped by the data and the constraints at hand. [sent-41, score-0.431]
</p><p>13 , 2011) to the relation extraction task, explain how to incorporate meaningful constraints, and develop a scalable inference technique. [sent-43, score-0.314]
</p><p>14 In the presence of multiple candidate relation decompositions for a given corpus, domain knowledge can steer the model towards relations which are best aligned with user and task modeling goals. [sent-44, score-0.412]
</p><p>15 We also argue that a general mechanism for encoding additional modeling assumptions and side information can lessen the need for “custom” relation extraction model variants. [sent-45, score-0.314]
</p><p>16 Experimental results on the ACE2007 Relation Detection and Categorization (RDC) dataset show that our model outperforms competi-  tive unsupervised approaches by a wide margin and is able to uncover meaningful relations with only two general rule types. [sent-46, score-0.264]
</p><p>17 2  Related Work  A variety of learning paradigms have been applied to relation extraction. [sent-49, score-0.25]
</p><p>18 Unsupervised relation extraction methods are not limited to a predefined set of target relations, but discover all types of relations found in the text. [sent-54, score-0.425]
</p><p>19 The idea is to take entities that appear in some relation in the database, find the sentences that express the relation in an unlabeled corpus, and use them to train a relation classifier. [sent-61, score-0.871]
</p><p>20 We extend their formulation to relation tuples rather than individual words. [sent-68, score-0.637]
</p><p>21 Our model generates a corpus of entity tuples which are in turn represented by features and uses automatically acquired FOL rules. [sent-69, score-0.439]
</p><p>22 3  Learning Setting  Our relation extraction task broadly adheres to the ACE specification guidelines. [sent-80, score-0.314]
</p><p>23 The input to our model is a corpus of documents, where each document is a bag of relation tuples which can be obtained from the output of any dependency parser. [sent-82, score-0.707]
</p><p>24 Each tuple represents a syntactic relationship between two named entity (NE) mentions, and consists of three components: the dependency path between the two mentions, the source NE, and the target NE. [sent-83, score-0.41]
</p><p>25 A dependency path is the concatenation of dependency edges and nodes along a path in the dependency  tree. [sent-84, score-0.295]
</p><p>26 Tedh→e tuple hteor→e expresses the relation Located, however our model does not observe any relation labels during training. [sent-87, score-0.675]
</p><p>27 The model assigns tuples to clusters, corresponding to an underlying relation type. [sent-88, score-0.637]
</p><p>28 (201 1) who develop a series of generative probabilistic models for relation extraction. [sent-91, score-0.25]
</p><p>29 In relational LDA, each document is a mixture of relations over tuples representing syntactic relations between two named entities. [sent-97, score-0.913]
</p><p>30 The relation tuples are in turn generated a 417 by set of features drawn independently from the underlying relation distribution. [sent-98, score-0.887]
</p><p>31 Relation tuples are generated tfr tohme a cmumuletinnto lmevieall d Riestlraitbiuotnio tnu θdi (zi |θdi ∼ Mult(θdi )) and are represented with k feature|θs. [sent-100, score-0.387]
</p><p>32 E∼ac Mh flet(aθture is drawn (independently) from a multinomial distribution selected by the relation assigned to tuple i(fik |zi, φzi ∼ Mult(φzi )). [sent-101, score-0.473]
</p><p>33 Itino notsh aerre ew dorrawdsn, e fraocmh tuple i cnh a edto pcruiomre (nφt i∼s assigned a hidden relation (z = z1. [sent-103, score-0.425]
</p><p>34 zN); each relation is represented by a multinomial distribution over features φr (Dirichlet prior β). [sent-106, score-0.298]
</p><p>35 Figure 1represents relational LDA model as a an undirected graphical model or factor graph (Bishop, 2006), ignoring for the moment the factor which connects the d, z, f1. [sent-113, score-0.266]
</p><p>36 We adopt the factor graph representation as is it convenient for introducing logic rules into the model. [sent-121, score-0.462]
</p><p>37 The model observes D documents (d) consisting of N tuples (p), each represented by a set of features f1,f2 . [sent-130, score-0.387]
</p><p>38 z represents the relation type assignment to a tuple, θ is the relation type proportion for a given document, and φ the relation type distribution over the features. [sent-134, score-0.75]
</p><p>39 The logic factor (indicated with the arrow) connects the KB with the relational LDA model. [sent-135, score-0.443]
</p><p>40 In our case, our model sees the corpus (p, d), where d is the variable representing the document and the tuples (p) are represented by a set of features f1,f2 . [sent-138, score-0.449]
</p><p>41 Empty circles are associated with latent variables to be estimated: z represents the relation type assignment to the tuple, θ is the relation type proportion for the given document, and φ is the relation type distribution over the features. [sent-142, score-0.851]
</p><p>42 The features representing the tuples tap onto semantic information expressed by different surface forms and are an important part of the model. [sent-143, score-0.416]
</p><p>43 tuTprhle fvakri-  able iranges over tuples in the corpus (i = [1. [sent-149, score-0.387]
</p><p>44 For example, assigned relation variable (Z(i, r)) is true if zi = r and false otherwise. [sent-168, score-0.425]
</p><p>45 At grounding time, we parse the corpus searching for the tuples that satisfy the logic rules and store the indices of the tuples that ground the rule. [sent-178, score-1.271]
</p><p>46 (201 1), we need to ground the rules while taking into account if the feature specified in the rule is expressed by any tuple or the specific given tuple, since we are assigning relations to tuples, and not directly to words. [sent-188, score-0.664]
</p><p>47 The MRF is defined over latent relation tuple assignments z, relation feature multinomials and relation document multinomials θ (the feature set, document, and external information o are observed). [sent-190, score-1.084]
</p><p>48 We select the relation that maximizes the probability arg maxr P(fi |φr) where f1. [sent-201, score-0.287]
</p><p>49 fk are features representinQg the tuple and r the relation index. [sent-204, score-0.518]
</p><p>50 The algorithm alternates between optimizing the multinomial parameters (φ, θ), whilst holding the relation assignments (z) fixed, and vice-versa. [sent-209, score-0.362]
</p><p>51 , groundings whose indicator functions 1g are not affected by the latent relation assignment z. [sent-215, score-0.391]
</p><p>52 aRxθdi(r)kY∈piφzi(fk)  (8)  The second part deals with the remaining zi that appear in non-trivial groundings in the first term of Equation (5). [sent-219, score-0.285]
</p><p>53 The sampled term can be a particPular ground rule Qg or the relational LDA term (Pr zir log θdi (r) Qk∈pi φzi (fk)) for some uniformPly sampled indexQ ki. [sent-224, score-0.42]
</p><p>54 ∈ The sampling of the terms isP weighted accordQing to the rule weight (λl) and the grounded value (G(ψl)) in the case of logic rules, and the size of corpus in tuples (|zKB |) for rerluatlieosn,a aln dLD thAe. [sent-225, score-0.715]
</p><p>55 The main advantage of this approach is that it requires only a means to sample groundings g for each rule ψl, and can avoid fully grounding the FOL rules. [sent-227, score-0.267]
</p><p>56 4 Logic Rules Our model assigns relations to tuples rather than topics to words. [sent-229, score-0.498]
</p><p>57 Since our tuples are described in terms 420 of features our logic rules must reflect this too. [sent-230, score-0.81]
</p><p>58 Must-link Tuple The motivation behind this rule is that tuples which share features probably express the same underlying relation. [sent-232, score-0.553]
</p><p>59 The rule must specify which feature has to be shared for the tuples to be clustered together. [sent-233, score-0.569]
</p><p>60 For example, tuples with ORG-LOC entities, probably express a Location relation and should not be clustered together with PER-PER tuples, which in all likelihood express a different relationship (e. [sent-235, score-0.785]
</p><p>61 The rule below expresses this constraint: ∀i, j,k, l : F(i, NEPAIR:PER-PER) ∧F(j, NEPAIR:ORG-LOC) ∧P(k, fi) ∧ P(l, fj) ⇒ ¬Z(k, r) ∨ ¬Z(l, r) The specification of the first order logic rules is an integral part of the model. [sent-238, score-0.535]
</p><p>62 The rules express knowledge about the task at hand, the domain involved, and the way the relation extraction problem is modeled (i. [sent-239, score-0.626]
</p><p>63 Instead, we obtain logic rules automatically from a corpus following the procedure described in Section 5. [sent-244, score-0.423]
</p><p>64 In our  experiments, we discarded tuples with paths longer than 10 edges (Lin and Pantel, 2001). [sent-254, score-0.387]
</p><p>65 Logic Rule Extraction We automatically extracted logic rules from the New York Times (NYT) corpus as follows. [sent-258, score-0.423]
</p><p>66 The intuition behind Must-link rules is that tuples with common features should cluster together. [sent-259, score-0.66]
</p><p>67 The main intuition behind Cannot-link rules is that tuples without any common features should not cluster together. [sent-267, score-0.66]
</p><p>68 We obtained 20 Must-link rules for coarsegrained relations and 400 rules for their subtypes. [sent-275, score-0.525]
</p><p>69 We extracted 1,814 Cannot-link rules for general relations (N = 50) and 34,522 rules for subtypes (N = 400). [sent-276, score-0.525]
</p><p>70 The number of features involved in the Must-link rules was 25 for coarse-grained relations  and 422 for fine-grained relations. [sent-277, score-0.318]
</p><p>71 The first rule in the upper half of the table states that tuples must cluster together if their source and target entities are PER and contain the trigger word wife in their dependency path. [sent-280, score-0.744]
</p><p>72 According to the third rule, tuples featuring the path PATH:←nsubj←die→prep→in→pobj→ should be in the: same jc←lusdteier. [sent-282, score-0.479]
</p><p>73 → pTrheep →fouinrt→h p roublej→ →for scheso tuples whose source entity is Kobe and target entity is Lakers to cluster together. [sent-283, score-0.557]
</p><p>74 The first rule prevents tuples with ORG-LOC entities to cluster together with PER-PER tuples. [sent-285, score-0.632]
</p><p>75 The second rule states that we cannot link LOC-LOC tuples with those whose trigger word is president, and so on. [sent-286, score-0.574]
</p><p>76 Table 3 shows the optimal number of clusters for different model variants and relation types. [sent-302, score-0.378]
</p><p>77 5 to each rule grounding and (b) we scaled the weights so as to make their contribution comparable to relational LDA. [sent-305, score-0.345]
</p><p>78 At test time, instances were assigned to the relation cluster most similar to them (according to the cosine measure). [sent-318, score-0.316]
</p><p>79 To assess the impact of the rules on the clustering, we conducted several rule ablation studies. [sent-322, score-0.319]
</p><p>80 We thus present results with a model that includes both Must-link and Cannot-link tuple rules (CLT+MLT), and models that include either Mustlink (MLT) or Cannot-link (CLT) rules but not both. [sent-323, score-0.589]
</p><p>81 We report results against coarse- and fine-grained relations (6 and 18 relation  types in ACE, respectively). [sent-325, score-0.361]
</p><p>82 The table shows the optimal number of relation clusters (in parentheses) per model and relation type. [sent-326, score-0.661]
</p><p>83 We thus trained an additional variant of our model with rules extracted from the ACE training set (75%) which contains relation annotations. [sent-329, score-0.457]
</p><p>84 The extraction procedure was similar to the unsupervised case, save that the relation types were known and thus informative features could be mined more reliably. [sent-330, score-0.355]
</p><p>85 For Must-link rules, we extracted unigram and bigram feature frequencies for each relation type and applied TF-IDF weighting in order to discover the most discriminative ones. [sent-331, score-0.28]
</p><p>86 We created logic rules for the 10 best feature combinations in each relation type. [sent-332, score-0.703]
</p><p>87 This is not entirely surprising, given that RelLDA is a relation extraction specific model. [sent-355, score-0.314]
</p><p>88 MLT rules deliver the largest improvement for both coarse and finegrained relation types. [sent-359, score-0.457]
</p><p>89 The inferior performance of the 423 rule combination may be due to the fact that MLT and CLT rules contain conflicting information and to a certain extent cancel each other out. [sent-361, score-0.319]
</p><p>90 Restricting the number of features and rules to named entity pairs only incurs a negligible drop in performance. [sent-365, score-0.313]
</p><p>91 Again, MLT rules perform best in the supervised case, whereas CLT rules marginally improve over RelLDA. [sent-368, score-0.414]
</p><p>92 Examples of relation clusters discovered by the U-MLT (ALL) model are shown in Table 4. [sent-382, score-0.348]
</p><p>93 Our experiments explored the parameter space extensively in order to examine any interactions between the induced relations and the logic rules. [sent-384, score-0.327]
</p><p>94 Overall, we found that the quality of the output is highly correlated with the quality of the logic rules and that a few good rules are more important than the optimal number of clusters. [sent-387, score-0.66]
</p><p>95 2For all comparison models the number of relation clusters was set to 10. [sent-389, score-0.348]
</p><p>96 7  Conclusions  In this paper we presented a new model for unsupervised relation extraction which operates over tu-  ples representing a syntactic relationship between two named entities. [sent-394, score-0.438]
</p><p>97 Our model clusters such tuples into underlying semantic relations (e. [sent-395, score-0.596]
</p><p>98 Specifically, we combine a topic model developed for the relation extraction task with domain relevant rules, and present an algorithm for estimating the parameters of this model. [sent-398, score-0.396]
</p><p>99 In the future, we would like to explore additional types of rules such as seed rules, which would assign tuples complying with the “seed” information to distinct relations. [sent-400, score-0.594]
</p><p>100 Tree kernel-based relation extraction with context-sensitive structured parse tree information. [sent-538, score-0.314]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tuples', 0.387), ('relation', 0.25), ('fol', 0.247), ('logic', 0.216), ('rules', 0.207), ('relational', 0.188), ('lda', 0.184), ('mlt', 0.183), ('zi', 0.175), ('tuple', 0.175), ('clt', 0.165), ('nepair', 0.165), ('rellda', 0.146), ('rule', 0.112), ('relations', 0.111), ('groundings', 0.11), ('hasegawa', 0.11), ('andrzejewski', 0.108), ('clusters', 0.098), ('pobj', 0.095), ('fk', 0.093), ('path', 0.092), ('traveled', 0.091), ('zir', 0.091), ('trigger', 0.075), ('prep', 0.073), ('ky', 0.073), ('bush', 0.073), ('pi', 0.071), ('di', 0.07), ('ace', 0.068), ('nsubj', 0.068), ('entities', 0.067), ('cluster', 0.066), ('yao', 0.064), ('extraction', 0.064), ('mirror', 0.064), ('rdc', 0.064), ('kb', 0.058), ('dest', 0.058), ('express', 0.054), ('named', 0.054), ('entity', 0.052), ('domain', 0.051), ('multinomial', 0.048), ('dirichlet', 0.046), ('grounding', 0.045), ('clique', 0.044), ('shaped', 0.044), ('yr', 0.044), ('loc', 0.043), ('unsupervised', 0.041), ('clustering', 0.041), ('mintz', 0.041), ('nyt', 0.041), ('clustered', 0.04), ('descent', 0.04), ('located', 0.039), ('factor', 0.039), ('mentions', 0.038), ('variables', 0.038), ('dependency', 0.037), ('culotta', 0.037), ('maxr', 0.037), ('njr', 0.037), ('nrf', 0.037), ('sourcepathdest', 0.037), ('france', 0.036), ('assignments', 0.035), ('xl', 0.035), ('ne', 0.034), ('per', 0.033), ('document', 0.033), ('circles', 0.032), ('entropic', 0.032), ('gondek', 0.032), ('basque', 0.032), ('mrf', 0.032), ('thursday', 0.032), ('schoenmackers', 0.032), ('domingos', 0.031), ('latent', 0.031), ('topic', 0.031), ('equation', 0.03), ('richardson', 0.03), ('logical', 0.03), ('feature', 0.03), ('optimal', 0.03), ('representing', 0.029), ('ground', 0.029), ('surprise', 0.029), ('whilst', 0.029), ('sekine', 0.029), ('shinyama', 0.029), ('xg', 0.029), ('horn', 0.029), ('wagstaff', 0.029), ('george', 0.029), ('edinburgh', 0.028), ('distant', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000015 <a title="194-tfidf-1" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>Author: Oier Lopez de Lacalle ; Mirella Lapata</p><p>Abstract: In this paper we present an unsupervised approach to relational information extraction. Our model partitions tuples representing an observed syntactic relationship between two named entities (e.g., “X was born in Y” and “X is from Y”) into clusters corresponding to underlying semantic relation types (e.g., BornIn, Located). Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task. Evaluation results on the ACE 2007 English Relation Detection and Categorization (RDC) task show that our model outperforms competitive unsupervised approaches by a wide margin and is able to produce clusters shaped by both the data and the rules.</p><p>2 0.21118169 <a title="194-tfidf-2" href="./emnlp-2013-Generating_Coherent_Event_Schemas_at_Scale.html">90 emnlp-2013-Generating Coherent Event Schemas at Scale</a></p>
<p>Author: Niranjan Balasubramanian ; Stephen Soderland ; Mausam ; Oren Etzioni</p><p>Abstract: Chambers and Jurafsky (2009) demonstrated that event schemas can be automatically induced from text corpora. However, our analysis of their schemas identifies several weaknesses, e.g., some schemas lack a common topic and distinct roles are incorrectly mixed into a single actor. It is due in part to their pair-wise representation that treats subjectverb independently from verb-object. This often leads to subject-verb-object triples that are not meaningful in the real-world. We present a novel approach to inducing open-domain event schemas that overcomes these limitations. Our approach uses cooccurrence statistics of semantically typed relational triples, which we call Rel-grams (relational n-grams). In a human evaluation, our schemas outperform Chambers’s schemas by wide margins on several evaluation criteria. Both Rel-grams and event schemas are freely available to the research community.</p><p>3 0.14197156 <a title="194-tfidf-3" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>4 0.1400952 <a title="194-tfidf-4" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>Author: Xiao Cheng ; Dan Roth</p><p>Abstract: Wikification, commonly referred to as Disambiguation to Wikipedia (D2W), is the task of identifying concepts and entities in text and disambiguating them into the most specific corresponding Wikipedia pages. Previous approaches to D2W focused on the use of local and global statistics over the given text, Wikipedia articles and its link structures, to evaluate context compatibility among a list of probable candidates. However, these methods fail (often, embarrassingly), when some level of text understanding is needed to support Wikification. In this paper we introduce a novel approach to Wikification by incorporating, along with statistical methods, richer relational analysis of the text. We provide an extensible, efficient and modular Integer Linear Programming (ILP) formulation of Wikification that incorporates the entity-relation inference problem, and show that the ability to identify relations in text helps both candi- date generation and ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task.</p><p>5 0.13473056 <a title="194-tfidf-5" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>Author: Benjamin Roth ; Dietrich Klakow</p><p>Abstract: Distant supervision is a scheme to generate noisy training data for relation extraction by aligning entities of a knowledge base with text. In this work we combine the output of a discriminative at-least-one learner with that of a generative hierarchical topic model to reduce the noise in distant supervision data. The combination significantly increases the ranking quality of extracted facts and achieves state-of-the-art extraction performance in an end-to-end setting. A simple linear interpolation of the model scores performs better than a parameter-free scheme based on nondominated sorting.</p><p>6 0.13330823 <a title="194-tfidf-6" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>7 0.12513471 <a title="194-tfidf-7" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>8 0.12453179 <a title="194-tfidf-8" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>9 0.11610303 <a title="194-tfidf-9" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>10 0.10948432 <a title="194-tfidf-10" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>11 0.10212244 <a title="194-tfidf-11" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>12 0.097558312 <a title="194-tfidf-12" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>13 0.086278498 <a title="194-tfidf-13" href="./emnlp-2013-Improving_Learning_and_Inference_in_a_Large_Knowledge-Base_using_Latent_Syntactic_Cues.html">102 emnlp-2013-Improving Learning and Inference in a Large Knowledge-Base using Latent Syntactic Cues</a></p>
<p>14 0.085732125 <a title="194-tfidf-14" href="./emnlp-2013-Translation_with_Source_Constituency_and_Dependency_Trees.html">187 emnlp-2013-Translation with Source Constituency and Dependency Trees</a></p>
<p>15 0.085171297 <a title="194-tfidf-15" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<p>16 0.083077632 <a title="194-tfidf-16" href="./emnlp-2013-Efficient_Collective_Entity_Linking_with_Stacking.html">69 emnlp-2013-Efficient Collective Entity Linking with Stacking</a></p>
<p>17 0.081906721 <a title="194-tfidf-17" href="./emnlp-2013-A_Multimodal_LDA_Model_integrating_Textual%2C_Cognitive_and_Visual_Modalities.html">11 emnlp-2013-A Multimodal LDA Model integrating Textual, Cognitive and Visual Modalities</a></p>
<p>18 0.081773773 <a title="194-tfidf-18" href="./emnlp-2013-Learning_Latent_Word_Representations_for_Domain_Adaptation_using_Supervised_Word_Clustering.html">120 emnlp-2013-Learning Latent Word Representations for Domain Adaptation using Supervised Word Clustering</a></p>
<p>19 0.081459865 <a title="194-tfidf-19" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>20 0.081296697 <a title="194-tfidf-20" href="./emnlp-2013-Building_Event_Threads_out_of_Multiple_News_Articles.html">41 emnlp-2013-Building Event Threads out of Multiple News Articles</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.271), (1, 0.095), (2, 0.019), (3, 0.128), (4, 0.0), (5, 0.072), (6, -0.076), (7, 0.037), (8, 0.112), (9, -0.007), (10, 0.114), (11, -0.224), (12, -0.138), (13, 0.107), (14, -0.121), (15, 0.027), (16, 0.049), (17, 0.003), (18, 0.119), (19, -0.036), (20, -0.033), (21, 0.184), (22, 0.049), (23, -0.111), (24, -0.144), (25, -0.055), (26, -0.035), (27, -0.024), (28, -0.008), (29, 0.064), (30, -0.089), (31, 0.089), (32, 0.002), (33, -0.062), (34, 0.019), (35, -0.069), (36, -0.052), (37, -0.01), (38, 0.051), (39, 0.101), (40, 0.043), (41, -0.11), (42, 0.065), (43, 0.133), (44, 0.111), (45, 0.012), (46, 0.022), (47, 0.054), (48, -0.009), (49, -0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96120816 <a title="194-lsi-1" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>Author: Oier Lopez de Lacalle ; Mirella Lapata</p><p>Abstract: In this paper we present an unsupervised approach to relational information extraction. Our model partitions tuples representing an observed syntactic relationship between two named entities (e.g., “X was born in Y” and “X is from Y”) into clusters corresponding to underlying semantic relation types (e.g., BornIn, Located). Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task. Evaluation results on the ACE 2007 English Relation Detection and Categorization (RDC) task show that our model outperforms competitive unsupervised approaches by a wide margin and is able to produce clusters shaped by both the data and the rules.</p><p>2 0.66742927 <a title="194-lsi-2" href="./emnlp-2013-Combining_Generative_and_Discriminative_Model_Scores_for_Distant_Supervision.html">49 emnlp-2013-Combining Generative and Discriminative Model Scores for Distant Supervision</a></p>
<p>Author: Benjamin Roth ; Dietrich Klakow</p><p>Abstract: Distant supervision is a scheme to generate noisy training data for relation extraction by aligning entities of a knowledge base with text. In this work we combine the output of a discriminative at-least-one learner with that of a generative hierarchical topic model to reduce the noise in distant supervision data. The combination significantly increases the ranking quality of extracted facts and achieves state-of-the-art extraction performance in an end-to-end setting. A simple linear interpolation of the model scores performs better than a parameter-free scheme based on nondominated sorting.</p><p>3 0.65088075 <a title="194-lsi-3" href="./emnlp-2013-Effectiveness_and_Efficiency_of_Open_Relation_Extraction.html">68 emnlp-2013-Effectiveness and Efficiency of Open Relation Extraction</a></p>
<p>Author: Filipe Mesquita ; Jordan Schmidek ; Denilson Barbosa</p><p>Abstract: A large number of Open Relation Extraction approaches have been proposed recently, covering a wide range of NLP machinery, from “shallow” (e.g., part-of-speech tagging) to “deep” (e.g., semantic role labeling–SRL). A natural question then is what is the tradeoff between NLP depth (and associated computational cost) versus effectiveness. This paper presents a fair and objective experimental comparison of 8 state-of-the-art approaches over 5 different datasets, and sheds some light on the issue. The paper also describes a novel method, EXEMPLAR, which adapts ideas from SRL to less costly NLP machinery, resulting in substantial gains both in efficiency and effectiveness, over binary and n-ary relation extraction tasks.</p><p>4 0.64548749 <a title="194-lsi-4" href="./emnlp-2013-Predicting_the_Presence_of_Discourse_Connectives.html">152 emnlp-2013-Predicting the Presence of Discourse Connectives</a></p>
<p>Author: Gary Patterson ; Andrew Kehler</p><p>Abstract: We present a classification model that predicts the presence or omission of a lexical connective between two clauses, based upon linguistic features of the clauses and the type of discourse relation holding between them. The model is trained on a set of high frequency relations extracted from the Penn Discourse Treebank and achieves an accuracy of 86.6%. Analysis of the results reveals that the most informative features relate to the discourse dependencies between sequences of coherence relations in the text. We also present results of an experiment that provides insight into the nature and difficulty of the task.</p><p>5 0.58497548 <a title="194-lsi-5" href="./emnlp-2013-Generating_Coherent_Event_Schemas_at_Scale.html">90 emnlp-2013-Generating Coherent Event Schemas at Scale</a></p>
<p>Author: Niranjan Balasubramanian ; Stephen Soderland ; Mausam ; Oren Etzioni</p><p>Abstract: Chambers and Jurafsky (2009) demonstrated that event schemas can be automatically induced from text corpora. However, our analysis of their schemas identifies several weaknesses, e.g., some schemas lack a common topic and distinct roles are incorrectly mixed into a single actor. It is due in part to their pair-wise representation that treats subjectverb independently from verb-object. This often leads to subject-verb-object triples that are not meaningful in the real-world. We present a novel approach to inducing open-domain event schemas that overcomes these limitations. Our approach uses cooccurrence statistics of semantically typed relational triples, which we call Rel-grams (relational n-grams). In a human evaluation, our schemas outperform Chambers’s schemas by wide margins on several evaluation criteria. Both Rel-grams and event schemas are freely available to the research community.</p><p>6 0.54327905 <a title="194-lsi-6" href="./emnlp-2013-Relational_Inference_for_Wikification.html">160 emnlp-2013-Relational Inference for Wikification</a></p>
<p>7 0.54187101 <a title="194-lsi-7" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>8 0.52081889 <a title="194-lsi-8" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>9 0.5139975 <a title="194-lsi-9" href="./emnlp-2013-Event_Schema_Induction_with_a_Probabilistic_Entity-Driven_Model.html">75 emnlp-2013-Event Schema Induction with a Probabilistic Entity-Driven Model</a></p>
<p>10 0.51002872 <a title="194-lsi-10" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>11 0.48925328 <a title="194-lsi-11" href="./emnlp-2013-Rule-Based_Information_Extraction_is_Dead%21_Long_Live_Rule-Based_Information_Extraction_Systems%21.html">161 emnlp-2013-Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!</a></p>
<p>12 0.45897871 <a title="194-lsi-12" href="./emnlp-2013-Implicit_Feature_Detection_via_a_Constrained_Topic_Model_and_SVM.html">99 emnlp-2013-Implicit Feature Detection via a Constrained Topic Model and SVM</a></p>
<p>13 0.45421788 <a title="194-lsi-13" href="./emnlp-2013-Naive_Bayes_Word_Sense_Induction.html">138 emnlp-2013-Naive Bayes Word Sense Induction</a></p>
<p>14 0.44409496 <a title="194-lsi-14" href="./emnlp-2013-Unsupervised_Spectral_Learning_of_WCFG_as_Low-rank_Matrix_Completion.html">195 emnlp-2013-Unsupervised Spectral Learning of WCFG as Low-rank Matrix Completion</a></p>
<p>15 0.41175333 <a title="194-lsi-15" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>16 0.40274227 <a title="194-lsi-16" href="./emnlp-2013-A_Semantically_Enhanced_Approach_to_Determine_Textual_Similarity.html">12 emnlp-2013-A Semantically Enhanced Approach to Determine Textual Similarity</a></p>
<p>17 0.3956176 <a title="194-lsi-17" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>18 0.38782305 <a title="194-lsi-18" href="./emnlp-2013-Improving_Learning_and_Inference_in_a_Large_Knowledge-Base_using_Latent_Syntactic_Cues.html">102 emnlp-2013-Improving Learning and Inference in a Large Knowledge-Base using Latent Syntactic Cues</a></p>
<p>19 0.38588148 <a title="194-lsi-19" href="./emnlp-2013-Multi-Relational_Latent_Semantic_Analysis.html">137 emnlp-2013-Multi-Relational Latent Semantic Analysis</a></p>
<p>20 0.38349798 <a title="194-lsi-20" href="./emnlp-2013-A_Multimodal_LDA_Model_integrating_Textual%2C_Cognitive_and_Visual_Modalities.html">11 emnlp-2013-A Multimodal LDA Model integrating Textual, Cognitive and Visual Modalities</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.037), (9, 0.028), (10, 0.264), (18, 0.043), (22, 0.054), (30, 0.076), (50, 0.014), (51, 0.162), (66, 0.043), (71, 0.039), (75, 0.083), (77, 0.02), (95, 0.011), (96, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.80656064 <a title="194-lda-1" href="./emnlp-2013-Improving_Statistical_Machine_Translation_with_Word_Class_Models.html">104 emnlp-2013-Improving Statistical Machine Translation with Word Class Models</a></p>
<p>Author: Joern Wuebker ; Stephan Peitz ; Felix Rietig ; Hermann Ney</p><p>Abstract: Automatically clustering words from a monolingual or bilingual training corpus into classes is a widely used technique in statistical natural language processing. We present a very simple and easy to implement method for using these word classes to improve translation quality. It can be applied across different machine translation paradigms and with arbitrary types of models. We show its efficacy on a small German→English and a larger F ornenc ah s→mGalelrm Gaenrm mtarann→slEatniognli tsahsk a nwdit ha lbaortghe rst Farnednacrhd→ phrase-based salandti nhie traaskrch wiciathl phrase-based translation systems for a common set of models. Our results show that with word class models, the baseline can be improved by up to 1.4% BLEU and 1.0% TER on the French→German task and 0.3% BLEU aonnd t h1e .1 F%re nTcEhR→ on tehrem German→English Btask.</p><p>same-paper 2 0.79269028 <a title="194-lda-2" href="./emnlp-2013-Unsupervised_Relation_Extraction_with_General_Domain_Knowledge.html">194 emnlp-2013-Unsupervised Relation Extraction with General Domain Knowledge</a></p>
<p>Author: Oier Lopez de Lacalle ; Mirella Lapata</p><p>Abstract: In this paper we present an unsupervised approach to relational information extraction. Our model partitions tuples representing an observed syntactic relationship between two named entities (e.g., “X was born in Y” and “X is from Y”) into clusters corresponding to underlying semantic relation types (e.g., BornIn, Located). Our approach incorporates general domain knowledge which we encode as First Order Logic rules and automatically combine with a topic model developed specifically for the relation extraction task. Evaluation results on the ACE 2007 English Relation Detection and Categorization (RDC) task show that our model outperforms competitive unsupervised approaches by a wide margin and is able to produce clusters shaped by both the data and the rules.</p><p>3 0.77593672 <a title="194-lda-3" href="./emnlp-2013-Gender_Inference_of_Twitter_Users_in_Non-English_Contexts.html">89 emnlp-2013-Gender Inference of Twitter Users in Non-English Contexts</a></p>
<p>Author: Morgane Ciot ; Morgan Sonderegger ; Derek Ruths</p><p>Abstract: While much work has considered the problem of latent attribute inference for users of social media such as Twitter, little has been done on non-English-based content and users. Here, we conduct the first assessment of latent attribute inference in languages beyond English, focusing on gender inference. We find that the gender inference problem in quite diverse languages can be addressed using existing machinery. Further, accuracy gains can be made by taking language-specific features into account. We identify languages with complex orthography, such as Japanese, as difficult for existing methods, suggesting a valuable direction for future research.</p><p>4 0.63682187 <a title="194-lda-4" href="./emnlp-2013-Exploring_Demographic_Language_Variations_to_Improve_Multilingual_Sentiment_Analysis_in_Social_Media.html">81 emnlp-2013-Exploring Demographic Language Variations to Improve Multilingual Sentiment Analysis in Social Media</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: Theresa Wilson Human Language Technology Center of Excellence Johns Hopkins University Baltimore, MD t aw@ j hu .edu differences may Different demographics, e.g., gender or age, can demonstrate substantial variation in their language use, particularly in informal contexts such as social media. In this paper we focus on learning gender differences in the use of subjective language in English, Spanish, and Russian Twitter data, and explore cross-cultural differences in emoticon and hashtag use for male and female users. We show that gender differences in subjective language can effectively be used to improve sentiment analysis, and in particular, polarity classification for Spanish and Russian. Our results show statistically significant relative F-measure improvement over the gender-independent baseline 1.5% and 1% for Russian, 2% and 0.5% for Spanish, and 2.5% and 5% for English for polarity and subjectivity classification.</p><p>5 0.62279147 <a title="194-lda-5" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>6 0.61308658 <a title="194-lda-6" href="./emnlp-2013-Deep_Learning_for_Chinese_Word_Segmentation_and_POS_Tagging.html">56 emnlp-2013-Deep Learning for Chinese Word Segmentation and POS Tagging</a></p>
<p>7 0.61158794 <a title="194-lda-7" href="./emnlp-2013-Exploiting_Zero_Pronouns_to_Improve_Chinese_Coreference_Resolution.html">80 emnlp-2013-Exploiting Zero Pronouns to Improve Chinese Coreference Resolution</a></p>
<p>8 0.61117327 <a title="194-lda-8" href="./emnlp-2013-Interactive_Machine_Translation_using_Hierarchical_Translation_Models.html">107 emnlp-2013-Interactive Machine Translation using Hierarchical Translation Models</a></p>
<p>9 0.61070931 <a title="194-lda-9" href="./emnlp-2013-Connecting_Language_and_Knowledge_Bases_with_Embedding_Models_for_Relation_Extraction.html">51 emnlp-2013-Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction</a></p>
<p>10 0.61016542 <a title="194-lda-10" href="./emnlp-2013-Latent_Anaphora_Resolution_for_Cross-Lingual_Pronoun_Prediction.html">117 emnlp-2013-Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction</a></p>
<p>11 0.60789794 <a title="194-lda-11" href="./emnlp-2013-Summarizing_Complex_Events%3A_a_Cross-Modal_Solution_of_Storylines_Extraction_and_Reconstruction.html">179 emnlp-2013-Summarizing Complex Events: a Cross-Modal Solution of Storylines Extraction and Reconstruction</a></p>
<p>12 0.60755271 <a title="194-lda-12" href="./emnlp-2013-Document_Summarization_via_Guided_Sentence_Compression.html">65 emnlp-2013-Document Summarization via Guided Sentence Compression</a></p>
<p>13 0.60513234 <a title="194-lda-13" href="./emnlp-2013-Converting_Continuous-Space_Language_Models_into_N-Gram_Language_Models_for_Statistical_Machine_Translation.html">52 emnlp-2013-Converting Continuous-Space Language Models into N-Gram Language Models for Statistical Machine Translation</a></p>
<p>14 0.60463738 <a title="194-lda-14" href="./emnlp-2013-Exploiting_Domain_Knowledge_in_Aspect_Extraction.html">77 emnlp-2013-Exploiting Domain Knowledge in Aspect Extraction</a></p>
<p>15 0.6038608 <a title="194-lda-15" href="./emnlp-2013-Collective_Opinion_Target_Extraction_in_Chinese_Microblogs.html">47 emnlp-2013-Collective Opinion Target Extraction in Chinese Microblogs</a></p>
<p>16 0.60216993 <a title="194-lda-16" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>17 0.60191244 <a title="194-lda-17" href="./emnlp-2013-Joint_Bootstrapping_of_Corpus_Annotations_and_Entity_Types.html">110 emnlp-2013-Joint Bootstrapping of Corpus Annotations and Entity Types</a></p>
<p>18 0.60167044 <a title="194-lda-18" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>19 0.60152274 <a title="194-lda-19" href="./emnlp-2013-Automatic_Feature_Engineering_for_Answer_Selection_and_Extraction.html">31 emnlp-2013-Automatic Feature Engineering for Answer Selection and Extraction</a></p>
<p>20 0.60028249 <a title="194-lda-20" href="./emnlp-2013-Automatically_Determining_a_Proper_Length_for_Multi-Document_Summarization%3A_A_Bayesian_Nonparametric_Approach.html">36 emnlp-2013-Automatically Determining a Proper Length for Multi-Document Summarization: A Bayesian Nonparametric Approach</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
