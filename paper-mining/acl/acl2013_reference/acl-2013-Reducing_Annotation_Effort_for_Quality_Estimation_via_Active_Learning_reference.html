<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>300 acl-2013-Reducing Annotation Effort for Quality Estimation via Active Learning</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-300" href="../acl2013/acl-2013-Reducing_Annotation_Effort_for_Quality_Estimation_via_Active_Learning.html">acl2013-300</a> <a title="acl-2013-300-reference" href="#">acl2013-300-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>300 acl-2013-Reducing Annotation Effort for Quality Estimation via Active Learning</h1>
<br/><p>Source: <a title="acl-2013-300-pdf" href="http://aclweb.org/anthology//P/P13/P13-2097.pdf">pdf</a></p><p>Author: Daniel Beck ; Lucia Specia ; Trevor Cohn</p><p>Abstract: Quality estimation models provide feedback on the quality of machine translated texts. They are usually trained on humanannotated datasets, which are very costly due to its task-specific nature. We investigate active learning techniques to reduce the size of these datasets and thus annotation effort. Experiments on a number of datasets show that with as little as 25% of the training instances it is possible to obtain similar or superior performance compared to that of the complete datasets. In other words, our active learning query strategies can not only reduce annotation effort but can also result in better quality predictors. ,t .</p><br/>
<h2>reference text</h2><p>Naoki Abe and Hiroshi Mamitsuka. 1998. Query learning strategies using boosting and bagging. In Proceedings of the Fifteenth International Conference on Machine Learning, pages 1–9.  Jason Baldridge and Miles Osborne. 2004. Active learning and the total cost of annotation. In Proceedings of EMNLP, pages 9–16. 547  John Blatz, Erin Fitzgerald, and George Foster. 2004. Confidence estimation for machine translation. In Proceedings of the 20th Conference on Computational Linguistics, pages 3 15–321. Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2012. Findings of the 2012 Workshop on Statistical Machine Translation. In Proceedings of 7th Workshop on Statistical Machine Translation. Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and psychological measurement, 20(1):37–46. George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Proceedings of the Second International Conference on Human Language Technology Research, pages 128–132. Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi,  Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 177–180. David D. Lewis and Willian A. Gale. 1994. A sequential algorithm for training text classifiers. In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval, pages 1 10. Fredrik Olsson. 2009. A literature survey of active machine learning in the context of natural language processing. Technical report. Fabian Pedregosa, Ga¨ el Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Duborg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and E´douard Duchesnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830. Chris Quirk. 2004. Training a sentence-level machine translation confidence measure. In Proceedings of  LREC, pages 825–828. Burr Settles and Mark Craven. 2008. An analysis of active learning strategies for sequence labeling tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1070–1079. Burr Settles. 2010. Active learning literature survey. Technical report. Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of Association for Machine Translation in the Americas. Lucia Specia and Atefeh Farzindar. 2010. Estimating machine translation post-editing effort with HTER. In Proceedings of AMTA Workshop Bringing MT to the User: MT Research and the Translation Industry. Lucia Specia, M Turchi, Zhuoran Wang, and J ShaweTaylor. 2009. Improving the confidence of machine translation quality estimates. In Proceedings of MT Summit XII. Lucia Specia, Najeh Hajlaoui, Catalina Hallett, and Wilker Aziz. 2011. Predicting machine translation  adequacy. In Proceedings of MT Summit XIII. Lucia Specia. 2011. Exploiting objective annotations for measuring translation post-editing effort. In Proceedings of EAMT. Andreas Vlachos. 2006. Active annotation. In Proceedings of the Workshop on Adaptive Text Extraction and Mining at EACL. 548</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
