<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-195" href="../acl2013/acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">acl2013-195</a> <a title="acl-2013-195-reference" href="#">acl2013-195-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</h1>
<br/><p>Source: <a title="acl-2013-195-pdf" href="http://aclweb.org/anthology//P/P13/P13-2067.pdf">pdf</a></p><p>Author: Chi-kiu Lo ; Karteek Addanki ; Markus Saers ; Dekai Wu</p><p>Abstract: We present the first ever results showing that tuning a machine translation system against a semantic frame based objective function, MEANT, produces more robustly adequate translations than tuning against BLEU or TER as measured across commonly used metrics and human subjective evaluation. Moreover, for informal web forum data, human evaluators preferred MEANT-tuned systems over BLEU- or TER-tuned systems by a significantly wider margin than that for formal newswire—even though automatic semantic parsing might be expected to fare worse on informal language. We argue thatbypreserving the meaning ofthe trans- lations as captured by semantic frames right in the training process, an MT system is constrained to make more accurate choices of both lexical and reordering rules. As a result, MT systems tuned against semantic frame based MT evaluation metrics produce output that is more adequate. Tuning a machine translation system against a semantic frame based objective function is independent ofthe translation model paradigm, so, any translation model can benefit from the semantic knowledge incorporated to improve translation adequacy through our approach.</p><br/>
<h2>reference text</h2><p>Wilker Aziz, Miguel Rios, and Lucia Specia. Shallow semantic trees for SMT. In Proceedings of the Sixth Workshop on Statistical Machine Translation (WMT2011), 2011. Satanjeev Banerjee and Alon Lavie. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic andExtrinsic Evaluation MeasuresforMachine  Translation and/or Summarization, pages 65– 72, Ann Arbor, Michigan, June 2005. Chris Callison-Burch, Miles Osborne, and Philipp Koehn. Re-evaluating the role of BLEU in Machine Translation Research. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06), pages 249–256, 2006. Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. (Meta-) evaluation of Machine Translation. In Proceedings of the 2nd Workshop on Statistical Machine Translation, pages 136–1 58, 2007. Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. Further Meta-evaluation of Machine Translation. In Proceedings of the 3rd Workshop on Statistical Machine Translation, pages 70–106, 2008. George Doddington. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Proceedings of the 2nd International Conference on Human Lan-  guage Technology Research, pages 138–145, San Diego, California, 2002. Jesús Giménez and Lluís Màrquez. Linguistic features for automatic evaluation of heterogenous MT systems. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 256–264, Prague, Czech Republic, June 2007. Jesús Giménez and Lluís Màrquez. A smorgasbord offeatures for automatic MT evaluation. InProceedings of the Third Workshop on Statistical Machine Translation, pages 195–198, Columbus, Ohio, June 2008. Philipp Koehn and Christof Monz. Manual and Automatic Evaluation of Machine Translation between European Languages. In Proceedings of the Workshop on Statistical Machine Translation (WMT-06), pages 102–121, 2006. Mamoru Komachi, Yuji Matsumoto, and Masaaki Nagata. Phrase reordering for statistical machine translation based on predicate-argument structure. In Proceedings of the 3rd International Workshop on Spoken Language Transla-  tion (IWSLT 2006), 2006. Patrik Lambert, Jesús Giménez, Marta R Costajussá, Enrique Amigó, Rafael E Banchs, Lluıs Márquez, and JAR Fonollosa. Machine Translation system development based on human likeness. In Spoken Language Technology Workshop, 2006. IEEE, pages 246–249. IEEE, 2006. Gregor Leusch, Nicola Ueffing, and Hermann Ney. CDer: Efficient MT Evaluation Using Block Movements. In Proceedings of the 13th Conference of the European Chapter of the Associationfor ComputationalLinguistics (EACL06), 2006. Ding Liu and Daniel Gildea. Semantic role features for machine translation. In Proceedings of the 23rd international conference on Computational Linguistics (COLING-10), 2010. Chi-kiu Lo, Anand Karthik Tumuluru, and Dekai Wu. Fully Automatic Semantic MT Evaluation. In Proceedings of the Seventh Workshop on StatisticalMachine Translation (WMT2012), 2012. Sonja Nießen, Franz Josef Och, Gregor Leusch, and Hermann Ney. A Evaluation Tool for Ma-  chine Translation: Fast Evaluation for MT Research. In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC-2000), 2000. Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 3 11 3 18, Philadelphia, Pennsylvania, July 2002. Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James H. Martin, and Dan Jurafsky. Shallow Semantic Parsing Using Support Vector Machines. In Proceedings of the 2004 Conference on Human Language Technology and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL-04), 2004. Miguel Rios, Wilker Aziz, and Lucia Specia. Tine: A metric to assess mt adequacy. In Proceed380  the Sixth Workshop on Statistical Machine Translation, pages 116–122. Association for Computational Linguistics, 201 1. Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference ings of  of the Association for Machine  Translation  in  theAmericas (AMTA-06), pages 223–23 1, Cambridge, Massachusetts, August 2006. Dekai Wu and Pascale Fung. Semantic Roles for SMT: A Hybrid Two-Pass Model. In Proceedings of the 2009 Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL-HLT-09), pages 13–16, 2009. Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, and Masaaki Nagata. Extracting preordering rules from predicate-argument structures. In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP-11), 2011. Deyi Xiong, Min Zhang, and Haizhou Li. Modeling the Translation of Predicate-Argument Structure for SMT. In Proceedings of the Joint conference ofthe 50thAnnualMeeting oftheAssociation for Computational Linguistics (ACL12), 2012. Omar F. Zaidan. Z-MERT: A Fully Configurable Open Source Tool for Minimum Error Rate Training of Machine Translation Systems. The Prague Bulletin of Mathematical Linguistics, 91:79–88, 2009. 381</p>
<br/>
<br/><br/><br/></body>
</html>
