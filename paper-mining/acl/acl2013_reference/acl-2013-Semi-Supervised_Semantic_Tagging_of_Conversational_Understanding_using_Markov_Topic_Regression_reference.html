<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>315 acl-2013-Semi-Supervised Semantic Tagging of Conversational Understanding using Markov Topic Regression</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-315" href="../acl2013/acl-2013-Semi-Supervised_Semantic_Tagging_of_Conversational_Understanding_using_Markov_Topic_Regression.html">acl2013-315</a> <a title="acl-2013-315-reference" href="#">acl2013-315-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>315 acl-2013-Semi-Supervised Semantic Tagging of Conversational Understanding using Markov Topic Regression</h1>
<br/><p>Source: <a title="acl-2013-315-pdf" href="http://aclweb.org/anthology//P/P13/P13-1090.pdf">pdf</a></p><p>Author: Asli Celikyilmaz ; Dilek Hakkani-Tur ; Gokhan Tur ; Ruhi Sarikaya</p><p>Abstract: Microsoft Research Microsoft Mountain View, CA, USA Redmond, WA, USA dilek @ ieee .org rus arika@mi cro s o ft . com gokhan .tur @ ieee .org performance (Tur and DeMori, 2011). This requires a tedious and time intensive data collection Finding concepts in natural language utterances is a challenging task, especially given the scarcity of labeled data for learning semantic ambiguity. Furthermore, data mismatch issues, which arise when the expected test (target) data does not exactly match the training data, aggravate this scarcity problem. To deal with these issues, we describe an efficient semisupervised learning (SSL) approach which has two components: (i) Markov Topic Regression is a new probabilistic model to cluster words into semantic tags (concepts). It can efficiently handle semantic ambiguity by extending standard topic models with two new features. First, it encodes word n-gram features from labeled source and unlabeled target data. Second, by going beyond a bag-of-words approach, it takes into account the inherent sequential nature of utterances to learn semantic classes based on context. (ii) Retrospective Learner is a new learning technique that adapts to the unlabeled target data. Our new SSL approach improves semantic tagging performance by 3% absolute over the baseline models, and also compares favorably on semi-supervised syntactic tagging.</p><br/>
<h2>reference text</h2><p>D. Blei, A. Ng, and M. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research. J. Boyd-Graber, D. Blei, and X. Zhu. 2007. A topic model for word sense disambiguation. Proc. EMNLP. P.F. Brown, V.J.D. Pietra, P.V. deSouza, and J.C. Lai. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4):467–479. O. Chapelle, B. Schlkopf, and Alexander Zien. 2006. Semi-supervised learning. MIT Press. H. Daum e´-III. 2010. Frustratingly easy semisupervised domain adaptation. Proc. Workshop on Domain Adaptation for Natural Language Processing at ACL. T.L Griffiths, M. Steyvers, D.M. Blei, and J.M. Tenenbaum. 2005. Integrating topics and syntax. Proc. of NIPS. A. Gruber, M. Rosen-Zvi, and Y. Weiss. 2005. Hidden  topic markov models. Proc. of ICML. H. Guo, H. Zhu, Z. Guo, X. Zhang, X. Wu, and Z. Su. 2009. Domain adaptation with latent semantic association for named entity recognition. Proc. NAACL. 922 J. Judge, A. Cahill, and J.Van Genabith. 2006. Question-bank: Creating corpus of parse-annotated questions. Proc. Int. Conf. Computational Linguistics and ACL. A. Lavoie, M.E. Otey, N. Ratliff, and D. Sculley. 2011. History dependent domain adaptation. Proc. NIPS Workshop on Domain Adaptation. X. Li, Y.-Y. Wang, and A. Acero. 2009. Extracting structured information from user queries with semisupervised conditional random fields. Proc. of SIGIR. L. Li, B. Roth, and C. Sporleder. 2010. Topic models for word sense disambiguation and token-based idiom detection. Proc. ACL. X. Li. 2010. Understanding semantic structure of noun phrase queries. Proc. ACL. J Liu, X. Li, A. Acero, and Ye-Yi Wang. 2011. Lexicon modeling for query understanding. Proc. of ICASSP. M. P. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 27: 1–30. D. Mimno, W. Li, and A. McCallum. 2008. Topic models conditioned on arbitrary features with dirichlet-multinomial regression. Proc. UAI. T. Moon, K. Erk, and J. Baldridge. 2010. Crouching dirichlet, hidden markov model: Unsupervised pos tagging with context local tag generation. Proc. ACL. V.-A. Nyugen, J. Boyd-Graber, and P. Resnik. 2012. Sits: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations. Proc. ACL. P. Pantel. 2003. Clustering by committee. Ph.D. Thesis, University of Alberta, Edmonton, Alta., Canada. J. Petterson, A. Smola, T. Caetano, W. Buntine, and S. Narayanamurthy. 2010. Word features for latent dirichlet allocation. In Proc. NIPS. J. Reisinger and R. Mooney. 2011. Cross-cutting models of lexical semantics. In Proc. of EMNLP. S. Singh, D. Hillard, and C. Leggetter. 2010. Minimally-supervised extraction of entities from text advertisements. Proc. NAACL-HLT. A. Stolcke. 2002. An extensible language modeling toolkit. Proc. Interspeech. A. Subramanya, S. Petrov, and F. Pereira. 2010. Effi-  Y.-Y. Wang, R. Hoffman, X. Li, and J. Syzmanski. 2009. Semi-supervised learning of semantic classes for query understanding from the web and for the web. In The 18th ACM Conference on Information  and Knowledge Management. X. Zhu. 2005. Semi-supervised learning literature survey. Technical Report 1530, University of Wisconsin-Madison.  cient graph-based semi-supervised learning of structured tagging models. In Proc. EMNLP. G. Tur and R. DeMori. 2011. Spoken language understanding: Systems for extracting semantic information from speech. Wiley Press. 923</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
