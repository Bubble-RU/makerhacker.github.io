<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-95" href="../acl2013/acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">acl2013-95</a> <a title="acl-2013-95-reference" href="#">acl2013-95-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</h1>
<br/><p>Source: <a title="acl-2013-95-pdf" href="http://aclweb.org/anthology//P/P13/P13-3002.pdf">pdf</a></p><p>Author: Adrien Barbaresi</p><p>Abstract: We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus. Three platforms are taken into consideration: FriendFeed, identi.ca and Reddit, as they account for a relative diversity of user profiles and more importantly user languages. In order to explore them, we introduce a traversal algorithm based on user pages. As we target lesser-known languages, we try to focus on non-English posts by filtering out English text. Using mature open-source software from the NLP research field, a spell checker (as- pell) and a language identification system (langid .py), our case study and our benchmarks give an insight into the linguistic structure of the considered services.</p><br/>
<h2>reference text</h2><p>Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta. 2009. The WaCky Wide Web: A collection of very large linguistically processed web-crawled corpora. Language Resources and Evaluation, 43(3):209–226. Eda Baykan, Monika Henzinger, and Ingmar Weber. 2008. Web Page Language Identification Based on URLs. Proceedings of the VLDB Endowment, 1(1): 176–187. Fabio Celli. 2009. Improving Language identification performance with FriendFeed data. Technical report, CLIC, University of Trento. Minas Gjoka, Maciej Kurant, Carter T. Butts, and Athina Markopoulou. 2011. Practical recommendations on crawling online social networks. IEEE Journal on Selected Areas in Communications, 29(9): 1872–1892. Trinabh Gupta, Sanchit Garg, Niklas Carlsson, Anirban Mahanti, and Martin Arlitt. 2009. Characterization of FriendFeed A Web-based Social Aggregation Service. In Proceedings of the AAAI ICWSM, volume 9. –  Monika R. Henzinger, Allan Heydon, Michael Mitzenmacher, and Marc Najork. 2000. On near-uniform URL sampling. In Proceedings of the 9th International World Wide Web conference on Computer Networks: The International Journal of Computer and Telecommunications Networking, pages 295– 308. North-Holland Publishing Co. Marco Lui and Timothy Baldwin. 2011. Cross-domain Feature Selection for Language Identification. In Proceedings of the Fifth International Joint Conference on Natural Language Processing (IJCNLP 2011), pages 553–561, Chiang Mai, Thailand. Marco Lui and Timothy Baldwin. 2012. langid.py: An Off-the-shelf Language Identification Tool. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012), Jeju, Republic of Korea. Roland Sch a¨fer and Felix Bildhauer. 2012. Building large corpora from the web using a new efficient tool chain. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), pages 486–493. 15</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
