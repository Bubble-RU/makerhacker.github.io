<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>109 acl-2012-Higher-order Constituent Parsing and Parser Combination</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-109" href="#">acl2012-109</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>109 acl-2012-Higher-order Constituent Parsing and Parser Combination</h1>
<br/><p>Source: <a title="acl-2012-109-pdf" href="http://aclweb.org/anthology//P/P12/P12-2001.pdf">pdf</a></p><p>Author: Xiao Chen ; Chunyu Kit</p><p>Abstract: This paper presents a higher-order model for constituent parsing aimed at utilizing more local structural context to decide the score of a grammar rule instance in a parse tree. Experiments on English and Chinese treebanks confirm its advantage over its first-order version. It achieves its best F1 scores of 91.86% and 85.58% on the two languages, respectively, and further pushes them to 92.80% and 85.60% via combination with other highperformance parsers.</p><p>Reference: <a title="acl-2012-109-reference" href="../acl2012_reference/acl-2012-Higher-order_Constituent_Parsing_and_Parser_Combination_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pars', 0.362), ('constitu', 0.328), ('foss', 0.2), ('recombin', 0.188), ('np', 0.168), ('discrimin', 0.158), ('collin', 0.145), ('petrov', 0.142), ('gramm', 0.141), ('mcdonald', 0.13), ('rul', 0.125), ('sibl', 0.124), ('vp', 0.122), ('structural', 0.114), ('forest', 0.102), ('pag', 0.099), ('slav', 0.098), ('xg', 0.094), ('saga', 0.093), ('koo', 0.09)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="109-tfidf-1" href="./acl-2012-Higher-order_Constituent_Parsing_and_Parser_Combination.html">109 acl-2012-Higher-order Constituent Parsing and Parser Combination</a></p>
<p>Author: Xiao Chen ; Chunyu Kit</p><p>Abstract: This paper presents a higher-order model for constituent parsing aimed at utilizing more local structural context to decide the score of a grammar rule instance in a parse tree. Experiments on English and Chinese treebanks confirm its advantage over its first-order version. It achieves its best F1 scores of 91.86% and 85.58% on the two languages, respectively, and further pushes them to 92.80% and 85.60% via combination with other highperformance parsers.</p><p>2 0.31786934 <a title="109-tfidf-2" href="./acl-2012-A_Comparison_of_Chinese_Parsers_for_Stanford_Dependencies.html">5 acl-2012-A Comparison of Chinese Parsers for Stanford Dependencies</a></p>
<p>Author: Wanxiang Che ; Valentin Spitkovsky ; Ting Liu</p><p>Abstract: Stanford dependencies are widely used in natural language processing as a semanticallyoriented representation, commonly generated either by (i) converting the output of a constituent parser, or (ii) predicting dependencies directly. Previous comparisons of the two approaches for English suggest that starting from constituents yields higher accuracies. In this paper, we re-evaluate both methods for Chinese, using more accurate dependency parsers than in previous work. Our comparison of performance and efficiency across seven popular open source parsers (four constituent and three dependency) shows, by contrast, that recent higher-order graph-based techniques can be more accurate, though somewhat slower, than constituent parsers. We demonstrate also that n-way jackknifing is a useful technique for producing automatic (rather than gold) partof-speech tags to train Chinese dependency parsers. Finally, we analyze the relations produced by both kinds of parsing and suggest which specific parsers to use in practice.</p><p>3 0.25758681 <a title="109-tfidf-3" href="./acl-2012-Utilizing_Dependency_Language_Models_for_Graph-based_Dependency_Parsing_Models.html">213 acl-2012-Utilizing Dependency Language Models for Graph-based Dependency Parsing Models</a></p>
<p>Author: Wenliang Chen ; Min Zhang ; Haizhou Li</p><p>Abstract: Most previous graph-based parsing models increase decoding complexity when they use high-order features due to exact-inference decoding. In this paper, we present an approach to enriching high-orderfeature representations for graph-based dependency parsing models using a dependency language model and beam search. The dependency language model is built on a large-amount of additional autoparsed data that is processed by a baseline parser. Based on the dependency language model, we represent a set of features for the parsing model. Finally, the features are efficiently integrated into the parsing model during decoding using beam search. Our approach has two advantages. Firstly we utilize rich high-order features defined over a view of large scope and additional large raw corpus. Secondly our approach does not increase the decoding complexity. We evaluate the proposed approach on English and Chinese data. The experimental results show that our new parser achieves the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data.</p><p>4 0.25342473 <a title="109-tfidf-4" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>Author: Hui Zhang ; David Chiang</p><p>Abstract: Syntax-based translation models that operate on the output of a source-language parser have been shown to perform better if allowed to choose from a set of possible parses. In this paper, we investigate whether this is because it allows the translation stage to overcome parser errors or to override the syntactic structure itself. We find that it is primarily the latter, but that under the right conditions, the translation stage does correct parser errors, improving parsing accuracy on the Chinese Treebank.</p><p>5 0.24609858 <a title="109-tfidf-5" href="./acl-2012-Head-driven_Transition-based_Parsing_with_Top-down_Prediction.html">106 acl-2012-Head-driven Transition-based Parsing with Top-down Prediction</a></p>
<p>Author: Katsuhiko Hayashi ; Taro Watanabe ; Masayuki Asahara ; Yuji Matsumoto</p><p>Abstract: This paper presents a novel top-down headdriven parsing algorithm for data-driven projective dependency analysis. This algorithm handles global structures, such as clause and coordination, better than shift-reduce or other bottom-up algorithms. Experiments on the English Penn Treebank data and the Chinese CoNLL-06 data show that the proposed algorithm achieves comparable results with other data-driven dependency parsing algorithms.</p><p>6 0.20376502 <a title="109-tfidf-6" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>7 0.20173913 <a title="109-tfidf-7" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>8 0.19173826 <a title="109-tfidf-8" href="./acl-2012-Attacking_Parsing_Bottlenecks_with_Unlabeled_Data_and_Relevant_Factorizations.html">30 acl-2012-Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations</a></p>
<p>9 0.18765737 <a title="109-tfidf-9" href="./acl-2012-Dependency_Hashing_for_n-best_CCG_Parsing.html">71 acl-2012-Dependency Hashing for n-best CCG Parsing</a></p>
<p>10 0.18644464 <a title="109-tfidf-10" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>11 0.18472794 <a title="109-tfidf-11" href="./acl-2012-Hierarchical_Chunk-to-String_Translation.html">108 acl-2012-Hierarchical Chunk-to-String Translation</a></p>
<p>12 0.17234536 <a title="109-tfidf-12" href="./acl-2012-Robust_Conversion_of_CCG_Derivations_to_Phrase_Structure_Trees.html">170 acl-2012-Robust Conversion of CCG Derivations to Phrase Structure Trees</a></p>
<p>13 0.17124175 <a title="109-tfidf-13" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>14 0.16893579 <a title="109-tfidf-14" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>15 0.16470511 <a title="109-tfidf-15" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>16 0.1562252 <a title="109-tfidf-16" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>17 0.15493324 <a title="109-tfidf-17" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>18 0.14647479 <a title="109-tfidf-18" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>19 0.13604665 <a title="109-tfidf-19" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<p>20 0.12803386 <a title="109-tfidf-20" href="./acl-2012-Joint_Evaluation_of_Morphological_Segmentation_and_Syntactic_Parsing.html">122 acl-2012-Joint Evaluation of Morphological Segmentation and Syntactic Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.314), (1, -0.058), (2, -0.286), (3, -0.331), (4, -0.156), (5, -0.031), (6, -0.005), (7, -0.021), (8, -0.026), (9, -0.037), (10, 0.135), (11, -0.145), (12, -0.05), (13, -0.101), (14, -0.01), (15, 0.022), (16, 0.006), (17, -0.042), (18, 0.038), (19, 0.009), (20, 0.038), (21, 0.022), (22, -0.011), (23, 0.004), (24, -0.023), (25, -0.035), (26, 0.043), (27, 0.006), (28, 0.005), (29, 0.054), (30, -0.043), (31, 0.089), (32, -0.019), (33, -0.031), (34, -0.043), (35, 0.124), (36, 0.058), (37, 0.126), (38, -0.048), (39, -0.02), (40, -0.027), (41, 0.007), (42, 0.026), (43, 0.012), (44, -0.057), (45, -0.142), (46, 0.052), (47, 0.003), (48, -0.133), (49, -0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97684312 <a title="109-lsi-1" href="./acl-2012-Higher-order_Constituent_Parsing_and_Parser_Combination.html">109 acl-2012-Higher-order Constituent Parsing and Parser Combination</a></p>
<p>Author: Xiao Chen ; Chunyu Kit</p><p>Abstract: This paper presents a higher-order model for constituent parsing aimed at utilizing more local structural context to decide the score of a grammar rule instance in a parse tree. Experiments on English and Chinese treebanks confirm its advantage over its first-order version. It achieves its best F1 scores of 91.86% and 85.58% on the two languages, respectively, and further pushes them to 92.80% and 85.60% via combination with other highperformance parsers.</p><p>2 0.84371769 <a title="109-lsi-2" href="./acl-2012-A_Comparison_of_Chinese_Parsers_for_Stanford_Dependencies.html">5 acl-2012-A Comparison of Chinese Parsers for Stanford Dependencies</a></p>
<p>Author: Wanxiang Che ; Valentin Spitkovsky ; Ting Liu</p><p>Abstract: Stanford dependencies are widely used in natural language processing as a semanticallyoriented representation, commonly generated either by (i) converting the output of a constituent parser, or (ii) predicting dependencies directly. Previous comparisons of the two approaches for English suggest that starting from constituents yields higher accuracies. In this paper, we re-evaluate both methods for Chinese, using more accurate dependency parsers than in previous work. Our comparison of performance and efficiency across seven popular open source parsers (four constituent and three dependency) shows, by contrast, that recent higher-order graph-based techniques can be more accurate, though somewhat slower, than constituent parsers. We demonstrate also that n-way jackknifing is a useful technique for producing automatic (rather than gold) partof-speech tags to train Chinese dependency parsers. Finally, we analyze the relations produced by both kinds of parsing and suggest which specific parsers to use in practice.</p><p>3 0.82033098 <a title="109-lsi-3" href="./acl-2012-Utilizing_Dependency_Language_Models_for_Graph-based_Dependency_Parsing_Models.html">213 acl-2012-Utilizing Dependency Language Models for Graph-based Dependency Parsing Models</a></p>
<p>Author: Wenliang Chen ; Min Zhang ; Haizhou Li</p><p>Abstract: Most previous graph-based parsing models increase decoding complexity when they use high-order features due to exact-inference decoding. In this paper, we present an approach to enriching high-orderfeature representations for graph-based dependency parsing models using a dependency language model and beam search. The dependency language model is built on a large-amount of additional autoparsed data that is processed by a baseline parser. Based on the dependency language model, we represent a set of features for the parsing model. Finally, the features are efficiently integrated into the parsing model during decoding using beam search. Our approach has two advantages. Firstly we utilize rich high-order features defined over a view of large scope and additional large raw corpus. Secondly our approach does not increase the decoding complexity. We evaluate the proposed approach on English and Chinese data. The experimental results show that our new parser achieves the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data.</p><p>4 0.80990523 <a title="109-lsi-4" href="./acl-2012-Attacking_Parsing_Bottlenecks_with_Unlabeled_Data_and_Relevant_Factorizations.html">30 acl-2012-Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations</a></p>
<p>Author: Emily Pitler</p><p>Abstract: Prepositions and conjunctions are two of the largest remaining bottlenecks in parsing. Across various existing parsers, these two categories have the lowest accuracies, and mistakes made have consequences for downstream applications. Prepositions and conjunctions are often assumed to depend on lexical dependencies for correct resolution. As lexical statistics based on the training set only are sparse, unlabeled data can help ameliorate this sparsity problem. By including unlabeled data features into a factorization of the problem which matches the representation of prepositions and conjunctions, we achieve a new state-of-the-art for English dependencies with 93.55% correct attachments on the current standard. Furthermore, conjunctions are attached with an accuracy of 90.8%, and prepositions with an accuracy of 87.4%.</p><p>5 0.80245352 <a title="109-lsi-5" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>Author: Zhenghua Li ; Ting Liu ; Wanxiang Che</p><p>Abstract: We present a simple and effective framework for exploiting multiple monolingual treebanks with different annotation guidelines for parsing. Several types of transformation patterns (TP) are designed to capture the systematic annotation inconsistencies among different treebanks. Based on such TPs, we design quasisynchronous grammar features to augment the baseline parsing models. Our approach can significantly advance the state-of-the-art parsing accuracy on two widely used target treebanks (Penn Chinese Treebank 5. 1 and 6.0) using the Chinese Dependency Treebank as the source treebank. The improvements are respectively 1.37% and 1.10% with automatic part-of-speech tags. Moreover, an indirect comparison indicates that our approach also outperforms previous work based on treebank conversion.</p><p>6 0.79044062 <a title="109-lsi-6" href="./acl-2012-Head-driven_Transition-based_Parsing_with_Top-down_Prediction.html">106 acl-2012-Head-driven Transition-based Parsing with Top-down Prediction</a></p>
<p>7 0.76002967 <a title="109-lsi-7" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>8 0.72785044 <a title="109-lsi-8" href="./acl-2012-Dependency_Hashing_for_n-best_CCG_Parsing.html">71 acl-2012-Dependency Hashing for n-best CCG Parsing</a></p>
<p>9 0.71939349 <a title="109-lsi-9" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>10 0.71620291 <a title="109-lsi-10" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>11 0.68671215 <a title="109-lsi-11" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>12 0.67682117 <a title="109-lsi-12" href="./acl-2012-Joint_Evaluation_of_Morphological_Segmentation_and_Syntactic_Parsing.html">122 acl-2012-Joint Evaluation of Morphological Segmentation and Syntactic Parsing</a></p>
<p>13 0.66667092 <a title="109-lsi-13" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>14 0.66215283 <a title="109-lsi-14" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>15 0.6598134 <a title="109-lsi-15" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>16 0.65784782 <a title="109-lsi-16" href="./acl-2012-Discriminative_Strategies_to_Integrate_Multiword_Expression_Recognition_and_Parsing.html">75 acl-2012-Discriminative Strategies to Integrate Multiword Expression Recognition and Parsing</a></p>
<p>17 0.63132459 <a title="109-lsi-17" href="./acl-2012-Hierarchical_Chunk-to-String_Translation.html">108 acl-2012-Hierarchical Chunk-to-String Translation</a></p>
<p>18 0.61258829 <a title="109-lsi-18" href="./acl-2012-A_Comparative_Study_of_Target_Dependency_Structures_for_Statistical_Machine_Translation.html">4 acl-2012-A Comparative Study of Target Dependency Structures for Statistical Machine Translation</a></p>
<p>19 0.58736646 <a title="109-lsi-19" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<p>20 0.55900794 <a title="109-lsi-20" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.021), (8, 0.02), (22, 0.568), (31, 0.02), (38, 0.027), (47, 0.018), (58, 0.025), (61, 0.027), (77, 0.041), (91, 0.099), (92, 0.035), (96, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95341003 <a title="109-lda-1" href="./acl-2012-Higher-order_Constituent_Parsing_and_Parser_Combination.html">109 acl-2012-Higher-order Constituent Parsing and Parser Combination</a></p>
<p>Author: Xiao Chen ; Chunyu Kit</p><p>Abstract: This paper presents a higher-order model for constituent parsing aimed at utilizing more local structural context to decide the score of a grammar rule instance in a parse tree. Experiments on English and Chinese treebanks confirm its advantage over its first-order version. It achieves its best F1 scores of 91.86% and 85.58% on the two languages, respectively, and further pushes them to 92.80% and 85.60% via combination with other highperformance parsers.</p><p>2 0.91937703 <a title="109-lda-2" href="./acl-2012-Entailment-based_Text_Exploration_with_Application_to_the_Health-care_Domain.html">82 acl-2012-Entailment-based Text Exploration with Application to the Health-care Domain</a></p>
<p>Author: Meni Adler ; Jonathan Berant ; Ido Dagan</p><p>Abstract: We present a novel text exploration model, which extends the scope of state-of-the-art technologies by moving from standard concept-based exploration to statement-based exploration. The proposed scheme utilizes the textual entailment relation between statements as the basis of the exploration process. A user of our system can explore the result space of a query by drilling down/up from one statement to another, according to entailment relations specified by an entailment graph and an optional concept taxonomy. As a prominent use case, we apply our exploration system and illustrate its benefit on the health-care domain. To the best of our knowledge this is the first implementation of an exploration system at the statement level that is based on the textual entailment relation. 1</p><p>3 0.89780354 <a title="109-lda-3" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>Author: Malte Nuhn ; Arne Mauser ; Hermann Ney</p><p>Abstract: In this paper we show how to train statistical machine translation systems on reallife tasks using only non-parallel monolingual data from two languages. We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model. The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. We also report results using data from the monolingual French and English GIGAWORD corpora.</p><p>4 0.8977102 <a title="109-lda-4" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>Author: Rafal Rak ; BalaKrishna Kolluru ; Sophia Ananiadou</p><p>Abstract: Argo is a web-based NLP and text mining workbench with a convenient graphical user interface for designing and executing processing workflows of various complexity. The workbench is intended for specialists and nontechnical audiences alike, and provides the ever expanding library of analytics compliant with the Unstructured Information Management Architecture, a widely adopted interoperability framework. We explore the flexibility of this framework by demonstrating workflows involving three processing components capable of performing self-contained machine learning-based tagging. The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated features, and 3) tagging unlabelled data with the model. The learning and tagging components are based on an implementation of conditional random fields (CRF); whereas the feature generation component is an analytic capable of extending basic token information to a comprehensive set of features. Users define the features of their choice directly from Argo’s graphical interface, without resorting to programming (a commonly used approach to feature engineering). The experimental results performed on two tagging tasks, chunking and named entity recognition, showed that a tagger with a generic set of features built in Argo is capable of competing with taskspecific solutions. 121</p><p>5 0.76157433 <a title="109-lda-5" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance. In this paper, we propose a method to estimate sense distributions for short queries. Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations. Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system, we obtain significant improvements over a state-of-the-art IR system.</p><p>6 0.76022923 <a title="109-lda-6" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>7 0.6779142 <a title="109-lda-7" href="./acl-2012-IRIS%3A_a_Chat-oriented_Dialogue_System_based_on_the_Vector_Space_Model.html">114 acl-2012-IRIS: a Chat-oriented Dialogue System based on the Vector Space Model</a></p>
<p>8 0.67617494 <a title="109-lda-8" href="./acl-2012-Robust_Conversion_of_CCG_Derivations_to_Phrase_Structure_Trees.html">170 acl-2012-Robust Conversion of CCG Derivations to Phrase Structure Trees</a></p>
<p>9 0.66757053 <a title="109-lda-9" href="./acl-2012-BIUTEE%3A_A_Modular_Open-Source_System_for_Recognizing_Textual_Entailment.html">36 acl-2012-BIUTEE: A Modular Open-Source System for Recognizing Textual Entailment</a></p>
<p>10 0.66251498 <a title="109-lda-10" href="./acl-2012-Head-driven_Transition-based_Parsing_with_Top-down_Prediction.html">106 acl-2012-Head-driven Transition-based Parsing with Top-down Prediction</a></p>
<p>11 0.65319979 <a title="109-lda-11" href="./acl-2012-Efficient_Search_for_Transformation-based_Inference.html">78 acl-2012-Efficient Search for Transformation-based Inference</a></p>
<p>12 0.63561887 <a title="109-lda-12" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>13 0.62851238 <a title="109-lda-13" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>14 0.61143035 <a title="109-lda-14" href="./acl-2012-Iterative_Viterbi_A%2A_Algorithm_for_K-Best_Sequential_Decoding.html">121 acl-2012-Iterative Viterbi A* Algorithm for K-Best Sequential Decoding</a></p>
<p>15 0.60930514 <a title="109-lda-15" href="./acl-2012-Bootstrapping_via_Graph_Propagation.html">42 acl-2012-Bootstrapping via Graph Propagation</a></p>
<p>16 0.59667832 <a title="109-lda-16" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>17 0.59262824 <a title="109-lda-17" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>18 0.58736891 <a title="109-lda-18" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>19 0.58381134 <a title="109-lda-19" href="./acl-2012-Utilizing_Dependency_Language_Models_for_Graph-based_Dependency_Parsing_Models.html">213 acl-2012-Utilizing Dependency Language Models for Graph-based Dependency Parsing Models</a></p>
<p>20 0.58107013 <a title="109-lda-20" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
