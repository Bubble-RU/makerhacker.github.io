<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-67" href="#">acl2012-67</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</h1>
<br/><p>Source: <a title="acl-2012-67-pdf" href="http://aclweb.org/anthology//P/P12/P12-1017.pdf">pdf</a></p><p>Author: Malte Nuhn ; Arne Mauser ; Hermann Ney</p><p>Abstract: In this paper we show how to train statistical machine translation systems on reallife tasks using only non-parallel monolingual data from two languages. We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model. The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. We also report results using data from the monolingual French and English GIGAWORD corpora.</p><p>Reference: <a title="acl-2012-67-reference" href="../acl2012_reference/acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. [sent-2, score-0.216]
</p><p>2 The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. [sent-4, score-0.261]
</p><p>3 We also report results using data from the monolingual French and English GIGAWORD corpora. [sent-5, score-0.122]
</p><p>4 In this work, we attempt to learn statistical translation models from only monolingual data in the source and target language. [sent-8, score-0.465]
</p><p>5 This work is a big step towards large-scale and large-vocabulary unsupervised training of statistical translation models. [sent-10, score-0.272]
</p><p>6 de to scale unsupervised training to real-life translation tasks and how large-scale experiments can be done. [sent-17, score-0.227]
</p><p>7 Learning from only monolingual data in real-life translation tasks could improve especially low resource language pairs where few or no parallel texts are available. [sent-19, score-0.356]
</p><p>8 In addition to that, this approach offers the opportunity to decipher new or unknown languages and derive translations based solely on the available monolingual data. [sent-20, score-0.158]
</p><p>9 We have large amounts of data available in source and target language. [sent-22, score-0.164]
</p><p>10 Previous approaches to unsupervised training for SMT prove feasible only for vocabulary sizes up to around 500 words (Ravi and Knight, 2011) and data Proce dJienjgus, R ofep thueb 5lic0t hof A Knonruea ,l M 8-e1e4ti Jnugly o f2 t0h1e2 A. [sent-31, score-0.228]
</p><p>11 In this work, we will develop, describe, and evaluate methods for large vocabulary unsupervised learning of machine translation models suitable for real-world tasks. [sent-35, score-0.346]
</p><p>12 The main difference of our work is, that it allows for much larger vocabulary sizes and more data to be used than previous work while at the same time not being dependent on seed lexica and/or any other knowledge of the languages. [sent-43, score-0.321]
</p><p>13 Close to the methods described in this work, Ravi and Knight (201 1) treat training and translation without parallel data as a deciphering problem. [sent-44, score-0.319]
</p><p>14 Their best performing approach uses an EMAlgorithm to train a generative word based translation model. [sent-45, score-0.207]
</p><p>15 They perform experiments on a Spanish/English task with vocabulary sizes of about 500 words and achieve a performance of around 20 BLEU compared to 70 BLEU obtained by a sys-  tem that was trained on parallel data. [sent-46, score-0.275]
</p><p>16 However, we use a new training procedure whose critical parts have constant time and memory complexity with respect to the vocabulary size so that our methods can scale to much larger vocabulary sizes while also being faster. [sent-48, score-0.367]
</p><p>17 In a different approach, Koehn and Knight (2002) 157 induce a bilingual lexicon from only non-parallel data. [sent-49, score-0.245]
</p><p>18 To achieve this they use a seed lexicon which they systematically extend by using orthographic as well as distributional features such as context, and frequency. [sent-50, score-0.291]
</p><p>19 We use a greedy method similar to (Koehn and Knight, 2002) for extending a given lexicon, and we implicitly also use the frequency as a feature. [sent-52, score-0.123]
</p><p>20 However, we perform fully unsupervised training and do not start with a seed lexicon or use linguistic features. [sent-53, score-0.303]
</p><p>21 (2008) induce a oneto-one translation lexicon only from non-parallel  monolingual data. [sent-55, score-0.546]
</p><p>22 Also starting with a seed lexicon, they use a generative model based on canonical correlation analysis to systematically extend the lexicon using context as well as spelling features. [sent-56, score-0.356]
</p><p>23 As mentioned above, our work neither uses a seed lexicon nor orthographic features. [sent-59, score-0.291]
</p><p>24 3  Translation Model  In this section, we describe the statistical training criterion and the translation model that is trained using monolingual data. [sent-60, score-0.347]
</p><p>25 Throughout this work, we denote the source language words as f and target language words as e. [sent-62, score-0.164]
</p><p>26 The source vocabulary is Vf and we write the size of this vocabulary as |Vf |. [sent-63, score-0.306]
</p><p>27 The same notation holds foofr t thhies target vocabulary |w. [sent-64, score-0.245]
</p><p>28 This becomes increasingly difficult with more complex translation models. [sent-69, score-0.179]
</p><p>29 Therefore, we use a simplified translation model that still contains all basic phenomena of a generic translation process. [sent-70, score-0.358]
</p><p>30 We formulate the translation process with the same generative story presented in (Ravi and Knight, 2011): 1. [sent-71, score-0.207]
</p><p>31 Insert NULL tokens between any two adjacent positions of the target string with uniform probability. [sent-74, score-0.125]
</p><p>32 For each target token ei (including NULL) choose a foreign translation fi (including NULL) with probability Pθ(fi |ei). [sent-76, score-0.507]
</p><p>33 Locally reorder any two adjacent foreign words fi−1 , fi with probability P(SWAP) = 0. [sent-78, score-0.165]
</p><p>34 Instead we only allo|we translation models where for each source word f the number of words e0 with P(f|e0) 0 is below some fixed value. [sent-83, score-0.247]
</p><p>35 r W of candidates of the translation model and denote it with NC. [sent-85, score-0.347]
</p><p>36 Choosing the translation probabilities for the given set of active lexicon entries. [sent-92, score-0.422]
</p><p>37 The second task can be achieved by running the EM algorithm on the restricted translation model. [sent-93, score-0.245]
</p><p>38 4  Monolingual Context Similarity  As described in Section 3 we need some mechanism to iteratively choose an active set of translation candidates. [sent-95, score-0.223]
</p><p>39 Based on the assumption that some of the active candidates and their respective probabilities are already correct, we induce new active candidates. [sent-96, score-0.302]
</p><p>40 Given two vectors v1 and v2 of two documents it is then possible to calculate a similarity coefficient between those given documents (which is usually denoted as s(v1, v2)). [sent-99, score-0.157]
</p><p>41 Similar to this we represent source and target words in a high dimensional vector space of target word weights which we call context vectors and use a similarity coefficient to find possible translation pairs. [sent-100, score-0.741]
</p><p>42 We first initialize these context vectors using the following procedure: 1. [sent-101, score-0.236]
</p><p>43 Using only the monolingual data for the target language, prepare the context vectors vei with entries vei,ej :  (a) Initialize all vei,ej = 0 (b) For each target sentence E: For each word ei in E: For each word ej ei in E: vei,ej vei,ej 1 e. [sent-102, score-0.819]
</p><p>44 (c) For each source sentence F: For each word fi in F:  = Eθ(fi)1  EFoθr(F ea):ch word ej = +1 vfi  (d) Normalize  ,ej  vfi  in  ,ej  each vector  vfi  such that  Pej(vfi,ej)2=! [sent-124, score-0.479]
</p><p>45 1denoting that ej is not the translation of fi in Eθ (F) Adapting the notation described above, these vectors might for example look like  . [sent-126, score-0.476]
</p><p>46 ) Once we have set up the context vectors ve and vf, we can retrieve translation candidates for some source word f by finding those words e0 that maximize the similarity coefficient s(ve0 , vf), as well as candidates for a given target word e by finding those words f0 that maximize s(ve, vf0). [sent-136, score-1.087]
</p><p>47 In our implementation we use the Euclidean distance d(ve, vf) = | |ve  −  vf  | |2 . [sent-137, score-0.223]
</p><p>48 2 The normalization of context  vectors described above is motivated by the fact that the context vectors should be invariant with respect to the absolute number of occurrences of words. [sent-139, score-0.384]
</p><p>49 3 Instead of just finding the best candidates for a given word, we are interested in an assignment that involves all source and target words, minimizing the sum of distances between the assigned words. [sent-140, score-0.437]
</p><p>50 In case of a one-to-one mapping the problem of assigning translation candidates such that the sum of distances is minimal can be solved optimally in polynomial time using the hungarian algorithm (Kuhn, 1955). [sent-141, score-0.468]
</p><p>51 In our case we are dealing with a manyto-many assignment that needs to satisfy the maximum number of candidates constraints. [sent-142, score-0.252]
</p><p>52 As soon as a target word e or source word f has reached the limit of maximum candidates, we skip all further candidates for that word e (or f respectively). [sent-144, score-0.332]
</p><p>53 Still it is noteworthy that this procedure is not equivalent to the tf-IDF context vectors described in (Salton et al. [sent-152, score-0.224]
</p><p>54 159  y  work (e)Arbeit (f)time (e)Zeit (f)x Figure 1: Hypothetical example for a greedy one-to-one assignment of translation candidates. [sent-154, score-0.271]
</p><p>55 As described in Section 4, the overall procedure is divided into two alternating steps: After initialization we first perform EM training of the translation model for 20-30 iterations using a 2-gram or 3-gram language model in the target language. [sent-157, score-0.43]
</p><p>56 With the obtained best translations we induce new translation candidates using context similarity. [sent-158, score-0.542]
</p><p>57 1 Initialization Let NC be the maximum number of candidates per source word we allow, Ve and Vf be the target/source vocabulary and r(e) and r(f) the frequency rank of a source/target word. [sent-161, score-0.471]
</p><p>58 (5)  beam4  This defines a diagonal when visualizing the lexicon entries in a matrix where both source and target words are sorted by their frequency rank. [sent-168, score-0.528]
</p><p>59 However, note that the result of sorting by frequency 4The diagonal has some artifacts for the highest and lowest frequency ranks. [sent-169, score-0.179]
</p><p>60 The big rectangles represent word lexica in different stages of the training procedure. [sent-173, score-0.133]
</p><p>61 The small rectangles represent word pairs (e, f) for which e is a translation candidate of f,while dots represent word pairs (e, f) for which this is not the case. [sent-174, score-0.218]
</p><p>62 Source and target words are sorted by frequency so that Figure  the most frequent source words appear on the very left, and the most frequent target words appear at the very bottom. [sent-175, score-0.344]
</p><p>63 We use the forward-backward algorithm on the composed transducers to efficiently train the lexicon model using the EM algorithm. [sent-186, score-0.23]
</p><p>64 3 Context Vector Step Given the trained parameters θ from the previous run of the EM algorithm we set the context vectors ve  160 and vf up as described in Section 4. [sent-188, score-0.638]
</p><p>65 We then calculate and sort all |Ve | · |Vf | distances which proves fealsaitbelea nind a fretwal lC|VPU| |hVou|rsd even feosrw vocabulary ssifezeasof more than 50,000 words. [sent-189, score-0.208]
</p><p>66 To set up the new lexicon we keep the beTsto otr saentsl uatpion thse f nore weac lhex source ewo krdee pwi tthhe respect to P(e|f), which we obtained in the previous EM run. [sent-191, score-0.307]
</p><p>67 Experiments wsheo wobetda tnheadt i nt i tsh helpful utos a ElsMo limit the number of candidates per target words. [sent-192, score-0.305]
</p><p>68 We therefore prune the resulting lexicon using P(f|e)  bN2Cc  bN20Cc  to a maximum of candidates per target word taoft aer mwaarxdims. [sent-193, score-0.504]
</p><p>69 Tmhe onf we ficll cthaned liedxaitceosn p ewrit tha new candidates using the previously sorted list of candidate pairs such that the final lexicon has at most NC candidates per source word and at most NC0 candidates per target word. [sent-194, score-0.986]
</p><p>70 Not limiting ≈the N number of candidates per target word at all also typically results in  weaker performance. [sent-198, score-0.333]
</p><p>71 After the lexicon is filled with candidates, we initialize the probabilities to be uniform. [sent-199, score-0.243]
</p><p>72 With this new lexicon the process is iterated starting with the EM training. [sent-200, score-0.199]
</p><p>73 After that we apply our method to a non-parallel version of the German/English VERBMOBIL corpus, which has a vocabulary size of 6,000 words on the German side, and 3,500 words on the target side and which thereby is approximately one order of magnitude larger than the previous OPUS experiment. [sent-209, score-0.327]
</p><p>74 We finally run our system on a subset of the nonparallel French/English GIGAWORD corpus, which has a vocabulary size of 60,000 words for both French and English. [sent-210, score-0.222]
</p><p>75 In case of the GIGAWORD corpus we show lexicon entries obtained during training. [sent-218, score-0.291]
</p><p>76 In comparison to this baseline we run our algorithm with NC = 50 candidates per source word for both, a 2-gram and a 3-gram LM. [sent-228, score-0.322]
</p><p>77 We use 30 EM iterations 161 between each context vector step. [sent-229, score-0.178]
</p><p>78 In case of the 2-gram LM (Figure 3) the translation quality increases until it reaches a plateau after 5 EM+Context cycles. [sent-234, score-0.179]
</p><p>79 Figure 3: Results on the OPUS corpus with a 2-gram LM, NC = 50, and 30 EM iterations between each context  vector step. [sent-238, score-0.178]
</p><p>80 Our 3-gram based method is 15-20 times faster than running the EM based training procedure presented in (Ravi and Knight, 2011) with a 3-gram LM5. [sent-244, score-0.134]
</p><p>81 a  2-gram  Figure 4: Results on the OPUS corpus with a 3-gram LM, NC = 50, and 30 EM iterations between each context vector step. [sent-246, score-0.178]
</p><p>82 We prepared a non-parallel subset of the original VERBMOBIL (Wahlster, 2000) by splitting the corpus into two parts and then selecting only the German side from the first half, and the English side from the second half such that the target side is not the translation of the source side. [sent-274, score-0.463]
</p><p>83 The source and target vocabularies of the resulting non-parallel corpus are both more than 9 times bigger compared to the OPUS vocabularies. [sent-275, score-0.215]
</p><p>84 We run our method for 5 EM+Context cycles (30 EM iterations each) using a 2-gram LM. [sent-278, score-0.189]
</p><p>85 translation quality increases from iteration to iteration until the algorithm finally reaches 11. [sent-292, score-0.179]
</p><p>86 2 BLEU for a single-word based translation system and 56. [sent-297, score-0.179]
</p><p>87 05  retour  les deux appelle dire janvier Suisse  −  Table 4: Lexicon entries obtained by running our method on the non-parallel GIGAWORD corpus. [sent-336, score-0.194]
</p><p>88 The first column shows in which iteration the algorithm found the first correct translations f (compared to a parallely trained lexicon)  among the top 5 candidates  6. [sent-337, score-0.204]
</p><p>89 1  Experimental Setup  This setup is based on a subset of the monolingual GIGAWORD  corpus. [sent-340, score-0.122]
</p><p>90 After initialization, we run our method with NC = 150 candidates per source word for 20 EM iterations using a 2-gram LM. [sent-347, score-0.419]
</p><p>91 After the first context vector step with NC = 50 we run another 4 20 iterations with NC = 5=0 5w0it hw a 2-gram LthMer. [sent-348, score-0.223]
</p><p>92 2 Results Table 4 shows example lexicon entries we obtained. [sent-351, score-0.251]
</p><p>93 Note that we obtained these results by using purely non-parallel data, and that we neither used a seed lexicon, nor orthographic features to assign e. [sent-352, score-0.132]
</p><p>94 163 7  Conclusion  We presented a method for learning statistical machine translation models from non-parallel data. [sent-356, score-0.215]
</p><p>95 The key to our method lies in limiting the translation  model to a limited set of translation candidates and then using the EM algorithm to learn the probabilities. [sent-357, score-0.59]
</p><p>96 Based on the translations obtained with this model we obtain new translation candidates using a context vector approach. [sent-358, score-0.54]
</p><p>97 Due to this efficiency improvement we were able to tackle larger tasks, such as a nonparallel version of the VERBMOBIL corpus having a nearly 10 times larger vocabulary. [sent-361, score-0.13]
</p><p>98 We also had a look at first results of our method on an even larger Task, incorporating a vocabulary of 60,000 words. [sent-362, score-0.191]
</p><p>99 We have shown that, using a limited set of translation candidates, we can significantly reduce the computational complexity of the learning task. [sent-363, score-0.179]
</p><p>100 This work serves as a big step towards large-scale unsupervised training for statistical machine translation systems. [sent-364, score-0.272]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ravi', 0.359), ('verbmobil', 0.293), ('opus', 0.254), ('knight', 0.225), ('vf', 0.223), ('lexicon', 0.199), ('em', 0.199), ('translation', 0.179), ('ve', 0.178), ('lm', 0.174), ('candidates', 0.168), ('nc', 0.143), ('monolingual', 0.122), ('vectors', 0.119), ('vocabulary', 0.119), ('bleu', 0.117), ('target', 0.096), ('fi', 0.095), ('gigaword', 0.093), ('deciphering', 0.085), ('vfi', 0.073), ('wahlster', 0.073), ('context', 0.073), ('allauzen', 0.073), ('foreign', 0.07), ('source', 0.068), ('ei', 0.067), ('running', 0.066), ('ter', 0.063), ('late', 0.062), ('initialization', 0.062), ('sizes', 0.061), ('iterations', 0.061), ('nonparallel', 0.058), ('null', 0.058), ('sorting', 0.056), ('seed', 0.056), ('parallel', 0.055), ('openfst', 0.054), ('sujith', 0.054), ('ej', 0.053), ('distances', 0.053), ('entries', 0.052), ('assignment', 0.052), ('aachen', 0.051), ('vocabularies', 0.051), ('kevin', 0.051), ('salton', 0.049), ('arbeit', 0.049), ('lexica', 0.049), ('pej', 0.049), ('subtitle', 0.049), ('zeit', 0.049), ('french', 0.048), ('unsupervised', 0.048), ('frequency', 0.047), ('cycles', 0.047), ('criterion', 0.046), ('induce', 0.046), ('big', 0.045), ('run', 0.045), ('initialize', 0.044), ('active', 0.044), ('vector', 0.044), ('vei', 0.043), ('per', 0.041), ('side', 0.04), ('obtained', 0.04), ('greedy', 0.04), ('rectangles', 0.039), ('germany', 0.038), ('coefficient', 0.038), ('sorted', 0.037), ('agency', 0.036), ('proves', 0.036), ('larger', 0.036), ('method', 0.036), ('translations', 0.036), ('orthographic', 0.036), ('mehryar', 0.034), ('hungarian', 0.034), ('optimally', 0.034), ('dempster', 0.033), ('dashed', 0.033), ('rwth', 0.033), ('procedure', 0.032), ('dealing', 0.032), ('prepare', 0.031), ('encouraging', 0.031), ('transducers', 0.031), ('notation', 0.03), ('snyder', 0.03), ('early', 0.03), ('diagonal', 0.029), ('snover', 0.029), ('tokens', 0.029), ('rank', 0.028), ('generative', 0.028), ('limiting', 0.028), ('dimensional', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="67-tfidf-1" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>Author: Malte Nuhn ; Arne Mauser ; Hermann Ney</p><p>Abstract: In this paper we show how to train statistical machine translation systems on reallife tasks using only non-parallel monolingual data from two languages. We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model. The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. We also report results using data from the monolingual French and English GIGAWORD corpora.</p><p>2 0.22437969 <a title="67-tfidf-2" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>Author: Joern Wuebker ; Hermann Ney ; Richard Zens</p><p>Abstract: In this work we present two extensions to the well-known dynamic programming beam search in phrase-based statistical machine translation (SMT), aiming at increased efficiency of decoding by minimizing the number of language model computations and hypothesis expansions. Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2. Two look-ahead methods are shown to further increase translation speed by a factor of2 without changing the search space and a factor of 4 with the side-effect of some additional search errors. We compare our ap- proach with Moses and observe the same performance, but a substantially better trade-off between translation quality and speed. At a speed of roughly 70 words per second, Moses reaches 17.2% BLEU, whereas our approach yields 20.0% with identical models.</p><p>3 0.22007117 <a title="67-tfidf-3" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>Author: Xiaodong He ; Li Deng</p><p>Abstract: This paper proposes a new discriminative training method in constructing phrase and lexicon translation models. In order to reliably learn a myriad of parameters in these models, we propose an expected BLEU score-based utility function with KL regularization as the objective, and train the models on a large parallel dataset. For training, we derive growth transformations for phrase and lexicon translation probabilities to iteratively improve the objective. The proposed method, evaluated on the Europarl German-to-English dataset, leads to a 1.1 BLEU point improvement over a state-of-the-art baseline translation system. In IWSLT 201 1 Benchmark, our system using the proposed method achieves the best Chinese-to-English translation result on the task of translating TED talks.</p><p>4 0.14230041 <a title="67-tfidf-4" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>Author: Jinsong Su ; Hua Wu ; Haifeng Wang ; Yidong Chen ; Xiaodong Shi ; Huailin Dong ; Qun Liu</p><p>Abstract: To adapt a translation model trained from the data in one domain to another, previous works paid more attention to the studies of parallel corpus while ignoring the in-domain monolingual corpora which can be obtained more easily. In this paper, we propose a novel approach for translation model adaptation by utilizing in-domain monolingual topic information instead of the in-domain bilingual corpora, which incorporates the topic information into translation probability estimation. Our method establishes the relationship between the out-of-domain bilingual corpus and the in-domain monolingual corpora via topic mapping and phrase-topic distribution probability estimation from in-domain monolingual corpora. Experimental result on the NIST Chinese-English translation task shows that our approach significantly outperforms the baseline system.</p><p>5 0.13851537 <a title="67-tfidf-5" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>Author: Graham Neubig ; Taro Watanabe ; Shinsuke Mori ; Tatsuya Kawahara</p><p>Abstract: In this paper, we demonstrate that accurate machine translation is possible without the concept of “words,” treating MT as a problem of transformation between character strings. We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to train a character-based translation model, and using this in the phrase-based MT framework. We also propose a look-ahead parsing algorithm and substring-informed prior probabilities to achieve more effective and efficient alignment. In an evaluation, we demonstrate that character-based translation can achieve results that compare to word-based systems while effectively translating unknown and uncommon words over several language pairs.</p><p>6 0.11892465 <a title="67-tfidf-6" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>7 0.11866894 <a title="67-tfidf-7" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>8 0.11721986 <a title="67-tfidf-8" href="./acl-2012-Smaller_Alignment_Models_for_Better_Translations%3A_Unsupervised_Word_Alignment_with_the_l0-norm.html">179 acl-2012-Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the l0-norm</a></p>
<p>9 0.11637317 <a title="67-tfidf-9" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>10 0.1150079 <a title="67-tfidf-10" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>11 0.11359232 <a title="67-tfidf-11" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>12 0.11152286 <a title="67-tfidf-12" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>13 0.11027118 <a title="67-tfidf-13" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>14 0.10877011 <a title="67-tfidf-14" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>15 0.1084886 <a title="67-tfidf-15" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>16 0.10821981 <a title="67-tfidf-16" href="./acl-2012-Modeling_the_Translation_of_Predicate-Argument_Structure_for_SMT.html">147 acl-2012-Modeling the Translation of Predicate-Argument Structure for SMT</a></p>
<p>17 0.10801949 <a title="67-tfidf-17" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>18 0.10329982 <a title="67-tfidf-18" href="./acl-2012-Improving_the_IBM_Alignment_Models_Using_Variational_Bayes.html">118 acl-2012-Improving the IBM Alignment Models Using Variational Bayes</a></p>
<p>19 0.095680073 <a title="67-tfidf-19" href="./acl-2012-Translation_Model_Size_Reduction_for_Hierarchical_Phrase-based_Statistical_Machine_Translation.html">204 acl-2012-Translation Model Size Reduction for Hierarchical Phrase-based Statistical Machine Translation</a></p>
<p>20 0.095439404 <a title="67-tfidf-20" href="./acl-2012-A_Topic_Similarity_Model_for_Hierarchical_Phrase-based_Translation.html">22 acl-2012-A Topic Similarity Model for Hierarchical Phrase-based Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.273), (1, -0.172), (2, 0.12), (3, 0.059), (4, 0.071), (5, -0.003), (6, 0.006), (7, 0.002), (8, -0.018), (9, -0.042), (10, 0.0), (11, -0.035), (12, -0.062), (13, 0.016), (14, -0.035), (15, -0.03), (16, 0.021), (17, 0.104), (18, 0.055), (19, 0.048), (20, -0.007), (21, -0.138), (22, 0.056), (23, 0.011), (24, 0.057), (25, -0.012), (26, 0.133), (27, 0.032), (28, -0.063), (29, 0.083), (30, 0.029), (31, -0.081), (32, -0.052), (33, 0.08), (34, 0.089), (35, -0.053), (36, 0.021), (37, 0.02), (38, -0.019), (39, 0.077), (40, 0.037), (41, -0.116), (42, -0.094), (43, 0.1), (44, 0.013), (45, 0.035), (46, 0.118), (47, 0.064), (48, 0.01), (49, -0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93644035 <a title="67-lsi-1" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>Author: Malte Nuhn ; Arne Mauser ; Hermann Ney</p><p>Abstract: In this paper we show how to train statistical machine translation systems on reallife tasks using only non-parallel monolingual data from two languages. We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model. The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. We also report results using data from the monolingual French and English GIGAWORD corpora.</p><p>2 0.83305192 <a title="67-lsi-2" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>Author: Joern Wuebker ; Hermann Ney ; Richard Zens</p><p>Abstract: In this work we present two extensions to the well-known dynamic programming beam search in phrase-based statistical machine translation (SMT), aiming at increased efficiency of decoding by minimizing the number of language model computations and hypothesis expansions. Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2. Two look-ahead methods are shown to further increase translation speed by a factor of2 without changing the search space and a factor of 4 with the side-effect of some additional search errors. We compare our ap- proach with Moses and observe the same performance, but a substantially better trade-off between translation quality and speed. At a speed of roughly 70 words per second, Moses reaches 17.2% BLEU, whereas our approach yields 20.0% with identical models.</p><p>3 0.74433762 <a title="67-lsi-3" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>Author: Xiaodong He ; Li Deng</p><p>Abstract: This paper proposes a new discriminative training method in constructing phrase and lexicon translation models. In order to reliably learn a myriad of parameters in these models, we propose an expected BLEU score-based utility function with KL regularization as the objective, and train the models on a large parallel dataset. For training, we derive growth transformations for phrase and lexicon translation probabilities to iteratively improve the objective. The proposed method, evaluated on the Europarl German-to-English dataset, leads to a 1.1 BLEU point improvement over a state-of-the-art baseline translation system. In IWSLT 201 1 Benchmark, our system using the proposed method achieves the best Chinese-to-English translation result on the task of translating TED talks.</p><p>4 0.65104109 <a title="67-lsi-4" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>Author: Sander Wubben ; Antal van den Bosch ; Emiel Krahmer</p><p>Abstract: In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar sim- a. plification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems.</p><p>5 0.62080121 <a title="67-lsi-5" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>Author: Shujie Liu ; Chi-Ho Li ; Mu Li ; Ming Zhou</p><p>Abstract: In this paper, we address the issue for learning better translation consensus in machine translation (MT) research, and explore the search of translation consensus from similar, rather than the same, source sentences or their spans. Unlike previous work on this topic, we formulate the problem as structured labeling over a much smaller graph, and we propose a novel structured label propagation for the task. We convert such graph-based translation consensus from similar source strings into useful features both for n-best output reranking and for decoding algorithm. Experimental results show that, our method can significantly improve machine translation performance on both IWSLT and NIST data, compared with a state-ofthe-art baseline. 1</p><p>6 0.61131704 <a title="67-lsi-6" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>7 0.59529662 <a title="67-lsi-7" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>8 0.58358848 <a title="67-lsi-8" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>9 0.57700044 <a title="67-lsi-9" href="./acl-2012-Improving_the_IBM_Alignment_Models_Using_Variational_Bayes.html">118 acl-2012-Improving the IBM Alignment Models Using Variational Bayes</a></p>
<p>10 0.57130319 <a title="67-lsi-10" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>11 0.55982631 <a title="67-lsi-11" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>12 0.55337995 <a title="67-lsi-12" href="./acl-2012-PORT%3A_a_Precision-Order-Recall_MT_Evaluation_Metric_for_Tuning.html">158 acl-2012-PORT: a Precision-Order-Recall MT Evaluation Metric for Tuning</a></p>
<p>13 0.55290055 <a title="67-lsi-13" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>14 0.54818445 <a title="67-lsi-14" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>15 0.54715931 <a title="67-lsi-15" href="./acl-2012-Decoding_Running_Key_Ciphers.html">68 acl-2012-Decoding Running Key Ciphers</a></p>
<p>16 0.5428583 <a title="67-lsi-16" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>17 0.53916121 <a title="67-lsi-17" href="./acl-2012-Smaller_Alignment_Models_for_Better_Translations%3A_Unsupervised_Word_Alignment_with_the_l0-norm.html">179 acl-2012-Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the l0-norm</a></p>
<p>18 0.53386688 <a title="67-lsi-18" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>19 0.52680391 <a title="67-lsi-19" href="./acl-2012-Prediction_of_Learning_Curves_in_Machine_Translation.html">163 acl-2012-Prediction of Learning Curves in Machine Translation</a></p>
<p>20 0.52442986 <a title="67-lsi-20" href="./acl-2012-Learning_to_Translate_with_Multiple_Objectives.html">136 acl-2012-Learning to Translate with Multiple Objectives</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.018), (26, 0.038), (28, 0.064), (30, 0.02), (37, 0.049), (39, 0.047), (59, 0.313), (74, 0.063), (82, 0.016), (84, 0.022), (85, 0.036), (90, 0.139), (92, 0.043), (94, 0.034), (99, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95951372 <a title="67-lda-1" href="./acl-2012-Deep_Learning_for_NLP_%28without_Magic%29.html">69 acl-2012-Deep Learning for NLP (without Magic)</a></p>
<p>Author: Richard Socher ; Yoshua Bengio ; Christopher D. Manning</p><p>Abstract: unkown-abstract</p><p>2 0.92825717 <a title="67-lda-2" href="./acl-2012-Corpus-based_Interpretation_of_Instructions_in_Virtual_Environments.html">59 acl-2012-Corpus-based Interpretation of Instructions in Virtual Environments</a></p>
<p>Author: Luciana Benotti ; Martin Villalba ; Tessa Lau ; Julian Cerruti</p><p>Abstract: Previous approaches to instruction interpretation have required either extensive domain adaptation or manually annotated corpora. This paper presents a novel approach to instruction interpretation that leverages a large amount of unannotated, easy-to-collect data from humans interacting with a virtual world. We compare several algorithms for automatically segmenting and discretizing this data into (utterance, reaction) pairs and training a classifier to predict reactions given the next utterance. Our empirical analysis shows that the best algorithm achieves 70% accuracy on this task, with no manual annotation required. 1 Introduction and motivation Mapping instructions into automatically executable actions would enable the creation of natural lan- , guage interfaces to many applications (Lau et al., 2009; Branavan et al., 2009; Orkin and Roy, 2009). In this paper, we focus on the task of navigation and manipulation of a virtual environment (Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Current symbolic approaches to the problem are brittle to the natural language variation present in instructions and require intensive rule authoring to be fit for a new task (Dzikovska et al., 2008). Current statistical approaches require extensive manual annotations of the corpora used for training (MacMahon et al., 2006; Matuszek et al., 2010; Gorniak and Roy, 2007; Rieser and Lemon, 2010). Manual annotation and rule authoring by natural language engineering experts are bottlenecks for developing conversational systems for new domains. 181 t e s s al au @ us . ibm . com, j ce rrut i ar .ibm . com @ This paper proposes a fully automated approach to interpreting natural language instructions to complete a task in a virtual world based on unsupervised recordings of human-human interactions perform- ing that task in that virtual world. Given unannotated corpora collected from humans following other humans’ instructions, our system automatically segments the corpus into labeled training data for a classification algorithm. Our interpretation algorithm is based on the observation that similar instructions uttered in similar contexts should lead to similar actions being taken in the virtual world. Given a previously unseen instruction, our system outputs actions that can be directly executed in the virtual world, based on what humans did when given similar instructions in the past. 2 Corpora situated in virtual worlds Our environment consists of six virtual worlds designed for the natural language generation shared task known as the GIVE Challenge (Koller et al., 2010), where a pair of partners must collaborate to solve a task in a 3D space (Figure 1). The “instruction follower” (IF) can move around in the virtual world, but has no knowledge of the task. The “instruction giver” (IG) types instructions to the IF in order to guide him to accomplish the task. Each corpus contains the IF’s actions and position recorded every 200 milliseconds, as well as the IG’s instruc- tions with their timestamps. We used two corpora for our experiments. The Cm corpus (Gargett et al., 2010) contains instructions given by multiple people, consisting of 37 games spanning 2163 instructions over 8: 17 hs. The Proce dJienjgus, R ofep thueb 5lic0t hof A Knonruea ,l M 8-e1e4ti Jnugly o f2 t0h1e2 A.s ?c so2c0ia1t2io Ans fso rc Ciatoiomnp fuotart Cio nmaplu Ltiantgiounisatlic Lsi,n pgaugiestsi1c 8s1–186, Figure 1: A screenshot of a virtual world. The world consists of interconnecting hallways, rooms and objects Cs corpus (Benotti and Denis, 2011), gathered using a single IG, is composed of 63 games and 3417 in- structions, and was recorded in a span of 6:09 hs. It took less than 15 hours to collect the corpora through the web and the subjects reported that the experiment was fun. While the environment is restricted, people describe the same route and the same objects in extremely different ways. Below are some examples of instructions from our corpus all given for the same route shown in Figure 1. 1) out 2) walk down the passage 3) nowgo [sic] to the pink room 4) back to the room with the plant 5) Go through the door on the left 6) go through opening with yellow wall paper People describe routes using landmarks (4) or specific actions (2). They may describe the same object differently (5 vs 6). Instructions also differ in their scope (3 vs 1). Thus, even ignoring spelling and grammatical errors, navigation instructions contain considerable variation which makes interpreting them a challenging problem. 3 Learning from previous interpretations Our algorithm consists of two phases: annotation and interpretation. Annotation is performed only once and consists of automatically associating each IG instruction to an IF reaction. Interpretation is performed every time the system receives an instruc182 tion and consists of predicting an appropriate reaction given reactions observed in the corpus. Our method is based on the assumption that a reaction captures the semantics of the instruction that caused it. Therefore, if two utterances result in the same reaction, they are paraphrases of each other, and similar utterances should generate the same reaction. This approach enables us to predict reactions for previously-unseen instructions. 3.1 Annotation phase The key challenge in learning from massive amounts of easily-collected data is to automatically annotate an unannotated corpus. Our annotation method consists of two parts: first, segmenting a low-level interaction trace into utterances and corresponding reactions, and second, discretizing those reactions into canonical action sequences. Segmentation enables our algorithm to learn from traces of IFs interacting directly with a virtual world. Since the IF can move freely in the virtual world, his actions are a stream of continuous behavior. Segmentation divides these traces into reactions that follow from each utterance of the IG. Consider the following example starting at the situation shown in Figure 1: IG(1): go through the yellow opening IF(2): [walks out of the room] IF(3): [turns left at the intersection] IF(4): [enters the room with the sofa] IG(5): stop It is not clear whether the IF is doing h3, 4i because h neo tis c reacting htoe r1 t or Fbec isadu soei hge h 3is, being proactive. While one could manually annotate this data to remove extraneous actions, our goal is to develop automated solutions that enable learning from massive amounts of data. We decided to approach this problem by experimenting with two alternative formal definitions: 1) a strict definition that considers the maximum reaction according to the IF behavior, and 2) a loose defini- tion based on the empirical observation that, in situated interaction, most instructions are constrained by the current visually perceived affordances (Gibson, 1979; Stoia et al., 2006). We formally define behavior segmentation (Bhv) as follows. A reaction rk to an instruction uk begins right after the instruction uk is uttered and ends right before the next instruction uk+1 is uttered. In the example, instruction 1corresponds to h2, 3, 4i . We formally d inefsitnrue visibility segmentation (Vis) as f Wolelows. A reaction rk to an instruction uk begins right after the instruction uk is uttered and ends right before the next instruction uk+1 is uttered or right after the IF leaves the area visible at 360◦ from where uk was uttered. In the example, instruction 1’s reaction would be limited to h2i because the intersection is nwootu vldisi bbele l ifmroimte dw htoer he2 tihe b eicnasutrsuec ttihoen was suetctetiroend. The Bhv and Vis methods define how to segment an interaction trace into utterances and their corresponding reactions. However, users frequently perform noisy behavior that is irrelevant to the goal of the task. For example, after hearing an instruction, an IF might go into the wrong room, realize the error, and leave the room. A reaction should not in- clude such irrelevant actions. In addition, IFs may accomplish the same goal using different behaviors: two different IFs may interpret “go to the pink room” by following different paths to the same destination. We would like to be able to generalize both reactions into one canonical reaction. As a result, our approach discretizes reactions into higher-level action sequences with less noise and less variation. Our discretization algorithm uses an automated planner and a planning representation of the task. This planning representation includes: (1) the task goal, (2) the actions which can be taken in the virtual world, and (3) the current state of the virtual world. Using the planning representation, the planner calculates an optimal path between the starting and ending states of the reaction, eliminating all unnecessary actions. While we use the classical planner FF (Hoffmann, 2003), our technique could also work with classical planning (Nau et al., 2004) or other techniques such as probabilistic planning (Bonet and Geffner, 2005). It is also not dependent on a particular discretization of the world in terms of actions. Now we are ready to define canonical reaction ck formally. Let Sk be the state of the virtual world when instruction uk was uttered, Sk+1 be the state of the world where the reaction ends (as defined by Bhv or Vis segmentation), and D be the planning domain representation of the virtual world. The canonical reaction to uk is defined as the sequence of actions 183 returned by the planner with Sk as initial state, Sk+1 as goal state and D as planning domain. 3.2 Interpretation phase The annotation phase results in a collection of (uk, ck) pairs. The interpretation phase uses these pairs to interpret new utterances in three steps. First, we filter the set of pairs into those whose reactions can be directly executed from the current IF position. Second, we group the filtered pairs according to their reactions. Third, we select the group with utterances most similar to the new utterance, and output that group’s reaction. Figure 2 shows the output of the first two steps: three groups of pairs whose reactions can all be executed from the IF’s current position. Figure 2: Utterance groups for this situation. Colored arrows show the reaction associated with each group. We treat the third step, selecting the most similar group for a new utterance, as a classification problem. We compare three different classification methods. One method uses nearest-neighbor classification with three different similarity metrics: Jaccard and Overlap coefficients (both of which measure the degree of overlap between two sets, differing only in the normalization of the final value (Nikravesh et al., 2005)), and Levenshtein Distance (a string met- ric for measuring the amount of differences between two sequences of words (Levenshtein, 1966)). Our second classification method employs a strategy in which we considered each group as a set of possible machine translations of our utterance, using the BLEU measure (Papineni et al., 2002) to select which group could be considered the best translation of our utterance. Finally, we trained an SVM classifier (Cortes and Vapnik, 1995) using the unigrams Corpus Cm Corpus Cs Algorithm Bhv Vis Bhv Vis Jaccard47%54%54%70% Overlap BLEU SVM Levenshtein 43% 44% 33% 21% 53% 52% 29% 20% 45% 54% 45% 8% 60% 50% 29% 17% Table 1: Accuracy comparison between Cm and Cs for Bhv and Vis segmentation of each paraphrase and the position of the IF as features, and setting their group as the output class using a libSVM wrapper (Chang and Lin, 2011). When the system misinterprets an instruction we use a similar approach to what people do in order to overcome misunderstandings. If the system executes an incorrect reaction, the IG can tell the system to cancel its current interpretation and try again using a paraphrase, selecting a different reaction. 4 Evaluation For the evaluation phase, we annotated both the Cm and Cs corpora entirely, and then we split them in an 80/20 proportion; the first 80% of data collected in each virtual world was used for training, while the remaining 20% was used for testing. For each pair (uk, ck) in the testing set, we used our algorithm to predict the reaction to the selected utterance, and then compared this result against the automatically annotated reaction. Table 1 shows the results. Comparing the Bhv and Vis segmentation strategies, Vis tends to obtain better results than Bhv. In addition, accuracy on the Cs corpus was generally higher than Cm. Given that Cs contained only one IG, we believe this led to less variability in the instructions and less noise in the training data. We evaluated the impact of user corrections by simulating them using the existing corpus. In case of a wrong response, the algorithm receives a second utterance with the same reaction (a paraphrase of the previous one). Then the new utterance is tested over the same set of possible groups, except for the one which was returned before. If the correct reaction is not predicted after four tries, or there are no utterances with the same reaction, the predictions are registered as wrong. To measure the effects of user corrections vs. without, we used a different evalu184 ation process for this algorithm: first, we split the corpus in a 50/50 proportion, and then we moved correctly predicted utterances from the testing set towards training, until either there was nothing more to learn or the training set reached 80% of the entire corpus size. As expected, user corrections significantly improve accuracy, as shown in Figure 3. The worst algorithm’s results improve linearly with each try, while the best ones behave asymptotically, barely improving after the second try. The best algorithm reaches 92% with just one correction from the IG. 5 Discussion and future work We presented an approach to instruction interpretation which learns from non-annotated logs of human behavior. Our empirical analysis shows that our best algorithm achieves 70% accuracy on this task, with no manual annotation required. When corrections are added, accuracy goes up to 92% for just one correction. We consider our results promising since state of the art semi-unsupervised approaches to instruction interpretation (Chen and Mooney, 2011) reports a 55% accuracy on manually segmented data. We plan to compare our system’s performance against human performance in comparable situations. Our informal observations of the GIVE corpus indicate that humans often follow instructions incorrectly, so our automated system’s performance may be on par with human performance. Although we have presented our approach in the context of 3D virtual worlds, we believe our technique is also applicable to other domains such as the web, video games, or Human Robot Interaction. Figure 3: Accuracy values with corrections over Cs References Luciana Benotti and Alexandre Denis. 2011. CL system: Giving instructions by corpus based selection. In Proceedings of the Generation Challenges Session at the 13th European Workshop on Natural Language Generation, pages 296–301, Nancy, France, September. Association for Computational Linguistics. Blai Bonet and H ´ector Geffner. 2005. mGPT: a probabilistic planner based on heuristic search. Journal of Artificial Intelligence Research, 24:933–944. S.R.K. Branavan, Harr Chen, Luke Zettlemoyer, and Regina Barzilay. 2009. Reinforcement learning for mapping instructions to actions. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 82–90, Suntec, Singapore, August. Association for Computational Linguistics. Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27: 1– 27:27. Software available at http : / /www . cs ie . ntu .edu .tw/ ˜ c j l in/ l ibsvm. David L. Chen and Raymond J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI2011), pages 859–865, August. Corinna Cortes and Vladimir Vapnik. 1995. Supportvector networks. Machine Learning, 20:273–297. Myroslava O. Dzikovska, James F. Allen, and Mary D. Swift. 2008. Linking semantic and knowledge representations in a multi-domain dialogue system. Journal of Logic and Computation, 18:405–430, June. Andrew Gargett, Konstantina Garoufi, Alexander Koller, and Kristina Striegnitz. 2010. The GIVE-2 corpus of giving instructions in virtual environments. In Proceedings of the 7th Conference on International Language Resources and Evaluation (LREC), Malta. James J. Gibson. 1979. The Ecological Approach to Visual Perception, volume 40. Houghton Mifflin. Peter Gorniak and Deb Roy. 2007. Situated language understanding as filtering perceived affordances. Cognitive Science, 3 1(2): 197–231. J o¨rg Hoffmann. 2003. The Metric-FF planning system: Translating ”ignoring delete lists” to numeric state variables. Journal of Artificial Intelligence Research (JAIR), 20:291–341. Alexander Koller, Kristina Striegnitz, Andrew Gargett, Donna Byron, Justine Cassell, Robert Dale, Johanna Moore, and Jon Oberlander. 2010. Report on the second challenge on generating instructions in virtual environments (GIVE-2). In Proceedings of the 6th In185 ternational Natural Language Generation Conference (INLG), Dublin. Tessa Lau, Clemens Drews, and Jeffrey Nichols. 2009. Interpreting written how-to instructions. In Proceedings of the 21st International Joint Conference on Artificial Intelligence, pages 1433–1438, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc. Vladimir I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Technical Report 8. Matt MacMahon, Brian Stankiewicz, and Benjamin Kuipers. 2006. Walk the talk: connecting language, knowledge, and action in route instructions. In Proceedings of the 21st National Conference on Artifi- cial Intelligence - Volume 2, pages 1475–1482. AAAI Press. Cynthia Matuszek, Dieter Fox, and Karl Koscher. 2010. Following directions using statistical machine translation. In Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction, HRI ’ 10, pages 251–258, New York, NY, USA. ACM. Dana Nau, Malik Ghallab, and Paolo Traverso. 2004. Automated Planning: Theory & Practice. Morgan Kaufmann Publishers Inc., California, USA. Masoud Nikravesh, Tomohiro Takagi, Masanori Tajima, Akiyoshi Shinmura, Ryosuke Ohgaya, Koji Taniguchi, Kazuyosi Kawahara, Kouta Fukano, and Akiko Aizawa. 2005. Soft computing for perception-based decision processing and analysis: Web-based BISCDSS. In Masoud Nikravesh, Lotfi Zadeh, and Janusz Kacprzyk, editors, Soft Computing for Information Processing and Analysis, volume 164 of Studies in Fuzziness and Soft Computing, chapter 4, pages 93– 188. Springer Berlin / Heidelberg. Jeff Orkin and Deb Roy. 2009. Automatic learning and generation of social behavior from collective human gameplay. In Proceedings of The 8th International Conference on Autonomous Agents and Multiagent SystemsVolume 1, volume 1, pages 385–392. International Foundation for Autonomous Agents and Multiagent Systems, International Foundation for Autonomous Agents and Multiagent Systems. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 3 11–3 18, Stroudsburg, PA, USA. Association for Computational Linguistics. Verena Rieser and Oliver Lemon. 2010. Learning human multimodal dialogue strategies. Natural Language Engineering, 16:3–23. Laura Stoia, Donna K. Byron, Darla Magdalene Shockley, and Eric Fosler-Lussier. 2006. Sentence planning for realtime navigational instructions. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, NAACLShort ’06, pages 157–160, Stroudsburg, PA, USA. Association for Computational Linguistics. Adam Vogel and Dan Jurafsky. 2010. Learning to follow navigational directions. In Proceedings ofthe 48th Annual Meeting of the Association for Computational Linguistics, ACL ’ 10, pages 806–814, Stroudsburg, PA, USA. Association for Computational Linguistics. 186</p><p>same-paper 3 0.77065343 <a title="67-lda-3" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>Author: Malte Nuhn ; Arne Mauser ; Hermann Ney</p><p>Abstract: In this paper we show how to train statistical machine translation systems on reallife tasks using only non-parallel monolingual data from two languages. We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model. The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. We also report results using data from the monolingual French and English GIGAWORD corpora.</p><p>4 0.64376789 <a title="67-lda-4" href="./acl-2012-Graph-based_Semi-Supervised_Learning_Algorithms_for_NLP.html">104 acl-2012-Graph-based Semi-Supervised Learning Algorithms for NLP</a></p>
<p>Author: Amar Subramanya ; Partha Pratim Talukdar</p><p>Abstract: While labeled data is expensive to prepare, ever increasing amounts of unlabeled linguistic data are becoming widely available. In order to adapt to this phenomenon, several semi-supervised learning (SSL) algorithms, which learn from labeled as well as unlabeled data, have been developed. In a separate line of work, researchers have started to realize that graphs provide a natural way to represent data in a variety of domains. Graph-based SSL algorithms, which bring together these two lines of work, have been shown to outperform the state-ofthe-art in many applications in speech processing, computer vision and NLP. In particular, recent NLP research has successfully used graph-based SSL algorithms for PoS tagging (Subramanya et al., 2010), semantic parsing (Das and Smith, 2011), knowledge acquisition (Talukdar et al., 2008), sentiment analysis (Goldberg and Zhu, 2006) and text categoriza- tion (Subramanya and Bilmes, 2008). Recognizing this promising and emerging area of research, this tutorial focuses on graph-based SSL algorithms (e.g., label propagation methods). The tutorial is intended to be a sequel to the ACL 2008 SSL tutorial, focusing exclusively on graph-based SSL methods and recent advances in this area, which were beyond the scope of the previous tutorial. The tutorial is divided in two parts. In the first part, we will motivate the need for graph-based SSL methods, introduce some standard graph-based SSL algorithms, and discuss connections between these approaches. We will also discuss how linguistic data can be encoded as graphs and show how graph-based algorithms can be scaled to large amounts of data (e.g., web-scale data). Part 2 of the tutorial will focus on how graph-based methods can be used to solve several critical NLP tasks, including basic problems such as PoS tagging, semantic parsing, and more downstream tasks such as text categorization, information acquisition, and 6 Partha Pratim Talukdar Carnegie Mellon University ppt @ cs . cmu . edu sentiment analysis. We will conclude the tutorial with some exciting avenues for future work. Familiarity with semi-supervised learning and graph-based methods will not be assumed, and the necessary background will be provided. Examples from NLP tasks will be used throughout the tutorial to convey the necessary concepts. At the end of this tutorial, the attendee will walk away with the following: • An in-depth knowledge of the current state-oftAhen- ainrt-d dienp graph-based SeS oLf algorithms, taantde- tohfeability to implement them. • The ability to decide on the suitability of graph-based S toSL d meceitdheod osn nfo trh a problem. • Familiarity with different NLP tasks where graph-based wSSitLh m dieftfehorednst h NaLveP Pb teaesnk successfully applied. In addition to the above goals, we hope that this tutorial will better prepare the attendee to conduct exciting research at the intersection of NLP and other emerging areas with natural graph-structured data (e.g., Computation Social Science). Please visit http://graph-ssl.wikidot.com/ for details. References Dipanjan Das and Noah A. Smith. 2011. Semi-supervised frame-semantic parsing for unknown predicates. In Proceedings of the ACL: Human Language Technologies. Andrew B. Goldberg and Xiaojin Zhu. 2006. Seeing stars when there aren’t many stars: graph-based semi-supervised learning for sentiment categorization. In Proceedings ofthe Workshop on Graph Based Methods for NLP. Amarnag Subramanya and Jeff Bilmes. 2008. Soft-supervised text classification. In EMNLP. Amarnag Subramanya, Slav Petrov, and Fernando Pereira. 2010. Graph-based semi-supervised learning of structured tagging models. In EMNLP. Partha Pratim Talukdar, Joseph Reisinger, Marius Pasca, Deepak Ravichandran, Rahul Bhagat, and Fernando Pereira. 2008. Weakly supervised acquisition of labeled class instances using graph random walks. In EMNLP. Jeju, Republic of Korea,T 8ut Jourliya 2l0 A1b2s.tr ?ac c2t0s1 o2f A ACssLo 2c0ia1t2io,n p faogre C 6o,mputational Linguistics</p><p>5 0.63458937 <a title="67-lda-5" href="./acl-2012-Topic_Models%2C_Latent_Space_Models%2C_Sparse_Coding%2C_and_All_That%3A_A_Systematic_Understanding_of_Probabilistic_Semantic_Extraction_in_Large_Corpus.html">198 acl-2012-Topic Models, Latent Space Models, Sparse Coding, and All That: A Systematic Understanding of Probabilistic Semantic Extraction in Large Corpus</a></p>
<p>Author: Eric Xing</p><p>Abstract: Probabilistic topic models have recently gained much popularity in informational retrieval and related areas. Via such models, one can project high-dimensional objects such as text documents into a low dimensional space where their latent semantics are captured and modeled; can integrate multiple sources of information—to ”share statistical strength” among components of a hierarchical probabilistic model; and can structurally display and classify the otherwise unstructured object collections. However, to many practitioners, how topic models work, what to and not to expect from a topic model, how is it different from and related to classical matrix algebraic techniques such as LSI, NMF in NLP, how to empower topic models to deal with complex scenarios such as multimodal data, contractual text in social media, evolving corpus, or presence of supervision such as labeling and rating, how to make topic modeling computationally tractable even on webscale data, etc., in a principled way, remain unclear. In this tutorial, I will demystify the conceptual, mathematical, and computational issues behind all such problems surrounding the topic models and their applications by presenting a systematic overview of the mathematical foundation of topic modeling, and its connections to a number of related methods popular in other fields such as the LDA, admixture model, mixed membership model, latent space models, and sparse coding. Iwill offer a simple and unifying view of all these techniques under the framework multi-view latent space embedding, and online the roadmap of model extension and algorithmic design to3 ward different applications in IR and NLP. A main theme of this tutorial that tie together a wide range of issues and problems will build on the ”probabilistic graphical model” formalism, a formalism that exploits the conjoined talents of graph theory and probability theory to build complex models out of simpler pieces. Iwill use this formalism as a main aid to discuss both the mathematical underpinnings for the models and the related computational issues in a unified, simplistic, transparent, and actionable fashion. Jeju, Republic of Korea,T 8ut Jourliya 2l0 A1b2s.tr ?ac c2t0s1 o2f A ACssLo 2c0ia1t2io,n p faogre C 3o,mputational Linguistics</p><p>6 0.59095967 <a title="67-lda-6" href="./acl-2012-State-of-the-Art_Kernels_for_Natural_Language_Processing.html">183 acl-2012-State-of-the-Art Kernels for Natural Language Processing</a></p>
<p>7 0.57550251 <a title="67-lda-7" href="./acl-2012-Improving_Word_Representations_via_Global_Context_and_Multiple_Word_Prototypes.html">117 acl-2012-Improving Word Representations via Global Context and Multiple Word Prototypes</a></p>
<p>8 0.5476324 <a title="67-lda-8" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>9 0.53849584 <a title="67-lda-9" href="./acl-2012-Learning_to_Translate_with_Multiple_Objectives.html">136 acl-2012-Learning to Translate with Multiple Objectives</a></p>
<p>10 0.5369007 <a title="67-lda-10" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>11 0.53546846 <a title="67-lda-11" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>12 0.53539628 <a title="67-lda-12" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>13 0.5336467 <a title="67-lda-13" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>14 0.53015 <a title="67-lda-14" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>15 0.52934217 <a title="67-lda-15" href="./acl-2012-Modeling_the_Translation_of_Predicate-Argument_Structure_for_SMT.html">147 acl-2012-Modeling the Translation of Predicate-Argument Structure for SMT</a></p>
<p>16 0.52778959 <a title="67-lda-16" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>17 0.5251236 <a title="67-lda-17" href="./acl-2012-Learning_Syntactic_Verb_Frames_using_Graphical_Models.html">130 acl-2012-Learning Syntactic Verb Frames using Graphical Models</a></p>
<p>18 0.52426833 <a title="67-lda-18" href="./acl-2012-Improving_the_IBM_Alignment_Models_Using_Variational_Bayes.html">118 acl-2012-Improving the IBM Alignment Models Using Variational Bayes</a></p>
<p>19 0.52413118 <a title="67-lda-19" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>20 0.52355331 <a title="67-lda-20" href="./acl-2012-Learning_High-Level_Planning_from_Text.html">129 acl-2012-Learning High-Level Planning from Text</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
