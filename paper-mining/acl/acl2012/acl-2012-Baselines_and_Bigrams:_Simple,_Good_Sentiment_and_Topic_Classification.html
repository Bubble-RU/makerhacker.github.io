<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-37" href="#">acl2012-37</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</h1>
<br/><p>Source: <a title="acl-2012-37-pdf" href="http://aclweb.org/anthology//P/P12/P12-2018.pdf">pdf</a></p><p>Author: Sida Wang ; Christopher Manning</p><p>Abstract: Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.</p><p>Reference: <a title="acl-2012-37-reference" href="../acl2012_reference/acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Manning Department of Computer Science Stanford University Stanford, CA 94305 {s idaw, manning} @ stanford . [sent-2, score-0.027]
</p><p>2 edu  Abstract Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. [sent-3, score-0.06]
</p><p>3 Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level. [sent-5, score-0.414]
</p><p>4 1 Introduction  Naive Bayes (NB) and Support Vector Machine (SVM) models are often used as baselines for other methods in text categorization and sentiment analysis research. [sent-6, score-0.3]
</p><p>5 However, their performance varies significantly depending on which variant, features and datasets are used. [sent-7, score-0.134]
</p><p>6 Indeed, we show that the better variants often outperform recently published state-of-the-art methods on many datasets. [sent-9, score-0.177]
</p><p>7 We attempt to categorize which method, which variants and which features perform better under which circumstances. [sent-10, score-0.106]
</p><p>8 First, we make an important distinction between sentiment classification and topical text classifica90 tion. [sent-11, score-0.375]
</p><p>9 We show that the usefulness of bigram features in bag of features sentiment classification has been underappreciated, perhaps because their usefulness is more of a mixed bag for topical text classification tasks. [sent-12, score-0.804]
</p><p>10 We then distinguish between short snippet sentiment tasks and longer reviews, showing that for the former, NB outperforms SVMs. [sent-13, score-0.508]
</p><p>11 Contrary to  claims in the literature, we show that bag of features models are still strong performers on snippet sentiment classification tasks, with NB models generally outperforming the sophisticated, structure-sensitive models explored in recent work. [sent-14, score-0.592]
</p><p>12 Furthermore, by combining generative and discriminative classifiers, we present a simple model variant where an SVM is built over NB log-count ratios as feature values, and show that it is a strong and robust performer over all the presented tasks. [sent-15, score-0.186]
</p><p>13 Finally, we confirm the wellknown result that MNB is normally better and more stable than multivariate Bernoulli NB, and the increasingly known result that binarized MNB is better than standard MNB. [sent-16, score-0.189]
</p><p>14 The code and datasets to reproduce the results in this paper are publicly available. [sent-17, score-0.074]
</p><p>15 1 2  The Methods  We formulate our main model variants as linear classifiers, where the prediction for test case k is  y(k) = sign(wTx(k)  + b) (1) Details of the equivalent probabilistic formulations are presented in (McCallum and Nigam, 1998). [sent-18, score-0.071]
</p><p>16 fT whis, interpolation can sb teh seen as a lfaotirmon of regularization: trust NB unless the SVM is very confident. [sent-42, score-0.066]
</p><p>17 β  3  Datasets and Task  We compare with published results on the following  datasets. [sent-43, score-0.071]
</p><p>18 RT-s: Short movie reviews dataset containing one sentence per review (Pang and Lee, 2005). [sent-45, score-0.226]
</p><p>19 CV: number of crossvalidation splits, or N for train/test split. [sent-48, score-0.027]
</p><p>20 CR: Customer review dataset (Hu and Liu, 2004) processed like in (Nakagawa et al. [sent-53, score-0.084]
</p><p>21 2 MPQA: Opinion polarity subtask of the MPQA dataset (Wiebe et al. [sent-55, score-0.08]
</p><p>22 3 Subj: The subjectivity dataset with subjective reviews and objective plot summaries (Pang and Lee, 2004). [sent-57, score-0.181]
</p><p>23 RT-2k: The standard 2000 full-length movie review dataset (Pang and Lee, 2004). [sent-58, score-0.143]
</p><p>24 IMDB: A large movie review dataset with 50k fulllength reviews (Maas et al. [sent-59, score-0.226]
</p><p>25 4 AthR, XGraph, BbCrypt: Classify pairs of newsgroups in the 20-newsgroups dataset with all headers stripped off (the third (18828) version5), namely: alt. [sent-61, score-0.05]
</p><p>26 For comparison with other published results, we use either 10-fold cross-validation or train/test split depending on what is standard for the dataset. [sent-92, score-0.1]
</p><p>27 The standard splits are used when they are available. [sent-94, score-0.034]
</p><p>28 2 MNB is better at snippets (Moilanen and Pulman, 2007) suggests that while “statistical methods” work well for datasets with hundreds of words in each example, they cannot handle snippets datasets and some rule-based system is necessary. [sent-98, score-0.427]
</p><p>29 Supporting this claim are examples such as not an inhumane monster6, or killing cancer that express an overall positive sentiment with nega-  tive words. [sent-99, score-0.272]
</p><p>30 Some previous work on classifying snippets include using pre-defined polarity reversing rules (Moilanen and Pulman, 2007), and learning complex models on parse trees such as in (Nakagawa et al. [sent-100, score-0.152]
</p><p>31 These works seem promising as they perform better than many sophisticated, rule-based methods used as baselines in (Nakagawa et al. [sent-103, score-0.063]
</p><p>32 However, we find that several NB/SVM variants in fact do better than these state-of-the-art methods, even compared to methods that use lexicons, reversal rules, or unsupervised pretraining. [sent-105, score-0.198]
</p><p>33 , 2010) used a SVM with secondorder polynomial kernel and additional features. [sent-110, score-0.027]
</p><p>34 With the only exception being MPQA, MNB performed better than SVM in all cases. [sent-111, score-0.035]
</p><p>35 MNB (and NBSVM) are much better on sentiment snippet tasks, and usually better than other published results. [sent-113, score-0.553]
</p><p>36 7We are unsure, but feel that MPQA may be less discriminative, since the documents are extremely short and all methods perform similarly. [sent-115, score-0.035]
</p><p>37 “Voting” and “Rule”: use a sentiment lexicon and hard-coded reversal rules. [sent-120, score-0.364]
</p><p>38 “w/Rev”: “the polarities of phrases which have odd numbers of reversal phrases in their ancestors”. [sent-121, score-0.092]
</p><p>39 sis that rule-based systems have an edge for snippet datasets to be false. [sent-123, score-0.214]
</p><p>40 MNB is stronger for snippets than for longer documents. [sent-124, score-0.212]
</p><p>41 While (Ng and Jordan, 2002) showed that NB is better than SVM/logistic regression (LR) with few training cases, we show that MNB is also better with short documents. [sent-125, score-0.11]
</p><p>42 In contrast to their result that an SVM usually beats NB when it has more than 30–50 training cases, we show that MNB is still better on snippets even with relatively large training sets (9k cases). [sent-126, score-0.157]
</p><p>43 3 SVM is better at full-length reviews As seen in table 1, the RT-2k and IMDB datasets contain much longer reviews. [sent-128, score-0.25]
</p><p>44 Compared to the excellent performance of MNB on snippet datasets, the many poor assumptions of MNB pointed out  in (Rennie et al. [sent-129, score-0.14]
</p><p>45 SVM is much stronger than MNB for the 2 full-length sentiment analysis tasks, but still worse than some other published results. [sent-131, score-0.375]
</p><p>46 BoWSVM: bag of words SVM used in (Pang and Lee, 2004). [sent-142, score-0.119]
</p><p>47 These sentiment analysis results are shown in table 3. [sent-151, score-0.272]
</p><p>48 4 Benefits of bigrams depends on the task Word bigram features are not that commonly used in text classification tasks (hence, the usual term, “bag of words”), probably due to their having mixed and overall limited utility in topical text classification tasks, as seen in table 4. [sent-153, score-0.332]
</p><p>49 This likely reflects that certain topic keywords are indicative alone. [sent-154, score-0.028]
</p><p>50 However, in both tables 2 and 3, adding bigrams always improved the performance, and often gives better results than previously published. [sent-155, score-0.097]
</p><p>51 8 This presumably reflects that in sentiment classification there are 8However, adding trigrams hurts slightly. [sent-156, score-0.361]
</p><p>52 5 NBSVM is a robust performer NBSVM performs well on snippets and longer documents, for sentiment, topic and subjectivity classification, and is often better than previously pub-  lished results. [sent-173, score-0.352]
</p><p>53 Therefore, NBSVM seems to be an appropriate and very strong baseline for sophisticated methods aiming to beat a bag of features. [sent-174, score-0.119]
</p><p>54 One disadvantage of NBSVM is having the interpolation parameter β. [sent-175, score-0.066]
</p><p>55 The performance on longer documents is virtually identical (within 0. [sent-176, score-0.093]
</p><p>56 6  Other results  Multivariate Bernoulli NB (BNB) usually performs worse than MNB. [sent-182, score-0.028]
</p><p>57 The only place where BNB is comparable to MNB is for snippet tasks using only unigrams. [sent-183, score-0.178]
</p><p>58 In general, BNB is less stable than MNB and performs up to 10% worse. [sent-184, score-0.057]
</p><p>59 For MNB and NBSVM, using the binarized MNB is slightly better (by 1%) than using the raw count feature f. [sent-187, score-0.08]
</p><p>60 Using logistic regression in place of SVM gives similar results, and some of our results can be viewed more generally in terms of generative vs. [sent-189, score-0.072]
</p><p>61 Sentiment classification of movie reviews using contextual valence shifters. [sent-215, score-0.246]
</p><p>62 Delta tfidf: An improved feature space for sentiment analysis. [sent-232, score-0.272]
</p><p>63 A comparison of event models for naive bayes text classification. [sent-236, score-0.219]
</p><p>64 Dependency tree-based sentiment classification using CRFs with hidden variables. [sent-248, score-0.333]
</p><p>65 generative classifiers: A comparison of logistic regression and naive bayes. [sent-253, score-0.208]
</p><p>66 A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. [sent-257, score-0.048]
</p><p>67 Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. [sent-261, score-0.272]
</p><p>68 Tackling the poor assumptions of naive bayes text classifiers. [sent-267, score-0.219]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mnb', 0.549), ('nb', 0.285), ('nbsvm', 0.275), ('sentiment', 0.272), ('svm', 0.225), ('nakagawa', 0.17), ('snippet', 0.14), ('naive', 0.136), ('snippets', 0.122), ('bnb', 0.122), ('bag', 0.119), ('mpqa', 0.106), ('pang', 0.104), ('maas', 0.092), ('moilanen', 0.092), ('reversal', 0.092), ('reviews', 0.083), ('bayes', 0.083), ('datasets', 0.074), ('variants', 0.071), ('published', 0.071), ('imdb', 0.068), ('socher', 0.068), ('interpolation', 0.066), ('bigrams', 0.062), ('classification', 0.061), ('bowsvm', 0.061), ('kennedy', 0.061), ('metsis', 0.061), ('performer', 0.061), ('pulman', 0.061), ('schohn', 0.061), ('movie', 0.059), ('longer', 0.058), ('boltzmann', 0.053), ('disclda', 0.053), ('appraisal', 0.053), ('martineau', 0.053), ('whitelaw', 0.053), ('dataset', 0.05), ('delta', 0.049), ('collobert', 0.049), ('dahl', 0.049), ('rennie', 0.049), ('variant', 0.048), ('subjectivity', 0.048), ('binarized', 0.045), ('multivariate', 0.045), ('valence', 0.043), ('topical', 0.042), ('ratios', 0.041), ('regression', 0.04), ('lee', 0.039), ('nigam', 0.039), ('tasks', 0.038), ('bigram', 0.038), ('liblinear', 0.037), ('idf', 0.037), ('discriminative', 0.036), ('better', 0.035), ('documents', 0.035), ('bernoulli', 0.035), ('andrew', 0.034), ('review', 0.034), ('splits', 0.034), ('customer', 0.034), ('cv', 0.034), ('wiebe', 0.033), ('lillian', 0.033), ('logistic', 0.032), ('fan', 0.032), ('recursive', 0.032), ('stronger', 0.032), ('ng', 0.031), ('classifiers', 0.031), ('usefulness', 0.031), ('varies', 0.031), ('mixed', 0.03), ('polarity', 0.03), ('depending', 0.029), ('mccallum', 0.029), ('stable', 0.029), ('reflects', 0.028), ('performs', 0.028), ('machines', 0.028), ('baselines', 0.028), ('stanford', 0.027), ('library', 0.027), ('pi', 0.027), ('benchmarking', 0.027), ('tetsuji', 0.027), ('negligible', 0.027), ('secondorder', 0.027), ('autoencoders', 0.027), ('casey', 0.027), ('crippling', 0.027), ('crossvalidation', 0.027), ('finin', 0.027), ('garg', 0.027), ('inkpen', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="37-tfidf-1" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>Author: Sida Wang ; Christopher Manning</p><p>Abstract: Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.</p><p>2 0.22302279 <a title="37-tfidf-2" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>Author: Fangtao Li ; Sinno Jialin Pan ; Ou Jin ; Qiang Yang ; Xiaoyan Zhu</p><p>Abstract: Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment- and topic- lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.</p><p>3 0.19270436 <a title="37-tfidf-3" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>Author: Xinfan Meng ; Furu Wei ; Xiaohua Liu ; Ming Zhou ; Ge Xu ; Houfeng Wang</p><p>Abstract: The amount of labeled sentiment data in English is much larger than that in other languages. Such a disproportion arouse interest in cross-lingual sentiment classification, which aims to conduct sentiment classification in the target language (e.g. Chinese) using labeled data in the source language (e.g. English). Most existing work relies on machine translation engines to directly adapt labeled data from the source language to the target language. This approach suffers from the limited coverage of vocabulary in the machine translation results. In this paper, we propose a generative cross-lingual mixture model (CLMM) to leverage unlabeled bilingual parallel data. By fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage signifi- cantly. Experiments on multiple data sets show that CLMM is consistently effective in two settings: (1) labeled data in the target language are unavailable; and (2) labeled data in the target language are also available.</p><p>4 0.18006554 <a title="37-tfidf-4" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>5 0.12620351 <a title="37-tfidf-5" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>Author: Hao Wang ; Dogan Can ; Abe Kazemzadeh ; Francois Bar ; Shrikanth Narayanan</p><p>Abstract: This paper describes a system for real-time analysis of public sentiment toward presidential candidates in the 2012 U.S. election as expressed on Twitter, a microblogging service. Twitter has become a central site where people express their opinions and views on political parties and candidates. Emerging events or news are often followed almost instantly by a burst in Twitter volume, providing a unique opportunity to gauge the relation between expressed public sentiment and electoral events. In addition, sentiment analysis can help explore how these events affect public opinion. While traditional content analysis takes days or weeks to complete, the system demonstrated here analyzes sentiment in the entire Twitter traffic about the election, delivering results instantly and continuously. It offers the public, the media, politicians and scholars a new and timely perspective on the dynamics of the electoral process and public opinion. 1</p><p>6 0.12425552 <a title="37-tfidf-6" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>7 0.1217566 <a title="37-tfidf-7" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>8 0.10745711 <a title="37-tfidf-8" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>9 0.10320035 <a title="37-tfidf-9" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>10 0.090862386 <a title="37-tfidf-10" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>11 0.085323505 <a title="37-tfidf-11" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>12 0.076882444 <a title="37-tfidf-12" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>13 0.075512066 <a title="37-tfidf-13" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>14 0.071249075 <a title="37-tfidf-14" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>15 0.06850481 <a title="37-tfidf-15" href="./acl-2012-Deep_Learning_for_NLP_%28without_Magic%29.html">69 acl-2012-Deep Learning for NLP (without Magic)</a></p>
<p>16 0.062767334 <a title="37-tfidf-16" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>17 0.060673993 <a title="37-tfidf-17" href="./acl-2012-Improving_Word_Representations_via_Global_Context_and_Multiple_Word_Prototypes.html">117 acl-2012-Improving Word Representations via Global Context and Multiple Word Prototypes</a></p>
<p>18 0.060351368 <a title="37-tfidf-18" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>19 0.051189926 <a title="37-tfidf-19" href="./acl-2012-Syntactic_Stylometry_for_Deception_Detection.html">190 acl-2012-Syntactic Stylometry for Deception Detection</a></p>
<p>20 0.048865084 <a title="37-tfidf-20" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.147), (1, 0.15), (2, 0.143), (3, -0.194), (4, 0.082), (5, -0.034), (6, 0.043), (7, 0.002), (8, -0.183), (9, -0.079), (10, 0.041), (11, -0.005), (12, -0.1), (13, -0.094), (14, -0.018), (15, -0.059), (16, 0.051), (17, 0.041), (18, -0.015), (19, -0.009), (20, 0.021), (21, 0.071), (22, 0.014), (23, 0.005), (24, 0.039), (25, 0.007), (26, 0.063), (27, -0.01), (28, 0.011), (29, 0.058), (30, 0.055), (31, 0.009), (32, -0.039), (33, -0.029), (34, 0.072), (35, -0.068), (36, 0.022), (37, -0.034), (38, -0.038), (39, 0.076), (40, 0.028), (41, 0.041), (42, -0.12), (43, 0.003), (44, 0.041), (45, 0.012), (46, 0.069), (47, -0.083), (48, 0.035), (49, -0.088)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95733446 <a title="37-lsi-1" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>Author: Sida Wang ; Christopher Manning</p><p>Abstract: Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.</p><p>2 0.76153296 <a title="37-lsi-2" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>Author: Xinfan Meng ; Furu Wei ; Xiaohua Liu ; Ming Zhou ; Ge Xu ; Houfeng Wang</p><p>Abstract: The amount of labeled sentiment data in English is much larger than that in other languages. Such a disproportion arouse interest in cross-lingual sentiment classification, which aims to conduct sentiment classification in the target language (e.g. Chinese) using labeled data in the source language (e.g. English). Most existing work relies on machine translation engines to directly adapt labeled data from the source language to the target language. This approach suffers from the limited coverage of vocabulary in the machine translation results. In this paper, we propose a generative cross-lingual mixture model (CLMM) to leverage unlabeled bilingual parallel data. By fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage signifi- cantly. Experiments on multiple data sets show that CLMM is consistently effective in two settings: (1) labeled data in the target language are unavailable; and (2) labeled data in the target language are also available.</p><p>3 0.7233687 <a title="37-lsi-3" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>Author: Rada Mihalcea ; Carmen Banea ; Janyce Wiebe</p><p>Abstract: Subjectivity and sentiment analysis focuses on the automatic identification of private states, such as opinions, emotions, sentiments, evaluations, beliefs, and speculations in natural language. While subjectivity classification labels text as either subjective or objective, sentiment classification adds an additional level of granularity, by further classifying subjective text as either positive, negative or neutral. While much of the research work in this area has been applied to English, research on other languages is growing, including Japanese, Chinese, German, Spanish, Romanian. While most of the researchers in the field are familiar with the methods applied on English, few of them have closely looked at the original research carried out in other languages. For example, in languages such as Chinese, researchers have been looking at the ability of characters to carry sentiment information (Ku et al., 2005; Xiang, 2011). In Romanian, due to markers of politeness and additional verbal modes embedded in the language, experiments have hinted that subjectivity detection may be easier to achieve (Banea et al., 2008). These additional sources ofinformation may not be available across all languages, yet, various articles have pointed out that by investigating a synergistic approach for detecting subjectivity and sentiment in multiple languages at the same time, improvements can be achieved not only in other languages, but in English as well. The development and interest in these methods is also highly motivated by the fact that only 27% of Internet users speak English (www.internetworldstats.com/stats.htm, 4 . unt . edu wiebe @ c s . pitt . edu Oct 11, 2011), and that number diminishes further every year, as more people across the globe gain Internet access. The aim of this tutorial is to familiarize the attendees with the subjectivity and sentiment research carried out on languages other than English in order to enable and promote crossfertilization. Specifically, we will review work along three main directions. First, we will present methods where the resources and tools have been specifically developed for a given target language. In this category, we will also briefly overview the main methods that have been proposed for English, but which can be easily ported to other languages. Second, we will describe cross-lingual approaches, including several methods that have been proposed to leverage on the resources and tools available in English by using cross-lingual projections. Finally, third, we will show how the expression of opinions and polarity pervades language boundaries, and thus methods that holistically explore multiple languages at the same time can be effectively considered. References C. Banea, R. Mihalcea, and J. Wiebe. 2008. A Bootstrapping method for building subjectivity lexicons for languages with scarce resources. In Proceedings of LREC 2008, Marrakech, Morocco. L. W. Ku, T. H. Wu, L. Y. Lee, and H. H. Chen. 2005. Construction of an Evaluation Corpus for Opinion Extraction. In Proceedings of NTCIR-5, Tokyo, Japan. L. Xiang. 2011. Ideogram Based Chinese Sentiment Word Orientation Computation. Computing Research Repository, page 4, October. Jeju, Republic of Korea,T 8ut Jourliya 2l0 A1b2s.tr ?ac c2t0s1 o2f A ACssLo 2c0ia1t2io,n p faogre C 4o,mputational Linguistics</p><p>4 0.70838445 <a title="37-lsi-4" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>Author: Fangtao Li ; Sinno Jialin Pan ; Ou Jin ; Qiang Yang ; Xiaoyan Zhu</p><p>Abstract: Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment- and topic- lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.</p><p>5 0.6678915 <a title="37-lsi-5" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>6 0.64969671 <a title="37-lsi-6" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>7 0.53953135 <a title="37-lsi-7" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>8 0.53587919 <a title="37-lsi-8" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>9 0.52140069 <a title="37-lsi-9" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>10 0.42052826 <a title="37-lsi-10" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>11 0.40225616 <a title="37-lsi-11" href="./acl-2012-Syntactic_Stylometry_for_Deception_Detection.html">190 acl-2012-Syntactic Stylometry for Deception Detection</a></p>
<p>12 0.40029746 <a title="37-lsi-12" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>13 0.39133233 <a title="37-lsi-13" href="./acl-2012-Toward_Automatically_Assembling_Hittite-Language_Cuneiform_Tablet_Fragments_into_Larger_Texts.html">200 acl-2012-Toward Automatically Assembling Hittite-Language Cuneiform Tablet Fragments into Larger Texts</a></p>
<p>14 0.38041523 <a title="37-lsi-14" href="./acl-2012-Beefmoves%3A_Dissemination%2C_Diversity%2C_and_Dynamics_of_English_Borrowings_in_a_German_Hip_Hop_Forum.html">39 acl-2012-Beefmoves: Dissemination, Diversity, and Dynamics of English Borrowings in a German Hip Hop Forum</a></p>
<p>15 0.37863594 <a title="37-lsi-15" href="./acl-2012-Information-theoretic_Multi-view_Domain_Adaptation.html">120 acl-2012-Information-theoretic Multi-view Domain Adaptation</a></p>
<p>16 0.34337771 <a title="37-lsi-16" href="./acl-2012-Improving_Word_Representations_via_Global_Context_and_Multiple_Word_Prototypes.html">117 acl-2012-Improving Word Representations via Global Context and Multiple Word Prototypes</a></p>
<p>17 0.34150338 <a title="37-lsi-17" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>18 0.33892331 <a title="37-lsi-18" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>19 0.32731956 <a title="37-lsi-19" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>20 0.32725179 <a title="37-lsi-20" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.011), (25, 0.021), (26, 0.037), (28, 0.03), (30, 0.025), (37, 0.048), (39, 0.074), (59, 0.032), (70, 0.299), (74, 0.024), (82, 0.038), (84, 0.023), (85, 0.025), (90, 0.096), (92, 0.067), (94, 0.022), (99, 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6998021 <a title="37-lda-1" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>Author: Sida Wang ; Christopher Manning</p><p>Abstract: Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.</p><p>2 0.47853482 <a title="37-lda-2" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>Author: Shujie Liu ; Chi-Ho Li ; Mu Li ; Ming Zhou</p><p>Abstract: In this paper, we address the issue for learning better translation consensus in machine translation (MT) research, and explore the search of translation consensus from similar, rather than the same, source sentences or their spans. Unlike previous work on this topic, we formulate the problem as structured labeling over a much smaller graph, and we propose a novel structured label propagation for the task. We convert such graph-based translation consensus from similar source strings into useful features both for n-best output reranking and for decoding algorithm. Experimental results show that, our method can significantly improve machine translation performance on both IWSLT and NIST data, compared with a state-ofthe-art baseline. 1</p><p>3 0.46677202 <a title="37-lda-3" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Pradeep Dasigi ; Mona Diab ; Dragomir Radev</p><p>Abstract: The rapid and continuous growth of social networking sites has led to the emergence of many communities of communicating groups. Many of these groups discuss ideological and political topics. It is not uncommon that the participants in such discussions split into two or more subgroups. The members of each subgroup share the same opinion toward the discussion topic and are more likely to agree with members of the same subgroup and disagree with members from opposing subgroups. In this paper, we propose an unsupervised approach for automatically detecting discussant subgroups in online communities. We analyze the text exchanged between the participants of a discussion to identify the attitude they carry toward each other and towards the various aspects of the discussion topic. We use attitude predictions to construct an attitude vector for each discussant. We use clustering techniques to cluster these vectors and, hence, determine the subgroup membership of each participant. We compare our methods to text clustering and other baselines, and show that our method achieves promising results.</p><p>4 0.46489894 <a title="37-lda-4" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>Author: Jonathan Berant ; Ido Dagan ; Meni Adler ; Jacob Goldberger</p><p>Abstract: Learning entailment rules is fundamental in many semantic-inference applications and has been an active field of research in recent years. In this paper we address the problem of learning transitive graphs that describe entailment rules between predicates (termed entailment graphs). We first identify that entailment graphs exhibit a “tree-like” property and are very similar to a novel type of graph termed forest-reducible graph. We utilize this property to develop an iterative efficient approximation algorithm for learning the graph edges, where each iteration takes linear time. We compare our approximation algorithm to a recently-proposed state-of-the-art exact algorithm and show that it is more efficient and scalable both theoretically and empirically, while its output quality is close to that given by the optimal solution of the exact algorithm.</p><p>5 0.46472731 <a title="37-lda-5" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>6 0.46274626 <a title="37-lda-6" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>7 0.46190366 <a title="37-lda-7" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>8 0.45996559 <a title="37-lda-8" href="./acl-2012-Topic_Models%2C_Latent_Space_Models%2C_Sparse_Coding%2C_and_All_That%3A_A_Systematic_Understanding_of_Probabilistic_Semantic_Extraction_in_Large_Corpus.html">198 acl-2012-Topic Models, Latent Space Models, Sparse Coding, and All That: A Systematic Understanding of Probabilistic Semantic Extraction in Large Corpus</a></p>
<p>9 0.45968845 <a title="37-lda-9" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>10 0.45916098 <a title="37-lda-10" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>11 0.45714712 <a title="37-lda-11" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>12 0.45691356 <a title="37-lda-12" href="./acl-2012-Learning_the_Latent_Semantics_of_a_Concept_from_its_Definition.html">132 acl-2012-Learning the Latent Semantics of a Concept from its Definition</a></p>
<p>13 0.45653239 <a title="37-lda-13" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>14 0.4560912 <a title="37-lda-14" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>15 0.45583299 <a title="37-lda-15" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>16 0.45428306 <a title="37-lda-16" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>17 0.4531894 <a title="37-lda-17" href="./acl-2012-Learning_Syntactic_Verb_Frames_using_Graphical_Models.html">130 acl-2012-Learning Syntactic Verb Frames using Graphical Models</a></p>
<p>18 0.45296794 <a title="37-lda-18" href="./acl-2012-Modeling_Topic_Dependencies_in_Hierarchical_Text_Categorization.html">146 acl-2012-Modeling Topic Dependencies in Hierarchical Text Categorization</a></p>
<p>19 0.45170662 <a title="37-lda-19" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>20 0.4513534 <a title="37-lda-20" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
