<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>131 acl-2012-Learning Translation Consensus with Structured Label Propagation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-131" href="#">acl2012-131</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>131 acl-2012-Learning Translation Consensus with Structured Label Propagation</h1>
<br/><p>Source: <a title="acl-2012-131-pdf" href="http://aclweb.org/anthology//P/P12/P12-1032.pdf">pdf</a></p><p>Author: Shujie Liu ; Chi-Ho Li ; Mu Li ; Ming Zhou</p><p>Abstract: In this paper, we address the issue for learning better translation consensus in machine translation (MT) research, and explore the search of translation consensus from similar, rather than the same, source sentences or their spans. Unlike previous work on this topic, we formulate the problem as structured labeling over a much smaller graph, and we propose a novel structured label propagation for the task. We convert such graph-based translation consensus from similar source strings into useful features both for n-best output reranking and for decoding algorithm. Experimental results show that, our method can significantly improve machine translation performance on both IWSLT and NIST data, compared with a state-ofthe-art baseline. 1</p><p>Reference: <a title="acl-2012-131-reference" href="../acl2012_reference/acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('consens', 0.762), ('transl', 0.28), ('decod', 0.229), ('nod', 0.187), ('alexandrescu', 0.145), ('iwslt', 0.135), ('graph', 0.125), ('candid', 0.113), ('structured', 0.112), ('prop', 0.108), ('nist', 0.103), ('mt', 0.095), ('sourc', 0.092), ('kirchhoff', 0.087), ('label', 0.085), ('span', 0.083), ('edg', 0.08), ('kum', 0.065), ('reform', 0.061), ('sent', 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="131-tfidf-1" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>Author: Shujie Liu ; Chi-Ho Li ; Mu Li ; Ming Zhou</p><p>Abstract: In this paper, we address the issue for learning better translation consensus in machine translation (MT) research, and explore the search of translation consensus from similar, rather than the same, source sentences or their spans. Unlike previous work on this topic, we formulate the problem as structured labeling over a much smaller graph, and we propose a novel structured label propagation for the task. We convert such graph-based translation consensus from similar source strings into useful features both for n-best output reranking and for decoding algorithm. Experimental results show that, our method can significantly improve machine translation performance on both IWSLT and NIST data, compared with a state-ofthe-art baseline. 1</p><p>2 0.25192592 <a title="131-tfidf-2" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>Author: Tong Xiao ; Jingbo Zhu ; Hao Zhang ; Qiang Li</p><p>Abstract: We present a new open source toolkit for phrase-based and syntax-based machine translation. The toolkit supports several state-of-the-art models developed in statistical machine translation, including the phrase-based model, the hierachical phrase-based model, and various syntaxbased models. The key innovation provided by the toolkit is that the decoder can work with various grammars and offers different choices of decoding algrithms, such as phrase-based decoding, decoding as parsing/tree-parsing and forest-based decoding. Moreover, several useful utilities were distributed with the toolkit, including a discriminative reordering model, a simple and fast language model, and an implementation of minimum error rate training for weight tuning. 1</p><p>3 0.21576542 <a title="131-tfidf-3" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>Author: Xiaodong He ; Li Deng</p><p>Abstract: This paper proposes a new discriminative training method in constructing phrase and lexicon translation models. In order to reliably learn a myriad of parameters in these models, we propose an expected BLEU score-based utility function with KL regularization as the objective, and train the models on a large parallel dataset. For training, we derive growth transformations for phrase and lexicon translation probabilities to iteratively improve the objective. The proposed method, evaluated on the Europarl German-to-English dataset, leads to a 1.1 BLEU point improvement over a state-of-the-art baseline translation system. In IWSLT 201 1 Benchmark, our system using the proposed method achieves the best Chinese-to-English translation result on the task of translating TED talks.</p><p>4 0.19890031 <a title="131-tfidf-4" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>Author: Hui Zhang ; David Chiang</p><p>Abstract: Syntax-based translation models that operate on the output of a source-language parser have been shown to perform better if allowed to choose from a set of possible parses. In this paper, we investigate whether this is because it allows the translation stage to overcome parser errors or to override the syntactic structure itself. We find that it is primarily the latter, but that under the right conditions, the translation stage does correct parser errors, improving parsing accuracy on the Chinese Treebank.</p><p>5 0.19343191 <a title="131-tfidf-5" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>Author: Majid Razmara ; George Foster ; Baskaran Sankaran ; Anoop Sarkar</p><p>Abstract: Statistical machine translation is often faced with the problem of combining training data from many diverse sources into a single translation model which then has to translate sentences in a new domain. We propose a novel approach, ensemble decoding, which combines a number of translation systems dynamically at the decoding step. In this paper, we evaluate performance on a domain adaptation setting where we translate sentences from the medical domain. Our experimental results show that ensemble decoding outperforms various strong baselines including mixture models, the current state-of-the-art for domain adaptation in machine translation.</p><p>6 0.17347619 <a title="131-tfidf-6" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>7 0.17260277 <a title="131-tfidf-7" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>8 0.1617821 <a title="131-tfidf-8" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>9 0.14888555 <a title="131-tfidf-9" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>10 0.14881943 <a title="131-tfidf-10" href="./acl-2012-Modeling_the_Translation_of_Predicate-Argument_Structure_for_SMT.html">147 acl-2012-Modeling the Translation of Predicate-Argument Structure for SMT</a></p>
<p>11 0.14801137 <a title="131-tfidf-11" href="./acl-2012-Translation_Model_Size_Reduction_for_Hierarchical_Phrase-based_Statistical_Machine_Translation.html">204 acl-2012-Translation Model Size Reduction for Hierarchical Phrase-based Statistical Machine Translation</a></p>
<p>12 0.1307572 <a title="131-tfidf-12" href="./acl-2012-Iterative_Viterbi_A%2A_Algorithm_for_K-Best_Sequential_Decoding.html">121 acl-2012-Iterative Viterbi A* Algorithm for K-Best Sequential Decoding</a></p>
<p>13 0.12786439 <a title="131-tfidf-13" href="./acl-2012-A_Ranking-based_Approach_to_Word_Reordering_for_Statistical_Machine_Translation.html">19 acl-2012-A Ranking-based Approach to Word Reordering for Statistical Machine Translation</a></p>
<p>14 0.12760153 <a title="131-tfidf-14" href="./acl-2012-A_Topic_Similarity_Model_for_Hierarchical_Phrase-based_Translation.html">22 acl-2012-A Topic Similarity Model for Hierarchical Phrase-based Translation</a></p>
<p>15 0.12626794 <a title="131-tfidf-15" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>16 0.12481555 <a title="131-tfidf-16" href="./acl-2012-PORT%3A_a_Precision-Order-Recall_MT_Evaluation_Metric_for_Tuning.html">158 acl-2012-PORT: a Precision-Order-Recall MT Evaluation Metric for Tuning</a></p>
<p>17 0.11803016 <a title="131-tfidf-17" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>18 0.11622318 <a title="131-tfidf-18" href="./acl-2012-Smaller_Alignment_Models_for_Better_Translations%3A_Unsupervised_Word_Alignment_with_the_l0-norm.html">179 acl-2012-Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the l0-norm</a></p>
<p>19 0.11509167 <a title="131-tfidf-19" href="./acl-2012-Topic_Models_for_Dynamic_Translation_Model_Adaptation.html">199 acl-2012-Topic Models for Dynamic Translation Model Adaptation</a></p>
<p>20 0.11499219 <a title="131-tfidf-20" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.284), (1, -0.236), (2, 0.102), (3, 0.011), (4, -0.035), (5, -0.022), (6, -0.033), (7, 0.002), (8, 0.002), (9, -0.047), (10, 0.03), (11, 0.025), (12, 0.054), (13, 0.013), (14, -0.08), (15, -0.024), (16, 0.111), (17, 0.054), (18, 0.018), (19, 0.007), (20, -0.013), (21, 0.087), (22, -0.012), (23, 0.014), (24, 0.053), (25, 0.094), (26, -0.021), (27, 0.093), (28, 0.011), (29, 0.055), (30, -0.064), (31, 0.098), (32, -0.002), (33, -0.051), (34, -0.086), (35, 0.048), (36, -0.014), (37, -0.082), (38, 0.006), (39, -0.009), (40, -0.136), (41, 0.063), (42, 0.095), (43, -0.024), (44, 0.031), (45, 0.034), (46, -0.103), (47, -0.02), (48, -0.11), (49, -0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93683678 <a title="131-lsi-1" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>Author: Shujie Liu ; Chi-Ho Li ; Mu Li ; Ming Zhou</p><p>Abstract: In this paper, we address the issue for learning better translation consensus in machine translation (MT) research, and explore the search of translation consensus from similar, rather than the same, source sentences or their spans. Unlike previous work on this topic, we formulate the problem as structured labeling over a much smaller graph, and we propose a novel structured label propagation for the task. We convert such graph-based translation consensus from similar source strings into useful features both for n-best output reranking and for decoding algorithm. Experimental results show that, our method can significantly improve machine translation performance on both IWSLT and NIST data, compared with a state-ofthe-art baseline. 1</p><p>2 0.79003465 <a title="131-lsi-2" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>Author: Tong Xiao ; Jingbo Zhu ; Hao Zhang ; Qiang Li</p><p>Abstract: We present a new open source toolkit for phrase-based and syntax-based machine translation. The toolkit supports several state-of-the-art models developed in statistical machine translation, including the phrase-based model, the hierachical phrase-based model, and various syntaxbased models. The key innovation provided by the toolkit is that the decoder can work with various grammars and offers different choices of decoding algrithms, such as phrase-based decoding, decoding as parsing/tree-parsing and forest-based decoding. Moreover, several useful utilities were distributed with the toolkit, including a discriminative reordering model, a simple and fast language model, and an implementation of minimum error rate training for weight tuning. 1</p><p>3 0.70285887 <a title="131-lsi-3" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>Author: Xiaodong He ; Li Deng</p><p>Abstract: This paper proposes a new discriminative training method in constructing phrase and lexicon translation models. In order to reliably learn a myriad of parameters in these models, we propose an expected BLEU score-based utility function with KL regularization as the objective, and train the models on a large parallel dataset. For training, we derive growth transformations for phrase and lexicon translation probabilities to iteratively improve the objective. The proposed method, evaluated on the Europarl German-to-English dataset, leads to a 1.1 BLEU point improvement over a state-of-the-art baseline translation system. In IWSLT 201 1 Benchmark, our system using the proposed method achieves the best Chinese-to-English translation result on the task of translating TED talks.</p><p>4 0.68096662 <a title="131-lsi-4" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>Author: Joern Wuebker ; Hermann Ney ; Richard Zens</p><p>Abstract: In this work we present two extensions to the well-known dynamic programming beam search in phrase-based statistical machine translation (SMT), aiming at increased efficiency of decoding by minimizing the number of language model computations and hypothesis expansions. Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2. Two look-ahead methods are shown to further increase translation speed by a factor of2 without changing the search space and a factor of 4 with the side-effect of some additional search errors. We compare our ap- proach with Moses and observe the same performance, but a substantially better trade-off between translation quality and speed. At a speed of roughly 70 words per second, Moses reaches 17.2% BLEU, whereas our approach yields 20.0% with identical models.</p><p>5 0.67823446 <a title="131-lsi-5" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>Author: Majid Razmara ; George Foster ; Baskaran Sankaran ; Anoop Sarkar</p><p>Abstract: Statistical machine translation is often faced with the problem of combining training data from many diverse sources into a single translation model which then has to translate sentences in a new domain. We propose a novel approach, ensemble decoding, which combines a number of translation systems dynamically at the decoding step. In this paper, we evaluate performance on a domain adaptation setting where we translate sentences from the medical domain. Our experimental results show that ensemble decoding outperforms various strong baselines including mixture models, the current state-of-the-art for domain adaptation in machine translation.</p><p>6 0.64788944 <a title="131-lsi-6" href="./acl-2012-Head-Driven_Hierarchical_Phrase-based_Translation.html">105 acl-2012-Head-Driven Hierarchical Phrase-based Translation</a></p>
<p>7 0.63863629 <a title="131-lsi-7" href="./acl-2012-Translation_Model_Size_Reduction_for_Hierarchical_Phrase-based_Statistical_Machine_Translation.html">204 acl-2012-Translation Model Size Reduction for Hierarchical Phrase-based Statistical Machine Translation</a></p>
<p>8 0.63796467 <a title="131-lsi-8" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>9 0.63212311 <a title="131-lsi-9" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>10 0.60953212 <a title="131-lsi-10" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>11 0.59343833 <a title="131-lsi-11" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>12 0.58846945 <a title="131-lsi-12" href="./acl-2012-Iterative_Viterbi_A%2A_Algorithm_for_K-Best_Sequential_Decoding.html">121 acl-2012-Iterative Viterbi A* Algorithm for K-Best Sequential Decoding</a></p>
<p>13 0.5781334 <a title="131-lsi-13" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>14 0.57337511 <a title="131-lsi-14" href="./acl-2012-Hierarchical_Chunk-to-String_Translation.html">108 acl-2012-Hierarchical Chunk-to-String Translation</a></p>
<p>15 0.56544179 <a title="131-lsi-15" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>16 0.56269914 <a title="131-lsi-16" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>17 0.56172252 <a title="131-lsi-17" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>18 0.54269892 <a title="131-lsi-18" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>19 0.5264194 <a title="131-lsi-19" href="./acl-2012-Bootstrapping_via_Graph_Propagation.html">42 acl-2012-Bootstrapping via Graph Propagation</a></p>
<p>20 0.52356231 <a title="131-lsi-20" href="./acl-2012-Character-Level_Machine_Translation_Evaluation_for_Languages_with_Ambiguous_Word_Boundaries.html">46 acl-2012-Character-Level Machine Translation Evaluation for Languages with Ambiguous Word Boundaries</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.073), (8, 0.041), (22, 0.075), (31, 0.02), (38, 0.034), (47, 0.032), (58, 0.041), (61, 0.187), (77, 0.058), (85, 0.157), (91, 0.099), (92, 0.042), (96, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82988447 <a title="131-lda-1" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>Author: Xiaodong He ; Li Deng</p><p>Abstract: This paper proposes a new discriminative training method in constructing phrase and lexicon translation models. In order to reliably learn a myriad of parameters in these models, we propose an expected BLEU score-based utility function with KL regularization as the objective, and train the models on a large parallel dataset. For training, we derive growth transformations for phrase and lexicon translation probabilities to iteratively improve the objective. The proposed method, evaluated on the Europarl German-to-English dataset, leads to a 1.1 BLEU point improvement over a state-of-the-art baseline translation system. In IWSLT 201 1 Benchmark, our system using the proposed method achieves the best Chinese-to-English translation result on the task of translating TED talks.</p><p>same-paper 2 0.82582855 <a title="131-lda-2" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>Author: Shujie Liu ; Chi-Ho Li ; Mu Li ; Ming Zhou</p><p>Abstract: In this paper, we address the issue for learning better translation consensus in machine translation (MT) research, and explore the search of translation consensus from similar, rather than the same, source sentences or their spans. Unlike previous work on this topic, we formulate the problem as structured labeling over a much smaller graph, and we propose a novel structured label propagation for the task. We convert such graph-based translation consensus from similar source strings into useful features both for n-best output reranking and for decoding algorithm. Experimental results show that, our method can significantly improve machine translation performance on both IWSLT and NIST data, compared with a state-ofthe-art baseline. 1</p><p>3 0.79197073 <a title="131-lda-3" href="./acl-2012-A_Comparative_Study_of_Target_Dependency_Structures_for_Statistical_Machine_Translation.html">4 acl-2012-A Comparative Study of Target Dependency Structures for Statistical Machine Translation</a></p>
<p>Author: Xianchao Wu ; Katsuhito Sudoh ; Kevin Duh ; Hajime Tsukada ; Masaaki Nagata</p><p>Abstract: This paper presents a comparative study of target dependency structures yielded by several state-of-the-art linguistic parsers. Our approach is to measure the impact of these nonisomorphic dependency structures to be used for string-to-dependency translation. Besides using traditional dependency parsers, we also use the dependency structures transformed from PCFG trees and predicate-argument structures (PASs) which are generated by an HPSG parser and a CCG parser. The experiments on Chinese-to-English translation show that the HPSG parser’s PASs achieved the best dependency and translation accuracies. 1</p><p>4 0.77121675 <a title="131-lda-4" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>Author: Ioannis Konstas ; Mirella Lapata</p><p>Abstract: This paper proposes a data-driven method for concept-to-text generation, the task of automatically producing textual output from non-linguistic input. A key insight in our approach is to reduce the tasks of content selection (“what to say”) and surface realization (“how to say”) into a common parsing problem. We define a probabilistic context-free grammar that describes the structure of the input (a corpus of database records and text describing some of them) and represent it compactly as a weighted hypergraph. The hypergraph structure encodes exponentially many derivations, which we rerank discriminatively using local and global features. We propose a novel decoding algorithm for finding the best scoring derivation and generating in this setting. Experimental evaluation on the ATIS domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study.</p><p>5 0.76833194 <a title="131-lda-5" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>Author: Tong Xiao ; Jingbo Zhu ; Hao Zhang ; Qiang Li</p><p>Abstract: We present a new open source toolkit for phrase-based and syntax-based machine translation. The toolkit supports several state-of-the-art models developed in statistical machine translation, including the phrase-based model, the hierachical phrase-based model, and various syntaxbased models. The key innovation provided by the toolkit is that the decoder can work with various grammars and offers different choices of decoding algrithms, such as phrase-based decoding, decoding as parsing/tree-parsing and forest-based decoding. Moreover, several useful utilities were distributed with the toolkit, including a discriminative reordering model, a simple and fast language model, and an implementation of minimum error rate training for weight tuning. 1</p><p>6 0.74141496 <a title="131-lda-6" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>7 0.73299122 <a title="131-lda-7" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>8 0.72298217 <a title="131-lda-8" href="./acl-2012-Translation_Model_Size_Reduction_for_Hierarchical_Phrase-based_Statistical_Machine_Translation.html">204 acl-2012-Translation Model Size Reduction for Hierarchical Phrase-based Statistical Machine Translation</a></p>
<p>9 0.71994352 <a title="131-lda-9" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>10 0.71523488 <a title="131-lda-10" href="./acl-2012-Modeling_the_Translation_of_Predicate-Argument_Structure_for_SMT.html">147 acl-2012-Modeling the Translation of Predicate-Argument Structure for SMT</a></p>
<p>11 0.70862478 <a title="131-lda-11" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>12 0.70354825 <a title="131-lda-12" href="./acl-2012-Robust_Conversion_of_CCG_Derivations_to_Phrase_Structure_Trees.html">170 acl-2012-Robust Conversion of CCG Derivations to Phrase Structure Trees</a></p>
<p>13 0.70125675 <a title="131-lda-13" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>14 0.69998056 <a title="131-lda-14" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>15 0.69472855 <a title="131-lda-15" href="./acl-2012-Improve_SMT_Quality_with_Automatically_Extracted_Paraphrase_Rules.html">116 acl-2012-Improve SMT Quality with Automatically Extracted Paraphrase Rules</a></p>
<p>16 0.68812001 <a title="131-lda-16" href="./acl-2012-Character-Level_Machine_Translation_Evaluation_for_Languages_with_Ambiguous_Word_Boundaries.html">46 acl-2012-Character-Level Machine Translation Evaluation for Languages with Ambiguous Word Boundaries</a></p>
<p>17 0.68629271 <a title="131-lda-17" href="./acl-2012-Joint_Learning_of_a_Dual_SMT_System_for_Paraphrase_Generation.html">125 acl-2012-Joint Learning of a Dual SMT System for Paraphrase Generation</a></p>
<p>18 0.6828714 <a title="131-lda-18" href="./acl-2012-A_Ranking-based_Approach_to_Word_Reordering_for_Statistical_Machine_Translation.html">19 acl-2012-A Ranking-based Approach to Word Reordering for Statistical Machine Translation</a></p>
<p>19 0.68209338 <a title="131-lda-19" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>20 0.6816895 <a title="131-lda-20" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
