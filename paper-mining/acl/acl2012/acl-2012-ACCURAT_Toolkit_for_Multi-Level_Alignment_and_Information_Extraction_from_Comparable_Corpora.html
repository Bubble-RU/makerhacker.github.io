<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-1" href="#">acl2012-1</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</h1>
<br/><p>Source: <a title="acl-2012-1-pdf" href="http://aclweb.org/anthology//P/P12/P12-3016.pdf">pdf</a></p><p>Author: Marcis Pinnis ; Radu Ion ; Dan Stefanescu ; Fangzhong Su ; Inguna Skadina ; Andrejs Vasiljevs ; Bogdan Babych</p><p>Abstract: The lack of parallel corpora and linguistic resources for many languages and domains is one of the major obstacles for the further advancement of automated translation. A possible solution is to exploit comparable corpora (non-parallel bi- or multi-lingual text resources) which are much more widely available than parallel translation data. Our presented toolkit deals with parallel content extraction from comparable corpora. It consists of tools bundled in two workflows: (1) alignment of comparable documents and extraction of parallel sentences and (2) extraction and bilingual mapping of terms and named entities. The toolkit pairs similar bilingual comparable documents and extracts parallel sentences and bilingual terminological and named entity dictionaries from comparable corpora. This demonstration focuses on the English, Latvian, Lithuanian, and Romanian languages.</p><p>Reference: <a title="acl-2012-1-reference" href="../acl2012_reference/acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 lv  ,  ,  2Research Institute for Artificial Intelligence, Romanian Academy { radu dan st e f } @ racai . [sent-4, score-0.086]
</p><p>2 uk  ,  Abstract The lack of parallel corpora and linguistic resources for many languages and domains is one of the major obstacles for the further advancement of automated translation. [sent-9, score-0.576]
</p><p>3 A possible solution is to exploit comparable corpora (non-parallel bi- or multi-lingual text resources) which are much more widely available than parallel translation data. [sent-10, score-0.802]
</p><p>4 Our presented toolkit deals with parallel content extraction from comparable corpora. [sent-11, score-0.739]
</p><p>5 It consists of tools bundled in two workflows: (1) alignment of comparable documents and extraction of parallel sentences and (2) extraction and bilingual mapping of terms and named entities. [sent-12, score-1.157]
</p><p>6 The toolkit pairs similar bilingual comparable documents and extracts parallel sentences and bilingual terminological and named entity dictionaries from comparable  corpora. [sent-13, score-1.366]
</p><p>7 Introduction In recent decades, data-driven approaches have significantly advanced the development of machine translation (MT). [sent-15, score-0.126]
</p><p>8 However, lack of sufficient bilingual linguistic resources for many languages and domains is still one of the major obstacles for further advancement of automated translation. [sent-16, score-0.255]
</p><p>9 , non-parallel bi- or multilingual text resources such as daily news articles and large knowledge 91 bases like Wikipedia, are much more widely available than parallel translation data. [sent-19, score-0.427]
</p><p>10 While methods for the use of parallel corpora in machine translation are well studied (Koehn, 2010), similar techniques for comparable corpora have not been thoroughly worked out. [sent-20, score-0.969]
</p><p>11 Only the latest research has shown that language pairs and domains with little parallel data can benefit from the exploitation of comparable corpora (Munteanu  and Marcu, 2005; Lu et al. [sent-21, score-0.744]
</p><p>12 In this paper we present the ACCURAT toolkit1 - a collection of tools that are capable of analysing comparable corpora and extracting parallel data which can be used to improve the performance of statistical and rule/example-based MT systems. [sent-24, score-0.783]
</p><p>13 Although the toolkit may be used for parallel data acquisition for open (broad) domain systems, it will be most beneficial for under-resourced languages or specific domains which are not covered by available parallel resources. [sent-25, score-0.651]
</p><p>14 The ACCURAT toolkit produces:  comparable document pairs with comparability scores, allowing to estimate the overall comparability of corpora;  parallel sentences which can be used as additional parallel data sources for statistical translation model learning; 1 http://www. [sent-26, score-2.185]
</p><p>15 c s 2o0c1ia2ti Aosns fo cria Ctio nm fpourta Ctoiomnpault Laitniognuaislt Licisn,g puaigsteiscs 91–96,   terminology dictionaries  ―  this type of  data is expected to improve domaindependent translation;  named entity dictionaries. [sent-30, score-0.323]
</p><p>16 The demonstration showcases two general use case scenarios defined in the toolkit: “parallel data mining from comparable corpora” and “named entity/terminology extraction and mapping from comparable corpora”. [sent-31, score-0.749]
</p><p>17 The next section provides a general overview of workflows followed by descriptions of methods and tools integrated in the workflows. [sent-32, score-0.264]
</p><p>18 1  Overview of the Workflows  The toolkit’s tools are integrated workflows (visualised in Figure 1). [sent-33, score-0.264]
</p><p>19 The workflow for parallel data mining from comparable corpora aligns comparable corpora in the document level (section 2. [sent-36, score-1.298]
</p><p>20 To minimise search space, documents are aligned with possible candidates that are likely  to contain parallel data. [sent-39, score-0.349]
</p><p>21 Then parallel sentence pairs are extracted from the aligned comparable corpora (section 2. [sent-40, score-0.797]
</p><p>22 The workflow for named entity (NE) and terminology extraction and mapping from comparable corpora extracts data in a dictionarylike format. [sent-42, score-0.968]
</p><p>23 Providing a list of document pairs, the workflow tags NEs or terms in all documents using 92 language specific taggers (named entity recognisers (NER) or term extractors) and performs multi-lingual NE (section 2. [sent-43, score-0.378]
</p><p>24 The workflow also accepts pre-processed documents, thus skipping the tagging process. [sent-46, score-0.108]
</p><p>25 Since all tools use command line interfaces, task automation and workflow specification can be done with simple console/terminal scripts. [sent-47, score-0.215]
</p><p>26 All tools can be run on the Windows operating system (some are also platform independent). [sent-48, score-0.107]
</p><p>27 2  Tools and Methods  This section provides an overview  of the main  tools and methods in the toolkit. [sent-49, score-0.107]
</p><p>28 1 Comparability Metrics We define comparability by how useful a pair of documents is for parallel data extraction. [sent-54, score-0.867]
</p><p>29 The higher the comparability score, the more likely two documents contain more overlapping parallel data. [sent-55, score-0.841]
</p><p>30 The methods are developed to perform lightweight comparability estimation that minimises search space of relatively large corpora (e. [sent-56, score-0.748]
</p><p>31 There are two comparability metric tools in the toolkit: a translation based and a dictionary based metric. [sent-59, score-0.861]
</p><p>32 The Translation based metric (Su and Babych, 2012a) uses MT APIs for document translation into English. [sent-60, score-0.245]
</p><p>33 Then four independent similarity feature functions are applied to a document pair:  Lexical feature both documents are preprocessed (tokenised, lemmatised, and stop-words are filtered) and then vectorised. [sent-61, score-0.251]
</p><p>34 The lexical overlap score is calculated as a cosine similarity function over the vectors of two documents. [sent-62, score-0.153]
</p><p>35  Structural feature the difference of sentence counts and content word counts ―  ―  (equally interpolated). [sent-63, score-0.093]
</p><p>36  Keyword feature the cosine similarity of top 20 keywords. [sent-64, score-0.088]
</p><p>37  NE feature the cosine similarity of NEs (extracted using Stanford NER). [sent-65, score-0.088]
</p><p>38 These similarity measures are linearly combined in a final comparability score. [sent-66, score-0.572]
</p><p>39 This is implemented by a simple weighted average strategy, in which each type of feature is associated with a weight indicating its relative confidence or importance. [sent-67, score-0.063]
</p><p>40 The comparability scores are normalised on a scale of 0 to 1, where a higher comparability score indicates a higher comparability level. [sent-68, score-1.674]
</p><p>41 The reliability of the proposed metric has been evaluated on a gold standard of comparable corpora for 11 language pairs (Skadiņa et al. [sent-69, score-0.545]
</p><p>42 Document pairs in the gold standard were rated by human judges as being parallel, strongly comparable, or weakly comparable. [sent-72, score-0.062]
</p><p>43 The evaluation results suggest that the comparability scores reliably reflect comparability levels. [sent-73, score-1.106]
</p><p>44 In addition, there is a strong correlation between human defined comparability levels and the confidence scores derived from the ―  ―  comparability metric, as the Pearson R correlation scores vary between 0. [sent-74, score-1.241]
</p><p>45 The Dictionary based metric (Su and Babych, 2012b) is a lightweight approach, which uses bilingual dictionaries to lexically map documents from one language to another. [sent-77, score-0.339]
</p><p>46 The dictionaries are automatically generated via word alignment using GIZA++ (Och and Ney, 2000) on parallel corpora. [sent-78, score-0.379]
</p><p>47 For each word in the source language, the top two translation candidates (based on the word alignment probability in GIZA++) are retrieved as possible translations into the target language. [sent-79, score-0.267]
</p><p>48 This metric provides a much faster lexical translation process, although word-for-word lexical mapping produces less reliable translations than MT based translations. [sent-80, score-0.368]
</p><p>49 Moreover, the lower quality of text translation in the dictionary based metric does not necessarily degrade its performance in predicting comparability levels of comparable document pairs. [sent-81, score-1.124]
</p><p>50 999) between human defined comparability levels and the confidence scores of the metric. [sent-84, score-0.625]
</p><p>51 2  Parallel  Sentence  Extractor  from  Comparable Corpora Phrase-based statistical translation models are among the most successful translation models that currently exist (Callison-Burch et al. [sent-86, score-0.252]
</p><p>52 Usually, phrases are extracted from parallel corpora by means of symmetrical word alignment 93 and/or by phrase generation (Koehn et al. [sent-88, score-0.468]
</p><p>53 Our toolkit exploits comparable corpora in order to find and extract comparable sentences for SMT training using a tool named LEXACC (Ştefănescu et al. [sent-90, score-0.936]
</p><p>54 LEXACC requires aligned document pairs (also m to n alignments) for sentence extraction. [sent-92, score-0.196]
</p><p>55 It also allows extraction from comparable corpora as a whole; however, precision may decrease due to larger search space. [sent-93, score-0.518]
</p><p>56 LEXACC scores sentence pairs according to five lexical overlap and structural matching feature functions. [sent-94, score-0.19]
</p><p>57 Therefore, the weights are trained on parallel corpora (in our case - 10,000 pairs). [sent-99, score-0.404]
</p><p>58 LEXACC does not score every sentence pair in the Cartesian product between source and target  document sentences. [sent-100, score-0.188]
</p><p>59 The first step makes use of the Cross-Language Information Retrieval framework and uses a search engine to find sentences in the target corpus that are the most probable translations of a given sentence. [sent-103, score-0.077]
</p><p>60 To work for a certain language pair, LEXACC needs additional resources: (i) a GIZA++-like translation dictionary, (ii) lists of stop-words in both languages, and (iii) lists of word suffixes in both languages (used for stemming). [sent-105, score-0.153]
</p><p>61 The performance of LEXACC, regarding precision and recall, can be controlled by a threshold applied to the overall interpolated parallelism score. [sent-106, score-0.075]
</p><p>62 The tool has been evaluated on news article comparable corpora. [sent-107, score-0.33]
</p><p>63 Table 1 shows results achieved by LEXACC with different parallelism thresholds on automatically crawled English-Latvian corpora, consisting of 41,914 unique English sentences and 10,058 unique Latvian sentences. [sent-108, score-0.091]
</p><p>64 English-Latvian parallel sentence extraction results on a comparable news corpus. [sent-110, score-0.651]
</p><p>65 English-Romanian parallel sentence extraction results on a comparable news corpus. [sent-112, score-0.651]
</p><p>66 94 Table 2 shows results for English-Romanian on corpora consisting of 3 10,740 unique English and 8 1,433 unique Romanian sentences. [sent-113, score-0.217]
</p><p>67 Useful pairs denote the total number of parallel and strongly comparable sentence pairs (at least 80% of the source sentence is a translation in the target sentence). [sent-114, score-0.805]
</p><p>68 The corpora size is given only as an indicative figure, as the amount of extracted parallel data greatly depends on the comparability  of the corpora. [sent-115, score-0.944]
</p><p>69 3 Named Entity Extraction and Mapping The second workflow of the toolkit allows NE and terminology extraction and mapping. [sent-117, score-0.433]
</p><p>70 Starting with named entity recognition, the toolkit features the first NER systems for Latvian and Lithuanian (Pinnis, 2012). [sent-118, score-0.239]
</p><p>71 In order to map named entities, documents have to be tagged with NER systems that support MUC-7 format NE SGML tags. [sent-120, score-0.202]
</p><p>72 The mapper requires comparable corpora aligned in the document level as input. [sent-122, score-0.639]
</p><p>73 NERA2 compares each NE from the source language to each NE from the target language using cognate based methods. [sent-123, score-0.069]
</p><p>74 It also uses a GIZA++ format statistical dictionary to map NEs containing common nouns that are frequent in location names. [sent-124, score-0.107]
</p><p>75 This approach allows frequent NE mapping if the cognate based method fails, therefore, allowing increasing the recall of the mapper. [sent-125, score-0.142]
</p><p>76 Precision and recall can be tuned with a confidence score threshold. [sent-126, score-0.064]
</p><p>77 4  Terminology Mapping  During recent years, automatic bilingual term mapping in comparable corpora has received greater attention in light of the scarcity of parallel data for under-resourced languages. [sent-128, score-0.916]
</p><p>78 Symbolic, statistical, and hybrid techniques have been implemented for bilingual lexicon extraction (Morin and Prochasson, 201 1). [sent-132, score-0.192]
</p><p>79 Our terminology mapper is designed to map terms extracted from comparable or parallel  2 Open NLP - http://incubator. [sent-133, score-0.741]
</p><p>80 The method is language independent and can be applied if a translation equivalents table exists for a language pair. [sent-137, score-0.171]
</p><p>81 As input, the application requires term-tagged bilingual corpora aligned in the document level. [sent-138, score-0.373]
</p><p>82 The toolkit includes term-tagging tools for English, Latvian, Lithuanian, and Romanian, but can be easily extended for other languages if a POS-tagger, a phrase pattern list, a stop-word list, and an inverse document frequency list (calculated  on balanced corpora) are available. [sent-139, score-0.329]
</p><p>83 , 2012; Ştefănescu, 2012): (i) a GIZA++-like translation equivalents table and (ii) string similarity in terms of Levenshtein distance between term candidates. [sent-141, score-0.263]
</p><p>84 Tables 4 and 5 show the performance figures of the mapper for English-Romanian and English-Latvian. [sent-144, score-0.077]
</p><p>85 3  Conclusions and Related Information  This demonstration paper describes the ACCURAT toolkit containing tools for multi-level alignment and information extraction from comparable corpora. [sent-157, score-0.671]
</p><p>86 These tools are integrated in predefined workflows that are ready for immediate 95 use. [sent-158, score-0.264]
</p><p>87 The workflows provide functionality for the extraction of parallel sentences, bilingual NE dictionaries, and bilingual term dictionaries from comparable corpora. [sent-159, score-1.049]
</p><p>88 The methods, including comparability metrics, parallel sentence extraction and named entity/term mapping, are language independent. [sent-160, score-0.966]
</p><p>89 However, they may require language dependent resources, for instance, POS-taggers, Giza++ translation dictionaries, NERs, term taggers, The ACCURAT toolkit is released under the Apache 2. [sent-161, score-0.306]
</p><p>90 On the use of comparable corpora to improve SMT performance. [sent-166, score-0.439]
</p><p>91 Parallel sentence generation from comparable corpora for  improved SMT. [sent-170, score-0.474]
</p><p>92 Toolkit for multi-level alignment and information extraction from comparable corpora (http://www. [sent-174, score-0.582]
</p><p>93 Building a large English-Chinese parallel corpus from comparable patents and its experimental application to SMT. [sent-218, score-0.509]
</p><p>94 Proceedings of the 3rd workshop on building and using comparable corpora: from parallel to non-parallel corpora, Valletta, Malta, 4248. [sent-219, score-0.509]
</p><p>95 Bilingual lexicon extraction from comparable corpora enhanced with parallel corpora. [sent-226, score-0.755]
</p><p>96 Term extraction, tagging, and mapping tools for under-resourced languages. [sent-234, score-0.204]
</p><p>97 Extracting parallel sentences from comparable corpora using document level alignment. [sent-243, score-0.751]
</p><p>98 Cross-lingual document similarity calculation using the multilingual thesaurus Eurovoc. [sent-251, score-0.107]
</p><p>99 Development and application of a cross-language document comparability metric. [sent-261, score-0.615]
</p><p>100 Measuring comparability of documents in non-parallel corpora for efficient extraction of (semi-) parallel translation equivalents. [sent-265, score-1.213]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('comparability', 0.54), ('comparable', 0.272), ('accurat', 0.257), ('parallel', 0.237), ('lexacc', 0.18), ('corpora', 0.167), ('workflows', 0.157), ('tef', 0.143), ('nescu', 0.128), ('terminology', 0.126), ('translation', 0.126), ('toolkit', 0.12), ('ne', 0.114), ('latvian', 0.112), ('workflow', 0.108), ('tools', 0.107), ('inguna', 0.103), ('mapping', 0.097), ('romanian', 0.095), ('lithuanian', 0.09), ('skadi', 0.09), ('bilingual', 0.083), ('extraction', 0.079), ('dictionaries', 0.078), ('bogdan', 0.077), ('fangzhong', 0.077), ('mapper', 0.077), ('morin', 0.077), ('pinnis', 0.077), ('rcis', 0.077), ('named', 0.075), ('document', 0.075), ('giza', 0.067), ('emmanuel', 0.067), ('documents', 0.064), ('alignment', 0.064), ('term', 0.06), ('istanbul', 0.057), ('nes', 0.057), ('radu', 0.057), ('ner', 0.055), ('translations', 0.053), ('babych', 0.051), ('daille', 0.051), ('sadaf', 0.051), ('steinberger', 0.051), ('aligned', 0.048), ('su', 0.045), ('cognate', 0.045), ('equivalents', 0.045), ('leeds', 0.045), ('dictionary', 0.044), ('entity', 0.044), ('metric', 0.044), ('advancement', 0.041), ('lightweight', 0.041), ('parallelism', 0.041), ('overlap', 0.04), ('pairs', 0.038), ('holger', 0.038), ('obstacles', 0.038), ('resources', 0.036), ('confidence', 0.036), ('munteanu', 0.036), ('sentence', 0.035), ('fung', 0.034), ('interpolated', 0.034), ('format', 0.034), ('similarity', 0.032), ('content', 0.031), ('hybrid', 0.03), ('compositional', 0.03), ('tool', 0.03), ('domains', 0.03), ('koehn', 0.029), ('map', 0.029), ('dan', 0.029), ('cosine', 0.029), ('demonstration', 0.029), ('news', 0.028), ('score', 0.028), ('mt', 0.028), ('languages', 0.027), ('feature', 0.027), ('june', 0.027), ('taggers', 0.027), ('ohio', 0.026), ('pair', 0.026), ('functions', 0.026), ('requirements', 0.026), ('scores', 0.026), ('correlation', 0.025), ('lrec', 0.025), ('unique', 0.025), ('gao', 0.024), ('target', 0.024), ('lexical', 0.024), ('gold', 0.024), ('levels', 0.023), ('och', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999911 <a title="1-tfidf-1" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>Author: Marcis Pinnis ; Radu Ion ; Dan Stefanescu ; Fangzhong Su ; Inguna Skadina ; Andrejs Vasiljevs ; Bogdan Babych</p><p>Abstract: The lack of parallel corpora and linguistic resources for many languages and domains is one of the major obstacles for the further advancement of automated translation. A possible solution is to exploit comparable corpora (non-parallel bi- or multi-lingual text resources) which are much more widely available than parallel translation data. Our presented toolkit deals with parallel content extraction from comparable corpora. It consists of tools bundled in two workflows: (1) alignment of comparable documents and extraction of parallel sentences and (2) extraction and bilingual mapping of terms and named entities. The toolkit pairs similar bilingual comparable documents and extracts parallel sentences and bilingual terminological and named entity dictionaries from comparable corpora. This demonstration focuses on the English, Latvian, Lithuanian, and Romanian languages.</p><p>2 0.1198764 <a title="1-tfidf-2" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>Author: Joseph Z. Chang ; Jason S. Chang ; Roger Jyh-Shing Jang</p><p>Abstract: Jason S. Chang Department of Computer Science, National Tsing Hua University 101, Kuangfu Road, Hsinchu, 300, Taiwan j s chang@ c s .nthu . edu .tw Jyh-Shing Roger Jang Department of Computer Science, National Tsing Hua University 101, Kuangfu Road, Hsinchu, 300, Taiwan j ang@ c s .nthu .edu .tw identifying such translation counterparts Web, we can cope with the OOV problem. In this paper, we present a new method on the for learning to finding translations and transliterations on the Web for a given term. The approach involves using a small set of terms and translations to obtain mixed-code snippets from a search engine, and automatically annotating the snippets with tags and features for training a conditional random field model. At runtime, the model is used to extracting translation candidates for a given term. Preliminary experiments and evaluation show our method cleanly combining various features, resulting in a system that outperforms previous work. 1</p><p>3 0.1077686 <a title="1-tfidf-3" href="./acl-2012-Smaller_Alignment_Models_for_Better_Translations%3A_Unsupervised_Word_Alignment_with_the_l0-norm.html">179 acl-2012-Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the l0-norm</a></p>
<p>Author: Ashish Vaswani ; Liang Huang ; David Chiang</p><p>Abstract: Two decades after their invention, the IBM word-based translation models, widely available in the GIZA++ toolkit, remain the dominant approach to word alignment and an integral part of many statistical translation systems. Although many models have surpassed them in accuracy, none have supplanted them in practice. In this paper, we propose a simple extension to the IBM models: an ‘0 prior to encourage sparsity in the word-to-word translation model. We explain how to implement this extension efficiently for large-scale data (also released as a modification to GIZA++) and demonstrate, in experiments on Czech, Arabic, Chinese, and Urdu to English translation, significant improvements over IBM Model 4 in both word alignment (up to +6.7 F1) and translation quality (up to +1.4 B ).</p><p>4 0.10718023 <a title="1-tfidf-4" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>Author: Graham Neubig ; Taro Watanabe ; Shinsuke Mori ; Tatsuya Kawahara</p><p>Abstract: In this paper, we demonstrate that accurate machine translation is possible without the concept of “words,” treating MT as a problem of transformation between character strings. We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to train a character-based translation model, and using this in the phrase-based MT framework. We also propose a look-ahead parsing algorithm and substring-informed prior probabilities to achieve more effective and efficient alignment. In an evaluation, we demonstrate that character-based translation can achieve results that compare to word-based systems while effectively translating unknown and uncommon words over several language pairs.</p><p>5 0.10590426 <a title="1-tfidf-5" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>Author: Tong Xiao ; Jingbo Zhu ; Hao Zhang ; Qiang Li</p><p>Abstract: We present a new open source toolkit for phrase-based and syntax-based machine translation. The toolkit supports several state-of-the-art models developed in statistical machine translation, including the phrase-based model, the hierachical phrase-based model, and various syntaxbased models. The key innovation provided by the toolkit is that the decoder can work with various grammars and offers different choices of decoding algrithms, such as phrase-based decoding, decoding as parsing/tree-parsing and forest-based decoding. Moreover, several useful utilities were distributed with the toolkit, including a discriminative reordering model, a simple and fast language model, and an implementation of minimum error rate training for weight tuning. 1</p><p>6 0.1048556 <a title="1-tfidf-6" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>7 0.1042814 <a title="1-tfidf-7" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>8 0.10237804 <a title="1-tfidf-8" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>9 0.095006935 <a title="1-tfidf-9" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>10 0.089563027 <a title="1-tfidf-10" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>11 0.08621075 <a title="1-tfidf-11" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>12 0.083209969 <a title="1-tfidf-12" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>13 0.081025809 <a title="1-tfidf-13" href="./acl-2012-Topic_Models_for_Dynamic_Translation_Model_Adaptation.html">199 acl-2012-Topic Models for Dynamic Translation Model Adaptation</a></p>
<p>14 0.078082673 <a title="1-tfidf-14" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>15 0.075960115 <a title="1-tfidf-15" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>16 0.074708074 <a title="1-tfidf-16" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>17 0.072815329 <a title="1-tfidf-17" href="./acl-2012-LetsMT%21%3A_Cloud-Based_Platform_for_Do-It-Yourself_Machine_Translation.html">138 acl-2012-LetsMT!: Cloud-Based Platform for Do-It-Yourself Machine Translation</a></p>
<p>18 0.072748341 <a title="1-tfidf-18" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>19 0.072436817 <a title="1-tfidf-19" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>20 0.071304962 <a title="1-tfidf-20" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.21), (1, -0.092), (2, 0.072), (3, 0.077), (4, 0.096), (5, 0.025), (6, -0.002), (7, -0.002), (8, -0.021), (9, -0.049), (10, 0.05), (11, -0.001), (12, 0.011), (13, 0.04), (14, 0.032), (15, -0.006), (16, 0.008), (17, 0.016), (18, 0.031), (19, 0.038), (20, -0.083), (21, 0.039), (22, 0.103), (23, -0.005), (24, 0.023), (25, 0.031), (26, -0.032), (27, -0.008), (28, 0.024), (29, 0.074), (30, 0.077), (31, 0.009), (32, 0.022), (33, 0.063), (34, -0.078), (35, 0.095), (36, -0.02), (37, -0.02), (38, 0.072), (39, -0.059), (40, 0.012), (41, 0.026), (42, -0.026), (43, -0.063), (44, -0.042), (45, -0.105), (46, -0.067), (47, -0.074), (48, -0.096), (49, 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93368286 <a title="1-lsi-1" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>Author: Marcis Pinnis ; Radu Ion ; Dan Stefanescu ; Fangzhong Su ; Inguna Skadina ; Andrejs Vasiljevs ; Bogdan Babych</p><p>Abstract: The lack of parallel corpora and linguistic resources for many languages and domains is one of the major obstacles for the further advancement of automated translation. A possible solution is to exploit comparable corpora (non-parallel bi- or multi-lingual text resources) which are much more widely available than parallel translation data. Our presented toolkit deals with parallel content extraction from comparable corpora. It consists of tools bundled in two workflows: (1) alignment of comparable documents and extraction of parallel sentences and (2) extraction and bilingual mapping of terms and named entities. The toolkit pairs similar bilingual comparable documents and extracts parallel sentences and bilingual terminological and named entity dictionaries from comparable corpora. This demonstration focuses on the English, Latvian, Lithuanian, and Romanian languages.</p><p>2 0.74039996 <a title="1-lsi-2" href="./acl-2012-LetsMT%21%3A_Cloud-Based_Platform_for_Do-It-Yourself_Machine_Translation.html">138 acl-2012-LetsMT!: Cloud-Based Platform for Do-It-Yourself Machine Translation</a></p>
<p>Author: Andrejs Vasiljevs ; Raivis Skadins ; Jorg Tiedemann</p><p>Abstract: Machine Translation Raivis Skadiņš TILDE Vienbas gatve 75a, Riga LV-1004, LATVIA raivi s . s kadins @ ti lde . lv Jörg Tiedemann Uppsala University Box 635, Uppsala SE-75 126, SWEDEN j org .t iedemann@ l ingfi l .uu . se the Universities of Copenhagen, and Uppsala. Edinburgh, Zagreb, To facilitate the creation and usage of custom SMT systems we have created a cloud-based platform for do-it-yourself MT. The platform is developed in the EU collaboration project LetsMT! . This system demonstration paper presents the motivation in developing the LetsMT! platform, its main features, architecture, and an evaluation in a practical use case. 1</p><p>3 0.66263694 <a title="1-lsi-3" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>Author: Meritxell Gonzalez ; Jesus Gimenez ; Lluis Marquez</p><p>Abstract: Error analysis in machine translation is a necessary step in order to investigate the strengths and weaknesses of the MT systems under development and allow fair comparisons among them. This work presents an application that shows how a set of heterogeneous automatic metrics can be used to evaluate a test bed of automatic translations. To do so, we have set up an online graphical interface for the ASIYA toolkit, a rich repository of evaluation measures working at different linguistic levels. The current implementation of the interface shows constituency and dependency trees as well as shallow syntactic and semantic annotations, and word alignments. The intelligent visualization of the linguistic structures used by the metrics, as well as a set of navigational functionalities, may lead towards advanced methods for automatic error analysis.</p><p>4 0.60904074 <a title="1-lsi-4" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>Author: Lea Frermann ; Francis Bond</p><p>Abstract: We present a system for cross-lingual parse disambiguation, exploiting the assumption that the meaning of a sentence remains unchanged during translation and the fact that different languages have different ambiguities. We simultaneously reduce ambiguity in multiple languages in a fully automatic way. Evaluation shows that the system reliably discards dispreferred parses from the raw parser output, which results in a pre-selection that can speed up manual treebanking.</p><p>5 0.60725045 <a title="1-lsi-5" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>Author: Rafal Rak ; BalaKrishna Kolluru ; Sophia Ananiadou</p><p>Abstract: Argo is a web-based NLP and text mining workbench with a convenient graphical user interface for designing and executing processing workflows of various complexity. The workbench is intended for specialists and nontechnical audiences alike, and provides the ever expanding library of analytics compliant with the Unstructured Information Management Architecture, a widely adopted interoperability framework. We explore the flexibility of this framework by demonstrating workflows involving three processing components capable of performing self-contained machine learning-based tagging. The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated features, and 3) tagging unlabelled data with the model. The learning and tagging components are based on an implementation of conditional random fields (CRF); whereas the feature generation component is an analytic capable of extending basic token information to a comprehensive set of features. Users define the features of their choice directly from Argo’s graphical interface, without resorting to programming (a commonly used approach to feature engineering). The experimental results performed on two tagging tasks, chunking and named entity recognition, showed that a tagger with a generic set of features built in Argo is capable of competing with taskspecific solutions. 121</p><p>6 0.60529608 <a title="1-lsi-6" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>7 0.59745783 <a title="1-lsi-7" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>8 0.57198548 <a title="1-lsi-8" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>9 0.57179385 <a title="1-lsi-9" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>10 0.55622709 <a title="1-lsi-10" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>11 0.5463683 <a title="1-lsi-11" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>12 0.53101677 <a title="1-lsi-12" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>13 0.51615727 <a title="1-lsi-13" href="./acl-2012-Private_Access_to_Phrase_Tables_for_Statistical_Machine_Translation.html">164 acl-2012-Private Access to Phrase Tables for Statistical Machine Translation</a></p>
<p>14 0.51468098 <a title="1-lsi-14" href="./acl-2012-Smaller_Alignment_Models_for_Better_Translations%3A_Unsupervised_Word_Alignment_with_the_l0-norm.html">179 acl-2012-Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the l0-norm</a></p>
<p>15 0.51188904 <a title="1-lsi-15" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>16 0.50457454 <a title="1-lsi-16" href="./acl-2012-Translation_Model_Size_Reduction_for_Hierarchical_Phrase-based_Statistical_Machine_Translation.html">204 acl-2012-Translation Model Size Reduction for Hierarchical Phrase-based Statistical Machine Translation</a></p>
<p>17 0.50364542 <a title="1-lsi-17" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>18 0.50224054 <a title="1-lsi-18" href="./acl-2012-Prediction_of_Learning_Curves_in_Machine_Translation.html">163 acl-2012-Prediction of Learning Curves in Machine Translation</a></p>
<p>19 0.5006243 <a title="1-lsi-19" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>20 0.49851766 <a title="1-lsi-20" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.436), (26, 0.074), (28, 0.05), (30, 0.017), (37, 0.012), (39, 0.036), (74, 0.03), (82, 0.01), (84, 0.014), (85, 0.039), (90, 0.095), (92, 0.033), (94, 0.024), (99, 0.041)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92443025 <a title="1-lda-1" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<p>Author: Nathan Schneider ; Behrang Mohit ; Kemal Oflazer ; Noah A. Smith</p><p>Abstract: “Lightweight” semantic annotation of text calls for a simple representation, ideally without requiring a semantic lexicon to achieve good coverage in the language and domain. In this paper, we repurpose WordNet’s supersense tags for annotation, developing specific guidelines for nominal expressions and applying them to Arabic Wikipedia articles in four topical domains. The resulting corpus has high coverage and was completed quickly with reasonable inter-annotator agreement.</p><p>2 0.89116997 <a title="1-lda-2" href="./acl-2012-Private_Access_to_Phrase_Tables_for_Statistical_Machine_Translation.html">164 acl-2012-Private Access to Phrase Tables for Statistical Machine Translation</a></p>
<p>Author: Nicola Cancedda</p><p>Abstract: Some Statistical Machine Translation systems never see the light because the owner of the appropriate training data cannot release them, and the potential user ofthe system cannot disclose what should be translated. We propose a simple and practical encryption-based method addressing this barrier.</p><p>same-paper 3 0.82773185 <a title="1-lda-3" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>Author: Marcis Pinnis ; Radu Ion ; Dan Stefanescu ; Fangzhong Su ; Inguna Skadina ; Andrejs Vasiljevs ; Bogdan Babych</p><p>Abstract: The lack of parallel corpora and linguistic resources for many languages and domains is one of the major obstacles for the further advancement of automated translation. A possible solution is to exploit comparable corpora (non-parallel bi- or multi-lingual text resources) which are much more widely available than parallel translation data. Our presented toolkit deals with parallel content extraction from comparable corpora. It consists of tools bundled in two workflows: (1) alignment of comparable documents and extraction of parallel sentences and (2) extraction and bilingual mapping of terms and named entities. The toolkit pairs similar bilingual comparable documents and extracts parallel sentences and bilingual terminological and named entity dictionaries from comparable corpora. This demonstration focuses on the English, Latvian, Lithuanian, and Romanian languages.</p><p>4 0.65883338 <a title="1-lda-4" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>Author: Geoffrey Zweig ; John C. Platt ; Christopher Meek ; Christopher J.C. Burges ; Ainur Yessenalina ; Qiang Liu</p><p>Abstract: This paper studies the problem of sentencelevel semantic coherence by answering SATstyle sentence completion questions. These questions test the ability of algorithms to distinguish sense from nonsense based on a variety of sentence-level phenomena. We tackle the problem with two approaches: methods that use local lexical information, such as the n-grams of a classical language model; and methods that evaluate global coherence, such as latent semantic analysis. We evaluate these methods on a suite of practice SAT questions, and on a recently released sentence completion task based on data taken from five Conan Doyle novels. We find that by fusing local and global information, we can exceed 50% on this task (chance baseline is 20%), and we suggest some avenues for further research.</p><p>5 0.41268456 <a title="1-lda-5" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>6 0.41063166 <a title="1-lda-6" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>7 0.39202386 <a title="1-lda-7" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>8 0.39134488 <a title="1-lda-8" href="./acl-2012-LetsMT%21%3A_Cloud-Based_Platform_for_Do-It-Yourself_Machine_Translation.html">138 acl-2012-LetsMT!: Cloud-Based Platform for Do-It-Yourself Machine Translation</a></p>
<p>9 0.38494465 <a title="1-lda-9" href="./acl-2012-Detecting_Semantic_Equivalence_and_Information_Disparity_in_Cross-lingual_Documents.html">72 acl-2012-Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents</a></p>
<p>10 0.38050354 <a title="1-lda-10" href="./acl-2012-Multilingual_WSD_with_Just_a_Few_Lines_of_Code%3A_the_BabelNet_API.html">152 acl-2012-Multilingual WSD with Just a Few Lines of Code: the BabelNet API</a></p>
<p>11 0.37859398 <a title="1-lda-11" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>12 0.37783036 <a title="1-lda-12" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>13 0.37661347 <a title="1-lda-13" href="./acl-2012-Combining_Coherence_Models_and_Machine_Translation_Evaluation_Metrics_for_Summarization_Evaluation.html">52 acl-2012-Combining Coherence Models and Machine Translation Evaluation Metrics for Summarization Evaluation</a></p>
<p>14 0.37394351 <a title="1-lda-14" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>15 0.37388945 <a title="1-lda-15" href="./acl-2012-BIUTEE%3A_A_Modular_Open-Source_System_for_Recognizing_Textual_Entailment.html">36 acl-2012-BIUTEE: A Modular Open-Source System for Recognizing Textual Entailment</a></p>
<p>16 0.37103611 <a title="1-lda-16" href="./acl-2012-Transforming_Standard_Arabic_to_Colloquial_Arabic.html">202 acl-2012-Transforming Standard Arabic to Colloquial Arabic</a></p>
<p>17 0.36911526 <a title="1-lda-17" href="./acl-2012-PDTB-style_Discourse_Annotation_of_Chinese_Text.html">157 acl-2012-PDTB-style Discourse Annotation of Chinese Text</a></p>
<p>18 0.3668412 <a title="1-lda-18" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>19 0.3650161 <a title="1-lda-19" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>20 0.36339217 <a title="1-lda-20" href="./acl-2012-Collective_Classification_for_Fine-grained_Information_Status.html">50 acl-2012-Collective Classification for Fine-grained Information Status</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
