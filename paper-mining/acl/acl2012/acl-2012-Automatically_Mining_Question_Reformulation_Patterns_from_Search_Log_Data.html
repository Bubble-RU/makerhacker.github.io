<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-35" href="#">acl2012-35</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</h1>
<br/><p>Source: <a title="acl-2012-35-pdf" href="http://aclweb.org/anthology//P/P12/P12-2037.pdf">pdf</a></p><p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>Reference: <a title="acl-2012-35-reference" href="../acl2012_reference/acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  ,  Abstract Natural language questions have become popular in web search. [sent-7, score-0.147]
</p><p>2 However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. [sent-8, score-0.243]
</p><p>3 In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. [sent-9, score-1.223]
</p><p>4 The question reformulations generated from these patterns are further incorporated into the retrieval model. [sent-10, score-0.899]
</p><p>5 Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions. [sent-11, score-1.116]
</p><p>6 1 Introduction More and more web users tend to use natural language questions as queries for web search. [sent-12, score-0.292]
</p><p>7 Some commercial natural language search engines such as  InQuira and Ask have also been developed to answer this type of queries. [sent-13, score-0.108]
</p><p>8 One major challenge is that various questions can be formulated for the same information need. [sent-14, score-0.111]
</p><p>9 Table 1shows some alternative expressions for the question “how far is it from Boston to Seattle”. [sent-15, score-0.394]
</p><p>10 It is difficult for search systems to achieve satisfactory retrieval performance without considering these alternative expressions. [sent-16, score-0.164]
</p><p>11 In this paper, we propose a method of automatically mining 5w1h question1 reformulation patterns to improve the search relevance of 5w1h questions. [sent-17, score-0.871]
</p><p>12 Question reformulations represent the alternative expressions for 5w1h questions. [sent-18, score-0.498]
</p><p>13 A question ∗Contribution during internship at Microsoft Research Asia 15w1h questions start with “Who”, “What”, “Where”, “When”, “Why” and “How”. [sent-19, score-0.367]
</p><p>14 For example, users may ask similar questions “how far is it from X1 to X2” where X1 and X2 represent some other cities besides Boston and Seattle. [sent-21, score-0.156]
</p><p>15 Then, similar question reformulations as in Table 1will be generated with the city names changed. [sent-22, score-0.701]
</p><p>16 These patterns increase the coverage of the system by handling the queries that did not appear before but share similar structures as previous queries. [sent-23, score-0.227]
</p><p>17 Using reformulation patterns as the key concept, we propose a question reformulation framework. [sent-24, score-1.67]
</p><p>18 First, we mine the question reformulation patterns from search logs that record users’ reformulation behavior. [sent-25, score-1.832]
</p><p>19 Second, given a new question, we use the most relevant reformulation patterns to generate question reformulations and each of the reformulations is associated with its probability. [sent-26, score-1.891]
</p><p>20 Third, the original question and these question reformulations are then combined together for retrieval. [sent-27, score-1.03]
</p><p>21 First, we propose a simple yet effective  approach to automatically mine 5w1h question reformulation patterns. [sent-29, score-0.953]
</p><p>22 Second, we conduct comprehensive studies in improving the search performance of 5w1h questions using the mined patterns. [sent-30, score-0.189]
</p><p>23 2  Related Work  In the Natural Language Processing (NLP) area, different expressions that convey the same meaning are referred as paraphrases (Lin and Pantel, 2001 ; Barzilay and McKeown, 2001 ; Pang et al. [sent-34, score-0.143]
</p><p>24 , 2006), question answering (Ravichandran and Hovy, 2002) and document summarization (McKeown et al. [sent-38, score-0.277]
</p><p>25 Yet, little research has considered improving web search performance using paraphrases. [sent-40, score-0.13]
</p><p>26 Query logs have become an important resource for many NLP applications such as class and attribute extraction (Pa ¸sca and Van Durme, 2008), paraphrasing (Zhao et al. [sent-41, score-0.093]
</p><p>27 Little research has been conducted to automatically mine 5w1h question reformulation patterns from query logs. [sent-44, score-1.303]
</p><p>28 Different techniques have been developed for query segmentation (Bergsma and Wang, 2007; Tan and Peng, 2008) and query substitution (Jones et al. [sent-48, score-0.422]
</p><p>29 Yet, most previous research focused on keyword queries without considering 5w1h questions. [sent-50, score-0.088]
</p><p>30 188 Table 2: Question reformulation patterns generated for the query pair (“how far is it from Boston to Seattle” ,“distance from Boston to Seattle”). [sent-53, score-1.02]
</p><p>31 1 Generating Reformulation Patterns From the search log, we extract all successive query pairs issued by the same user within a certain time period where the first query is a 5w1h question. [sent-55, score-0.594]
</p><p>32 In such query pair, the second query is considered as a question reformulation. [sent-56, score-0.699]
</p><p>33 Set = {(q, qr)}, as the input and outputs a pattern Sbaetse = consisting o, fa s5 wth1eh i question  reformulation patterns, i. [sent-59, score-0.952]
</p><p>34 Specifically, fuolra teioanch p query pair (q, qr), we fpirs)t} c). [sent-62, score-0.211]
</p><p>35 ol Slepcetc aifllcommon words between q and qr except for stopwords ST2, where CW = {w|w ∈ q, w ∈ q′, w ∈/ ST}. [sent-63, score-0.096]
</p><p>36 s in Si are replaced as slots in q and qr to construct a reformulation pattern. [sent-65, score-0.696]
</p><p>37 Finally, the patterns observed in many different query pairs are kept. [sent-67, score-0.35]
</p><p>38 In other words, we rely on the frequency of a pattern to filter noisy patterns. [sent-68, score-0.048]
</p><p>39 Generating patterns using more NLP features such as the parsing information will be studied in the future work. [sent-69, score-0.164]
</p><p>40 We select the pattern that has the most prefix words, since this pattern is more likely to have the same information as If sev-  qnew. [sent-72, score-0.126]
</p><p>41 eral patterns have the same number of prefix words, we use the total number of words to break the tie. [sent-75, score-0.169]
</p><p>42 After picking the best question pattern p⋆, we further rank all question reformulation patterns containing p⋆, i. [sent-76, score-1.412]
</p><p>43 The probability P(pr |p⋆) associated with the pattern (p⋆, pr) is assigned to the corresponding question reformulation  qrnew  qrnew. [sent-82, score-1.045]
</p><p>44 3 Retrieval Model Given the original question and k question reformulations {qrnew}, the query distribution model (Xue ualandti Croft, 2010) (denoted as QDist) i os adopted  qnew  qnew  to combine and {qrnew} using their associated probabilities. [sent-84, score-1.519]
</p><p>45 score(qnew, D), is calculated as follows: score(qnew, D) = λ log P(qnew|D) Xk  +(1 − λ)XP(pri|p⋆)logP(qrniew|D)  (2)  Xi=1  In Eq. [sent-87, score-0.055]
</p><p>46 2, λ is a parameter that indicates the probability assigned to the original query. [sent-88, score-0.052]
</p><p>47 4  Experiments  A large scale search log from a commercial search engine (201 1. [sent-91, score-0.289]
</p><p>48 From the search log, we extract all successive query pairs issued by the same user within 30 minutes (Boldi et al. [sent-94, score-0.405]
</p><p>49 , 2008)3 where the first query is a 5w1h question. [sent-95, score-0.211]
</p><p>50 For the retrieval experiments, we randomly sample 10,000 natural language questions as queries 3In web search, queries issued within 30 minutes  are  usually  considered having the  same  information need. [sent-97, score-0.477]
</p><p>51 189 Table 4: Retrieval Performance of using question reformulations. [sent-98, score-0.277]
</p><p>52 For each question, we generate the top ten questions reformulations. [sent-104, score-0.121]
</p><p>53 A web collection from a commercial search engine is used for retrieval experiments. [sent-106, score-0.251]
</p><p>54 1 Examples and Performance Table 3 shows examples of the generated questions reformulations. [sent-110, score-0.09]
</p><p>55 Several interesting expressions are generated to reformulate the original question. [sent-111, score-0.094]
</p><p>56 We compare the retrieval performance of using the question reformulations (QDist) with the performance of using the original question (Orig) in Table 4. [sent-112, score-1.089]
</p><p>57 Table 4 shows that using the question reformulations can significantly improve the retrieval performance ofnatural language questions. [sent-115, score-0.76]
</p><p>58 Note that, considering the scale of experiments (10,000 queries), around 3% improvement with respect to NDCG is a very interesting result for web search. [sent-116, score-0.083]
</p><p>59 2 Analysis In this subsection, we analyze the results to better understand the effect of question reformulations. [sent-118, score-0.277]
</p><p>60 First, we report the performance of always picking the best question reformulation for each query (denoted as Upper) in Table 5, which provides an 4www . [sent-119, score-1.159]
</p><p>61 3D 2059C689G741@5  Table 6: Best reformulation within different positions. [sent-125, score-0.648]
</p><p>62 t4h%in top 3  upper bound for the performance of the question reformulation. [sent-129, score-0.331]
</p><p>63 Table 5 shows that if we were able to always picking the best question reformulation, the performance of Orig could be improved by around 30% (from 0. [sent-130, score-0.321]
</p><p>64 It indicates that we do generate some high quality question reformulations. [sent-133, score-0.277]
</p><p>65 Table 6 further reports the percent of those 10,000 queries where the best question reformulation can be observed in the top 1position, within the top 2 positions and within the top 3 positions, respectively. [sent-134, score-1.154]
</p><p>66 Table 6 shows that for most queries, our method successfully ranks the best reformulation within the top 3 positions. [sent-135, score-0.679]
</p><p>67 Second, we study the effect of different types of question reformulations. [sent-136, score-0.277]
</p><p>68 We roughly divide the question reformulations generated by our method into five categories as shown in Table 7. [sent-137, score-0.701]
</p><p>69 For each category, we report the percent of reformulations which performance is bigger/smaller/equal with respect to the original question. [sent-138, score-0.503]
</p><p>70 Table 7 shows that the “more specific” reformulations and the “equivalent” reformulations are more likely to improve the original question. [sent-139, score-0.9]
</p><p>71 Reformu-  lations that make “morphological change” do not have much effect on improving the original question. [sent-140, score-0.052]
</p><p>72 “More general” and “not relevant” reformulations usually decrease the performance. [sent-141, score-0.424]
</p><p>73 Third, we conduct the error analysis on the question reformulations that decrease the performance of the original question. [sent-142, score-0.753]
</p><p>74 First, some important words are removed from the original question. [sent-144, score-0.052]
</p><p>75 For example, “what is the role ofcorporate executives” is reformulated as “corporate executives”. [sent-145, score-0.055]
</p><p>76 For example, “how to effectively organize your classroom” is reformulated as “how to effectively organize your elementary classroom”. [sent-147, score-0.123]
</p><p>77 Third, some reformulations entirely change 190 Table 7: Analysis of different types of reformulations. [sent-148, score-0.424]
</p><p>78 For example, “what is the adjective of anxiously” is reformulated as “what is the noun of anxiously”. [sent-154, score-0.055]
</p><p>79 Fourth, we compare our question reformulation method with two long query processing techniques, i. [sent-155, score-1.115]
</p><p>80 NoStop removes all stopwords in the query and DropOne learns to drop a single word from the query. [sent-159, score-0.238]
</p><p>81 Table 8 reports the retrieval performance of different methods. [sent-162, score-0.059]
</p><p>82 Table 8 shows that both NoStop and DropOne perform worse than using the original question, which indicates that the general techniques developed for long queries are not appropriate for natural language questions. [sent-163, score-0.14]
</p><p>83 5  Conclusion  Improving the search relevance of natural language questions poses a great challenge for search systems. [sent-165, score-0.299]
</p><p>84 We propose to automatically mine 5w1h question reformulation patterns from search log data. [sent-166, score-1.22]
</p><p>85 The effectiveness of the extracted patterns has been shown on web search. [sent-167, score-0.196]
</p><p>86 These patterns are potentially useful for many other applications, which will be studied in the future work. [sent-168, score-0.164]
</p><p>87 How to automatically classify the extracted patterns is also an interesting future issue. [sent-169, score-0.139]
</p><p>88 In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pages 571–578. [sent-179, score-0.043]
</p><p>89 In Proceedings of the 43rd Annual Meeting on Association for Compu-  tational Linguistics, pages 597–604. [sent-186, score-0.043]
</p><p>90 In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, pages 50–57. [sent-194, score-0.043]
</p><p>91 Large scale acquisition of paraphrases for learning surface patterns. [sent-207, score-0.121]
</p><p>92 From “Dango” to “Japanese Cakes”: Query reformulation models and patterns. [sent-219, score-0.627]
</p><p>93 IEEE/WIC/ACM International Joint Conferences on, volume 1, pages 183–190. [sent-222, score-0.043]
</p><p>94 Exploring web scale language models for search query processing. [sent-241, score-0.367]
</p><p>95 Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. [sent-302, score-0.095]
</p><p>96 Weakly-supervised acquisition of open-domain classes and class attributes from web documents and query logs. [sent-315, score-0.29]
</p><p>97 Learning surface text patterns for a question answering system. [sent-329, score-0.416]
</p><p>98 Unsupervised query segmentation using generative language models and Wikipedia. [sent-335, score-0.211]
</p><p>99 Mining term association patterns from search logs for effective query reformulation. [sent-341, score-0.485]
</p><p>100 Pivot approach for extracting paraphrase patterns from bilingual corpora. [sent-362, score-0.161]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reformulation', 0.627), ('reformulations', 0.424), ('question', 0.277), ('query', 0.211), ('seattle', 0.163), ('qnew', 0.139), ('patterns', 0.139), ('boston', 0.138), ('boldi', 0.093), ('qrnew', 0.093), ('questions', 0.09), ('queries', 0.088), ('search', 0.073), ('paraphrases', 0.073), ('balasubramanian', 0.07), ('dropone', 0.07), ('nostop', 0.07), ('qdist', 0.07), ('qr', 0.069), ('croft', 0.059), ('retrieval', 0.059), ('web', 0.057), ('pr', 0.056), ('ndcg', 0.055), ('reformulated', 0.055), ('log', 0.055), ('paraphrasing', 0.053), ('tan', 0.053), ('issued', 0.052), ('original', 0.052), ('mine', 0.049), ('pattern', 0.048), ('anxiously', 0.046), ('castillo', 0.046), ('classroom', 0.046), ('executives', 0.046), ('orig', 0.046), ('picking', 0.044), ('pages', 0.043), ('far', 0.043), ('pas', 0.043), ('expressions', 0.042), ('barzilay', 0.041), ('bonchi', 0.04), ('huston', 0.04), ('ponte', 0.04), ('pri', 0.04), ('logs', 0.04), ('ravichandran', 0.04), ('kauchak', 0.037), ('mckeown', 0.035), ('zhao', 0.035), ('commercial', 0.035), ('organize', 0.034), ('cw', 0.032), ('bannard', 0.032), ('relevance', 0.032), ('alternative', 0.032), ('jansen', 0.031), ('bergsma', 0.031), ('bhagat', 0.031), ('poses', 0.031), ('top', 0.031), ('xue', 0.03), ('prefix', 0.03), ('wang', 0.029), ('dis', 0.028), ('convey', 0.028), ('stopwords', 0.027), ('engine', 0.027), ('zhai', 0.027), ('percent', 0.027), ('scale', 0.026), ('successive', 0.026), ('mined', 0.026), ('proceeding', 0.026), ('studied', 0.025), ('jones', 0.024), ('cro', 0.024), ('upper', 0.023), ('ask', 0.023), ('minutes', 0.022), ('pang', 0.022), ('acquisition', 0.022), ('generating', 0.022), ('paraphrase', 0.022), ('association', 0.022), ('ca', 0.021), ('formulated', 0.021), ('within', 0.021), ('asia', 0.021), ('sigir', 0.021), ('kuansan', 0.02), ('xiaolong', 0.02), ('opr', 0.02), ('aristides', 0.02), ('booth', 0.02), ('burch', 0.02), ('cbe', 0.02), ('francesco', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="35-tfidf-1" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>2 0.13824619 <a title="35-tfidf-2" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>3 0.11969363 <a title="35-tfidf-3" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>Author: Kuzman Ganchev ; Keith Hall ; Ryan McDonald ; Slav Petrov</p><p>Abstract: Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult. We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time. Unlike previous work, our final model does not require any additional resources at run-time. Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction. Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.</p><p>4 0.10709044 <a title="35-tfidf-4" href="./acl-2012-Community_Answer_Summarization_for_Multi-Sentence_Question_with_Group_L1_Regularization.html">55 acl-2012-Community Answer Summarization for Multi-Sentence Question with Group L1 Regularization</a></p>
<p>Author: Wen Chan ; Xiangdong Zhou ; Wei Wang ; Tat-Seng Chua</p><p>Abstract: We present a novel answer summarization method for community Question Answering services (cQAs) to address the problem of “incomplete answer”, i.e., the “best answer” of a complex multi-sentence question misses valuable information that is contained in other answers. In order to automatically generate a novel and non-redundant community answer summary, we segment the complex original multi-sentence question into several sub questions and then propose a general Conditional Random Field (CRF) based answer summary method with group L1 regularization. Various textual and non-textual QA features are explored. Specifically, we explore four different types of contextual factors, namely, the information novelty and non-redundancy modeling for local and non-local sentence interactions under question segmentation. To further unleash the potential of the abundant cQA features, we introduce the group L1 regularization for feature learning. Experimental results on a Yahoo! Answers dataset show that our proposed method significantly outperforms state-of-the-art methods on cQA summarization task.</p><p>5 0.10421934 <a title="35-tfidf-5" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance. In this paper, we propose a method to estimate sense distributions for short queries. Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations. Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system, we obtain significant improvements over a state-of-the-art IR system.</p><p>6 0.086253032 <a title="35-tfidf-6" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>7 0.083456434 <a title="35-tfidf-7" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>8 0.071664736 <a title="35-tfidf-8" href="./acl-2012-Joint_Learning_of_a_Dual_SMT_System_for_Paraphrase_Generation.html">125 acl-2012-Joint Learning of a Dual SMT System for Paraphrase Generation</a></p>
<p>9 0.066657998 <a title="35-tfidf-9" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>10 0.06638889 <a title="35-tfidf-10" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>11 0.055110868 <a title="35-tfidf-11" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>12 0.052538343 <a title="35-tfidf-12" href="./acl-2012-Unsupervized_Word_Segmentation%3A_the_Case_for_Mandarin_Chinese.html">210 acl-2012-Unsupervized Word Segmentation: the Case for Mandarin Chinese</a></p>
<p>13 0.051323034 <a title="35-tfidf-13" href="./acl-2012-Improve_SMT_Quality_with_Automatically_Extracted_Paraphrase_Rules.html">116 acl-2012-Improve SMT Quality with Automatically Extracted Paraphrase Rules</a></p>
<p>14 0.045036919 <a title="35-tfidf-14" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>15 0.041361567 <a title="35-tfidf-15" href="./acl-2012-FLOW%3A_A_First-Language-Oriented_Writing_Assistant_System.html">92 acl-2012-FLOW: A First-Language-Oriented Writing Assistant System</a></p>
<p>16 0.041213788 <a title="35-tfidf-16" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>17 0.039811589 <a title="35-tfidf-17" href="./acl-2012-Arabic_Retrieval_Revisited%3A_Morphological_Hole_Filling.html">27 acl-2012-Arabic Retrieval Revisited: Morphological Hole Filling</a></p>
<p>18 0.039499305 <a title="35-tfidf-18" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>19 0.038145263 <a title="35-tfidf-19" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>20 0.037028853 <a title="35-tfidf-20" href="./acl-2012-Efficient_Search_for_Transformation-based_Inference.html">78 acl-2012-Efficient Search for Transformation-based Inference</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.119), (1, 0.034), (2, -0.001), (3, 0.043), (4, 0.046), (5, 0.096), (6, 0.016), (7, 0.015), (8, -0.011), (9, -0.031), (10, 0.081), (11, 0.102), (12, 0.003), (13, 0.084), (14, 0.057), (15, -0.025), (16, 0.081), (17, -0.044), (18, 0.021), (19, -0.037), (20, 0.18), (21, 0.186), (22, 0.086), (23, -0.01), (24, -0.121), (25, -0.147), (26, 0.093), (27, -0.018), (28, 0.001), (29, -0.055), (30, -0.084), (31, -0.024), (32, 0.06), (33, -0.037), (34, -0.022), (35, 0.002), (36, 0.096), (37, -0.047), (38, -0.026), (39, -0.084), (40, -0.063), (41, -0.11), (42, -0.036), (43, 0.065), (44, 0.022), (45, -0.013), (46, 0.044), (47, 0.029), (48, -0.13), (49, 0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96202195 <a title="35-lsi-1" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>2 0.66661978 <a title="35-lsi-2" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>3 0.63827789 <a title="35-lsi-3" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>4 0.58893436 <a title="35-lsi-4" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>Author: Kuzman Ganchev ; Keith Hall ; Ryan McDonald ; Slav Petrov</p><p>Abstract: Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult. We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time. Unlike previous work, our final model does not require any additional resources at run-time. Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction. Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.</p><p>5 0.53927743 <a title="35-lsi-5" href="./acl-2012-Community_Answer_Summarization_for_Multi-Sentence_Question_with_Group_L1_Regularization.html">55 acl-2012-Community Answer Summarization for Multi-Sentence Question with Group L1 Regularization</a></p>
<p>Author: Wen Chan ; Xiangdong Zhou ; Wei Wang ; Tat-Seng Chua</p><p>Abstract: We present a novel answer summarization method for community Question Answering services (cQAs) to address the problem of “incomplete answer”, i.e., the “best answer” of a complex multi-sentence question misses valuable information that is contained in other answers. In order to automatically generate a novel and non-redundant community answer summary, we segment the complex original multi-sentence question into several sub questions and then propose a general Conditional Random Field (CRF) based answer summary method with group L1 regularization. Various textual and non-textual QA features are explored. Specifically, we explore four different types of contextual factors, namely, the information novelty and non-redundancy modeling for local and non-local sentence interactions under question segmentation. To further unleash the potential of the abundant cQA features, we introduce the group L1 regularization for feature learning. Experimental results on a Yahoo! Answers dataset show that our proposed method significantly outperforms state-of-the-art methods on cQA summarization task.</p><p>6 0.47739175 <a title="35-lsi-6" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>7 0.43362573 <a title="35-lsi-7" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>8 0.38461941 <a title="35-lsi-8" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>9 0.37384748 <a title="35-lsi-9" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>10 0.35905159 <a title="35-lsi-10" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>11 0.32568944 <a title="35-lsi-11" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>12 0.31567338 <a title="35-lsi-12" href="./acl-2012-Humor_as_Circuits_in_Semantic_Networks.html">112 acl-2012-Humor as Circuits in Semantic Networks</a></p>
<p>13 0.3140153 <a title="35-lsi-13" href="./acl-2012-Joint_Learning_of_a_Dual_SMT_System_for_Paraphrase_Generation.html">125 acl-2012-Joint Learning of a Dual SMT System for Paraphrase Generation</a></p>
<p>14 0.28770989 <a title="35-lsi-14" href="./acl-2012-Improve_SMT_Quality_with_Automatically_Extracted_Paraphrase_Rules.html">116 acl-2012-Improve SMT Quality with Automatically Extracted Paraphrase Rules</a></p>
<p>15 0.28551182 <a title="35-lsi-15" href="./acl-2012-Unsupervized_Word_Segmentation%3A_the_Case_for_Mandarin_Chinese.html">210 acl-2012-Unsupervized Word Segmentation: the Case for Mandarin Chinese</a></p>
<p>16 0.28099713 <a title="35-lsi-16" href="./acl-2012-Ecological_Evaluation_of_Persuasive_Messages_Using_Google_AdWords.html">77 acl-2012-Ecological Evaluation of Persuasive Messages Using Google AdWords</a></p>
<p>17 0.27177832 <a title="35-lsi-17" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<p>18 0.26457819 <a title="35-lsi-18" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>19 0.25012222 <a title="35-lsi-19" href="./acl-2012-Collective_Generation_of_Natural_Image_Descriptions.html">51 acl-2012-Collective Generation of Natural Image Descriptions</a></p>
<p>20 0.24846637 <a title="35-lsi-20" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.017), (26, 0.055), (28, 0.03), (30, 0.027), (37, 0.023), (39, 0.046), (48, 0.02), (52, 0.332), (74, 0.022), (82, 0.013), (84, 0.022), (85, 0.017), (90, 0.166), (92, 0.069), (99, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74305862 <a title="35-lda-1" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>2 0.74185205 <a title="35-lda-2" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>Author: Nathanael Chambers</p><p>Abstract: Temporal reasoners for document understanding typically assume that a document’s creation date is known. Algorithms to ground relative time expressions and order events often rely on this timestamp to assist the learner. Unfortunately, the timestamp is not always known, particularly on the Web. This paper addresses the task of automatic document timestamping, presenting two new models that incorporate rich linguistic features about time. The first is a discriminative classifier with new features extracted from the text’s time expressions (e.g., ‘since 1999’). This model alone improves on previous generative models by 77%. The second model learns probabilistic constraints between time expressions and the unknown document time. Imposing these learned constraints on the discriminative model further improves its accuracy. Finally, we present a new experiment design that facil- itates easier comparison by future work.</p><p>3 0.69752347 <a title="35-lda-3" href="./acl-2012-Fast_Online_Training_with_Frequency-Adaptive_Learning_Rates_for_Chinese_Word_Segmentation_and_New_Word_Detection.html">94 acl-2012-Fast Online Training with Frequency-Adaptive Learning Rates for Chinese Word Segmentation and New Word Detection</a></p>
<p>Author: Xu Sun ; Houfeng Wang ; Wenjie Li</p><p>Abstract: We present a joint model for Chinese word segmentation and new word detection. We present high dimensional new features, including word-based features and enriched edge (label-transition) features, for the joint modeling. As we know, training a word segmentation system on large-scale datasets is already costly. In our case, adding high dimensional new features will further slow down the training speed. To solve this problem, we propose a new training method, adaptive online gradient descent based on feature frequency information, for very fast online training of the parameters, even given large-scale datasets with high dimensional features. Compared with existing training methods, our training method is an order magnitude faster in terms of training time, and can achieve equal or even higher accuracies. The proposed fast training method is a general purpose optimization method, and it is not limited in the specific task discussed in this paper.</p><p>4 0.69737256 <a title="35-lda-4" href="./acl-2012-Head-Driven_Hierarchical_Phrase-based_Translation.html">105 acl-2012-Head-Driven Hierarchical Phrase-based Translation</a></p>
<p>Author: Junhui Li ; Zhaopeng Tu ; Guodong Zhou ; Josef van Genabith</p><p>Abstract: This paper presents an extension of Chiang’s hierarchical phrase-based (HPB) model, called Head-Driven HPB (HD-HPB), which incorporates head information in translation rules to better capture syntax-driven information, as well as improved reordering between any two neighboring non-terminals at any stage of a derivation to explore a larger reordering search space. Experiments on Chinese-English translation on four NIST MT test sets show that the HD-HPB model significantly outperforms Chiang’s model with average gains of 1.91 points absolute in BLEU. 1</p><p>5 0.51444918 <a title="35-lda-5" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>6 0.51331669 <a title="35-lda-6" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>7 0.512748 <a title="35-lda-7" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>8 0.51176912 <a title="35-lda-8" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>9 0.51160705 <a title="35-lda-9" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>10 0.51035684 <a title="35-lda-10" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>11 0.50716066 <a title="35-lda-11" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>12 0.50627655 <a title="35-lda-12" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>13 0.50549263 <a title="35-lda-13" href="./acl-2012-Finding_Bursty_Topics_from_Microblogs.html">98 acl-2012-Finding Bursty Topics from Microblogs</a></p>
<p>14 0.50512558 <a title="35-lda-14" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>15 0.50506777 <a title="35-lda-15" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>16 0.50459403 <a title="35-lda-16" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>17 0.50436068 <a title="35-lda-17" href="./acl-2012-A_Nonparametric_Bayesian_Approach_to_Acoustic_Model_Discovery.html">16 acl-2012-A Nonparametric Bayesian Approach to Acoustic Model Discovery</a></p>
<p>18 0.50427377 <a title="35-lda-18" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>19 0.50412899 <a title="35-lda-19" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>20 0.50383878 <a title="35-lda-20" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
