<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 acl-2012-Sentence Simplification by Monolingual Machine Translation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-178" href="#">acl2012-178</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>178 acl-2012-Sentence Simplification by Monolingual Machine Translation</h1>
<br/><p>Source: <a title="acl-2012-178-pdf" href="http://aclweb.org/anthology//P/P12/P12-1107.pdf">pdf</a></p><p>Author: Sander Wubben ; Antal van den Bosch ; Emiel Krahmer</p><p>Abstract: In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar sim- a. plification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems.</p><p>Reference: <a title="acl-2012-178-reference" href="../acl2012_reference/acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 nl Abstract In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. [sent-5, score-0.199]
</p><p>2 We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. [sent-6, score-0.188]
</p><p>3 Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar sim-  a. [sent-8, score-0.108]
</p><p>4 We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems. [sent-10, score-0.731]
</p><p>5 Sentence simplification can also serve to preprocess the input 1015 P. [sent-18, score-0.426]
</p><p>6 nl of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al. [sent-28, score-0.105]
</p><p>7 , 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). [sent-29, score-0.086]
</p><p>8 The goal of simplification is to achieve an improvement in readability, defined as the ease with which a text can be understood. [sent-30, score-0.465]
</p><p>9 Some of the factors that are known to help increase the readability oftext are the vocabulary used, the length of the sentences, the syntactic structures present in the text, and the usage of discourse markers. [sent-31, score-0.132]
</p><p>10 One effort to create a simple version of English at the vocabulary level has been the creation of Basic English by Charles Kay Ogden. [sent-32, score-0.101]
</p><p>11 Generally the structure of the sentences in English Simple Wikipedia is less complicated and the sentences are somewhat shorter than those found in English Wikipedia; we offer more detailed statistics below. [sent-37, score-0.122]
</p><p>12 1  Related work  Most earlier work on sentence simplification adopted rule-based approaches. [sent-39, score-0.512]
</p><p>13 A frequently applied type of rule, aimed to reduce overall sentence length, splits long sentences on the basis of syntactic ProceediJnegjus, o Rfe thpeu 5bl0icth o Afn Knouraela M, 8e-e1t4in Jgul oyf t 2h0e1 A2. [sent-40, score-0.147]
</p><p>14 There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al. [sent-45, score-0.092]
</p><p>15 (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplifi-  cation task. [sent-48, score-0.127]
</p><p>16 They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. [sent-49, score-0.681]
</p><p>17 In a similar vein, Coster and Kauchak (201 1) use a parallel corpus of paired documents from Simple Wikipedia and Wikipedia to train a phrase-based machine translation model coupled with a deletion model. [sent-50, score-0.186]
</p><p>18 Another useful resource is the edit history of Simple Wikipedia, from which simplifications can be learned (Yatskar et al. [sent-51, score-0.131]
</p><p>19 They select the most appropriate simplification by using integer linear programming. [sent-54, score-0.426]
</p><p>20 (2010) and Coster and Kauchak (201 1) in proposing that sentence simplification can be approached as a monolingual machine translation task, where the source and target languages are the same and where the output should be simpler in form from the input but similar in meaning. [sent-56, score-0.779]
</p><p>21 1 shows the average sentence length and the average 1http : / / s imple . [sent-61, score-0.086]
</p><p>22 Statistical machine translation (SMT) has already been successfully applied to the related task of paraphrasing (Quirk et al. [sent-74, score-0.161]
</p><p>23 These corpora need to be aligned at the sentence level. [sent-80, score-0.086]
</p><p>24 Phrase-Based Machine Translation (PBMT) is a form of SMT where the translation model aims to translate longer sequences of words (“phrases”) in one go, solving part of the word ordering problem along the way that would be left to the target language model in a word-based SMT system. [sent-82, score-0.105]
</p><p>25 The PBMT model makes use of a translation model, derived from the parallel corpus, and a language model, derived from a monolingual corpus in the target language. [sent-85, score-0.208]
</p><p>26 For any given input sentence, a search is carried out producing an n-best list of candidate translations, ranked by the decoder score, a complex scoring function including likelihood scores from the translation model, and the target language model. [sent-87, score-0.208]
</p><p>27 In principle, all of this should be transportable to a data-driven machine translation account of sentence simplification, provided that a parallel corpus is available that pairs text to simplified versions of that text. [sent-88, score-0.299]
</p><p>28 2 This study In this work we aim to investigate the use of phrasebased machine translation modified with a dissimilarity component for the task of sentence simplification. [sent-90, score-0.269]
</p><p>29 (2010) have demonstrated that their approach outperforms a PBMT approach in terms of Flesch Reading Ease test scores, we are not aware ofany studies that evaluate PBMT for sen-  tence simplification with human judgements. [sent-92, score-0.426]
</p><p>30 1 Word-Substitution Baseline The word substitution baseline replaces words in the source sentence with (near-)synonyms that are more likely according to a language model. [sent-99, score-0.188]
</p><p>31 For each noun, adjective and verb in the sentence this model takes that word and its part-of-speech tag and retrieves from WordNet all synonyms from all synsets the word occurs in. [sent-100, score-0.086]
</p><p>32 (2010) learn a sentence simplification model which is able to perform four rewrite operations on the parse trees of the input sentences, namely substitution, reordering, splitting, and deletion. [sent-113, score-0.553]
</p><p>33 Their model is inspired by syntax-based SMT (Yamada and Knight, 2001) and consists of a language model, a translation model and a decoder. [sent-114, score-0.105]
</p><p>34 The four mentioned simplification operations together form the translation model. [sent-115, score-0.572]
</p><p>35 TF*IDF at the sentence level was used to align the sentences in the different articles (Nelken and Shieber, 2006). [sent-119, score-0.147]
</p><p>36 (2010) evaluate their system using BLEU and NIST scores, as well as various readability scores that only take into account the output sentence, such as the Flesch Reading Ease test and n-gram language model perplexity. [sent-121, score-0.306]
</p><p>37 Although their system outperforms several baselines at the level of these readability metrics, they do not achieve better when evaluated with BLEU or NIST. [sent-122, score-0.173]
</p><p>38 Their model is trained on two different datasets: one containing alignments between Wikipedia and English Simple Wikipedia (AlignILP), and one containing alignments between edits in the revision history of Simple Wikipedia (RevILP). [sent-128, score-0.144]
</p><p>39 (2010)’s system and is not scored significantly differently from English Simple Wikipedia. [sent-133, score-0.108]
</p><p>40 Figure 1: Levenshtein distance and Flesch-Kincaid score of output when varying the n of the n-best output of Moses. [sent-135, score-0.195]
</p><p>41 Then we invoke the GIZA++ aligner using the training simplification pairs. [sent-144, score-0.426]
</p><p>42 Finally, we use the Moses decoder to generate simplifications for the sentences in the test set. [sent-147, score-0.163]
</p><p>43 For each sentence we let the system generate the ten best distinct solutions (or less, if fewer than ten solutions are generated) as ranked by Moses. [sent-148, score-0.225]
</p><p>44 Arguably, dissimilarity is a key factor in simplification (and in paraphrasing in general). [sent-149, score-0.56]
</p><p>45 As output we would like to be able to select fluent sentences that adequately convey the meaning of the original input, yet that contain differences that operationalize the intended simplification. [sent-150, score-0.165]
</p><p>46 To expand the functionality of Moses in the intended direction we perform post-hoc re-ranking on the output based on dissimilarity to the input. [sent-152, score-0.142]
</p><p>47 Figure 1 displays Levenshtein Distance and FleschKincaid grade level scores for different values of n. [sent-157, score-0.179]
</p><p>48 The readability score stays more or less the same, indicating no relation between n and readability. [sent-159, score-0.164]
</p><p>49 The average  edit distance starts out at just above 2 when selecting the 1-best output string, and increases roughly until n = 10. [sent-160, score-0.162]
</p><p>50 5 Descriptive statistics Table 2 displays the average edit distance and the percentage of cases in which no edits were performed for each of the systems and for Simple Wikipedia. [sent-162, score-0.217]
</p><p>51 About half of the original tokens in the source sentence do not return in the output. [sent-169, score-0.126]
</p><p>52 Of the three simplification systems, the Zhu system (7. [sent-170, score-0.467]
</p><p>53 18) attain similar edit distances, less substantial than the edits in Simple Wikipedia, but still consid4http : / /http : / / search . [sent-172, score-0.141]
</p><p>54 pm  1019 erable compared to the baseline word-substitution system (4. [sent-176, score-0.086]
</p><p>55 On the other hand, we observe some differences in the percentage of cases in which the systems decide to produce a sentence identical to the input. [sent-183, score-0.086]
</p><p>56 This test set consists of 100 sentences from articles on English Wikipedia, paired with sentences from corresponding articles in English Simple Wikipedia. [sent-193, score-0.163]
</p><p>57 We selected only those sentences where every system would perform minimally one edit, because we only want to compare the different systems when they actually generate altered, assumedly simplified output. [sent-194, score-0.17]
</p><p>58 From this subset we randomly pick 20 source sentences, resulting in 20 clusters of one source sentence and 5 simplified sentences, as generated by humans (Simple  Wikipedia) and the four systems. [sent-195, score-0.154]
</p><p>59 3 Procedure The participants were told that they participated in the evaluation of a system that could simplify sentences, and that they would see one source sentence and five automatically simplified versions of that sentence. [sent-197, score-0.316]
</p><p>60 Following earlier evaluation studies (Doddington, 2002; Woodsend and Lapata, 2011), we asked participants to evaluate Simplicity, Fluency and Adequacy of the target headlines on a five point Likert scale. [sent-199, score-0.078]
</p><p>61 Fluency was defined in the instructions as the extent to which a sentence is proper, grammatical English. [sent-200, score-0.086]
</p><p>62 Adequacy was defined as the extent to which the sentence has the same meaning as the source sentence. [sent-201, score-0.086]
</p><p>63 Simplicity was defined as the extent to which the sentence was simpler than the original and thus easier to understand. [sent-202, score-0.161]
</p><p>64 The order in which the clusters had to be judged was randomized and the order of the output of the various systems was randomized as well. [sent-203, score-0.126]
</p><p>65 In terms of the Flesch-Kincaid grade level score, where lower scores are better, the Zhu system scores best, with 7. [sent-206, score-0.248]
</p><p>66 With regard to the BLEU score, where Simple Wikipedia is the reference, the PBMT-R system scores highest with 0. [sent-213, score-0.11]
</p><p>67 The word substitution baseline scores lowest with a BLEU score of 0. [sent-217, score-0.203]
</p><p>68 E34 U3128  Table 3: Flesch-Kincaid grade level and BLEU scores  1020 4. [sent-221, score-0.138]
</p><p>69 2  Human judgements  To test for significance we ran repeated measures analyses of variance with system (Simple Wikipedia, PBMT-R, Zhu, RevILP, wordsubstitution baseline) as the independent variable, and the three individual metrics as well as their combined mean as the dependent variables. [sent-222, score-0.172]
</p><p>70 Mauchlys test for sphericity was used to test for homogeneity of variance, and when this test was significant we applied a Greenhouse-Geisser correction on the degrees of freedom (for the purpose of readability we report the normal degrees of freedom in these cases). [sent-223, score-0.167]
</p><p>71 Planned pairwise comparisons were made with the Bonferroni method. [sent-224, score-0.086]
</p><p>72 We find that participants rated the Fluency of the simplified sentences from the four systems and Simple Wikipedia differently, F(4, 180) = 178. [sent-227, score-0.253]
</p><p>73 All other pairwise comparisons are significant at p < . [sent-235, score-0.121]
</p><p>74 Participants also rated the systems significantly differently on the Adequacy scale, F(4, 180) = 116. [sent-240, score-0.113]
</p><p>75 Simple Wikipedia and the Zhu system do not differ significantly, and all other pairwise comparisons are significant at p < . [sent-250, score-0.162]
</p><p>76 Key to the task of simplification are the human judgements of Simplicity. [sent-253, score-0.478]
</p><p>77 Participants rated the Simplicity of the output from the four systems and Simple Wikipedia differently, F(4, 180) = 74. [sent-254, score-0.11]
</p><p>78 05 and scores  as assigned by humans and the automatic  marked ** are significant at p  metrics. [sent-279, score-0.104]
</p><p>79 01  tems, which do not score significantly differently from each other. [sent-281, score-0.099]
</p><p>80 All other pairwise comparisons are significant at p < . [sent-282, score-0.121]
</p><p>81 We find that participants rated the systems significantly differently overall, F(4, 180) = 98. [sent-291, score-0.191]
</p><p>82 All pairwise comparisons were statistically significant (p < . [sent-295, score-0.121]
</p><p>83 3 Correlations Table 5 displays the correlations between the scores assigned by humans (Fluency, Adequacy and Simplicity) and the automatic metrics (Flesch-Kincaid and BLEU). [sent-298, score-0.188]
</p><p>84 There is a negative significant correlation between Flesch-Kincaid scores and Simplicity (-0. [sent-302, score-0.142]
</p><p>85 5  Discussion  We conclude that a phrase-based  machine trans-  lation system with added dissimilarity-based reranking of the best ten output sentences can successfully be used to perform sentence simplification. [sent-309, score-0.301]
</p><p>86 From the relatively low average numbers of edits made by our system we can conclude that our system performs relatively small numbers of changes to the input, that still constitute as sensible simplifications. [sent-312, score-0.16]
</p><p>87 The output of all systems, the original and the simplified version of an example sentence from the PWKP dataset is displayed in Table 6. [sent-315, score-0.258]
</p><p>88 The Simple Wikipedia sentences illustrate that significant portions of the original sentences may be dropped, and parts of the semantics of the original sentence discarded. [sent-316, score-0.323]
</p><p>89 We also see the Zhu and RevILP systems resorting to splitting the original sentence in two, leading to better Flesch-Kincaid scores. [sent-317, score-0.126]
</p><p>90 The wordsubstitution baseline changes ‘receive’ in ‘have’, while the PBMT-R system changes the same ‘receive’ in ’get’, ‘slightly’ to ‘a little bit’, and ‘maximum’ to ‘highest’ . [sent-318, score-0.125]
</p><p>91 In terms of automatic measures we see that the Zhu system scores particularly well on the FleschKincaid metric, while the RevILP system and our PBMT-R system achieve the highest BLEU scores. [sent-319, score-0.192]
</p><p>92 We believe that for the evaluation of sentence simplification, BLEU is a more appropriate metric than Flesch-Kincaid or a similar readability metric, although it should be noted that BLEU was found only to correlate significantly with Fluency, not with Adequacy. [sent-320, score-0.218]
</p><p>93 While BLEU and NIST may be used with this in mind, readability metrics should be avoided altogether in our view. [sent-321, score-0.172]
</p><p>94 1022 Arguably, readability metrics are best suited to be applied to texts that can be considered grammatical and meaningful, which is not necessarily true for the output of simplification algorithms. [sent-323, score-0.662]
</p><p>95 In the future we would like to investigate how we can boost the number of edits the system performs, while still producing grammatical and meaningpreserving output. [sent-325, score-0.119]
</p><p>96 Practical simplification of English newspaper text to assist aphasic readers. [sent-347, score-0.426]
</p><p>97 The hiero machine translation system: extensions, evaluation, and analysis. [sent-366, score-0.105]
</p><p>98 Automatic sentence simplification  1023 for subtitling in dutch and english. [sent-382, score-0.512]
</p><p>99 Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. [sent-386, score-0.105]
</p><p>100 Learning to simplify sentences with quasi-synchronous grammar and integer programming. [sent-480, score-0.104]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('simplification', 0.426), ('revilp', 0.352), ('wikipedia', 0.342), ('zhu', 0.25), ('fluency', 0.156), ('pbmt', 0.156), ('adequacy', 0.144), ('pwkp', 0.137), ('readability', 0.132), ('woodsend', 0.125), ('translation', 0.105), ('simple', 0.101), ('bleu', 0.1), ('tilburg', 0.098), ('sentence', 0.086), ('simplicity', 0.08), ('edits', 0.078), ('canning', 0.078), ('chandrasekar', 0.078), ('coster', 0.078), ('dissimilarity', 0.078), ('participants', 0.078), ('moses', 0.071), ('levenshtein', 0.07), ('scores', 0.069), ('grade', 0.069), ('simplifications', 0.068), ('simplified', 0.068), ('differently', 0.067), ('output', 0.064), ('edit', 0.063), ('monolingual', 0.063), ('daelemans', 0.062), ('sentences', 0.061), ('fleschkincaid', 0.059), ('vickrey', 0.059), ('wubben', 0.059), ('yvonne', 0.059), ('substitution', 0.057), ('paraphrasing', 0.056), ('judgements', 0.052), ('madnani', 0.051), ('netherlands', 0.051), ('lapata', 0.05), ('chris', 0.049), ('ten', 0.049), ('carroll', 0.048), ('kauchak', 0.047), ('stroudsburg', 0.047), ('rated', 0.046), ('comparisons', 0.045), ('baseline', 0.045), ('simplify', 0.043), ('english', 0.042), ('system', 0.041), ('displays', 0.041), ('paired', 0.041), ('pairwise', 0.041), ('operations', 0.041), ('original', 0.04), ('metrics', 0.04), ('parallel', 0.04), ('reading', 0.039), ('emiel', 0.039), ('fathom', 0.039), ('flesch', 0.039), ('krahmer', 0.039), ('nelken', 0.039), ('nijmegen', 0.039), ('sander', 0.039), ('siobhan', 0.039), ('uvt', 0.039), ('wordsubstitution', 0.039), ('yatskar', 0.039), ('zhemin', 0.039), ('ease', 0.039), ('correlation', 0.038), ('correlations', 0.038), ('inui', 0.038), ('wordnet', 0.036), ('significant', 0.035), ('distance', 0.035), ('pages', 0.035), ('henceforth', 0.035), ('simplifying', 0.035), ('simpler', 0.035), ('decoder', 0.034), ('pa', 0.034), ('lingua', 0.034), ('guido', 0.034), ('cpan', 0.034), ('antal', 0.034), ('devlin', 0.034), ('alignments', 0.033), ('score', 0.032), ('smt', 0.032), ('minnen', 0.031), ('randomized', 0.031), ('quasisynchronous', 0.031), ('filippova', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="178-tfidf-1" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>Author: Sander Wubben ; Antal van den Bosch ; Emiel Krahmer</p><p>Abstract: In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar sim- a. plification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems.</p><p>2 0.17284854 <a title="178-tfidf-2" href="./acl-2012-Joint_Learning_of_a_Dual_SMT_System_for_Paraphrase_Generation.html">125 acl-2012-Joint Learning of a Dual SMT System for Paraphrase Generation</a></p>
<p>Author: Hong Sun ; Ming Zhou</p><p>Abstract: SMT has been used in paraphrase generation by translating a source sentence into another (pivot) language and then back into the source. The resulting sentences can be used as candidate paraphrases ofthe source sentence. Existing work that uses two independently trained SMT systems cannot directly optimize the paraphrase results. Paraphrase criteria especially the paraphrase rate is not able to be ensured in that way. In this paper, we propose a joint learning method of two SMT systems to optimize the process of paraphrase generation. In addition, a revised BLEU score (called iBLEU) which measures the adequacy and diversity of the generated paraphrase sentence is proposed for tuning parameters in SMT systems. Our experiments on NIST 2008 testing data with automatic evaluation as well as human judgments suggest that the proposed method is able to enhance the paraphrase quality by adjusting between semantic equivalency and surface dissimilarity.</p><p>3 0.13627987 <a title="178-tfidf-3" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>Author: Xiaodong He ; Li Deng</p><p>Abstract: This paper proposes a new discriminative training method in constructing phrase and lexicon translation models. In order to reliably learn a myriad of parameters in these models, we propose an expected BLEU score-based utility function with KL regularization as the objective, and train the models on a large parallel dataset. For training, we derive growth transformations for phrase and lexicon translation probabilities to iteratively improve the objective. The proposed method, evaluated on the Europarl German-to-English dataset, leads to a 1.1 BLEU point improvement over a state-of-the-art baseline translation system. In IWSLT 201 1 Benchmark, our system using the proposed method achieves the best Chinese-to-English translation result on the task of translating TED talks.</p><p>4 0.10913607 <a title="178-tfidf-4" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>Author: Tong Xiao ; Jingbo Zhu ; Hao Zhang ; Qiang Li</p><p>Abstract: We present a new open source toolkit for phrase-based and syntax-based machine translation. The toolkit supports several state-of-the-art models developed in statistical machine translation, including the phrase-based model, the hierachical phrase-based model, and various syntaxbased models. The key innovation provided by the toolkit is that the decoder can work with various grammars and offers different choices of decoding algrithms, such as phrase-based decoding, decoding as parsing/tree-parsing and forest-based decoding. Moreover, several useful utilities were distributed with the toolkit, including a discriminative reordering model, a simple and fast language model, and an implementation of minimum error rate training for weight tuning. 1</p><p>5 0.10893459 <a title="178-tfidf-5" href="./acl-2012-Improve_SMT_Quality_with_Automatically_Extracted_Paraphrase_Rules.html">116 acl-2012-Improve SMT Quality with Automatically Extracted Paraphrase Rules</a></p>
<p>Author: Wei He ; Hua Wu ; Haifeng Wang ; Ting Liu</p><p>Abstract: unkown-abstract</p><p>6 0.10515023 <a title="178-tfidf-6" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>7 0.10471155 <a title="178-tfidf-7" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>8 0.10379709 <a title="178-tfidf-8" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>9 0.10001711 <a title="178-tfidf-9" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>10 0.099774867 <a title="178-tfidf-10" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>11 0.09809012 <a title="178-tfidf-11" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>12 0.097355567 <a title="178-tfidf-12" href="./acl-2012-Smaller_Alignment_Models_for_Better_Translations%3A_Unsupervised_Word_Alignment_with_the_l0-norm.html">179 acl-2012-Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the l0-norm</a></p>
<p>13 0.096906431 <a title="178-tfidf-13" href="./acl-2012-Character-Level_Machine_Translation_Evaluation_for_Languages_with_Ambiguous_Word_Boundaries.html">46 acl-2012-Character-Level Machine Translation Evaluation for Languages with Ambiguous Word Boundaries</a></p>
<p>14 0.096080281 <a title="178-tfidf-14" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>15 0.092117287 <a title="178-tfidf-15" href="./acl-2012-Combining_Coherence_Models_and_Machine_Translation_Evaluation_Metrics_for_Summarization_Evaluation.html">52 acl-2012-Combining Coherence Models and Machine Translation Evaluation Metrics for Summarization Evaluation</a></p>
<p>16 0.089040615 <a title="178-tfidf-16" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>17 0.086439595 <a title="178-tfidf-17" href="./acl-2012-Learning_Better_Rule_Extraction_with_Translation_Span_Alignment.html">128 acl-2012-Learning Better Rule Extraction with Translation Span Alignment</a></p>
<p>18 0.085553445 <a title="178-tfidf-18" href="./acl-2012-An_Exploration_of_Forest-to-String_Translation%3A_Does_Translation_Help_or_Hurt_Parsing%3F.html">25 acl-2012-An Exploration of Forest-to-String Translation: Does Translation Help or Hurt Parsing?</a></p>
<p>19 0.08418826 <a title="178-tfidf-19" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>20 0.083383858 <a title="178-tfidf-20" href="./acl-2012-PORT%3A_a_Precision-Order-Recall_MT_Evaluation_Metric_for_Tuning.html">158 acl-2012-PORT: a Precision-Order-Recall MT Evaluation Metric for Tuning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.239), (1, -0.129), (2, 0.069), (3, 0.067), (4, 0.09), (5, 0.015), (6, -0.039), (7, 0.026), (8, -0.049), (9, 0.008), (10, -0.001), (11, 0.022), (12, 0.013), (13, 0.101), (14, 0.018), (15, 0.001), (16, 0.074), (17, -0.085), (18, -0.069), (19, 0.065), (20, 0.035), (21, -0.069), (22, 0.085), (23, -0.044), (24, 0.043), (25, 0.089), (26, 0.003), (27, 0.029), (28, -0.009), (29, 0.072), (30, 0.027), (31, 0.018), (32, -0.017), (33, 0.084), (34, -0.015), (35, -0.069), (36, -0.09), (37, -0.032), (38, 0.081), (39, -0.001), (40, -0.063), (41, 0.009), (42, -0.037), (43, 0.112), (44, 0.011), (45, 0.037), (46, 0.092), (47, -0.031), (48, -0.049), (49, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91960579 <a title="178-lsi-1" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>Author: Sander Wubben ; Antal van den Bosch ; Emiel Krahmer</p><p>Abstract: In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar sim- a. plification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems.</p><p>2 0.65829843 <a title="178-lsi-2" href="./acl-2012-Joint_Learning_of_a_Dual_SMT_System_for_Paraphrase_Generation.html">125 acl-2012-Joint Learning of a Dual SMT System for Paraphrase Generation</a></p>
<p>Author: Hong Sun ; Ming Zhou</p><p>Abstract: SMT has been used in paraphrase generation by translating a source sentence into another (pivot) language and then back into the source. The resulting sentences can be used as candidate paraphrases ofthe source sentence. Existing work that uses two independently trained SMT systems cannot directly optimize the paraphrase results. Paraphrase criteria especially the paraphrase rate is not able to be ensured in that way. In this paper, we propose a joint learning method of two SMT systems to optimize the process of paraphrase generation. In addition, a revised BLEU score (called iBLEU) which measures the adequacy and diversity of the generated paraphrase sentence is proposed for tuning parameters in SMT systems. Our experiments on NIST 2008 testing data with automatic evaluation as well as human judgments suggest that the proposed method is able to enhance the paraphrase quality by adjusting between semantic equivalency and surface dissimilarity.</p><p>3 0.62836224 <a title="178-lsi-3" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>Author: Malte Nuhn ; Arne Mauser ; Hermann Ney</p><p>Abstract: In this paper we show how to train statistical machine translation systems on reallife tasks using only non-parallel monolingual data from two languages. We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model. The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. We also report results using data from the monolingual French and English GIGAWORD corpora.</p><p>4 0.62483066 <a title="178-lsi-4" href="./acl-2012-PORT%3A_a_Precision-Order-Recall_MT_Evaluation_Metric_for_Tuning.html">158 acl-2012-PORT: a Precision-Order-Recall MT Evaluation Metric for Tuning</a></p>
<p>Author: Boxing Chen ; Roland Kuhn ; Samuel Larkin</p><p>Abstract: Many machine translation (MT) evaluation metrics have been shown to correlate better with human judgment than BLEU. In principle, tuning on these metrics should yield better systems than tuning on BLEU. However, due to issues such as speed, requirements for linguistic resources, and optimization difficulty, they have not been widely adopted for tuning. This paper presents PORT , a new MT evaluation metric which combines precision, recall and an ordering metric and which is primarily designed for tuning MT systems. PORT does not require external resources and is quick to compute. It has a better correlation with human judgment than BLEU. We compare PORT-tuned MT systems to BLEU-tuned baselines in five experimental conditions involving four language pairs. PORT tuning achieves 1 consistently better performance than BLEU tuning, according to four automated metrics (including BLEU) and to human evaluation: in comparisons of outputs from 300 source sentences, human judges preferred the PORT-tuned output 45.3% of the time (vs. 32.7% BLEU tuning preferences and 22.0% ties). 1</p><p>5 0.61944991 <a title="178-lsi-5" href="./acl-2012-Character-Level_Machine_Translation_Evaluation_for_Languages_with_Ambiguous_Word_Boundaries.html">46 acl-2012-Character-Level Machine Translation Evaluation for Languages with Ambiguous Word Boundaries</a></p>
<p>Author: Chang Liu ; Hwee Tou Ng</p><p>Abstract: In this work, we introduce the TESLACELAB metric (Translation Evaluation of Sentences with Linear-programming-based Analysis Character-level Evaluation for Languages with Ambiguous word Boundaries) for automatic machine translation evaluation. For languages such as Chinese where words usually have meaningful internal structure and word boundaries are often fuzzy, TESLA-CELAB acknowledges the advantage of character-level evaluation over word-level evaluation. By reformulating the problem in the linear programming framework, TESLACELAB addresses several drawbacks of the character-level metrics, in particular the modeling of synonyms spanning multiple characters. We show empirically that TESLACELAB significantly outperforms characterlevel BLEU in the English-Chinese translation evaluation tasks. –</p><p>6 0.6122725 <a title="178-lsi-6" href="./acl-2012-FLOW%3A_A_First-Language-Oriented_Writing_Assistant_System.html">92 acl-2012-FLOW: A First-Language-Oriented Writing Assistant System</a></p>
<p>7 0.60674709 <a title="178-lsi-7" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>8 0.59750074 <a title="178-lsi-8" href="./acl-2012-Improve_SMT_Quality_with_Automatically_Extracted_Paraphrase_Rules.html">116 acl-2012-Improve SMT Quality with Automatically Extracted Paraphrase Rules</a></p>
<p>9 0.57212824 <a title="178-lsi-9" href="./acl-2012-Maximum_Expected_BLEU_Training_of_Phrase_and_Lexicon_Translation_Models.html">141 acl-2012-Maximum Expected BLEU Training of Phrase and Lexicon Translation Models</a></p>
<p>10 0.554533 <a title="178-lsi-10" href="./acl-2012-Combining_Word-Level_and_Character-Level_Models_for_Machine_Translation_Between_Closely-Related_Languages.html">54 acl-2012-Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages</a></p>
<p>11 0.54470396 <a title="178-lsi-11" href="./acl-2012-The_Creation_of_a_Corpus_of_English_Metalanguage.html">195 acl-2012-The Creation of a Corpus of English Metalanguage</a></p>
<p>12 0.53752553 <a title="178-lsi-12" href="./acl-2012-Learning_to_Translate_with_Multiple_Objectives.html">136 acl-2012-Learning to Translate with Multiple Objectives</a></p>
<p>13 0.52778435 <a title="178-lsi-13" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>14 0.52744895 <a title="178-lsi-14" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>15 0.52598441 <a title="178-lsi-15" href="./acl-2012-Prediction_of_Learning_Curves_in_Machine_Translation.html">163 acl-2012-Prediction of Learning Curves in Machine Translation</a></p>
<p>16 0.50131124 <a title="178-lsi-16" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>17 0.49937016 <a title="178-lsi-17" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>18 0.49907893 <a title="178-lsi-18" href="./acl-2012-Beefmoves%3A_Dissemination%2C_Diversity%2C_and_Dynamics_of_English_Borrowings_in_a_German_Hip_Hop_Forum.html">39 acl-2012-Beefmoves: Dissemination, Diversity, and Dynamics of English Borrowings in a German Hip Hop Forum</a></p>
<p>19 0.49750495 <a title="178-lsi-19" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>20 0.49083203 <a title="178-lsi-20" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.031), (26, 0.053), (28, 0.06), (30, 0.039), (37, 0.027), (39, 0.046), (48, 0.028), (57, 0.034), (69, 0.239), (74, 0.039), (81, 0.011), (82, 0.017), (84, 0.022), (85, 0.042), (90, 0.124), (92, 0.041), (94, 0.026), (99, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90295041 <a title="178-lda-1" href="./acl-2012-Demonstration_of_IlluMe%3A_Creating_Ambient_According_to_Instant_Message_Logs.html">70 acl-2012-Demonstration of IlluMe: Creating Ambient According to Instant Message Logs</a></p>
<p>Author: Lun-Wei Ku ; Cheng-Wei Sun ; Ya-Hsin Hsueh</p><p>Abstract: We present IlluMe, a software tool pack which creates a personalized ambient using the music and lighting. IlluMe includes an emotion analysis software, the small space ambient lighting, and a multimedia controller. The software analyzes emotional changes from instant message logs and corresponds the detected emotion to the best sound and light settings. The ambient lighting can sparkle with different forms of light and the smart phone can broadcast music respectively according to different atmosphere. All settings can be modified by the multimedia controller at any time and the new settings will be feedback to the emotion analysis software. The IlluMe system, equipped with the learning function, provides a link between residential situation and personal emotion. It works in a Chinese chatting environment to illustrate the language technology in life.</p><p>2 0.8303718 <a title="178-lda-2" href="./acl-2012-How_Are_Spelling_Errors_Generated_and_Corrected%3F_A_Study_of_Corrected_and_Uncorrected_Spelling_Errors_Using_Keystroke_Logs.html">111 acl-2012-How Are Spelling Errors Generated and Corrected? A Study of Corrected and Uncorrected Spelling Errors Using Keystroke Logs</a></p>
<p>Author: Yukino Baba ; Hisami Suzuki</p><p>Abstract: This paper presents a comparative study of spelling errors that are corrected as you type, vs. those that remain uncorrected. First, we generate naturally occurring online error correction data by logging users’ keystrokes, and by automatically deriving pre- and postcorrection strings from them. We then perform an analysis of this data against the errors that remain in the final text as well as across languages. Our analysis shows a clear distinction between the types of errors that are generated and those that remain uncorrected, as well as across languages.</p><p>same-paper 3 0.72451651 <a title="178-lda-3" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>Author: Sander Wubben ; Antal van den Bosch ; Emiel Krahmer</p><p>Abstract: In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar sim- a. plification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems.</p><p>4 0.58122098 <a title="178-lda-4" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>Author: Arianna Bisazza ; Marcello Federico</p><p>Abstract: This paper presents a novel method to suggest long word reorderings to a phrase-based SMT decoder. We address language pairs where long reordering concentrates on few patterns, and use fuzzy chunk-based rules to predict likely reorderings for these phenomena. Then we use reordered n-gram LMs to rank the resulting permutations and select the n-best for translation. Finally we encode these reorderings by modifying selected entries of the distortion cost matrix, on a per-sentence basis. In this way, we expand the search space by a much finer degree than if we simply raised the distortion limit. The proposed techniques are tested on Arabic-English and German-English using well-known SMT benchmarks.</p><p>5 0.58096385 <a title="178-lda-5" href="./acl-2012-Error_Mining_on_Dependency_Trees.html">83 acl-2012-Error Mining on Dependency Trees</a></p>
<p>Author: Claire Gardent ; Shashi Narayan</p><p>Abstract: In recent years, error mining approaches were developed to help identify the most likely sources of parsing failures in parsing systems using handcrafted grammars and lexicons. However the techniques they use to enumerate and count n-grams builds on the sequential nature of a text corpus and do not easily extend to structured data. In this paper, we propose an algorithm for mining trees and apply it to detect the most likely sources of generation failure. We show that this tree mining algorithm permits identifying not only errors in the generation system (grammar, lexicon) but also mismatches between the structures contained in the input and the input structures expected by our generator as well as a few idiosyncrasies/error in the input data.</p><p>6 0.57830209 <a title="178-lda-6" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>7 0.57367837 <a title="178-lda-7" href="./acl-2012-Detecting_Semantic_Equivalence_and_Information_Disparity_in_Cross-lingual_Documents.html">72 acl-2012-Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents</a></p>
<p>8 0.5736683 <a title="178-lda-8" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>9 0.57140064 <a title="178-lda-9" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>10 0.57118791 <a title="178-lda-10" href="./acl-2012-Joint_Learning_of_a_Dual_SMT_System_for_Paraphrase_Generation.html">125 acl-2012-Joint Learning of a Dual SMT System for Paraphrase Generation</a></p>
<p>11 0.57072407 <a title="178-lda-11" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>12 0.57016045 <a title="178-lda-12" href="./acl-2012-Improve_SMT_Quality_with_Automatically_Extracted_Paraphrase_Rules.html">116 acl-2012-Improve SMT Quality with Automatically Extracted Paraphrase Rules</a></p>
<p>13 0.56947517 <a title="178-lda-13" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>14 0.56900764 <a title="178-lda-14" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>15 0.56885749 <a title="178-lda-15" href="./acl-2012-Learning_to_Translate_with_Multiple_Objectives.html">136 acl-2012-Learning to Translate with Multiple Objectives</a></p>
<p>16 0.56748712 <a title="178-lda-16" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>17 0.56657195 <a title="178-lda-17" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>18 0.56649143 <a title="178-lda-18" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>19 0.56643909 <a title="178-lda-19" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>20 0.56437939 <a title="178-lda-20" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
