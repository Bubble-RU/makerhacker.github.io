<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>200 acl-2012-Toward Automatically Assembling Hittite-Language Cuneiform Tablet Fragments into Larger Texts</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-200" href="#">acl2012-200</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>200 acl-2012-Toward Automatically Assembling Hittite-Language Cuneiform Tablet Fragments into Larger Texts</h1>
<br/><p>Source: <a title="acl-2012-200-pdf" href="http://aclweb.org/anthology//P/P12/P12-2048.pdf">pdf</a></p><p>Author: Stephen Tyndall</p><p>Abstract: This paper presents the problem within Hittite and Ancient Near Eastern studies of fragmented and damaged cuneiform texts, and proposes to use well-known text classification metrics, in combination with some facts about the structure of Hittite-language cuneiform texts, to help classify a number offragments of clay cuneiform-script tablets into more complete texts. In particular, Ipropose using Sumerian and Akkadian ideogrammatic signs within Hittite texts to improve the performance of Naive Bayes and Maximum Entropy classifiers. The performance in some cases is improved, and in some cases very much not, suggesting that the variable frequency of occurrence of these ideograms in individual fragments makes considerable difference in the ideal choice for a classification method. Further, complexities of the writing system and the digital availability ofHittite texts complicate the problem.</p><p>Reference: <a title="acl-2012-200-reference" href="../acl2012_reference/acl-2012-Toward_Automatically_Assembling_Hittite-Language_Cuneiform_Tablet_Fragments_into_Larger_Texts_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In particular, Ipropose using Sumerian and Akkadian ideogrammatic signs within Hittite texts to improve the performance of Naive Bayes and Maximum Entropy classifiers. [sent-3, score-0.158]
</p><p>2 The performance in some cases is improved, and in some cases very much not, suggesting that the variable frequency of occurrence of these ideograms in individual fragments makes considerable difference in the ideal choice for a classification method. [sent-4, score-0.538]
</p><p>3 Further, complexities of the writing system and the digital availability ofHittite texts complicate the problem. [sent-5, score-0.143]
</p><p>4 1 Introduction The Hittite empire, in existence for about 600 years between 1800 and 1200 BCE, left numerous historical, political, and literary documents behind, written in cuneiform in clay tablets. [sent-6, score-0.448]
</p><p>5 There are a number of common problems that confront Hittite scholars interested in any subdiscipline of Hittitology, be it history, philology, or linguistics. [sent-7, score-0.052]
</p><p>6 First, the bulk of the cuneiform material is fragmentary. [sent-9, score-0.351]
</p><p>7 The tablets, discovered in various depots in the Hittite capital and in some provincial centers, normally were of a larger size. [sent-10, score-0.09]
</p><p>8 When the archives were destroyed, the tablets for the most part broke into many pieces. [sent-11, score-0.125]
</p><p>9 Therefore, the joining of fragments became an important prereq-  uisite for interpretation(Klengel, 2002). [sent-12, score-0.282]
</p><p>10 Most Hittite texts are broken, but a number exist in more than one fragmentary copy. [sent-13, score-0.101]
</p><p>11 Figure 1 shows a photograph, taken from the University of Meinz Konkordanz der hethitischen Texte1, of a typical Hittite cuneiform fragment. [sent-14, score-0.351]
</p><p>12 Complete or partially-complete texts are assembled from collections of fragments based on shape, writing size and style, and sentence similarity. [sent-15, score-0.425]
</p><p>13 Joins between fragments are not made systematically, but are usually discovered by scholars assembling large numbers of fragments that reference a specific subject, like some joins recently made in Hittite treaty documents in (Beckman, 1997). [sent-16, score-0.8]
</p><p>14 Such joins and the larger texts created therewith are catalogued according to a CTH (Catalogue des Textes Hittites2) number. [sent-18, score-0.273]
</p><p>15 Each individual text is composed of one or more cuneiform fragments belonging to one or more copies of a single original work. [sent-19, score-0.704]
</p><p>16 c so2c0ia1t2io Ans fso rc Ciatoiomnp fuotart Cio nmaplu Ltiantgiounisatlic Lsi,n pgaugiestsi2c 4s3–247, Figure 2 shows a published join in hand-copied cuneiform fragments. [sent-29, score-0.404]
</p><p>17 In this case, the fragments are not contiguous, and only the text on the two fragments was used to make the join. [sent-30, score-0.586]
</p><p>18 The task then, for the purposes of this paper, is to connect unknown fragments of Hittite cuneiform tablets with larger texts. [sent-31, score-0.761]
</p><p>19 I’m viewing this as a text classification task, where larger, CTH-numbered texts are the categories, and small fragments are the bits of text to be assigned to these categories. [sent-32, score-0.502]
</p><p>20 2  The Corpus of Hittite  Hittite cuneiform consists of a mix of syllabic writing for Hittite words and logographic writing, typically Sumerian ideograms, standing in for Hittite words. [sent-33, score-0.437]
</p><p>21 Most words are written out phonologically using syllabic signs, in structure mostly CV and VC, and a few CVC. [sent-34, score-0.084]
</p><p>22 Some common words are written with logograms from other Ancient Near Eastern languages, e. [sent-35, score-0.04]
</p><p>23 Hittite antuh ˇsa- ‘man’ is commonly written with the Sumerian-language logogram tran-  scribed LU´. [sent-37, score-0.04]
</p><p>24 Such writings are called Sumerograms or Akkadograms, depending on the language from which the ideogram is taken. [sent-38, score-0.057]
</p><p>25 The extant corpus of Hittite consists of more than 30,000 clay tablets and fragments excavated at sites in Turkey, Syria, and Egypt (Hoffner and Melchert, 2008, 2-3). [sent-39, score-0.435]
</p><p>26 Many of these fragments are assigned to one of the 835 texts catalogued in the CTH. [sent-40, score-0.427]
</p><p>27 3  Prior Work  A large number of prior studies on text classification have informed the progress of this study. [sent-41, score-0.059]
</p><p>28 Categorization of texts into genres is very well studied (Dewdney et al. [sent-42, score-0.101]
</p><p>29 Measures of similarity among sections of a single  document bear a closer relation to this project than the works above. [sent-46, score-0.03]
</p><p>30 Very little computational work on cuneiform lan-  guages or texts exists. [sent-48, score-0.452]
</p><p>31 The most notable example is a study that examined grapheme distribution as a way to understand Hurrian substratal interference in the orthography of Akkadian-language cuneiform texts written in the Hurrian-speaking town of Nuzi (Smith, 2007). [sent-49, score-0.527]
</p><p>32 4  The Project Corpus  For this project, I use a corpus of neo-Hittite fragment transcriptions available from H. [sent-51, score-0.068]
</p><p>33 The fragments themselves are included as plain text, with restorations by the transcribers left intact and set off by brackets, in the manner typical of cuneiform transcription. [sent-56, score-0.764]
</p><p>34 In transcription, signs with phonemic value are written in lower case characters, while ideograms are represented in all caps. [sent-57, score-0.316]
</p><p>35 Sign boundaries are represented by a hyphen, indicating the next sign is part of the current word, by an equals sign, indicating the next sign is a clitic, or a space, indicating that the next sign is part of a new word. [sent-58, score-0.213]
</p><p>36 i s -t ar-ni=sum-m [ i ] ] x nu=kn ki-x [  [ ] KUR URUMi-i z -ri=y [ a [ i -t ar-ni ] =sum-mi e-e s -du [ s [ ] nu=kn A-NA KUR URUMi-i z -ri [ [ A-NA EGI ] R UDmi i -t ar-ni=su [ m-mi s This fragment, KUB XXI25, is very small and broken on both sides. [sent-60, score-0.035]
</p><p>37 The areas between brackets are sections of the text broken off or effaced by erosion of tablet surface material. [sent-61, score-0.344]
</p><p>38 Any text present between brackets has been inferred from context and transcriber experience with usual phrasing in Hittite. [sent-62, score-0.204]
</p><p>39 In the last line, the sign EGIR, a Sumerian ideogram, which is split by a bracket, was partially effaced but still recognizable to the transcriber, and so is split by a bracket. [sent-63, score-0.115]
</p><p>40 5  Methods  For this project, Iused both Naive Bayes and Maximum Entropy classifiers as implemented by the MAchine Learning for LanguagE Toolkit, MALLET(McCallum, 2002). [sent-64, score-0.03]
</p><p>41 In one, anything in brackets or partially remaining after brackets was removed, leaving only characters actu-  ally preserved on the fragment. [sent-66, score-0.352]
</p><p>42 The other has all bracket characters removed, leaving all actual characters and all characters suggested by the transcribers. [sent-68, score-0.212]
</p><p>43 By removing the brackets but leaving the suggested characters, Ihoped to use the transcribers’ intuitions about Hittite texts to further improve the performance of both classifiers. [sent-70, score-0.297]
</p><p>44 The tokens were defined only by spaces, capturing all words in the corpus. [sent-72, score-0.031]
</p><p>45 The tokens were defined as a series of capital letters and punctuation marks, capturing only the Sumerian and Akkadian ideograms in the text, i. [sent-74, score-0.277]
</p><p>46 The training and tests were all performed using MALLET’s standard algorithms, cross-validated, Table 1: Results for Plain Corpus  IdTeAo klgeranToimzksaetOinosn lyNaiv. [sent-78, score-0.037]
</p><p>47 6  Results and Discussion  Accuracy values from the classifiers using the Plain corpus, and from the corpus with the Brackets Removed, are presented in Tables 1 and 2, respectively. [sent-86, score-0.03]
</p><p>48 The measures are raw accuracy, the fraction of the test fragments that the methods categorized correctly. [sent-87, score-0.282]
</p><p>49 The results for the Plain Corpus show that the Naive Bayes classifier was 55% accurate with all tokens, and 44% accurate with ideograms alone. [sent-88, score-0.303]
</p><p>50 The Maximum Entropy classifier was 61% accurate with  all tokens, and 51% accurate with ideograms only. [sent-89, score-0.303]
</p><p>51 Both classifiers performed better with the Brackets Removed corpus. [sent-90, score-0.03]
</p><p>52 The Naive Bayes classifier was accurate 64% of the time with all tokens and 49% of the time with ideograms only. [sent-91, score-0.292]
</p><p>53 The Maximum Entropy classifier was 67% accurate with all tokens, and 54% accurate with ideograms only. [sent-92, score-0.303]
</p><p>54 The predicted increase in accuracy using ideograms was not upheld by the above tests. [sent-93, score-0.219]
</p><p>55 Some early tests suggested occasional excellent results for this tokenization scheme, including a single random 90-10 training/test run that showed a test accuracy of . [sent-95, score-0.06]
</p><p>56 86, much higher than any larger cross-validated test included above. [sent-96, score-0.032]
</p><p>57 This suggests, 246 perhaps unsurprisingly, that the accuracy of classification using Sumerograms and Akkadograms is heavily dependent on the structure of the fragments in question. [sent-97, score-0.319]
</p><p>58 Maximum Entropy classification proved to be  slightly better, in every instance, than Naive Bayes classification, a fact that will prove useful in future tests and applications. [sent-98, score-0.074]
</p><p>59 The fact that removing the brackets and including the transcribers’ additions improved the performance of all classifiers will likewise prove useful, since transcriptions of fragments are typically published with such bracketed additions. [sent-99, score-0.542]
</p><p>60 It also seems to demonstrate the quality of these additions made by transcribers. [sent-100, score-0.038]
</p><p>61 Overall, these tests suggest that in general, the ‘use-everything’ approach is better for accurate classification of Hittite tablet fragments with larger CTH texts. [sent-101, score-0.535]
</p><p>62 However, in some cases, when the fragments in question have a large number of Sumerograms and Akkadograms, using them exclusively may be the right choice. [sent-102, score-0.282]
</p><p>63 regarding tablet fragments as elements for con-  nection by clustering algorithms, might work well. [sent-106, score-0.387]
</p><p>64 Given the large number of small fragments now coming to light, this method could speed the process of text assembly considerably. [sent-107, score-0.304]
</p><p>65 A new set of archives, recently discovered in the Hittite city of are only now beginning to see publication. [sent-108, score-0.031]
</p><p>66 This site contains more than 3000 new Hittite tablet fragments, with excavations ongoing(S u¨el, 2002). [sent-109, score-0.139]
</p><p>67 The jumbled nature of the dig site means that the process of assembling new texts from this site will be one of the major tasks in for Hittite scholars in the near future. [sent-110, score-0.307]
</p><p>68 , editor, Recent developments in Hittite archaeology and history: papers in memory of Hans G. [sent-147, score-0.077]
</p><p>69 Applied bayesian and classical inference: The case of the federalist papers. [sent-170, score-0.044]
</p><p>70 , editor, Recent developments in Hittite archaeology and history: papers in memory of Hans G. [sent-194, score-0.077]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hittite', 0.658), ('cuneiform', 0.351), ('fragments', 0.282), ('ideograms', 0.219), ('brackets', 0.138), ('sumerian', 0.132), ('akkadian', 0.11), ('tablet', 0.105), ('texts', 0.101), ('joins', 0.096), ('tablets', 0.096), ('akkadograms', 0.088), ('hoffner', 0.088), ('sumerograms', 0.088), ('naive', 0.073), ('sign', 0.071), ('kub', 0.066), ('kur', 0.066), ('melchert', 0.066), ('nuzi', 0.066), ('transcribers', 0.066), ('plain', 0.065), ('assembling', 0.057), ('clay', 0.057), ('ideogram', 0.057), ('signs', 0.057), ('scholars', 0.052), ('bayes', 0.051), ('copies', 0.049), ('cth', 0.046), ('removed', 0.045), ('mallet', 0.044), ('archaeology', 0.044), ('aslihan', 0.044), ('aus', 0.044), ('boghazk', 0.044), ('catalogued', 0.044), ('dewdney', 0.044), ('dhesi', 0.044), ('effaced', 0.044), ('federalist', 0.044), ('hethport', 0.044), ('horst', 0.044), ('hurrian', 0.044), ('ihope', 0.044), ('klengel', 0.044), ('mosteller', 0.044), ('simrit', 0.044), ('southeastcon', 0.044), ('syllabic', 0.044), ('tomokiyo', 0.044), ('transcriber', 0.044), ('uterbock', 0.044), ('yener', 0.044), ('zburg', 0.044), ('writing', 0.042), ('accurate', 0.042), ('characters', 0.041), ('history', 0.041), ('written', 0.04), ('fragment', 0.04), ('viewing', 0.038), ('photograph', 0.038), ('fragmented', 0.038), ('eastern', 0.038), ('additions', 0.038), ('tests', 0.037), ('classification', 0.037), ('broken', 0.035), ('leaving', 0.035), ('categorization', 0.035), ('interference', 0.035), ('hans', 0.035), ('ancient', 0.035), ('site', 0.034), ('harry', 0.033), ('developments', 0.033), ('larger', 0.032), ('discovered', 0.031), ('tokens', 0.031), ('craig', 0.031), ('bracket', 0.031), ('entropy', 0.03), ('classifiers', 0.03), ('project', 0.03), ('nu', 0.029), ('archives', 0.029), ('near', 0.029), ('transcriptions', 0.028), ('kn', 0.027), ('capital', 0.027), ('join', 0.027), ('classify', 0.026), ('published', 0.026), ('newspaper', 0.025), ('ent', 0.024), ('editor', 0.024), ('suggested', 0.023), ('smith', 0.022), ('text', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="200-tfidf-1" href="./acl-2012-Toward_Automatically_Assembling_Hittite-Language_Cuneiform_Tablet_Fragments_into_Larger_Texts.html">200 acl-2012-Toward Automatically Assembling Hittite-Language Cuneiform Tablet Fragments into Larger Texts</a></p>
<p>Author: Stephen Tyndall</p><p>Abstract: This paper presents the problem within Hittite and Ancient Near Eastern studies of fragmented and damaged cuneiform texts, and proposes to use well-known text classification metrics, in combination with some facts about the structure of Hittite-language cuneiform texts, to help classify a number offragments of clay cuneiform-script tablets into more complete texts. In particular, Ipropose using Sumerian and Akkadian ideogrammatic signs within Hittite texts to improve the performance of Naive Bayes and Maximum Entropy classifiers. The performance in some cases is improved, and in some cases very much not, suggesting that the variable frequency of occurrence of these ideograms in individual fragments makes considerable difference in the ideal choice for a classification method. Further, complexities of the writing system and the digital availability ofHittite texts complicate the problem.</p><p>2 0.11285498 <a title="200-tfidf-2" href="./acl-2012-Native_Language_Detection_with_Tree_Substitution_Grammars.html">154 acl-2012-Native Language Detection with Tree Substitution Grammars</a></p>
<p>Author: Benjamin Swanson ; Eugene Charniak</p><p>Abstract: We investigate the potential of Tree Substitution Grammars as a source of features for native language detection, the task of inferring an author’s native language from text in a different language. We compare two state of the art methods for Tree Substitution Grammar induction and show that features from both methods outperform previous state of the art results at native language detection. Furthermore, we contrast these two induction algorithms and show that the Bayesian approach produces superior classification results with a smaller feature set.</p><p>3 0.038892094 <a title="200-tfidf-3" href="./acl-2012-Text_Segmentation_by_Language_Using_Minimum_Description_Length.html">194 acl-2012-Text Segmentation by Language Using Minimum Description Length</a></p>
<p>Author: Hiroshi Yamaguchi ; Kumiko Tanaka-Ishii</p><p>Abstract: The problem addressed in this paper is to segment a given multilingual document into segments for each language and then identify the language of each segment. The problem was motivated by an attempt to collect a large amount of linguistic data for non-major languages from the web. The problem is formulated in terms of obtaining the minimum description length of a text, and the proposed solution finds the segments and their languages through dynamic programming. Empirical results demonstrating the potential of this approach are presented for experiments using texts taken from the Universal Declaration of Human Rights and Wikipedia, covering more than 200 languages.</p><p>4 0.035723098 <a title="200-tfidf-4" href="./acl-2012-Modeling_Topic_Dependencies_in_Hierarchical_Text_Categorization.html">146 acl-2012-Modeling Topic Dependencies in Hierarchical Text Categorization</a></p>
<p>Author: Alessandro Moschitti ; Qi Ju ; Richard Johansson</p><p>Abstract: In this paper, we encode topic dependencies in hierarchical multi-label Text Categorization (TC) by means of rerankers. We represent reranking hypotheses with several innovative kernels considering both the structure of the hierarchy and the probability of nodes. Additionally, to better investigate the role ofcategory relationships, we consider two interesting cases: (i) traditional schemes in which node-fathers include all the documents of their child-categories; and (ii) more general schemes, in which children can include documents not belonging to their fathers. The extensive experimentation on Reuters Corpus Volume 1 shows that our rerankers inject effective structural semantic dependencies in multi-classifiers and significantly outperform the state-of-the-art.</p><p>5 0.030588616 <a title="200-tfidf-5" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>Author: Hiroyuki Shindo ; Yusuke Miyao ; Akinori Fujino ; Masaaki Nagata</p><p>Abstract: We propose Symbol-Refined Tree Substitution Grammars (SR-TSGs) for syntactic parsing. An SR-TSG is an extension of the conventional TSG model where each nonterminal symbol can be refined (subcategorized) to fit the training data. We aim to provide a unified model where TSG rules and symbol refinement are learned from training data in a fully automatic and consistent fashion. We present a novel probabilistic SR-TSG model based on the hierarchical Pitman-Yor Process to encode backoff smoothing from a fine-grained SR-TSG to simpler CFG rules, and develop an efficient training method based on Markov Chain Monte Carlo (MCMC) sampling. Our SR-TSG parser achieves an F1 score of 92.4% in the Wall Street Journal (WSJ) English Penn Treebank parsing task, which is a 7.7 point improvement over a conventional Bayesian TSG parser, and better than state-of-the-art discriminative reranking parsers.</p><p>6 0.029717535 <a title="200-tfidf-6" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>7 0.027221246 <a title="200-tfidf-7" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>8 0.026650742 <a title="200-tfidf-8" href="./acl-2012-A_Meta_Learning_Approach_to_Grammatical_Error_Correction.html">15 acl-2012-A Meta Learning Approach to Grammatical Error Correction</a></p>
<p>9 0.024474276 <a title="200-tfidf-9" href="./acl-2012-A_Corpus_of_Textual_Revisions_in_Second_Language_Writing.html">8 acl-2012-A Corpus of Textual Revisions in Second Language Writing</a></p>
<p>10 0.02405699 <a title="200-tfidf-10" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>11 0.023254484 <a title="200-tfidf-11" href="./acl-2012-FLOW%3A_A_First-Language-Oriented_Writing_Assistant_System.html">92 acl-2012-FLOW: A First-Language-Oriented Writing Assistant System</a></p>
<p>12 0.023080396 <a title="200-tfidf-12" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>13 0.022782398 <a title="200-tfidf-13" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<p>14 0.02245694 <a title="200-tfidf-14" href="./acl-2012-Applications_of_GPC_Rules_and_Character_Structures_in_Games_for_Learning_Chinese_Characters.html">26 acl-2012-Applications of GPC Rules and Character Structures in Games for Learning Chinese Characters</a></p>
<p>15 0.020810928 <a title="200-tfidf-15" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>16 0.020380059 <a title="200-tfidf-16" href="./acl-2012-Tokenization%3A_Returning_to_a_Long_Solved_Problem__A_Survey%2C_Contrastive_Experiment%2C_Recommendations%2C_and_Toolkit_.html">197 acl-2012-Tokenization: Returning to a Long Solved Problem  A Survey, Contrastive Experiment, Recommendations, and Toolkit </a></p>
<p>17 0.019926189 <a title="200-tfidf-17" href="./acl-2012-Efficient_Search_for_Transformation-based_Inference.html">78 acl-2012-Efficient Search for Transformation-based Inference</a></p>
<p>18 0.01979379 <a title="200-tfidf-18" href="./acl-2012-Collective_Classification_for_Fine-grained_Information_Status.html">50 acl-2012-Collective Classification for Fine-grained Information Status</a></p>
<p>19 0.018455338 <a title="200-tfidf-19" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>20 0.018158918 <a title="200-tfidf-20" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.066), (1, 0.019), (2, -0.016), (3, -0.013), (4, -0.021), (5, 0.024), (6, 0.004), (7, 0.037), (8, -0.019), (9, -0.001), (10, -0.04), (11, -0.055), (12, -0.012), (13, 0.034), (14, 0.019), (15, -0.05), (16, 0.011), (17, -0.049), (18, 0.018), (19, 0.028), (20, -0.012), (21, 0.025), (22, 0.023), (23, -0.008), (24, 0.035), (25, 0.01), (26, -0.04), (27, 0.069), (28, 0.02), (29, -0.034), (30, 0.012), (31, 0.001), (32, 0.035), (33, -0.022), (34, 0.05), (35, -0.066), (36, 0.008), (37, 0.041), (38, 0.017), (39, 0.04), (40, 0.012), (41, 0.097), (42, -0.13), (43, 0.037), (44, 0.028), (45, 0.007), (46, 0.095), (47, 0.023), (48, -0.018), (49, -0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.933451 <a title="200-lsi-1" href="./acl-2012-Toward_Automatically_Assembling_Hittite-Language_Cuneiform_Tablet_Fragments_into_Larger_Texts.html">200 acl-2012-Toward Automatically Assembling Hittite-Language Cuneiform Tablet Fragments into Larger Texts</a></p>
<p>Author: Stephen Tyndall</p><p>Abstract: This paper presents the problem within Hittite and Ancient Near Eastern studies of fragmented and damaged cuneiform texts, and proposes to use well-known text classification metrics, in combination with some facts about the structure of Hittite-language cuneiform texts, to help classify a number offragments of clay cuneiform-script tablets into more complete texts. In particular, Ipropose using Sumerian and Akkadian ideogrammatic signs within Hittite texts to improve the performance of Naive Bayes and Maximum Entropy classifiers. The performance in some cases is improved, and in some cases very much not, suggesting that the variable frequency of occurrence of these ideograms in individual fragments makes considerable difference in the ideal choice for a classification method. Further, complexities of the writing system and the digital availability ofHittite texts complicate the problem.</p><p>2 0.57291359 <a title="200-lsi-2" href="./acl-2012-Native_Language_Detection_with_Tree_Substitution_Grammars.html">154 acl-2012-Native Language Detection with Tree Substitution Grammars</a></p>
<p>Author: Benjamin Swanson ; Eugene Charniak</p><p>Abstract: We investigate the potential of Tree Substitution Grammars as a source of features for native language detection, the task of inferring an author’s native language from text in a different language. We compare two state of the art methods for Tree Substitution Grammar induction and show that features from both methods outperform previous state of the art results at native language detection. Furthermore, we contrast these two induction algorithms and show that the Bayesian approach produces superior classification results with a smaller feature set.</p><p>3 0.54210287 <a title="200-lsi-3" href="./acl-2012-Text_Segmentation_by_Language_Using_Minimum_Description_Length.html">194 acl-2012-Text Segmentation by Language Using Minimum Description Length</a></p>
<p>Author: Hiroshi Yamaguchi ; Kumiko Tanaka-Ishii</p><p>Abstract: The problem addressed in this paper is to segment a given multilingual document into segments for each language and then identify the language of each segment. The problem was motivated by an attempt to collect a large amount of linguistic data for non-major languages from the web. The problem is formulated in terms of obtaining the minimum description length of a text, and the proposed solution finds the segments and their languages through dynamic programming. Empirical results demonstrating the potential of this approach are presented for experiments using texts taken from the Universal Declaration of Human Rights and Wikipedia, covering more than 200 languages.</p><p>4 0.49058679 <a title="200-lsi-4" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>Author: Marco Lui ; Timothy Baldwin</p><p>Abstract: We present langid .py, an off-the-shelflanguage identification tool. We discuss the design and implementation of langid .py, and provide an empirical comparison on 5 longdocument datasets, and 2 datasets from the microblog domain. We find that langid .py maintains consistently high accuracy across all domains, making it ideal for end-users that require language identification without wanting to invest in preparation of in-domain training data.</p><p>5 0.42652538 <a title="200-lsi-5" href="./acl-2012-Beefmoves%3A_Dissemination%2C_Diversity%2C_and_Dynamics_of_English_Borrowings_in_a_German_Hip_Hop_Forum.html">39 acl-2012-Beefmoves: Dissemination, Diversity, and Dynamics of English Borrowings in a German Hip Hop Forum</a></p>
<p>Author: Matt Garley ; Julia Hockenmaier</p><p>Abstract: We investigate how novel English-derived words (anglicisms) are used in a Germanlanguage Internet hip hop forum, and what factors contribute to their uptake.</p><p>6 0.41197512 <a title="200-lsi-6" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>7 0.4026618 <a title="200-lsi-7" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>8 0.3874923 <a title="200-lsi-8" href="./acl-2012-A_Meta_Learning_Approach_to_Grammatical_Error_Correction.html">15 acl-2012-A Meta Learning Approach to Grammatical Error Correction</a></p>
<p>9 0.38003278 <a title="200-lsi-9" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>10 0.35994458 <a title="200-lsi-10" href="./acl-2012-Unsupervized_Word_Segmentation%3A_the_Case_for_Mandarin_Chinese.html">210 acl-2012-Unsupervized Word Segmentation: the Case for Mandarin Chinese</a></p>
<p>11 0.35681325 <a title="200-lsi-11" href="./acl-2012-Syntactic_Stylometry_for_Deception_Detection.html">190 acl-2012-Syntactic Stylometry for Deception Detection</a></p>
<p>12 0.34600037 <a title="200-lsi-12" href="./acl-2012-Applications_of_GPC_Rules_and_Character_Structures_in_Games_for_Learning_Chinese_Characters.html">26 acl-2012-Applications of GPC Rules and Character Structures in Games for Learning Chinese Characters</a></p>
<p>13 0.33603638 <a title="200-lsi-13" href="./acl-2012-A_Corpus_of_Textual_Revisions_in_Second_Language_Writing.html">8 acl-2012-A Corpus of Textual Revisions in Second Language Writing</a></p>
<p>14 0.33350798 <a title="200-lsi-14" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>15 0.31401616 <a title="200-lsi-15" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>16 0.30836412 <a title="200-lsi-16" href="./acl-2012-You_Had_Me_at_Hello%3A_How_Phrasing_Affects_Memorability.html">218 acl-2012-You Had Me at Hello: How Phrasing Affects Memorability</a></p>
<p>17 0.30258012 <a title="200-lsi-17" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>18 0.29861811 <a title="200-lsi-18" href="./acl-2012-Tokenization%3A_Returning_to_a_Long_Solved_Problem__A_Survey%2C_Contrastive_Experiment%2C_Recommendations%2C_and_Toolkit_.html">197 acl-2012-Tokenization: Returning to a Long Solved Problem  A Survey, Contrastive Experiment, Recommendations, and Toolkit </a></p>
<p>19 0.29592526 <a title="200-lsi-19" href="./acl-2012-The_Creation_of_a_Corpus_of_English_Metalanguage.html">195 acl-2012-The Creation of a Corpus of English Metalanguage</a></p>
<p>20 0.29590479 <a title="200-lsi-20" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.026), (26, 0.032), (28, 0.039), (30, 0.02), (34, 0.46), (39, 0.029), (74, 0.031), (82, 0.028), (84, 0.025), (85, 0.012), (90, 0.06), (92, 0.073), (94, 0.012), (99, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80484778 <a title="200-lda-1" href="./acl-2012-Toward_Automatically_Assembling_Hittite-Language_Cuneiform_Tablet_Fragments_into_Larger_Texts.html">200 acl-2012-Toward Automatically Assembling Hittite-Language Cuneiform Tablet Fragments into Larger Texts</a></p>
<p>Author: Stephen Tyndall</p><p>Abstract: This paper presents the problem within Hittite and Ancient Near Eastern studies of fragmented and damaged cuneiform texts, and proposes to use well-known text classification metrics, in combination with some facts about the structure of Hittite-language cuneiform texts, to help classify a number offragments of clay cuneiform-script tablets into more complete texts. In particular, Ipropose using Sumerian and Akkadian ideogrammatic signs within Hittite texts to improve the performance of Naive Bayes and Maximum Entropy classifiers. The performance in some cases is improved, and in some cases very much not, suggesting that the variable frequency of occurrence of these ideograms in individual fragments makes considerable difference in the ideal choice for a classification method. Further, complexities of the writing system and the digital availability ofHittite texts complicate the problem.</p><p>2 0.75528455 <a title="200-lda-2" href="./acl-2012-Humor_as_Circuits_in_Semantic_Networks.html">112 acl-2012-Humor as Circuits in Semantic Networks</a></p>
<p>Author: Igor Labutov ; Hod Lipson</p><p>Abstract: This work presents a first step to a general implementation of the Semantic-Script Theory of Humor (SSTH). Of the scarce amount of research in computational humor, no research had focused on humor generation beyond simple puns and punning riddles. We propose an algorithm for mining simple humorous scripts from a semantic network (ConceptNet) by specifically searching for dual scripts that jointly maximize overlap and incongruity metrics in line with Raskin’s Semantic-Script Theory of Humor. Initial results show that a more relaxed constraint of this form is capable of generating humor of deeper semantic content than wordplay riddles. We evaluate the said metrics through a user-assessed quality of the generated two-liners.</p><p>3 0.52723885 <a title="200-lda-3" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>Author: Marco Lui ; Timothy Baldwin</p><p>Abstract: We present langid .py, an off-the-shelflanguage identification tool. We discuss the design and implementation of langid .py, and provide an empirical comparison on 5 longdocument datasets, and 2 datasets from the microblog domain. We find that langid .py maintains consistently high accuracy across all domains, making it ideal for end-users that require language identification without wanting to invest in preparation of in-domain training data.</p><p>4 0.37984854 <a title="200-lda-4" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>5 0.25212446 <a title="200-lda-5" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>Author: Elif Yamangil ; Stuart Shieber</p><p>Abstract: We present a Bayesian nonparametric model for estimating tree insertion grammars (TIG), building upon recent work in Bayesian inference of tree substitution grammars (TSG) via Dirichlet processes. Under our general variant of TIG, grammars are estimated via the Metropolis-Hastings algorithm that uses a context free grammar transformation as a proposal, which allows for cubic-time string parsing as well as tree-wide joint sampling of derivations in the spirit of Cohn and Blunsom (2010). We use the Penn treebank for our experiments and find that our proposal Bayesian TIG model not only has competitive parsing performance but also finds compact yet linguistically rich TIG representations of the data.</p><p>6 0.24767812 <a title="200-lda-6" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>7 0.24580327 <a title="200-lda-7" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>8 0.24531642 <a title="200-lda-8" href="./acl-2012-BIUTEE%3A_A_Modular_Open-Source_System_for_Recognizing_Textual_Entailment.html">36 acl-2012-BIUTEE: A Modular Open-Source System for Recognizing Textual Entailment</a></p>
<p>9 0.24419856 <a title="200-lda-9" href="./acl-2012-MIX_Is_Not_a_Tree-Adjoining_Language.html">139 acl-2012-MIX Is Not a Tree-Adjoining Language</a></p>
<p>10 0.24029057 <a title="200-lda-10" href="./acl-2012-Tweet_Recommendation_with_Graph_Co-Ranking.html">205 acl-2012-Tweet Recommendation with Graph Co-Ranking</a></p>
<p>11 0.23946916 <a title="200-lda-11" href="./acl-2012-Native_Language_Detection_with_Tree_Substitution_Grammars.html">154 acl-2012-Native Language Detection with Tree Substitution Grammars</a></p>
<p>12 0.23887119 <a title="200-lda-12" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>13 0.23727576 <a title="200-lda-13" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>14 0.23709382 <a title="200-lda-14" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>15 0.23606783 <a title="200-lda-15" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>16 0.23582272 <a title="200-lda-16" href="./acl-2012-Exploiting_Latent_Information_to_Predict_Diffusions_of_Novel_Topics_on_Social_Networks.html">86 acl-2012-Exploiting Latent Information to Predict Diffusions of Novel Topics on Social Networks</a></p>
<p>17 0.23207608 <a title="200-lda-17" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>18 0.23198649 <a title="200-lda-18" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>19 0.2319359 <a title="200-lda-19" href="./acl-2012-Learning_the_Latent_Semantics_of_a_Concept_from_its_Definition.html">132 acl-2012-Learning the Latent Semantics of a Concept from its Definition</a></p>
<p>20 0.23176938 <a title="200-lda-20" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
