<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-196" href="#">acl2012-196</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</h1>
<br/><p>Source: <a title="acl-2012-196-pdf" href="http://aclweb.org/anthology//P/P12/P12-3011.pdf">pdf</a></p><p>Author: Brian Roark ; Richard Sproat ; Cyril Allauzen ; Michael Riley ; Jeffrey Sorensen ; Terry Tai</p><p>Abstract: In this paper, we present a new collection of open-source software libraries that provides command line binary utilities and library classes and functions for compiling regular expression and context-sensitive rewrite rules into finite-state transducers, and for n-gram language modeling. The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models.</p><p>Reference: <a title="acl-2012-196-reference" href="../acl2012_reference/acl-2012-The_OpenGrm_open-source_finite-state_grammar_software_libraries_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The OpenGrm open-source finite-state grammar software libraries Brian Roark† Richard Sproat†◦ Cyril Allauzen◦ Michael Riley◦ Jeffrey Sorensen◦ & Terry Tai◦ †Oregon Health & Science University, Portland, Oregon ◦Google, Inc. [sent-1, score-0.371]
</p><p>2 The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models. [sent-3, score-0.495]
</p><p>3 1 Introduction  libraries1  The OpenGrm are a (growing) collection of open-source software libraries for building and applying various kinds of formal grammars. [sent-4, score-0.348]
</p><p>4 The C++ libraries use the OpenFst for the underlying finite-state representation, which allows for easy inspection of the resulting grammars and models, as well as straightforward combination with other finite-state transducers. [sent-5, score-0.404]
</p><p>5 Like OpenFst, there are easy-to-use command line binaries for fre-  library2  quently used operations, as well as a C++ library interface, allowing library users to create their own algorithms from the basic classes and functions provided. [sent-6, score-0.532]
</p><p>6 The libraries can be used for a range of common string processing tasks, such as text normalization, as well as for building and using large statistical models for applications like speech recognition. [sent-7, score-0.347]
</p><p>7 In the rest of the paper, we will present each of the two libraries, starting with the Thrax grammar compiler and then the NGram library. [sent-8, score-0.22]
</p><p>8 First, though, we will briefly present some preliminary (informal) background on weighted finite-state transducers (WFST), just as needed for this paper. [sent-9, score-0.164]
</p><p>9 org/ 61 2  Informal WFST preliminaries  A weighted finite-state transducer consists of a set of states and transitions between states. [sent-14, score-0.289]
</p><p>10 There is an initial state and a subset of states are final. [sent-15, score-0.138]
</p><p>11 Each transition is labeled with an input symbol from an input alphabet; an output symbol from an output alpha-  bet; an origin state; a destination state; and a weight. [sent-16, score-0.797]
</p><p>12 A path in the WFST is a sequence of transitions where each transition’s destination state is the next transition’s origin state. [sent-18, score-0.423]
</p><p>13 A valid path through the WFST is a path where the origin state of the first transition is an initial state, and the the last transition is to a final state. [sent-19, score-0.774]
</p><p>14 Weights combine along the path according to the semiring of the WFST. [sent-20, score-0.237]
</p><p>15 If every transition in the transducer has the same input and output symbol, then the WFST represents a weighted finite-state automaton. [sent-21, score-0.382]
</p><p>16 symbol represents the empty string, which allows the transition to be traversed without consuming any symbol. [sent-24, score-0.637]
</p><p>17 The φ (or failure) symbol on a transition also allows it to be traversed without consuming any symbol, but it differs from ? [sent-25, score-0.604]
</p><p>18 in only allowing traversal if the symbol being matched does not label any other transition leaving the same state, i. [sent-26, score-0.501]
</p><p>19 For a more detailed presentation of WFSTs, see Allauzen et al. [sent-29, score-0.037]
</p><p>20 3  The Thrax Grammar Compiler  The Thrax grammar compiler3 compiles grammars that consist of regular expressions, and contextdependent rewrite rules, into FST archives (fars) of weighted finite state transducers. [sent-31, score-0.496]
</p><p>21 Grammars may 3The compiler is named after Dionysius Thrax (170– 90BCE), the reputed first Greek grammarian. [sent-32, score-0.166]
</p><p>22 c s 2o0c1ia2ti Aosns fo cria Ctio nm fpourta Ctoiomnpault Laitniognuaislt Licisn,g puaigsteiscs 61–6 , be split over multiple files and imported into other grammars. [sent-35, score-0.07]
</p><p>23 Strings in the rules may be parsed in one of three different ways: as a sequence of bytes (the default), as utf8 encodings, or according to a user-provided symbol table. [sent-36, score-0.292]
</p><p>24 With the --s ave symbol s flag, the transducers can be saved out into fars with appropriate symbol tables. [sent-37, score-0.709]
</p><p>25 The Thrax libraries provide full support for different weight (semiring) classes. [sent-38, score-0.262]
</p><p>26 The command-line flag --semi ring allows one to set the semiring, currently to one of: tropical (default), log or log64 semirings. [sent-39, score-0.209]
</p><p>27 1 General Description Thrax revolves around rules which, typically, construct an FST based on a given input. [sent-41, score-0.037]
</p><p>28 Thrax provides a set of built-in functions that aid in the construction of more complex expressions. [sent-43, score-0.102]
</p><p>29 We have already seen the disjunction “|” in tshioen s pr. [sent-44, score-0.048]
</p><p>30 O sethener hstean ddiasjrudn rcetigounla “r| operations are expr*, expr+, expr? [sent-46, score-0.038]
</p><p>31 and expr{m,n}, the latter repeating expr between m dan edx n {timm,ne}s,, inclusive. [sent-47, score-0.317]
</p><p>32 Composition is notated with “@” so that expr1 @ expr2 denotes the composition of expr1 and expr2. [sent-48, score-0.106]
</p><p>33 Rewriting is denoted with “:”  where expr1 : expr2 rewrites strings that match expr1 into expr2. [sent-49, score-0.096]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('thrax', 0.442), ('expr', 0.276), ('libraries', 0.262), ('opengrm', 0.221), ('pear', 0.221), ('wfst', 0.22), ('symbol', 0.207), ('openfst', 0.205), ('transition', 0.193), ('compiler', 0.166), ('kiwi', 0.166), ('semiring', 0.166), ('library', 0.123), ('origin', 0.116), ('fst', 0.111), ('fars', 0.11), ('traversed', 0.11), ('transducers', 0.106), ('state', 0.104), ('transducer', 0.098), ('fsts', 0.096), ('flag', 0.088), ('enclosed', 0.088), ('allauzen', 0.082), ('command', 0.077), ('grammars', 0.076), ('destination', 0.074), ('identifier', 0.074), ('path', 0.071), ('functions', 0.069), ('consuming', 0.065), ('strings', 0.059), ('weighted', 0.058), ('composition', 0.058), ('transitions', 0.058), ('rewrite', 0.058), ('informal', 0.055), ('software', 0.055), ('string', 0.054), ('grammar', 0.054), ('tropical', 0.048), ('sorensen', 0.048), ('bet', 0.048), ('quently', 0.048), ('disjunction', 0.048), ('wfsts', 0.048), ('notated', 0.048), ('uni', 0.048), ('bytes', 0.048), ('oregon', 0.045), ('ring', 0.044), ('contextdependent', 0.044), ('utilities', 0.044), ('ave', 0.044), ('repeating', 0.041), ('operators', 0.041), ('encodings', 0.041), ('preliminaries', 0.041), ('imported', 0.041), ('regular', 0.039), ('compiling', 0.039), ('operations', 0.038), ('rules', 0.037), ('sproat', 0.037), ('traversal', 0.037), ('greek', 0.037), ('presentation', 0.037), ('riley', 0.037), ('rewrites', 0.037), ('archives', 0.037), ('health', 0.037), ('inspection', 0.037), ('saved', 0.035), ('custom', 0.035), ('roark', 0.035), ('modifying', 0.034), ('terry', 0.034), ('allowing', 0.034), ('states', 0.034), ('default', 0.033), ('expressions', 0.033), ('represents', 0.033), ('aid', 0.033), ('alphabet', 0.032), ('failure', 0.032), ('building', 0.031), ('classes', 0.031), ('operator', 0.031), ('cyril', 0.031), ('rewriting', 0.03), ('hs', 0.03), ('leaving', 0.03), ('files', 0.029), ('allows', 0.029), ('simplest', 0.028), ('line', 0.027), ('ngram', 0.026), ('final', 0.026), ('brian', 0.026), ('finite', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="196-tfidf-1" href="./acl-2012-The_OpenGrm_open-source_finite-state_grammar_software_libraries.html">196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</a></p>
<p>Author: Brian Roark ; Richard Sproat ; Cyril Allauzen ; Michael Riley ; Jeffrey Sorensen ; Terry Tai</p><p>Abstract: In this paper, we present a new collection of open-source software libraries that provides command line binary utilities and library classes and functions for compiling regular expression and context-sensitive rewrite rules into finite-state transducers, and for n-gram language modeling. The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models.</p><p>2 0.10479038 <a title="196-tfidf-2" href="./acl-2012-Automated_Essay_Scoring_Based_on_Finite_State_Transducer%3A_towards_ASR_Transcription_of_Oral_English_Speech.html">32 acl-2012-Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech</a></p>
<p>Author: Xingyuan Peng ; Dengfeng Ke ; Bo Xu</p><p>Abstract: Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription. Therefore, we introduce a framework of Finite State Transducer (FST) to avoid the shortcomings. Compared with the Latent Semantic Analysis with Support Vector Regression (LSA-SVR) method (stands for the conventional measures), our FST method shows better performance especially towards the ASR transcription. In addition, we apply the synonyms similarity to expand the FST model. The final scoring performance reaches an acceptable level of 0.80 which is only 0.07 lower than the correlation (0.87) between human raters.</p><p>3 0.094572082 <a title="196-tfidf-3" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>Author: Bevan Jones ; Mark Johnson ; Sharon Goldwater</p><p>Abstract: Many semantic parsing models use tree transformations to map between natural language and meaning representation. However, while tree transformations are central to several state-of-the-art approaches, little use has been made of the rich literature on tree automata. This paper makes the connection concrete with a tree transducer based semantic parsing model and suggests that other models can be interpreted in a similar framework, increasing the generality of their contributions. In particular, this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers, producing state-of-the-art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers.</p><p>4 0.079538248 <a title="196-tfidf-4" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>Author: Hiroyuki Shindo ; Yusuke Miyao ; Akinori Fujino ; Masaaki Nagata</p><p>Abstract: We propose Symbol-Refined Tree Substitution Grammars (SR-TSGs) for syntactic parsing. An SR-TSG is an extension of the conventional TSG model where each nonterminal symbol can be refined (subcategorized) to fit the training data. We aim to provide a unified model where TSG rules and symbol refinement are learned from training data in a fully automatic and consistent fashion. We present a novel probabilistic SR-TSG model based on the hierarchical Pitman-Yor Process to encode backoff smoothing from a fine-grained SR-TSG to simpler CFG rules, and develop an efficient training method based on Markov Chain Monte Carlo (MCMC) sampling. Our SR-TSG parser achieves an F1 score of 92.4% in the Wall Street Journal (WSJ) English Penn Treebank parsing task, which is a 7.7 point improvement over a conventional Bayesian TSG parser, and better than state-of-the-art discriminative reranking parsers.</p><p>5 0.068468124 <a title="196-tfidf-5" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>Author: Micha Elsner ; Sharon Goldwater ; Jacob Eisenstein</p><p>Abstract: ILCC, School of Informatics School of Interactive Computing University of Edinburgh Georgia Institute of Technology Edinburgh, EH8 9AB, UK Atlanta, GA, 30308, USA (a) intended: /ju want w2n/ /want e kUki/ (b) surface: [j@ w a?P w2n] [wan @ kUki] During early language acquisition, infants must learn both a lexicon and a model of phonetics that explains how lexical items can vary in pronunciation—for instance “the” might be realized as [Di] or [D@]. Previous models of acquisition have generally tackled these problems in isolation, yet behavioral evidence suggests infants acquire lexical and phonetic knowledge simultaneously. We present a Bayesian model that clusters together phonetic variants of the same lexical item while learning both a language model over lexical items and a log-linear model of pronunciation variability based on articulatory features. The model is trained on transcribed surface pronunciations, and learns by bootstrapping, without access to the true lexicon. We test the model using a corpus of child-directed speech with realistic phonetic variation and either gold standard or automatically induced word boundaries. In both cases modeling variability improves the accuracy of the learned lexicon over a system that assumes each lexical item has a unique pronunciation.</p><p>6 0.048960056 <a title="196-tfidf-6" href="./acl-2012-MIX_Is_Not_a_Tree-Adjoining_Language.html">139 acl-2012-MIX Is Not a Tree-Adjoining Language</a></p>
<p>7 0.039373964 <a title="196-tfidf-7" href="./acl-2012-Efficient_Search_for_Transformation-based_Inference.html">78 acl-2012-Efficient Search for Transformation-based Inference</a></p>
<p>8 0.03858982 <a title="196-tfidf-8" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>9 0.037175391 <a title="196-tfidf-9" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>10 0.034874689 <a title="196-tfidf-10" href="./acl-2012-Strong_Lexicalization_of_Tree_Adjoining_Grammars.html">185 acl-2012-Strong Lexicalization of Tree Adjoining Grammars</a></p>
<p>11 0.031917877 <a title="196-tfidf-11" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>12 0.030403718 <a title="196-tfidf-12" href="./acl-2012-String_Re-writing_Kernel.html">184 acl-2012-String Re-writing Kernel</a></p>
<p>13 0.028890729 <a title="196-tfidf-13" href="./acl-2012-A_Nonparametric_Bayesian_Approach_to_Acoustic_Model_Discovery.html">16 acl-2012-A Nonparametric Bayesian Approach to Acoustic Model Discovery</a></p>
<p>14 0.028855663 <a title="196-tfidf-14" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>15 0.028827488 <a title="196-tfidf-15" href="./acl-2012-Probabilistic_Integration_of_Partial_Lexical_Information_for_Noise_Robust_Haptic_Voice_Recognition.html">165 acl-2012-Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice Recognition</a></p>
<p>16 0.02737119 <a title="196-tfidf-16" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>17 0.027243813 <a title="196-tfidf-17" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>18 0.025368644 <a title="196-tfidf-18" href="./acl-2012-Native_Language_Detection_with_Tree_Substitution_Grammars.html">154 acl-2012-Native Language Detection with Tree Substitution Grammars</a></p>
<p>19 0.024962163 <a title="196-tfidf-19" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>20 0.02369426 <a title="196-tfidf-20" href="./acl-2012-Tokenization%3A_Returning_to_a_Long_Solved_Problem__A_Survey%2C_Contrastive_Experiment%2C_Recommendations%2C_and_Toolkit_.html">197 acl-2012-Tokenization: Returning to a Long Solved Problem  A Survey, Contrastive Experiment, Recommendations, and Toolkit </a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.077), (1, 0.009), (2, -0.026), (3, -0.007), (4, -0.04), (5, 0.031), (6, 0.006), (7, 0.061), (8, 0.029), (9, 0.005), (10, -0.049), (11, -0.04), (12, -0.053), (13, 0.038), (14, 0.024), (15, -0.073), (16, 0.014), (17, 0.016), (18, 0.029), (19, 0.053), (20, 0.048), (21, -0.034), (22, -0.057), (23, -0.003), (24, -0.09), (25, 0.013), (26, 0.12), (27, 0.027), (28, 0.028), (29, 0.078), (30, 0.086), (31, 0.069), (32, -0.107), (33, 0.018), (34, -0.068), (35, -0.004), (36, -0.073), (37, 0.075), (38, 0.14), (39, 0.034), (40, 0.079), (41, -0.11), (42, 0.046), (43, 0.064), (44, 0.066), (45, -0.059), (46, 0.104), (47, 0.041), (48, 0.067), (49, 0.126)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96732777 <a title="196-lsi-1" href="./acl-2012-The_OpenGrm_open-source_finite-state_grammar_software_libraries.html">196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</a></p>
<p>Author: Brian Roark ; Richard Sproat ; Cyril Allauzen ; Michael Riley ; Jeffrey Sorensen ; Terry Tai</p><p>Abstract: In this paper, we present a new collection of open-source software libraries that provides command line binary utilities and library classes and functions for compiling regular expression and context-sensitive rewrite rules into finite-state transducers, and for n-gram language modeling. The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models.</p><p>2 0.66197622 <a title="196-lsi-2" href="./acl-2012-Automated_Essay_Scoring_Based_on_Finite_State_Transducer%3A_towards_ASR_Transcription_of_Oral_English_Speech.html">32 acl-2012-Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech</a></p>
<p>Author: Xingyuan Peng ; Dengfeng Ke ; Bo Xu</p><p>Abstract: Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription. Therefore, we introduce a framework of Finite State Transducer (FST) to avoid the shortcomings. Compared with the Latent Semantic Analysis with Support Vector Regression (LSA-SVR) method (stands for the conventional measures), our FST method shows better performance especially towards the ASR transcription. In addition, we apply the synonyms similarity to expand the FST model. The final scoring performance reaches an acceptable level of 0.80 which is only 0.07 lower than the correlation (0.87) between human raters.</p><p>3 0.63650531 <a title="196-lsi-3" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>Author: Bevan Jones ; Mark Johnson ; Sharon Goldwater</p><p>Abstract: Many semantic parsing models use tree transformations to map between natural language and meaning representation. However, while tree transformations are central to several state-of-the-art approaches, little use has been made of the rich literature on tree automata. This paper makes the connection concrete with a tree transducer based semantic parsing model and suggests that other models can be interpreted in a similar framework, increasing the generality of their contributions. In particular, this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers, producing state-of-the-art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers.</p><p>4 0.5905987 <a title="196-lsi-4" href="./acl-2012-Probabilistic_Integration_of_Partial_Lexical_Information_for_Noise_Robust_Haptic_Voice_Recognition.html">165 acl-2012-Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice Recognition</a></p>
<p>Author: Khe Chai Sim</p><p>Abstract: This paper presents a probabilistic framework that combines multiple knowledge sources for Haptic Voice Recognition (HVR), a multimodal input method designed to provide efficient text entry on modern mobile devices. HVR extends the conventional voice input by allowing users to provide complementary partial lexical information via touch input to improve the efficiency and accuracy of voice recognition. This paper investigates the use of the initial letter of the words in the utterance as the partial lexical information. In addition to the acoustic and language models used in automatic speech recognition systems, HVR uses the haptic and partial lexical models as additional knowledge sources to reduce the recognition search space and suppress confusions. Experimental results show that both the word error rate and runtime factor can be re- duced by a factor of two using HVR.</p><p>5 0.44663754 <a title="196-lsi-5" href="./acl-2012-Strong_Lexicalization_of_Tree_Adjoining_Grammars.html">185 acl-2012-Strong Lexicalization of Tree Adjoining Grammars</a></p>
<p>Author: Andreas Maletti ; Joost Engelfriet</p><p>Abstract: Recently, it was shown (KUHLMANN, SATTA: Tree-adjoining grammars are not closed under strong lexicalization. Comput. Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol. A more powerful model, the simple context-free tree grammar, admits such a normal form. It can be effectively constructed and the maximal rank of the nonterminals only increases by 1. Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves.</p><p>6 0.39573565 <a title="196-lsi-6" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>7 0.38940164 <a title="196-lsi-7" href="./acl-2012-MIX_Is_Not_a_Tree-Adjoining_Language.html">139 acl-2012-MIX Is Not a Tree-Adjoining Language</a></p>
<p>8 0.30914566 <a title="196-lsi-8" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>9 0.27603605 <a title="196-lsi-9" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>10 0.27464971 <a title="196-lsi-10" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>11 0.27100903 <a title="196-lsi-11" href="./acl-2012-Discriminative_Strategies_to_Integrate_Multiword_Expression_Recognition_and_Parsing.html">75 acl-2012-Discriminative Strategies to Integrate Multiword Expression Recognition and Parsing</a></p>
<p>12 0.26768702 <a title="196-lsi-12" href="./acl-2012-WizIE%3A_A_Best_Practices_Guided_Development_Environment_for_Information_Extraction.html">215 acl-2012-WizIE: A Best Practices Guided Development Environment for Information Extraction</a></p>
<p>13 0.26126352 <a title="196-lsi-13" href="./acl-2012-Discriminative_Pronunciation_Modeling%3A_A_Large-Margin%2C_Feature-Rich_Approach.html">74 acl-2012-Discriminative Pronunciation Modeling: A Large-Margin, Feature-Rich Approach</a></p>
<p>14 0.2351101 <a title="196-lsi-14" href="./acl-2012-Hierarchical_Chunk-to-String_Translation.html">108 acl-2012-Hierarchical Chunk-to-String Translation</a></p>
<p>15 0.23480743 <a title="196-lsi-15" href="./acl-2012-Heuristic_Cube_Pruning_in_Linear_Time.html">107 acl-2012-Heuristic Cube Pruning in Linear Time</a></p>
<p>16 0.23450302 <a title="196-lsi-16" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>17 0.2206313 <a title="196-lsi-17" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>18 0.20268422 <a title="196-lsi-18" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>19 0.20215419 <a title="196-lsi-19" href="./acl-2012-A_Nonparametric_Bayesian_Approach_to_Acoustic_Model_Discovery.html">16 acl-2012-A Nonparametric Bayesian Approach to Acoustic Model Discovery</a></p>
<p>20 0.20184082 <a title="196-lsi-20" href="./acl-2012-How_Are_Spelling_Errors_Generated_and_Corrected%3F_A_Study_of_Corrected_and_Uncorrected_Spelling_Errors_Using_Keystroke_Logs.html">111 acl-2012-How Are Spelling Errors Generated and Corrected? A Study of Corrected and Uncorrected Spelling Errors Using Keystroke Logs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.027), (26, 0.048), (28, 0.019), (30, 0.025), (32, 0.327), (37, 0.013), (39, 0.046), (43, 0.011), (60, 0.12), (74, 0.023), (82, 0.023), (84, 0.014), (85, 0.022), (86, 0.012), (90, 0.072), (92, 0.078), (99, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76953065 <a title="196-lda-1" href="./acl-2012-The_OpenGrm_open-source_finite-state_grammar_software_libraries.html">196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</a></p>
<p>Author: Brian Roark ; Richard Sproat ; Cyril Allauzen ; Michael Riley ; Jeffrey Sorensen ; Terry Tai</p><p>Abstract: In this paper, we present a new collection of open-source software libraries that provides command line binary utilities and library classes and functions for compiling regular expression and context-sensitive rewrite rules into finite-state transducers, and for n-gram language modeling. The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models.</p><p>2 0.62036091 <a title="196-lda-2" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>3 0.38771924 <a title="196-lda-3" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>Author: Remy Kessler ; Xavier Tannier ; Caroline Hagege ; Veronique Moriceau ; Andre Bittar</p><p>Abstract: We present an approach for detecting salient (important) dates in texts in order to automatically build event timelines from a search query (e.g. the name of an event or person, etc.). This work was carried out on a corpus of newswire texts in English provided by the Agence France Presse (AFP). In order to extract salient dates that warrant inclusion in an event timeline, we first recognize and normalize temporal expressions in texts and then use a machine-learning approach to extract salient dates that relate to a particular topic. We focused only on extracting the dates and not the events to which they are related.</p><p>4 0.35056785 <a title="196-lda-4" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>Author: Bevan Jones ; Mark Johnson ; Sharon Goldwater</p><p>Abstract: Many semantic parsing models use tree transformations to map between natural language and meaning representation. However, while tree transformations are central to several state-of-the-art approaches, little use has been made of the rich literature on tree automata. This paper makes the connection concrete with a tree transducer based semantic parsing model and suggests that other models can be interpreted in a similar framework, increasing the generality of their contributions. In particular, this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers, producing state-of-the-art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers.</p><p>5 0.34224424 <a title="196-lda-5" href="./acl-2012-Improve_SMT_Quality_with_Automatically_Extracted_Paraphrase_Rules.html">116 acl-2012-Improve SMT Quality with Automatically Extracted Paraphrase Rules</a></p>
<p>Author: Wei He ; Hua Wu ; Haifeng Wang ; Ting Liu</p><p>Abstract: unkown-abstract</p><p>6 0.33623409 <a title="196-lda-6" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>7 0.33431441 <a title="196-lda-7" href="./acl-2012-BIUTEE%3A_A_Modular_Open-Source_System_for_Recognizing_Textual_Entailment.html">36 acl-2012-BIUTEE: A Modular Open-Source System for Recognizing Textual Entailment</a></p>
<p>8 0.33409145 <a title="196-lda-8" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>9 0.33130011 <a title="196-lda-9" href="./acl-2012-Learning_the_Latent_Semantics_of_a_Concept_from_its_Definition.html">132 acl-2012-Learning the Latent Semantics of a Concept from its Definition</a></p>
<p>10 0.33129632 <a title="196-lda-10" href="./acl-2012-Tweet_Recommendation_with_Graph_Co-Ranking.html">205 acl-2012-Tweet Recommendation with Graph Co-Ranking</a></p>
<p>11 0.33041468 <a title="196-lda-11" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>12 0.32791853 <a title="196-lda-12" href="./acl-2012-Native_Language_Detection_with_Tree_Substitution_Grammars.html">154 acl-2012-Native Language Detection with Tree Substitution Grammars</a></p>
<p>13 0.32791418 <a title="196-lda-13" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>14 0.32351804 <a title="196-lda-14" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>15 0.32289714 <a title="196-lda-15" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>16 0.32156694 <a title="196-lda-16" href="./acl-2012-Exploiting_Latent_Information_to_Predict_Diffusions_of_Novel_Topics_on_Social_Networks.html">86 acl-2012-Exploiting Latent Information to Predict Diffusions of Novel Topics on Social Networks</a></p>
<p>17 0.31978503 <a title="196-lda-17" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>18 0.31817436 <a title="196-lda-18" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>19 0.31780821 <a title="196-lda-19" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>20 0.31780422 <a title="196-lda-20" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
