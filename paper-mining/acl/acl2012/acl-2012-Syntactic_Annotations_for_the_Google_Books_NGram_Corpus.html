<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-189" href="#">acl2012-189</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</h1>
<br/><p>Source: <a title="acl-2012-189-pdf" href="http://aclweb.org/anthology//P/P12/P12-3029.pdf">pdf</a></p><p>Author: Yuri Lin ; Jean-Baptiste Michel ; Erez Aiden Lieberman ; Jon Orwant ; Will Brockman ; Slav Petrov</p><p>Abstract: We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6% of all books ever published. This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and headmodifier relationships are recorded. The annotations are produced automatically with statistical models that are specifically adapted to historical text. The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax.</p><p>Reference: <a title="acl-2012-189-reference" href="../acl2012_reference/acl-2012-Syntactic_Annotations_for_the_Google_Books_NGram_Corpus_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 {yuri l jbmi che l in, ,dre re z ,orwant ,brockman ,s l @ google . [sent-2, score-0.117]
</p><p>2 com av}  Abstract We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6% of all books ever published. [sent-3, score-0.712]
</p><p>3 This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and headmodifier relationships are recorded. [sent-4, score-0.308]
</p><p>4 The annotations are produced automatically with statistical models that are specifically adapted to historical text. [sent-5, score-0.234]
</p><p>5 The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax. [sent-6, score-0.089]
</p><p>6 , 2011) has enabled the quantitative analysis of linguistic and cultural trends as reflected in millions of books written over the past five centuries. [sent-8, score-0.512]
</p><p>7 The sheer quantity of and broad historical scope of the data has enabled a wide range of analyses (Michel et al. [sent-15, score-0.14]
</p><p>8 Of course, examining raw ngram frequencies is of limited utility when studying many aspects oflinguistic change, particularly the ones related to syntax. [sent-17, score-0.397]
</p><p>9 169  Figure 1: Usage frequencies of burned and burnt over time, showing that burned became the dominant spelling around 1880. [sent-19, score-0.603]
</p><p>10 Our new syntactic annotations enable a more refined analysis, suggesting that the crossing-point for the verb usage (burned VERB vs. [sent-20, score-0.261]
</p><p>11 Figure 1 illustrates how burned gradually overtook burnt, becoming more frequent around 1880. [sent-24, score-0.128]
</p><p>12 Unfortunately, as a study of verb regularization, this analysis is skewed by a significant confound: both words can serve as either verbs (e. [sent-25, score-0.174]
</p><p>13 Because many words have multiple syntactic interpretations, such confounds  often limit the utility of raw ngram frequency data. [sent-30, score-0.449]
</p><p>14 In this work we provide a new edition of the Google Books Ngram Corpus that contains over 8 million books, or 6% of all books ever published (cf. [sent-31, score-0.629]
</p><p>15 Moreover, we include syntactic analysis in order to facilitate a fine-grained analysis of the evolution of syntax. [sent-33, score-0.102]
</p><p>16 , in the phrase he burnt the toast, burnt is a verb; in the burnt toast, burnt is an adjective) and head-modifier dependencies (e. [sent-36, score-1.259]
</p><p>17 The annotated ngrams are far more useful for exProce dJienjgus, R ofep thueb 5lic0t hof A Knonruea ,l M 8-e1e4ti Jnugly o f2 t0h1e2 A. [sent-39, score-0.488]
</p><p>18 For our study of the regularization of the verb burn, the availability of syntactic annotations resolves the verb vs. [sent-42, score-0.338]
</p><p>19 adjective ambiguity in the original data, allowing us to only examine instances where burnt and burned appear as verbs. [sent-43, score-0.436]
</p><p>20 This more refined analysis suggests a crossover date for the frequency of the verb forms that is several decades earlier than the overall (verbs and adjectives) crossover. [sent-44, score-0.206]
</p><p>21 We use state-of-the-art statistical part-of-speech  taggers and dependency parsers to produce syntactic annotations for eight languages in the Google Books collection. [sent-45, score-0.31]
</p><p>22 The annotations consist of 12 language universal part-of-speech tags and unlabeled head-modifier dependencies. [sent-46, score-0.251]
</p><p>23 Section 4 describes the models that we used and the format of the annotations in detail. [sent-47, score-0.08]
</p><p>24 We assess the expected annotation accuracies experimentally and discuss how we adapt the taggers and parsers to historical text in Section 5. [sent-48, score-0.208]
</p><p>25 The annotated ngrams are available as a new edition of the Google Books Ngram Corpus; we provide some examples from the new corpus in Figure 3. [sent-49, score-0.705]
</p><p>26 (201 1) described the construction of the first edition of the Google Books Ngram Corpus and used it to quantitatively analyze a variety of topics ranging from language growth to public health. [sent-51, score-0.18]
</p><p>27 In addition to studying frequency patterns in the data, researchers have also attempted to analyze the grammatical function of the ngrams (Davies, 2011). [sent-53, score-0.49]
</p><p>28 Such endeavors are hampered by the fact that the Ngram Corpus provides only aggregate statistics in the form of ngram counts and not the full sentences. [sent-54, score-0.259]
</p><p>29 In contrast, because we have access to the full text, we can annotate ngrams to reflect the particular grammatical functions they take in the sentences 170  guage in our corpus. [sent-56, score-0.428]
</p><p>30 The total collection contains more than 6% of all books ever published. [sent-57, score-0.476]
</p><p>31 they were extracted from, and can also account for the contribution ofrare ngrams to otherwise frequent grammatical functions. [sent-58, score-0.428]
</p><p>32 This work presents new corpora that have been extracted from an even larger book collec-  tion, adds a new language (Italian), and introduces syntactically annotated ngrams. [sent-62, score-0.241]
</p><p>33 1 Books Data The new edition of the Ngram Corpus supports the eight languages shown in Table 1. [sent-65, score-0.262]
</p><p>34 The book volumes were selected from the larger collection of all books digitized at Google following exactly the procedure described in Michel et al. [sent-66, score-0.638]
</p><p>35 The new edition contains data from 8,116,746 books, or over 6% of all books ever published. [sent-68, score-0.629]
</p><p>36 This collection of books is much larger than any other digitized collection; its generation required a substantial effort involving obtaining and manually scanning millions of books. [sent-70, score-0.649]
</p><p>37 2 Raw Ngrams We extract ngrams in a similar way to the first edition of the corpus (Michel et al. [sent-72, score-0.645]
</p><p>38 Previously, tokenization was done on whitespace characters and all ngrams occurring on a given page were extracted, including ones that span sentence boundaries, but omitting  ngrams that span page boundaries. [sent-74, score-0.976]
</p><p>39 We capture sentences that span across page boundaries, and then extract ngrams only within sentences. [sent-76, score-0.488]
</p><p>40 As is typically done in language model estimation, we add sentence beginning ( START ) and end tokens ( END ) that are included in the ngram extraction. [sent-77, score-0.232]
</p><p>41 This allows us to distinguish ngrams that appear in sentence-medial positions from ngrams that occur at sentence boundaries (e. [sent-78, score-0.904]
</p><p>42 As a result, this new edition is not a superset of the first edition. [sent-83, score-0.18]
</p><p>43 4  Syntactic Annotations  In addition to extracting raw ngrams, we part-ofspeech tag and parse the entire corpus and extract syntactically annotated ngrams (see Figure 2). [sent-84, score-0.682]
</p><p>44 We use manually annotated treebanks of modern text (often newswire) as training data for the POS tagger and parser models. [sent-85, score-0.176]
</p><p>45 We discuss our approach to adapting the models to historical text in Section 5. [sent-86, score-0.107]
</p><p>46 Over the years, POS tag-  ging accuracies have steadily improved, appearing to plateau at an accuracy level that approaches human inter-annotator agreement (Manning, 2011). [sent-91, score-0.074]
</p><p>47 We therefore need to specifically adapt our models to handle noisy and historical text. [sent-93, score-0.107]
</p><p>48 We perform POS tagging with a state-of-the-art2 Conditional Random Field (CRF) based tagger (Lafferty et al. [sent-94, score-0.077]
</p><p>49 We use the following fairly standard features in our tagger: current word, suffixes and prefixes of length 1, 2 and 3; additionally we use word cluster features (Uszkoreit and Brants, 2008) for the current word, and transition features of the cluster of the current and previous word. [sent-96, score-0.13]
</p><p>50 To provide a language-independent interface, we use the universal POS tagset described in detail in Petrov et al. [sent-97, score-0.152]
</p><p>51 hair END  _S  NOUN hair  END  Annotated Ngrams John NOUN John has VERB John VERB short _N  _V  hair=>short hair=>black NOUN_ <=has  Figure 2: An English sentence and its part-of-speech tags and dependency parse tree. [sent-113, score-0.587]
</p><p>52 ADJ  _A  ROOT_ =>has  Below are some of the raw  ngrams available in the first release of the Ngram Corpus, as well as some of the new, syntactically  annotated ngrams. [sent-117, score-0.607]
</p><p>53 More typical examples might be big for adjectives, quickly for adverbs or read for verbs. [sent-121, score-0.085]
</p><p>54 (2012), we train on the language-specific treebank POS tags, and then map the predicted tags to the universal tags. [sent-123, score-0.235]
</p><p>55 Table 3  shows POS tagging accuracies on the treebank evaluation sets using the 12 universal POS tags. [sent-124, score-0.276]
</p><p>56 2 Syntactic Parsing We use a dependency syntax representation, since it is intuitive to work with and can be predicted effectively. [sent-126, score-0.071]
</p><p>57 Additionally, dependency parse tree corpora exist for several languages, making the representation desirable from a practical standpoint. [sent-127, score-0.109]
</p><p>58 Dependency parse trees specify pairwise relationships between words in the same sentence. [sent-128, score-0.071]
</p><p>59 Directed arcs specify which words modify a given word (if any), or alternatively, which head word governs a given word (there can only be one). [sent-129, score-0.104]
</p><p>60 For example, in Figure 2, hair is the head of the modifier short. [sent-130, score-0.358]
</p><p>61 For treebanks with non-projective trees we use the pseudo-projective parsing technique to transform the treebank into projective structures (Nivre and Nilsson, 2005). [sent-134, score-0.104]
</p><p>62 To standardize and simplify the dependency relations across languages we use unlabeled directed dependency arcs. [sent-135, score-0.174]
</p><p>63 3 Syntactic Ngrams As described above, we extract raw ngrams (n ≤ 5) fArsom de etshcer biboeodk a text. [sent-138, score-0.5]
</p><p>64 Additionally, we provide ngrams annotated with POS tags and dependency relations. [sent-139, score-0.627]
</p><p>65 All of these forms can be mixed freely in 1-, 2- and 3-grams (e. [sent-147, score-0.082]
</p><p>66 To limit the combinatorial explosion, we restrict the forms that can be mixed in 4- and 5-grams. [sent-150, score-0.082]
</p><p>67 , the house is ADJ ) and we also allow every word to be annotated (e. [sent-153, score-0.142]
</p><p>68 However, we do not allow annotated words to be mixed with other forms (e. [sent-156, score-0.175]
</p><p>69 , both the house NOUN is ADJ and the house NOUN is red are not allowed). [sent-158, score-0.164]
</p><p>70 Both the head and the modifier can take any of the forms described above. [sent-160, score-0.184]
</p><p>71 We use an arrow that points from the head word to the modifier word (e. [sent-161, score-0.153]
</p><p>72 Accuracies on the out-of-domain book data are likely lower. [sent-168, score-0.134]
</p><p>73 Figure 2 shows an English sentence, its POS tags and dependency parse tree, and some concrete examples of ngrams that are extracted. [sent-169, score-0.605]
</p><p>74 Using the raw ngrams it is not possible to accurately estimate how frequently hair is described as short, as there are often intervening words between the head and the modifier. [sent-171, score-0.809]
</p><p>75 Because dependency relations are independent of word order, we are able to calculate the frequency of both hair= >black and hair=>short. [sent-172, score-0.106]
</p><p>76 The 3gram read DET book aggregates several more specific 3-grams like read a book, read the book, etc. [sent-175, score-0.302]
</p><p>77 The dependency representation read=>book is even more general, enforcing the requirement that the two words obey a specific syntactic configuration, but ignoring the number of words that appear in between. [sent-176, score-0.187]
</p><p>78 To get a better estimate of the POS tagging and parsing accuracies we conducted a detailed study for English. [sent-178, score-0.109]
</p><p>79 We chose English since it is the largest language in our corpus and because labeled treebank data for multiple domains is available. [sent-179, score-0.101]
</p><p>80 The dependency conversion was unfortunately not possible for the PPCMBE corpus since it uses a different set of constituency labels. [sent-191, score-0.108]
</p><p>81 The tagset of PPCMBE is also unique and cannot be mapped deterministically to the universal tagset. [sent-192, score-0.182]
</p><p>82 For example the string “one” has its own POS tag in PPCMBE, but is ambiguous in general it can be used either as a number (NUM), noun (NOUN) or pronoun (PRON). [sent-193, score-0.072]
</p><p>83 We did our best to convert the tags as closely as possible, leaving tags that cannot be mapped untouched. [sent-194, score-0.136]
</p><p>84 Consequently, our evaluation results underestimate the accuracy of our tagger since it might correctly disambiguate certain words that are not disambiguated in the PPCMBE evaluation data. [sent-195, score-0.075]
</p><p>85 –  Table 4 shows the accuracies on the different domains for our baseline and adapted models. [sent-196, score-0.121]
</p><p>86 The baseline model is trained only on newswire text and hence performs best on the newswire evaluation set. [sent-197, score-0.08]
</p><p>87 Second, and more importantly, we estimate word cluster features on the books data and use them as features in the POS tagger. [sent-200, score-0.447]
</p><p>88 The word cluster features group words deterministically into clusters that have similar distributional properties. [sent-201, score-0.115]
</p><p>89 This approach improves the accuracy on rare words, and also makes our models robust to scanning er-  1ciyane8lrFvuqRte0rad1_e85DradeE0tThd=i_s>aeb o k 190 52 1cRvae8yrlFituqn0ackle_f1V8oN5OEt0RUbaBNl190 520  Figure 3: Several queries expressing that somebody is reading a book (left). [sent-203, score-0.282]
</p><p>90 1uvtqlcaFeRyn8ire0_ NPROU MN_ 18509 1502  Frequencies of tackle used  as noun vs. [sent-204, score-0.072]
</p><p>91 verb compared to the frequency of football (middle). [sent-205, score-0.139]
</p><p>92 For example, in older books the medial-s (R) is often incorrectly recognized as an ‘f’ by the OCRR software (e. [sent-208, score-0.395]
</p><p>93 Such systematic scanning errors will produce spurious words that have very similar co-occurrence patterns as the correct spelling of the word. [sent-211, score-0.136]
</p><p>94 In fact, a manual examination reveals that words with systematic scanning errors tend to be in the same cluster as their correctly spelled versions. [sent-212, score-0.188]
</p><p>95 While the final annotations are by no means perfect, we expect that in aggregate they are accurate enough to be useful when analyzing broad trends in the evolution of grammar. [sent-214, score-0.201]
</p><p>96 6  Conclusions  We described a new edition of the Google Books Ngram Corpus that provides syntactically annotated ngrams for eight languages. [sent-215, score-0.765]
</p><p>97 We discussed the statistical models used to produce the syntactic annotations and how they were adapted to handle historical text more robustly, resulting in significantly improved annotation quality. [sent-219, score-0.284]
</p><p>98 Building a large annotated corpus of English: the Penn treebank. [sent-291, score-0.097]
</p><p>99 Quantitative analysis of culture using millions of digitized books. [sent-314, score-0.124]
</p><p>100 The two poverty enlightenments: Historical insights from digitized books spanning three centuries. [sent-339, score-0.556]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ngrams', 0.428), ('books', 0.395), ('burnt', 0.308), ('ngram', 0.232), ('hair', 0.205), ('edition', 0.18), ('book', 0.134), ('burned', 0.128), ('ppcmbe', 0.128), ('adj', 0.126), ('google', 0.117), ('historical', 0.107), ('verb', 0.104), ('universal', 0.103), ('lieberman', 0.103), ('scanning', 0.103), ('toast', 0.103), ('pos', 0.094), ('michel', 0.089), ('house', 0.082), ('modifier', 0.082), ('digitized', 0.082), ('annotations', 0.08), ('accuracies', 0.074), ('noun', 0.072), ('raw', 0.072), ('head', 0.071), ('dependency', 0.071), ('tags', 0.068), ('det', 0.067), ('questionbank', 0.067), ('treebank', 0.064), ('annotated', 0.06), ('read', 0.056), ('ever', 0.054), ('black', 0.053), ('cluster', 0.052), ('evolution', 0.052), ('kroch', 0.051), ('yuri', 0.051), ('mixed', 0.051), ('eight', 0.05), ('syntactic', 0.05), ('tagset', 0.049), ('boundaries', 0.048), ('syntactically', 0.047), ('adapted', 0.047), ('stack', 0.046), ('headmodifier', 0.045), ('centuries', 0.045), ('aiden', 0.045), ('orwant', 0.045), ('poverty', 0.045), ('somebody', 0.045), ('viewer', 0.045), ('tagger', 0.042), ('trends', 0.042), ('millions', 0.042), ('buffer', 0.041), ('adjectives', 0.041), ('treebanks', 0.04), ('newswire', 0.04), ('frequencies', 0.039), ('john', 0.038), ('pron', 0.038), ('russian', 0.038), ('parse', 0.038), ('verbs', 0.037), ('corpus', 0.037), ('decades', 0.036), ('petrov', 0.035), ('frequency', 0.035), ('tagging', 0.035), ('uszkoreit', 0.034), ('page', 0.034), ('modern', 0.034), ('spanning', 0.034), ('enabled', 0.033), ('francis', 0.033), ('words', 0.033), ('nivre', 0.032), ('languages', 0.032), ('download', 0.032), ('forms', 0.031), ('deterministically', 0.03), ('marcus', 0.03), ('adverbs', 0.029), ('conjunctions', 0.029), ('brown', 0.029), ('marneffe', 0.029), ('pronouns', 0.028), ('usage', 0.027), ('taggers', 0.027), ('studying', 0.027), ('utility', 0.027), ('aggregate', 0.027), ('collection', 0.027), ('dependencies', 0.027), ('additionally', 0.026), ('span', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999911 <a title="189-tfidf-1" href="./acl-2012-Syntactic_Annotations_for_the_Google_Books_NGram_Corpus.html">189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</a></p>
<p>Author: Yuri Lin ; Jean-Baptiste Michel ; Erez Aiden Lieberman ; Jon Orwant ; Will Brockman ; Slav Petrov</p><p>Abstract: We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6% of all books ever published. This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and headmodifier relationships are recorded. The annotations are produced automatically with statistical models that are specifically adapted to historical text. The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax.</p><p>2 0.12550618 <a title="189-tfidf-2" href="./acl-2012-Word_Epoch_Disambiguation%3A_Finding_How_Words_Change_Over_Time.html">216 acl-2012-Word Epoch Disambiguation: Finding How Words Change Over Time</a></p>
<p>Author: Rada Mihalcea ; Vivi Nastase</p><p>Abstract: In this paper we introduce the novel task of “word epoch disambiguation,” defined as the problem of identifying changes in word usage over time. Through experiments run using word usage examples collected from three major periods of time (1800, 1900, 2000), we show that the task is feasible, and significant differences can be observed between occurrences of words in different periods of time.</p><p>3 0.10001744 <a title="189-tfidf-3" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>Author: Spence Green ; John DeNero</p><p>Abstract: When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agreement errors. To address this issue, we present a target-side, class-based agreement model. Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis. For English-to-Arabic translation, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders. 1</p><p>4 0.088502295 <a title="189-tfidf-4" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>5 0.08204776 <a title="189-tfidf-5" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>Author: Zhenghua Li ; Ting Liu ; Wanxiang Che</p><p>Abstract: We present a simple and effective framework for exploiting multiple monolingual treebanks with different annotation guidelines for parsing. Several types of transformation patterns (TP) are designed to capture the systematic annotation inconsistencies among different treebanks. Based on such TPs, we design quasisynchronous grammar features to augment the baseline parsing models. Our approach can significantly advance the state-of-the-art parsing accuracy on two widely used target treebanks (Penn Chinese Treebank 5. 1 and 6.0) using the Chinese Dependency Treebank as the source treebank. The improvements are respectively 1.37% and 1.10% with automatic part-of-speech tags. Moreover, an indirect comparison indicates that our approach also outperforms previous work based on treebank conversion.</p><p>6 0.078925923 <a title="189-tfidf-6" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>7 0.078536905 <a title="189-tfidf-7" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>8 0.077927694 <a title="189-tfidf-8" href="./acl-2012-Attacking_Parsing_Bottlenecks_with_Unlabeled_Data_and_Relevant_Factorizations.html">30 acl-2012-Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations</a></p>
<p>9 0.07739412 <a title="189-tfidf-9" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>10 0.076925263 <a title="189-tfidf-10" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>11 0.076866217 <a title="189-tfidf-11" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>12 0.073414512 <a title="189-tfidf-12" href="./acl-2012-A_Comparative_Study_of_Target_Dependency_Structures_for_Statistical_Machine_Translation.html">4 acl-2012-A Comparative Study of Target Dependency Structures for Statistical Machine Translation</a></p>
<p>13 0.070913039 <a title="189-tfidf-13" href="./acl-2012-Head-driven_Transition-based_Parsing_with_Top-down_Prediction.html">106 acl-2012-Head-driven Transition-based Parsing with Top-down Prediction</a></p>
<p>14 0.069057018 <a title="189-tfidf-14" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<p>15 0.068798788 <a title="189-tfidf-15" href="./acl-2012-Utilizing_Dependency_Language_Models_for_Graph-based_Dependency_Parsing_Models.html">213 acl-2012-Utilizing Dependency Language Models for Graph-based Dependency Parsing Models</a></p>
<p>16 0.067417733 <a title="189-tfidf-16" href="./acl-2012-Tense_and_Aspect_Error_Correction_for_ESL_Learners_Using_Global_Context.html">192 acl-2012-Tense and Aspect Error Correction for ESL Learners Using Global Context</a></p>
<p>17 0.063462041 <a title="189-tfidf-17" href="./acl-2012-A_Comparison_of_Chinese_Parsers_for_Stanford_Dependencies.html">5 acl-2012-A Comparison of Chinese Parsers for Stanford Dependencies</a></p>
<p>18 0.063300394 <a title="189-tfidf-18" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>19 0.062063608 <a title="189-tfidf-19" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>20 0.06050542 <a title="189-tfidf-20" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.174), (1, 0.029), (2, -0.123), (3, -0.066), (4, -0.013), (5, 0.047), (6, 0.04), (7, -0.087), (8, -0.005), (9, -0.013), (10, 0.022), (11, 0.016), (12, 0.091), (13, 0.034), (14, -0.02), (15, 0.013), (16, 0.02), (17, -0.026), (18, -0.012), (19, -0.066), (20, -0.049), (21, 0.036), (22, -0.018), (23, -0.003), (24, 0.074), (25, 0.025), (26, 0.085), (27, 0.029), (28, 0.133), (29, 0.045), (30, -0.038), (31, -0.013), (32, -0.034), (33, 0.118), (34, 0.132), (35, -0.016), (36, 0.033), (37, -0.038), (38, -0.033), (39, 0.061), (40, 0.035), (41, 0.015), (42, -0.067), (43, 0.068), (44, -0.129), (45, -0.008), (46, 0.145), (47, -0.07), (48, -0.011), (49, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94678581 <a title="189-lsi-1" href="./acl-2012-Syntactic_Annotations_for_the_Google_Books_NGram_Corpus.html">189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</a></p>
<p>Author: Yuri Lin ; Jean-Baptiste Michel ; Erez Aiden Lieberman ; Jon Orwant ; Will Brockman ; Slav Petrov</p><p>Abstract: We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6% of all books ever published. This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and headmodifier relationships are recorded. The annotations are produced automatically with statistical models that are specifically adapted to historical text. The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax.</p><p>2 0.65555573 <a title="189-lsi-2" href="./acl-2012-Beefmoves%3A_Dissemination%2C_Diversity%2C_and_Dynamics_of_English_Borrowings_in_a_German_Hip_Hop_Forum.html">39 acl-2012-Beefmoves: Dissemination, Diversity, and Dynamics of English Borrowings in a German Hip Hop Forum</a></p>
<p>Author: Matt Garley ; Julia Hockenmaier</p><p>Abstract: We investigate how novel English-derived words (anglicisms) are used in a Germanlanguage Internet hip hop forum, and what factors contribute to their uptake.</p><p>3 0.63888264 <a title="189-lsi-3" href="./acl-2012-Discriminative_Strategies_to_Integrate_Multiword_Expression_Recognition_and_Parsing.html">75 acl-2012-Discriminative Strategies to Integrate Multiword Expression Recognition and Parsing</a></p>
<p>Author: Matthieu Constant ; Anthony Sigogne ; Patrick Watrin</p><p>Abstract: and Parsing Anthony Sigogne Universit e´ Paris-Est LIGM, CNRS France s igogne @univ-mlv . fr Patrick Watrin Universit e´ de Louvain CENTAL Belgium pat rick .wat rin @ ucl ouvain .be view, their incorporation has also been considered The integration of multiword expressions in a parsing procedure has been shown to improve accuracy in an artificial context where such expressions have been perfectly pre-identified. This paper evaluates two empirical strategies to integrate multiword units in a real constituency parsing context and shows that the results are not as promising as has sometimes been suggested. Firstly, we show that pregrouping multiword expressions before parsing with a state-of-the-art recognizer improves multiword recognition accuracy and unlabeled attachment score. However, it has no statistically significant impact in terms of F-score as incorrect multiword expression recognition has important side effects on parsing. Secondly, integrating multiword expressions in the parser grammar followed by a reranker specific to such expressions slightly improves all evaluation metrics.</p><p>4 0.62935346 <a title="189-lsi-4" href="./acl-2012-Word_Epoch_Disambiguation%3A_Finding_How_Words_Change_Over_Time.html">216 acl-2012-Word Epoch Disambiguation: Finding How Words Change Over Time</a></p>
<p>Author: Rada Mihalcea ; Vivi Nastase</p><p>Abstract: In this paper we introduce the novel task of “word epoch disambiguation,” defined as the problem of identifying changes in word usage over time. Through experiments run using word usage examples collected from three major periods of time (1800, 1900, 2000), we show that the task is feasible, and significant differences can be observed between occurrences of words in different periods of time.</p><p>5 0.55597621 <a title="189-lsi-5" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>6 0.53491682 <a title="189-lsi-6" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>7 0.52213234 <a title="189-lsi-7" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>8 0.49874958 <a title="189-lsi-8" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>9 0.49003208 <a title="189-lsi-9" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>10 0.48907012 <a title="189-lsi-10" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>11 0.48312989 <a title="189-lsi-11" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>12 0.48158979 <a title="189-lsi-12" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>13 0.4786962 <a title="189-lsi-13" href="./acl-2012-Ecological_Evaluation_of_Persuasive_Messages_Using_Google_AdWords.html">77 acl-2012-Ecological Evaluation of Persuasive Messages Using Google AdWords</a></p>
<p>14 0.47417301 <a title="189-lsi-14" href="./acl-2012-Attacking_Parsing_Bottlenecks_with_Unlabeled_Data_and_Relevant_Factorizations.html">30 acl-2012-Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations</a></p>
<p>15 0.4727692 <a title="189-lsi-15" href="./acl-2012-Learning_Syntactic_Verb_Frames_using_Graphical_Models.html">130 acl-2012-Learning Syntactic Verb Frames using Graphical Models</a></p>
<p>16 0.46232909 <a title="189-lsi-16" href="./acl-2012-Tokenization%3A_Returning_to_a_Long_Solved_Problem__A_Survey%2C_Contrastive_Experiment%2C_Recommendations%2C_and_Toolkit_.html">197 acl-2012-Tokenization: Returning to a Long Solved Problem  A Survey, Contrastive Experiment, Recommendations, and Toolkit </a></p>
<p>17 0.45269489 <a title="189-lsi-17" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>18 0.44240776 <a title="189-lsi-18" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<p>19 0.44233546 <a title="189-lsi-19" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>20 0.44126943 <a title="189-lsi-20" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.284), (25, 0.017), (26, 0.056), (28, 0.044), (30, 0.031), (37, 0.019), (39, 0.039), (74, 0.037), (82, 0.024), (84, 0.041), (85, 0.027), (90, 0.164), (92, 0.053), (94, 0.025), (99, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80484092 <a title="189-lda-1" href="./acl-2012-Syntactic_Annotations_for_the_Google_Books_NGram_Corpus.html">189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</a></p>
<p>Author: Yuri Lin ; Jean-Baptiste Michel ; Erez Aiden Lieberman ; Jon Orwant ; Will Brockman ; Slav Petrov</p><p>Abstract: We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6% of all books ever published. This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and headmodifier relationships are recorded. The annotations are produced automatically with statistical models that are specifically adapted to historical text. The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax.</p><p>2 0.57871395 <a title="189-lda-2" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>Author: Patrick Simianer ; Stefan Riezler ; Chris Dyer</p><p>Abstract: With a few exceptions, discriminative training in statistical machine translation (SMT) has been content with tuning weights for large feature sets on small development data. Evidence from machine learning indicates that increasing the training sample size results in better prediction. The goal of this paper is to show that this common wisdom can also be brought to bear upon SMT. We deploy local features for SCFG-based SMT that can be read off from rules at runtime, and present a learning algorithm that applies ‘1/‘2 regularization for joint feature selection over distributed stochastic learning processes. We present experiments on learning on 1.5 million training sentences, and show significant improvements over tuning discriminative models on small development sets.</p><p>3 0.57856613 <a title="189-lda-3" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>4 0.57536745 <a title="189-lda-4" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>Author: Spence Green ; John DeNero</p><p>Abstract: When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agreement errors. To address this issue, we present a target-side, class-based agreement model. Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis. For English-to-Arabic translation, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders. 1</p><p>5 0.57439828 <a title="189-lda-5" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>Author: Adam Pauls ; Dan Klein</p><p>Abstract: We propose a simple generative, syntactic language model that conditions on overlapping windows of tree context (or treelets) in the same way that n-gram language models condition on overlapping windows of linear context. We estimate the parameters of our model by collecting counts from automatically parsed text using standard n-gram language model estimation techniques, allowing us to train a model on over one billion tokens of data using a single machine in a matter of hours. We evaluate on perplexity and a range of grammaticality tasks, and find that we perform as well or better than n-gram models and other generative baselines. Our model even competes with state-of-the-art discriminative models hand-designed for the grammaticality tasks, despite training on positive data alone. We also show fluency improvements in a preliminary machine translation experiment.</p><p>6 0.57344359 <a title="189-lda-6" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>7 0.57183427 <a title="189-lda-7" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>8 0.57125127 <a title="189-lda-8" href="./acl-2012-Word_Epoch_Disambiguation%3A_Finding_How_Words_Change_Over_Time.html">216 acl-2012-Word Epoch Disambiguation: Finding How Words Change Over Time</a></p>
<p>9 0.57062143 <a title="189-lda-9" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>10 0.57058209 <a title="189-lda-10" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>11 0.56990337 <a title="189-lda-11" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>12 0.5695284 <a title="189-lda-12" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>13 0.5684526 <a title="189-lda-13" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<p>14 0.56746399 <a title="189-lda-14" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>15 0.56726539 <a title="189-lda-15" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>16 0.56712282 <a title="189-lda-16" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>17 0.56603444 <a title="189-lda-17" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>18 0.56587017 <a title="189-lda-18" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>19 0.56550372 <a title="189-lda-19" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<p>20 0.56501555 <a title="189-lda-20" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
