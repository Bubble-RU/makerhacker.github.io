<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-9" href="#">acl2012-9</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</h1>
<br/><p>Source: <a title="acl-2012-9-pdf" href="http://aclweb.org/anthology//P/P12/P12-1108.pdf">pdf</a></p><p>Author: Hyun-Je Song ; Jeong-Woo Son ; Tae-Gil Noh ; Seong-Bae Park ; Sang-Jo Lee</p><p>Abstract: All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost to serious errors and a smaller one to minor errors. Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub- sequent NLP tasks.</p><p>Reference: <a title="acl-2012-9-reference" href="../acl2012_reference/acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract  All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. [sent-9, score-0.644]
</p><p>2 However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. [sent-10, score-0.753]
</p><p>3 This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. [sent-11, score-0.579]
</p><p>4 Two gradient loss functions are proposed to reflect the different types of errors. [sent-12, score-0.58]
</p><p>5 They are designed to assign a larger cost to serious errors and a smaller one to minor errors. [sent-13, score-0.756]
</p><p>6 Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. [sent-14, score-1.282]
</p><p>7 In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub-  sequent NLP tasks. [sent-15, score-0.653]
</p><p>8 1 Introduction Part-of-speech (POS) tagging is needed as a preprocessor for various natural language processing (NLP) tasks such as parsing, named entity recognition (NER), and text chunking. [sent-16, score-0.263]
</p><p>9 Since POS tagging is normally performed in the early step of NLP tasks, the errors in POS tagging are critical in that they affect subsequent steps and often lower the overall performance of NLP tasks. [sent-17, score-0.93]
</p><p>10 Previous studies on POS tagging have shown high performance with machine learning techniques (Ratnaparkhi, 1996; Brants, 2000; Lafferty et al. [sent-18, score-0.308]
</p><p>11 , 2004) and informative features for POS tagging (Toutanova and Manning, 2000), the state-of-the-art supervised POS tagging achieves over 97% of accuracy (Shen et al. [sent-26, score-0.591]
</p><p>12 There have also been many studies on POS tagging with semi-supervised (Subramanya et al. [sent-29, score-0.308]
</p><p>13 However, there still exists room to improve supervised POS tagging in terms of error differentiation. [sent-32, score-0.461]
</p><p>14 It should be noted that not all errors are equally important in POS tagging. [sent-33, score-0.343]
</p><p>15 This error results in a wrong parse tree that is severely different from the correct tree shown in Figure 1(b). [sent-36, score-0.294]
</p><p>16 Figure 1(c) and (d) show another tagging error and its effect. [sent-38, score-0.356]
</p><p>17 oc c2ia0t1io2n A fsosro Cciaotmiopnu ftaotrio Cnoamlp Luintagtuioisntaicls L,i pnaggueis t 1i0c2s5–1034,  VB CD CD IN NN (a) A parse tree with a serious error. [sent-43, score-0.325]
</p><p>18 VB CD CD IN NN (b) The correct parse tree of the sentence “The treasury plans . [sent-45, score-0.145]
</p><p>19 ” ”  Figure 1: An example of POS tagging errors  the correct one in Figure 1(d). [sent-53, score-0.545]
</p><p>20 The goal of this paper is to differentiate the serious POS tagging errors from the minor errors. [sent-55, score-0.928]
</p><p>21 POS tagging is generally regarded as a classification task, and zero-one loss is commonly used in learning classifiers (Altun et al. [sent-56, score-0.685]
</p><p>22 Since zero-one loss considers all errors equally, it can not distinguish error types. [sent-58, score-0.752]
</p><p>23 Therefore, a new loss is required to incorporate different error types into the learning machines. [sent-59, score-0.47]
</p><p>24 This paper proposes two gradient loss functions to reflect differences among POS tagging errors. [sent-60, score-0.804]
</p><p>25 The functions assign relatively small cost to minor errors, while larger cost is given to serious errors. [sent-61, score-0.666]
</p><p>26 They are applied to learning multiclass support vector machines (Tsochantaridis et al. [sent-62, score-0.169]
</p><p>27 , 2004) which is trained to minimize the serious errors. [sent-63, score-0.261]
</p><p>28 Overall accu-  racy of this SVM is not improved against the state1026 of-the-art POS tagger, but the serious errors are significantly reduced with the proposed method. [sent-64, score-0.547]
</p><p>29 The effect of the fewer serious errors is shown by applying it to the well-known NLP task of text chunking. [sent-65, score-0.508]
</p><p>30 In Section 3, serious and minor errors are defined, and it is shown that both errors are observable in a general corpus. [sent-69, score-0.906]
</p><p>31 Section 4 proposes two new loss functions for discriminating the error types in POS tagging. [sent-70, score-0.603]
</p><p>32 Following this direction, various studies have been proposed to extend informative features for POS tagging (Toutanova and Manning, 2000; Toutanova et al. [sent-78, score-0.347]
</p><p>33 As a result of these efforts, the performance of state-of-the-art supervised POS tagging shows over 97% of accuracy (Toutanova et al. [sent-86, score-0.328]
</p><p>34 Due to the high accuracy of supervised approaches for POS tagging, it has been deemed that there is no room to improve the performance on POS tagging in supervised manner. [sent-89, score-0.433]
</p><p>35 Thus, recent studies on POS tagging focus on semi-supervised (Spoustov a´ et al. [sent-90, score-0.308]
</p><p>36 Most previous studies on POS tagging have focused on how to extract more linguistic features or how to adopt supervised or unsupervised 1027 approaches based on a single evaluation measure, accuracy. [sent-95, score-0.403]
</p><p>37 However, with a different viewpoint for errors on POS tagging, there is still some room to improve the performance of POS tagging for subse-  quent NLP tasks, even though the overall accuracy can not be much improved. [sent-96, score-0.621]
</p><p>38 In ordinary studies on POS tagging, costs of errors are equally assigned. [sent-97, score-0.45]
</p><p>39 However, with respect to the performance of NLP tasks relying on the result of POS tagging, errors should be treated differently. [sent-98, score-0.32]
</p><p>40 In the machine learning community, cost sensitive learning has been studied to differentiate costs among errors. [sent-99, score-0.2]
</p><p>41 By adopting different misclassification costs for each type of errors, a classifier is optimized to achieve the lowest expected cost (Elkan, 2001; Cai and Hofmann, 2004; Zhou and Liu, 2006). [sent-100, score-0.191]
</p><p>42 3  Error Analysis of Existing POS Tagger  The effects of POS tagging errors to subsequent NLP tasks vary according to their type. [sent-101, score-0.599]
</p><p>43 In this paper, the seriousness of tagging errors is determined by categorical structures of POS tags. [sent-103, score-0.621]
</p><p>44 Serious tagging errors are defined as misclassifications among  the categories, while minor errors are defined as misclassifications within a category. [sent-106, score-1.039]
</p><p>45 That is, inter-category errors are treated as serious errors, while intra-category errors are treated as minor errors. [sent-108, score-0.982]
</p><p>46 Table 2 shows the distribution of inter-category and intra-category errors observed in section 22– 24 of the WSJ corpus (Marcus et al. [sent-109, score-0.282]
</p><p>47 In this table, bold numbers denote intercategory errors while all other numbers show intracategory errors. [sent-112, score-0.425]
</p><p>48 The number of total errors is 3,471 out of 129,654 words. [sent-113, score-0.282]
</p><p>49 19%) are intra-category, while 1,590 of the errors (45. [sent-115, score-0.282]
</p><p>50 If we can reduce these inter-category errors under the cost of mini-  mally increasing intra-category errors, the tagging results would improve in quality. [sent-117, score-0.642]
</p><p>51 Generally in POS tagging, all tagging errors are regarded equally in importance. [sent-118, score-0.651]
</p><p>52 Since a machine learning method is optimized by a loss function, inter-category errors can be efficiently reduced if a loss function is designed to handle both types of errors with different cost. [sent-120, score-1.382]
</p><p>53 We propose two loss functions for POS tagging and they are applied to multiclass Support Vector Machines. [sent-121, score-0.904]
</p><p>54 4  Learning SVMs with Class Similarity  POS tagging has been solved as a sequential labeling problem which assumes dependency among words. [sent-122, score-0.263]
</p><p>55 If it is assumed that words are independent of one another, POS tagging can be regarded as a multiclass classification problem. [sent-124, score-0.477]
</p><p>56 , (xl , yl)} is given where xi ∈ Rd is an instance vector )a}nd i yi ∈ {+1, −1} is it∈s c Rlass label. [sent-130, score-0.349]
</p><p>57 SVM finds an optimal hyperplane 1028 satisfying w + b ≥ +1 for yi = +1, xi · w + b ≤ −1 for yi = −1, where w and b are parameters to be estimated from training data D. [sent-131, score-0.592]
</p><p>58 To estimate the parameters, SVMs minimizes a hinge loss defined as ξi = Lhinge(yi, w · xi b) = max{0, 1 − yi · (w · xi b)}. [sent-132, score-0.908]
</p><p>59 Since both binary and multiclass SVMs adopt a hinge loss, the errors between classes have the same cost. [sent-138, score-0.527]
</p><p>60 (2004) proposed an efficient way to adopt arbitrary loss function, L(yi, yj) which returns zero if yi = yj, otherwise L(yi, yj) > 0. [sent-140, score-0.688]
</p><p>61 Then, the hinge loss ξi is re-scaled with the inverse of the additional loss between two classes. [sent-141, score-0.83]
</p><p>62 By scaling slack variables with the inverse loss, margin violation with high loss L(yi, yj) is more severely restricted than that with low loss. [sent-142, score-0.531]
</p><p>63 mαin21Xil,jki∈XK\yikj∈XK\yjαi,kiαj,kj× Xl  J(xi,yi,ki)J(xj,yj,kj) −X X  Xi ki∈XK\yi  αi,ki,  1029 with constraints  α ≥ 0 andki∈XK\yiL(αyii, kkii)≤ C,  ∀i = 1,··· ,l,  where J(xi, yi , ki) is defined as J(xi , yi, ki) = φ(xi , yi)  −  φ(xi, ki) . [sent-144, score-0.243]
</p><p>64 2 Loss Functions for POS tagging To design a loss function for POS tagging, this paper adopts categorical structures of POS tags. [sent-146, score-0.748]
</p><p>65 The simplest way to reflect the structure of POS tags shown in Table 1 is to assign larger cost to inter-category errors than to intra-category errors. [sent-147, score-0.5]
</p><p>66 Thus, the loss function with the categorical structure in Table 1 is defined as  wLhc(eyri,0j<)=δ <10δisatof chy toihenrs=6wtsaiy nmjet,bouPrtOehdSuycaebt hlgoenrvgya,lue(o2f)  Lc(yi, yj) when yi and yj are similar. [sent-148, score-0.926]
</p><p>67 As shown in this equation, inter-category errors have larger cost than intra-category errors. [sent-149, score-0.379]
</p><p>68 The loss function Lc(yi, yj) is designed to reflect the categories in Table 1. [sent-151, score-0.446]
</p><p>69 ξ  function Figure 3: Effect of the proposed loss function in multiclass  SVMs  This category has ten POS tags, and can be further categorized into two sub-categories: verb and ad-  ject. [sent-154, score-0.681]
</p><p>70 Figure 2 represents a categorical structure of POS tags as a tree with five categories of POS tags and their seven sub-categories. [sent-155, score-0.238]
</p><p>71 The user parameter γ is a scaling factor of a unit loss for a single step. [sent-157, score-0.377]
</p><p>72 This loss Lt(yi, yj) returns large value if the distance between yi and yj is far in the tree structure, and it is named as tree loss. [sent-158, score-0.975]
</p><p>73 As shown in Equation (1), two proposed loss functions adjust margin violation between classes. [sent-159, score-0.627]
</p><p>74 They basically assign less value for intra-category errors than inter-category errors. [sent-160, score-0.317]
</p><p>75 Thus, a classifier is optimized to strictly keep inter-category errors within a smaller boundary. [sent-161, score-0.314]
</p><p>76 Figure 3(b) also presents the decision boundary of NN, but it is determined with the proposed loss function. [sent-167, score-0.416]
</p><p>77 It results in reducing errors between NN and VB even if the errors between NN and NNS could be slightly increased. [sent-169, score-0.564]
</p><p>78 In the experiments, two multiclass SVMs with the proposed loss functions are used. [sent-184, score-0.68]
</p><p>79 One is CL-MSVM with category loss and the other is TL-MSVM with  tree loss. [sent-185, score-0.473]
</p><p>80 4 implies that the cost of intra-category errors is set to 40% of that of inter-category errors. [sent-192, score-0.379]
</p><p>81 The number of inter-category error is 1,567, which shows 23 errors reduction compared to previous best inter-category result by (Manning, 2011). [sent-208, score-0.375]
</p><p>82 TL-MSVM also makes 16 less intercategory errors than Manning’s tagger. [sent-209, score-0.425]
</p><p>83 When com-  pared with Shen’s tagger, both CL-MSVM and TLMSVM make far less inter-category errors even if their overall performance is slightly lower than that of Shen’s tagger. [sent-210, score-0.318]
</p><p>84 The purpose of proposed methods is to minimize inter-category errors but preserving overall performance. [sent-212, score-0.392]
</p><p>85 From these results, it can be found that the proposed methods which are trained with the proposed loss functions do differentiate serious and minor POS tagging errors. [sent-213, score-1.196]
</p><p>86 Especially inter-category POS errors seriously affect the performance of chunking because they are more likely to mislead the chunk compared to intra-category errors. [sent-217, score-0.531]
</p><p>87 As shown in Table 5, both CL-MSVM and TL-MSVM achieve lower accuracies than other methods, while their inter-category errors are less than that of other experimental methods. [sent-259, score-0.311]
</p><p>88 Thus, the improvement of CL-MSVM and TLMSVM implies that, for the subsequent natural language processing, a POS tagger should considers different cost of tagging errors. [sent-260, score-0.485]
</p><p>89 1032 6  Conclusion  In this paper, we have shown that supervised POS  tagging can be improved by discriminating intercategory errors from intra-category ones. [sent-261, score-0.791]
</p><p>90 An intercategory error occurs by mislabeling a word with a totally different tag, while an intra-category error is caused by a similar POS tag. [sent-262, score-0.329]
</p><p>91 Therefore, intercategory errors affect the performances of subsequent NLP tasks far more than intra-category errors. [sent-263, score-0.511]
</p><p>92 This implies that different costs should be considered in training POS tagger according to error types. [sent-264, score-0.226]
</p><p>93 As a solution to this problem, we have proposed two gradient loss functions which reflect different costs for two error types. [sent-265, score-0.735]
</p><p>94 The cost of an error type is set according to (i) categorical difference or (ii) distance in the tree structure of POS tags. [sent-266, score-0.33]
</p><p>95 Our POS experiment has shown that if these loss functions are applied to multiclass SVMs, they could significantly reduce inter-category errors. [sent-267, score-0.641]
</p><p>96 Through the text chunking experiment, it is shown that the multiclass SVMs trained with the proposed loss functions which generate fewer inter-category errors achieve higher performance than existing POS taggers. [sent-268, score-1.078]
</p><p>97 We have shown that cost sensitive learning can be applied to POS tagging only with multiclass SVMs. [sent-269, score-0.529]
</p><p>98 However, the proposed loss functions are general  enough to be applied to other existing POS taggers. [sent-270, score-0.511]
</p><p>99 Most supervised machine learning techniques are optimized on their loss functions. [sent-271, score-0.474]
</p><p>100 Therefore, the performance of POS taggers based on supervised machine learning techniques can be improved by applying the proposed loss functions to learn their classifiers. [sent-272, score-0.576]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('loss', 0.377), ('pos', 0.343), ('errors', 0.282), ('tagging', 0.263), ('yi', 0.243), ('serious', 0.226), ('yj', 0.198), ('multiclass', 0.169), ('intercategory', 0.143), ('svms', 0.128), ('chunking', 0.116), ('minor', 0.116), ('xi', 0.106), ('cost', 0.097), ('functions', 0.095), ('error', 0.093), ('nn', 0.085), ('kudo', 0.08), ('toutanova', 0.077), ('categorical', 0.076), ('manning', 0.076), ('hinge', 0.076), ('violation', 0.076), ('tagger', 0.071), ('vb', 0.071), ('crfs', 0.066), ('supervised', 0.065), ('tree', 0.064), ('costs', 0.062), ('dist', 0.062), ('shen', 0.061), ('equally', 0.061), ('nns', 0.061), ('chunk', 0.059), ('ki', 0.059), ('wk', 0.059), ('gaard', 0.057), ('equation', 0.056), ('tsuruoka', 0.055), ('subsequent', 0.054), ('cd', 0.053), ('tsujii', 0.051), ('fernando', 0.051), ('taku', 0.05), ('subramanya', 0.05), ('tsochantaridis', 0.05), ('noun', 0.049), ('tags', 0.049), ('nlp', 0.048), ('ratnaparkhi', 0.048), ('cix', 0.048), ('misclassifications', 0.048), ('tlmsvm', 0.048), ('wyi', 0.048), ('xk', 0.047), ('plans', 0.046), ('regarded', 0.045), ('studies', 0.045), ('wsj', 0.044), ('lc', 0.042), ('lt', 0.042), ('graca', 0.042), ('seriously', 0.042), ('spoustov', 0.042), ('differentiate', 0.041), ('margin', 0.04), ('room', 0.04), ('proposed', 0.039), ('severely', 0.038), ('altun', 0.038), ('discriminating', 0.038), ('nakagawa', 0.038), ('treated', 0.038), ('optimization', 0.038), ('crf', 0.037), ('marcus', 0.037), ('reflect', 0.037), ('overall', 0.036), ('parse', 0.035), ('minimize', 0.035), ('assign', 0.035), ('das', 0.034), ('gim', 0.033), ('nez', 0.033), ('ong', 0.033), ('sha', 0.033), ('optimized', 0.032), ('category', 0.032), ('affect', 0.032), ('svm', 0.032), ('function', 0.032), ('gradient', 0.032), ('tag', 0.031), ('cai', 0.03), ('heidelberg', 0.03), ('lafferty', 0.03), ('unsupervised', 0.03), ('returns', 0.029), ('xl', 0.029), ('experimental', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="9-tfidf-1" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>Author: Hyun-Je Song ; Jeong-Woo Son ; Tae-Gil Noh ; Seong-Bae Park ; Sang-Jo Lee</p><p>Abstract: All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost to serious errors and a smaller one to minor errors. Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub- sequent NLP tasks.</p><p>2 0.23831218 <a title="9-tfidf-2" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, leftto-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. this model selection approach to more sophisticated tagging improve their robustness even We believe that can be applied algorithms and further.</p><p>3 0.18802494 <a title="9-tfidf-3" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>4 0.15518601 <a title="9-tfidf-4" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>Author: Jun Hatori ; Takuya Matsuzaki ; Yusuke Miyao ; Jun'ichi Tsujii</p><p>Abstract: We propose the first joint model for word segmentation, POS tagging, and dependency parsing for Chinese. Based on an extension of the incremental joint model for POS tagging and dependency parsing (Hatori et al., 2011), we propose an efficient character-based decoding method that can combine features from state-of-the-art segmentation, POS tagging, and dependency parsing models. We also describe our method to align comparable states in the beam, and how we can combine features of different characteristics in our incremental framework. In experiments using the Chinese Treebank (CTB), we show that the accuracies of the three tasks can be improved significantly over the baseline models, particularly by 0.6% for POS tagging and 2.4% for dependency parsing. We also perform comparison experiments with the partially joint models.</p><p>5 0.14235887 <a title="9-tfidf-5" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>Author: Qiuye Zhao ; Mitch Marcus</p><p>Abstract: We show for both English POS tagging and Chinese word segmentation that with proper representation, large number of deterministic constraints can be learned from training examples, and these are useful in constraining probabilistic inference. For tagging, learned constraints are directly used to constrain Viterbi decoding. For segmentation, character-based tagging constraints can be learned with the same templates. However, they are better applied to a word-based model, thus an integer linear programming (ILP) formulation is proposed. For both problems, the corresponding constrained solutions have advantages in both efficiency and accuracy. 1 introduction In recent work, interesting results are reported for applications of integer linear programming (ILP) such as semantic role labeling (SRL) (Roth and Yih, 2005), dependency parsing (Martins et al., 2009) and so on. In an ILP formulation, ’non-local’ deterministic constraints on output structures can be naturally incorporated, such as ”a verb cannot take two subject arguments” for SRL, and the projectivity constraint for dependency parsing. In contrast to probabilistic constraints that are estimated from training examples, this type of constraint is usually hand-written reflecting one’s linguistic knowledge. Dynamic programming techniques based on Markov assumptions, such as Viterbi decoding, cannot handle those ’non-local’ constraints as discussed above. However, it is possible to constrain Viterbi 1054 decoding by ’local’ constraints, e.g. ”assign label t to word w” for POS tagging. This type of constraint may come from human input solicited in interactive inference procedure (Kristjansson et al., 2004). In this work, we explore deterministic constraints for two fundamental NLP problems, English POS tagging and Chinese word segmentation. We show by experiments that, with proper representation, large number of deterministic constraints can be learned automatically from training data, which can then be used to constrain probabilistic inference. For POS tagging, the learned constraints are directly used to constrain Viterbi decoding. The corresponding constrained tagger is 10 times faster than searching in a raw space pruned with beam-width 5. Tagging accuracy is moderately improved as well. For Chinese word segmentation (CWS), which can be formulated as character tagging, analogous constraints can be learned with the same templates as English POS tagging. High-quality constraints can be learned with respect to a special tagset, however, with this tagset, the best segmentation accuracy is hard to achieve. Therefore, these character-based constraints are not directly used for determining predictions as in English POS tagging. We propose an ILP formulation of the CWS problem. By adopting this ILP formulation, segmentation F-measure is increased from 0.968 to 0.974, as compared to Viterbi decoding with the same feature set. Moreover, the learned constraints can be applied to reduce the number of possible words over a character sequence, i.e. to reduce the number of variables to set. This reduction of problem size immediately speeds up an ILP solver by more than 100 times. ProceediJnegjus, o Rfe thpeu 5bl0icth o Afn Knouraela M, 8e-e1t4in Jgul oyf t 2h0e1 A2.s ?oc c2ia0t1io2n A fsosro Cciaotmiopnu ftaotrio Cnoamlp Luintagtuioisntaicls L,i pnaggueis t 1i0c5s4–1062, 2 English POS tagging 2.1 Explore deterministic constraints Suppose that, following (Chomsky, 1970), we distinguish major lexical categories (Noun, Verb, Adjective and Preposition) by two binary features: + |− N and +|− V. Let (+N −V) =Noun, (−N +V) =Verb, (+N, +V) =Adjective, aonudn (−N, −V) =preposition. A word occurring in betw(e−eNn a preceding wosoitrdio nth.e Aand w a following wgo irnd of always bears the feature +N. On the other hand, consider the annotation guideline of English Treebank (Marcus et al., 1993) instead. Part-of-speech (POS) tags are used to categorize words, for example, the POS tag VBG tags verbal gerunds, NNS tags nominal plurals, DT tags determiners and so on. Following this POS representation, there are as many as 10 possible POS tags that may occur in between the–of, as estimated from the WSJ corpus of Penn Treebank. , 2.1.1 Templates of deterministic constraints , To explore determinacy in the distribution of POS tags in Penn Treebank, we need to consider that a POS tag marks the basic syntactic category of a word as well as its morphological inflection. A constraint that may determine the POS category should reflect both the context and the morphological feature of the corresponding word. The practical difficulty in representing such deterministic constraints is that we do not have a perfect mechanism to analyze morphological features of a word. Endings or prefixes of English words do not deterministically mark their morphological inflections. We propose to compute the morph feature of a word as the set of all of its possible tags, i.e. all tag types that are assigned to the word in training data. Furthermore, we approximate unknown words in testing data by rare words in training data. For a word that occurs less than 5 times in the training corpus, we compute its morph feature as its last two characters, which is also conjoined with binary features indicating whether the rare word contains digits, hyphens or upper-case characters respectively. See examples of morph features in Table 1. We consider bigram and trigram templates for generating potentially deterministic constraints. Let denote the ith word relative to the current word w0; and mi denote the morph feature of wi. A wi 1055 w(fr0e=qtruaednets)(set of pmos0s=ib{lNeN taSg,s V oBfZ th}e word) w0=t(imraere-s)hares(thme0 l=as{t- tewso, c HhYaPraHcEteNrs}. .) Table 1: Morph features offrequent words and rare words as computed from the WSJ Corpus of Penn Treebank. -gtbr ai -m w −1w 0w−mw1 m,wm 0−, 1mw1 0 w mw1 , mw m− 1m 1mw0m0w,1 wm, m0 −m1 m 0wm1 Table 2: The templates for generating potentially deterministic constraints of English POS tagging. bigram constraint includes one contextual word (w−1 |w1) or the corresponding morph feature; and a trigram constraint includes both contextual words or their morph features. Each constraint is also con- joined with w0 or m0, as described in Table 2. 2.1.2 Learning of deterministic constraints In the above section, we explore templates for potentially deterministic constraints that may determine POS category. With respect to a training corpus, if a constraint C relative to w0 ’always’ assigns a certain POS category t∗ to w0 in its context, i.e. > thr, and this constraint occurs more than a cutoff number, we consider it as a deterministic constraint. The threshold thr is a real number just under 1.0 and the cutoff number is empirically set to 5 in our experiments. counctou(Cnt∧(tC0)=t∗) 2.1.3 Decoding of deterministic constraints By the above definition, the constraint of w−1 = the, m0 = {NNS VBZ } and w1 = of is deterministic. It det=er{mNiNneSs, ,the V BPZO}S category of w0 to be NNS. There are at least two ways of decoding these constraints during POS tagging. Take the word trades for example, whose morph feature is {NNS, VBZ}. fOonre e xaaltemrnplaet,ive w hiso sthea tm as long as rtera dises { occurs Zb e}-. tween the-of, it is tagged with NNS. The second alternative is that the tag decision is made only if all deterministic constraints relative to this occurrence , of trades agree on the same tag. Both ways of decoding are purely rule-based and involve no probabilistic inference. In favor of a higher precision, we adopt the latter one in our experiments. tTchoe/nDscrotTamwSpci&lnoeLmxpd;/–fiulenbtaxp/i–cloufntg/aNpnlOci(amgnw/1–tOhNTpe(lanS+Ti&/m2cNL)lubTdaien2ls/)IoVNuBtlZamwn.1=ic2l3ud,ems.2=1 Table 3: Comparison of raw input and constrained input. 2.2 Search in a constrained space Following most previous work, we consider POS tagging as a sequence classification problem and de- compose the overall sequence scnore over the linear structure, i.e. ˆt =t∈atraggGmENa(xw)Xi=1score(ti) where function tagGEN maps input seXntence w = w1...wn to the set of all tag sequences that are of length n. If a POS tagger takes raw input only, i.e. for every word, the number of possible tags is a constant T, the space of tagGEN is as large as Tn. On the other hand, if we decode deterministic constraints first be- fore a probabilistic search, i.e. for some words, the number of possible tags is reduced to 1, the search space is reduced to Tm, where m is the number of (unconstrained) words that are not subject to any deterministic constraints. Viterbi algorithm is widely used for tagging, and runs in O(nT2) when searching in an unconstrained space. On the other hand, consider searching in a constrained space. Suppose that among the m unconstrained words, m1 of them follow a word that has been tagged by deterministic constraints and m2 (=m-m1) of them follow another unconstrained word. Viterbi decoder runs in O(m1T + m2T2) while searching in such a constrained space. The example in Table 3 shows raw and constrained input with respect to a typical input sentence. Lookahead features The score of tag predictions are usually computed in a high-dimensional feature space. We adopt the basic feature set used in (Ratnaparkhi, 1996) and (Collins, 2002). Moreover, when deterministic constraints have applied to contextual words of w0, it is also possible to include some lookahead feature templates, such as: t0&t1; , t0&t1;&t2; , and t−1&t0;&t1; where ti represents the tag of the ith word relative 1056 to the current word w0. As discussed in (Shen et al., 2007), categorical information of neighbouring words on both sides of w0 help resolve POS ambiguity of w0. In (Shen et al., 2007), lookahead features may be available for use during decoding since searching is bidirectional instead of left-to-right as in Viterbi decoding. In this work, deterministic constraints are decoded before the application of probabilistic models, therefore lookahead features are made available during Viterbi decoding. 3 Chinese Word Segmentation (CWS) 3.1 Word segmentation as character tagging Considering the ambiguity problem that a Chinese character may appear in any relative position in a word and the out-of-vocabulary (OOV) problem that it is impossible to observe all words in training data, CWS is widely formulated as a character tagging problem (Xue, 2003). A character-based CWS decoder is to find the highest scoring tag sequence tˆ over the input character sequence c, i.e. Xn tˆ =t∈ atraggGmEaNx(c)Xi=1score(ti) . This is the same formulation as POS tagging. The Viterbi algorithm is also widely used for decoding. The tag of each character represents its relative position in a word. Two popular tagsets include 1) IB: where B tags the beginning of a word and I all other positions; and 2) BMES: where B, M and E represent the beginning, middle and end of a multicharacter word respectively, and S tags a singlecharacter word. For example, after decoding with BMES, 4 consecutive characters associated with the tag sequence BMME compose a word. However, after decoding with IB, characters associated with BIII may compose a word if the following tag is B or only form part of a word if the following tag is I. Even though character tagging accuracy is higher with tagset IB, tagset BMES is more popular in use since better performance of the original problem CWS can be achieved by this tagset. Character-based feature templates We adopt the ’non-lexical-target’ feature templates in (Jiang et al., 2008a). Let ci denote the ith character relative to the current character c0 and t0 denote the tag assigned to c0. The following templates are used: ci&t0; (i=-2...2), cici+1&t0; (i=-2...1) and c−1c1&t0.; Character-based deterministic constraints We can use the same templates as described in Table 2 to generate potentially deterministic constraints for CWS character tagging, except that there are no morph features computed for Chinese characters. As we will show with experimental results in Section 5.2, useful deterministic constraints for CWS can be learned with tagset IB but not with tagset BMES. It is interesting but not surprising to notice, again, that the determinacy of a problem is sensitive to its representation. Since it is hard to achieve the best segmentations with tagset IB, we propose an indirect way to use these constraints in the following section, instead of applying these constraints as straightforwardly as in English POS tagging. 3.2 Word-based word segmentation A word-based CWS decoder finds the highest scoring segmentation sequence wˆ that is composed by the input character sequence c, i.e. wˆ =w∈arseggGmEaNx(c)Xi|=w1|score(wi) . where function segGEN maps character sequence c to the set of all possible segmentations of c. For example, w = (c1. .cl1 ) ...(cn−lk+1 ...cn) represents a segmentation of k words and the lengths of the first and last word are l1 and lk respectively. In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996). Exact search is possible with a Viterbi-style algorithm, but beamsearch decoding is more popular as used in (Zhang and Clark, 2007) and (Jiang et al., 2008a). We propose an Integer Linear Programming (ILP) formulation of word segmentation, which is naturally viewed as a word-based model for CWS. Character-based deterministic constraints, as discussed in Section 3.1, can be easily applied. 3.3 ILP formulation of CWS Given a character sequence c=c1 ...cn, there are s(= n(n + 1)/2) possible words that are contiguous subsets of c, i.e. w1, ..., ws ⊆ c. Our goal is to find 1057 Table 4: Comparison of raw input and constrained input. an optimal solution x = ...xs that maximizes x1 Xs Xscore(wi) · xi, subject to Xi= X1 (1) X xi = 1, ∀c ∈ c; (2) ix:Xic∈∈wi {0,1},1 ≤i≤s The boolean value of xi, as guaranteed by constraint (2), indicates whether wi is selected in the segmentation solution or not. Constraint (1) requires every character to be included in exactly one selected word, thus guarantees a proper segmentation of the whole sequence. This resembles the ILP formulation of the set cover problem, though the first con- straint is different. Take n = 2 for example, i.e. c = c1c2, the set of possible words is {c1, c2 , c1c2}, i.e. s = |x| = t3 o. T pohesrseib are only t iwso { possible soli.uet.ion ss = subject t o3 .co Tnhsetrreain artse (1) yan tdw (2), x = 1 s1o0giving an output set {c1, c2}, or x = 001 giving an output asent {c1c2}. tTphuet efficiency o.f solving this problem depends on the number of possible words (contiguous subsets) over a character sequence, i.e. the number of variables in x. So as to reduce |x|, we apply determiniasbtlice sc ionn xs.tra Sinots a predicting I |xB| tags first, w dehtiecrhm are learned as described in Section 3.1. Possible words are generated with respect to the partially tagged character sequence. A character tagged with B always occurs at the beginning of a possible word. Table 4 illustrates the constrained and raw input with respect to a typical character sequence. 3.4 Character- and word-based features As studied in previous work, word-based feature templates usually include the word itself, sub-words contained in the word, contextual characters/words and so on. It has been shown that combining the use of character- and word-based features helps improve performance. However, in the character tag- ging formulation, word-based features are non-local. To incorporate these non-local features and make the search tractable, various efforts have been made. For example, Jiang et al. (2008a) combine different levels of knowledge in an outside linear model of a twolayer cascaded model; Jiang et al. (2008b) uses the forest re-ranking technique (Huang, 2008); and in (Kruengkrai et al., 2009), only known words in vocabulary are included in the hybrid lattice consisting of both character- and word-level nodes. We propose to incorporate character-based features in word-based models. Consider a characterbased feature function φ(c, t,c) that maps a character-tag pair to a high-dimensional feature space, with respect to an input character sequence c. For a possible word over c of length l , wi = ci0 ...ci0+l−1, tag each character cij in this word with a character-based tag tij . Character-based features of wi can be computed as {φ(cij , tij , c) |0 ≤ j < l}. The ficrsant row oofm pTautbeled a5s i {llφus(tcrates c,ch)a|r0ac ≤ter j-b</p><p>6 0.13657828 <a title="9-tfidf-6" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>7 0.13045312 <a title="9-tfidf-7" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<p>8 0.10584085 <a title="9-tfidf-8" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>9 0.10198832 <a title="9-tfidf-9" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>10 0.099527277 <a title="9-tfidf-10" href="./acl-2012-Automatic_Event_Extraction_with_Structured_Preference_Modeling.html">33 acl-2012-Automatic Event Extraction with Structured Preference Modeling</a></p>
<p>11 0.099006087 <a title="9-tfidf-11" href="./acl-2012-How_Are_Spelling_Errors_Generated_and_Corrected%3F_A_Study_of_Corrected_and_Uncorrected_Spelling_Errors_Using_Keystroke_Logs.html">111 acl-2012-How Are Spelling Errors Generated and Corrected? A Study of Corrected and Uncorrected Spelling Errors Using Keystroke Logs</a></p>
<p>12 0.092037432 <a title="9-tfidf-12" href="./acl-2012-Grammar_Error_Correction_Using_Pseudo-Error_Sentences_and_Domain_Adaptation.html">103 acl-2012-Grammar Error Correction Using Pseudo-Error Sentences and Domain Adaptation</a></p>
<p>13 0.089469068 <a title="9-tfidf-13" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>14 0.088966608 <a title="9-tfidf-14" href="./acl-2012-Error_Mining_on_Dependency_Trees.html">83 acl-2012-Error Mining on Dependency Trees</a></p>
<p>15 0.085793473 <a title="9-tfidf-15" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>16 0.083775163 <a title="9-tfidf-16" href="./acl-2012-Fast_Online_Training_with_Frequency-Adaptive_Learning_Rates_for_Chinese_Word_Segmentation_and_New_Word_Detection.html">94 acl-2012-Fast Online Training with Frequency-Adaptive Learning Rates for Chinese Word Segmentation and New Word Detection</a></p>
<p>17 0.082256816 <a title="9-tfidf-17" href="./acl-2012-Improving_the_IBM_Alignment_Models_Using_Variational_Bayes.html">118 acl-2012-Improving the IBM Alignment Models Using Variational Bayes</a></p>
<p>18 0.082017899 <a title="9-tfidf-18" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>19 0.080225766 <a title="9-tfidf-19" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>20 0.078925923 <a title="9-tfidf-20" href="./acl-2012-Syntactic_Annotations_for_the_Google_Books_NGram_Corpus.html">189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.233), (1, 0.017), (2, -0.149), (3, -0.129), (4, -0.008), (5, 0.149), (6, 0.083), (7, -0.126), (8, -0.035), (9, -0.056), (10, -0.071), (11, -0.016), (12, 0.062), (13, -0.006), (14, 0.043), (15, 0.197), (16, 0.136), (17, -0.046), (18, 0.146), (19, -0.111), (20, 0.023), (21, 0.077), (22, -0.11), (23, 0.114), (24, 0.116), (25, 0.02), (26, -0.036), (27, -0.061), (28, -0.041), (29, 0.102), (30, 0.1), (31, 0.083), (32, 0.015), (33, 0.002), (34, 0.118), (35, 0.007), (36, -0.144), (37, -0.09), (38, -0.066), (39, 0.042), (40, -0.032), (41, -0.057), (42, 0.214), (43, 0.084), (44, -0.085), (45, -0.045), (46, -0.013), (47, -0.017), (48, 0.122), (49, -0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98608959 <a title="9-lsi-1" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>Author: Hyun-Je Song ; Jeong-Woo Son ; Tae-Gil Noh ; Seong-Bae Park ; Sang-Jo Lee</p><p>Abstract: All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost to serious errors and a smaller one to minor errors. Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub- sequent NLP tasks.</p><p>2 0.83639187 <a title="9-lsi-2" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, leftto-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. this model selection approach to more sophisticated tagging improve their robustness even We believe that can be applied algorithms and further.</p><p>3 0.70269853 <a title="9-lsi-3" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>4 0.67905581 <a title="9-lsi-4" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>Author: Andrea Gesmundo ; Tanja Samardzic</p><p>Abstract: We present a novel approach to the task of word lemmatisation. We formalise lemmatisation as a category tagging task, by describing how a word-to-lemma transformation rule can be encoded in a single label and how a set of such labels can be inferred for a specific language. In this way, a lemmatisation system can be trained and tested using any supervised tagging model. In contrast to previous approaches, the proposed technique allows us to easily integrate relevant contextual information. We test our approach on eight languages reaching a new state-of-the-art level for the lemmatisation task.</p><p>5 0.65165311 <a title="9-lsi-5" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<p>Author: Weiwei Sun ; Xiaojun Wan</p><p>Abstract: We address the issue of consuming heterogeneous annotation data for Chinese word segmentation and part-of-speech tagging. We empirically analyze the diversity between two representative corpora, i.e. Penn Chinese Treebank (CTB) and PKU’s People’s Daily (PPD), on manually mapped data, and show that their linguistic annotations are systematically different and highly compatible. The analysis is further exploited to improve processing accuracy by (1) integrating systems that are respectively trained on heterogeneous annotations to reduce the approximation error, and (2) re-training models with high quality automatically converted data to reduce the estimation error. Evaluation on the CTB and PPD data shows that our novel model achieves a relative error reduction of 11% over the best reported result in the literature.</p><p>6 0.59768176 <a title="9-lsi-6" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>7 0.59398848 <a title="9-lsi-7" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>8 0.5540756 <a title="9-lsi-8" href="./acl-2012-Error_Mining_on_Dependency_Trees.html">83 acl-2012-Error Mining on Dependency Trees</a></p>
<p>9 0.51971322 <a title="9-lsi-9" href="./acl-2012-Syntactic_Annotations_for_the_Google_Books_NGram_Corpus.html">189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</a></p>
<p>10 0.44793385 <a title="9-lsi-10" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>11 0.44025844 <a title="9-lsi-11" href="./acl-2012-How_Are_Spelling_Errors_Generated_and_Corrected%3F_A_Study_of_Corrected_and_Uncorrected_Spelling_Errors_Using_Keystroke_Logs.html">111 acl-2012-How Are Spelling Errors Generated and Corrected? A Study of Corrected and Uncorrected Spelling Errors Using Keystroke Logs</a></p>
<p>12 0.42918962 <a title="9-lsi-12" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>13 0.40806627 <a title="9-lsi-13" href="./acl-2012-Strong_Lexicalization_of_Tree_Adjoining_Grammars.html">185 acl-2012-Strong Lexicalization of Tree Adjoining Grammars</a></p>
<p>14 0.39865166 <a title="9-lsi-14" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>15 0.39305854 <a title="9-lsi-15" href="./acl-2012-Grammar_Error_Correction_Using_Pseudo-Error_Sentences_and_Domain_Adaptation.html">103 acl-2012-Grammar Error Correction Using Pseudo-Error Sentences and Domain Adaptation</a></p>
<p>16 0.37554878 <a title="9-lsi-16" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>17 0.36595538 <a title="9-lsi-17" href="./acl-2012-A_Meta_Learning_Approach_to_Grammatical_Error_Correction.html">15 acl-2012-A Meta Learning Approach to Grammatical Error Correction</a></p>
<p>18 0.3648904 <a title="9-lsi-18" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>19 0.35679531 <a title="9-lsi-19" href="./acl-2012-Discriminative_Strategies_to_Integrate_Multiword_Expression_Recognition_and_Parsing.html">75 acl-2012-Discriminative Strategies to Integrate Multiword Expression Recognition and Parsing</a></p>
<p>20 0.35436586 <a title="9-lsi-20" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.011), (8, 0.139), (25, 0.012), (26, 0.055), (28, 0.038), (30, 0.023), (37, 0.029), (39, 0.028), (57, 0.012), (59, 0.013), (74, 0.053), (81, 0.018), (82, 0.033), (84, 0.022), (85, 0.074), (90, 0.217), (92, 0.052), (94, 0.039), (99, 0.058)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9202649 <a title="9-lda-1" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance. In this paper, we propose a method to estimate sense distributions for short queries. Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations. Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system, we obtain significant improvements over a state-of-the-art IR system.</p><p>2 0.91033804 <a title="9-lda-2" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>Author: Gregory Druck ; Bo Pang</p><p>Abstract: There are a growing number of popular web sites where users submit and review instructions for completing tasks as varied as building a table and baking a pie. In addition to providing their subjective evaluation, reviewers often provide actionable refinements. These refinements clarify, correct, improve, or provide alternatives to the original instructions. However, identifying and reading all relevant reviews is a daunting task for a user. In this paper, we propose a generative model that jointly identifies user-proposed refinements in instruction reviews at multiple granularities, and aligns them to the appropriate steps in the original instructions. Labeled data is not readily available for these tasks, so we focus on the unsupervised setting. In experiments in the recipe domain, our model provides 90. 1% F1 for predicting refinements at the review level, and 77.0% F1 for predicting refinement segments within reviews.</p><p>same-paper 3 0.9028489 <a title="9-lda-3" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>Author: Hyun-Je Song ; Jeong-Woo Son ; Tae-Gil Noh ; Seong-Bae Park ; Sang-Jo Lee</p><p>Abstract: All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost to serious errors and a smaller one to minor errors. Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub- sequent NLP tasks.</p><p>4 0.8585375 <a title="9-lda-4" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>5 0.85783285 <a title="9-lda-5" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<p>Author: Patrick Simianer ; Stefan Riezler ; Chris Dyer</p><p>Abstract: With a few exceptions, discriminative training in statistical machine translation (SMT) has been content with tuning weights for large feature sets on small development data. Evidence from machine learning indicates that increasing the training sample size results in better prediction. The goal of this paper is to show that this common wisdom can also be brought to bear upon SMT. We deploy local features for SCFG-based SMT that can be read off from rules at runtime, and present a learning algorithm that applies ‘1/‘2 regularization for joint feature selection over distributed stochastic learning processes. We present experiments on learning on 1.5 million training sentences, and show significant improvements over tuning discriminative models on small development sets.</p><p>6 0.85722417 <a title="9-lda-6" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>7 0.85693717 <a title="9-lda-7" href="./acl-2012-PORT%3A_a_Precision-Order-Recall_MT_Evaluation_Metric_for_Tuning.html">158 acl-2012-PORT: a Precision-Order-Recall MT Evaluation Metric for Tuning</a></p>
<p>8 0.85039341 <a title="9-lda-8" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>9 0.85019666 <a title="9-lda-9" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>10 0.84941989 <a title="9-lda-10" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>11 0.84638786 <a title="9-lda-11" href="./acl-2012-Character-Level_Machine_Translation_Evaluation_for_Languages_with_Ambiguous_Word_Boundaries.html">46 acl-2012-Character-Level Machine Translation Evaluation for Languages with Ambiguous Word Boundaries</a></p>
<p>12 0.84548938 <a title="9-lda-12" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>13 0.84460789 <a title="9-lda-13" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>14 0.84436142 <a title="9-lda-14" href="./acl-2012-Modeling_the_Translation_of_Predicate-Argument_Structure_for_SMT.html">147 acl-2012-Modeling the Translation of Predicate-Argument Structure for SMT</a></p>
<p>15 0.84321356 <a title="9-lda-15" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>16 0.84302175 <a title="9-lda-16" href="./acl-2012-Learning_to_Translate_with_Multiple_Objectives.html">136 acl-2012-Learning to Translate with Multiple Objectives</a></p>
<p>17 0.84170419 <a title="9-lda-17" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<p>18 0.84061491 <a title="9-lda-18" href="./acl-2012-Machine_Translation_without_Words_through_Substring_Alignment.html">140 acl-2012-Machine Translation without Words through Substring Alignment</a></p>
<p>19 0.83726209 <a title="9-lda-19" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>20 0.83614159 <a title="9-lda-20" href="./acl-2012-Improving_Word_Representations_via_Global_Context_and_Multiple_Word_Prototypes.html">117 acl-2012-Improving Word Representations via Global Context and Multiple Word Prototypes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
