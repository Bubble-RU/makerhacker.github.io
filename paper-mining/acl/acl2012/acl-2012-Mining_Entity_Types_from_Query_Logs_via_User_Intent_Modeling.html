<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-142" href="#">acl2012-142</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</h1>
<br/><p>Source: <a title="acl-2012-142-pdf" href="http://aclweb.org/anthology//P/P12/P12-1059.pdf">pdf</a></p><p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>Reference: <a title="acl-2012-142-reference" href="../acl2012_reference/acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  tl in@ c s  Abstract We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. [sent-2, score-1.101]
</p><p>2 We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. [sent-3, score-1.621]
</p><p>3 We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. [sent-4, score-0.772]
</p><p>4 We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in  tail query performance. [sent-6, score-1.692]
</p><p>5 There are, however, inherent problems in the entity repositories: (a) coverage: although coverage of head entity types is often reliable, the tail can be sparse; (b) noise: created by spammers, extraction 563 . [sent-12, score-0.855]
</p><p>6 com  errors or errors in crowdsourced content; (c) ambiguity: multiple types or entity identifiers are of-  ten associated with the same surface string; and (d) over-expression: many entities have types that are never used in the context of Web search. [sent-15, score-0.532]
</p><p>7 In this paper, we build such a system by leveraging Web search usage logs with large numbers of user sessions seeking or transacting on entities. [sent-18, score-0.329]
</p><p>8 We cast the task as performing probabilistic inference in a graphical model that captures how queries are generated, and then apply the model to contextually recognize entity types in new queries. [sent-19, score-0.641]
</p><p>9 We motivate and design several generative models based on the theory that search users’ (unobserved) intents govern the types of entities, the query formulations, and the ultimate clicks on Web documents. [sent-20, score-0.994]
</p><p>10 We show that jointly modeling user intent and entity type significantly outperforms the current state of the art on the task of entity type resolution in queries. [sent-21, score-1.275]
</p><p>11 The major contributions of our research are:  •  •  We introduce the idea that latent user intents can b inet an important dfaeacto trh aint modeling type ednits-s tributions over entities in Web search. [sent-22, score-0.872]
</p><p>12 We propose generative models and inference procedures using signals fordoemls query context, click, entity, entity type, and user intent. [sent-23, score-0.741]
</p><p>13 c so2c0ia1t2io Ans fso rc Ciatoiomnp fuotart Cio nmaplu Ltiantgiounisatlic Lsi,n pgaugiestsi5c 6s3–571,  •  •  2  We propose an efficient learning technique and a erob purospt implementation oafr our models, using real-world query data, and a realistic large set of entity types. [sent-26, score-0.548]
</p><p>14 The aforementioned methods do not use query logs or explicitly determine the relative probabilities of different entity senses. [sent-38, score-0.672]
</p><p>15 Query logs can contain billions of en564 tries, they provide an independent signal from text corpora, their timestamps allow the learning of type priors at specific points in time, and they can contain information such as clickthroughs that are not found in text corpora. [sent-48, score-0.251]
</p><p>16 Sekine and Suzuki (2007) used frequency features on context words in query logs to learn semantic classes of entities. [sent-49, score-0.445]
</p><p>17 Pas ¸ca (2007) used extraction techniques to mine instances of semantic classes from query logs. [sent-50, score-0.321]
</p><p>18 (2010) mined query logs to find attributes of entity instances. [sent-54, score-0.672]
</p><p>19 3 User Intents in Search Learning from query logs also allows us to leverage the concept of user intents. [sent-57, score-0.557]
</p><p>20 When users submit search queries, they often have specific intents in mind. [sent-58, score-0.514]
</p><p>21 (2010) examined how to infer the intent of queries. [sent-68, score-0.344]
</p><p>22 We are not aware of any other work that has leveraged user intents to learn type distributions. [sent-69, score-0.689]
</p><p>23 Given an entity-bearing query, they attempt to identify the entity and determine the type posteriors. [sent-73, score-0.355]
</p><p>24 While they only have four potential types (Movie, Game, Book, Mus i for c)  each entity, we employ over 70 popular types, allowing much greater coverage of real entities and their types. [sent-75, score-0.243]
</p><p>25 In contrast, our system self-labels training examples by searching query logs for high-likelihood entities, and must handle any errors introduced by this process. [sent-77, score-0.417]
</p><p>26 Our models also expand upon theirs by jointly modeling entity type with latent user intents, and by incorporating click signals. [sent-78, score-0.678]
</p><p>27 Other projects have also demonstrated the utility of topic modeling on query logs. [sent-79, score-0.32]
</p><p>28 (201 1) applied topic models to query logs in order to improve document ranking for search. [sent-82, score-0.417]
</p><p>29 3  Joint Model of Types and User Intents  We turn our attention now to the task of mining the type distributions of entities and of resolving the type of an entity in a particular query context. [sent-83, score-0.939]
</p><p>30 Our approach is to probabilistically describe how entitybearing queries are generated in Web search. [sent-84, score-0.323]
</p><p>31 We theorize that search queries are governed by a latent  user intent, which in turn influences the entity types, the choice of query words, and the clicked hosts. [sent-85, score-1.277]
</p><p>32 We develop inference procedures to infer the prior type distributions of entities in Web search as well as to resolve the type of an entity in a query, by maximizing the probability of observing a large collection of real-world queries and their clicked hosts. [sent-86, score-1.172]
</p><p>33 We represent a query q by a triple {n1, e, n2}, whWeree e represents t qhuee entity bmyen ati tornipeled i {nn nthe query, n1 and n2 are respectively the pre- and post-entity contexts (possibly empty), referred to as refiners. [sent-87, score-0.548]
</p><p>34 The unobserved semantic type of an entity e in a query is strongly correlated with the unobserved user intent. [sent-97, score-0.866]
</p><p>35 For example, if a user queries for “song”, then she is likely looking to ‘listen to it’, ‘download it’, ‘buy it’, or ‘find lyrics’ for it. [sent-98, score-0.413]
</p><p>36 Our  model incorporates this user intent as a latent variable. [sent-99, score-0.535]
</p><p>37 The choice of the query refiner words, n1 and n2, is also clearly influenced by the user intent. [sent-100, score-0.516]
</p><p>38 For example, refiners such as “lyrics” and “words” are more likely to be used in queries where the intent is 565  bearing queries. [sent-101, score-0.709]
</p><p>39 to ‘find lyrics’ than in queries where the intent is to ‘listen’ . [sent-102, score-0.617]
</p><p>40 com” are more likely to occur when the intent is to ‘find lyrics’, whereas  clicks on “pandora. [sent-105, score-0.379]
</p><p>41 Model IM leverages each of these signals: latent intent, query refiners, and clicked hosts. [sent-108, score-0.503]
</p><p>42 It generates entity-bearing queries by first generating an entity type, from which the user intent and entity is generated. [sent-109, score-1.267]
</p><p>43 In turn, the user intent is then used to generate the query refiners and the clicked host. [sent-110, score-1.002]
</p><p>44 In our data analysis, we observed that over 90% of entitybearing queries did not contain any refiner words n1 and n2. [sent-111, score-0.406]
</p><p>45 Our model first generates the type song, then given the type it generates the entity “ymca” and the intent ‘find lyrics’ . [sent-115, score-0.799]
</p><p>46 The intent is then used to generate the preand post-context words and “lyrics”, respectively, aanndd a ocsltic-cko on a th wosotr sdusc ∅h as “lyrics. [sent-116, score-0.344]
</p><p>47 For mathematical convenience, we assume that the user intent is generated independently of the entity itself. [sent-118, score-0.739]
</p><p>48 Model IM further  constrains the query by the latent user intent. [sent-125, score-0.484]
</p><p>49 Let K be the number of latent user intents that govern our query log, where K is fixed in advance. [sent-131, score-0.999]
</p><p>50 Then, the probability of intents i is defined as a multinomial distribution with probability vector θt such that Θ = [θ1 , θ2, . [sent-132, score-0.509]
</p><p>51 The probability ofgenerating an entity e is similarly governed by a parameter Ψ across all T types: YE  P(e= eˆ | t=ˆt) =  YΨtIˆ,[jj=ˆ e] Yj=1  XE  , s. [sent-138, score-0.357]
</p><p>52 ∀t XΨt,j = 1 Xj=1  The probability of generating an empty or nonempty context s given intent iis given by a Bernoulli with parameter σi:  P(s | i=ˆi) = σiˆI[s=1](1 − σiˆ)I[s=0] 566 Let V be the shared vocabulary size of all query refiner words n1 and n2. [sent-140, score-0.857]
</p><p>53 A click on a host is similarly determined by an intent iand is governed by parameter Ω across all K intents: YH  P(c= cˆ | i=ˆi) = Y hY= Y1  ΩiˆI,[hh= ˆc]  XH  , s. [sent-147, score-0.571]
</p><p>54 2 Learning Given a query corpus Q consisting of N independently aunedry identically d cisotrnisbiustteindg queries q inj = ej, and their corresponding clicked hosts  {nj1, n2j}  Φ,  {cjn, we estim}a atned dth teh parameters τ, nΘg, Ψ, σ, oanstds Ω by maximizing the (log) probability of observing Q. [sent-150, score-0.804]
</p><p>55 The log P(Q) can be written as: XN  logP(Q) =XXPj(t,i | q,c)logPj(q,c,t,i) jX= X1 Xt,i  In the above equation, Pj (t, i | q, c) is the posterior distribution over types a(nt,di user ci)nt iesn tthse f poro sttheejth query. [sent-151, score-0.293]
</p><p>56 It is important to note that at runtime when a new query is issued, we have to resolve the entity in the absence of any observed click. [sent-157, score-0.548]
</p><p>57 4, which utilizes only query refinement words to infer entity type distributions. [sent-162, score-0.648]
</p><p>58 Fitting to an existing Knowledge Base: Although in general our model decodes type distributions for arbitrary entities, in many practical cases it is beneficial to constrain the types to those admissible in a fixed knowledge base (such as Freebase). [sent-173, score-0.284]
</p><p>59 As an example, if the entity is “ymca”, admissible types may include song, place, and educat ional inst itut i on. [sent-174, score-0.56]
</p><p>60 4 Evaluation Methodology We refer to QL as a set of English Web search queries issued to a commercial search engine over a period of several months. [sent-177, score-0.466]
</p><p>61 1 Entity Inventory  Although our models generalize to any entity repository, we experiment in this paper with entities covering a wide range ofweb search queries, coming from 73 types in Freebase. [sent-179, score-0.511]
</p><p>62 2, and then choosing the top most frequent types such that 50% of the queries are covered by an entity of one of these types1 . [sent-181, score-0.614]
</p><p>63 2 Training Data Construction In order to learn type distributions by jointly modeling user intents and a large number of types, we require a large set of training examples containing tagged entities and their potential types. [sent-183, score-0.906]
</p><p>64 Reliably recognizing entities in queries is not a solved problem. [sent-186, score-0.378]
</p><p>65 However, for training we do not require high coverage of entities in QL, so high precision on a sizeable set of query instances can be a proper proxy. [sent-187, score-0.423]
</p><p>66 To this end, we collect candidate entities in QL via simple string matching on Freebase entity  strings within our preselected 73 types. [sent-188, score-0.36]
</p><p>67 568 an exact match in queries to how often it occurs as a partial match. [sent-200, score-0.273]
</p><p>68 The resulting queries are further filtered by keeping only those where the pre- and post-entity contexts (n1 and n2) were empty or a single word (accounting for a very large fraction of the queries). [sent-201, score-0.349]
</p><p>69 We also eliminate entries with clicked hosts that have  been clicked fewer than 100 times over the entire QL. [sent-202, score-0.367]
</p><p>70 Finally, for training we filter out any query with an entity that has more than two potential types2. [sent-203, score-0.575]
</p><p>71 The resulting training data consists of several million queries, 73 different entity types, and approximately 135K different entities, 100K different refiner words, and 40K clicked hosts. [sent-206, score-0.497]
</p><p>72 3 Test Set Annotation We sampled two datasets, HEAD and TAIL, each consisting of 500 queries containing an entity belonging to one of the 73 types in our inventory, from a frequency-weighted random sample and a uniform random sample of QL, respectively. [sent-208, score-0.614]
</p><p>73 We conducted a user study to establish a gold standard of the correct entity types in each query. [sent-209, score-0.481]
</p><p>74 For each query in our test sets, we displayed the query, associated clicked host, and entity to the annotator,  along with a list of permissible types from our type inventory. [sent-211, score-0.893]
</p><p>75 The annotator is tasked with identifying all applicable types from that list, or marking the test case as faulty because of an error in entity identification, bad click host (e. [sent-212, score-0.496]
</p><p>76 From HEAD and TAIL, we eliminated three categories of queries that did not offer any interesting type disambiguation opportunities: • •  queries that contained entities with only one  queries  t  2For testing we did not omit any entity or type. [sent-224, score-1.279]
</p><p>77 For Model IM, we varied the number of user intents (K) in intervals from 100 to 400 (see Figure 3), under the assumption that multiple intents would exist per entity type. [sent-266, score-1.293]
</p><p>78 The first baseline is an assignment of Freebase types according to their frequency in our query set BFB, and the second is Model Guo009 (Guo et al. [sent-268, score-0.379]
</p><p>79 On head queries, the addition of the empty context parameter σ and click signal Ω to-  gether (Model M1) significantly outperforms both the baseline and the state-of-the-art model Guo009. [sent-272, score-0.324]
</p><p>80 Further modeling the user intent in Model IM results in significantly better performance over all models and across all metrics. [sent-273, score-0.537]
</p><p>81 We observe a different behavior on tail queries where all models significantly outperform the baseline BFB, but are not significantly different from each other. [sent-275, score-0.473]
</p><p>82 Our models can also assign a prior type distribu-  tion to each entity by further marginalizing Eq. [sent-287, score-0.384]
</p><p>83 We measured the quality of our learned type priors using the subset of queries in our HEAD test set that consisted of only an entity without any refiners. [sent-289, score-0.655]
</p><p>84 Inspection of the TAIL queries revealed that entities were greatly skewed towards people (e. [sent-298, score-0.378]
</p><p>85 Analysis of the latent user intent parameter Θ in Model IM showed that most people types had most of their probability mass assigned to the same three generic and common intents for people types: ‘see pictures of’, ‘find biographical information about’, and ‘see video of’ . [sent-301, score-1.131]
</p><p>86 In other words, latent intents in Model IM are over-  expressive and they do not help in differentiating people types. [sent-302, score-0.527]
</p><p>87 570 The largest class of errors came from queries bearing an entity with semantically very similar types where our highest ranked type was not judged correct by the annotators. [sent-303, score-0.771]
</p><p>88 For example, for the query “philippine daily inquirer” our system ranked newspaper ahead of periodi cal but a judge rejected the former and approved the latter. [sent-304, score-0.388]
</p><p>89 An interesting success case in the TAIL is highlighted by two queries involving the entity “ymca”, which in our data can either be a s ong, place, or educat ional inst itut i on. [sent-306, score-0.707]
</p><p>90 For the query “jamestown ymca ny”, IM correctly classified “ymca” as a place and for the query “ymca palomar” it correctly classified it as an educat i onal inst itut ion. [sent-311, score-0.869]
</p><p>91 We further issued the query “ymca lyrics” and the type song  was then highest ranked. [sent-312, score-0.469]
</p><p>92 Finally, although we do not formally evaluate it, it is clear that training our model on different time spans of queries should lead to type distributions adapted to that time period. [sent-315, score-0.431]
</p><p>93 6  Conclusion  Jointly modeling the interplay between the underlying user intents and entity types in web search queries shows significant improvements over the current state of the art on the task of resolving entity types in head queries. [sent-316, score-1.88]
</p><p>94 At the same time, no degradation in tail queries is observed. [sent-317, score-0.421]
</p><p>95 Our proposed models can be efficiently trained using an EM algorithm and can be further used to assign prior type distributions to entities in an existing knowledge base and to insert new entities into it. [sent-318, score-0.368]
</p><p>96 Although this paper leverages latent intents in search queries, it stops short of understanding the  nature of the intents. [sent-319, score-0.565]
</p><p>97 It remains an open problem to characterize and enumerate intents and to identify the types of queries that benefit most from intent models. [sent-320, score-1.152]
</p><p>98 Determining the user intent of web search engine queries. [sent-376, score-0.648]
</p><p>99 Piggyback: Using search engines for robust cross-domain named entity recognition. [sent-427, score-0.32]
</p><p>100 Building taxonomy of web search intents for name entity queries. [sent-441, score-0.842]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('intents', 0.449), ('intent', 0.344), ('query', 0.293), ('queries', 0.273), ('entity', 0.255), ('clicked', 0.159), ('tail', 0.148), ('user', 0.14), ('im', 0.139), ('ymca', 0.133), ('logs', 0.124), ('freebase', 0.122), ('lyrics', 0.116), ('entities', 0.105), ('click', 0.105), ('type', 0.1), ('bfb', 0.1), ('prec', 0.1), ('ql', 0.1), ('head', 0.086), ('types', 0.086), ('refiner', 0.083), ('empty', 0.076), ('web', 0.073), ('ny', 0.07), ('mapw', 0.066), ('pjn', 0.066), ('refiners', 0.066), ('ndcg', 0.066), ('govern', 0.066), ('search', 0.065), ('www', 0.062), ('distributions', 0.058), ('latent', 0.051), ('educat', 0.05), ('entitybearing', 0.05), ('host', 0.05), ('inst', 0.05), ('itut', 0.05), ('repositories', 0.05), ('hosts', 0.049), ('listen', 0.043), ('guo', 0.042), ('york', 0.042), ('pantel', 0.041), ('governed', 0.041), ('wanting', 0.04), ('admissible', 0.04), ('unobserved', 0.039), ('song', 0.039), ('sch', 0.038), ('posterior', 0.037), ('issued', 0.037), ('cal', 0.037), ('clicks', 0.035), ('hyponym', 0.033), ('maga', 0.033), ('periodi', 0.033), ('radlinski', 0.033), ('uppdate', 0.033), ('pages', 0.031), ('judged', 0.031), ('hinrich', 0.031), ('parameter', 0.031), ('probability', 0.03), ('log', 0.03), ('switch', 0.03), ('yin', 0.029), ('marginalizing', 0.029), ('carman', 0.029), ('bollacker', 0.029), ('interplay', 0.029), ('ional', 0.029), ('senses', 0.029), ('map', 0.028), ('classes', 0.028), ('art', 0.028), ('yj', 0.028), ('resolving', 0.028), ('inventory', 0.028), ('priors', 0.027), ('inference', 0.027), ('potential', 0.027), ('expressive', 0.027), ('modeling', 0.027), ('bearing', 0.026), ('alfonseca', 0.026), ('marius', 0.026), ('kozareva', 0.026), ('microsoft', 0.026), ('significantly', 0.026), ('signals', 0.026), ('engine', 0.026), ('coverage', 0.025), ('qi', 0.025), ('wa', 0.025), ('jain', 0.025), ('rahman', 0.025), ('rejected', 0.025), ('redmond', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="142-tfidf-1" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>2 0.25879842 <a title="142-tfidf-2" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>Author: Kuzman Ganchev ; Keith Hall ; Ryan McDonald ; Slav Petrov</p><p>Abstract: Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult. We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time. Unlike previous work, our final model does not require any additional resources at run-time. Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction. Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.</p><p>3 0.16488792 <a title="142-tfidf-3" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>Author: Limin Yao ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: To discover relation types from text, most methods cluster shallow or syntactic patterns of relation mentions, but consider only one possible sense per pattern. In practice this assumption is often violated. In this paper we overcome this issue by inducing clusters of pattern senses from feature representations of patterns. In particular, we employ a topic model to partition entity pairs associated with patterns into sense clusters using local and global features. We merge these sense clusters into semantic relations using hierarchical agglomerative clustering. We compare against several baselines: a generative latent-variable model, a clustering method that does not disambiguate between path senses, and our own approach but with only local features. Experimental results show our proposed approach discovers dramatically more accurate clusters than models without sense disambiguation, and that incorporating global features, such as the document theme, is crucial.</p><p>4 0.15414034 <a title="142-tfidf-4" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>5 0.15209875 <a title="142-tfidf-5" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance. In this paper, we propose a method to estimate sense distributions for short queries. Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations. Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system, we obtain significant improvements over a state-of-the-art IR system.</p><p>6 0.13824619 <a title="142-tfidf-6" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>7 0.13190705 <a title="142-tfidf-7" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>8 0.11705193 <a title="142-tfidf-8" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>9 0.10348944 <a title="142-tfidf-9" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>10 0.096798293 <a title="142-tfidf-10" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>11 0.085309237 <a title="142-tfidf-11" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>12 0.082080916 <a title="142-tfidf-12" href="./acl-2012-Joint_Inference_of_Named_Entity_Recognition_and_Normalization_for_Tweets.html">124 acl-2012-Joint Inference of Named Entity Recognition and Normalization for Tweets</a></p>
<p>13 0.078293733 <a title="142-tfidf-13" href="./acl-2012-A_Probabilistic_Model_for_Canonicalizing_Named_Entity_Mentions.html">18 acl-2012-A Probabilistic Model for Canonicalizing Named Entity Mentions</a></p>
<p>14 0.072834767 <a title="142-tfidf-14" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>15 0.070616715 <a title="142-tfidf-15" href="./acl-2012-Tweet_Recommendation_with_Graph_Co-Ranking.html">205 acl-2012-Tweet Recommendation with Graph Co-Ranking</a></p>
<p>16 0.068430953 <a title="142-tfidf-16" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>17 0.065440752 <a title="142-tfidf-17" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>18 0.063276239 <a title="142-tfidf-18" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>19 0.058468461 <a title="142-tfidf-19" href="./acl-2012-Reducing_Wrong_Labels_in_Distant_Supervision_for_Relation_Extraction.html">169 acl-2012-Reducing Wrong Labels in Distant Supervision for Relation Extraction</a></p>
<p>20 0.054575983 <a title="142-tfidf-20" href="./acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction.html">60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.188), (1, 0.118), (2, -0.003), (3, 0.111), (4, 0.048), (5, 0.184), (6, 0.004), (7, 0.035), (8, 0.072), (9, -0.04), (10, 0.22), (11, 0.033), (12, -0.026), (13, 0.077), (14, 0.041), (15, -0.11), (16, 0.038), (17, 0.02), (18, 0.093), (19, -0.106), (20, 0.094), (21, 0.236), (22, 0.101), (23, 0.044), (24, -0.074), (25, -0.145), (26, 0.243), (27, 0.074), (28, 0.013), (29, 0.033), (30, -0.092), (31, 0.032), (32, 0.061), (33, -0.094), (34, -0.039), (35, -0.005), (36, 0.014), (37, -0.006), (38, -0.127), (39, 0.028), (40, -0.006), (41, 0.025), (42, 0.01), (43, 0.005), (44, 0.014), (45, 0.036), (46, -0.026), (47, 0.129), (48, -0.042), (49, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96650463 <a title="142-lsi-1" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>2 0.78696632 <a title="142-lsi-2" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>Author: Kuzman Ganchev ; Keith Hall ; Ryan McDonald ; Slav Petrov</p><p>Abstract: Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult. We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time. Unlike previous work, our final model does not require any additional resources at run-time. Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction. Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.</p><p>3 0.78497881 <a title="142-lsi-3" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>4 0.71549946 <a title="142-lsi-4" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>5 0.58540756 <a title="142-lsi-5" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance. In this paper, we propose a method to estimate sense distributions for short queries. Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations. Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system, we obtain significant improvements over a state-of-the-art IR system.</p><p>6 0.56517851 <a title="142-lsi-6" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>7 0.50932842 <a title="142-lsi-7" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>8 0.45112452 <a title="142-lsi-8" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>9 0.42689112 <a title="142-lsi-9" href="./acl-2012-Ecological_Evaluation_of_Persuasive_Messages_Using_Google_AdWords.html">77 acl-2012-Ecological Evaluation of Persuasive Messages Using Google AdWords</a></p>
<p>10 0.37389573 <a title="142-lsi-10" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>11 0.35050473 <a title="142-lsi-11" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>12 0.35038206 <a title="142-lsi-12" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>13 0.34268323 <a title="142-lsi-13" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<p>14 0.33822465 <a title="142-lsi-14" href="./acl-2012-Structuring_E-Commerce_Inventory.html">186 acl-2012-Structuring E-Commerce Inventory</a></p>
<p>15 0.33743644 <a title="142-lsi-15" href="./acl-2012-Joint_Inference_of_Named_Entity_Recognition_and_Normalization_for_Tweets.html">124 acl-2012-Joint Inference of Named Entity Recognition and Normalization for Tweets</a></p>
<p>16 0.33216718 <a title="142-lsi-16" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>17 0.32760128 <a title="142-lsi-17" href="./acl-2012-A_Probabilistic_Model_for_Canonicalizing_Named_Entity_Mentions.html">18 acl-2012-A Probabilistic Model for Canonicalizing Named Entity Mentions</a></p>
<p>18 0.30517635 <a title="142-lsi-18" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>19 0.28117767 <a title="142-lsi-19" href="./acl-2012-WizIE%3A_A_Best_Practices_Guided_Development_Environment_for_Information_Extraction.html">215 acl-2012-WizIE: A Best Practices Guided Development Environment for Information Extraction</a></p>
<p>20 0.27040738 <a title="142-lsi-20" href="./acl-2012-Coreference_Semantics_from_Web_Features.html">58 acl-2012-Coreference Semantics from Web Features</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.019), (26, 0.044), (28, 0.032), (30, 0.034), (37, 0.027), (39, 0.081), (52, 0.012), (74, 0.028), (81, 0.232), (82, 0.028), (84, 0.021), (85, 0.023), (90, 0.152), (92, 0.096), (94, 0.02), (96, 0.011), (99, 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80758536 <a title="142-lda-1" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>2 0.77649403 <a title="142-lda-2" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>Author: Xinfan Meng ; Furu Wei ; Xiaohua Liu ; Ming Zhou ; Ge Xu ; Houfeng Wang</p><p>Abstract: The amount of labeled sentiment data in English is much larger than that in other languages. Such a disproportion arouse interest in cross-lingual sentiment classification, which aims to conduct sentiment classification in the target language (e.g. Chinese) using labeled data in the source language (e.g. English). Most existing work relies on machine translation engines to directly adapt labeled data from the source language to the target language. This approach suffers from the limited coverage of vocabulary in the machine translation results. In this paper, we propose a generative cross-lingual mixture model (CLMM) to leverage unlabeled bilingual parallel data. By fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage signifi- cantly. Experiments on multiple data sets show that CLMM is consistently effective in two settings: (1) labeled data in the target language are unavailable; and (2) labeled data in the target language are also available.</p><p>3 0.75516194 <a title="142-lda-3" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>Author: Qiuye Zhao ; Mitch Marcus</p><p>Abstract: We show for both English POS tagging and Chinese word segmentation that with proper representation, large number of deterministic constraints can be learned from training examples, and these are useful in constraining probabilistic inference. For tagging, learned constraints are directly used to constrain Viterbi decoding. For segmentation, character-based tagging constraints can be learned with the same templates. However, they are better applied to a word-based model, thus an integer linear programming (ILP) formulation is proposed. For both problems, the corresponding constrained solutions have advantages in both efficiency and accuracy. 1 introduction In recent work, interesting results are reported for applications of integer linear programming (ILP) such as semantic role labeling (SRL) (Roth and Yih, 2005), dependency parsing (Martins et al., 2009) and so on. In an ILP formulation, ’non-local’ deterministic constraints on output structures can be naturally incorporated, such as ”a verb cannot take two subject arguments” for SRL, and the projectivity constraint for dependency parsing. In contrast to probabilistic constraints that are estimated from training examples, this type of constraint is usually hand-written reflecting one’s linguistic knowledge. Dynamic programming techniques based on Markov assumptions, such as Viterbi decoding, cannot handle those ’non-local’ constraints as discussed above. However, it is possible to constrain Viterbi 1054 decoding by ’local’ constraints, e.g. ”assign label t to word w” for POS tagging. This type of constraint may come from human input solicited in interactive inference procedure (Kristjansson et al., 2004). In this work, we explore deterministic constraints for two fundamental NLP problems, English POS tagging and Chinese word segmentation. We show by experiments that, with proper representation, large number of deterministic constraints can be learned automatically from training data, which can then be used to constrain probabilistic inference. For POS tagging, the learned constraints are directly used to constrain Viterbi decoding. The corresponding constrained tagger is 10 times faster than searching in a raw space pruned with beam-width 5. Tagging accuracy is moderately improved as well. For Chinese word segmentation (CWS), which can be formulated as character tagging, analogous constraints can be learned with the same templates as English POS tagging. High-quality constraints can be learned with respect to a special tagset, however, with this tagset, the best segmentation accuracy is hard to achieve. Therefore, these character-based constraints are not directly used for determining predictions as in English POS tagging. We propose an ILP formulation of the CWS problem. By adopting this ILP formulation, segmentation F-measure is increased from 0.968 to 0.974, as compared to Viterbi decoding with the same feature set. Moreover, the learned constraints can be applied to reduce the number of possible words over a character sequence, i.e. to reduce the number of variables to set. This reduction of problem size immediately speeds up an ILP solver by more than 100 times. ProceediJnegjus, o Rfe thpeu 5bl0icth o Afn Knouraela M, 8e-e1t4in Jgul oyf t 2h0e1 A2.s ?oc c2ia0t1io2n A fsosro Cciaotmiopnu ftaotrio Cnoamlp Luintagtuioisntaicls L,i pnaggueis t 1i0c5s4–1062, 2 English POS tagging 2.1 Explore deterministic constraints Suppose that, following (Chomsky, 1970), we distinguish major lexical categories (Noun, Verb, Adjective and Preposition) by two binary features: + |− N and +|− V. Let (+N −V) =Noun, (−N +V) =Verb, (+N, +V) =Adjective, aonudn (−N, −V) =preposition. A word occurring in betw(e−eNn a preceding wosoitrdio nth.e Aand w a following wgo irnd of always bears the feature +N. On the other hand, consider the annotation guideline of English Treebank (Marcus et al., 1993) instead. Part-of-speech (POS) tags are used to categorize words, for example, the POS tag VBG tags verbal gerunds, NNS tags nominal plurals, DT tags determiners and so on. Following this POS representation, there are as many as 10 possible POS tags that may occur in between the–of, as estimated from the WSJ corpus of Penn Treebank. , 2.1.1 Templates of deterministic constraints , To explore determinacy in the distribution of POS tags in Penn Treebank, we need to consider that a POS tag marks the basic syntactic category of a word as well as its morphological inflection. A constraint that may determine the POS category should reflect both the context and the morphological feature of the corresponding word. The practical difficulty in representing such deterministic constraints is that we do not have a perfect mechanism to analyze morphological features of a word. Endings or prefixes of English words do not deterministically mark their morphological inflections. We propose to compute the morph feature of a word as the set of all of its possible tags, i.e. all tag types that are assigned to the word in training data. Furthermore, we approximate unknown words in testing data by rare words in training data. For a word that occurs less than 5 times in the training corpus, we compute its morph feature as its last two characters, which is also conjoined with binary features indicating whether the rare word contains digits, hyphens or upper-case characters respectively. See examples of morph features in Table 1. We consider bigram and trigram templates for generating potentially deterministic constraints. Let denote the ith word relative to the current word w0; and mi denote the morph feature of wi. A wi 1055 w(fr0e=qtruaednets)(set of pmos0s=ib{lNeN taSg,s V oBfZ th}e word) w0=t(imraere-s)hares(thme0 l=as{t- tewso, c HhYaPraHcEteNrs}. .) Table 1: Morph features offrequent words and rare words as computed from the WSJ Corpus of Penn Treebank. -gtbr ai -m w −1w 0w−mw1 m,wm 0−, 1mw1 0 w mw1 , mw m− 1m 1mw0m0w,1 wm, m0 −m1 m 0wm1 Table 2: The templates for generating potentially deterministic constraints of English POS tagging. bigram constraint includes one contextual word (w−1 |w1) or the corresponding morph feature; and a trigram constraint includes both contextual words or their morph features. Each constraint is also con- joined with w0 or m0, as described in Table 2. 2.1.2 Learning of deterministic constraints In the above section, we explore templates for potentially deterministic constraints that may determine POS category. With respect to a training corpus, if a constraint C relative to w0 ’always’ assigns a certain POS category t∗ to w0 in its context, i.e. > thr, and this constraint occurs more than a cutoff number, we consider it as a deterministic constraint. The threshold thr is a real number just under 1.0 and the cutoff number is empirically set to 5 in our experiments. counctou(Cnt∧(tC0)=t∗) 2.1.3 Decoding of deterministic constraints By the above definition, the constraint of w−1 = the, m0 = {NNS VBZ } and w1 = of is deterministic. It det=er{mNiNneSs, ,the V BPZO}S category of w0 to be NNS. There are at least two ways of decoding these constraints during POS tagging. Take the word trades for example, whose morph feature is {NNS, VBZ}. fOonre e xaaltemrnplaet,ive w hiso sthea tm as long as rtera dises { occurs Zb e}-. tween the-of, it is tagged with NNS. The second alternative is that the tag decision is made only if all deterministic constraints relative to this occurrence , of trades agree on the same tag. Both ways of decoding are purely rule-based and involve no probabilistic inference. In favor of a higher precision, we adopt the latter one in our experiments. tTchoe/nDscrotTamwSpci&lnoeLmxpd;/–fiulenbtaxp/i–cloufntg/aNpnlOci(amgnw/1–tOhNTpe(lanS+Ti&/m2cNL)lubTdaien2ls/)IoVNuBtlZamwn.1=ic2l3ud,ems.2=1 Table 3: Comparison of raw input and constrained input. 2.2 Search in a constrained space Following most previous work, we consider POS tagging as a sequence classification problem and de- compose the overall sequence scnore over the linear structure, i.e. ˆt =t∈atraggGmENa(xw)Xi=1score(ti) where function tagGEN maps input seXntence w = w1...wn to the set of all tag sequences that are of length n. If a POS tagger takes raw input only, i.e. for every word, the number of possible tags is a constant T, the space of tagGEN is as large as Tn. On the other hand, if we decode deterministic constraints first be- fore a probabilistic search, i.e. for some words, the number of possible tags is reduced to 1, the search space is reduced to Tm, where m is the number of (unconstrained) words that are not subject to any deterministic constraints. Viterbi algorithm is widely used for tagging, and runs in O(nT2) when searching in an unconstrained space. On the other hand, consider searching in a constrained space. Suppose that among the m unconstrained words, m1 of them follow a word that has been tagged by deterministic constraints and m2 (=m-m1) of them follow another unconstrained word. Viterbi decoder runs in O(m1T + m2T2) while searching in such a constrained space. The example in Table 3 shows raw and constrained input with respect to a typical input sentence. Lookahead features The score of tag predictions are usually computed in a high-dimensional feature space. We adopt the basic feature set used in (Ratnaparkhi, 1996) and (Collins, 2002). Moreover, when deterministic constraints have applied to contextual words of w0, it is also possible to include some lookahead feature templates, such as: t0&t1; , t0&t1;&t2; , and t−1&t0;&t1; where ti represents the tag of the ith word relative 1056 to the current word w0. As discussed in (Shen et al., 2007), categorical information of neighbouring words on both sides of w0 help resolve POS ambiguity of w0. In (Shen et al., 2007), lookahead features may be available for use during decoding since searching is bidirectional instead of left-to-right as in Viterbi decoding. In this work, deterministic constraints are decoded before the application of probabilistic models, therefore lookahead features are made available during Viterbi decoding. 3 Chinese Word Segmentation (CWS) 3.1 Word segmentation as character tagging Considering the ambiguity problem that a Chinese character may appear in any relative position in a word and the out-of-vocabulary (OOV) problem that it is impossible to observe all words in training data, CWS is widely formulated as a character tagging problem (Xue, 2003). A character-based CWS decoder is to find the highest scoring tag sequence tˆ over the input character sequence c, i.e. Xn tˆ =t∈ atraggGmEaNx(c)Xi=1score(ti) . This is the same formulation as POS tagging. The Viterbi algorithm is also widely used for decoding. The tag of each character represents its relative position in a word. Two popular tagsets include 1) IB: where B tags the beginning of a word and I all other positions; and 2) BMES: where B, M and E represent the beginning, middle and end of a multicharacter word respectively, and S tags a singlecharacter word. For example, after decoding with BMES, 4 consecutive characters associated with the tag sequence BMME compose a word. However, after decoding with IB, characters associated with BIII may compose a word if the following tag is B or only form part of a word if the following tag is I. Even though character tagging accuracy is higher with tagset IB, tagset BMES is more popular in use since better performance of the original problem CWS can be achieved by this tagset. Character-based feature templates We adopt the ’non-lexical-target’ feature templates in (Jiang et al., 2008a). Let ci denote the ith character relative to the current character c0 and t0 denote the tag assigned to c0. The following templates are used: ci&t0; (i=-2...2), cici+1&t0; (i=-2...1) and c−1c1&t0.; Character-based deterministic constraints We can use the same templates as described in Table 2 to generate potentially deterministic constraints for CWS character tagging, except that there are no morph features computed for Chinese characters. As we will show with experimental results in Section 5.2, useful deterministic constraints for CWS can be learned with tagset IB but not with tagset BMES. It is interesting but not surprising to notice, again, that the determinacy of a problem is sensitive to its representation. Since it is hard to achieve the best segmentations with tagset IB, we propose an indirect way to use these constraints in the following section, instead of applying these constraints as straightforwardly as in English POS tagging. 3.2 Word-based word segmentation A word-based CWS decoder finds the highest scoring segmentation sequence wˆ that is composed by the input character sequence c, i.e. wˆ =w∈arseggGmEaNx(c)Xi|=w1|score(wi) . where function segGEN maps character sequence c to the set of all possible segmentations of c. For example, w = (c1. .cl1 ) ...(cn−lk+1 ...cn) represents a segmentation of k words and the lengths of the first and last word are l1 and lk respectively. In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996). Exact search is possible with a Viterbi-style algorithm, but beamsearch decoding is more popular as used in (Zhang and Clark, 2007) and (Jiang et al., 2008a). We propose an Integer Linear Programming (ILP) formulation of word segmentation, which is naturally viewed as a word-based model for CWS. Character-based deterministic constraints, as discussed in Section 3.1, can be easily applied. 3.3 ILP formulation of CWS Given a character sequence c=c1 ...cn, there are s(= n(n + 1)/2) possible words that are contiguous subsets of c, i.e. w1, ..., ws ⊆ c. Our goal is to find 1057 Table 4: Comparison of raw input and constrained input. an optimal solution x = ...xs that maximizes x1 Xs Xscore(wi) · xi, subject to Xi= X1 (1) X xi = 1, ∀c ∈ c; (2) ix:Xic∈∈wi {0,1},1 ≤i≤s The boolean value of xi, as guaranteed by constraint (2), indicates whether wi is selected in the segmentation solution or not. Constraint (1) requires every character to be included in exactly one selected word, thus guarantees a proper segmentation of the whole sequence. This resembles the ILP formulation of the set cover problem, though the first con- straint is different. Take n = 2 for example, i.e. c = c1c2, the set of possible words is {c1, c2 , c1c2}, i.e. s = |x| = t3 o. T pohesrseib are only t iwso { possible soli.uet.ion ss = subject t o3 .co Tnhsetrreain artse (1) yan tdw (2), x = 1 s1o0giving an output set {c1, c2}, or x = 001 giving an output asent {c1c2}. tTphuet efficiency o.f solving this problem depends on the number of possible words (contiguous subsets) over a character sequence, i.e. the number of variables in x. So as to reduce |x|, we apply determiniasbtlice sc ionn xs.tra Sinots a predicting I |xB| tags first, w dehtiecrhm are learned as described in Section 3.1. Possible words are generated with respect to the partially tagged character sequence. A character tagged with B always occurs at the beginning of a possible word. Table 4 illustrates the constrained and raw input with respect to a typical character sequence. 3.4 Character- and word-based features As studied in previous work, word-based feature templates usually include the word itself, sub-words contained in the word, contextual characters/words and so on. It has been shown that combining the use of character- and word-based features helps improve performance. However, in the character tag- ging formulation, word-based features are non-local. To incorporate these non-local features and make the search tractable, various efforts have been made. For example, Jiang et al. (2008a) combine different levels of knowledge in an outside linear model of a twolayer cascaded model; Jiang et al. (2008b) uses the forest re-ranking technique (Huang, 2008); and in (Kruengkrai et al., 2009), only known words in vocabulary are included in the hybrid lattice consisting of both character- and word-level nodes. We propose to incorporate character-based features in word-based models. Consider a characterbased feature function φ(c, t,c) that maps a character-tag pair to a high-dimensional feature space, with respect to an input character sequence c. For a possible word over c of length l , wi = ci0 ...ci0+l−1, tag each character cij in this word with a character-based tag tij . Character-based features of wi can be computed as {φ(cij , tij , c) |0 ≤ j < l}. The ficrsant row oofm pTautbeled a5s i {llφus(tcrates c,ch)a|r0ac ≤ter j-b</p><p>4 0.66144055 <a title="142-lda-4" href="./acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</a></p>
<p>Author: Hiroyuki Shindo ; Yusuke Miyao ; Akinori Fujino ; Masaaki Nagata</p><p>Abstract: We propose Symbol-Refined Tree Substitution Grammars (SR-TSGs) for syntactic parsing. An SR-TSG is an extension of the conventional TSG model where each nonterminal symbol can be refined (subcategorized) to fit the training data. We aim to provide a unified model where TSG rules and symbol refinement are learned from training data in a fully automatic and consistent fashion. We present a novel probabilistic SR-TSG model based on the hierarchical Pitman-Yor Process to encode backoff smoothing from a fine-grained SR-TSG to simpler CFG rules, and develop an efficient training method based on Markov Chain Monte Carlo (MCMC) sampling. Our SR-TSG parser achieves an F1 score of 92.4% in the Wall Street Journal (WSJ) English Penn Treebank parsing task, which is a 7.7 point improvement over a conventional Bayesian TSG parser, and better than state-of-the-art discriminative reranking parsers.</p><p>5 0.65954584 <a title="142-lda-5" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>Author: Xiaohua Liu ; Furu Wei ; Ming Zhou ; QuickView Team Microsoft</p><p>Abstract: Tweets have become a comprehensive repository for real-time information. However, it is often hard for users to quickly get information they are interested in from tweets, owing to the sheer volume of tweets as well as their noisy and informal nature. We present QuickView, an NLP-based tweet search platform to tackle this issue. Specifically, it exploits a series of natural language processing technologies, such as tweet normalization, named entity recognition, semantic role labeling, sentiment analysis, tweet classification, to extract useful information, i.e., named entities, events, opinions, etc., from a large volume of tweets. Then, non-noisy tweets, together with the mined information, are indexed, on top of which two brand new scenarios are enabled, i.e., categorized browsing and advanced search, allowing users to effectively access either the tweets or fine-grained information they are interested in.</p><p>6 0.65935493 <a title="142-lda-6" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>7 0.65875781 <a title="142-lda-7" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>8 0.65677226 <a title="142-lda-8" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>9 0.65583277 <a title="142-lda-9" href="./acl-2012-Learning_the_Latent_Semantics_of_a_Concept_from_its_Definition.html">132 acl-2012-Learning the Latent Semantics of a Concept from its Definition</a></p>
<p>10 0.65379101 <a title="142-lda-10" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>11 0.65298986 <a title="142-lda-11" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>12 0.65120244 <a title="142-lda-12" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>13 0.65109897 <a title="142-lda-13" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>14 0.65018278 <a title="142-lda-14" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>15 0.64852649 <a title="142-lda-15" href="./acl-2012-Finding_Bursty_Topics_from_Microblogs.html">98 acl-2012-Finding Bursty Topics from Microblogs</a></p>
<p>16 0.64766151 <a title="142-lda-16" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>17 0.64637077 <a title="142-lda-17" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>18 0.64580202 <a title="142-lda-18" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>19 0.64542675 <a title="142-lda-19" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>20 0.64462578 <a title="142-lda-20" href="./acl-2012-A_Topic_Similarity_Model_for_Hierarchical_Phrase-based_Translation.html">22 acl-2012-A Topic Similarity Model for Hierarchical Phrase-based Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
