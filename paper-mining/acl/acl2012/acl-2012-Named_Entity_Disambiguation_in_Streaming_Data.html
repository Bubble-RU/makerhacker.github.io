<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>153 acl-2012-Named Entity Disambiguation in Streaming Data</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-153" href="#">acl2012-153</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>153 acl-2012-Named Entity Disambiguation in Streaming Data</h1>
<br/><p>Source: <a title="acl-2012-153-pdf" href="http://aclweb.org/anthology//P/P12/P12-1086.pdf">pdf</a></p><p>Author: Alexandre Davis ; Adriano Veloso ; Altigran Soares ; Alberto Laender ; Wagner Meira Jr.</p><p>Abstract: The named entity disambiguation task is to resolve the many-to-many correspondence between ambiguous names and the unique realworld entity. This task can be modeled as a classification problem, provided that positive and negative examples are available for learning binary classifiers. High-quality senseannotated data, however, are hard to be obtained in streaming environments, since the training corpus would have to be constantly updated in order to accomodate the fresh data coming on the stream. On the other hand, few positive examples plus large amounts of unlabeled data may be easily acquired. Producing binary classifiers directly from this data, however, leads to poor disambiguation performance. Thus, we propose to enhance the quality of the classifiers using finer-grained variations of the well-known ExpectationMaximization (EM) algorithm. We conducted a systematic evaluation using Twitter streaming data and the results show that our classifiers are extremely effective, providing improvements ranging from 1% to 20%, when compared to the current state-of-the-art biased SVMs, being more than 120 times faster.</p><p>Reference: <a title="acl-2012-153-reference" href="../acl2012_reference/acl-2012-Named_Entity_Disambiguation_in_Streaming_Data_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 − Fedeedrearlal U Unniviveresristiyty o of fM Ainmaasz Goenarasi {agCdoamvpiu tse ,a Sdcrieincaeno Devp, m. [sent-8, score-0.046]
</p><p>2 e− −i F Fread ,rla ale Unndivee rrs}i t@y yd ocfc A . [sent-9, score-0.1]
</p><p>3 bsr −− F  aialtn io @v d,mcce Abstract The named entity disambiguation task is to resolve the many-to-many correspondence between ambiguous names and the unique realworld entity. [sent-11, score-0.916]
</p><p>4 This task can be modeled as a classification problem, provided that positive and negative examples are available for learning binary classifiers. [sent-12, score-0.288]
</p><p>5 High-quality senseannotated data, however, are hard to be obtained in streaming environments, since the training corpus would have to be constantly updated in order to accomodate the fresh data coming on the stream. [sent-13, score-0.647]
</p><p>6 On the other hand, few positive examples plus large amounts of unlabeled data may be easily acquired. [sent-14, score-0.331]
</p><p>7 Producing binary classifiers directly from this data, however, leads to poor disambiguation performance. [sent-15, score-0.642]
</p><p>8 Thus, we propose to enhance the quality of the classifiers using finer-grained  variations of the well-known ExpectationMaximization (EM) algorithm. [sent-16, score-0.158]
</p><p>9 We conducted a systematic evaluation using Twitter streaming data and the results show that our classifiers are extremely effective, providing improvements ranging from 1% to 20%, when compared to the current state-of-the-art biased SVMs, being more than 120 times faster. [sent-17, score-0.574]
</p><p>10 The task of named entity disambiguation is to identify which names refer to the same entity in a textual collection (Sarmento et al. [sent-22, score-1.165]
</p><p>11 The emergence of new communication technologies, such as micro-blog platforms, brought a humongous amount of textual mentions with ambiguous entity names, raising an urgent need for novel disambiguation approaches and algorithms. [sent-26, score-0.885]
</p><p>12 In this paper we address the named entity disambiguation task under a particularly challenging scenario. [sent-27, score-0.645]
</p><p>13 We are given a stream of messages from a micro-blog channel such as Twitter2 and a list of names n1, n2, . [sent-28, score-0.803]
</p><p>14 Our problem is to monitor the stream and predict whether an incoming message containing ni indeed refers to e (positive example) or not (negative example). [sent-32, score-0.885]
</p><p>15 First, micro-blog messages are composed of a small amount of words and they are written in informal, sometimes cryptic style. [sent-34, score-0.359]
</p><p>16 These characteristics make hard the identification of entities and the semantics of their relationships (Liu et al. [sent-35, score-0.24]
</p><p>17 Further, the scarcity of text in the messages makes it even harder to properly characterize a common context for the entities. [sent-37, score-0.405]
</p><p>18 Second, as we need to monitor messages that keep coming at a fast pace, we cannot afford to gather information from external Human language is not exact. [sent-38, score-0.618]
</p><p>19 Finally, fresh data coming in the tity1 may be referred by multiple names (i. [sent-40, score-0.411]
</p><p>20 , poly- stream introduces new patterns, quickly invalidating semy), and also the same name may refer to different static disambiguation models. [sent-42, score-0.542]
</p><p>21 , 2Twitter is one of the fastest-growing micro-blog channels, 1The term entity refers to anything that has a distinct, sepa- and an authoritative source for breaking news (Jansen et al. [sent-45, score-0.358]
</p><p>22 The information embedded in such a stream of messages may be exploited for entity disambiguation through the application of supervised learning methods, for instance, with the application of binary classifiers. [sent-51, score-1.163]
</p><p>23 Such methods, however, suffer from a data acquisition bottleneck, since they are based on training datasets that are built by skilled human annotators who manually inspect the messages. [sent-52, score-0.093]
</p><p>24 This annotation process is usually lengthy and laborious, being clearly unfeasible to be adopted in data streaming scenarios. [sent-53, score-0.422]
</p><p>25 As an alternative to such manual process, a large amount of unlabeled data, augmented with a small amount of (likely) positive examples, can be collected automatically from the message stream (Liu et al. [sent-54, score-0.742]
</p><p>26 Binary classifiers may be learned from such data by considering unlabeled data as negative examples. [sent-58, score-0.351]
</p><p>27 This strategy, however, leads to classifiers with poor disambiguation performance, due to a potentially large number of false-negative examples. [sent-59, score-0.571]
</p><p>28 In this paper we propose to refine binary classifiers iteratively, by performing Expectation-Maximization (EM) approaches (Dempster et al. [sent-60, score-0.229]
</p><p>29 Basically, a partial classifier is used to evaluate the likelihood of an un-  labeled example being a positive example or a negative example, thus automatically and (continuously) creating a labeled training corpus. [sent-62, score-0.227]
</p><p>30 This process continues iteratively by changing the label of some examples (an operation we call label-transition), so that, after some iterations, the combination of labels is expected to converge to the one for which the observed data is most likely. [sent-63, score-0.155]
</p><p>31 Based on such an approach, we introduce novel disambiguation algorithms that differ among themselves on the granularity in which the classifier is updated, and on the label-transition operations that are allowed. [sent-64, score-0.385]
</p><p>32 An important feature of the proposed approach is that, at each iteration of the EM-process, a new classifier (an improved one) is produced in order to account for the current set of labeled examples. [sent-65, score-0.122]
</p><p>33 We introduce a novel strategy to maintain the classifiers 816 up-to-date incrementally after each iteration, or even after each label-transition operation. [sent-66, score-0.204]
</p><p>34 Indeed, we theoretically show that our classifier needs to be updated just partially and we are able to determine exactly which parts must be updated, making our dis-  ambiguation methods extremely fast. [sent-67, score-0.277]
</p><p>35 To evaluate the effectiveness of the proposed algorithms, we performed a systematic set of experiments using large-scale Twitter data containing messages with ambiguous entity names. [sent-68, score-0.702]
</p><p>36 In order to validate our claims, disambiguation performance is investigated by varying the proportion of falsenegative examples in the unlabeled dataset. [sent-69, score-0.505]
</p><p>37 Our algorithms are compared against a state-of-the-art technique for named entity disambiguation based on classifiers, providing performance gains ranging from 1% to 20% and being roughly 120 times faster. [sent-70, score-0.691]
</p><p>38 2  Related Work  In the context of databases, traditional entity disambiguation methods rely on similarity functions over attributes associated to the entities (de Carvalho et al. [sent-71, score-0.663]
</p><p>39 Obviously, such an approach is unfeasible for the scenario we consider here. [sent-73, score-0.158]
</p><p>40 al (2005) propose graph-based disambiguation methods that generate clusters of coreferent entities using known relationships between  entities of several types. [sent-75, score-0.679]
</p><p>41 Methods to disambiguate person names in e-mail (Minkov et al. [sent-76, score-0.207]
</p><p>42 In emails, information taken from the header of the messages leads to establish relationships between users and building a co-reference graph. [sent-79, score-0.488]
</p><p>43 Such graph-based approach could hardly be applied to the context we consider, in which the implied relationships between entities mentioned in a given micro-blog message are not clearly defined. [sent-81, score-0.351]
</p><p>44 In the case of textual corpora, traditional disambiguation methods represent entity names and their context (Hasegawa et al. [sent-82, score-0.826]
</p><p>45 , words, phrases and other names occurring near them) as weighted vectors (Bagga and Baldwin, 1998; Pedersen et al. [sent-85, score-0.207]
</p><p>46 To evaluate whether two names refer to the same entity, these methods compute the similarity between these vectors. [sent-87, score-0.207]
</p><p>47 Clusters of co-referent names are then built based on such similarity measure. [sent-88, score-0.207]
</p><p>48 Although effective for the tasks considered in these papers, the simplistic BOW-based approaches they adopt are not suitable for cases in which the  context is harder to capture due to the small number of terms available or to informal writing style. [sent-89, score-0.186]
</p><p>49 To address these problems, some authors argue that contextual information may be enriched with knowledge from external sources, such as search results and the Wikipedia (Cucerzan, 2007; Bunescu and Pasca, 2006; Han and Zhao, 2009). [sent-90, score-0.072]
</p><p>50 While such a strategy is feasible in an off-line setting, two problems arise when monitoring streams of micro-blog messages. [sent-91, score-0.089]
</p><p>51 First, gathering information from external sources through the Internet can be costly and, second, informal mentions to named entities make it hard to look for related information in such sources. [sent-92, score-0.505]
</p><p>52 The disambiguation methods we propose fall into a learning scenario known as PU (positive and unlabeled) learning (Liu et al. [sent-93, score-0.372]
</p><p>53 , 2000), in which a classifier is built from a set of positive examples plus unlabeled data. [sent-96, score-0.41]
</p><p>54 Most of the approaches for PU learning, such as the biased-SVM approach (Li and Liu, 2003), are based on extracting negative examples from unlabeled data. [sent-97, score-0.262]
</p><p>55 We notice that existing approaches for PU learning are not likely to scale given the restrictions imposed by streaming data. [sent-98, score-0.284]
</p><p>56 Thus, we propose highly incremental approaches, which  are able to process large-scale streaming data. [sent-99, score-0.284]
</p><p>57 3  Disambiguation in Streaming Data  Consider a stream of messages from a micro-blog channel such as Twitter and let n1, n2, . [sent-100, score-0.596]
</p><p>58 , nN be names used for mentioning a specific entity e in these messages. [sent-103, score-0.547]
</p><p>59 Our problem is to continually monitor the stream and predict whether an incoming message containing ni indeed refers to e or not. [sent-104, score-0.928]
</p><p>60 In this case, we are given an input data set called the training corpus (denoted as D) which consists of examples of tphues f (odremno  , whhicehre c e sisi tthse o entity, m iss a message containing the entity name (i. [sent-106, score-0.624]
</p><p>61 } is a binary variable that specifies wanhdet che ∈r o {r? [sent-110, score-0.071]
</p><p>62 t }th ies e an tbitiyna rnyam vear i anb lme hr eafter ssp etcoi ftihees 817 desired real-world entity e. [sent-112, score-0.35]
</p><p>63 The training corpus is used to produce a classifier that relates textual patterns (i. [sent-113, score-0.138]
</p><p>64 The test set (denoted as T ) consists of a set ooff cre. [sent-116, score-0.041]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('disambiguation', 0.306), ('messages', 0.296), ('streaming', 0.284), ('entity', 0.254), ('stream', 0.236), ('names', 0.207), ('message', 0.165), ('classifiers', 0.158), ('monitor', 0.138), ('unlabeled', 0.13), ('comit', 0.116), ('letouzey', 0.116), ('coming', 0.112), ('updated', 0.105), ('pu', 0.103), ('entities', 0.103), ('incoming', 0.101), ('unfeasible', 0.092), ('fresh', 0.092), ('informal', 0.086), ('mentioning', 0.086), ('positive', 0.085), ('named', 0.085), ('twitter', 0.084), ('ni', 0.084), ('relationships', 0.083), ('classifier', 0.079), ('denis', 0.077), ('external', 0.072), ('binary', 0.071), ('examples', 0.069), ('scenario', 0.066), ('channel', 0.064), ('ambiguous', 0.064), ('amount', 0.063), ('negative', 0.063), ('refers', 0.061), ('textual', 0.059), ('leads', 0.059), ('harder', 0.059), ('databases', 0.059), ('sources', 0.057), ('indeed', 0.055), ('hard', 0.054), ('scarcity', 0.05), ('bhattacharya', 0.05), ('ale', 0.05), ('inspect', 0.05), ('ocfc', 0.05), ('hoffart', 0.05), ('yosef', 0.05), ('header', 0.05), ('sisi', 0.05), ('homonymy', 0.05), ('ambiguation', 0.05), ('adriano', 0.05), ('anb', 0.05), ('hasegawa', 0.05), ('urgent', 0.05), ('mentions', 0.048), ('poor', 0.048), ('plus', 0.047), ('strategy', 0.046), ('tse', 0.046), ('ssp', 0.046), ('lengthy', 0.046), ('federal', 0.046), ('channels', 0.046), ('alberto', 0.046), ('ranging', 0.046), ('iteratively', 0.045), ('containing', 0.045), ('extremely', 0.043), ('liu', 0.043), ('compensated', 0.043), ('minkov', 0.043), ('bagga', 0.043), ('coreferent', 0.043), ('monitoring', 0.043), ('fto', 0.043), ('skilled', 0.043), ('expectationmaximization', 0.043), ('continually', 0.043), ('authoritative', 0.043), ('cucerzan', 0.043), ('systematic', 0.043), ('iteration', 0.043), ('nn', 0.041), ('denoted', 0.041), ('clusters', 0.041), ('emails', 0.041), ('simplistic', 0.041), ('wagner', 0.041), ('getoor', 0.041), ('tthse', 0.041), ('pasca', 0.041), ('continues', 0.041), ('platforms', 0.041), ('emergence', 0.041), ('ooff', 0.041)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="153-tfidf-1" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>Author: Alexandre Davis ; Adriano Veloso ; Altigran Soares ; Alberto Laender ; Wagner Meira Jr.</p><p>Abstract: The named entity disambiguation task is to resolve the many-to-many correspondence between ambiguous names and the unique realworld entity. This task can be modeled as a classification problem, provided that positive and negative examples are available for learning binary classifiers. High-quality senseannotated data, however, are hard to be obtained in streaming environments, since the training corpus would have to be constantly updated in order to accomodate the fresh data coming on the stream. On the other hand, few positive examples plus large amounts of unlabeled data may be easily acquired. Producing binary classifiers directly from this data, however, leads to poor disambiguation performance. Thus, we propose to enhance the quality of the classifiers using finer-grained variations of the well-known ExpectationMaximization (EM) algorithm. We conducted a systematic evaluation using Twitter streaming data and the results show that our classifiers are extremely effective, providing improvements ranging from 1% to 20%, when compared to the current state-of-the-art biased SVMs, being more than 120 times faster.</p><p>2 0.14338467 <a title="153-tfidf-2" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>Author: Limin Yao ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: To discover relation types from text, most methods cluster shallow or syntactic patterns of relation mentions, but consider only one possible sense per pattern. In practice this assumption is often violated. In this paper we overcome this issue by inducing clusters of pattern senses from feature representations of patterns. In particular, we employ a topic model to partition entity pairs associated with patterns into sense clusters using local and global features. We merge these sense clusters into semantic relations using hierarchical agglomerative clustering. We compare against several baselines: a generative latent-variable model, a clustering method that does not disambiguate between path senses, and our own approach but with only local features. Experimental results show our proposed approach discovers dramatically more accurate clusters than models without sense disambiguation, and that incorporating global features, such as the document theme, is crucial.</p><p>3 0.10801408 <a title="153-tfidf-3" href="./acl-2012-A_Probabilistic_Model_for_Canonicalizing_Named_Entity_Mentions.html">18 acl-2012-A Probabilistic Model for Canonicalizing Named Entity Mentions</a></p>
<p>Author: Dani Yogatama ; Yanchuan Sim ; Noah A. Smith</p><p>Abstract: We present a statistical model for canonicalizing named entity mentions into a table whose rows represent entities and whose columns are attributes (or parts of attributes). The model is novel in that it incorporates entity context, surface features, firstorder dependencies among attribute-parts, and a notion of noise. Transductive learning from a few seeds and a collection of mention tokens combines Bayesian inference and conditional estimation. We evaluate our model and its components on two datasets collected from political blogs and sports news, finding that it outperforms a simple agglomerative clustering approach and previous work.</p><p>4 0.10257109 <a title="153-tfidf-4" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>Author: Enrique Alfonseca ; Katja Filippova ; Jean-Yves Delort ; Guillermo Garrido</p><p>Abstract: We describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations. We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections. Results show that the learned patterns can be used to extract new relations with good precision.</p><p>5 0.10243277 <a title="153-tfidf-5" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>Author: Sungchul Kim ; Kristina Toutanova ; Hwanjo Yu</p><p>Abstract: In this paper we propose a method to automatically label multi-lingual data with named entity tags. We build on prior work utilizing Wikipedia metadata and show how to effectively combine the weak annotations stemming from Wikipedia metadata with information obtained through English-foreign language parallel Wikipedia sentences. The combination is achieved using a novel semi-CRF model for foreign sentence tagging in the context of a parallel English sentence. The model outperforms both standard annotation projection methods and methods based solely on Wikipedia metadata.</p><p>6 0.10203619 <a title="153-tfidf-6" href="./acl-2012-Joint_Inference_of_Named_Entity_Recognition_and_Normalization_for_Tweets.html">124 acl-2012-Joint Inference of Named Entity Recognition and Normalization for Tweets</a></p>
<p>7 0.096798293 <a title="153-tfidf-7" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>8 0.095504664 <a title="153-tfidf-8" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>9 0.095372267 <a title="153-tfidf-9" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>10 0.094814964 <a title="153-tfidf-10" href="./acl-2012-Personalized_Normalization_for_a_Multilingual_Chat_System.html">160 acl-2012-Personalized Normalization for a Multilingual Chat System</a></p>
<p>11 0.08656209 <a title="153-tfidf-11" href="./acl-2012-Word_Epoch_Disambiguation%3A_Finding_How_Words_Change_Over_Time.html">216 acl-2012-Word Epoch Disambiguation: Finding How Words Change Over Time</a></p>
<p>12 0.077821836 <a title="153-tfidf-12" href="./acl-2012-Ecological_Evaluation_of_Persuasive_Messages_Using_Google_AdWords.html">77 acl-2012-Ecological Evaluation of Persuasive Messages Using Google AdWords</a></p>
<p>13 0.076579429 <a title="153-tfidf-13" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>14 0.075313047 <a title="153-tfidf-14" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>15 0.070593134 <a title="153-tfidf-15" href="./acl-2012-A_Meta_Learning_Approach_to_Grammatical_Error_Correction.html">15 acl-2012-A Meta Learning Approach to Grammatical Error Correction</a></p>
<p>16 0.06529431 <a title="153-tfidf-16" href="./acl-2012-A_Broad-Coverage_Normalization_System_for_Social_Media_Language.html">2 acl-2012-A Broad-Coverage Normalization System for Social Media Language</a></p>
<p>17 0.064500622 <a title="153-tfidf-17" href="./acl-2012-Bootstrapping_via_Graph_Propagation.html">42 acl-2012-Bootstrapping via Graph Propagation</a></p>
<p>18 0.063904479 <a title="153-tfidf-18" href="./acl-2012-A_Computational_Approach_to_the_Automation_of_Creative_Naming.html">7 acl-2012-A Computational Approach to the Automation of Creative Naming</a></p>
<p>19 0.063225001 <a title="153-tfidf-19" href="./acl-2012-FLOW%3A_A_First-Language-Oriented_Writing_Assistant_System.html">92 acl-2012-FLOW: A First-Language-Oriented Writing Assistant System</a></p>
<p>20 0.062040258 <a title="153-tfidf-20" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.172), (1, 0.133), (2, -0.007), (3, 0.079), (4, 0.081), (5, 0.101), (6, 0.038), (7, 0.046), (8, 0.077), (9, -0.008), (10, 0.138), (11, -0.062), (12, -0.058), (13, 0.039), (14, 0.065), (15, 0.019), (16, -0.017), (17, 0.012), (18, -0.086), (19, -0.045), (20, -0.101), (21, -0.017), (22, -0.017), (23, -0.059), (24, -0.049), (25, 0.061), (26, -0.002), (27, 0.06), (28, 0.01), (29, -0.03), (30, 0.09), (31, -0.042), (32, 0.07), (33, 0.138), (34, -0.01), (35, -0.002), (36, 0.1), (37, 0.115), (38, -0.076), (39, 0.147), (40, 0.029), (41, 0.083), (42, -0.115), (43, 0.092), (44, -0.138), (45, -0.056), (46, -0.158), (47, 0.21), (48, 0.081), (49, -0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97545028 <a title="153-lsi-1" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>Author: Alexandre Davis ; Adriano Veloso ; Altigran Soares ; Alberto Laender ; Wagner Meira Jr.</p><p>Abstract: The named entity disambiguation task is to resolve the many-to-many correspondence between ambiguous names and the unique realworld entity. This task can be modeled as a classification problem, provided that positive and negative examples are available for learning binary classifiers. High-quality senseannotated data, however, are hard to be obtained in streaming environments, since the training corpus would have to be constantly updated in order to accomodate the fresh data coming on the stream. On the other hand, few positive examples plus large amounts of unlabeled data may be easily acquired. Producing binary classifiers directly from this data, however, leads to poor disambiguation performance. Thus, we propose to enhance the quality of the classifiers using finer-grained variations of the well-known ExpectationMaximization (EM) algorithm. We conducted a systematic evaluation using Twitter streaming data and the results show that our classifiers are extremely effective, providing improvements ranging from 1% to 20%, when compared to the current state-of-the-art biased SVMs, being more than 120 times faster.</p><p>2 0.60155308 <a title="153-lsi-2" href="./acl-2012-Personalized_Normalization_for_a_Multilingual_Chat_System.html">160 acl-2012-Personalized Normalization for a Multilingual Chat System</a></p>
<p>Author: Ai Ti Aw ; Lian Hau Lee</p><p>Abstract: This paper describes the personalized normalization of a multilingual chat system that supports chatting in user defined short-forms or abbreviations. One of the major challenges for multilingual chat realized through machine translation technology is the normalization of non-standard, self-created short-forms in the chat message to standard words before translation. Due to the lack of training data and the variations of short-forms used among different social communities, it is hard to normalize and translate chat messages if user uses vocabularies outside the training data and create short-forms freely. We develop a personalized chat normalizer for English and integrate it with a multilingual chat system, allowing user to create and use personalized short-forms in multilingual chat. 1</p><p>3 0.54976535 <a title="153-lsi-3" href="./acl-2012-A_Broad-Coverage_Normalization_System_for_Social_Media_Language.html">2 acl-2012-A Broad-Coverage Normalization System for Social Media Language</a></p>
<p>Author: Fei Liu ; Fuliang Weng ; Xiao Jiang</p><p>Abstract: Social media language contains huge amount and wide variety of nonstandard tokens, created both intentionally and unintentionally by the users. It is of crucial importance to normalize the noisy nonstandard tokens before applying other NLP techniques. A major challenge facing this task is the system coverage, i.e., for any user-created nonstandard term, the system should be able to restore the correct word within its top n output candidates. In this paper, we propose a cognitivelydriven normalization system that integrates different human perspectives in normalizing the nonstandard tokens, including the enhanced letter transformation, visual priming, and string/phonetic similarity. The system was evaluated on both word- and messagelevel using four SMS and Twitter data sets. Results show that our system achieves over 90% word-coverage across all data sets (a . 10% absolute increase compared to state-ofthe-art); the broad word-coverage can also successfully translate into message-level performance gain, yielding 6% absolute increase compared to the best prior approach.</p><p>4 0.54914331 <a title="153-lsi-4" href="./acl-2012-Joint_Inference_of_Named_Entity_Recognition_and_Normalization_for_Tweets.html">124 acl-2012-Joint Inference of Named Entity Recognition and Normalization for Tweets</a></p>
<p>Author: Xiaohua Liu ; Ming Zhou ; Xiangyang Zhou ; Zhongyang Fu ; Furu Wei</p><p>Abstract: Tweets represent a critical source of fresh information, in which named entities occur frequently with rich variations. We study the problem of named entity normalization (NEN) for tweets. Two main challenges are the errors propagated from named entity recognition (NER) and the dearth of information in a single tweet. We propose a novel graphical model to simultaneously conduct NER and NEN on multiple tweets to address these challenges. Particularly, our model introduces a binary random variable for each pair of words with the same lemma across similar tweets, whose value indicates whether the two related words are mentions of the same entity. We evaluate our method on a manually annotated data set, and show that our method outperforms the baseline that handles these two tasks separately, boosting the F1 from 80.2% to 83.6% for NER, and the Accuracy from 79.4% to 82.6% for NEN, respectively.</p><p>5 0.54523319 <a title="153-lsi-5" href="./acl-2012-Ecological_Evaluation_of_Persuasive_Messages_Using_Google_AdWords.html">77 acl-2012-Ecological Evaluation of Persuasive Messages Using Google AdWords</a></p>
<p>Author: Marco Guerini ; Carlo Strapparava ; Oliviero Stock</p><p>Abstract: In recent years there has been a growing interest in crowdsourcing methodologies to be used in experimental research for NLP tasks. In particular, evaluation of systems and theories about persuasion is difficult to accommodate within existing frameworks. In this paper we present a new cheap and fast methodology that allows fast experiment building and evaluation with fully-automated analysis at a low cost. The central idea is exploiting existing commercial tools for advertising on the web, such as Google AdWords, to measure message impact in an ecological setting. The paper includes a description of the approach, tips for how to use AdWords for scientific research, and results of pilot experiments on the impact of affective text variations which confirm the effectiveness of the approach.</p><p>6 0.52245396 <a title="153-lsi-6" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>7 0.5196805 <a title="153-lsi-7" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>8 0.51600707 <a title="153-lsi-8" href="./acl-2012-A_Probabilistic_Model_for_Canonicalizing_Named_Entity_Mentions.html">18 acl-2012-A Probabilistic Model for Canonicalizing Named Entity Mentions</a></p>
<p>9 0.4730038 <a title="153-lsi-9" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>10 0.46373552 <a title="153-lsi-10" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>11 0.46117991 <a title="153-lsi-11" href="./acl-2012-Word_Epoch_Disambiguation%3A_Finding_How_Words_Change_Over_Time.html">216 acl-2012-Word Epoch Disambiguation: Finding How Words Change Over Time</a></p>
<p>12 0.41867983 <a title="153-lsi-12" href="./acl-2012-A_Computational_Approach_to_the_Automation_of_Creative_Naming.html">7 acl-2012-A Computational Approach to the Automation of Creative Naming</a></p>
<p>13 0.39016044 <a title="153-lsi-13" href="./acl-2012-Structuring_E-Commerce_Inventory.html">186 acl-2012-Structuring E-Commerce Inventory</a></p>
<p>14 0.38524625 <a title="153-lsi-14" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>15 0.37122902 <a title="153-lsi-15" href="./acl-2012-The_Creation_of_a_Corpus_of_English_Metalanguage.html">195 acl-2012-The Creation of a Corpus of English Metalanguage</a></p>
<p>16 0.36988243 <a title="153-lsi-16" href="./acl-2012-Bootstrapping_via_Graph_Propagation.html">42 acl-2012-Bootstrapping via Graph Propagation</a></p>
<p>17 0.3690061 <a title="153-lsi-17" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>18 0.36841959 <a title="153-lsi-18" href="./acl-2012-Beefmoves%3A_Dissemination%2C_Diversity%2C_and_Dynamics_of_English_Borrowings_in_a_German_Hip_Hop_Forum.html">39 acl-2012-Beefmoves: Dissemination, Diversity, and Dynamics of English Borrowings in a German Hip Hop Forum</a></p>
<p>19 0.36766744 <a title="153-lsi-19" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>20 0.3657662 <a title="153-lsi-20" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(26, 0.028), (28, 0.032), (39, 0.025), (74, 0.017), (82, 0.011), (85, 0.015), (90, 0.068), (92, 0.038), (99, 0.68)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97882748 <a title="153-lda-1" href="./acl-2012-Reducing_Wrong_Labels_in_Distant_Supervision_for_Relation_Extraction.html">169 acl-2012-Reducing Wrong Labels in Distant Supervision for Relation Extraction</a></p>
<p>Author: Shingo Takamatsu ; Issei Sato ; Hiroshi Nakagawa</p><p>Abstract: In relation extraction, distant supervision seeks to extract relations between entities from text by using a knowledge base, such as Freebase, as a source of supervision. When a sentence and a knowledge base refer to the same entity pair, this approach heuristically labels the sentence with the corresponding relation in the knowledge base. However, this heuristic can fail with the result that some sentences are labeled wrongly. This noisy labeled data causes poor extraction performance. In this paper, we propose a method to reduce the number of wrong labels. We present a novel generative model that directly models the heuristic labeling process of distant supervision. The model predicts whether assigned labels are correct or wrong via its hidden variables. Our experimental results show that this model detected wrong labels with higher performance than baseline methods. In the ex- periment, we also found that our wrong label reduction boosted the performance of relation extraction.</p><p>same-paper 2 0.96702188 <a title="153-lda-2" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>Author: Alexandre Davis ; Adriano Veloso ; Altigran Soares ; Alberto Laender ; Wagner Meira Jr.</p><p>Abstract: The named entity disambiguation task is to resolve the many-to-many correspondence between ambiguous names and the unique realworld entity. This task can be modeled as a classification problem, provided that positive and negative examples are available for learning binary classifiers. High-quality senseannotated data, however, are hard to be obtained in streaming environments, since the training corpus would have to be constantly updated in order to accomodate the fresh data coming on the stream. On the other hand, few positive examples plus large amounts of unlabeled data may be easily acquired. Producing binary classifiers directly from this data, however, leads to poor disambiguation performance. Thus, we propose to enhance the quality of the classifiers using finer-grained variations of the well-known ExpectationMaximization (EM) algorithm. We conducted a systematic evaluation using Twitter streaming data and the results show that our classifiers are extremely effective, providing improvements ranging from 1% to 20%, when compared to the current state-of-the-art biased SVMs, being more than 120 times faster.</p><p>3 0.92350703 <a title="153-lda-3" href="./acl-2012-Movie-DiC%3A_a_Movie_Dialogue_Corpus_for_Research_and_Development.html">149 acl-2012-Movie-DiC: a Movie Dialogue Corpus for Research and Development</a></p>
<p>Author: Rafael E. Banchs</p><p>Abstract: This paper describes Movie-DiC a Movie Dialogue Corpus recently collected for research and development purposes. The collected dataset comprises 132,229 dialogues containing a total of 764,146 turns that have been extracted from 753 movies. Details on how the data collection has been created and how it is structured are provided along with its main statistics and characteristics. 1</p><p>4 0.92328221 <a title="153-lda-4" href="./acl-2012-Combining_Textual_Entailment_and_Argumentation_Theory_for_Supporting_Online_Debates_Interactions.html">53 acl-2012-Combining Textual Entailment and Argumentation Theory for Supporting Online Debates Interactions</a></p>
<p>Author: Elena Cabrio ; Serena Villata</p><p>Abstract: Blogs and forums are widely adopted by online communities to debate about various issues. However, a user that wants to cut in on a debate may experience some difficulties in extracting the current accepted positions, and can be discouraged from interacting through these applications. In our paper, we combine textual entailment with argumentation theory to automatically extract the arguments from debates and to evaluate their acceptability.</p><p>5 0.88175607 <a title="153-lda-5" href="./acl-2012-Fully_Abstractive_Approach_to_Guided_Summarization.html">101 acl-2012-Fully Abstractive Approach to Guided Summarization</a></p>
<p>Author: Pierre-Etienne Genest ; Guy Lapalme</p><p>Abstract: This paper shows that full abstraction can be accomplished in the context of guided summarization. We describe a work in progress that relies on Information Extraction, statistical content selection and Natural Language Generation. Early results already demonstrate the effectiveness of the approach.</p><p>6 0.8604725 <a title="153-lda-6" href="./acl-2012-Robust_Conversion_of_CCG_Derivations_to_Phrase_Structure_Trees.html">170 acl-2012-Robust Conversion of CCG Derivations to Phrase Structure Trees</a></p>
<p>7 0.56226617 <a title="153-lda-7" href="./acl-2012-Assessing_the_Effect_of_Inconsistent_Assessors_on_Summarization_Evaluation.html">29 acl-2012-Assessing the Effect of Inconsistent Assessors on Summarization Evaluation</a></p>
<p>8 0.5519951 <a title="153-lda-8" href="./acl-2012-Big_Data_versus_the_Crowd%3A_Looking_for_Relationships_in_All_the_Right_Places.html">40 acl-2012-Big Data versus the Crowd: Looking for Relationships in All the Right Places</a></p>
<p>9 0.54563856 <a title="153-lda-9" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>10 0.50231779 <a title="153-lda-10" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>11 0.49842736 <a title="153-lda-11" href="./acl-2012-Towards_the_Unsupervised_Acquisition_of_Discourse_Relations.html">201 acl-2012-Towards the Unsupervised Acquisition of Discourse Relations</a></p>
<p>12 0.49396443 <a title="153-lda-12" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>13 0.48480299 <a title="153-lda-13" href="./acl-2012-Graph-based_Semi-Supervised_Learning_Algorithms_for_NLP.html">104 acl-2012-Graph-based Semi-Supervised Learning Algorithms for NLP</a></p>
<p>14 0.47397298 <a title="153-lda-14" href="./acl-2012-PDTB-style_Discourse_Annotation_of_Chinese_Text.html">157 acl-2012-PDTB-style Discourse Annotation of Chinese Text</a></p>
<p>15 0.47278893 <a title="153-lda-15" href="./acl-2012-Combining_Coherence_Models_and_Machine_Translation_Evaluation_Metrics_for_Summarization_Evaluation.html">52 acl-2012-Combining Coherence Models and Machine Translation Evaluation Metrics for Summarization Evaluation</a></p>
<p>16 0.46937868 <a title="153-lda-16" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>17 0.45544302 <a title="153-lda-17" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>18 0.45052958 <a title="153-lda-18" href="./acl-2012-A_Corpus_of_Textual_Revisions_in_Second_Language_Writing.html">8 acl-2012-A Corpus of Textual Revisions in Second Language Writing</a></p>
<p>19 0.44673243 <a title="153-lda-19" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>20 0.44338581 <a title="153-lda-20" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
