<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-60" href="#">acl2012-60</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</h1>
<br/><p>Source: <a title="acl-2012-60-pdf" href="http://aclweb.org/anthology//P/P12/P12-2046.pdf">pdf</a></p><p>Author: Yafang Wang ; Maximilian Dylla ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: The Web and digitized text sources contain a wealth of information about named entities such as politicians, actors, companies, or cultural landmarks. Extracting this information has enabled the automated construction oflarge knowledge bases, containing hundred millions of binary relationships or attribute values about these named entities. However, in reality most knowledge is transient, i.e. changes over time, requiring a temporal dimension in fact extraction. In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles.</p><p>Reference: <a title="acl-2012-60-reference" href="../acl2012_reference/acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract The Web and digitized text sources contain a wealth of information about named entities such as politicians, actors, companies, or cultural landmarks. [sent-3, score-0.105]
</p><p>2 changes over time, requiring a temporal dimension in fact extraction. [sent-7, score-0.461]
</p><p>3 In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction. [sent-8, score-0.668]
</p><p>4 Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. [sent-9, score-0.635]
</p><p>5 1 Introduction In recent years, automated fact extraction from Web contents has seen significant progress with the emergence of freely available knowledge bases, such as DBpedia (Auer et al. [sent-11, score-0.207]
</p><p>6 These knowledge bases are constantly growing and contain currently (by example of DBpedia) several million entities and half a billion facts about them. [sent-16, score-0.321]
</p><p>7 This wealth of data allows to satisfy the information needs of advanced Internet users by raising queries from keywords to entities. [sent-17, score-0.056]
</p><p>8 This enables queries like “Who is married to Prince Charles? [sent-18, score-0.056]
</p><p>9 ” or “Who are the teammates of Lionel Messi at FC Barcelona? [sent-19, score-0.064]
</p><p>10 233 However, factual knowledge is highly ephemeral: Royals get married and divorced, politicians hold positions only for a limited time and soccer players transfer from one club to another. [sent-21, score-0.343]
</p><p>11 Consequently, knowledge bases should be able to support more sophisticated temporal queries at entity-level, such as “Who have been the spouses of Prince Charles  before 2000? [sent-22, score-0.41]
</p><p>12 ” or “Who are the teammates of Lionel Messi at FC Barcelona in the season 2011/2012? [sent-23, score-0.064]
</p><p>13 In order to achieve this goal, the next big step is to distill temporal knowledge from the Web. [sent-25, score-0.331]
</p><p>14 Extracting temporal facts is a complex and timeconsuming endeavor. [sent-26, score-0.524]
</p><p>15 To this end, we introduce a method that allows us to gain maximum benefit from both “worlds” by “aggressively” gathering fact candidates and subsequently “cleaning-up” the incorrect ones. [sent-29, score-0.212]
</p><p>16 The salient properties of our approach and the novel contributions of this paper are the following: • A temporal fact extraction strategy that is able to efficiently gather thousands of fact candidates based on a handful of seed facts. [sent-30, score-0.848]
</p><p>17 • An ILP solver incorporating constraints on temporal relations among events (e. [sent-31, score-0.406]
</p><p>18 • Experiments on real world news and Wikipedia articles showing that we gain recall while keep-  ing up with precision. [sent-34, score-0.042]
</p><p>19 2 Related Work Recently, there have been several approaches that aim at the extraction of temporal facts for the automated construction of large knowledge bases, but Proce dJienjgus, R ofep thueb 5lic0t hof A Knonruea ,l M 8-e1e4ti Jnugly o f2 t0h1e2 A. [sent-35, score-0.601]
</p><p>20 c so2c0ia1t2io Ans fso rc Ciatoiomnp fuotart Cio nmaplu Ltiantgiounisatlic Lsi,n pgaugiestsi2c 3s3–237, time-aware fact extraction is still in its infancy. [sent-37, score-0.207]
</p><p>21 An approach toward fact extraction based on coupled semi-supervised learning for information extraction (IE) is NELL (Carlson et al. [sent-38, score-0.351]
</p><p>22 TIE (Ling and Weld, 2010) binds time-points of events described in sentences, but does not disambiguate entities or combine observations to facts. [sent-41, score-0.049]
</p><p>23 A pattern-based approach for temporal fact extraction is PRAVDA (Wang et al. [sent-42, score-0.538]
</p><p>24 , 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. [sent-43, score-0.207]
</p><p>25 Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al. [sent-44, score-0.599]
</p><p>26 , 2012) introduces a constraint-based approach of coupled  semi-supervised learning for IE, however not focusing on the extraction part. [sent-47, score-0.144]
</p><p>27 , 2009) identify temporal relationships in free text, but don’t focus on fact extraction. [sent-53, score-0.461]
</p><p>28 We aim to extract factual knowledge transient over time from free text. [sent-55, score-0.105]
</p><p>29 Furthermore, a fact consists of a relation with two typed arguments and a timeinterval defining its validity. [sent-57, score-0.197]
</p><p>30 Since sentences containing a fact and its full time-interval are sparse, we consider three kinds of textual observations for each relation, namely begin, during, and end. [sent-59, score-0.13]
</p><p>31 “Beckham signed for Real Madrid from Manchester United in 2003. [sent-60, score-0.045]
</p><p>32 ” includes both the begin observation of Beckham being with Real Madrid as well as the end observation  of working for Manchester. [sent-61, score-0.233]
</p><p>33 A positive seed fact is a valid fact of a relation, while a negative seed fact is incorrect (e. [sent-62, score-0.586]
</p><p>34 , for relation worksForClub, a positive seed fact is worksForClub(Beckham, RMadrid), while worksForClub(Beckham, BMunich) is a negative seed fact). [sent-64, score-0.393]
</p><p>35 We retrieve all sentences from the corpus comprising at least two entities and a temporal expression, where we use YAGO for entity recognition and disambiguation (cf. [sent-68, score-0.38]
</p><p>36 It is generated by replacing entities by their types, keeping only stemmed nouns, verbs converted to present tense and the last preposition. [sent-73, score-0.049]
</p><p>37 For example, considering “Beckham signed for Real Madrid from Manchester United in 2003. [sent-74, score-0.045]
</p><p>38 ” the corresponding pattern for the end occurrence is “sign for CLUB from”. [sent-75, score-0.089]
</p><p>39 We quantify the strength of each pattern by investigating how frequent the pattern occurs with seed facts of a particular relation and how infrequent it appears with negative seed facts. [sent-76, score-0.54]
</p><p>40 Entity pairs that cooccur with patterns whose strength is above a minimum threshold become fact candidates and are fed into the next stage of label propagation. [sent-78, score-0.45]
</p><p>41 , 2011) we utilize Label Propagation (Talukdar and Crammer, 2009) to determine the relation and observation type expressed by each pattern. [sent-80, score-0.116]
</p><p>42 We create a graph G = (VF∪˙VP, E) having one vertex v ∈ VF for eachG Gfa =ct (cVan∪didVate,E Eo)bserved in the text avn ∈d one vertex v ∈ VP for each pattern. [sent-82, score-0.082]
</p><p>43 Edges between VF and VP are ∈in Vtroduced whenever a fact candidate appeared with a pattern. [sent-83, score-0.171]
</p><p>44 Moreover, we use one label for each observation type (begin, during, and end) of each relation and a dummy label representing the unknown relation. [sent-87, score-0.348]
</p><p>45 Let Y ∈ de-  R|+V|×|Labels|  Yb  note the graph’s initial label assignment, and ∈ stand for the estimated labels of allb vertices, Sl encode the seed’s weights on its diagobnal, and R∗l contain zeroes except for the dummy label’s column∗. [sent-89, score-0.148]
</p><p>46 l Then, the objective function is:  R|+V|×|Labels|  L(Yb) =X‘"+µ(1YYb∗‘∗T−‘LYYbb∗∗‘‘)+TS µ‘2(kYYb∗‘∗‘− Yb R∗∗‘‘)k2#  (1)  eHnseurere,s th teha ftir sthte te ermbstim(Yabt∗e‘d− laYb e∗ls‘)bT apSp‘r(oYxi∗m‘−ateYb th∗‘e)  initial labels. [sent-90, score-0.059]
</p><p>47 5 Cleaning of Fbact Cbandidates To prune noisy t-facts, we compute a consistent subset of t-facts with respect to temporal constraints (e. [sent-93, score-0.406]
</p><p>48 joining a sports club takes place before leaving a sports club) by an Integer Linear Program (ILP). [sent-95, score-0.201]
</p><p>49 We introduce a variable xr ∈ {0, 1} for each t-fact candidate r ∈ R, where 1means t,h1e} candidate is valid. [sent-97, score-0.278]
</p><p>50 Two vra ∈ria Rbles xf,b, xf,e ∈ [0, Tmax] denote begin (b) and end (e) of time-inter∈val [ 0o,fT a fact f ∈ F. [sent-98, score-0.265]
</p><p>51 Note, that many t-fact candidates refer to the same fact f, since they share their entity pairs. [sent-99, score-0.212]
</p><p>52 The objective function intends to maximize the number of valid raw t-facts, where wr is a weight obtained from the previous stage:  maxXwr· xr Intra-Fact Constraints. [sent-101, score-0.196]
</p><p>53 xf,b and xf,e encode a proper time-interval by adding the constraint:  <  ∀f ∈ F xf,b xf,e Considering only a single relation, we assume the sets Rb, Rd, and Re to comprise its t-fact candidates withR R respRect to thRe begin, during, and end observations. [sent-102, score-0.129]
</p><p>54 Then, we introduce the constraints ∀l ∀l  ∈ ∈  {b, e}, r ∈ Rl {b, e}, r ∈ Rl ∀r ∈ Rd ∀r ∈ Rd  tl · xr ≤ xf,l xf,l ≤ tl · xr + (1 − xr)Tmax xf,b ≤ tb · xr (1 − xr)Tmax te · xr ≤ xf,e  +  (2) (3) (4) (5)  235 where f has the same entity pair as r and tb, te are begin and end of time-interval. [sent-103, score-1.284]
</p><p>55 Whenever xr is set to 1 for begin or end t-fact candidates, Eq. [sent-104, score-0.331]
</p><p>56 (3) set the value of xf,b or xf,e to tb or te, respectively. [sent-106, score-0.09]
</p><p>57 For each during t-fact candidate with xr = 1, Eq. [sent-107, score-0.237]
</p><p>58 Since we can refer to a fact f’s time interval by xf,b and xf,e and the connectives of Boolean Logic can be encoded in ILPs (Karp, 1972), we can use all temporal constraints expressible by Allen’s Interval Algebra (Allen, 1983) to specify inter-fact constraints. [sent-111, score-0.593]
</p><p>59 Furthermore, because we allow all relations of Allen’s Interval Algebra, we support a richer class of temporal constraints. [sent-117, score-0.331]
</p><p>60 Experiments are conducted in the soccer and the celebrity domain by considering the worksForClub and isMarriedTo relation, respectively. [sent-119, score-0.148]
</p><p>61 In addition, we obtained about 80,000 documents for the soccer domain and 370,000 documents for the celebrity domain from BBC, The Telegraph, Times Online and ESPN by querying Google’s News Archive Search1 in the time window from 1990-201 1. [sent-121, score-0.148]
</p><p>62 For each relation we manually select the 10 positive and negative fact candidates with highest occurrence frequencies in the corpus as seeds. [sent-124, score-0.279]
</p><p>63 We evaluate precision by randomly sampling 50 (isMarriedTo) and 100 (worksForClub) facts for each observation type and manually evaluating them against the text documents. [sent-126, score-0.308]
</p><p>64 In this experiment we compare the performance of the pipeline being stages 3 and 4 in Figure 1news . [sent-131, score-0.055]
</p><p>65 de /yago-naga /pravda / 1 and a joint model in form of an ILP solving the t-fact extraction and noise cleaning at the same time. [sent-136, score-0.374]
</p><p>66 Hence, the joint model resembles (Roth and Yih, 2004) extended by Section 5’s temporal constraints. [sent-137, score-0.331]
</p><p>67 Table 1 shows the results on the pipeline model (lower-left), joint model (lower-right), labelpropagation w/o noise cleaning (upper-left), and ILP for t-fact extraction w/o noise cleaning (upper-right). [sent-139, score-0.726]
</p><p>68 Regarding the upper part of Table 1 the pattern-based extraction works very well for works-  ForClub, however it fails on isMarriedTo. [sent-141, score-0.077]
</p><p>69 The reason is, that the types of worksForClub distinguish the patterns well from other relations. [sent-142, score-0.04]
</p><p>70 In contrast, isMarriedTo’s patterns interfere with other person-person relations making constraints a decisive asset. [sent-143, score-0.115]
</p><p>71 When comparing the joint model and the pipeline model, the former sacrifices recall in order to keep up with the latter’s precision level. [sent-144, score-0.121]
</p><p>72 That is because the joint model’s ILP decides with binary variables on which patterns to accept. [sent-145, score-0.04]
</p><p>73 In contrast, label propagation addresses the inherent uncertainty by providing label assignments with confidence numbers. [sent-146, score-0.291]
</p><p>74 In a second experiment, we move the t-fact extraction stage away from high precision towards higher recall, where the successive noise cleaning stage attempts to restore the precision level. [sent-149, score-0.734]
</p><p>75 The table’s upper part reports on the output of stage 3, whereas the  lower part covers the facts returned by noise cleaning. [sent-157, score-0.39]
</p><p>76 For the conservative setting label propagation produces high precision facts with only few inconsistencies, so the noise cleaning stage has no effect, i. [sent-159, score-0.922]
</p><p>77 This is the setting usual pattern-based approaches without cleaning stage are working in. [sent-162, score-0.328]
</p><p>78 In contrast, for the standard setting (coinciding with Table 1’s left column) stage 3 yields less precision, but higher recall. [sent-163, score-0.114]
</p><p>79 Since there are more inconsistencies in this setup, the noise cleaning stage accomplishes precision gains compensating for the losses in the previous stage. [sent-164, score-0.516]
</p><p>80 In the relaxed setting precision drops too low, so the noise cleaning stage is unable to figure out the truly correct facts. [sent-165, score-0.477]
</p><p>81 In general, the effects on worksForClub are weaker, since in this relation the constraints are less influential. [sent-166, score-0.142]
</p><p>82 7 Conclusion In this paper we have developed a method that combines label propagation with constraint reasoning for temporal fact extraction. [sent-167, score-0.668]
</p><p>83 Our experiments have shown that best results can be achieved by applying  “aggressive” label propagation with a subsequent ILP for “clean-up”. [sent-168, score-0.207]
</p><p>84 By coupling both approaches we achieve both high(er) precision and high(er) recall. [sent-169, score-0.111]
</p><p>85 Thus, our method efficiently extracts high quality temporal facts at large scale. [sent-170, score-0.524]
</p><p>86 TimeML: Robust specification of event and temporal expressions in text. [sent-234, score-0.331]
</p><p>87 Harvesting facts from textual web sources by constrained label propagation. [sent-265, score-0.329]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('temporal', 0.331), ('worksforclub', 0.288), ('beckham', 0.224), ('cleaning', 0.214), ('xr', 0.196), ('facts', 0.193), ('ilp', 0.171), ('fact', 0.13), ('tmax', 0.128), ('propagation', 0.123), ('talukdar', 0.119), ('stage', 0.114), ('gerhard', 0.112), ('club', 0.111), ('verhagen', 0.102), ('seed', 0.098), ('ismarriedto', 0.096), ('yb', 0.096), ('marc', 0.093), ('tb', 0.09), ('begin', 0.088), ('label', 0.084), ('dbpedia', 0.084), ('soccer', 0.084), ('spaniol', 0.084), ('noise', 0.083), ('candidates', 0.082), ('madrid', 0.082), ('bases', 0.079), ('carlson', 0.078), ('extraction', 0.077), ('constraints', 0.075), ('suchanek', 0.071), ('yago', 0.067), ('vf', 0.067), ('mani', 0.067), ('coupled', 0.067), ('relation', 0.067), ('precision', 0.066), ('archive', 0.064), ('allen', 0.064), ('celebrity', 0.064), ('dummy', 0.064), ('lionel', 0.064), ('messi', 0.064), ('rmadrid', 0.064), ('teammates', 0.064), ('transient', 0.064), ('te', 0.059), ('vp', 0.058), ('interval', 0.057), ('married', 0.056), ('prince', 0.056), ('hoffart', 0.056), ('wealth', 0.056), ('yafang', 0.056), ('pipeline', 0.055), ('web', 0.052), ('politicians', 0.051), ('aggressively', 0.051), ('auer', 0.051), ('algebra', 0.051), ('tob', 0.051), ('observation', 0.049), ('entities', 0.049), ('tom', 0.048), ('betteridge', 0.047), ('hruschka', 0.047), ('partha', 0.047), ('pratim', 0.047), ('sauri', 0.047), ('end', 0.047), ('fc', 0.045), ('sports', 0.045), ('conservative', 0.045), ('fabian', 0.045), ('signed', 0.045), ('jessica', 0.045), ('coupling', 0.045), ('inderjeet', 0.045), ('timeml', 0.045), ('weikum', 0.045), ('yoshikawa', 0.045), ('rd', 0.044), ('james', 0.044), ('aggressive', 0.043), ('wsdm', 0.043), ('yih', 0.043), ('justin', 0.043), ('real', 0.042), ('pattern', 0.042), ('vertex', 0.041), ('tl', 0.041), ('factual', 0.041), ('roser', 0.041), ('candidate', 0.041), ('patterns', 0.04), ('inconsistencies', 0.039), ('rl', 0.039), ('robert', 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="60-tfidf-1" href="./acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction.html">60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</a></p>
<p>Author: Yafang Wang ; Maximilian Dylla ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: The Web and digitized text sources contain a wealth of information about named entities such as politicians, actors, companies, or cultural landmarks. Extracting this information has enabled the automated construction oflarge knowledge bases, containing hundred millions of binary relationships or attribute values about these named entities. However, in reality most knowledge is transient, i.e. changes over time, requiring a temporal dimension in fact extraction. In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles.</p><p>2 0.3646563 <a title="60-tfidf-2" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>3 0.23525903 <a title="60-tfidf-3" href="./acl-2012-Extracting_Narrative_Timelines_as_Temporal_Dependency_Structures.html">90 acl-2012-Extracting Narrative Timelines as Temporal Dependency Structures</a></p>
<p>Author: Oleksandr Kolomiyets ; Steven Bethard ; Marie-Francine Moens</p><p>Abstract: We propose a new approach to characterizing the timeline of a text: temporal dependency structures, where all the events of a narrative are linked via partial ordering relations like BEFORE, AFTER, OVERLAP and IDENTITY. We annotate a corpus of children’s stories with temporal dependency trees, achieving agreement (Krippendorff’s Alpha) of 0.856 on the event words, 0.822 on the links between events, and of 0.700 on the ordering relation labels. We compare two parsing models for temporal dependency structures, and show that a deterministic non-projective dependency parser outperforms a graph-based maximum spanning tree parser, achieving labeled attachment accuracy of 0.647 and labeled tree edit distance of 0.596. Our analysis of the dependency parser errors gives some insights into future research directions.</p><p>4 0.15224873 <a title="60-tfidf-4" href="./acl-2012-Learning_to_Temporally_Order_Medical_Events_in_Clinical_Text.html">135 acl-2012-Learning to Temporally Order Medical Events in Clinical Text</a></p>
<p>Author: Preethi Raghavan ; Albert Lai ; Eric Fosler-Lussier</p><p>Abstract: We investigate the problem of ordering medical events in unstructured clinical narratives by learning to rank them based on their time of occurrence. We represent each medical event as a time duration, with a corresponding start and stop, and learn to rank the starts/stops based on their proximity to the admission date. Such a representation allows us to learn all of Allen’s temporal relations between medical events. Interestingly, we observe that this methodology performs better than a classification-based approach for this domain, but worse on the relationships found in the Timebank corpus. This finding has important implications for styles of data representation and resources used for temporal relation learning: clinical narratives may have different language attributes corresponding to temporal ordering relative to Timebank, implying that the field may need to look at a wider range ofdomains to fully understand the nature of temporal ordering.</p><p>5 0.13481668 <a title="60-tfidf-5" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>Author: Remy Kessler ; Xavier Tannier ; Caroline Hagege ; Veronique Moriceau ; Andre Bittar</p><p>Abstract: We present an approach for detecting salient (important) dates in texts in order to automatically build event timelines from a search query (e.g. the name of an event or person, etc.). This work was carried out on a corpus of newswire texts in English provided by the Agence France Presse (AFP). In order to extract salient dates that warrant inclusion in an event timeline, we first recognize and normalize temporal expressions in texts and then use a machine-learning approach to extract salient dates that relate to a particular topic. We focused only on extracting the dates and not the events to which they are related.</p><p>6 0.12646142 <a title="60-tfidf-6" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>7 0.12288015 <a title="60-tfidf-7" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>8 0.10030111 <a title="60-tfidf-8" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<p>9 0.096256234 <a title="60-tfidf-9" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<p>10 0.090896279 <a title="60-tfidf-10" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>11 0.089315131 <a title="60-tfidf-11" href="./acl-2012-Extracting_and_modeling_durations_for_habits_and_events_from_Twitter.html">91 acl-2012-Extracting and modeling durations for habits and events from Twitter</a></p>
<p>12 0.087451547 <a title="60-tfidf-12" href="./acl-2012-Collective_Generation_of_Natural_Image_Descriptions.html">51 acl-2012-Collective Generation of Natural Image Descriptions</a></p>
<p>13 0.086069681 <a title="60-tfidf-13" href="./acl-2012-Tense_and_Aspect_Error_Correction_for_ESL_Learners_Using_Global_Context.html">192 acl-2012-Tense and Aspect Error Correction for ESL Learners Using Global Context</a></p>
<p>14 0.083302669 <a title="60-tfidf-14" href="./acl-2012-Event_Linking%3A_Grounding_Event_Reference_in_a_News_Archive.html">85 acl-2012-Event Linking: Grounding Event Reference in a News Archive</a></p>
<p>15 0.081062183 <a title="60-tfidf-15" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>16 0.080211885 <a title="60-tfidf-16" href="./acl-2012-Bootstrapping_via_Graph_Propagation.html">42 acl-2012-Bootstrapping via Graph Propagation</a></p>
<p>17 0.078730837 <a title="60-tfidf-17" href="./acl-2012-A_Novel_Burst-based_Text_Representation_Model_for_Scalable_Event_Detection.html">17 acl-2012-A Novel Burst-based Text Representation Model for Scalable Event Detection</a></p>
<p>18 0.07790906 <a title="60-tfidf-18" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>19 0.077201575 <a title="60-tfidf-19" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>20 0.075973906 <a title="60-tfidf-20" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.196), (1, 0.171), (2, -0.107), (3, 0.244), (4, 0.073), (5, -0.156), (6, -0.035), (7, -0.047), (8, 0.002), (9, -0.227), (10, -0.051), (11, 0.063), (12, -0.035), (13, 0.016), (14, 0.027), (15, -0.076), (16, -0.046), (17, 0.004), (18, 0.118), (19, 0.03), (20, 0.063), (21, -0.031), (22, -0.047), (23, 0.027), (24, 0.058), (25, 0.125), (26, 0.107), (27, -0.163), (28, -0.009), (29, -0.069), (30, -0.157), (31, 0.096), (32, 0.018), (33, 0.067), (34, -0.002), (35, -0.036), (36, -0.01), (37, 0.05), (38, -0.001), (39, 0.065), (40, 0.013), (41, 0.039), (42, -0.024), (43, 0.031), (44, 0.046), (45, -0.074), (46, -0.13), (47, -0.078), (48, -0.124), (49, -0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96516371 <a title="60-lsi-1" href="./acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction.html">60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</a></p>
<p>Author: Yafang Wang ; Maximilian Dylla ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: The Web and digitized text sources contain a wealth of information about named entities such as politicians, actors, companies, or cultural landmarks. Extracting this information has enabled the automated construction oflarge knowledge bases, containing hundred millions of binary relationships or attribute values about these named entities. However, in reality most knowledge is transient, i.e. changes over time, requiring a temporal dimension in fact extraction. In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles.</p><p>2 0.8756116 <a title="60-lsi-2" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>3 0.77139592 <a title="60-lsi-3" href="./acl-2012-Learning_to_Temporally_Order_Medical_Events_in_Clinical_Text.html">135 acl-2012-Learning to Temporally Order Medical Events in Clinical Text</a></p>
<p>Author: Preethi Raghavan ; Albert Lai ; Eric Fosler-Lussier</p><p>Abstract: We investigate the problem of ordering medical events in unstructured clinical narratives by learning to rank them based on their time of occurrence. We represent each medical event as a time duration, with a corresponding start and stop, and learn to rank the starts/stops based on their proximity to the admission date. Such a representation allows us to learn all of Allen’s temporal relations between medical events. Interestingly, we observe that this methodology performs better than a classification-based approach for this domain, but worse on the relationships found in the Timebank corpus. This finding has important implications for styles of data representation and resources used for temporal relation learning: clinical narratives may have different language attributes corresponding to temporal ordering relative to Timebank, implying that the field may need to look at a wider range ofdomains to fully understand the nature of temporal ordering.</p><p>4 0.68564075 <a title="60-lsi-4" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>Author: Nathanael Chambers</p><p>Abstract: Temporal reasoners for document understanding typically assume that a document’s creation date is known. Algorithms to ground relative time expressions and order events often rely on this timestamp to assist the learner. Unfortunately, the timestamp is not always known, particularly on the Web. This paper addresses the task of automatic document timestamping, presenting two new models that incorporate rich linguistic features about time. The first is a discriminative classifier with new features extracted from the text’s time expressions (e.g., ‘since 1999’). This model alone improves on previous generative models by 77%. The second model learns probabilistic constraints between time expressions and the unknown document time. Imposing these learned constraints on the discriminative model further improves its accuracy. Finally, we present a new experiment design that facil- itates easier comparison by future work.</p><p>5 0.63169283 <a title="60-lsi-5" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>Author: Remy Kessler ; Xavier Tannier ; Caroline Hagege ; Veronique Moriceau ; Andre Bittar</p><p>Abstract: We present an approach for detecting salient (important) dates in texts in order to automatically build event timelines from a search query (e.g. the name of an event or person, etc.). This work was carried out on a corpus of newswire texts in English provided by the Agence France Presse (AFP). In order to extract salient dates that warrant inclusion in an event timeline, we first recognize and normalize temporal expressions in texts and then use a machine-learning approach to extract salient dates that relate to a particular topic. We focused only on extracting the dates and not the events to which they are related.</p><p>6 0.59243345 <a title="60-lsi-6" href="./acl-2012-Extracting_Narrative_Timelines_as_Temporal_Dependency_Structures.html">90 acl-2012-Extracting Narrative Timelines as Temporal Dependency Structures</a></p>
<p>7 0.50159627 <a title="60-lsi-7" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<p>8 0.4759025 <a title="60-lsi-8" href="./acl-2012-Extracting_and_modeling_durations_for_habits_and_events_from_Twitter.html">91 acl-2012-Extracting and modeling durations for habits and events from Twitter</a></p>
<p>9 0.41243264 <a title="60-lsi-9" href="./acl-2012-Bootstrapping_via_Graph_Propagation.html">42 acl-2012-Bootstrapping via Graph Propagation</a></p>
<p>10 0.39498559 <a title="60-lsi-10" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<p>11 0.36617154 <a title="60-lsi-11" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>12 0.35869053 <a title="60-lsi-12" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>13 0.35515922 <a title="60-lsi-13" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>14 0.31295997 <a title="60-lsi-14" href="./acl-2012-Tense_and_Aspect_Error_Correction_for_ESL_Learners_Using_Global_Context.html">192 acl-2012-Tense and Aspect Error Correction for ESL Learners Using Global Context</a></p>
<p>15 0.30730087 <a title="60-lsi-15" href="./acl-2012-Learning_High-Level_Planning_from_Text.html">129 acl-2012-Learning High-Level Planning from Text</a></p>
<p>16 0.30693665 <a title="60-lsi-16" href="./acl-2012-A_Comprehensive_Gold_Standard_for_the_Enron_Organizational_Hierarchy.html">6 acl-2012-A Comprehensive Gold Standard for the Enron Organizational Hierarchy</a></p>
<p>17 0.29712102 <a title="60-lsi-17" href="./acl-2012-Collective_Generation_of_Natural_Image_Descriptions.html">51 acl-2012-Collective Generation of Natural Image Descriptions</a></p>
<p>18 0.29292285 <a title="60-lsi-18" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>19 0.27156362 <a title="60-lsi-19" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>20 0.25140586 <a title="60-lsi-20" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.017), (26, 0.041), (28, 0.03), (30, 0.029), (37, 0.043), (39, 0.062), (59, 0.016), (64, 0.306), (74, 0.017), (82, 0.072), (84, 0.017), (85, 0.027), (90, 0.093), (92, 0.054), (94, 0.03), (99, 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78155106 <a title="60-lda-1" href="./acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction.html">60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</a></p>
<p>Author: Yafang Wang ; Maximilian Dylla ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: The Web and digitized text sources contain a wealth of information about named entities such as politicians, actors, companies, or cultural landmarks. Extracting this information has enabled the automated construction oflarge knowledge bases, containing hundred millions of binary relationships or attribute values about these named entities. However, in reality most knowledge is transient, i.e. changes over time, requiring a temporal dimension in fact extraction. In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles.</p><p>2 0.49138364 <a title="60-lda-2" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>3 0.4884685 <a title="60-lda-3" href="./acl-2012-A_Topic_Similarity_Model_for_Hierarchical_Phrase-based_Translation.html">22 acl-2012-A Topic Similarity Model for Hierarchical Phrase-based Translation</a></p>
<p>Author: Xinyan Xiao ; Deyi Xiong ; Min Zhang ; Qun Liu ; Shouxun Lin</p><p>Abstract: Previous work using topic model for statistical machine translation (SMT) explore topic information at the word level. However, SMT has been advanced from word-based paradigm to phrase/rule-based paradigm. We therefore propose a topic similarity model to exploit topic information at the synchronous rule level for hierarchical phrase-based translation. We associate each synchronous rule with a topic distribution, and select desirable rules according to the similarity of their topic distributions with given documents. We show that our model significantly improves the translation performance over the baseline on NIST Chinese-to-English translation experiments. Our model also achieves a better performance and a faster speed than previous approaches that work at the word level.</p><p>4 0.47178739 <a title="60-lda-4" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Pradeep Dasigi ; Mona Diab ; Dragomir Radev</p><p>Abstract: The rapid and continuous growth of social networking sites has led to the emergence of many communities of communicating groups. Many of these groups discuss ideological and political topics. It is not uncommon that the participants in such discussions split into two or more subgroups. The members of each subgroup share the same opinion toward the discussion topic and are more likely to agree with members of the same subgroup and disagree with members from opposing subgroups. In this paper, we propose an unsupervised approach for automatically detecting discussant subgroups in online communities. We analyze the text exchanged between the participants of a discussion to identify the attitude they carry toward each other and towards the various aspects of the discussion topic. We use attitude predictions to construct an attitude vector for each discussant. We use clustering techniques to cluster these vectors and, hence, determine the subgroup membership of each participant. We compare our methods to text clustering and other baselines, and show that our method achieves promising results.</p><p>5 0.46477339 <a title="60-lda-5" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<p>Author: Seokhwan Kim ; Gary Geunbae Lee</p><p>Abstract: Although researchers have conducted extensive studies on relation extraction in the last decade, supervised approaches are still limited because they require large amounts of training data to achieve high performances. To build a relation extractor without significant annotation effort, we can exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus.</p><p>6 0.45332837 <a title="60-lda-6" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<p>7 0.45222673 <a title="60-lda-7" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>8 0.45102093 <a title="60-lda-8" href="./acl-2012-Extracting_Narrative_Timelines_as_Temporal_Dependency_Structures.html">90 acl-2012-Extracting Narrative Timelines as Temporal Dependency Structures</a></p>
<p>9 0.44615421 <a title="60-lda-9" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>10 0.44502205 <a title="60-lda-10" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>11 0.44438997 <a title="60-lda-11" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>12 0.43927222 <a title="60-lda-12" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>13 0.43635988 <a title="60-lda-13" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>14 0.43586504 <a title="60-lda-14" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>15 0.43489 <a title="60-lda-15" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>16 0.43299848 <a title="60-lda-16" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>17 0.43280473 <a title="60-lda-17" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>18 0.43186194 <a title="60-lda-18" href="./acl-2012-Modeling_Topic_Dependencies_in_Hierarchical_Text_Categorization.html">146 acl-2012-Modeling Topic Dependencies in Hierarchical Text Categorization</a></p>
<p>19 0.4304688 <a title="60-lda-19" href="./acl-2012-Event_Linking%3A_Grounding_Event_Reference_in_a_News_Archive.html">85 acl-2012-Event Linking: Grounding Event Reference in a News Archive</a></p>
<p>20 0.43019003 <a title="60-lda-20" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
