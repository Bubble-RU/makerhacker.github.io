<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-102" href="#">acl2012-102</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</h1>
<br/><p>Source: <a title="acl-2012-102-pdf" href="http://aclweb.org/anthology//P/P12/P12-2013.pdf">pdf</a></p><p>Author: Pradeep Dasigi ; Weiwei Guo ; Mona Diab</p><p>Abstract: We describe an unsupervised approach to the problem of automatically detecting subgroups of people holding similar opinions in a discussion thread. An intuitive way of identifying this is to detect the attitudes of discussants towards each other or named entities or topics mentioned in the discussion. Sentiment tags play an important role in this detection, but we also note another dimension to the detection of people’s attitudes in a discussion: if two persons share the same opinion, they tend to use similar language content. We consider the latter to be an implicit attitude. In this paper, we investigate the impact of implicit and explicit attitude in two genres of social media discussion data, more formal wikipedia discussions and a debate discussion forum that is much more informal. Experimental results strongly suggest that implicit attitude is an important complement for explicit attitudes (expressed via sentiment) and it can improve the sub-group detection performance independent of genre.</p><p>Reference: <a title="acl-2012-102-reference" href="../acl2012_reference/acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu Center for Computational Learning Systems, Columbia University  Abstract We describe an unsupervised approach to the problem of automatically detecting subgroups of people holding similar opinions in a discussion thread. [sent-6, score-0.258]
</p><p>2 An intuitive way of identifying this is to detect the attitudes of discussants towards each other or named entities or topics mentioned in the discussion. [sent-7, score-0.893]
</p><p>3 Sentiment tags play an important role in this detection, but we also note another dimension to the detection of people’s attitudes in a discussion: if two persons share the same opinion, they tend to use similar language content. [sent-8, score-0.356]
</p><p>4 We consider the latter to be an implicit attitude. [sent-9, score-0.246]
</p><p>5 In this paper, we investigate the impact of implicit and explicit attitude in two genres of social media discussion data, more formal wikipedia discussions and a debate discussion forum that is much more informal. [sent-10, score-1.248]
</p><p>6 Experimental results strongly suggest that implicit attitude is an important complement for explicit attitudes (expressed via sentiment) and it can improve the  sub-group detection performance independent of genre. [sent-11, score-1.15]
</p><p>7 1 Introduction There has been a significant increase in discussion forum data in online media recently. [sent-12, score-0.169]
</p><p>8 Most of such discussion threads have a clear debate component in them with varying levels of formality. [sent-13, score-0.269]
</p><p>9 A straight-forward approach to this problem is to apply Opinion Mining techniques, and extract 65 each discussant’s attitudes towards other discussants and entities being discussed. [sent-15, score-0.78]
</p><p>10 But the challenge is that Opinion Mining is not mature enough to extract all the correct opinions of discussants. [sent-16, score-0.076]
</p><p>11 On observing interactions from these threads, we believe that there is another dimension of attitude which is expressed implicitly. [sent-18, score-0.511]
</p><p>12 We find that people sharing the same opinion tend to speak about the same topics even though they do not explicitly express their sentiment. [sent-19, score-0.211]
</p><p>13 One such example may be seen in the two posts in Table 1. [sent-21, score-0.097]
</p><p>14 It can be seen that even though discussants A and B do not express explicit sentiments, they hold similar views. [sent-22, score-0.502]
</p><p>15 Hence it can be said that there is an agreement in their implicit attitudes. [sent-23, score-0.275]
</p><p>16 Attempting to find a surface level word similarity between posts of two discussants is not sufficient as there are typically few overlapping words shared among the posts. [sent-24, score-0.487]
</p><p>17 Accordingly, in this work, we attempt to model the implicit latent similarity between posts as a means of identifying the implicit attitudes among discussants. [sent-26, score-1.0]
</p><p>18 We apply variants on Latent Dirichelet Allocation (LDA) based topic models to the problem (Blei et al. [sent-27, score-0.046]
</p><p>19 Our goal is identify subgroups with respect to discussants’ attitudes towards each other, the entities  and topics in a discussion forum. [sent-29, score-0.647]
</p><p>20 To our knowledge, this is the first attempt at using text similarity as an indication of user attitudes. [sent-30, score-0.042]
</p><p>21 We investigate the influence of the explicit and implicit attitudes on two genres of data, one more formal than the other. [sent-31, score-0.758]
</p><p>22 Explicit attitude alone Proce Jedijung, sR oefpu thbeli c50 othf K Aonrneua,a8l -M14e Jtiunlgy o 2f0 t1h2e. [sent-33, score-0.417]
</p><p>23 c s 2o0c1ia2ti Aosns fo cria Ctio nm fpourta Ctoiomnpault Laitniognuaislt Licisn,g puaigsteiscs 65–69, as a feature is more useful than implicit attitude in identifying sub-groups in informal data. [sent-35, score-0.763]
</p><p>24 But in the case of formal data, implicit attitude yields better results. [sent-36, score-0.723]
</p><p>25 This may be due to the fact that in informal data, strong subjective opinions about entities/events or towards other discussants are expressed more explicitly. [sent-37, score-0.598]
</p><p>26 This is generally not the case in the formal genre where ideas do not have as much sentiment associated with them, and hence the opinions are more “implicit”. [sent-38, score-0.445]
</p><p>27 (Ganapathibhotla and  Liu, 2008) deal with the problem of finding opinions from comparative sentences. [sent-41, score-0.076]
</p><p>28 , 2007; Jakob and Gurevych, 2010), focus on the domain of product reviews where they exploit the genre in multiple ways. [sent-43, score-0.099]
</p><p>29 Somasundaran and Wiebe (2009) used unsupervised methods to identify stances in online debates. [sent-44, score-0.124]
</p><p>30 They mine the web to find associations indicative of opinions and combine them with discourse information. [sent-45, score-0.076]
</p><p>31 Their problem essentially deals with the debate genre and finding the stance of an individual given two options. [sent-46, score-0.206]
</p><p>32 Ours is a more general problem since we deal with discussion data in general and not debates on specific topics. [sent-47, score-0.069]
</p><p>33 Hence our aim is to identify multiple groups, not just two. [sent-48, score-0.033]
</p><p>34 (2010) in using part-of-speech and dependency structures to identify polarities of attitudes is similar to our work. [sent-50, score-0.377]
</p><p>35 But they predict binary polarities in attitudes, and our goal of identification of sub-groups is a more general problem in that we aim at identifying multiple subgroups. [sent-51, score-0.133]
</p><p>36 3 Approach  We tackle the problem using Vector Space Modeling techniques to represent the discussion threads. [sent-52, score-0.069]
</p><p>37 Each vector represents a discussant in the thread creating an Attitude Profile (AP). [sent-53, score-0.487]
</p><p>38 We use a clustering algorithm to partition the vector space of APs into multiple sub-groups. [sent-54, score-0.085]
</p><p>39 The idea is that resulting clusters would comprise sub-groups of discussants with 66 similar attitudes. [sent-55, score-0.409]
</p><p>40 1 Basic Features We use two basic features, namely Negative and Positive sentiment towards specific discussants and entities like in the work done by (Abu-Jbara et al. [sent-57, score-0.65]
</p><p>41 We start off by determining sentences that express attitude in the thread, attitude sentences (AS). [sent-59, score-0.865]
</p><p>42 For determining discussant sentiment, we need to first identify who the target of their sentiment is: another discussant, or an entity, where an entity could be a topic or a person not participating in the discussion. [sent-62, score-0.594]
</p><p>43 Sentiment toward another discussant:  This is quite challenging since explicit sentiment expressed in a post is not necessarily directed towards another discussant to whom it is a reply. [sent-63, score-0.747]
</p><p>44 It is possible that a discussant may be replying to another poster but expressing an attitude towards a third entity or discussant. [sent-64, score-0.856]
</p><p>45 However as a simplifying assumption, similar to the work of (Hassan et al. [sent-65, score-0.034]
</p><p>46 , 2010), we adopt the view that replies in the sentences that are determined to be attitudinal and contain secondperson pronouns (you, your, yourself) are assumed to be directed towards the recipients of the replies. [sent-66, score-0.166]
</p><p>47 Sentiment toward an entity: We again adopt a simplifying view by modeling all the named entities in a sentence without heeding the roles these entities play, i. [sent-67, score-0.194]
</p><p>48 Accordingly, we extract all the named entities in a sentence using Stanford’s Name Entity Recognizer (Finkel et al. [sent-70, score-0.094]
</p><p>49 We only focus on Person and Organization named entities. [sent-72, score-0.028]
</p><p>50 2  Extracting Implicit Attitudes  We define implicit attitudes as the semantic similarity between texts comprising discussant utter-  ances or posts in a thread. [sent-74, score-0.995]
</p><p>51 We cannot find enough overlapping words between posts, since some posts are very short. [sent-75, score-0.097]
</p><p>52 , 2003) on texts to extract latent semantics of texts. [sent-77, score-0.041]
</p><p>53 By computing the similarity on these vectors, we obtain a more accurate semantic similarity. [sent-82, score-0.042]
</p><p>54 His films are very philosophically deep, they say something about everything, war, crime, relationships, humanity, etc. [sent-84, score-0.051]
</p><p>55 B: All of his films show the true human nature of man and their inner fights and all of them are very philosophical. [sent-85, score-0.076]
</p><p>56 3 Clustering Attitude Space A tree-based (hierarchical) clustering algorithm, SLINK (Sibson, 1973) is used to cluster the vector space. [sent-88, score-0.085]
</p><p>57 Cosine Similarity between the vectors is used as the inter-data point similarity measure for We choose the number of clusters to be dpn2e, described as the rule of thumb by (Mardia et alp. [sent-89, score-0.189]
</p><p>58 , 1979), wcrihbeerde n tihs eth reu lneu omfb theru mofb d biysc (uMssaarndtisa eint  clustering. [sent-90, score-0.025]
</p><p>59 This rule seems to be validated by the fact that in the data sets with which we experiment, we note that the predicted number of clusters according to this rule and the classes identified in the gold data are very close as illustrated in Table 2. [sent-92, score-0.061]
</p><p>60 On average we note that the gold data has the number of classes per thread to be roughly 2-5. [sent-93, score-0.13]
</p><p>61 4 Data We use data from two online forums - Create Debate [CD]2 and discussions from Wikipedia [WIKI]3. [sent-94, score-0.081]
</p><p>62 There is a significant difference in the kind of discussions in these two sources. [sent-95, score-0.033]
</p><p>63 Our WIKI data comprises 117 threads crawled from Wikipedia. [sent-96, score-0.124]
</p><p>64 It does not have much negative polarity and discussants essentially discuss the Wikipedia page in question. [sent-98, score-0.449]
</p><p>65 Hence it is closer to an academic discussion forum. [sent-99, score-0.098]
</p><p>66 Given a thread, the annotator is asked to identify if there are any sub-groups among the discussants with similar opinions, and ifyes, the membership ofthose 1We also experimented with K-means (MacQueen, 1967) and found that it yields worse results compared to SLINK. [sent-101, score-0.381]
</p><p>67 Hence, tree based clustering algorithms are more well suited for the current task. [sent-105, score-0.052]
</p><p>68 On the other hand, CD is a forum where people debate a specific topic. [sent-113, score-0.202]
</p><p>69 It is more informal (with pervasive negative language and personal insults) than WIKI and has longer threads. [sent-115, score-0.102]
</p><p>70 The votes cast by the discussants in the poll are used as the class labels for our experiments. [sent-118, score-0.394]
</p><p>71 This is because there are two polarities and n possible targets. [sent-121, score-0.058]
</p><p>72 The value representing this feature is the number of sentences with the respective polarity negative or positive towards the particular discussant. [sent-122, score-0.211]
</p><p>73 • Sentiment towards entities in discussion (SE) N•u Smebnteirm oefn dtim toewnasriodnss e corresponding utsos tihoins f (eSaEtu)re is 2 ∗ e, where e is the number of entities discovered. [sent-123, score-0.281]
</p><p>74 number of sentences in which that specific polarity is shown by the discussant towards the entity. [sent-125, score-0.461]
</p><p>75 • Implicit Attitude (IA) - n ∗ t dimensions are expressed using itthuids feature, wn h∗er te d ti mise tnhsieo nnusm abreer e xoftopics that the topic model contains. [sent-126, score-0.082]
</p><p>76 This means that the AP of every discussant contains the topic model distribution of his/her interactions with every other –  –  member in the thread. [sent-127, score-0.402]
</p><p>77 Hence, the topics in the interation between the given discussant and other members in the thread are being modeled here. [sent-128, score-0.528]
</p><p>78 Accordingly, high vector similarity due to IA between two members in a thread means that they discussed similar topics with the same people in the thread. [sent-129, score-0.322]
</p><p>79 The LDA model is built on definitions of two online dictionaries WordNet, and Wiktionary, in addition to the Brown corpus (BC). [sent-132, score-0.048]
</p><p>80 The degree of agreement among discussants in terms of these three features is used to identify subgroups among them. [sent-135, score-0.48]
</p><p>81 Our experiments are aimed at investigating the effect of explicit attitude features (SD and SE) in comparison with implicit feature (IA) and how they perform when combined. [sent-136, score-0.786]
</p><p>82 So the experimental conditions are: the three features in isolation, each of the explicit features SD and SE together with IA, and then all three features together. [sent-137, score-0.167]
</p><p>83 SWD-BASE: As a baseline, we employ a simple  word frequency based model to capture topic distribution, Surface Word Distribution (SWD). [sent-138, score-0.046]
</p><p>84 SWD is still topic modeling in the vector space, but the dimensions of the vectors are the frequencies of all the unique words used by the discussant in question. [sent-139, score-0.431]
</p><p>85 RAND-BASE: We also apply a very simple baseline using random assignment of discussants to groups, however the number of clusters is determined by the rule of thumb described in Section 3. [sent-140, score-0.467]
</p><p>86 The following observations can be made: All the individual conditions SD, SE and IA clearly outperform SWD-BASE. [sent-145, score-0.044]
</p><p>87 All the experimental conditions outperform RAND-BASE which indicates that using clustering is contributing positively to the problem. [sent-146, score-0.096]
</p><p>88 This may be due to two reasons: Firstly, since the problem is of clustering the discussant space, SD should be a better indicator than SE. [sent-148, score-0.376]
</p><p>89 This is an interesting result and we believe it is mainly due to the genre of the data. [sent-154, score-0.099]
</p><p>90 Explicit expression of sentiment usually increases with the increase in the informal nature of discussions. [sent-155, score-0.214]
</p><p>91 Hence IA is more useful in WIKI which is more formal compared to CD, where there is less overt sentiment expression. [sent-156, score-0.216]
</p><p>92 There is significantly more negative language  than positive language in CD when compared with the ratios of negative to positive language in WIKI, which are almost the same. [sent-160, score-0.148]
</p><p>93 The best results overall are yielded from the combination of IA with SD and SE, the implicit and explicit features together for both data sets, which suggests that Implicit and explicit attitude features complement each other capturing more information than each of them individually. [sent-161, score-0.943]
</p><p>94 7 Conclusions We proposed the use of LDA based topic modeling as an implicit agreement feature for the task of identifying similar attitudes in online discussions. [sent-162, score-0.697]
</p><p>95 We specifically applied latent modeling to the problem of sub-group detection. [sent-163, score-0.041]
</p><p>96 We compared this with explicit sentiment features in different genres both in isolation and in combination. [sent-164, score-0.353]
</p><p>97 We highlighted the difference in genre in the datasets and the necessity for capturing different forms of information from them for the task at hand. [sent-165, score-0.099]
</p><p>98 The best yielding condition in both the dat sets combines implicit and explicit features suggesting that there is a complementarity between the two tpes of feaures. [sent-166, score-0.369]
</p><p>99 Using anaphora resolution to improve opinion target identification in movie reviews. [sent-205, score-0.127]
</p><p>100 Some methods for classification and analysis of multivariate observations. [sent-214, score-0.043]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('attitude', 0.417), ('discussants', 0.348), ('discussant', 0.324), ('attitudes', 0.286), ('implicit', 0.246), ('sd', 0.168), ('sentiment', 0.156), ('ia', 0.138), ('thread', 0.13), ('explicit', 0.123), ('cd', 0.113), ('wiki', 0.113), ('debate', 0.107), ('genre', 0.099), ('posts', 0.097), ('opinion', 0.094), ('threads', 0.093), ('slink', 0.087), ('towards', 0.08), ('se', 0.077), ('opinions', 0.076), ('subgroups', 0.07), ('discussion', 0.069), ('entities', 0.066), ('subgroup', 0.065), ('clusters', 0.061), ('formal', 0.06), ('polarities', 0.058), ('attitudinal', 0.058), ('ganapathibhotla', 0.058), ('mardia', 0.058), ('thumb', 0.058), ('informal', 0.058), ('lda', 0.058), ('polarity', 0.057), ('hassan', 0.056), ('somasundaran', 0.056), ('hence', 0.054), ('accordingly', 0.053), ('clustering', 0.052), ('forum', 0.052), ('films', 0.051), ('dasigi', 0.051), ('pradeep', 0.051), ('swd', 0.051), ('online', 0.048), ('poll', 0.046), ('opinionfinder', 0.046), ('topic', 0.046), ('ap', 0.046), ('mining', 0.044), ('negative', 0.044), ('conditions', 0.044), ('detection', 0.044), ('genres', 0.043), ('stances', 0.043), ('multivariate', 0.043), ('swapna', 0.043), ('people', 0.043), ('topics', 0.043), ('identifying', 0.042), ('similarity', 0.042), ('latent', 0.041), ('kobayashi', 0.041), ('columbia', 0.04), ('bc', 0.039), ('expressed', 0.036), ('blei', 0.036), ('entity', 0.035), ('mona', 0.034), ('complement', 0.034), ('simplifying', 0.034), ('dragomir', 0.034), ('diab', 0.033), ('vector', 0.033), ('identify', 0.033), ('identification', 0.033), ('discussions', 0.033), ('jakob', 0.032), ('wilson', 0.032), ('interactions', 0.032), ('isolation', 0.031), ('express', 0.031), ('members', 0.031), ('comprises', 0.031), ('positive', 0.03), ('agreement', 0.029), ('closer', 0.029), ('wikipedia', 0.029), ('vectors', 0.028), ('named', 0.028), ('directed', 0.028), ('groups', 0.028), ('finkel', 0.028), ('griffiths', 0.027), ('dimension', 0.026), ('tailed', 0.025), ('murthy', 0.025), ('mofb', 0.025), ('fights', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="102-tfidf-1" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>Author: Pradeep Dasigi ; Weiwei Guo ; Mona Diab</p><p>Abstract: We describe an unsupervised approach to the problem of automatically detecting subgroups of people holding similar opinions in a discussion thread. An intuitive way of identifying this is to detect the attitudes of discussants towards each other or named entities or topics mentioned in the discussion. Sentiment tags play an important role in this detection, but we also note another dimension to the detection of people’s attitudes in a discussion: if two persons share the same opinion, they tend to use similar language content. We consider the latter to be an implicit attitude. In this paper, we investigate the impact of implicit and explicit attitude in two genres of social media discussion data, more formal wikipedia discussions and a debate discussion forum that is much more informal. Experimental results strongly suggest that implicit attitude is an important complement for explicit attitudes (expressed via sentiment) and it can improve the sub-group detection performance independent of genre.</p><p>2 0.61332345 <a title="102-tfidf-2" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: We present Subgroup Detector, a system for analyzing threaded discussions and identifying the attitude of discussants towards one another and towards the discussion topic. The system uses attitude predictions to detect the split of discussants into subgroups of opposing views. The system uses an unsupervised approach based on rule-based opinion target detecting and unsupervised clustering techniques. The system is open source and is freely available for download. An online demo of the system is available at: http://clair.eecs.umich.edu/SubgroupDetector/</p><p>3 0.60676849 <a title="102-tfidf-3" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Pradeep Dasigi ; Mona Diab ; Dragomir Radev</p><p>Abstract: The rapid and continuous growth of social networking sites has led to the emergence of many communities of communicating groups. Many of these groups discuss ideological and political topics. It is not uncommon that the participants in such discussions split into two or more subgroups. The members of each subgroup share the same opinion toward the discussion topic and are more likely to agree with members of the same subgroup and disagree with members from opposing subgroups. In this paper, we propose an unsupervised approach for automatically detecting discussant subgroups in online communities. We analyze the text exchanged between the participants of a discussion to identify the attitude they carry toward each other and towards the various aspects of the discussion topic. We use attitude predictions to construct an attitude vector for each discussant. We use clustering techniques to cluster these vectors and, hence, determine the subgroup membership of each participant. We compare our methods to text clustering and other baselines, and show that our method achieves promising results.</p><p>4 0.1515484 <a title="102-tfidf-4" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>Author: Fangtao Li ; Sinno Jialin Pan ; Ou Jin ; Qiang Yang ; Xiaoyan Zhu</p><p>Abstract: Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment- and topic- lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.</p><p>5 0.12457293 <a title="102-tfidf-5" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>Author: Eduard Dragut ; Hong Wang ; Clement Yu ; Prasad Sistla ; Weiyi Meng</p><p>Abstract: Polarity classification of words is important for applications such as Opinion Mining and Sentiment Analysis. A number of sentiment word/sense dictionaries have been manually or (semi)automatically constructed. The dictionaries have substantial inaccuracies. Besides obvious instances, where the same word appears with different polarities in different dictionaries, the dictionaries exhibit complex cases, which cannot be detected by mere manual inspection. We introduce the concept of polarity consistency of words/senses in sentiment dictionaries in this paper. We show that the consistency problem is NP-complete. We reduce the polarity consistency problem to the satisfiability problem and utilize a fast SAT solver to detect inconsistencies in a sentiment dictionary. We perform experiments on four sentiment dictionaries and WordNet.</p><p>6 0.11137813 <a title="102-tfidf-6" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>7 0.11088938 <a title="102-tfidf-7" href="./acl-2012-PDTB-style_Discourse_Annotation_of_Chinese_Text.html">157 acl-2012-PDTB-style Discourse Annotation of Chinese Text</a></p>
<p>8 0.10727531 <a title="102-tfidf-8" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>9 0.102558 <a title="102-tfidf-9" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>10 0.098835438 <a title="102-tfidf-10" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>11 0.096976906 <a title="102-tfidf-11" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>12 0.096959166 <a title="102-tfidf-12" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>13 0.091170475 <a title="102-tfidf-13" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>14 0.08670903 <a title="102-tfidf-14" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>15 0.078508399 <a title="102-tfidf-15" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>16 0.076882444 <a title="102-tfidf-16" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>17 0.076065212 <a title="102-tfidf-17" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>18 0.074581444 <a title="102-tfidf-18" href="./acl-2012-Topic_Models_for_Dynamic_Translation_Model_Adaptation.html">199 acl-2012-Topic Models for Dynamic Translation Model Adaptation</a></p>
<p>19 0.072495319 <a title="102-tfidf-19" href="./acl-2012-SITS%3A_A_Hierarchical_Nonparametric_Model_using_Speaker_Identity_for_Topic_Segmentation_in_Multiparty_Conversations.html">171 acl-2012-SITS: A Hierarchical Nonparametric Model using Speaker Identity for Topic Segmentation in Multiparty Conversations</a></p>
<p>20 0.068634994 <a title="102-tfidf-20" href="./acl-2012-Finding_Bursty_Topics_from_Microblogs.html">98 acl-2012-Finding Bursty Topics from Microblogs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.201), (1, 0.296), (2, 0.254), (3, -0.291), (4, 0.271), (5, -0.062), (6, -0.32), (7, -0.083), (8, 0.383), (9, 0.101), (10, -0.16), (11, -0.013), (12, 0.073), (13, 0.108), (14, 0.044), (15, 0.011), (16, -0.014), (17, -0.01), (18, 0.056), (19, 0.022), (20, 0.005), (21, -0.024), (22, -0.001), (23, 0.014), (24, 0.005), (25, -0.024), (26, 0.009), (27, -0.016), (28, -0.018), (29, -0.005), (30, -0.021), (31, 0.003), (32, 0.004), (33, -0.038), (34, 0.004), (35, -0.008), (36, -0.021), (37, 0.0), (38, -0.011), (39, 0.003), (40, 0.039), (41, 0.013), (42, -0.022), (43, -0.009), (44, -0.01), (45, 0.001), (46, 0.01), (47, 0.014), (48, 0.002), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.94689262 <a title="102-lsi-1" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: We present Subgroup Detector, a system for analyzing threaded discussions and identifying the attitude of discussants towards one another and towards the discussion topic. The system uses attitude predictions to detect the split of discussants into subgroups of opposing views. The system uses an unsupervised approach based on rule-based opinion target detecting and unsupervised clustering techniques. The system is open source and is freely available for download. An online demo of the system is available at: http://clair.eecs.umich.edu/SubgroupDetector/</p><p>same-paper 2 0.93903208 <a title="102-lsi-2" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>Author: Pradeep Dasigi ; Weiwei Guo ; Mona Diab</p><p>Abstract: We describe an unsupervised approach to the problem of automatically detecting subgroups of people holding similar opinions in a discussion thread. An intuitive way of identifying this is to detect the attitudes of discussants towards each other or named entities or topics mentioned in the discussion. Sentiment tags play an important role in this detection, but we also note another dimension to the detection of people’s attitudes in a discussion: if two persons share the same opinion, they tend to use similar language content. We consider the latter to be an implicit attitude. In this paper, we investigate the impact of implicit and explicit attitude in two genres of social media discussion data, more formal wikipedia discussions and a debate discussion forum that is much more informal. Experimental results strongly suggest that implicit attitude is an important complement for explicit attitudes (expressed via sentiment) and it can improve the sub-group detection performance independent of genre.</p><p>3 0.92863131 <a title="102-lsi-3" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Pradeep Dasigi ; Mona Diab ; Dragomir Radev</p><p>Abstract: The rapid and continuous growth of social networking sites has led to the emergence of many communities of communicating groups. Many of these groups discuss ideological and political topics. It is not uncommon that the participants in such discussions split into two or more subgroups. The members of each subgroup share the same opinion toward the discussion topic and are more likely to agree with members of the same subgroup and disagree with members from opposing subgroups. In this paper, we propose an unsupervised approach for automatically detecting discussant subgroups in online communities. We analyze the text exchanged between the participants of a discussion to identify the attitude they carry toward each other and towards the various aspects of the discussion topic. We use attitude predictions to construct an attitude vector for each discussant. We use clustering techniques to cluster these vectors and, hence, determine the subgroup membership of each participant. We compare our methods to text clustering and other baselines, and show that our method achieves promising results.</p><p>4 0.37322307 <a title="102-lsi-4" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>Author: Eduard Dragut ; Hong Wang ; Clement Yu ; Prasad Sistla ; Weiyi Meng</p><p>Abstract: Polarity classification of words is important for applications such as Opinion Mining and Sentiment Analysis. A number of sentiment word/sense dictionaries have been manually or (semi)automatically constructed. The dictionaries have substantial inaccuracies. Besides obvious instances, where the same word appears with different polarities in different dictionaries, the dictionaries exhibit complex cases, which cannot be detected by mere manual inspection. We introduce the concept of polarity consistency of words/senses in sentiment dictionaries in this paper. We show that the consistency problem is NP-complete. We reduce the polarity consistency problem to the satisfiability problem and utilize a fast SAT solver to detect inconsistencies in a sentiment dictionary. We perform experiments on four sentiment dictionaries and WordNet.</p><p>5 0.32352507 <a title="102-lsi-5" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>Author: Wen-Tai Hsieh ; Chen-Ming Wu ; Tsun Ku ; Seng-cho T. Chou</p><p>Abstract: Social Event Radar is a new social networking-based service platform, that aim to alert as well as monitor any merchandise flaws, food-safety related issues, unexpected eruption of diseases or campaign issues towards to the Government, enterprises of any kind or election parties, through keyword expansion detection module, using bilingual sentiment opinion analysis tool kit to conclude the specific event social dashboard and deliver the outcome helping authorities to plan “risk control” strategy. With the rapid development of social network, people can now easily publish their opinions on the Internet. On the other hand, people can also obtain various opinions from others in a few seconds even though they do not know each other. A typical approach to obtain required information is to use a search engine with some relevant keywords. We thus take the social media and forum as our major data source and aim at collecting specific issues efficiently and effectively in this work. 163 Chen-Ming Wu Institute for Information Industry cmwu@ i i i .org .tw Seng-cho T. Chou Department of IM, National Taiwan University chou @ im .ntu .edu .tw 1</p><p>6 0.25751361 <a title="102-lsi-6" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>7 0.24201088 <a title="102-lsi-7" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>8 0.23942083 <a title="102-lsi-8" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>9 0.22296958 <a title="102-lsi-9" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>10 0.21841517 <a title="102-lsi-10" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>11 0.21368171 <a title="102-lsi-11" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>12 0.20839092 <a title="102-lsi-12" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>13 0.20601937 <a title="102-lsi-13" href="./acl-2012-Historical_Analysis_of_Legal_Opinions_with_a_Sparse_Mixed-Effects_Latent_Variable_Model.html">110 acl-2012-Historical Analysis of Legal Opinions with a Sparse Mixed-Effects Latent Variable Model</a></p>
<p>14 0.20394172 <a title="102-lsi-14" href="./acl-2012-The_Creation_of_a_Corpus_of_English_Metalanguage.html">195 acl-2012-The Creation of a Corpus of English Metalanguage</a></p>
<p>15 0.20358503 <a title="102-lsi-15" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>16 0.20300691 <a title="102-lsi-16" href="./acl-2012-A_Comprehensive_Gold_Standard_for_the_Enron_Organizational_Hierarchy.html">6 acl-2012-A Comprehensive Gold Standard for the Enron Organizational Hierarchy</a></p>
<p>17 0.20119745 <a title="102-lsi-17" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>18 0.19864176 <a title="102-lsi-18" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>19 0.19613522 <a title="102-lsi-19" href="./acl-2012-Information-theoretic_Multi-view_Domain_Adaptation.html">120 acl-2012-Information-theoretic Multi-view Domain Adaptation</a></p>
<p>20 0.19112056 <a title="102-lsi-20" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.018), (26, 0.04), (28, 0.039), (30, 0.029), (37, 0.038), (39, 0.093), (57, 0.01), (59, 0.015), (82, 0.127), (84, 0.023), (85, 0.031), (90, 0.114), (91, 0.186), (92, 0.066), (94, 0.017), (99, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90328193 <a title="102-lda-1" href="./acl-2012-PDTB-style_Discourse_Annotation_of_Chinese_Text.html">157 acl-2012-PDTB-style Discourse Annotation of Chinese Text</a></p>
<p>Author: Yuping Zhou ; Nianwen Xue</p><p>Abstract: We describe a discourse annotation scheme for Chinese and report on the preliminary results. Our scheme, inspired by the Penn Discourse TreeBank (PDTB), adopts the lexically grounded approach; at the same time, it makes adaptations based on the linguistic and statistical characteristics of Chinese text. Annotation results show that these adaptations work well in practice. Our scheme, taken together with other PDTB-style schemes (e.g. for English, Turkish, Hindi, and Czech), affords a broader perspective on how the generalized lexically grounded approach can flesh itself out in the context of cross-linguistic annotation of discourse relations.</p><p>2 0.85373861 <a title="102-lda-2" href="./acl-2012-Tokenization%3A_Returning_to_a_Long_Solved_Problem__A_Survey%2C_Contrastive_Experiment%2C_Recommendations%2C_and_Toolkit_.html">197 acl-2012-Tokenization: Returning to a Long Solved Problem  A Survey, Contrastive Experiment, Recommendations, and Toolkit </a></p>
<p>Author: Rebecca Dridan ; Stephan Oepen</p><p>Abstract: We examine some of the frequently disregarded subtleties of tokenization in Penn Treebank style, and present a new rule-based preprocessing toolkit that not only reproduces the Treebank tokenization with unmatched accuracy, but also maintains exact stand-off pointers to the original text and allows flexible configuration to diverse use cases (e.g. to genreor domain-specific idiosyncrasies). 1 Introduction—Motivation The task of tokenization is hardly counted among the grand challenges of NLP and is conventionally interpreted as breaking up “natural language text [...] into distinct meaningful units (or tokens)” (Kaplan, 2005). Practically speaking, however, tokenization is often combined with other string-level preprocessing—for example normalization of punctuation (of different conventions for dashes, say), disambiguation of quotation marks (into opening vs. closing quotes), or removal of unwanted mark-up— where the specifics of such pre-processing depend both on properties of the input text as well as on assumptions made in downstream processing. Applying some string-level normalizationprior to the identification of token boundaries can improve (or simplify) tokenization, and a sub-task like the disambiguation of quote marks would in fact be hard to perform after tokenization, seeing that it depends on adjacency to whitespace. In the following, we thus assume a generalized notion of tokenization, comprising all string-level processing up to and including the conversion of a sequence of characters (a string) to a sequence of token objects.1 1Obviously, some of the normalization we include in the tokenization task (in this generalized interpretation) could be left to downstream analysis, where a tagger or parser, for example, could be expected to accept non-disambiguated quote marks (so-called straight or typewriter quotes) and disambiguate as 378 Arguably, even in an overtly ‘separating’ language like English, there can be token-level ambiguities that ultimately can only be resolved through parsing (see § 3 for candidate examples), and indeed Waldron et al. (2006) entertain the idea of downstream processing on a token lattice. In this article, however, we accept the tokenization conventions and sequential nature of the Penn Treebank (PTB; Marcus et al., 1993) as a useful point of reference— primarily for interoperability of different NLP tools. Still, we argue, there is remaining work to be done on PTB-compliant tokenization (reviewed in§ 2), both methodologically, practically, and technologically. In § 3 we observe that state-of-the-art tools perform poorly on re-creating PTB tokenization, and move on in § 4 to develop a modular, parameterizable, and transparent framework for tokenization. Besides improvements in tokenization accuracy and adaptability to diverse use cases, in § 5 we further argue that each token object should unambiguously link back to an underlying element of the original input, which in the case of tokenization of text we realize through a notion of characterization. 2 Common Conventions Due to the popularity of the PTB, its tokenization has been a de-facto standard for two decades. Ap- proximately, this means splitting off punctuation into separate tokens, disambiguating straight quotes, and separating contractions such as can’t into ca and n ’t. There are, however, many special cases— part of syntactic analysis. However, on the (predominant) point of view that punctuation marks form tokens in their own right, the tokenizer would then have to adorn quote marks in some way, as to whether they were split off the left or right periphery of a larger token, to avoid unwanted syntactic ambiguity. Further, increasing use of Unicode makes texts containing ‘natively’ disambiguated quotes more common, where it would seem unfortunate to discard linguistically pertinent information by normalizing towards the poverty of pure ASCII punctuation. ProceedJienjgus, R ofep thueb 5lic0t hof A Knonrueaa,l M 8-e1e4ti Jnugly o f2 t0h1e2 A.s ?c so2c0ia1t2io Ans fsoorc Ciatoiomnp fuotart Cioonmaplu Ltiantgiounisatlic Lsi,n pgaugiestsi3c 7s8–382, documented and undocumented. In much tagging and parsing work, PTB data has been used with gold-standard tokens, to a point where many researchers are unaware of the existence of the original ‘raw’ (untokenized) text. Accordingly, the formal definition of PTB has received little attention, but reproducing PTB tokenization automatically actually is not a trivial task (see § 3). As the NLP community has moved to process data other than the PTB, some of the limitations of the tokenization2 PTB tokenization have been recognized, and many recently released data sets are accompanied by a note on tokenization along the lines of: Tokenization is similar to that used in PTB, except . . . Most exceptions are to do with hyphenation, or special forms of named entities such as chemical names or URLs. None of the documentation with extant data sets is sufficient to fully reproduce the tokenization.3 The CoNLL 2008 Shared Task data actually provided two forms of tokenization: that from the PTB (which many pre-processing tools would have been trained on), and another form that splits (most) hyphenated terms. This latter convention recently seems to be gaining ground in data sets like the Google 1T n-gram corpus (LDC #2006T13) and OntoNotes (Hovy et al., 2006). Clearly, as one moves towards a more application- and domaindriven idea of ‘correct’ tokenization, a more transparent, flexible, and adaptable approach to stringlevel pre-processing is called for. 3 A Contrastive Experiment To get an overview of current tokenization methods, we recovered and tokenized the raw text which was the source of the (Wall Street Journal portion of the) PTB, and compared it to the gold tokenization in the syntactic annotation in the We used three common methods of tokenization: (a) the original treebank.4 2See http : / /www . cis .upenn .edu/ ~t reebank/ t okeni z at ion .html for available ‘documentation’ and a sed script for PTB-style tokenization. 3Øvrelid et al. (2010) observe that tokenizing with the GENIA tagger yields mismatches in one of five sentences of the GENIA Treebank, although the GENIA guidelines refer to scripts that may be available on request (Tateisi & Tsujii, 2006). 4The original WSJ text was last included with the 1995 release of the PTB (LDC #95T07) and required alignment with the treebank, with some manual correction so that the same text is represented in both raw and parsed formats. 379 Tokenization Differing Levenshtein Method Sentences Distance tokenizer.sed 3264 11168 CoreNLP 1781 3717 C&J; parser 2597 4516 Table 1: Quantitative view on tokenization differences. PTB tokenizer.sed script; (b) the tokenizer from the Stanford CoreNLP tools5; and (c) tokenization from the parser of Charniak & Johnson (2005). Table 1 shows quantitative differences between each of the three methods and the PTB, both in terms of the number of sentences where the tokenization differs, and also in the total Levenshtein distance (Levenshtein, 1966) over tokens (for a total of 49,208 sentences and 1,173,750 gold-standard tokens). Looking at the differences qualitatively, the most consistent issue across all tokenization methods was ambiguity of sentence-final periods. In the treebank, final periods are always (with about 10 exceptions) a separate token. If the sentence ends in U.S. (but not other abbreviations, oddly), an extra period is hallucinated, so the abbreviation also has one. In contrast, C&J; add a period to all final abbreviations, CoreNLP groups the final period with a final abbreviation and hence lacks a sentence-final period token, and the sed script strips the period off U.S. The ‘correct’ choice in this case is not obvious and will depend on how the tokens are to be used. The majority of the discrepancies in the sed script tokenization come from an under-restricted punctuation rule that incorrectly splits on commas within numbers or ampersands within names. Other than that, the problematic cases are mostly shared across tokenization methods, and include issues with currencies, Irish names, hyphenization, and quote disambiguation. In addition, C&J; make some additional modifications to the text, lemmatising expressions such as won ’t as will and n ’t. 4 REPP: A Generalized Framework For tokenization to be studied as a first-class problem, and to enable customization and flexibility to diverse use cases, we suggest a non-procedural, rule-based framework dubbed REPP (Regular 5See corenlp / / nlp . st anford . edu / so ftware / run in ‘ st rict Treebank3 ’ mode. http : . shtml, Expression-Based Pre-Processing)—essentially a cascade of ordered finite-state string rewriting rules, though transcending the formal complexity of regular languages by inclusion of (a) full perl-compatible regular expressions and (b) fixpoint iteration over groups of rules. In this approach, a first phase of string-level substitutions inserts whitespace around, for example, punctuation marks; upon completion of string rewriting, token boundaries are stipulated between all whitespace-separated substrings (and only these). For a good balance of human and machine readability, REPP tokenization rules are specified in a simple, line-oriented textual form. Figure 1 shows a (simplified) excerpt from our PTB-style tokenizer, where the first character on each line is one of four REPP operators, as follows: (a) ‘#’ for group formation; (b) ‘>’ for group invocation, (c) ‘ ! ’ for substitution (allowing capture groups), and (d) ‘ : ’ for token boundary detection.6 In Figure 1, the two rules stripping off prefix and suffix punctuation marks adjacent to whitespace (i.e. matching the tab-separated left-hand side of the rule, to replace the match with its right-hand side) form a numbered group (‘# 1’), which will be iterated when called (‘> 1 until none ’) of the rules in the group fires (a fixpoint). In this example, conditioning on whitespace adjacency avoids the issues observed with the PTB sed script (e.g. token boundaries within comma-separated numbers) and also protects against infinite loops in the group.7 REPP rule sets can be organized as modules, typ6Strictly speaking, there are another two operators, for lineoriented comments and automated versioning of rule files. 7For this example, the same effects seemingly could be obtained without iteration (using greatly more complex rules); our actual, non-simplified rules, however, further deal with punctuation marks that can function as prefixes or suffixes, as well as with corner cases like factor(s) or Ca[2+]. Also in mark-up removal and normalization, we have found it necessary to ‘parse’ nested structures by means of iterative groups. 380 ically each in a file of its own, and invoked selectively by name (e.g. ‘>wiki’ in Figure 1); to date, there exist modules for quote disambiguation, (relevant subsets of) various mark-up languages (HTML, LATEX, wiki, and XML), and a handful of robustness rules (e.g. seeking to identify and repair ‘sandwiched’ inter-token punctuation). Individual tokenizers are configured at run-time, by selectively activating a set of modules (through command-line op- tions). An open-source reference implementation of the REPP framework (in C++) is available, together with a library of modules for English. 5 Characterization for Traceability Tokenization, and specifically our notion of generalized tokenization which allows text normalization, involves changes to the original text being analyzed, rather than just additional annotation. As such, full traceability from the token objects to the original text is required, which we formalize as ‘characterization’, in terms of character position links back to the source.8 This has the practical benefit of allowing downstream analysis as direct (stand-off) annotation on the source text, as seen for example in the ACL Anthology Searchbench (Schäfer et al., 2011). With our general regular expression replacement rules in REPP, making precise what it means for a token to link back to its ‘underlying’ substring requires some care in the design and implementation. Definite characterization links between the string before (I) and after (O) the application of a single orurele ( can only bftee res (tOab)li tshheed a pinp lcicerattiaoinn positions, viz. (a) spans not matched by the rule: unchanged text in O outside the span matched by the left-hand tseixdet regex outfs tidhee truhele s can always d be b ylin thkeed le bfta-chka ntod I; and (b) spans caught by a regex capture group: capture groups represent bthye a same te caxtp tiunr eth ger oleufpt-: and right-hand sides of a substitution, and so can be linked back to O.9 Outside these text spans, we can only md bakace kd etofin Oit.e statements about characterization links at boundary points, which include the start and end of the full string, the start and end of the string 8If the tokenization process was only concerned with the identification of token boundaries, characterization would be near-trivial. 9If capture group references are used out-of-order, however, the per-group linkage is no longer well-defined, and we resort to the maximum-span ‘union’ of boundary points (see below). matched by the rule, and the start and end of any capture groups in the rule. Each character in the string being processed has a start and end position, marking the point before and after the character in the original string. Before processing, the end position would always be one greater than the start position. However, if a rule mapped a string-initial, PTB-style opening double quote (``) to one-character Unicode “, the new first character of the string would have start position 0, but end position 2. In contrast, if there were a rule !wo (n’ t ) will \1 (1) applied to the string I ’t go!, all characters in the won second token of the resulting string (I will n’t go!) will have start position 2 and end position 4. This demonstrates one of the formal consequences of our design: we have no reason to assign the characters ill any start position other than 2.10 Since explicit character links between each I O will only be estaband laicstheerd l iantk kms abtecthw or capture group boundaries, any tteabxtfrom the left-hand side of a rule that should appear in O must be explicitly linked through a capture group rOefe mreunstc eb (rather tihtlayn l merely hwroriuttgehn ao cuta ipntu utrhee righthand side of the rule). In other words, rule (1) above should be preferred to the following variant (which would result in character start and end offsets of 0 and 5 for both output tokens): ! won’ t will n’ t (2) During rule application, we keep track of character start and end positions as offsets between a string before and after each rule application (i.e. all pairs hI, Oi), and these offsets are eventually traced back thoI ,thOe original string fats etthse atireme ev oefn ftiunaalll yto tkraecneidzat biaocnk. 6 Quantitative and Qualitative Evaluation In our own work on preparing various (non-PTB) genres for parsing, we devised a set of REPP rules with the goal of following the PTB conventions. When repeating the experiment of § 3 above using REPP tokenization, we obtained an initial difference in 1505 sentences, with a Levenshtein dis10This subtlety will actually be invisible in the final token objects if will remains a single token, but if subsequent rules were to split this token further, all its output tokens would have a start position of 2 and an end position of 4. While this example may seem unlikely, we have come across similar scenarios in fine-tuning actual REPP rules. 381 tance of 3543 (broadly comparable to CoreNLP, if marginally more accurate). Examining these discrepancies, we revealed some deficiencies in our rules, as well as some peculiarities of the ‘raw’ Wall Street Journal text from the PTB distribution. A little more than 200 mismatches were owed to improper treatment of currency symbols (AU$) and decade abbreviations (’60s), which led to the refinement of two existing rules. Notable PTB idiosyncrasies (in the sense of deviations from common typography) include ellipses with spaces separating the periods and a fairly large number of possessives (’s) being separated from their preceding token. Other aspects of gold-standard PTB tokenization we consider unwarranted ‘damage’ to the input text, such as hallucinating an extra period after U . S . and splitting cannot (which adds spurious ambiguity). For use cases where the goal were strict compliance, for instance in pre-processing inputs for a PTB-derived parser, we added an optional REPP module (of currently half a dozen rules) to cater to these corner cases—in a spirit similar to the CoreNLP mode we used in § 3. With these extra rules, remaining tokenization discrepancies are contained in 603 sentences (just over 1%), which gives a Levenshtein distance of 1389. 7 Discussion—Conclusion Compared to the best-performing off-the-shelf system in our earlier experiment (where it is reasonable to assume that PTB data has played at least some role in development), our results eliminate two thirds of the remaining tokenization errors—a more substantial reduction than recent improvements in parsing accuracy against the PTB, for example. Of the remaining differences, cerned with mid-sentence at least half of those riod was separated treebank—a pattern Some differences over 350 are con- period ambiguity, are instances where where from an abbreviation a pein the we do not wish to emulate. in quote disambiguation also re- main, often triggered by whitespace on both sides of quote marks in the raw text. The final 200 or so dif- ferences stem from manual corrections made during treebanking, and we consider that these cases could not be replicated automatically in any generalizable fashion. References Waldron, B., Copestake, A., Schäfer, U., & Kiefer, Ch(ionap-frgbpnt.heias1Ikt7nA,p3asEP–rs.1,oi8&cn0ieag;)J.todiaAohni dgnsfmonAroa,fxCbMethon.ermt,(pd42Uui30sStcraAd5ti.m)oA.niCanloutaLivrlsneMgr-eutorieas-ftni kceg-s Isd5Bota.hurlyd(2.scIne0itsne0ra6Dn)ad.Et LiPorvneHapl-ruIoaCNcteio snofin(elrpsge.nacIn2ed6Pot3rno–kcLe2naei6dns8iagnt)ui.oasgGnoe sfntRaohne-, Hovy, E., Marcus, M., Palmer, M., Ramshaw, L., & Weischedel, R. (2006). Ontonotes. The 90% solution. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (pp. 57–60). New York City, USA. Kaplan, R. M. (2005). A method for tokenizing text. Festschrift for Kimmo Koskenniemi on his 60th birthday. In A. Arppe, L. Carlson, K. Lindén, J. Piitulainen, M. Suominen, M. Vainio, H. Westerlund, & A. Yli-Jyrä (Eds.), Inquiries into words, constraints and contexts (pp. 55 64). Stanford, CA: CSLI Publications. – Levenshtein, V. (1966). Binary codes capable ofcor- recting deletions, insertions and reversals. Soviet Physice Doklady, 10, 707–710. – Marcus, M. P., Santorini, B., & Marcinkiewicz, M. A. (1993). Building a large annotated corpus of English. The Penn Treebank. Computational Linguistics, 19, 3 13 330. – Øvrelid, L., Velldal, E., & Oepen, S. (2010). Syntactic scope resolution in uncertainty analysis. In Proceedings of the 23rd international conference on computational linguistics (pp. 1379 1387). Beijing, China. – Schäfer, U., Kiefer, B., Spurk, C., Steffen, J., & Wang, R. (201 1). The ACL Anthology Searchbench. In Proceedings of the ACL-HLT 2011 system demonstrations (pp. 7–13). Portland, Oregon, USA. Tateisi, Y., & Tsujii, J. (2006). GENIA annotation guidelines for tokenization and POS tagging (Technical Report # TR-NLP-UT-2006-4). Tokyo, Japan: Tsujii Lab, University of Tokyo. 382</p><p>same-paper 3 0.82360411 <a title="102-lda-3" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>Author: Pradeep Dasigi ; Weiwei Guo ; Mona Diab</p><p>Abstract: We describe an unsupervised approach to the problem of automatically detecting subgroups of people holding similar opinions in a discussion thread. An intuitive way of identifying this is to detect the attitudes of discussants towards each other or named entities or topics mentioned in the discussion. Sentiment tags play an important role in this detection, but we also note another dimension to the detection of people’s attitudes in a discussion: if two persons share the same opinion, they tend to use similar language content. We consider the latter to be an implicit attitude. In this paper, we investigate the impact of implicit and explicit attitude in two genres of social media discussion data, more formal wikipedia discussions and a debate discussion forum that is much more informal. Experimental results strongly suggest that implicit attitude is an important complement for explicit attitudes (expressed via sentiment) and it can improve the sub-group detection performance independent of genre.</p><p>4 0.7408067 <a title="102-lda-4" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Pradeep Dasigi ; Mona Diab ; Dragomir Radev</p><p>Abstract: The rapid and continuous growth of social networking sites has led to the emergence of many communities of communicating groups. Many of these groups discuss ideological and political topics. It is not uncommon that the participants in such discussions split into two or more subgroups. The members of each subgroup share the same opinion toward the discussion topic and are more likely to agree with members of the same subgroup and disagree with members from opposing subgroups. In this paper, we propose an unsupervised approach for automatically detecting discussant subgroups in online communities. We analyze the text exchanged between the participants of a discussion to identify the attitude they carry toward each other and towards the various aspects of the discussion topic. We use attitude predictions to construct an attitude vector for each discussant. We use clustering techniques to cluster these vectors and, hence, determine the subgroup membership of each participant. We compare our methods to text clustering and other baselines, and show that our method achieves promising results.</p><p>5 0.73414928 <a title="102-lda-5" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: We present Subgroup Detector, a system for analyzing threaded discussions and identifying the attitude of discussants towards one another and towards the discussion topic. The system uses attitude predictions to detect the split of discussants into subgroups of opposing views. The system uses an unsupervised approach based on rule-based opinion target detecting and unsupervised clustering techniques. The system is open source and is freely available for download. An online demo of the system is available at: http://clair.eecs.umich.edu/SubgroupDetector/</p><p>6 0.72544318 <a title="102-lda-6" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<p>7 0.71662021 <a title="102-lda-7" href="./acl-2012-Extracting_Narrative_Timelines_as_Temporal_Dependency_Structures.html">90 acl-2012-Extracting Narrative Timelines as Temporal Dependency Structures</a></p>
<p>8 0.70400566 <a title="102-lda-8" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>9 0.68609792 <a title="102-lda-9" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>10 0.65433526 <a title="102-lda-10" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>11 0.64801776 <a title="102-lda-11" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>12 0.64220542 <a title="102-lda-12" href="./acl-2012-Event_Linking%3A_Grounding_Event_Reference_in_a_News_Archive.html">85 acl-2012-Event Linking: Grounding Event Reference in a News Archive</a></p>
<p>13 0.64188558 <a title="102-lda-13" href="./acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction.html">60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</a></p>
<p>14 0.63940018 <a title="102-lda-14" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>15 0.63776946 <a title="102-lda-15" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>16 0.63452804 <a title="102-lda-16" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>17 0.63129175 <a title="102-lda-17" href="./acl-2012-Learning_the_Latent_Semantics_of_a_Concept_from_its_Definition.html">132 acl-2012-Learning the Latent Semantics of a Concept from its Definition</a></p>
<p>18 0.63028246 <a title="102-lda-18" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>19 0.62951463 <a title="102-lda-19" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>20 0.62808138 <a title="102-lda-20" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
