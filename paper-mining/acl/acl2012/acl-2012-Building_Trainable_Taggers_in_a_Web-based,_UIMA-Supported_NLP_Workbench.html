<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-43" href="#">acl2012-43</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</h1>
<br/><p>Source: <a title="acl-2012-43-pdf" href="http://aclweb.org/anthology//P/P12/P12-3021.pdf">pdf</a></p><p>Author: Rafal Rak ; BalaKrishna Kolluru ; Sophia Ananiadou</p><p>Abstract: Argo is a web-based NLP and text mining workbench with a convenient graphical user interface for designing and executing processing workflows of various complexity. The workbench is intended for specialists and nontechnical audiences alike, and provides the ever expanding library of analytics compliant with the Unstructured Information Management Architecture, a widely adopted interoperability framework. We explore the flexibility of this framework by demonstrating workflows involving three processing components capable of performing self-contained machine learning-based tagging. The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated features, and 3) tagging unlabelled data with the model. The learning and tagging components are based on an implementation of conditional random fields (CRF); whereas the feature generation component is an analytic capable of extending basic token information to a comprehensive set of features. Users define the features of their choice directly from Argo’s graphical interface, without resorting to programming (a commonly used approach to feature engineering). The experimental results performed on two tagging tasks, chunking and named entity recognition, showed that a tagger with a generic set of features built in Argo is capable of competing with taskspecific solutions. 121</p><p>Reference: <a title="acl-2012-43-reference" href="../acl2012_reference/acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Building trainable taggers in a web-based, UIMA-supported NLP workbench Rafal Rak, BalaKrishna Kolluru and Sophia Ananiadou National Centre for Text Mining School of Computer Science, University of Manchester Manchester Interdisciplinary Biocentre 131 Princess St, M1 7DN, Manchester, UK {rafal . [sent-1, score-0.128]
</p><p>2 uk  Abstract Argo is a web-based NLP and text mining workbench with a convenient graphical user interface for designing and executing processing workflows of various complexity. [sent-6, score-0.571]
</p><p>3 The workbench is intended for specialists and nontechnical audiences alike, and provides the ever expanding library of analytics compliant with the Unstructured Information Management Architecture, a widely adopted interoperability framework. [sent-7, score-0.164]
</p><p>4 We explore the flexibility of this framework by demonstrating workflows involving three processing components capable of performing self-contained machine learning-based tagging. [sent-8, score-0.564]
</p><p>5 The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated  features, and 3) tagging unlabelled data with the model. [sent-9, score-0.292]
</p><p>6 The learning and tagging components are based on an implementation of conditional random fields (CRF); whereas the feature generation component is an analytic capable of extending basic token information to a comprehensive set of features. [sent-10, score-0.754]
</p><p>7 Users define the features of their choice directly from Argo’s graphical interface, without resorting to programming (a commonly used approach to feature engineering). [sent-11, score-0.25]
</p><p>8 The experimental results performed on two tagging tasks, chunking and named entity recognition, showed that a tagger with a generic set of features built in Argo is capable of competing with taskspecific solutions. [sent-12, score-0.43]
</p><p>9 121 1 Introduction The applications of automatic recognition of categories, or tagging, in natural language processing (NLP), range from part of speech tagging to chunking to named entity recognition and complex scientific discourse analyses. [sent-13, score-0.29]
</p><p>10 Currently, there is a variety  of tools capable of performing these tasks. [sent-14, score-0.127]
</p><p>11 Since the machine learning algorithms for building models are well established, the challenge shifted to feature engineering, i. [sent-16, score-0.114]
</p><p>12 We alleviate this problem by demonstrating Argo1, a web-based platform that allows the user to build NLP and other text analysis workflows via a graphical user interface (GUI) available in a web browser. [sent-20, score-0.569]
</p><p>13 The system is equipped with an ever growing library of text processing components ranging from low-level syntactic analysers to semantic annotators. [sent-21, score-0.209]
</p><p>14 It also allows for including user-interactive components, such as an annotation editor, into otherwise fully automatic workflows. [sent-22, score-0.08]
</p><p>15 The interoperability of processing components is ensured in Argo by adopting Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004) as  the system’s framework. [sent-23, score-0.272]
</p><p>16 c so2c0ia1t2io Ans fso rc Ciatoiomnp fuotart Cio nmaplu Ltiantgiounisatlic Lsi,n pgaugiestsi1c 2s1–126, learning components for tagging textual content. [sent-28, score-0.231]
</p><p>17 The details ofthe three machine learning components are discussed in Section 4. [sent-31, score-0.146]
</p><p>18 Section 5 provides evaluation, whereas Section 6 concludes the paper. [sent-32, score-0.051]
</p><p>19 2  Related work  Language processing tools with machine learning capabilities for tagging textual content have been distributed by various groups in form of either standalone applications or application programming interfaces (API). [sent-33, score-0.209]
</p><p>20 Packages such as Lingpipe2, Mallet3, Stanford NLP tools4 and OpenNLP5 have been extensively used by the NLP and text mining communities (Kolluru et al. [sent-34, score-0.041]
</p><p>21 However, such tools inherently impose inconveniences on users, such as a lack of GUI, often arduous manual installation procedures, proficiency in programming or familiarity with the details of machine learning algorithms. [sent-36, score-0.047]
</p><p>22 These limitations are overcome by GUI-equipped, workflow-supporting platforms that often directly use the solutions provided by the former tools. [sent-37, score-0.121]
</p><p>23 The notable examples of such platforms designed specifically for NLP and text mining tasks are GATE (Cunningham et al. [sent-38, score-0.107]
</p><p>24 , 2002), a suite of text processing and annotation tools, and U-Compare (Kano et al. [sent-39, score-0.08]
</p><p>25 , 2010), a standalone application supporting the UIMA framework that formed the inspiration for Argo. [sent-40, score-0.04]
</p><p>26 Although the GUI platforms provide machine learning solutions, these are usually limited to using pre-trained models and providing a rich set of features for training requires resorting to programming. [sent-41, score-0.176]
</p><p>27 Argo, on the other hand, allows the users to train their own models with either a generic set of features or customisable features without having to write a single line of code. [sent-42, score-0.248]
</p><p>28 3  Argo and UIMA  Argo’s main user interface consists of three panels  as shown in Figure 1. [sent-54, score-0.142]
</p><p>29 The left-hand panel includes user-owned or shared storable objects; the middle panel is a drawing space for constructing workflows and the right-hand panel displays context-dependent information. [sent-55, score-0.868]
</p><p>30 Component interoperability in Argo is ensured by UIMA which defines common structures and interfaces. [sent-57, score-0.126]
</p><p>31 A typical UIMA processing pipeline consists of a collection reader, a set of analysis engines and a consumer. [sent-58, score-0.047]
</p><p>32 The role of a collection reader is to fetch a resource (e. [sent-59, score-0.061]
</p><p>33 , a text document) and deposit it in a common annotation structure, or CAS, as the subject of annotation. [sent-61, score-0.121]
</p><p>34 Analysis engines then process the subject of annotation stored in the CAS and populate the CAS with their respective annotations. [sent-62, score-0.256]
</p><p>35 The consumer’s role is to transform some or all of the annotations and/or the subject of annotation from the  CAS and serialise it into some storable format. [sent-63, score-0.259]
</p><p>36 Readers, analysers and consumers are represented graphically in Argo as blocks with incoming only, incoming and outgoing, and outgoing only ports, respectively, visible in the middle of Figure 1. [sent-64, score-0.317]
</p><p>37 Figure 2: Two generic workflows demonstrating the use of the Feature Generator component for (a) training and (b) tagging. [sent-65, score-0.41]
</p><p>38 4  Machine learning components in Argo  In order to ensure flexibility in building workflows, we split the machine learning capability into three distinct processing components, namely feature generator, model trainer and tagger. [sent-66, score-0.561]
</p><p>39 The trainer and the tagger are intrinsic machine learning components, whereas the feature generator is a convenient and customisable processing component capable of building a feature space for a user-defined domain. [sent-67, score-0.989]
</p><p>40 From UIMA’s perspective, the feature generator and the tagger are both analysis engines whose purpose is to analyse the incoming CASes and enrich them with additional annotations; whereas the  trainer is a consumer that transforms the information stored in CASes into a statistical model. [sent-68, score-0.819]
</p><p>41 A typical use of the three components is shown in Figure 2. [sent-69, score-0.146]
</p><p>42 The three components are repre123 sented as the Feature Generator, CRF++ Trainer and CRF++ Tagger blocks. [sent-70, score-0.146]
</p><p>43 Figure 2a shows a process of building a statistical model supported by a document reader, common, well-established preprocessing components (in this case, to establish boundaries of sentences and tokens), and the previously mentioned editor for manually creating annotations6. [sent-71, score-0.232]
</p><p>44 The manual annotations serve to generate tags/labels which are used in the training process together with the features produced by Feature Generator. [sent-72, score-0.079]
</p><p>45 The trained model is then used in the workflow shown in Figure 2b to tag new resources. [sent-73, score-0.088]
</p><p>46 Although the tagging workflow automatically recognises the labels of interest (based on the model supplied in CRF++ Tagger), in practice, the labels need further correction, hence the use of Annotation Editor after the tagger. [sent-74, score-0.249]
</p><p>47 1 Training and tagging At present, our implementation of the training and tagging components is based on the conditional random fields (CRF) (Lafferty et al. [sent-76, score-0.375]
</p><p>48 Our choice is dictated by the fact that CRF models are currently one of the best models for tagging and efficient algorithms to compute marginal probabilities and n-best sequences are freely available. [sent-78, score-0.085]
</p><p>49 The trainer deals with the optimisation of feature parameters, whereas word observations are produced by Feature Generator, as described in the following section. [sent-80, score-0.463]
</p><p>50 2 From annotations to features The Feature Generator component is an intermediary between annotations stored in CASes and the training component. [sent-82, score-0.237]
</p><p>51 This component is customisable via the component’s settings panel, parts of which are shown in Figure 3. [sent-83, score-0.191]
</p><p>52 com/p/crfpp/ 8The definition of token depends on the selected UIMA annotation type. [sent-87, score-0.216]
</p><p>53 (a) Selecting a token annotation type  (b) Defining features Figure 3: Feature Generator settings panel allows the user to (a) select labels for machine learning and (b) define features. [sent-89, score-0.513]
</p><p>54 sentences), and 3) define features or token observations (Figure 3b). [sent-90, score-0.232]
</p><p>55 Each feature definition consists of a name, a token field, an optional list of token field transformations, and an optional set of context windows. [sent-91, score-0.482]
</p><p>56 The name is only for the user’s convenience of identifying individual feature definitions. [sent-92, score-0.115]
</p><p>57 The token field is the  primary subject of transformations (if any) and it is one of the data fields of the selected token annotation type. [sent-93, score-0.674]
</p><p>58 For instance, the token annotation type may define data fields such as part of speech, chunk, or lemma. [sent-94, score-0.275]
</p><p>59 , the span of text covered by an annotation, since this data field is available for any annotation. [sent-97, score-0.137]
</p><p>60 If no transformation is declared, the string rep124  Figure 4: UML diagram of transformation types  resentation of the token field’s value ultimately becomes the value of the generated feature. [sent-98, score-0.266]
</p><p>61 If the user declares one or more transformations then these are applied on the token field’s value in sequence, i. [sent-99, score-0.435]
</p><p>62 Figure 4 shows the various transformations currently available in the system. [sent-102, score-0.161]
</p><p>63 Context windows allow for enriching the current token’s feature set by introducing observations from surrounding tokens as n-grams. [sent-103, score-0.191]
</p><p>64 For example, the selected feature definition in Figure 3b, “surface has symbols”, declares the covered text as the feature’s basis and defines two transformations and two context windows. [sent-104, score-0.379]
</p><p>65 The two transformations will first transform the covered text to a collapsed shape (e. [sent-105, score-0.322]
</p><p>66 , “NF-kappa” will become “A#a”) and then produce “Y” or “N” depending on whether the collapsed shape matches the simple regular expression “#” (e. [sent-107, score-0.085]
</p><p>67 The two context windows define six unigrams and four bigrams, which will ultimately result in this single feature definition’s producing ten observations for training. [sent-110, score-0.194]
</p><p>68 5  Evaluation  We show the performance of taggers trained with two distinct sets of features, basic and extended. [sent-111, score-0.052]
</p><p>69 The basic set of features uses token fields such as the covered text and the part of speech without any transformations or context n-grams. [sent-112, score-0.519]
</p><p>70 The extended set makes the full use of Feature Generator’s settings and enriches the basic set with various transformations and context n-grams. [sent-113, score-0.253]
</p><p>71 The transformations in-  and IOB vs IOBES) on the chunking and NER tasks. [sent-114, score-0.328]
</p><p>72 68713  Table 2: Comparison of setups with basic and extended features for the chunking and NER tasks. [sent-119, score-0.415]
</p><p>73 The context n-grams include unigrams for all feature definitions and bigrams for selected ones. [sent-121, score-0.079]
</p><p>74 We use two datasets, one prepared for the CoNLL 2000 shared task (Tjong et al. [sent-123, score-0.086]
</p><p>75 , 2000) and another prepared for the BioNLP/NLPBA 2004 shared task (Kim et al. [sent-124, score-0.086]
</p><p>76 They represent two different tagging tasks, chunking and named entity recognition, respectively. [sent-126, score-0.21]
</p><p>77 The CoNLL 2000 chunking dataset involves 10 labels and comes pre-tokenised with 211,727 tokens in the training set and 47,377 tokens in the test set. [sent-127, score-0.265]
</p><p>78 The BioNLP/NLPBA 2004 named entity recognition dataset involves five biology-related labels and consists of 472,006 and 96,780 tokens in the training and testing sets, respectively. [sent-129, score-0.129]
</p><p>79 Contrary to the former dataset, there is  125 no other information supporting the tokens in the BioNLP/NLPBA dataset. [sent-130, score-0.051]
</p><p>80 Our goal is not to claim the superiority of our approach over the solutions reported in the respective shared tasks. [sent-133, score-0.137]
</p><p>81 Instead, we aim to show that our generic setup is comparable to those task-tuned solutions. [sent-134, score-0.053]
</p><p>82 We further explore the options of both Feature Generator and CRF++ Trainer by manipulating labelling formats (IOB vs IOBES (Kudo and Matsumoto, 2001)) for the former and parameter estimation algorithms (L2- vs L1-norm regularisation) for the latter. [sent-135, score-0.2]
</p><p>83 Ultimately, there are 32 setups as the result of the combinations of the two feature sets, the two datasets, the two labelling formats and the two estimation algorithms. [sent-136, score-0.358]
</p><p>84 1 Results Table 1 shows the precision, recall and f-scores of  our extended-feature setups against each other as well as with reference to the best and baseline solutions as reported in the respective shared tasks. [sent-138, score-0.3]
</p><p>85 The gap to the best performing solution for the chunking task is about 1. [sent-139, score-0.125]
</p><p>86 3% points in F-score, ahead of the baseline by 15. [sent-140, score-0.08]
</p><p>87 Respectively for the NER task, our best setup stands behind the best reported solution by about 7% points, ahead of the baseline by about 18% points. [sent-142, score-0.044]
</p><p>88 In both instances our solution would be placed in the middle of the reported rankings, which is a promising result, especially that our setups are based solely on the tokens’ surface form, part of speech, and (in the case of the NER task) chunk. [sent-143, score-0.203]
</p><p>89 In contrast, the best solutions for the NER task involve the use of dictionaries and advanced analyses such as acronym resolution. [sent-144, score-0.055]
</p><p>90 The tested combinations of the labelling formats and parameter estimation algorithms showed to be inconclusive, with a difference between the best and worst setups of only 0. [sent-145, score-0.279]
</p><p>91 The advantage of using the extended set of features over the basic set is clearly illustrated in Table 2. [sent-147, score-0.127]
</p><p>92 The performance of the basic set on the chunking dataset is only at the level of the baseline, whereas  for the NER task it falls nearly 6% points behind the  sation algorithm to converge. [sent-148, score-0.264]
</p><p>93 Table 3 shows the number of iterations9 needed for the optimisation algorithm of the trainer to converge. [sent-150, score-0.272]
</p><p>94 The advantage of the L1 regularisation is apparent with nearly two to five times less iterations needed when compared to the L2 regularisation. [sent-151, score-0.094]
</p><p>95 Given the close F-scores achieved by the two  family of setups, the L1 regularisation becomes a clear winner in our experimentation setup. [sent-152, score-0.094]
</p><p>96 6  Conclusions  Argo’s strength is manifested by its online availability, an intuitive graphical user interface available from a web browser, convenience in building even most complex text processing workflows, and the availability of trainable machine learning components. [sent-153, score-0.32]
</p><p>97 The Feature Generator component, customisable entirely through a GUI, provides the flexibility needed to extend the basic set of features without resorting to programming. [sent-154, score-0.334]
</p><p>98 As a reference we note that the workflows completed in 15 minutes to about 11 hours  depending on a feature space size and machine load. [sent-158, score-0.324]
</p><p>99 GATE: A framework and graphical development environment for robust NLP tools and applications. [sent-173, score-0.108]
</p><p>100 Automatic extraction of microorganisms and their habitats from free text using text mining workflows. [sent-212, score-0.041]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('argo', 0.438), ('workflows', 0.245), ('uima', 0.245), ('trainer', 0.218), ('generator', 0.204), ('setups', 0.163), ('transformations', 0.161), ('panel', 0.149), ('components', 0.146), ('token', 0.136), ('customisable', 0.125), ('chunking', 0.125), ('cas', 0.124), ('crf', 0.121), ('gui', 0.109), ('kolluru', 0.094), ('regularisation', 0.094), ('storable', 0.094), ('workflow', 0.088), ('tagging', 0.085), ('incoming', 0.082), ('interoperability', 0.082), ('workbench', 0.082), ('annotation', 0.08), ('capable', 0.08), ('ner', 0.08), ('feature', 0.079), ('covered', 0.076), ('user', 0.075), ('resorting', 0.075), ('interface', 0.067), ('component', 0.066), ('platforms', 0.066), ('analysers', 0.063), ('ananiadou', 0.063), ('corbett', 0.063), ('declares', 0.063), ('ferrucci', 0.063), ('iobes', 0.063), ('pathways', 0.063), ('rafal', 0.063), ('rak', 0.063), ('field', 0.061), ('observations', 0.061), ('graphical', 0.061), ('reader', 0.061), ('formats', 0.06), ('fields', 0.059), ('labelling', 0.056), ('solutions', 0.055), ('optimisation', 0.054), ('ultimately', 0.054), ('generic', 0.053), ('basic', 0.052), ('tagger', 0.052), ('tokens', 0.051), ('whereas', 0.051), ('manchester', 0.051), ('unstructured', 0.051), ('editor', 0.051), ('iob', 0.05), ('kano', 0.05), ('cunningham', 0.05), ('gate', 0.05), ('outgoing', 0.05), ('tjong', 0.05), ('shape', 0.049), ('stored', 0.048), ('engines', 0.047), ('flexibility', 0.047), ('tools', 0.047), ('trainable', 0.046), ('nlp', 0.046), ('demonstrating', 0.046), ('annotations', 0.044), ('ahead', 0.044), ('ensured', 0.044), ('prepared', 0.044), ('shared', 0.042), ('kudo', 0.042), ('vs', 0.042), ('mining', 0.041), ('subject', 0.041), ('extended', 0.04), ('middle', 0.04), ('respective', 0.04), ('standalone', 0.04), ('life', 0.04), ('recognition', 0.04), ('transformation', 0.038), ('consumer', 0.038), ('labels', 0.038), ('capabilities', 0.037), ('points', 0.036), ('capability', 0.036), ('collapsed', 0.036), ('convenience', 0.036), ('building', 0.035), ('features', 0.035), ('optional', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="43-tfidf-1" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>Author: Rafal Rak ; BalaKrishna Kolluru ; Sophia Ananiadou</p><p>Abstract: Argo is a web-based NLP and text mining workbench with a convenient graphical user interface for designing and executing processing workflows of various complexity. The workbench is intended for specialists and nontechnical audiences alike, and provides the ever expanding library of analytics compliant with the Unstructured Information Management Architecture, a widely adopted interoperability framework. We explore the flexibility of this framework by demonstrating workflows involving three processing components capable of performing self-contained machine learning-based tagging. The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated features, and 3) tagging unlabelled data with the model. The learning and tagging components are based on an implementation of conditional random fields (CRF); whereas the feature generation component is an analytic capable of extending basic token information to a comprehensive set of features. Users define the features of their choice directly from Argo’s graphical interface, without resorting to programming (a commonly used approach to feature engineering). The experimental results performed on two tagging tasks, chunking and named entity recognition, showed that a tagger with a generic set of features built in Argo is capable of competing with taskspecific solutions. 121</p><p>2 0.10147615 <a title="43-tfidf-2" href="./acl-2012-Efficient_Search_for_Transformation-based_Inference.html">78 acl-2012-Efficient Search for Transformation-based Inference</a></p>
<p>Author: Asher Stern ; Roni Stern ; Ido Dagan ; Ariel Felner</p><p>Abstract: This paper addresses the search problem in textual inference, where systems need to infer one piece of text from another. A prominent approach to this task is attempts to transform one text into the other through a sequence of inference-preserving transformations, a.k.a. a proof, while estimating the proof’s validity. This raises a search challenge of finding the best possible proof. We explore this challenge through a comprehensive investigation of prominent search algorithms and propose two novel algorithmic components specifically designed for textual inference: a gradient-style evaluation function, and a locallookahead node expansion method. Evaluations, using the open-source system, BIUTEE, show the contribution of these ideas to search efficiency and proof quality.</p><p>3 0.097553469 <a title="43-tfidf-3" href="./acl-2012-BIUTEE%3A_A_Modular_Open-Source_System_for_Recognizing_Textual_Entailment.html">36 acl-2012-BIUTEE: A Modular Open-Source System for Recognizing Textual Entailment</a></p>
<p>Author: Asher Stern ; Ido Dagan</p><p>Abstract: This paper introduces BIUTEE1 , an opensource system for recognizing textual entailment. Its main advantages are its ability to utilize various types of knowledge resources, and its extensibility by which new knowledge resources and inference components can be easily integrated. These abilities make BIUTEE an appealing RTE system for two research communities: (1) researchers of end applications, that can benefit from generic textual inference, and (2) RTE researchers, who can integrate their novel algorithms and knowledge resources into our system, saving the time and effort of developing a complete RTE system from scratch. Notable assistance for these re- searchers is provided by a visual tracing tool, by which researchers can refine and “debug” their knowledge resources and inference components.</p><p>4 0.08621075 <a title="43-tfidf-4" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>Author: Marcis Pinnis ; Radu Ion ; Dan Stefanescu ; Fangzhong Su ; Inguna Skadina ; Andrejs Vasiljevs ; Bogdan Babych</p><p>Abstract: The lack of parallel corpora and linguistic resources for many languages and domains is one of the major obstacles for the further advancement of automated translation. A possible solution is to exploit comparable corpora (non-parallel bi- or multi-lingual text resources) which are much more widely available than parallel translation data. Our presented toolkit deals with parallel content extraction from comparable corpora. It consists of tools bundled in two workflows: (1) alignment of comparable documents and extraction of parallel sentences and (2) extraction and bilingual mapping of terms and named entities. The toolkit pairs similar bilingual comparable documents and extracts parallel sentences and bilingual terminological and named entity dictionaries from comparable corpora. This demonstration focuses on the English, Latvian, Lithuanian, and Romanian languages.</p><p>5 0.083489843 <a title="43-tfidf-5" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>Author: Zhonghua Qu ; Yang Liu</p><p>Abstract: Online forums are becoming a popular resource in the state of the art question answering (QA) systems. Because of its nature as an online community, it contains more updated knowledge than other places. However, going through tedious and redundant posts to look for answers could be very time consuming. Most prior work focused on extracting only question answering sentences from user conversations. In this paper, we introduce the task of sentence dependency tagging. Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. Our experimental results show that our proposed approach performs well for sentence dependency tagging. This dependency information can benefit other tasks such as thread ranking and answer summarization in online forums.</p><p>6 0.081518359 <a title="43-tfidf-6" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>7 0.080225766 <a title="43-tfidf-7" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>8 0.071802355 <a title="43-tfidf-8" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>9 0.070479922 <a title="43-tfidf-9" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>10 0.068828993 <a title="43-tfidf-10" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>11 0.064120032 <a title="43-tfidf-11" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>12 0.063429415 <a title="43-tfidf-12" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>13 0.062757351 <a title="43-tfidf-13" href="./acl-2012-A_Web-based_Evaluation_Framework_for_Spatial_Instruction-Giving_Systems.html">24 acl-2012-A Web-based Evaluation Framework for Spatial Instruction-Giving Systems</a></p>
<p>14 0.061661586 <a title="43-tfidf-14" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>15 0.061292164 <a title="43-tfidf-15" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>16 0.060576461 <a title="43-tfidf-16" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>17 0.059537459 <a title="43-tfidf-17" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<p>18 0.056261979 <a title="43-tfidf-18" href="./acl-2012-A_Broad-Coverage_Normalization_System_for_Social_Media_Language.html">2 acl-2012-A Broad-Coverage Normalization System for Social Media Language</a></p>
<p>19 0.055683758 <a title="43-tfidf-19" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>20 0.054160461 <a title="43-tfidf-20" href="./acl-2012-Automatic_Event_Extraction_with_Structured_Preference_Modeling.html">33 acl-2012-Automatic Event Extraction with Structured Preference Modeling</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.166), (1, 0.053), (2, -0.05), (3, 0.018), (4, 0.042), (5, 0.146), (6, 0.065), (7, 0.018), (8, 0.017), (9, 0.048), (10, -0.056), (11, 0.051), (12, -0.037), (13, 0.0), (14, 0.05), (15, 0.044), (16, 0.025), (17, 0.045), (18, 0.078), (19, -0.089), (20, -0.026), (21, 0.06), (22, 0.002), (23, 0.063), (24, 0.025), (25, 0.074), (26, 0.0), (27, -0.02), (28, -0.01), (29, 0.152), (30, 0.121), (31, 0.027), (32, -0.012), (33, 0.031), (34, 0.013), (35, 0.158), (36, 0.056), (37, 0.02), (38, 0.065), (39, -0.133), (40, -0.005), (41, 0.073), (42, -0.027), (43, -0.107), (44, -0.105), (45, -0.016), (46, -0.074), (47, -0.063), (48, -0.123), (49, 0.155)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9252367 <a title="43-lsi-1" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>Author: Rafal Rak ; BalaKrishna Kolluru ; Sophia Ananiadou</p><p>Abstract: Argo is a web-based NLP and text mining workbench with a convenient graphical user interface for designing and executing processing workflows of various complexity. The workbench is intended for specialists and nontechnical audiences alike, and provides the ever expanding library of analytics compliant with the Unstructured Information Management Architecture, a widely adopted interoperability framework. We explore the flexibility of this framework by demonstrating workflows involving three processing components capable of performing self-contained machine learning-based tagging. The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated features, and 3) tagging unlabelled data with the model. The learning and tagging components are based on an implementation of conditional random fields (CRF); whereas the feature generation component is an analytic capable of extending basic token information to a comprehensive set of features. Users define the features of their choice directly from Argo’s graphical interface, without resorting to programming (a commonly used approach to feature engineering). The experimental results performed on two tagging tasks, chunking and named entity recognition, showed that a tagger with a generic set of features built in Argo is capable of competing with taskspecific solutions. 121</p><p>2 0.55287004 <a title="43-lsi-2" href="./acl-2012-WizIE%3A_A_Best_Practices_Guided_Development_Environment_for_Information_Extraction.html">215 acl-2012-WizIE: A Best Practices Guided Development Environment for Information Extraction</a></p>
<p>Author: Yunyao Li ; Laura Chiticariu ; Huahai Yang ; Frederick Reiss ; Arnaldo Carreno-fuentes</p><p>Abstract: Information extraction (IE) is becoming a critical building block in many enterprise applications. In order to satisfy the increasing text analytics demands of enterprise applications, it is crucial to enable developers with general computer science background to develop high quality IE extractors. In this demonstration, we present WizIE, an IE development environment intended to reduce the development life cycle and enable developers with little or no linguistic background to write high quality IE rules. WizI E provides an integrated wizard-like environment that guides IE developers step-by-step throughout the entire development process, based on best practices synthesized from the experience of expert developers. In addition, WizIE reduces the manual effort involved in performing key IE development tasks by offering automatic result explanation and rule discovery functionality. Preliminary results indicate that WizI E is a step forward towards enabling extractor development for novice IE developers.</p><p>3 0.51922339 <a title="43-lsi-3" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>Author: Andrea Gesmundo ; Tanja Samardzic</p><p>Abstract: We present a novel approach to the task of word lemmatisation. We formalise lemmatisation as a category tagging task, by describing how a word-to-lemma transformation rule can be encoded in a single label and how a set of such labels can be inferred for a specific language. In this way, a lemmatisation system can be trained and tested using any supervised tagging model. In contrast to previous approaches, the proposed technique allows us to easily integrate relevant contextual information. We test our approach on eight languages reaching a new state-of-the-art level for the lemmatisation task.</p><p>4 0.5053159 <a title="43-lsi-4" href="./acl-2012-BIUTEE%3A_A_Modular_Open-Source_System_for_Recognizing_Textual_Entailment.html">36 acl-2012-BIUTEE: A Modular Open-Source System for Recognizing Textual Entailment</a></p>
<p>Author: Asher Stern ; Ido Dagan</p><p>Abstract: This paper introduces BIUTEE1 , an opensource system for recognizing textual entailment. Its main advantages are its ability to utilize various types of knowledge resources, and its extensibility by which new knowledge resources and inference components can be easily integrated. These abilities make BIUTEE an appealing RTE system for two research communities: (1) researchers of end applications, that can benefit from generic textual inference, and (2) RTE researchers, who can integrate their novel algorithms and knowledge resources into our system, saving the time and effort of developing a complete RTE system from scratch. Notable assistance for these re- searchers is provided by a visual tracing tool, by which researchers can refine and “debug” their knowledge resources and inference components.</p><p>5 0.49046761 <a title="43-lsi-5" href="./acl-2012-Efficient_Search_for_Transformation-based_Inference.html">78 acl-2012-Efficient Search for Transformation-based Inference</a></p>
<p>Author: Asher Stern ; Roni Stern ; Ido Dagan ; Ariel Felner</p><p>Abstract: This paper addresses the search problem in textual inference, where systems need to infer one piece of text from another. A prominent approach to this task is attempts to transform one text into the other through a sequence of inference-preserving transformations, a.k.a. a proof, while estimating the proof’s validity. This raises a search challenge of finding the best possible proof. We explore this challenge through a comprehensive investigation of prominent search algorithms and propose two novel algorithmic components specifically designed for textual inference: a gradient-style evaluation function, and a locallookahead node expansion method. Evaluations, using the open-source system, BIUTEE, show the contribution of these ideas to search efficiency and proof quality.</p><p>6 0.47353801 <a title="43-lsi-6" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>7 0.44501194 <a title="43-lsi-7" href="./acl-2012-LetsMT%21%3A_Cloud-Based_Platform_for_Do-It-Yourself_Machine_Translation.html">138 acl-2012-LetsMT!: Cloud-Based Platform for Do-It-Yourself Machine Translation</a></p>
<p>8 0.44443113 <a title="43-lsi-8" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>9 0.44427913 <a title="43-lsi-9" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>10 0.44143066 <a title="43-lsi-10" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<p>11 0.4379518 <a title="43-lsi-11" href="./acl-2012-Discriminative_Strategies_to_Integrate_Multiword_Expression_Recognition_and_Parsing.html">75 acl-2012-Discriminative Strategies to Integrate Multiword Expression Recognition and Parsing</a></p>
<p>12 0.43442923 <a title="43-lsi-12" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>13 0.43097571 <a title="43-lsi-13" href="./acl-2012-Concept-to-text_Generation_via_Discriminative_Reranking.html">57 acl-2012-Concept-to-text Generation via Discriminative Reranking</a></p>
<p>14 0.42445022 <a title="43-lsi-14" href="./acl-2012-INPROwidth.3emiSS%3A_A_Component_for_Just-In-Time_Incremental_Speech_Synthesis.html">113 acl-2012-INPROwidth.3emiSS: A Component for Just-In-Time Incremental Speech Synthesis</a></p>
<p>15 0.41388452 <a title="43-lsi-15" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>16 0.37755251 <a title="43-lsi-16" href="./acl-2012-Tokenization%3A_Returning_to_a_Long_Solved_Problem__A_Survey%2C_Contrastive_Experiment%2C_Recommendations%2C_and_Toolkit_.html">197 acl-2012-Tokenization: Returning to a Long Solved Problem  A Survey, Contrastive Experiment, Recommendations, and Toolkit </a></p>
<p>17 0.37107503 <a title="43-lsi-17" href="./acl-2012-A_Computational_Approach_to_the_Automation_of_Creative_Naming.html">7 acl-2012-A Computational Approach to the Automation of Creative Naming</a></p>
<p>18 0.35986984 <a title="43-lsi-18" href="./acl-2012-A_Comprehensive_Gold_Standard_for_the_Enron_Organizational_Hierarchy.html">6 acl-2012-A Comprehensive Gold Standard for the Enron Organizational Hierarchy</a></p>
<p>19 0.34617952 <a title="43-lsi-19" href="./acl-2012-Structuring_E-Commerce_Inventory.html">186 acl-2012-Structuring E-Commerce Inventory</a></p>
<p>20 0.34231657 <a title="43-lsi-20" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(26, 0.516), (28, 0.021), (30, 0.012), (37, 0.021), (39, 0.043), (74, 0.027), (82, 0.019), (84, 0.014), (85, 0.024), (90, 0.122), (92, 0.046), (94, 0.014), (99, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92611843 <a title="43-lda-1" href="./acl-2012-Extracting_and_modeling_durations_for_habits_and_events_from_Twitter.html">91 acl-2012-Extracting and modeling durations for habits and events from Twitter</a></p>
<p>Author: Jennifer Williams ; Graham Katz</p><p>Abstract: We seek to automatically estimate typical durations for events and habits described in Twitter tweets. A corpus of more than 14 million tweets containing temporal duration information was collected. These tweets were classified as to their habituality status using a bootstrapped, decision tree. For each verb lemma, associated duration information was collected for episodic and habitual uses of the verb. Summary statistics for 483 verb lemmas and their typical habit and episode durations has been compiled and made available. This automatically generated duration information is broadly comparable to hand-annotation. 1</p><p>same-paper 2 0.89656699 <a title="43-lda-2" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>Author: Rafal Rak ; BalaKrishna Kolluru ; Sophia Ananiadou</p><p>Abstract: Argo is a web-based NLP and text mining workbench with a convenient graphical user interface for designing and executing processing workflows of various complexity. The workbench is intended for specialists and nontechnical audiences alike, and provides the ever expanding library of analytics compliant with the Unstructured Information Management Architecture, a widely adopted interoperability framework. We explore the flexibility of this framework by demonstrating workflows involving three processing components capable of performing self-contained machine learning-based tagging. The three components are responsible for the three distinct tasks of 1) generating observations or features, 2) training a statistical model based on the generated features, and 3) tagging unlabelled data with the model. The learning and tagging components are based on an implementation of conditional random fields (CRF); whereas the feature generation component is an analytic capable of extending basic token information to a comprehensive set of features. Users define the features of their choice directly from Argo’s graphical interface, without resorting to programming (a commonly used approach to feature engineering). The experimental results performed on two tagging tasks, chunking and named entity recognition, showed that a tagger with a generic set of features built in Argo is capable of competing with taskspecific solutions. 121</p><p>3 0.89492881 <a title="43-lda-3" href="./acl-2012-Unsupervised_Semantic_Role_Induction_with_Global_Role_Ordering.html">209 acl-2012-Unsupervised Semantic Role Induction with Global Role Ordering</a></p>
<p>Author: Nikhil Garg ; James Henserdon</p><p>Abstract: We propose a probabilistic generative model for unsupervised semantic role induction, which integrates local role assignment decisions and a global role ordering decision in a unified model. The role sequence is divided into intervals based on the notion of primary roles, and each interval generates a sequence of secondary roles and syntactic constituents using local features. The global role ordering consists of the sequence of primary roles only, thus making it a partial ordering.</p><p>4 0.83793235 <a title="43-lda-4" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>Author: Joseph Z. Chang ; Jason S. Chang ; Roger Jyh-Shing Jang</p><p>Abstract: Jason S. Chang Department of Computer Science, National Tsing Hua University 101, Kuangfu Road, Hsinchu, 300, Taiwan j s chang@ c s .nthu . edu .tw Jyh-Shing Roger Jang Department of Computer Science, National Tsing Hua University 101, Kuangfu Road, Hsinchu, 300, Taiwan j ang@ c s .nthu .edu .tw identifying such translation counterparts Web, we can cope with the OOV problem. In this paper, we present a new method on the for learning to finding translations and transliterations on the Web for a given term. The approach involves using a small set of terms and translations to obtain mixed-code snippets from a search engine, and automatically annotating the snippets with tags and features for training a conditional random field model. At runtime, the model is used to extracting translation candidates for a given term. Preliminary experiments and evaluation show our method cleanly combining various features, resulting in a system that outperforms previous work. 1</p><p>5 0.72516495 <a title="43-lda-5" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>Author: Micha Elsner ; Sharon Goldwater ; Jacob Eisenstein</p><p>Abstract: ILCC, School of Informatics School of Interactive Computing University of Edinburgh Georgia Institute of Technology Edinburgh, EH8 9AB, UK Atlanta, GA, 30308, USA (a) intended: /ju want w2n/ /want e kUki/ (b) surface: [j@ w a?P w2n] [wan @ kUki] During early language acquisition, infants must learn both a lexicon and a model of phonetics that explains how lexical items can vary in pronunciation—for instance “the” might be realized as [Di] or [D@]. Previous models of acquisition have generally tackled these problems in isolation, yet behavioral evidence suggests infants acquire lexical and phonetic knowledge simultaneously. We present a Bayesian model that clusters together phonetic variants of the same lexical item while learning both a language model over lexical items and a log-linear model of pronunciation variability based on articulatory features. The model is trained on transcribed surface pronunciations, and learns by bootstrapping, without access to the true lexicon. We test the model using a corpus of child-directed speech with realistic phonetic variation and either gold standard or automatically induced word boundaries. In both cases modeling variability improves the accuracy of the learned lexicon over a system that assumes each lexical item has a unique pronunciation.</p><p>6 0.55310458 <a title="43-lda-6" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>7 0.54830766 <a title="43-lda-7" href="./acl-2012-Classifying_French_Verbs_Using_French_and_English_Lexical_Resources.html">48 acl-2012-Classifying French Verbs Using French and English Lexical Resources</a></p>
<p>8 0.50040299 <a title="43-lda-8" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>9 0.48300385 <a title="43-lda-9" href="./acl-2012-A_Comparison_of_Chinese_Parsers_for_Stanford_Dependencies.html">5 acl-2012-A Comparison of Chinese Parsers for Stanford Dependencies</a></p>
<p>10 0.48212919 <a title="43-lda-10" href="./acl-2012-Error_Mining_on_Dependency_Trees.html">83 acl-2012-Error Mining on Dependency Trees</a></p>
<p>11 0.47918156 <a title="43-lda-11" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>12 0.47514081 <a title="43-lda-12" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>13 0.47191024 <a title="43-lda-13" href="./acl-2012-Joint_Inference_of_Named_Entity_Recognition_and_Normalization_for_Tweets.html">124 acl-2012-Joint Inference of Named Entity Recognition and Normalization for Tweets</a></p>
<p>14 0.47059831 <a title="43-lda-14" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>15 0.46887237 <a title="43-lda-15" href="./acl-2012-Modeling_the_Translation_of_Predicate-Argument_Structure_for_SMT.html">147 acl-2012-Modeling the Translation of Predicate-Argument Structure for SMT</a></p>
<p>16 0.46880424 <a title="43-lda-16" href="./acl-2012-Chinese_Comma_Disambiguation_for_Discourse_Analysis.html">47 acl-2012-Chinese Comma Disambiguation for Discourse Analysis</a></p>
<p>17 0.46658301 <a title="43-lda-17" href="./acl-2012-Using_Rejuvenation_to_Improve_Particle_Filtering_for_Bayesian_Word_Segmentation.html">211 acl-2012-Using Rejuvenation to Improve Particle Filtering for Bayesian Word Segmentation</a></p>
<p>18 0.46507758 <a title="43-lda-18" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>19 0.46470273 <a title="43-lda-19" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>20 0.46381059 <a title="43-lda-20" href="./acl-2012-Assessing_the_Effect_of_Inconsistent_Assessors_on_Summarization_Evaluation.html">29 acl-2012-Assessing the Effect of Inconsistent Assessors on Summarization Evaluation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
