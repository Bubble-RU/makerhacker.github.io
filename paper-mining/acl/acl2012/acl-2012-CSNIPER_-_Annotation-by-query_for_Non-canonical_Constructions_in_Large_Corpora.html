<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-44" href="#">acl2012-44</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</h1>
<br/><p>Source: <a title="acl-2012-44-pdf" href="http://aclweb.org/anthology//P/P12/P12-3015.pdf">pdf</a></p><p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>Reference: <a title="acl-2012-44-reference" href="../acl2012_reference/acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 CSNIPER Annotation-by-query for non-canonical constructions in large corpora Richard Eckart de Castilho, Iryna Gurevych Sabine Bartsch Ubiquitous Knowledge Processing Lab (UKP-TUDA) English linguistics  Department of Computer Science Technische Universit a¨t Darmstadt http : / /www . [sent-1, score-0.25]
</p><p>2 de Abstract We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. [sent-4, score-0.801]
</p><p>3 This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools. [sent-5, score-0.452]
</p><p>4 1 Introduction Linguistic annotation by means of automatic procedures, such as part-of-speech (POS) tagging, is a backbone of modern corpus linguistics; POS tagged corpora enhance the possibilities of corpus  query. [sent-6, score-0.314]
</p><p>5 However, many linguistic phenomena are not amenable to automatic annotation and are not readily identifiable on the basis of surface features. [sent-7, score-0.302]
</p><p>6 Non-canonical constructions (NCCs), which are the use-case of the tool presented in this paper, are a case in point. [sent-8, score-0.313]
</p><p>7 Yet, they warrant corpus study due to the relatively low frequency of individual instances, their deviation from canonical construction patterns and frequent ambiguity. [sent-10, score-0.2]
</p><p>8 Expert knowledge is thus required to reliably identify and annotate such phenomena in sufficiently large corpora like the 100 mil. [sent-12, score-0.106]
</p><p>9 This necessitates manual annotation which is time-consuming and  error-prone when carried out by individual linguists. [sent-17, score-0.158]
</p><p>10 The actual annotation step is deferred until after this evaluation in order to achieve high annotation confidence. [sent-22, score-0.316]
</p><p>11 1): Query development: Corpus queries can be developed and refined within the tool. [sent-24, score-0.104]
</p><p>12 Based on query results which are assessed and labeled by the user, queries can be systematically evaluated and refined for precision. [sent-25, score-0.592]
</p><p>13 c s 2o0c1ia2ti Aosns fo cria Ctio nm fpourta Ctoiomnpault Laitniognuaislt Licisn,g puaigsteiscs 85–90, relevance feedback, which is a common method of improving search results in information retrieval, to a linguistic corpus query system. [sent-28, score-0.414]
</p><p>14 Assessment: Query results are presented to the user as a list of sentences with optional additional context; the user assesses and labels each sentence as representing or not representing an instance of the linguistic phenomenon under study. [sent-29, score-0.35]
</p><p>15 The tool implements a function that allows the user to comment on decisions and to temporarily mark sentences with uncertain assessments for later review. [sent-30, score-0.465]
</p><p>16 1) It in-  tegrates with the query development by providing feedback to refine queries and improve query precision. [sent-32, score-0.764]
</p><p>17 3) It calculates the interrater agreement which is used in the corpus annotation step to ensure high annotation confidence. [sent-34, score-0.395]
</p><p>18 Corpus annotation: By assessing and labeling query results as correct or wrong, raters provide the tool with their annotation decisions. [sent-35, score-0.672]
</p><p>19 CSNIPER annotates the corpus with those annotation decisions that exceed a certain inter-rater agreement threshold. [sent-36, score-0.237]
</p><p>20 This annotation-by-query approach of querying, assessing, evaluating and annotating allows multiple distributed raters to incrementally improve query results and achieve high quality annotations. [sent-37, score-0.409]
</p><p>21 In this paper, we show how such an approach is well-suited for annotation tasks that require manual analysis over large corpora. [sent-38, score-0.158]
</p><p>22 The approach is generalizable to any kind of linguistic phenomena that can be located in corpora on the basis of queries and require manual assessment by multiple expert raters. [sent-39, score-0.581]
</p><p>23 2) and discuss why existing tools do not provide viable solutions (sect. [sent-41, score-0.147]
</p><p>24 2  Non-canonical grammatical constructions  The initial purpose of CSNIPER is the corpus-based study of so-called non-canonical grammatical constructions (NCC) (examples (2) - (5) below): 86 1. [sent-46, score-0.47]
</p><p>25 It was Reagan whom the media was now calling the frontrunner. [sent-49, score-0.154]
</p><p>26 It was the media who was now calling Reagan the frontrunner. [sent-51, score-0.154]
</p><p>27 It was now that the media were calling Reagan the frontrunner. [sent-53, score-0.154]
</p><p>28 (inversion) NCCs are linguistic constructions that deviate  in characteristic ways from the unmarked lexicogrammatical patterning and informational ordering in the sentence. [sent-56, score-0.288]
</p><p>29 This is exemplified by the constructions of sentences (2) - (5) above. [sent-57, score-0.266]
</p><p>30 While expressing the same propositional content, the order of information units available through the permissible grammatical constructions offers interesting insights into the constructional inventory of a language. [sent-58, score-0.273]
</p><p>31 It also opens up the possibility of comparing seemingly closely related languages in terms of the sets of available related constructions as well as the relations between instances of canonical and noncanonical constructions. [sent-59, score-0.402]
</p><p>32 , it-clefts are comprised of the following constituents:  sdubumjemcty itmatoin b veerbeclleemfteendtclause The NCCs under study pose interesting challenges both from a linguistic and a natural language processing perspective. [sent-63, score-0.087]
</p><p>33 Due to their deviation from  the canonical constructions, they come in a variety of potential construction patterns as exemplified above. [sent-64, score-0.227]
</p><p>34 Non-canonical constructions can be expected to be individually rarer in any given corpus than their canonical counterparts. [sent-65, score-0.302]
</p><p>35 A major task in recognizing NCCs is distinguishing them from structurally similar constructions with default logical and propositional content. [sent-68, score-0.239]
</p><p>36 Other issues arise in cases of true relative clauses as exemplified in (7) below: 6. [sent-70, score-0.149]
</p><p>37 The linguistic aim of our research is a comparison of non-canonical constructions in English and German. [sent-77, score-0.288]
</p><p>38 Therefore, multiple experts have to manually assess candidates in corpora. [sent-80, score-0.102]
</p><p>39 Our approach does not aim at the exhaustive annotation of all NCCs. [sent-81, score-0.158]
</p><p>40 The major goal is to improve the understanding of the linguistic properties and usage of NCCs. [sent-82, score-0.087]
</p><p>41 To address this, we exhaustively annotate a small part of the corpus and extrapolate the estimated number of total NCC candidates. [sent-86, score-0.079]
</p><p>42 In summary, the requirements for a tool to support multi-user annotation of NCCs are as follows: 1. [sent-87, score-0.297]
</p><p>43 querying large linguistically pre-processed corpora and query refinement 2. [sent-88, score-0.397]
</p><p>44 assessment of sentences that are true instances of NCCs in a multi-user setting 87 3. [sent-89, score-0.288]
</p><p>45 evaluation of inter-rater agreement and query precision In the following section, we review previous work to support linguistic annotation tasks. [sent-90, score-0.621]
</p><p>46 3  Related work  We differentiate three categories of linguistic tools which all partially fulfill our requirements: querying tools, annotation tools, and transformation tools. [sent-91, score-0.496]
</p><p>47 Linguistic query tools: Such tools allow to query  a corpus using linguistic features, e. [sent-92, score-0.85]
</p><p>48 Both tools provide powerful query engines designed for large linguistically annotated corpora. [sent-97, score-0.436]
</p><p>49 Both are server-based tools that can be used concurrently by multiple users. [sent-98, score-0.191]
</p><p>50 However, they do not allow to assess the query results. [sent-99, score-0.329]
</p><p>51 Linguistic annotation tools: Such tools allow the user to add linguistic annotations to a corpus. [sent-100, score-0.573]
</p><p>52 These tools typically display a full document for the user to annotate. [sent-102, score-0.286]
</p><p>53 As NCCs appear only occasionally in a text, such tools cannot be effectively applied to our task, as they offer no linguistic query capabilities to quickly locate potential NCCs in a large corpus. [sent-103, score-0.523]
</p><p>54 Linguistic transformation tools: Such tools allow the creation of annotations using transformation rules. [sent-104, score-0.306]
</p><p>55 A rule has the form category := pattern and creates new annotation of the type category on any part of a text matching pattern. [sent-107, score-0.192]
</p><p>56 A rule for the annotation  of passive clauses in the UAM CorpusTool could be passive-clause := clause + containing be% participle. [sent-108, score-0.185]
</p><p>57 These tools do not support the assessment of the results, though. [sent-109, score-0.36]
</p><p>58 In contrast to the querying tools, transformation tools are not specifically designed to operate efficiently on large corpora. [sent-110, score-0.251]
</p><p>59 4  CSNIPER  We present CSNIPER, an annotation tool for noncanonical constructions. [sent-112, score-0.325]
</p><p>60 If the sentence contains the NCC of interest, the user manually labels it as correct and otherwise wrong. [sent-116, score-0.151]
</p><p>61 Distributed multi-user setting Our web-based tool supports multiple users concurrently assessing query results. [sent-118, score-0.543]
</p><p>62 Each user can only see and edit their own assessments and has a personal query history. [sent-119, score-0.51]
</p><p>63 Evaluation The evaluation module provides information on assessments, number of annotated instances, query precision and inter-rater agreement. [sent-120, score-0.335]
</p><p>64 1 Implementation and data CSNIPER is implemented in Java and uses the CWB as its linguistic search engine (cf. [sent-122, score-0.087]
</p><p>65 Apache UIMA and DKPro Core2 are used for linguistic pre-processing, format conversion, and to drive the indexing of the corpora. [sent-127, score-0.087]
</p><p>66 2 Query (Figure 2) The user begins by selecting a ? [sent-131, score-0.112]
</p><p>67 6 Submit query button, the tool presents the user ? [sent-150, score-0.513]
</p><p>68 wi Sthu a KitW qIuCe yvie bwu toofn t,h teh query results (fig. [sent-151, score-0.289]
</p><p>69 At this point, the user may choose to 2http : / /www . [sent-153, score-0.112]
</p><p>70 de / re search/ current -pro j ect s / dkpro / 88 refine and re-run the query. [sent-156, score-0.159]
</p><p>71 As each user may use different queries, they will typically assess different sets of query results. [sent-157, score-0.441]
</p><p>72 This can yield a set of sentences labeled by a single user only. [sent-158, score-0.15]
</p><p>73 Therefore, the tool can display those sentences for assessment that other users have assessed, but the current user has not. [sent-159, score-0.51]
</p><p>74 This allows getting labels from all users for every NCC candidate. [sent-160, score-0.085]
</p><p>75 3 Assessment (Figure 3) If the query results match the expectation, the user can switch to the assessment mode by clicking the ? [sent-162, score-0.669]
</p><p>76 In addition, anAnnotationCandidateLabel record is created for each sentence to hold the assessment to be provided by the user. [sent-168, score-0.213]
</p><p>77 When the user is uncertain, the label check can be used to mark candidates for later review. [sent-172, score-0.174]
</p><p>78 f uArtllh changes are iimffimcuel-t diately saved to the database, so the user can stop assessing at any time and resume the process later. [sent-177, score-0.164]
</p><p>79 The proper assessment of a sentence as an in-  stance of a particular construction type sometimes depends on the context found in the preceding and following sentences. [sent-178, score-0.314]
</p><p>80 P dOisSp tags are shown in the sentence to facilitate query refinement. [sent-183, score-0.289]
</p><p>81 4 Evaluation (Figure 5) The evaluation function provides an overview of the current assessment state (fig. [sent-185, score-0.213]
</p><p>82 We support two evaluation views: by construction type and by query. [sent-187, score-0.101]
</p><p>83 Ainc candidate is disputed if it is not labeled consistently by  all selected users. [sent-198, score-0.11]
</p><p>84 A candidate is incompletely assessed if at least one of the selected users labeled it and at least one other did not. [sent-199, score-0.273]
</p><p>85 16 inter-rater agreement per type using Fleiss’ Kappa (Fleiss, 1971) are mtheen tm paeirn uses of this view. [sent-201, score-0.075]
</p><p>86 The inter-rater agreement is calculated using only candidates labeled by all selected users. [sent-202, score-0.141]
</p><p>87 By query: In this view, query precision and assessment completeness are calculated for a set of ? [sent-203, score-0.548]
</p><p>88 c Tahnedi qduaetersy as:  precision =|TP||T +P ||FP| We treat a candidate as a true positive (TP) if: 1) the number of correct labels is larger than the number of wrong labels; 2) the ratio of correct labels compared to the number of raters exceeds a given ? [sent-210, score-0.269]
</p><p>89 Candidates are conversely treated as false positives (FPs) iaft tehse a nreum cobnevr orsfe wrong ltaedbe alss is larger and the threshold is exceeded. [sent-212, score-0.112]
</p><p>90 The estimated precision is the precision to be expected if TP and FP are equally distributed over the set of candidates. [sent-219, score-0.151]
</p><p>91 Both values are the same once all candidates have been labeled by all users. [sent-221, score-0.1]
</p><p>92 5 Annotation When the assessment process is complete, corpus annotations can be generated from the assessed candidates. [sent-223, score-0.454]
</p><p>93 Alternatively, a file with all assessed candidates can be generated to serve as training data for identification methods based on machine learning. [sent-229, score-0.196]
</p><p>94 Our tool integrates the complete functionality needed for the annotation-by-query workflow. [sent-231, score-0.144]
</p><p>95 The feedback provided by the integrated evaluation module can be used to systematically refine queries and improve assessments. [sent-233, score-0.213]
</p><p>96 Figure  5: Evaluation  by query and by NCC type  The annotation-by-query approach can be generalized beyond non-canonical constructions to other linguistic phenomena with similar properties. [sent-235, score-0.668]
</p><p>97 We plan to integrate further automatic annotations and query possibilities to support such further use-cases. [sent-237, score-0.389]
</p><p>98 Data cited herein have been extracted from the British National Corpus, distributed by Oxford University Com-  puting Services on behalf of the BNC Consortium. [sent-241, score-0.103]
</p><p>99 A modular and flexible architecture for an integrated corpus query system. [sent-255, score-0.327]
</p><p>100 The UAM CorpusTool: Software for corpus annotation and exploration. [sent-277, score-0.196]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('csniper', 0.383), ('nccs', 0.301), ('query', 0.289), ('ncc', 0.246), ('bnc', 0.218), ('assessment', 0.213), ('constructions', 0.201), ('annotation', 0.158), ('tools', 0.147), ('assessed', 0.134), ('reagan', 0.119), ('tool', 0.112), ('user', 0.112), ('dkpro', 0.109), ('assessments', 0.109), ('tp', 0.105), ('queries', 0.104), ('calling', 0.096), ('linguistic', 0.087), ('corpustool', 0.082), ('uam', 0.082), ('fp', 0.081), ('uima', 0.072), ('adt', 0.072), ('disputed', 0.072), ('unk', 0.072), ('expert', 0.071), ('annotations', 0.069), ('construction', 0.067), ('exemplified', 0.065), ('canonical', 0.063), ('candidates', 0.062), ('raters', 0.061), ('querying', 0.059), ('distributed', 0.059), ('media', 0.058), ('positives', 0.058), ('phenomena', 0.057), ('implements', 0.056), ('clicking', 0.055), ('almer', 0.055), ('castilho', 0.055), ('cwb', 0.055), ('darmstadt', 0.055), ('eckart', 0.055), ('gscl', 0.055), ('incompletely', 0.055), ('kluegl', 0.055), ('kwic', 0.055), ('noncanonical', 0.055), ('technische', 0.055), ('textmarker', 0.055), ('zeldes', 0.055), ('wrong', 0.054), ('british', 0.053), ('assessing', 0.052), ('refine', 0.05), ('corpora', 0.049), ('precision', 0.046), ('users', 0.046), ('instances', 0.045), ('transformation', 0.045), ('concurrently', 0.044), ('cited', 0.044), ('agreement', 0.041), ('exhaustively', 0.041), ('fleiss', 0.041), ('assess', 0.04), ('labels', 0.039), ('labeled', 0.038), ('comment', 0.038), ('uncertain', 0.038), ('propositional', 0.038), ('seemingly', 0.038), ('uller', 0.038), ('services', 0.038), ('corpus', 0.038), ('view', 0.036), ('la', 0.036), ('hard', 0.034), ('apache', 0.034), ('type', 0.034), ('grammatical', 0.034), ('functionality', 0.032), ('oxford', 0.032), ('deviation', 0.032), ('universit', 0.032), ('feedback', 0.032), ('sabine', 0.031), ('christian', 0.031), ('possibilities', 0.031), ('true', 0.03), ('consortium', 0.03), ('psychological', 0.029), ('examples', 0.029), ('requirements', 0.027), ('systematically', 0.027), ('display', 0.027), ('clauses', 0.027), ('issues', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="44-tfidf-1" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>2 0.15830116 <a title="44-tfidf-2" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>Author: Kuzman Ganchev ; Keith Hall ; Ryan McDonald ; Slav Petrov</p><p>Abstract: Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult. We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time. Unlike previous work, our final model does not require any additional resources at run-time. Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction. Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.</p><p>3 0.15414034 <a title="44-tfidf-3" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>4 0.11241624 <a title="44-tfidf-4" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance. In this paper, we propose a method to estimate sense distributions for short queries. Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations. Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system, we obtain significant improvements over a state-of-the-art IR system.</p><p>5 0.083456434 <a title="44-tfidf-5" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>6 0.081518359 <a title="44-tfidf-6" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>7 0.072548546 <a title="44-tfidf-7" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>8 0.055508588 <a title="44-tfidf-8" href="./acl-2012-The_Creation_of_a_Corpus_of_English_Metalanguage.html">195 acl-2012-The Creation of a Corpus of English Metalanguage</a></p>
<p>9 0.055183787 <a title="44-tfidf-9" href="./acl-2012-Crowdsourcing_Inference-Rule_Evaluation.html">65 acl-2012-Crowdsourcing Inference-Rule Evaluation</a></p>
<p>10 0.05487936 <a title="44-tfidf-10" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>11 0.053245757 <a title="44-tfidf-11" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>12 0.05246881 <a title="44-tfidf-12" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>13 0.051553193 <a title="44-tfidf-13" href="./acl-2012-PDTB-style_Discourse_Annotation_of_Chinese_Text.html">157 acl-2012-PDTB-style Discourse Annotation of Chinese Text</a></p>
<p>14 0.049381744 <a title="44-tfidf-14" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<p>15 0.049279783 <a title="44-tfidf-15" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>16 0.048910372 <a title="44-tfidf-16" href="./acl-2012-Collective_Generation_of_Natural_Image_Descriptions.html">51 acl-2012-Collective Generation of Natural Image Descriptions</a></p>
<p>17 0.04850968 <a title="44-tfidf-17" href="./acl-2012-Entailment-based_Text_Exploration_with_Application_to_the_Health-care_Domain.html">82 acl-2012-Entailment-based Text Exploration with Application to the Health-care Domain</a></p>
<p>18 0.04817139 <a title="44-tfidf-18" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>19 0.047353819 <a title="44-tfidf-19" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<p>20 0.046585094 <a title="44-tfidf-20" href="./acl-2012-A_Web-based_Evaluation_Framework_for_Spatial_Instruction-Giving_Systems.html">24 acl-2012-A Web-based Evaluation Framework for Spatial Instruction-Giving Systems</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.148), (1, 0.07), (2, -0.028), (3, 0.057), (4, 0.065), (5, 0.125), (6, 0.027), (7, 0.017), (8, -0.035), (9, 0.019), (10, 0.072), (11, 0.108), (12, 0.016), (13, 0.086), (14, 0.028), (15, -0.124), (16, 0.01), (17, -0.001), (18, 0.049), (19, -0.117), (20, 0.038), (21, 0.194), (22, 0.128), (23, 0.035), (24, -0.025), (25, -0.073), (26, 0.182), (27, 0.051), (28, -0.007), (29, 0.024), (30, 0.013), (31, 0.024), (32, 0.086), (33, 0.005), (34, -0.034), (35, 0.084), (36, -0.052), (37, -0.064), (38, -0.037), (39, -0.027), (40, 0.096), (41, 0.017), (42, 0.008), (43, -0.05), (44, 0.057), (45, -0.021), (46, 0.034), (47, 0.031), (48, -0.106), (49, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96886367 <a title="44-lsi-1" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>2 0.78489345 <a title="44-lsi-2" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>Author: Kuzman Ganchev ; Keith Hall ; Ryan McDonald ; Slav Petrov</p><p>Abstract: Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult. We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time. Unlike previous work, our final model does not require any additional resources at run-time. Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction. Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.</p><p>3 0.76210988 <a title="44-lsi-3" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>Author: Patrick Pantel ; Thomas Lin ; Michael Gamon</p><p>Abstract: We predict entity type distributions in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model the interplay between latent user intents that govern queries and unobserved entity types, leveraging observed signals from query formulations and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over the state ofthe art, on several metrics, without degradation in tail query performance.</p><p>4 0.65428925 <a title="44-lsi-4" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>5 0.52246201 <a title="44-lsi-5" href="./acl-2012-Ecological_Evaluation_of_Persuasive_Messages_Using_Google_AdWords.html">77 acl-2012-Ecological Evaluation of Persuasive Messages Using Google AdWords</a></p>
<p>Author: Marco Guerini ; Carlo Strapparava ; Oliviero Stock</p><p>Abstract: In recent years there has been a growing interest in crowdsourcing methodologies to be used in experimental research for NLP tasks. In particular, evaluation of systems and theories about persuasion is difficult to accommodate within existing frameworks. In this paper we present a new cheap and fast methodology that allows fast experiment building and evaluation with fully-automated analysis at a low cost. The central idea is exploiting existing commercial tools for advertising on the web, such as Google AdWords, to measure message impact in an ecological setting. The paper includes a description of the approach, tips for how to use AdWords for scientific research, and results of pilot experiments on the impact of affective text variations which confirm the effectiveness of the approach.</p><p>6 0.51456332 <a title="44-lsi-6" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>7 0.48464897 <a title="44-lsi-7" href="./acl-2012-Word_Sense_Disambiguation_Improves_Information_Retrieval.html">217 acl-2012-Word Sense Disambiguation Improves Information Retrieval</a></p>
<p>8 0.47386491 <a title="44-lsi-8" href="./acl-2012-WizIE%3A_A_Best_Practices_Guided_Development_Environment_for_Information_Extraction.html">215 acl-2012-WizIE: A Best Practices Guided Development Environment for Information Extraction</a></p>
<p>9 0.41890845 <a title="44-lsi-9" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>10 0.38992837 <a title="44-lsi-10" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>11 0.3893086 <a title="44-lsi-11" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<p>12 0.37932691 <a title="44-lsi-12" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>13 0.36255601 <a title="44-lsi-13" href="./acl-2012-Automatically_Learning_Measures_of_Child_Language_Development.html">34 acl-2012-Automatically Learning Measures of Child Language Development</a></p>
<p>14 0.36078551 <a title="44-lsi-14" href="./acl-2012-DOMCAT%3A_A_Bilingual_Concordancer_for_Domain-Specific_Computer_Assisted_Translation.html">66 acl-2012-DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation</a></p>
<p>15 0.34972781 <a title="44-lsi-15" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>16 0.33571407 <a title="44-lsi-16" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>17 0.33557221 <a title="44-lsi-17" href="./acl-2012-Learning_to_Find_Translations_and_Transliterations_on_the_Web.html">134 acl-2012-Learning to Find Translations and Transliterations on the Web</a></p>
<p>18 0.33050966 <a title="44-lsi-18" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<p>19 0.32470912 <a title="44-lsi-19" href="./acl-2012-LetsMT%21%3A_Cloud-Based_Platform_for_Do-It-Yourself_Machine_Translation.html">138 acl-2012-LetsMT!: Cloud-Based Platform for Do-It-Yourself Machine Translation</a></p>
<p>20 0.32199958 <a title="44-lsi-20" href="./acl-2012-Demonstration_of_IlluMe%3A_Creating_Ambient_According_to_Instant_Message_Logs.html">70 acl-2012-Demonstration of IlluMe: Creating Ambient According to Instant Message Logs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.043), (26, 0.043), (28, 0.033), (30, 0.036), (32, 0.284), (37, 0.026), (39, 0.057), (49, 0.015), (59, 0.016), (74, 0.031), (82, 0.024), (84, 0.03), (85, 0.037), (90, 0.117), (92, 0.05), (99, 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84055626 <a title="44-lda-1" href="./acl-2012-The_OpenGrm_open-source_finite-state_grammar_software_libraries.html">196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</a></p>
<p>Author: Brian Roark ; Richard Sproat ; Cyril Allauzen ; Michael Riley ; Jeffrey Sorensen ; Terry Tai</p><p>Abstract: In this paper, we present a new collection of open-source software libraries that provides command line binary utilities and library classes and functions for compiling regular expression and context-sensitive rewrite rules into finite-state transducers, and for n-gram language modeling. The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models.</p><p>same-paper 2 0.7963258 <a title="44-lda-2" href="./acl-2012-CSNIPER_-_Annotation-by-query_for_Non-canonical_Constructions_in_Large_Corpora.html">44 acl-2012-CSNIPER - Annotation-by-query for Non-canonical Constructions in Large Corpora</a></p>
<p>Author: Richard Eckart de Castilho ; Sabine Bartsch ; Iryna Gurevych</p><p>Abstract: We present CSNIPER (Corpus Sniper), a tool that implements (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on linguistic queries and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena that are hard to identify by means of existing automatic annotation tools.</p><p>3 0.50574827 <a title="44-lda-3" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>Author: Gerard de Melo ; Gerhard Weikum</p><p>Abstract: We present UWN, a large multilingual lexical knowledge base that describes the meanings and relationships of words in over 200 languages. This paper explains how link prediction, information integration and taxonomy induction methods have been used to build UWN based on WordNet and extend it with millions of named entities from Wikipedia. We additionally introduce extensions to cover lexical relationships, frame-semantic knowledge, and language data. An online interface provides human access to the data, while a software API enables applications to look up over 16 million words and names.</p><p>4 0.50393623 <a title="44-lda-4" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>5 0.50076687 <a title="44-lda-5" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<p>Author: Remy Kessler ; Xavier Tannier ; Caroline Hagege ; Veronique Moriceau ; Andre Bittar</p><p>Abstract: We present an approach for detecting salient (important) dates in texts in order to automatically build event timelines from a search query (e.g. the name of an event or person, etc.). This work was carried out on a corpus of newswire texts in English provided by the Agence France Presse (AFP). In order to extract salient dates that warrant inclusion in an event timeline, we first recognize and normalize temporal expressions in texts and then use a machine-learning approach to extract salient dates that relate to a particular topic. We focused only on extracting the dates and not the events to which they are related.</p><p>6 0.49900839 <a title="44-lda-6" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>7 0.49589625 <a title="44-lda-7" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>8 0.49564496 <a title="44-lda-8" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>9 0.4954755 <a title="44-lda-9" href="./acl-2012-Learning_Syntactic_Verb_Frames_using_Graphical_Models.html">130 acl-2012-Learning Syntactic Verb Frames using Graphical Models</a></p>
<p>10 0.49492997 <a title="44-lda-10" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>11 0.49447882 <a title="44-lda-11" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>12 0.49394643 <a title="44-lda-12" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>13 0.49394631 <a title="44-lda-13" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>14 0.49351227 <a title="44-lda-14" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>15 0.49332213 <a title="44-lda-15" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>16 0.49328834 <a title="44-lda-16" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>17 0.4926534 <a title="44-lda-17" href="./acl-2012-Detecting_Semantic_Equivalence_and_Information_Disparity_in_Cross-lingual_Documents.html">72 acl-2012-Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents</a></p>
<p>18 0.49216437 <a title="44-lda-18" href="./acl-2012-BIUTEE%3A_A_Modular_Open-Source_System_for_Recognizing_Textual_Entailment.html">36 acl-2012-BIUTEE: A Modular Open-Source System for Recognizing Textual Entailment</a></p>
<p>19 0.49154037 <a title="44-lda-19" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>20 0.49135572 <a title="44-lda-20" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
