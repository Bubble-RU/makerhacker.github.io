<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-177" href="#">acl2012-177</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</h1>
<br/><p>Source: <a title="acl-2012-177-pdf" href="http://aclweb.org/anthology//P/P12/P12-1058.pdf">pdf</a></p><p>Author: Zhonghua Qu ; Yang Liu</p><p>Abstract: Online forums are becoming a popular resource in the state of the art question answering (QA) systems. Because of its nature as an online community, it contains more updated knowledge than other places. However, going through tedious and redundant posts to look for answers could be very time consuming. Most prior work focused on extracting only question answering sentences from user conversations. In this paper, we introduce the task of sentence dependency tagging. Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. Our experimental results show that our proposed approach performs well for sentence dependency tagging. This dependency information can benefit other tasks such as thread ranking and answer summarization in online forums.</p><p>Reference: <a title="acl-2012-177-reference" href="../acl2012_reference/acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Sentence Dependency Tagging in Online Question Answering Forums Zhonghua Qu and Yang Liu The University of Texas at Dallas  ,  {qzh yangl @ hlt Abstract Online forums are becoming a popular resource in the state of the art question answering (QA) systems. [sent-1, score-0.528]
</p><p>2 Most prior work focused on extracting only question answering sentences from user conversations. [sent-4, score-0.489]
</p><p>3 In this paper, we introduce the task of sentence dependency tagging. [sent-5, score-0.499]
</p><p>4 Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. [sent-6, score-0.671]
</p><p>5 We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. [sent-7, score-0.868]
</p><p>6 Our experimental results show that our proposed approach performs well for sentence dependency tagging. [sent-8, score-0.499]
</p><p>7 This dependency information can  benefit other tasks such as thread ranking and answer summarization in online forums. [sent-9, score-0.726]
</p><p>8 Question answering forums, such as technical support forums, are places where users find answers through conversations. [sent-11, score-0.407]
</p><p>9 Because of their nature as online communities, question answering forums provide more updated answers to new problems. [sent-12, score-0.796]
</p><p>10 However, unlike other structured knowledge bases, often it is not straightforward to extract information such as questions and answers in online forums because such information spreads in the conversations among multiple users in a thread. [sent-16, score-0.654]
</p><p>11 A lot of previous work has focused on extract-  ing the question and answer sentences from forum threads. [sent-17, score-0.679]
</p><p>12 However, there is much richer information in forum conversations, and simply knowing a sentence is a question or answer is not enough. [sent-18, score-0.863]
</p><p>13 Usually several candidate answers are provided, and not all answers are useful. [sent-21, score-0.384]
</p><p>14 Each sentence is labeled with its type (a detailed description of sentence types is provided Table 1). [sent-24, score-0.758]
</p><p>15 We can see from the example that questions and answers are not expressed in a single sentence or a single post. [sent-25, score-0.535]
</p><p>16 Only identifying question and answering sentences from the thread is not enough for automatic question answering. [sent-26, score-0.928]
</p><p>17 For this example, in order to get the complete question, we would need to know that sentence S3 is a question that inquires for more details about the problem asked earlier, instead of stating its own question. [sent-27, score-0.487]
</p><p>18 Also, sentence S5 should not be included in the correct answer since it is not a working solution, which is indicated by a negative feedback in sentence S6. [sent-28, score-0.808]
</p><p>19 We define that there is a dependency between a pair of sentences if one sentence ProceedJienjgus, R ofep thueb 5lic0t hof A Knonrueaa,l M 8-e1e4ti Jnugly o f2 t0h1e2 A. [sent-30, score-0.64]
</p><p>20 For example, question context sentences exist because ofthe question itself; an answering sentence exists because of a question; or a feedback sentence exists because of an answer. [sent-33, score-1.396]
</p><p>21 The sentence dependency structure of this example dialog is shown in Figure 2. [sent-34, score-0.62]
</p><p>22 S 52189: AMCP - GSPGOTRALSUET S63:MA-NIEQGUAS74:AQ-SCOLRFU Figure 2: Dependency Structure of the Above Example This example shows that in order to extract information from QA forums accurately, we need to understand the sentence dependency structure of a QA thread. [sent-35, score-0.714]
</p><p>23 Towards this goal, in this paper, we define two tasks: labeling the types for sentences, and  finding the dependency relations between sentences. [sent-36, score-0.473]
</p><p>24 For the first task of sentence type labeling, we define a rich set of categories representing the purpose 555 of the sentences. [sent-37, score-0.469]
</p><p>25 However, other relations can also be useful for information extraction from online threads, such as user’s feedbacks on the answers, problem detail inquiry and question clarifications. [sent-41, score-0.435]
</p><p>26 In this study, we use two approaches for labeling of dependency relation between sentences. [sent-42, score-0.399]
</p><p>27 First each sentence is considered as a source, and we run a linear-chain CRF to label whether each of the other sentences is its target. [sent-43, score-0.411]
</p><p>28 Our experimental results show that our proposed sentence type tagging method works very well, even for the minority categories, and that using 2D CRF further improves performance over linear-chain CRFs for identifying dependency relation between sentences. [sent-46, score-0.907]
</p><p>29 In the following section, we discuss related work on finding questions and answers in online environment as well as some dialog act tagging techniques. [sent-48, score-0.697]
</p><p>30 In Section 3, we introduce the use of CRFs for sentence type and dependency tagging. [sent-49, score-0.6]
</p><p>31 In Section 5, we show that our approach achieves promising results in thread sentence dependency tagging. [sent-51, score-0.752]
</p><p>32 This knowledge source could substantially help automatic question answering systems. [sent-54, score-0.439]
</p><p>33 There has been some previous work  focusing on the extraction of question and corresponding answer pairs in online forums. [sent-55, score-0.461]
</p><p>34 An approach using email structure to detect and summarize question answer pairs was introduced in (Shrestha and Mckeown, 2004). [sent-60, score-0.457]
</p><p>35 These studies focused primarily on finding questions and answers in an online environment. [sent-61, score-0.377]
</p><p>36 In this paper, in order to provide a better foundation for question answer detection in online forums, we investigate tagging sentences with a much richer set of categories, as well as identifying their dependency relationships. [sent-62, score-0.983]
</p><p>37 The sentence types we use are similar to dialog acts (DA), but defined specifically for question answering forums. [sent-63, score-0.787]
</p><p>38 Our study is different in several aspects: we are using forum domains, unlike most work of DA tagging on conversational speech; we use CRFs for sentence type tagging; and more importantly, we also propose to use different CRFs for sentence relation detection. [sent-69, score-1.12]
</p><p>39 3  Thread Structure Tagging  As described earlier, we decompose the structure analysis of QA threads into two tasks, first determine the sentence type, and then identify related sentences. [sent-72, score-0.458]
</p><p>40 Different sets of 556 DAs have been adopted in various studies, ranging from very coarse categories to fine grained ones. [sent-76, score-0.409]
</p><p>41 In this study, we define 13 fine grained sentence types (corresponding to 4 coarse categories) tailored to our domain of QA forum threads. [sent-77, score-0.804]
</p><p>42 These sentence types can be grouped into 4 coarse categories, as shown in Table 1. [sent-84, score-0.425]
</p><p>43 TypesCategoryDescription  To automatically label sentences in a thread with their types, we adopt a sequence labeling approach, specifically linear-chain conditional random fields (CRFs), which have shown good performance in many other tasks (Lafferty, 2001). [sent-85, score-0.664]
</p><p>44 For example, in our data set, 45% sentences follow-  ing a greeting sentence (M-GRET) are question related sentences; 53% sentences following a question inquiry sentence (Q-INQ) are solution related sentences. [sent-87, score-1.333]
</p><p>45 The following describes our modeling approaches and features used for sentence type tagging. [sent-88, score-0.404]
</p><p>46 In our case of sentence tagging, cliques only contain two adjacent sentences. [sent-100, score-0.491]
</p><p>47 2  Sentence Type Tagging Features  We used various types of feature functions in sentence type tagging. [sent-120, score-0.518]
</p><p>48 For example, the presence of a question mark indicates that a sentence may be a question or inquiry. [sent-126, score-0.738]
</p><p>49 Since technical forums tend to contain many system outputs, we include the perplexity of the sentence as a feature which is calculated based on a background language model (LM) learned from common English documents. [sent-128, score-0.591]
</p><p>50 Furthermore, we add features to represent post level information to account for the structure of QA threads, for example, whether or not a sentence belongs to the author’s post, or if a sentence is the beginning sentence of a post. [sent-130, score-0.974]
</p><p>51 2 Sentence Dependency Tagging Knowing only the sentence types without their dependency relations is not enough for question answering tasks. [sent-132, score-0.973]
</p><p>52 For example, correct labeling of an answer without knowing which question it actually refers to is problematic; not knowing which answer a positive or negative feedback refers to will not be helpful at all. [sent-133, score-0.908]
</p><p>53 In this section we describe how sentence dependency information is determined. [sent-134, score-0.499]
</p><p>54 Note that sentence dependency relations might not be a one-to-one relation. [sent-135, score-0.539]
</p><p>55 Dependency relationship could happen between many different types of sentences, for example, an-  swer(s) to question(s), problem clarification to question inquiry, feedback to solutions, etc. [sent-140, score-0.436]
</p><p>56 Instead of developing models for each dependency type, we treat them uniformly as dependency relations between sentences. [sent-141, score-0.5]
</p><p>57 For a pair of sentences, we call the depending sentence the source sentence, and the depended sentence the target sentence. [sent-145, score-0.79]
</p><p>58 As described earlier, one source sentence can potentially depend on many different target sentences, and one target sentence can also correspond to multiple sources. [sent-146, score-0.817]
</p><p>59 The sentence dependency task is formally defined as, given a set of sentences St of a thread, find the dependency relation {(s, t) |s ∈ St, t ∈ St}, where s idse tpheen source sentence a(ns,dt t) |iss t∈he S target sentence trhea st s depends on. [sent-147, score-1.643]
</p><p>60 From the data, we found given a source sentence, there is strong dependency between adjacent target sentences. [sent-150, score-0.553]
</p><p>61 If one sentence is a target sentence of the source, often the next sentence  is a target sentence too. [sent-151, score-1.266]
</p><p>62 In order to take advantage of such adjacent sentence dependency, we use the linear-chain CRFs for the sequence labeling. [sent-152, score-0.445]
</p><p>63 Features used in sentence dependency labeling are listed 558 in Table 3. [sent-153, score-0.583]
</p><p>64 Note that a lot of the node features used here are relative to the source sentence since the task here is to determine if the two sentences are related. [sent-154, score-0.599]
</p><p>65 For a thread of N sentences, we need to perform N runs of CRF labeling, one for each sentence (as the source sentence) in order to label the target sentence corresponding to this source sentence. [sent-155, score-1.099]
</p><p>66 * indicates an edge feature  Table 3: Features Used in Sentence Dependency Labeling The linear-chain CRFs can represent the dependency between adjacent target sentences quite well. [sent-165, score-0.673]
</p><p>67 However they cannot model the dependency between adjacent source sentences, because labeling is done for each source sentence individually. [sent-166, score-0.9]
</p><p>68 To model the dependency between both the source sentences and the target sentences, we propose to use 2D CRFs for sentence relation labeling. [sent-167, score-0.875]
</p><p>69 In the sentence relation task, the source and target pair is a 2D relation in which its label depends on labels of both its adjacent source and its adjacent target sentence. [sent-173, score-1.154]
</p><p>70 As shown in Figure 4, looking from x-axis is the sequence of target sentences with a fixed source sentence, and from yaxis is the sequence of source sentences with a fixed  ×  target sentence. [sent-174, score-0.702]
</p><p>71 We use the same edge features and node features as in linear-chain CRFs for node features and y-axis edge features in 2D CRFs. [sent-177, score-0.386]
</p><p>72 For the x-axis eXdge features, we use the same feature functions as for y-axis, except that now they represent the relation between adjacent source sentences. [sent-178, score-0.377]
</p><p>73 Two annotators were recruited to annotate the sentence type and the dependency relation between sentences. [sent-204, score-0.722]
</p><p>74 The distribution of sentence types in the annotated data is shown in Table 4, along with inter-annotator Kappa statistics calculated using 20 559 common threads annotated by both annotators. [sent-207, score-0.505]
</p><p>75 Note that we are only dealing with intrathread sentence dependency, that is, no dependency among sentences in different threads is labeled. [sent-211, score-0.758]
</p><p>76 Considering all the possible sentence pairs in each thread, the labeled dependency relations represent a small percentage. [sent-212, score-0.539]
</p><p>77 The relation of answering solutions and question dependency is also very common, as expected. [sent-217, score-0.739]
</p><p>78 Within each fold, first sentence types are labeled using linear-chain CRFs, then the resulting sentence type tagging is used in the second pass to determine dependency relations. [sent-222, score-1.173]
</p><p>79 In the sentence type tagging task, we calculate precision, recall, and F1 score for each individual tag. [sent-226, score-0.555]
</p><p>80 For the dependency tagging task, a pair identified by the system is correct only ifthe exact pair appears in the reference annotation. [sent-227, score-0.483]
</p><p>81 1 Sentence Type Tagging Results The results of sentence type tagging using linear-  chain CRFs are shown in Table 5. [sent-230, score-0.555]
</p><p>82 The observation probability is the probability of the sentence generated by a unigram language model, trained for different sentence types. [sent-233, score-0.538]
</p><p>83 Since for some applications, fine grained categories may not be needed, for example, in the case of finding questions and answers in a thread, we also include in the table the tagging results when only the general categories are used in both training and testing. [sent-234, score-0.922]
</p><p>84 2 Sentence Dependency Tagging Results Table 6 shows the results using linear-chain CRFs (L-CRF) and 2D CRFs for sentence dependency tag-  ging. [sent-262, score-0.499]
</p><p>85 For the categories of sentence types, we evaluate using both the fine grained (13 types) and the coarse categories (4 types). [sent-264, score-0.777]
</p><p>86 First, we use the output from automatic sentence type tagging. [sent-266, score-0.37]
</p><p>87 In the second one, we use the sentence type information from the human annotated data in order to avoid the error propagation from automatic sentence type labeling. [sent-267, score-0.785]
</p><p>88 This shows that by modeling the 2D dependency in source and target sentences, system performance is improved. [sent-276, score-0.414]
</p><p>89 For the sentence types, when using automatic sentence type tagging systems, there is a performance drop. [sent-277, score-0.824]
</p><p>90 The performance gap between using the reference and automatic sentence types suggests that there is still room for improvement from better sentence type tagging. [sent-278, score-0.723]
</p><p>91 Regarding the categories used for the sentence types, we observe that they have an impact on dependence tagging performance. [sent-279, score-0.553]
</p><p>92 For example, a dependency relation can be: “A-EXPL” (explanation for solutions) depends on “A-SOLU” (solutions); however, when using coarse categories, both are mapped to “Solution”, and having one “Solution” depending on another “Solution” is not very intuitive and hard to model properly. [sent-282, score-0.421]
</p><p>93 This shows that detailed category information is very important for dependency tagging even though the tagging accuracy from the  first pass is far from perfect. [sent-283, score-0.635]
</p><p>94 In the system output we find that sometimes there are obvious dependency errors, such as a positive feedback depending on a negative feedback. [sent-285, score-0.4]
</p><p>95 We may improve our models by taking into account different sentence types and dependency relations. [sent-286, score-0.583]
</p><p>96 561 6  Conclusion  In this paper, we investigated sentence dependency tagging of question and answer (QA) threads in online forums. [sent-287, score-1.297]
</p><p>97 We define the thread tagging task as a two-step process. [sent-288, score-0.438]
</p><p>98 We defined 13 sentence types in order to capture rich information of sentences to benefit question answering systems. [sent-290, score-0.81]
</p><p>99 Linear chain CRF is used for sentence type tagging. [sent-291, score-0.37]
</p><p>100 Using conditional random fields to extract contexts and answers of questions from online forums. [sent-323, score-0.49]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('crfs', 0.337), ('sentence', 0.269), ('thread', 0.253), ('dependency', 0.23), ('question', 0.218), ('answers', 0.192), ('tagging', 0.185), ('forums', 0.178), ('crf', 0.174), ('answer', 0.167), ('threads', 0.152), ('grained', 0.148), ('forum', 0.141), ('adjacent', 0.139), ('answering', 0.132), ('qa', 0.114), ('sentences', 0.107), ('ubuntu', 0.106), ('feedback', 0.103), ('graphical', 0.103), ('type', 0.101), ('categories', 0.099), ('post', 0.096), ('target', 0.095), ('fine', 0.09), ('source', 0.089), ('relation', 0.085), ('dialog', 0.084), ('types', 0.084), ('labeling', 0.084), ('online', 0.076), ('solutions', 0.074), ('questions', 0.074), ('coarse', 0.072), ('edge', 0.071), ('knowing', 0.068), ('conversations', 0.065), ('undirected', 0.063), ('cong', 0.063), ('da', 0.063), ('inquiry', 0.059), ('posts', 0.059), ('fields', 0.058), ('node', 0.054), ('boyer', 0.053), ('chinyew', 0.053), ('greeting', 0.053), ('shrestha', 0.053), ('act', 0.051), ('conditional', 0.051), ('cliques', 0.046), ('yaxis', 0.046), ('lot', 0.046), ('propagation', 0.045), ('technical', 0.045), ('hmm', 0.044), ('dialogue', 0.044), ('elizabeth', 0.042), ('feedbacks', 0.042), ('quattoni', 0.042), ('relations', 0.04), ('cosine', 0.04), ('exists', 0.04), ('conversational', 0.039), ('xk', 0.039), ('random', 0.039), ('users', 0.038), ('structure', 0.037), ('contain', 0.037), ('loopy', 0.037), ('minority', 0.037), ('annotators', 0.037), ('sequence', 0.037), ('ji', 0.036), ('exp', 0.036), ('email', 0.035), ('mallet', 0.035), ('statement', 0.035), ('description', 0.035), ('pass', 0.035), ('label', 0.035), ('finding', 0.035), ('features', 0.034), ('pair', 0.034), ('depending', 0.034), ('linux', 0.034), ('tagset', 0.034), ('solution', 0.033), ('positive', 0.033), ('functions', 0.033), ('presence', 0.033), ('hmms', 0.032), ('user', 0.032), ('latest', 0.031), ('happen', 0.031), ('perplexity', 0.031), ('feature', 0.031), ('unlike', 0.031), ('belief', 0.03), ('bag', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="177-tfidf-1" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>Author: Zhonghua Qu ; Yang Liu</p><p>Abstract: Online forums are becoming a popular resource in the state of the art question answering (QA) systems. Because of its nature as an online community, it contains more updated knowledge than other places. However, going through tedious and redundant posts to look for answers could be very time consuming. Most prior work focused on extracting only question answering sentences from user conversations. In this paper, we introduce the task of sentence dependency tagging. Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. Our experimental results show that our proposed approach performs well for sentence dependency tagging. This dependency information can benefit other tasks such as thread ranking and answer summarization in online forums.</p><p>2 0.31717315 <a title="177-tfidf-2" href="./acl-2012-Community_Answer_Summarization_for_Multi-Sentence_Question_with_Group_L1_Regularization.html">55 acl-2012-Community Answer Summarization for Multi-Sentence Question with Group L1 Regularization</a></p>
<p>Author: Wen Chan ; Xiangdong Zhou ; Wei Wang ; Tat-Seng Chua</p><p>Abstract: We present a novel answer summarization method for community Question Answering services (cQAs) to address the problem of “incomplete answer”, i.e., the “best answer” of a complex multi-sentence question misses valuable information that is contained in other answers. In order to automatically generate a novel and non-redundant community answer summary, we segment the complex original multi-sentence question into several sub questions and then propose a general Conditional Random Field (CRF) based answer summary method with group L1 regularization. Various textual and non-textual QA features are explored. Specifically, we explore four different types of contextual factors, namely, the information novelty and non-redundancy modeling for local and non-local sentence interactions under question segmentation. To further unleash the potential of the abundant cQA features, we introduce the group L1 regularization for feature learning. Experimental results on a Yahoo! Answers dataset show that our proposed method significantly outperforms state-of-the-art methods on cQA summarization task.</p><p>3 0.13657828 <a title="177-tfidf-3" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>Author: Hyun-Je Song ; Jeong-Woo Son ; Tae-Gil Noh ; Seong-Bae Park ; Sang-Jo Lee</p><p>Abstract: All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost to serious errors and a smaller one to minor errors. Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub- sequent NLP tasks.</p><p>4 0.11854956 <a title="177-tfidf-4" href="./acl-2012-A_Comparative_Study_of_Target_Dependency_Structures_for_Statistical_Machine_Translation.html">4 acl-2012-A Comparative Study of Target Dependency Structures for Statistical Machine Translation</a></p>
<p>Author: Xianchao Wu ; Katsuhito Sudoh ; Kevin Duh ; Hajime Tsukada ; Masaaki Nagata</p><p>Abstract: This paper presents a comparative study of target dependency structures yielded by several state-of-the-art linguistic parsers. Our approach is to measure the impact of these nonisomorphic dependency structures to be used for string-to-dependency translation. Besides using traditional dependency parsers, we also use the dependency structures transformed from PCFG trees and predicate-argument structures (PASs) which are generated by an HPSG parser and a CCG parser. The experiments on Chinese-to-English translation show that the HPSG parser’s PASs achieved the best dependency and translation accuracies. 1</p><p>5 0.1075419 <a title="177-tfidf-5" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Writing comments about news articles, blogs, or reviews have become a popular activity in social media. In this paper, we analyze reader comments about reviews. Analyzing review comments is important because reviews only tell the experiences and evaluations of reviewers about the reviewed products or services. Comments, on the other hand, are readers’ evaluations of reviews, their questions and concerns. Clearly, the information in comments is valuable for both future readers and brands. This paper proposes two latent variable models to simultaneously model and extract these key pieces of information. The results also enable classification of comments accurately. Experiments using Amazon review comments demonstrate the effectiveness of the proposed models.</p><p>6 0.10705487 <a title="177-tfidf-6" href="./acl-2012-Fast_Online_Training_with_Frequency-Adaptive_Learning_Rates_for_Chinese_Word_Segmentation_and_New_Word_Detection.html">94 acl-2012-Fast Online Training with Frequency-Adaptive Learning Rates for Chinese Word Segmentation and New Word Detection</a></p>
<p>7 0.102558 <a title="177-tfidf-7" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>8 0.10223936 <a title="177-tfidf-8" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>9 0.099331066 <a title="177-tfidf-9" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>10 0.095843084 <a title="177-tfidf-10" href="./acl-2012-Extracting_Narrative_Timelines_as_Temporal_Dependency_Structures.html">90 acl-2012-Extracting Narrative Timelines as Temporal Dependency Structures</a></p>
<p>11 0.095139399 <a title="177-tfidf-11" href="./acl-2012-Big_Data_versus_the_Crowd%3A_Looking_for_Relationships_in_All_the_Right_Places.html">40 acl-2012-Big Data versus the Crowd: Looking for Relationships in All the Right Places</a></p>
<p>12 0.094868906 <a title="177-tfidf-12" href="./acl-2012-Utilizing_Dependency_Language_Models_for_Graph-based_Dependency_Parsing_Models.html">213 acl-2012-Utilizing Dependency Language Models for Graph-based Dependency Parsing Models</a></p>
<p>13 0.094546549 <a title="177-tfidf-13" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>14 0.094441049 <a title="177-tfidf-14" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>15 0.093656875 <a title="177-tfidf-15" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>16 0.092517287 <a title="177-tfidf-16" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>17 0.090701796 <a title="177-tfidf-17" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>18 0.090176105 <a title="177-tfidf-18" href="./acl-2012-A_Comparison_of_Chinese_Parsers_for_Stanford_Dependencies.html">5 acl-2012-A Comparison of Chinese Parsers for Stanford Dependencies</a></p>
<p>19 0.089561537 <a title="177-tfidf-19" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>20 0.088392846 <a title="177-tfidf-20" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.27), (1, 0.099), (2, -0.079), (3, -0.043), (4, 0.042), (5, 0.066), (6, -0.03), (7, -0.068), (8, 0.041), (9, 0.014), (10, -0.013), (11, 0.085), (12, -0.057), (13, 0.052), (14, -0.0), (15, 0.177), (16, 0.07), (17, -0.097), (18, 0.175), (19, -0.119), (20, 0.211), (21, 0.046), (22, 0.037), (23, -0.061), (24, -0.079), (25, -0.126), (26, -0.203), (27, -0.156), (28, -0.104), (29, 0.082), (30, -0.032), (31, -0.122), (32, 0.04), (33, 0.095), (34, 0.058), (35, 0.074), (36, 0.097), (37, -0.074), (38, 0.108), (39, -0.121), (40, -0.152), (41, -0.098), (42, 0.033), (43, 0.163), (44, -0.05), (45, -0.085), (46, 0.042), (47, 0.045), (48, 0.003), (49, 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97300482 <a title="177-lsi-1" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>Author: Zhonghua Qu ; Yang Liu</p><p>Abstract: Online forums are becoming a popular resource in the state of the art question answering (QA) systems. Because of its nature as an online community, it contains more updated knowledge than other places. However, going through tedious and redundant posts to look for answers could be very time consuming. Most prior work focused on extracting only question answering sentences from user conversations. In this paper, we introduce the task of sentence dependency tagging. Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. Our experimental results show that our proposed approach performs well for sentence dependency tagging. This dependency information can benefit other tasks such as thread ranking and answer summarization in online forums.</p><p>2 0.89007497 <a title="177-lsi-2" href="./acl-2012-Community_Answer_Summarization_for_Multi-Sentence_Question_with_Group_L1_Regularization.html">55 acl-2012-Community Answer Summarization for Multi-Sentence Question with Group L1 Regularization</a></p>
<p>Author: Wen Chan ; Xiangdong Zhou ; Wei Wang ; Tat-Seng Chua</p><p>Abstract: We present a novel answer summarization method for community Question Answering services (cQAs) to address the problem of “incomplete answer”, i.e., the “best answer” of a complex multi-sentence question misses valuable information that is contained in other answers. In order to automatically generate a novel and non-redundant community answer summary, we segment the complex original multi-sentence question into several sub questions and then propose a general Conditional Random Field (CRF) based answer summary method with group L1 regularization. Various textual and non-textual QA features are explored. Specifically, we explore four different types of contextual factors, namely, the information novelty and non-redundancy modeling for local and non-local sentence interactions under question segmentation. To further unleash the potential of the abundant cQA features, we introduce the group L1 regularization for feature learning. Experimental results on a Yahoo! Answers dataset show that our proposed method significantly outperforms state-of-the-art methods on cQA summarization task.</p><p>3 0.58486897 <a title="177-lsi-3" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>Author: Xiaobing Xue ; Yu Tao ; Daxin Jiang ; Hang Li</p><p>Abstract: Natural language questions have become popular in web search. However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems. In this paper, we automatically mined 5w1h question reformulation patterns from large scale search log data. The question reformulations generated from these patterns are further incorporated into the retrieval model. Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.</p><p>4 0.52411079 <a title="177-lsi-4" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>Author: Geoffrey Zweig ; John C. Platt ; Christopher Meek ; Christopher J.C. Burges ; Ainur Yessenalina ; Qiang Liu</p><p>Abstract: This paper studies the problem of sentencelevel semantic coherence by answering SATstyle sentence completion questions. These questions test the ability of algorithms to distinguish sense from nonsense based on a variety of sentence-level phenomena. We tackle the problem with two approaches: methods that use local lexical information, such as the n-grams of a classical language model; and methods that evaluate global coherence, such as latent semantic analysis. We evaluate these methods on a suite of practice SAT questions, and on a recently released sentence completion task based on data taken from five Conan Doyle novels. We find that by fusing local and global information, we can exceed 50% on this task (chance baseline is 20%), and we suggest some avenues for further research.</p><p>5 0.50733483 <a title="177-lsi-5" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Writing comments about news articles, blogs, or reviews have become a popular activity in social media. In this paper, we analyze reader comments about reviews. Analyzing review comments is important because reviews only tell the experiences and evaluations of reviewers about the reviewed products or services. Comments, on the other hand, are readers’ evaluations of reviews, their questions and concerns. Clearly, the information in comments is valuable for both future readers and brands. This paper proposes two latent variable models to simultaneously model and extract these key pieces of information. The results also enable classification of comments accurately. Experiments using Amazon review comments demonstrate the effectiveness of the proposed models.</p><p>6 0.44403592 <a title="177-lsi-6" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>7 0.42370847 <a title="177-lsi-7" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>8 0.40966415 <a title="177-lsi-8" href="./acl-2012-A_Comparative_Study_of_Target_Dependency_Structures_for_Statistical_Machine_Translation.html">4 acl-2012-A Comparative Study of Target Dependency Structures for Statistical Machine Translation</a></p>
<p>9 0.38512632 <a title="177-lsi-9" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>10 0.38287702 <a title="177-lsi-10" href="./acl-2012-Utilizing_Dependency_Language_Models_for_Graph-based_Dependency_Parsing_Models.html">213 acl-2012-Utilizing Dependency Language Models for Graph-based Dependency Parsing Models</a></p>
<p>11 0.37489229 <a title="177-lsi-11" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>12 0.37305892 <a title="177-lsi-12" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<p>13 0.37145048 <a title="177-lsi-13" href="./acl-2012-A_Two-step_Approach_to_Sentence_Compression_of_Spoken_Utterances.html">23 acl-2012-A Two-step Approach to Sentence Compression of Spoken Utterances</a></p>
<p>14 0.35810494 <a title="177-lsi-14" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>15 0.3550728 <a title="177-lsi-15" href="./acl-2012-Fast_Online_Training_with_Frequency-Adaptive_Learning_Rates_for_Chinese_Word_Segmentation_and_New_Word_Detection.html">94 acl-2012-Fast Online Training with Frequency-Adaptive Learning Rates for Chinese Word Segmentation and New Word Detection</a></p>
<p>16 0.3511326 <a title="177-lsi-16" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>17 0.34888834 <a title="177-lsi-17" href="./acl-2012-Humor_as_Circuits_in_Semantic_Networks.html">112 acl-2012-Humor as Circuits in Semantic Networks</a></p>
<p>18 0.34794649 <a title="177-lsi-18" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>19 0.3428103 <a title="177-lsi-19" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<p>20 0.34233832 <a title="177-lsi-20" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(26, 0.025), (28, 0.021), (30, 0.02), (37, 0.017), (39, 0.039), (74, 0.019), (82, 0.015), (84, 0.011), (85, 0.023), (90, 0.631), (92, 0.032), (94, 0.017), (99, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99938536 <a title="177-lda-1" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>Author: Zhonghua Qu ; Yang Liu</p><p>Abstract: Online forums are becoming a popular resource in the state of the art question answering (QA) systems. Because of its nature as an online community, it contains more updated knowledge than other places. However, going through tedious and redundant posts to look for answers could be very time consuming. Most prior work focused on extracting only question answering sentences from user conversations. In this paper, we introduce the task of sentence dependency tagging. Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. Our experimental results show that our proposed approach performs well for sentence dependency tagging. This dependency information can benefit other tasks such as thread ranking and answer summarization in online forums.</p><p>2 0.9979468 <a title="177-lda-2" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>Author: Kuzman Ganchev ; Keith Hall ; Ryan McDonald ; Slav Petrov</p><p>Abstract: Syntactic analysis of search queries is important for a variety of information-retrieval tasks; however, the lack of annotated data makes training query analysis models difficult. We propose a simple, efficient procedure in which part-of-speech tags are transferred from retrieval-result snippets to queries at training time. Unlike previous work, our final model does not require any additional resources at run-time. Compared to a state-ofthe-art approach, we achieve more than 20% relative error reduction. Additionally, we annotate a corpus of search queries with partof-speech tags, providing a resource for future work on syntactic query analysis.</p><p>3 0.99770337 <a title="177-lda-3" href="./acl-2012-Automatic_Event_Extraction_with_Structured_Preference_Modeling.html">33 acl-2012-Automatic Event Extraction with Structured Preference Modeling</a></p>
<p>Author: Wei Lu ; Dan Roth</p><p>Abstract: This paper presents a novel sequence labeling model based on the latent-variable semiMarkov conditional random fields for jointly extracting argument roles of events from texts. The model takes in coarse mention and type information and predicts argument roles for a given event template. This paper addresses the event extraction problem in a primarily unsupervised setting, where no labeled training instances are available. Our key contribution is a novel learning framework called structured preference modeling (PM), that allows arbitrary preference to be assigned to certain structures during the learning procedure. We establish and discuss connections between this framework and other existing works. We show empirically that the structured preferences are crucial to the success of our task. Our model, trained without annotated data and with a small number of structured preferences, yields performance competitive to some baseline supervised approaches.</p><p>4 0.99709535 <a title="177-lda-4" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>Author: Majid Razmara ; George Foster ; Baskaran Sankaran ; Anoop Sarkar</p><p>Abstract: Statistical machine translation is often faced with the problem of combining training data from many diverse sources into a single translation model which then has to translate sentences in a new domain. We propose a novel approach, ensemble decoding, which combines a number of translation systems dynamically at the decoding step. In this paper, we evaluate performance on a domain adaptation setting where we translate sentences from the medical domain. Our experimental results show that ensemble decoding outperforms various strong baselines including mixture models, the current state-of-the-art for domain adaptation in machine translation.</p><p>5 0.99380374 <a title="177-lda-5" href="./acl-2012-A_Broad-Coverage_Normalization_System_for_Social_Media_Language.html">2 acl-2012-A Broad-Coverage Normalization System for Social Media Language</a></p>
<p>Author: Fei Liu ; Fuliang Weng ; Xiao Jiang</p><p>Abstract: Social media language contains huge amount and wide variety of nonstandard tokens, created both intentionally and unintentionally by the users. It is of crucial importance to normalize the noisy nonstandard tokens before applying other NLP techniques. A major challenge facing this task is the system coverage, i.e., for any user-created nonstandard term, the system should be able to restore the correct word within its top n output candidates. In this paper, we propose a cognitivelydriven normalization system that integrates different human perspectives in normalizing the nonstandard tokens, including the enhanced letter transformation, visual priming, and string/phonetic similarity. The system was evaluated on both word- and messagelevel using four SMS and Twitter data sets. Results show that our system achieves over 90% word-coverage across all data sets (a . 10% absolute increase compared to state-ofthe-art); the broad word-coverage can also successfully translate into message-level performance gain, yielding 6% absolute increase compared to the best prior approach.</p><p>6 0.97032547 <a title="177-lda-6" href="./acl-2012-A_Two-step_Approach_to_Sentence_Compression_of_Spoken_Utterances.html">23 acl-2012-A Two-step Approach to Sentence Compression of Spoken Utterances</a></p>
<p>7 0.96713722 <a title="177-lda-7" href="./acl-2012-Word_Epoch_Disambiguation%3A_Finding_How_Words_Change_Over_Time.html">216 acl-2012-Word Epoch Disambiguation: Finding How Words Change Over Time</a></p>
<p>8 0.95700008 <a title="177-lda-8" href="./acl-2012-Learning_Translation_Consensus_with_Structured_Label_Propagation.html">131 acl-2012-Learning Translation Consensus with Structured Label Propagation</a></p>
<p>9 0.95581675 <a title="177-lda-9" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>10 0.95316702 <a title="177-lda-10" href="./acl-2012-Community_Answer_Summarization_for_Multi-Sentence_Question_with_Group_L1_Regularization.html">55 acl-2012-Community Answer Summarization for Multi-Sentence Question with Group L1 Regularization</a></p>
<p>11 0.95090944 <a title="177-lda-11" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>12 0.94861853 <a title="177-lda-12" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>13 0.94772959 <a title="177-lda-13" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>14 0.947142 <a title="177-lda-14" href="./acl-2012-Selective_Sharing_for_Multilingual_Dependency_Parsing.html">172 acl-2012-Selective Sharing for Multilingual Dependency Parsing</a></p>
<p>15 0.946558 <a title="177-lda-15" href="./acl-2012-Utilizing_Dependency_Language_Models_for_Graph-based_Dependency_Parsing_Models.html">213 acl-2012-Utilizing Dependency Language Models for Graph-based Dependency Parsing Models</a></p>
<p>16 0.93449736 <a title="177-lda-16" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>17 0.93382329 <a title="177-lda-17" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>18 0.93326426 <a title="177-lda-18" href="./acl-2012-A_Statistical_Model_for_Unsupervised_and_Semi-supervised_Transliteration_Mining.html">20 acl-2012-A Statistical Model for Unsupervised and Semi-supervised Transliteration Mining</a></p>
<p>19 0.93016213 <a title="177-lda-19" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>20 0.92590213 <a title="177-lda-20" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
